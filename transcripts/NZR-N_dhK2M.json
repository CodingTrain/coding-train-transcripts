{
  "id": "2fmjjjbbzslqxdlasc6hjmp27a",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/NZR-N_dhK2M.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/431503 [00:00<?, ?frames/s]\n  1%|          | 2900/431503 [00:04<10:40, 668.75frames/s]\n  1%|          | 5260/431503 [00:11<15:59, 444.43frames/s]\n  2%|▏         | 8152/431503 [00:18<16:49, 419.55frames/s]\n  3%|▎         | 10932/431503 [00:25<17:28, 400.95frames/s]\n  3%|▎         | 13464/431503 [00:34<19:11, 363.20frames/s]\n  4%|▍         | 16384/431503 [00:42<19:39, 351.96frames/s]\n  4%|▍         | 19240/431503 [00:50<19:11, 358.04frames/s]\n  5%|▌         | 21948/431503 [00:55<17:10, 397.41frames/s]\n  6%|▌         | 24640/431503 [01:01<16:12, 418.31frames/s]\n  6%|▋         | 27328/431503 [01:06<15:17, 440.70frames/s]\n  7%|▋         | 30262/431503 [01:13<15:02, 444.57frames/s]\n  8%|▊         | 32906/431503 [01:18<14:29, 458.17frames/s]\n  8%|▊         | 35750/431503 [01:26<15:55, 414.08frames/s]\n  8%|▊         | 36282/431503 [01:29<16:55, 389.36frames/s]\n  9%|▉         | 39010/431503 [01:30<12:02, 542.93frames/s]\n 10%|▉         | 41750/431503 [01:35<11:21, 571.53frames/s]\n 10%|█         | 44414/431503 [01:40<11:58, 538.87frames/s]\n 11%|█         | 47242/431503 [01:47<13:10, 486.01frames/s]\n 12%|█▏        | 49854/431503 [01:56<15:32, 409.27frames/s]\n 12%|█▏        | 52714/431503 [02:02<15:08, 417.09frames/s]\n 13%|█▎        | 55714/431503 [02:08<14:11, 441.54frames/s]\n 14%|█▎        | 58610/431503 [02:15<13:53, 447.14frames/s]\n 14%|█▍        | 61610/431503 [02:21<13:40, 450.86frames/s]\n 15%|█▍        | 64294/431503 [02:26<12:57, 472.27frames/s]\n 16%|█▌        | 67034/431503 [02:31<12:07, 500.77frames/s]\n 16%|█▌        | 69910/431503 [02:36<11:49, 509.83frames/s]\n 17%|█▋        | 72894/431503 [02:44<13:08, 454.52frames/s]\n 18%|█▊        | 75670/431503 [02:52<14:03, 421.81frames/s]\n 18%|█▊        | 78282/431503 [03:00<14:47, 397.84frames/s]\n 19%|█▉        | 81182/431503 [03:09<15:45, 370.69frames/s]\n 19%|█▉        | 83962/431503 [03:13<13:49, 418.94frames/s]\n 20%|██        | 86806/431503 [03:17<11:59, 479.22frames/s]\n 21%|██        | 89574/431503 [03:24<12:36, 451.81frames/s]\n 21%|██▏       | 92574/431503 [03:30<11:52, 475.60frames/s]\n 22%|██▏       | 95390/431503 [03:36<11:50, 472.88frames/s]\n 23%|██▎       | 98126/431503 [03:42<11:49, 469.80frames/s]\n 23%|██▎       | 100806/431503 [03:49<12:26, 443.19frames/s]\n 24%|██▍       | 103806/431503 [03:56<12:53, 423.91frames/s]\n 25%|██▍       | 106806/431503 [04:03<12:41, 426.61frames/s]\n 25%|██▌       | 109674/431503 [04:06<10:34, 507.47frames/s]\n 26%|██▌       | 112670/431503 [04:13<10:51, 489.01frames/s]\n 27%|██▋       | 115318/431503 [04:20<11:33, 456.09frames/s]\n 27%|██▋       | 118234/431503 [04:29<13:04, 399.33frames/s]\n 28%|██▊       | 121186/431503 [04:37<13:06, 394.34frames/s]\n 29%|██▊       | 123902/431503 [04:42<12:13, 419.46frames/s]\n 29%|██▉       | 126902/431503 [04:49<11:43, 432.96frames/s]\n 30%|███       | 129742/431503 [04:58<13:10, 381.51frames/s]\n 31%|███       | 132554/431503 [05:07<13:49, 360.27frames/s]\n 31%|███▏      | 135542/431503 [05:15<13:30, 365.15frames/s]\n 32%|███▏      | 138382/431503 [05:23<13:12, 369.86frames/s]\n 33%|███▎      | 141146/431503 [05:29<12:24, 390.19frames/s]\n 33%|███▎      | 144030/431503 [05:38<13:04, 366.28frames/s]\n 34%|███▍      | 146904/431503 [05:45<12:45, 371.87frames/s]\n 35%|███▍      | 149754/431503 [05:53<12:52, 364.83frames/s]\n 35%|███▌      | 152632/431503 [05:59<11:42, 397.19frames/s]\n 36%|███▌      | 155312/431503 [06:07<12:00, 383.52frames/s]\n 37%|███▋      | 158240/431503 [06:16<12:49, 354.98frames/s]\n 37%|███▋      | 161200/431503 [06:26<13:16, 339.26frames/s]\n 38%|███▊      | 164144/431503 [06:35<13:32, 329.06frames/s]\n 39%|███▊      | 166970/431503 [06:43<13:00, 338.86frames/s]\n 39%|███▉      | 169806/431503 [06:51<12:35, 346.21frames/s]\n 40%|███▉      | 172402/431503 [06:58<12:05, 357.14frames/s]\n 41%|████      | 174894/431503 [07:02<10:52, 393.14frames/s]\n 41%|████      | 177894/431503 [07:10<10:38, 397.16frames/s]\n 42%|████▏     | 180730/431503 [07:18<10:52, 384.20frames/s]\n 43%|████▎     | 183526/431503 [07:26<11:07, 371.55frames/s]\n 43%|████▎     | 186446/431503 [07:36<12:04, 338.19frames/s]\n 44%|████▍     | 189090/431503 [07:44<11:59, 337.05frames/s]\n 44%|████▍     | 191902/431503 [07:53<12:08, 329.12frames/s]\n 45%|████▍     | 193910/431503 [07:59<12:10, 325.13frames/s]\n 46%|████▌     | 196654/431503 [08:05<10:56, 357.95frames/s]\n 46%|████▋     | 199574/431503 [08:15<11:35, 333.37frames/s]\n 47%|████▋     | 202538/431503 [08:25<11:47, 323.67frames/s]\n 48%|████▊     | 205526/431503 [08:33<11:05, 339.73frames/s]\n 48%|████▊     | 208462/431503 [08:42<11:07, 334.24frames/s]\n 49%|████▉     | 211446/431503 [08:48<09:53, 370.63frames/s]\n 50%|████▉     | 214318/431503 [08:56<09:37, 375.99frames/s]\n 50%|█████     | 217106/431503 [09:01<08:56, 399.99frames/s]\n 51%|█████     | 219998/431503 [09:06<07:46, 453.39frames/s]\n 51%|█████▏    | 222222/431503 [09:10<07:17, 478.56frames/s]\n 52%|█████▏    | 225190/431503 [09:16<07:10, 479.45frames/s]\n 53%|█████▎    | 228022/431503 [09:23<07:28, 454.05frames/s]\n 54%|█████▎    | 231022/431503 [09:27<06:31, 512.16frames/s]\n 54%|█████▍    | 233930/431503 [09:34<06:57, 472.74frames/s]\n 55%|█████▍    | 236694/431503 [09:43<07:42, 420.77frames/s]\n 56%|█████▌    | 239662/431503 [09:50<07:37, 419.54frames/s]\n 56%|█████▌    | 242614/431503 [10:00<08:36, 365.49frames/s]\n 57%|█████▋    | 245434/431503 [10:09<08:52, 349.20frames/s]\n 58%|█████▊    | 248206/431503 [10:15<07:57, 383.73frames/s]\n 58%|█████▊    | 250766/431503 [10:22<08:06, 371.33frames/s]\n 59%|█████▉    | 253548/431503 [10:28<07:23, 401.36frames/s]\n 59%|█████▉    | 256476/431503 [10:35<07:21, 396.45frames/s]\n 60%|██████    | 259400/431503 [10:42<07:08, 401.34frames/s]\n 61%|██████    | 262384/431503 [10:49<06:50, 411.62frames/s]\n 61%|██████▏   | 264772/431503 [10:55<06:43, 413.63frames/s]\n 62%|██████▏   | 267700/431503 [11:02<06:39, 410.45frames/s]\n 63%|██████▎   | 270344/431503 [11:11<07:15, 370.25frames/s]\n 63%|██████▎   | 272924/431503 [11:18<07:09, 368.80frames/s]\n 64%|██████▍   | 275620/431503 [11:25<06:58, 372.13frames/s]\n 65%|██████▍   | 278432/431503 [11:29<05:43, 445.57frames/s]\n 65%|██████▌   | 281356/431503 [11:37<06:02, 414.26frames/s]\n 66%|██████▌   | 284216/431503 [11:43<05:43, 429.34frames/s]\n 67%|██████▋   | 287164/431503 [11:52<06:12, 387.43frames/s]\n 67%|██████▋   | 289960/431503 [12:02<06:39, 353.88frames/s]\n 68%|██████▊   | 291744/431503 [12:05<06:08, 378.92frames/s]\n 68%|██████▊   | 294436/431503 [12:11<05:39, 404.29frames/s]\n 69%|██████▉   | 296928/431503 [12:17<05:34, 401.87frames/s]\n 69%|██████▉   | 299688/431503 [12:24<05:29, 399.76frames/s]\n 70%|███████   | 302672/431503 [12:34<05:51, 366.59frames/s]\n 71%|███████   | 305460/431503 [12:41<05:39, 371.68frames/s]\n 71%|███████▏  | 308460/431503 [12:49<05:25, 377.67frames/s]\n 72%|███████▏  | 311460/431503 [12:56<05:04, 393.99frames/s]\n 73%|███████▎  | 314096/431503 [13:00<04:34, 427.62frames/s]\n 73%|███████▎  | 316984/431503 [13:06<04:09, 459.49frames/s]\n 74%|███████▍  | 319632/431503 [13:13<04:28, 416.38frames/s]\n 75%|███████▍  | 322540/431503 [13:19<04:01, 451.31frames/s]\n 75%|███████▌  | 325432/431503 [13:27<04:20, 407.04frames/s]\n 76%|███████▌  | 328300/431503 [13:34<04:07, 417.27frames/s]\n 77%|███████▋  | 331224/431503 [13:41<03:56, 423.71frames/s]\n 77%|███████▋  | 334004/431503 [13:46<03:41, 439.90frames/s]\n 78%|███████▊  | 336920/431503 [13:54<03:43, 422.75frames/s]\n 79%|███████▊  | 339528/431503 [13:58<03:19, 459.92frames/s]\n 79%|███████▉  | 342348/431503 [14:05<03:23, 437.24frames/s]\n 80%|███████▉  | 345010/431503 [14:12<03:21, 429.21frames/s]\n 81%|████████  | 348010/431503 [14:21<03:34, 389.19frames/s]\n 81%|████████▏ | 350786/431503 [14:28<03:21, 400.42frames/s]\n 82%|████████▏ | 353494/431503 [14:31<02:48, 462.82frames/s]\n 83%|████████▎ | 356282/431503 [14:36<02:33, 488.96frames/s]\n 83%|████████▎ | 359066/431503 [14:42<02:31, 477.44frames/s]\n 84%|████████▍ | 361986/431503 [14:49<02:30, 460.82frames/s]\n 85%|████████▍ | 364874/431503 [14:57<02:33, 434.02frames/s]\n 85%|████████▌ | 367506/431503 [15:04<02:35, 411.22frames/s]\n 86%|████████▌ | 370258/431503 [15:10<02:25, 421.52frames/s]\n 86%|████████▋ | 373154/431503 [15:21<02:42, 358.73frames/s]\n 87%|████████▋ | 375970/431503 [15:26<02:21, 392.67frames/s]\n 88%|████████▊ | 378690/431503 [15:35<02:25, 363.67frames/s]\n 88%|████████▊ | 381650/431503 [15:43<02:13, 373.40frames/s]\n 89%|████████▉ | 384326/431503 [15:49<02:01, 389.10frames/s]\n 90%|████████▉ | 387218/431503 [15:56<01:50, 400.04frames/s]\n 90%|█████████ | 390106/431503 [16:05<01:53, 364.01frames/s]\n 91%|█████████ | 392910/431503 [16:14<01:51, 345.64frames/s]\n 92%|█████████▏| 395386/431503 [16:24<01:55, 311.96frames/s]\n 92%|█████████▏| 398322/431503 [16:31<01:37, 340.98frames/s]\n 93%|█████████▎| 401118/431503 [16:39<01:26, 350.70frames/s]\n 94%|█████████▎| 404030/431503 [16:45<01:13, 372.49frames/s]\n 94%|█████████▍| 407030/431503 [16:54<01:06, 368.80frames/s]\n 95%|█████████▌| 409982/431503 [16:59<00:53, 404.23frames/s]\n 96%|█████████▌| 412926/431503 [17:07<00:46, 399.75frames/s]\n 96%|█████████▋| 415898/431503 [17:16<00:41, 372.35frames/s]\n 97%|█████████▋| 418894/431503 [17:24<00:33, 373.90frames/s]\n 98%|█████████▊| 421566/431503 [17:32<00:27, 362.35frames/s]\n 98%|█████████▊| 424454/431503 [17:42<00:20, 341.42frames/s]\n 99%|█████████▉| 427338/431503 [17:49<00:11, 350.52frames/s]\n100%|█████████▉| 430338/431503 [17:59<00:03, 332.20frames/s]\n100%|██████████| 431503/431503 [18:00<00:00, 373.74frames/s]\n100%|██████████| 431503/431503 [18:00<00:00, 399.26frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.27688211108010913,
        "compression_ratio": 1.4012345679012346,
        "end": 20.28,
        "id": 0,
        "no_speech_prob": 0.01262062881141901,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " My event has started, which means that it is me, Dan Shiffman, coming to you again for",
        "tokens": [
          50364,
          1222,
          2280,
          575,
          1409,
          11,
          597,
          1355,
          300,
          309,
          307,
          385,
          11,
          3394,
          1160,
          3661,
          1601,
          11,
          1348,
          281,
          291,
          797,
          337,
          51378
        ]
      },
      {
        "avg_logprob": -0.27688211108010913,
        "compression_ratio": 1.4012345679012346,
        "end": 24.64,
        "id": 1,
        "no_speech_prob": 0.01262062881141901,
        "seek": 0,
        "start": 20.28,
        "temperature": 0,
        "text": " the second time today, for the third time in two days.",
        "tokens": [
          51378,
          264,
          1150,
          565,
          965,
          11,
          337,
          264,
          2636,
          565,
          294,
          732,
          1708,
          13,
          51596
        ]
      },
      {
        "avg_logprob": -0.27688211108010913,
        "compression_ratio": 1.4012345679012346,
        "end": 29,
        "id": 2,
        "no_speech_prob": 0.01262062881141901,
        "seek": 0,
        "start": 24.64,
        "temperature": 0,
        "text": " This is probably really not so advisable, there's a lot of reasons why I shouldn't be",
        "tokens": [
          51596,
          639,
          307,
          1391,
          534,
          406,
          370,
          10280,
          712,
          11,
          456,
          311,
          257,
          688,
          295,
          4112,
          983,
          286,
          4659,
          380,
          312,
          51814
        ]
      },
      {
        "avg_logprob": -0.34414598779770933,
        "compression_ratio": 1.5868544600938967,
        "end": 30.88,
        "id": 3,
        "no_speech_prob": 0.0019267078023403883,
        "seek": 2900,
        "start": 29.6,
        "temperature": 0,
        "text": " here, but I am here.",
        "tokens": [
          50394,
          510,
          11,
          457,
          286,
          669,
          510,
          13,
          50458
        ]
      },
      {
        "avg_logprob": -0.34414598779770933,
        "compression_ratio": 1.5868544600938967,
        "end": 35.52,
        "id": 4,
        "no_speech_prob": 0.0019267078023403883,
        "seek": 2900,
        "start": 30.88,
        "temperature": 0,
        "text": " And I am going to, I have about one hour, so I'm really going to jump right in.",
        "tokens": [
          50458,
          400,
          286,
          669,
          516,
          281,
          11,
          286,
          362,
          466,
          472,
          1773,
          11,
          370,
          286,
          478,
          534,
          516,
          281,
          3012,
          558,
          294,
          13,
          50690
        ]
      },
      {
        "avg_logprob": -0.34414598779770933,
        "compression_ratio": 1.5868544600938967,
        "end": 39.84,
        "id": 5,
        "no_speech_prob": 0.0019267078023403883,
        "seek": 2900,
        "start": 35.52,
        "temperature": 0,
        "text": " I have, I think I might actually even call this, dare I say, a coding challenge.",
        "tokens": [
          50690,
          286,
          362,
          11,
          286,
          519,
          286,
          1062,
          767,
          754,
          818,
          341,
          11,
          8955,
          286,
          584,
          11,
          257,
          17720,
          3430,
          13,
          50906
        ]
      },
      {
        "avg_logprob": -0.34414598779770933,
        "compression_ratio": 1.5868544600938967,
        "end": 42.4,
        "id": 6,
        "no_speech_prob": 0.0019267078023403883,
        "seek": 2900,
        "start": 39.84,
        "temperature": 0,
        "text": " The thing about this, it's okay.",
        "tokens": [
          50906,
          440,
          551,
          466,
          341,
          11,
          309,
          311,
          1392,
          13,
          51034
        ]
      },
      {
        "avg_logprob": -0.34414598779770933,
        "compression_ratio": 1.5868544600938967,
        "end": 46.2,
        "id": 7,
        "no_speech_prob": 0.0019267078023403883,
        "seek": 2900,
        "start": 42.4,
        "temperature": 0,
        "text": " I don't, this is not the important thing to talk about.",
        "tokens": [
          51034,
          286,
          500,
          380,
          11,
          341,
          307,
          406,
          264,
          1021,
          551,
          281,
          751,
          466,
          13,
          51224
        ]
      },
      {
        "avg_logprob": -0.34414598779770933,
        "compression_ratio": 1.5868544600938967,
        "end": 49.6,
        "id": 8,
        "no_speech_prob": 0.0019267078023403883,
        "seek": 2900,
        "start": 46.2,
        "temperature": 0,
        "text": " This is the topic for today.",
        "tokens": [
          51224,
          639,
          307,
          264,
          4829,
          337,
          965,
          13,
          51394
        ]
      },
      {
        "avg_logprob": -0.34414598779770933,
        "compression_ratio": 1.5868544600938967,
        "end": 52.6,
        "id": 9,
        "no_speech_prob": 0.0019267078023403883,
        "seek": 2900,
        "start": 49.6,
        "temperature": 0,
        "text": " Linear regression using TensorFlow.js.",
        "tokens": [
          51394,
          14670,
          289,
          24590,
          1228,
          37624,
          13,
          25530,
          13,
          51544
        ]
      },
      {
        "avg_logprob": -0.2720690987326882,
        "compression_ratio": 1.5992779783393503,
        "end": 58.92,
        "id": 10,
        "no_speech_prob": 0.024797169491648674,
        "seek": 5260,
        "start": 52.6,
        "temperature": 0,
        "text": " Now before you all start going and running away, which would be completely understandable,",
        "tokens": [
          50364,
          823,
          949,
          291,
          439,
          722,
          516,
          293,
          2614,
          1314,
          11,
          597,
          576,
          312,
          2584,
          25648,
          11,
          50680
        ]
      },
      {
        "avg_logprob": -0.2720690987326882,
        "compression_ratio": 1.5992779783393503,
        "end": 62.56,
        "id": 11,
        "no_speech_prob": 0.024797169491648674,
        "seek": 5260,
        "start": 58.92,
        "temperature": 0,
        "text": " I'm really doing this for a couple of reasons.",
        "tokens": [
          50680,
          286,
          478,
          534,
          884,
          341,
          337,
          257,
          1916,
          295,
          4112,
          13,
          50862
        ]
      },
      {
        "avg_logprob": -0.2720690987326882,
        "compression_ratio": 1.5992779783393503,
        "end": 67.84,
        "id": 12,
        "no_speech_prob": 0.024797169491648674,
        "seek": 5260,
        "start": 62.56,
        "temperature": 0,
        "text": " Number one is I have started a series of TensorFlow.js tutorials, just looking at some of the basic",
        "tokens": [
          50862,
          5118,
          472,
          307,
          286,
          362,
          1409,
          257,
          2638,
          295,
          37624,
          13,
          25530,
          17616,
          11,
          445,
          1237,
          412,
          512,
          295,
          264,
          3875,
          51126
        ]
      },
      {
        "avg_logprob": -0.2720690987326882,
        "compression_ratio": 1.5992779783393503,
        "end": 69.52000000000001,
        "id": 13,
        "no_speech_prob": 0.024797169491648674,
        "seek": 5260,
        "start": 67.84,
        "temperature": 0,
        "text": " features of the API.",
        "tokens": [
          51126,
          4122,
          295,
          264,
          9362,
          13,
          51210
        ]
      },
      {
        "avg_logprob": -0.2720690987326882,
        "compression_ratio": 1.5992779783393503,
        "end": 74,
        "id": 14,
        "no_speech_prob": 0.024797169491648674,
        "seek": 5260,
        "start": 69.52000000000001,
        "temperature": 0,
        "text": " And I want to at least get into an example where we're actually using this stuff for",
        "tokens": [
          51210,
          400,
          286,
          528,
          281,
          412,
          1935,
          483,
          666,
          364,
          1365,
          689,
          321,
          434,
          767,
          1228,
          341,
          1507,
          337,
          51434
        ]
      },
      {
        "avg_logprob": -0.2720690987326882,
        "compression_ratio": 1.5992779783393503,
        "end": 75.36,
        "id": 15,
        "no_speech_prob": 0.024797169491648674,
        "seek": 5260,
        "start": 74,
        "temperature": 0,
        "text": " some purpose.",
        "tokens": [
          51434,
          512,
          4334,
          13,
          51502
        ]
      },
      {
        "avg_logprob": -0.2720690987326882,
        "compression_ratio": 1.5992779783393503,
        "end": 81.52000000000001,
        "id": 16,
        "no_speech_prob": 0.024797169491648674,
        "seek": 5260,
        "start": 75.36,
        "temperature": 0,
        "text": " Now, what kind of, you know, this is really foundational knowledge, it's kind of like",
        "tokens": [
          51502,
          823,
          11,
          437,
          733,
          295,
          11,
          291,
          458,
          11,
          341,
          307,
          534,
          32195,
          3601,
          11,
          309,
          311,
          733,
          295,
          411,
          51810
        ]
      },
      {
        "avg_logprob": -0.2925477684090991,
        "compression_ratio": 1.6130268199233717,
        "end": 85.2,
        "id": 17,
        "no_speech_prob": 0.018263204023241997,
        "seek": 8152,
        "start": 81.52,
        "temperature": 0,
        "text": " a classic example of like the beginning stages of machine learning.",
        "tokens": [
          50364,
          257,
          7230,
          1365,
          295,
          411,
          264,
          2863,
          10232,
          295,
          3479,
          2539,
          13,
          50548
        ]
      },
      {
        "avg_logprob": -0.2925477684090991,
        "compression_ratio": 1.6130268199233717,
        "end": 88.92,
        "id": 18,
        "no_speech_prob": 0.018263204023241997,
        "seek": 8152,
        "start": 85.2,
        "temperature": 0,
        "text": " I have actually made some videos about this already.",
        "tokens": [
          50548,
          286,
          362,
          767,
          1027,
          512,
          2145,
          466,
          341,
          1217,
          13,
          50734
        ]
      },
      {
        "avg_logprob": -0.2925477684090991,
        "compression_ratio": 1.6130268199233717,
        "end": 93.84,
        "id": 19,
        "no_speech_prob": 0.018263204023241997,
        "seek": 8152,
        "start": 88.92,
        "temperature": 0,
        "text": " In notably, notably, this linear regression with gradient descent video that I made just",
        "tokens": [
          50734,
          682,
          31357,
          11,
          31357,
          11,
          341,
          8213,
          24590,
          365,
          16235,
          23475,
          960,
          300,
          286,
          1027,
          445,
          50980
        ]
      },
      {
        "avg_logprob": -0.2925477684090991,
        "compression_ratio": 1.6130268199233717,
        "end": 94.84,
        "id": 20,
        "no_speech_prob": 0.018263204023241997,
        "seek": 8152,
        "start": 93.84,
        "temperature": 0,
        "text": " with plain JavaScript.",
        "tokens": [
          50980,
          365,
          11121,
          15778,
          13,
          51030
        ]
      },
      {
        "avg_logprob": -0.2925477684090991,
        "compression_ratio": 1.6130268199233717,
        "end": 103.44,
        "id": 21,
        "no_speech_prob": 0.018263204023241997,
        "seek": 8152,
        "start": 94.84,
        "temperature": 0,
        "text": " I also made this ill-advised video about the mathematics of, oh, underlying audio is not",
        "tokens": [
          51030,
          286,
          611,
          1027,
          341,
          3171,
          12,
          345,
          24420,
          960,
          466,
          264,
          18666,
          295,
          11,
          1954,
          11,
          14217,
          6278,
          307,
          406,
          51460
        ]
      },
      {
        "avg_logprob": -0.2925477684090991,
        "compression_ratio": 1.6130268199233717,
        "end": 104.44,
        "id": 22,
        "no_speech_prob": 0.018263204023241997,
        "seek": 8152,
        "start": 103.44,
        "temperature": 0,
        "text": " working.",
        "tokens": [
          51460,
          1364,
          13,
          51510
        ]
      },
      {
        "avg_logprob": -0.2925477684090991,
        "compression_ratio": 1.6130268199233717,
        "end": 105.44,
        "id": 23,
        "no_speech_prob": 0.018263204023241997,
        "seek": 8152,
        "start": 104.44,
        "temperature": 0,
        "text": " All right, well, hold on, I won't worry about that.",
        "tokens": [
          51510,
          1057,
          558,
          11,
          731,
          11,
          1797,
          322,
          11,
          286,
          1582,
          380,
          3292,
          466,
          300,
          13,
          51560
        ]
      },
      {
        "avg_logprob": -0.2925477684090991,
        "compression_ratio": 1.6130268199233717,
        "end": 108.08,
        "id": 24,
        "no_speech_prob": 0.018263204023241997,
        "seek": 8152,
        "start": 105.44,
        "temperature": 0,
        "text": " Let me just check the chat here.",
        "tokens": [
          51560,
          961,
          385,
          445,
          1520,
          264,
          5081,
          510,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.2925477684090991,
        "compression_ratio": 1.6130268199233717,
        "end": 109.32,
        "id": 25,
        "no_speech_prob": 0.018263204023241997,
        "seek": 8152,
        "start": 108.08,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51692,
          1033,
          13,
          51754
        ]
      },
      {
        "avg_logprob": -0.309998296922253,
        "compression_ratio": 1.633587786259542,
        "end": 111.72,
        "id": 26,
        "no_speech_prob": 0.592553436756134,
        "seek": 10932,
        "start": 109.32,
        "temperature": 0,
        "text": " This video about the sort of mathematics of gradient descent.",
        "tokens": [
          50364,
          639,
          960,
          466,
          264,
          1333,
          295,
          18666,
          295,
          16235,
          23475,
          13,
          50484
        ]
      },
      {
        "avg_logprob": -0.309998296922253,
        "compression_ratio": 1.633587786259542,
        "end": 114.75999999999999,
        "id": 27,
        "no_speech_prob": 0.592553436756134,
        "seek": 10932,
        "start": 111.72,
        "temperature": 0,
        "text": " So these would be two pieces of background.",
        "tokens": [
          50484,
          407,
          613,
          576,
          312,
          732,
          3755,
          295,
          3678,
          13,
          50636
        ]
      },
      {
        "avg_logprob": -0.309998296922253,
        "compression_ratio": 1.633587786259542,
        "end": 117.8,
        "id": 28,
        "no_speech_prob": 0.592553436756134,
        "seek": 10932,
        "start": 114.75999999999999,
        "temperature": 0,
        "text": " You're watching this live, so you probably don't want to stop and go watch those, but",
        "tokens": [
          50636,
          509,
          434,
          1976,
          341,
          1621,
          11,
          370,
          291,
          1391,
          500,
          380,
          528,
          281,
          1590,
          293,
          352,
          1159,
          729,
          11,
          457,
          50788
        ]
      },
      {
        "avg_logprob": -0.309998296922253,
        "compression_ratio": 1.633587786259542,
        "end": 119.8,
        "id": 29,
        "no_speech_prob": 0.592553436756134,
        "seek": 10932,
        "start": 117.8,
        "temperature": 0,
        "text": " you could.",
        "tokens": [
          50788,
          291,
          727,
          13,
          50888
        ]
      },
      {
        "avg_logprob": -0.309998296922253,
        "compression_ratio": 1.633587786259542,
        "end": 121.39999999999999,
        "id": 30,
        "no_speech_prob": 0.592553436756134,
        "seek": 10932,
        "start": 119.8,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50888,
          1033,
          13,
          50968
        ]
      },
      {
        "avg_logprob": -0.309998296922253,
        "compression_ratio": 1.633587786259542,
        "end": 126.11999999999999,
        "id": 31,
        "no_speech_prob": 0.592553436756134,
        "seek": 10932,
        "start": 121.39999999999999,
        "temperature": 0,
        "text": " And so I think this is going to be helpful in terms of, first of all, thank you.",
        "tokens": [
          50968,
          400,
          370,
          286,
          519,
          341,
          307,
          516,
          281,
          312,
          4961,
          294,
          2115,
          295,
          11,
          700,
          295,
          439,
          11,
          1309,
          291,
          13,
          51204
        ]
      },
      {
        "avg_logprob": -0.309998296922253,
        "compression_ratio": 1.633587786259542,
        "end": 130.88,
        "id": 32,
        "no_speech_prob": 0.592553436756134,
        "seek": 10932,
        "start": 126.11999999999999,
        "temperature": 0,
        "text": " I'm going to be saying all this stuff again in a second, because I'm going to, but just",
        "tokens": [
          51204,
          286,
          478,
          516,
          281,
          312,
          1566,
          439,
          341,
          1507,
          797,
          294,
          257,
          1150,
          11,
          570,
          286,
          478,
          516,
          281,
          11,
          457,
          445,
          51442
        ]
      },
      {
        "avg_logprob": -0.309998296922253,
        "compression_ratio": 1.633587786259542,
        "end": 132.07999999999998,
        "id": 33,
        "no_speech_prob": 0.592553436756134,
        "seek": 10932,
        "start": 130.88,
        "temperature": 0,
        "text": " bear with me, please.",
        "tokens": [
          51442,
          6155,
          365,
          385,
          11,
          1767,
          13,
          51502
        ]
      },
      {
        "avg_logprob": -0.309998296922253,
        "compression_ratio": 1.633587786259542,
        "end": 133.07999999999998,
        "id": 34,
        "no_speech_prob": 0.592553436756134,
        "seek": 10932,
        "start": 132.07999999999998,
        "temperature": 0,
        "text": " Thank you.",
        "tokens": [
          51502,
          1044,
          291,
          13,
          51552
        ]
      },
      {
        "avg_logprob": -0.309998296922253,
        "compression_ratio": 1.633587786259542,
        "end": 134.64,
        "id": 35,
        "no_speech_prob": 0.592553436756134,
        "seek": 10932,
        "start": 133.07999999999998,
        "temperature": 0,
        "text": " You're very kind.",
        "tokens": [
          51552,
          509,
          434,
          588,
          733,
          13,
          51630
        ]
      },
      {
        "avg_logprob": -0.2584923605882484,
        "compression_ratio": 1.614864864864865,
        "end": 145.6,
        "id": 36,
        "no_speech_prob": 0.32411742210388184,
        "seek": 13464,
        "start": 134.64,
        "temperature": 0,
        "text": " Thank you to Ol Podkar on Twitter, who posted this code for an interactive simulation of",
        "tokens": [
          50364,
          1044,
          291,
          281,
          6141,
          12646,
          12303,
          322,
          5794,
          11,
          567,
          9437,
          341,
          3089,
          337,
          364,
          15141,
          16575,
          295,
          50912
        ]
      },
      {
        "avg_logprob": -0.2584923605882484,
        "compression_ratio": 1.614864864864865,
        "end": 148.88,
        "id": 37,
        "no_speech_prob": 0.32411742210388184,
        "seek": 13464,
        "start": 145.6,
        "temperature": 0,
        "text": " linear regression with TensorFlow and P5.js.",
        "tokens": [
          50912,
          8213,
          24590,
          365,
          37624,
          293,
          430,
          20,
          13,
          25530,
          13,
          51076
        ]
      },
      {
        "avg_logprob": -0.2584923605882484,
        "compression_ratio": 1.614864864864865,
        "end": 149.95999999999998,
        "id": 38,
        "no_speech_prob": 0.32411742210388184,
        "seek": 13464,
        "start": 148.88,
        "temperature": 0,
        "text": " This gave me the idea.",
        "tokens": [
          51076,
          639,
          2729,
          385,
          264,
          1558,
          13,
          51130
        ]
      },
      {
        "avg_logprob": -0.2584923605882484,
        "compression_ratio": 1.614864864864865,
        "end": 150.95999999999998,
        "id": 39,
        "no_speech_prob": 0.32411742210388184,
        "seek": 13464,
        "start": 149.95999999999998,
        "temperature": 0,
        "text": " You can read in this thread.",
        "tokens": [
          51130,
          509,
          393,
          1401,
          294,
          341,
          7207,
          13,
          51180
        ]
      },
      {
        "avg_logprob": -0.2584923605882484,
        "compression_ratio": 1.614864864864865,
        "end": 151.95999999999998,
        "id": 40,
        "no_speech_prob": 0.32411742210388184,
        "seek": 13464,
        "start": 150.95999999999998,
        "temperature": 0,
        "text": " Oh, great work.",
        "tokens": [
          51180,
          876,
          11,
          869,
          589,
          13,
          51230
        ]
      },
      {
        "avg_logprob": -0.2584923605882484,
        "compression_ratio": 1.614864864864865,
        "end": 155.83999999999997,
        "id": 41,
        "no_speech_prob": 0.32411742210388184,
        "seek": 13464,
        "start": 151.95999999999998,
        "temperature": 0,
        "text": " I wonder if a video tutorial redoing my linear regression example in a similar fashion would",
        "tokens": [
          51230,
          286,
          2441,
          498,
          257,
          960,
          7073,
          29956,
          278,
          452,
          8213,
          24590,
          1365,
          294,
          257,
          2531,
          6700,
          576,
          51424
        ]
      },
      {
        "avg_logprob": -0.2584923605882484,
        "compression_ratio": 1.614864864864865,
        "end": 157.16,
        "id": 42,
        "no_speech_prob": 0.32411742210388184,
        "seek": 13464,
        "start": 155.83999999999997,
        "temperature": 0,
        "text": " be useful.",
        "tokens": [
          51424,
          312,
          4420,
          13,
          51490
        ]
      },
      {
        "avg_logprob": -0.2584923605882484,
        "compression_ratio": 1.614864864864865,
        "end": 158.64,
        "id": 43,
        "no_speech_prob": 0.32411742210388184,
        "seek": 13464,
        "start": 157.16,
        "temperature": 0,
        "text": " And then the reply was, thanks.",
        "tokens": [
          51490,
          400,
          550,
          264,
          16972,
          390,
          11,
          3231,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2584923605882484,
        "compression_ratio": 1.614864864864865,
        "end": 159.64,
        "id": 44,
        "no_speech_prob": 0.32411742210388184,
        "seek": 13464,
        "start": 158.64,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          51564,
          1079,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2584923605882484,
        "compression_ratio": 1.614864864864865,
        "end": 161.32,
        "id": 45,
        "no_speech_prob": 0.32411742210388184,
        "seek": 13464,
        "start": 159.64,
        "temperature": 0,
        "text": " And some other people replied and thought this would be useful as well.",
        "tokens": [
          51614,
          400,
          512,
          661,
          561,
          20345,
          293,
          1194,
          341,
          576,
          312,
          4420,
          382,
          731,
          13,
          51698
        ]
      },
      {
        "avg_logprob": -0.2584923605882484,
        "compression_ratio": 1.614864864864865,
        "end": 162.57999999999998,
        "id": 46,
        "no_speech_prob": 0.32411742210388184,
        "seek": 13464,
        "start": 161.32,
        "temperature": 0,
        "text": " So that's what I'm going to do.",
        "tokens": [
          51698,
          407,
          300,
          311,
          437,
          286,
          478,
          516,
          281,
          360,
          13,
          51761
        ]
      },
      {
        "avg_logprob": -0.2584923605882484,
        "compression_ratio": 1.614864864864865,
        "end": 163.83999999999997,
        "id": 47,
        "no_speech_prob": 0.32411742210388184,
        "seek": 13464,
        "start": 162.57999999999998,
        "temperature": 0,
        "text": " This is foundational knowledge.",
        "tokens": [
          51761,
          639,
          307,
          32195,
          3601,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.2879439975904382,
        "compression_ratio": 1.6820083682008369,
        "end": 165.04,
        "id": 48,
        "no_speech_prob": 0.012053078040480614,
        "seek": 16384,
        "start": 164.04,
        "temperature": 0,
        "text": " So let me see.",
        "tokens": [
          50374,
          407,
          718,
          385,
          536,
          13,
          50424
        ]
      },
      {
        "avg_logprob": -0.2879439975904382,
        "compression_ratio": 1.6820083682008369,
        "end": 168.04,
        "id": 49,
        "no_speech_prob": 0.012053078040480614,
        "seek": 16384,
        "start": 165.04,
        "temperature": 0,
        "text": " Where, oh, where does this appear?",
        "tokens": [
          50424,
          2305,
          11,
          1954,
          11,
          689,
          775,
          341,
          4204,
          30,
          50574
        ]
      },
      {
        "avg_logprob": -0.2879439975904382,
        "compression_ratio": 1.6820083682008369,
        "end": 171.84,
        "id": 50,
        "no_speech_prob": 0.012053078040480614,
        "seek": 16384,
        "start": 168.04,
        "temperature": 0,
        "text": " Where, oh, where?",
        "tokens": [
          50574,
          2305,
          11,
          1954,
          11,
          689,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.2879439975904382,
        "compression_ratio": 1.6820083682008369,
        "end": 176.36,
        "id": 51,
        "no_speech_prob": 0.012053078040480614,
        "seek": 16384,
        "start": 171.84,
        "temperature": 0,
        "text": " Under here, this is all my neural networks and machine learning playlists.",
        "tokens": [
          50764,
          6974,
          510,
          11,
          341,
          307,
          439,
          452,
          18161,
          9590,
          293,
          3479,
          2539,
          862,
          36693,
          13,
          50990
        ]
      },
      {
        "avg_logprob": -0.2879439975904382,
        "compression_ratio": 1.6820083682008369,
        "end": 180.28,
        "id": 52,
        "no_speech_prob": 0.012053078040480614,
        "seek": 16384,
        "start": 176.36,
        "temperature": 0,
        "text": " We're looking for this one, session six.",
        "tokens": [
          50990,
          492,
          434,
          1237,
          337,
          341,
          472,
          11,
          5481,
          2309,
          13,
          51186
        ]
      },
      {
        "avg_logprob": -0.2879439975904382,
        "compression_ratio": 1.6820083682008369,
        "end": 183.88,
        "id": 53,
        "no_speech_prob": 0.012053078040480614,
        "seek": 16384,
        "start": 180.28,
        "temperature": 0,
        "text": " So this is what I've done so far.",
        "tokens": [
          51186,
          407,
          341,
          307,
          437,
          286,
          600,
          1096,
          370,
          1400,
          13,
          51366
        ]
      },
      {
        "avg_logprob": -0.2879439975904382,
        "compression_ratio": 1.6820083682008369,
        "end": 187.8,
        "id": 54,
        "no_speech_prob": 0.012053078040480614,
        "seek": 16384,
        "start": 183.88,
        "temperature": 0,
        "text": " And the thing that I really want to get to, which is going to come next week, is the layers",
        "tokens": [
          51366,
          400,
          264,
          551,
          300,
          286,
          534,
          528,
          281,
          483,
          281,
          11,
          597,
          307,
          516,
          281,
          808,
          958,
          1243,
          11,
          307,
          264,
          7914,
          51562
        ]
      },
      {
        "avg_logprob": -0.2879439975904382,
        "compression_ratio": 1.6820083682008369,
        "end": 188.88,
        "id": 55,
        "no_speech_prob": 0.012053078040480614,
        "seek": 16384,
        "start": 187.8,
        "temperature": 0,
        "text": " API.",
        "tokens": [
          51562,
          9362,
          13,
          51616
        ]
      },
      {
        "avg_logprob": -0.2879439975904382,
        "compression_ratio": 1.6820083682008369,
        "end": 192.4,
        "id": 56,
        "no_speech_prob": 0.012053078040480614,
        "seek": 16384,
        "start": 188.88,
        "temperature": 0,
        "text": " And this is where I'm going to actually begin building some neural network examples and",
        "tokens": [
          51616,
          400,
          341,
          307,
          689,
          286,
          478,
          516,
          281,
          767,
          1841,
          2390,
          512,
          18161,
          3209,
          5110,
          293,
          51792
        ]
      },
      {
        "avg_logprob": -0.360660457611084,
        "compression_ratio": 1.515625,
        "end": 196.88,
        "id": 57,
        "no_speech_prob": 0.0022169961594045162,
        "seek": 19240,
        "start": 192.44,
        "temperature": 0,
        "text": " remaking some previous things I've done on this channel without TensorFlow.js.",
        "tokens": [
          50366,
          890,
          2456,
          512,
          3894,
          721,
          286,
          600,
          1096,
          322,
          341,
          2269,
          1553,
          37624,
          13,
          25530,
          13,
          50588
        ]
      },
      {
        "avg_logprob": -0.360660457611084,
        "compression_ratio": 1.515625,
        "end": 203.28,
        "id": 58,
        "no_speech_prob": 0.0022169961594045162,
        "seek": 19240,
        "start": 196.88,
        "temperature": 0,
        "text": " But I think before we get there, I want to just look at some other features of the TensorFlow.js",
        "tokens": [
          50588,
          583,
          286,
          519,
          949,
          321,
          483,
          456,
          11,
          286,
          528,
          281,
          445,
          574,
          412,
          512,
          661,
          4122,
          295,
          264,
          37624,
          13,
          25530,
          50908
        ]
      },
      {
        "avg_logprob": -0.360660457611084,
        "compression_ratio": 1.515625,
        "end": 206.08,
        "id": 59,
        "no_speech_prob": 0.0022169961594045162,
        "seek": 19240,
        "start": 203.28,
        "temperature": 0,
        "text": " library in the context of linear regression.",
        "tokens": [
          50908,
          6405,
          294,
          264,
          4319,
          295,
          8213,
          24590,
          13,
          51048
        ]
      },
      {
        "avg_logprob": -0.360660457611084,
        "compression_ratio": 1.515625,
        "end": 209.28,
        "id": 60,
        "no_speech_prob": 0.0022169961594045162,
        "seek": 19240,
        "start": 206.08,
        "temperature": 0,
        "text": " So that's the plan for today.",
        "tokens": [
          51048,
          407,
          300,
          311,
          264,
          1393,
          337,
          965,
          13,
          51208
        ]
      },
      {
        "avg_logprob": -0.360660457611084,
        "compression_ratio": 1.515625,
        "end": 214.56,
        "id": 61,
        "no_speech_prob": 0.0022169961594045162,
        "seek": 19240,
        "start": 209.28,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51208,
          2264,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -0.360660457611084,
        "compression_ratio": 1.515625,
        "end": 219.48000000000002,
        "id": 62,
        "no_speech_prob": 0.0022169961594045162,
        "seek": 19240,
        "start": 214.56,
        "temperature": 0,
        "text": " So I think I just want to get going.",
        "tokens": [
          51472,
          407,
          286,
          519,
          286,
          445,
          528,
          281,
          483,
          516,
          13,
          51718
        ]
      },
      {
        "avg_logprob": -0.24161011190975415,
        "compression_ratio": 1.4922279792746114,
        "end": 225.35999999999999,
        "id": 63,
        "no_speech_prob": 0.00047285103937610984,
        "seek": 21948,
        "start": 220.48,
        "temperature": 0,
        "text": " So I need to reference all these things.",
        "tokens": [
          50414,
          407,
          286,
          643,
          281,
          6408,
          439,
          613,
          721,
          13,
          50658
        ]
      },
      {
        "avg_logprob": -0.24161011190975415,
        "compression_ratio": 1.4922279792746114,
        "end": 229.2,
        "id": 64,
        "no_speech_prob": 0.00047285103937610984,
        "seek": 21948,
        "start": 225.35999999999999,
        "temperature": 0,
        "text": " I guess I will just tab my way through them.",
        "tokens": [
          50658,
          286,
          2041,
          286,
          486,
          445,
          4421,
          452,
          636,
          807,
          552,
          13,
          50850
        ]
      },
      {
        "avg_logprob": -0.24161011190975415,
        "compression_ratio": 1.4922279792746114,
        "end": 234.32,
        "id": 65,
        "no_speech_prob": 0.00047285103937610984,
        "seek": 21948,
        "start": 229.2,
        "temperature": 0,
        "text": " I'm going to move this here.",
        "tokens": [
          50850,
          286,
          478,
          516,
          281,
          1286,
          341,
          510,
          13,
          51106
        ]
      },
      {
        "avg_logprob": -0.24161011190975415,
        "compression_ratio": 1.4922279792746114,
        "end": 236.2,
        "id": 66,
        "no_speech_prob": 0.00047285103937610984,
        "seek": 21948,
        "start": 234.32,
        "temperature": 0,
        "text": " And I haven't implemented this.",
        "tokens": [
          51106,
          400,
          286,
          2378,
          380,
          12270,
          341,
          13,
          51200
        ]
      },
      {
        "avg_logprob": -0.24161011190975415,
        "compression_ratio": 1.4922279792746114,
        "end": 241.95999999999998,
        "id": 67,
        "no_speech_prob": 0.00047285103937610984,
        "seek": 21948,
        "start": 236.2,
        "temperature": 0,
        "text": " I scanned over this GitHub user's code.",
        "tokens": [
          51200,
          286,
          45089,
          670,
          341,
          23331,
          4195,
          311,
          3089,
          13,
          51488
        ]
      },
      {
        "avg_logprob": -0.24161011190975415,
        "compression_ratio": 1.4922279792746114,
        "end": 245.39999999999998,
        "id": 68,
        "no_speech_prob": 0.00047285103937610984,
        "seek": 21948,
        "start": 241.95999999999998,
        "temperature": 0,
        "text": " So I do have that a little bit in the back of my head, but I have not tried to implement",
        "tokens": [
          51488,
          407,
          286,
          360,
          362,
          300,
          257,
          707,
          857,
          294,
          264,
          646,
          295,
          452,
          1378,
          11,
          457,
          286,
          362,
          406,
          3031,
          281,
          4445,
          51660
        ]
      },
      {
        "avg_logprob": -0.24161011190975415,
        "compression_ratio": 1.4922279792746114,
        "end": 246.39999999999998,
        "id": 69,
        "no_speech_prob": 0.00047285103937610984,
        "seek": 21948,
        "start": 245.39999999999998,
        "temperature": 0,
        "text": " this myself.",
        "tokens": [
          51660,
          341,
          2059,
          13,
          51710
        ]
      },
      {
        "avg_logprob": -0.2718413670857747,
        "compression_ratio": 1.35678391959799,
        "end": 251.68,
        "id": 70,
        "no_speech_prob": 0.6957518458366394,
        "seek": 24640,
        "start": 246.4,
        "temperature": 0,
        "text": " I've got the Slack channel going here for patrons and YouTube sponsors.",
        "tokens": [
          50364,
          286,
          600,
          658,
          264,
          37211,
          2269,
          516,
          510,
          337,
          27559,
          293,
          3088,
          22593,
          13,
          50628
        ]
      },
      {
        "avg_logprob": -0.2718413670857747,
        "compression_ratio": 1.35678391959799,
        "end": 252.68,
        "id": 71,
        "no_speech_prob": 0.6957518458366394,
        "seek": 24640,
        "start": 251.68,
        "temperature": 0,
        "text": " Thank you.",
        "tokens": [
          50628,
          1044,
          291,
          13,
          50678
        ]
      },
      {
        "avg_logprob": -0.2718413670857747,
        "compression_ratio": 1.35678391959799,
        "end": 256.56,
        "id": 72,
        "no_speech_prob": 0.6957518458366394,
        "seek": 24640,
        "start": 252.68,
        "temperature": 0,
        "text": " So you'll be keeping me in check.",
        "tokens": [
          50678,
          407,
          291,
          603,
          312,
          5145,
          385,
          294,
          1520,
          13,
          50872
        ]
      },
      {
        "avg_logprob": -0.2718413670857747,
        "compression_ratio": 1.35678391959799,
        "end": 258.8,
        "id": 73,
        "no_speech_prob": 0.6957518458366394,
        "seek": 24640,
        "start": 256.56,
        "temperature": 0,
        "text": " And I've got until about 5.30 PM.",
        "tokens": [
          50872,
          400,
          286,
          600,
          658,
          1826,
          466,
          1025,
          13,
          3446,
          12499,
          13,
          50984
        ]
      },
      {
        "avg_logprob": -0.2718413670857747,
        "compression_ratio": 1.35678391959799,
        "end": 272,
        "id": 74,
        "no_speech_prob": 0.6957518458366394,
        "seek": 24640,
        "start": 258.8,
        "temperature": 0,
        "text": " I'm just trying to decide, does this sit as 6.5 linear regression with gradient descent?",
        "tokens": [
          50984,
          286,
          478,
          445,
          1382,
          281,
          4536,
          11,
          775,
          341,
          1394,
          382,
          1386,
          13,
          20,
          8213,
          24590,
          365,
          16235,
          23475,
          30,
          51644
        ]
      },
      {
        "avg_logprob": -0.2718413670857747,
        "compression_ratio": 1.35678391959799,
        "end": 273.28000000000003,
        "id": 75,
        "no_speech_prob": 0.6957518458366394,
        "seek": 24640,
        "start": 272,
        "temperature": 0,
        "text": " Or is this a coding challenge?",
        "tokens": [
          51644,
          1610,
          307,
          341,
          257,
          17720,
          3430,
          30,
          51708
        ]
      },
      {
        "avg_logprob": -0.3282943367958069,
        "compression_ratio": 1.519047619047619,
        "end": 278.28,
        "id": 76,
        "no_speech_prob": 0.02297615259885788,
        "seek": 27328,
        "start": 273.4,
        "temperature": 0,
        "text": " So I'm seeing in the chat that a chat user says, if you want to do interactive stuff",
        "tokens": [
          50370,
          407,
          286,
          478,
          2577,
          294,
          264,
          5081,
          300,
          257,
          5081,
          4195,
          1619,
          11,
          498,
          291,
          528,
          281,
          360,
          15141,
          1507,
          50614
        ]
      },
      {
        "avg_logprob": -0.3282943367958069,
        "compression_ratio": 1.519047619047619,
        "end": 281.59999999999997,
        "id": 77,
        "no_speech_prob": 0.02297615259885788,
        "seek": 27328,
        "start": 278.28,
        "temperature": 0,
        "text": " with TF.js, you should check out TF next frame.",
        "tokens": [
          50614,
          365,
          40964,
          13,
          25530,
          11,
          291,
          820,
          1520,
          484,
          40964,
          958,
          3920,
          13,
          50780
        ]
      },
      {
        "avg_logprob": -0.3282943367958069,
        "compression_ratio": 1.519047619047619,
        "end": 282.84,
        "id": 78,
        "no_speech_prob": 0.02297615259885788,
        "seek": 27328,
        "start": 281.59999999999997,
        "temperature": 0,
        "text": " OK, hold on.",
        "tokens": [
          50780,
          2264,
          11,
          1797,
          322,
          13,
          50842
        ]
      },
      {
        "avg_logprob": -0.3282943367958069,
        "compression_ratio": 1.519047619047619,
        "end": 286.35999999999996,
        "id": 79,
        "no_speech_prob": 0.02297615259885788,
        "seek": 27328,
        "start": 282.84,
        "temperature": 0,
        "text": " I was not aware of this.",
        "tokens": [
          50842,
          286,
          390,
          406,
          3650,
          295,
          341,
          13,
          51018
        ]
      },
      {
        "avg_logprob": -0.3282943367958069,
        "compression_ratio": 1.519047619047619,
        "end": 293.52,
        "id": 80,
        "no_speech_prob": 0.02297615259885788,
        "seek": 27328,
        "start": 286.35999999999996,
        "temperature": 0,
        "text": " So let me have a look at next frame.",
        "tokens": [
          51018,
          407,
          718,
          385,
          362,
          257,
          574,
          412,
          958,
          3920,
          13,
          51376
        ]
      },
      {
        "avg_logprob": -0.3282943367958069,
        "compression_ratio": 1.519047619047619,
        "end": 298.47999999999996,
        "id": 81,
        "no_speech_prob": 0.02297615259885788,
        "seek": 27328,
        "start": 293.52,
        "temperature": 0,
        "text": " Returns a promise that resolves when a request animation frame has completed.",
        "tokens": [
          51376,
          24350,
          82,
          257,
          6228,
          300,
          7923,
          977,
          562,
          257,
          5308,
          9603,
          3920,
          575,
          7365,
          13,
          51624
        ]
      },
      {
        "avg_logprob": -0.3282943367958069,
        "compression_ratio": 1.519047619047619,
        "end": 300.47999999999996,
        "id": 82,
        "no_speech_prob": 0.02297615259885788,
        "seek": 27328,
        "start": 298.47999999999996,
        "temperature": 0,
        "text": " Oh, fascinating.",
        "tokens": [
          51624,
          876,
          11,
          10343,
          13,
          51724
        ]
      },
      {
        "avg_logprob": -0.3282943367958069,
        "compression_ratio": 1.519047619047619,
        "end": 302.61999999999995,
        "id": 83,
        "no_speech_prob": 0.02297615259885788,
        "seek": 27328,
        "start": 300.47999999999996,
        "temperature": 0,
        "text": " Oh, interesting.",
        "tokens": [
          51724,
          876,
          11,
          1880,
          13,
          51831
        ]
      },
      {
        "avg_logprob": -0.260501319979444,
        "compression_ratio": 1.4662921348314606,
        "end": 303.66,
        "id": 84,
        "no_speech_prob": 0.010327971540391445,
        "seek": 30262,
        "start": 302.62,
        "temperature": 0,
        "text": " So that's really interesting.",
        "tokens": [
          50364,
          407,
          300,
          311,
          534,
          1880,
          13,
          50416
        ]
      },
      {
        "avg_logprob": -0.260501319979444,
        "compression_ratio": 1.4662921348314606,
        "end": 307.54,
        "id": 85,
        "no_speech_prob": 0.010327971540391445,
        "seek": 30262,
        "start": 303.66,
        "temperature": 0,
        "text": " I think I'm going to do this is right.",
        "tokens": [
          50416,
          286,
          519,
          286,
          478,
          516,
          281,
          360,
          341,
          307,
          558,
          13,
          50610
        ]
      },
      {
        "avg_logprob": -0.260501319979444,
        "compression_ratio": 1.4662921348314606,
        "end": 315.34000000000003,
        "id": 86,
        "no_speech_prob": 0.010327971540391445,
        "seek": 30262,
        "start": 307.54,
        "temperature": 0,
        "text": " So what I'm doing is so incredibly, well, it's comparably simple.",
        "tokens": [
          50610,
          407,
          437,
          286,
          478,
          884,
          307,
          370,
          6252,
          11,
          731,
          11,
          309,
          311,
          6311,
          1188,
          2199,
          13,
          51000
        ]
      },
      {
        "avg_logprob": -0.260501319979444,
        "compression_ratio": 1.4662921348314606,
        "end": 326.46,
        "id": 87,
        "no_speech_prob": 0.010327971540391445,
        "seek": 30262,
        "start": 315.34000000000003,
        "temperature": 0,
        "text": " And I can probably do it with pulling the, yeah, let's see how this goes.",
        "tokens": [
          51000,
          400,
          286,
          393,
          1391,
          360,
          309,
          365,
          8407,
          264,
          11,
          1338,
          11,
          718,
          311,
          536,
          577,
          341,
          1709,
          13,
          51556
        ]
      },
      {
        "avg_logprob": -0.260501319979444,
        "compression_ratio": 1.4662921348314606,
        "end": 327.46,
        "id": 88,
        "no_speech_prob": 0.010327971540391445,
        "seek": 30262,
        "start": 326.46,
        "temperature": 0,
        "text": " Let me try to build it.",
        "tokens": [
          51556,
          961,
          385,
          853,
          281,
          1322,
          309,
          13,
          51606
        ]
      },
      {
        "avg_logprob": -0.260501319979444,
        "compression_ratio": 1.4662921348314606,
        "end": 329.06,
        "id": 89,
        "no_speech_prob": 0.010327971540391445,
        "seek": 30262,
        "start": 327.46,
        "temperature": 0,
        "text": " And thank you for this note.",
        "tokens": [
          51606,
          400,
          1309,
          291,
          337,
          341,
          3637,
          13,
          51686
        ]
      },
      {
        "avg_logprob": -0.2698198537357518,
        "compression_ratio": 1.6555555555555554,
        "end": 331.58,
        "id": 90,
        "no_speech_prob": 0.043362244963645935,
        "seek": 32906,
        "start": 329.06,
        "temperature": 0,
        "text": " I'm going to try to do it probably in a less correct way",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          853,
          281,
          360,
          309,
          1391,
          294,
          257,
          1570,
          3006,
          636,
          50490
        ]
      },
      {
        "avg_logprob": -0.2698198537357518,
        "compression_ratio": 1.6555555555555554,
        "end": 332.98,
        "id": 91,
        "no_speech_prob": 0.043362244963645935,
        "seek": 32906,
        "start": 331.58,
        "temperature": 0,
        "text": " and just get it kind of working.",
        "tokens": [
          50490,
          293,
          445,
          483,
          309,
          733,
          295,
          1364,
          13,
          50560
        ]
      },
      {
        "avg_logprob": -0.2698198537357518,
        "compression_ratio": 1.6555555555555554,
        "end": 336.02,
        "id": 92,
        "no_speech_prob": 0.043362244963645935,
        "seek": 32906,
        "start": 332.98,
        "temperature": 0,
        "text": " Let the threads kind of like, the amount of computation",
        "tokens": [
          50560,
          961,
          264,
          19314,
          733,
          295,
          411,
          11,
          264,
          2372,
          295,
          24903,
          50712
        ]
      },
      {
        "avg_logprob": -0.2698198537357518,
        "compression_ratio": 1.6555555555555554,
        "end": 338.86,
        "id": 93,
        "no_speech_prob": 0.043362244963645935,
        "seek": 32906,
        "start": 336.02,
        "temperature": 0,
        "text": " that I'm going to do for linear regression is so simple",
        "tokens": [
          50712,
          300,
          286,
          478,
          516,
          281,
          360,
          337,
          8213,
          24590,
          307,
          370,
          2199,
          50854
        ]
      },
      {
        "avg_logprob": -0.2698198537357518,
        "compression_ratio": 1.6555555555555554,
        "end": 340.98,
        "id": 94,
        "no_speech_prob": 0.043362244963645935,
        "seek": 32906,
        "start": 338.86,
        "temperature": 0,
        "text": " that even if it locks up for a second, it's",
        "tokens": [
          50854,
          300,
          754,
          498,
          309,
          20703,
          493,
          337,
          257,
          1150,
          11,
          309,
          311,
          50960
        ]
      },
      {
        "avg_logprob": -0.2698198537357518,
        "compression_ratio": 1.6555555555555554,
        "end": 343.14,
        "id": 95,
        "no_speech_prob": 0.043362244963645935,
        "seek": 32906,
        "start": 340.98,
        "temperature": 0,
        "text": " going to be fine to let the animation keep going.",
        "tokens": [
          50960,
          516,
          281,
          312,
          2489,
          281,
          718,
          264,
          9603,
          1066,
          516,
          13,
          51068
        ]
      },
      {
        "avg_logprob": -0.2698198537357518,
        "compression_ratio": 1.6555555555555554,
        "end": 347.22,
        "id": 96,
        "no_speech_prob": 0.043362244963645935,
        "seek": 32906,
        "start": 343.14,
        "temperature": 0,
        "text": " But this is absolutely something that I will need to pay attention to more later,",
        "tokens": [
          51068,
          583,
          341,
          307,
          3122,
          746,
          300,
          286,
          486,
          643,
          281,
          1689,
          3202,
          281,
          544,
          1780,
          11,
          51272
        ]
      },
      {
        "avg_logprob": -0.2698198537357518,
        "compression_ratio": 1.6555555555555554,
        "end": 349.74,
        "id": 97,
        "no_speech_prob": 0.043362244963645935,
        "seek": 32906,
        "start": 347.22,
        "temperature": 0,
        "text": " for sure.",
        "tokens": [
          51272,
          337,
          988,
          13,
          51398
        ]
      },
      {
        "avg_logprob": -0.2698198537357518,
        "compression_ratio": 1.6555555555555554,
        "end": 350.24,
        "id": 98,
        "no_speech_prob": 0.043362244963645935,
        "seek": 32906,
        "start": 349.74,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51398,
          2264,
          13,
          51423
        ]
      },
      {
        "avg_logprob": -0.2698198537357518,
        "compression_ratio": 1.6555555555555554,
        "end": 357.5,
        "id": 99,
        "no_speech_prob": 0.043362244963645935,
        "seek": 32906,
        "start": 354.9,
        "temperature": 0,
        "text": " Can anyone help me with the pronunciation of this name?",
        "tokens": [
          51656,
          1664,
          2878,
          854,
          385,
          365,
          264,
          23338,
          295,
          341,
          1315,
          30,
          51786
        ]
      },
      {
        "avg_logprob": -0.4900382564913842,
        "compression_ratio": 1.2388059701492538,
        "end": 359.66,
        "id": 100,
        "no_speech_prob": 0.013845437206327915,
        "seek": 35750,
        "start": 357.58,
        "temperature": 0,
        "text": " Calstube Old Pod Car?",
        "tokens": [
          50368,
          3511,
          372,
          1977,
          8633,
          12646,
          2741,
          30,
          50472
        ]
      },
      {
        "avg_logprob": -0.4900382564913842,
        "compression_ratio": 1.2388059701492538,
        "end": 361.22,
        "id": 101,
        "no_speech_prob": 0.013845437206327915,
        "seek": 35750,
        "start": 359.66,
        "temperature": 0,
        "text": " Calstube Old Pod Car?",
        "tokens": [
          50472,
          3511,
          372,
          1977,
          8633,
          12646,
          2741,
          30,
          50550
        ]
      },
      {
        "avg_logprob": -0.4900382564913842,
        "compression_ratio": 1.2388059701492538,
        "end": 362.82,
        "id": 102,
        "no_speech_prob": 0.013845437206327915,
        "seek": 35750,
        "start": 361.22,
        "temperature": 0,
        "text": " Any chance that that was kind of close?",
        "tokens": [
          50550,
          2639,
          2931,
          300,
          300,
          390,
          733,
          295,
          1998,
          30,
          50630
        ]
      },
      {
        "avg_logprob": -0.47886308034261066,
        "compression_ratio": 0.9019607843137255,
        "end": 363.32,
        "id": 103,
        "no_speech_prob": 0.004397988319396973,
        "seek": 36282,
        "start": 362.82,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50364,
          2264,
          13,
          50389
        ]
      },
      {
        "avg_logprob": -0.47886308034261066,
        "compression_ratio": 0.9019607843137255,
        "end": 390.1,
        "id": 104,
        "no_speech_prob": 0.004397988319396973,
        "seek": 36282,
        "start": 386.58,
        "temperature": 0,
        "text": " We will be getting going in just a second.",
        "tokens": [
          51552,
          492,
          486,
          312,
          1242,
          516,
          294,
          445,
          257,
          1150,
          13,
          51728
        ]
      },
      {
        "avg_logprob": -0.22285068035125732,
        "compression_ratio": 1.4204545454545454,
        "end": 392.82000000000005,
        "id": 105,
        "no_speech_prob": 0.0015978362644091249,
        "seek": 39010,
        "start": 390.14000000000004,
        "temperature": 0,
        "text": " I'm waiting for the live chat to maybe catch up to me",
        "tokens": [
          50366,
          286,
          478,
          3806,
          337,
          264,
          1621,
          5081,
          281,
          1310,
          3745,
          493,
          281,
          385,
          50500
        ]
      },
      {
        "avg_logprob": -0.22285068035125732,
        "compression_ratio": 1.4204545454545454,
        "end": 396.38,
        "id": 106,
        "no_speech_prob": 0.0015978362644091249,
        "seek": 39010,
        "start": 392.82000000000005,
        "temperature": 0,
        "text": " and somebody might help me pronounce this name correctly.",
        "tokens": [
          50500,
          293,
          2618,
          1062,
          854,
          385,
          19567,
          341,
          1315,
          8944,
          13,
          50678
        ]
      },
      {
        "avg_logprob": -0.22285068035125732,
        "compression_ratio": 1.4204545454545454,
        "end": 406.94,
        "id": 107,
        "no_speech_prob": 0.0015978362644091249,
        "seek": 39010,
        "start": 405.66,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51142,
          1057,
          558,
          13,
          51206
        ]
      },
      {
        "avg_logprob": -0.22285068035125732,
        "compression_ratio": 1.4204545454545454,
        "end": 408.1,
        "id": 108,
        "no_speech_prob": 0.0015978362644091249,
        "seek": 39010,
        "start": 406.94,
        "temperature": 0,
        "text": " Close enough, I think.",
        "tokens": [
          51206,
          16346,
          1547,
          11,
          286,
          519,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.22285068035125732,
        "compression_ratio": 1.4204545454545454,
        "end": 410.22,
        "id": 109,
        "no_speech_prob": 0.0015978362644091249,
        "seek": 39010,
        "start": 408.1,
        "temperature": 0,
        "text": " Well, that's what it's going to have to be.",
        "tokens": [
          51264,
          1042,
          11,
          300,
          311,
          437,
          309,
          311,
          516,
          281,
          362,
          281,
          312,
          13,
          51370
        ]
      },
      {
        "avg_logprob": -0.22285068035125732,
        "compression_ratio": 1.4204545454545454,
        "end": 412.22,
        "id": 110,
        "no_speech_prob": 0.0015978362644091249,
        "seek": 39010,
        "start": 410.22,
        "temperature": 0,
        "text": " Where's my marker?",
        "tokens": [
          51370,
          2305,
          311,
          452,
          15247,
          30,
          51470
        ]
      },
      {
        "avg_logprob": -0.22285068035125732,
        "compression_ratio": 1.4204545454545454,
        "end": 413.98,
        "id": 111,
        "no_speech_prob": 0.0015978362644091249,
        "seek": 39010,
        "start": 412.22,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          51470,
          1692,
          321,
          352,
          13,
          51558
        ]
      },
      {
        "avg_logprob": -0.22285068035125732,
        "compression_ratio": 1.4204545454545454,
        "end": 417.5,
        "id": 112,
        "no_speech_prob": 0.0015978362644091249,
        "seek": 39010,
        "start": 413.98,
        "temperature": 0,
        "text": " And I'm going to get started.",
        "tokens": [
          51558,
          400,
          286,
          478,
          516,
          281,
          483,
          1409,
          13,
          51734
        ]
      },
      {
        "avg_logprob": -0.3046123716566298,
        "compression_ratio": 1.5725806451612903,
        "end": 420.54,
        "id": 113,
        "no_speech_prob": 0.014728100970387459,
        "seek": 41750,
        "start": 417.5,
        "temperature": 0,
        "text": " I wish I could just call and pronounce it.",
        "tokens": [
          50364,
          286,
          3172,
          286,
          727,
          445,
          818,
          293,
          19567,
          309,
          13,
          50516
        ]
      },
      {
        "avg_logprob": -0.3046123716566298,
        "compression_ratio": 1.5725806451612903,
        "end": 423.38,
        "id": 114,
        "no_speech_prob": 0.014728100970387459,
        "seek": 41750,
        "start": 420.54,
        "temperature": 0,
        "text": " That's a good point.",
        "tokens": [
          50516,
          663,
          311,
          257,
          665,
          935,
          13,
          50658
        ]
      },
      {
        "avg_logprob": -0.3046123716566298,
        "compression_ratio": 1.5725806451612903,
        "end": 424.38,
        "id": 115,
        "no_speech_prob": 0.014728100970387459,
        "seek": 41750,
        "start": 423.38,
        "temperature": 0,
        "text": " Let's move on.",
        "tokens": [
          50658,
          961,
          311,
          1286,
          322,
          13,
          50708
        ]
      },
      {
        "avg_logprob": -0.3046123716566298,
        "compression_ratio": 1.5725806451612903,
        "end": 426.82,
        "id": 116,
        "no_speech_prob": 0.014728100970387459,
        "seek": 41750,
        "start": 424.38,
        "temperature": 0,
        "text": " There's probably some fancy technological way",
        "tokens": [
          50708,
          821,
          311,
          1391,
          512,
          10247,
          18439,
          636,
          50830
        ]
      },
      {
        "avg_logprob": -0.3046123716566298,
        "compression_ratio": 1.5725806451612903,
        "end": 429.5,
        "id": 117,
        "no_speech_prob": 0.014728100970387459,
        "seek": 41750,
        "start": 426.82,
        "temperature": 0,
        "text": " we can make that happen.",
        "tokens": [
          50830,
          321,
          393,
          652,
          300,
          1051,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.3046123716566298,
        "compression_ratio": 1.5725806451612903,
        "end": 431.14,
        "id": 118,
        "no_speech_prob": 0.014728100970387459,
        "seek": 41750,
        "start": 429.5,
        "temperature": 0,
        "text": " Everybody should stretch.",
        "tokens": [
          50964,
          7646,
          820,
          5985,
          13,
          51046
        ]
      },
      {
        "avg_logprob": -0.3046123716566298,
        "compression_ratio": 1.5725806451612903,
        "end": 431.94,
        "id": 119,
        "no_speech_prob": 0.014728100970387459,
        "seek": 41750,
        "start": 431.14,
        "temperature": 0,
        "text": " Stretch.",
        "tokens": [
          51046,
          38817,
          13,
          51086
        ]
      },
      {
        "avg_logprob": -0.3046123716566298,
        "compression_ratio": 1.5725806451612903,
        "end": 435.94,
        "id": 120,
        "no_speech_prob": 0.014728100970387459,
        "seek": 41750,
        "start": 431.94,
        "temperature": 0,
        "text": " This really, this extra live stream towards the end of the day,",
        "tokens": [
          51086,
          639,
          534,
          11,
          341,
          2857,
          1621,
          4309,
          3030,
          264,
          917,
          295,
          264,
          786,
          11,
          51286
        ]
      },
      {
        "avg_logprob": -0.3046123716566298,
        "compression_ratio": 1.5725806451612903,
        "end": 439.26,
        "id": 121,
        "no_speech_prob": 0.014728100970387459,
        "seek": 41750,
        "start": 435.94,
        "temperature": 0,
        "text": " trying to do something with machine learning and TensorFlow.js,",
        "tokens": [
          51286,
          1382,
          281,
          360,
          746,
          365,
          3479,
          2539,
          293,
          37624,
          13,
          25530,
          11,
          51452
        ]
      },
      {
        "avg_logprob": -0.3046123716566298,
        "compression_ratio": 1.5725806451612903,
        "end": 442.42,
        "id": 122,
        "no_speech_prob": 0.014728100970387459,
        "seek": 41750,
        "start": 439.26,
        "temperature": 0,
        "text": " this really needs some space melon.",
        "tokens": [
          51452,
          341,
          534,
          2203,
          512,
          1901,
          41722,
          13,
          51610
        ]
      },
      {
        "avg_logprob": -0.3046123716566298,
        "compression_ratio": 1.5725806451612903,
        "end": 444.14,
        "id": 123,
        "no_speech_prob": 0.014728100970387459,
        "seek": 41750,
        "start": 442.42,
        "temperature": 0,
        "text": " But I don't have any space melon with me,",
        "tokens": [
          51610,
          583,
          286,
          500,
          380,
          362,
          604,
          1901,
          41722,
          365,
          385,
          11,
          51696
        ]
      },
      {
        "avg_logprob": -0.284575564190022,
        "compression_ratio": 1.5748502994011977,
        "end": 448.65999999999997,
        "id": 124,
        "no_speech_prob": 0.004982147365808487,
        "seek": 44414,
        "start": 444.14,
        "temperature": 0,
        "text": " so I'm just going to have to try my best.",
        "tokens": [
          50364,
          370,
          286,
          478,
          445,
          516,
          281,
          362,
          281,
          853,
          452,
          1151,
          13,
          50590
        ]
      },
      {
        "avg_logprob": -0.284575564190022,
        "compression_ratio": 1.5748502994011977,
        "end": 449.34,
        "id": 125,
        "no_speech_prob": 0.004982147365808487,
        "seek": 44414,
        "start": 448.65999999999997,
        "temperature": 0,
        "text": " Kustub.",
        "tokens": [
          50590,
          591,
          381,
          836,
          13,
          50624
        ]
      },
      {
        "avg_logprob": -0.284575564190022,
        "compression_ratio": 1.5748502994011977,
        "end": 449.86,
        "id": 126,
        "no_speech_prob": 0.004982147365808487,
        "seek": 44414,
        "start": 449.34,
        "temperature": 0,
        "text": " Thank you.",
        "tokens": [
          50624,
          1044,
          291,
          13,
          50650
        ]
      },
      {
        "avg_logprob": -0.284575564190022,
        "compression_ratio": 1.5748502994011977,
        "end": 451.53999999999996,
        "id": 127,
        "no_speech_prob": 0.004982147365808487,
        "seek": 44414,
        "start": 449.86,
        "temperature": 0,
        "text": " Kustub.",
        "tokens": [
          50650,
          591,
          381,
          836,
          13,
          50734
        ]
      },
      {
        "avg_logprob": -0.284575564190022,
        "compression_ratio": 1.5748502994011977,
        "end": 453.53999999999996,
        "id": 128,
        "no_speech_prob": 0.004982147365808487,
        "seek": 44414,
        "start": 451.53999999999996,
        "temperature": 0,
        "text": " Kustub Old Pod Car.",
        "tokens": [
          50734,
          591,
          381,
          836,
          8633,
          12646,
          2741,
          13,
          50834
        ]
      },
      {
        "avg_logprob": -0.284575564190022,
        "compression_ratio": 1.5748502994011977,
        "end": 454.58,
        "id": 129,
        "no_speech_prob": 0.004982147365808487,
        "seek": 44414,
        "start": 453.53999999999996,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50834,
          2264,
          13,
          50886
        ]
      },
      {
        "avg_logprob": -0.284575564190022,
        "compression_ratio": 1.5748502994011977,
        "end": 456.78,
        "id": 130,
        "no_speech_prob": 0.004982147365808487,
        "seek": 44414,
        "start": 454.58,
        "temperature": 0,
        "text": " Thank you.",
        "tokens": [
          50886,
          1044,
          291,
          13,
          50996
        ]
      },
      {
        "avg_logprob": -0.284575564190022,
        "compression_ratio": 1.5748502994011977,
        "end": 461.26,
        "id": 131,
        "no_speech_prob": 0.004982147365808487,
        "seek": 44414,
        "start": 456.78,
        "temperature": 0,
        "text": " Calstube Old Pod Car.",
        "tokens": [
          50996,
          3511,
          372,
          1977,
          8633,
          12646,
          2741,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.284575564190022,
        "compression_ratio": 1.5748502994011977,
        "end": 462.26,
        "id": 132,
        "no_speech_prob": 0.004982147365808487,
        "seek": 44414,
        "start": 461.26,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51220,
          2264,
          13,
          51270
        ]
      },
      {
        "avg_logprob": -0.284575564190022,
        "compression_ratio": 1.5748502994011977,
        "end": 464.41999999999996,
        "id": 133,
        "no_speech_prob": 0.004982147365808487,
        "seek": 44414,
        "start": 462.26,
        "temperature": 0,
        "text": " Now people are just trolling me in the chat",
        "tokens": [
          51270,
          823,
          561,
          366,
          445,
          4495,
          2669,
          385,
          294,
          264,
          5081,
          51378
        ]
      },
      {
        "avg_logprob": -0.284575564190022,
        "compression_ratio": 1.5748502994011977,
        "end": 467.34,
        "id": 134,
        "no_speech_prob": 0.004982147365808487,
        "seek": 44414,
        "start": 464.41999999999996,
        "temperature": 0,
        "text": " by saying it's pronounced with the actual spelling of the name.",
        "tokens": [
          51378,
          538,
          1566,
          309,
          311,
          23155,
          365,
          264,
          3539,
          22254,
          295,
          264,
          1315,
          13,
          51524
        ]
      },
      {
        "avg_logprob": -0.284575564190022,
        "compression_ratio": 1.5748502994011977,
        "end": 468.3,
        "id": 135,
        "no_speech_prob": 0.004982147365808487,
        "seek": 44414,
        "start": 467.34,
        "temperature": 0,
        "text": " I will do my best.",
        "tokens": [
          51524,
          286,
          486,
          360,
          452,
          1151,
          13,
          51572
        ]
      },
      {
        "avg_logprob": -0.284575564190022,
        "compression_ratio": 1.5748502994011977,
        "end": 472.41999999999996,
        "id": 136,
        "no_speech_prob": 0.004982147365808487,
        "seek": 44414,
        "start": 471.58,
        "temperature": 0,
        "text": " Hello.",
        "tokens": [
          51736,
          2425,
          13,
          51778
        ]
      },
      {
        "avg_logprob": -0.25053611168494594,
        "compression_ratio": 1.8014705882352942,
        "end": 475.06,
        "id": 137,
        "no_speech_prob": 0.0006878331187181175,
        "seek": 47242,
        "start": 472.46000000000004,
        "temperature": 0,
        "text": " You are here watching another coding challenge.",
        "tokens": [
          50366,
          509,
          366,
          510,
          1976,
          1071,
          17720,
          3430,
          13,
          50496
        ]
      },
      {
        "avg_logprob": -0.25053611168494594,
        "compression_ratio": 1.8014705882352942,
        "end": 478.38,
        "id": 138,
        "no_speech_prob": 0.0006878331187181175,
        "seek": 47242,
        "start": 475.06,
        "temperature": 0,
        "text": " And this coding challenge, maybe this",
        "tokens": [
          50496,
          400,
          341,
          17720,
          3430,
          11,
          1310,
          341,
          50662
        ]
      },
      {
        "avg_logprob": -0.25053611168494594,
        "compression_ratio": 1.8014705882352942,
        "end": 480.82,
        "id": 139,
        "no_speech_prob": 0.0006878331187181175,
        "seek": 47242,
        "start": 478.38,
        "temperature": 0,
        "text": " should just fit and be in one of my tutorial videos.",
        "tokens": [
          50662,
          820,
          445,
          3318,
          293,
          312,
          294,
          472,
          295,
          452,
          7073,
          2145,
          13,
          50784
        ]
      },
      {
        "avg_logprob": -0.25053611168494594,
        "compression_ratio": 1.8014705882352942,
        "end": 482.58000000000004,
        "id": 140,
        "no_speech_prob": 0.0006878331187181175,
        "seek": 47242,
        "start": 480.82,
        "temperature": 0,
        "text": " But I'm going to make it a coding challenge",
        "tokens": [
          50784,
          583,
          286,
          478,
          516,
          281,
          652,
          309,
          257,
          17720,
          3430,
          50872
        ]
      },
      {
        "avg_logprob": -0.25053611168494594,
        "compression_ratio": 1.8014705882352942,
        "end": 484.62,
        "id": 141,
        "no_speech_prob": 0.0006878331187181175,
        "seek": 47242,
        "start": 482.58000000000004,
        "temperature": 0,
        "text": " because I'm going to attempt to do it in one video.",
        "tokens": [
          50872,
          570,
          286,
          478,
          516,
          281,
          5217,
          281,
          360,
          309,
          294,
          472,
          960,
          13,
          50974
        ]
      },
      {
        "avg_logprob": -0.25053611168494594,
        "compression_ratio": 1.8014705882352942,
        "end": 486.54,
        "id": 142,
        "no_speech_prob": 0.0006878331187181175,
        "seek": 47242,
        "start": 484.62,
        "temperature": 0,
        "text": " And what I'm doing is recreating something",
        "tokens": [
          50974,
          400,
          437,
          286,
          478,
          884,
          307,
          850,
          44613,
          746,
          51070
        ]
      },
      {
        "avg_logprob": -0.25053611168494594,
        "compression_ratio": 1.8014705882352942,
        "end": 489.74,
        "id": 143,
        "no_speech_prob": 0.0006878331187181175,
        "seek": 47242,
        "start": 486.54,
        "temperature": 0,
        "text": " that I've done before in some of my machine learning tutorials.",
        "tokens": [
          51070,
          300,
          286,
          600,
          1096,
          949,
          294,
          512,
          295,
          452,
          3479,
          2539,
          17616,
          13,
          51230
        ]
      },
      {
        "avg_logprob": -0.25053611168494594,
        "compression_ratio": 1.8014705882352942,
        "end": 492.22,
        "id": 144,
        "no_speech_prob": 0.0006878331187181175,
        "seek": 47242,
        "start": 489.74,
        "temperature": 0,
        "text": " And it was suggested here.",
        "tokens": [
          51230,
          400,
          309,
          390,
          10945,
          510,
          13,
          51354
        ]
      },
      {
        "avg_logprob": -0.25053611168494594,
        "compression_ratio": 1.8014705882352942,
        "end": 495.54,
        "id": 145,
        "no_speech_prob": 0.0006878331187181175,
        "seek": 47242,
        "start": 492.22,
        "temperature": 0,
        "text": " I don't know if it was suggested exactly, but a Twitter user,",
        "tokens": [
          51354,
          286,
          500,
          380,
          458,
          498,
          309,
          390,
          10945,
          2293,
          11,
          457,
          257,
          5794,
          4195,
          11,
          51520
        ]
      },
      {
        "avg_logprob": -0.25053611168494594,
        "compression_ratio": 1.8014705882352942,
        "end": 498.54,
        "id": 146,
        "no_speech_prob": 0.0006878331187181175,
        "seek": 47242,
        "start": 495.54,
        "temperature": 0,
        "text": " Calstube Old Pod Car, apologies if I'm pronouncing the name",
        "tokens": [
          51520,
          3511,
          372,
          1977,
          8633,
          12646,
          2741,
          11,
          34929,
          498,
          286,
          478,
          14144,
          2175,
          264,
          1315,
          51670
        ]
      },
      {
        "avg_logprob": -0.22446302795410156,
        "compression_ratio": 1.7703180212014133,
        "end": 502.86,
        "id": 147,
        "no_speech_prob": 0.0001609286555321887,
        "seek": 49854,
        "start": 498.54,
        "temperature": 0,
        "text": " incorrectly, created this interactive simulation",
        "tokens": [
          50364,
          42892,
          11,
          2942,
          341,
          15141,
          16575,
          50580
        ]
      },
      {
        "avg_logprob": -0.22446302795410156,
        "compression_ratio": 1.7703180212014133,
        "end": 506.26000000000005,
        "id": 148,
        "no_speech_prob": 0.0001609286555321887,
        "seek": 49854,
        "start": 502.86,
        "temperature": 0,
        "text": " of linear regression using TensorFlow.js.",
        "tokens": [
          50580,
          295,
          8213,
          24590,
          1228,
          37624,
          13,
          25530,
          13,
          50750
        ]
      },
      {
        "avg_logprob": -0.22446302795410156,
        "compression_ratio": 1.7703180212014133,
        "end": 508.90000000000003,
        "id": 149,
        "no_speech_prob": 0.0001609286555321887,
        "seek": 49854,
        "start": 506.26000000000005,
        "temperature": 0,
        "text": " And so this is very similar to something",
        "tokens": [
          50750,
          400,
          370,
          341,
          307,
          588,
          2531,
          281,
          746,
          50882
        ]
      },
      {
        "avg_logprob": -0.22446302795410156,
        "compression_ratio": 1.7703180212014133,
        "end": 510.38,
        "id": 150,
        "no_speech_prob": 0.0001609286555321887,
        "seek": 49854,
        "start": 508.90000000000003,
        "temperature": 0,
        "text": " that I've done previously.",
        "tokens": [
          50882,
          300,
          286,
          600,
          1096,
          8046,
          13,
          50956
        ]
      },
      {
        "avg_logprob": -0.22446302795410156,
        "compression_ratio": 1.7703180212014133,
        "end": 511.86,
        "id": 151,
        "no_speech_prob": 0.0001609286555321887,
        "seek": 49854,
        "start": 510.38,
        "temperature": 0,
        "text": " I have this video, Linear Regression",
        "tokens": [
          50956,
          286,
          362,
          341,
          960,
          11,
          14670,
          289,
          4791,
          2775,
          51030
        ]
      },
      {
        "avg_logprob": -0.22446302795410156,
        "compression_ratio": 1.7703180212014133,
        "end": 513.46,
        "id": 152,
        "no_speech_prob": 0.0001609286555321887,
        "seek": 49854,
        "start": 511.86,
        "temperature": 0,
        "text": " with Gradient Descent, where I just",
        "tokens": [
          51030,
          365,
          16710,
          1196,
          3885,
          2207,
          11,
          689,
          286,
          445,
          51110
        ]
      },
      {
        "avg_logprob": -0.22446302795410156,
        "compression_ratio": 1.7703180212014133,
        "end": 515.7,
        "id": 153,
        "no_speech_prob": 0.0001609286555321887,
        "seek": 49854,
        "start": 513.46,
        "temperature": 0,
        "text": " did this with plain JavaScript.",
        "tokens": [
          51110,
          630,
          341,
          365,
          11121,
          15778,
          13,
          51222
        ]
      },
      {
        "avg_logprob": -0.22446302795410156,
        "compression_ratio": 1.7703180212014133,
        "end": 517.9,
        "id": 154,
        "no_speech_prob": 0.0001609286555321887,
        "seek": 49854,
        "start": 515.7,
        "temperature": 0,
        "text": " And then you could also look at this other video,",
        "tokens": [
          51222,
          400,
          550,
          291,
          727,
          611,
          574,
          412,
          341,
          661,
          960,
          11,
          51332
        ]
      },
      {
        "avg_logprob": -0.22446302795410156,
        "compression_ratio": 1.7703180212014133,
        "end": 520.2,
        "id": 155,
        "no_speech_prob": 0.0001609286555321887,
        "seek": 49854,
        "start": 517.9,
        "temperature": 0,
        "text": " which I go through the mathematics of gradient descent",
        "tokens": [
          51332,
          597,
          286,
          352,
          807,
          264,
          18666,
          295,
          16235,
          23475,
          51447
        ]
      },
      {
        "avg_logprob": -0.22446302795410156,
        "compression_ratio": 1.7703180212014133,
        "end": 520.82,
        "id": 156,
        "no_speech_prob": 0.0001609286555321887,
        "seek": 49854,
        "start": 520.2,
        "temperature": 0,
        "text": " a little bit.",
        "tokens": [
          51447,
          257,
          707,
          857,
          13,
          51478
        ]
      },
      {
        "avg_logprob": -0.22446302795410156,
        "compression_ratio": 1.7703180212014133,
        "end": 522.3000000000001,
        "id": 157,
        "no_speech_prob": 0.0001609286555321887,
        "seek": 49854,
        "start": 520.82,
        "temperature": 0,
        "text": " But here's the thing.",
        "tokens": [
          51478,
          583,
          510,
          311,
          264,
          551,
          13,
          51552
        ]
      },
      {
        "avg_logprob": -0.22446302795410156,
        "compression_ratio": 1.7703180212014133,
        "end": 525.1,
        "id": 158,
        "no_speech_prob": 0.0001609286555321887,
        "seek": 49854,
        "start": 522.3000000000001,
        "temperature": 0,
        "text": " Going through the mathematics, making this video",
        "tokens": [
          51552,
          10963,
          807,
          264,
          18666,
          11,
          1455,
          341,
          960,
          51692
        ]
      },
      {
        "avg_logprob": -0.22446302795410156,
        "compression_ratio": 1.7703180212014133,
        "end": 527.14,
        "id": 159,
        "no_speech_prob": 0.0001609286555321887,
        "seek": 49854,
        "start": 525.1,
        "temperature": 0,
        "text": " where I implement the mathematics in JavaScript",
        "tokens": [
          51692,
          689,
          286,
          4445,
          264,
          18666,
          294,
          15778,
          51794
        ]
      },
      {
        "avg_logprob": -0.25542082105364117,
        "compression_ratio": 1.591743119266055,
        "end": 530.34,
        "id": 160,
        "no_speech_prob": 0.000029311520847841166,
        "seek": 52714,
        "start": 527.14,
        "temperature": 0,
        "text": " while useful, and perhaps background for this video,",
        "tokens": [
          50364,
          1339,
          4420,
          11,
          293,
          4317,
          3678,
          337,
          341,
          960,
          11,
          50524
        ]
      },
      {
        "avg_logprob": -0.25542082105364117,
        "compression_ratio": 1.591743119266055,
        "end": 533.74,
        "id": 161,
        "no_speech_prob": 0.000029311520847841166,
        "seek": 52714,
        "start": 530.34,
        "temperature": 0,
        "text": " one of the exciting things about doing this with TensorFlow.js",
        "tokens": [
          50524,
          472,
          295,
          264,
          4670,
          721,
          466,
          884,
          341,
          365,
          37624,
          13,
          25530,
          50694
        ]
      },
      {
        "avg_logprob": -0.25542082105364117,
        "compression_ratio": 1.591743119266055,
        "end": 541.34,
        "id": 162,
        "no_speech_prob": 0.000029311520847841166,
        "seek": 52714,
        "start": 533.74,
        "temperature": 0,
        "text": " is TensorFlow.js has a nice API for optimizing loss functions",
        "tokens": [
          50694,
          307,
          37624,
          13,
          25530,
          575,
          257,
          1481,
          9362,
          337,
          40425,
          4470,
          6828,
          51074
        ]
      },
      {
        "avg_logprob": -0.25542082105364117,
        "compression_ratio": 1.591743119266055,
        "end": 544.66,
        "id": 163,
        "no_speech_prob": 0.000029311520847841166,
        "seek": 52714,
        "start": 541.34,
        "temperature": 0,
        "text": " with the gradient descent algorithm built into it.",
        "tokens": [
          51074,
          365,
          264,
          16235,
          23475,
          9284,
          3094,
          666,
          309,
          13,
          51240
        ]
      },
      {
        "avg_logprob": -0.25542082105364117,
        "compression_ratio": 1.591743119266055,
        "end": 545.9,
        "id": 164,
        "no_speech_prob": 0.000029311520847841166,
        "seek": 52714,
        "start": 544.66,
        "temperature": 0,
        "text": " So I could just do things.",
        "tokens": [
          51240,
          407,
          286,
          727,
          445,
          360,
          721,
          13,
          51302
        ]
      },
      {
        "avg_logprob": -0.25542082105364117,
        "compression_ratio": 1.591743119266055,
        "end": 546.74,
        "id": 165,
        "no_speech_prob": 0.000029311520847841166,
        "seek": 52714,
        "start": 545.9,
        "temperature": 0,
        "text": " So let's make a list.",
        "tokens": [
          51302,
          407,
          718,
          311,
          652,
          257,
          1329,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.25542082105364117,
        "compression_ratio": 1.591743119266055,
        "end": 548.74,
        "id": 166,
        "no_speech_prob": 0.000029311520847841166,
        "seek": 52714,
        "start": 546.74,
        "temperature": 0,
        "text": " I got to come back here, but let's make a list.",
        "tokens": [
          51344,
          286,
          658,
          281,
          808,
          646,
          510,
          11,
          457,
          718,
          311,
          652,
          257,
          1329,
          13,
          51444
        ]
      },
      {
        "avg_logprob": -0.25542082105364117,
        "compression_ratio": 1.591743119266055,
        "end": 549.66,
        "id": 167,
        "no_speech_prob": 0.000029311520847841166,
        "seek": 52714,
        "start": 548.74,
        "temperature": 0,
        "text": " Oh, hold on.",
        "tokens": [
          51444,
          876,
          11,
          1797,
          322,
          13,
          51490
        ]
      },
      {
        "avg_logprob": -0.25542082105364117,
        "compression_ratio": 1.591743119266055,
        "end": 554.52,
        "id": 168,
        "no_speech_prob": 0.000029311520847841166,
        "seek": 52714,
        "start": 554.02,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          51708,
          6962,
          322,
          13,
          51733
        ]
      },
      {
        "avg_logprob": -0.3766149174083363,
        "compression_ratio": 1.430232558139535,
        "end": 557.64,
        "id": 169,
        "no_speech_prob": 0.00003120099790976383,
        "seek": 55714,
        "start": 557.14,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          50364,
          6962,
          322,
          13,
          50389
        ]
      },
      {
        "avg_logprob": -0.3766149174083363,
        "compression_ratio": 1.430232558139535,
        "end": 567.04,
        "id": 170,
        "no_speech_prob": 0.00003120099790976383,
        "seek": 55714,
        "start": 566.54,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50834,
          2264,
          13,
          50859
        ]
      },
      {
        "avg_logprob": -0.3766149174083363,
        "compression_ratio": 1.430232558139535,
        "end": 573.06,
        "id": 171,
        "no_speech_prob": 0.00003120099790976383,
        "seek": 55714,
        "start": 570.02,
        "temperature": 0,
        "text": " The things that I'm going to need, right?",
        "tokens": [
          51008,
          440,
          721,
          300,
          286,
          478,
          516,
          281,
          643,
          11,
          558,
          30,
          51160
        ]
      },
      {
        "avg_logprob": -0.3766149174083363,
        "compression_ratio": 1.430232558139535,
        "end": 574.74,
        "id": 172,
        "no_speech_prob": 0.00003120099790976383,
        "seek": 55714,
        "start": 573.06,
        "temperature": 0,
        "text": " I need to have.",
        "tokens": [
          51160,
          286,
          643,
          281,
          362,
          13,
          51244
        ]
      },
      {
        "avg_logprob": -0.3766149174083363,
        "compression_ratio": 1.430232558139535,
        "end": 575.22,
        "id": 173,
        "no_speech_prob": 0.00003120099790976383,
        "seek": 55714,
        "start": 574.74,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51244,
          2264,
          13,
          51268
        ]
      },
      {
        "avg_logprob": -0.3766149174083363,
        "compression_ratio": 1.430232558139535,
        "end": 576.22,
        "id": 174,
        "no_speech_prob": 0.00003120099790976383,
        "seek": 55714,
        "start": 575.22,
        "temperature": 0,
        "text": " So what's going on here?",
        "tokens": [
          51268,
          407,
          437,
          311,
          516,
          322,
          510,
          30,
          51318
        ]
      },
      {
        "avg_logprob": -0.3766149174083363,
        "compression_ratio": 1.430232558139535,
        "end": 578.54,
        "id": 175,
        "no_speech_prob": 0.00003120099790976383,
        "seek": 55714,
        "start": 576.22,
        "temperature": 0,
        "text": " What is linear regression, first of all?",
        "tokens": [
          51318,
          708,
          307,
          8213,
          24590,
          11,
          700,
          295,
          439,
          30,
          51434
        ]
      },
      {
        "avg_logprob": -0.3766149174083363,
        "compression_ratio": 1.430232558139535,
        "end": 583.06,
        "id": 176,
        "no_speech_prob": 0.00003120099790976383,
        "seek": 55714,
        "start": 578.54,
        "temperature": 0,
        "text": " And of course, you can compute the eq-",
        "tokens": [
          51434,
          400,
          295,
          1164,
          11,
          291,
          393,
          14722,
          264,
          308,
          80,
          12,
          51660
        ]
      },
      {
        "avg_logprob": -0.3766149174083363,
        "compression_ratio": 1.430232558139535,
        "end": 584.26,
        "id": 177,
        "no_speech_prob": 0.00003120099790976383,
        "seek": 55714,
        "start": 583.06,
        "temperature": 0,
        "text": " Let me do that again.",
        "tokens": [
          51660,
          961,
          385,
          360,
          300,
          797,
          13,
          51720
        ]
      },
      {
        "avg_logprob": -0.3766149174083363,
        "compression_ratio": 1.430232558139535,
        "end": 586.1,
        "id": 178,
        "no_speech_prob": 0.00003120099790976383,
        "seek": 55714,
        "start": 584.26,
        "temperature": 0,
        "text": " I was going to do this as a coding challenge",
        "tokens": [
          51720,
          286,
          390,
          516,
          281,
          360,
          341,
          382,
          257,
          17720,
          3430,
          51812
        ]
      },
      {
        "avg_logprob": -0.20351226513202375,
        "compression_ratio": 1.5446428571428572,
        "end": 590.7,
        "id": 179,
        "no_speech_prob": 0.0000035008501981792506,
        "seek": 58610,
        "start": 586.1,
        "temperature": 0,
        "text": " with no editing, but so much for that.",
        "tokens": [
          50364,
          365,
          572,
          10000,
          11,
          457,
          370,
          709,
          337,
          300,
          13,
          50594
        ]
      },
      {
        "avg_logprob": -0.20351226513202375,
        "compression_ratio": 1.5446428571428572,
        "end": 591.2,
        "id": 180,
        "no_speech_prob": 0.0000035008501981792506,
        "seek": 58610,
        "start": 590.7,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50594,
          1057,
          558,
          13,
          50619
        ]
      },
      {
        "avg_logprob": -0.20351226513202375,
        "compression_ratio": 1.5446428571428572,
        "end": 596.14,
        "id": 181,
        "no_speech_prob": 0.0000035008501981792506,
        "seek": 58610,
        "start": 591.2,
        "temperature": 0,
        "text": " So first of all, what is linear regression anyway?",
        "tokens": [
          50619,
          407,
          700,
          295,
          439,
          11,
          437,
          307,
          8213,
          24590,
          4033,
          30,
          50866
        ]
      },
      {
        "avg_logprob": -0.20351226513202375,
        "compression_ratio": 1.5446428571428572,
        "end": 598.22,
        "id": 182,
        "no_speech_prob": 0.0000035008501981792506,
        "seek": 58610,
        "start": 596.14,
        "temperature": 0,
        "text": " So let's say we have a space.",
        "tokens": [
          50866,
          407,
          718,
          311,
          584,
          321,
          362,
          257,
          1901,
          13,
          50970
        ]
      },
      {
        "avg_logprob": -0.20351226513202375,
        "compression_ratio": 1.5446428571428572,
        "end": 599.98,
        "id": 183,
        "no_speech_prob": 0.0000035008501981792506,
        "seek": 58610,
        "start": 598.22,
        "temperature": 0,
        "text": " And I drew this as like a canvas,",
        "tokens": [
          50970,
          400,
          286,
          12804,
          341,
          382,
          411,
          257,
          16267,
          11,
          51058
        ]
      },
      {
        "avg_logprob": -0.20351226513202375,
        "compression_ratio": 1.5446428571428572,
        "end": 601.4200000000001,
        "id": 184,
        "no_speech_prob": 0.0000035008501981792506,
        "seek": 58610,
        "start": 599.98,
        "temperature": 0,
        "text": " but really I should be talking just",
        "tokens": [
          51058,
          457,
          534,
          286,
          820,
          312,
          1417,
          445,
          51130
        ]
      },
      {
        "avg_logprob": -0.20351226513202375,
        "compression_ratio": 1.5446428571428572,
        "end": 606.3000000000001,
        "id": 185,
        "no_speech_prob": 0.0000035008501981792506,
        "seek": 58610,
        "start": 601.4200000000001,
        "temperature": 0,
        "text": " about a generic kind of two-dimensional Cartesian plane.",
        "tokens": [
          51130,
          466,
          257,
          19577,
          733,
          295,
          732,
          12,
          18759,
          22478,
          42434,
          5720,
          13,
          51374
        ]
      },
      {
        "avg_logprob": -0.20351226513202375,
        "compression_ratio": 1.5446428571428572,
        "end": 608.78,
        "id": 186,
        "no_speech_prob": 0.0000035008501981792506,
        "seek": 58610,
        "start": 606.3000000000001,
        "temperature": 0,
        "text": " And in that plane, there are a lot of points.",
        "tokens": [
          51374,
          400,
          294,
          300,
          5720,
          11,
          456,
          366,
          257,
          688,
          295,
          2793,
          13,
          51498
        ]
      },
      {
        "avg_logprob": -0.20351226513202375,
        "compression_ratio": 1.5446428571428572,
        "end": 610.5400000000001,
        "id": 187,
        "no_speech_prob": 0.0000035008501981792506,
        "seek": 58610,
        "start": 608.78,
        "temperature": 0,
        "text": " And I don't like the way I just drew that.",
        "tokens": [
          51498,
          400,
          286,
          500,
          380,
          411,
          264,
          636,
          286,
          445,
          12804,
          300,
          13,
          51586
        ]
      },
      {
        "avg_logprob": -0.23653275939239854,
        "compression_ratio": 1.5314009661835748,
        "end": 621.66,
        "id": 188,
        "no_speech_prob": 4.0525452504880377e-7,
        "seek": 61610,
        "start": 616.9,
        "temperature": 0,
        "text": " In that plane, there are a bunch of points.",
        "tokens": [
          50404,
          682,
          300,
          5720,
          11,
          456,
          366,
          257,
          3840,
          295,
          2793,
          13,
          50642
        ]
      },
      {
        "avg_logprob": -0.23653275939239854,
        "compression_ratio": 1.5314009661835748,
        "end": 626.78,
        "id": 189,
        "no_speech_prob": 4.0525452504880377e-7,
        "seek": 61610,
        "start": 621.66,
        "temperature": 0,
        "text": " The idea of linear regression is to figure out, can we fit?",
        "tokens": [
          50642,
          440,
          1558,
          295,
          8213,
          24590,
          307,
          281,
          2573,
          484,
          11,
          393,
          321,
          3318,
          30,
          50898
        ]
      },
      {
        "avg_logprob": -0.23653275939239854,
        "compression_ratio": 1.5314009661835748,
        "end": 630.22,
        "id": 190,
        "no_speech_prob": 4.0525452504880377e-7,
        "seek": 61610,
        "start": 626.78,
        "temperature": 0,
        "text": " Oh, this is a time for another colored marker.",
        "tokens": [
          50898,
          876,
          11,
          341,
          307,
          257,
          565,
          337,
          1071,
          14332,
          15247,
          13,
          51070
        ]
      },
      {
        "avg_logprob": -0.23653275939239854,
        "compression_ratio": 1.5314009661835748,
        "end": 635.26,
        "id": 191,
        "no_speech_prob": 4.0525452504880377e-7,
        "seek": 61610,
        "start": 630.22,
        "temperature": 0,
        "text": " Can we fit a line into this two-dimensional space",
        "tokens": [
          51070,
          1664,
          321,
          3318,
          257,
          1622,
          666,
          341,
          732,
          12,
          18759,
          1901,
          51322
        ]
      },
      {
        "avg_logprob": -0.23653275939239854,
        "compression_ratio": 1.5314009661835748,
        "end": 638.0600000000001,
        "id": 192,
        "no_speech_prob": 4.0525452504880377e-7,
        "seek": 61610,
        "start": 635.26,
        "temperature": 0,
        "text": " that approximates all of these points as best we can?",
        "tokens": [
          51322,
          300,
          8542,
          1024,
          439,
          295,
          613,
          2793,
          382,
          1151,
          321,
          393,
          30,
          51462
        ]
      },
      {
        "avg_logprob": -0.23653275939239854,
        "compression_ratio": 1.5314009661835748,
        "end": 642.94,
        "id": 193,
        "no_speech_prob": 4.0525452504880377e-7,
        "seek": 61610,
        "start": 638.0600000000001,
        "temperature": 0,
        "text": " And I can visually just kind of make myself do this like this.",
        "tokens": [
          51462,
          400,
          286,
          393,
          19622,
          445,
          733,
          295,
          652,
          2059,
          360,
          341,
          411,
          341,
          13,
          51706
        ]
      },
      {
        "avg_logprob": -0.2256347356217631,
        "compression_ratio": 1.5507246376811594,
        "end": 646.1,
        "id": 194,
        "no_speech_prob": 0.0000016280511090371874,
        "seek": 64294,
        "start": 642.94,
        "temperature": 0,
        "text": " So I can eyeball it and say, this line kind of gets close.",
        "tokens": [
          50364,
          407,
          286,
          393,
          38868,
          309,
          293,
          584,
          11,
          341,
          1622,
          733,
          295,
          2170,
          1998,
          13,
          50522
        ]
      },
      {
        "avg_logprob": -0.2256347356217631,
        "compression_ratio": 1.5507246376811594,
        "end": 652.74,
        "id": 195,
        "no_speech_prob": 0.0000016280511090371874,
        "seek": 64294,
        "start": 646.1,
        "temperature": 0,
        "text": " What we're trying to do is minimize all of these.",
        "tokens": [
          50522,
          708,
          321,
          434,
          1382,
          281,
          360,
          307,
          17522,
          439,
          295,
          613,
          13,
          50854
        ]
      },
      {
        "avg_logprob": -0.2256347356217631,
        "compression_ratio": 1.5507246376811594,
        "end": 654.82,
        "id": 196,
        "no_speech_prob": 0.0000016280511090371874,
        "seek": 64294,
        "start": 652.74,
        "temperature": 0,
        "text": " This is the most beautiful diagram I've ever made.",
        "tokens": [
          50854,
          639,
          307,
          264,
          881,
          2238,
          10686,
          286,
          600,
          1562,
          1027,
          13,
          50958
        ]
      },
      {
        "avg_logprob": -0.2256347356217631,
        "compression_ratio": 1.5507246376811594,
        "end": 658.0600000000001,
        "id": 197,
        "no_speech_prob": 0.0000016280511090371874,
        "seek": 64294,
        "start": 654.82,
        "temperature": 0,
        "text": " All of these distances of all of the points to the line.",
        "tokens": [
          50958,
          1057,
          295,
          613,
          22182,
          295,
          439,
          295,
          264,
          2793,
          281,
          264,
          1622,
          13,
          51120
        ]
      },
      {
        "avg_logprob": -0.2256347356217631,
        "compression_ratio": 1.5507246376811594,
        "end": 661.5400000000001,
        "id": 198,
        "no_speech_prob": 0.0000016280511090371874,
        "seek": 64294,
        "start": 658.0600000000001,
        "temperature": 0,
        "text": " The idea here then is that we can make some predictions.",
        "tokens": [
          51120,
          440,
          1558,
          510,
          550,
          307,
          300,
          321,
          393,
          652,
          512,
          21264,
          13,
          51294
        ]
      },
      {
        "avg_logprob": -0.2256347356217631,
        "compression_ratio": 1.5507246376811594,
        "end": 670.34,
        "id": 199,
        "no_speech_prob": 0.0000016280511090371874,
        "seek": 64294,
        "start": 661.5400000000001,
        "temperature": 0,
        "text": " If this data, if this x-axis represents height,",
        "tokens": [
          51294,
          759,
          341,
          1412,
          11,
          498,
          341,
          2031,
          12,
          24633,
          8855,
          6681,
          11,
          51734
        ]
      },
      {
        "avg_logprob": -0.19999843562414887,
        "compression_ratio": 1.6260504201680672,
        "end": 676.46,
        "id": 200,
        "no_speech_prob": 0.0000013925453004048904,
        "seek": 67034,
        "start": 670.38,
        "temperature": 0,
        "text": " we might predict on the y-axis weight.",
        "tokens": [
          50366,
          321,
          1062,
          6069,
          322,
          264,
          288,
          12,
          24633,
          3364,
          13,
          50670
        ]
      },
      {
        "avg_logprob": -0.19999843562414887,
        "compression_ratio": 1.6260504201680672,
        "end": 681.1,
        "id": 201,
        "no_speech_prob": 0.0000013925453004048904,
        "seek": 67034,
        "start": 676.46,
        "temperature": 0,
        "text": " You can think of kinds of data sets, simple 2D data",
        "tokens": [
          50670,
          509,
          393,
          519,
          295,
          3685,
          295,
          1412,
          6352,
          11,
          2199,
          568,
          35,
          1412,
          50902
        ]
      },
      {
        "avg_logprob": -0.19999843562414887,
        "compression_ratio": 1.6260504201680672,
        "end": 686.26,
        "id": 202,
        "no_speech_prob": 0.0000013925453004048904,
        "seek": 67034,
        "start": 681.1,
        "temperature": 0,
        "text": " sets, where there's a linear relationship between one",
        "tokens": [
          50902,
          6352,
          11,
          689,
          456,
          311,
          257,
          8213,
          2480,
          1296,
          472,
          51160
        ]
      },
      {
        "avg_logprob": -0.19999843562414887,
        "compression_ratio": 1.6260504201680672,
        "end": 688.5,
        "id": 203,
        "no_speech_prob": 0.0000013925453004048904,
        "seek": 67034,
        "start": 686.26,
        "temperature": 0,
        "text": " field of data and another field of data.",
        "tokens": [
          51160,
          2519,
          295,
          1412,
          293,
          1071,
          2519,
          295,
          1412,
          13,
          51272
        ]
      },
      {
        "avg_logprob": -0.19999843562414887,
        "compression_ratio": 1.6260504201680672,
        "end": 691.0600000000001,
        "id": 204,
        "no_speech_prob": 0.0000013925453004048904,
        "seek": 67034,
        "start": 688.5,
        "temperature": 0,
        "text": " So if we pick a new height, we can kind of",
        "tokens": [
          51272,
          407,
          498,
          321,
          1888,
          257,
          777,
          6681,
          11,
          321,
          393,
          733,
          295,
          51400
        ]
      },
      {
        "avg_logprob": -0.19999843562414887,
        "compression_ratio": 1.6260504201680672,
        "end": 693.6600000000001,
        "id": 205,
        "no_speech_prob": 0.0000013925453004048904,
        "seek": 67034,
        "start": 691.0600000000001,
        "temperature": 0,
        "text": " make a guess approximately what that weight is going to be.",
        "tokens": [
          51400,
          652,
          257,
          2041,
          10447,
          437,
          300,
          3364,
          307,
          516,
          281,
          312,
          13,
          51530
        ]
      },
      {
        "avg_logprob": -0.19999843562414887,
        "compression_ratio": 1.6260504201680672,
        "end": 695.1800000000001,
        "id": 206,
        "no_speech_prob": 0.0000013925453004048904,
        "seek": 67034,
        "start": 693.6600000000001,
        "temperature": 0,
        "text": " That's the idea of linear regression.",
        "tokens": [
          51530,
          663,
          311,
          264,
          1558,
          295,
          8213,
          24590,
          13,
          51606
        ]
      },
      {
        "avg_logprob": -0.19999843562414887,
        "compression_ratio": 1.6260504201680672,
        "end": 696.7,
        "id": 207,
        "no_speech_prob": 0.0000013925453004048904,
        "seek": 67034,
        "start": 695.1800000000001,
        "temperature": 0,
        "text": " It's incredibly simple.",
        "tokens": [
          51606,
          467,
          311,
          6252,
          2199,
          13,
          51682
        ]
      },
      {
        "avg_logprob": -0.19999843562414887,
        "compression_ratio": 1.6260504201680672,
        "end": 699.1,
        "id": 208,
        "no_speech_prob": 0.0000013925453004048904,
        "seek": 67034,
        "start": 696.7,
        "temperature": 0,
        "text": " A lot of data isn't two-dimensional.",
        "tokens": [
          51682,
          316,
          688,
          295,
          1412,
          1943,
          380,
          732,
          12,
          18759,
          13,
          51802
        ]
      },
      {
        "avg_logprob": -0.21646134303166317,
        "compression_ratio": 1.7317073170731707,
        "end": 701.4200000000001,
        "id": 209,
        "no_speech_prob": 0.000002368797140661627,
        "seek": 69910,
        "start": 699.1,
        "temperature": 0,
        "text": " A lot of data doesn't fit a line.",
        "tokens": [
          50364,
          316,
          688,
          295,
          1412,
          1177,
          380,
          3318,
          257,
          1622,
          13,
          50480
        ]
      },
      {
        "avg_logprob": -0.21646134303166317,
        "compression_ratio": 1.7317073170731707,
        "end": 702.82,
        "id": 210,
        "no_speech_prob": 0.000002368797140661627,
        "seek": 69910,
        "start": 701.4200000000001,
        "temperature": 0,
        "text": " Maybe a curve fits it better.",
        "tokens": [
          50480,
          2704,
          257,
          7605,
          9001,
          309,
          1101,
          13,
          50550
        ]
      },
      {
        "avg_logprob": -0.21646134303166317,
        "compression_ratio": 1.7317073170731707,
        "end": 705.1,
        "id": 211,
        "no_speech_prob": 0.000002368797140661627,
        "seek": 69910,
        "start": 702.82,
        "temperature": 0,
        "text": " And this is more complex scenarios",
        "tokens": [
          50550,
          400,
          341,
          307,
          544,
          3997,
          15077,
          50664
        ]
      },
      {
        "avg_logprob": -0.21646134303166317,
        "compression_ratio": 1.7317073170731707,
        "end": 708.98,
        "id": 212,
        "no_speech_prob": 0.000002368797140661627,
        "seek": 69910,
        "start": 705.1,
        "temperature": 0,
        "text": " will come as we move forward and make more scenarios",
        "tokens": [
          50664,
          486,
          808,
          382,
          321,
          1286,
          2128,
          293,
          652,
          544,
          15077,
          50858
        ]
      },
      {
        "avg_logprob": -0.21646134303166317,
        "compression_ratio": 1.7317073170731707,
        "end": 711.34,
        "id": 213,
        "no_speech_prob": 0.000002368797140661627,
        "seek": 69910,
        "start": 708.98,
        "temperature": 0,
        "text": " with complex polynomial equations,",
        "tokens": [
          50858,
          365,
          3997,
          26110,
          11787,
          11,
          50976
        ]
      },
      {
        "avg_logprob": -0.21646134303166317,
        "compression_ratio": 1.7317073170731707,
        "end": 712.86,
        "id": 214,
        "no_speech_prob": 0.000002368797140661627,
        "seek": 69910,
        "start": 711.34,
        "temperature": 0,
        "text": " or neural network-based learning,",
        "tokens": [
          50976,
          420,
          18161,
          3209,
          12,
          6032,
          2539,
          11,
          51052
        ]
      },
      {
        "avg_logprob": -0.21646134303166317,
        "compression_ratio": 1.7317073170731707,
        "end": 714.82,
        "id": 215,
        "no_speech_prob": 0.000002368797140661627,
        "seek": 69910,
        "start": 712.86,
        "temperature": 0,
        "text": " and other types of machine learning algorithms.",
        "tokens": [
          51052,
          293,
          661,
          3467,
          295,
          3479,
          2539,
          14642,
          13,
          51150
        ]
      },
      {
        "avg_logprob": -0.21646134303166317,
        "compression_ratio": 1.7317073170731707,
        "end": 717.1800000000001,
        "id": 216,
        "no_speech_prob": 0.000002368797140661627,
        "seek": 69910,
        "start": 714.82,
        "temperature": 0,
        "text": " But this is a good place for us to start.",
        "tokens": [
          51150,
          583,
          341,
          307,
          257,
          665,
          1081,
          337,
          505,
          281,
          722,
          13,
          51268
        ]
      },
      {
        "avg_logprob": -0.21646134303166317,
        "compression_ratio": 1.7317073170731707,
        "end": 718.38,
        "id": 217,
        "no_speech_prob": 0.000002368797140661627,
        "seek": 69910,
        "start": 717.1800000000001,
        "temperature": 0,
        "text": " So what do we need?",
        "tokens": [
          51268,
          407,
          437,
          360,
          321,
          643,
          30,
          51328
        ]
      },
      {
        "avg_logprob": -0.21646134303166317,
        "compression_ratio": 1.7317073170731707,
        "end": 720.62,
        "id": 218,
        "no_speech_prob": 0.000002368797140661627,
        "seek": 69910,
        "start": 718.38,
        "temperature": 0,
        "text": " We need a data set.",
        "tokens": [
          51328,
          492,
          643,
          257,
          1412,
          992,
          13,
          51440
        ]
      },
      {
        "avg_logprob": -0.21646134303166317,
        "compression_ratio": 1.7317073170731707,
        "end": 723.58,
        "id": 219,
        "no_speech_prob": 0.000002368797140661627,
        "seek": 69910,
        "start": 720.62,
        "temperature": 0,
        "text": " So we need a set of x's and y's.",
        "tokens": [
          51440,
          407,
          321,
          643,
          257,
          992,
          295,
          2031,
          311,
          293,
          288,
          311,
          13,
          51588
        ]
      },
      {
        "avg_logprob": -0.21646134303166317,
        "compression_ratio": 1.7317073170731707,
        "end": 724.6600000000001,
        "id": 220,
        "no_speech_prob": 0.000002368797140661627,
        "seek": 69910,
        "start": 723.58,
        "temperature": 0,
        "text": " This is the data set.",
        "tokens": [
          51588,
          639,
          307,
          264,
          1412,
          992,
          13,
          51642
        ]
      },
      {
        "avg_logprob": -0.21646134303166317,
        "compression_ratio": 1.7317073170731707,
        "end": 728.94,
        "id": 221,
        "no_speech_prob": 0.000002368797140661627,
        "seek": 69910,
        "start": 727.58,
        "temperature": 0,
        "text": " We need x's and y's.",
        "tokens": [
          51788,
          492,
          643,
          2031,
          311,
          293,
          288,
          311,
          13,
          51856
        ]
      },
      {
        "avg_logprob": -0.2784858467304601,
        "compression_ratio": 1.9035087719298245,
        "end": 731.2600000000001,
        "id": 222,
        "no_speech_prob": 0.000019223141862312332,
        "seek": 72894,
        "start": 729.7800000000001,
        "temperature": 0,
        "text": " And I'm going to create that data set",
        "tokens": [
          50406,
          400,
          286,
          478,
          516,
          281,
          1884,
          300,
          1412,
          992,
          50480
        ]
      },
      {
        "avg_logprob": -0.2784858467304601,
        "compression_ratio": 1.9035087719298245,
        "end": 733.86,
        "id": 223,
        "no_speech_prob": 0.000019223141862312332,
        "seek": 72894,
        "start": 731.2600000000001,
        "temperature": 0,
        "text": " through interactive clicking.",
        "tokens": [
          50480,
          807,
          15141,
          9697,
          13,
          50610
        ]
      },
      {
        "avg_logprob": -0.2784858467304601,
        "compression_ratio": 1.9035087719298245,
        "end": 735.34,
        "id": 224,
        "no_speech_prob": 0.000019223141862312332,
        "seek": 72894,
        "start": 733.86,
        "temperature": 0,
        "text": " Interactive clicking is the way I'm",
        "tokens": [
          50610,
          5751,
          12596,
          9697,
          307,
          264,
          636,
          286,
          478,
          50684
        ]
      },
      {
        "avg_logprob": -0.2784858467304601,
        "compression_ratio": 1.9035087719298245,
        "end": 738.9000000000001,
        "id": 225,
        "no_speech_prob": 0.000019223141862312332,
        "seek": 72894,
        "start": 735.34,
        "temperature": 0,
        "text": " going to create that data set with the mouse.",
        "tokens": [
          50684,
          516,
          281,
          1884,
          300,
          1412,
          992,
          365,
          264,
          9719,
          13,
          50862
        ]
      },
      {
        "avg_logprob": -0.2784858467304601,
        "compression_ratio": 1.9035087719298245,
        "end": 743.74,
        "id": 226,
        "no_speech_prob": 0.000019223141862312332,
        "seek": 72894,
        "start": 738.9000000000001,
        "temperature": 0,
        "text": " I need to have something called a loss function.",
        "tokens": [
          50862,
          286,
          643,
          281,
          362,
          746,
          1219,
          257,
          4470,
          2445,
          13,
          51104
        ]
      },
      {
        "avg_logprob": -0.2784858467304601,
        "compression_ratio": 1.9035087719298245,
        "end": 747.22,
        "id": 227,
        "no_speech_prob": 0.000019223141862312332,
        "seek": 72894,
        "start": 743.74,
        "temperature": 0,
        "text": " The loss function is a way of computing the error.",
        "tokens": [
          51104,
          440,
          4470,
          2445,
          307,
          257,
          636,
          295,
          15866,
          264,
          6713,
          13,
          51278
        ]
      },
      {
        "avg_logprob": -0.2784858467304601,
        "compression_ratio": 1.9035087719298245,
        "end": 749.5400000000001,
        "id": 228,
        "no_speech_prob": 0.000019223141862312332,
        "seek": 72894,
        "start": 747.22,
        "temperature": 0,
        "text": " And there are a bunch of different loss functions.",
        "tokens": [
          51278,
          400,
          456,
          366,
          257,
          3840,
          295,
          819,
          4470,
          6828,
          13,
          51394
        ]
      },
      {
        "avg_logprob": -0.2784858467304601,
        "compression_ratio": 1.9035087719298245,
        "end": 752.58,
        "id": 229,
        "no_speech_prob": 0.000019223141862312332,
        "seek": 72894,
        "start": 749.5400000000001,
        "temperature": 0,
        "text": " And we'll see these as I use TensorFlow.js in more",
        "tokens": [
          51394,
          400,
          321,
          603,
          536,
          613,
          382,
          286,
          764,
          37624,
          13,
          25530,
          294,
          544,
          51546
        ]
      },
      {
        "avg_logprob": -0.2784858467304601,
        "compression_ratio": 1.9035087719298245,
        "end": 753.4200000000001,
        "id": 230,
        "no_speech_prob": 0.000019223141862312332,
        "seek": 72894,
        "start": 752.58,
        "temperature": 0,
        "text": " tutorials.",
        "tokens": [
          51546,
          17616,
          13,
          51588
        ]
      },
      {
        "avg_logprob": -0.2784858467304601,
        "compression_ratio": 1.9035087719298245,
        "end": 755.3800000000001,
        "id": 231,
        "no_speech_prob": 0.000019223141862312332,
        "seek": 72894,
        "start": 753.4200000000001,
        "temperature": 0,
        "text": " I can select different kinds of loss functions",
        "tokens": [
          51588,
          286,
          393,
          3048,
          819,
          3685,
          295,
          4470,
          6828,
          51686
        ]
      },
      {
        "avg_logprob": -0.2784858467304601,
        "compression_ratio": 1.9035087719298245,
        "end": 756.7,
        "id": 232,
        "no_speech_prob": 0.000019223141862312332,
        "seek": 72894,
        "start": 755.3800000000001,
        "temperature": 0,
        "text": " for different scenarios.",
        "tokens": [
          51686,
          337,
          819,
          15077,
          13,
          51752
        ]
      },
      {
        "avg_logprob": -0.24037248362665592,
        "compression_ratio": 1.5774058577405858,
        "end": 759.1400000000001,
        "id": 233,
        "no_speech_prob": 0.000005338149094313849,
        "seek": 75670,
        "start": 756.74,
        "temperature": 0,
        "text": " But in this scenario, I'm going to use a simple basic one,",
        "tokens": [
          50366,
          583,
          294,
          341,
          9005,
          11,
          286,
          478,
          516,
          281,
          764,
          257,
          2199,
          3875,
          472,
          11,
          50486
        ]
      },
      {
        "avg_logprob": -0.24037248362665592,
        "compression_ratio": 1.5774058577405858,
        "end": 765.94,
        "id": 234,
        "no_speech_prob": 0.000005338149094313849,
        "seek": 75670,
        "start": 759.1400000000001,
        "temperature": 0,
        "text": " which I believe is called root mean squared error.",
        "tokens": [
          50486,
          597,
          286,
          1697,
          307,
          1219,
          5593,
          914,
          8889,
          6713,
          13,
          50826
        ]
      },
      {
        "avg_logprob": -0.24037248362665592,
        "compression_ratio": 1.5774058577405858,
        "end": 767.22,
        "id": 235,
        "no_speech_prob": 0.000005338149094313849,
        "seek": 75670,
        "start": 765.94,
        "temperature": 0,
        "text": " Did I say that correctly?",
        "tokens": [
          50826,
          2589,
          286,
          584,
          300,
          8944,
          30,
          50890
        ]
      },
      {
        "avg_logprob": -0.24037248362665592,
        "compression_ratio": 1.5774058577405858,
        "end": 768.46,
        "id": 236,
        "no_speech_prob": 0.000005338149094313849,
        "seek": 75670,
        "start": 767.22,
        "temperature": 0,
        "text": " Is that the right name of it?",
        "tokens": [
          50890,
          1119,
          300,
          264,
          558,
          1315,
          295,
          309,
          30,
          50952
        ]
      },
      {
        "avg_logprob": -0.24037248362665592,
        "compression_ratio": 1.5774058577405858,
        "end": 772.22,
        "id": 237,
        "no_speech_prob": 0.000005338149094313849,
        "seek": 75670,
        "start": 768.46,
        "temperature": 0,
        "text": " But the idea is that I want to look at all of those distances.",
        "tokens": [
          50952,
          583,
          264,
          1558,
          307,
          300,
          286,
          528,
          281,
          574,
          412,
          439,
          295,
          729,
          22182,
          13,
          51140
        ]
      },
      {
        "avg_logprob": -0.24037248362665592,
        "compression_ratio": 1.5774058577405858,
        "end": 773.74,
        "id": 238,
        "no_speech_prob": 0.000005338149094313849,
        "seek": 75670,
        "start": 772.22,
        "temperature": 0,
        "text": " And I want to minimize them.",
        "tokens": [
          51140,
          400,
          286,
          528,
          281,
          17522,
          552,
          13,
          51216
        ]
      },
      {
        "avg_logprob": -0.24037248362665592,
        "compression_ratio": 1.5774058577405858,
        "end": 777.6600000000001,
        "id": 239,
        "no_speech_prob": 0.000005338149094313849,
        "seek": 75670,
        "start": 773.74,
        "temperature": 0,
        "text": " So that number, if I find all these distances,",
        "tokens": [
          51216,
          407,
          300,
          1230,
          11,
          498,
          286,
          915,
          439,
          613,
          22182,
          11,
          51412
        ]
      },
      {
        "avg_logprob": -0.24037248362665592,
        "compression_ratio": 1.5774058577405858,
        "end": 780.22,
        "id": 240,
        "no_speech_prob": 0.000005338149094313849,
        "seek": 75670,
        "start": 777.6600000000001,
        "temperature": 0,
        "text": " the difference, and by the way, I totally,",
        "tokens": [
          51412,
          264,
          2649,
          11,
          293,
          538,
          264,
          636,
          11,
          286,
          3879,
          11,
          51540
        ]
      },
      {
        "avg_logprob": -0.24037248362665592,
        "compression_ratio": 1.5774058577405858,
        "end": 782.3000000000001,
        "id": 241,
        "no_speech_prob": 0.000005338149094313849,
        "seek": 75670,
        "start": 780.22,
        "temperature": 0,
        "text": " oh, I botched this.",
        "tokens": [
          51540,
          1954,
          11,
          286,
          10592,
          19318,
          341,
          13,
          51644
        ]
      },
      {
        "avg_logprob": -0.24037248362665592,
        "compression_ratio": 1.5774058577405858,
        "end": 782.82,
        "id": 242,
        "no_speech_prob": 0.000005338149094313849,
        "seek": 75670,
        "start": 782.3000000000001,
        "temperature": 0,
        "text": " Time out.",
        "tokens": [
          51644,
          6161,
          484,
          13,
          51670
        ]
      },
      {
        "avg_logprob": -0.38805246353149414,
        "compression_ratio": 1.7659574468085106,
        "end": 784.82,
        "id": 243,
        "no_speech_prob": 0.000024300181394210085,
        "seek": 78282,
        "start": 783.82,
        "temperature": 0,
        "text": " Vertical distance.",
        "tokens": [
          50414,
          21044,
          804,
          4560,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.38805246353149414,
        "compression_ratio": 1.7659574468085106,
        "end": 785.82,
        "id": 244,
        "no_speech_prob": 0.000024300181394210085,
        "seek": 78282,
        "start": 784.82,
        "temperature": 0,
        "text": " It's even in the chat.",
        "tokens": [
          50464,
          467,
          311,
          754,
          294,
          264,
          5081,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.38805246353149414,
        "compression_ratio": 1.7659574468085106,
        "end": 790.86,
        "id": 245,
        "no_speech_prob": 0.000024300181394210085,
        "seek": 78282,
        "start": 788.94,
        "temperature": 0,
        "text": " So the good news is you can barely see it.",
        "tokens": [
          50670,
          407,
          264,
          665,
          2583,
          307,
          291,
          393,
          10268,
          536,
          309,
          13,
          50766
        ]
      },
      {
        "avg_logprob": -0.38805246353149414,
        "compression_ratio": 1.7659574468085106,
        "end": 792.94,
        "id": 246,
        "no_speech_prob": 0.000024300181394210085,
        "seek": 78282,
        "start": 790.86,
        "temperature": 0,
        "text": " I'm looking over here on my monitor.",
        "tokens": [
          50766,
          286,
          478,
          1237,
          670,
          510,
          322,
          452,
          6002,
          13,
          50870
        ]
      },
      {
        "avg_logprob": -0.38805246353149414,
        "compression_ratio": 1.7659574468085106,
        "end": 793.9000000000001,
        "id": 247,
        "no_speech_prob": 0.000024300181394210085,
        "seek": 78282,
        "start": 792.94,
        "temperature": 0,
        "text": " And I can't see it.",
        "tokens": [
          50870,
          400,
          286,
          393,
          380,
          536,
          309,
          13,
          50918
        ]
      },
      {
        "avg_logprob": -0.38805246353149414,
        "compression_ratio": 1.7659574468085106,
        "end": 794.82,
        "id": 248,
        "no_speech_prob": 0.000024300181394210085,
        "seek": 78282,
        "start": 793.9000000000001,
        "temperature": 0,
        "text": " You can barely see it.",
        "tokens": [
          50918,
          509,
          393,
          10268,
          536,
          309,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.38805246353149414,
        "compression_ratio": 1.7659574468085106,
        "end": 797.1800000000001,
        "id": 249,
        "no_speech_prob": 0.000024300181394210085,
        "seek": 78282,
        "start": 794.82,
        "temperature": 0,
        "text": " But I really botched what I was drawing there.",
        "tokens": [
          50964,
          583,
          286,
          534,
          10592,
          19318,
          437,
          286,
          390,
          6316,
          456,
          13,
          51082
        ]
      },
      {
        "avg_logprob": -0.38805246353149414,
        "compression_ratio": 1.7659574468085106,
        "end": 799.7,
        "id": 250,
        "no_speech_prob": 0.000024300181394210085,
        "seek": 78282,
        "start": 797.1800000000001,
        "temperature": 0,
        "text": " So let me fix that.",
        "tokens": [
          51082,
          407,
          718,
          385,
          3191,
          300,
          13,
          51208
        ]
      },
      {
        "avg_logprob": -0.38805246353149414,
        "compression_ratio": 1.7659574468085106,
        "end": 802.0200000000001,
        "id": 251,
        "no_speech_prob": 0.000024300181394210085,
        "seek": 78282,
        "start": 799.7,
        "temperature": 0,
        "text": " I don't think I'm going to go back and redo this video.",
        "tokens": [
          51208,
          286,
          500,
          380,
          519,
          286,
          478,
          516,
          281,
          352,
          646,
          293,
          29956,
          341,
          960,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.38805246353149414,
        "compression_ratio": 1.7659574468085106,
        "end": 804.1400000000001,
        "id": 252,
        "no_speech_prob": 0.000024300181394210085,
        "seek": 78282,
        "start": 802.0200000000001,
        "temperature": 0,
        "text": " I think I'm just going to get a different pen color,",
        "tokens": [
          51324,
          286,
          519,
          286,
          478,
          445,
          516,
          281,
          483,
          257,
          819,
          3435,
          2017,
          11,
          51430
        ]
      },
      {
        "avg_logprob": -0.38805246353149414,
        "compression_ratio": 1.7659574468085106,
        "end": 808.82,
        "id": 253,
        "no_speech_prob": 0.000024300181394210085,
        "seek": 78282,
        "start": 804.1400000000001,
        "temperature": 0,
        "text": " since you can't see it anyway, and just fix that.",
        "tokens": [
          51430,
          1670,
          291,
          393,
          380,
          536,
          309,
          4033,
          11,
          293,
          445,
          3191,
          300,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.38805246353149414,
        "compression_ratio": 1.7659574468085106,
        "end": 811.82,
        "id": 254,
        "no_speech_prob": 0.000024300181394210085,
        "seek": 78282,
        "start": 808.82,
        "temperature": 0,
        "text": " So I'm going to go back.",
        "tokens": [
          51664,
          407,
          286,
          478,
          516,
          281,
          352,
          646,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2490292224255237,
        "compression_ratio": 1.5841584158415842,
        "end": 814.6600000000001,
        "id": 255,
        "no_speech_prob": 0.0000020904565189994173,
        "seek": 81182,
        "start": 811.94,
        "temperature": 0,
        "text": " So a little editing point here.",
        "tokens": [
          50370,
          407,
          257,
          707,
          10000,
          935,
          510,
          13,
          50506
        ]
      },
      {
        "avg_logprob": -0.2490292224255237,
        "compression_ratio": 1.5841584158415842,
        "end": 822.3000000000001,
        "id": 256,
        "no_speech_prob": 0.0000020904565189994173,
        "seek": 81182,
        "start": 821.7800000000001,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50862,
          2264,
          13,
          50888
        ]
      },
      {
        "avg_logprob": -0.2490292224255237,
        "compression_ratio": 1.5841584158415842,
        "end": 824.38,
        "id": 257,
        "no_speech_prob": 0.0000020904565189994173,
        "seek": 81182,
        "start": 822.3000000000001,
        "temperature": 0,
        "text": " I'm back, because I started talking about the loss",
        "tokens": [
          50888,
          286,
          478,
          646,
          11,
          570,
          286,
          1409,
          1417,
          466,
          264,
          4470,
          50992
        ]
      },
      {
        "avg_logprob": -0.2490292224255237,
        "compression_ratio": 1.5841584158415842,
        "end": 824.88,
        "id": 258,
        "no_speech_prob": 0.0000020904565189994173,
        "seek": 81182,
        "start": 824.38,
        "temperature": 0,
        "text": " function.",
        "tokens": [
          50992,
          2445,
          13,
          51017
        ]
      },
      {
        "avg_logprob": -0.2490292224255237,
        "compression_ratio": 1.5841584158415842,
        "end": 827.1400000000001,
        "id": 259,
        "no_speech_prob": 0.0000020904565189994173,
        "seek": 81182,
        "start": 824.88,
        "temperature": 0,
        "text": " I realized I really didn't draw.",
        "tokens": [
          51017,
          286,
          5334,
          286,
          534,
          994,
          380,
          2642,
          13,
          51130
        ]
      },
      {
        "avg_logprob": -0.2490292224255237,
        "compression_ratio": 1.5841584158415842,
        "end": 829.94,
        "id": 260,
        "no_speech_prob": 0.0000020904565189994173,
        "seek": 81182,
        "start": 827.1400000000001,
        "temperature": 0,
        "text": " I'm not actually looking for the distance",
        "tokens": [
          51130,
          286,
          478,
          406,
          767,
          1237,
          337,
          264,
          4560,
          51270
        ]
      },
      {
        "avg_logprob": -0.2490292224255237,
        "compression_ratio": 1.5841584158415842,
        "end": 832.46,
        "id": 261,
        "no_speech_prob": 0.0000020904565189994173,
        "seek": 81182,
        "start": 829.94,
        "temperature": 0,
        "text": " from the point to that line, which would be perpendicular.",
        "tokens": [
          51270,
          490,
          264,
          935,
          281,
          300,
          1622,
          11,
          597,
          576,
          312,
          26734,
          13,
          51396
        ]
      },
      {
        "avg_logprob": -0.2490292224255237,
        "compression_ratio": 1.5841584158415842,
        "end": 836.82,
        "id": 262,
        "no_speech_prob": 0.0000020904565189994173,
        "seek": 81182,
        "start": 832.46,
        "temperature": 0,
        "text": " I'm looking for this vertical distance, which is,",
        "tokens": [
          51396,
          286,
          478,
          1237,
          337,
          341,
          9429,
          4560,
          11,
          597,
          307,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.2490292224255237,
        "compression_ratio": 1.5841584158415842,
        "end": 839.62,
        "id": 263,
        "no_speech_prob": 0.0000020904565189994173,
        "seek": 81182,
        "start": 836.82,
        "temperature": 0,
        "text": " so this is what I'm trying to minimize.",
        "tokens": [
          51614,
          370,
          341,
          307,
          437,
          286,
          478,
          1382,
          281,
          17522,
          13,
          51754
        ]
      },
      {
        "avg_logprob": -0.26450576782226565,
        "compression_ratio": 1.5119047619047619,
        "end": 842.7,
        "id": 264,
        "no_speech_prob": 0.0000246828276431188,
        "seek": 83962,
        "start": 839.62,
        "temperature": 0,
        "text": " I'm trying to minimize and get a line that has,",
        "tokens": [
          50364,
          286,
          478,
          1382,
          281,
          17522,
          293,
          483,
          257,
          1622,
          300,
          575,
          11,
          50518
        ]
      },
      {
        "avg_logprob": -0.26450576782226565,
        "compression_ratio": 1.5119047619047619,
        "end": 848.46,
        "id": 265,
        "no_speech_prob": 0.0000246828276431188,
        "seek": 83962,
        "start": 842.7,
        "temperature": 0,
        "text": " and this, that is the least, the sum of all these distances",
        "tokens": [
          50518,
          293,
          341,
          11,
          300,
          307,
          264,
          1935,
          11,
          264,
          2408,
          295,
          439,
          613,
          22182,
          50806
        ]
      },
      {
        "avg_logprob": -0.26450576782226565,
        "compression_ratio": 1.5119047619047619,
        "end": 851.7,
        "id": 266,
        "no_speech_prob": 0.0000246828276431188,
        "seek": 83962,
        "start": 848.46,
        "temperature": 0,
        "text": " is the smallest number, minimizing the loss.",
        "tokens": [
          50806,
          307,
          264,
          16998,
          1230,
          11,
          46608,
          264,
          4470,
          13,
          50968
        ]
      },
      {
        "avg_logprob": -0.26450576782226565,
        "compression_ratio": 1.5119047619047619,
        "end": 852.86,
        "id": 267,
        "no_speech_prob": 0.0000246828276431188,
        "seek": 83962,
        "start": 851.7,
        "temperature": 0,
        "text": " So I have a loss function.",
        "tokens": [
          50968,
          407,
          286,
          362,
          257,
          4470,
          2445,
          13,
          51026
        ]
      },
      {
        "avg_logprob": -0.26450576782226565,
        "compression_ratio": 1.5119047619047619,
        "end": 854.18,
        "id": 268,
        "no_speech_prob": 0.0000246828276431188,
        "seek": 83962,
        "start": 852.86,
        "temperature": 0,
        "text": " I need that.",
        "tokens": [
          51026,
          286,
          643,
          300,
          13,
          51092
        ]
      },
      {
        "avg_logprob": -0.26450576782226565,
        "compression_ratio": 1.5119047619047619,
        "end": 868.0600000000001,
        "id": 269,
        "no_speech_prob": 0.0000246828276431188,
        "seek": 83962,
        "start": 854.18,
        "temperature": 0,
        "text": " I also need, in TensorFlow.js, something called an optimizer.",
        "tokens": [
          51092,
          286,
          611,
          643,
          11,
          294,
          37624,
          13,
          25530,
          11,
          746,
          1219,
          364,
          5028,
          6545,
          13,
          51786
        ]
      },
      {
        "avg_logprob": -0.19763057572501047,
        "compression_ratio": 1.9405940594059405,
        "end": 870.3399999999999,
        "id": 270,
        "no_speech_prob": 0.000009368695828015916,
        "seek": 86806,
        "start": 868.06,
        "temperature": 0,
        "text": " And the optimizer is the thing that",
        "tokens": [
          50364,
          400,
          264,
          5028,
          6545,
          307,
          264,
          551,
          300,
          50478
        ]
      },
      {
        "avg_logprob": -0.19763057572501047,
        "compression_ratio": 1.9405940594059405,
        "end": 876.54,
        "id": 271,
        "no_speech_prob": 0.000009368695828015916,
        "seek": 86806,
        "start": 870.3399999999999,
        "temperature": 0,
        "text": " allows me to minimize the loss function.",
        "tokens": [
          50478,
          4045,
          385,
          281,
          17522,
          264,
          4470,
          2445,
          13,
          50788
        ]
      },
      {
        "avg_logprob": -0.19763057572501047,
        "compression_ratio": 1.9405940594059405,
        "end": 882.7399999999999,
        "id": 272,
        "no_speech_prob": 0.000009368695828015916,
        "seek": 86806,
        "start": 876.54,
        "temperature": 0,
        "text": " And in order to do that, I also need to have a learning rate.",
        "tokens": [
          50788,
          400,
          294,
          1668,
          281,
          360,
          300,
          11,
          286,
          611,
          643,
          281,
          362,
          257,
          2539,
          3314,
          13,
          51098
        ]
      },
      {
        "avg_logprob": -0.19763057572501047,
        "compression_ratio": 1.9405940594059405,
        "end": 884.9799999999999,
        "id": 273,
        "no_speech_prob": 0.000009368695828015916,
        "seek": 86806,
        "start": 882.7399999999999,
        "temperature": 0,
        "text": " So these are all, I actually missed something very important",
        "tokens": [
          51098,
          407,
          613,
          366,
          439,
          11,
          286,
          767,
          6721,
          746,
          588,
          1021,
          51210
        ]
      },
      {
        "avg_logprob": -0.19763057572501047,
        "compression_ratio": 1.9405940594059405,
        "end": 886.4799999999999,
        "id": 274,
        "no_speech_prob": 0.000009368695828015916,
        "seek": 86806,
        "start": 884.9799999999999,
        "temperature": 0,
        "text": " here, but these are all the pieces.",
        "tokens": [
          51210,
          510,
          11,
          457,
          613,
          366,
          439,
          264,
          3755,
          13,
          51285
        ]
      },
      {
        "avg_logprob": -0.19763057572501047,
        "compression_ratio": 1.9405940594059405,
        "end": 888.02,
        "id": 275,
        "no_speech_prob": 0.000009368695828015916,
        "seek": 86806,
        "start": 886.4799999999999,
        "temperature": 0,
        "text": " I need the data.",
        "tokens": [
          51285,
          286,
          643,
          264,
          1412,
          13,
          51362
        ]
      },
      {
        "avg_logprob": -0.19763057572501047,
        "compression_ratio": 1.9405940594059405,
        "end": 889.9,
        "id": 276,
        "no_speech_prob": 0.000009368695828015916,
        "seek": 86806,
        "start": 888.02,
        "temperature": 0,
        "text": " I need to define a loss function.",
        "tokens": [
          51362,
          286,
          643,
          281,
          6964,
          257,
          4470,
          2445,
          13,
          51456
        ]
      },
      {
        "avg_logprob": -0.19763057572501047,
        "compression_ratio": 1.9405940594059405,
        "end": 891.54,
        "id": 277,
        "no_speech_prob": 0.000009368695828015916,
        "seek": 86806,
        "start": 889.9,
        "temperature": 0,
        "text": " I need to define an optimizer.",
        "tokens": [
          51456,
          286,
          643,
          281,
          6964,
          364,
          5028,
          6545,
          13,
          51538
        ]
      },
      {
        "avg_logprob": -0.19763057572501047,
        "compression_ratio": 1.9405940594059405,
        "end": 894.5,
        "id": 278,
        "no_speech_prob": 0.000009368695828015916,
        "seek": 86806,
        "start": 891.54,
        "temperature": 0,
        "text": " I say, hey, optimizer, minimize the loss function",
        "tokens": [
          51538,
          286,
          584,
          11,
          4177,
          11,
          5028,
          6545,
          11,
          17522,
          264,
          4470,
          2445,
          51686
        ]
      },
      {
        "avg_logprob": -0.19763057572501047,
        "compression_ratio": 1.9405940594059405,
        "end": 895.7399999999999,
        "id": 279,
        "no_speech_prob": 0.000009368695828015916,
        "seek": 86806,
        "start": 894.5,
        "temperature": 0,
        "text": " with this learning rate.",
        "tokens": [
          51686,
          365,
          341,
          2539,
          3314,
          13,
          51748
        ]
      },
      {
        "avg_logprob": -0.2665355546133859,
        "compression_ratio": 1.6407185628742516,
        "end": 898.3,
        "id": 280,
        "no_speech_prob": 0.002434358699247241,
        "seek": 89574,
        "start": 895.74,
        "temperature": 0,
        "text": " So keep tweaking the parameters, tweaking the parameters.",
        "tokens": [
          50364,
          407,
          1066,
          6986,
          2456,
          264,
          9834,
          11,
          6986,
          2456,
          264,
          9834,
          13,
          50492
        ]
      },
      {
        "avg_logprob": -0.2665355546133859,
        "compression_ratio": 1.6407185628742516,
        "end": 899.5,
        "id": 281,
        "no_speech_prob": 0.002434358699247241,
        "seek": 89574,
        "start": 898.3,
        "temperature": 0,
        "text": " So that's the thing I forgot.",
        "tokens": [
          50492,
          407,
          300,
          311,
          264,
          551,
          286,
          5298,
          13,
          50552
        ]
      },
      {
        "avg_logprob": -0.2665355546133859,
        "compression_ratio": 1.6407185628742516,
        "end": 900.7,
        "id": 282,
        "no_speech_prob": 0.002434358699247241,
        "seek": 89574,
        "start": 899.5,
        "temperature": 0,
        "text": " What are those parameters?",
        "tokens": [
          50552,
          708,
          366,
          729,
          9834,
          30,
          50612
        ]
      },
      {
        "avg_logprob": -0.2665355546133859,
        "compression_ratio": 1.6407185628742516,
        "end": 906.58,
        "id": 283,
        "no_speech_prob": 0.002434358699247241,
        "seek": 89574,
        "start": 900.7,
        "temperature": 0,
        "text": " Well, the formula for a line is y equals mx plus b.",
        "tokens": [
          50612,
          1042,
          11,
          264,
          8513,
          337,
          257,
          1622,
          307,
          288,
          6915,
          275,
          87,
          1804,
          272,
          13,
          50906
        ]
      },
      {
        "avg_logprob": -0.2665355546133859,
        "compression_ratio": 1.6407185628742516,
        "end": 912.94,
        "id": 284,
        "no_speech_prob": 0.002434358699247241,
        "seek": 89574,
        "start": 906.58,
        "temperature": 0,
        "text": " m is often referred to as the slope, b as the offset.",
        "tokens": [
          50906,
          275,
          307,
          2049,
          10839,
          281,
          382,
          264,
          13525,
          11,
          272,
          382,
          264,
          18687,
          13,
          51224
        ]
      },
      {
        "avg_logprob": -0.2665355546133859,
        "compression_ratio": 1.6407185628742516,
        "end": 914.94,
        "id": 285,
        "no_speech_prob": 0.002434358699247241,
        "seek": 89574,
        "start": 912.94,
        "temperature": 0,
        "text": " What's the name for that?",
        "tokens": [
          51224,
          708,
          311,
          264,
          1315,
          337,
          300,
          30,
          51324
        ]
      },
      {
        "avg_logprob": -0.2665355546133859,
        "compression_ratio": 1.6407185628742516,
        "end": 916.14,
        "id": 286,
        "no_speech_prob": 0.002434358699247241,
        "seek": 89574,
        "start": 914.94,
        "temperature": 0,
        "text": " You'll tell me in the chat.",
        "tokens": [
          51324,
          509,
          603,
          980,
          385,
          294,
          264,
          5081,
          13,
          51384
        ]
      },
      {
        "avg_logprob": -0.3310117621170847,
        "compression_ratio": 1.4331550802139037,
        "end": 927.98,
        "id": 287,
        "no_speech_prob": 0.0018675605533644557,
        "seek": 92574,
        "start": 926.0600000000001,
        "temperature": 0,
        "text": " What's the name of that formula for a line?",
        "tokens": [
          50380,
          708,
          311,
          264,
          1315,
          295,
          300,
          8513,
          337,
          257,
          1622,
          30,
          50476
        ]
      },
      {
        "avg_logprob": -0.3310117621170847,
        "compression_ratio": 1.4331550802139037,
        "end": 932.82,
        "id": 288,
        "no_speech_prob": 0.0018675605533644557,
        "seek": 92574,
        "start": 930.66,
        "temperature": 0,
        "text": " See, this is why I shouldn't do these live streams",
        "tokens": [
          50610,
          3008,
          11,
          341,
          307,
          983,
          286,
          4659,
          380,
          360,
          613,
          1621,
          15842,
          50718
        ]
      },
      {
        "avg_logprob": -0.3310117621170847,
        "compression_ratio": 1.4331550802139037,
        "end": 934.94,
        "id": 289,
        "no_speech_prob": 0.0018675605533644557,
        "seek": 92574,
        "start": 932.82,
        "temperature": 0,
        "text": " at the end of the day.",
        "tokens": [
          50718,
          412,
          264,
          917,
          295,
          264,
          786,
          13,
          50824
        ]
      },
      {
        "avg_logprob": -0.3310117621170847,
        "compression_ratio": 1.4331550802139037,
        "end": 937.1800000000001,
        "id": 290,
        "no_speech_prob": 0.0018675605533644557,
        "seek": 92574,
        "start": 934.94,
        "temperature": 0,
        "text": " I was so with it when I was talking about promises",
        "tokens": [
          50824,
          286,
          390,
          370,
          365,
          309,
          562,
          286,
          390,
          1417,
          466,
          16403,
          50936
        ]
      },
      {
        "avg_logprob": -0.3310117621170847,
        "compression_ratio": 1.4331550802139037,
        "end": 938.78,
        "id": 291,
        "no_speech_prob": 0.0018675605533644557,
        "seek": 92574,
        "start": 937.1800000000001,
        "temperature": 0,
        "text": " this morning, wasn't I?",
        "tokens": [
          50936,
          341,
          2446,
          11,
          2067,
          380,
          286,
          30,
          51016
        ]
      },
      {
        "avg_logprob": -0.3310117621170847,
        "compression_ratio": 1.4331550802139037,
        "end": 940.1,
        "id": 292,
        "no_speech_prob": 0.0018675605533644557,
        "seek": 92574,
        "start": 938.78,
        "temperature": 0,
        "text": " y-intercept.",
        "tokens": [
          51016,
          288,
          12,
          5106,
          1336,
          13,
          51082
        ]
      },
      {
        "avg_logprob": -0.3310117621170847,
        "compression_ratio": 1.4331550802139037,
        "end": 940.82,
        "id": 293,
        "no_speech_prob": 0.0018675605533644557,
        "seek": 92574,
        "start": 940.1,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51082,
          821,
          321,
          352,
          13,
          51118
        ]
      },
      {
        "avg_logprob": -0.3310117621170847,
        "compression_ratio": 1.4331550802139037,
        "end": 941.7,
        "id": 294,
        "no_speech_prob": 0.0018675605533644557,
        "seek": 92574,
        "start": 940.82,
        "temperature": 0,
        "text": " y-intercept.",
        "tokens": [
          51118,
          288,
          12,
          5106,
          1336,
          13,
          51162
        ]
      },
      {
        "avg_logprob": -0.3310117621170847,
        "compression_ratio": 1.4331550802139037,
        "end": 942.2,
        "id": 295,
        "no_speech_prob": 0.0018675605533644557,
        "seek": 92574,
        "start": 941.7,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51162,
          2264,
          13,
          51187
        ]
      },
      {
        "avg_logprob": -0.3310117621170847,
        "compression_ratio": 1.4331550802139037,
        "end": 953.9,
        "id": 296,
        "no_speech_prob": 0.0018675605533644557,
        "seek": 92574,
        "start": 952.38,
        "temperature": 0,
        "text": " I'm back because I looked it up.",
        "tokens": [
          51696,
          286,
          478,
          646,
          570,
          286,
          2956,
          309,
          493,
          13,
          51772
        ]
      },
      {
        "avg_logprob": -0.25154429410411194,
        "compression_ratio": 1.5873015873015872,
        "end": 961.02,
        "id": 297,
        "no_speech_prob": 0.000002332073790967115,
        "seek": 95390,
        "start": 953.9399999999999,
        "temperature": 0,
        "text": " m is the slope, and b referred to as the y-intercept.",
        "tokens": [
          50366,
          275,
          307,
          264,
          13525,
          11,
          293,
          272,
          10839,
          281,
          382,
          264,
          288,
          12,
          5106,
          1336,
          13,
          50720
        ]
      },
      {
        "avg_logprob": -0.25154429410411194,
        "compression_ratio": 1.5873015873015872,
        "end": 962.8199999999999,
        "id": 298,
        "no_speech_prob": 0.000002332073790967115,
        "seek": 95390,
        "start": 961.02,
        "temperature": 0,
        "text": " Kind of like bias, by the way, if you've",
        "tokens": [
          50720,
          9242,
          295,
          411,
          12577,
          11,
          538,
          264,
          636,
          11,
          498,
          291,
          600,
          50810
        ]
      },
      {
        "avg_logprob": -0.25154429410411194,
        "compression_ratio": 1.5873015873015872,
        "end": 965.06,
        "id": 299,
        "no_speech_prob": 0.000002332073790967115,
        "seek": 95390,
        "start": 962.8199999999999,
        "temperature": 0,
        "text": " watched some of my other neural network tutorials.",
        "tokens": [
          50810,
          6337,
          512,
          295,
          452,
          661,
          18161,
          3209,
          17616,
          13,
          50922
        ]
      },
      {
        "avg_logprob": -0.25154429410411194,
        "compression_ratio": 1.5873015873015872,
        "end": 966.98,
        "id": 300,
        "no_speech_prob": 0.000002332073790967115,
        "seek": 95390,
        "start": 965.06,
        "temperature": 0,
        "text": " This is like the thing we're doing with all the neurons.",
        "tokens": [
          50922,
          639,
          307,
          411,
          264,
          551,
          321,
          434,
          884,
          365,
          439,
          264,
          22027,
          13,
          51018
        ]
      },
      {
        "avg_logprob": -0.25154429410411194,
        "compression_ratio": 1.5873015873015872,
        "end": 968.26,
        "id": 301,
        "no_speech_prob": 0.000002332073790967115,
        "seek": 95390,
        "start": 966.98,
        "temperature": 0,
        "text": " Oh, it's all so connected.",
        "tokens": [
          51018,
          876,
          11,
          309,
          311,
          439,
          370,
          4582,
          13,
          51082
        ]
      },
      {
        "avg_logprob": -0.25154429410411194,
        "compression_ratio": 1.5873015873015872,
        "end": 970.9399999999999,
        "id": 302,
        "no_speech_prob": 0.000002332073790967115,
        "seek": 95390,
        "start": 968.26,
        "temperature": 0,
        "text": " But we're just living in this very simple place.",
        "tokens": [
          51082,
          583,
          321,
          434,
          445,
          2647,
          294,
          341,
          588,
          2199,
          1081,
          13,
          51216
        ]
      },
      {
        "avg_logprob": -0.25154429410411194,
        "compression_ratio": 1.5873015873015872,
        "end": 974.26,
        "id": 303,
        "no_speech_prob": 0.000002332073790967115,
        "seek": 95390,
        "start": 970.9399999999999,
        "temperature": 0,
        "text": " So I need these parameters.",
        "tokens": [
          51216,
          407,
          286,
          643,
          613,
          9834,
          13,
          51382
        ]
      },
      {
        "avg_logprob": -0.25154429410411194,
        "compression_ratio": 1.5873015873015872,
        "end": 977.78,
        "id": 304,
        "no_speech_prob": 0.000002332073790967115,
        "seek": 95390,
        "start": 974.26,
        "temperature": 0,
        "text": " I need these variables because that's",
        "tokens": [
          51382,
          286,
          643,
          613,
          9102,
          570,
          300,
          311,
          51558
        ]
      },
      {
        "avg_logprob": -0.25154429410411194,
        "compression_ratio": 1.5873015873015872,
        "end": 981.26,
        "id": 305,
        "no_speech_prob": 0.000002332073790967115,
        "seek": 95390,
        "start": 977.78,
        "temperature": 0,
        "text": " what's going to allow me to create the predictions that",
        "tokens": [
          51558,
          437,
          311,
          516,
          281,
          2089,
          385,
          281,
          1884,
          264,
          21264,
          300,
          51732
        ]
      },
      {
        "avg_logprob": -0.19824309910044952,
        "compression_ratio": 1.7714285714285714,
        "end": 984.5,
        "id": 306,
        "no_speech_prob": 0.00005562202204600908,
        "seek": 98126,
        "start": 981.26,
        "temperature": 0,
        "text": " are on the line to compare with the actual points",
        "tokens": [
          50364,
          366,
          322,
          264,
          1622,
          281,
          6794,
          365,
          264,
          3539,
          2793,
          50526
        ]
      },
      {
        "avg_logprob": -0.19824309910044952,
        "compression_ratio": 1.7714285714285714,
        "end": 987.74,
        "id": 307,
        "no_speech_prob": 0.00005562202204600908,
        "seek": 98126,
        "start": 984.5,
        "temperature": 0,
        "text": " and compute the loss, minimize it, tweaking these values.",
        "tokens": [
          50526,
          293,
          14722,
          264,
          4470,
          11,
          17522,
          309,
          11,
          6986,
          2456,
          613,
          4190,
          13,
          50688
        ]
      },
      {
        "avg_logprob": -0.19824309910044952,
        "compression_ratio": 1.7714285714285714,
        "end": 990.14,
        "id": 308,
        "no_speech_prob": 0.00005562202204600908,
        "seek": 98126,
        "start": 987.74,
        "temperature": 0,
        "text": " So tweak these values, minimizing the loss.",
        "tokens": [
          50688,
          407,
          29879,
          613,
          4190,
          11,
          46608,
          264,
          4470,
          13,
          50808
        ]
      },
      {
        "avg_logprob": -0.19824309910044952,
        "compression_ratio": 1.7714285714285714,
        "end": 991.38,
        "id": 309,
        "no_speech_prob": 0.00005562202204600908,
        "seek": 98126,
        "start": 990.14,
        "temperature": 0,
        "text": " This is what we're doing.",
        "tokens": [
          50808,
          639,
          307,
          437,
          321,
          434,
          884,
          13,
          50870
        ]
      },
      {
        "avg_logprob": -0.19824309910044952,
        "compression_ratio": 1.7714285714285714,
        "end": 994.22,
        "id": 310,
        "no_speech_prob": 0.00005562202204600908,
        "seek": 98126,
        "start": 991.38,
        "temperature": 0,
        "text": " And I've done this before in great detail.",
        "tokens": [
          50870,
          400,
          286,
          600,
          1096,
          341,
          949,
          294,
          869,
          2607,
          13,
          51012
        ]
      },
      {
        "avg_logprob": -0.19824309910044952,
        "compression_ratio": 1.7714285714285714,
        "end": 995.66,
        "id": 311,
        "no_speech_prob": 0.00005562202204600908,
        "seek": 98126,
        "start": 994.22,
        "temperature": 0,
        "text": " This is going to be in less detail",
        "tokens": [
          51012,
          639,
          307,
          516,
          281,
          312,
          294,
          1570,
          2607,
          51084
        ]
      },
      {
        "avg_logprob": -0.19824309910044952,
        "compression_ratio": 1.7714285714285714,
        "end": 998.3,
        "id": 312,
        "no_speech_prob": 0.00005562202204600908,
        "seek": 98126,
        "start": 995.66,
        "temperature": 0,
        "text": " because TensorFlow.js is going to do a lot of this for us.",
        "tokens": [
          51084,
          570,
          37624,
          13,
          25530,
          307,
          516,
          281,
          360,
          257,
          688,
          295,
          341,
          337,
          505,
          13,
          51216
        ]
      },
      {
        "avg_logprob": -0.19824309910044952,
        "compression_ratio": 1.7714285714285714,
        "end": 1000.8199999999999,
        "id": 313,
        "no_speech_prob": 0.00005562202204600908,
        "seek": 98126,
        "start": 998.3,
        "temperature": 0,
        "text": " The thing that's a little extra complicated",
        "tokens": [
          51216,
          440,
          551,
          300,
          311,
          257,
          707,
          2857,
          6179,
          51342
        ]
      },
      {
        "avg_logprob": -0.19824309910044952,
        "compression_ratio": 1.7714285714285714,
        "end": 1004.3,
        "id": 314,
        "no_speech_prob": 0.00005562202204600908,
        "seek": 98126,
        "start": 1000.8199999999999,
        "temperature": 0,
        "text": " is we can't just work with arrays of numbers and variables",
        "tokens": [
          51342,
          307,
          321,
          393,
          380,
          445,
          589,
          365,
          41011,
          295,
          3547,
          293,
          9102,
          51516
        ]
      },
      {
        "avg_logprob": -0.19824309910044952,
        "compression_ratio": 1.7714285714285714,
        "end": 1006.38,
        "id": 315,
        "no_speech_prob": 0.00005562202204600908,
        "seek": 98126,
        "start": 1004.3,
        "temperature": 0,
        "text": " in the way that we're used to in JavaScript.",
        "tokens": [
          51516,
          294,
          264,
          636,
          300,
          321,
          434,
          1143,
          281,
          294,
          15778,
          13,
          51620
        ]
      },
      {
        "avg_logprob": -0.19824309910044952,
        "compression_ratio": 1.7714285714285714,
        "end": 1008.06,
        "id": 316,
        "no_speech_prob": 0.00005562202204600908,
        "seek": 98126,
        "start": 1006.38,
        "temperature": 0,
        "text": " And so this is what brings me to,",
        "tokens": [
          51620,
          400,
          370,
          341,
          307,
          437,
          5607,
          385,
          281,
          11,
          51704
        ]
      },
      {
        "avg_logprob": -0.24644312105680766,
        "compression_ratio": 1.659375,
        "end": 1011.54,
        "id": 317,
        "no_speech_prob": 0.0003150370321236551,
        "seek": 100806,
        "start": 1008.06,
        "temperature": 0,
        "text": " if you haven't looked at these particular videos",
        "tokens": [
          50364,
          498,
          291,
          2378,
          380,
          2956,
          412,
          613,
          1729,
          2145,
          50538
        ]
      },
      {
        "avg_logprob": -0.24644312105680766,
        "compression_ratio": 1.659375,
        "end": 1015.6999999999999,
        "id": 318,
        "no_speech_prob": 0.0003150370321236551,
        "seek": 100806,
        "start": 1011.54,
        "temperature": 0,
        "text": " that I've made already, what's a TensorFlow tensor?",
        "tokens": [
          50538,
          300,
          286,
          600,
          1027,
          1217,
          11,
          437,
          311,
          257,
          37624,
          40863,
          30,
          50746
        ]
      },
      {
        "avg_logprob": -0.24644312105680766,
        "compression_ratio": 1.659375,
        "end": 1016.54,
        "id": 319,
        "no_speech_prob": 0.0003150370321236551,
        "seek": 100806,
        "start": 1015.6999999999999,
        "temperature": 0,
        "text": " What's a variable?",
        "tokens": [
          50746,
          708,
          311,
          257,
          7006,
          30,
          50788
        ]
      },
      {
        "avg_logprob": -0.24644312105680766,
        "compression_ratio": 1.659375,
        "end": 1017.42,
        "id": 320,
        "no_speech_prob": 0.0003150370321236551,
        "seek": 100806,
        "start": 1016.54,
        "temperature": 0,
        "text": " What's an operation?",
        "tokens": [
          50788,
          708,
          311,
          364,
          6916,
          30,
          50832
        ]
      },
      {
        "avg_logprob": -0.24644312105680766,
        "compression_ratio": 1.659375,
        "end": 1018.9,
        "id": 321,
        "no_speech_prob": 0.0003150370321236551,
        "seek": 100806,
        "start": 1017.42,
        "temperature": 0,
        "text": " How's the memory management stuff?",
        "tokens": [
          50832,
          1012,
          311,
          264,
          4675,
          4592,
          1507,
          30,
          50906
        ]
      },
      {
        "avg_logprob": -0.24644312105680766,
        "compression_ratio": 1.659375,
        "end": 1020.8599999999999,
        "id": 322,
        "no_speech_prob": 0.0003150370321236551,
        "seek": 100806,
        "start": 1018.9,
        "temperature": 0,
        "text": " This is stuff we're going to have to lean on",
        "tokens": [
          50906,
          639,
          307,
          1507,
          321,
          434,
          516,
          281,
          362,
          281,
          11659,
          322,
          51004
        ]
      },
      {
        "avg_logprob": -0.24644312105680766,
        "compression_ratio": 1.659375,
        "end": 1022.3,
        "id": 323,
        "no_speech_prob": 0.0003150370321236551,
        "seek": 100806,
        "start": 1020.8599999999999,
        "temperature": 0,
        "text": " while I build this example.",
        "tokens": [
          51004,
          1339,
          286,
          1322,
          341,
          1365,
          13,
          51076
        ]
      },
      {
        "avg_logprob": -0.24644312105680766,
        "compression_ratio": 1.659375,
        "end": 1025.98,
        "id": 324,
        "no_speech_prob": 0.0003150370321236551,
        "seek": 100806,
        "start": 1022.3,
        "temperature": 0,
        "text": " And this should be, by the way, an actual practical example",
        "tokens": [
          51076,
          400,
          341,
          820,
          312,
          11,
          538,
          264,
          636,
          11,
          364,
          3539,
          8496,
          1365,
          51260
        ]
      },
      {
        "avg_logprob": -0.24644312105680766,
        "compression_ratio": 1.659375,
        "end": 1027.98,
        "id": 325,
        "no_speech_prob": 0.0003150370321236551,
        "seek": 100806,
        "start": 1025.98,
        "temperature": 0,
        "text": " of where I need a tf variable.",
        "tokens": [
          51260,
          295,
          689,
          286,
          643,
          257,
          256,
          69,
          7006,
          13,
          51360
        ]
      },
      {
        "avg_logprob": -0.24644312105680766,
        "compression_ratio": 1.659375,
        "end": 1030.56,
        "id": 326,
        "no_speech_prob": 0.0003150370321236551,
        "seek": 100806,
        "start": 1027.98,
        "temperature": 0,
        "text": " So I kind of, in this video, explained what a tf variable is,",
        "tokens": [
          51360,
          407,
          286,
          733,
          295,
          11,
          294,
          341,
          960,
          11,
          8825,
          437,
          257,
          256,
          69,
          7006,
          307,
          11,
          51489
        ]
      },
      {
        "avg_logprob": -0.24644312105680766,
        "compression_ratio": 1.659375,
        "end": 1032.8999999999999,
        "id": 327,
        "no_speech_prob": 0.0003150370321236551,
        "seek": 100806,
        "start": 1030.56,
        "temperature": 0,
        "text": " but just kind of moved on and didn't use it for anything.",
        "tokens": [
          51489,
          457,
          445,
          733,
          295,
          4259,
          322,
          293,
          994,
          380,
          764,
          309,
          337,
          1340,
          13,
          51606
        ]
      },
      {
        "avg_logprob": -0.24644312105680766,
        "compression_ratio": 1.659375,
        "end": 1035.1399999999999,
        "id": 328,
        "no_speech_prob": 0.0003150370321236551,
        "seek": 100806,
        "start": 1032.8999999999999,
        "temperature": 0,
        "text": " So hopefully, this will show us that.",
        "tokens": [
          51606,
          407,
          4696,
          11,
          341,
          486,
          855,
          505,
          300,
          13,
          51718
        ]
      },
      {
        "avg_logprob": -0.24644312105680766,
        "compression_ratio": 1.659375,
        "end": 1036.54,
        "id": 329,
        "no_speech_prob": 0.0003150370321236551,
        "seek": 100806,
        "start": 1035.1399999999999,
        "temperature": 0,
        "text": " How about we write some code now?",
        "tokens": [
          51718,
          1012,
          466,
          321,
          2464,
          512,
          3089,
          586,
          30,
          51788
        ]
      },
      {
        "avg_logprob": -0.27237789154052733,
        "compression_ratio": 1.5405405405405406,
        "end": 1044.1399999999999,
        "id": 330,
        "no_speech_prob": 0.000004289299795345869,
        "seek": 103806,
        "start": 1038.46,
        "temperature": 0,
        "text": " I'm pausing for a second, taking a look at the chat.",
        "tokens": [
          50384,
          286,
          478,
          2502,
          7981,
          337,
          257,
          1150,
          11,
          1940,
          257,
          574,
          412,
          264,
          5081,
          13,
          50668
        ]
      },
      {
        "avg_logprob": -0.27237789154052733,
        "compression_ratio": 1.5405405405405406,
        "end": 1045.7,
        "id": 331,
        "no_speech_prob": 0.000004289299795345869,
        "seek": 103806,
        "start": 1044.1399999999999,
        "temperature": 0,
        "text": " The root shouldn't be there.",
        "tokens": [
          50668,
          440,
          5593,
          4659,
          380,
          312,
          456,
          13,
          50746
        ]
      },
      {
        "avg_logprob": -0.27237789154052733,
        "compression_ratio": 1.5405405405405406,
        "end": 1046.8999999999999,
        "id": 332,
        "no_speech_prob": 0.000004289299795345869,
        "seek": 103806,
        "start": 1045.7,
        "temperature": 0,
        "text": " I don't know what that means.",
        "tokens": [
          50746,
          286,
          500,
          380,
          458,
          437,
          300,
          1355,
          13,
          50806
        ]
      },
      {
        "avg_logprob": -0.27237789154052733,
        "compression_ratio": 1.5405405405405406,
        "end": 1047.58,
        "id": 333,
        "no_speech_prob": 0.000004289299795345869,
        "seek": 103806,
        "start": 1046.8999999999999,
        "temperature": 0,
        "text": " Offset is fine.",
        "tokens": [
          50806,
          6318,
          3854,
          307,
          2489,
          13,
          50840
        ]
      },
      {
        "avg_logprob": -0.27237789154052733,
        "compression_ratio": 1.5405405405405406,
        "end": 1050.8999999999999,
        "id": 334,
        "no_speech_prob": 0.000004289299795345869,
        "seek": 103806,
        "start": 1047.58,
        "temperature": 0,
        "text": " Y intersect or intercept.",
        "tokens": [
          50840,
          398,
          27815,
          420,
          24700,
          13,
          51006
        ]
      },
      {
        "avg_logprob": -0.27237789154052733,
        "compression_ratio": 1.5405405405405406,
        "end": 1051.74,
        "id": 335,
        "no_speech_prob": 0.000004289299795345869,
        "seek": 103806,
        "start": 1050.8999999999999,
        "temperature": 0,
        "text": " What's the root?",
        "tokens": [
          51006,
          708,
          311,
          264,
          5593,
          30,
          51048
        ]
      },
      {
        "avg_logprob": -0.27237789154052733,
        "compression_ratio": 1.5405405405405406,
        "end": 1057.74,
        "id": 336,
        "no_speech_prob": 0.000004289299795345869,
        "seek": 103806,
        "start": 1051.74,
        "temperature": 0,
        "text": " Oh, so what's the, let me look this up on the,",
        "tokens": [
          51048,
          876,
          11,
          370,
          437,
          311,
          264,
          11,
          718,
          385,
          574,
          341,
          493,
          322,
          264,
          11,
          51348
        ]
      },
      {
        "avg_logprob": -0.27237789154052733,
        "compression_ratio": 1.5405405405405406,
        "end": 1060.46,
        "id": 337,
        "no_speech_prob": 0.000004289299795345869,
        "seek": 103806,
        "start": 1057.74,
        "temperature": 0,
        "text": " what's the wire mess?",
        "tokens": [
          51348,
          437,
          311,
          264,
          6234,
          2082,
          30,
          51484
        ]
      },
      {
        "avg_logprob": -0.27237789154052733,
        "compression_ratio": 1.5405405405405406,
        "end": 1065.1799999999998,
        "id": 338,
        "no_speech_prob": 0.000004289299795345869,
        "seek": 103806,
        "start": 1060.46,
        "temperature": 0,
        "text": " Oh, in the back of my, yeah, let me fix that.",
        "tokens": [
          51484,
          876,
          11,
          294,
          264,
          646,
          295,
          452,
          11,
          1338,
          11,
          718,
          385,
          3191,
          300,
          13,
          51720
        ]
      },
      {
        "avg_logprob": -0.45144317263648626,
        "compression_ratio": 1.1584158415841583,
        "end": 1080.4199999999998,
        "id": 339,
        "no_speech_prob": 0.00023782174685038626,
        "seek": 106806,
        "start": 1068.06,
        "temperature": 0,
        "text": " What's the, why did I say root?",
        "tokens": [
          50364,
          708,
          311,
          264,
          11,
          983,
          630,
          286,
          584,
          5593,
          30,
          50982
        ]
      },
      {
        "avg_logprob": -0.45144317263648626,
        "compression_ratio": 1.1584158415841583,
        "end": 1093.54,
        "id": 340,
        "no_speech_prob": 0.00023782174685038626,
        "seek": 106806,
        "start": 1086.34,
        "temperature": 0,
        "text": " Let me look at loss square.",
        "tokens": [
          51278,
          961,
          385,
          574,
          412,
          4470,
          3732,
          13,
          51638
        ]
      },
      {
        "avg_logprob": -0.45144317263648626,
        "compression_ratio": 1.1584158415841583,
        "end": 1095.62,
        "id": 341,
        "no_speech_prob": 0.00023782174685038626,
        "seek": 106806,
        "start": 1093.54,
        "temperature": 0,
        "text": " Oh, because I don't have to square root it.",
        "tokens": [
          51638,
          876,
          11,
          570,
          286,
          500,
          380,
          362,
          281,
          3732,
          5593,
          309,
          13,
          51742
        ]
      },
      {
        "avg_logprob": -0.45144317263648626,
        "compression_ratio": 1.1584158415841583,
        "end": 1096.74,
        "id": 342,
        "no_speech_prob": 0.00023782174685038626,
        "seek": 106806,
        "start": 1095.62,
        "temperature": 0,
        "text": " Mean squared.",
        "tokens": [
          51742,
          12302,
          8889,
          13,
          51798
        ]
      },
      {
        "avg_logprob": -0.2640402576710918,
        "compression_ratio": 1.573394495412844,
        "end": 1099.06,
        "id": 343,
        "no_speech_prob": 0.000014971060409152415,
        "seek": 109674,
        "start": 1096.78,
        "temperature": 0,
        "text": " Yeah, so I'm going to just use mean squared error.",
        "tokens": [
          50366,
          865,
          11,
          370,
          286,
          478,
          516,
          281,
          445,
          764,
          914,
          8889,
          6713,
          13,
          50480
        ]
      },
      {
        "avg_logprob": -0.2640402576710918,
        "compression_ratio": 1.573394495412844,
        "end": 1100.46,
        "id": 344,
        "no_speech_prob": 0.000014971060409152415,
        "seek": 109674,
        "start": 1099.06,
        "temperature": 0,
        "text": " Thank you.",
        "tokens": [
          50480,
          1044,
          291,
          13,
          50550
        ]
      },
      {
        "avg_logprob": -0.2640402576710918,
        "compression_ratio": 1.573394495412844,
        "end": 1100.94,
        "id": 345,
        "no_speech_prob": 0.000014971060409152415,
        "seek": 109674,
        "start": 1100.46,
        "temperature": 0,
        "text": " Thank you.",
        "tokens": [
          50550,
          1044,
          291,
          13,
          50574
        ]
      },
      {
        "avg_logprob": -0.2640402576710918,
        "compression_ratio": 1.573394495412844,
        "end": 1104.6200000000001,
        "id": 346,
        "no_speech_prob": 0.000014971060409152415,
        "seek": 109674,
        "start": 1100.94,
        "temperature": 0,
        "text": " Simon in the chat, in the Slack group, makes a good point.",
        "tokens": [
          50574,
          13193,
          294,
          264,
          5081,
          11,
          294,
          264,
          37211,
          1594,
          11,
          1669,
          257,
          665,
          935,
          13,
          50758
        ]
      },
      {
        "avg_logprob": -0.2640402576710918,
        "compression_ratio": 1.573394495412844,
        "end": 1106.54,
        "id": 347,
        "no_speech_prob": 0.000014971060409152415,
        "seek": 109674,
        "start": 1104.6200000000001,
        "temperature": 0,
        "text": " So maybe I should correct that really quickly.",
        "tokens": [
          50758,
          407,
          1310,
          286,
          820,
          3006,
          300,
          534,
          2661,
          13,
          50854
        ]
      },
      {
        "avg_logprob": -0.2640402576710918,
        "compression_ratio": 1.573394495412844,
        "end": 1111.78,
        "id": 348,
        "no_speech_prob": 0.000014971060409152415,
        "seek": 109674,
        "start": 1109.34,
        "temperature": 0,
        "text": " I am not going to be doing partial derivatives again.",
        "tokens": [
          50994,
          286,
          669,
          406,
          516,
          281,
          312,
          884,
          14641,
          33733,
          797,
          13,
          51116
        ]
      },
      {
        "avg_logprob": -0.2640402576710918,
        "compression_ratio": 1.573394495412844,
        "end": 1114.7,
        "id": 349,
        "no_speech_prob": 0.000014971060409152415,
        "seek": 109674,
        "start": 1111.78,
        "temperature": 0,
        "text": " Definitely not, asked Kenneth.",
        "tokens": [
          51116,
          12151,
          406,
          11,
          2351,
          33735,
          13,
          51262
        ]
      },
      {
        "avg_logprob": -0.2640402576710918,
        "compression_ratio": 1.573394495412844,
        "end": 1118.06,
        "id": 350,
        "no_speech_prob": 0.000014971060409152415,
        "seek": 109674,
        "start": 1114.7,
        "temperature": 0,
        "text": " So maybe I should go back and define that better.",
        "tokens": [
          51262,
          407,
          1310,
          286,
          820,
          352,
          646,
          293,
          6964,
          300,
          1101,
          13,
          51430
        ]
      },
      {
        "avg_logprob": -0.2640402576710918,
        "compression_ratio": 1.573394495412844,
        "end": 1126.7,
        "id": 351,
        "no_speech_prob": 0.000014971060409152415,
        "seek": 109674,
        "start": 1118.06,
        "temperature": 0,
        "text": " Root mean squared is, oh, OK.",
        "tokens": [
          51430,
          3101,
          310,
          914,
          8889,
          307,
          11,
          1954,
          11,
          2264,
          13,
          51862
        ]
      },
      {
        "avg_logprob": -0.22286345226929918,
        "compression_ratio": 1.6160337552742616,
        "end": 1129.3400000000001,
        "id": 352,
        "no_speech_prob": 0.0000027694040909409523,
        "seek": 112670,
        "start": 1127.22,
        "temperature": 0,
        "text": " So actually, I magically appeared over here",
        "tokens": [
          50390,
          407,
          767,
          11,
          286,
          39763,
          8516,
          670,
          510,
          50496
        ]
      },
      {
        "avg_logprob": -0.22286345226929918,
        "compression_ratio": 1.6160337552742616,
        "end": 1132.42,
        "id": 353,
        "no_speech_prob": 0.0000027694040909409523,
        "seek": 112670,
        "start": 1129.3400000000001,
        "temperature": 0,
        "text": " for a second, because instead of,",
        "tokens": [
          50496,
          337,
          257,
          1150,
          11,
          570,
          2602,
          295,
          11,
          50650
        ]
      },
      {
        "avg_logprob": -0.22286345226929918,
        "compression_ratio": 1.6160337552742616,
        "end": 1133.82,
        "id": 354,
        "no_speech_prob": 0.0000027694040909409523,
        "seek": 112670,
        "start": 1132.42,
        "temperature": 0,
        "text": " I did make a little mistake here.",
        "tokens": [
          50650,
          286,
          630,
          652,
          257,
          707,
          6146,
          510,
          13,
          50720
        ]
      },
      {
        "avg_logprob": -0.22286345226929918,
        "compression_ratio": 1.6160337552742616,
        "end": 1138.18,
        "id": 355,
        "no_speech_prob": 0.0000027694040909409523,
        "seek": 112670,
        "start": 1133.82,
        "temperature": 0,
        "text": " I mean, root mean squared is a perfectly legitimate loss",
        "tokens": [
          50720,
          286,
          914,
          11,
          5593,
          914,
          8889,
          307,
          257,
          6239,
          17956,
          4470,
          50938
        ]
      },
      {
        "avg_logprob": -0.22286345226929918,
        "compression_ratio": 1.6160337552742616,
        "end": 1138.94,
        "id": 356,
        "no_speech_prob": 0.0000027694040909409523,
        "seek": 112670,
        "start": 1138.18,
        "temperature": 0,
        "text": " function.",
        "tokens": [
          50938,
          2445,
          13,
          50976
        ]
      },
      {
        "avg_logprob": -0.22286345226929918,
        "compression_ratio": 1.6160337552742616,
        "end": 1142.74,
        "id": 357,
        "no_speech_prob": 0.0000027694040909409523,
        "seek": 112670,
        "start": 1138.94,
        "temperature": 0,
        "text": " But most linear regression with gradient descent examples",
        "tokens": [
          50976,
          583,
          881,
          8213,
          24590,
          365,
          16235,
          23475,
          5110,
          51166
        ]
      },
      {
        "avg_logprob": -0.22286345226929918,
        "compression_ratio": 1.6160337552742616,
        "end": 1144.78,
        "id": 358,
        "no_speech_prob": 0.0000027694040909409523,
        "seek": 112670,
        "start": 1142.74,
        "temperature": 0,
        "text": " will not bother with the root.",
        "tokens": [
          51166,
          486,
          406,
          8677,
          365,
          264,
          5593,
          13,
          51268
        ]
      },
      {
        "avg_logprob": -0.22286345226929918,
        "compression_ratio": 1.6160337552742616,
        "end": 1146.74,
        "id": 359,
        "no_speech_prob": 0.0000027694040909409523,
        "seek": 112670,
        "start": 1144.78,
        "temperature": 0,
        "text": " And the root refers to square root.",
        "tokens": [
          51268,
          400,
          264,
          5593,
          14942,
          281,
          3732,
          5593,
          13,
          51366
        ]
      },
      {
        "avg_logprob": -0.22286345226929918,
        "compression_ratio": 1.6160337552742616,
        "end": 1148.9,
        "id": 360,
        "no_speech_prob": 0.0000027694040909409523,
        "seek": 112670,
        "start": 1146.74,
        "temperature": 0,
        "text": " We just want the mean squared error,",
        "tokens": [
          51366,
          492,
          445,
          528,
          264,
          914,
          8889,
          6713,
          11,
          51474
        ]
      },
      {
        "avg_logprob": -0.22286345226929918,
        "compression_ratio": 1.6160337552742616,
        "end": 1153.18,
        "id": 361,
        "no_speech_prob": 0.0000027694040909409523,
        "seek": 112670,
        "start": 1148.9,
        "temperature": 0,
        "text": " which means if I say that this value is y,",
        "tokens": [
          51474,
          597,
          1355,
          498,
          286,
          584,
          300,
          341,
          2158,
          307,
          288,
          11,
          51688
        ]
      },
      {
        "avg_logprob": -0.25932304008857354,
        "compression_ratio": 1.8047808764940239,
        "end": 1161.8200000000002,
        "id": 362,
        "no_speech_prob": 0.0000043568793444137555,
        "seek": 115318,
        "start": 1153.18,
        "temperature": 0,
        "text": " and this value is the guess, the error is guess minus y",
        "tokens": [
          50364,
          293,
          341,
          2158,
          307,
          264,
          2041,
          11,
          264,
          6713,
          307,
          2041,
          3175,
          288,
          50796
        ]
      },
      {
        "avg_logprob": -0.25932304008857354,
        "compression_ratio": 1.8047808764940239,
        "end": 1162.94,
        "id": 363,
        "no_speech_prob": 0.0000043568793444137555,
        "seek": 115318,
        "start": 1161.8200000000002,
        "temperature": 0,
        "text": " and squared.",
        "tokens": [
          50796,
          293,
          8889,
          13,
          50852
        ]
      },
      {
        "avg_logprob": -0.25932304008857354,
        "compression_ratio": 1.8047808764940239,
        "end": 1166.5800000000002,
        "id": 364,
        "no_speech_prob": 0.0000043568793444137555,
        "seek": 115318,
        "start": 1162.94,
        "temperature": 0,
        "text": " And if I do that for all of these, that's the mean.",
        "tokens": [
          50852,
          400,
          498,
          286,
          360,
          300,
          337,
          439,
          295,
          613,
          11,
          300,
          311,
          264,
          914,
          13,
          51034
        ]
      },
      {
        "avg_logprob": -0.25932304008857354,
        "compression_ratio": 1.8047808764940239,
        "end": 1167.38,
        "id": 365,
        "no_speech_prob": 0.0000043568793444137555,
        "seek": 115318,
        "start": 1166.5800000000002,
        "temperature": 0,
        "text": " I average them.",
        "tokens": [
          51034,
          286,
          4274,
          552,
          13,
          51074
        ]
      },
      {
        "avg_logprob": -0.25932304008857354,
        "compression_ratio": 1.8047808764940239,
        "end": 1168,
        "id": 366,
        "no_speech_prob": 0.0000043568793444137555,
        "seek": 115318,
        "start": 1167.38,
        "temperature": 0,
        "text": " It's the mean.",
        "tokens": [
          51074,
          467,
          311,
          264,
          914,
          13,
          51105
        ]
      },
      {
        "avg_logprob": -0.25932304008857354,
        "compression_ratio": 1.8047808764940239,
        "end": 1169.5800000000002,
        "id": 367,
        "no_speech_prob": 0.0000043568793444137555,
        "seek": 115318,
        "start": 1168,
        "temperature": 0,
        "text": " So I can really sum them or mean them.",
        "tokens": [
          51105,
          407,
          286,
          393,
          534,
          2408,
          552,
          420,
          914,
          552,
          13,
          51184
        ]
      },
      {
        "avg_logprob": -0.25932304008857354,
        "compression_ratio": 1.8047808764940239,
        "end": 1172.3400000000001,
        "id": 368,
        "no_speech_prob": 0.0000043568793444137555,
        "seek": 115318,
        "start": 1169.5800000000002,
        "temperature": 0,
        "text": " Well, it's going to take care of that for us.",
        "tokens": [
          51184,
          1042,
          11,
          309,
          311,
          516,
          281,
          747,
          1127,
          295,
          300,
          337,
          505,
          13,
          51322
        ]
      },
      {
        "avg_logprob": -0.25932304008857354,
        "compression_ratio": 1.8047808764940239,
        "end": 1174.66,
        "id": 369,
        "no_speech_prob": 0.0000043568793444137555,
        "seek": 115318,
        "start": 1172.3400000000001,
        "temperature": 0,
        "text": " So we're just going to use the mean squared error.",
        "tokens": [
          51322,
          407,
          321,
          434,
          445,
          516,
          281,
          764,
          264,
          914,
          8889,
          6713,
          13,
          51438
        ]
      },
      {
        "avg_logprob": -0.25932304008857354,
        "compression_ratio": 1.8047808764940239,
        "end": 1175.9,
        "id": 370,
        "no_speech_prob": 0.0000043568793444137555,
        "seek": 115318,
        "start": 1174.66,
        "temperature": 0,
        "text": " But that's the idea.",
        "tokens": [
          51438,
          583,
          300,
          311,
          264,
          1558,
          13,
          51500
        ]
      },
      {
        "avg_logprob": -0.25932304008857354,
        "compression_ratio": 1.8047808764940239,
        "end": 1177.18,
        "id": 371,
        "no_speech_prob": 0.0000043568793444137555,
        "seek": 115318,
        "start": 1175.9,
        "temperature": 0,
        "text": " We take the differences.",
        "tokens": [
          51500,
          492,
          747,
          264,
          7300,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.25932304008857354,
        "compression_ratio": 1.8047808764940239,
        "end": 1179.14,
        "id": 372,
        "no_speech_prob": 0.0000043568793444137555,
        "seek": 115318,
        "start": 1177.18,
        "temperature": 0,
        "text": " The reason why we have to square it, well,",
        "tokens": [
          51564,
          440,
          1778,
          983,
          321,
          362,
          281,
          3732,
          309,
          11,
          731,
          11,
          51662
        ]
      },
      {
        "avg_logprob": -0.25932304008857354,
        "compression_ratio": 1.8047808764940239,
        "end": 1180.26,
        "id": 373,
        "no_speech_prob": 0.0000043568793444137555,
        "seek": 115318,
        "start": 1179.14,
        "temperature": 0,
        "text": " for a variety of reasons.",
        "tokens": [
          51662,
          337,
          257,
          5673,
          295,
          4112,
          13,
          51718
        ]
      },
      {
        "avg_logprob": -0.25932304008857354,
        "compression_ratio": 1.8047808764940239,
        "end": 1182.3400000000001,
        "id": 374,
        "no_speech_prob": 0.0000043568793444137555,
        "seek": 115318,
        "start": 1180.26,
        "temperature": 0,
        "text": " One, it has to do with the derivative stuff that's",
        "tokens": [
          51718,
          1485,
          11,
          309,
          575,
          281,
          360,
          365,
          264,
          13760,
          1507,
          300,
          311,
          51822
        ]
      },
      {
        "avg_logprob": -0.2931008924517715,
        "compression_ratio": 1.6591928251121075,
        "end": 1183.98,
        "id": 375,
        "no_speech_prob": 0.00009761541878106073,
        "seek": 118234,
        "start": 1182.3799999999999,
        "temperature": 0,
        "text": " in my other videos, but also just",
        "tokens": [
          50366,
          294,
          452,
          661,
          2145,
          11,
          457,
          611,
          445,
          50446
        ]
      },
      {
        "avg_logprob": -0.2931008924517715,
        "compression_ratio": 1.6591928251121075,
        "end": 1187.6999999999998,
        "id": 376,
        "no_speech_prob": 0.00009761541878106073,
        "seek": 118234,
        "start": 1183.98,
        "temperature": 0,
        "text": " because positive or negative, it's",
        "tokens": [
          50446,
          570,
          3353,
          420,
          3671,
          11,
          309,
          311,
          50632
        ]
      },
      {
        "avg_logprob": -0.2931008924517715,
        "compression_ratio": 1.6591928251121075,
        "end": 1189.78,
        "id": 377,
        "no_speech_prob": 0.00009761541878106073,
        "seek": 118234,
        "start": 1187.6999999999998,
        "temperature": 0,
        "text": " the distance, the size of the error,",
        "tokens": [
          50632,
          264,
          4560,
          11,
          264,
          2744,
          295,
          264,
          6713,
          11,
          50736
        ]
      },
      {
        "avg_logprob": -0.2931008924517715,
        "compression_ratio": 1.6591928251121075,
        "end": 1192.74,
        "id": 378,
        "no_speech_prob": 0.00009761541878106073,
        "seek": 118234,
        "start": 1189.78,
        "temperature": 0,
        "text": " whether it's up or down, which is key.",
        "tokens": [
          50736,
          1968,
          309,
          311,
          493,
          420,
          760,
          11,
          597,
          307,
          2141,
          13,
          50884
        ]
      },
      {
        "avg_logprob": -0.2931008924517715,
        "compression_ratio": 1.6591928251121075,
        "end": 1193.62,
        "id": 379,
        "no_speech_prob": 0.00009761541878106073,
        "seek": 118234,
        "start": 1192.74,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50884,
          1057,
          558,
          13,
          50928
        ]
      },
      {
        "avg_logprob": -0.2931008924517715,
        "compression_ratio": 1.6591928251121075,
        "end": 1195.62,
        "id": 380,
        "no_speech_prob": 0.00009761541878106073,
        "seek": 118234,
        "start": 1193.62,
        "temperature": 0,
        "text": " So I need to start the coding, but the microphone",
        "tokens": [
          50928,
          407,
          286,
          643,
          281,
          722,
          264,
          17720,
          11,
          457,
          264,
          10952,
          51028
        ]
      },
      {
        "avg_logprob": -0.2931008924517715,
        "compression_ratio": 1.6591928251121075,
        "end": 1196.82,
        "id": 381,
        "no_speech_prob": 0.00009761541878106073,
        "seek": 118234,
        "start": 1195.62,
        "temperature": 0,
        "text": " is making me crazy right now.",
        "tokens": [
          51028,
          307,
          1455,
          385,
          3219,
          558,
          586,
          13,
          51088
        ]
      },
      {
        "avg_logprob": -0.2931008924517715,
        "compression_ratio": 1.6591928251121075,
        "end": 1198.02,
        "id": 382,
        "no_speech_prob": 0.00009761541878106073,
        "seek": 118234,
        "start": 1196.82,
        "temperature": 0,
        "text": " I need to tape it to my ear.",
        "tokens": [
          51088,
          286,
          643,
          281,
          7314,
          309,
          281,
          452,
          1273,
          13,
          51148
        ]
      },
      {
        "avg_logprob": -0.2931008924517715,
        "compression_ratio": 1.6591928251121075,
        "end": 1204.98,
        "id": 383,
        "no_speech_prob": 0.00009761541878106073,
        "seek": 118234,
        "start": 1204.3,
        "temperature": 0,
        "text": " So hold on.",
        "tokens": [
          51462,
          407,
          1797,
          322,
          13,
          51496
        ]
      },
      {
        "avg_logprob": -0.2931008924517715,
        "compression_ratio": 1.6591928251121075,
        "end": 1207.3,
        "id": 384,
        "no_speech_prob": 0.00009761541878106073,
        "seek": 118234,
        "start": 1204.98,
        "temperature": 0,
        "text": " I just need to get a little piece of tape.",
        "tokens": [
          51496,
          286,
          445,
          643,
          281,
          483,
          257,
          707,
          2522,
          295,
          7314,
          13,
          51612
        ]
      },
      {
        "avg_logprob": -0.2931008924517715,
        "compression_ratio": 1.6591928251121075,
        "end": 1211.86,
        "id": 385,
        "no_speech_prob": 0.00009761541878106073,
        "seek": 118234,
        "start": 1207.3,
        "temperature": 0,
        "text": " It really distracts me when the microphone starts.",
        "tokens": [
          51612,
          467,
          534,
          9945,
          82,
          385,
          562,
          264,
          10952,
          3719,
          13,
          51840
        ]
      },
      {
        "avg_logprob": -0.30183578672863187,
        "compression_ratio": 1.5459770114942528,
        "end": 1214.4599999999998,
        "id": 386,
        "no_speech_prob": 0.00001241140671481844,
        "seek": 121186,
        "start": 1211.86,
        "temperature": 0,
        "text": " Yeah, by the way, Ricardo in the chat",
        "tokens": [
          50364,
          865,
          11,
          538,
          264,
          636,
          11,
          42634,
          294,
          264,
          5081,
          50494
        ]
      },
      {
        "avg_logprob": -0.30183578672863187,
        "compression_ratio": 1.5459770114942528,
        "end": 1216.06,
        "id": 387,
        "no_speech_prob": 0.00001241140671481844,
        "seek": 121186,
        "start": 1214.4599999999998,
        "temperature": 0,
        "text": " is mentioning the Coding Train hoodie.",
        "tokens": [
          50494,
          307,
          18315,
          264,
          383,
          8616,
          28029,
          41191,
          13,
          50574
        ]
      },
      {
        "avg_logprob": -0.30183578672863187,
        "compression_ratio": 1.5459770114942528,
        "end": 1217.5,
        "id": 388,
        "no_speech_prob": 0.00001241140671481844,
        "seek": 121186,
        "start": 1216.06,
        "temperature": 0,
        "text": " This is a new Coding Train hoodie",
        "tokens": [
          50574,
          639,
          307,
          257,
          777,
          383,
          8616,
          28029,
          41191,
          50646
        ]
      },
      {
        "avg_logprob": -0.30183578672863187,
        "compression_ratio": 1.5459770114942528,
        "end": 1219.5,
        "id": 389,
        "no_speech_prob": 0.00001241140671481844,
        "seek": 121186,
        "start": 1217.5,
        "temperature": 0,
        "text": " that will be available later today.",
        "tokens": [
          50646,
          300,
          486,
          312,
          2435,
          1780,
          965,
          13,
          50746
        ]
      },
      {
        "avg_logprob": -0.30183578672863187,
        "compression_ratio": 1.5459770114942528,
        "end": 1225.8799999999999,
        "id": 390,
        "no_speech_prob": 0.00001241140671481844,
        "seek": 121186,
        "start": 1225.3799999999999,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51040,
          1057,
          558,
          13,
          51065
        ]
      },
      {
        "avg_logprob": -0.30183578672863187,
        "compression_ratio": 1.5459770114942528,
        "end": 1227.5,
        "id": 391,
        "no_speech_prob": 0.00001241140671481844,
        "seek": 121186,
        "start": 1225.8799999999999,
        "temperature": 0,
        "text": " Am I good to start coding?",
        "tokens": [
          51065,
          2012,
          286,
          665,
          281,
          722,
          17720,
          30,
          51146
        ]
      },
      {
        "avg_logprob": -0.30183578672863187,
        "compression_ratio": 1.5459770114942528,
        "end": 1229.82,
        "id": 392,
        "no_speech_prob": 0.00001241140671481844,
        "seek": 121186,
        "start": 1227.5,
        "temperature": 0,
        "text": " Any last comments before I start coding?",
        "tokens": [
          51146,
          2639,
          1036,
          3053,
          949,
          286,
          722,
          17720,
          30,
          51262
        ]
      },
      {
        "avg_logprob": -0.30183578672863187,
        "compression_ratio": 1.5459770114942528,
        "end": 1237.78,
        "id": 393,
        "no_speech_prob": 0.00001241140671481844,
        "seek": 121186,
        "start": 1233.2199999999998,
        "temperature": 0,
        "text": " This feels, it's staying on my ear now.",
        "tokens": [
          51432,
          639,
          3417,
          11,
          309,
          311,
          7939,
          322,
          452,
          1273,
          586,
          13,
          51660
        ]
      },
      {
        "avg_logprob": -0.30183578672863187,
        "compression_ratio": 1.5459770114942528,
        "end": 1239.02,
        "id": 394,
        "no_speech_prob": 0.00001241140671481844,
        "seek": 121186,
        "start": 1237.78,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51660,
          2264,
          13,
          51722
        ]
      },
      {
        "avg_logprob": -0.26708434025446576,
        "compression_ratio": 1.4285714285714286,
        "end": 1242.3799999999999,
        "id": 395,
        "no_speech_prob": 0.0001398217718815431,
        "seek": 123902,
        "start": 1239.1,
        "temperature": 0,
        "text": " And maybe next time, I'll get the lapel mic back.",
        "tokens": [
          50368,
          400,
          1310,
          958,
          565,
          11,
          286,
          603,
          483,
          264,
          13214,
          338,
          3123,
          646,
          13,
          50532
        ]
      },
      {
        "avg_logprob": -0.26708434025446576,
        "compression_ratio": 1.4285714285714286,
        "end": 1243.5,
        "id": 396,
        "no_speech_prob": 0.0001398217718815431,
        "seek": 123902,
        "start": 1242.3799999999999,
        "temperature": 0,
        "text": " How are we, 451?",
        "tokens": [
          50532,
          1012,
          366,
          321,
          11,
          6905,
          16,
          30,
          50588
        ]
      },
      {
        "avg_logprob": -0.26708434025446576,
        "compression_ratio": 1.4285714285714286,
        "end": 1244.5,
        "id": 397,
        "no_speech_prob": 0.0001398217718815431,
        "seek": 123902,
        "start": 1243.5,
        "temperature": 0,
        "text": " We're doing pretty well.",
        "tokens": [
          50588,
          492,
          434,
          884,
          1238,
          731,
          13,
          50638
        ]
      },
      {
        "avg_logprob": -0.26708434025446576,
        "compression_ratio": 1.4285714285714286,
        "end": 1254.78,
        "id": 398,
        "no_speech_prob": 0.0001398217718815431,
        "seek": 123902,
        "start": 1249.82,
        "temperature": 0,
        "text": " To check my, I'm just going to keep going.",
        "tokens": [
          50904,
          1407,
          1520,
          452,
          11,
          286,
          478,
          445,
          516,
          281,
          1066,
          516,
          13,
          51152
        ]
      },
      {
        "avg_logprob": -0.26708434025446576,
        "compression_ratio": 1.4285714285714286,
        "end": 1256.1399999999999,
        "id": 399,
        "no_speech_prob": 0.0001398217718815431,
        "seek": 123902,
        "start": 1254.78,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51152,
          1057,
          558,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.26708434025446576,
        "compression_ratio": 1.4285714285714286,
        "end": 1257.7,
        "id": 400,
        "no_speech_prob": 0.0001398217718815431,
        "seek": 123902,
        "start": 1256.1399999999999,
        "temperature": 0,
        "text": " I think I'm good.",
        "tokens": [
          51220,
          286,
          519,
          286,
          478,
          665,
          13,
          51298
        ]
      },
      {
        "avg_logprob": -0.26708434025446576,
        "compression_ratio": 1.4285714285714286,
        "end": 1261.54,
        "id": 401,
        "no_speech_prob": 0.0001398217718815431,
        "seek": 123902,
        "start": 1257.7,
        "temperature": 0,
        "text": " I think we're ready to start writing some code.",
        "tokens": [
          51298,
          286,
          519,
          321,
          434,
          1919,
          281,
          722,
          3579,
          512,
          3089,
          13,
          51490
        ]
      },
      {
        "avg_logprob": -0.26708434025446576,
        "compression_ratio": 1.4285714285714286,
        "end": 1264.46,
        "id": 402,
        "no_speech_prob": 0.0001398217718815431,
        "seek": 123902,
        "start": 1261.54,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51490,
          1057,
          558,
          13,
          51636
        ]
      },
      {
        "avg_logprob": -0.26708434025446576,
        "compression_ratio": 1.4285714285714286,
        "end": 1266.18,
        "id": 403,
        "no_speech_prob": 0.0001398217718815431,
        "seek": 123902,
        "start": 1264.46,
        "temperature": 0,
        "text": " Where's my marker in case I need it?",
        "tokens": [
          51636,
          2305,
          311,
          452,
          15247,
          294,
          1389,
          286,
          643,
          309,
          30,
          51722
        ]
      },
      {
        "avg_logprob": -0.26708434025446576,
        "compression_ratio": 1.4285714285714286,
        "end": 1266.68,
        "id": 404,
        "no_speech_prob": 0.0001398217718815431,
        "seek": 123902,
        "start": 1266.18,
        "temperature": 0,
        "text": " Over here.",
        "tokens": [
          51722,
          4886,
          510,
          13,
          51747
        ]
      },
      {
        "avg_logprob": -0.4084787230560745,
        "compression_ratio": 1.6611570247933884,
        "end": 1270.26,
        "id": 405,
        "no_speech_prob": 0.00001544623046356719,
        "seek": 126902,
        "start": 1269.74,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50400,
          1057,
          558,
          13,
          50426
        ]
      },
      {
        "avg_logprob": -0.4084787230560745,
        "compression_ratio": 1.6611570247933884,
        "end": 1272.58,
        "id": 406,
        "no_speech_prob": 0.00001544623046356719,
        "seek": 126902,
        "start": 1270.26,
        "temperature": 0,
        "text": " So here's the amount of code we're going to start with.",
        "tokens": [
          50426,
          407,
          510,
          311,
          264,
          2372,
          295,
          3089,
          321,
          434,
          516,
          281,
          722,
          365,
          13,
          50542
        ]
      },
      {
        "avg_logprob": -0.4084787230560745,
        "compression_ratio": 1.6611570247933884,
        "end": 1275.5,
        "id": 407,
        "no_speech_prob": 0.00001544623046356719,
        "seek": 126902,
        "start": 1272.58,
        "temperature": 0,
        "text": " I'm using p5 so that I can draw stuff.",
        "tokens": [
          50542,
          286,
          478,
          1228,
          280,
          20,
          370,
          300,
          286,
          393,
          2642,
          1507,
          13,
          50688
        ]
      },
      {
        "avg_logprob": -0.4084787230560745,
        "compression_ratio": 1.6611570247933884,
        "end": 1277.3799999999999,
        "id": 408,
        "no_speech_prob": 0.00001544623046356719,
        "seek": 126902,
        "start": 1275.5,
        "temperature": 0,
        "text": " I'm making a canvas, and the background",
        "tokens": [
          50688,
          286,
          478,
          1455,
          257,
          16267,
          11,
          293,
          264,
          3678,
          50782
        ]
      },
      {
        "avg_logprob": -0.4084787230560745,
        "compression_ratio": 1.6611570247933884,
        "end": 1279.5,
        "id": 409,
        "no_speech_prob": 0.00001544623046356719,
        "seek": 126902,
        "start": 1277.3799999999999,
        "temperature": 0,
        "text": " is 0, which means it's black.",
        "tokens": [
          50782,
          307,
          1958,
          11,
          597,
          1355,
          309,
          311,
          2211,
          13,
          50888
        ]
      },
      {
        "avg_logprob": -0.4084787230560745,
        "compression_ratio": 1.6611570247933884,
        "end": 1281.1,
        "id": 410,
        "no_speech_prob": 0.00001544623046356719,
        "seek": 126902,
        "start": 1279.5,
        "temperature": 0,
        "text": " And this is what I have so far.",
        "tokens": [
          50888,
          400,
          341,
          307,
          437,
          286,
          362,
          370,
          1400,
          13,
          50968
        ]
      },
      {
        "avg_logprob": -0.4084787230560745,
        "compression_ratio": 1.6611570247933884,
        "end": 1283.18,
        "id": 411,
        "no_speech_prob": 0.00001544623046356719,
        "seek": 126902,
        "start": 1281.1,
        "temperature": 0,
        "text": " So let's look at our list over here.",
        "tokens": [
          50968,
          407,
          718,
          311,
          574,
          412,
          527,
          1329,
          670,
          510,
          13,
          51072
        ]
      },
      {
        "avg_logprob": -0.4084787230560745,
        "compression_ratio": 1.6611570247933884,
        "end": 1286.62,
        "id": 412,
        "no_speech_prob": 0.00001544623046356719,
        "seek": 126902,
        "start": 1283.18,
        "temperature": 0,
        "text": " And let's first add the data set, the x's and y's.",
        "tokens": [
          51072,
          400,
          718,
          311,
          700,
          909,
          264,
          1412,
          992,
          11,
          264,
          2031,
          311,
          293,
          288,
          311,
          13,
          51244
        ]
      },
      {
        "avg_logprob": -0.4084787230560745,
        "compression_ratio": 1.6611570247933884,
        "end": 1289.5,
        "id": 413,
        "no_speech_prob": 0.00001544623046356719,
        "seek": 126902,
        "start": 1286.62,
        "temperature": 0,
        "text": " So this is going to be easy because I just",
        "tokens": [
          51244,
          407,
          341,
          307,
          516,
          281,
          312,
          1858,
          570,
          286,
          445,
          51388
        ]
      },
      {
        "avg_logprob": -0.4084787230560745,
        "compression_ratio": 1.6611570247933884,
        "end": 1295.9,
        "id": 414,
        "no_speech_prob": 0.00001544623046356719,
        "seek": 126902,
        "start": 1289.5,
        "temperature": 0,
        "text": " want to have x's be an array, y's be a list,",
        "tokens": [
          51388,
          528,
          281,
          362,
          2031,
          311,
          312,
          364,
          10225,
          11,
          288,
          311,
          312,
          257,
          1329,
          11,
          51708
        ]
      },
      {
        "avg_logprob": -0.4084787230560745,
        "compression_ratio": 1.6611570247933884,
        "end": 1297.42,
        "id": 415,
        "no_speech_prob": 0.00001544623046356719,
        "seek": 126902,
        "start": 1295.9,
        "temperature": 0,
        "text": " and z's be a list.",
        "tokens": [
          51708,
          293,
          710,
          311,
          312,
          257,
          1329,
          13,
          51784
        ]
      },
      {
        "avg_logprob": -0.3167084742636576,
        "compression_ratio": 1.8354978354978355,
        "end": 1300.78,
        "id": 416,
        "no_speech_prob": 0.001501179300248623,
        "seek": 129742,
        "start": 1297.42,
        "temperature": 0,
        "text": " So x's be an array, y's also be an array.",
        "tokens": [
          50364,
          407,
          2031,
          311,
          312,
          364,
          10225,
          11,
          288,
          311,
          611,
          312,
          364,
          10225,
          13,
          50532
        ]
      },
      {
        "avg_logprob": -0.3167084742636576,
        "compression_ratio": 1.8354978354978355,
        "end": 1306.8600000000001,
        "id": 417,
        "no_speech_prob": 0.001501179300248623,
        "seek": 129742,
        "start": 1300.78,
        "temperature": 0,
        "text": " And then whenever I click the mouse, I want to say,",
        "tokens": [
          50532,
          400,
          550,
          5699,
          286,
          2052,
          264,
          9719,
          11,
          286,
          528,
          281,
          584,
          11,
          50836
        ]
      },
      {
        "avg_logprob": -0.3167084742636576,
        "compression_ratio": 1.8354978354978355,
        "end": 1308.1000000000001,
        "id": 418,
        "no_speech_prob": 0.001501179300248623,
        "seek": 129742,
        "start": 1306.8600000000001,
        "temperature": 0,
        "text": " oh, you know what I could do?",
        "tokens": [
          50836,
          1954,
          11,
          291,
          458,
          437,
          286,
          727,
          360,
          30,
          50898
        ]
      },
      {
        "avg_logprob": -0.3167084742636576,
        "compression_ratio": 1.8354978354978355,
        "end": 1311.0600000000002,
        "id": 419,
        "no_speech_prob": 0.001501179300248623,
        "seek": 129742,
        "start": 1308.1000000000001,
        "temperature": 0,
        "text": " I could make those vectors, let's make them separate arrays.",
        "tokens": [
          50898,
          286,
          727,
          652,
          729,
          18875,
          11,
          718,
          311,
          652,
          552,
          4994,
          41011,
          13,
          51046
        ]
      },
      {
        "avg_logprob": -0.3167084742636576,
        "compression_ratio": 1.8354978354978355,
        "end": 1311.8200000000002,
        "id": 420,
        "no_speech_prob": 0.001501179300248623,
        "seek": 129742,
        "start": 1311.0600000000002,
        "temperature": 0,
        "text": " I think we're going to, actually,",
        "tokens": [
          51046,
          286,
          519,
          321,
          434,
          516,
          281,
          11,
          767,
          11,
          51084
        ]
      },
      {
        "avg_logprob": -0.3167084742636576,
        "compression_ratio": 1.8354978354978355,
        "end": 1314.0600000000002,
        "id": 421,
        "no_speech_prob": 0.001501179300248623,
        "seek": 129742,
        "start": 1311.8200000000002,
        "temperature": 0,
        "text": " I know we're going to want to do that for a variety of reasons.",
        "tokens": [
          51084,
          286,
          458,
          321,
          434,
          516,
          281,
          528,
          281,
          360,
          300,
          337,
          257,
          5673,
          295,
          4112,
          13,
          51196
        ]
      },
      {
        "avg_logprob": -0.3167084742636576,
        "compression_ratio": 1.8354978354978355,
        "end": 1315.94,
        "id": 422,
        "no_speech_prob": 0.001501179300248623,
        "seek": 129742,
        "start": 1314.0600000000002,
        "temperature": 0,
        "text": " We're going to keep those as separate arrays.",
        "tokens": [
          51196,
          492,
          434,
          516,
          281,
          1066,
          729,
          382,
          4994,
          41011,
          13,
          51290
        ]
      },
      {
        "avg_logprob": -0.3167084742636576,
        "compression_ratio": 1.8354978354978355,
        "end": 1319.18,
        "id": 423,
        "no_speech_prob": 0.001501179300248623,
        "seek": 129742,
        "start": 1315.94,
        "temperature": 0,
        "text": " So every time I click the mouse, I'm going to say x's,",
        "tokens": [
          51290,
          407,
          633,
          565,
          286,
          2052,
          264,
          9719,
          11,
          286,
          478,
          516,
          281,
          584,
          2031,
          311,
          11,
          51452
        ]
      },
      {
        "avg_logprob": -0.3167084742636576,
        "compression_ratio": 1.8354978354978355,
        "end": 1323.0600000000002,
        "id": 424,
        "no_speech_prob": 0.001501179300248623,
        "seek": 129742,
        "start": 1319.18,
        "temperature": 0,
        "text": " push mouse x, y's, push mouse y.",
        "tokens": [
          51452,
          2944,
          9719,
          2031,
          11,
          288,
          311,
          11,
          2944,
          9719,
          288,
          13,
          51646
        ]
      },
      {
        "avg_logprob": -0.3167084742636576,
        "compression_ratio": 1.8354978354978355,
        "end": 1325.54,
        "id": 425,
        "no_speech_prob": 0.001501179300248623,
        "seek": 129742,
        "start": 1323.0600000000002,
        "temperature": 0,
        "text": " Ah, OK.",
        "tokens": [
          51646,
          2438,
          11,
          2264,
          13,
          51770
        ]
      },
      {
        "avg_logprob": -0.2353331683433219,
        "compression_ratio": 1.736842105263158,
        "end": 1328.74,
        "id": 426,
        "no_speech_prob": 0.0000019033838043469586,
        "seek": 132554,
        "start": 1326.1,
        "temperature": 0,
        "text": " Here's a little thing.",
        "tokens": [
          50392,
          1692,
          311,
          257,
          707,
          551,
          13,
          50524
        ]
      },
      {
        "avg_logprob": -0.2353331683433219,
        "compression_ratio": 1.736842105263158,
        "end": 1331.18,
        "id": 427,
        "no_speech_prob": 0.0000019033838043469586,
        "seek": 132554,
        "start": 1328.74,
        "temperature": 0,
        "text": " So this is our canvas.",
        "tokens": [
          50524,
          407,
          341,
          307,
          527,
          16267,
          13,
          50646
        ]
      },
      {
        "avg_logprob": -0.2353331683433219,
        "compression_ratio": 1.736842105263158,
        "end": 1333.06,
        "id": 428,
        "no_speech_prob": 0.0000019033838043469586,
        "seek": 132554,
        "start": 1331.18,
        "temperature": 0,
        "text": " This is my drawing of the canvas.",
        "tokens": [
          50646,
          639,
          307,
          452,
          6316,
          295,
          264,
          16267,
          13,
          50740
        ]
      },
      {
        "avg_logprob": -0.2353331683433219,
        "compression_ratio": 1.736842105263158,
        "end": 1334.6599999999999,
        "id": 429,
        "no_speech_prob": 0.0000019033838043469586,
        "seek": 132554,
        "start": 1333.06,
        "temperature": 0,
        "text": " Now I'm having a deja vu thing.",
        "tokens": [
          50740,
          823,
          286,
          478,
          1419,
          257,
          38260,
          9732,
          551,
          13,
          50820
        ]
      },
      {
        "avg_logprob": -0.2353331683433219,
        "compression_ratio": 1.736842105263158,
        "end": 1336.6599999999999,
        "id": 430,
        "no_speech_prob": 0.0000019033838043469586,
        "seek": 132554,
        "start": 1334.6599999999999,
        "temperature": 0,
        "text": " I totally talked about this in the other video.",
        "tokens": [
          50820,
          286,
          3879,
          2825,
          466,
          341,
          294,
          264,
          661,
          960,
          13,
          50920
        ]
      },
      {
        "avg_logprob": -0.2353331683433219,
        "compression_ratio": 1.736842105263158,
        "end": 1338.54,
        "id": 431,
        "no_speech_prob": 0.0000019033838043469586,
        "seek": 132554,
        "start": 1336.6599999999999,
        "temperature": 0,
        "text": " The width is 400.",
        "tokens": [
          50920,
          440,
          11402,
          307,
          8423,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2353331683433219,
        "compression_ratio": 1.736842105263158,
        "end": 1339.74,
        "id": 432,
        "no_speech_prob": 0.0000019033838043469586,
        "seek": 132554,
        "start": 1338.54,
        "temperature": 0,
        "text": " The height is 400.",
        "tokens": [
          51014,
          440,
          6681,
          307,
          8423,
          13,
          51074
        ]
      },
      {
        "avg_logprob": -0.2353331683433219,
        "compression_ratio": 1.736842105263158,
        "end": 1343.5,
        "id": 433,
        "no_speech_prob": 0.0000019033838043469586,
        "seek": 132554,
        "start": 1339.74,
        "temperature": 0,
        "text": " But I really want to think of this as,",
        "tokens": [
          51074,
          583,
          286,
          534,
          528,
          281,
          519,
          295,
          341,
          382,
          11,
          51262
        ]
      },
      {
        "avg_logprob": -0.2353331683433219,
        "compression_ratio": 1.736842105263158,
        "end": 1346.1,
        "id": 434,
        "no_speech_prob": 0.0000019033838043469586,
        "seek": 132554,
        "start": 1343.5,
        "temperature": 0,
        "text": " I really want to think of 0, 0 down here,",
        "tokens": [
          51262,
          286,
          534,
          528,
          281,
          519,
          295,
          1958,
          11,
          1958,
          760,
          510,
          11,
          51392
        ]
      },
      {
        "avg_logprob": -0.2353331683433219,
        "compression_ratio": 1.736842105263158,
        "end": 1347.54,
        "id": 435,
        "no_speech_prob": 0.0000019033838043469586,
        "seek": 132554,
        "start": 1346.1,
        "temperature": 0,
        "text": " and maybe 1 being over here.",
        "tokens": [
          51392,
          293,
          1310,
          502,
          885,
          670,
          510,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2353331683433219,
        "compression_ratio": 1.736842105263158,
        "end": 1349.8999999999999,
        "id": 436,
        "no_speech_prob": 0.0000019033838043469586,
        "seek": 132554,
        "start": 1347.54,
        "temperature": 0,
        "text": " I want to normalize everything between 0 and 1.",
        "tokens": [
          51464,
          286,
          528,
          281,
          2710,
          1125,
          1203,
          1296,
          1958,
          293,
          502,
          13,
          51582
        ]
      },
      {
        "avg_logprob": -0.2353331683433219,
        "compression_ratio": 1.736842105263158,
        "end": 1352.18,
        "id": 437,
        "no_speech_prob": 0.0000019033838043469586,
        "seek": 132554,
        "start": 1349.8999999999999,
        "temperature": 0,
        "text": " Everything is just going to work better if we do that.",
        "tokens": [
          51582,
          5471,
          307,
          445,
          516,
          281,
          589,
          1101,
          498,
          321,
          360,
          300,
          13,
          51696
        ]
      },
      {
        "avg_logprob": -0.2353331683433219,
        "compression_ratio": 1.736842105263158,
        "end": 1353.82,
        "id": 438,
        "no_speech_prob": 0.0000019033838043469586,
        "seek": 132554,
        "start": 1352.18,
        "temperature": 0,
        "text": " So with y pointing up.",
        "tokens": [
          51696,
          407,
          365,
          288,
          12166,
          493,
          13,
          51778
        ]
      },
      {
        "avg_logprob": -0.2353331683433219,
        "compression_ratio": 1.736842105263158,
        "end": 1355.42,
        "id": 439,
        "no_speech_prob": 0.0000019033838043469586,
        "seek": 132554,
        "start": 1353.82,
        "temperature": 0,
        "text": " So I'm going to do a mapping.",
        "tokens": [
          51778,
          407,
          286,
          478,
          516,
          281,
          360,
          257,
          18350,
          13,
          51858
        ]
      },
      {
        "avg_logprob": -0.19432687759399414,
        "compression_ratio": 2.049079754601227,
        "end": 1359.22,
        "id": 440,
        "no_speech_prob": 0.0000011726417596946703,
        "seek": 135542,
        "start": 1356.3000000000002,
        "temperature": 0,
        "text": " So every y value, that's pixel value between 0 and height,",
        "tokens": [
          50408,
          407,
          633,
          288,
          2158,
          11,
          300,
          311,
          19261,
          2158,
          1296,
          1958,
          293,
          6681,
          11,
          50554
        ]
      },
      {
        "avg_logprob": -0.19432687759399414,
        "compression_ratio": 2.049079754601227,
        "end": 1361.22,
        "id": 441,
        "no_speech_prob": 0.0000011726417596946703,
        "seek": 135542,
        "start": 1359.22,
        "temperature": 0,
        "text": " I'm going to map between 1 and 0.",
        "tokens": [
          50554,
          286,
          478,
          516,
          281,
          4471,
          1296,
          502,
          293,
          1958,
          13,
          50654
        ]
      },
      {
        "avg_logprob": -0.19432687759399414,
        "compression_ratio": 2.049079754601227,
        "end": 1363.46,
        "id": 442,
        "no_speech_prob": 0.0000011726417596946703,
        "seek": 135542,
        "start": 1361.22,
        "temperature": 0,
        "text": " And every x value that's between 0 and width,",
        "tokens": [
          50654,
          400,
          633,
          2031,
          2158,
          300,
          311,
          1296,
          1958,
          293,
          11402,
          11,
          50766
        ]
      },
      {
        "avg_logprob": -0.19432687759399414,
        "compression_ratio": 2.049079754601227,
        "end": 1365.42,
        "id": 443,
        "no_speech_prob": 0.0000011726417596946703,
        "seek": 135542,
        "start": 1363.46,
        "temperature": 0,
        "text": " I'm going to map between 0 and 1.",
        "tokens": [
          50766,
          286,
          478,
          516,
          281,
          4471,
          1296,
          1958,
          293,
          502,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19432687759399414,
        "compression_ratio": 2.049079754601227,
        "end": 1366.98,
        "id": 444,
        "no_speech_prob": 0.0000011726417596946703,
        "seek": 135542,
        "start": 1365.42,
        "temperature": 0,
        "text": " So let's do that.",
        "tokens": [
          50864,
          407,
          718,
          311,
          360,
          300,
          13,
          50942
        ]
      },
      {
        "avg_logprob": -0.19432687759399414,
        "compression_ratio": 2.049079754601227,
        "end": 1372.66,
        "id": 445,
        "no_speech_prob": 0.0000011726417596946703,
        "seek": 135542,
        "start": 1366.98,
        "temperature": 0,
        "text": " So I'm going to say let x equal map mouse x, which",
        "tokens": [
          50942,
          407,
          286,
          478,
          516,
          281,
          584,
          718,
          2031,
          2681,
          4471,
          9719,
          2031,
          11,
          597,
          51226
        ]
      },
      {
        "avg_logprob": -0.19432687759399414,
        "compression_ratio": 2.049079754601227,
        "end": 1378.3400000000001,
        "id": 446,
        "no_speech_prob": 0.0000011726417596946703,
        "seek": 135542,
        "start": 1372.66,
        "temperature": 0,
        "text": " goes between 0 and width, to between 0 and 1.",
        "tokens": [
          51226,
          1709,
          1296,
          1958,
          293,
          11402,
          11,
          281,
          1296,
          1958,
          293,
          502,
          13,
          51510
        ]
      },
      {
        "avg_logprob": -0.19432687759399414,
        "compression_ratio": 2.049079754601227,
        "end": 1383.8200000000002,
        "id": 447,
        "no_speech_prob": 0.0000011726417596946703,
        "seek": 135542,
        "start": 1378.3400000000001,
        "temperature": 0,
        "text": " Let y, which is mouse y, between 0 and height,",
        "tokens": [
          51510,
          961,
          288,
          11,
          597,
          307,
          9719,
          288,
          11,
          1296,
          1958,
          293,
          6681,
          11,
          51784
        ]
      },
      {
        "avg_logprob": -0.2750110842964866,
        "compression_ratio": 1.5344827586206897,
        "end": 1390.86,
        "id": 448,
        "no_speech_prob": 0.0000016797312127891928,
        "seek": 138382,
        "start": 1383.82,
        "temperature": 0,
        "text": " and have that go between 1 and 0, and then push x and push y.",
        "tokens": [
          50364,
          293,
          362,
          300,
          352,
          1296,
          502,
          293,
          1958,
          11,
          293,
          550,
          2944,
          2031,
          293,
          2944,
          288,
          13,
          50716
        ]
      },
      {
        "avg_logprob": -0.2750110842964866,
        "compression_ratio": 1.5344827586206897,
        "end": 1393.54,
        "id": 449,
        "no_speech_prob": 0.0000016797312127891928,
        "seek": 138382,
        "start": 1390.86,
        "temperature": 0,
        "text": " The other thing I want to do is I just want to,",
        "tokens": [
          50716,
          440,
          661,
          551,
          286,
          528,
          281,
          360,
          307,
          286,
          445,
          528,
          281,
          11,
          50850
        ]
      },
      {
        "avg_logprob": -0.2750110842964866,
        "compression_ratio": 1.5344827586206897,
        "end": 1396.62,
        "id": 450,
        "no_speech_prob": 0.0000016797312127891928,
        "seek": 138382,
        "start": 1393.54,
        "temperature": 0,
        "text": " you know, I'm going to add a draw loop,",
        "tokens": [
          50850,
          291,
          458,
          11,
          286,
          478,
          516,
          281,
          909,
          257,
          2642,
          6367,
          11,
          51004
        ]
      },
      {
        "avg_logprob": -0.2750110842964866,
        "compression_ratio": 1.5344827586206897,
        "end": 1399.7,
        "id": 451,
        "no_speech_prob": 0.0000016797312127891928,
        "seek": 138382,
        "start": 1396.62,
        "temperature": 0,
        "text": " and I want to draw all those points.",
        "tokens": [
          51004,
          293,
          286,
          528,
          281,
          2642,
          439,
          729,
          2793,
          13,
          51158
        ]
      },
      {
        "avg_logprob": -0.2750110842964866,
        "compression_ratio": 1.5344827586206897,
        "end": 1406.9399999999998,
        "id": 452,
        "no_speech_prob": 0.0000016797312127891928,
        "seek": 138382,
        "start": 1399.7,
        "temperature": 0,
        "text": " So I'm also now going to say stroke 255, stroke weight 4,",
        "tokens": [
          51158,
          407,
          286,
          478,
          611,
          586,
          516,
          281,
          584,
          12403,
          3552,
          20,
          11,
          12403,
          3364,
          1017,
          11,
          51520
        ]
      },
      {
        "avg_logprob": -0.2750110842964866,
        "compression_ratio": 1.5344827586206897,
        "end": 1411.46,
        "id": 453,
        "no_speech_prob": 0.0000016797312127891928,
        "seek": 138382,
        "start": 1406.9399999999998,
        "temperature": 0,
        "text": " for let i equal, what?",
        "tokens": [
          51520,
          337,
          718,
          741,
          2681,
          11,
          437,
          30,
          51746
        ]
      },
      {
        "avg_logprob": -0.2639200077500454,
        "compression_ratio": 1.7333333333333334,
        "end": 1417.26,
        "id": 454,
        "no_speech_prob": 0.00003373721119714901,
        "seek": 141146,
        "start": 1411.46,
        "temperature": 0,
        "text": " Let i equal 0, i is less than x dot length, i plus plus.",
        "tokens": [
          50364,
          961,
          741,
          2681,
          1958,
          11,
          741,
          307,
          1570,
          813,
          2031,
          5893,
          4641,
          11,
          741,
          1804,
          1804,
          13,
          50654
        ]
      },
      {
        "avg_logprob": -0.2639200077500454,
        "compression_ratio": 1.7333333333333334,
        "end": 1422.66,
        "id": 455,
        "no_speech_prob": 0.00003373721119714901,
        "seek": 141146,
        "start": 1417.26,
        "temperature": 0,
        "text": " And those are actually called x's, x's dot length.",
        "tokens": [
          50654,
          400,
          729,
          366,
          767,
          1219,
          2031,
          311,
          11,
          2031,
          311,
          5893,
          4641,
          13,
          50924
        ]
      },
      {
        "avg_logprob": -0.2639200077500454,
        "compression_ratio": 1.7333333333333334,
        "end": 1426.26,
        "id": 456,
        "no_speech_prob": 0.00003373721119714901,
        "seek": 141146,
        "start": 1422.66,
        "temperature": 0,
        "text": " And what I'm going to do is I'm going to say let pixel x equal map.",
        "tokens": [
          50924,
          400,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          584,
          718,
          19261,
          2031,
          2681,
          4471,
          13,
          51104
        ]
      },
      {
        "avg_logprob": -0.2639200077500454,
        "compression_ratio": 1.7333333333333334,
        "end": 1429.1000000000001,
        "id": 457,
        "no_speech_prob": 0.00003373721119714901,
        "seek": 141146,
        "start": 1426.26,
        "temperature": 0,
        "text": " I really should make just like, I'm probably going to do this a lot,",
        "tokens": [
          51104,
          286,
          534,
          820,
          652,
          445,
          411,
          11,
          286,
          478,
          1391,
          516,
          281,
          360,
          341,
          257,
          688,
          11,
          51246
        ]
      },
      {
        "avg_logprob": -0.2639200077500454,
        "compression_ratio": 1.7333333333333334,
        "end": 1432.78,
        "id": 458,
        "no_speech_prob": 0.00003373721119714901,
        "seek": 141146,
        "start": 1429.1000000000001,
        "temperature": 0,
        "text": " so I should probably make a function that just like normalize and un-normalize",
        "tokens": [
          51246,
          370,
          286,
          820,
          1391,
          652,
          257,
          2445,
          300,
          445,
          411,
          2710,
          1125,
          293,
          517,
          12,
          23157,
          1125,
          51430
        ]
      },
      {
        "avg_logprob": -0.2639200077500454,
        "compression_ratio": 1.7333333333333334,
        "end": 1435.02,
        "id": 459,
        "no_speech_prob": 0.00003373721119714901,
        "seek": 141146,
        "start": 1432.78,
        "temperature": 0,
        "text": " or de-normalize.",
        "tokens": [
          51430,
          420,
          368,
          12,
          23157,
          1125,
          13,
          51542
        ]
      },
      {
        "avg_logprob": -0.2639200077500454,
        "compression_ratio": 1.7333333333333334,
        "end": 1439.38,
        "id": 460,
        "no_speech_prob": 0.00003373721119714901,
        "seek": 141146,
        "start": 1435.02,
        "temperature": 0,
        "text": " Px equals map x's index i, which goes between 0 and 1,",
        "tokens": [
          51542,
          430,
          87,
          6915,
          4471,
          2031,
          311,
          8186,
          741,
          11,
          597,
          1709,
          1296,
          1958,
          293,
          502,
          11,
          51760
        ]
      },
      {
        "avg_logprob": -0.2639200077500454,
        "compression_ratio": 1.7333333333333334,
        "end": 1440.3,
        "id": 461,
        "no_speech_prob": 0.00003373721119714901,
        "seek": 141146,
        "start": 1439.38,
        "temperature": 0,
        "text": " back to 0 and width.",
        "tokens": [
          51760,
          646,
          281,
          1958,
          293,
          11402,
          13,
          51806
        ]
      },
      {
        "avg_logprob": -0.2259011854205215,
        "compression_ratio": 1.517094017094017,
        "end": 1442.06,
        "id": 462,
        "no_speech_prob": 9.13254780243733e-7,
        "seek": 144030,
        "start": 1440.3,
        "temperature": 0,
        "text": " So this is the reverse.",
        "tokens": [
          50364,
          407,
          341,
          307,
          264,
          9943,
          13,
          50452
        ]
      },
      {
        "avg_logprob": -0.2259011854205215,
        "compression_ratio": 1.517094017094017,
        "end": 1451.5,
        "id": 463,
        "no_speech_prob": 9.13254780243733e-7,
        "seek": 144030,
        "start": 1442.06,
        "temperature": 0,
        "text": " Py, which maps y, which goes between 0 and 1 to height, comma, 0.",
        "tokens": [
          50452,
          9953,
          11,
          597,
          11317,
          288,
          11,
          597,
          1709,
          1296,
          1958,
          293,
          502,
          281,
          6681,
          11,
          22117,
          11,
          1958,
          13,
          50924
        ]
      },
      {
        "avg_logprob": -0.2259011854205215,
        "compression_ratio": 1.517094017094017,
        "end": 1455.06,
        "id": 464,
        "no_speech_prob": 9.13254780243733e-7,
        "seek": 144030,
        "start": 1451.5,
        "temperature": 0,
        "text": " And then I want to say point px py.",
        "tokens": [
          50924,
          400,
          550,
          286,
          528,
          281,
          584,
          935,
          280,
          87,
          10664,
          13,
          51102
        ]
      },
      {
        "avg_logprob": -0.2259011854205215,
        "compression_ratio": 1.517094017094017,
        "end": 1459.5,
        "id": 465,
        "no_speech_prob": 9.13254780243733e-7,
        "seek": 144030,
        "start": 1455.06,
        "temperature": 0,
        "text": " So I haven't done any, I'm not even using TensorFlow.js yet.",
        "tokens": [
          51102,
          407,
          286,
          2378,
          380,
          1096,
          604,
          11,
          286,
          478,
          406,
          754,
          1228,
          37624,
          13,
          25530,
          1939,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.2259011854205215,
        "compression_ratio": 1.517094017094017,
        "end": 1462.8999999999999,
        "id": 466,
        "no_speech_prob": 9.13254780243733e-7,
        "seek": 144030,
        "start": 1459.5,
        "temperature": 0,
        "text": " I'm just kind of doing the stuff with p5 to draw things.",
        "tokens": [
          51324,
          286,
          478,
          445,
          733,
          295,
          884,
          264,
          1507,
          365,
          280,
          20,
          281,
          2642,
          721,
          13,
          51494
        ]
      },
      {
        "avg_logprob": -0.2259011854205215,
        "compression_ratio": 1.517094017094017,
        "end": 1465.6599999999999,
        "id": 467,
        "no_speech_prob": 9.13254780243733e-7,
        "seek": 144030,
        "start": 1462.8999999999999,
        "temperature": 0,
        "text": " So let's see if I'm getting the results that I want,",
        "tokens": [
          51494,
          407,
          718,
          311,
          536,
          498,
          286,
          478,
          1242,
          264,
          3542,
          300,
          286,
          528,
          11,
          51632
        ]
      },
      {
        "avg_logprob": -0.2259011854205215,
        "compression_ratio": 1.517094017094017,
        "end": 1468.1,
        "id": 468,
        "no_speech_prob": 9.13254780243733e-7,
        "seek": 144030,
        "start": 1465.6599999999999,
        "temperature": 0,
        "text": " which is whenever I click, I get the point there.",
        "tokens": [
          51632,
          597,
          307,
          5699,
          286,
          2052,
          11,
          286,
          483,
          264,
          935,
          456,
          13,
          51754
        ]
      },
      {
        "avg_logprob": -0.2259011854205215,
        "compression_ratio": 1.517094017094017,
        "end": 1469.04,
        "id": 469,
        "no_speech_prob": 9.13254780243733e-7,
        "seek": 144030,
        "start": 1468.1,
        "temperature": 0,
        "text": " Perfect.",
        "tokens": [
          51754,
          10246,
          13,
          51801
        ]
      },
      {
        "avg_logprob": -0.23931501706441244,
        "compression_ratio": 1.6214953271028036,
        "end": 1470.8,
        "id": 470,
        "no_speech_prob": 0.0007554024341516197,
        "seek": 146904,
        "start": 1469.04,
        "temperature": 0,
        "text": " And I kind of want to see them a bit more.",
        "tokens": [
          50364,
          400,
          286,
          733,
          295,
          528,
          281,
          536,
          552,
          257,
          857,
          544,
          13,
          50452
        ]
      },
      {
        "avg_logprob": -0.23931501706441244,
        "compression_ratio": 1.6214953271028036,
        "end": 1472.56,
        "id": 471,
        "no_speech_prob": 0.0007554024341516197,
        "seek": 146904,
        "start": 1470.8,
        "temperature": 0,
        "text": " Let's like really make it bigger.",
        "tokens": [
          50452,
          961,
          311,
          411,
          534,
          652,
          309,
          3801,
          13,
          50540
        ]
      },
      {
        "avg_logprob": -0.23931501706441244,
        "compression_ratio": 1.6214953271028036,
        "end": 1474.76,
        "id": 472,
        "no_speech_prob": 0.0007554024341516197,
        "seek": 146904,
        "start": 1472.56,
        "temperature": 0,
        "text": " Great, that's like too big.",
        "tokens": [
          50540,
          3769,
          11,
          300,
          311,
          411,
          886,
          955,
          13,
          50650
        ]
      },
      {
        "avg_logprob": -0.23931501706441244,
        "compression_ratio": 1.6214953271028036,
        "end": 1476.56,
        "id": 473,
        "no_speech_prob": 0.0007554024341516197,
        "seek": 146904,
        "start": 1474.76,
        "temperature": 0,
        "text": " OK, great.",
        "tokens": [
          50650,
          2264,
          11,
          869,
          13,
          50740
        ]
      },
      {
        "avg_logprob": -0.23931501706441244,
        "compression_ratio": 1.6214953271028036,
        "end": 1478.92,
        "id": 474,
        "no_speech_prob": 0.0007554024341516197,
        "seek": 146904,
        "start": 1476.56,
        "temperature": 0,
        "text": " So we can see those are the points I'm clicking on.",
        "tokens": [
          50740,
          407,
          321,
          393,
          536,
          729,
          366,
          264,
          2793,
          286,
          478,
          9697,
          322,
          13,
          50858
        ]
      },
      {
        "avg_logprob": -0.23931501706441244,
        "compression_ratio": 1.6214953271028036,
        "end": 1479.42,
        "id": 475,
        "no_speech_prob": 0.0007554024341516197,
        "seek": 146904,
        "start": 1478.92,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50858,
          2264,
          13,
          50883
        ]
      },
      {
        "avg_logprob": -0.23931501706441244,
        "compression_ratio": 1.6214953271028036,
        "end": 1490.96,
        "id": 476,
        "no_speech_prob": 0.0007554024341516197,
        "seek": 146904,
        "start": 1487.3999999999999,
        "temperature": 0,
        "text": " Pause, pause, edit, edit, pause, pause, edit, edit.",
        "tokens": [
          51282,
          31973,
          11,
          10465,
          11,
          8129,
          11,
          8129,
          11,
          10465,
          11,
          10465,
          11,
          8129,
          11,
          8129,
          13,
          51460
        ]
      },
      {
        "avg_logprob": -0.23931501706441244,
        "compression_ratio": 1.6214953271028036,
        "end": 1493.32,
        "id": 477,
        "no_speech_prob": 0.0007554024341516197,
        "seek": 146904,
        "start": 1490.96,
        "temperature": 0,
        "text": " I'm like drunk with power with the editing.",
        "tokens": [
          51460,
          286,
          478,
          411,
          11192,
          365,
          1347,
          365,
          264,
          10000,
          13,
          51578
        ]
      },
      {
        "avg_logprob": -0.23931501706441244,
        "compression_ratio": 1.6214953271028036,
        "end": 1494.28,
        "id": 478,
        "no_speech_prob": 0.0007554024341516197,
        "seek": 146904,
        "start": 1493.32,
        "temperature": 0,
        "text": " I just take a break.",
        "tokens": [
          51578,
          286,
          445,
          747,
          257,
          1821,
          13,
          51626
        ]
      },
      {
        "avg_logprob": -0.23931501706441244,
        "compression_ratio": 1.6214953271028036,
        "end": 1496.08,
        "id": 479,
        "no_speech_prob": 0.0007554024341516197,
        "seek": 146904,
        "start": 1494.28,
        "temperature": 0,
        "text": " It'll get edited later.",
        "tokens": [
          51626,
          467,
          603,
          483,
          23016,
          1780,
          13,
          51716
        ]
      },
      {
        "avg_logprob": -0.23931501706441244,
        "compression_ratio": 1.6214953271028036,
        "end": 1497.54,
        "id": 480,
        "no_speech_prob": 0.0007554024341516197,
        "seek": 146904,
        "start": 1496.08,
        "temperature": 0,
        "text": " I used to say that, and it didn't.",
        "tokens": [
          51716,
          286,
          1143,
          281,
          584,
          300,
          11,
          293,
          309,
          994,
          380,
          13,
          51789
        ]
      },
      {
        "avg_logprob": -0.328862132796322,
        "compression_ratio": 1.4294478527607362,
        "end": 1500.02,
        "id": 481,
        "no_speech_prob": 0.00037409443757496774,
        "seek": 149754,
        "start": 1497.54,
        "temperature": 0,
        "text": " It does.",
        "tokens": [
          50364,
          467,
          775,
          13,
          50488
        ]
      },
      {
        "avg_logprob": -0.328862132796322,
        "compression_ratio": 1.4294478527607362,
        "end": 1503.1399999999999,
        "id": 482,
        "no_speech_prob": 0.00037409443757496774,
        "seek": 149754,
        "start": 1500.02,
        "temperature": 0,
        "text": " I think it was probably better when I didn't stop in the middle.",
        "tokens": [
          50488,
          286,
          519,
          309,
          390,
          1391,
          1101,
          562,
          286,
          994,
          380,
          1590,
          294,
          264,
          2808,
          13,
          50644
        ]
      },
      {
        "avg_logprob": -0.328862132796322,
        "compression_ratio": 1.4294478527607362,
        "end": 1503.6399999999999,
        "id": 483,
        "no_speech_prob": 0.00037409443757496774,
        "seek": 149754,
        "start": 1503.1399999999999,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50644,
          1057,
          558,
          13,
          50669
        ]
      },
      {
        "avg_logprob": -0.328862132796322,
        "compression_ratio": 1.4294478527607362,
        "end": 1516.7,
        "id": 484,
        "no_speech_prob": 0.00037409443757496774,
        "seek": 149754,
        "start": 1515.7,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51272,
          1057,
          558,
          13,
          51322
        ]
      },
      {
        "avg_logprob": -0.328862132796322,
        "compression_ratio": 1.4294478527607362,
        "end": 1518.42,
        "id": 485,
        "no_speech_prob": 0.00037409443757496774,
        "seek": 149754,
        "start": 1516.7,
        "temperature": 0,
        "text": " So what's next?",
        "tokens": [
          51322,
          407,
          437,
          311,
          958,
          30,
          51408
        ]
      },
      {
        "avg_logprob": -0.328862132796322,
        "compression_ratio": 1.4294478527607362,
        "end": 1519.74,
        "id": 486,
        "no_speech_prob": 0.00037409443757496774,
        "seek": 149754,
        "start": 1518.42,
        "temperature": 0,
        "text": " I need a loss function.",
        "tokens": [
          51408,
          286,
          643,
          257,
          4470,
          2445,
          13,
          51474
        ]
      },
      {
        "avg_logprob": -0.328862132796322,
        "compression_ratio": 1.4294478527607362,
        "end": 1521.06,
        "id": 487,
        "no_speech_prob": 0.00037409443757496774,
        "seek": 149754,
        "start": 1519.74,
        "temperature": 0,
        "text": " I need an optimizer.",
        "tokens": [
          51474,
          286,
          643,
          364,
          5028,
          6545,
          13,
          51540
        ]
      },
      {
        "avg_logprob": -0.328862132796322,
        "compression_ratio": 1.4294478527607362,
        "end": 1523.54,
        "id": 488,
        "no_speech_prob": 0.00037409443757496774,
        "seek": 149754,
        "start": 1521.06,
        "temperature": 0,
        "text": " Ah, oh, I need these.",
        "tokens": [
          51540,
          2438,
          11,
          1954,
          11,
          286,
          643,
          613,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.328862132796322,
        "compression_ratio": 1.4294478527607362,
        "end": 1524.82,
        "id": 489,
        "no_speech_prob": 0.00037409443757496774,
        "seek": 149754,
        "start": 1523.54,
        "temperature": 0,
        "text": " Let's make these.",
        "tokens": [
          51664,
          961,
          311,
          652,
          613,
          13,
          51728
        ]
      },
      {
        "avg_logprob": -0.328862132796322,
        "compression_ratio": 1.4294478527607362,
        "end": 1526.32,
        "id": 490,
        "no_speech_prob": 0.00037409443757496774,
        "seek": 149754,
        "start": 1524.82,
        "temperature": 0,
        "text": " So because I'm looking for somewhere",
        "tokens": [
          51728,
          407,
          570,
          286,
          478,
          1237,
          337,
          4079,
          51803
        ]
      },
      {
        "avg_logprob": -0.25572756717079564,
        "compression_ratio": 1.6217391304347826,
        "end": 1529.6,
        "id": 491,
        "no_speech_prob": 0.00020988253527320921,
        "seek": 152632,
        "start": 1526.3999999999999,
        "temperature": 0,
        "text": " I need to get some TensorFlow.js stuff working.",
        "tokens": [
          50368,
          286,
          643,
          281,
          483,
          512,
          37624,
          13,
          25530,
          1507,
          1364,
          13,
          50528
        ]
      },
      {
        "avg_logprob": -0.25572756717079564,
        "compression_ratio": 1.6217391304347826,
        "end": 1533.48,
        "id": 492,
        "no_speech_prob": 0.00020988253527320921,
        "seek": 152632,
        "start": 1529.6,
        "temperature": 0,
        "text": " So what I need is I need to have m and b.",
        "tokens": [
          50528,
          407,
          437,
          286,
          643,
          307,
          286,
          643,
          281,
          362,
          275,
          293,
          272,
          13,
          50722
        ]
      },
      {
        "avg_logprob": -0.25572756717079564,
        "compression_ratio": 1.6217391304347826,
        "end": 1535.36,
        "id": 493,
        "no_speech_prob": 0.00020988253527320921,
        "seek": 152632,
        "start": 1533.48,
        "temperature": 0,
        "text": " So let's figure that out.",
        "tokens": [
          50722,
          407,
          718,
          311,
          2573,
          300,
          484,
          13,
          50816
        ]
      },
      {
        "avg_logprob": -0.25572756717079564,
        "compression_ratio": 1.6217391304347826,
        "end": 1541.3999999999999,
        "id": 494,
        "no_speech_prob": 0.00020988253527320921,
        "seek": 152632,
        "start": 1535.36,
        "temperature": 0,
        "text": " So I'm going to create an m and a b.",
        "tokens": [
          50816,
          407,
          286,
          478,
          516,
          281,
          1884,
          364,
          275,
          293,
          257,
          272,
          13,
          51118
        ]
      },
      {
        "avg_logprob": -0.25572756717079564,
        "compression_ratio": 1.6217391304347826,
        "end": 1545.6799999999998,
        "id": 495,
        "no_speech_prob": 0.00020988253527320921,
        "seek": 152632,
        "start": 1541.3999999999999,
        "temperature": 0,
        "text": " And I'm not going to initialize them up here.",
        "tokens": [
          51118,
          400,
          286,
          478,
          406,
          516,
          281,
          5883,
          1125,
          552,
          493,
          510,
          13,
          51332
        ]
      },
      {
        "avg_logprob": -0.25572756717079564,
        "compression_ratio": 1.6217391304347826,
        "end": 1548.28,
        "id": 496,
        "no_speech_prob": 0.00020988253527320921,
        "seek": 152632,
        "start": 1545.6799999999998,
        "temperature": 0,
        "text": " And I probably should be using const in various places here",
        "tokens": [
          51332,
          400,
          286,
          1391,
          820,
          312,
          1228,
          1817,
          294,
          3683,
          3190,
          510,
          51462
        ]
      },
      {
        "avg_logprob": -0.25572756717079564,
        "compression_ratio": 1.6217391304347826,
        "end": 1550.12,
        "id": 497,
        "no_speech_prob": 0.00020988253527320921,
        "seek": 152632,
        "start": 1548.28,
        "temperature": 0,
        "text": " just to protect myself from reassigning something",
        "tokens": [
          51462,
          445,
          281,
          2371,
          2059,
          490,
          19486,
          9676,
          746,
          51554
        ]
      },
      {
        "avg_logprob": -0.25572756717079564,
        "compression_ratio": 1.6217391304347826,
        "end": 1550.72,
        "id": 498,
        "no_speech_prob": 0.00020988253527320921,
        "seek": 152632,
        "start": 1550.12,
        "temperature": 0,
        "text": " by accident.",
        "tokens": [
          51554,
          538,
          6398,
          13,
          51584
        ]
      },
      {
        "avg_logprob": -0.25572756717079564,
        "compression_ratio": 1.6217391304347826,
        "end": 1553.12,
        "id": 499,
        "no_speech_prob": 0.00020988253527320921,
        "seek": 152632,
        "start": 1550.72,
        "temperature": 0,
        "text": " But I'm going to be loosey-goosey and just use let.",
        "tokens": [
          51584,
          583,
          286,
          478,
          516,
          281,
          312,
          9612,
          88,
          12,
          1571,
          541,
          88,
          293,
          445,
          764,
          718,
          13,
          51704
        ]
      },
      {
        "avg_logprob": -0.31667178950897634,
        "compression_ratio": 1.7285223367697595,
        "end": 1555.6399999999999,
        "id": 500,
        "no_speech_prob": 0.00002078514444292523,
        "seek": 155312,
        "start": 1554.12,
        "temperature": 0,
        "text": " You know, these could be const.",
        "tokens": [
          50414,
          509,
          458,
          11,
          613,
          727,
          312,
          1817,
          13,
          50490
        ]
      },
      {
        "avg_logprob": -0.31667178950897634,
        "compression_ratio": 1.7285223367697595,
        "end": 1557.76,
        "id": 501,
        "no_speech_prob": 0.00002078514444292523,
        "seek": 155312,
        "start": 1555.6399999999999,
        "temperature": 0,
        "text": " But anyway, I'm not going to get into the whole let",
        "tokens": [
          50490,
          583,
          4033,
          11,
          286,
          478,
          406,
          516,
          281,
          483,
          666,
          264,
          1379,
          718,
          50596
        ]
      },
      {
        "avg_logprob": -0.31667178950897634,
        "compression_ratio": 1.7285223367697595,
        "end": 1560.3999999999999,
        "id": 502,
        "no_speech_prob": 0.00002078514444292523,
        "seek": 155312,
        "start": 1557.76,
        "temperature": 0,
        "text": " versus const thing because it makes me crazy.",
        "tokens": [
          50596,
          5717,
          1817,
          551,
          570,
          309,
          1669,
          385,
          3219,
          13,
          50728
        ]
      },
      {
        "avg_logprob": -0.31667178950897634,
        "compression_ratio": 1.7285223367697595,
        "end": 1566.7199999999998,
        "id": 503,
        "no_speech_prob": 0.00002078514444292523,
        "seek": 155312,
        "start": 1560.3999999999999,
        "temperature": 0,
        "text": " I'm going to say up here m equals tf scalar random 1.",
        "tokens": [
          50728,
          286,
          478,
          516,
          281,
          584,
          493,
          510,
          275,
          6915,
          256,
          69,
          39684,
          4974,
          502,
          13,
          51044
        ]
      },
      {
        "avg_logprob": -0.31667178950897634,
        "compression_ratio": 1.7285223367697595,
        "end": 1569.1999999999998,
        "id": 504,
        "no_speech_prob": 0.00002078514444292523,
        "seek": 155312,
        "start": 1566.7199999999998,
        "temperature": 0,
        "text": " So I'm going to use the p5 random function",
        "tokens": [
          51044,
          407,
          286,
          478,
          516,
          281,
          764,
          264,
          280,
          20,
          4974,
          2445,
          51168
        ]
      },
      {
        "avg_logprob": -0.31667178950897634,
        "compression_ratio": 1.7285223367697595,
        "end": 1570.9199999999998,
        "id": 505,
        "no_speech_prob": 0.00002078514444292523,
        "seek": 155312,
        "start": 1569.1999999999998,
        "temperature": 0,
        "text": " to give me a random number between 0 and 1",
        "tokens": [
          51168,
          281,
          976,
          385,
          257,
          4974,
          1230,
          1296,
          1958,
          293,
          502,
          51254
        ]
      },
      {
        "avg_logprob": -0.31667178950897634,
        "compression_ratio": 1.7285223367697595,
        "end": 1572.4799999999998,
        "id": 506,
        "no_speech_prob": 0.00002078514444292523,
        "seek": 155312,
        "start": 1570.9199999999998,
        "temperature": 0,
        "text": " because I've got to start somewhere.",
        "tokens": [
          51254,
          570,
          286,
          600,
          658,
          281,
          722,
          4079,
          13,
          51332
        ]
      },
      {
        "avg_logprob": -0.31667178950897634,
        "compression_ratio": 1.7285223367697595,
        "end": 1574.1599999999999,
        "id": 507,
        "no_speech_prob": 0.00002078514444292523,
        "seek": 155312,
        "start": 1572.4799999999998,
        "temperature": 0,
        "text": " So this is kind of like initializing",
        "tokens": [
          51332,
          407,
          341,
          307,
          733,
          295,
          411,
          5883,
          3319,
          51416
        ]
      },
      {
        "avg_logprob": -0.31667178950897634,
        "compression_ratio": 1.7285223367697595,
        "end": 1575.4399999999998,
        "id": 508,
        "no_speech_prob": 0.00002078514444292523,
        "seek": 155312,
        "start": 1574.1599999999999,
        "temperature": 0,
        "text": " the weights of a neural network.",
        "tokens": [
          51416,
          264,
          17443,
          295,
          257,
          18161,
          3209,
          13,
          51480
        ]
      },
      {
        "avg_logprob": -0.31667178950897634,
        "compression_ratio": 1.7285223367697595,
        "end": 1576.56,
        "id": 509,
        "no_speech_prob": 0.00002078514444292523,
        "seek": 155312,
        "start": 1575.4399999999998,
        "temperature": 0,
        "text": " There is no neural network.",
        "tokens": [
          51480,
          821,
          307,
          572,
          18161,
          3209,
          13,
          51536
        ]
      },
      {
        "avg_logprob": -0.31667178950897634,
        "compression_ratio": 1.7285223367697595,
        "end": 1580.1599999999999,
        "id": 510,
        "no_speech_prob": 0.00002078514444292523,
        "seek": 155312,
        "start": 1576.56,
        "temperature": 0,
        "text": " I'm just kind of optimizing this function y equals mx plus b.",
        "tokens": [
          51536,
          286,
          478,
          445,
          733,
          295,
          40425,
          341,
          2445,
          288,
          6915,
          275,
          87,
          1804,
          272,
          13,
          51716
        ]
      },
      {
        "avg_logprob": -0.31667178950897634,
        "compression_ratio": 1.7285223367697595,
        "end": 1582.3999999999999,
        "id": 511,
        "no_speech_prob": 0.00002078514444292523,
        "seek": 155312,
        "start": 1580.1599999999999,
        "temperature": 0,
        "text": " But those are like weights, m and b.",
        "tokens": [
          51716,
          583,
          729,
          366,
          411,
          17443,
          11,
          275,
          293,
          272,
          13,
          51828
        ]
      },
      {
        "avg_logprob": -0.25035589035243205,
        "compression_ratio": 1.7316176470588236,
        "end": 1585.68,
        "id": 512,
        "no_speech_prob": 0.0000016280511090371874,
        "seek": 158240,
        "start": 1583.4,
        "temperature": 0,
        "text": " So I'm going to initialize them randomly and scalar",
        "tokens": [
          50414,
          407,
          286,
          478,
          516,
          281,
          5883,
          1125,
          552,
          16979,
          293,
          39684,
          50528
        ]
      },
      {
        "avg_logprob": -0.25035589035243205,
        "compression_ratio": 1.7316176470588236,
        "end": 1587.1200000000001,
        "id": 513,
        "no_speech_prob": 0.0000016280511090371874,
        "seek": 158240,
        "start": 1585.68,
        "temperature": 0,
        "text": " because it's a single number.",
        "tokens": [
          50528,
          570,
          309,
          311,
          257,
          2167,
          1230,
          13,
          50600
        ]
      },
      {
        "avg_logprob": -0.25035589035243205,
        "compression_ratio": 1.7316176470588236,
        "end": 1590.3200000000002,
        "id": 514,
        "no_speech_prob": 0.0000016280511090371874,
        "seek": 158240,
        "start": 1587.1200000000001,
        "temperature": 0,
        "text": " So go back to my TensorFlow.js intro videos, and you'll see.",
        "tokens": [
          50600,
          407,
          352,
          646,
          281,
          452,
          37624,
          13,
          25530,
          12897,
          2145,
          11,
          293,
          291,
          603,
          536,
          13,
          50760
        ]
      },
      {
        "avg_logprob": -0.25035589035243205,
        "compression_ratio": 1.7316176470588236,
        "end": 1592.48,
        "id": 515,
        "no_speech_prob": 0.0000016280511090371874,
        "seek": 158240,
        "start": 1590.3200000000002,
        "temperature": 0,
        "text": " Then b, I'm going to say the same thing.",
        "tokens": [
          50760,
          1396,
          272,
          11,
          286,
          478,
          516,
          281,
          584,
          264,
          912,
          551,
          13,
          50868
        ]
      },
      {
        "avg_logprob": -0.25035589035243205,
        "compression_ratio": 1.7316176470588236,
        "end": 1594.72,
        "id": 516,
        "no_speech_prob": 0.0000016280511090371874,
        "seek": 158240,
        "start": 1592.48,
        "temperature": 0,
        "text": " Ah, but.",
        "tokens": [
          50868,
          2438,
          11,
          457,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.25035589035243205,
        "compression_ratio": 1.7316176470588236,
        "end": 1597.2800000000002,
        "id": 517,
        "no_speech_prob": 0.0000016280511090371874,
        "seek": 158240,
        "start": 1594.72,
        "temperature": 0,
        "text": " These are the things that have to change, right?",
        "tokens": [
          50980,
          1981,
          366,
          264,
          721,
          300,
          362,
          281,
          1319,
          11,
          558,
          30,
          51108
        ]
      },
      {
        "avg_logprob": -0.25035589035243205,
        "compression_ratio": 1.7316176470588236,
        "end": 1598.92,
        "id": 518,
        "no_speech_prob": 0.0000016280511090371874,
        "seek": 158240,
        "start": 1597.2800000000002,
        "temperature": 0,
        "text": " The data never changes.",
        "tokens": [
          51108,
          440,
          1412,
          1128,
          2962,
          13,
          51190
        ]
      },
      {
        "avg_logprob": -0.25035589035243205,
        "compression_ratio": 1.7316176470588236,
        "end": 1600.6000000000001,
        "id": 519,
        "no_speech_prob": 0.0000016280511090371874,
        "seek": 158240,
        "start": 1598.92,
        "temperature": 0,
        "text": " It's sort of fixed.",
        "tokens": [
          51190,
          467,
          311,
          1333,
          295,
          6806,
          13,
          51274
        ]
      },
      {
        "avg_logprob": -0.25035589035243205,
        "compression_ratio": 1.7316176470588236,
        "end": 1602.68,
        "id": 520,
        "no_speech_prob": 0.0000016280511090371874,
        "seek": 158240,
        "start": 1600.6000000000001,
        "temperature": 0,
        "text": " m and b change over time.",
        "tokens": [
          51274,
          275,
          293,
          272,
          1319,
          670,
          565,
          13,
          51378
        ]
      },
      {
        "avg_logprob": -0.25035589035243205,
        "compression_ratio": 1.7316176470588236,
        "end": 1604.52,
        "id": 521,
        "no_speech_prob": 0.0000016280511090371874,
        "seek": 158240,
        "start": 1602.68,
        "temperature": 0,
        "text": " I need to tweak those, which means",
        "tokens": [
          51378,
          286,
          643,
          281,
          29879,
          729,
          11,
          597,
          1355,
          51470
        ]
      },
      {
        "avg_logprob": -0.25035589035243205,
        "compression_ratio": 1.7316176470588236,
        "end": 1606.0400000000002,
        "id": 522,
        "no_speech_prob": 0.0000016280511090371874,
        "seek": 158240,
        "start": 1604.52,
        "temperature": 0,
        "text": " they have to be variable.",
        "tokens": [
          51470,
          436,
          362,
          281,
          312,
          7006,
          13,
          51546
        ]
      },
      {
        "avg_logprob": -0.25035589035243205,
        "compression_ratio": 1.7316176470588236,
        "end": 1609.44,
        "id": 523,
        "no_speech_prob": 0.0000016280511090371874,
        "seek": 158240,
        "start": 1606.0400000000002,
        "temperature": 0,
        "text": " They have to be able to change, which means when I over here,",
        "tokens": [
          51546,
          814,
          362,
          281,
          312,
          1075,
          281,
          1319,
          11,
          597,
          1355,
          562,
          286,
          670,
          510,
          11,
          51716
        ]
      },
      {
        "avg_logprob": -0.25035589035243205,
        "compression_ratio": 1.7316176470588236,
        "end": 1612,
        "id": 524,
        "no_speech_prob": 0.0000016280511090371874,
        "seek": 158240,
        "start": 1609.44,
        "temperature": 0,
        "text": " I think what I write is tf variable.",
        "tokens": [
          51716,
          286,
          519,
          437,
          286,
          2464,
          307,
          256,
          69,
          7006,
          13,
          51844
        ]
      },
      {
        "avg_logprob": -0.24307937092251247,
        "compression_ratio": 1.643884892086331,
        "end": 1615.04,
        "id": 525,
        "no_speech_prob": 0.0000014823577885181294,
        "seek": 161200,
        "start": 1612.08,
        "temperature": 0,
        "text": " I wrap them in the tf variable.",
        "tokens": [
          50368,
          286,
          7019,
          552,
          294,
          264,
          256,
          69,
          7006,
          13,
          50516
        ]
      },
      {
        "avg_logprob": -0.24307937092251247,
        "compression_ratio": 1.643884892086331,
        "end": 1620,
        "id": 526,
        "no_speech_prob": 0.0000014823577885181294,
        "seek": 161200,
        "start": 1615.04,
        "temperature": 0,
        "text": " So now I have m and b as tf variable, right?",
        "tokens": [
          50516,
          407,
          586,
          286,
          362,
          275,
          293,
          272,
          382,
          256,
          69,
          7006,
          11,
          558,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.24307937092251247,
        "compression_ratio": 1.643884892086331,
        "end": 1620.76,
        "id": 527,
        "no_speech_prob": 0.0000014823577885181294,
        "seek": 161200,
        "start": 1620,
        "temperature": 0,
        "text": " Isn't it crazy?",
        "tokens": [
          50764,
          6998,
          380,
          309,
          3219,
          30,
          50802
        ]
      },
      {
        "avg_logprob": -0.24307937092251247,
        "compression_ratio": 1.643884892086331,
        "end": 1622.56,
        "id": 528,
        "no_speech_prob": 0.0000014823577885181294,
        "seek": 161200,
        "start": 1620.76,
        "temperature": 0,
        "text": " You see this kind of code, and you're like,",
        "tokens": [
          50802,
          509,
          536,
          341,
          733,
          295,
          3089,
          11,
          293,
          291,
          434,
          411,
          11,
          50892
        ]
      },
      {
        "avg_logprob": -0.24307937092251247,
        "compression_ratio": 1.643884892086331,
        "end": 1624.48,
        "id": 529,
        "no_speech_prob": 0.0000014823577885181294,
        "seek": 161200,
        "start": 1622.56,
        "temperature": 0,
        "text": " that looks like the craziest, scariest thing.",
        "tokens": [
          50892,
          300,
          1542,
          411,
          264,
          46339,
          11,
          47755,
          551,
          13,
          50988
        ]
      },
      {
        "avg_logprob": -0.24307937092251247,
        "compression_ratio": 1.643884892086331,
        "end": 1626.64,
        "id": 530,
        "no_speech_prob": 0.0000014823577885181294,
        "seek": 161200,
        "start": 1624.48,
        "temperature": 0,
        "text": " But you realize it's just like, make a number.",
        "tokens": [
          50988,
          583,
          291,
          4325,
          309,
          311,
          445,
          411,
          11,
          652,
          257,
          1230,
          13,
          51096
        ]
      },
      {
        "avg_logprob": -0.24307937092251247,
        "compression_ratio": 1.643884892086331,
        "end": 1629.44,
        "id": 531,
        "no_speech_prob": 0.0000014823577885181294,
        "seek": 161200,
        "start": 1626.64,
        "temperature": 0,
        "text": " And because we're in this kind of lower level,",
        "tokens": [
          51096,
          400,
          570,
          321,
          434,
          294,
          341,
          733,
          295,
          3126,
          1496,
          11,
          51236
        ]
      },
      {
        "avg_logprob": -0.24307937092251247,
        "compression_ratio": 1.643884892086331,
        "end": 1632.84,
        "id": 532,
        "no_speech_prob": 0.0000014823577885181294,
        "seek": 161200,
        "start": 1629.44,
        "temperature": 0,
        "text": " working on the GPU land, I've got to be very specific.",
        "tokens": [
          51236,
          1364,
          322,
          264,
          18407,
          2117,
          11,
          286,
          600,
          658,
          281,
          312,
          588,
          2685,
          13,
          51406
        ]
      },
      {
        "avg_logprob": -0.24307937092251247,
        "compression_ratio": 1.643884892086331,
        "end": 1635.52,
        "id": 533,
        "no_speech_prob": 0.0000014823577885181294,
        "seek": 161200,
        "start": 1632.84,
        "temperature": 0,
        "text": " This is a single number, and it's going to be variable.",
        "tokens": [
          51406,
          639,
          307,
          257,
          2167,
          1230,
          11,
          293,
          309,
          311,
          516,
          281,
          312,
          7006,
          13,
          51540
        ]
      },
      {
        "avg_logprob": -0.24307937092251247,
        "compression_ratio": 1.643884892086331,
        "end": 1638.28,
        "id": 534,
        "no_speech_prob": 0.0000014823577885181294,
        "seek": 161200,
        "start": 1635.52,
        "temperature": 0,
        "text": " But really, it's just a random number.",
        "tokens": [
          51540,
          583,
          534,
          11,
          309,
          311,
          445,
          257,
          4974,
          1230,
          13,
          51678
        ]
      },
      {
        "avg_logprob": -0.24307937092251247,
        "compression_ratio": 1.643884892086331,
        "end": 1641.44,
        "id": 535,
        "no_speech_prob": 0.0000014823577885181294,
        "seek": 161200,
        "start": 1638.28,
        "temperature": 0,
        "text": " OK, now what do we need to do?",
        "tokens": [
          51678,
          2264,
          11,
          586,
          437,
          360,
          321,
          643,
          281,
          360,
          30,
          51836
        ]
      },
      {
        "avg_logprob": -0.22480904342781785,
        "compression_ratio": 1.7136752136752136,
        "end": 1644.8400000000001,
        "id": 536,
        "no_speech_prob": 0.000005682433766196482,
        "seek": 164144,
        "start": 1642.2,
        "temperature": 0,
        "text": " I don't think I actually said this,",
        "tokens": [
          50402,
          286,
          500,
          380,
          519,
          286,
          767,
          848,
          341,
          11,
          50534
        ]
      },
      {
        "avg_logprob": -0.22480904342781785,
        "compression_ratio": 1.7136752136752136,
        "end": 1651.04,
        "id": 537,
        "no_speech_prob": 0.000005682433766196482,
        "seek": 164144,
        "start": 1644.8400000000001,
        "temperature": 0,
        "text": " but I need to write a function called predict maybe,",
        "tokens": [
          50534,
          457,
          286,
          643,
          281,
          2464,
          257,
          2445,
          1219,
          6069,
          1310,
          11,
          50844
        ]
      },
      {
        "avg_logprob": -0.22480904342781785,
        "compression_ratio": 1.7136752136752136,
        "end": 1656.2,
        "id": 538,
        "no_speech_prob": 0.000005682433766196482,
        "seek": 164144,
        "start": 1651.04,
        "temperature": 0,
        "text": " which takes in all of the x's, just the x's,",
        "tokens": [
          50844,
          597,
          2516,
          294,
          439,
          295,
          264,
          2031,
          311,
          11,
          445,
          264,
          2031,
          311,
          11,
          51102
        ]
      },
      {
        "avg_logprob": -0.22480904342781785,
        "compression_ratio": 1.7136752136752136,
        "end": 1659,
        "id": 539,
        "no_speech_prob": 0.000005682433766196482,
        "seek": 164144,
        "start": 1656.2,
        "temperature": 0,
        "text": " and gives me the y predictions based on where the line is,",
        "tokens": [
          51102,
          293,
          2709,
          385,
          264,
          288,
          21264,
          2361,
          322,
          689,
          264,
          1622,
          307,
          11,
          51242
        ]
      },
      {
        "avg_logprob": -0.22480904342781785,
        "compression_ratio": 1.7136752136752136,
        "end": 1659.48,
        "id": 540,
        "no_speech_prob": 0.000005682433766196482,
        "seek": 164144,
        "start": 1659,
        "temperature": 0,
        "text": " right?",
        "tokens": [
          51242,
          558,
          30,
          51266
        ]
      },
      {
        "avg_logprob": -0.22480904342781785,
        "compression_ratio": 1.7136752136752136,
        "end": 1662.0800000000002,
        "id": 541,
        "no_speech_prob": 0.000005682433766196482,
        "seek": 164144,
        "start": 1659.48,
        "temperature": 0,
        "text": " Because I need to compare the y predictions to the actual y",
        "tokens": [
          51266,
          1436,
          286,
          643,
          281,
          6794,
          264,
          288,
          21264,
          281,
          264,
          3539,
          288,
          51396
        ]
      },
      {
        "avg_logprob": -0.22480904342781785,
        "compression_ratio": 1.7136752136752136,
        "end": 1665.68,
        "id": 542,
        "no_speech_prob": 0.000005682433766196482,
        "seek": 164144,
        "start": 1662.0800000000002,
        "temperature": 0,
        "text": " values to get the mean squared error.",
        "tokens": [
          51396,
          4190,
          281,
          483,
          264,
          914,
          8889,
          6713,
          13,
          51576
        ]
      },
      {
        "avg_logprob": -0.22480904342781785,
        "compression_ratio": 1.7136752136752136,
        "end": 1667.1200000000001,
        "id": 543,
        "no_speech_prob": 0.000005682433766196482,
        "seek": 164144,
        "start": 1665.68,
        "temperature": 0,
        "text": " So let's write that function.",
        "tokens": [
          51576,
          407,
          718,
          311,
          2464,
          300,
          2445,
          13,
          51648
        ]
      },
      {
        "avg_logprob": -0.22480904342781785,
        "compression_ratio": 1.7136752136752136,
        "end": 1668.3200000000002,
        "id": 544,
        "no_speech_prob": 0.000005682433766196482,
        "seek": 164144,
        "start": 1667.1200000000001,
        "temperature": 0,
        "text": " So I'm just going to, I'm putting these",
        "tokens": [
          51648,
          407,
          286,
          478,
          445,
          516,
          281,
          11,
          286,
          478,
          3372,
          613,
          51708
        ]
      },
      {
        "avg_logprob": -0.22480904342781785,
        "compression_ratio": 1.7136752136752136,
        "end": 1669.7,
        "id": 545,
        "no_speech_prob": 0.000005682433766196482,
        "seek": 164144,
        "start": 1668.3200000000002,
        "temperature": 0,
        "text": " in like arbitrary places, but I'm",
        "tokens": [
          51708,
          294,
          411,
          23211,
          3190,
          11,
          457,
          286,
          478,
          51777
        ]
      },
      {
        "avg_logprob": -0.21135632745150862,
        "compression_ratio": 1.6965174129353233,
        "end": 1672.66,
        "id": 546,
        "no_speech_prob": 0.0003459910803940147,
        "seek": 166970,
        "start": 1669.7,
        "temperature": 0,
        "text": " going to write a function called predict.",
        "tokens": [
          50364,
          516,
          281,
          2464,
          257,
          2445,
          1219,
          6069,
          13,
          50512
        ]
      },
      {
        "avg_logprob": -0.21135632745150862,
        "compression_ratio": 1.6965174129353233,
        "end": 1680.74,
        "id": 547,
        "no_speech_prob": 0.0003459910803940147,
        "seek": 166970,
        "start": 1672.66,
        "temperature": 0,
        "text": " And there, what I need to do is I need to have some x's,",
        "tokens": [
          50512,
          400,
          456,
          11,
          437,
          286,
          643,
          281,
          360,
          307,
          286,
          643,
          281,
          362,
          512,
          2031,
          311,
          11,
          50916
        ]
      },
      {
        "avg_logprob": -0.21135632745150862,
        "compression_ratio": 1.6965174129353233,
        "end": 1684.7,
        "id": 548,
        "no_speech_prob": 0.0003459910803940147,
        "seek": 166970,
        "start": 1680.74,
        "temperature": 0,
        "text": " and I need to return some y's.",
        "tokens": [
          50916,
          293,
          286,
          643,
          281,
          2736,
          512,
          288,
          311,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21135632745150862,
        "compression_ratio": 1.6965174129353233,
        "end": 1686.18,
        "id": 549,
        "no_speech_prob": 0.0003459910803940147,
        "seek": 166970,
        "start": 1684.7,
        "temperature": 0,
        "text": " I think that's the idea, right?",
        "tokens": [
          51114,
          286,
          519,
          300,
          311,
          264,
          1558,
          11,
          558,
          30,
          51188
        ]
      },
      {
        "avg_logprob": -0.21135632745150862,
        "compression_ratio": 1.6965174129353233,
        "end": 1687.18,
        "id": 550,
        "no_speech_prob": 0.0003459910803940147,
        "seek": 166970,
        "start": 1686.18,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          51188,
          1079,
          13,
          51238
        ]
      },
      {
        "avg_logprob": -0.21135632745150862,
        "compression_ratio": 1.6965174129353233,
        "end": 1689.5,
        "id": 551,
        "no_speech_prob": 0.0003459910803940147,
        "seek": 166970,
        "start": 1687.18,
        "temperature": 0,
        "text": " So I don't want to just predict one value.",
        "tokens": [
          51238,
          407,
          286,
          500,
          380,
          528,
          281,
          445,
          6069,
          472,
          2158,
          13,
          51354
        ]
      },
      {
        "avg_logprob": -0.21135632745150862,
        "compression_ratio": 1.6965174129353233,
        "end": 1690.6200000000001,
        "id": 552,
        "no_speech_prob": 0.0003459910803940147,
        "seek": 166970,
        "start": 1689.5,
        "temperature": 0,
        "text": " I want to predict a bunch.",
        "tokens": [
          51354,
          286,
          528,
          281,
          6069,
          257,
          3840,
          13,
          51410
        ]
      },
      {
        "avg_logprob": -0.21135632745150862,
        "compression_ratio": 1.6965174129353233,
        "end": 1692.46,
        "id": 553,
        "no_speech_prob": 0.0003459910803940147,
        "seek": 166970,
        "start": 1690.6200000000001,
        "temperature": 0,
        "text": " So the x's, here's the thing.",
        "tokens": [
          51410,
          407,
          264,
          2031,
          311,
          11,
          510,
          311,
          264,
          551,
          13,
          51502
        ]
      },
      {
        "avg_logprob": -0.21135632745150862,
        "compression_ratio": 1.6965174129353233,
        "end": 1695.94,
        "id": 554,
        "no_speech_prob": 0.0003459910803940147,
        "seek": 166970,
        "start": 1692.46,
        "temperature": 0,
        "text": " So if I call this function, the x's,",
        "tokens": [
          51502,
          407,
          498,
          286,
          818,
          341,
          2445,
          11,
          264,
          2031,
          311,
          11,
          51676
        ]
      },
      {
        "avg_logprob": -0.21135632745150862,
        "compression_ratio": 1.6965174129353233,
        "end": 1698.06,
        "id": 555,
        "no_speech_prob": 0.0003459910803940147,
        "seek": 166970,
        "start": 1695.94,
        "temperature": 0,
        "text": " if they're just a plain array, I need",
        "tokens": [
          51676,
          498,
          436,
          434,
          445,
          257,
          11121,
          10225,
          11,
          286,
          643,
          51782
        ]
      },
      {
        "avg_logprob": -0.32763699690500897,
        "compression_ratio": 1.5205479452054795,
        "end": 1700.1,
        "id": 556,
        "no_speech_prob": 0.00015356227231677622,
        "seek": 169806,
        "start": 1698.1,
        "temperature": 0,
        "text": " to make it into a tensor.",
        "tokens": [
          50366,
          281,
          652,
          309,
          666,
          257,
          40863,
          13,
          50466
        ]
      },
      {
        "avg_logprob": -0.32763699690500897,
        "compression_ratio": 1.5205479452054795,
        "end": 1704.58,
        "id": 557,
        "no_speech_prob": 0.00015356227231677622,
        "seek": 169806,
        "start": 1700.1,
        "temperature": 0,
        "text": " So I'm going to call it const tf x's.",
        "tokens": [
          50466,
          407,
          286,
          478,
          516,
          281,
          818,
          309,
          1817,
          256,
          69,
          2031,
          311,
          13,
          50690
        ]
      },
      {
        "avg_logprob": -0.32763699690500897,
        "compression_ratio": 1.5205479452054795,
        "end": 1705.46,
        "id": 558,
        "no_speech_prob": 0.00015356227231677622,
        "seek": 169806,
        "start": 1704.58,
        "temperature": 0,
        "text": " That might be a bad.",
        "tokens": [
          50690,
          663,
          1062,
          312,
          257,
          1578,
          13,
          50734
        ]
      },
      {
        "avg_logprob": -0.32763699690500897,
        "compression_ratio": 1.5205479452054795,
        "end": 1707.58,
        "id": 559,
        "no_speech_prob": 0.00015356227231677622,
        "seek": 169806,
        "start": 1705.46,
        "temperature": 0,
        "text": " It's tensor.",
        "tokens": [
          50734,
          467,
          311,
          40863,
          13,
          50840
        ]
      },
      {
        "avg_logprob": -0.32763699690500897,
        "compression_ratio": 1.5205479452054795,
        "end": 1709.6599999999999,
        "id": 560,
        "no_speech_prob": 0.00015356227231677622,
        "seek": 169806,
        "start": 1707.58,
        "temperature": 0,
        "text": " And this is a 1D tensor.",
        "tokens": [
          50840,
          400,
          341,
          307,
          257,
          502,
          35,
          40863,
          13,
          50944
        ]
      },
      {
        "avg_logprob": -0.32763699690500897,
        "compression_ratio": 1.5205479452054795,
        "end": 1710.6599999999999,
        "id": 561,
        "no_speech_prob": 0.00015356227231677622,
        "seek": 169806,
        "start": 1709.6599999999999,
        "temperature": 0,
        "text": " Tensor 1D.",
        "tokens": [
          50944,
          34306,
          502,
          35,
          13,
          50994
        ]
      },
      {
        "avg_logprob": -0.32763699690500897,
        "compression_ratio": 1.5205479452054795,
        "end": 1716.58,
        "id": 562,
        "no_speech_prob": 0.00015356227231677622,
        "seek": 169806,
        "start": 1714.3,
        "temperature": 0,
        "text": " Oh, tf.",
        "tokens": [
          51176,
          876,
          11,
          256,
          69,
          13,
          51290
        ]
      },
      {
        "avg_logprob": -0.32763699690500897,
        "compression_ratio": 1.5205479452054795,
        "end": 1717.7,
        "id": 563,
        "no_speech_prob": 0.00015356227231677622,
        "seek": 169806,
        "start": 1716.58,
        "temperature": 0,
        "text": " Tensor 1D.",
        "tokens": [
          51290,
          34306,
          502,
          35,
          13,
          51346
        ]
      },
      {
        "avg_logprob": -0.32763699690500897,
        "compression_ratio": 1.5205479452054795,
        "end": 1719.1399999999999,
        "id": 564,
        "no_speech_prob": 0.00015356227231677622,
        "seek": 169806,
        "start": 1717.7,
        "temperature": 0,
        "text": " I think this will do it.",
        "tokens": [
          51346,
          286,
          519,
          341,
          486,
          360,
          309,
          13,
          51418
        ]
      },
      {
        "avg_logprob": -0.32763699690500897,
        "compression_ratio": 1.5205479452054795,
        "end": 1720.34,
        "id": 565,
        "no_speech_prob": 0.00015356227231677622,
        "seek": 169806,
        "start": 1719.1399999999999,
        "temperature": 0,
        "text": " x's, right?",
        "tokens": [
          51418,
          2031,
          311,
          11,
          558,
          30,
          51478
        ]
      },
      {
        "avg_logprob": -0.32763699690500897,
        "compression_ratio": 1.5205479452054795,
        "end": 1724.02,
        "id": 566,
        "no_speech_prob": 0.00015356227231677622,
        "seek": 169806,
        "start": 1720.34,
        "temperature": 0,
        "text": " I need to turn it into a tensor.",
        "tokens": [
          51478,
          286,
          643,
          281,
          1261,
          309,
          666,
          257,
          40863,
          13,
          51662
        ]
      },
      {
        "avg_logprob": -0.292807658513387,
        "compression_ratio": 1.4532374100719425,
        "end": 1731.06,
        "id": 567,
        "no_speech_prob": 0.000004495180746744154,
        "seek": 172402,
        "start": 1724.06,
        "temperature": 0,
        "text": " And then I need to have the formula for a line.",
        "tokens": [
          50366,
          400,
          550,
          286,
          643,
          281,
          362,
          264,
          8513,
          337,
          257,
          1622,
          13,
          50716
        ]
      },
      {
        "avg_logprob": -0.292807658513387,
        "compression_ratio": 1.4532374100719425,
        "end": 1737.1399999999999,
        "id": 568,
        "no_speech_prob": 0.000004495180746744154,
        "seek": 172402,
        "start": 1731.06,
        "temperature": 0,
        "text": " So I need to say, which is y equals mx plus b.",
        "tokens": [
          50716,
          407,
          286,
          643,
          281,
          584,
          11,
          597,
          307,
          288,
          6915,
          275,
          87,
          1804,
          272,
          13,
          51020
        ]
      },
      {
        "avg_logprob": -0.292807658513387,
        "compression_ratio": 1.4532374100719425,
        "end": 1742.22,
        "id": 569,
        "no_speech_prob": 0.000004495180746744154,
        "seek": 172402,
        "start": 1737.1399999999999,
        "temperature": 0,
        "text": " So what I would be doing is I would be saying tf x's",
        "tokens": [
          51020,
          407,
          437,
          286,
          576,
          312,
          884,
          307,
          286,
          576,
          312,
          1566,
          256,
          69,
          2031,
          311,
          51274
        ]
      },
      {
        "avg_logprob": -0.292807658513387,
        "compression_ratio": 1.4532374100719425,
        "end": 1745.02,
        "id": 570,
        "no_speech_prob": 0.000004495180746744154,
        "seek": 172402,
        "start": 1742.22,
        "temperature": 0,
        "text": " multiplied.",
        "tokens": [
          51274,
          17207,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.292807658513387,
        "compression_ratio": 1.4532374100719425,
        "end": 1746.7,
        "id": 571,
        "no_speech_prob": 0.000004495180746744154,
        "seek": 172402,
        "start": 1745.02,
        "temperature": 0,
        "text": " Is it mul or mult?",
        "tokens": [
          51414,
          1119,
          309,
          14077,
          420,
          2120,
          30,
          51498
        ]
      },
      {
        "avg_logprob": -0.292807658513387,
        "compression_ratio": 1.4532374100719425,
        "end": 1748.94,
        "id": 572,
        "no_speech_prob": 0.000004495180746744154,
        "seek": 172402,
        "start": 1746.7,
        "temperature": 0,
        "text": " Multiplied by m plus b.",
        "tokens": [
          51498,
          29238,
          564,
          1091,
          538,
          275,
          1804,
          272,
          13,
          51610
        ]
      },
      {
        "avg_logprob": -0.3675258570703967,
        "compression_ratio": 1.555045871559633,
        "end": 1750.42,
        "id": 573,
        "no_speech_prob": 0.000010616133295116015,
        "seek": 174894,
        "start": 1749.94,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          50414,
          1779,
          30,
          50438
        ]
      },
      {
        "avg_logprob": -0.3675258570703967,
        "compression_ratio": 1.555045871559633,
        "end": 1752.5800000000002,
        "id": 574,
        "no_speech_prob": 0.000010616133295116015,
        "seek": 174894,
        "start": 1750.42,
        "temperature": 0,
        "text": " This is the idea.",
        "tokens": [
          50438,
          639,
          307,
          264,
          1558,
          13,
          50546
        ]
      },
      {
        "avg_logprob": -0.3675258570703967,
        "compression_ratio": 1.555045871559633,
        "end": 1755.3400000000001,
        "id": 575,
        "no_speech_prob": 0.000010616133295116015,
        "seek": 174894,
        "start": 1752.5800000000002,
        "temperature": 0,
        "text": " If I'm getting just a plain array of numbers,",
        "tokens": [
          50546,
          759,
          286,
          478,
          1242,
          445,
          257,
          11121,
          10225,
          295,
          3547,
          11,
          50684
        ]
      },
      {
        "avg_logprob": -0.3675258570703967,
        "compression_ratio": 1.555045871559633,
        "end": 1757.54,
        "id": 576,
        "no_speech_prob": 0.000010616133295116015,
        "seek": 174894,
        "start": 1755.3400000000001,
        "temperature": 0,
        "text": " I turn them into a tensor.",
        "tokens": [
          50684,
          286,
          1261,
          552,
          666,
          257,
          40863,
          13,
          50794
        ]
      },
      {
        "avg_logprob": -0.3675258570703967,
        "compression_ratio": 1.555045871559633,
        "end": 1759.78,
        "id": 577,
        "no_speech_prob": 0.000010616133295116015,
        "seek": 174894,
        "start": 1757.54,
        "temperature": 0,
        "text": " Then I apply the formula for a line.",
        "tokens": [
          50794,
          1396,
          286,
          3079,
          264,
          8513,
          337,
          257,
          1622,
          13,
          50906
        ]
      },
      {
        "avg_logprob": -0.3675258570703967,
        "compression_ratio": 1.555045871559633,
        "end": 1761.98,
        "id": 578,
        "no_speech_prob": 0.000010616133295116015,
        "seek": 174894,
        "start": 1759.78,
        "temperature": 0,
        "text": " And these are the predictions, the y's.",
        "tokens": [
          50906,
          400,
          613,
          366,
          264,
          21264,
          11,
          264,
          288,
          311,
          13,
          51016
        ]
      },
      {
        "avg_logprob": -0.3675258570703967,
        "compression_ratio": 1.555045871559633,
        "end": 1764.18,
        "id": 579,
        "no_speech_prob": 0.000010616133295116015,
        "seek": 174894,
        "start": 1761.98,
        "temperature": 0,
        "text": " I guess I don't like my naming here.",
        "tokens": [
          51016,
          286,
          2041,
          286,
          500,
          380,
          411,
          452,
          25290,
          510,
          13,
          51126
        ]
      },
      {
        "avg_logprob": -0.3675258570703967,
        "compression_ratio": 1.555045871559633,
        "end": 1768.94,
        "id": 580,
        "no_speech_prob": 0.000010616133295116015,
        "seek": 174894,
        "start": 1767.78,
        "temperature": 0,
        "text": " I'm just going to call this x.",
        "tokens": [
          51306,
          286,
          478,
          445,
          516,
          281,
          818,
          341,
          2031,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.3675258570703967,
        "compression_ratio": 1.555045871559633,
        "end": 1770.22,
        "id": 581,
        "no_speech_prob": 0.000010616133295116015,
        "seek": 174894,
        "start": 1768.94,
        "temperature": 0,
        "text": " And maybe I'll call this x's.",
        "tokens": [
          51364,
          400,
          1310,
          286,
          603,
          818,
          341,
          2031,
          311,
          13,
          51428
        ]
      },
      {
        "avg_logprob": -0.3675258570703967,
        "compression_ratio": 1.555045871559633,
        "end": 1772.7,
        "id": 582,
        "no_speech_prob": 0.000010616133295116015,
        "seek": 174894,
        "start": 1770.22,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          51428,
          286,
          500,
          380,
          458,
          13,
          51552
        ]
      },
      {
        "avg_logprob": -0.3675258570703967,
        "compression_ratio": 1.555045871559633,
        "end": 1774.6200000000001,
        "id": 583,
        "no_speech_prob": 0.000010616133295116015,
        "seek": 174894,
        "start": 1772.7,
        "temperature": 0,
        "text": " I have to think about.",
        "tokens": [
          51552,
          286,
          362,
          281,
          519,
          466,
          13,
          51648
        ]
      },
      {
        "avg_logprob": -0.3675258570703967,
        "compression_ratio": 1.555045871559633,
        "end": 1775.98,
        "id": 584,
        "no_speech_prob": 0.000010616133295116015,
        "seek": 174894,
        "start": 1774.6200000000001,
        "temperature": 0,
        "text": " I'll come back to this later.",
        "tokens": [
          51648,
          286,
          603,
          808,
          646,
          281,
          341,
          1780,
          13,
          51716
        ]
      },
      {
        "avg_logprob": -0.274937375969843,
        "compression_ratio": 1.7230769230769232,
        "end": 1780.94,
        "id": 585,
        "no_speech_prob": 0.000002902311507568811,
        "seek": 177894,
        "start": 1779.94,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50414,
          2264,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.274937375969843,
        "compression_ratio": 1.7230769230769232,
        "end": 1781.8200000000002,
        "id": 586,
        "no_speech_prob": 0.000002902311507568811,
        "seek": 177894,
        "start": 1780.94,
        "temperature": 0,
        "text": " So I have that.",
        "tokens": [
          50464,
          407,
          286,
          362,
          300,
          13,
          50508
        ]
      },
      {
        "avg_logprob": -0.274937375969843,
        "compression_ratio": 1.7230769230769232,
        "end": 1790.94,
        "id": 587,
        "no_speech_prob": 0.000002902311507568811,
        "seek": 177894,
        "start": 1784.94,
        "temperature": 0,
        "text": " Now, let's go back and look at the things that I need.",
        "tokens": [
          50664,
          823,
          11,
          718,
          311,
          352,
          646,
          293,
          574,
          412,
          264,
          721,
          300,
          286,
          643,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.274937375969843,
        "compression_ratio": 1.7230769230769232,
        "end": 1792.6200000000001,
        "id": 588,
        "no_speech_prob": 0.000002902311507568811,
        "seek": 177894,
        "start": 1790.94,
        "temperature": 0,
        "text": " So I have this predict function.",
        "tokens": [
          50964,
          407,
          286,
          362,
          341,
          6069,
          2445,
          13,
          51048
        ]
      },
      {
        "avg_logprob": -0.274937375969843,
        "compression_ratio": 1.7230769230769232,
        "end": 1794.7,
        "id": 589,
        "no_speech_prob": 0.000002902311507568811,
        "seek": 177894,
        "start": 1792.6200000000001,
        "temperature": 0,
        "text": " I have a data set.",
        "tokens": [
          51048,
          286,
          362,
          257,
          1412,
          992,
          13,
          51152
        ]
      },
      {
        "avg_logprob": -0.274937375969843,
        "compression_ratio": 1.7230769230769232,
        "end": 1796.98,
        "id": 590,
        "no_speech_prob": 0.000002902311507568811,
        "seek": 177894,
        "start": 1794.7,
        "temperature": 0,
        "text": " I need a loss function.",
        "tokens": [
          51152,
          286,
          643,
          257,
          4470,
          2445,
          13,
          51266
        ]
      },
      {
        "avg_logprob": -0.274937375969843,
        "compression_ratio": 1.7230769230769232,
        "end": 1797.98,
        "id": 591,
        "no_speech_prob": 0.000002902311507568811,
        "seek": 177894,
        "start": 1796.98,
        "temperature": 0,
        "text": " I need a loss function.",
        "tokens": [
          51266,
          286,
          643,
          257,
          4470,
          2445,
          13,
          51316
        ]
      },
      {
        "avg_logprob": -0.274937375969843,
        "compression_ratio": 1.7230769230769232,
        "end": 1800.6200000000001,
        "id": 592,
        "no_speech_prob": 0.000002902311507568811,
        "seek": 177894,
        "start": 1797.98,
        "temperature": 0,
        "text": " And I need a, oh, before we do the loss function,",
        "tokens": [
          51316,
          400,
          286,
          643,
          257,
          11,
          1954,
          11,
          949,
          321,
          360,
          264,
          4470,
          2445,
          11,
          51448
        ]
      },
      {
        "avg_logprob": -0.274937375969843,
        "compression_ratio": 1.7230769230769232,
        "end": 1803.1000000000001,
        "id": 593,
        "no_speech_prob": 0.000002902311507568811,
        "seek": 177894,
        "start": 1800.6200000000001,
        "temperature": 0,
        "text": " let's create the optimizer and the learning rate.",
        "tokens": [
          51448,
          718,
          311,
          1884,
          264,
          5028,
          6545,
          293,
          264,
          2539,
          3314,
          13,
          51572
        ]
      },
      {
        "avg_logprob": -0.274937375969843,
        "compression_ratio": 1.7230769230769232,
        "end": 1805.06,
        "id": 594,
        "no_speech_prob": 0.000002902311507568811,
        "seek": 177894,
        "start": 1803.1000000000001,
        "temperature": 0,
        "text": " So this is what's wonderful about working",
        "tokens": [
          51572,
          407,
          341,
          307,
          437,
          311,
          3715,
          466,
          1364,
          51670
        ]
      },
      {
        "avg_logprob": -0.274937375969843,
        "compression_ratio": 1.7230769230769232,
        "end": 1807.3,
        "id": 595,
        "no_speech_prob": 0.000002902311507568811,
        "seek": 177894,
        "start": 1805.06,
        "temperature": 0,
        "text": " with TensorFlow.js.",
        "tokens": [
          51670,
          365,
          37624,
          13,
          25530,
          13,
          51782
        ]
      },
      {
        "avg_logprob": -0.20170555443599306,
        "compression_ratio": 1.6205357142857142,
        "end": 1811.94,
        "id": 596,
        "no_speech_prob": 0.000001414475946148741,
        "seek": 180730,
        "start": 1807.34,
        "temperature": 0,
        "text": " When I say make the optimizer, I just mean make a tf.optimizer.",
        "tokens": [
          50366,
          1133,
          286,
          584,
          652,
          264,
          5028,
          6545,
          11,
          286,
          445,
          914,
          652,
          257,
          256,
          69,
          13,
          5747,
          332,
          6545,
          13,
          50596
        ]
      },
      {
        "avg_logprob": -0.20170555443599306,
        "compression_ratio": 1.6205357142857142,
        "end": 1812.58,
        "id": 597,
        "no_speech_prob": 0.000001414475946148741,
        "seek": 180730,
        "start": 1811.94,
        "temperature": 0,
        "text": " It exists.",
        "tokens": [
          50596,
          467,
          8198,
          13,
          50628
        ]
      },
      {
        "avg_logprob": -0.20170555443599306,
        "compression_ratio": 1.6205357142857142,
        "end": 1814.34,
        "id": 598,
        "no_speech_prob": 0.000001414475946148741,
        "seek": 180730,
        "start": 1812.58,
        "temperature": 0,
        "text": " It'll do this math for us.",
        "tokens": [
          50628,
          467,
          603,
          360,
          341,
          5221,
          337,
          505,
          13,
          50716
        ]
      },
      {
        "avg_logprob": -0.20170555443599306,
        "compression_ratio": 1.6205357142857142,
        "end": 1816.3,
        "id": 599,
        "no_speech_prob": 0.000001414475946148741,
        "seek": 180730,
        "start": 1814.34,
        "temperature": 0,
        "text": " So let's go to the, this is not something",
        "tokens": [
          50716,
          407,
          718,
          311,
          352,
          281,
          264,
          11,
          341,
          307,
          406,
          746,
          50814
        ]
      },
      {
        "avg_logprob": -0.20170555443599306,
        "compression_ratio": 1.6205357142857142,
        "end": 1818.22,
        "id": 600,
        "no_speech_prob": 0.000001414475946148741,
        "seek": 180730,
        "start": 1816.3,
        "temperature": 0,
        "text": " that I covered in my other videos.",
        "tokens": [
          50814,
          300,
          286,
          5343,
          294,
          452,
          661,
          2145,
          13,
          50910
        ]
      },
      {
        "avg_logprob": -0.20170555443599306,
        "compression_ratio": 1.6205357142857142,
        "end": 1820.4199999999998,
        "id": 601,
        "no_speech_prob": 0.000001414475946148741,
        "seek": 180730,
        "start": 1818.22,
        "temperature": 0,
        "text": " So let's go look for optimizer.",
        "tokens": [
          50910,
          407,
          718,
          311,
          352,
          574,
          337,
          5028,
          6545,
          13,
          51020
        ]
      },
      {
        "avg_logprob": -0.20170555443599306,
        "compression_ratio": 1.6205357142857142,
        "end": 1822.62,
        "id": 602,
        "no_speech_prob": 0.000001414475946148741,
        "seek": 180730,
        "start": 1820.4199999999998,
        "temperature": 0,
        "text": " And I want an optimizer.",
        "tokens": [
          51020,
          400,
          286,
          528,
          364,
          5028,
          6545,
          13,
          51130
        ]
      },
      {
        "avg_logprob": -0.20170555443599306,
        "compression_ratio": 1.6205357142857142,
        "end": 1825.5,
        "id": 603,
        "no_speech_prob": 0.000001414475946148741,
        "seek": 180730,
        "start": 1822.62,
        "temperature": 0,
        "text": " Now, there's all these different kinds of optimizers.",
        "tokens": [
          51130,
          823,
          11,
          456,
          311,
          439,
          613,
          819,
          3685,
          295,
          5028,
          22525,
          13,
          51274
        ]
      },
      {
        "avg_logprob": -0.20170555443599306,
        "compression_ratio": 1.6205357142857142,
        "end": 1829.82,
        "id": 604,
        "no_speech_prob": 0.000001414475946148741,
        "seek": 180730,
        "start": 1825.5,
        "temperature": 0,
        "text": " SGD, stochastic gradient descent.",
        "tokens": [
          51274,
          34520,
          35,
          11,
          342,
          8997,
          2750,
          16235,
          23475,
          13,
          51490
        ]
      },
      {
        "avg_logprob": -0.20170555443599306,
        "compression_ratio": 1.6205357142857142,
        "end": 1835.26,
        "id": 605,
        "no_speech_prob": 0.000001414475946148741,
        "seek": 180730,
        "start": 1829.82,
        "temperature": 0,
        "text": " This means the idea of slowly adjusting",
        "tokens": [
          51490,
          639,
          1355,
          264,
          1558,
          295,
          5692,
          23559,
          51762
        ]
      },
      {
        "avg_logprob": -0.2472979065718924,
        "compression_ratio": 1.8314606741573034,
        "end": 1839.98,
        "id": 606,
        "no_speech_prob": 0.0010987265268340707,
        "seek": 183526,
        "start": 1835.26,
        "temperature": 0,
        "text": " m and b to minimize the loss function.",
        "tokens": [
          50364,
          275,
          293,
          272,
          281,
          17522,
          264,
          4470,
          2445,
          13,
          50600
        ]
      },
      {
        "avg_logprob": -0.2472979065718924,
        "compression_ratio": 1.8314606741573034,
        "end": 1844.3,
        "id": 607,
        "no_speech_prob": 0.0010987265268340707,
        "seek": 183526,
        "start": 1839.98,
        "temperature": 0,
        "text": " And I've covered this in more detail in the other videos.",
        "tokens": [
          50600,
          400,
          286,
          600,
          5343,
          341,
          294,
          544,
          2607,
          294,
          264,
          661,
          2145,
          13,
          50816
        ]
      },
      {
        "avg_logprob": -0.2472979065718924,
        "compression_ratio": 1.8314606741573034,
        "end": 1845.62,
        "id": 608,
        "no_speech_prob": 0.0010987265268340707,
        "seek": 183526,
        "start": 1844.3,
        "temperature": 0,
        "text": " So I'm going to click on that.",
        "tokens": [
          50816,
          407,
          286,
          478,
          516,
          281,
          2052,
          322,
          300,
          13,
          50882
        ]
      },
      {
        "avg_logprob": -0.2472979065718924,
        "compression_ratio": 1.8314606741573034,
        "end": 1846.46,
        "id": 609,
        "no_speech_prob": 0.0010987265268340707,
        "seek": 183526,
        "start": 1845.62,
        "temperature": 0,
        "text": " And I'm going to look here.",
        "tokens": [
          50882,
          400,
          286,
          478,
          516,
          281,
          574,
          510,
          13,
          50924
        ]
      },
      {
        "avg_logprob": -0.2472979065718924,
        "compression_ratio": 1.8314606741573034,
        "end": 1847.86,
        "id": 610,
        "no_speech_prob": 0.0010987265268340707,
        "seek": 183526,
        "start": 1846.46,
        "temperature": 0,
        "text": " And this is basically what I need to do.",
        "tokens": [
          50924,
          400,
          341,
          307,
          1936,
          437,
          286,
          643,
          281,
          360,
          13,
          50994
        ]
      },
      {
        "avg_logprob": -0.2472979065718924,
        "compression_ratio": 1.8314606741573034,
        "end": 1848.1,
        "id": 611,
        "no_speech_prob": 0.0010987265268340707,
        "seek": 183526,
        "start": 1847.86,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50994,
          1057,
          558,
          13,
          51006
        ]
      },
      {
        "avg_logprob": -0.2472979065718924,
        "compression_ratio": 1.8314606741573034,
        "end": 1849.26,
        "id": 612,
        "no_speech_prob": 0.0010987265268340707,
        "seek": 183526,
        "start": 1848.1,
        "temperature": 0,
        "text": " We got the code right here.",
        "tokens": [
          51006,
          492,
          658,
          264,
          3089,
          558,
          510,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2472979065718924,
        "compression_ratio": 1.8314606741573034,
        "end": 1851.1,
        "id": 613,
        "no_speech_prob": 0.0010987265268340707,
        "seek": 183526,
        "start": 1849.26,
        "temperature": 0,
        "text": " Look, there's even a, look at this.",
        "tokens": [
          51064,
          2053,
          11,
          456,
          311,
          754,
          257,
          11,
          574,
          412,
          341,
          13,
          51156
        ]
      },
      {
        "avg_logprob": -0.2472979065718924,
        "compression_ratio": 1.8314606741573034,
        "end": 1851.78,
        "id": 614,
        "no_speech_prob": 0.0010987265268340707,
        "seek": 183526,
        "start": 1851.1,
        "temperature": 0,
        "text": " Oh my goodness.",
        "tokens": [
          51156,
          876,
          452,
          8387,
          13,
          51190
        ]
      },
      {
        "avg_logprob": -0.2472979065718924,
        "compression_ratio": 1.8314606741573034,
        "end": 1854.3799999999999,
        "id": 615,
        "no_speech_prob": 0.0010987265268340707,
        "seek": 183526,
        "start": 1851.78,
        "temperature": 0,
        "text": " There's like some stuff here we can really use.",
        "tokens": [
          51190,
          821,
          311,
          411,
          512,
          1507,
          510,
          321,
          393,
          534,
          764,
          13,
          51320
        ]
      },
      {
        "avg_logprob": -0.2472979065718924,
        "compression_ratio": 1.8314606741573034,
        "end": 1855.74,
        "id": 616,
        "no_speech_prob": 0.0010987265268340707,
        "seek": 183526,
        "start": 1854.3799999999999,
        "temperature": 0,
        "text": " So I'm going to grab this.",
        "tokens": [
          51320,
          407,
          286,
          478,
          516,
          281,
          4444,
          341,
          13,
          51388
        ]
      },
      {
        "avg_logprob": -0.2472979065718924,
        "compression_ratio": 1.8314606741573034,
        "end": 1860.86,
        "id": 617,
        "no_speech_prob": 0.0010987265268340707,
        "seek": 183526,
        "start": 1859.02,
        "temperature": 0,
        "text": " And I'm going to put this up here.",
        "tokens": [
          51552,
          400,
          286,
          478,
          516,
          281,
          829,
          341,
          493,
          510,
          13,
          51644
        ]
      },
      {
        "avg_logprob": -0.2472979065718924,
        "compression_ratio": 1.8314606741573034,
        "end": 1861.94,
        "id": 618,
        "no_speech_prob": 0.0010987265268340707,
        "seek": 183526,
        "start": 1860.86,
        "temperature": 0,
        "text": " So I want a learning rate.",
        "tokens": [
          51644,
          407,
          286,
          528,
          257,
          2539,
          3314,
          13,
          51698
        ]
      },
      {
        "avg_logprob": -0.2472979065718924,
        "compression_ratio": 1.8314606741573034,
        "end": 1863.82,
        "id": 619,
        "no_speech_prob": 0.0010987265268340707,
        "seek": 183526,
        "start": 1861.94,
        "temperature": 0,
        "text": " And I'm going to have a much bigger learning rate",
        "tokens": [
          51698,
          400,
          286,
          478,
          516,
          281,
          362,
          257,
          709,
          3801,
          2539,
          3314,
          51792
        ]
      },
      {
        "avg_logprob": -0.2472979065718924,
        "compression_ratio": 1.8314606741573034,
        "end": 1864.46,
        "id": 620,
        "no_speech_prob": 0.0010987265268340707,
        "seek": 183526,
        "start": 1863.82,
        "temperature": 0,
        "text": " to start with.",
        "tokens": [
          51792,
          281,
          722,
          365,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.19985139781031117,
        "compression_ratio": 1.8285714285714285,
        "end": 1865.74,
        "id": 621,
        "no_speech_prob": 0.00000788925444794586,
        "seek": 186446,
        "start": 1864.46,
        "temperature": 0,
        "text": " And I want an optimizer.",
        "tokens": [
          50364,
          400,
          286,
          528,
          364,
          5028,
          6545,
          13,
          50428
        ]
      },
      {
        "avg_logprob": -0.19985139781031117,
        "compression_ratio": 1.8285714285714285,
        "end": 1867.76,
        "id": 622,
        "no_speech_prob": 0.00000788925444794586,
        "seek": 186446,
        "start": 1865.74,
        "temperature": 0,
        "text": " So now I have a learning rate and an optimizer.",
        "tokens": [
          50428,
          407,
          586,
          286,
          362,
          257,
          2539,
          3314,
          293,
          364,
          5028,
          6545,
          13,
          50529
        ]
      },
      {
        "avg_logprob": -0.19985139781031117,
        "compression_ratio": 1.8285714285714285,
        "end": 1871.22,
        "id": 623,
        "no_speech_prob": 0.00000788925444794586,
        "seek": 186446,
        "start": 1867.76,
        "temperature": 0,
        "text": " And the optimizer is doing stochastic gradient descent.",
        "tokens": [
          50529,
          400,
          264,
          5028,
          6545,
          307,
          884,
          342,
          8997,
          2750,
          16235,
          23475,
          13,
          50702
        ]
      },
      {
        "avg_logprob": -0.19985139781031117,
        "compression_ratio": 1.8285714285714285,
        "end": 1873.78,
        "id": 624,
        "no_speech_prob": 0.00000788925444794586,
        "seek": 186446,
        "start": 1871.22,
        "temperature": 0,
        "text": " So I have learning rate, optimizer.",
        "tokens": [
          50702,
          407,
          286,
          362,
          2539,
          3314,
          11,
          5028,
          6545,
          13,
          50830
        ]
      },
      {
        "avg_logprob": -0.19985139781031117,
        "compression_ratio": 1.8285714285714285,
        "end": 1876.9,
        "id": 625,
        "no_speech_prob": 0.00000788925444794586,
        "seek": 186446,
        "start": 1873.78,
        "temperature": 0,
        "text": " Now I need that loss function.",
        "tokens": [
          50830,
          823,
          286,
          643,
          300,
          4470,
          2445,
          13,
          50986
        ]
      },
      {
        "avg_logprob": -0.19985139781031117,
        "compression_ratio": 1.8285714285714285,
        "end": 1879.7,
        "id": 626,
        "no_speech_prob": 0.00000788925444794586,
        "seek": 186446,
        "start": 1876.9,
        "temperature": 0,
        "text": " I need the loss function.",
        "tokens": [
          50986,
          286,
          643,
          264,
          4470,
          2445,
          13,
          51126
        ]
      },
      {
        "avg_logprob": -0.19985139781031117,
        "compression_ratio": 1.8285714285714285,
        "end": 1884.88,
        "id": 627,
        "no_speech_prob": 0.00000788925444794586,
        "seek": 186446,
        "start": 1879.7,
        "temperature": 0,
        "text": " The loss function is something I'm going to write, loss.",
        "tokens": [
          51126,
          440,
          4470,
          2445,
          307,
          746,
          286,
          478,
          516,
          281,
          2464,
          11,
          4470,
          13,
          51385
        ]
      },
      {
        "avg_logprob": -0.19985139781031117,
        "compression_ratio": 1.8285714285714285,
        "end": 1886.8600000000001,
        "id": 628,
        "no_speech_prob": 0.00000788925444794586,
        "seek": 186446,
        "start": 1884.88,
        "temperature": 0,
        "text": " And actually, let's go back to here.",
        "tokens": [
          51385,
          400,
          767,
          11,
          718,
          311,
          352,
          646,
          281,
          510,
          13,
          51484
        ]
      },
      {
        "avg_logprob": -0.19985139781031117,
        "compression_ratio": 1.8285714285714285,
        "end": 1887.78,
        "id": 629,
        "no_speech_prob": 0.00000788925444794586,
        "seek": 186446,
        "start": 1886.8600000000001,
        "temperature": 0,
        "text": " So look at this.",
        "tokens": [
          51484,
          407,
          574,
          412,
          341,
          13,
          51530
        ]
      },
      {
        "avg_logprob": -0.19985139781031117,
        "compression_ratio": 1.8285714285714285,
        "end": 1890.9,
        "id": 630,
        "no_speech_prob": 0.00000788925444794586,
        "seek": 186446,
        "start": 1887.78,
        "temperature": 0,
        "text": " So this is the fancy ES6 way of writing a function.",
        "tokens": [
          51530,
          407,
          341,
          307,
          264,
          10247,
          12564,
          21,
          636,
          295,
          3579,
          257,
          2445,
          13,
          51686
        ]
      },
      {
        "avg_logprob": -0.2293731509231207,
        "compression_ratio": 1.8508771929824561,
        "end": 1895.5800000000002,
        "id": 631,
        "no_speech_prob": 0.0000010348529713155585,
        "seek": 189090,
        "start": 1890.9,
        "temperature": 0,
        "text": " But I'm going to write it in a less fancy way.",
        "tokens": [
          50364,
          583,
          286,
          478,
          516,
          281,
          2464,
          309,
          294,
          257,
          1570,
          10247,
          636,
          13,
          50598
        ]
      },
      {
        "avg_logprob": -0.2293731509231207,
        "compression_ratio": 1.8508771929824561,
        "end": 1898.46,
        "id": 632,
        "no_speech_prob": 0.0000010348529713155585,
        "seek": 189090,
        "start": 1895.5800000000002,
        "temperature": 0,
        "text": " And I'm going to do this.",
        "tokens": [
          50598,
          400,
          286,
          478,
          516,
          281,
          360,
          341,
          13,
          50742
        ]
      },
      {
        "avg_logprob": -0.2293731509231207,
        "compression_ratio": 1.8508771929824561,
        "end": 1900.46,
        "id": 633,
        "no_speech_prob": 0.0000010348529713155585,
        "seek": 189090,
        "start": 1898.46,
        "temperature": 0,
        "text": " So what I want is I need the loss function.",
        "tokens": [
          50742,
          407,
          437,
          286,
          528,
          307,
          286,
          643,
          264,
          4470,
          2445,
          13,
          50842
        ]
      },
      {
        "avg_logprob": -0.2293731509231207,
        "compression_ratio": 1.8508771929824561,
        "end": 1901.7800000000002,
        "id": 634,
        "no_speech_prob": 0.0000010348529713155585,
        "seek": 189090,
        "start": 1900.46,
        "temperature": 0,
        "text": " I have some predictions.",
        "tokens": [
          50842,
          286,
          362,
          512,
          21264,
          13,
          50908
        ]
      },
      {
        "avg_logprob": -0.2293731509231207,
        "compression_ratio": 1.8508771929824561,
        "end": 1903.6200000000001,
        "id": 635,
        "no_speech_prob": 0.0000010348529713155585,
        "seek": 189090,
        "start": 1901.7800000000002,
        "temperature": 0,
        "text": " And I have some labels.",
        "tokens": [
          50908,
          400,
          286,
          362,
          512,
          16949,
          13,
          51000
        ]
      },
      {
        "avg_logprob": -0.2293731509231207,
        "compression_ratio": 1.8508771929824561,
        "end": 1907.8200000000002,
        "id": 636,
        "no_speech_prob": 0.0000010348529713155585,
        "seek": 189090,
        "start": 1903.6200000000001,
        "temperature": 0,
        "text": " So these are, the predictions are the y values",
        "tokens": [
          51000,
          407,
          613,
          366,
          11,
          264,
          21264,
          366,
          264,
          288,
          4190,
          51210
        ]
      },
      {
        "avg_logprob": -0.2293731509231207,
        "compression_ratio": 1.8508771929824561,
        "end": 1910.22,
        "id": 637,
        "no_speech_prob": 0.0000010348529713155585,
        "seek": 189090,
        "start": 1907.8200000000002,
        "temperature": 0,
        "text": " I'm getting from the predict function.",
        "tokens": [
          51210,
          286,
          478,
          1242,
          490,
          264,
          6069,
          2445,
          13,
          51330
        ]
      },
      {
        "avg_logprob": -0.2293731509231207,
        "compression_ratio": 1.8508771929824561,
        "end": 1914.8600000000001,
        "id": 638,
        "no_speech_prob": 0.0000010348529713155585,
        "seek": 189090,
        "start": 1910.22,
        "temperature": 0,
        "text": " The labels are the actual y values that are part of this.",
        "tokens": [
          51330,
          440,
          16949,
          366,
          264,
          3539,
          288,
          4190,
          300,
          366,
          644,
          295,
          341,
          13,
          51562
        ]
      },
      {
        "avg_logprob": -0.2293731509231207,
        "compression_ratio": 1.8508771929824561,
        "end": 1917.14,
        "id": 639,
        "no_speech_prob": 0.0000010348529713155585,
        "seek": 189090,
        "start": 1914.8600000000001,
        "temperature": 0,
        "text": " And by the way, I'm going to have to do memory management.",
        "tokens": [
          51562,
          400,
          538,
          264,
          636,
          11,
          286,
          478,
          516,
          281,
          362,
          281,
          360,
          4675,
          4592,
          13,
          51676
        ]
      },
      {
        "avg_logprob": -0.2293731509231207,
        "compression_ratio": 1.8508771929824561,
        "end": 1917.7,
        "id": 640,
        "no_speech_prob": 0.0000010348529713155585,
        "seek": 189090,
        "start": 1917.14,
        "temperature": 0,
        "text": " Don't worry.",
        "tokens": [
          51676,
          1468,
          380,
          3292,
          13,
          51704
        ]
      },
      {
        "avg_logprob": -0.2293731509231207,
        "compression_ratio": 1.8508771929824561,
        "end": 1919.02,
        "id": 641,
        "no_speech_prob": 0.0000010348529713155585,
        "seek": 189090,
        "start": 1917.7,
        "temperature": 0,
        "text": " If you're screaming at me that I haven't",
        "tokens": [
          51704,
          759,
          291,
          434,
          12636,
          412,
          385,
          300,
          286,
          2378,
          380,
          51770
        ]
      },
      {
        "avg_logprob": -0.2519008802331012,
        "compression_ratio": 1.695187165775401,
        "end": 1921.26,
        "id": 642,
        "no_speech_prob": 0.000012606938980752602,
        "seek": 191902,
        "start": 1919.06,
        "temperature": 0,
        "text": " worked out memory management, I'm going to do that.",
        "tokens": [
          50366,
          2732,
          484,
          4675,
          4592,
          11,
          286,
          478,
          516,
          281,
          360,
          300,
          13,
          50476
        ]
      },
      {
        "avg_logprob": -0.2519008802331012,
        "compression_ratio": 1.695187165775401,
        "end": 1922.74,
        "id": 643,
        "no_speech_prob": 0.000012606938980752602,
        "seek": 191902,
        "start": 1921.26,
        "temperature": 0,
        "text": " I'm just going to do that later.",
        "tokens": [
          50476,
          286,
          478,
          445,
          516,
          281,
          360,
          300,
          1780,
          13,
          50550
        ]
      },
      {
        "avg_logprob": -0.2519008802331012,
        "compression_ratio": 1.695187165775401,
        "end": 1928.1,
        "id": 644,
        "no_speech_prob": 0.000012606938980752602,
        "seek": 191902,
        "start": 1922.74,
        "temperature": 0,
        "text": " So what I want to do is say return the predictions",
        "tokens": [
          50550,
          407,
          437,
          286,
          528,
          281,
          360,
          307,
          584,
          2736,
          264,
          21264,
          50818
        ]
      },
      {
        "avg_logprob": -0.2519008802331012,
        "compression_ratio": 1.695187165775401,
        "end": 1929.22,
        "id": 645,
        "no_speech_prob": 0.000012606938980752602,
        "seek": 191902,
        "start": 1928.1,
        "temperature": 0,
        "text": " minus the labels.",
        "tokens": [
          50818,
          3175,
          264,
          16949,
          13,
          50874
        ]
      },
      {
        "avg_logprob": -0.2519008802331012,
        "compression_ratio": 1.695187165775401,
        "end": 1930.62,
        "id": 646,
        "no_speech_prob": 0.000012606938980752602,
        "seek": 191902,
        "start": 1929.22,
        "temperature": 0,
        "text": " That makes sense, right?",
        "tokens": [
          50874,
          663,
          1669,
          2020,
          11,
          558,
          30,
          50944
        ]
      },
      {
        "avg_logprob": -0.2519008802331012,
        "compression_ratio": 1.695187165775401,
        "end": 1934.18,
        "id": 647,
        "no_speech_prob": 0.000012606938980752602,
        "seek": 191902,
        "start": 1930.62,
        "temperature": 0,
        "text": " Because I said here, when I said mean squared error,",
        "tokens": [
          50944,
          1436,
          286,
          848,
          510,
          11,
          562,
          286,
          848,
          914,
          8889,
          6713,
          11,
          51122
        ]
      },
      {
        "avg_logprob": -0.2519008802331012,
        "compression_ratio": 1.695187165775401,
        "end": 1936.5,
        "id": 648,
        "no_speech_prob": 0.000012606938980752602,
        "seek": 191902,
        "start": 1934.18,
        "temperature": 0,
        "text": " is the predictions, like the guess,",
        "tokens": [
          51122,
          307,
          264,
          21264,
          11,
          411,
          264,
          2041,
          11,
          51238
        ]
      },
      {
        "avg_logprob": -0.2519008802331012,
        "compression_ratio": 1.695187165775401,
        "end": 1939.1,
        "id": 649,
        "no_speech_prob": 0.000012606938980752602,
        "seek": 191902,
        "start": 1936.5,
        "temperature": 0,
        "text": " minus the labels, which is the actual y, squared.",
        "tokens": [
          51238,
          3175,
          264,
          16949,
          11,
          597,
          307,
          264,
          3539,
          288,
          11,
          8889,
          13,
          51368
        ]
      },
      {
        "avg_logprob": -0.42513403731785465,
        "compression_ratio": 1.641304347826087,
        "end": 1947.1399999999999,
        "id": 650,
        "no_speech_prob": 0.000008398071258852724,
        "seek": 193910,
        "start": 1939.82,
        "temperature": 0,
        "text": " And so predictions minus the labels squared.",
        "tokens": [
          50400,
          400,
          370,
          21264,
          3175,
          264,
          16949,
          8889,
          13,
          50766
        ]
      },
      {
        "avg_logprob": -0.42513403731785465,
        "compression_ratio": 1.641304347826087,
        "end": 1949.6999999999998,
        "id": 651,
        "no_speech_prob": 0.000008398071258852724,
        "seek": 193910,
        "start": 1947.1399999999999,
        "temperature": 0,
        "text": " And then take the mean of them.",
        "tokens": [
          50766,
          400,
          550,
          747,
          264,
          914,
          295,
          552,
          13,
          50894
        ]
      },
      {
        "avg_logprob": -0.42513403731785465,
        "compression_ratio": 1.641304347826087,
        "end": 1950.9399999999998,
        "id": 652,
        "no_speech_prob": 0.000008398071258852724,
        "seek": 193910,
        "start": 1949.6999999999998,
        "temperature": 0,
        "text": " Look at this.",
        "tokens": [
          50894,
          2053,
          412,
          341,
          13,
          50956
        ]
      },
      {
        "avg_logprob": -0.42513403731785465,
        "compression_ratio": 1.641304347826087,
        "end": 1953.54,
        "id": 653,
        "no_speech_prob": 0.000008398071258852724,
        "seek": 193910,
        "start": 1950.9399999999998,
        "temperature": 0,
        "text": " All of these mathematical operations",
        "tokens": [
          50956,
          1057,
          295,
          613,
          18894,
          7705,
          51086
        ]
      },
      {
        "avg_logprob": -0.42513403731785465,
        "compression_ratio": 1.641304347826087,
        "end": 1955.3,
        "id": 654,
        "no_speech_prob": 0.000008398071258852724,
        "seek": 193910,
        "start": 1953.54,
        "temperature": 0,
        "text": " are inside of TensorFlow.js.",
        "tokens": [
          51086,
          366,
          1854,
          295,
          37624,
          13,
          25530,
          13,
          51174
        ]
      },
      {
        "avg_logprob": -0.42513403731785465,
        "compression_ratio": 1.641304347826087,
        "end": 1957.1399999999999,
        "id": 655,
        "no_speech_prob": 0.000008398071258852724,
        "seek": 193910,
        "start": 1955.3,
        "temperature": 0,
        "text": " And you can chain them.",
        "tokens": [
          51174,
          400,
          291,
          393,
          5021,
          552,
          13,
          51266
        ]
      },
      {
        "avg_logprob": -0.42513403731785465,
        "compression_ratio": 1.641304347826087,
        "end": 1961.1399999999999,
        "id": 656,
        "no_speech_prob": 0.000008398071258852724,
        "seek": 193910,
        "start": 1957.1399999999999,
        "temperature": 0,
        "text": " So predictions is a tensor.",
        "tokens": [
          51266,
          407,
          21264,
          307,
          257,
          40863,
          13,
          51466
        ]
      },
      {
        "avg_logprob": -0.42513403731785465,
        "compression_ratio": 1.641304347826087,
        "end": 1962.6999999999998,
        "id": 657,
        "no_speech_prob": 0.000008398071258852724,
        "seek": 193910,
        "start": 1961.1399999999999,
        "temperature": 0,
        "text": " Labels is a tensor.",
        "tokens": [
          51466,
          10137,
          1625,
          307,
          257,
          40863,
          13,
          51544
        ]
      },
      {
        "avg_logprob": -0.42513403731785465,
        "compression_ratio": 1.641304347826087,
        "end": 1964.34,
        "id": 658,
        "no_speech_prob": 0.000008398071258852724,
        "seek": 193910,
        "start": 1962.6999999999998,
        "temperature": 0,
        "text": " All of these, remember, they're just",
        "tokens": [
          51544,
          1057,
          295,
          613,
          11,
          1604,
          11,
          436,
          434,
          445,
          51626
        ]
      },
      {
        "avg_logprob": -0.42513403731785465,
        "compression_ratio": 1.641304347826087,
        "end": 1966.54,
        "id": 659,
        "no_speech_prob": 0.000008398071258852724,
        "seek": 193910,
        "start": 1964.34,
        "temperature": 0,
        "text": " going to keep producing new tensors.",
        "tokens": [
          51626,
          516,
          281,
          1066,
          10501,
          777,
          10688,
          830,
          13,
          51736
        ]
      },
      {
        "avg_logprob": -0.3643966933428231,
        "compression_ratio": 1.8916083916083917,
        "end": 1968.86,
        "id": 660,
        "no_speech_prob": 0.001325005665421486,
        "seek": 196654,
        "start": 1966.58,
        "temperature": 0,
        "text": " And I'm going to have to tidy and clean all this stuff up",
        "tokens": [
          50366,
          400,
          286,
          478,
          516,
          281,
          362,
          281,
          34646,
          293,
          2541,
          439,
          341,
          1507,
          493,
          50480
        ]
      },
      {
        "avg_logprob": -0.3643966933428231,
        "compression_ratio": 1.8916083916083917,
        "end": 1969.78,
        "id": 661,
        "no_speech_prob": 0.001325005665421486,
        "seek": 196654,
        "start": 1968.86,
        "temperature": 0,
        "text": " for memory management.",
        "tokens": [
          50480,
          337,
          4675,
          4592,
          13,
          50526
        ]
      },
      {
        "avg_logprob": -0.3643966933428231,
        "compression_ratio": 1.8916083916083917,
        "end": 1971.42,
        "id": 662,
        "no_speech_prob": 0.001325005665421486,
        "seek": 196654,
        "start": 1969.78,
        "temperature": 0,
        "text": " But again, I'll worry about that later.",
        "tokens": [
          50526,
          583,
          797,
          11,
          286,
          603,
          3292,
          466,
          300,
          1780,
          13,
          50608
        ]
      },
      {
        "avg_logprob": -0.3643966933428231,
        "compression_ratio": 1.8916083916083917,
        "end": 1973.22,
        "id": 663,
        "no_speech_prob": 0.001325005665421486,
        "seek": 196654,
        "start": 1971.42,
        "temperature": 0,
        "text": " So now I have the loss function.",
        "tokens": [
          50608,
          407,
          586,
          286,
          362,
          264,
          4470,
          2445,
          13,
          50698
        ]
      },
      {
        "avg_logprob": -0.3643966933428231,
        "compression_ratio": 1.8916083916083917,
        "end": 1973.74,
        "id": 664,
        "no_speech_prob": 0.001325005665421486,
        "seek": 196654,
        "start": 1973.22,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50698,
          1057,
          558,
          13,
          50724
        ]
      },
      {
        "avg_logprob": -0.3643966933428231,
        "compression_ratio": 1.8916083916083917,
        "end": 1975.5,
        "id": 665,
        "no_speech_prob": 0.001325005665421486,
        "seek": 196654,
        "start": 1973.74,
        "temperature": 0,
        "text": " Well, what is it that I want to do?",
        "tokens": [
          50724,
          1042,
          11,
          437,
          307,
          309,
          300,
          286,
          528,
          281,
          360,
          30,
          50812
        ]
      },
      {
        "avg_logprob": -0.3643966933428231,
        "compression_ratio": 1.8916083916083917,
        "end": 1978.98,
        "id": 666,
        "no_speech_prob": 0.001325005665421486,
        "seek": 196654,
        "start": 1975.5,
        "temperature": 0,
        "text": " Every time, so let's say, I think I'm actually like,",
        "tokens": [
          50812,
          2048,
          565,
          11,
          370,
          718,
          311,
          584,
          11,
          286,
          519,
          286,
          478,
          767,
          411,
          11,
          50986
        ]
      },
      {
        "avg_logprob": -0.3643966933428231,
        "compression_ratio": 1.8916083916083917,
        "end": 1980.7,
        "id": 667,
        "no_speech_prob": 0.001325005665421486,
        "seek": 196654,
        "start": 1978.98,
        "temperature": 0,
        "text": " I have everything.",
        "tokens": [
          50986,
          286,
          362,
          1203,
          13,
          51072
        ]
      },
      {
        "avg_logprob": -0.3643966933428231,
        "compression_ratio": 1.8916083916083917,
        "end": 1982.82,
        "id": 668,
        "no_speech_prob": 0.001325005665421486,
        "seek": 196654,
        "start": 1980.7,
        "temperature": 0,
        "text": " I have the loss function.",
        "tokens": [
          51072,
          286,
          362,
          264,
          4470,
          2445,
          13,
          51178
        ]
      },
      {
        "avg_logprob": -0.3643966933428231,
        "compression_ratio": 1.8916083916083917,
        "end": 1984.06,
        "id": 669,
        "no_speech_prob": 0.001325005665421486,
        "seek": 196654,
        "start": 1982.82,
        "temperature": 0,
        "text": " I have the data.",
        "tokens": [
          51178,
          286,
          362,
          264,
          1412,
          13,
          51240
        ]
      },
      {
        "avg_logprob": -0.3643966933428231,
        "compression_ratio": 1.8916083916083917,
        "end": 1985.02,
        "id": 670,
        "no_speech_prob": 0.001325005665421486,
        "seek": 196654,
        "start": 1984.06,
        "temperature": 0,
        "text": " I have the optimizer.",
        "tokens": [
          51240,
          286,
          362,
          264,
          5028,
          6545,
          13,
          51288
        ]
      },
      {
        "avg_logprob": -0.3643966933428231,
        "compression_ratio": 1.8916083916083917,
        "end": 1986.1399999999999,
        "id": 671,
        "no_speech_prob": 0.001325005665421486,
        "seek": 196654,
        "start": 1985.02,
        "temperature": 0,
        "text": " I have a predict function.",
        "tokens": [
          51288,
          286,
          362,
          257,
          6069,
          2445,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.3643966933428231,
        "compression_ratio": 1.8916083916083917,
        "end": 1987.06,
        "id": 672,
        "no_speech_prob": 0.001325005665421486,
        "seek": 196654,
        "start": 1986.1399999999999,
        "temperature": 0,
        "text": " I have a learning rate.",
        "tokens": [
          51344,
          286,
          362,
          257,
          2539,
          3314,
          13,
          51390
        ]
      },
      {
        "avg_logprob": -0.3643966933428231,
        "compression_ratio": 1.8916083916083917,
        "end": 1987.74,
        "id": 673,
        "no_speech_prob": 0.001325005665421486,
        "seek": 196654,
        "start": 1987.06,
        "temperature": 0,
        "text": " I can minimize.",
        "tokens": [
          51390,
          286,
          393,
          17522,
          13,
          51424
        ]
      },
      {
        "avg_logprob": -0.3643966933428231,
        "compression_ratio": 1.8916083916083917,
        "end": 1989.62,
        "id": 674,
        "no_speech_prob": 0.001325005665421486,
        "seek": 196654,
        "start": 1987.74,
        "temperature": 0,
        "text": " Well, oh, this I haven't done.",
        "tokens": [
          51424,
          1042,
          11,
          1954,
          11,
          341,
          286,
          2378,
          380,
          1096,
          13,
          51518
        ]
      },
      {
        "avg_logprob": -0.3643966933428231,
        "compression_ratio": 1.8916083916083917,
        "end": 1992.3,
        "id": 675,
        "no_speech_prob": 0.001325005665421486,
        "seek": 196654,
        "start": 1989.62,
        "temperature": 0,
        "text": " So the training, the actual training,",
        "tokens": [
          51518,
          407,
          264,
          3097,
          11,
          264,
          3539,
          3097,
          11,
          51652
        ]
      },
      {
        "avg_logprob": -0.3643966933428231,
        "compression_ratio": 1.8916083916083917,
        "end": 1993.98,
        "id": 676,
        "no_speech_prob": 0.001325005665421486,
        "seek": 196654,
        "start": 1992.3,
        "temperature": 0,
        "text": " what does it mean to train it?",
        "tokens": [
          51652,
          437,
          775,
          309,
          914,
          281,
          3847,
          309,
          30,
          51736
        ]
      },
      {
        "avg_logprob": -0.3643966933428231,
        "compression_ratio": 1.8916083916083917,
        "end": 1995.74,
        "id": 677,
        "no_speech_prob": 0.001325005665421486,
        "seek": 196654,
        "start": 1993.98,
        "temperature": 0,
        "text": " To train it, I'm going to have to do",
        "tokens": [
          51736,
          1407,
          3847,
          309,
          11,
          286,
          478,
          516,
          281,
          362,
          281,
          360,
          51824
        ]
      },
      {
        "avg_logprob": -0.2808891346580104,
        "compression_ratio": 1.7275862068965517,
        "end": 1999.1,
        "id": 678,
        "no_speech_prob": 0.00002977303483930882,
        "seek": 199574,
        "start": 1996.26,
        "temperature": 0,
        "text": " To train it means minimize the loss function",
        "tokens": [
          50390,
          1407,
          3847,
          309,
          1355,
          17522,
          264,
          4470,
          2445,
          50532
        ]
      },
      {
        "avg_logprob": -0.2808891346580104,
        "compression_ratio": 1.7275862068965517,
        "end": 2003.14,
        "id": 679,
        "no_speech_prob": 0.00002977303483930882,
        "seek": 199574,
        "start": 1999.1,
        "temperature": 0,
        "text": " with the optimizer and adjusting m and b based on that.",
        "tokens": [
          50532,
          365,
          264,
          5028,
          6545,
          293,
          23559,
          275,
          293,
          272,
          2361,
          322,
          300,
          13,
          50734
        ]
      },
      {
        "avg_logprob": -0.2808891346580104,
        "compression_ratio": 1.7275862068965517,
        "end": 2004.42,
        "id": 680,
        "no_speech_prob": 0.00002977303483930882,
        "seek": 199574,
        "start": 2003.14,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50734,
          1057,
          558,
          13,
          50798
        ]
      },
      {
        "avg_logprob": -0.2808891346580104,
        "compression_ratio": 1.7275862068965517,
        "end": 2005.9,
        "id": 681,
        "no_speech_prob": 0.00002977303483930882,
        "seek": 199574,
        "start": 2004.42,
        "temperature": 0,
        "text": " So let's see if we can make that.",
        "tokens": [
          50798,
          407,
          718,
          311,
          536,
          498,
          321,
          393,
          652,
          300,
          13,
          50872
        ]
      },
      {
        "avg_logprob": -0.2808891346580104,
        "compression_ratio": 1.7275862068965517,
        "end": 2008.34,
        "id": 682,
        "no_speech_prob": 0.00002977303483930882,
        "seek": 199574,
        "start": 2005.9,
        "temperature": 0,
        "text": " I have a feeling that was in that page that I went to.",
        "tokens": [
          50872,
          286,
          362,
          257,
          2633,
          300,
          390,
          294,
          300,
          3028,
          300,
          286,
          1437,
          281,
          13,
          50994
        ]
      },
      {
        "avg_logprob": -0.2808891346580104,
        "compression_ratio": 1.7275862068965517,
        "end": 2010.58,
        "id": 683,
        "no_speech_prob": 0.00002977303483930882,
        "seek": 199574,
        "start": 2008.34,
        "temperature": 0,
        "text": " So maybe I could just copy it from there.",
        "tokens": [
          50994,
          407,
          1310,
          286,
          727,
          445,
          5055,
          309,
          490,
          456,
          13,
          51106
        ]
      },
      {
        "avg_logprob": -0.2808891346580104,
        "compression_ratio": 1.7275862068965517,
        "end": 2012.6200000000001,
        "id": 684,
        "no_speech_prob": 0.00002977303483930882,
        "seek": 199574,
        "start": 2010.58,
        "temperature": 0,
        "text": " This is like very, so it totally is.",
        "tokens": [
          51106,
          639,
          307,
          411,
          588,
          11,
          370,
          309,
          3879,
          307,
          13,
          51208
        ]
      },
      {
        "avg_logprob": -0.2808891346580104,
        "compression_ratio": 1.7275862068965517,
        "end": 2013.18,
        "id": 685,
        "no_speech_prob": 0.00002977303483930882,
        "seek": 199574,
        "start": 2012.6200000000001,
        "temperature": 0,
        "text": " That's fine.",
        "tokens": [
          51208,
          663,
          311,
          2489,
          13,
          51236
        ]
      },
      {
        "avg_logprob": -0.2808891346580104,
        "compression_ratio": 1.7275862068965517,
        "end": 2015.3,
        "id": 686,
        "no_speech_prob": 0.00002977303483930882,
        "seek": 199574,
        "start": 2013.18,
        "temperature": 0,
        "text": " I'm going to happily cheat here.",
        "tokens": [
          51236,
          286,
          478,
          516,
          281,
          19909,
          17470,
          510,
          13,
          51342
        ]
      },
      {
        "avg_logprob": -0.2808891346580104,
        "compression_ratio": 1.7275862068965517,
        "end": 2016.34,
        "id": 687,
        "no_speech_prob": 0.00002977303483930882,
        "seek": 199574,
        "start": 2015.3,
        "temperature": 0,
        "text": " It was in that example.",
        "tokens": [
          51342,
          467,
          390,
          294,
          300,
          1365,
          13,
          51394
        ]
      },
      {
        "avg_logprob": -0.2808891346580104,
        "compression_ratio": 1.7275862068965517,
        "end": 2017.18,
        "id": 688,
        "no_speech_prob": 0.00002977303483930882,
        "seek": 199574,
        "start": 2016.34,
        "temperature": 0,
        "text": " Thank you very much.",
        "tokens": [
          51394,
          1044,
          291,
          588,
          709,
          13,
          51436
        ]
      },
      {
        "avg_logprob": -0.2808891346580104,
        "compression_ratio": 1.7275862068965517,
        "end": 2021.54,
        "id": 689,
        "no_speech_prob": 0.00002977303483930882,
        "seek": 199574,
        "start": 2017.18,
        "temperature": 0,
        "text": " Thank you, TensorFlow.js documentation.",
        "tokens": [
          51436,
          1044,
          291,
          11,
          37624,
          13,
          25530,
          14333,
          13,
          51654
        ]
      },
      {
        "avg_logprob": -0.2808891346580104,
        "compression_ratio": 1.7275862068965517,
        "end": 2023.38,
        "id": 690,
        "no_speech_prob": 0.00002977303483930882,
        "seek": 199574,
        "start": 2021.54,
        "temperature": 0,
        "text": " And so I'm going to just put this in draw.",
        "tokens": [
          51654,
          400,
          370,
          286,
          478,
          516,
          281,
          445,
          829,
          341,
          294,
          2642,
          13,
          51746
        ]
      },
      {
        "avg_logprob": -0.2808891346580104,
        "compression_ratio": 1.7275862068965517,
        "end": 2025.38,
        "id": 691,
        "no_speech_prob": 0.00002977303483930882,
        "seek": 199574,
        "start": 2023.38,
        "temperature": 0,
        "text": " Every time through draw, I'm going to minimize.",
        "tokens": [
          51746,
          2048,
          565,
          807,
          2642,
          11,
          286,
          478,
          516,
          281,
          17522,
          13,
          51846
        ]
      },
      {
        "avg_logprob": -0.22027977875300817,
        "compression_ratio": 1.6144067796610169,
        "end": 2026.1000000000001,
        "id": 692,
        "no_speech_prob": 0.000005682426944986219,
        "seek": 202538,
        "start": 2025.38,
        "temperature": 0,
        "text": " So let's look at this.",
        "tokens": [
          50364,
          407,
          718,
          311,
          574,
          412,
          341,
          13,
          50400
        ]
      },
      {
        "avg_logprob": -0.22027977875300817,
        "compression_ratio": 1.6144067796610169,
        "end": 2026.8200000000002,
        "id": 693,
        "no_speech_prob": 0.000005682426944986219,
        "seek": 202538,
        "start": 2026.1000000000001,
        "temperature": 0,
        "text": " Oh, look at this.",
        "tokens": [
          50400,
          876,
          11,
          574,
          412,
          341,
          13,
          50436
        ]
      },
      {
        "avg_logprob": -0.22027977875300817,
        "compression_ratio": 1.6144067796610169,
        "end": 2028.38,
        "id": 694,
        "no_speech_prob": 0.000005682426944986219,
        "seek": 202538,
        "start": 2026.8200000000002,
        "temperature": 0,
        "text": " OK, so this is a little different.",
        "tokens": [
          50436,
          2264,
          11,
          370,
          341,
          307,
          257,
          707,
          819,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.22027977875300817,
        "compression_ratio": 1.6144067796610169,
        "end": 2032.5800000000002,
        "id": 695,
        "no_speech_prob": 0.000005682426944986219,
        "seek": 202538,
        "start": 2028.38,
        "temperature": 0,
        "text": " So first of all, this is using nice, fancy ES6 arrow",
        "tokens": [
          50514,
          407,
          700,
          295,
          439,
          11,
          341,
          307,
          1228,
          1481,
          11,
          10247,
          12564,
          21,
          11610,
          50724
        ]
      },
      {
        "avg_logprob": -0.22027977875300817,
        "compression_ratio": 1.6144067796610169,
        "end": 2034.6200000000001,
        "id": 696,
        "no_speech_prob": 0.000005682426944986219,
        "seek": 202538,
        "start": 2032.5800000000002,
        "temperature": 0,
        "text": " notation, which I'm somewhat happy about.",
        "tokens": [
          50724,
          24657,
          11,
          597,
          286,
          478,
          8344,
          2055,
          466,
          13,
          50826
        ]
      },
      {
        "avg_logprob": -0.22027977875300817,
        "compression_ratio": 1.6144067796610169,
        "end": 2038.5,
        "id": 697,
        "no_speech_prob": 0.000005682426944986219,
        "seek": 202538,
        "start": 2034.6200000000001,
        "temperature": 0,
        "text": " But let me just write a function here called train.",
        "tokens": [
          50826,
          583,
          718,
          385,
          445,
          2464,
          257,
          2445,
          510,
          1219,
          3847,
          13,
          51020
        ]
      },
      {
        "avg_logprob": -0.22027977875300817,
        "compression_ratio": 1.6144067796610169,
        "end": 2040.7,
        "id": 698,
        "no_speech_prob": 0.000005682426944986219,
        "seek": 202538,
        "start": 2038.5,
        "temperature": 0,
        "text": " And the idea of the train function",
        "tokens": [
          51020,
          400,
          264,
          1558,
          295,
          264,
          3847,
          2445,
          51130
        ]
      },
      {
        "avg_logprob": -0.22027977875300817,
        "compression_ratio": 1.6144067796610169,
        "end": 2051.06,
        "id": 699,
        "no_speech_prob": 0.000005682426944986219,
        "seek": 202538,
        "start": 2040.7,
        "temperature": 0,
        "text": " is to execute the loss with the predictions and the actual y's.",
        "tokens": [
          51130,
          307,
          281,
          14483,
          264,
          4470,
          365,
          264,
          21264,
          293,
          264,
          3539,
          288,
          311,
          13,
          51648
        ]
      },
      {
        "avg_logprob": -0.22027977875300817,
        "compression_ratio": 1.6144067796610169,
        "end": 2055.26,
        "id": 700,
        "no_speech_prob": 0.000005682426944986219,
        "seek": 202538,
        "start": 2051.06,
        "temperature": 0,
        "text": " OK, so here, what I'm really doing is minimizing the train.",
        "tokens": [
          51648,
          2264,
          11,
          370,
          510,
          11,
          437,
          286,
          478,
          534,
          884,
          307,
          46608,
          264,
          3847,
          13,
          51858
        ]
      },
      {
        "avg_logprob": -0.2425978840261266,
        "compression_ratio": 1.7608695652173914,
        "end": 2057.46,
        "id": 701,
        "no_speech_prob": 0.000007646534868399613,
        "seek": 205526,
        "start": 2056.26,
        "temperature": 0,
        "text": " That's weird.",
        "tokens": [
          50414,
          663,
          311,
          3657,
          13,
          50474
        ]
      },
      {
        "avg_logprob": -0.2425978840261266,
        "compression_ratio": 1.7608695652173914,
        "end": 2059.6600000000003,
        "id": 702,
        "no_speech_prob": 0.000007646534868399613,
        "seek": 205526,
        "start": 2057.46,
        "temperature": 0,
        "text": " This isn't really, no, training would be doing this.",
        "tokens": [
          50474,
          639,
          1943,
          380,
          534,
          11,
          572,
          11,
          3097,
          576,
          312,
          884,
          341,
          13,
          50584
        ]
      },
      {
        "avg_logprob": -0.2425978840261266,
        "compression_ratio": 1.7608695652173914,
        "end": 2061.6600000000003,
        "id": 703,
        "no_speech_prob": 0.000007646534868399613,
        "seek": 205526,
        "start": 2059.6600000000003,
        "temperature": 0,
        "text": " So this is a terrible name for this.",
        "tokens": [
          50584,
          407,
          341,
          307,
          257,
          6237,
          1315,
          337,
          341,
          13,
          50684
        ]
      },
      {
        "avg_logprob": -0.2425978840261266,
        "compression_ratio": 1.7608695652173914,
        "end": 2064.46,
        "id": 704,
        "no_speech_prob": 0.000007646534868399613,
        "seek": 205526,
        "start": 2061.6600000000003,
        "temperature": 0,
        "text": " And actually, this is silly for me to even name this.",
        "tokens": [
          50684,
          400,
          767,
          11,
          341,
          307,
          11774,
          337,
          385,
          281,
          754,
          1315,
          341,
          13,
          50824
        ]
      },
      {
        "avg_logprob": -0.2425978840261266,
        "compression_ratio": 1.7608695652173914,
        "end": 2066.5800000000004,
        "id": 705,
        "no_speech_prob": 0.000007646534868399613,
        "seek": 205526,
        "start": 2064.46,
        "temperature": 0,
        "text": " It really makes sense for me to just make",
        "tokens": [
          50824,
          467,
          534,
          1669,
          2020,
          337,
          385,
          281,
          445,
          652,
          50930
        ]
      },
      {
        "avg_logprob": -0.2425978840261266,
        "compression_ratio": 1.7608695652173914,
        "end": 2070.1800000000003,
        "id": 706,
        "no_speech_prob": 0.000007646534868399613,
        "seek": 205526,
        "start": 2066.5800000000004,
        "temperature": 0,
        "text": " this an anonymous function and that what I'm minimizing",
        "tokens": [
          50930,
          341,
          364,
          24932,
          2445,
          293,
          300,
          437,
          286,
          478,
          46608,
          51110
        ]
      },
      {
        "avg_logprob": -0.2425978840261266,
        "compression_ratio": 1.7608695652173914,
        "end": 2072.7400000000002,
        "id": 707,
        "no_speech_prob": 0.000007646534868399613,
        "seek": 205526,
        "start": 2070.1800000000003,
        "temperature": 0,
        "text": " is this, right?",
        "tokens": [
          51110,
          307,
          341,
          11,
          558,
          30,
          51238
        ]
      },
      {
        "avg_logprob": -0.2425978840261266,
        "compression_ratio": 1.7608695652173914,
        "end": 2075.78,
        "id": 708,
        "no_speech_prob": 0.000007646534868399613,
        "seek": 205526,
        "start": 2072.7400000000002,
        "temperature": 0,
        "text": " This is what I want to minimize, the loss function.",
        "tokens": [
          51238,
          639,
          307,
          437,
          286,
          528,
          281,
          17522,
          11,
          264,
          4470,
          2445,
          13,
          51390
        ]
      },
      {
        "avg_logprob": -0.2425978840261266,
        "compression_ratio": 1.7608695652173914,
        "end": 2079.5800000000004,
        "id": 709,
        "no_speech_prob": 0.000007646534868399613,
        "seek": 205526,
        "start": 2075.78,
        "temperature": 0,
        "text": " But if I want to be nice and ES6-like with my arrow notation,",
        "tokens": [
          51390,
          583,
          498,
          286,
          528,
          281,
          312,
          1481,
          293,
          12564,
          21,
          12,
          4092,
          365,
          452,
          11610,
          24657,
          11,
          51580
        ]
      },
      {
        "avg_logprob": -0.2425978840261266,
        "compression_ratio": 1.7608695652173914,
        "end": 2082.82,
        "id": 710,
        "no_speech_prob": 0.000007646534868399613,
        "seek": 205526,
        "start": 2079.5800000000004,
        "temperature": 0,
        "text": " which I think by the fact that I'm using TensorFlow.js,",
        "tokens": [
          51580,
          597,
          286,
          519,
          538,
          264,
          1186,
          300,
          286,
          478,
          1228,
          37624,
          13,
          25530,
          11,
          51742
        ]
      },
      {
        "avg_logprob": -0.2425978840261266,
        "compression_ratio": 1.7608695652173914,
        "end": 2084.6200000000003,
        "id": 711,
        "no_speech_prob": 0.000007646534868399613,
        "seek": 205526,
        "start": 2082.82,
        "temperature": 0,
        "text": " and you can watch my arrow notation function",
        "tokens": [
          51742,
          293,
          291,
          393,
          1159,
          452,
          11610,
          24657,
          2445,
          51832
        ]
      },
      {
        "avg_logprob": -0.2110490398246701,
        "compression_ratio": 1.668103448275862,
        "end": 2090.7799999999997,
        "id": 712,
        "no_speech_prob": 1.855391076333035e-7,
        "seek": 208462,
        "start": 2085.46,
        "temperature": 0,
        "text": " if I can kind of get rid of a lot of the extra stuff here.",
        "tokens": [
          50406,
          498,
          286,
          393,
          733,
          295,
          483,
          3973,
          295,
          257,
          688,
          295,
          264,
          2857,
          1507,
          510,
          13,
          50672
        ]
      },
      {
        "avg_logprob": -0.2110490398246701,
        "compression_ratio": 1.668103448275862,
        "end": 2092.14,
        "id": 713,
        "no_speech_prob": 1.855391076333035e-7,
        "seek": 208462,
        "start": 2090.7799999999997,
        "temperature": 0,
        "text": " And this should be good.",
        "tokens": [
          50672,
          400,
          341,
          820,
          312,
          665,
          13,
          50740
        ]
      },
      {
        "avg_logprob": -0.2110490398246701,
        "compression_ratio": 1.668103448275862,
        "end": 2094.42,
        "id": 714,
        "no_speech_prob": 1.855391076333035e-7,
        "seek": 208462,
        "start": 2092.14,
        "temperature": 0,
        "text": " So I just want to minimize the loss function.",
        "tokens": [
          50740,
          407,
          286,
          445,
          528,
          281,
          17522,
          264,
          4470,
          2445,
          13,
          50854
        ]
      },
      {
        "avg_logprob": -0.2110490398246701,
        "compression_ratio": 1.668103448275862,
        "end": 2097.02,
        "id": 715,
        "no_speech_prob": 1.855391076333035e-7,
        "seek": 208462,
        "start": 2094.42,
        "temperature": 0,
        "text": " Now, here's the thing.",
        "tokens": [
          50854,
          823,
          11,
          510,
          311,
          264,
          551,
          13,
          50984
        ]
      },
      {
        "avg_logprob": -0.2110490398246701,
        "compression_ratio": 1.668103448275862,
        "end": 2099.66,
        "id": 716,
        "no_speech_prob": 1.855391076333035e-7,
        "seek": 208462,
        "start": 2097.02,
        "temperature": 0,
        "text": " These have to be tensors, right?",
        "tokens": [
          50984,
          1981,
          362,
          281,
          312,
          10688,
          830,
          11,
          558,
          30,
          51116
        ]
      },
      {
        "avg_logprob": -0.2110490398246701,
        "compression_ratio": 1.668103448275862,
        "end": 2104.02,
        "id": 717,
        "no_speech_prob": 1.855391076333035e-7,
        "seek": 208462,
        "start": 2099.66,
        "temperature": 0,
        "text": " The loss function requires predictions and labels.",
        "tokens": [
          51116,
          440,
          4470,
          2445,
          7029,
          21264,
          293,
          16949,
          13,
          51334
        ]
      },
      {
        "avg_logprob": -0.2110490398246701,
        "compression_ratio": 1.668103448275862,
        "end": 2105.06,
        "id": 718,
        "no_speech_prob": 1.855391076333035e-7,
        "seek": 208462,
        "start": 2104.02,
        "temperature": 0,
        "text": " They have to be tensors.",
        "tokens": [
          51334,
          814,
          362,
          281,
          312,
          10688,
          830,
          13,
          51386
        ]
      },
      {
        "avg_logprob": -0.2110490398246701,
        "compression_ratio": 1.668103448275862,
        "end": 2108.9,
        "id": 719,
        "no_speech_prob": 1.855391076333035e-7,
        "seek": 208462,
        "start": 2105.06,
        "temperature": 0,
        "text": " And if you remember, my x's and y's aren't tensors.",
        "tokens": [
          51386,
          400,
          498,
          291,
          1604,
          11,
          452,
          2031,
          311,
          293,
          288,
          311,
          3212,
          380,
          10688,
          830,
          13,
          51578
        ]
      },
      {
        "avg_logprob": -0.2110490398246701,
        "compression_ratio": 1.668103448275862,
        "end": 2111.18,
        "id": 720,
        "no_speech_prob": 1.855391076333035e-7,
        "seek": 208462,
        "start": 2108.9,
        "temperature": 0,
        "text": " When I call the predict function with the x's,",
        "tokens": [
          51578,
          1133,
          286,
          818,
          264,
          6069,
          2445,
          365,
          264,
          2031,
          311,
          11,
          51692
        ]
      },
      {
        "avg_logprob": -0.2110490398246701,
        "compression_ratio": 1.668103448275862,
        "end": 2114.46,
        "id": 721,
        "no_speech_prob": 1.855391076333035e-7,
        "seek": 208462,
        "start": 2111.18,
        "temperature": 0,
        "text": " it gives me back a tensor.",
        "tokens": [
          51692,
          309,
          2709,
          385,
          646,
          257,
          40863,
          13,
          51856
        ]
      },
      {
        "avg_logprob": -0.20529397758277687,
        "compression_ratio": 1.7272727272727273,
        "end": 2117.26,
        "id": 722,
        "no_speech_prob": 0.000009223466804542113,
        "seek": 211446,
        "start": 2115.46,
        "temperature": 0,
        "text": " I can't believe I haven't run this code yet.",
        "tokens": [
          50414,
          286,
          393,
          380,
          1697,
          286,
          2378,
          380,
          1190,
          341,
          3089,
          1939,
          13,
          50504
        ]
      },
      {
        "avg_logprob": -0.20529397758277687,
        "compression_ratio": 1.7272727272727273,
        "end": 2118.5,
        "id": 723,
        "no_speech_prob": 0.000009223466804542113,
        "seek": 211446,
        "start": 2117.26,
        "temperature": 0,
        "text": " This is a terrible thing.",
        "tokens": [
          50504,
          639,
          307,
          257,
          6237,
          551,
          13,
          50566
        ]
      },
      {
        "avg_logprob": -0.20529397758277687,
        "compression_ratio": 1.7272727272727273,
        "end": 2121.58,
        "id": 724,
        "no_speech_prob": 0.000009223466804542113,
        "seek": 211446,
        "start": 2118.5,
        "temperature": 0,
        "text": " Usually, I try to run my code incrementally all the time.",
        "tokens": [
          50566,
          11419,
          11,
          286,
          853,
          281,
          1190,
          452,
          3089,
          26200,
          379,
          439,
          264,
          565,
          13,
          50720
        ]
      },
      {
        "avg_logprob": -0.20529397758277687,
        "compression_ratio": 1.7272727272727273,
        "end": 2123.14,
        "id": 725,
        "no_speech_prob": 0.000009223466804542113,
        "seek": 211446,
        "start": 2121.58,
        "temperature": 0,
        "text": " I guess I've forgotten to do that.",
        "tokens": [
          50720,
          286,
          2041,
          286,
          600,
          11832,
          281,
          360,
          300,
          13,
          50798
        ]
      },
      {
        "avg_logprob": -0.20529397758277687,
        "compression_ratio": 1.7272727272727273,
        "end": 2125.02,
        "id": 726,
        "no_speech_prob": 0.000009223466804542113,
        "seek": 211446,
        "start": 2123.14,
        "temperature": 0,
        "text": " So probably people in the chat are telling me",
        "tokens": [
          50798,
          407,
          1391,
          561,
          294,
          264,
          5081,
          366,
          3585,
          385,
          50892
        ]
      },
      {
        "avg_logprob": -0.20529397758277687,
        "compression_ratio": 1.7272727272727273,
        "end": 2126.1,
        "id": 727,
        "no_speech_prob": 0.000009223466804542113,
        "seek": 211446,
        "start": 2125.02,
        "temperature": 0,
        "text": " about mistakes I'm making.",
        "tokens": [
          50892,
          466,
          8038,
          286,
          478,
          1455,
          13,
          50946
        ]
      },
      {
        "avg_logprob": -0.20529397758277687,
        "compression_ratio": 1.7272727272727273,
        "end": 2130.34,
        "id": 728,
        "no_speech_prob": 0.000009223466804542113,
        "seek": 211446,
        "start": 2126.1,
        "temperature": 0,
        "text": " So this is a tensor, but this is still a plain array.",
        "tokens": [
          50946,
          407,
          341,
          307,
          257,
          40863,
          11,
          457,
          341,
          307,
          920,
          257,
          11121,
          10225,
          13,
          51158
        ]
      },
      {
        "avg_logprob": -0.20529397758277687,
        "compression_ratio": 1.7272727272727273,
        "end": 2132.62,
        "id": 729,
        "no_speech_prob": 0.000009223466804542113,
        "seek": 211446,
        "start": 2130.34,
        "temperature": 0,
        "text": " So what I need to do is say constant.",
        "tokens": [
          51158,
          407,
          437,
          286,
          643,
          281,
          360,
          307,
          584,
          5754,
          13,
          51272
        ]
      },
      {
        "avg_logprob": -0.20529397758277687,
        "compression_ratio": 1.7272727272727273,
        "end": 2134.02,
        "id": 730,
        "no_speech_prob": 0.000009223466804542113,
        "seek": 211446,
        "start": 2132.62,
        "temperature": 0,
        "text": " And I got to rethink the naming.",
        "tokens": [
          51272,
          400,
          286,
          658,
          281,
          34595,
          264,
          25290,
          13,
          51342
        ]
      },
      {
        "avg_logprob": -0.20529397758277687,
        "compression_ratio": 1.7272727272727273,
        "end": 2137.94,
        "id": 731,
        "no_speech_prob": 0.000009223466804542113,
        "seek": 211446,
        "start": 2134.02,
        "temperature": 0,
        "text": " Maybe somebody in the chat has an idea for me.",
        "tokens": [
          51342,
          2704,
          2618,
          294,
          264,
          5081,
          575,
          364,
          1558,
          337,
          385,
          13,
          51538
        ]
      },
      {
        "avg_logprob": -0.20529397758277687,
        "compression_ratio": 1.7272727272727273,
        "end": 2140.54,
        "id": 732,
        "no_speech_prob": 0.000009223466804542113,
        "seek": 211446,
        "start": 2137.94,
        "temperature": 0,
        "text": " I think what I actually should do, I have an idea.",
        "tokens": [
          51538,
          286,
          519,
          437,
          286,
          767,
          820,
          360,
          11,
          286,
          362,
          364,
          1558,
          13,
          51668
        ]
      },
      {
        "avg_logprob": -0.20529397758277687,
        "compression_ratio": 1.7272727272727273,
        "end": 2143.18,
        "id": 733,
        "no_speech_prob": 0.000009223466804542113,
        "seek": 211446,
        "start": 2140.54,
        "temperature": 0,
        "text": " Permit me a moment of refactoring.",
        "tokens": [
          51668,
          41006,
          270,
          385,
          257,
          1623,
          295,
          1895,
          578,
          3662,
          13,
          51800
        ]
      },
      {
        "avg_logprob": -0.2160099457050192,
        "compression_ratio": 1.7156862745098038,
        "end": 2146.02,
        "id": 734,
        "no_speech_prob": 0.000020462914108065888,
        "seek": 214318,
        "start": 2143.18,
        "temperature": 0,
        "text": " x valves, y valves.",
        "tokens": [
          50364,
          2031,
          371,
          304,
          977,
          11,
          288,
          34950,
          13,
          50506
        ]
      },
      {
        "avg_logprob": -0.2160099457050192,
        "compression_ratio": 1.7156862745098038,
        "end": 2147.7,
        "id": 735,
        "no_speech_prob": 0.000020462914108065888,
        "seek": 214318,
        "start": 2146.02,
        "temperature": 0,
        "text": " So I think when it's not a tensor,",
        "tokens": [
          50506,
          407,
          286,
          519,
          562,
          309,
          311,
          406,
          257,
          40863,
          11,
          50590
        ]
      },
      {
        "avg_logprob": -0.2160099457050192,
        "compression_ratio": 1.7156862745098038,
        "end": 2151.3799999999997,
        "id": 736,
        "no_speech_prob": 0.000020462914108065888,
        "seek": 214318,
        "start": 2147.7,
        "temperature": 0,
        "text": " I'm just going to call it x underscore valves,",
        "tokens": [
          50590,
          286,
          478,
          445,
          516,
          281,
          818,
          309,
          2031,
          37556,
          34950,
          11,
          50774
        ]
      },
      {
        "avg_logprob": -0.2160099457050192,
        "compression_ratio": 1.7156862745098038,
        "end": 2155.14,
        "id": 737,
        "no_speech_prob": 0.000020462914108065888,
        "seek": 214318,
        "start": 2151.3799999999997,
        "temperature": 0,
        "text": " because that's going to help me remember.",
        "tokens": [
          50774,
          570,
          300,
          311,
          516,
          281,
          854,
          385,
          1604,
          13,
          50962
        ]
      },
      {
        "avg_logprob": -0.2160099457050192,
        "compression_ratio": 1.7156862745098038,
        "end": 2158.62,
        "id": 738,
        "no_speech_prob": 0.000020462914108065888,
        "seek": 214318,
        "start": 2155.14,
        "temperature": 0,
        "text": " So x valves, y valves.",
        "tokens": [
          50962,
          407,
          2031,
          34950,
          11,
          288,
          34950,
          13,
          51136
        ]
      },
      {
        "avg_logprob": -0.2160099457050192,
        "compression_ratio": 1.7156862745098038,
        "end": 2162.4199999999996,
        "id": 739,
        "no_speech_prob": 0.000020462914108065888,
        "seek": 214318,
        "start": 2158.62,
        "temperature": 0,
        "text": " And then whenever I say, and this should be x,",
        "tokens": [
          51136,
          400,
          550,
          5699,
          286,
          584,
          11,
          293,
          341,
          820,
          312,
          2031,
          11,
          51326
        ]
      },
      {
        "avg_logprob": -0.2160099457050192,
        "compression_ratio": 1.7156862745098038,
        "end": 2165.5,
        "id": 740,
        "no_speech_prob": 0.000020462914108065888,
        "seek": 214318,
        "start": 2162.4199999999996,
        "temperature": 0,
        "text": " whenever I say xs or ys, that's really a tensor.",
        "tokens": [
          51326,
          5699,
          286,
          584,
          2031,
          82,
          420,
          288,
          82,
          11,
          300,
          311,
          534,
          257,
          40863,
          13,
          51480
        ]
      },
      {
        "avg_logprob": -0.2160099457050192,
        "compression_ratio": 1.7156862745098038,
        "end": 2167.06,
        "id": 741,
        "no_speech_prob": 0.000020462914108065888,
        "seek": 214318,
        "start": 2165.5,
        "temperature": 0,
        "text": " I guess I could have done txs.",
        "tokens": [
          51480,
          286,
          2041,
          286,
          727,
          362,
          1096,
          256,
          87,
          82,
          13,
          51558
        ]
      },
      {
        "avg_logprob": -0.2160099457050192,
        "compression_ratio": 1.7156862745098038,
        "end": 2171.06,
        "id": 742,
        "no_speech_prob": 0.000020462914108065888,
        "seek": 214318,
        "start": 2167.06,
        "temperature": 0,
        "text": " So here, what I'm doing is predicting from the x valves.",
        "tokens": [
          51558,
          407,
          510,
          11,
          437,
          286,
          478,
          884,
          307,
          32884,
          490,
          264,
          2031,
          34950,
          13,
          51758
        ]
      },
      {
        "avg_logprob": -0.2771474501665901,
        "compression_ratio": 1.4935897435897436,
        "end": 2175.62,
        "id": 743,
        "no_speech_prob": 0.000003288748985141865,
        "seek": 217106,
        "start": 2171.06,
        "temperature": 0,
        "text": " And then ys is tf tensor.",
        "tokens": [
          50364,
          400,
          550,
          288,
          82,
          307,
          256,
          69,
          40863,
          13,
          50592
        ]
      },
      {
        "avg_logprob": -0.2771474501665901,
        "compression_ratio": 1.4935897435897436,
        "end": 2178.18,
        "id": 744,
        "no_speech_prob": 0.000003288748985141865,
        "seek": 217106,
        "start": 2175.62,
        "temperature": 0,
        "text": " Shoot.",
        "tokens": [
          50592,
          19760,
          13,
          50720
        ]
      },
      {
        "avg_logprob": -0.2771474501665901,
        "compression_ratio": 1.4935897435897436,
        "end": 2179.72,
        "id": 745,
        "no_speech_prob": 0.000003288748985141865,
        "seek": 217106,
        "start": 2178.18,
        "temperature": 0,
        "text": " Somehow I went past a half an hour.",
        "tokens": [
          50720,
          28357,
          286,
          1437,
          1791,
          257,
          1922,
          364,
          1773,
          13,
          50797
        ]
      },
      {
        "avg_logprob": -0.2771474501665901,
        "compression_ratio": 1.4935897435897436,
        "end": 2189.34,
        "id": 746,
        "no_speech_prob": 0.000003288748985141865,
        "seek": 217106,
        "start": 2184.2599999999998,
        "temperature": 0,
        "text": " ys is tf.tensor1dy valves.",
        "tokens": [
          51024,
          288,
          82,
          307,
          256,
          69,
          13,
          83,
          23153,
          16,
          3173,
          34950,
          13,
          51278
        ]
      },
      {
        "avg_logprob": -0.2771474501665901,
        "compression_ratio": 1.4935897435897436,
        "end": 2191.38,
        "id": 747,
        "no_speech_prob": 0.000003288748985141865,
        "seek": 217106,
        "start": 2189.34,
        "temperature": 0,
        "text": " So I need to create that tensor.",
        "tokens": [
          51278,
          407,
          286,
          643,
          281,
          1884,
          300,
          40863,
          13,
          51380
        ]
      },
      {
        "avg_logprob": -0.2771474501665901,
        "compression_ratio": 1.4935897435897436,
        "end": 2194.2599999999998,
        "id": 748,
        "no_speech_prob": 0.000003288748985141865,
        "seek": 217106,
        "start": 2191.38,
        "temperature": 0,
        "text": " And now I can minimize the loss with predicting",
        "tokens": [
          51380,
          400,
          586,
          286,
          393,
          17522,
          264,
          4470,
          365,
          32884,
          51524
        ]
      },
      {
        "avg_logprob": -0.2771474501665901,
        "compression_ratio": 1.4935897435897436,
        "end": 2197.06,
        "id": 749,
        "no_speech_prob": 0.000003288748985141865,
        "seek": 217106,
        "start": 2194.2599999999998,
        "temperature": 0,
        "text": " from the x valves and the y valves.",
        "tokens": [
          51524,
          490,
          264,
          2031,
          34950,
          293,
          264,
          288,
          34950,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2771474501665901,
        "compression_ratio": 1.4935897435897436,
        "end": 2198.22,
        "id": 750,
        "no_speech_prob": 0.000003288748985141865,
        "seek": 217106,
        "start": 2197.06,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51664,
          2264,
          13,
          51722
        ]
      },
      {
        "avg_logprob": -0.2771474501665901,
        "compression_ratio": 1.4935897435897436,
        "end": 2199.98,
        "id": 751,
        "no_speech_prob": 0.000003288748985141865,
        "seek": 217106,
        "start": 2198.22,
        "temperature": 0,
        "text": " So this is good.",
        "tokens": [
          51722,
          407,
          341,
          307,
          665,
          13,
          51810
        ]
      },
      {
        "avg_logprob": -0.35389339390085706,
        "compression_ratio": 1.3541666666666667,
        "end": 2203.06,
        "id": 752,
        "no_speech_prob": 0.00008092755888355896,
        "seek": 219998,
        "start": 2199.98,
        "temperature": 0,
        "text": " Let's just run this, see what errors we get.",
        "tokens": [
          50364,
          961,
          311,
          445,
          1190,
          341,
          11,
          536,
          437,
          13603,
          321,
          483,
          13,
          50518
        ]
      },
      {
        "avg_logprob": -0.35389339390085706,
        "compression_ratio": 1.3541666666666667,
        "end": 2207.7400000000002,
        "id": 753,
        "no_speech_prob": 0.00008092755888355896,
        "seek": 219998,
        "start": 2207.22,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50726,
          2264,
          13,
          50752
        ]
      },
      {
        "avg_logprob": -0.35389339390085706,
        "compression_ratio": 1.3541666666666667,
        "end": 2210.26,
        "id": 754,
        "no_speech_prob": 0.00008092755888355896,
        "seek": 219998,
        "start": 2207.7400000000002,
        "temperature": 0,
        "text": " predict.sub.squared is not a function",
        "tokens": [
          50752,
          6069,
          13,
          30131,
          13,
          33292,
          1642,
          307,
          406,
          257,
          2445,
          50878
        ]
      },
      {
        "avg_logprob": -0.35389339390085706,
        "compression_ratio": 1.3541666666666667,
        "end": 2212.5,
        "id": 755,
        "no_speech_prob": 0.00008092755888355896,
        "seek": 219998,
        "start": 2210.26,
        "temperature": 0,
        "text": " at loss at optimize or minimize.",
        "tokens": [
          50878,
          412,
          4470,
          412,
          19719,
          420,
          17522,
          13,
          50990
        ]
      },
      {
        "avg_logprob": -0.35389339390085706,
        "compression_ratio": 1.3541666666666667,
        "end": 2215.5,
        "id": 756,
        "no_speech_prob": 0.00008092755888355896,
        "seek": 219998,
        "start": 2212.5,
        "temperature": 0,
        "text": " So what do I have wrong here?",
        "tokens": [
          50990,
          407,
          437,
          360,
          286,
          362,
          2085,
          510,
          30,
          51140
        ]
      },
      {
        "avg_logprob": -0.35389339390085706,
        "compression_ratio": 1.3541666666666667,
        "end": 2222.22,
        "id": 757,
        "no_speech_prob": 0.00008092755888355896,
        "seek": 219998,
        "start": 2215.5,
        "temperature": 0,
        "text": " In my loss function, sub labels.squared.mean.",
        "tokens": [
          51140,
          682,
          452,
          4470,
          2445,
          11,
          1422,
          16949,
          13,
          33292,
          1642,
          13,
          1398,
          282,
          13,
          51476
        ]
      },
      {
        "avg_logprob": -0.30666173737624597,
        "compression_ratio": 1.4827586206896552,
        "end": 2223.72,
        "id": 758,
        "no_speech_prob": 0.0003740947286132723,
        "seek": 222222,
        "start": 2223.22,
        "temperature": 0,
        "text": " Hmm.",
        "tokens": [
          50414,
          8239,
          13,
          50439
        ]
      },
      {
        "avg_logprob": -0.30666173737624597,
        "compression_ratio": 1.4827586206896552,
        "end": 2233.7799999999997,
        "id": 759,
        "no_speech_prob": 0.0003740947286132723,
        "seek": 222222,
        "start": 2229.54,
        "temperature": 0,
        "text": " So let me put no loop in here because I just",
        "tokens": [
          50730,
          407,
          718,
          385,
          829,
          572,
          6367,
          294,
          510,
          570,
          286,
          445,
          50942
        ]
      },
      {
        "avg_logprob": -0.30666173737624597,
        "compression_ratio": 1.4827586206896552,
        "end": 2236.7,
        "id": 760,
        "no_speech_prob": 0.0003740947286132723,
        "seek": 222222,
        "start": 2233.7799999999997,
        "temperature": 0,
        "text": " want to run this once.",
        "tokens": [
          50942,
          528,
          281,
          1190,
          341,
          1564,
          13,
          51088
        ]
      },
      {
        "avg_logprob": -0.30666173737624597,
        "compression_ratio": 1.4827586206896552,
        "end": 2241.4599999999996,
        "id": 761,
        "no_speech_prob": 0.0003740947286132723,
        "seek": 222222,
        "start": 2236.7,
        "temperature": 0,
        "text": " And let me say, I just want to console log.",
        "tokens": [
          51088,
          400,
          718,
          385,
          584,
          11,
          286,
          445,
          528,
          281,
          11076,
          3565,
          13,
          51326
        ]
      },
      {
        "avg_logprob": -0.30666173737624597,
        "compression_ratio": 1.4827586206896552,
        "end": 2244.62,
        "id": 762,
        "no_speech_prob": 0.0003740947286132723,
        "seek": 222222,
        "start": 2241.4599999999996,
        "temperature": 0,
        "text": " Oh, actually, I can just do ys.print.",
        "tokens": [
          51326,
          876,
          11,
          767,
          11,
          286,
          393,
          445,
          360,
          288,
          82,
          13,
          14030,
          13,
          51484
        ]
      },
      {
        "avg_logprob": -0.30666173737624597,
        "compression_ratio": 1.4827586206896552,
        "end": 2248.3799999999997,
        "id": 763,
        "no_speech_prob": 0.0003740947286132723,
        "seek": 222222,
        "start": 2244.62,
        "temperature": 0,
        "text": " Oh, you know what it is?",
        "tokens": [
          51484,
          876,
          11,
          291,
          458,
          437,
          309,
          307,
          30,
          51672
        ]
      },
      {
        "avg_logprob": -0.30666173737624597,
        "compression_ratio": 1.4827586206896552,
        "end": 2250.5,
        "id": 764,
        "no_speech_prob": 0.0003740947286132723,
        "seek": 222222,
        "start": 2248.3799999999997,
        "temperature": 0,
        "text": " There's nothing in the arrays at the beginning.",
        "tokens": [
          51672,
          821,
          311,
          1825,
          294,
          264,
          41011,
          412,
          264,
          2863,
          13,
          51778
        ]
      },
      {
        "avg_logprob": -0.30666173737624597,
        "compression_ratio": 1.4827586206896552,
        "end": 2251.8999999999996,
        "id": 765,
        "no_speech_prob": 0.0003740947286132723,
        "seek": 222222,
        "start": 2250.5,
        "temperature": 0,
        "text": " They have zero things in them.",
        "tokens": [
          51778,
          814,
          362,
          4018,
          721,
          294,
          552,
          13,
          51848
        ]
      },
      {
        "avg_logprob": -0.300841398017351,
        "compression_ratio": 1.593984962406015,
        "end": 2252.5,
        "id": 766,
        "no_speech_prob": 0.000004860447461396689,
        "seek": 225190,
        "start": 2251.9,
        "temperature": 0,
        "text": " So a couple of things.",
        "tokens": [
          50364,
          407,
          257,
          1916,
          295,
          721,
          13,
          50394
        ]
      },
      {
        "avg_logprob": -0.300841398017351,
        "compression_ratio": 1.593984962406015,
        "end": 2254.02,
        "id": 767,
        "no_speech_prob": 0.000004860447461396689,
        "seek": 225190,
        "start": 2252.5,
        "temperature": 0,
        "text": " One is I could put something in it.",
        "tokens": [
          50394,
          1485,
          307,
          286,
          727,
          829,
          746,
          294,
          309,
          13,
          50470
        ]
      },
      {
        "avg_logprob": -0.300841398017351,
        "compression_ratio": 1.593984962406015,
        "end": 2256.6600000000003,
        "id": 768,
        "no_speech_prob": 0.000004860447461396689,
        "seek": 225190,
        "start": 2254.02,
        "temperature": 0,
        "text": " But I think I probably should just say,",
        "tokens": [
          50470,
          583,
          286,
          519,
          286,
          1391,
          820,
          445,
          584,
          11,
          50602
        ]
      },
      {
        "avg_logprob": -0.300841398017351,
        "compression_ratio": 1.593984962406015,
        "end": 2262.06,
        "id": 769,
        "no_speech_prob": 0.000004860447461396689,
        "seek": 225190,
        "start": 2256.6600000000003,
        "temperature": 0,
        "text": " I shouldn't do it only if x.length is greater than 0.",
        "tokens": [
          50602,
          286,
          4659,
          380,
          360,
          309,
          787,
          498,
          2031,
          13,
          45390,
          307,
          5044,
          813,
          1958,
          13,
          50872
        ]
      },
      {
        "avg_logprob": -0.300841398017351,
        "compression_ratio": 1.593984962406015,
        "end": 2266.7400000000002,
        "id": 770,
        "no_speech_prob": 0.000004860447461396689,
        "seek": 225190,
        "start": 2262.06,
        "temperature": 0,
        "text": " So this is definitely, do I want to bother with doing any of this?",
        "tokens": [
          50872,
          407,
          341,
          307,
          2138,
          11,
          360,
          286,
          528,
          281,
          8677,
          365,
          884,
          604,
          295,
          341,
          30,
          51106
        ]
      },
      {
        "avg_logprob": -0.300841398017351,
        "compression_ratio": 1.593984962406015,
        "end": 2269.26,
        "id": 771,
        "no_speech_prob": 0.000004860447461396689,
        "seek": 225190,
        "start": 2266.7400000000002,
        "temperature": 0,
        "text": " If there's no values in there, like calling predict and stuff",
        "tokens": [
          51106,
          759,
          456,
          311,
          572,
          4190,
          294,
          456,
          11,
          411,
          5141,
          6069,
          293,
          1507,
          51232
        ]
      },
      {
        "avg_logprob": -0.300841398017351,
        "compression_ratio": 1.593984962406015,
        "end": 2272.1800000000003,
        "id": 772,
        "no_speech_prob": 0.000004860447461396689,
        "seek": 225190,
        "start": 2269.26,
        "temperature": 0,
        "text": " with an empty array, I think it's going to cause problems.",
        "tokens": [
          51232,
          365,
          364,
          6707,
          10225,
          11,
          286,
          519,
          309,
          311,
          516,
          281,
          3082,
          2740,
          13,
          51378
        ]
      },
      {
        "avg_logprob": -0.300841398017351,
        "compression_ratio": 1.593984962406015,
        "end": 2273.46,
        "id": 773,
        "no_speech_prob": 0.000004860447461396689,
        "seek": 225190,
        "start": 2272.1800000000003,
        "temperature": 0,
        "text": " That makes sense.",
        "tokens": [
          51378,
          663,
          1669,
          2020,
          13,
          51442
        ]
      },
      {
        "avg_logprob": -0.300841398017351,
        "compression_ratio": 1.593984962406015,
        "end": 2275.62,
        "id": 774,
        "no_speech_prob": 0.000004860447461396689,
        "seek": 225190,
        "start": 2273.46,
        "temperature": 0,
        "text": " All right, let's try this.",
        "tokens": [
          51442,
          1057,
          558,
          11,
          718,
          311,
          853,
          341,
          13,
          51550
        ]
      },
      {
        "avg_logprob": -0.300841398017351,
        "compression_ratio": 1.593984962406015,
        "end": 2276.78,
        "id": 775,
        "no_speech_prob": 0.000004860447461396689,
        "seek": 225190,
        "start": 2275.62,
        "temperature": 0,
        "text": " x is not defined.",
        "tokens": [
          51550,
          2031,
          307,
          406,
          7642,
          13,
          51608
        ]
      },
      {
        "avg_logprob": -0.300841398017351,
        "compression_ratio": 1.593984962406015,
        "end": 2280.2200000000003,
        "id": 776,
        "no_speech_prob": 0.000004860447461396689,
        "seek": 225190,
        "start": 2276.78,
        "temperature": 0,
        "text": " x valves, my naming.",
        "tokens": [
          51608,
          2031,
          34950,
          11,
          452,
          25290,
          13,
          51780
        ]
      },
      {
        "avg_logprob": -0.347591495513916,
        "compression_ratio": 1.3666666666666667,
        "end": 2283.74,
        "id": 777,
        "no_speech_prob": 0.000041335326386615634,
        "seek": 228022,
        "start": 2280.22,
        "temperature": 0,
        "text": " OK, sketch 45.",
        "tokens": [
          50364,
          2264,
          11,
          12325,
          6905,
          13,
          50540
        ]
      },
      {
        "avg_logprob": -0.347591495513916,
        "compression_ratio": 1.3666666666666667,
        "end": 2284.9399999999996,
        "id": 778,
        "no_speech_prob": 0.000041335326386615634,
        "seek": 228022,
        "start": 2283.74,
        "temperature": 0,
        "text": " Ah, this is x valves.",
        "tokens": [
          50540,
          2438,
          11,
          341,
          307,
          2031,
          34950,
          13,
          50600
        ]
      },
      {
        "avg_logprob": -0.347591495513916,
        "compression_ratio": 1.3666666666666667,
        "end": 2292.54,
        "id": 779,
        "no_speech_prob": 0.000041335326386615634,
        "seek": 228022,
        "start": 2287.8599999999997,
        "temperature": 0,
        "text": " And this is x valves, y valves.",
        "tokens": [
          50746,
          400,
          341,
          307,
          2031,
          34950,
          11,
          288,
          34950,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.347591495513916,
        "compression_ratio": 1.3666666666666667,
        "end": 2294.8999999999996,
        "id": 780,
        "no_speech_prob": 0.000041335326386615634,
        "seek": 228022,
        "start": 2292.54,
        "temperature": 0,
        "text": " OK, that should be good.",
        "tokens": [
          50980,
          2264,
          11,
          300,
          820,
          312,
          665,
          13,
          51098
        ]
      },
      {
        "avg_logprob": -0.347591495513916,
        "compression_ratio": 1.3666666666666667,
        "end": 2296.8999999999996,
        "id": 781,
        "no_speech_prob": 0.000041335326386615634,
        "seek": 228022,
        "start": 2294.8999999999996,
        "temperature": 0,
        "text": " All right, let's try this.",
        "tokens": [
          51098,
          1057,
          558,
          11,
          718,
          311,
          853,
          341,
          13,
          51198
        ]
      },
      {
        "avg_logprob": -0.347591495513916,
        "compression_ratio": 1.3666666666666667,
        "end": 2308.4599999999996,
        "id": 782,
        "no_speech_prob": 0.000041335326386615634,
        "seek": 228022,
        "start": 2303.18,
        "temperature": 0,
        "text": " All right, I think I have frozen the world.",
        "tokens": [
          51512,
          1057,
          558,
          11,
          286,
          519,
          286,
          362,
          12496,
          264,
          1002,
          13,
          51776
        ]
      },
      {
        "avg_logprob": -0.3384079138437907,
        "compression_ratio": 1.6,
        "end": 2316.66,
        "id": 783,
        "no_speech_prob": 0.0001609307510079816,
        "seek": 231022,
        "start": 2310.22,
        "temperature": 0,
        "text": " Oh, this is not square.",
        "tokens": [
          50364,
          876,
          11,
          341,
          307,
          406,
          3732,
          13,
          50686
        ]
      },
      {
        "avg_logprob": -0.3384079138437907,
        "compression_ratio": 1.6,
        "end": 2319.8199999999997,
        "id": 784,
        "no_speech_prob": 0.0001609307510079816,
        "seek": 231022,
        "start": 2316.66,
        "temperature": 0,
        "text": " I'm being told in the chat, breaking news,",
        "tokens": [
          50686,
          286,
          478,
          885,
          1907,
          294,
          264,
          5081,
          11,
          7697,
          2583,
          11,
          50844
        ]
      },
      {
        "avg_logprob": -0.3384079138437907,
        "compression_ratio": 1.6,
        "end": 2322.8599999999997,
        "id": 785,
        "no_speech_prob": 0.0001609307510079816,
        "seek": 231022,
        "start": 2319.8199999999997,
        "temperature": 0,
        "text": " that this is actually dot square, not dot squared.",
        "tokens": [
          50844,
          300,
          341,
          307,
          767,
          5893,
          3732,
          11,
          406,
          5893,
          8889,
          13,
          50996
        ]
      },
      {
        "avg_logprob": -0.3384079138437907,
        "compression_ratio": 1.6,
        "end": 2325.3799999999997,
        "id": 786,
        "no_speech_prob": 0.0001609307510079816,
        "seek": 231022,
        "start": 2322.8599999999997,
        "temperature": 0,
        "text": " Is that right?",
        "tokens": [
          50996,
          1119,
          300,
          558,
          30,
          51122
        ]
      },
      {
        "avg_logprob": -0.3384079138437907,
        "compression_ratio": 1.6,
        "end": 2326.62,
        "id": 787,
        "no_speech_prob": 0.0001609307510079816,
        "seek": 231022,
        "start": 2325.3799999999997,
        "temperature": 0,
        "text": " Operations, square.",
        "tokens": [
          51122,
          36381,
          11,
          3732,
          13,
          51184
        ]
      },
      {
        "avg_logprob": -0.3384079138437907,
        "compression_ratio": 1.6,
        "end": 2332.58,
        "id": 788,
        "no_speech_prob": 0.0001609307510079816,
        "seek": 231022,
        "start": 2329.7,
        "temperature": 0,
        "text": " Whoa, this I might be able to use.",
        "tokens": [
          51338,
          7521,
          11,
          341,
          286,
          1062,
          312,
          1075,
          281,
          764,
          13,
          51482
        ]
      },
      {
        "avg_logprob": -0.3384079138437907,
        "compression_ratio": 1.6,
        "end": 2335.06,
        "id": 789,
        "no_speech_prob": 0.0001609307510079816,
        "seek": 231022,
        "start": 2332.58,
        "temperature": 0,
        "text": " Computes the mean squared error between two tensors.",
        "tokens": [
          51482,
          6620,
          1819,
          264,
          914,
          8889,
          6713,
          1296,
          732,
          10688,
          830,
          13,
          51606
        ]
      },
      {
        "avg_logprob": -0.3384079138437907,
        "compression_ratio": 1.6,
        "end": 2336.7,
        "id": 790,
        "no_speech_prob": 0.0001609307510079816,
        "seek": 231022,
        "start": 2335.06,
        "temperature": 0,
        "text": " So I could also use this probably,",
        "tokens": [
          51606,
          407,
          286,
          727,
          611,
          764,
          341,
          1391,
          11,
          51688
        ]
      },
      {
        "avg_logprob": -0.3384079138437907,
        "compression_ratio": 1.6,
        "end": 2339.2999999999997,
        "id": 791,
        "no_speech_prob": 0.0001609307510079816,
        "seek": 231022,
        "start": 2336.7,
        "temperature": 0,
        "text": " but that's not what I'm looking for.",
        "tokens": [
          51688,
          457,
          300,
          311,
          406,
          437,
          286,
          478,
          1237,
          337,
          13,
          51818
        ]
      },
      {
        "avg_logprob": -0.2592586086642358,
        "compression_ratio": 1.553921568627451,
        "end": 2340.78,
        "id": 792,
        "no_speech_prob": 0.00001012999018712435,
        "seek": 233930,
        "start": 2339.34,
        "temperature": 0,
        "text": " Yeah, oh, it's square.",
        "tokens": [
          50366,
          865,
          11,
          1954,
          11,
          309,
          311,
          3732,
          13,
          50438
        ]
      },
      {
        "avg_logprob": -0.2592586086642358,
        "compression_ratio": 1.553921568627451,
        "end": 2341.78,
        "id": 793,
        "no_speech_prob": 0.00001012999018712435,
        "seek": 233930,
        "start": 2340.78,
        "temperature": 0,
        "text": " A dot square.",
        "tokens": [
          50438,
          316,
          5893,
          3732,
          13,
          50488
        ]
      },
      {
        "avg_logprob": -0.2592586086642358,
        "compression_ratio": 1.553921568627451,
        "end": 2342.28,
        "id": 794,
        "no_speech_prob": 0.00001012999018712435,
        "seek": 233930,
        "start": 2341.78,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50488,
          2264,
          13,
          50513
        ]
      },
      {
        "avg_logprob": -0.2592586086642358,
        "compression_ratio": 1.553921568627451,
        "end": 2349.98,
        "id": 795,
        "no_speech_prob": 0.00001012999018712435,
        "seek": 233930,
        "start": 2349.42,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          50870,
          6962,
          322,
          13,
          50898
        ]
      },
      {
        "avg_logprob": -0.2592586086642358,
        "compression_ratio": 1.553921568627451,
        "end": 2351.7400000000002,
        "id": 796,
        "no_speech_prob": 0.00001012999018712435,
        "seek": 233930,
        "start": 2349.98,
        "temperature": 0,
        "text": " So what's going on?",
        "tokens": [
          50898,
          407,
          437,
          311,
          516,
          322,
          30,
          50986
        ]
      },
      {
        "avg_logprob": -0.2592586086642358,
        "compression_ratio": 1.553921568627451,
        "end": 2352.78,
        "id": 797,
        "no_speech_prob": 0.00001012999018712435,
        "seek": 233930,
        "start": 2351.7400000000002,
        "temperature": 0,
        "text": " Let's comment this out.",
        "tokens": [
          50986,
          961,
          311,
          2871,
          341,
          484,
          13,
          51038
        ]
      },
      {
        "avg_logprob": -0.2592586086642358,
        "compression_ratio": 1.553921568627451,
        "end": 2353.82,
        "id": 798,
        "no_speech_prob": 0.00001012999018712435,
        "seek": 233930,
        "start": 2352.78,
        "temperature": 0,
        "text": " Oh, I put no loop.",
        "tokens": [
          51038,
          876,
          11,
          286,
          829,
          572,
          6367,
          13,
          51090
        ]
      },
      {
        "avg_logprob": -0.2592586086642358,
        "compression_ratio": 1.553921568627451,
        "end": 2355.1800000000003,
        "id": 799,
        "no_speech_prob": 0.00001012999018712435,
        "seek": 233930,
        "start": 2353.82,
        "temperature": 0,
        "text": " I put no loop in there.",
        "tokens": [
          51090,
          286,
          829,
          572,
          6367,
          294,
          456,
          13,
          51158
        ]
      },
      {
        "avg_logprob": -0.2592586086642358,
        "compression_ratio": 1.553921568627451,
        "end": 2355.98,
        "id": 800,
        "no_speech_prob": 0.00001012999018712435,
        "seek": 233930,
        "start": 2355.1800000000003,
        "temperature": 0,
        "text": " Silly me.",
        "tokens": [
          51158,
          318,
          6917,
          385,
          13,
          51198
        ]
      },
      {
        "avg_logprob": -0.2592586086642358,
        "compression_ratio": 1.553921568627451,
        "end": 2357.2200000000003,
        "id": 801,
        "no_speech_prob": 0.00001012999018712435,
        "seek": 233930,
        "start": 2355.98,
        "temperature": 0,
        "text": " OK, everything's fine.",
        "tokens": [
          51198,
          2264,
          11,
          1203,
          311,
          2489,
          13,
          51260
        ]
      },
      {
        "avg_logprob": -0.2592586086642358,
        "compression_ratio": 1.553921568627451,
        "end": 2361.54,
        "id": 802,
        "no_speech_prob": 0.00001012999018712435,
        "seek": 233930,
        "start": 2357.2200000000003,
        "temperature": 0,
        "text": " I put no loop when I was trying to console log stuff.",
        "tokens": [
          51260,
          286,
          829,
          572,
          6367,
          562,
          286,
          390,
          1382,
          281,
          11076,
          3565,
          1507,
          13,
          51476
        ]
      },
      {
        "avg_logprob": -0.2592586086642358,
        "compression_ratio": 1.553921568627451,
        "end": 2362.0600000000004,
        "id": 803,
        "no_speech_prob": 0.00001012999018712435,
        "seek": 233930,
        "start": 2361.54,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51476,
          821,
          321,
          352,
          13,
          51502
        ]
      },
      {
        "avg_logprob": -0.2592586086642358,
        "compression_ratio": 1.553921568627451,
        "end": 2363.46,
        "id": 804,
        "no_speech_prob": 0.00001012999018712435,
        "seek": 233930,
        "start": 2362.0600000000004,
        "temperature": 0,
        "text": " OK, so things are going.",
        "tokens": [
          51502,
          2264,
          11,
          370,
          721,
          366,
          516,
          13,
          51572
        ]
      },
      {
        "avg_logprob": -0.2592586086642358,
        "compression_ratio": 1.553921568627451,
        "end": 2366.94,
        "id": 805,
        "no_speech_prob": 0.00001012999018712435,
        "seek": 233930,
        "start": 2363.46,
        "temperature": 0,
        "text": " And there's no, I don't have any, like I could look at.",
        "tokens": [
          51572,
          400,
          456,
          311,
          572,
          11,
          286,
          500,
          380,
          362,
          604,
          11,
          411,
          286,
          727,
          574,
          412,
          13,
          51746
        ]
      },
      {
        "avg_logprob": -0.26035404205322266,
        "compression_ratio": 1.518348623853211,
        "end": 2369.46,
        "id": 806,
        "no_speech_prob": 0.000009368715836899355,
        "seek": 236694,
        "start": 2366.94,
        "temperature": 0,
        "text": " That's m, m, m dot print.",
        "tokens": [
          50364,
          663,
          311,
          275,
          11,
          275,
          11,
          275,
          5893,
          4482,
          13,
          50490
        ]
      },
      {
        "avg_logprob": -0.26035404205322266,
        "compression_ratio": 1.518348623853211,
        "end": 2374.7000000000003,
        "id": 807,
        "no_speech_prob": 0.000009368715836899355,
        "seek": 236694,
        "start": 2373.3,
        "temperature": 0,
        "text": " So you can see it's changing.",
        "tokens": [
          50682,
          407,
          291,
          393,
          536,
          309,
          311,
          4473,
          13,
          50752
        ]
      },
      {
        "avg_logprob": -0.26035404205322266,
        "compression_ratio": 1.518348623853211,
        "end": 2376.26,
        "id": 808,
        "no_speech_prob": 0.000009368715836899355,
        "seek": 236694,
        "start": 2374.7000000000003,
        "temperature": 0,
        "text": " It's actually like training it.",
        "tokens": [
          50752,
          467,
          311,
          767,
          411,
          3097,
          309,
          13,
          50830
        ]
      },
      {
        "avg_logprob": -0.26035404205322266,
        "compression_ratio": 1.518348623853211,
        "end": 2377.7400000000002,
        "id": 809,
        "no_speech_prob": 0.000009368715836899355,
        "seek": 236694,
        "start": 2376.26,
        "temperature": 0,
        "text": " Like the value of m is changing.",
        "tokens": [
          50830,
          1743,
          264,
          2158,
          295,
          275,
          307,
          4473,
          13,
          50904
        ]
      },
      {
        "avg_logprob": -0.26035404205322266,
        "compression_ratio": 1.518348623853211,
        "end": 2379.5,
        "id": 810,
        "no_speech_prob": 0.000009368715836899355,
        "seek": 236694,
        "start": 2377.7400000000002,
        "temperature": 0,
        "text": " So everything's going and working.",
        "tokens": [
          50904,
          407,
          1203,
          311,
          516,
          293,
          1364,
          13,
          50992
        ]
      },
      {
        "avg_logprob": -0.26035404205322266,
        "compression_ratio": 1.518348623853211,
        "end": 2382.42,
        "id": 811,
        "no_speech_prob": 0.000009368715836899355,
        "seek": 236694,
        "start": 2379.5,
        "temperature": 0,
        "text": " The problem is I'm not seeing the results.",
        "tokens": [
          50992,
          440,
          1154,
          307,
          286,
          478,
          406,
          2577,
          264,
          3542,
          13,
          51138
        ]
      },
      {
        "avg_logprob": -0.26035404205322266,
        "compression_ratio": 1.518348623853211,
        "end": 2383.46,
        "id": 812,
        "no_speech_prob": 0.000009368715836899355,
        "seek": 236694,
        "start": 2382.42,
        "temperature": 0,
        "text": " Let's just check b.",
        "tokens": [
          51138,
          961,
          311,
          445,
          1520,
          272,
          13,
          51190
        ]
      },
      {
        "avg_logprob": -0.26035404205322266,
        "compression_ratio": 1.518348623853211,
        "end": 2390.34,
        "id": 813,
        "no_speech_prob": 0.000009368715836899355,
        "seek": 236694,
        "start": 2387.58,
        "temperature": 0,
        "text": " And I haven't done any memory cleanup.",
        "tokens": [
          51396,
          400,
          286,
          2378,
          380,
          1096,
          604,
          4675,
          40991,
          13,
          51534
        ]
      },
      {
        "avg_logprob": -0.26035404205322266,
        "compression_ratio": 1.518348623853211,
        "end": 2395.54,
        "id": 814,
        "no_speech_prob": 0.000009368715836899355,
        "seek": 236694,
        "start": 2390.34,
        "temperature": 0,
        "text": " So if I say memory dot num tensors, is that what it is?",
        "tokens": [
          51534,
          407,
          498,
          286,
          584,
          4675,
          5893,
          1031,
          10688,
          830,
          11,
          307,
          300,
          437,
          309,
          307,
          30,
          51794
        ]
      },
      {
        "avg_logprob": -0.26035404205322266,
        "compression_ratio": 1.518348623853211,
        "end": 2396.62,
        "id": 815,
        "no_speech_prob": 0.000009368715836899355,
        "seek": 236694,
        "start": 2395.54,
        "temperature": 0,
        "text": " What is it again?",
        "tokens": [
          51794,
          708,
          307,
          309,
          797,
          30,
          51848
        ]
      },
      {
        "avg_logprob": -0.24614968299865722,
        "compression_ratio": 1.7208480565371025,
        "end": 2401.02,
        "id": 816,
        "no_speech_prob": 0.000027969252187176608,
        "seek": 239662,
        "start": 2396.62,
        "temperature": 0,
        "text": " So let's look under memory management.",
        "tokens": [
          50364,
          407,
          718,
          311,
          574,
          833,
          4675,
          4592,
          13,
          50584
        ]
      },
      {
        "avg_logprob": -0.24614968299865722,
        "compression_ratio": 1.7208480565371025,
        "end": 2403.7799999999997,
        "id": 817,
        "no_speech_prob": 0.000027969252187176608,
        "seek": 239662,
        "start": 2401.02,
        "temperature": 0,
        "text": " Memory, oh, memory num, oh, this, tf.",
        "tokens": [
          50584,
          38203,
          11,
          1954,
          11,
          4675,
          1031,
          11,
          1954,
          11,
          341,
          11,
          256,
          69,
          13,
          50722
        ]
      },
      {
        "avg_logprob": -0.24614968299865722,
        "compression_ratio": 1.7208480565371025,
        "end": 2406.02,
        "id": 818,
        "no_speech_prob": 0.000027969252187176608,
        "seek": 239662,
        "start": 2403.7799999999997,
        "temperature": 0,
        "text": " So I know you can't see this, but this is what I want.",
        "tokens": [
          50722,
          407,
          286,
          458,
          291,
          393,
          380,
          536,
          341,
          11,
          457,
          341,
          307,
          437,
          286,
          528,
          13,
          50834
        ]
      },
      {
        "avg_logprob": -0.24614968299865722,
        "compression_ratio": 1.7208480565371025,
        "end": 2409.02,
        "id": 819,
        "no_speech_prob": 0.000027969252187176608,
        "seek": 239662,
        "start": 2406.02,
        "temperature": 0,
        "text": " I want to check how much, I want to check and see",
        "tokens": [
          50834,
          286,
          528,
          281,
          1520,
          577,
          709,
          11,
          286,
          528,
          281,
          1520,
          293,
          536,
          50984
        ]
      },
      {
        "avg_logprob": -0.24614968299865722,
        "compression_ratio": 1.7208480565371025,
        "end": 2412.22,
        "id": 820,
        "no_speech_prob": 0.000027969252187176608,
        "seek": 239662,
        "start": 2409.02,
        "temperature": 0,
        "text": " like how if I have cleaned up stuff.",
        "tokens": [
          50984,
          411,
          577,
          498,
          286,
          362,
          16146,
          493,
          1507,
          13,
          51144
        ]
      },
      {
        "avg_logprob": -0.24614968299865722,
        "compression_ratio": 1.7208480565371025,
        "end": 2414.74,
        "id": 821,
        "no_speech_prob": 0.000027969252187176608,
        "seek": 239662,
        "start": 2412.22,
        "temperature": 0,
        "text": " You can see I have 1,147 tensors.",
        "tokens": [
          51144,
          509,
          393,
          536,
          286,
          362,
          502,
          11,
          7271,
          22,
          10688,
          830,
          13,
          51270
        ]
      },
      {
        "avg_logprob": -0.24614968299865722,
        "compression_ratio": 1.7208480565371025,
        "end": 2416.18,
        "id": 822,
        "no_speech_prob": 0.000027969252187176608,
        "seek": 239662,
        "start": 2414.74,
        "temperature": 0,
        "text": " So I need to do the memory cleanup.",
        "tokens": [
          51270,
          407,
          286,
          643,
          281,
          360,
          264,
          4675,
          40991,
          13,
          51342
        ]
      },
      {
        "avg_logprob": -0.24614968299865722,
        "compression_ratio": 1.7208480565371025,
        "end": 2417.52,
        "id": 823,
        "no_speech_prob": 0.000027969252187176608,
        "seek": 239662,
        "start": 2416.18,
        "temperature": 0,
        "text": " I don't know, probably better practice",
        "tokens": [
          51342,
          286,
          500,
          380,
          458,
          11,
          1391,
          1101,
          3124,
          51409
        ]
      },
      {
        "avg_logprob": -0.24614968299865722,
        "compression_ratio": 1.7208480565371025,
        "end": 2419.22,
        "id": 824,
        "no_speech_prob": 0.000027969252187176608,
        "seek": 239662,
        "start": 2417.52,
        "temperature": 0,
        "text": " would be for me to clean up as I'm going,",
        "tokens": [
          51409,
          576,
          312,
          337,
          385,
          281,
          2541,
          493,
          382,
          286,
          478,
          516,
          11,
          51494
        ]
      },
      {
        "avg_logprob": -0.24614968299865722,
        "compression_ratio": 1.7208480565371025,
        "end": 2421.74,
        "id": 825,
        "no_speech_prob": 0.000027969252187176608,
        "seek": 239662,
        "start": 2419.22,
        "temperature": 0,
        "text": " but I'm kind of going to clean up at the end.",
        "tokens": [
          51494,
          457,
          286,
          478,
          733,
          295,
          516,
          281,
          2541,
          493,
          412,
          264,
          917,
          13,
          51620
        ]
      },
      {
        "avg_logprob": -0.24614968299865722,
        "compression_ratio": 1.7208480565371025,
        "end": 2425.38,
        "id": 826,
        "no_speech_prob": 0.000027969252187176608,
        "seek": 239662,
        "start": 2421.74,
        "temperature": 0,
        "text": " All right, so let's, I just want to click back here for a second.",
        "tokens": [
          51620,
          1057,
          558,
          11,
          370,
          718,
          311,
          11,
          286,
          445,
          528,
          281,
          2052,
          646,
          510,
          337,
          257,
          1150,
          13,
          51802
        ]
      },
      {
        "avg_logprob": -0.24614968299865722,
        "compression_ratio": 1.7208480565371025,
        "end": 2426.14,
        "id": 827,
        "no_speech_prob": 0.000027969252187176608,
        "seek": 239662,
        "start": 2425.38,
        "temperature": 0,
        "text": " Oops.",
        "tokens": [
          51802,
          21726,
          13,
          51840
        ]
      },
      {
        "avg_logprob": -0.19710309268864057,
        "compression_ratio": 1.728448275862069,
        "end": 2429.98,
        "id": 828,
        "no_speech_prob": 0.0000012679275869231788,
        "seek": 242614,
        "start": 2426.14,
        "temperature": 0,
        "text": " No, I'm just going to click no loop to shut this off.",
        "tokens": [
          50364,
          883,
          11,
          286,
          478,
          445,
          516,
          281,
          2052,
          572,
          6367,
          281,
          5309,
          341,
          766,
          13,
          50556
        ]
      },
      {
        "avg_logprob": -0.19710309268864057,
        "compression_ratio": 1.728448275862069,
        "end": 2430.8199999999997,
        "id": 829,
        "no_speech_prob": 0.0000012679275869231788,
        "seek": 242614,
        "start": 2429.98,
        "temperature": 0,
        "text": " And let's go here.",
        "tokens": [
          50556,
          400,
          718,
          311,
          352,
          510,
          13,
          50598
        ]
      },
      {
        "avg_logprob": -0.19710309268864057,
        "compression_ratio": 1.728448275862069,
        "end": 2431.8199999999997,
        "id": 830,
        "no_speech_prob": 0.0000012679275869231788,
        "seek": 242614,
        "start": 2430.8199999999997,
        "temperature": 0,
        "text": " So what do I need to do?",
        "tokens": [
          50598,
          407,
          437,
          360,
          286,
          643,
          281,
          360,
          30,
          50648
        ]
      },
      {
        "avg_logprob": -0.19710309268864057,
        "compression_ratio": 1.728448275862069,
        "end": 2434.8199999999997,
        "id": 831,
        "no_speech_prob": 0.0000012679275869231788,
        "seek": 242614,
        "start": 2431.8199999999997,
        "temperature": 0,
        "text": " Ah, I need to visualize what's going on.",
        "tokens": [
          50648,
          2438,
          11,
          286,
          643,
          281,
          23273,
          437,
          311,
          516,
          322,
          13,
          50798
        ]
      },
      {
        "avg_logprob": -0.19710309268864057,
        "compression_ratio": 1.728448275862069,
        "end": 2436.9,
        "id": 832,
        "no_speech_prob": 0.0000012679275869231788,
        "seek": 242614,
        "start": 2434.8199999999997,
        "temperature": 0,
        "text": " All right, so how do I do that?",
        "tokens": [
          50798,
          1057,
          558,
          11,
          370,
          577,
          360,
          286,
          360,
          300,
          30,
          50902
        ]
      },
      {
        "avg_logprob": -0.19710309268864057,
        "compression_ratio": 1.728448275862069,
        "end": 2440.62,
        "id": 833,
        "no_speech_prob": 0.0000012679275869231788,
        "seek": 242614,
        "start": 2436.9,
        "temperature": 0,
        "text": " So I need to draw a line.",
        "tokens": [
          50902,
          407,
          286,
          643,
          281,
          2642,
          257,
          1622,
          13,
          51088
        ]
      },
      {
        "avg_logprob": -0.19710309268864057,
        "compression_ratio": 1.728448275862069,
        "end": 2443.98,
        "id": 834,
        "no_speech_prob": 0.0000012679275869231788,
        "seek": 242614,
        "start": 2440.62,
        "temperature": 0,
        "text": " So the way that I would draw the line is first what I would do",
        "tokens": [
          51088,
          407,
          264,
          636,
          300,
          286,
          576,
          2642,
          264,
          1622,
          307,
          700,
          437,
          286,
          576,
          360,
          51256
        ]
      },
      {
        "avg_logprob": -0.19710309268864057,
        "compression_ratio": 1.728448275862069,
        "end": 2448.5,
        "id": 835,
        "no_speech_prob": 0.0000012679275869231788,
        "seek": 242614,
        "start": 2443.98,
        "temperature": 0,
        "text": " is all I really need is to give myself the x value of 0",
        "tokens": [
          51256,
          307,
          439,
          286,
          534,
          643,
          307,
          281,
          976,
          2059,
          264,
          2031,
          2158,
          295,
          1958,
          51482
        ]
      },
      {
        "avg_logprob": -0.19710309268864057,
        "compression_ratio": 1.728448275862069,
        "end": 2451.94,
        "id": 836,
        "no_speech_prob": 0.0000012679275869231788,
        "seek": 242614,
        "start": 2448.5,
        "temperature": 0,
        "text": " and the x value of 1, get the two y values,",
        "tokens": [
          51482,
          293,
          264,
          2031,
          2158,
          295,
          502,
          11,
          483,
          264,
          732,
          288,
          4190,
          11,
          51654
        ]
      },
      {
        "avg_logprob": -0.19710309268864057,
        "compression_ratio": 1.728448275862069,
        "end": 2454.3399999999997,
        "id": 837,
        "no_speech_prob": 0.0000012679275869231788,
        "seek": 242614,
        "start": 2451.94,
        "temperature": 0,
        "text": " and draw a line between those two points.",
        "tokens": [
          51654,
          293,
          2642,
          257,
          1622,
          1296,
          729,
          732,
          2793,
          13,
          51774
        ]
      },
      {
        "avg_logprob": -0.23165519149215133,
        "compression_ratio": 1.5895522388059702,
        "end": 2462.58,
        "id": 838,
        "no_speech_prob": 0.000005093703293823637,
        "seek": 245434,
        "start": 2454.34,
        "temperature": 0,
        "text": " So if I were to say, let x equal tf scalar.",
        "tokens": [
          50364,
          407,
          498,
          286,
          645,
          281,
          584,
          11,
          718,
          2031,
          2681,
          256,
          69,
          39684,
          13,
          50776
        ]
      },
      {
        "avg_logprob": -0.23165519149215133,
        "compression_ratio": 1.5895522388059702,
        "end": 2466.42,
        "id": 839,
        "no_speech_prob": 0.000005093703293823637,
        "seek": 245434,
        "start": 2462.58,
        "temperature": 0,
        "text": " This is silly for me to use the predict function.",
        "tokens": [
          50776,
          639,
          307,
          11774,
          337,
          385,
          281,
          764,
          264,
          6069,
          2445,
          13,
          50968
        ]
      },
      {
        "avg_logprob": -0.23165519149215133,
        "compression_ratio": 1.5895522388059702,
        "end": 2467.1800000000003,
        "id": 840,
        "no_speech_prob": 0.000005093703293823637,
        "seek": 245434,
        "start": 2466.42,
        "temperature": 0,
        "text": " Why not?",
        "tokens": [
          50968,
          1545,
          406,
          30,
          51006
        ]
      },
      {
        "avg_logprob": -0.23165519149215133,
        "compression_ratio": 1.5895522388059702,
        "end": 2467.94,
        "id": 841,
        "no_speech_prob": 0.000005093703293823637,
        "seek": 245434,
        "start": 2467.1800000000003,
        "temperature": 0,
        "text": " Why not?",
        "tokens": [
          51006,
          1545,
          406,
          30,
          51044
        ]
      },
      {
        "avg_logprob": -0.23165519149215133,
        "compression_ratio": 1.5895522388059702,
        "end": 2469.38,
        "id": 842,
        "no_speech_prob": 0.000005093703293823637,
        "seek": 245434,
        "start": 2467.94,
        "temperature": 0,
        "text": " Let's use the predict function.",
        "tokens": [
          51044,
          961,
          311,
          764,
          264,
          6069,
          2445,
          13,
          51116
        ]
      },
      {
        "avg_logprob": -0.23165519149215133,
        "compression_ratio": 1.5895522388059702,
        "end": 2471.5,
        "id": 843,
        "no_speech_prob": 0.000005093703293823637,
        "seek": 245434,
        "start": 2469.38,
        "temperature": 0,
        "text": " tf scalar is 0.",
        "tokens": [
          51116,
          256,
          69,
          39684,
          307,
          1958,
          13,
          51222
        ]
      },
      {
        "avg_logprob": -0.23165519149215133,
        "compression_ratio": 1.5895522388059702,
        "end": 2474.34,
        "id": 844,
        "no_speech_prob": 0.000005093703293823637,
        "seek": 245434,
        "start": 2471.5,
        "temperature": 0,
        "text": " So x1 is tf scalar 0.",
        "tokens": [
          51222,
          407,
          2031,
          16,
          307,
          256,
          69,
          39684,
          1958,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.23165519149215133,
        "compression_ratio": 1.5895522388059702,
        "end": 2482.06,
        "id": 845,
        "no_speech_prob": 0.000005093703293823637,
        "seek": 245434,
        "start": 2474.34,
        "temperature": 0,
        "text": " y1 equals tf equals predict x1.",
        "tokens": [
          51364,
          288,
          16,
          6915,
          256,
          69,
          6915,
          6069,
          2031,
          16,
          13,
          51750
        ]
      },
      {
        "avg_logprob": -0.20188431191233408,
        "compression_ratio": 1.5137614678899083,
        "end": 2486.18,
        "id": 846,
        "no_speech_prob": 0.000025867428121273406,
        "seek": 248206,
        "start": 2482.06,
        "temperature": 0,
        "text": " x2 equals tf scalar 1.",
        "tokens": [
          50364,
          2031,
          17,
          6915,
          256,
          69,
          39684,
          502,
          13,
          50570
        ]
      },
      {
        "avg_logprob": -0.20188431191233408,
        "compression_ratio": 1.5137614678899083,
        "end": 2490.2999999999997,
        "id": 847,
        "no_speech_prob": 0.000025867428121273406,
        "seek": 248206,
        "start": 2486.18,
        "temperature": 0,
        "text": " y2 equals predict x2.",
        "tokens": [
          50570,
          288,
          17,
          6915,
          6069,
          2031,
          17,
          13,
          50776
        ]
      },
      {
        "avg_logprob": -0.20188431191233408,
        "compression_ratio": 1.5137614678899083,
        "end": 2492.9,
        "id": 848,
        "no_speech_prob": 0.000025867428121273406,
        "seek": 248206,
        "start": 2490.2999999999997,
        "temperature": 0,
        "text": " So this should give me, I mean, it's a little bit silly for me",
        "tokens": [
          50776,
          407,
          341,
          820,
          976,
          385,
          11,
          286,
          914,
          11,
          309,
          311,
          257,
          707,
          857,
          11774,
          337,
          385,
          50906
        ]
      },
      {
        "avg_logprob": -0.20188431191233408,
        "compression_ratio": 1.5137614678899083,
        "end": 2496.06,
        "id": 849,
        "no_speech_prob": 0.000025867428121273406,
        "seek": 248206,
        "start": 2492.9,
        "temperature": 0,
        "text": " to not just do this, keep an extra copy of like m and b",
        "tokens": [
          50906,
          281,
          406,
          445,
          360,
          341,
          11,
          1066,
          364,
          2857,
          5055,
          295,
          411,
          275,
          293,
          272,
          51064
        ]
      },
      {
        "avg_logprob": -0.20188431191233408,
        "compression_ratio": 1.5137614678899083,
        "end": 2497.34,
        "id": 850,
        "no_speech_prob": 0.000025867428121273406,
        "seek": 248206,
        "start": 2496.06,
        "temperature": 0,
        "text": " as regular numbers.",
        "tokens": [
          51064,
          382,
          3890,
          3547,
          13,
          51128
        ]
      },
      {
        "avg_logprob": -0.20188431191233408,
        "compression_ratio": 1.5137614678899083,
        "end": 2498.86,
        "id": 851,
        "no_speech_prob": 0.000025867428121273406,
        "seek": 248206,
        "start": 2497.34,
        "temperature": 0,
        "text": " But let's keep going with this.",
        "tokens": [
          51128,
          583,
          718,
          311,
          1066,
          516,
          365,
          341,
          13,
          51204
        ]
      },
      {
        "avg_logprob": -0.20188431191233408,
        "compression_ratio": 1.5137614678899083,
        "end": 2500.18,
        "id": 852,
        "no_speech_prob": 0.000025867428121273406,
        "seek": 248206,
        "start": 2498.86,
        "temperature": 0,
        "text": " Will this work?",
        "tokens": [
          51204,
          3099,
          341,
          589,
          30,
          51270
        ]
      },
      {
        "avg_logprob": -0.20188431191233408,
        "compression_ratio": 1.5137614678899083,
        "end": 2504.1,
        "id": 853,
        "no_speech_prob": 0.000025867428121273406,
        "seek": 248206,
        "start": 2500.18,
        "temperature": 0,
        "text": " Is it going to be able to take a scalar and make a 1D tensor?",
        "tokens": [
          51270,
          1119,
          309,
          516,
          281,
          312,
          1075,
          281,
          747,
          257,
          39684,
          293,
          652,
          257,
          502,
          35,
          40863,
          30,
          51466
        ]
      },
      {
        "avg_logprob": -0.20188431191233408,
        "compression_ratio": 1.5137614678899083,
        "end": 2505.5,
        "id": 854,
        "no_speech_prob": 0.000025867428121273406,
        "seek": 248206,
        "start": 2504.1,
        "temperature": 0,
        "text": " I think so.",
        "tokens": [
          51466,
          286,
          519,
          370,
          13,
          51536
        ]
      },
      {
        "avg_logprob": -0.20188431191233408,
        "compression_ratio": 1.5137614678899083,
        "end": 2507.66,
        "id": 855,
        "no_speech_prob": 0.000025867428121273406,
        "seek": 248206,
        "start": 2505.5,
        "temperature": 0,
        "text": " So let me just see here.",
        "tokens": [
          51536,
          407,
          718,
          385,
          445,
          536,
          510,
          13,
          51644
        ]
      },
      {
        "avg_logprob": -0.2803395509719849,
        "compression_ratio": 1.329192546583851,
        "end": 2512.42,
        "id": 856,
        "no_speech_prob": 0.00701175956055522,
        "seek": 250766,
        "start": 2507.66,
        "temperature": 0,
        "text": " Let me do x1.print, y1.print.",
        "tokens": [
          50364,
          961,
          385,
          360,
          2031,
          16,
          13,
          14030,
          11,
          288,
          16,
          13,
          14030,
          13,
          50602
        ]
      },
      {
        "avg_logprob": -0.2803395509719849,
        "compression_ratio": 1.329192546583851,
        "end": 2515.2599999999998,
        "id": 857,
        "no_speech_prob": 0.00701175956055522,
        "seek": 250766,
        "start": 2512.42,
        "temperature": 0,
        "text": " So let's see that.",
        "tokens": [
          50602,
          407,
          718,
          311,
          536,
          300,
          13,
          50744
        ]
      },
      {
        "avg_logprob": -0.2803395509719849,
        "compression_ratio": 1.329192546583851,
        "end": 2519.2999999999997,
        "id": 858,
        "no_speech_prob": 0.00701175956055522,
        "seek": 250766,
        "start": 2515.2599999999998,
        "temperature": 0,
        "text": " Tensor 1D requires values to be a flat typed array.",
        "tokens": [
          50744,
          34306,
          502,
          35,
          7029,
          4190,
          281,
          312,
          257,
          4962,
          33941,
          10225,
          13,
          50946
        ]
      },
      {
        "avg_logprob": -0.2803395509719849,
        "compression_ratio": 1.329192546583851,
        "end": 2524.54,
        "id": 859,
        "no_speech_prob": 0.00701175956055522,
        "seek": 250766,
        "start": 2519.2999999999997,
        "temperature": 0,
        "text": " So I could reshape.",
        "tokens": [
          50946,
          407,
          286,
          727,
          725,
          42406,
          13,
          51208
        ]
      },
      {
        "avg_logprob": -0.2803395509719849,
        "compression_ratio": 1.329192546583851,
        "end": 2530.58,
        "id": 860,
        "no_speech_prob": 0.00701175956055522,
        "seek": 250766,
        "start": 2528.18,
        "temperature": 0,
        "text": " Yes, good point.",
        "tokens": [
          51390,
          1079,
          11,
          665,
          935,
          13,
          51510
        ]
      },
      {
        "avg_logprob": -0.2803395509719849,
        "compression_ratio": 1.329192546583851,
        "end": 2531.22,
        "id": 861,
        "no_speech_prob": 0.00701175956055522,
        "seek": 250766,
        "start": 2530.58,
        "temperature": 0,
        "text": " Minimize.",
        "tokens": [
          51510,
          2829,
          43890,
          13,
          51542
        ]
      },
      {
        "avg_logprob": -0.2803395509719849,
        "compression_ratio": 1.329192546583851,
        "end": 2532.98,
        "id": 862,
        "no_speech_prob": 0.00701175956055522,
        "seek": 250766,
        "start": 2531.22,
        "temperature": 0,
        "text": " Sorry.",
        "tokens": [
          51542,
          4919,
          13,
          51630
        ]
      },
      {
        "avg_logprob": -0.2803395509719849,
        "compression_ratio": 1.329192546583851,
        "end": 2535.48,
        "id": 863,
        "no_speech_prob": 0.00701175956055522,
        "seek": 250766,
        "start": 2532.98,
        "temperature": 0,
        "text": " Sorry, I started looking at the chat, which I shouldn't do.",
        "tokens": [
          51630,
          4919,
          11,
          286,
          1409,
          1237,
          412,
          264,
          5081,
          11,
          597,
          286,
          4659,
          380,
          360,
          13,
          51755
        ]
      },
      {
        "avg_logprob": -0.30709877720585577,
        "compression_ratio": 1.6339285714285714,
        "end": 2537.28,
        "id": 864,
        "no_speech_prob": 0.0011160062858834863,
        "seek": 253548,
        "start": 2535.48,
        "temperature": 0,
        "text": " Pause for a second for a little edit point.",
        "tokens": [
          50364,
          31973,
          337,
          257,
          1150,
          337,
          257,
          707,
          8129,
          935,
          13,
          50454
        ]
      },
      {
        "avg_logprob": -0.30709877720585577,
        "compression_ratio": 1.6339285714285714,
        "end": 2547.64,
        "id": 865,
        "no_speech_prob": 0.0011160062858834863,
        "seek": 253548,
        "start": 2546.12,
        "temperature": 0,
        "text": " Alex Prats Ferrer writes, you need",
        "tokens": [
          50896,
          5202,
          2114,
          1720,
          10728,
          9797,
          13657,
          11,
          291,
          643,
          50972
        ]
      },
      {
        "avg_logprob": -0.30709877720585577,
        "compression_ratio": 1.6339285714285714,
        "end": 2548.92,
        "id": 866,
        "no_speech_prob": 0.0011160062858834863,
        "seek": 253548,
        "start": 2547.64,
        "temperature": 0,
        "text": " to average the squared error.",
        "tokens": [
          50972,
          281,
          4274,
          264,
          8889,
          6713,
          13,
          51036
        ]
      },
      {
        "avg_logprob": -0.30709877720585577,
        "compression_ratio": 1.6339285714285714,
        "end": 2549.92,
        "id": 867,
        "no_speech_prob": 0.0011160062858834863,
        "seek": 253548,
        "start": 2548.92,
        "temperature": 0,
        "text": " I don't think I need to average it",
        "tokens": [
          51036,
          286,
          500,
          380,
          519,
          286,
          643,
          281,
          4274,
          309,
          51086
        ]
      },
      {
        "avg_logprob": -0.30709877720585577,
        "compression_ratio": 1.6339285714285714,
        "end": 2551.8,
        "id": 868,
        "no_speech_prob": 0.0011160062858834863,
        "seek": 253548,
        "start": 2549.92,
        "temperature": 0,
        "text": " because I have the dot mean function.",
        "tokens": [
          51086,
          570,
          286,
          362,
          264,
          5893,
          914,
          2445,
          13,
          51180
        ]
      },
      {
        "avg_logprob": -0.30709877720585577,
        "compression_ratio": 1.6339285714285714,
        "end": 2553.88,
        "id": 869,
        "no_speech_prob": 0.0011160062858834863,
        "seek": 253548,
        "start": 2551.8,
        "temperature": 0,
        "text": " So that takes the average automatically, I think.",
        "tokens": [
          51180,
          407,
          300,
          2516,
          264,
          4274,
          6772,
          11,
          286,
          519,
          13,
          51284
        ]
      },
      {
        "avg_logprob": -0.30709877720585577,
        "compression_ratio": 1.6339285714285714,
        "end": 2557.08,
        "id": 870,
        "no_speech_prob": 0.0011160062858834863,
        "seek": 253548,
        "start": 2556.28,
        "temperature": 0,
        "text": " So let me think.",
        "tokens": [
          51404,
          407,
          718,
          385,
          519,
          13,
          51444
        ]
      },
      {
        "avg_logprob": -0.30709877720585577,
        "compression_ratio": 1.6339285714285714,
        "end": 2559.4,
        "id": 871,
        "no_speech_prob": 0.0011160062858834863,
        "seek": 253548,
        "start": 2557.08,
        "temperature": 0,
        "text": " What might be better is for me to just,",
        "tokens": [
          51444,
          708,
          1062,
          312,
          1101,
          307,
          337,
          385,
          281,
          445,
          11,
          51560
        ]
      },
      {
        "avg_logprob": -0.30709877720585577,
        "compression_ratio": 1.6339285714285714,
        "end": 2562.2,
        "id": 872,
        "no_speech_prob": 0.0011160062858834863,
        "seek": 253548,
        "start": 2559.4,
        "temperature": 0,
        "text": " should I just, I should just bite the bullet",
        "tokens": [
          51560,
          820,
          286,
          445,
          11,
          286,
          820,
          445,
          7988,
          264,
          11632,
          51700
        ]
      },
      {
        "avg_logprob": -0.30709877720585577,
        "compression_ratio": 1.6339285714285714,
        "end": 2564.76,
        "id": 873,
        "no_speech_prob": 0.0011160062858834863,
        "seek": 253548,
        "start": 2562.2,
        "temperature": 0,
        "text": " and get the m and b values back.",
        "tokens": [
          51700,
          293,
          483,
          264,
          275,
          293,
          272,
          4190,
          646,
          13,
          51828
        ]
      },
      {
        "avg_logprob": -0.3104728185213529,
        "compression_ratio": 1.5611111111111111,
        "end": 2566.1400000000003,
        "id": 874,
        "no_speech_prob": 0.000007071894742693985,
        "seek": 256476,
        "start": 2565.6400000000003,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          50408,
          865,
          13,
          50433
        ]
      },
      {
        "avg_logprob": -0.3104728185213529,
        "compression_ratio": 1.5611111111111111,
        "end": 2572.2400000000002,
        "id": 875,
        "no_speech_prob": 0.000007071894742693985,
        "seek": 256476,
        "start": 2570.36,
        "temperature": 0,
        "text": " I could reshape this.",
        "tokens": [
          50644,
          286,
          727,
          725,
          42406,
          341,
          13,
          50738
        ]
      },
      {
        "avg_logprob": -0.3104728185213529,
        "compression_ratio": 1.5611111111111111,
        "end": 2573.88,
        "id": 876,
        "no_speech_prob": 0.000007071894742693985,
        "seek": 256476,
        "start": 2572.2400000000002,
        "temperature": 0,
        "text": " Oh, no, this is silly.",
        "tokens": [
          50738,
          876,
          11,
          572,
          11,
          341,
          307,
          11774,
          13,
          50820
        ]
      },
      {
        "avg_logprob": -0.3104728185213529,
        "compression_ratio": 1.5611111111111111,
        "end": 2576.5200000000004,
        "id": 877,
        "no_speech_prob": 0.000007071894742693985,
        "seek": 256476,
        "start": 2573.88,
        "temperature": 0,
        "text": " I can just do this.",
        "tokens": [
          50820,
          286,
          393,
          445,
          360,
          341,
          13,
          50952
        ]
      },
      {
        "avg_logprob": -0.3104728185213529,
        "compression_ratio": 1.5611111111111111,
        "end": 2577,
        "id": 878,
        "no_speech_prob": 0.000007071894742693985,
        "seek": 256476,
        "start": 2576.5200000000004,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          50952,
          6962,
          322,
          13,
          50976
        ]
      },
      {
        "avg_logprob": -0.3104728185213529,
        "compression_ratio": 1.5611111111111111,
        "end": 2586.76,
        "id": 879,
        "no_speech_prob": 0.000007071894742693985,
        "seek": 256476,
        "start": 2580.6000000000004,
        "temperature": 0,
        "text": " So one thing I could do is instead of making it a scalar,",
        "tokens": [
          51156,
          407,
          472,
          551,
          286,
          727,
          360,
          307,
          2602,
          295,
          1455,
          309,
          257,
          39684,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.3104728185213529,
        "compression_ratio": 1.5611111111111111,
        "end": 2588.2400000000002,
        "id": 880,
        "no_speech_prob": 0.000007071894742693985,
        "seek": 256476,
        "start": 2586.76,
        "temperature": 0,
        "text": " I can make it a 1D tensor.",
        "tokens": [
          51464,
          286,
          393,
          652,
          309,
          257,
          502,
          35,
          40863,
          13,
          51538
        ]
      },
      {
        "avg_logprob": -0.3104728185213529,
        "compression_ratio": 1.5611111111111111,
        "end": 2589.7200000000003,
        "id": 881,
        "no_speech_prob": 0.000007071894742693985,
        "seek": 256476,
        "start": 2588.2400000000002,
        "temperature": 0,
        "text": " That's what it wants.",
        "tokens": [
          51538,
          663,
          311,
          437,
          309,
          2738,
          13,
          51612
        ]
      },
      {
        "avg_logprob": -0.3104728185213529,
        "compression_ratio": 1.5611111111111111,
        "end": 2590.84,
        "id": 882,
        "no_speech_prob": 0.000007071894742693985,
        "seek": 256476,
        "start": 2589.7200000000003,
        "temperature": 0,
        "text": " And do the same thing here.",
        "tokens": [
          51612,
          400,
          360,
          264,
          912,
          551,
          510,
          13,
          51668
        ]
      },
      {
        "avg_logprob": -0.3104728185213529,
        "compression_ratio": 1.5611111111111111,
        "end": 2592.6800000000003,
        "id": 883,
        "no_speech_prob": 0.000007071894742693985,
        "seek": 256476,
        "start": 2590.84,
        "temperature": 0,
        "text": " And I have to put it in as an array then,",
        "tokens": [
          51668,
          400,
          286,
          362,
          281,
          829,
          309,
          294,
          382,
          364,
          10225,
          550,
          11,
          51760
        ]
      },
      {
        "avg_logprob": -0.3104728185213529,
        "compression_ratio": 1.5611111111111111,
        "end": 2594,
        "id": 884,
        "no_speech_prob": 0.000007071894742693985,
        "seek": 256476,
        "start": 2592.6800000000003,
        "temperature": 0,
        "text": " but it's just one value.",
        "tokens": [
          51760,
          457,
          309,
          311,
          445,
          472,
          2158,
          13,
          51826
        ]
      },
      {
        "avg_logprob": -0.23791426532673385,
        "compression_ratio": 1.5133689839572193,
        "end": 2595.4,
        "id": 885,
        "no_speech_prob": 0.0000033405365229555173,
        "seek": 259400,
        "start": 2594.04,
        "temperature": 0,
        "text": " Oh, this is so silly.",
        "tokens": [
          50366,
          876,
          11,
          341,
          307,
          370,
          11774,
          13,
          50434
        ]
      },
      {
        "avg_logprob": -0.23791426532673385,
        "compression_ratio": 1.5133689839572193,
        "end": 2600.44,
        "id": 886,
        "no_speech_prob": 0.0000033405365229555173,
        "seek": 259400,
        "start": 2595.4,
        "temperature": 0,
        "text": " Why am I doing x1 and, I could just do this, right?",
        "tokens": [
          50434,
          1545,
          669,
          286,
          884,
          2031,
          16,
          293,
          11,
          286,
          727,
          445,
          360,
          341,
          11,
          558,
          30,
          50686
        ]
      },
      {
        "avg_logprob": -0.23791426532673385,
        "compression_ratio": 1.5133689839572193,
        "end": 2603.68,
        "id": 887,
        "no_speech_prob": 0.0000033405365229555173,
        "seek": 259400,
        "start": 2600.44,
        "temperature": 0,
        "text": " Xs, once again, can I use xs?",
        "tokens": [
          50686,
          1783,
          82,
          11,
          1564,
          797,
          11,
          393,
          286,
          764,
          2031,
          82,
          30,
          50848
        ]
      },
      {
        "avg_logprob": -0.23791426532673385,
        "compression_ratio": 1.5133689839572193,
        "end": 2605.2,
        "id": 888,
        "no_speech_prob": 0.0000033405365229555173,
        "seek": 259400,
        "start": 2603.68,
        "temperature": 0,
        "text": " Yeah, yeah, yeah.",
        "tokens": [
          50848,
          865,
          11,
          1338,
          11,
          1338,
          13,
          50924
        ]
      },
      {
        "avg_logprob": -0.23791426532673385,
        "compression_ratio": 1.5133689839572193,
        "end": 2608.68,
        "id": 889,
        "no_speech_prob": 0.0000033405365229555173,
        "seek": 259400,
        "start": 2605.2,
        "temperature": 0,
        "text": " So I could just do it with 0 and 1.",
        "tokens": [
          50924,
          407,
          286,
          727,
          445,
          360,
          309,
          365,
          1958,
          293,
          502,
          13,
          51098
        ]
      },
      {
        "avg_logprob": -0.23791426532673385,
        "compression_ratio": 1.5133689839572193,
        "end": 2615.4,
        "id": 890,
        "no_speech_prob": 0.0000033405365229555173,
        "seek": 259400,
        "start": 2608.68,
        "temperature": 0,
        "text": " Constant xs and then constant ys equals predict xs.",
        "tokens": [
          51098,
          37413,
          2031,
          82,
          293,
          550,
          5754,
          288,
          82,
          6915,
          6069,
          2031,
          82,
          13,
          51434
        ]
      },
      {
        "avg_logprob": -0.23791426532673385,
        "compression_ratio": 1.5133689839572193,
        "end": 2617.44,
        "id": 891,
        "no_speech_prob": 0.0000033405365229555173,
        "seek": 259400,
        "start": 2615.4,
        "temperature": 0,
        "text": " So I could have both these points now.",
        "tokens": [
          51434,
          407,
          286,
          727,
          362,
          1293,
          613,
          2793,
          586,
          13,
          51536
        ]
      },
      {
        "avg_logprob": -0.23791426532673385,
        "compression_ratio": 1.5133689839572193,
        "end": 2623.84,
        "id": 892,
        "no_speech_prob": 0.0000033405365229555173,
        "seek": 259400,
        "start": 2617.44,
        "temperature": 0,
        "text": " Then let's say xs.print, ys.print.",
        "tokens": [
          51536,
          1396,
          718,
          311,
          584,
          2031,
          82,
          13,
          14030,
          11,
          288,
          82,
          13,
          14030,
          13,
          51856
        ]
      },
      {
        "avg_logprob": -0.2588206890017487,
        "compression_ratio": 1.4827586206896552,
        "end": 2624.6400000000003,
        "id": 893,
        "no_speech_prob": 0.000010783307516248897,
        "seek": 262384,
        "start": 2623.84,
        "temperature": 0,
        "text": " Let's look at that.",
        "tokens": [
          50364,
          961,
          311,
          574,
          412,
          300,
          13,
          50404
        ]
      },
      {
        "avg_logprob": -0.2588206890017487,
        "compression_ratio": 1.4827586206896552,
        "end": 2625.6800000000003,
        "id": 894,
        "no_speech_prob": 0.000010783307516248897,
        "seek": 262384,
        "start": 2624.6400000000003,
        "temperature": 0,
        "text": " Let's see if this works.",
        "tokens": [
          50404,
          961,
          311,
          536,
          498,
          341,
          1985,
          13,
          50456
        ]
      },
      {
        "avg_logprob": -0.2588206890017487,
        "compression_ratio": 1.4827586206896552,
        "end": 2631.04,
        "id": 895,
        "no_speech_prob": 0.000010783307516248897,
        "seek": 262384,
        "start": 2628.08,
        "temperature": 0,
        "text": " Predict is not defined because my E key doesn't work,",
        "tokens": [
          50576,
          430,
          24945,
          307,
          406,
          7642,
          570,
          452,
          462,
          2141,
          1177,
          380,
          589,
          11,
          50724
        ]
      },
      {
        "avg_logprob": -0.2588206890017487,
        "compression_ratio": 1.4827586206896552,
        "end": 2634.4,
        "id": 896,
        "no_speech_prob": 0.000010783307516248897,
        "seek": 262384,
        "start": 2631.04,
        "temperature": 0,
        "text": " and I have to type it several times.",
        "tokens": [
          50724,
          293,
          286,
          362,
          281,
          2010,
          309,
          2940,
          1413,
          13,
          50892
        ]
      },
      {
        "avg_logprob": -0.2588206890017487,
        "compression_ratio": 1.4827586206896552,
        "end": 2638.92,
        "id": 897,
        "no_speech_prob": 0.000010783307516248897,
        "seek": 262384,
        "start": 2634.4,
        "temperature": 0,
        "text": " Tensor 1D requires values to be a flat typed array.",
        "tokens": [
          50892,
          34306,
          502,
          35,
          7029,
          4190,
          281,
          312,
          257,
          4962,
          33941,
          10225,
          13,
          51118
        ]
      },
      {
        "avg_logprob": -0.2588206890017487,
        "compression_ratio": 1.4827586206896552,
        "end": 2642.6400000000003,
        "id": 898,
        "no_speech_prob": 0.000010783307516248897,
        "seek": 262384,
        "start": 2638.92,
        "temperature": 0,
        "text": " Oh, silly, silly me.",
        "tokens": [
          51118,
          876,
          11,
          11774,
          11,
          11774,
          385,
          13,
          51304
        ]
      },
      {
        "avg_logprob": -0.2588206890017487,
        "compression_ratio": 1.4827586206896552,
        "end": 2644.56,
        "id": 899,
        "no_speech_prob": 0.000010783307516248897,
        "seek": 262384,
        "start": 2642.6400000000003,
        "temperature": 0,
        "text": " Predict doesn't want a tensor.",
        "tokens": [
          51304,
          430,
          24945,
          1177,
          380,
          528,
          257,
          40863,
          13,
          51400
        ]
      },
      {
        "avg_logprob": -0.2588206890017487,
        "compression_ratio": 1.4827586206896552,
        "end": 2647.7200000000003,
        "id": 900,
        "no_speech_prob": 0.000010783307516248897,
        "seek": 262384,
        "start": 2644.56,
        "temperature": 0,
        "text": " Oh, it wants this.",
        "tokens": [
          51400,
          876,
          11,
          309,
          2738,
          341,
          13,
          51558
        ]
      },
      {
        "avg_logprob": -0.2484832300203983,
        "compression_ratio": 1.566326530612245,
        "end": 2656.48,
        "id": 901,
        "no_speech_prob": 0.00011591928341658786,
        "seek": 264772,
        "start": 2647.72,
        "temperature": 0,
        "text": " So line x equal, let me just, this is a little bit silly,",
        "tokens": [
          50364,
          407,
          1622,
          2031,
          2681,
          11,
          718,
          385,
          445,
          11,
          341,
          307,
          257,
          707,
          857,
          11774,
          11,
          50802
        ]
      },
      {
        "avg_logprob": -0.2484832300203983,
        "compression_ratio": 1.566326530612245,
        "end": 2658.72,
        "id": 902,
        "no_speech_prob": 0.00011591928341658786,
        "seek": 264772,
        "start": 2656.48,
        "temperature": 0,
        "text": " but I'm going to do this.",
        "tokens": [
          50802,
          457,
          286,
          478,
          516,
          281,
          360,
          341,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2484832300203983,
        "compression_ratio": 1.566326530612245,
        "end": 2661.56,
        "id": 903,
        "no_speech_prob": 0.00011591928341658786,
        "seek": 264772,
        "start": 2658.72,
        "temperature": 0,
        "text": " So I'm going to make the, oh, but I",
        "tokens": [
          50914,
          407,
          286,
          478,
          516,
          281,
          652,
          264,
          11,
          1954,
          11,
          457,
          286,
          51056
        ]
      },
      {
        "avg_logprob": -0.2484832300203983,
        "compression_ratio": 1.566326530612245,
        "end": 2663.4399999999996,
        "id": 904,
        "no_speech_prob": 0.00011591928341658786,
        "seek": 264772,
        "start": 2661.56,
        "temperature": 0,
        "text": " don't need to know the xs.",
        "tokens": [
          51056,
          500,
          380,
          643,
          281,
          458,
          264,
          2031,
          82,
          13,
          51150
        ]
      },
      {
        "avg_logprob": -0.2484832300203983,
        "compression_ratio": 1.566326530612245,
        "end": 2668.52,
        "id": 905,
        "no_speech_prob": 0.00011591928341658786,
        "seek": 264772,
        "start": 2663.4399999999996,
        "temperature": 0,
        "text": " I don't need to have the xs as a tensor because, yeah.",
        "tokens": [
          51150,
          286,
          500,
          380,
          643,
          281,
          362,
          264,
          2031,
          82,
          382,
          257,
          40863,
          570,
          11,
          1338,
          13,
          51404
        ]
      },
      {
        "avg_logprob": -0.2484832300203983,
        "compression_ratio": 1.566326530612245,
        "end": 2670.7599999999998,
        "id": 906,
        "no_speech_prob": 0.00011591928341658786,
        "seek": 264772,
        "start": 2668.52,
        "temperature": 0,
        "text": " Sorry, everybody.",
        "tokens": [
          51404,
          4919,
          11,
          2201,
          13,
          51516
        ]
      },
      {
        "avg_logprob": -0.2484832300203983,
        "compression_ratio": 1.566326530612245,
        "end": 2672.3999999999996,
        "id": 907,
        "no_speech_prob": 0.00011591928341658786,
        "seek": 264772,
        "start": 2670.7599999999998,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51516,
          821,
          321,
          352,
          13,
          51598
        ]
      },
      {
        "avg_logprob": -0.2484832300203983,
        "compression_ratio": 1.566326530612245,
        "end": 2675.72,
        "id": 908,
        "no_speech_prob": 0.00011591928341658786,
        "seek": 264772,
        "start": 2672.3999999999996,
        "temperature": 0,
        "text": " My predict function, I totally forgot.",
        "tokens": [
          51598,
          1222,
          6069,
          2445,
          11,
          286,
          3879,
          5298,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2484832300203983,
        "compression_ratio": 1.566326530612245,
        "end": 2677,
        "id": 909,
        "no_speech_prob": 0.00011591928341658786,
        "seek": 264772,
        "start": 2675.72,
        "temperature": 0,
        "text": " Already, see, this is just, there's",
        "tokens": [
          51764,
          23741,
          11,
          536,
          11,
          341,
          307,
          445,
          11,
          456,
          311,
          51828
        ]
      },
      {
        "avg_logprob": -0.26772412131814394,
        "compression_ratio": 1.6319702602230484,
        "end": 2678.72,
        "id": 910,
        "no_speech_prob": 0.0000961021869443357,
        "seek": 267700,
        "start": 2677,
        "temperature": 0,
        "text": " so many different ways you could do this.",
        "tokens": [
          50364,
          370,
          867,
          819,
          2098,
          291,
          727,
          360,
          341,
          13,
          50450
        ]
      },
      {
        "avg_logprob": -0.26772412131814394,
        "compression_ratio": 1.6319702602230484,
        "end": 2681.4,
        "id": 911,
        "no_speech_prob": 0.0000961021869443357,
        "seek": 267700,
        "start": 2678.72,
        "temperature": 0,
        "text": " I could enforce you to convert to a tensor",
        "tokens": [
          50450,
          286,
          727,
          24825,
          291,
          281,
          7620,
          281,
          257,
          40863,
          50584
        ]
      },
      {
        "avg_logprob": -0.26772412131814394,
        "compression_ratio": 1.6319702602230484,
        "end": 2683.76,
        "id": 912,
        "no_speech_prob": 0.0000961021869443357,
        "seek": 267700,
        "start": 2681.4,
        "temperature": 0,
        "text": " before you pass it into predict, but I've just,",
        "tokens": [
          50584,
          949,
          291,
          1320,
          309,
          666,
          6069,
          11,
          457,
          286,
          600,
          445,
          11,
          50702
        ]
      },
      {
        "avg_logprob": -0.26772412131814394,
        "compression_ratio": 1.6319702602230484,
        "end": 2686.16,
        "id": 913,
        "no_speech_prob": 0.0000961021869443357,
        "seek": 267700,
        "start": 2683.76,
        "temperature": 0,
        "text": " a lot of these decisions are completely arbitrary.",
        "tokens": [
          50702,
          257,
          688,
          295,
          613,
          5327,
          366,
          2584,
          23211,
          13,
          50822
        ]
      },
      {
        "avg_logprob": -0.26772412131814394,
        "compression_ratio": 1.6319702602230484,
        "end": 2687.96,
        "id": 914,
        "no_speech_prob": 0.0000961021869443357,
        "seek": 267700,
        "start": 2686.16,
        "temperature": 0,
        "text": " So you might have a better way of doing it,",
        "tokens": [
          50822,
          407,
          291,
          1062,
          362,
          257,
          1101,
          636,
          295,
          884,
          309,
          11,
          50912
        ]
      },
      {
        "avg_logprob": -0.26772412131814394,
        "compression_ratio": 1.6319702602230484,
        "end": 2689.76,
        "id": 915,
        "no_speech_prob": 0.0000961021869443357,
        "seek": 267700,
        "start": 2687.96,
        "temperature": 0,
        "text": " but still I'm going to do this.",
        "tokens": [
          50912,
          457,
          920,
          286,
          478,
          516,
          281,
          360,
          341,
          13,
          51002
        ]
      },
      {
        "avg_logprob": -0.26772412131814394,
        "compression_ratio": 1.6319702602230484,
        "end": 2692.88,
        "id": 916,
        "no_speech_prob": 0.0000961021869443357,
        "seek": 267700,
        "start": 2689.76,
        "temperature": 0,
        "text": " So now I have the xs and the ys, and I don't even",
        "tokens": [
          51002,
          407,
          586,
          286,
          362,
          264,
          2031,
          82,
          293,
          264,
          288,
          82,
          11,
          293,
          286,
          500,
          380,
          754,
          51158
        ]
      },
      {
        "avg_logprob": -0.26772412131814394,
        "compression_ratio": 1.6319702602230484,
        "end": 2695.36,
        "id": 917,
        "no_speech_prob": 0.0000961021869443357,
        "seek": 267700,
        "start": 2692.88,
        "temperature": 0,
        "text": " need to say xs.print.",
        "tokens": [
          51158,
          643,
          281,
          584,
          2031,
          82,
          13,
          14030,
          13,
          51282
        ]
      },
      {
        "avg_logprob": -0.26772412131814394,
        "compression_ratio": 1.6319702602230484,
        "end": 2696.76,
        "id": 918,
        "no_speech_prob": 0.0000961021869443357,
        "seek": 267700,
        "start": 2695.36,
        "temperature": 0,
        "text": " So we can see, OK, great.",
        "tokens": [
          51282,
          407,
          321,
          393,
          536,
          11,
          2264,
          11,
          869,
          13,
          51352
        ]
      },
      {
        "avg_logprob": -0.26772412131814394,
        "compression_ratio": 1.6319702602230484,
        "end": 2698.32,
        "id": 919,
        "no_speech_prob": 0.0000961021869443357,
        "seek": 267700,
        "start": 2696.76,
        "temperature": 0,
        "text": " So I'm getting these points.",
        "tokens": [
          51352,
          407,
          286,
          478,
          1242,
          613,
          2793,
          13,
          51430
        ]
      },
      {
        "avg_logprob": -0.26772412131814394,
        "compression_ratio": 1.6319702602230484,
        "end": 2703.44,
        "id": 920,
        "no_speech_prob": 0.0000961021869443357,
        "seek": 267700,
        "start": 2698.32,
        "temperature": 0,
        "text": " Kate Wieckmann in the chat makes an excellent point,",
        "tokens": [
          51430,
          16251,
          9233,
          547,
          14912,
          294,
          264,
          5081,
          1669,
          364,
          7103,
          935,
          11,
          51686
        ]
      },
      {
        "avg_logprob": -0.21776476273169884,
        "compression_ratio": 1.5497835497835497,
        "end": 2709.12,
        "id": 921,
        "no_speech_prob": 0.00003373720028321259,
        "seek": 270344,
        "start": 2703.44,
        "temperature": 0,
        "text": " which is that I should think about actually mapping it",
        "tokens": [
          50364,
          597,
          307,
          300,
          286,
          820,
          519,
          466,
          767,
          18350,
          309,
          50648
        ]
      },
      {
        "avg_logprob": -0.21776476273169884,
        "compression_ratio": 1.5497835497835497,
        "end": 2712.76,
        "id": 922,
        "no_speech_prob": 0.00003373720028321259,
        "seek": 270344,
        "start": 2709.12,
        "temperature": 0,
        "text": " between negative 1 and 1 with 0, 0 in the center.",
        "tokens": [
          50648,
          1296,
          3671,
          502,
          293,
          502,
          365,
          1958,
          11,
          1958,
          294,
          264,
          3056,
          13,
          50830
        ]
      },
      {
        "avg_logprob": -0.21776476273169884,
        "compression_ratio": 1.5497835497835497,
        "end": 2715.76,
        "id": 923,
        "no_speech_prob": 0.00003373720028321259,
        "seek": 270344,
        "start": 2712.76,
        "temperature": 0,
        "text": " That's not such a bad idea.",
        "tokens": [
          50830,
          663,
          311,
          406,
          1270,
          257,
          1578,
          1558,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.21776476273169884,
        "compression_ratio": 1.5497835497835497,
        "end": 2717.12,
        "id": 924,
        "no_speech_prob": 0.00003373720028321259,
        "seek": 270344,
        "start": 2715.76,
        "temperature": 0,
        "text": " Let me just keep going with this,",
        "tokens": [
          50980,
          961,
          385,
          445,
          1066,
          516,
          365,
          341,
          11,
          51048
        ]
      },
      {
        "avg_logprob": -0.21776476273169884,
        "compression_ratio": 1.5497835497835497,
        "end": 2718.7200000000003,
        "id": 925,
        "no_speech_prob": 0.00003373720028321259,
        "seek": 270344,
        "start": 2717.12,
        "temperature": 0,
        "text": " and then maybe I'll change that after the fact",
        "tokens": [
          51048,
          293,
          550,
          1310,
          286,
          603,
          1319,
          300,
          934,
          264,
          1186,
          51128
        ]
      },
      {
        "avg_logprob": -0.21776476273169884,
        "compression_ratio": 1.5497835497835497,
        "end": 2720.04,
        "id": 926,
        "no_speech_prob": 0.00003373720028321259,
        "seek": 270344,
        "start": 2718.7200000000003,
        "temperature": 0,
        "text": " because this should work anyway.",
        "tokens": [
          51128,
          570,
          341,
          820,
          589,
          4033,
          13,
          51194
        ]
      },
      {
        "avg_logprob": -0.21776476273169884,
        "compression_ratio": 1.5497835497835497,
        "end": 2721.6,
        "id": 927,
        "no_speech_prob": 0.00003373720028321259,
        "seek": 270344,
        "start": 2720.04,
        "temperature": 0,
        "text": " So now here's the thing.",
        "tokens": [
          51194,
          407,
          586,
          510,
          311,
          264,
          551,
          13,
          51272
        ]
      },
      {
        "avg_logprob": -0.21776476273169884,
        "compression_ratio": 1.5497835497835497,
        "end": 2724.2000000000003,
        "id": 928,
        "no_speech_prob": 0.00003373720028321259,
        "seek": 270344,
        "start": 2721.6,
        "temperature": 0,
        "text": " Here's the awkward thing.",
        "tokens": [
          51272,
          1692,
          311,
          264,
          11411,
          551,
          13,
          51402
        ]
      },
      {
        "avg_logprob": -0.21776476273169884,
        "compression_ratio": 1.5497835497835497,
        "end": 2729.2400000000002,
        "id": 929,
        "no_speech_prob": 0.00003373720028321259,
        "seek": 270344,
        "start": 2724.2000000000003,
        "temperature": 0,
        "text": " In order for me, all I need to do now is basically say this.",
        "tokens": [
          51402,
          682,
          1668,
          337,
          385,
          11,
          439,
          286,
          643,
          281,
          360,
          586,
          307,
          1936,
          584,
          341,
          13,
          51654
        ]
      },
      {
        "avg_logprob": -0.2173925308954148,
        "compression_ratio": 1.595959595959596,
        "end": 2734.72,
        "id": 930,
        "no_speech_prob": 0.00005562204751186073,
        "seek": 272924,
        "start": 2729.24,
        "temperature": 0,
        "text": " Let x1 equal map x's 0, which goes between 0 and 1,",
        "tokens": [
          50364,
          961,
          2031,
          16,
          2681,
          4471,
          2031,
          311,
          1958,
          11,
          597,
          1709,
          1296,
          1958,
          293,
          502,
          11,
          50638
        ]
      },
      {
        "avg_logprob": -0.2173925308954148,
        "compression_ratio": 1.595959595959596,
        "end": 2736.2799999999997,
        "id": 931,
        "no_speech_prob": 0.00005562204751186073,
        "seek": 272924,
        "start": 2734.72,
        "temperature": 0,
        "text": " between 0 and width.",
        "tokens": [
          50638,
          1296,
          1958,
          293,
          11402,
          13,
          50716
        ]
      },
      {
        "avg_logprob": -0.2173925308954148,
        "compression_ratio": 1.595959595959596,
        "end": 2738.2,
        "id": 932,
        "no_speech_prob": 0.00005562204751186073,
        "seek": 272924,
        "start": 2736.2799999999997,
        "temperature": 0,
        "text": " And this is kind of silly because I could just",
        "tokens": [
          50716,
          400,
          341,
          307,
          733,
          295,
          11774,
          570,
          286,
          727,
          445,
          50812
        ]
      },
      {
        "avg_logprob": -0.2173925308954148,
        "compression_ratio": 1.595959595959596,
        "end": 2741.08,
        "id": 933,
        "no_speech_prob": 0.00005562204751186073,
        "seek": 272924,
        "start": 2738.2,
        "temperature": 0,
        "text": " multiply it times width.",
        "tokens": [
          50812,
          12972,
          309,
          1413,
          11402,
          13,
          50956
        ]
      },
      {
        "avg_logprob": -0.2173925308954148,
        "compression_ratio": 1.595959595959596,
        "end": 2743.7599999999998,
        "id": 934,
        "no_speech_prob": 0.00005562204751186073,
        "seek": 272924,
        "start": 2741.08,
        "temperature": 0,
        "text": " But I'm going to just go with the normalizing,",
        "tokens": [
          50956,
          583,
          286,
          478,
          516,
          281,
          445,
          352,
          365,
          264,
          2710,
          3319,
          11,
          51090
        ]
      },
      {
        "avg_logprob": -0.2173925308954148,
        "compression_ratio": 1.595959595959596,
        "end": 2745.8399999999997,
        "id": 935,
        "no_speech_prob": 0.00005562204751186073,
        "seek": 272924,
        "start": 2743.7599999999998,
        "temperature": 0,
        "text": " the full normalizing.",
        "tokens": [
          51090,
          264,
          1577,
          2710,
          3319,
          13,
          51194
        ]
      },
      {
        "avg_logprob": -0.2173925308954148,
        "compression_ratio": 1.595959595959596,
        "end": 2752.6,
        "id": 936,
        "no_speech_prob": 0.00005562204751186073,
        "seek": 272924,
        "start": 2745.8399999999997,
        "temperature": 0,
        "text": " y1 equals map x, oh, sorry, x2, which map x's index 1.",
        "tokens": [
          51194,
          288,
          16,
          6915,
          4471,
          2031,
          11,
          1954,
          11,
          2597,
          11,
          2031,
          17,
          11,
          597,
          4471,
          2031,
          311,
          8186,
          502,
          13,
          51532
        ]
      },
      {
        "avg_logprob": -0.2173925308954148,
        "compression_ratio": 1.595959595959596,
        "end": 2756.2,
        "id": 937,
        "no_speech_prob": 0.00005562204751186073,
        "seek": 272924,
        "start": 2752.6,
        "temperature": 0,
        "text": " So this gives me x1, which is just 0 and width.",
        "tokens": [
          51532,
          407,
          341,
          2709,
          385,
          2031,
          16,
          11,
          597,
          307,
          445,
          1958,
          293,
          11402,
          13,
          51712
        ]
      },
      {
        "avg_logprob": -0.24981401404555964,
        "compression_ratio": 1.2136752136752136,
        "end": 2768.72,
        "id": 938,
        "no_speech_prob": 0.000002090458337988821,
        "seek": 275620,
        "start": 2756.2,
        "temperature": 0,
        "text": " Now, y1 and y2, I want to map ys,",
        "tokens": [
          50364,
          823,
          11,
          288,
          16,
          293,
          288,
          17,
          11,
          286,
          528,
          281,
          4471,
          288,
          82,
          11,
          50990
        ]
      },
      {
        "avg_logprob": -0.24981401404555964,
        "compression_ratio": 1.2136752136752136,
        "end": 2777.3599999999997,
        "id": 939,
        "no_speech_prob": 0.000002090458337988821,
        "seek": 275620,
        "start": 2768.72,
        "temperature": 0,
        "text": " the y values between height and 0 because I'm flipping it.",
        "tokens": [
          50990,
          264,
          288,
          4190,
          1296,
          6681,
          293,
          1958,
          570,
          286,
          478,
          26886,
          309,
          13,
          51422
        ]
      },
      {
        "avg_logprob": -0.24981401404555964,
        "compression_ratio": 1.2136752136752136,
        "end": 2784.3199999999997,
        "id": 940,
        "no_speech_prob": 0.000002090458337988821,
        "seek": 275620,
        "start": 2780.68,
        "temperature": 0,
        "text": " The problem is, and then I just want to say line,",
        "tokens": [
          51588,
          440,
          1154,
          307,
          11,
          293,
          550,
          286,
          445,
          528,
          281,
          584,
          1622,
          11,
          51770
        ]
      },
      {
        "avg_logprob": -0.18058386081602515,
        "compression_ratio": 1.6056338028169015,
        "end": 2788.2400000000002,
        "id": 941,
        "no_speech_prob": 0.000011843138963740785,
        "seek": 278432,
        "start": 2784.32,
        "temperature": 0,
        "text": " x1, y1, x2, y2.",
        "tokens": [
          50364,
          2031,
          16,
          11,
          288,
          16,
          11,
          2031,
          17,
          11,
          288,
          17,
          13,
          50560
        ]
      },
      {
        "avg_logprob": -0.18058386081602515,
        "compression_ratio": 1.6056338028169015,
        "end": 2790.96,
        "id": 942,
        "no_speech_prob": 0.000011843138963740785,
        "seek": 278432,
        "start": 2788.2400000000002,
        "temperature": 0,
        "text": " So this is really all I need to do.",
        "tokens": [
          50560,
          407,
          341,
          307,
          534,
          439,
          286,
          643,
          281,
          360,
          13,
          50696
        ]
      },
      {
        "avg_logprob": -0.18058386081602515,
        "compression_ratio": 1.6056338028169015,
        "end": 2795.6000000000004,
        "id": 943,
        "no_speech_prob": 0.000011843138963740785,
        "seek": 278432,
        "start": 2790.96,
        "temperature": 0,
        "text": " I just want to get the sort of two points on the line",
        "tokens": [
          50696,
          286,
          445,
          528,
          281,
          483,
          264,
          1333,
          295,
          732,
          2793,
          322,
          264,
          1622,
          50928
        ]
      },
      {
        "avg_logprob": -0.18058386081602515,
        "compression_ratio": 1.6056338028169015,
        "end": 2797.8,
        "id": 944,
        "no_speech_prob": 0.000011843138963740785,
        "seek": 278432,
        "start": 2795.6000000000004,
        "temperature": 0,
        "text": " and then draw a line between them.",
        "tokens": [
          50928,
          293,
          550,
          2642,
          257,
          1622,
          1296,
          552,
          13,
          51038
        ]
      },
      {
        "avg_logprob": -0.18058386081602515,
        "compression_ratio": 1.6056338028169015,
        "end": 2801.0800000000004,
        "id": 945,
        "no_speech_prob": 0.000011843138963740785,
        "seek": 278432,
        "start": 2797.8,
        "temperature": 0,
        "text": " This is fine because my x's are not tensors.",
        "tokens": [
          51038,
          639,
          307,
          2489,
          570,
          452,
          2031,
          311,
          366,
          406,
          10688,
          830,
          13,
          51202
        ]
      },
      {
        "avg_logprob": -0.18058386081602515,
        "compression_ratio": 1.6056338028169015,
        "end": 2805.88,
        "id": 946,
        "no_speech_prob": 0.000011843138963740785,
        "seek": 278432,
        "start": 2801.0800000000004,
        "temperature": 0,
        "text": " And I can use plain numbers right here, x1, x2.",
        "tokens": [
          51202,
          400,
          286,
          393,
          764,
          11121,
          3547,
          558,
          510,
          11,
          2031,
          16,
          11,
          2031,
          17,
          13,
          51442
        ]
      },
      {
        "avg_logprob": -0.18058386081602515,
        "compression_ratio": 1.6056338028169015,
        "end": 2809.6400000000003,
        "id": 947,
        "no_speech_prob": 0.000011843138963740785,
        "seek": 278432,
        "start": 2805.88,
        "temperature": 0,
        "text": " But my y's, and here, but my y's are tensors.",
        "tokens": [
          51442,
          583,
          452,
          288,
          311,
          11,
          293,
          510,
          11,
          457,
          452,
          288,
          311,
          366,
          10688,
          830,
          13,
          51630
        ]
      },
      {
        "avg_logprob": -0.18058386081602515,
        "compression_ratio": 1.6056338028169015,
        "end": 2811.76,
        "id": 948,
        "no_speech_prob": 0.000011843138963740785,
        "seek": 278432,
        "start": 2809.6400000000003,
        "temperature": 0,
        "text": " So for me to be able to, I really",
        "tokens": [
          51630,
          407,
          337,
          385,
          281,
          312,
          1075,
          281,
          11,
          286,
          534,
          51736
        ]
      },
      {
        "avg_logprob": -0.18058386081602515,
        "compression_ratio": 1.6056338028169015,
        "end": 2813.56,
        "id": 949,
        "no_speech_prob": 0.000011843138963740785,
        "seek": 278432,
        "start": 2811.76,
        "temperature": 0,
        "text": " need to get the values back.",
        "tokens": [
          51736,
          643,
          281,
          483,
          264,
          4190,
          646,
          13,
          51826
        ]
      },
      {
        "avg_logprob": -0.2147525187288777,
        "compression_ratio": 1.6033519553072626,
        "end": 2819.08,
        "id": 950,
        "no_speech_prob": 0.000002521573378544417,
        "seek": 281356,
        "start": 2813.56,
        "temperature": 0,
        "text": " And a way to do that is with the function called data.",
        "tokens": [
          50364,
          400,
          257,
          636,
          281,
          360,
          300,
          307,
          365,
          264,
          2445,
          1219,
          1412,
          13,
          50640
        ]
      },
      {
        "avg_logprob": -0.2147525187288777,
        "compression_ratio": 1.6033519553072626,
        "end": 2828.7599999999998,
        "id": 951,
        "no_speech_prob": 0.000002521573378544417,
        "seek": 281356,
        "start": 2819.08,
        "temperature": 0,
        "text": " So I'm going to say let line y equal ys.data.",
        "tokens": [
          50640,
          407,
          286,
          478,
          516,
          281,
          584,
          718,
          1622,
          288,
          2681,
          288,
          82,
          13,
          67,
          3274,
          13,
          51124
        ]
      },
      {
        "avg_logprob": -0.2147525187288777,
        "compression_ratio": 1.6033519553072626,
        "end": 2831.64,
        "id": 952,
        "no_speech_prob": 0.000002521573378544417,
        "seek": 281356,
        "start": 2828.7599999999998,
        "temperature": 0,
        "text": " And I'm just going to say data sync right now.",
        "tokens": [
          51124,
          400,
          286,
          478,
          445,
          516,
          281,
          584,
          1412,
          20271,
          558,
          586,
          13,
          51268
        ]
      },
      {
        "avg_logprob": -0.2147525187288777,
        "compression_ratio": 1.6033519553072626,
        "end": 2834.52,
        "id": 953,
        "no_speech_prob": 0.000002521573378544417,
        "seek": 281356,
        "start": 2831.64,
        "temperature": 0,
        "text": " And let me comment all this out.",
        "tokens": [
          51268,
          400,
          718,
          385,
          2871,
          439,
          341,
          484,
          13,
          51412
        ]
      },
      {
        "avg_logprob": -0.2147525187288777,
        "compression_ratio": 1.6033519553072626,
        "end": 2838.84,
        "id": 954,
        "no_speech_prob": 0.000002521573378544417,
        "seek": 281356,
        "start": 2834.52,
        "temperature": 0,
        "text": " And let me console log that and see if this comes.",
        "tokens": [
          51412,
          400,
          718,
          385,
          11076,
          3565,
          300,
          293,
          536,
          498,
          341,
          1487,
          13,
          51628
        ]
      },
      {
        "avg_logprob": -0.2147525187288777,
        "compression_ratio": 1.6033519553072626,
        "end": 2842.16,
        "id": 955,
        "no_speech_prob": 0.000002521573378544417,
        "seek": 281356,
        "start": 2838.84,
        "temperature": 0,
        "text": " So this is kind of a bad idea for a variety of reasons.",
        "tokens": [
          51628,
          407,
          341,
          307,
          733,
          295,
          257,
          1578,
          1558,
          337,
          257,
          5673,
          295,
          4112,
          13,
          51794
        ]
      },
      {
        "avg_logprob": -0.22423921214590828,
        "compression_ratio": 1.632996632996633,
        "end": 2843.56,
        "id": 956,
        "no_speech_prob": 0.000008398056706937496,
        "seek": 284216,
        "start": 2842.16,
        "temperature": 0,
        "text": " But I think it's going to work OK.",
        "tokens": [
          50364,
          583,
          286,
          519,
          309,
          311,
          516,
          281,
          589,
          2264,
          13,
          50434
        ]
      },
      {
        "avg_logprob": -0.22423921214590828,
        "compression_ratio": 1.632996632996633,
        "end": 2850,
        "id": 957,
        "no_speech_prob": 0.000008398056706937496,
        "seek": 284216,
        "start": 2846.3199999999997,
        "temperature": 0,
        "text": " So you can see I'm getting those numbers back as a float array.",
        "tokens": [
          50572,
          407,
          291,
          393,
          536,
          286,
          478,
          1242,
          729,
          3547,
          646,
          382,
          257,
          15706,
          10225,
          13,
          50756
        ]
      },
      {
        "avg_logprob": -0.22423921214590828,
        "compression_ratio": 1.632996632996633,
        "end": 2851.08,
        "id": 958,
        "no_speech_prob": 0.000008398056706937496,
        "seek": 284216,
        "start": 2850,
        "temperature": 0,
        "text": " So here's the thing.",
        "tokens": [
          50756,
          407,
          510,
          311,
          264,
          551,
          13,
          50810
        ]
      },
      {
        "avg_logprob": -0.22423921214590828,
        "compression_ratio": 1.632996632996633,
        "end": 2854.3199999999997,
        "id": 959,
        "no_speech_prob": 0.000008398056706937496,
        "seek": 284216,
        "start": 2851.08,
        "temperature": 0,
        "text": " This really requires not a callback, but a promise.",
        "tokens": [
          50810,
          639,
          534,
          7029,
          406,
          257,
          818,
          3207,
          11,
          457,
          257,
          6228,
          13,
          50972
        ]
      },
      {
        "avg_logprob": -0.22423921214590828,
        "compression_ratio": 1.632996632996633,
        "end": 2857.52,
        "id": 960,
        "no_speech_prob": 0.000008398056706937496,
        "seek": 284216,
        "start": 2854.3199999999997,
        "temperature": 0,
        "text": " And I'm so happy I just did a whole video series on promises.",
        "tokens": [
          50972,
          400,
          286,
          478,
          370,
          2055,
          286,
          445,
          630,
          257,
          1379,
          960,
          2638,
          322,
          16403,
          13,
          51132
        ]
      },
      {
        "avg_logprob": -0.22423921214590828,
        "compression_ratio": 1.632996632996633,
        "end": 2860.2799999999997,
        "id": 961,
        "no_speech_prob": 0.000008398056706937496,
        "seek": 284216,
        "start": 2857.52,
        "temperature": 0,
        "text": " I really should be saying data.then.",
        "tokens": [
          51132,
          286,
          534,
          820,
          312,
          1566,
          1412,
          13,
          19096,
          13,
          51270
        ]
      },
      {
        "avg_logprob": -0.22423921214590828,
        "compression_ratio": 1.632996632996633,
        "end": 2863.24,
        "id": 962,
        "no_speech_prob": 0.000008398056706937496,
        "seek": 284216,
        "start": 2860.2799999999997,
        "temperature": 0,
        "text": " And there's even something called tf.nextframe,",
        "tokens": [
          51270,
          400,
          456,
          311,
          754,
          746,
          1219,
          256,
          69,
          13,
          716,
          734,
          17265,
          11,
          51418
        ]
      },
      {
        "avg_logprob": -0.22423921214590828,
        "compression_ratio": 1.632996632996633,
        "end": 2866.2799999999997,
        "id": 963,
        "no_speech_prob": 0.000008398056706937496,
        "seek": 284216,
        "start": 2863.24,
        "temperature": 0,
        "text": " which allows me to sort of think about the asynchronous nature",
        "tokens": [
          51418,
          597,
          4045,
          385,
          281,
          1333,
          295,
          519,
          466,
          264,
          49174,
          3687,
          51570
        ]
      },
      {
        "avg_logprob": -0.22423921214590828,
        "compression_ratio": 1.632996632996633,
        "end": 2869.04,
        "id": 964,
        "no_speech_prob": 0.000008398056706937496,
        "seek": 284216,
        "start": 2866.2799999999997,
        "temperature": 0,
        "text": " of pulling the data out of a tensor into a number",
        "tokens": [
          51570,
          295,
          8407,
          264,
          1412,
          484,
          295,
          257,
          40863,
          666,
          257,
          1230,
          51708
        ]
      },
      {
        "avg_logprob": -0.22423921214590828,
        "compression_ratio": 1.632996632996633,
        "end": 2870.6,
        "id": 965,
        "no_speech_prob": 0.000008398056706937496,
        "seek": 284216,
        "start": 2869.04,
        "temperature": 0,
        "text": " that I can use in an animation.",
        "tokens": [
          51708,
          300,
          286,
          393,
          764,
          294,
          364,
          9603,
          13,
          51786
        ]
      },
      {
        "avg_logprob": -0.22423921214590828,
        "compression_ratio": 1.632996632996633,
        "end": 2871.64,
        "id": 966,
        "no_speech_prob": 0.000008398056706937496,
        "seek": 284216,
        "start": 2870.6,
        "temperature": 0,
        "text": " These are key things.",
        "tokens": [
          51786,
          1981,
          366,
          2141,
          721,
          13,
          51838
        ]
      },
      {
        "avg_logprob": -0.22095137376051682,
        "compression_ratio": 1.687732342007435,
        "end": 2873.44,
        "id": 967,
        "no_speech_prob": 0.000017778551409719512,
        "seek": 287164,
        "start": 2871.64,
        "temperature": 0,
        "text": " I'm definitely going to have to get to them.",
        "tokens": [
          50364,
          286,
          478,
          2138,
          516,
          281,
          362,
          281,
          483,
          281,
          552,
          13,
          50454
        ]
      },
      {
        "avg_logprob": -0.22095137376051682,
        "compression_ratio": 1.687732342007435,
        "end": 2874.3199999999997,
        "id": 968,
        "no_speech_prob": 0.000017778551409719512,
        "seek": 287164,
        "start": 2873.44,
        "temperature": 0,
        "text": " But here's the thing.",
        "tokens": [
          50454,
          583,
          510,
          311,
          264,
          551,
          13,
          50498
        ]
      },
      {
        "avg_logprob": -0.22095137376051682,
        "compression_ratio": 1.687732342007435,
        "end": 2876.08,
        "id": 969,
        "no_speech_prob": 0.000017778551409719512,
        "seek": 287164,
        "start": 2874.3199999999997,
        "temperature": 0,
        "text": " This is just two numbers.",
        "tokens": [
          50498,
          639,
          307,
          445,
          732,
          3547,
          13,
          50586
        ]
      },
      {
        "avg_logprob": -0.22095137376051682,
        "compression_ratio": 1.687732342007435,
        "end": 2879.6,
        "id": 970,
        "no_speech_prob": 0.000017778551409719512,
        "seek": 287164,
        "start": 2876.08,
        "temperature": 0,
        "text": " I think my animation can handle using data sync.",
        "tokens": [
          50586,
          286,
          519,
          452,
          9603,
          393,
          4813,
          1228,
          1412,
          20271,
          13,
          50762
        ]
      },
      {
        "avg_logprob": -0.22095137376051682,
        "compression_ratio": 1.687732342007435,
        "end": 2882.7999999999997,
        "id": 971,
        "no_speech_prob": 0.000017778551409719512,
        "seek": 287164,
        "start": 2879.6,
        "temperature": 0,
        "text": " And maybe somebody from the TensorFlow.js team",
        "tokens": [
          50762,
          400,
          1310,
          2618,
          490,
          264,
          37624,
          13,
          25530,
          1469,
          50922
        ]
      },
      {
        "avg_logprob": -0.22095137376051682,
        "compression_ratio": 1.687732342007435,
        "end": 2884.7999999999997,
        "id": 972,
        "no_speech_prob": 0.000017778551409719512,
        "seek": 287164,
        "start": 2882.7999999999997,
        "temperature": 0,
        "text": " is going to want to say, actually, this is not",
        "tokens": [
          50922,
          307,
          516,
          281,
          528,
          281,
          584,
          11,
          767,
          11,
          341,
          307,
          406,
          51022
        ]
      },
      {
        "avg_logprob": -0.22095137376051682,
        "compression_ratio": 1.687732342007435,
        "end": 2886.96,
        "id": 973,
        "no_speech_prob": 0.000017778551409719512,
        "seek": 287164,
        "start": 2884.7999999999997,
        "temperature": 0,
        "text": " just a bad idea, but a really bad idea.",
        "tokens": [
          51022,
          445,
          257,
          1578,
          1558,
          11,
          457,
          257,
          534,
          1578,
          1558,
          13,
          51130
        ]
      },
      {
        "avg_logprob": -0.22095137376051682,
        "compression_ratio": 1.687732342007435,
        "end": 2887.7999999999997,
        "id": 974,
        "no_speech_prob": 0.000017778551409719512,
        "seek": 287164,
        "start": 2886.96,
        "temperature": 0,
        "text": " I'm not so sure.",
        "tokens": [
          51130,
          286,
          478,
          406,
          370,
          988,
          13,
          51172
        ]
      },
      {
        "avg_logprob": -0.22095137376051682,
        "compression_ratio": 1.687732342007435,
        "end": 2889.92,
        "id": 975,
        "no_speech_prob": 0.000017778551409719512,
        "seek": 287164,
        "start": 2887.7999999999997,
        "temperature": 0,
        "text": " But I think it's going to let's just get it to work",
        "tokens": [
          51172,
          583,
          286,
          519,
          309,
          311,
          516,
          281,
          718,
          311,
          445,
          483,
          309,
          281,
          589,
          51278
        ]
      },
      {
        "avg_logprob": -0.22095137376051682,
        "compression_ratio": 1.687732342007435,
        "end": 2891.56,
        "id": 976,
        "no_speech_prob": 0.000017778551409719512,
        "seek": 287164,
        "start": 2889.92,
        "temperature": 0,
        "text": " and see if this demonstrates the idea.",
        "tokens": [
          51278,
          293,
          536,
          498,
          341,
          31034,
          264,
          1558,
          13,
          51360
        ]
      },
      {
        "avg_logprob": -0.22095137376051682,
        "compression_ratio": 1.687732342007435,
        "end": 2895,
        "id": 977,
        "no_speech_prob": 0.000017778551409719512,
        "seek": 287164,
        "start": 2891.56,
        "temperature": 0,
        "text": " So now, I'm going to call this line y.",
        "tokens": [
          51360,
          407,
          586,
          11,
          286,
          478,
          516,
          281,
          818,
          341,
          1622,
          288,
          13,
          51532
        ]
      },
      {
        "avg_logprob": -0.22095137376051682,
        "compression_ratio": 1.687732342007435,
        "end": 2899.6,
        "id": 978,
        "no_speech_prob": 0.000017778551409719512,
        "seek": 287164,
        "start": 2895,
        "temperature": 0,
        "text": " I should be able to say y1, y2.",
        "tokens": [
          51532,
          286,
          820,
          312,
          1075,
          281,
          584,
          288,
          16,
          11,
          288,
          17,
          13,
          51762
        ]
      },
      {
        "avg_logprob": -0.31853876308519014,
        "compression_ratio": 1.205607476635514,
        "end": 2904.96,
        "id": 979,
        "no_speech_prob": 0.000019525848983903416,
        "seek": 289960,
        "start": 2899.64,
        "temperature": 0,
        "text": " And I should get 0 and 1 from line y.",
        "tokens": [
          50366,
          400,
          286,
          820,
          483,
          1958,
          293,
          502,
          490,
          1622,
          288,
          13,
          50632
        ]
      },
      {
        "avg_logprob": -0.31853876308519014,
        "compression_ratio": 1.205607476635514,
        "end": 2908.68,
        "id": 980,
        "no_speech_prob": 0.000019525848983903416,
        "seek": 289960,
        "start": 2904.96,
        "temperature": 0,
        "text": " And now, we should see, we should be done.",
        "tokens": [
          50632,
          400,
          586,
          11,
          321,
          820,
          536,
          11,
          321,
          820,
          312,
          1096,
          13,
          50818
        ]
      },
      {
        "avg_logprob": -0.31853876308519014,
        "compression_ratio": 1.205607476635514,
        "end": 2914.44,
        "id": 981,
        "no_speech_prob": 0.000019525848983903416,
        "seek": 289960,
        "start": 2911.88,
        "temperature": 0,
        "text": " Line y is not defined.",
        "tokens": [
          50978,
          14670,
          288,
          307,
          406,
          7642,
          13,
          51106
        ]
      },
      {
        "avg_logprob": -0.31853876308519014,
        "compression_ratio": 1.205607476635514,
        "end": 2916.24,
        "id": 982,
        "no_speech_prob": 0.000019525848983903416,
        "seek": 289960,
        "start": 2914.44,
        "temperature": 0,
        "text": " Where?",
        "tokens": [
          51106,
          2305,
          30,
          51196
        ]
      },
      {
        "avg_logprob": -0.31853876308519014,
        "compression_ratio": 1.205607476635514,
        "end": 2917.44,
        "id": 983,
        "no_speech_prob": 0.000019525848983903416,
        "seek": 289960,
        "start": 2916.24,
        "temperature": 0,
        "text": " Sketch.js line 61.",
        "tokens": [
          51196,
          49245,
          13,
          25530,
          1622,
          28294,
          13,
          51256
        ]
      },
      {
        "avg_logprob": -0.41678458524037554,
        "compression_ratio": 1.4507042253521127,
        "end": 2917.94,
        "id": 984,
        "no_speech_prob": 0.004007270559668541,
        "seek": 291744,
        "start": 2917.44,
        "temperature": 0,
        "text": " 61.",
        "tokens": [
          50364,
          28294,
          13,
          50389
        ]
      },
      {
        "avg_logprob": -0.41678458524037554,
        "compression_ratio": 1.4507042253521127,
        "end": 2931.44,
        "id": 985,
        "no_speech_prob": 0.004007270559668541,
        "seek": 291744,
        "start": 2928.84,
        "temperature": 0,
        "text": " I think I just didn't hit Save.",
        "tokens": [
          50934,
          286,
          519,
          286,
          445,
          994,
          380,
          2045,
          15541,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.41678458524037554,
        "compression_ratio": 1.4507042253521127,
        "end": 2934.2400000000002,
        "id": 986,
        "no_speech_prob": 0.004007270559668541,
        "seek": 291744,
        "start": 2931.44,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51064,
          865,
          13,
          51204
        ]
      },
      {
        "avg_logprob": -0.41678458524037554,
        "compression_ratio": 1.4507042253521127,
        "end": 2936.36,
        "id": 987,
        "no_speech_prob": 0.004007270559668541,
        "seek": 291744,
        "start": 2934.2400000000002,
        "temperature": 0,
        "text": " Oh, I haven't clicked any points.",
        "tokens": [
          51204,
          876,
          11,
          286,
          2378,
          380,
          23370,
          604,
          2793,
          13,
          51310
        ]
      },
      {
        "avg_logprob": -0.41678458524037554,
        "compression_ratio": 1.4507042253521127,
        "end": 2938.16,
        "id": 988,
        "no_speech_prob": 0.004007270559668541,
        "seek": 291744,
        "start": 2936.36,
        "temperature": 0,
        "text": " Hey, look at that.",
        "tokens": [
          51310,
          1911,
          11,
          574,
          412,
          300,
          13,
          51400
        ]
      },
      {
        "avg_logprob": -0.41678458524037554,
        "compression_ratio": 1.4507042253521127,
        "end": 2939.4,
        "id": 989,
        "no_speech_prob": 0.004007270559668541,
        "seek": 291744,
        "start": 2938.16,
        "temperature": 0,
        "text": " Oh, hey, look.",
        "tokens": [
          51400,
          876,
          11,
          4177,
          11,
          574,
          13,
          51462
        ]
      },
      {
        "avg_logprob": -0.41678458524037554,
        "compression_ratio": 1.4507042253521127,
        "end": 2940,
        "id": 990,
        "no_speech_prob": 0.004007270559668541,
        "seek": 291744,
        "start": 2939.4,
        "temperature": 0,
        "text": " It's working.",
        "tokens": [
          51462,
          467,
          311,
          1364,
          13,
          51492
        ]
      },
      {
        "avg_logprob": -0.41678458524037554,
        "compression_ratio": 1.4507042253521127,
        "end": 2940.96,
        "id": 991,
        "no_speech_prob": 0.004007270559668541,
        "seek": 291744,
        "start": 2940,
        "temperature": 0,
        "text": " Oh, that's so exciting.",
        "tokens": [
          51492,
          876,
          11,
          300,
          311,
          370,
          4670,
          13,
          51540
        ]
      },
      {
        "avg_logprob": -0.41678458524037554,
        "compression_ratio": 1.4507042253521127,
        "end": 2941.96,
        "id": 992,
        "no_speech_prob": 0.004007270559668541,
        "seek": 291744,
        "start": 2940.96,
        "temperature": 0,
        "text": " Oh, that's so exciting.",
        "tokens": [
          51540,
          876,
          11,
          300,
          311,
          370,
          4670,
          13,
          51590
        ]
      },
      {
        "avg_logprob": -0.41678458524037554,
        "compression_ratio": 1.4507042253521127,
        "end": 2944.36,
        "id": 993,
        "no_speech_prob": 0.004007270559668541,
        "seek": 291744,
        "start": 2941.96,
        "temperature": 0,
        "text": " All right, for a couple of things.",
        "tokens": [
          51590,
          1057,
          558,
          11,
          337,
          257,
          1916,
          295,
          721,
          13,
          51710
        ]
      },
      {
        "avg_logprob": -0.3227450463079637,
        "compression_ratio": 1.6424581005586592,
        "end": 2947.6800000000003,
        "id": 994,
        "no_speech_prob": 0.00021654338343068957,
        "seek": 294436,
        "start": 2944.4,
        "temperature": 0,
        "text": " Number one is, let's say, stroke weight 2.",
        "tokens": [
          50366,
          5118,
          472,
          307,
          11,
          718,
          311,
          584,
          11,
          12403,
          3364,
          568,
          13,
          50530
        ]
      },
      {
        "avg_logprob": -0.3227450463079637,
        "compression_ratio": 1.6424581005586592,
        "end": 2953.96,
        "id": 995,
        "no_speech_prob": 0.00021654338343068957,
        "seek": 294436,
        "start": 2951.32,
        "temperature": 0,
        "text": " And by the way, we can now start to play with the learning rate.",
        "tokens": [
          50712,
          400,
          538,
          264,
          636,
          11,
          321,
          393,
          586,
          722,
          281,
          862,
          365,
          264,
          2539,
          3314,
          13,
          50844
        ]
      },
      {
        "avg_logprob": -0.3227450463079637,
        "compression_ratio": 1.6424581005586592,
        "end": 2957.56,
        "id": 996,
        "no_speech_prob": 0.00021654338343068957,
        "seek": 294436,
        "start": 2953.96,
        "temperature": 0,
        "text": " I don't have to clean up the memory stuff.",
        "tokens": [
          50844,
          286,
          500,
          380,
          362,
          281,
          2541,
          493,
          264,
          4675,
          1507,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.3227450463079637,
        "compression_ratio": 1.6424581005586592,
        "end": 2959.6800000000003,
        "id": 997,
        "no_speech_prob": 0.00021654338343068957,
        "seek": 294436,
        "start": 2957.56,
        "temperature": 0,
        "text": " I can play with the learning rate.",
        "tokens": [
          51024,
          286,
          393,
          862,
          365,
          264,
          2539,
          3314,
          13,
          51130
        ]
      },
      {
        "avg_logprob": -0.3227450463079637,
        "compression_ratio": 1.6424581005586592,
        "end": 2964.92,
        "id": 998,
        "no_speech_prob": 0.00021654338343068957,
        "seek": 294436,
        "start": 2959.6800000000003,
        "temperature": 0,
        "text": " Like, let's make this 0.01.",
        "tokens": [
          51130,
          1743,
          11,
          718,
          311,
          652,
          341,
          1958,
          13,
          10607,
          13,
          51392
        ]
      },
      {
        "avg_logprob": -0.3227450463079637,
        "compression_ratio": 1.6424581005586592,
        "end": 2968.44,
        "id": 999,
        "no_speech_prob": 0.00021654338343068957,
        "seek": 294436,
        "start": 2964.92,
        "temperature": 0,
        "text": " So you can see what happens with this lower learning rate.",
        "tokens": [
          51392,
          407,
          291,
          393,
          536,
          437,
          2314,
          365,
          341,
          3126,
          2539,
          3314,
          13,
          51568
        ]
      },
      {
        "avg_logprob": -0.3227450463079637,
        "compression_ratio": 1.6424581005586592,
        "end": 2969.28,
        "id": 1000,
        "no_speech_prob": 0.00021654338343068957,
        "seek": 294436,
        "start": 2968.44,
        "temperature": 0,
        "text": " I don't know if it's.",
        "tokens": [
          51568,
          286,
          500,
          380,
          458,
          498,
          309,
          311,
          13,
          51610
        ]
      },
      {
        "avg_logprob": -0.21930829002743676,
        "compression_ratio": 1.5373831775700935,
        "end": 2974.0800000000004,
        "id": 1001,
        "no_speech_prob": 0.0000017061830703823944,
        "seek": 296928,
        "start": 2969.28,
        "temperature": 0,
        "text": " Um, let's see.",
        "tokens": [
          50364,
          3301,
          11,
          718,
          311,
          536,
          13,
          50604
        ]
      },
      {
        "avg_logprob": -0.21930829002743676,
        "compression_ratio": 1.5373831775700935,
        "end": 2975,
        "id": 1002,
        "no_speech_prob": 0.0000017061830703823944,
        "seek": 296928,
        "start": 2974.0800000000004,
        "temperature": 0,
        "text": " Is it really working?",
        "tokens": [
          50604,
          1119,
          309,
          534,
          1364,
          30,
          50650
        ]
      },
      {
        "avg_logprob": -0.21930829002743676,
        "compression_ratio": 1.5373831775700935,
        "end": 2977,
        "id": 1003,
        "no_speech_prob": 0.0000017061830703823944,
        "seek": 296928,
        "start": 2975,
        "temperature": 0,
        "text": " Well, I shouldn't use such a low learning rate.",
        "tokens": [
          50650,
          1042,
          11,
          286,
          4659,
          380,
          764,
          1270,
          257,
          2295,
          2539,
          3314,
          13,
          50750
        ]
      },
      {
        "avg_logprob": -0.21930829002743676,
        "compression_ratio": 1.5373831775700935,
        "end": 2980.2400000000002,
        "id": 1004,
        "no_speech_prob": 0.0000017061830703823944,
        "seek": 296928,
        "start": 2977,
        "temperature": 0,
        "text": " Let's make it 0.5.",
        "tokens": [
          50750,
          961,
          311,
          652,
          309,
          1958,
          13,
          20,
          13,
          50912
        ]
      },
      {
        "avg_logprob": -0.21930829002743676,
        "compression_ratio": 1.5373831775700935,
        "end": 2983.28,
        "id": 1005,
        "no_speech_prob": 0.0000017061830703823944,
        "seek": 296928,
        "start": 2980.2400000000002,
        "temperature": 0,
        "text": " Yeah, it's definitely happy.",
        "tokens": [
          50912,
          865,
          11,
          309,
          311,
          2138,
          2055,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.21930829002743676,
        "compression_ratio": 1.5373831775700935,
        "end": 2984.88,
        "id": 1006,
        "no_speech_prob": 0.0000017061830703823944,
        "seek": 296928,
        "start": 2983.28,
        "temperature": 0,
        "text": " OK, so this is working.",
        "tokens": [
          51064,
          2264,
          11,
          370,
          341,
          307,
          1364,
          13,
          51144
        ]
      },
      {
        "avg_logprob": -0.21930829002743676,
        "compression_ratio": 1.5373831775700935,
        "end": 2986.5600000000004,
        "id": 1007,
        "no_speech_prob": 0.0000017061830703823944,
        "seek": 296928,
        "start": 2984.88,
        "temperature": 0,
        "text": " Linear regression with gradient descent.",
        "tokens": [
          51144,
          14670,
          289,
          24590,
          365,
          16235,
          23475,
          13,
          51228
        ]
      },
      {
        "avg_logprob": -0.21930829002743676,
        "compression_ratio": 1.5373831775700935,
        "end": 2990,
        "id": 1008,
        "no_speech_prob": 0.0000017061830703823944,
        "seek": 296928,
        "start": 2986.5600000000004,
        "temperature": 0,
        "text": " But I have a severe problem.",
        "tokens": [
          51228,
          583,
          286,
          362,
          257,
          8922,
          1154,
          13,
          51400
        ]
      },
      {
        "avg_logprob": -0.21930829002743676,
        "compression_ratio": 1.5373831775700935,
        "end": 2993.32,
        "id": 1009,
        "no_speech_prob": 0.0000017061830703823944,
        "seek": 296928,
        "start": 2990,
        "temperature": 0,
        "text": " I am just filling the GPU with tensors and tensors",
        "tokens": [
          51400,
          286,
          669,
          445,
          10623,
          264,
          18407,
          365,
          10688,
          830,
          293,
          10688,
          830,
          51566
        ]
      },
      {
        "avg_logprob": -0.21930829002743676,
        "compression_ratio": 1.5373831775700935,
        "end": 2996.88,
        "id": 1010,
        "no_speech_prob": 0.0000017061830703823944,
        "seek": 296928,
        "start": 2993.32,
        "temperature": 0,
        "text": " and tensors and tensors and never cleaning them up.",
        "tokens": [
          51566,
          293,
          10688,
          830,
          293,
          10688,
          830,
          293,
          1128,
          8924,
          552,
          493,
          13,
          51744
        ]
      },
      {
        "avg_logprob": -0.2313175470056668,
        "compression_ratio": 1.6415770609318996,
        "end": 3000.12,
        "id": 1011,
        "no_speech_prob": 0.000012606938980752602,
        "seek": 299688,
        "start": 2996.92,
        "temperature": 0,
        "text": " So now it's my job to go through and find every place I'm",
        "tokens": [
          50366,
          407,
          586,
          309,
          311,
          452,
          1691,
          281,
          352,
          807,
          293,
          915,
          633,
          1081,
          286,
          478,
          50526
        ]
      },
      {
        "avg_logprob": -0.2313175470056668,
        "compression_ratio": 1.6415770609318996,
        "end": 3002.48,
        "id": 1012,
        "no_speech_prob": 0.000012606938980752602,
        "seek": 299688,
        "start": 3000.12,
        "temperature": 0,
        "text": " creating a tensor and dispose of it.",
        "tokens": [
          50526,
          4084,
          257,
          40863,
          293,
          42537,
          295,
          309,
          13,
          50644
        ]
      },
      {
        "avg_logprob": -0.2313175470056668,
        "compression_ratio": 1.6415770609318996,
        "end": 3005.2000000000003,
        "id": 1013,
        "no_speech_prob": 0.000012606938980752602,
        "seek": 299688,
        "start": 3002.48,
        "temperature": 0,
        "text": " So I can use tftidy to do that automatically,",
        "tokens": [
          50644,
          407,
          286,
          393,
          764,
          256,
          844,
          38836,
          281,
          360,
          300,
          6772,
          11,
          50780
        ]
      },
      {
        "avg_logprob": -0.2313175470056668,
        "compression_ratio": 1.6415770609318996,
        "end": 3007.88,
        "id": 1014,
        "no_speech_prob": 0.000012606938980752602,
        "seek": 299688,
        "start": 3005.2000000000003,
        "temperature": 0,
        "text": " or I can just use the actual dispose function, which I might",
        "tokens": [
          50780,
          420,
          286,
          393,
          445,
          764,
          264,
          3539,
          42537,
          2445,
          11,
          597,
          286,
          1062,
          50914
        ]
      },
      {
        "avg_logprob": -0.2313175470056668,
        "compression_ratio": 1.6415770609318996,
        "end": 3009.12,
        "id": 1015,
        "no_speech_prob": 0.000012606938980752602,
        "seek": 299688,
        "start": 3007.88,
        "temperature": 0,
        "text": " be inclined to do at first.",
        "tokens": [
          50914,
          312,
          28173,
          281,
          360,
          412,
          700,
          13,
          50976
        ]
      },
      {
        "avg_logprob": -0.2313175470056668,
        "compression_ratio": 1.6415770609318996,
        "end": 3010.6,
        "id": 1016,
        "no_speech_prob": 0.000012606938980752602,
        "seek": 299688,
        "start": 3009.12,
        "temperature": 0,
        "text": " All right, so let's go through.",
        "tokens": [
          50976,
          1057,
          558,
          11,
          370,
          718,
          311,
          352,
          807,
          13,
          51050
        ]
      },
      {
        "avg_logprob": -0.2313175470056668,
        "compression_ratio": 1.6415770609318996,
        "end": 3014,
        "id": 1017,
        "no_speech_prob": 0.000012606938980752602,
        "seek": 299688,
        "start": 3010.6,
        "temperature": 0,
        "text": " So here, these, I do not, I always want to keep them.",
        "tokens": [
          51050,
          407,
          510,
          11,
          613,
          11,
          286,
          360,
          406,
          11,
          286,
          1009,
          528,
          281,
          1066,
          552,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.2313175470056668,
        "compression_ratio": 1.6415770609318996,
        "end": 3017.08,
        "id": 1018,
        "no_speech_prob": 0.000012606938980752602,
        "seek": 299688,
        "start": 3014,
        "temperature": 0,
        "text": " m and b are variables that I need to keep throughout",
        "tokens": [
          51220,
          275,
          293,
          272,
          366,
          9102,
          300,
          286,
          643,
          281,
          1066,
          3710,
          51374
        ]
      },
      {
        "avg_logprob": -0.2313175470056668,
        "compression_ratio": 1.6415770609318996,
        "end": 3019.2000000000003,
        "id": 1019,
        "no_speech_prob": 0.000012606938980752602,
        "seek": 299688,
        "start": 3017.08,
        "temperature": 0,
        "text": " the course of this program.",
        "tokens": [
          51374,
          264,
          1164,
          295,
          341,
          1461,
          13,
          51480
        ]
      },
      {
        "avg_logprob": -0.2313175470056668,
        "compression_ratio": 1.6415770609318996,
        "end": 3023.92,
        "id": 1020,
        "no_speech_prob": 0.000012606938980752602,
        "seek": 299688,
        "start": 3019.2000000000003,
        "temperature": 0,
        "text": " Loss, do I just put tidy in here?",
        "tokens": [
          51480,
          441,
          772,
          11,
          360,
          286,
          445,
          829,
          34646,
          294,
          510,
          30,
          51716
        ]
      },
      {
        "avg_logprob": -0.2313175470056668,
        "compression_ratio": 1.6415770609318996,
        "end": 3024.52,
        "id": 1021,
        "no_speech_prob": 0.000012606938980752602,
        "seek": 299688,
        "start": 3023.92,
        "temperature": 0,
        "text": " Or should I?",
        "tokens": [
          51716,
          1610,
          820,
          286,
          30,
          51746
        ]
      },
      {
        "avg_logprob": -0.2313175470056668,
        "compression_ratio": 1.6415770609318996,
        "end": 3026.7200000000003,
        "id": 1022,
        "no_speech_prob": 0.000012606938980752602,
        "seek": 299688,
        "start": 3024.52,
        "temperature": 0,
        "text": " Let's predict.",
        "tokens": [
          51746,
          961,
          311,
          6069,
          13,
          51856
        ]
      },
      {
        "avg_logprob": -0.2032018287159572,
        "compression_ratio": 1.7243243243243243,
        "end": 3030.2799999999997,
        "id": 1023,
        "no_speech_prob": 0.0000017330513628621702,
        "seek": 302672,
        "start": 3026.72,
        "temperature": 0,
        "text": " So do I put tidy in here, or do I wrap tidy here?",
        "tokens": [
          50364,
          407,
          360,
          286,
          829,
          34646,
          294,
          510,
          11,
          420,
          360,
          286,
          7019,
          34646,
          510,
          30,
          50542
        ]
      },
      {
        "avg_logprob": -0.2032018287159572,
        "compression_ratio": 1.7243243243243243,
        "end": 3032.6,
        "id": 1024,
        "no_speech_prob": 0.0000017330513628621702,
        "seek": 302672,
        "start": 3030.2799999999997,
        "temperature": 0,
        "text": " What if I just put tidy here?",
        "tokens": [
          50542,
          708,
          498,
          286,
          445,
          829,
          34646,
          510,
          30,
          50658
        ]
      },
      {
        "avg_logprob": -0.2032018287159572,
        "compression_ratio": 1.7243243243243243,
        "end": 3041.48,
        "id": 1025,
        "no_speech_prob": 0.0000017330513628621702,
        "seek": 302672,
        "start": 3032.6,
        "temperature": 0,
        "text": " Like, what if I say tf.tidy and put all of this?",
        "tokens": [
          50658,
          1743,
          11,
          437,
          498,
          286,
          584,
          256,
          69,
          13,
          83,
          38836,
          293,
          829,
          439,
          295,
          341,
          30,
          51102
        ]
      },
      {
        "avg_logprob": -0.2032018287159572,
        "compression_ratio": 1.7243243243243243,
        "end": 3043.3599999999997,
        "id": 1026,
        "no_speech_prob": 0.0000017330513628621702,
        "seek": 302672,
        "start": 3041.48,
        "temperature": 0,
        "text": " Will this do it?",
        "tokens": [
          51102,
          3099,
          341,
          360,
          309,
          30,
          51196
        ]
      },
      {
        "avg_logprob": -0.2032018287159572,
        "compression_ratio": 1.7243243243243243,
        "end": 3047.9199999999996,
        "id": 1027,
        "no_speech_prob": 0.0000017330513628621702,
        "seek": 302672,
        "start": 3043.3599999999997,
        "temperature": 0,
        "text": " And then here, I also need to, well,",
        "tokens": [
          51196,
          400,
          550,
          510,
          11,
          286,
          611,
          643,
          281,
          11,
          731,
          11,
          51424
        ]
      },
      {
        "avg_logprob": -0.2032018287159572,
        "compression_ratio": 1.7243243243243243,
        "end": 3050.3199999999997,
        "id": 1028,
        "no_speech_prob": 0.0000017330513628621702,
        "seek": 302672,
        "start": 3047.9199999999996,
        "temperature": 0,
        "text": " here maybe what I'm going to do is just dispose these.",
        "tokens": [
          51424,
          510,
          1310,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          445,
          42537,
          613,
          13,
          51544
        ]
      },
      {
        "avg_logprob": -0.2032018287159572,
        "compression_ratio": 1.7243243243243243,
        "end": 3052.2,
        "id": 1029,
        "no_speech_prob": 0.0000017330513628621702,
        "seek": 302672,
        "start": 3050.3199999999997,
        "temperature": 0,
        "text": " There's no logic to what I'm doing,",
        "tokens": [
          51544,
          821,
          311,
          572,
          9952,
          281,
          437,
          286,
          478,
          884,
          11,
          51638
        ]
      },
      {
        "avg_logprob": -0.2032018287159572,
        "compression_ratio": 1.7243243243243243,
        "end": 3054.6,
        "id": 1030,
        "no_speech_prob": 0.0000017330513628621702,
        "seek": 302672,
        "start": 3052.2,
        "temperature": 0,
        "text": " but I'm just going to dispose these manually.",
        "tokens": [
          51638,
          457,
          286,
          478,
          445,
          516,
          281,
          42537,
          613,
          16945,
          13,
          51758
        ]
      },
      {
        "avg_logprob": -0.22654005858275267,
        "compression_ratio": 1.610655737704918,
        "end": 3059.68,
        "id": 1031,
        "no_speech_prob": 3.205827852070797e-7,
        "seek": 305460,
        "start": 3054.6,
        "temperature": 0,
        "text": " Oh, and that's just the y's, right?",
        "tokens": [
          50364,
          876,
          11,
          293,
          300,
          311,
          445,
          264,
          288,
          311,
          11,
          558,
          30,
          50618
        ]
      },
      {
        "avg_logprob": -0.22654005858275267,
        "compression_ratio": 1.610655737704918,
        "end": 3063.52,
        "id": 1032,
        "no_speech_prob": 3.205827852070797e-7,
        "seek": 305460,
        "start": 3059.68,
        "temperature": 0,
        "text": " Line y is just, ys is the only thing that's a tensor here.",
        "tokens": [
          50618,
          14670,
          288,
          307,
          445,
          11,
          288,
          82,
          307,
          264,
          787,
          551,
          300,
          311,
          257,
          40863,
          510,
          13,
          50810
        ]
      },
      {
        "avg_logprob": -0.22654005858275267,
        "compression_ratio": 1.610655737704918,
        "end": 3066.8399999999997,
        "id": 1033,
        "no_speech_prob": 3.205827852070797e-7,
        "seek": 305460,
        "start": 3063.52,
        "temperature": 0,
        "text": " So this should tidy everything, but hopefully not",
        "tokens": [
          50810,
          407,
          341,
          820,
          34646,
          1203,
          11,
          457,
          4696,
          406,
          50976
        ]
      },
      {
        "avg_logprob": -0.22654005858275267,
        "compression_ratio": 1.610655737704918,
        "end": 3069.2799999999997,
        "id": 1034,
        "no_speech_prob": 3.205827852070797e-7,
        "seek": 305460,
        "start": 3066.8399999999997,
        "temperature": 0,
        "text": " the variables that I need to keep,",
        "tokens": [
          50976,
          264,
          9102,
          300,
          286,
          643,
          281,
          1066,
          11,
          51098
        ]
      },
      {
        "avg_logprob": -0.22654005858275267,
        "compression_ratio": 1.610655737704918,
        "end": 3072.68,
        "id": 1035,
        "no_speech_prob": 3.205827852070797e-7,
        "seek": 305460,
        "start": 3069.2799999999997,
        "temperature": 0,
        "text": " rather than individually figuring out what to dispose of.",
        "tokens": [
          51098,
          2831,
          813,
          16652,
          15213,
          484,
          437,
          281,
          42537,
          295,
          13,
          51268
        ]
      },
      {
        "avg_logprob": -0.22654005858275267,
        "compression_ratio": 1.610655737704918,
        "end": 3076.96,
        "id": 1036,
        "no_speech_prob": 3.205827852070797e-7,
        "seek": 305460,
        "start": 3072.68,
        "temperature": 0,
        "text": " And down here, I kind of know that this is my only tensor.",
        "tokens": [
          51268,
          400,
          760,
          510,
          11,
          286,
          733,
          295,
          458,
          300,
          341,
          307,
          452,
          787,
          40863,
          13,
          51482
        ]
      },
      {
        "avg_logprob": -0.22654005858275267,
        "compression_ratio": 1.610655737704918,
        "end": 3080.12,
        "id": 1037,
        "no_speech_prob": 3.205827852070797e-7,
        "seek": 305460,
        "start": 3076.96,
        "temperature": 0,
        "text": " This, by the way, I should call this like line x,",
        "tokens": [
          51482,
          639,
          11,
          538,
          264,
          636,
          11,
          286,
          820,
          818,
          341,
          411,
          1622,
          2031,
          11,
          51640
        ]
      },
      {
        "avg_logprob": -0.22654005858275267,
        "compression_ratio": 1.610655737704918,
        "end": 3082.16,
        "id": 1038,
        "no_speech_prob": 3.205827852070797e-7,
        "seek": 305460,
        "start": 3080.12,
        "temperature": 0,
        "text": " just to be consistent with my variable naming.",
        "tokens": [
          51640,
          445,
          281,
          312,
          8398,
          365,
          452,
          7006,
          25290,
          13,
          51742
        ]
      },
      {
        "avg_logprob": -0.2659626183686433,
        "compression_ratio": 1.4657534246575343,
        "end": 3090.24,
        "id": 1039,
        "no_speech_prob": 4.116363641060161e-7,
        "seek": 308460,
        "start": 3085.6,
        "temperature": 0,
        "text": " You know, I'm only using the ys and xs variable name",
        "tokens": [
          50414,
          509,
          458,
          11,
          286,
          478,
          787,
          1228,
          264,
          288,
          82,
          293,
          2031,
          82,
          7006,
          1315,
          50646
        ]
      },
      {
        "avg_logprob": -0.2659626183686433,
        "compression_ratio": 1.4657534246575343,
        "end": 3092.44,
        "id": 1040,
        "no_speech_prob": 4.116363641060161e-7,
        "seek": 308460,
        "start": 3090.24,
        "temperature": 0,
        "text": " when I have something that's actually a tensor, which",
        "tokens": [
          50646,
          562,
          286,
          362,
          746,
          300,
          311,
          767,
          257,
          40863,
          11,
          597,
          50756
        ]
      },
      {
        "avg_logprob": -0.2659626183686433,
        "compression_ratio": 1.4657534246575343,
        "end": 3094.52,
        "id": 1041,
        "no_speech_prob": 4.116363641060161e-7,
        "seek": 308460,
        "start": 3092.44,
        "temperature": 0,
        "text": " helps me remember what I need to clean up and not.",
        "tokens": [
          50756,
          3665,
          385,
          1604,
          437,
          286,
          643,
          281,
          2541,
          493,
          293,
          406,
          13,
          50860
        ]
      },
      {
        "avg_logprob": -0.2659626183686433,
        "compression_ratio": 1.4657534246575343,
        "end": 3097.68,
        "id": 1042,
        "no_speech_prob": 4.116363641060161e-7,
        "seek": 308460,
        "start": 3094.52,
        "temperature": 0,
        "text": " Let's see if this goes.",
        "tokens": [
          50860,
          961,
          311,
          536,
          498,
          341,
          1709,
          13,
          51018
        ]
      },
      {
        "avg_logprob": -0.2659626183686433,
        "compression_ratio": 1.4657534246575343,
        "end": 3101.12,
        "id": 1043,
        "no_speech_prob": 4.116363641060161e-7,
        "seek": 308460,
        "start": 3097.68,
        "temperature": 0,
        "text": " It's still running.",
        "tokens": [
          51018,
          467,
          311,
          920,
          2614,
          13,
          51190
        ]
      },
      {
        "avg_logprob": -0.2659626183686433,
        "compression_ratio": 1.4657534246575343,
        "end": 3102,
        "id": 1044,
        "no_speech_prob": 4.116363641060161e-7,
        "seek": 308460,
        "start": 3101.12,
        "temperature": 0,
        "text": " 221.",
        "tokens": [
          51190,
          568,
          4436,
          13,
          51234
        ]
      },
      {
        "avg_logprob": -0.2659626183686433,
        "compression_ratio": 1.4657534246575343,
        "end": 3102.56,
        "id": 1045,
        "no_speech_prob": 4.116363641060161e-7,
        "seek": 308460,
        "start": 3102,
        "temperature": 0,
        "text": " Oh, no.",
        "tokens": [
          51234,
          876,
          11,
          572,
          13,
          51262
        ]
      },
      {
        "avg_logprob": -0.2659626183686433,
        "compression_ratio": 1.4657534246575343,
        "end": 3103.12,
        "id": 1046,
        "no_speech_prob": 4.116363641060161e-7,
        "seek": 308460,
        "start": 3102.56,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51262,
          2264,
          13,
          51290
        ]
      },
      {
        "avg_logprob": -0.2659626183686433,
        "compression_ratio": 1.4657534246575343,
        "end": 3104.6,
        "id": 1047,
        "no_speech_prob": 4.116363641060161e-7,
        "seek": 308460,
        "start": 3103.12,
        "temperature": 0,
        "text": " So I'm better.",
        "tokens": [
          51290,
          407,
          286,
          478,
          1101,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2659626183686433,
        "compression_ratio": 1.4657534246575343,
        "end": 3108.3199999999997,
        "id": 1048,
        "no_speech_prob": 4.116363641060161e-7,
        "seek": 308460,
        "start": 3104.6,
        "temperature": 0,
        "text": " There's fewer tensors, but I haven't cleaned up everything.",
        "tokens": [
          51364,
          821,
          311,
          13366,
          10688,
          830,
          11,
          457,
          286,
          2378,
          380,
          16146,
          493,
          1203,
          13,
          51550
        ]
      },
      {
        "avg_logprob": -0.2659626183686433,
        "compression_ratio": 1.4657534246575343,
        "end": 3109.52,
        "id": 1049,
        "no_speech_prob": 4.116363641060161e-7,
        "seek": 308460,
        "start": 3108.3199999999997,
        "temperature": 0,
        "text": " So what could I be missing?",
        "tokens": [
          51550,
          407,
          437,
          727,
          286,
          312,
          5361,
          30,
          51610
        ]
      },
      {
        "avg_logprob": -0.57125767417576,
        "compression_ratio": 1.4106280193236715,
        "end": 3118.2,
        "id": 1050,
        "no_speech_prob": 0.00003705295603140257,
        "seek": 311460,
        "start": 3115.6,
        "temperature": 0,
        "text": " Maybe the call to predict.",
        "tokens": [
          50414,
          2704,
          264,
          818,
          281,
          6069,
          13,
          50544
        ]
      },
      {
        "avg_logprob": -0.57125767417576,
        "compression_ratio": 1.4106280193236715,
        "end": 3121.16,
        "id": 1051,
        "no_speech_prob": 0.00003705295603140257,
        "seek": 311460,
        "start": 3118.2,
        "temperature": 0,
        "text": " Wouldn't tidy clean that up?",
        "tokens": [
          50544,
          26291,
          380,
          34646,
          2541,
          300,
          493,
          30,
          50692
        ]
      },
      {
        "avg_logprob": -0.57125767417576,
        "compression_ratio": 1.4106280193236715,
        "end": 3125.2,
        "id": 1052,
        "no_speech_prob": 0.00003705295603140257,
        "seek": 311460,
        "start": 3121.16,
        "temperature": 0,
        "text": " You know, we need a I'm going to have to think about this",
        "tokens": [
          50692,
          509,
          458,
          11,
          321,
          643,
          257,
          286,
          478,
          516,
          281,
          362,
          281,
          519,
          466,
          341,
          50894
        ]
      },
      {
        "avg_logprob": -0.57125767417576,
        "compression_ratio": 1.4106280193236715,
        "end": 3126.7999999999997,
        "id": 1053,
        "no_speech_prob": 0.00003705295603140257,
        "seek": 311460,
        "start": 3125.2,
        "temperature": 0,
        "text": " for a little bit.",
        "tokens": [
          50894,
          337,
          257,
          707,
          857,
          13,
          50974
        ]
      },
      {
        "avg_logprob": -0.57125767417576,
        "compression_ratio": 1.4106280193236715,
        "end": 3133.12,
        "id": 1054,
        "no_speech_prob": 0.00003705295603140257,
        "seek": 311460,
        "start": 3130.48,
        "temperature": 0,
        "text": " Farrink asked, just joined in, is it being recorded and posted",
        "tokens": [
          51158,
          479,
          2284,
          475,
          2351,
          11,
          445,
          6869,
          294,
          11,
          307,
          309,
          885,
          8287,
          293,
          9437,
          51290
        ]
      },
      {
        "avg_logprob": -0.57125767417576,
        "compression_ratio": 1.4106280193236715,
        "end": 3133.92,
        "id": 1055,
        "no_speech_prob": 0.00003705295603140257,
        "seek": 311460,
        "start": 3133.12,
        "temperature": 0,
        "text": " later on YouTube?",
        "tokens": [
          51290,
          1780,
          322,
          3088,
          30,
          51330
        ]
      },
      {
        "avg_logprob": -0.57125767417576,
        "compression_ratio": 1.4106280193236715,
        "end": 3134.42,
        "id": 1056,
        "no_speech_prob": 0.00003705295603140257,
        "seek": 311460,
        "start": 3133.92,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          51330,
          1079,
          13,
          51355
        ]
      },
      {
        "avg_logprob": -0.57125767417576,
        "compression_ratio": 1.4106280193236715,
        "end": 3139.4,
        "id": 1057,
        "no_speech_prob": 0.00003705295603140257,
        "seek": 311460,
        "start": 3137.68,
        "temperature": 0,
        "text": " Anybody see what tensors I'm missing?",
        "tokens": [
          51518,
          19082,
          536,
          437,
          10688,
          830,
          286,
          478,
          5361,
          30,
          51604
        ]
      },
      {
        "avg_logprob": -0.57125767417576,
        "compression_ratio": 1.4106280193236715,
        "end": 3140.96,
        "id": 1058,
        "no_speech_prob": 0.00003705295603140257,
        "seek": 311460,
        "start": 3139.4,
        "temperature": 0,
        "text": " This is like the laziest thing ever.",
        "tokens": [
          51604,
          639,
          307,
          411,
          264,
          635,
          37567,
          551,
          1562,
          13,
          51682
        ]
      },
      {
        "avg_logprob": -0.28870436724494486,
        "compression_ratio": 1.469387755102041,
        "end": 3143.16,
        "id": 1059,
        "no_speech_prob": 0.000004157361672696425,
        "seek": 314096,
        "start": 3141.4,
        "temperature": 0,
        "text": " Anybody see what tensors I'm missing?",
        "tokens": [
          50386,
          19082,
          536,
          437,
          10688,
          830,
          286,
          478,
          5361,
          30,
          50474
        ]
      },
      {
        "avg_logprob": -0.28870436724494486,
        "compression_ratio": 1.469387755102041,
        "end": 3144.68,
        "id": 1060,
        "no_speech_prob": 0.000004157361672696425,
        "seek": 314096,
        "start": 3143.16,
        "temperature": 0,
        "text": " This is like the laziest thing ever.",
        "tokens": [
          50474,
          639,
          307,
          411,
          264,
          635,
          37567,
          551,
          1562,
          13,
          50550
        ]
      },
      {
        "avg_logprob": -0.28870436724494486,
        "compression_ratio": 1.469387755102041,
        "end": 3150.32,
        "id": 1061,
        "no_speech_prob": 0.000004157361672696425,
        "seek": 314096,
        "start": 3148.48,
        "temperature": 0,
        "text": " There's got to be a good way to debug this.",
        "tokens": [
          50740,
          821,
          311,
          658,
          281,
          312,
          257,
          665,
          636,
          281,
          24083,
          341,
          13,
          50832
        ]
      },
      {
        "avg_logprob": -0.28870436724494486,
        "compression_ratio": 1.469387755102041,
        "end": 3157.44,
        "id": 1062,
        "no_speech_prob": 0.000004157361672696425,
        "seek": 314096,
        "start": 3155.92,
        "temperature": 0,
        "text": " So this definitely gets cleaned up.",
        "tokens": [
          51112,
          407,
          341,
          2138,
          2170,
          16146,
          493,
          13,
          51188
        ]
      },
      {
        "avg_logprob": -0.28870436724494486,
        "compression_ratio": 1.469387755102041,
        "end": 3158.92,
        "id": 1063,
        "no_speech_prob": 0.000004157361672696425,
        "seek": 314096,
        "start": 3157.44,
        "temperature": 0,
        "text": " The question, does everything that's",
        "tokens": [
          51188,
          440,
          1168,
          11,
          775,
          1203,
          300,
          311,
          51262
        ]
      },
      {
        "avg_logprob": -0.28870436724494486,
        "compression_ratio": 1.469387755102041,
        "end": 3166.2400000000002,
        "id": 1064,
        "no_speech_prob": 0.000004157361672696425,
        "seek": 314096,
        "start": 3158.92,
        "temperature": 0,
        "text": " made inside of the loss and the predict function get cleaned up?",
        "tokens": [
          51262,
          1027,
          1854,
          295,
          264,
          4470,
          293,
          264,
          6069,
          2445,
          483,
          16146,
          493,
          30,
          51628
        ]
      },
      {
        "avg_logprob": -0.28870436724494486,
        "compression_ratio": 1.469387755102041,
        "end": 3167.6,
        "id": 1065,
        "no_speech_prob": 0.000004157361672696425,
        "seek": 314096,
        "start": 3166.2400000000002,
        "temperature": 0,
        "text": " It would seem not.",
        "tokens": [
          51628,
          467,
          576,
          1643,
          406,
          13,
          51696
        ]
      },
      {
        "avg_logprob": -0.28870436724494486,
        "compression_ratio": 1.469387755102041,
        "end": 3169.84,
        "id": 1066,
        "no_speech_prob": 0.000004157361672696425,
        "seek": 314096,
        "start": 3167.6,
        "temperature": 0,
        "text": " Oh, hold on.",
        "tokens": [
          51696,
          876,
          11,
          1797,
          322,
          13,
          51808
        ]
      },
      {
        "avg_logprob": -0.27958108624841416,
        "compression_ratio": 1.543859649122807,
        "end": 3170.88,
        "id": 1067,
        "no_speech_prob": 0.000021444928279379383,
        "seek": 316984,
        "start": 3169.84,
        "temperature": 0,
        "text": " Let's comment this out.",
        "tokens": [
          50364,
          961,
          311,
          2871,
          341,
          484,
          13,
          50416
        ]
      },
      {
        "avg_logprob": -0.27958108624841416,
        "compression_ratio": 1.543859649122807,
        "end": 3176.88,
        "id": 1068,
        "no_speech_prob": 0.000021444928279379383,
        "seek": 316984,
        "start": 3174,
        "temperature": 0,
        "text": " It's not working, but no.",
        "tokens": [
          50572,
          467,
          311,
          406,
          1364,
          11,
          457,
          572,
          13,
          50716
        ]
      },
      {
        "avg_logprob": -0.27958108624841416,
        "compression_ratio": 1.543859649122807,
        "end": 3177.36,
        "id": 1069,
        "no_speech_prob": 0.000021444928279379383,
        "seek": 316984,
        "start": 3176.88,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50716,
          2264,
          13,
          50740
        ]
      },
      {
        "avg_logprob": -0.27958108624841416,
        "compression_ratio": 1.543859649122807,
        "end": 3177.88,
        "id": 1070,
        "no_speech_prob": 0.000021444928279379383,
        "seek": 316984,
        "start": 3177.36,
        "temperature": 0,
        "text": " That's good to know.",
        "tokens": [
          50740,
          663,
          311,
          665,
          281,
          458,
          13,
          50766
        ]
      },
      {
        "avg_logprob": -0.27958108624841416,
        "compression_ratio": 1.543859649122807,
        "end": 3178.1200000000003,
        "id": 1071,
        "no_speech_prob": 0.000021444928279379383,
        "seek": 316984,
        "start": 3177.88,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50766,
          2264,
          13,
          50778
        ]
      },
      {
        "avg_logprob": -0.27958108624841416,
        "compression_ratio": 1.543859649122807,
        "end": 3178.6200000000003,
        "id": 1072,
        "no_speech_prob": 0.000021444928279379383,
        "seek": 316984,
        "start": 3178.1200000000003,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          50778,
          6962,
          322,
          13,
          50803
        ]
      },
      {
        "avg_logprob": -0.27958108624841416,
        "compression_ratio": 1.543859649122807,
        "end": 3181.96,
        "id": 1073,
        "no_speech_prob": 0.000021444928279379383,
        "seek": 316984,
        "start": 3181.48,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50946,
          1057,
          558,
          13,
          50970
        ]
      },
      {
        "avg_logprob": -0.27958108624841416,
        "compression_ratio": 1.543859649122807,
        "end": 3183.2000000000003,
        "id": 1074,
        "no_speech_prob": 0.000021444928279379383,
        "seek": 316984,
        "start": 3181.96,
        "temperature": 0,
        "text": " I need to debug this somehow.",
        "tokens": [
          50970,
          286,
          643,
          281,
          24083,
          341,
          6063,
          13,
          51032
        ]
      },
      {
        "avg_logprob": -0.27958108624841416,
        "compression_ratio": 1.543859649122807,
        "end": 3185.6800000000003,
        "id": 1075,
        "no_speech_prob": 0.000021444928279379383,
        "seek": 316984,
        "start": 3183.2000000000003,
        "temperature": 0,
        "text": " One thing I could do is start commenting stuff out",
        "tokens": [
          51032,
          1485,
          551,
          286,
          727,
          360,
          307,
          722,
          29590,
          1507,
          484,
          51156
        ]
      },
      {
        "avg_logprob": -0.27958108624841416,
        "compression_ratio": 1.543859649122807,
        "end": 3187.88,
        "id": 1076,
        "no_speech_prob": 0.000021444928279379383,
        "seek": 316984,
        "start": 3185.6800000000003,
        "temperature": 0,
        "text": " to see where is the memory leak.",
        "tokens": [
          51156,
          281,
          536,
          689,
          307,
          264,
          4675,
          17143,
          13,
          51266
        ]
      },
      {
        "avg_logprob": -0.27958108624841416,
        "compression_ratio": 1.543859649122807,
        "end": 3189.84,
        "id": 1077,
        "no_speech_prob": 0.000021444928279379383,
        "seek": 316984,
        "start": 3187.88,
        "temperature": 0,
        "text": " So one worry I have, I really think",
        "tokens": [
          51266,
          407,
          472,
          3292,
          286,
          362,
          11,
          286,
          534,
          519,
          51364
        ]
      },
      {
        "avg_logprob": -0.27958108624841416,
        "compression_ratio": 1.543859649122807,
        "end": 3191.92,
        "id": 1078,
        "no_speech_prob": 0.000021444928279379383,
        "seek": 316984,
        "start": 3189.84,
        "temperature": 0,
        "text": " loss and predict, those functions",
        "tokens": [
          51364,
          4470,
          293,
          6069,
          11,
          729,
          6828,
          51468
        ]
      },
      {
        "avg_logprob": -0.27958108624841416,
        "compression_ratio": 1.543859649122807,
        "end": 3193.48,
        "id": 1079,
        "no_speech_prob": 0.000021444928279379383,
        "seek": 316984,
        "start": 3191.92,
        "temperature": 0,
        "text": " generate a lot of tensors.",
        "tokens": [
          51468,
          8460,
          257,
          688,
          295,
          10688,
          830,
          13,
          51546
        ]
      },
      {
        "avg_logprob": -0.27958108624841416,
        "compression_ratio": 1.543859649122807,
        "end": 3196.32,
        "id": 1080,
        "no_speech_prob": 0.000021444928279379383,
        "seek": 316984,
        "start": 3193.48,
        "temperature": 0,
        "text": " I believe tftidy should clean up anything.",
        "tokens": [
          51546,
          286,
          1697,
          256,
          844,
          38836,
          820,
          2541,
          493,
          1340,
          13,
          51688
        ]
      },
      {
        "avg_logprob": -0.2811826818129596,
        "compression_ratio": 1.5,
        "end": 3200.88,
        "id": 1081,
        "no_speech_prob": 0.000014064043170947116,
        "seek": 319632,
        "start": 3196.36,
        "temperature": 0,
        "text": " But let's just, for the sake of argument, comment this out.",
        "tokens": [
          50366,
          583,
          718,
          311,
          445,
          11,
          337,
          264,
          9717,
          295,
          6770,
          11,
          2871,
          341,
          484,
          13,
          50592
        ]
      },
      {
        "avg_logprob": -0.2811826818129596,
        "compression_ratio": 1.5,
        "end": 3207.2000000000003,
        "id": 1082,
        "no_speech_prob": 0.000014064043170947116,
        "seek": 319632,
        "start": 3203.36,
        "temperature": 0,
        "text": " And now, of course, the learning is no longer happening.",
        "tokens": [
          50716,
          400,
          586,
          11,
          295,
          1164,
          11,
          264,
          2539,
          307,
          572,
          2854,
          2737,
          13,
          50908
        ]
      },
      {
        "avg_logprob": -0.2811826818129596,
        "compression_ratio": 1.5,
        "end": 3211.56,
        "id": 1083,
        "no_speech_prob": 0.000014064043170947116,
        "seek": 319632,
        "start": 3207.2000000000003,
        "temperature": 0,
        "text": " And what I might as well do is console log",
        "tokens": [
          50908,
          400,
          437,
          286,
          1062,
          382,
          731,
          360,
          307,
          11076,
          3565,
          51126
        ]
      },
      {
        "avg_logprob": -0.2811826818129596,
        "compression_ratio": 1.5,
        "end": 3217.52,
        "id": 1084,
        "no_speech_prob": 0.000014064043170947116,
        "seek": 319632,
        "start": 3211.56,
        "temperature": 0,
        "text": " the amount of tensors, not have to ask for it.",
        "tokens": [
          51126,
          264,
          2372,
          295,
          10688,
          830,
          11,
          406,
          362,
          281,
          1029,
          337,
          309,
          13,
          51424
        ]
      },
      {
        "avg_logprob": -0.2811826818129596,
        "compression_ratio": 1.5,
        "end": 3219.44,
        "id": 1085,
        "no_speech_prob": 0.000014064043170947116,
        "seek": 319632,
        "start": 3217.52,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          51424,
          45263,
          13,
          51520
        ]
      },
      {
        "avg_logprob": -0.2811826818129596,
        "compression_ratio": 1.5,
        "end": 3220.6800000000003,
        "id": 1086,
        "no_speech_prob": 0.000014064043170947116,
        "seek": 319632,
        "start": 3219.44,
        "temperature": 0,
        "text": " What did I do wrong?",
        "tokens": [
          51520,
          708,
          630,
          286,
          360,
          2085,
          30,
          51582
        ]
      },
      {
        "avg_logprob": -0.2811826818129596,
        "compression_ratio": 1.5,
        "end": 3223,
        "id": 1087,
        "no_speech_prob": 0.000014064043170947116,
        "seek": 319632,
        "start": 3220.6800000000003,
        "temperature": 0,
        "text": " tfmemory numtensors?",
        "tokens": [
          51582,
          256,
          69,
          17886,
          827,
          1031,
          83,
          694,
          830,
          30,
          51698
        ]
      },
      {
        "avg_logprob": -0.2811826818129596,
        "compression_ratio": 1.5,
        "end": 3223.52,
        "id": 1088,
        "no_speech_prob": 0.000014064043170947116,
        "seek": 319632,
        "start": 3223,
        "temperature": 0,
        "text": " What is it?",
        "tokens": [
          51698,
          708,
          307,
          309,
          30,
          51724
        ]
      },
      {
        "avg_logprob": -0.2811826818129596,
        "compression_ratio": 1.5,
        "end": 3225.4,
        "id": 1089,
        "no_speech_prob": 0.000014064043170947116,
        "seek": 319632,
        "start": 3223.52,
        "temperature": 0,
        "text": " How come I can't remember what it is?",
        "tokens": [
          51724,
          1012,
          808,
          286,
          393,
          380,
          1604,
          437,
          309,
          307,
          30,
          51818
        ]
      },
      {
        "avg_logprob": -0.2711950514051649,
        "compression_ratio": 1.668141592920354,
        "end": 3226.36,
        "id": 1090,
        "no_speech_prob": 0.000022474079742096364,
        "seek": 322540,
        "start": 3225.4,
        "temperature": 0,
        "text": " Numtensors.",
        "tokens": [
          50364,
          22592,
          83,
          694,
          830,
          13,
          50412
        ]
      },
      {
        "avg_logprob": -0.2711950514051649,
        "compression_ratio": 1.668141592920354,
        "end": 3228.6800000000003,
        "id": 1091,
        "no_speech_prob": 0.000022474079742096364,
        "seek": 322540,
        "start": 3226.36,
        "temperature": 0,
        "text": " No.",
        "tokens": [
          50412,
          883,
          13,
          50528
        ]
      },
      {
        "avg_logprob": -0.2711950514051649,
        "compression_ratio": 1.668141592920354,
        "end": 3229.48,
        "id": 1092,
        "no_speech_prob": 0.000022474079742096364,
        "seek": 322540,
        "start": 3228.6800000000003,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          50528,
          1079,
          13,
          50568
        ]
      },
      {
        "avg_logprob": -0.2711950514051649,
        "compression_ratio": 1.668141592920354,
        "end": 3230.28,
        "id": 1093,
        "no_speech_prob": 0.000022474079742096364,
        "seek": 322540,
        "start": 3229.48,
        "temperature": 0,
        "text": " It's not a function.",
        "tokens": [
          50568,
          467,
          311,
          406,
          257,
          2445,
          13,
          50608
        ]
      },
      {
        "avg_logprob": -0.2711950514051649,
        "compression_ratio": 1.668141592920354,
        "end": 3231.12,
        "id": 1094,
        "no_speech_prob": 0.000022474079742096364,
        "seek": 322540,
        "start": 3230.28,
        "temperature": 0,
        "text": " It's just numtensors.",
        "tokens": [
          50608,
          467,
          311,
          445,
          1031,
          83,
          694,
          830,
          13,
          50650
        ]
      },
      {
        "avg_logprob": -0.2711950514051649,
        "compression_ratio": 1.668141592920354,
        "end": 3231.8,
        "id": 1095,
        "no_speech_prob": 0.000022474079742096364,
        "seek": 322540,
        "start": 3231.12,
        "temperature": 0,
        "text": " Sorry, everybody.",
        "tokens": [
          50650,
          4919,
          11,
          2201,
          13,
          50684
        ]
      },
      {
        "avg_logprob": -0.2711950514051649,
        "compression_ratio": 1.668141592920354,
        "end": 3234,
        "id": 1096,
        "no_speech_prob": 0.000022474079742096364,
        "seek": 322540,
        "start": 3231.8,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50684,
          2264,
          13,
          50794
        ]
      },
      {
        "avg_logprob": -0.2711950514051649,
        "compression_ratio": 1.668141592920354,
        "end": 3235.64,
        "id": 1097,
        "no_speech_prob": 0.000022474079742096364,
        "seek": 322540,
        "start": 3234,
        "temperature": 0,
        "text": " And I need another parentheses here.",
        "tokens": [
          50794,
          400,
          286,
          643,
          1071,
          34153,
          510,
          13,
          50876
        ]
      },
      {
        "avg_logprob": -0.2711950514051649,
        "compression_ratio": 1.668141592920354,
        "end": 3236.76,
        "id": 1098,
        "no_speech_prob": 0.000022474079742096364,
        "seek": 322540,
        "start": 3235.64,
        "temperature": 0,
        "text": " A little digression there.",
        "tokens": [
          50876,
          316,
          707,
          2528,
          2775,
          456,
          13,
          50932
        ]
      },
      {
        "avg_logprob": -0.2711950514051649,
        "compression_ratio": 1.668141592920354,
        "end": 3237.96,
        "id": 1099,
        "no_speech_prob": 0.000022474079742096364,
        "seek": 322540,
        "start": 3236.76,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50932,
          1057,
          558,
          13,
          50992
        ]
      },
      {
        "avg_logprob": -0.2711950514051649,
        "compression_ratio": 1.668141592920354,
        "end": 3238.44,
        "id": 1100,
        "no_speech_prob": 0.000022474079742096364,
        "seek": 322540,
        "start": 3237.96,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50992,
          1057,
          558,
          13,
          51016
        ]
      },
      {
        "avg_logprob": -0.2711950514051649,
        "compression_ratio": 1.668141592920354,
        "end": 3239.64,
        "id": 1101,
        "no_speech_prob": 0.000022474079742096364,
        "seek": 322540,
        "start": 3238.44,
        "temperature": 0,
        "text": " So we can see it's growing.",
        "tokens": [
          51016,
          407,
          321,
          393,
          536,
          309,
          311,
          4194,
          13,
          51076
        ]
      },
      {
        "avg_logprob": -0.2711950514051649,
        "compression_ratio": 1.668141592920354,
        "end": 3241.28,
        "id": 1102,
        "no_speech_prob": 0.000022474079742096364,
        "seek": 322540,
        "start": 3239.64,
        "temperature": 0,
        "text": " So let's keep commenting stuff out",
        "tokens": [
          51076,
          407,
          718,
          311,
          1066,
          29590,
          1507,
          484,
          51158
        ]
      },
      {
        "avg_logprob": -0.2711950514051649,
        "compression_ratio": 1.668141592920354,
        "end": 3244.8,
        "id": 1103,
        "no_speech_prob": 0.000022474079742096364,
        "seek": 322540,
        "start": 3241.28,
        "temperature": 0,
        "text": " to see what's causing the memory leak.",
        "tokens": [
          51158,
          281,
          536,
          437,
          311,
          9853,
          264,
          4675,
          17143,
          13,
          51334
        ]
      },
      {
        "avg_logprob": -0.2711950514051649,
        "compression_ratio": 1.668141592920354,
        "end": 3249.32,
        "id": 1104,
        "no_speech_prob": 0.000022474079742096364,
        "seek": 322540,
        "start": 3244.8,
        "temperature": 0,
        "text": " Let's comment out this whole area down here.",
        "tokens": [
          51334,
          961,
          311,
          2871,
          484,
          341,
          1379,
          1859,
          760,
          510,
          13,
          51560
        ]
      },
      {
        "avg_logprob": -0.2711950514051649,
        "compression_ratio": 1.668141592920354,
        "end": 3250.08,
        "id": 1105,
        "no_speech_prob": 0.000022474079742096364,
        "seek": 322540,
        "start": 3249.32,
        "temperature": 0,
        "text": " Ah.",
        "tokens": [
          51560,
          2438,
          13,
          51598
        ]
      },
      {
        "avg_logprob": -0.2711950514051649,
        "compression_ratio": 1.668141592920354,
        "end": 3251.88,
        "id": 1106,
        "no_speech_prob": 0.000022474079742096364,
        "seek": 322540,
        "start": 3250.08,
        "temperature": 0,
        "text": " Good news, everybody.",
        "tokens": [
          51598,
          2205,
          2583,
          11,
          2201,
          13,
          51688
        ]
      },
      {
        "avg_logprob": -0.2711950514051649,
        "compression_ratio": 1.668141592920354,
        "end": 3254.32,
        "id": 1107,
        "no_speech_prob": 0.000022474079742096364,
        "seek": 322540,
        "start": 3251.88,
        "temperature": 0,
        "text": " The memory leak is in that part.",
        "tokens": [
          51688,
          440,
          4675,
          17143,
          307,
          294,
          300,
          644,
          13,
          51810
        ]
      },
      {
        "avg_logprob": -0.2753209851004861,
        "compression_ratio": 1.4814814814814814,
        "end": 3256.88,
        "id": 1108,
        "no_speech_prob": 0.00002753568878688384,
        "seek": 325432,
        "start": 3254.32,
        "temperature": 0,
        "text": " Let's put this back just to be sure.",
        "tokens": [
          50364,
          961,
          311,
          829,
          341,
          646,
          445,
          281,
          312,
          988,
          13,
          50492
        ]
      },
      {
        "avg_logprob": -0.2753209851004861,
        "compression_ratio": 1.4814814814814814,
        "end": 3263.26,
        "id": 1109,
        "no_speech_prob": 0.00002753568878688384,
        "seek": 325432,
        "start": 3262.76,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50786,
          2264,
          13,
          50811
        ]
      },
      {
        "avg_logprob": -0.2753209851004861,
        "compression_ratio": 1.4814814814814814,
        "end": 3263.76,
        "id": 1110,
        "no_speech_prob": 0.00002753568878688384,
        "seek": 325432,
        "start": 3263.26,
        "temperature": 0,
        "text": " Ah.",
        "tokens": [
          50811,
          2438,
          13,
          50836
        ]
      },
      {
        "avg_logprob": -0.2753209851004861,
        "compression_ratio": 1.4814814814814814,
        "end": 3266.6400000000003,
        "id": 1111,
        "no_speech_prob": 0.00002753568878688384,
        "seek": 325432,
        "start": 3263.76,
        "temperature": 0,
        "text": " So the memory leak is definitely down here.",
        "tokens": [
          50836,
          407,
          264,
          4675,
          17143,
          307,
          2138,
          760,
          510,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.2753209851004861,
        "compression_ratio": 1.4814814814814814,
        "end": 3268.2000000000003,
        "id": 1112,
        "no_speech_prob": 0.00002753568878688384,
        "seek": 325432,
        "start": 3266.6400000000003,
        "temperature": 0,
        "text": " And I'm probably creating.",
        "tokens": [
          50980,
          400,
          286,
          478,
          1391,
          4084,
          13,
          51058
        ]
      },
      {
        "avg_logprob": -0.2753209851004861,
        "compression_ratio": 1.4814814814814814,
        "end": 3269.52,
        "id": 1113,
        "no_speech_prob": 0.00002753568878688384,
        "seek": 325432,
        "start": 3268.2000000000003,
        "temperature": 0,
        "text": " Oh my goodness.",
        "tokens": [
          51058,
          876,
          452,
          8387,
          13,
          51124
        ]
      },
      {
        "avg_logprob": -0.2753209851004861,
        "compression_ratio": 1.4814814814814814,
        "end": 3273.7200000000003,
        "id": 1114,
        "no_speech_prob": 0.00002753568878688384,
        "seek": 325432,
        "start": 3273,
        "temperature": 0,
        "text": " Oh my goodness.",
        "tokens": [
          51298,
          876,
          452,
          8387,
          13,
          51334
        ]
      },
      {
        "avg_logprob": -0.2753209851004861,
        "compression_ratio": 1.4814814814814814,
        "end": 3278.8,
        "id": 1115,
        "no_speech_prob": 0.00002753568878688384,
        "seek": 325432,
        "start": 3277.76,
        "temperature": 0,
        "text": " No, I'm not sure.",
        "tokens": [
          51536,
          883,
          11,
          286,
          478,
          406,
          988,
          13,
          51588
        ]
      },
      {
        "avg_logprob": -0.2753209851004861,
        "compression_ratio": 1.4814814814814814,
        "end": 3280.52,
        "id": 1116,
        "no_speech_prob": 0.00002753568878688384,
        "seek": 325432,
        "start": 3278.8,
        "temperature": 0,
        "text": " Well, let's put this back in.",
        "tokens": [
          51588,
          1042,
          11,
          718,
          311,
          829,
          341,
          646,
          294,
          13,
          51674
        ]
      },
      {
        "avg_logprob": -0.2753209851004861,
        "compression_ratio": 1.4814814814814814,
        "end": 3283,
        "id": 1117,
        "no_speech_prob": 0.00002753568878688384,
        "seek": 325432,
        "start": 3280.52,
        "temperature": 0,
        "text": " I thought I saw it, but then I didn't again.",
        "tokens": [
          51674,
          286,
          1194,
          286,
          1866,
          309,
          11,
          457,
          550,
          286,
          994,
          380,
          797,
          13,
          51798
        ]
      },
      {
        "avg_logprob": -0.2960950930913289,
        "compression_ratio": 1.5280898876404494,
        "end": 3284.92,
        "id": 1118,
        "no_speech_prob": 0.000005862812031409703,
        "seek": 328300,
        "start": 3283.04,
        "temperature": 0,
        "text": " So this is a tensor.",
        "tokens": [
          50366,
          407,
          341,
          307,
          257,
          40863,
          13,
          50460
        ]
      },
      {
        "avg_logprob": -0.2960950930913289,
        "compression_ratio": 1.5280898876404494,
        "end": 3286.16,
        "id": 1119,
        "no_speech_prob": 0.000005862812031409703,
        "seek": 328300,
        "start": 3284.92,
        "temperature": 0,
        "text": " And I'm disposing it.",
        "tokens": [
          50460,
          400,
          286,
          478,
          4920,
          6110,
          309,
          13,
          50522
        ]
      },
      {
        "avg_logprob": -0.2960950930913289,
        "compression_ratio": 1.5280898876404494,
        "end": 3290.92,
        "id": 1120,
        "no_speech_prob": 0.000005862812031409703,
        "seek": 328300,
        "start": 3289.04,
        "temperature": 0,
        "text": " Oh, predict.",
        "tokens": [
          50666,
          876,
          11,
          6069,
          13,
          50760
        ]
      },
      {
        "avg_logprob": -0.2960950930913289,
        "compression_ratio": 1.5280898876404494,
        "end": 3292.28,
        "id": 1121,
        "no_speech_prob": 0.000005862812031409703,
        "seek": 328300,
        "start": 3290.92,
        "temperature": 0,
        "text": " Aha.",
        "tokens": [
          50760,
          27448,
          13,
          50828
        ]
      },
      {
        "avg_logprob": -0.2960950930913289,
        "compression_ratio": 1.5280898876404494,
        "end": 3295.16,
        "id": 1122,
        "no_speech_prob": 0.000005862812031409703,
        "seek": 328300,
        "start": 3292.28,
        "temperature": 0,
        "text": " The predict function makes other tensors.",
        "tokens": [
          50828,
          440,
          6069,
          2445,
          1669,
          661,
          10688,
          830,
          13,
          50972
        ]
      },
      {
        "avg_logprob": -0.2960950930913289,
        "compression_ratio": 1.5280898876404494,
        "end": 3298.16,
        "id": 1123,
        "no_speech_prob": 0.000005862812031409703,
        "seek": 328300,
        "start": 3295.16,
        "temperature": 0,
        "text": " And predict got cleaned up because it was in tidy,",
        "tokens": [
          50972,
          400,
          6069,
          658,
          16146,
          493,
          570,
          309,
          390,
          294,
          34646,
          11,
          51122
        ]
      },
      {
        "avg_logprob": -0.2960950930913289,
        "compression_ratio": 1.5280898876404494,
        "end": 3301.84,
        "id": 1124,
        "no_speech_prob": 0.000005862812031409703,
        "seek": 328300,
        "start": 3298.16,
        "temperature": 0,
        "text": " but I'm just manually disposing the y's down there.",
        "tokens": [
          51122,
          457,
          286,
          478,
          445,
          16945,
          4920,
          6110,
          264,
          288,
          311,
          760,
          456,
          13,
          51306
        ]
      },
      {
        "avg_logprob": -0.2960950930913289,
        "compression_ratio": 1.5280898876404494,
        "end": 3303.04,
        "id": 1125,
        "no_speech_prob": 0.000005862812031409703,
        "seek": 328300,
        "start": 3301.84,
        "temperature": 0,
        "text": " That's what it is.",
        "tokens": [
          51306,
          663,
          311,
          437,
          309,
          307,
          13,
          51366
        ]
      },
      {
        "avg_logprob": -0.2960950930913289,
        "compression_ratio": 1.5280898876404494,
        "end": 3304.28,
        "id": 1126,
        "no_speech_prob": 0.000005862812031409703,
        "seek": 328300,
        "start": 3303.04,
        "temperature": 0,
        "text": " So let me use tidy.",
        "tokens": [
          51366,
          407,
          718,
          385,
          764,
          34646,
          13,
          51428
        ]
      },
      {
        "avg_logprob": -0.2960950930913289,
        "compression_ratio": 1.5280898876404494,
        "end": 3308.14,
        "id": 1127,
        "no_speech_prob": 0.000005862812031409703,
        "seek": 328300,
        "start": 3307.64,
        "temperature": 0,
        "text": " I guess.",
        "tokens": [
          51596,
          286,
          2041,
          13,
          51621
        ]
      },
      {
        "avg_logprob": -0.2960950930913289,
        "compression_ratio": 1.5280898876404494,
        "end": 3312.24,
        "id": 1128,
        "no_speech_prob": 0.000005862812031409703,
        "seek": 328300,
        "start": 3311.04,
        "temperature": 0,
        "text": " So let me do this.",
        "tokens": [
          51766,
          407,
          718,
          385,
          360,
          341,
          13,
          51826
        ]
      },
      {
        "avg_logprob": -0.22390163306033972,
        "compression_ratio": 1.6666666666666667,
        "end": 3314,
        "id": 1129,
        "no_speech_prob": 0.000009818325452215504,
        "seek": 331224,
        "start": 3312.2799999999997,
        "temperature": 0,
        "text": " Let me put this up here.",
        "tokens": [
          50366,
          961,
          385,
          829,
          341,
          493,
          510,
          13,
          50452
        ]
      },
      {
        "avg_logprob": -0.22390163306033972,
        "compression_ratio": 1.6666666666666667,
        "end": 3317.52,
        "id": 1130,
        "no_speech_prob": 0.000009818325452215504,
        "seek": 331224,
        "start": 3314,
        "temperature": 0,
        "text": " So this is really what I need to tidy.",
        "tokens": [
          50452,
          407,
          341,
          307,
          534,
          437,
          286,
          643,
          281,
          34646,
          13,
          50628
        ]
      },
      {
        "avg_logprob": -0.22390163306033972,
        "compression_ratio": 1.6666666666666667,
        "end": 3324.6,
        "id": 1131,
        "no_speech_prob": 0.000009818325452215504,
        "seek": 331224,
        "start": 3320.4799999999996,
        "temperature": 0,
        "text": " So instead of disposing manually,",
        "tokens": [
          50776,
          407,
          2602,
          295,
          4920,
          6110,
          16945,
          11,
          50982
        ]
      },
      {
        "avg_logprob": -0.22390163306033972,
        "compression_ratio": 1.6666666666666667,
        "end": 3326.4799999999996,
        "id": 1132,
        "no_speech_prob": 0.000009818325452215504,
        "seek": 331224,
        "start": 3324.6,
        "temperature": 0,
        "text": " I kind of like disposing things manually.",
        "tokens": [
          50982,
          286,
          733,
          295,
          411,
          4920,
          6110,
          721,
          16945,
          13,
          51076
        ]
      },
      {
        "avg_logprob": -0.22390163306033972,
        "compression_ratio": 1.6666666666666667,
        "end": 3328.6,
        "id": 1133,
        "no_speech_prob": 0.000009818325452215504,
        "seek": 331224,
        "start": 3326.4799999999996,
        "temperature": 0,
        "text": " The tidy thing kind of freaks me out.",
        "tokens": [
          51076,
          440,
          34646,
          551,
          733,
          295,
          2130,
          5461,
          385,
          484,
          13,
          51182
        ]
      },
      {
        "avg_logprob": -0.22390163306033972,
        "compression_ratio": 1.6666666666666667,
        "end": 3332.16,
        "id": 1134,
        "no_speech_prob": 0.000009818325452215504,
        "seek": 331224,
        "start": 3328.6,
        "temperature": 0,
        "text": " But the problem with this is I have a scope issue,",
        "tokens": [
          51182,
          583,
          264,
          1154,
          365,
          341,
          307,
          286,
          362,
          257,
          11923,
          2734,
          11,
          51360
        ]
      },
      {
        "avg_logprob": -0.22390163306033972,
        "compression_ratio": 1.6666666666666667,
        "end": 3336.8799999999997,
        "id": 1135,
        "no_speech_prob": 0.000009818325452215504,
        "seek": 331224,
        "start": 3332.16,
        "temperature": 0,
        "text": " which is that line y, no matter what I do,",
        "tokens": [
          51360,
          597,
          307,
          300,
          1622,
          288,
          11,
          572,
          1871,
          437,
          286,
          360,
          11,
          51596
        ]
      },
      {
        "avg_logprob": -0.22390163306033972,
        "compression_ratio": 1.6666666666666667,
        "end": 3340.04,
        "id": 1136,
        "no_speech_prob": 0.000009818325452215504,
        "seek": 331224,
        "start": 3336.8799999999997,
        "temperature": 0,
        "text": " if I take this out here, this is going to tidy everything.",
        "tokens": [
          51596,
          498,
          286,
          747,
          341,
          484,
          510,
          11,
          341,
          307,
          516,
          281,
          34646,
          1203,
          13,
          51754
        ]
      },
      {
        "avg_logprob": -0.20812393117834022,
        "compression_ratio": 1.7028301886792452,
        "end": 3343.64,
        "id": 1137,
        "no_speech_prob": 7.224439855235687e-7,
        "seek": 334004,
        "start": 3340.04,
        "temperature": 0,
        "text": " So I guess it's not the biggest deal, at the moment at least,",
        "tokens": [
          50364,
          407,
          286,
          2041,
          309,
          311,
          406,
          264,
          3880,
          2028,
          11,
          412,
          264,
          1623,
          412,
          1935,
          11,
          50544
        ]
      },
      {
        "avg_logprob": -0.20812393117834022,
        "compression_ratio": 1.7028301886792452,
        "end": 3348.32,
        "id": 1138,
        "no_speech_prob": 7.224439855235687e-7,
        "seek": 334004,
        "start": 3343.64,
        "temperature": 0,
        "text": " for me to just put everything inside the tidy.",
        "tokens": [
          50544,
          337,
          385,
          281,
          445,
          829,
          1203,
          1854,
          264,
          34646,
          13,
          50778
        ]
      },
      {
        "avg_logprob": -0.20812393117834022,
        "compression_ratio": 1.7028301886792452,
        "end": 3354.08,
        "id": 1139,
        "no_speech_prob": 7.224439855235687e-7,
        "seek": 334004,
        "start": 3348.32,
        "temperature": 0,
        "text": " Well, let's put everything inside the tidy for right now.",
        "tokens": [
          50778,
          1042,
          11,
          718,
          311,
          829,
          1203,
          1854,
          264,
          34646,
          337,
          558,
          586,
          13,
          51066
        ]
      },
      {
        "avg_logprob": -0.20812393117834022,
        "compression_ratio": 1.7028301886792452,
        "end": 3356.36,
        "id": 1140,
        "no_speech_prob": 7.224439855235687e-7,
        "seek": 334004,
        "start": 3354.08,
        "temperature": 0,
        "text": " There's probably a way I could simplify that,",
        "tokens": [
          51066,
          821,
          311,
          1391,
          257,
          636,
          286,
          727,
          20460,
          300,
          11,
          51180
        ]
      },
      {
        "avg_logprob": -0.20812393117834022,
        "compression_ratio": 1.7028301886792452,
        "end": 3357.2799999999997,
        "id": 1141,
        "no_speech_prob": 7.224439855235687e-7,
        "seek": 334004,
        "start": 3356.36,
        "temperature": 0,
        "text": " but this should work.",
        "tokens": [
          51180,
          457,
          341,
          820,
          589,
          13,
          51226
        ]
      },
      {
        "avg_logprob": -0.20812393117834022,
        "compression_ratio": 1.7028301886792452,
        "end": 3358.2,
        "id": 1142,
        "no_speech_prob": 7.224439855235687e-7,
        "seek": 334004,
        "start": 3357.2799999999997,
        "temperature": 0,
        "text": " Let's give this a try.",
        "tokens": [
          51226,
          961,
          311,
          976,
          341,
          257,
          853,
          13,
          51272
        ]
      },
      {
        "avg_logprob": -0.20812393117834022,
        "compression_ratio": 1.7028301886792452,
        "end": 3362.6,
        "id": 1143,
        "no_speech_prob": 7.224439855235687e-7,
        "seek": 334004,
        "start": 3361.92,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51458,
          821,
          321,
          352,
          13,
          51492
        ]
      },
      {
        "avg_logprob": -0.20812393117834022,
        "compression_ratio": 1.7028301886792452,
        "end": 3366.4,
        "id": 1144,
        "no_speech_prob": 7.224439855235687e-7,
        "seek": 334004,
        "start": 3362.6,
        "temperature": 0,
        "text": " There's only ever five tensors all the time.",
        "tokens": [
          51492,
          821,
          311,
          787,
          1562,
          1732,
          10688,
          830,
          439,
          264,
          565,
          13,
          51682
        ]
      },
      {
        "avg_logprob": -0.20812393117834022,
        "compression_ratio": 1.7028301886792452,
        "end": 3369.2,
        "id": 1145,
        "no_speech_prob": 7.224439855235687e-7,
        "seek": 334004,
        "start": 3366.4,
        "temperature": 0,
        "text": " So there's no more memory leak, five tensors,",
        "tokens": [
          51682,
          407,
          456,
          311,
          572,
          544,
          4675,
          17143,
          11,
          1732,
          10688,
          830,
          11,
          51822
        ]
      },
      {
        "avg_logprob": -0.33518558740615845,
        "compression_ratio": 1.2857142857142858,
        "end": 3371.6,
        "id": 1146,
        "no_speech_prob": 0.00006302749534370378,
        "seek": 336920,
        "start": 3369.24,
        "temperature": 0,
        "text": " linear regression with gradient descent,",
        "tokens": [
          50366,
          8213,
          24590,
          365,
          16235,
          23475,
          11,
          50484
        ]
      },
      {
        "avg_logprob": -0.33518558740615845,
        "compression_ratio": 1.2857142857142858,
        "end": 3373.72,
        "id": 1147,
        "no_speech_prob": 0.00006302749534370378,
        "seek": 336920,
        "start": 3371.6,
        "temperature": 0,
        "text": " TensorFlow.js, interactive.",
        "tokens": [
          50484,
          37624,
          13,
          25530,
          11,
          15141,
          13,
          50590
        ]
      },
      {
        "avg_logprob": -0.33518558740615845,
        "compression_ratio": 1.2857142857142858,
        "end": 3374.24,
        "id": 1148,
        "no_speech_prob": 0.00006302749534370378,
        "seek": 336920,
        "start": 3373.72,
        "temperature": 0,
        "text": " Here it is.",
        "tokens": [
          50590,
          1692,
          309,
          307,
          13,
          50616
        ]
      },
      {
        "avg_logprob": -0.33518558740615845,
        "compression_ratio": 1.2857142857142858,
        "end": 3376.2,
        "id": 1149,
        "no_speech_prob": 0.00006302749534370378,
        "seek": 336920,
        "start": 3374.24,
        "temperature": 0,
        "text": " So what's left here?",
        "tokens": [
          50616,
          407,
          437,
          311,
          1411,
          510,
          30,
          50714
        ]
      },
      {
        "avg_logprob": -0.33518558740615845,
        "compression_ratio": 1.2857142857142858,
        "end": 3379.7999999999997,
        "id": 1150,
        "no_speech_prob": 0.00006302749534370378,
        "seek": 336920,
        "start": 3376.2,
        "temperature": 0,
        "text": " So number one, things that could be improved.",
        "tokens": [
          50714,
          407,
          1230,
          472,
          11,
          721,
          300,
          727,
          312,
          9689,
          13,
          50894
        ]
      },
      {
        "avg_logprob": -0.33518558740615845,
        "compression_ratio": 1.2857142857142858,
        "end": 3380.2999999999997,
        "id": 1151,
        "no_speech_prob": 0.00006302749534370378,
        "seek": 336920,
        "start": 3379.7999999999997,
        "temperature": 0,
        "text": " Pause.",
        "tokens": [
          50894,
          31973,
          13,
          50919
        ]
      },
      {
        "avg_logprob": -0.33518558740615845,
        "compression_ratio": 1.2857142857142858,
        "end": 3387.2599999999998,
        "id": 1152,
        "no_speech_prob": 0.00006302749534370378,
        "seek": 336920,
        "start": 3386.7599999999998,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          51242,
          876,
          13,
          51267
        ]
      },
      {
        "avg_logprob": -0.33518558740615845,
        "compression_ratio": 1.2857142857142858,
        "end": 3395.2799999999997,
        "id": 1153,
        "no_speech_prob": 0.00006302749534370378,
        "seek": 336920,
        "start": 3392.48,
        "temperature": 0,
        "text": " So I could say, ah, all right.",
        "tokens": [
          51528,
          407,
          286,
          727,
          584,
          11,
          3716,
          11,
          439,
          558,
          13,
          51668
        ]
      },
      {
        "avg_logprob": -0.308564786557798,
        "compression_ratio": 1.6217391304347826,
        "end": 3398.52,
        "id": 1154,
        "no_speech_prob": 0.000004092911694897339,
        "seek": 339528,
        "start": 3395.28,
        "temperature": 0,
        "text": " So line y, ys.",
        "tokens": [
          50364,
          407,
          1622,
          288,
          11,
          288,
          82,
          13,
          50526
        ]
      },
      {
        "avg_logprob": -0.308564786557798,
        "compression_ratio": 1.6217391304347826,
        "end": 3401.7200000000003,
        "id": 1155,
        "no_speech_prob": 0.000004092911694897339,
        "seek": 339528,
        "start": 3398.52,
        "temperature": 0,
        "text": " So I could actually just put a tidy here and have it return.",
        "tokens": [
          50526,
          407,
          286,
          727,
          767,
          445,
          829,
          257,
          34646,
          510,
          293,
          362,
          309,
          2736,
          13,
          50686
        ]
      },
      {
        "avg_logprob": -0.308564786557798,
        "compression_ratio": 1.6217391304347826,
        "end": 3408.44,
        "id": 1156,
        "no_speech_prob": 0.000004092911694897339,
        "seek": 339528,
        "start": 3405.8,
        "temperature": 0,
        "text": " So I wanted to talk through some things that could be improved,",
        "tokens": [
          50890,
          407,
          286,
          1415,
          281,
          751,
          807,
          512,
          721,
          300,
          727,
          312,
          9689,
          11,
          51022
        ]
      },
      {
        "avg_logprob": -0.308564786557798,
        "compression_ratio": 1.6217391304347826,
        "end": 3410.0400000000004,
        "id": 1157,
        "no_speech_prob": 0.000004092911694897339,
        "seek": 339528,
        "start": 3408.44,
        "temperature": 0,
        "text": " but already, meiamsami in the chat",
        "tokens": [
          51022,
          457,
          1217,
          11,
          385,
          2918,
          82,
          4526,
          294,
          264,
          5081,
          51102
        ]
      },
      {
        "avg_logprob": -0.308564786557798,
        "compression_ratio": 1.6217391304347826,
        "end": 3411.2000000000003,
        "id": 1158,
        "no_speech_prob": 0.000004092911694897339,
        "seek": 339528,
        "start": 3410.0400000000004,
        "temperature": 0,
        "text": " made a very good suggestion.",
        "tokens": [
          51102,
          1027,
          257,
          588,
          665,
          16541,
          13,
          51160
        ]
      },
      {
        "avg_logprob": -0.308564786557798,
        "compression_ratio": 1.6217391304347826,
        "end": 3413.48,
        "id": 1159,
        "no_speech_prob": 0.000004092911694897339,
        "seek": 339528,
        "start": 3411.2000000000003,
        "temperature": 0,
        "text": " This is very awkward, how I put everything in tidy.",
        "tokens": [
          51160,
          639,
          307,
          588,
          11411,
          11,
          577,
          286,
          829,
          1203,
          294,
          34646,
          13,
          51274
        ]
      },
      {
        "avg_logprob": -0.308564786557798,
        "compression_ratio": 1.6217391304347826,
        "end": 3416.1200000000003,
        "id": 1160,
        "no_speech_prob": 0.000004092911694897339,
        "seek": 339528,
        "start": 3413.48,
        "temperature": 0,
        "text": " So unnecessary.",
        "tokens": [
          51274,
          407,
          19350,
          13,
          51406
        ]
      },
      {
        "avg_logprob": -0.308564786557798,
        "compression_ratio": 1.6217391304347826,
        "end": 3417.5600000000004,
        "id": 1161,
        "no_speech_prob": 0.000004092911694897339,
        "seek": 339528,
        "start": 3416.1200000000003,
        "temperature": 0,
        "text": " Let me take that out.",
        "tokens": [
          51406,
          961,
          385,
          747,
          300,
          484,
          13,
          51478
        ]
      },
      {
        "avg_logprob": -0.308564786557798,
        "compression_ratio": 1.6217391304347826,
        "end": 3421.1600000000003,
        "id": 1162,
        "no_speech_prob": 0.000004092911694897339,
        "seek": 339528,
        "start": 3417.5600000000004,
        "temperature": 0,
        "text": " Because predict returns something,",
        "tokens": [
          51478,
          1436,
          6069,
          11247,
          746,
          11,
          51658
        ]
      },
      {
        "avg_logprob": -0.308564786557798,
        "compression_ratio": 1.6217391304347826,
        "end": 3423.48,
        "id": 1163,
        "no_speech_prob": 0.000004092911694897339,
        "seek": 339528,
        "start": 3421.1600000000003,
        "temperature": 0,
        "text": " I can actually just put the tidy right here.",
        "tokens": [
          51658,
          286,
          393,
          767,
          445,
          829,
          264,
          34646,
          558,
          510,
          13,
          51774
        ]
      },
      {
        "avg_logprob": -0.21696014404296876,
        "compression_ratio": 1.5606060606060606,
        "end": 3425.52,
        "id": 1164,
        "no_speech_prob": 8.851569646139978e-7,
        "seek": 342348,
        "start": 3423.48,
        "temperature": 0,
        "text": " I don't know why I didn't think of that.",
        "tokens": [
          50364,
          286,
          500,
          380,
          458,
          983,
          286,
          994,
          380,
          519,
          295,
          300,
          13,
          50466
        ]
      },
      {
        "avg_logprob": -0.21696014404296876,
        "compression_ratio": 1.5606060606060606,
        "end": 3429.6,
        "id": 1165,
        "no_speech_prob": 8.851569646139978e-7,
        "seek": 342348,
        "start": 3425.52,
        "temperature": 0,
        "text": " I can actually just, it's only this predict function.",
        "tokens": [
          50466,
          286,
          393,
          767,
          445,
          11,
          309,
          311,
          787,
          341,
          6069,
          2445,
          13,
          50670
        ]
      },
      {
        "avg_logprob": -0.21696014404296876,
        "compression_ratio": 1.5606060606060606,
        "end": 3433.32,
        "id": 1166,
        "no_speech_prob": 8.851569646139978e-7,
        "seek": 342348,
        "start": 3429.6,
        "temperature": 0,
        "text": " So I can actually put the tidy right here.",
        "tokens": [
          50670,
          407,
          286,
          393,
          767,
          829,
          264,
          34646,
          558,
          510,
          13,
          50856
        ]
      },
      {
        "avg_logprob": -0.21696014404296876,
        "compression_ratio": 1.5606060606060606,
        "end": 3438.84,
        "id": 1167,
        "no_speech_prob": 8.851569646139978e-7,
        "seek": 342348,
        "start": 3433.32,
        "temperature": 0,
        "text": " And I can use my fancy ES6 arrow syntax.",
        "tokens": [
          50856,
          400,
          286,
          393,
          764,
          452,
          10247,
          12564,
          21,
          11610,
          28431,
          13,
          51132
        ]
      },
      {
        "avg_logprob": -0.21696014404296876,
        "compression_ratio": 1.5606060606060606,
        "end": 3441.16,
        "id": 1168,
        "no_speech_prob": 8.851569646139978e-7,
        "seek": 342348,
        "start": 3438.84,
        "temperature": 0,
        "text": " And the return is now assumed.",
        "tokens": [
          51132,
          400,
          264,
          2736,
          307,
          586,
          15895,
          13,
          51248
        ]
      },
      {
        "avg_logprob": -0.21696014404296876,
        "compression_ratio": 1.5606060606060606,
        "end": 3444.56,
        "id": 1169,
        "no_speech_prob": 8.851569646139978e-7,
        "seek": 342348,
        "start": 3441.16,
        "temperature": 0,
        "text": " And then I can just say ys.dispose.",
        "tokens": [
          51248,
          400,
          550,
          286,
          393,
          445,
          584,
          288,
          82,
          13,
          67,
          7631,
          541,
          13,
          51418
        ]
      },
      {
        "avg_logprob": -0.21696014404296876,
        "compression_ratio": 1.5606060606060606,
        "end": 3445.68,
        "id": 1170,
        "no_speech_prob": 8.851569646139978e-7,
        "seek": 342348,
        "start": 3444.56,
        "temperature": 0,
        "text": " So this should work.",
        "tokens": [
          51418,
          407,
          341,
          820,
          589,
          13,
          51474
        ]
      },
      {
        "avg_logprob": -0.21696014404296876,
        "compression_ratio": 1.5606060606060606,
        "end": 3450.1,
        "id": 1171,
        "no_speech_prob": 8.851569646139978e-7,
        "seek": 342348,
        "start": 3445.68,
        "temperature": 0,
        "text": " Tidy is not going to tidy up this y value,",
        "tokens": [
          51474,
          314,
          38836,
          307,
          406,
          516,
          281,
          34646,
          493,
          341,
          288,
          2158,
          11,
          51695
        ]
      },
      {
        "avg_logprob": -0.26800496813277125,
        "compression_ratio": 1.6334519572953736,
        "end": 3453.54,
        "id": 1172,
        "no_speech_prob": 0.00003883110184688121,
        "seek": 345010,
        "start": 3450.1,
        "temperature": 0,
        "text": " but I can dispose that manually once I have the values.",
        "tokens": [
          50364,
          457,
          286,
          393,
          42537,
          300,
          16945,
          1564,
          286,
          362,
          264,
          4190,
          13,
          50536
        ]
      },
      {
        "avg_logprob": -0.26800496813277125,
        "compression_ratio": 1.6334519572953736,
        "end": 3455.02,
        "id": 1173,
        "no_speech_prob": 0.00003883110184688121,
        "seek": 345010,
        "start": 3453.54,
        "temperature": 0,
        "text": " So I think this will do the trick.",
        "tokens": [
          50536,
          407,
          286,
          519,
          341,
          486,
          360,
          264,
          4282,
          13,
          50610
        ]
      },
      {
        "avg_logprob": -0.26800496813277125,
        "compression_ratio": 1.6334519572953736,
        "end": 3456.94,
        "id": 1174,
        "no_speech_prob": 0.00003883110184688121,
        "seek": 345010,
        "start": 3455.02,
        "temperature": 0,
        "text": " Let me just take a look at this.",
        "tokens": [
          50610,
          961,
          385,
          445,
          747,
          257,
          574,
          412,
          341,
          13,
          50706
        ]
      },
      {
        "avg_logprob": -0.26800496813277125,
        "compression_ratio": 1.6334519572953736,
        "end": 3457.7,
        "id": 1175,
        "no_speech_prob": 0.00003883110184688121,
        "seek": 345010,
        "start": 3456.94,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          50706,
          865,
          13,
          50744
        ]
      },
      {
        "avg_logprob": -0.26800496813277125,
        "compression_ratio": 1.6334519572953736,
        "end": 3459.3399999999997,
        "id": 1176,
        "no_speech_prob": 0.00003883110184688121,
        "seek": 345010,
        "start": 3457.7,
        "temperature": 0,
        "text": " So this I like better.",
        "tokens": [
          50744,
          407,
          341,
          286,
          411,
          1101,
          13,
          50826
        ]
      },
      {
        "avg_logprob": -0.26800496813277125,
        "compression_ratio": 1.6334519572953736,
        "end": 3461.74,
        "id": 1177,
        "no_speech_prob": 0.00003883110184688121,
        "seek": 345010,
        "start": 3459.3399999999997,
        "temperature": 0,
        "text": " And there's probably other styles or ways you could do it.",
        "tokens": [
          50826,
          400,
          456,
          311,
          1391,
          661,
          13273,
          420,
          2098,
          291,
          727,
          360,
          309,
          13,
          50946
        ]
      },
      {
        "avg_logprob": -0.26800496813277125,
        "compression_ratio": 1.6334519572953736,
        "end": 3464.1,
        "id": 1178,
        "no_speech_prob": 0.00003883110184688121,
        "seek": 345010,
        "start": 3461.74,
        "temperature": 0,
        "text": " The point is, you've got to keep track of all the tensors",
        "tokens": [
          50946,
          440,
          935,
          307,
          11,
          291,
          600,
          658,
          281,
          1066,
          2837,
          295,
          439,
          264,
          10688,
          830,
          51064
        ]
      },
      {
        "avg_logprob": -0.26800496813277125,
        "compression_ratio": 1.6334519572953736,
        "end": 3467.14,
        "id": 1179,
        "no_speech_prob": 0.00003883110184688121,
        "seek": 345010,
        "start": 3464.1,
        "temperature": 0,
        "text": " you're making and dispose them.",
        "tokens": [
          51064,
          291,
          434,
          1455,
          293,
          42537,
          552,
          13,
          51216
        ]
      },
      {
        "avg_logprob": -0.26800496813277125,
        "compression_ratio": 1.6334519572953736,
        "end": 3468.66,
        "id": 1180,
        "no_speech_prob": 0.00003883110184688121,
        "seek": 345010,
        "start": 3467.14,
        "temperature": 0,
        "text": " OK, pause, edit, point.",
        "tokens": [
          51216,
          2264,
          11,
          10465,
          11,
          8129,
          11,
          935,
          13,
          51292
        ]
      },
      {
        "avg_logprob": -0.26800496813277125,
        "compression_ratio": 1.6334519572953736,
        "end": 3471.14,
        "id": 1181,
        "no_speech_prob": 0.00003883110184688121,
        "seek": 345010,
        "start": 3468.66,
        "temperature": 0,
        "text": " Let me see, what are some other things?",
        "tokens": [
          51292,
          961,
          385,
          536,
          11,
          437,
          366,
          512,
          661,
          721,
          30,
          51416
        ]
      },
      {
        "avg_logprob": -0.26800496813277125,
        "compression_ratio": 1.6334519572953736,
        "end": 3474.38,
        "id": 1182,
        "no_speech_prob": 0.00003883110184688121,
        "seek": 345010,
        "start": 3471.14,
        "temperature": 0,
        "text": " I could use the data sync in there,",
        "tokens": [
          51416,
          286,
          727,
          764,
          264,
          1412,
          20271,
          294,
          456,
          11,
          51578
        ]
      },
      {
        "avg_logprob": -0.26800496813277125,
        "compression_ratio": 1.6334519572953736,
        "end": 3476.38,
        "id": 1183,
        "no_speech_prob": 0.00003883110184688121,
        "seek": 345010,
        "start": 3474.38,
        "temperature": 0,
        "text": " but I'm going to keep that as a separate line.",
        "tokens": [
          51578,
          457,
          286,
          478,
          516,
          281,
          1066,
          300,
          382,
          257,
          4994,
          1622,
          13,
          51678
        ]
      },
      {
        "avg_logprob": -0.26800496813277125,
        "compression_ratio": 1.6334519572953736,
        "end": 3476.88,
        "id": 1184,
        "no_speech_prob": 0.00003883110184688121,
        "seek": 345010,
        "start": 3476.38,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51678,
          1057,
          558,
          13,
          51703
        ]
      },
      {
        "avg_logprob": -0.40999437086653,
        "compression_ratio": 1.58,
        "end": 3482.1,
        "id": 1185,
        "no_speech_prob": 0.000040063659980660304,
        "seek": 348010,
        "start": 3481.1,
        "temperature": 0,
        "text": " Ah, interesting.",
        "tokens": [
          50414,
          2438,
          11,
          1880,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.40999437086653,
        "compression_ratio": 1.58,
        "end": 3488.2599999999998,
        "id": 1186,
        "no_speech_prob": 0.000040063659980660304,
        "seek": 348010,
        "start": 3486.1,
        "temperature": 0,
        "text": " All right, let's add a few more things.",
        "tokens": [
          50664,
          1057,
          558,
          11,
          718,
          311,
          909,
          257,
          1326,
          544,
          721,
          13,
          50772
        ]
      },
      {
        "avg_logprob": -0.40999437086653,
        "compression_ratio": 1.58,
        "end": 3491.66,
        "id": 1187,
        "no_speech_prob": 0.000040063659980660304,
        "seek": 348010,
        "start": 3488.2599999999998,
        "temperature": 0,
        "text": " Riza in the chat asks, can you print the loss?",
        "tokens": [
          50772,
          497,
          13427,
          294,
          264,
          5081,
          8962,
          11,
          393,
          291,
          4482,
          264,
          4470,
          30,
          50942
        ]
      },
      {
        "avg_logprob": -0.40999437086653,
        "compression_ratio": 1.58,
        "end": 3494.06,
        "id": 1188,
        "no_speech_prob": 0.000040063659980660304,
        "seek": 348010,
        "start": 3491.66,
        "temperature": 0,
        "text": " That would be really useful for us to see the loss.",
        "tokens": [
          50942,
          663,
          576,
          312,
          534,
          4420,
          337,
          505,
          281,
          536,
          264,
          4470,
          13,
          51062
        ]
      },
      {
        "avg_logprob": -0.40999437086653,
        "compression_ratio": 1.58,
        "end": 3495.14,
        "id": 1189,
        "no_speech_prob": 0.000040063659980660304,
        "seek": 348010,
        "start": 3494.06,
        "temperature": 0,
        "text": " I could even graph it.",
        "tokens": [
          51062,
          286,
          727,
          754,
          4295,
          309,
          13,
          51116
        ]
      },
      {
        "avg_logprob": -0.40999437086653,
        "compression_ratio": 1.58,
        "end": 3498.7,
        "id": 1190,
        "no_speech_prob": 0.000040063659980660304,
        "seek": 348010,
        "start": 3495.14,
        "temperature": 0,
        "text": " So I'm sure there's a way for me to do that.",
        "tokens": [
          51116,
          407,
          286,
          478,
          988,
          456,
          311,
          257,
          636,
          337,
          385,
          281,
          360,
          300,
          13,
          51294
        ]
      },
      {
        "avg_logprob": -0.40999437086653,
        "compression_ratio": 1.58,
        "end": 3501.7,
        "id": 1191,
        "no_speech_prob": 0.000040063659980660304,
        "seek": 348010,
        "start": 3498.7,
        "temperature": 0,
        "text": " I need to grab the loss somewhere.",
        "tokens": [
          51294,
          286,
          643,
          281,
          4444,
          264,
          4470,
          4079,
          13,
          51444
        ]
      },
      {
        "avg_logprob": -0.40999437086653,
        "compression_ratio": 1.58,
        "end": 3507.86,
        "id": 1192,
        "no_speech_prob": 0.000040063659980660304,
        "seek": 348010,
        "start": 3501.7,
        "temperature": 0,
        "text": " So the loss, I think the loss would come out here, right?",
        "tokens": [
          51444,
          407,
          264,
          4470,
          11,
          286,
          519,
          264,
          4470,
          576,
          808,
          484,
          510,
          11,
          558,
          30,
          51752
        ]
      },
      {
        "avg_logprob": -0.8156805038452148,
        "compression_ratio": 1.228813559322034,
        "end": 3509.26,
        "id": 1193,
        "no_speech_prob": 0.00011061141412938014,
        "seek": 350786,
        "start": 3507.86,
        "temperature": 0,
        "text": " I wonder if it would get returned.",
        "tokens": [
          50364,
          286,
          2441,
          498,
          309,
          576,
          483,
          8752,
          13,
          50434
        ]
      },
      {
        "avg_logprob": -0.8156805038452148,
        "compression_ratio": 1.228813559322034,
        "end": 3515.2200000000003,
        "id": 1194,
        "no_speech_prob": 0.00011061141412938014,
        "seek": 350786,
        "start": 3513.98,
        "temperature": 0,
        "text": " Let's just take a look at that.",
        "tokens": [
          50670,
          961,
          311,
          445,
          747,
          257,
          574,
          412,
          300,
          13,
          50732
        ]
      },
      {
        "avg_logprob": -0.8156805038452148,
        "compression_ratio": 1.228813559322034,
        "end": 3518.1200000000003,
        "id": 1195,
        "no_speech_prob": 0.00011061141412938014,
        "seek": 350786,
        "start": 3517.6200000000003,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          50852,
          45263,
          13,
          50877
        ]
      },
      {
        "avg_logprob": -0.8156805038452148,
        "compression_ratio": 1.228813559322034,
        "end": 3525.06,
        "id": 1196,
        "no_speech_prob": 0.00011061141412938014,
        "seek": 350786,
        "start": 3521.6200000000003,
        "temperature": 0,
        "text": " No, hold on.",
        "tokens": [
          51052,
          883,
          11,
          1797,
          322,
          13,
          51224
        ]
      },
      {
        "avg_logprob": -0.8156805038452148,
        "compression_ratio": 1.228813559322034,
        "end": 3534.94,
        "id": 1197,
        "no_speech_prob": 0.00011061141412938014,
        "seek": 350786,
        "start": 3525.06,
        "temperature": 0,
        "text": " I mean, I could call the loss function, but I'm not sure.",
        "tokens": [
          51224,
          286,
          914,
          11,
          286,
          727,
          818,
          264,
          4470,
          2445,
          11,
          457,
          286,
          478,
          406,
          988,
          13,
          51718
        ]
      },
      {
        "avg_logprob": -0.350468741522895,
        "compression_ratio": 1.329192546583851,
        "end": 3541.3,
        "id": 1198,
        "no_speech_prob": 0.00003269924854976125,
        "seek": 353494,
        "start": 3535.18,
        "temperature": 0,
        "text": " But maybe let's not.",
        "tokens": [
          50376,
          583,
          1310,
          718,
          311,
          406,
          13,
          50682
        ]
      },
      {
        "avg_logprob": -0.350468741522895,
        "compression_ratio": 1.329192546583851,
        "end": 3543.82,
        "id": 1199,
        "no_speech_prob": 0.00003269924854976125,
        "seek": 353494,
        "start": 3541.3,
        "temperature": 0,
        "text": " The return is implied sounds better than assumed.",
        "tokens": [
          50682,
          440,
          2736,
          307,
          32614,
          3263,
          1101,
          813,
          15895,
          13,
          50808
        ]
      },
      {
        "avg_logprob": -0.350468741522895,
        "compression_ratio": 1.329192546583851,
        "end": 3544.82,
        "id": 1200,
        "no_speech_prob": 0.00003269924854976125,
        "seek": 353494,
        "start": 3543.82,
        "temperature": 0,
        "text": " Yes, thank you.",
        "tokens": [
          50808,
          1079,
          11,
          1309,
          291,
          13,
          50858
        ]
      },
      {
        "avg_logprob": -0.350468741522895,
        "compression_ratio": 1.329192546583851,
        "end": 3545.66,
        "id": 1201,
        "no_speech_prob": 0.00003269924854976125,
        "seek": 353494,
        "start": 3544.82,
        "temperature": 0,
        "text": " That's a good point.",
        "tokens": [
          50858,
          663,
          311,
          257,
          665,
          935,
          13,
          50900
        ]
      },
      {
        "avg_logprob": -0.350468741522895,
        "compression_ratio": 1.329192546583851,
        "end": 3551.94,
        "id": 1202,
        "no_speech_prob": 0.00003269924854976125,
        "seek": 353494,
        "start": 3548.82,
        "temperature": 0,
        "text": " Hello, Izumi, Coding Train sponsor.",
        "tokens": [
          51058,
          2425,
          11,
          30296,
          17800,
          11,
          383,
          8616,
          28029,
          16198,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.350468741522895,
        "compression_ratio": 1.329192546583851,
        "end": 3558.66,
        "id": 1203,
        "no_speech_prob": 0.00003269924854976125,
        "seek": 353494,
        "start": 3556.94,
        "temperature": 0,
        "text": " Outliers.",
        "tokens": [
          51464,
          5925,
          23646,
          13,
          51550
        ]
      },
      {
        "avg_logprob": -0.350468741522895,
        "compression_ratio": 1.329192546583851,
        "end": 3559.14,
        "id": 1204,
        "no_speech_prob": 0.00003269924854976125,
        "seek": 353494,
        "start": 3558.66,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          51550,
          6962,
          322,
          13,
          51574
        ]
      },
      {
        "avg_logprob": -0.350468741522895,
        "compression_ratio": 1.329192546583851,
        "end": 3562.82,
        "id": 1205,
        "no_speech_prob": 0.00003269924854976125,
        "seek": 353494,
        "start": 3559.14,
        "temperature": 0,
        "text": " What are some things that I can do to improve this?",
        "tokens": [
          51574,
          708,
          366,
          512,
          721,
          300,
          286,
          393,
          360,
          281,
          3470,
          341,
          30,
          51758
        ]
      },
      {
        "avg_logprob": -0.2742980061745157,
        "compression_ratio": 1.4902912621359223,
        "end": 3565.86,
        "id": 1206,
        "no_speech_prob": 0.0000031875645163381705,
        "seek": 356282,
        "start": 3562.82,
        "temperature": 0,
        "text": " Adding the loss, I'm going to leave that as an exercise.",
        "tokens": [
          50364,
          31204,
          264,
          4470,
          11,
          286,
          478,
          516,
          281,
          1856,
          300,
          382,
          364,
          5380,
          13,
          50516
        ]
      },
      {
        "avg_logprob": -0.2742980061745157,
        "compression_ratio": 1.4902912621359223,
        "end": 3568.5,
        "id": 1207,
        "no_speech_prob": 0.0000031875645163381705,
        "seek": 356282,
        "start": 3565.86,
        "temperature": 0,
        "text": " So Mathieu, we're at the edit point",
        "tokens": [
          50516,
          407,
          15776,
          19347,
          11,
          321,
          434,
          412,
          264,
          8129,
          935,
          50648
        ]
      },
      {
        "avg_logprob": -0.2742980061745157,
        "compression_ratio": 1.4902912621359223,
        "end": 3571.02,
        "id": 1208,
        "no_speech_prob": 0.0000031875645163381705,
        "seek": 356282,
        "start": 3568.5,
        "temperature": 0,
        "text": " where I was about to add some improvements.",
        "tokens": [
          50648,
          689,
          286,
          390,
          466,
          281,
          909,
          512,
          13797,
          13,
          50774
        ]
      },
      {
        "avg_logprob": -0.2742980061745157,
        "compression_ratio": 1.4902912621359223,
        "end": 3571.6600000000003,
        "id": 1209,
        "no_speech_prob": 0.0000031875645163381705,
        "seek": 356282,
        "start": 3571.02,
        "temperature": 0,
        "text": " Anything else?",
        "tokens": [
          50774,
          11998,
          1646,
          30,
          50806
        ]
      },
      {
        "avg_logprob": -0.2742980061745157,
        "compression_ratio": 1.4902912621359223,
        "end": 3577.82,
        "id": 1210,
        "no_speech_prob": 0.0000031875645163381705,
        "seek": 356282,
        "start": 3574.7400000000002,
        "temperature": 0,
        "text": " TensorBoard to visualize the training graph.",
        "tokens": [
          50960,
          34306,
          22493,
          515,
          281,
          23273,
          264,
          3097,
          4295,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2742980061745157,
        "compression_ratio": 1.4902912621359223,
        "end": 3580.5,
        "id": 1211,
        "no_speech_prob": 0.0000031875645163381705,
        "seek": 356282,
        "start": 3577.82,
        "temperature": 0,
        "text": " It's 5.30, so I also have to go.",
        "tokens": [
          51114,
          467,
          311,
          1025,
          13,
          3446,
          11,
          370,
          286,
          611,
          362,
          281,
          352,
          13,
          51248
        ]
      },
      {
        "avg_logprob": -0.2742980061745157,
        "compression_ratio": 1.4902912621359223,
        "end": 3583.02,
        "id": 1212,
        "no_speech_prob": 0.0000031875645163381705,
        "seek": 356282,
        "start": 3580.5,
        "temperature": 0,
        "text": " I do think I completed this.",
        "tokens": [
          51248,
          286,
          360,
          519,
          286,
          7365,
          341,
          13,
          51374
        ]
      },
      {
        "avg_logprob": -0.2742980061745157,
        "compression_ratio": 1.4902912621359223,
        "end": 3583.98,
        "id": 1213,
        "no_speech_prob": 0.0000031875645163381705,
        "seek": 356282,
        "start": 3583.02,
        "temperature": 0,
        "text": " I just want to check.",
        "tokens": [
          51374,
          286,
          445,
          528,
          281,
          1520,
          13,
          51422
        ]
      },
      {
        "avg_logprob": -0.2742980061745157,
        "compression_ratio": 1.4902912621359223,
        "end": 3590.6600000000003,
        "id": 1214,
        "no_speech_prob": 0.0000031875645163381705,
        "seek": 356282,
        "start": 3588.1400000000003,
        "temperature": 0,
        "text": " I just want to just check.",
        "tokens": [
          51630,
          286,
          445,
          528,
          281,
          445,
          1520,
          13,
          51756
        ]
      },
      {
        "avg_logprob": -0.29658814678041956,
        "compression_ratio": 1.6051502145922747,
        "end": 3592.54,
        "id": 1215,
        "no_speech_prob": 0.000015446283214259893,
        "seek": 359066,
        "start": 3590.66,
        "temperature": 0,
        "text": " The reason why I have to go is because I have",
        "tokens": [
          50364,
          440,
          1778,
          983,
          286,
          362,
          281,
          352,
          307,
          570,
          286,
          362,
          50458
        ]
      },
      {
        "avg_logprob": -0.29658814678041956,
        "compression_ratio": 1.6051502145922747,
        "end": 3595.02,
        "id": 1216,
        "no_speech_prob": 0.000015446283214259893,
        "seek": 359066,
        "start": 3592.54,
        "temperature": 0,
        "text": " to be home at a certain time, and I just",
        "tokens": [
          50458,
          281,
          312,
          1280,
          412,
          257,
          1629,
          565,
          11,
          293,
          286,
          445,
          50582
        ]
      },
      {
        "avg_logprob": -0.29658814678041956,
        "compression_ratio": 1.6051502145922747,
        "end": 3597.8999999999996,
        "id": 1217,
        "no_speech_prob": 0.000015446283214259893,
        "seek": 359066,
        "start": 3595.02,
        "temperature": 0,
        "text": " want to make sure it's not an emergency for me to be home.",
        "tokens": [
          50582,
          528,
          281,
          652,
          988,
          309,
          311,
          406,
          364,
          7473,
          337,
          385,
          281,
          312,
          1280,
          13,
          50726
        ]
      },
      {
        "avg_logprob": -0.29658814678041956,
        "compression_ratio": 1.6051502145922747,
        "end": 3599.62,
        "id": 1218,
        "no_speech_prob": 0.000015446283214259893,
        "seek": 359066,
        "start": 3597.8999999999996,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50726,
          2264,
          13,
          50812
        ]
      },
      {
        "avg_logprob": -0.29658814678041956,
        "compression_ratio": 1.6051502145922747,
        "end": 3600.18,
        "id": 1219,
        "no_speech_prob": 0.000015446283214259893,
        "seek": 359066,
        "start": 3599.62,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50812,
          1057,
          558,
          13,
          50840
        ]
      },
      {
        "avg_logprob": -0.29658814678041956,
        "compression_ratio": 1.6051502145922747,
        "end": 3602.62,
        "id": 1220,
        "no_speech_prob": 0.000015446283214259893,
        "seek": 359066,
        "start": 3600.18,
        "temperature": 0,
        "text": " So I've got like 5 or 10 minutes, I think.",
        "tokens": [
          50840,
          407,
          286,
          600,
          658,
          411,
          1025,
          420,
          1266,
          2077,
          11,
          286,
          519,
          13,
          50962
        ]
      },
      {
        "avg_logprob": -0.29658814678041956,
        "compression_ratio": 1.6051502145922747,
        "end": 3604.3399999999997,
        "id": 1221,
        "no_speech_prob": 0.000015446283214259893,
        "seek": 359066,
        "start": 3602.62,
        "temperature": 0,
        "text": " I'm good.",
        "tokens": [
          50962,
          286,
          478,
          665,
          13,
          51048
        ]
      },
      {
        "avg_logprob": -0.29658814678041956,
        "compression_ratio": 1.6051502145922747,
        "end": 3605.98,
        "id": 1222,
        "no_speech_prob": 0.000015446283214259893,
        "seek": 359066,
        "start": 3604.3399999999997,
        "temperature": 0,
        "text": " Try another optimizer.",
        "tokens": [
          51048,
          6526,
          1071,
          5028,
          6545,
          13,
          51130
        ]
      },
      {
        "avg_logprob": -0.29658814678041956,
        "compression_ratio": 1.6051502145922747,
        "end": 3607.66,
        "id": 1223,
        "no_speech_prob": 0.000015446283214259893,
        "seek": 359066,
        "start": 3605.98,
        "temperature": 0,
        "text": " All right, so these are things I want.",
        "tokens": [
          51130,
          1057,
          558,
          11,
          370,
          613,
          366,
          721,
          286,
          528,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.29658814678041956,
        "compression_ratio": 1.6051502145922747,
        "end": 3610.2999999999997,
        "id": 1224,
        "no_speech_prob": 0.000015446283214259893,
        "seek": 359066,
        "start": 3607.66,
        "temperature": 0,
        "text": " I think I want this video to be over.",
        "tokens": [
          51214,
          286,
          519,
          286,
          528,
          341,
          960,
          281,
          312,
          670,
          13,
          51346
        ]
      },
      {
        "avg_logprob": -0.29658814678041956,
        "compression_ratio": 1.6051502145922747,
        "end": 3613.74,
        "id": 1225,
        "no_speech_prob": 0.000015446283214259893,
        "seek": 359066,
        "start": 3610.2999999999997,
        "temperature": 0,
        "text": " So you get the loss with a callback.",
        "tokens": [
          51346,
          407,
          291,
          483,
          264,
          4470,
          365,
          257,
          818,
          3207,
          13,
          51518
        ]
      },
      {
        "avg_logprob": -0.29658814678041956,
        "compression_ratio": 1.6051502145922747,
        "end": 3618.5,
        "id": 1226,
        "no_speech_prob": 0.000015446283214259893,
        "seek": 359066,
        "start": 3616.66,
        "temperature": 0,
        "text": " Interesting.",
        "tokens": [
          51664,
          14711,
          13,
          51756
        ]
      },
      {
        "avg_logprob": -0.29658814678041956,
        "compression_ratio": 1.6051502145922747,
        "end": 3619.8599999999997,
        "id": 1227,
        "no_speech_prob": 0.000015446283214259893,
        "seek": 359066,
        "start": 3618.5,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51756,
          1057,
          558,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.25139505281223085,
        "compression_ratio": 1.6451612903225807,
        "end": 3621.54,
        "id": 1228,
        "no_speech_prob": 0.00002212559775216505,
        "seek": 361986,
        "start": 3619.86,
        "temperature": 0,
        "text": " Print mean squared error.",
        "tokens": [
          50364,
          34439,
          914,
          8889,
          6713,
          13,
          50448
        ]
      },
      {
        "avg_logprob": -0.25139505281223085,
        "compression_ratio": 1.6451612903225807,
        "end": 3624.06,
        "id": 1229,
        "no_speech_prob": 0.00002212559775216505,
        "seek": 361986,
        "start": 3621.54,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50448,
          1057,
          558,
          13,
          50574
        ]
      },
      {
        "avg_logprob": -0.25139505281223085,
        "compression_ratio": 1.6451612903225807,
        "end": 3628.58,
        "id": 1230,
        "no_speech_prob": 0.00002212559775216505,
        "seek": 361986,
        "start": 3624.06,
        "temperature": 0,
        "text": " All right, so let me, why don't you tidy the tensors",
        "tokens": [
          50574,
          1057,
          558,
          11,
          370,
          718,
          385,
          11,
          983,
          500,
          380,
          291,
          34646,
          264,
          10688,
          830,
          50800
        ]
      },
      {
        "avg_logprob": -0.25139505281223085,
        "compression_ratio": 1.6451612903225807,
        "end": 3631.06,
        "id": 1231,
        "no_speech_prob": 0.00002212559775216505,
        "seek": 361986,
        "start": 3628.58,
        "temperature": 0,
        "text": " inside the predict?",
        "tokens": [
          50800,
          1854,
          264,
          6069,
          30,
          50924
        ]
      },
      {
        "avg_logprob": -0.25139505281223085,
        "compression_ratio": 1.6451612903225807,
        "end": 3633.2200000000003,
        "id": 1232,
        "no_speech_prob": 0.00002212559775216505,
        "seek": 361986,
        "start": 3631.06,
        "temperature": 0,
        "text": " Yeah, that would have been another way to do it.",
        "tokens": [
          50924,
          865,
          11,
          300,
          576,
          362,
          668,
          1071,
          636,
          281,
          360,
          309,
          13,
          51032
        ]
      },
      {
        "avg_logprob": -0.25139505281223085,
        "compression_ratio": 1.6451612903225807,
        "end": 3634.6600000000003,
        "id": 1233,
        "no_speech_prob": 0.00002212559775216505,
        "seek": 361986,
        "start": 3633.2200000000003,
        "temperature": 0,
        "text": " There's just so many different ways.",
        "tokens": [
          51032,
          821,
          311,
          445,
          370,
          867,
          819,
          2098,
          13,
          51104
        ]
      },
      {
        "avg_logprob": -0.25139505281223085,
        "compression_ratio": 1.6451612903225807,
        "end": 3635.54,
        "id": 1234,
        "no_speech_prob": 0.00002212559775216505,
        "seek": 361986,
        "start": 3634.6600000000003,
        "temperature": 0,
        "text": " All right, so here.",
        "tokens": [
          51104,
          1057,
          558,
          11,
          370,
          510,
          13,
          51148
        ]
      },
      {
        "avg_logprob": -0.25139505281223085,
        "compression_ratio": 1.6451612903225807,
        "end": 3636.58,
        "id": 1235,
        "no_speech_prob": 0.00002212559775216505,
        "seek": 361986,
        "start": 3635.54,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51148,
          2264,
          13,
          51200
        ]
      },
      {
        "avg_logprob": -0.25139505281223085,
        "compression_ratio": 1.6451612903225807,
        "end": 3638.9,
        "id": 1236,
        "no_speech_prob": 0.00002212559775216505,
        "seek": 361986,
        "start": 3636.58,
        "temperature": 0,
        "text": " OK, so I think I'm going to wrap this video up.",
        "tokens": [
          51200,
          2264,
          11,
          370,
          286,
          519,
          286,
          478,
          516,
          281,
          7019,
          341,
          960,
          493,
          13,
          51316
        ]
      },
      {
        "avg_logprob": -0.25139505281223085,
        "compression_ratio": 1.6451612903225807,
        "end": 3642.3,
        "id": 1237,
        "no_speech_prob": 0.00002212559775216505,
        "seek": 361986,
        "start": 3638.9,
        "temperature": 0,
        "text": " I'm getting all these great suggestions from the chat.",
        "tokens": [
          51316,
          286,
          478,
          1242,
          439,
          613,
          869,
          13396,
          490,
          264,
          5081,
          13,
          51486
        ]
      },
      {
        "avg_logprob": -0.25139505281223085,
        "compression_ratio": 1.6451612903225807,
        "end": 3646.06,
        "id": 1238,
        "no_speech_prob": 0.00002212559775216505,
        "seek": 361986,
        "start": 3642.3,
        "temperature": 0,
        "text": " I could have tidied the tensors here in predict.",
        "tokens": [
          51486,
          286,
          727,
          362,
          9422,
          1091,
          264,
          10688,
          830,
          510,
          294,
          6069,
          13,
          51674
        ]
      },
      {
        "avg_logprob": -0.25139505281223085,
        "compression_ratio": 1.6451612903225807,
        "end": 3648.7400000000002,
        "id": 1239,
        "no_speech_prob": 0.00002212559775216505,
        "seek": 361986,
        "start": 3646.06,
        "temperature": 0,
        "text": " So number one is, this code is going",
        "tokens": [
          51674,
          407,
          1230,
          472,
          307,
          11,
          341,
          3089,
          307,
          516,
          51808
        ]
      },
      {
        "avg_logprob": -0.3095839246571493,
        "compression_ratio": 1.749063670411985,
        "end": 3650.9799999999996,
        "id": 1240,
        "no_speech_prob": 0.006797445006668568,
        "seek": 364874,
        "start": 3648.74,
        "temperature": 0,
        "text": " to get posted to the Coding Train website and coding",
        "tokens": [
          50364,
          281,
          483,
          9437,
          281,
          264,
          383,
          8616,
          28029,
          3144,
          293,
          17720,
          50476
        ]
      },
      {
        "avg_logprob": -0.3095839246571493,
        "compression_ratio": 1.749063670411985,
        "end": 3651.5,
        "id": 1241,
        "no_speech_prob": 0.006797445006668568,
        "seek": 364874,
        "start": 3650.9799999999996,
        "temperature": 0,
        "text": " challenges.",
        "tokens": [
          50476,
          4759,
          13,
          50502
        ]
      },
      {
        "avg_logprob": -0.3095839246571493,
        "compression_ratio": 1.749063670411985,
        "end": 3653.22,
        "id": 1242,
        "no_speech_prob": 0.006797445006668568,
        "seek": 364874,
        "start": 3651.5,
        "temperature": 0,
        "text": " Make your improvements and add them",
        "tokens": [
          50502,
          4387,
          428,
          13797,
          293,
          909,
          552,
          50588
        ]
      },
      {
        "avg_logprob": -0.3095839246571493,
        "compression_ratio": 1.749063670411985,
        "end": 3654.7,
        "id": 1243,
        "no_speech_prob": 0.006797445006668568,
        "seek": 364874,
        "start": 3653.22,
        "temperature": 0,
        "text": " as community contributions.",
        "tokens": [
          50588,
          382,
          1768,
          15725,
          13,
          50662
        ]
      },
      {
        "avg_logprob": -0.3095839246571493,
        "compression_ratio": 1.749063670411985,
        "end": 3656.58,
        "id": 1244,
        "no_speech_prob": 0.006797445006668568,
        "seek": 364874,
        "start": 3654.7,
        "temperature": 0,
        "text": " Some things that I would love to see.",
        "tokens": [
          50662,
          2188,
          721,
          300,
          286,
          576,
          959,
          281,
          536,
          13,
          50756
        ]
      },
      {
        "avg_logprob": -0.3095839246571493,
        "compression_ratio": 1.749063670411985,
        "end": 3658.7799999999997,
        "id": 1245,
        "no_speech_prob": 0.006797445006668568,
        "seek": 364874,
        "start": 3656.58,
        "temperature": 0,
        "text": " Visualize, graph the loss value.",
        "tokens": [
          50756,
          23187,
          1125,
          11,
          4295,
          264,
          4470,
          2158,
          13,
          50866
        ]
      },
      {
        "avg_logprob": -0.3095839246571493,
        "compression_ratio": 1.749063670411985,
        "end": 3660.62,
        "id": 1246,
        "no_speech_prob": 0.006797445006668568,
        "seek": 364874,
        "start": 3658.7799999999997,
        "temperature": 0,
        "text": " I think there's a way to get the loss.",
        "tokens": [
          50866,
          286,
          519,
          456,
          311,
          257,
          636,
          281,
          483,
          264,
          4470,
          13,
          50958
        ]
      },
      {
        "avg_logprob": -0.3095839246571493,
        "compression_ratio": 1.749063670411985,
        "end": 3662.62,
        "id": 1247,
        "no_speech_prob": 0.006797445006668568,
        "seek": 364874,
        "start": 3660.62,
        "temperature": 0,
        "text": " I'm sure there's a way to get the loss value out",
        "tokens": [
          50958,
          286,
          478,
          988,
          456,
          311,
          257,
          636,
          281,
          483,
          264,
          4470,
          2158,
          484,
          51058
        ]
      },
      {
        "avg_logprob": -0.3095839246571493,
        "compression_ratio": 1.749063670411985,
        "end": 3663.2599999999998,
        "id": 1248,
        "no_speech_prob": 0.006797445006668568,
        "seek": 364874,
        "start": 3662.62,
        "temperature": 0,
        "text": " of that function.",
        "tokens": [
          51058,
          295,
          300,
          2445,
          13,
          51090
        ]
      },
      {
        "avg_logprob": -0.3095839246571493,
        "compression_ratio": 1.749063670411985,
        "end": 3664.06,
        "id": 1249,
        "no_speech_prob": 0.006797445006668568,
        "seek": 364874,
        "start": 3663.2599999999998,
        "temperature": 0,
        "text": " That's one idea.",
        "tokens": [
          51090,
          663,
          311,
          472,
          1558,
          13,
          51130
        ]
      },
      {
        "avg_logprob": -0.3095839246571493,
        "compression_ratio": 1.749063670411985,
        "end": 3668.3799999999997,
        "id": 1250,
        "no_speech_prob": 0.006797445006668568,
        "seek": 364874,
        "start": 3666.9399999999996,
        "temperature": 0,
        "text": " There was another good one.",
        "tokens": [
          51274,
          821,
          390,
          1071,
          665,
          472,
          13,
          51346
        ]
      },
      {
        "avg_logprob": -0.3095839246571493,
        "compression_ratio": 1.749063670411985,
        "end": 3670.14,
        "id": 1251,
        "no_speech_prob": 0.006797445006668568,
        "seek": 364874,
        "start": 3668.3799999999997,
        "temperature": 0,
        "text": " There was another good one that I forgot.",
        "tokens": [
          51346,
          821,
          390,
          1071,
          665,
          472,
          300,
          286,
          5298,
          13,
          51434
        ]
      },
      {
        "avg_logprob": -0.3095839246571493,
        "compression_ratio": 1.749063670411985,
        "end": 3671.14,
        "id": 1252,
        "no_speech_prob": 0.006797445006668568,
        "seek": 364874,
        "start": 3670.14,
        "temperature": 0,
        "text": " Oh, yes.",
        "tokens": [
          51434,
          876,
          11,
          2086,
          13,
          51484
        ]
      },
      {
        "avg_logprob": -0.3095839246571493,
        "compression_ratio": 1.749063670411985,
        "end": 3673.5,
        "id": 1253,
        "no_speech_prob": 0.006797445006668568,
        "seek": 364874,
        "start": 3671.14,
        "temperature": 0,
        "text": " K. Wieckmann suggested maybe trying",
        "tokens": [
          51484,
          591,
          13,
          9233,
          547,
          14912,
          10945,
          1310,
          1382,
          51602
        ]
      },
      {
        "avg_logprob": -0.3095839246571493,
        "compression_ratio": 1.749063670411985,
        "end": 3675.06,
        "id": 1254,
        "no_speech_prob": 0.006797445006668568,
        "seek": 364874,
        "start": 3673.5,
        "temperature": 0,
        "text": " some of the other optimizers.",
        "tokens": [
          51602,
          512,
          295,
          264,
          661,
          5028,
          22525,
          13,
          51680
        ]
      },
      {
        "avg_logprob": -0.2655540992473734,
        "compression_ratio": 1.5810276679841897,
        "end": 3678.9,
        "id": 1255,
        "no_speech_prob": 0.00001095311381504871,
        "seek": 367506,
        "start": 3675.1,
        "temperature": 0,
        "text": " So what happens if I go to the TensorFlow.js documentation",
        "tokens": [
          50366,
          407,
          437,
          2314,
          498,
          286,
          352,
          281,
          264,
          37624,
          13,
          25530,
          14333,
          50556
        ]
      },
      {
        "avg_logprob": -0.2655540992473734,
        "compression_ratio": 1.5810276679841897,
        "end": 3681.22,
        "id": 1256,
        "no_speech_prob": 0.00001095311381504871,
        "seek": 367506,
        "start": 3678.9,
        "temperature": 0,
        "text": " and just use some of these other optimizers?",
        "tokens": [
          50556,
          293,
          445,
          764,
          512,
          295,
          613,
          661,
          5028,
          22525,
          30,
          50672
        ]
      },
      {
        "avg_logprob": -0.2655540992473734,
        "compression_ratio": 1.5810276679841897,
        "end": 3681.82,
        "id": 1257,
        "no_speech_prob": 0.00001095311381504871,
        "seek": 367506,
        "start": 3681.22,
        "temperature": 0,
        "text": " What are they?",
        "tokens": [
          50672,
          708,
          366,
          436,
          30,
          50702
        ]
      },
      {
        "avg_logprob": -0.2655540992473734,
        "compression_ratio": 1.5810276679841897,
        "end": 3682.58,
        "id": 1258,
        "no_speech_prob": 0.00001095311381504871,
        "seek": 367506,
        "start": 3681.82,
        "temperature": 0,
        "text": " What will they do?",
        "tokens": [
          50702,
          708,
          486,
          436,
          360,
          30,
          50740
        ]
      },
      {
        "avg_logprob": -0.2655540992473734,
        "compression_ratio": 1.5810276679841897,
        "end": 3684.5,
        "id": 1259,
        "no_speech_prob": 0.00001095311381504871,
        "seek": 367506,
        "start": 3682.58,
        "temperature": 0,
        "text": " Do you get better or worse results?",
        "tokens": [
          50740,
          1144,
          291,
          483,
          1101,
          420,
          5324,
          3542,
          30,
          50836
        ]
      },
      {
        "avg_logprob": -0.2655540992473734,
        "compression_ratio": 1.5810276679841897,
        "end": 3687.42,
        "id": 1260,
        "no_speech_prob": 0.00001095311381504871,
        "seek": 367506,
        "start": 3684.5,
        "temperature": 0,
        "text": " Can you make the learning rate somehow interactive?",
        "tokens": [
          50836,
          1664,
          291,
          652,
          264,
          2539,
          3314,
          6063,
          15141,
          30,
          50982
        ]
      },
      {
        "avg_logprob": -0.2655540992473734,
        "compression_ratio": 1.5810276679841897,
        "end": 3688.82,
        "id": 1261,
        "no_speech_prob": 0.00001095311381504871,
        "seek": 367506,
        "start": 3687.42,
        "temperature": 0,
        "text": " Adjust the learning rate?",
        "tokens": [
          50982,
          34049,
          264,
          2539,
          3314,
          30,
          51052
        ]
      },
      {
        "avg_logprob": -0.2655540992473734,
        "compression_ratio": 1.5810276679841897,
        "end": 3693.1,
        "id": 1262,
        "no_speech_prob": 0.00001095311381504871,
        "seek": 367506,
        "start": 3688.82,
        "temperature": 0,
        "text": " I don't know if you could come up with any really clever visual",
        "tokens": [
          51052,
          286,
          500,
          380,
          458,
          498,
          291,
          727,
          808,
          493,
          365,
          604,
          534,
          13494,
          5056,
          51266
        ]
      },
      {
        "avg_logprob": -0.2655540992473734,
        "compression_ratio": 1.5810276679841897,
        "end": 3697.46,
        "id": 1263,
        "no_speech_prob": 0.00001095311381504871,
        "seek": 367506,
        "start": 3693.1,
        "temperature": 0,
        "text": " ideas with this.",
        "tokens": [
          51266,
          3487,
          365,
          341,
          13,
          51484
        ]
      },
      {
        "avg_logprob": -0.2655540992473734,
        "compression_ratio": 1.5810276679841897,
        "end": 3699.74,
        "id": 1264,
        "no_speech_prob": 0.00001095311381504871,
        "seek": 367506,
        "start": 3697.46,
        "temperature": 0,
        "text": " But anyway.",
        "tokens": [
          51484,
          583,
          4033,
          13,
          51598
        ]
      },
      {
        "avg_logprob": -0.2655540992473734,
        "compression_ratio": 1.5810276679841897,
        "end": 3700.7799999999997,
        "id": 1265,
        "no_speech_prob": 0.00001095311381504871,
        "seek": 367506,
        "start": 3699.74,
        "temperature": 0,
        "text": " So but I think I'm good.",
        "tokens": [
          51598,
          407,
          457,
          286,
          519,
          286,
          478,
          665,
          13,
          51650
        ]
      },
      {
        "avg_logprob": -0.2655540992473734,
        "compression_ratio": 1.5810276679841897,
        "end": 3702.58,
        "id": 1266,
        "no_speech_prob": 0.00001095311381504871,
        "seek": 367506,
        "start": 3700.7799999999997,
        "temperature": 0,
        "text": " I think I have the basic idea.",
        "tokens": [
          51650,
          286,
          519,
          286,
          362,
          264,
          3875,
          1558,
          13,
          51740
        ]
      },
      {
        "avg_logprob": -0.2365072942843103,
        "compression_ratio": 1.7190332326283988,
        "end": 3705.66,
        "id": 1267,
        "no_speech_prob": 0.0003859568096231669,
        "seek": 370258,
        "start": 3702.58,
        "temperature": 0,
        "text": " So if you really want to dive as deeply as you can",
        "tokens": [
          50364,
          407,
          498,
          291,
          534,
          528,
          281,
          9192,
          382,
          8760,
          382,
          291,
          393,
          50518
        ]
      },
      {
        "avg_logprob": -0.2365072942843103,
        "compression_ratio": 1.7190332326283988,
        "end": 3707.8199999999997,
        "id": 1268,
        "no_speech_prob": 0.0003859568096231669,
        "seek": 370258,
        "start": 3705.66,
        "temperature": 0,
        "text": " into linear regression with gradient descent,",
        "tokens": [
          50518,
          666,
          8213,
          24590,
          365,
          16235,
          23475,
          11,
          50626
        ]
      },
      {
        "avg_logprob": -0.2365072942843103,
        "compression_ratio": 1.7190332326283988,
        "end": 3709.9,
        "id": 1269,
        "no_speech_prob": 0.0003859568096231669,
        "seek": 370258,
        "start": 3707.8199999999997,
        "temperature": 0,
        "text": " you can go back and watch my other videos",
        "tokens": [
          50626,
          291,
          393,
          352,
          646,
          293,
          1159,
          452,
          661,
          2145,
          50730
        ]
      },
      {
        "avg_logprob": -0.2365072942843103,
        "compression_ratio": 1.7190332326283988,
        "end": 3712.8199999999997,
        "id": 1270,
        "no_speech_prob": 0.0003859568096231669,
        "seek": 370258,
        "start": 3709.9,
        "temperature": 0,
        "text": " where I did this with just JavaScript and p5.js.",
        "tokens": [
          50730,
          689,
          286,
          630,
          341,
          365,
          445,
          15778,
          293,
          280,
          20,
          13,
          25530,
          13,
          50876
        ]
      },
      {
        "avg_logprob": -0.2365072942843103,
        "compression_ratio": 1.7190332326283988,
        "end": 3715.62,
        "id": 1271,
        "no_speech_prob": 0.0003859568096231669,
        "seek": 370258,
        "start": 3712.8199999999997,
        "temperature": 0,
        "text": " Now you've seen it with JavaScript, p5.js,",
        "tokens": [
          50876,
          823,
          291,
          600,
          1612,
          309,
          365,
          15778,
          11,
          280,
          20,
          13,
          25530,
          11,
          51016
        ]
      },
      {
        "avg_logprob": -0.2365072942843103,
        "compression_ratio": 1.7190332326283988,
        "end": 3716.8199999999997,
        "id": 1272,
        "no_speech_prob": 0.0003859568096231669,
        "seek": 370258,
        "start": 3715.62,
        "temperature": 0,
        "text": " and TensorFlow.js.",
        "tokens": [
          51016,
          293,
          37624,
          13,
          25530,
          13,
          51076
        ]
      },
      {
        "avg_logprob": -0.2365072942843103,
        "compression_ratio": 1.7190332326283988,
        "end": 3718.34,
        "id": 1273,
        "no_speech_prob": 0.0003859568096231669,
        "seek": 370258,
        "start": 3716.8199999999997,
        "temperature": 0,
        "text": " So I look forward to your feedback",
        "tokens": [
          51076,
          407,
          286,
          574,
          2128,
          281,
          428,
          5824,
          51152
        ]
      },
      {
        "avg_logprob": -0.2365072942843103,
        "compression_ratio": 1.7190332326283988,
        "end": 3719.7,
        "id": 1274,
        "no_speech_prob": 0.0003859568096231669,
        "seek": 370258,
        "start": 3718.34,
        "temperature": 0,
        "text": " and hearing more about it.",
        "tokens": [
          51152,
          293,
          4763,
          544,
          466,
          309,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.2365072942843103,
        "compression_ratio": 1.7190332326283988,
        "end": 3721.98,
        "id": 1275,
        "no_speech_prob": 0.0003859568096231669,
        "seek": 370258,
        "start": 3719.7,
        "temperature": 0,
        "text": " More TensorFlow.js videos to come.",
        "tokens": [
          51220,
          5048,
          37624,
          13,
          25530,
          2145,
          281,
          808,
          13,
          51334
        ]
      },
      {
        "avg_logprob": -0.2365072942843103,
        "compression_ratio": 1.7190332326283988,
        "end": 3724.46,
        "id": 1276,
        "no_speech_prob": 0.0003859568096231669,
        "seek": 370258,
        "start": 3721.98,
        "temperature": 0,
        "text": " I want to get to some actual more practical things",
        "tokens": [
          51334,
          286,
          528,
          281,
          483,
          281,
          512,
          3539,
          544,
          8496,
          721,
          51458
        ]
      },
      {
        "avg_logprob": -0.2365072942843103,
        "compression_ratio": 1.7190332326283988,
        "end": 3726.66,
        "id": 1277,
        "no_speech_prob": 0.0003859568096231669,
        "seek": 370258,
        "start": 3724.46,
        "temperature": 0,
        "text": " that you might want to do for interactive creative arts",
        "tokens": [
          51458,
          300,
          291,
          1062,
          528,
          281,
          360,
          337,
          15141,
          5880,
          8609,
          51568
        ]
      },
      {
        "avg_logprob": -0.2365072942843103,
        "compression_ratio": 1.7190332326283988,
        "end": 3727.2999999999997,
        "id": 1278,
        "no_speech_prob": 0.0003859568096231669,
        "seek": 370258,
        "start": 3726.66,
        "temperature": 0,
        "text": " projects.",
        "tokens": [
          51568,
          4455,
          13,
          51600
        ]
      },
      {
        "avg_logprob": -0.2365072942843103,
        "compression_ratio": 1.7190332326283988,
        "end": 3728.92,
        "id": 1279,
        "no_speech_prob": 0.0003859568096231669,
        "seek": 370258,
        "start": 3727.2999999999997,
        "temperature": 0,
        "text": " But I'm still in the weeds here of just",
        "tokens": [
          51600,
          583,
          286,
          478,
          920,
          294,
          264,
          26370,
          510,
          295,
          445,
          51681
        ]
      },
      {
        "avg_logprob": -0.2365072942843103,
        "compression_ratio": 1.7190332326283988,
        "end": 3730.7799999999997,
        "id": 1280,
        "no_speech_prob": 0.0003859568096231669,
        "seek": 370258,
        "start": 3728.92,
        "temperature": 0,
        "text": " trying to understand the nuts and bolts of how",
        "tokens": [
          51681,
          1382,
          281,
          1223,
          264,
          10483,
          293,
          18127,
          295,
          577,
          51774
        ]
      },
      {
        "avg_logprob": -0.2365072942843103,
        "compression_ratio": 1.7190332326283988,
        "end": 3731.54,
        "id": 1281,
        "no_speech_prob": 0.0003859568096231669,
        "seek": 370258,
        "start": 3730.7799999999997,
        "temperature": 0,
        "text": " the library works.",
        "tokens": [
          51774,
          264,
          6405,
          1985,
          13,
          51812
        ]
      },
      {
        "avg_logprob": -0.3698457956314087,
        "compression_ratio": 1.4695121951219512,
        "end": 3733.7,
        "id": 1282,
        "no_speech_prob": 0.00016092974692583084,
        "seek": 373154,
        "start": 3731.58,
        "temperature": 0,
        "text": " So I hope you're enjoying that, and I look forward",
        "tokens": [
          50366,
          407,
          286,
          1454,
          291,
          434,
          9929,
          300,
          11,
          293,
          286,
          574,
          2128,
          50472
        ]
      },
      {
        "avg_logprob": -0.3698457956314087,
        "compression_ratio": 1.4695121951219512,
        "end": 3735.02,
        "id": 1283,
        "no_speech_prob": 0.00016092974692583084,
        "seek": 373154,
        "start": 3733.7,
        "temperature": 0,
        "text": " to seeing you in future videos.",
        "tokens": [
          50472,
          281,
          2577,
          291,
          294,
          2027,
          2145,
          13,
          50538
        ]
      },
      {
        "avg_logprob": -0.3698457956314087,
        "compression_ratio": 1.4695121951219512,
        "end": 3742.46,
        "id": 1284,
        "no_speech_prob": 0.00016092974692583084,
        "seek": 373154,
        "start": 3739.46,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50760,
          1057,
          558,
          13,
          50910
        ]
      },
      {
        "avg_logprob": -0.3698457956314087,
        "compression_ratio": 1.4695121951219512,
        "end": 3743.34,
        "id": 1285,
        "no_speech_prob": 0.00016092974692583084,
        "seek": 373154,
        "start": 3742.46,
        "temperature": 0,
        "text": " Put on hold.",
        "tokens": [
          50910,
          4935,
          322,
          1797,
          13,
          50954
        ]
      },
      {
        "avg_logprob": -0.3698457956314087,
        "compression_ratio": 1.4695121951219512,
        "end": 3744.42,
        "id": 1286,
        "no_speech_prob": 0.00016092974692583084,
        "seek": 373154,
        "start": 3743.34,
        "temperature": 0,
        "text": " I am reading your comment.",
        "tokens": [
          50954,
          286,
          669,
          3760,
          428,
          2871,
          13,
          51008
        ]
      },
      {
        "avg_logprob": -0.3698457956314087,
        "compression_ratio": 1.4695121951219512,
        "end": 3748.36,
        "id": 1287,
        "no_speech_prob": 0.00016092974692583084,
        "seek": 373154,
        "start": 3747.86,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51180,
          1057,
          558,
          13,
          51205
        ]
      },
      {
        "avg_logprob": -0.3698457956314087,
        "compression_ratio": 1.4695121951219512,
        "end": 3754.7,
        "id": 1288,
        "no_speech_prob": 0.00016092974692583084,
        "seek": 373154,
        "start": 3748.36,
        "temperature": 0,
        "text": " So I am done for the day.",
        "tokens": [
          51205,
          407,
          286,
          669,
          1096,
          337,
          264,
          786,
          13,
          51522
        ]
      },
      {
        "avg_logprob": -0.3698457956314087,
        "compression_ratio": 1.4695121951219512,
        "end": 3758.14,
        "id": 1289,
        "no_speech_prob": 0.00016092974692583084,
        "seek": 373154,
        "start": 3754.7,
        "temperature": 0,
        "text": " I have done a lot of live streaming this week.",
        "tokens": [
          51522,
          286,
          362,
          1096,
          257,
          688,
          295,
          1621,
          11791,
          341,
          1243,
          13,
          51694
        ]
      },
      {
        "avg_logprob": -0.3698457956314087,
        "compression_ratio": 1.4695121951219512,
        "end": 3759.7,
        "id": 1290,
        "no_speech_prob": 0.00016092974692583084,
        "seek": 373154,
        "start": 3758.14,
        "temperature": 0,
        "text": " Pat myself on the back.",
        "tokens": [
          51694,
          4379,
          2059,
          322,
          264,
          646,
          13,
          51772
        ]
      },
      {
        "avg_logprob": -0.22656264449610855,
        "compression_ratio": 1.6581818181818182,
        "end": 3761.7799999999997,
        "id": 1291,
        "no_speech_prob": 0.00024922899319790304,
        "seek": 375970,
        "start": 3759.74,
        "temperature": 0,
        "text": " At least five hours of live streaming",
        "tokens": [
          50366,
          1711,
          1935,
          1732,
          2496,
          295,
          1621,
          11791,
          50468
        ]
      },
      {
        "avg_logprob": -0.22656264449610855,
        "compression_ratio": 1.6581818181818182,
        "end": 3763.14,
        "id": 1292,
        "no_speech_prob": 0.00024922899319790304,
        "seek": 375970,
        "start": 3761.7799999999997,
        "temperature": 0,
        "text": " this week, which is pretty good.",
        "tokens": [
          50468,
          341,
          1243,
          11,
          597,
          307,
          1238,
          665,
          13,
          50536
        ]
      },
      {
        "avg_logprob": -0.22656264449610855,
        "compression_ratio": 1.6581818181818182,
        "end": 3766.2599999999998,
        "id": 1293,
        "no_speech_prob": 0.00024922899319790304,
        "seek": 375970,
        "start": 3763.14,
        "temperature": 0,
        "text": " Hopefully that makes up for the weeks that I've missed.",
        "tokens": [
          50536,
          10429,
          300,
          1669,
          493,
          337,
          264,
          3259,
          300,
          286,
          600,
          6721,
          13,
          50692
        ]
      },
      {
        "avg_logprob": -0.22656264449610855,
        "compression_ratio": 1.6581818181818182,
        "end": 3768.7,
        "id": 1294,
        "no_speech_prob": 0.00024922899319790304,
        "seek": 375970,
        "start": 3766.2599999999998,
        "temperature": 0,
        "text": " Next week, I think I might actually not be live streaming",
        "tokens": [
          50692,
          3087,
          1243,
          11,
          286,
          519,
          286,
          1062,
          767,
          406,
          312,
          1621,
          11791,
          50814
        ]
      },
      {
        "avg_logprob": -0.22656264449610855,
        "compression_ratio": 1.6581818181818182,
        "end": 3770.2999999999997,
        "id": 1295,
        "no_speech_prob": 0.00024922899319790304,
        "seek": 375970,
        "start": 3768.7,
        "temperature": 0,
        "text": " on Fridays this summer.",
        "tokens": [
          50814,
          322,
          46306,
          341,
          4266,
          13,
          50894
        ]
      },
      {
        "avg_logprob": -0.22656264449610855,
        "compression_ratio": 1.6581818181818182,
        "end": 3773.22,
        "id": 1296,
        "no_speech_prob": 0.00024922899319790304,
        "seek": 375970,
        "start": 3770.2999999999997,
        "temperature": 0,
        "text": " I think I'm going to be doing Wednesdays and Thursdays",
        "tokens": [
          50894,
          286,
          519,
          286,
          478,
          516,
          281,
          312,
          884,
          10579,
          82,
          293,
          10383,
          82,
          51040
        ]
      },
      {
        "avg_logprob": -0.22656264449610855,
        "compression_ratio": 1.6581818181818182,
        "end": 3775.3799999999997,
        "id": 1297,
        "no_speech_prob": 0.00024922899319790304,
        "seek": 375970,
        "start": 3773.22,
        "temperature": 0,
        "text": " during the day, which is my New York time.",
        "tokens": [
          51040,
          1830,
          264,
          786,
          11,
          597,
          307,
          452,
          1873,
          3609,
          565,
          13,
          51148
        ]
      },
      {
        "avg_logprob": -0.22656264449610855,
        "compression_ratio": 1.6581818181818182,
        "end": 3779.2599999999998,
        "id": 1298,
        "no_speech_prob": 0.00024922899319790304,
        "seek": 375970,
        "start": 3775.3799999999997,
        "temperature": 0,
        "text": " But it's going to be kind of game time decision each week.",
        "tokens": [
          51148,
          583,
          309,
          311,
          516,
          281,
          312,
          733,
          295,
          1216,
          565,
          3537,
          1184,
          1243,
          13,
          51342
        ]
      },
      {
        "avg_logprob": -0.22656264449610855,
        "compression_ratio": 1.6581818181818182,
        "end": 3779.8999999999996,
        "id": 1299,
        "no_speech_prob": 0.00024922899319790304,
        "seek": 375970,
        "start": 3779.2599999999998,
        "temperature": 0,
        "text": " Stay tuned.",
        "tokens": [
          51342,
          8691,
          10870,
          13,
          51374
        ]
      },
      {
        "avg_logprob": -0.22656264449610855,
        "compression_ratio": 1.6581818181818182,
        "end": 3783.7,
        "id": 1300,
        "no_speech_prob": 0.00024922899319790304,
        "seek": 375970,
        "start": 3779.8999999999996,
        "temperature": 0,
        "text": " So what's the stuff you need to know about?",
        "tokens": [
          51374,
          407,
          437,
          311,
          264,
          1507,
          291,
          643,
          281,
          458,
          466,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.22656264449610855,
        "compression_ratio": 1.6581818181818182,
        "end": 3786.8999999999996,
        "id": 1301,
        "no_speech_prob": 0.00024922899319790304,
        "seek": 375970,
        "start": 3783.7,
        "temperature": 0,
        "text": " So if you go to thecodingtrain.com",
        "tokens": [
          51564,
          407,
          498,
          291,
          352,
          281,
          264,
          66,
          8616,
          83,
          7146,
          13,
          1112,
          51724
        ]
      },
      {
        "avg_logprob": -0.2539219812515679,
        "compression_ratio": 1.5203619909502262,
        "end": 3790.98,
        "id": 1302,
        "no_speech_prob": 0.0010649565374478698,
        "seek": 378690,
        "start": 3786.9,
        "temperature": 0,
        "text": " and you click here to subscribe on YouTube,",
        "tokens": [
          50364,
          293,
          291,
          2052,
          510,
          281,
          3022,
          322,
          3088,
          11,
          50568
        ]
      },
      {
        "avg_logprob": -0.2539219812515679,
        "compression_ratio": 1.5203619909502262,
        "end": 3792.3,
        "id": 1303,
        "no_speech_prob": 0.0010649565374478698,
        "seek": 378690,
        "start": 3790.98,
        "temperature": 0,
        "text": " it will take you to the channel.",
        "tokens": [
          50568,
          309,
          486,
          747,
          291,
          281,
          264,
          2269,
          13,
          50634
        ]
      },
      {
        "avg_logprob": -0.2539219812515679,
        "compression_ratio": 1.5203619909502262,
        "end": 3794.78,
        "id": 1304,
        "no_speech_prob": 0.0010649565374478698,
        "seek": 378690,
        "start": 3792.3,
        "temperature": 0,
        "text": " Hey, yeah, I totally want to subscribe.",
        "tokens": [
          50634,
          1911,
          11,
          1338,
          11,
          286,
          3879,
          528,
          281,
          3022,
          13,
          50758
        ]
      },
      {
        "avg_logprob": -0.2539219812515679,
        "compression_ratio": 1.5203619909502262,
        "end": 3795.38,
        "id": 1305,
        "no_speech_prob": 0.0010649565374478698,
        "seek": 378690,
        "start": 3794.78,
        "temperature": 0,
        "text": " I may not.",
        "tokens": [
          50758,
          286,
          815,
          406,
          13,
          50788
        ]
      },
      {
        "avg_logprob": -0.2539219812515679,
        "compression_ratio": 1.5203619909502262,
        "end": 3800.7400000000002,
        "id": 1306,
        "no_speech_prob": 0.0010649565374478698,
        "seek": 378690,
        "start": 3799.3,
        "temperature": 0,
        "text": " Why not?",
        "tokens": [
          50984,
          1545,
          406,
          30,
          51056
        ]
      },
      {
        "avg_logprob": -0.2539219812515679,
        "compression_ratio": 1.5203619909502262,
        "end": 3804.38,
        "id": 1307,
        "no_speech_prob": 0.0010649565374478698,
        "seek": 378690,
        "start": 3800.7400000000002,
        "temperature": 0,
        "text": " I'm so close to 500,000, which is nuts.",
        "tokens": [
          51056,
          286,
          478,
          370,
          1998,
          281,
          5923,
          11,
          1360,
          11,
          597,
          307,
          10483,
          13,
          51238
        ]
      },
      {
        "avg_logprob": -0.2539219812515679,
        "compression_ratio": 1.5203619909502262,
        "end": 3807.58,
        "id": 1308,
        "no_speech_prob": 0.0010649565374478698,
        "seek": 378690,
        "start": 3804.38,
        "temperature": 0,
        "text": " You can get 50,000 subscribers in the next 10 minutes.",
        "tokens": [
          51238,
          509,
          393,
          483,
          2625,
          11,
          1360,
          11092,
          294,
          264,
          958,
          1266,
          2077,
          13,
          51398
        ]
      },
      {
        "avg_logprob": -0.2539219812515679,
        "compression_ratio": 1.5203619909502262,
        "end": 3809.7400000000002,
        "id": 1309,
        "no_speech_prob": 0.0010649565374478698,
        "seek": 378690,
        "start": 3807.58,
        "temperature": 0,
        "text": " That would be exciting.",
        "tokens": [
          51398,
          663,
          576,
          312,
          4670,
          13,
          51506
        ]
      },
      {
        "avg_logprob": -0.2539219812515679,
        "compression_ratio": 1.5203619909502262,
        "end": 3813.14,
        "id": 1310,
        "no_speech_prob": 0.0010649565374478698,
        "seek": 378690,
        "start": 3809.7400000000002,
        "temperature": 0,
        "text": " So look, it says I'm live now, which is this.",
        "tokens": [
          51506,
          407,
          574,
          11,
          309,
          1619,
          286,
          478,
          1621,
          586,
          11,
          597,
          307,
          341,
          13,
          51676
        ]
      },
      {
        "avg_logprob": -0.2539219812515679,
        "compression_ratio": 1.5203619909502262,
        "end": 3816.5,
        "id": 1311,
        "no_speech_prob": 0.0010649565374478698,
        "seek": 378690,
        "start": 3813.14,
        "temperature": 0,
        "text": " But when I schedule a live stream,",
        "tokens": [
          51676,
          583,
          562,
          286,
          7567,
          257,
          1621,
          4309,
          11,
          51844
        ]
      },
      {
        "avg_logprob": -0.37252119217795887,
        "compression_ratio": 1.4684210526315788,
        "end": 3818.74,
        "id": 1312,
        "no_speech_prob": 0.00009915234841173515,
        "seek": 381650,
        "start": 3816.5,
        "temperature": 0,
        "text": " I'm getting some important messages I really got to go.",
        "tokens": [
          50364,
          286,
          478,
          1242,
          512,
          1021,
          7897,
          286,
          534,
          658,
          281,
          352,
          13,
          50476
        ]
      },
      {
        "avg_logprob": -0.37252119217795887,
        "compression_ratio": 1.4684210526315788,
        "end": 3819.9,
        "id": 1313,
        "no_speech_prob": 0.00009915234841173515,
        "seek": 381650,
        "start": 3818.74,
        "temperature": 0,
        "text": " Putting on my goodbye song.",
        "tokens": [
          50476,
          31367,
          322,
          452,
          12084,
          2153,
          13,
          50534
        ]
      },
      {
        "avg_logprob": -0.37252119217795887,
        "compression_ratio": 1.4684210526315788,
        "end": 3825.54,
        "id": 1314,
        "no_speech_prob": 0.00009915234841173515,
        "seek": 381650,
        "start": 3822.62,
        "temperature": 0,
        "text": " Let me just send a little text message back here.",
        "tokens": [
          50670,
          961,
          385,
          445,
          2845,
          257,
          707,
          2487,
          3636,
          646,
          510,
          13,
          50816
        ]
      },
      {
        "avg_logprob": -0.37252119217795887,
        "compression_ratio": 1.4684210526315788,
        "end": 3826.66,
        "id": 1315,
        "no_speech_prob": 0.00009915234841173515,
        "seek": 381650,
        "start": 3825.54,
        "temperature": 0,
        "text": " Yes, will do.",
        "tokens": [
          50816,
          1079,
          11,
          486,
          360,
          13,
          50872
        ]
      },
      {
        "avg_logprob": -0.37252119217795887,
        "compression_ratio": 1.4684210526315788,
        "end": 3832.98,
        "id": 1316,
        "no_speech_prob": 0.00009915234841173515,
        "seek": 381650,
        "start": 3831.66,
        "temperature": 0,
        "text": " Try asking it now.",
        "tokens": [
          51122,
          6526,
          3365,
          309,
          586,
          13,
          51188
        ]
      },
      {
        "avg_logprob": -0.37252119217795887,
        "compression_ratio": 1.4684210526315788,
        "end": 3837.58,
        "id": 1317,
        "no_speech_prob": 0.00009915234841173515,
        "seek": 381650,
        "start": 3836.94,
        "temperature": 0,
        "text": " I missed it.",
        "tokens": [
          51386,
          286,
          6721,
          309,
          13,
          51418
        ]
      },
      {
        "avg_logprob": -0.37252119217795887,
        "compression_ratio": 1.4684210526315788,
        "end": 3838.14,
        "id": 1318,
        "no_speech_prob": 0.00009915234841173515,
        "seek": 381650,
        "start": 3837.58,
        "temperature": 0,
        "text": " There was a question.",
        "tokens": [
          51418,
          821,
          390,
          257,
          1168,
          13,
          51446
        ]
      },
      {
        "avg_logprob": -0.37252119217795887,
        "compression_ratio": 1.4684210526315788,
        "end": 3839.5,
        "id": 1319,
        "no_speech_prob": 0.00009915234841173515,
        "seek": 381650,
        "start": 3838.14,
        "temperature": 0,
        "text": " Show us the hoodie.",
        "tokens": [
          51446,
          6895,
          505,
          264,
          41191,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.37252119217795887,
        "compression_ratio": 1.4684210526315788,
        "end": 3843.26,
        "id": 1320,
        "no_speech_prob": 0.00009915234841173515,
        "seek": 381650,
        "start": 3839.5,
        "temperature": 0,
        "text": " So this hoodie, I don't know if the hoodie available yet.",
        "tokens": [
          51514,
          407,
          341,
          41191,
          11,
          286,
          500,
          380,
          458,
          498,
          264,
          41191,
          2435,
          1939,
          13,
          51702
        ]
      },
      {
        "avg_logprob": -0.3170483509699504,
        "compression_ratio": 1.4536082474226804,
        "end": 3846.6600000000003,
        "id": 1321,
        "no_speech_prob": 0.00008220157906180248,
        "seek": 384326,
        "start": 3843.3,
        "temperature": 0,
        "text": " Oh, the music's not working.",
        "tokens": [
          50366,
          876,
          11,
          264,
          1318,
          311,
          406,
          1364,
          13,
          50534
        ]
      },
      {
        "avg_logprob": -0.3170483509699504,
        "compression_ratio": 1.4536082474226804,
        "end": 3847.82,
        "id": 1322,
        "no_speech_prob": 0.00008220157906180248,
        "seek": 384326,
        "start": 3846.6600000000003,
        "temperature": 0,
        "text": " Sorry about that, everybody.",
        "tokens": [
          50534,
          4919,
          466,
          300,
          11,
          2201,
          13,
          50592
        ]
      },
      {
        "avg_logprob": -0.3170483509699504,
        "compression_ratio": 1.4536082474226804,
        "end": 3848.46,
        "id": 1323,
        "no_speech_prob": 0.00008220157906180248,
        "seek": 384326,
        "start": 3847.82,
        "temperature": 0,
        "text": " I forgot.",
        "tokens": [
          50592,
          286,
          5298,
          13,
          50624
        ]
      },
      {
        "avg_logprob": -0.3170483509699504,
        "compression_ratio": 1.4536082474226804,
        "end": 3851.1000000000004,
        "id": 1324,
        "no_speech_prob": 0.00008220157906180248,
        "seek": 384326,
        "start": 3848.46,
        "temperature": 0,
        "text": " I turned it off.",
        "tokens": [
          50624,
          286,
          3574,
          309,
          766,
          13,
          50756
        ]
      },
      {
        "avg_logprob": -0.3170483509699504,
        "compression_ratio": 1.4536082474226804,
        "end": 3854.34,
        "id": 1325,
        "no_speech_prob": 0.00008220157906180248,
        "seek": 384326,
        "start": 3851.1000000000004,
        "temperature": 0,
        "text": " The hoodie will soon be available.",
        "tokens": [
          50756,
          440,
          41191,
          486,
          2321,
          312,
          2435,
          13,
          50918
        ]
      },
      {
        "avg_logprob": -0.3170483509699504,
        "compression_ratio": 1.4536082474226804,
        "end": 3859.86,
        "id": 1326,
        "no_speech_prob": 0.00008220157906180248,
        "seek": 384326,
        "start": 3854.34,
        "temperature": 0,
        "text": " The store is codingtrain.store.",
        "tokens": [
          50918,
          440,
          3531,
          307,
          17720,
          83,
          7146,
          13,
          21624,
          13,
          51194
        ]
      },
      {
        "avg_logprob": -0.3170483509699504,
        "compression_ratio": 1.4536082474226804,
        "end": 3860.36,
        "id": 1327,
        "no_speech_prob": 0.00008220157906180248,
        "seek": 384326,
        "start": 3859.86,
        "temperature": 0,
        "text": " nv.com.",
        "tokens": [
          51194,
          297,
          85,
          13,
          1112,
          13,
          51219
        ]
      },
      {
        "avg_logprob": -0.3170483509699504,
        "compression_ratio": 1.4536082474226804,
        "end": 3866.1800000000003,
        "id": 1328,
        "no_speech_prob": 0.00008220157906180248,
        "seek": 384326,
        "start": 3862.78,
        "temperature": 0,
        "text": " So this is the URL for the Coding Train store,",
        "tokens": [
          51340,
          407,
          341,
          307,
          264,
          12905,
          337,
          264,
          383,
          8616,
          28029,
          3531,
          11,
          51510
        ]
      },
      {
        "avg_logprob": -0.3170483509699504,
        "compression_ratio": 1.4536082474226804,
        "end": 3868.82,
        "id": 1329,
        "no_speech_prob": 0.00008220157906180248,
        "seek": 384326,
        "start": 3866.1800000000003,
        "temperature": 0,
        "text": " for those of you who are interested.",
        "tokens": [
          51510,
          337,
          729,
          295,
          291,
          567,
          366,
          3102,
          13,
          51642
        ]
      },
      {
        "avg_logprob": -0.3170483509699504,
        "compression_ratio": 1.4536082474226804,
        "end": 3872.1800000000003,
        "id": 1330,
        "no_speech_prob": 0.00008220157906180248,
        "seek": 384326,
        "start": 3868.82,
        "temperature": 0,
        "text": " But right now, if you go here, hoodie,",
        "tokens": [
          51642,
          583,
          558,
          586,
          11,
          498,
          291,
          352,
          510,
          11,
          41191,
          11,
          51810
        ]
      },
      {
        "avg_logprob": -0.22792505536760602,
        "compression_ratio": 1.6814516129032258,
        "end": 3875.2599999999998,
        "id": 1331,
        "no_speech_prob": 0.00001363134288112633,
        "seek": 387218,
        "start": 3872.18,
        "temperature": 0,
        "text": " that's a different hoodie, zip up hoodie.",
        "tokens": [
          50364,
          300,
          311,
          257,
          819,
          41191,
          11,
          20730,
          493,
          41191,
          13,
          50518
        ]
      },
      {
        "avg_logprob": -0.22792505536760602,
        "compression_ratio": 1.6814516129032258,
        "end": 3880.2999999999997,
        "id": 1332,
        "no_speech_prob": 0.00001363134288112633,
        "seek": 387218,
        "start": 3875.2599999999998,
        "temperature": 0,
        "text": " I think, is this the new one or not?",
        "tokens": [
          50518,
          286,
          519,
          11,
          307,
          341,
          264,
          777,
          472,
          420,
          406,
          30,
          50770
        ]
      },
      {
        "avg_logprob": -0.22792505536760602,
        "compression_ratio": 1.6814516129032258,
        "end": 3881.74,
        "id": 1333,
        "no_speech_prob": 0.00001363134288112633,
        "seek": 387218,
        "start": 3880.2999999999997,
        "temperature": 0,
        "text": " Interesting question.",
        "tokens": [
          50770,
          14711,
          1168,
          13,
          50842
        ]
      },
      {
        "avg_logprob": -0.22792505536760602,
        "compression_ratio": 1.6814516129032258,
        "end": 3883.74,
        "id": 1334,
        "no_speech_prob": 0.00001363134288112633,
        "seek": 387218,
        "start": 3881.74,
        "temperature": 0,
        "text": " I think this, I have to see.",
        "tokens": [
          50842,
          286,
          519,
          341,
          11,
          286,
          362,
          281,
          536,
          13,
          50942
        ]
      },
      {
        "avg_logprob": -0.22792505536760602,
        "compression_ratio": 1.6814516129032258,
        "end": 3886.22,
        "id": 1335,
        "no_speech_prob": 0.00001363134288112633,
        "seek": 387218,
        "start": 3883.74,
        "temperature": 0,
        "text": " Let's click on this.",
        "tokens": [
          50942,
          961,
          311,
          2052,
          322,
          341,
          13,
          51066
        ]
      },
      {
        "avg_logprob": -0.22792505536760602,
        "compression_ratio": 1.6814516129032258,
        "end": 3887.02,
        "id": 1336,
        "no_speech_prob": 0.00001363134288112633,
        "seek": 387218,
        "start": 3886.22,
        "temperature": 0,
        "text": " It's expensive.",
        "tokens": [
          51066,
          467,
          311,
          5124,
          13,
          51106
        ]
      },
      {
        "avg_logprob": -0.22792505536760602,
        "compression_ratio": 1.6814516129032258,
        "end": 3889.06,
        "id": 1337,
        "no_speech_prob": 0.00001363134288112633,
        "seek": 387218,
        "start": 3887.02,
        "temperature": 0,
        "text": " Yeah, no, this is the old one.",
        "tokens": [
          51106,
          865,
          11,
          572,
          11,
          341,
          307,
          264,
          1331,
          472,
          13,
          51208
        ]
      },
      {
        "avg_logprob": -0.22792505536760602,
        "compression_ratio": 1.6814516129032258,
        "end": 3891.8199999999997,
        "id": 1338,
        "no_speech_prob": 0.00001363134288112633,
        "seek": 387218,
        "start": 3889.06,
        "temperature": 0,
        "text": " So you could get this, but I'm going to change it.",
        "tokens": [
          51208,
          407,
          291,
          727,
          483,
          341,
          11,
          457,
          286,
          478,
          516,
          281,
          1319,
          309,
          13,
          51346
        ]
      },
      {
        "avg_logprob": -0.22792505536760602,
        "compression_ratio": 1.6814516129032258,
        "end": 3893.4199999999996,
        "id": 1339,
        "no_speech_prob": 0.00001363134288112633,
        "seek": 387218,
        "start": 3891.8199999999997,
        "temperature": 0,
        "text": " This is a new American Apparel hoodie.",
        "tokens": [
          51346,
          639,
          307,
          257,
          777,
          2665,
          3132,
          37675,
          41191,
          13,
          51426
        ]
      },
      {
        "avg_logprob": -0.22792505536760602,
        "compression_ratio": 1.6814516129032258,
        "end": 3894.14,
        "id": 1340,
        "no_speech_prob": 0.00001363134288112633,
        "seek": 387218,
        "start": 3893.4199999999996,
        "temperature": 0,
        "text": " I like it better.",
        "tokens": [
          51426,
          286,
          411,
          309,
          1101,
          13,
          51462
        ]
      },
      {
        "avg_logprob": -0.22792505536760602,
        "compression_ratio": 1.6814516129032258,
        "end": 3897.02,
        "id": 1341,
        "no_speech_prob": 0.00001363134288112633,
        "seek": 387218,
        "start": 3894.14,
        "temperature": 0,
        "text": " And it also has the Coding Train on the back.",
        "tokens": [
          51462,
          400,
          309,
          611,
          575,
          264,
          383,
          8616,
          28029,
          322,
          264,
          646,
          13,
          51606
        ]
      },
      {
        "avg_logprob": -0.22792505536760602,
        "compression_ratio": 1.6814516129032258,
        "end": 3898.74,
        "id": 1342,
        "no_speech_prob": 0.00001363134288112633,
        "seek": 387218,
        "start": 3897.02,
        "temperature": 0,
        "text": " Although, this was the sample.",
        "tokens": [
          51606,
          5780,
          11,
          341,
          390,
          264,
          6889,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.22792505536760602,
        "compression_ratio": 1.6814516129032258,
        "end": 3901.06,
        "id": 1343,
        "no_speech_prob": 0.00001363134288112633,
        "seek": 387218,
        "start": 3898.74,
        "temperature": 0,
        "text": " So I'm going to, we're moving, I'm",
        "tokens": [
          51692,
          407,
          286,
          478,
          516,
          281,
          11,
          321,
          434,
          2684,
          11,
          286,
          478,
          51808
        ]
      },
      {
        "avg_logprob": -0.24624404354371887,
        "compression_ratio": 1.6133333333333333,
        "end": 3903.1,
        "id": 1344,
        "no_speech_prob": 0.00009461250010645017,
        "seek": 390106,
        "start": 3901.06,
        "temperature": 0,
        "text": " going to move it down to about here.",
        "tokens": [
          50364,
          516,
          281,
          1286,
          309,
          760,
          281,
          466,
          510,
          13,
          50466
        ]
      },
      {
        "avg_logprob": -0.24624404354371887,
        "compression_ratio": 1.6133333333333333,
        "end": 3905.2999999999997,
        "id": 1345,
        "no_speech_prob": 0.00009461250010645017,
        "seek": 390106,
        "start": 3903.1,
        "temperature": 0,
        "text": " If anybody has any suggestions or ideas.",
        "tokens": [
          50466,
          759,
          4472,
          575,
          604,
          13396,
          420,
          3487,
          13,
          50576
        ]
      },
      {
        "avg_logprob": -0.24624404354371887,
        "compression_ratio": 1.6133333333333333,
        "end": 3908.18,
        "id": 1346,
        "no_speech_prob": 0.00009461250010645017,
        "seek": 390106,
        "start": 3905.2999999999997,
        "temperature": 0,
        "text": " By the way, all of this is fulfilled through a website",
        "tokens": [
          50576,
          3146,
          264,
          636,
          11,
          439,
          295,
          341,
          307,
          21380,
          807,
          257,
          3144,
          50720
        ]
      },
      {
        "avg_logprob": -0.24624404354371887,
        "compression_ratio": 1.6133333333333333,
        "end": 3909.7799999999997,
        "id": 1347,
        "no_speech_prob": 0.00009461250010645017,
        "seek": 390106,
        "start": 3908.18,
        "temperature": 0,
        "text": " called printful.com.",
        "tokens": [
          50720,
          1219,
          4482,
          906,
          13,
          1112,
          13,
          50800
        ]
      },
      {
        "avg_logprob": -0.24624404354371887,
        "compression_ratio": 1.6133333333333333,
        "end": 3911.94,
        "id": 1348,
        "no_speech_prob": 0.00009461250010645017,
        "seek": 390106,
        "start": 3909.7799999999997,
        "temperature": 0,
        "text": " So in theory, I have the capability",
        "tokens": [
          50800,
          407,
          294,
          5261,
          11,
          286,
          362,
          264,
          13759,
          50908
        ]
      },
      {
        "avg_logprob": -0.24624404354371887,
        "compression_ratio": 1.6133333333333333,
        "end": 3916.74,
        "id": 1349,
        "no_speech_prob": 0.00009461250010645017,
        "seek": 390106,
        "start": 3911.94,
        "temperature": 0,
        "text": " to produce any, like a ton of other things.",
        "tokens": [
          50908,
          281,
          5258,
          604,
          11,
          411,
          257,
          2952,
          295,
          661,
          721,
          13,
          51148
        ]
      },
      {
        "avg_logprob": -0.24624404354371887,
        "compression_ratio": 1.6133333333333333,
        "end": 3918.9,
        "id": 1350,
        "no_speech_prob": 0.00009461250010645017,
        "seek": 390106,
        "start": 3916.74,
        "temperature": 0,
        "text": " But it's just not my priority, merchandise.",
        "tokens": [
          51148,
          583,
          309,
          311,
          445,
          406,
          452,
          9365,
          11,
          34485,
          13,
          51256
        ]
      },
      {
        "avg_logprob": -0.24624404354371887,
        "compression_ratio": 1.6133333333333333,
        "end": 3920.74,
        "id": 1351,
        "no_speech_prob": 0.00009461250010645017,
        "seek": 390106,
        "start": 3918.9,
        "temperature": 0,
        "text": " I don't really know what I'm doing with that.",
        "tokens": [
          51256,
          286,
          500,
          380,
          534,
          458,
          437,
          286,
          478,
          884,
          365,
          300,
          13,
          51348
        ]
      },
      {
        "avg_logprob": -0.24624404354371887,
        "compression_ratio": 1.6133333333333333,
        "end": 3923.22,
        "id": 1352,
        "no_speech_prob": 0.00009461250010645017,
        "seek": 390106,
        "start": 3920.74,
        "temperature": 0,
        "text": " But people were asking me about the hoodie.",
        "tokens": [
          51348,
          583,
          561,
          645,
          3365,
          385,
          466,
          264,
          41191,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -0.24624404354371887,
        "compression_ratio": 1.6133333333333333,
        "end": 3925.18,
        "id": 1353,
        "no_speech_prob": 0.00009461250010645017,
        "seek": 390106,
        "start": 3923.22,
        "temperature": 0,
        "text": " Yeah, Printful ships internationally.",
        "tokens": [
          51472,
          865,
          11,
          34439,
          906,
          11434,
          24422,
          13,
          51570
        ]
      },
      {
        "avg_logprob": -0.24624404354371887,
        "compression_ratio": 1.6133333333333333,
        "end": 3926.54,
        "id": 1354,
        "no_speech_prob": 0.00009461250010645017,
        "seek": 390106,
        "start": 3925.18,
        "temperature": 0,
        "text": " It's not me who's sending it out.",
        "tokens": [
          51570,
          467,
          311,
          406,
          385,
          567,
          311,
          7750,
          309,
          484,
          13,
          51638
        ]
      },
      {
        "avg_logprob": -0.24624404354371887,
        "compression_ratio": 1.6133333333333333,
        "end": 3929.1,
        "id": 1355,
        "no_speech_prob": 0.00009461250010645017,
        "seek": 390106,
        "start": 3926.54,
        "temperature": 0,
        "text": " It's done through a print on demand service.",
        "tokens": [
          51638,
          467,
          311,
          1096,
          807,
          257,
          4482,
          322,
          4733,
          2643,
          13,
          51766
        ]
      },
      {
        "avg_logprob": -0.2511709767875942,
        "compression_ratio": 1.7142857142857142,
        "end": 3930.02,
        "id": 1356,
        "no_speech_prob": 0.00009610212146071717,
        "seek": 392910,
        "start": 3929.1,
        "temperature": 0,
        "text": " It is marked up.",
        "tokens": [
          50364,
          467,
          307,
          12658,
          493,
          13,
          50410
        ]
      },
      {
        "avg_logprob": -0.2511709767875942,
        "compression_ratio": 1.7142857142857142,
        "end": 3932.02,
        "id": 1357,
        "no_speech_prob": 0.00009610212146071717,
        "seek": 392910,
        "start": 3930.02,
        "temperature": 0,
        "text": " So there's like a shipping and a slight markup.",
        "tokens": [
          50410,
          407,
          456,
          311,
          411,
          257,
          14122,
          293,
          257,
          4036,
          1491,
          1010,
          13,
          50510
        ]
      },
      {
        "avg_logprob": -0.2511709767875942,
        "compression_ratio": 1.7142857142857142,
        "end": 3933.14,
        "id": 1358,
        "no_speech_prob": 0.00009610212146071717,
        "seek": 392910,
        "start": 3932.02,
        "temperature": 0,
        "text": " So if you buy the hoodie, I probably",
        "tokens": [
          50510,
          407,
          498,
          291,
          2256,
          264,
          41191,
          11,
          286,
          1391,
          50566
        ]
      },
      {
        "avg_logprob": -0.2511709767875942,
        "compression_ratio": 1.7142857142857142,
        "end": 3934.9,
        "id": 1359,
        "no_speech_prob": 0.00009610212146071717,
        "seek": 392910,
        "start": 3933.14,
        "temperature": 0,
        "text": " make like $4 or $5 or something.",
        "tokens": [
          50566,
          652,
          411,
          1848,
          19,
          420,
          1848,
          20,
          420,
          746,
          13,
          50654
        ]
      },
      {
        "avg_logprob": -0.2511709767875942,
        "compression_ratio": 1.7142857142857142,
        "end": 3936.86,
        "id": 1360,
        "no_speech_prob": 0.00009610212146071717,
        "seek": 392910,
        "start": 3934.9,
        "temperature": 0,
        "text": " I don't know what the exact amount is.",
        "tokens": [
          50654,
          286,
          500,
          380,
          458,
          437,
          264,
          1900,
          2372,
          307,
          13,
          50752
        ]
      },
      {
        "avg_logprob": -0.2511709767875942,
        "compression_ratio": 1.7142857142857142,
        "end": 3939.02,
        "id": 1361,
        "no_speech_prob": 0.00009610212146071717,
        "seek": 392910,
        "start": 3936.86,
        "temperature": 0,
        "text": " It sort of depends on what the, there's",
        "tokens": [
          50752,
          467,
          1333,
          295,
          5946,
          322,
          437,
          264,
          11,
          456,
          311,
          50860
        ]
      },
      {
        "avg_logprob": -0.2511709767875942,
        "compression_ratio": 1.7142857142857142,
        "end": 3940.8199999999997,
        "id": 1362,
        "no_speech_prob": 0.00009610212146071717,
        "seek": 392910,
        "start": 3939.02,
        "temperature": 0,
        "text": " all these weird taxes and shipping things.",
        "tokens": [
          50860,
          439,
          613,
          3657,
          10041,
          293,
          14122,
          721,
          13,
          50950
        ]
      },
      {
        "avg_logprob": -0.2511709767875942,
        "compression_ratio": 1.7142857142857142,
        "end": 3945.06,
        "id": 1363,
        "no_speech_prob": 0.00009610212146071717,
        "seek": 392910,
        "start": 3940.8199999999997,
        "temperature": 0,
        "text": " But I don't, it's actually no, the Patreon stuff,",
        "tokens": [
          50950,
          583,
          286,
          500,
          380,
          11,
          309,
          311,
          767,
          572,
          11,
          264,
          15692,
          1507,
          11,
          51162
        ]
      },
      {
        "avg_logprob": -0.2511709767875942,
        "compression_ratio": 1.7142857142857142,
        "end": 3947.62,
        "id": 1364,
        "no_speech_prob": 0.00009610212146071717,
        "seek": 392910,
        "start": 3945.06,
        "temperature": 0,
        "text": " I actually mail myself.",
        "tokens": [
          51162,
          286,
          767,
          10071,
          2059,
          13,
          51290
        ]
      },
      {
        "avg_logprob": -0.2511709767875942,
        "compression_ratio": 1.7142857142857142,
        "end": 3949.86,
        "id": 1365,
        "no_speech_prob": 0.00009610212146071717,
        "seek": 392910,
        "start": 3947.62,
        "temperature": 0,
        "text": " If you're funding through Patreon or whatever.",
        "tokens": [
          51290,
          759,
          291,
          434,
          6137,
          807,
          15692,
          420,
          2035,
          13,
          51402
        ]
      },
      {
        "avg_logprob": -0.2511709767875942,
        "compression_ratio": 1.7142857142857142,
        "end": 3951.5,
        "id": 1366,
        "no_speech_prob": 0.00009610212146071717,
        "seek": 392910,
        "start": 3949.86,
        "temperature": 0,
        "text": " But the merchandise stuff just gets",
        "tokens": [
          51402,
          583,
          264,
          34485,
          1507,
          445,
          2170,
          51484
        ]
      },
      {
        "avg_logprob": -0.2511709767875942,
        "compression_ratio": 1.7142857142857142,
        "end": 3952.7,
        "id": 1367,
        "no_speech_prob": 0.00009610212146071717,
        "seek": 392910,
        "start": 3951.5,
        "temperature": 0,
        "text": " fulfilled through the Printful store.",
        "tokens": [
          51484,
          21380,
          807,
          264,
          34439,
          906,
          3531,
          13,
          51544
        ]
      },
      {
        "avg_logprob": -0.2511709767875942,
        "compression_ratio": 1.7142857142857142,
        "end": 3953.86,
        "id": 1368,
        "no_speech_prob": 0.00009610212146071717,
        "seek": 392910,
        "start": 3952.7,
        "temperature": 0,
        "text": " I don't have to do anything.",
        "tokens": [
          51544,
          286,
          500,
          380,
          362,
          281,
          360,
          1340,
          13,
          51602
        ]
      },
      {
        "avg_logprob": -0.34956983340683806,
        "compression_ratio": 1.5217391304347827,
        "end": 3959.5,
        "id": 1369,
        "no_speech_prob": 0.000011300777259748429,
        "seek": 395386,
        "start": 3954.86,
        "temperature": 0,
        "text": " Um, do you know, ah, the Nair Engineer question.",
        "tokens": [
          50414,
          3301,
          11,
          360,
          291,
          458,
          11,
          3716,
          11,
          264,
          426,
          1246,
          15808,
          1168,
          13,
          50646
        ]
      },
      {
        "avg_logprob": -0.34956983340683806,
        "compression_ratio": 1.5217391304347827,
        "end": 3961.2200000000003,
        "id": 1370,
        "no_speech_prob": 0.000011300777259748429,
        "seek": 395386,
        "start": 3959.5,
        "temperature": 0,
        "text": " Do you know any reference how to link",
        "tokens": [
          50646,
          1144,
          291,
          458,
          604,
          6408,
          577,
          281,
          2113,
          50732
        ]
      },
      {
        "avg_logprob": -0.34956983340683806,
        "compression_ratio": 1.5217391304347827,
        "end": 3963.06,
        "id": 1371,
        "no_speech_prob": 0.000011300777259748429,
        "seek": 395386,
        "start": 3961.2200000000003,
        "temperature": 0,
        "text": " processing-java to Atom?",
        "tokens": [
          50732,
          9007,
          12,
          73,
          4061,
          281,
          1711,
          298,
          30,
          50824
        ]
      },
      {
        "avg_logprob": -0.34956983340683806,
        "compression_ratio": 1.5217391304347827,
        "end": 3964.3,
        "id": 1372,
        "no_speech_prob": 0.000011300777259748429,
        "seek": 395386,
        "start": 3963.06,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          50824,
          1079,
          13,
          50886
        ]
      },
      {
        "avg_logprob": -0.34956983340683806,
        "compression_ratio": 1.5217391304347827,
        "end": 3966.86,
        "id": 1373,
        "no_speech_prob": 0.000011300777259748429,
        "seek": 395386,
        "start": 3964.3,
        "temperature": 0,
        "text": " So what you want to look at is,",
        "tokens": [
          50886,
          407,
          437,
          291,
          528,
          281,
          574,
          412,
          307,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.34956983340683806,
        "compression_ratio": 1.5217391304347827,
        "end": 3969.6600000000003,
        "id": 1374,
        "no_speech_prob": 0.000011300777259748429,
        "seek": 395386,
        "start": 3966.86,
        "temperature": 0,
        "text": " a commander, processing command line.",
        "tokens": [
          51014,
          257,
          17885,
          11,
          9007,
          5622,
          1622,
          13,
          51154
        ]
      },
      {
        "avg_logprob": -0.34956983340683806,
        "compression_ratio": 1.5217391304347827,
        "end": 3973.98,
        "id": 1375,
        "no_speech_prob": 0.000011300777259748429,
        "seek": 395386,
        "start": 3972.34,
        "temperature": 0,
        "text": " So you want to look at,",
        "tokens": [
          51288,
          407,
          291,
          528,
          281,
          574,
          412,
          11,
          51370
        ]
      },
      {
        "avg_logprob": -0.34956983340683806,
        "compression_ratio": 1.5217391304347827,
        "end": 3981.26,
        "id": 1376,
        "no_speech_prob": 0.000011300777259748429,
        "seek": 395386,
        "start": 3980.06,
        "temperature": 0,
        "text": " command, hold on, don't worry.",
        "tokens": [
          51674,
          5622,
          11,
          1797,
          322,
          11,
          500,
          380,
          3292,
          13,
          51734
        ]
      },
      {
        "avg_logprob": -0.34956983340683806,
        "compression_ratio": 1.5217391304347827,
        "end": 3983.2200000000003,
        "id": 1377,
        "no_speech_prob": 0.000011300777259748429,
        "seek": 395386,
        "start": 3981.26,
        "temperature": 0,
        "text": " I know the camera went off, everybody.",
        "tokens": [
          51734,
          286,
          458,
          264,
          2799,
          1437,
          766,
          11,
          2201,
          13,
          51832
        ]
      },
      {
        "avg_logprob": -0.26240463594419766,
        "compression_ratio": 1.643835616438356,
        "end": 3984.4199999999996,
        "id": 1378,
        "no_speech_prob": 0.0000063391753428732045,
        "seek": 398322,
        "start": 3983.58,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50382,
          821,
          321,
          352,
          13,
          50424
        ]
      },
      {
        "avg_logprob": -0.26240463594419766,
        "compression_ratio": 1.643835616438356,
        "end": 3987.9399999999996,
        "id": 1379,
        "no_speech_prob": 0.0000063391753428732045,
        "seek": 398322,
        "start": 3986.5,
        "temperature": 0,
        "text": " I think somebody's already done this",
        "tokens": [
          50528,
          286,
          519,
          2618,
          311,
          1217,
          1096,
          341,
          50600
        ]
      },
      {
        "avg_logprob": -0.26240463594419766,
        "compression_ratio": 1.643835616438356,
        "end": 3989.8999999999996,
        "id": 1380,
        "no_speech_prob": 0.0000063391753428732045,
        "seek": 398322,
        "start": 3987.9399999999996,
        "temperature": 0,
        "text": " with like an Atom plugin.",
        "tokens": [
          50600,
          365,
          411,
          364,
          1711,
          298,
          23407,
          13,
          50698
        ]
      },
      {
        "avg_logprob": -0.26240463594419766,
        "compression_ratio": 1.643835616438356,
        "end": 3991.74,
        "id": 1381,
        "no_speech_prob": 0.0000063391753428732045,
        "seek": 398322,
        "start": 3989.8999999999996,
        "temperature": 0,
        "text": " But if you go here to this wiki,",
        "tokens": [
          50698,
          583,
          498,
          291,
          352,
          510,
          281,
          341,
          261,
          9850,
          11,
          50790
        ]
      },
      {
        "avg_logprob": -0.26240463594419766,
        "compression_ratio": 1.643835616438356,
        "end": 3993.3799999999997,
        "id": 1382,
        "no_speech_prob": 0.0000063391753428732045,
        "seek": 398322,
        "start": 3991.74,
        "temperature": 0,
        "text": " command line processing,",
        "tokens": [
          50790,
          5622,
          1622,
          9007,
          11,
          50872
        ]
      },
      {
        "avg_logprob": -0.26240463594419766,
        "compression_ratio": 1.643835616438356,
        "end": 3999.3799999999997,
        "id": 1383,
        "no_speech_prob": 0.0000063391753428732045,
        "seek": 398322,
        "start": 3994.98,
        "temperature": 0,
        "text": " there is a command line tool that you can install.",
        "tokens": [
          50952,
          456,
          307,
          257,
          5622,
          1622,
          2290,
          300,
          291,
          393,
          3625,
          13,
          51172
        ]
      },
      {
        "avg_logprob": -0.26240463594419766,
        "compression_ratio": 1.643835616438356,
        "end": 4000.4199999999996,
        "id": 1384,
        "no_speech_prob": 0.0000063391753428732045,
        "seek": 398322,
        "start": 3999.3799999999997,
        "temperature": 0,
        "text": " And,",
        "tokens": [
          51172,
          400,
          11,
          51224
        ]
      },
      {
        "avg_logprob": -0.26240463594419766,
        "compression_ratio": 1.643835616438356,
        "end": 4005.14,
        "id": 1385,
        "no_speech_prob": 0.0000063391753428732045,
        "seek": 398322,
        "start": 4002.18,
        "temperature": 0,
        "text": " then you can have Atom like execute",
        "tokens": [
          51312,
          550,
          291,
          393,
          362,
          1711,
          298,
          411,
          14483,
          51460
        ]
      },
      {
        "avg_logprob": -0.26240463594419766,
        "compression_ratio": 1.643835616438356,
        "end": 4006.66,
        "id": 1386,
        "no_speech_prob": 0.0000063391753428732045,
        "seek": 398322,
        "start": 4005.14,
        "temperature": 0,
        "text": " the sketch via a command line.",
        "tokens": [
          51460,
          264,
          12325,
          5766,
          257,
          5622,
          1622,
          13,
          51536
        ]
      },
      {
        "avg_logprob": -0.26240463594419766,
        "compression_ratio": 1.643835616438356,
        "end": 4008.5,
        "id": 1387,
        "no_speech_prob": 0.0000063391753428732045,
        "seek": 398322,
        "start": 4006.66,
        "temperature": 0,
        "text": " So you have to like configure Atom in a goofy way.",
        "tokens": [
          51536,
          407,
          291,
          362,
          281,
          411,
          22162,
          1711,
          298,
          294,
          257,
          42995,
          636,
          13,
          51628
        ]
      },
      {
        "avg_logprob": -0.26240463594419766,
        "compression_ratio": 1.643835616438356,
        "end": 4009.8199999999997,
        "id": 1388,
        "no_speech_prob": 0.0000063391753428732045,
        "seek": 398322,
        "start": 4008.5,
        "temperature": 0,
        "text": " This has been done.",
        "tokens": [
          51628,
          639,
          575,
          668,
          1096,
          13,
          51694
        ]
      },
      {
        "avg_logprob": -0.26240463594419766,
        "compression_ratio": 1.643835616438356,
        "end": 4011.18,
        "id": 1389,
        "no_speech_prob": 0.0000063391753428732045,
        "seek": 398322,
        "start": 4009.8199999999997,
        "temperature": 0,
        "text": " I know it was done with Sublime.",
        "tokens": [
          51694,
          286,
          458,
          309,
          390,
          1096,
          365,
          8511,
          40941,
          13,
          51762
        ]
      },
      {
        "avg_logprob": -0.27249071515839673,
        "compression_ratio": 1.617117117117117,
        "end": 4013.94,
        "id": 1390,
        "no_speech_prob": 0.0008295800071209669,
        "seek": 401118,
        "start": 4011.18,
        "temperature": 0,
        "text": " Atom editor processing.org.",
        "tokens": [
          50364,
          1711,
          298,
          9839,
          9007,
          13,
          4646,
          13,
          50502
        ]
      },
      {
        "avg_logprob": -0.27249071515839673,
        "compression_ratio": 1.617117117117117,
        "end": 4017.2999999999997,
        "id": 1391,
        "no_speech_prob": 0.0008295800071209669,
        "seek": 401118,
        "start": 4014.8599999999997,
        "temperature": 0,
        "text": " Yeah, so like, yeah.",
        "tokens": [
          50548,
          865,
          11,
          370,
          411,
          11,
          1338,
          13,
          50670
        ]
      },
      {
        "avg_logprob": -0.27249071515839673,
        "compression_ratio": 1.617117117117117,
        "end": 4019.8199999999997,
        "id": 1392,
        "no_speech_prob": 0.0008295800071209669,
        "seek": 401118,
        "start": 4017.2999999999997,
        "temperature": 0,
        "text": " So I have a feeling, yeah.",
        "tokens": [
          50670,
          407,
          286,
          362,
          257,
          2633,
          11,
          1338,
          13,
          50796
        ]
      },
      {
        "avg_logprob": -0.27249071515839673,
        "compression_ratio": 1.617117117117117,
        "end": 4022.1,
        "id": 1393,
        "no_speech_prob": 0.0008295800071209669,
        "seek": 401118,
        "start": 4019.8199999999997,
        "temperature": 0,
        "text": " So you can see somebody's already done this already.",
        "tokens": [
          50796,
          407,
          291,
          393,
          536,
          2618,
          311,
          1217,
          1096,
          341,
          1217,
          13,
          50910
        ]
      },
      {
        "avg_logprob": -0.27249071515839673,
        "compression_ratio": 1.617117117117117,
        "end": 4023.1,
        "id": 1394,
        "no_speech_prob": 0.0008295800071209669,
        "seek": 401118,
        "start": 4022.1,
        "temperature": 0,
        "text": " And figured it out.",
        "tokens": [
          50910,
          400,
          8932,
          309,
          484,
          13,
          50960
        ]
      },
      {
        "avg_logprob": -0.27249071515839673,
        "compression_ratio": 1.617117117117117,
        "end": 4026.8999999999996,
        "id": 1395,
        "no_speech_prob": 0.0008295800071209669,
        "seek": 401118,
        "start": 4023.1,
        "temperature": 0,
        "text": " So you have to install processing-java.",
        "tokens": [
          50960,
          407,
          291,
          362,
          281,
          3625,
          9007,
          12,
          73,
          4061,
          13,
          51150
        ]
      },
      {
        "avg_logprob": -0.27249071515839673,
        "compression_ratio": 1.617117117117117,
        "end": 4028.2999999999997,
        "id": 1396,
        "no_speech_prob": 0.0008295800071209669,
        "seek": 401118,
        "start": 4026.8999999999996,
        "temperature": 0,
        "text": " And this is, so these are the instructions.",
        "tokens": [
          51150,
          400,
          341,
          307,
          11,
          370,
          613,
          366,
          264,
          9415,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.27249071515839673,
        "compression_ratio": 1.617117117117117,
        "end": 4029.58,
        "id": 1397,
        "no_speech_prob": 0.0008295800071209669,
        "seek": 401118,
        "start": 4028.2999999999997,
        "temperature": 0,
        "text": " Then you have to add stuff to your path",
        "tokens": [
          51220,
          1396,
          291,
          362,
          281,
          909,
          1507,
          281,
          428,
          3100,
          51284
        ]
      },
      {
        "avg_logprob": -0.27249071515839673,
        "compression_ratio": 1.617117117117117,
        "end": 4030.4199999999996,
        "id": 1398,
        "no_speech_prob": 0.0008295800071209669,
        "seek": 401118,
        "start": 4029.58,
        "temperature": 0,
        "text": " and that sort of thing.",
        "tokens": [
          51284,
          293,
          300,
          1333,
          295,
          551,
          13,
          51326
        ]
      },
      {
        "avg_logprob": -0.27249071515839673,
        "compression_ratio": 1.617117117117117,
        "end": 4031.7,
        "id": 1399,
        "no_speech_prob": 0.0008295800071209669,
        "seek": 401118,
        "start": 4030.4199999999996,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51326,
          1033,
          13,
          51390
        ]
      },
      {
        "avg_logprob": -0.27249071515839673,
        "compression_ratio": 1.617117117117117,
        "end": 4033.18,
        "id": 1400,
        "no_speech_prob": 0.0008295800071209669,
        "seek": 401118,
        "start": 4031.7,
        "temperature": 0,
        "text": " Let's look at the chat.",
        "tokens": [
          51390,
          961,
          311,
          574,
          412,
          264,
          5081,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.27249071515839673,
        "compression_ratio": 1.617117117117117,
        "end": 4040.2999999999997,
        "id": 1401,
        "no_speech_prob": 0.0008295800071209669,
        "seek": 401118,
        "start": 4038.3799999999997,
        "temperature": 0,
        "text": " Dan, why do you know everything?",
        "tokens": [
          51724,
          3394,
          11,
          983,
          360,
          291,
          458,
          1203,
          30,
          51820
        ]
      },
      {
        "avg_logprob": -0.2700651234593885,
        "compression_ratio": 1.7447552447552448,
        "end": 4041.2200000000003,
        "id": 1402,
        "no_speech_prob": 0.004755012225359678,
        "seek": 404030,
        "start": 4040.3,
        "temperature": 0,
        "text": " Asks Melon Goggles.",
        "tokens": [
          50364,
          1018,
          1694,
          7375,
          266,
          39690,
          70,
          904,
          13,
          50410
        ]
      },
      {
        "avg_logprob": -0.2700651234593885,
        "compression_ratio": 1.7447552447552448,
        "end": 4042.7000000000003,
        "id": 1403,
        "no_speech_prob": 0.004755012225359678,
        "seek": 404030,
        "start": 4041.2200000000003,
        "temperature": 0,
        "text": " It is absolutely an illusion.",
        "tokens": [
          50410,
          467,
          307,
          3122,
          364,
          18854,
          13,
          50484
        ]
      },
      {
        "avg_logprob": -0.2700651234593885,
        "compression_ratio": 1.7447552447552448,
        "end": 4044.9,
        "id": 1404,
        "no_speech_prob": 0.004755012225359678,
        "seek": 404030,
        "start": 4042.7000000000003,
        "temperature": 0,
        "text": " I definitely do not know everything.",
        "tokens": [
          50484,
          286,
          2138,
          360,
          406,
          458,
          1203,
          13,
          50594
        ]
      },
      {
        "avg_logprob": -0.2700651234593885,
        "compression_ratio": 1.7447552447552448,
        "end": 4046.78,
        "id": 1405,
        "no_speech_prob": 0.004755012225359678,
        "seek": 404030,
        "start": 4044.9,
        "temperature": 0,
        "text": " And I just know, I just know like,",
        "tokens": [
          50594,
          400,
          286,
          445,
          458,
          11,
          286,
          445,
          458,
          411,
          11,
          50688
        ]
      },
      {
        "avg_logprob": -0.2700651234593885,
        "compression_ratio": 1.7447552447552448,
        "end": 4048.78,
        "id": 1406,
        "no_speech_prob": 0.004755012225359678,
        "seek": 404030,
        "start": 4046.78,
        "temperature": 0,
        "text": " just enough to like get through the tutorial.",
        "tokens": [
          50688,
          445,
          1547,
          281,
          411,
          483,
          807,
          264,
          7073,
          13,
          50788
        ]
      },
      {
        "avg_logprob": -0.2700651234593885,
        "compression_ratio": 1.7447552447552448,
        "end": 4050.78,
        "id": 1407,
        "no_speech_prob": 0.004755012225359678,
        "seek": 404030,
        "start": 4048.78,
        "temperature": 0,
        "text": " And then like, if I were to go two steps further,",
        "tokens": [
          50788,
          400,
          550,
          411,
          11,
          498,
          286,
          645,
          281,
          352,
          732,
          4439,
          3052,
          11,
          50888
        ]
      },
      {
        "avg_logprob": -0.2700651234593885,
        "compression_ratio": 1.7447552447552448,
        "end": 4052.5800000000004,
        "id": 1408,
        "no_speech_prob": 0.004755012225359678,
        "seek": 404030,
        "start": 4050.78,
        "temperature": 0,
        "text": " there'd be like a hundred things I don't know.",
        "tokens": [
          50888,
          456,
          1116,
          312,
          411,
          257,
          3262,
          721,
          286,
          500,
          380,
          458,
          13,
          50978
        ]
      },
      {
        "avg_logprob": -0.2700651234593885,
        "compression_ratio": 1.7447552447552448,
        "end": 4054.94,
        "id": 1409,
        "no_speech_prob": 0.004755012225359678,
        "seek": 404030,
        "start": 4052.5800000000004,
        "temperature": 0,
        "text": " And you've, all of you have I'm sure seen",
        "tokens": [
          50978,
          400,
          291,
          600,
          11,
          439,
          295,
          291,
          362,
          286,
          478,
          988,
          1612,
          51096
        ]
      },
      {
        "avg_logprob": -0.2700651234593885,
        "compression_ratio": 1.7447552447552448,
        "end": 4057.9,
        "id": 1410,
        "no_speech_prob": 0.004755012225359678,
        "seek": 404030,
        "start": 4054.94,
        "temperature": 0,
        "text": " my disastrous live streams where I get completely lost.",
        "tokens": [
          51096,
          452,
          44502,
          1621,
          15842,
          689,
          286,
          483,
          2584,
          2731,
          13,
          51244
        ]
      },
      {
        "avg_logprob": -0.2700651234593885,
        "compression_ratio": 1.7447552447552448,
        "end": 4061.38,
        "id": 1411,
        "no_speech_prob": 0.004755012225359678,
        "seek": 404030,
        "start": 4059.6200000000003,
        "temperature": 0,
        "text": " If any of you try to watch some of my tutorials",
        "tokens": [
          51330,
          759,
          604,
          295,
          291,
          853,
          281,
          1159,
          512,
          295,
          452,
          17616,
          51418
        ]
      },
      {
        "avg_logprob": -0.2700651234593885,
        "compression_ratio": 1.7447552447552448,
        "end": 4062.7000000000003,
        "id": 1412,
        "no_speech_prob": 0.004755012225359678,
        "seek": 404030,
        "start": 4061.38,
        "temperature": 0,
        "text": " where I try to explain calculus stuff,",
        "tokens": [
          51418,
          689,
          286,
          853,
          281,
          2903,
          33400,
          1507,
          11,
          51484
        ]
      },
      {
        "avg_logprob": -0.2700651234593885,
        "compression_ratio": 1.7447552447552448,
        "end": 4064.5800000000004,
        "id": 1413,
        "no_speech_prob": 0.004755012225359678,
        "seek": 404030,
        "start": 4062.7000000000003,
        "temperature": 0,
        "text": " you would see that I don't know everything.",
        "tokens": [
          51484,
          291,
          576,
          536,
          300,
          286,
          500,
          380,
          458,
          1203,
          13,
          51578
        ]
      },
      {
        "avg_logprob": -0.2700651234593885,
        "compression_ratio": 1.7447552447552448,
        "end": 4066.5,
        "id": 1414,
        "no_speech_prob": 0.004755012225359678,
        "seek": 404030,
        "start": 4065.6600000000003,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51632,
          1033,
          13,
          51674
        ]
      },
      {
        "avg_logprob": -0.27832948244535005,
        "compression_ratio": 1.566820276497696,
        "end": 4073.54,
        "id": 1415,
        "no_speech_prob": 0.00000471089106213185,
        "seek": 407030,
        "start": 4070.6600000000003,
        "temperature": 0,
        "text": " Um, all right.",
        "tokens": [
          50382,
          3301,
          11,
          439,
          558,
          13,
          50526
        ]
      },
      {
        "avg_logprob": -0.27832948244535005,
        "compression_ratio": 1.566820276497696,
        "end": 4076.26,
        "id": 1416,
        "no_speech_prob": 0.00000471089106213185,
        "seek": 407030,
        "start": 4073.54,
        "temperature": 0,
        "text": " So thank you for all the questions in the chat.",
        "tokens": [
          50526,
          407,
          1309,
          291,
          337,
          439,
          264,
          1651,
          294,
          264,
          5081,
          13,
          50662
        ]
      },
      {
        "avg_logprob": -0.27832948244535005,
        "compression_ratio": 1.566820276497696,
        "end": 4078.42,
        "id": 1417,
        "no_speech_prob": 0.00000471089106213185,
        "seek": 407030,
        "start": 4076.26,
        "temperature": 0,
        "text": " I'll answer the last question.",
        "tokens": [
          50662,
          286,
          603,
          1867,
          264,
          1036,
          1168,
          13,
          50770
        ]
      },
      {
        "avg_logprob": -0.27832948244535005,
        "compression_ratio": 1.566820276497696,
        "end": 4084.1400000000003,
        "id": 1418,
        "no_speech_prob": 0.00000471089106213185,
        "seek": 407030,
        "start": 4081.2200000000003,
        "temperature": 0,
        "text": " Justine asks,",
        "tokens": [
          50910,
          1449,
          533,
          8962,
          11,
          51056
        ]
      },
      {
        "avg_logprob": -0.27832948244535005,
        "compression_ratio": 1.566820276497696,
        "end": 4088.98,
        "id": 1419,
        "no_speech_prob": 0.00000471089106213185,
        "seek": 407030,
        "start": 4086.46,
        "temperature": 0,
        "text": " what's up with the camera going off every 30 minutes?",
        "tokens": [
          51172,
          437,
          311,
          493,
          365,
          264,
          2799,
          516,
          766,
          633,
          2217,
          2077,
          30,
          51298
        ]
      },
      {
        "avg_logprob": -0.27832948244535005,
        "compression_ratio": 1.566820276497696,
        "end": 4091.46,
        "id": 1420,
        "no_speech_prob": 0.00000471089106213185,
        "seek": 407030,
        "start": 4088.98,
        "temperature": 0,
        "text": " Have you ever watched the TV show Lost?",
        "tokens": [
          51298,
          3560,
          291,
          1562,
          6337,
          264,
          3558,
          855,
          23422,
          30,
          51422
        ]
      },
      {
        "avg_logprob": -0.27832948244535005,
        "compression_ratio": 1.566820276497696,
        "end": 4093.9,
        "id": 1421,
        "no_speech_prob": 0.00000471089106213185,
        "seek": 407030,
        "start": 4091.46,
        "temperature": 0,
        "text": " Basically this is the, what's the thing called?",
        "tokens": [
          51422,
          8537,
          341,
          307,
          264,
          11,
          437,
          311,
          264,
          551,
          1219,
          30,
          51544
        ]
      },
      {
        "avg_logprob": -0.27832948244535005,
        "compression_ratio": 1.566820276497696,
        "end": 4094.78,
        "id": 1422,
        "no_speech_prob": 0.00000471089106213185,
        "seek": 407030,
        "start": 4093.9,
        "temperature": 0,
        "text": " The hatch.",
        "tokens": [
          51544,
          440,
          17387,
          13,
          51588
        ]
      },
      {
        "avg_logprob": -0.27832948244535005,
        "compression_ratio": 1.566820276497696,
        "end": 4097.1,
        "id": 1423,
        "no_speech_prob": 0.00000471089106213185,
        "seek": 407030,
        "start": 4094.78,
        "temperature": 0,
        "text": " I'm in the like Swan station.",
        "tokens": [
          51588,
          286,
          478,
          294,
          264,
          411,
          40884,
          5214,
          13,
          51704
        ]
      },
      {
        "avg_logprob": -0.27832948244535005,
        "compression_ratio": 1.566820276497696,
        "end": 4099.820000000001,
        "id": 1424,
        "no_speech_prob": 0.00000471089106213185,
        "seek": 407030,
        "start": 4097.1,
        "temperature": 0,
        "text": " And if I don't press the button every 30 minutes,",
        "tokens": [
          51704,
          400,
          498,
          286,
          500,
          380,
          1886,
          264,
          2960,
          633,
          2217,
          2077,
          11,
          51840
        ]
      },
      {
        "avg_logprob": -0.21104184397450693,
        "compression_ratio": 1.6363636363636365,
        "end": 4101.42,
        "id": 1425,
        "no_speech_prob": 0.000013007088455196936,
        "seek": 409982,
        "start": 4100.219999999999,
        "temperature": 0,
        "text": " the world will end.",
        "tokens": [
          50384,
          264,
          1002,
          486,
          917,
          13,
          50444
        ]
      },
      {
        "avg_logprob": -0.21104184397450693,
        "compression_ratio": 1.6363636363636365,
        "end": 4103.38,
        "id": 1426,
        "no_speech_prob": 0.000013007088455196936,
        "seek": 409982,
        "start": 4101.42,
        "temperature": 0,
        "text": " That's why I press the button every 30 minutes.",
        "tokens": [
          50444,
          663,
          311,
          983,
          286,
          1886,
          264,
          2960,
          633,
          2217,
          2077,
          13,
          50542
        ]
      },
      {
        "avg_logprob": -0.21104184397450693,
        "compression_ratio": 1.6363636363636365,
        "end": 4105.0599999999995,
        "id": 1427,
        "no_speech_prob": 0.000013007088455196936,
        "seek": 409982,
        "start": 4103.38,
        "temperature": 0,
        "text": " No, the cameras have,",
        "tokens": [
          50542,
          883,
          11,
          264,
          8622,
          362,
          11,
          50626
        ]
      },
      {
        "avg_logprob": -0.21104184397450693,
        "compression_ratio": 1.6363636363636365,
        "end": 4107.099999999999,
        "id": 1428,
        "no_speech_prob": 0.000013007088455196936,
        "seek": 409982,
        "start": 4105.0599999999995,
        "temperature": 0,
        "text": " these cameras are set to go to sleep.",
        "tokens": [
          50626,
          613,
          8622,
          366,
          992,
          281,
          352,
          281,
          2817,
          13,
          50728
        ]
      },
      {
        "avg_logprob": -0.21104184397450693,
        "compression_ratio": 1.6363636363636365,
        "end": 4108.38,
        "id": 1429,
        "no_speech_prob": 0.000013007088455196936,
        "seek": 409982,
        "start": 4107.099999999999,
        "temperature": 0,
        "text": " And there are, I've been,",
        "tokens": [
          50728,
          400,
          456,
          366,
          11,
          286,
          600,
          668,
          11,
          50792
        ]
      },
      {
        "avg_logprob": -0.21104184397450693,
        "compression_ratio": 1.6363636363636365,
        "end": 4110.179999999999,
        "id": 1430,
        "no_speech_prob": 0.000013007088455196936,
        "seek": 409982,
        "start": 4108.38,
        "temperature": 0,
        "text": " many people have given me many suggestions",
        "tokens": [
          50792,
          867,
          561,
          362,
          2212,
          385,
          867,
          13396,
          50882
        ]
      },
      {
        "avg_logprob": -0.21104184397450693,
        "compression_ratio": 1.6363636363636365,
        "end": 4111.259999999999,
        "id": 1431,
        "no_speech_prob": 0.000013007088455196936,
        "seek": 409982,
        "start": 4110.179999999999,
        "temperature": 0,
        "text": " to get them not to do that.",
        "tokens": [
          50882,
          281,
          483,
          552,
          406,
          281,
          360,
          300,
          13,
          50936
        ]
      },
      {
        "avg_logprob": -0.21104184397450693,
        "compression_ratio": 1.6363636363636365,
        "end": 4112.5,
        "id": 1432,
        "no_speech_prob": 0.000013007088455196936,
        "seek": 409982,
        "start": 4111.259999999999,
        "temperature": 0,
        "text": " And I have not successfully been able",
        "tokens": [
          50936,
          400,
          286,
          362,
          406,
          10727,
          668,
          1075,
          50998
        ]
      },
      {
        "avg_logprob": -0.21104184397450693,
        "compression_ratio": 1.6363636363636365,
        "end": 4113.74,
        "id": 1433,
        "no_speech_prob": 0.000013007088455196936,
        "seek": 409982,
        "start": 4112.5,
        "temperature": 0,
        "text": " to implement any of them.",
        "tokens": [
          50998,
          281,
          4445,
          604,
          295,
          552,
          13,
          51060
        ]
      },
      {
        "avg_logprob": -0.21104184397450693,
        "compression_ratio": 1.6363636363636365,
        "end": 4117.74,
        "id": 1434,
        "no_speech_prob": 0.000013007088455196936,
        "seek": 409982,
        "start": 4114.62,
        "temperature": 0,
        "text": " So I, that's kind of a goal I have for the summer for sure.",
        "tokens": [
          51104,
          407,
          286,
          11,
          300,
          311,
          733,
          295,
          257,
          3387,
          286,
          362,
          337,
          264,
          4266,
          337,
          988,
          13,
          51260
        ]
      },
      {
        "avg_logprob": -0.21104184397450693,
        "compression_ratio": 1.6363636363636365,
        "end": 4120.94,
        "id": 1435,
        "no_speech_prob": 0.000013007088455196936,
        "seek": 409982,
        "start": 4119.0199999999995,
        "temperature": 0,
        "text": " Oh, did I just spoil Lost for people?",
        "tokens": [
          51324,
          876,
          11,
          630,
          286,
          445,
          18630,
          23422,
          337,
          561,
          30,
          51420
        ]
      },
      {
        "avg_logprob": -0.21104184397450693,
        "compression_ratio": 1.6363636363636365,
        "end": 4122.74,
        "id": 1436,
        "no_speech_prob": 0.000013007088455196936,
        "seek": 409982,
        "start": 4120.94,
        "temperature": 0,
        "text": " I'm terribly sorry.",
        "tokens": [
          51420,
          286,
          478,
          22903,
          2597,
          13,
          51510
        ]
      },
      {
        "avg_logprob": -0.21104184397450693,
        "compression_ratio": 1.6363636363636365,
        "end": 4125.099999999999,
        "id": 1437,
        "no_speech_prob": 0.000013007088455196936,
        "seek": 409982,
        "start": 4122.74,
        "temperature": 0,
        "text": " The thing is that didn't really spoil anything.",
        "tokens": [
          51510,
          440,
          551,
          307,
          300,
          994,
          380,
          534,
          18630,
          1340,
          13,
          51628
        ]
      },
      {
        "avg_logprob": -0.21104184397450693,
        "compression_ratio": 1.6363636363636365,
        "end": 4129.259999999999,
        "id": 1438,
        "no_speech_prob": 0.000013007088455196936,
        "seek": 409982,
        "start": 4127.66,
        "temperature": 0,
        "text": " A little bit.",
        "tokens": [
          51756,
          316,
          707,
          857,
          13,
          51836
        ]
      },
      {
        "avg_logprob": -0.2623786649842193,
        "compression_ratio": 1.5346534653465347,
        "end": 4131.14,
        "id": 1439,
        "no_speech_prob": 0.0005357746849767864,
        "seek": 412926,
        "start": 4129.62,
        "temperature": 0,
        "text": " Lost is one of my favorite television shows.",
        "tokens": [
          50382,
          23422,
          307,
          472,
          295,
          452,
          2954,
          8815,
          3110,
          13,
          50458
        ]
      },
      {
        "avg_logprob": -0.2623786649842193,
        "compression_ratio": 1.5346534653465347,
        "end": 4132.14,
        "id": 1440,
        "no_speech_prob": 0.0005357746849767864,
        "seek": 412926,
        "start": 4131.14,
        "temperature": 0,
        "text": " I need some, what am I?",
        "tokens": [
          50458,
          286,
          643,
          512,
          11,
          437,
          669,
          286,
          30,
          50508
        ]
      },
      {
        "avg_logprob": -0.2623786649842193,
        "compression_ratio": 1.5346534653465347,
        "end": 4134.3,
        "id": 1441,
        "no_speech_prob": 0.0005357746849767864,
        "seek": 412926,
        "start": 4132.14,
        "temperature": 0,
        "text": " I'm trying to watch some stuff this summer.",
        "tokens": [
          50508,
          286,
          478,
          1382,
          281,
          1159,
          512,
          1507,
          341,
          4266,
          13,
          50616
        ]
      },
      {
        "avg_logprob": -0.2623786649842193,
        "compression_ratio": 1.5346534653465347,
        "end": 4136.14,
        "id": 1442,
        "no_speech_prob": 0.0005357746849767864,
        "seek": 412926,
        "start": 4135.3,
        "temperature": 0,
        "text": " But anyway.",
        "tokens": [
          50666,
          583,
          4033,
          13,
          50708
        ]
      },
      {
        "avg_logprob": -0.2623786649842193,
        "compression_ratio": 1.5346534653465347,
        "end": 4139.900000000001,
        "id": 1443,
        "no_speech_prob": 0.0005357746849767864,
        "seek": 412926,
        "start": 4139.06,
        "temperature": 0,
        "text": " Oh, blockchain.",
        "tokens": [
          50854,
          876,
          11,
          17176,
          13,
          50896
        ]
      },
      {
        "avg_logprob": -0.2623786649842193,
        "compression_ratio": 1.5346534653465347,
        "end": 4140.860000000001,
        "id": 1444,
        "no_speech_prob": 0.0005357746849767864,
        "seek": 412926,
        "start": 4139.900000000001,
        "temperature": 0,
        "text": " I don't think you're gonna find me",
        "tokens": [
          50896,
          286,
          500,
          380,
          519,
          291,
          434,
          799,
          915,
          385,
          50944
        ]
      },
      {
        "avg_logprob": -0.2623786649842193,
        "compression_ratio": 1.5346534653465347,
        "end": 4142.46,
        "id": 1445,
        "no_speech_prob": 0.0005357746849767864,
        "seek": 412926,
        "start": 4140.860000000001,
        "temperature": 0,
        "text": " doing any blockchain tutorials.",
        "tokens": [
          50944,
          884,
          604,
          17176,
          17616,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.2623786649842193,
        "compression_ratio": 1.5346534653465347,
        "end": 4143.7,
        "id": 1446,
        "no_speech_prob": 0.0005357746849767864,
        "seek": 412926,
        "start": 4142.46,
        "temperature": 0,
        "text": " Sorry to disappoint.",
        "tokens": [
          51024,
          4919,
          281,
          8505,
          13,
          51086
        ]
      },
      {
        "avg_logprob": -0.2623786649842193,
        "compression_ratio": 1.5346534653465347,
        "end": 4148.26,
        "id": 1447,
        "no_speech_prob": 0.0005357746849767864,
        "seek": 412926,
        "start": 4146.3,
        "temperature": 0,
        "text": " Would you possibly do a time series prediction",
        "tokens": [
          51216,
          6068,
          291,
          6264,
          360,
          257,
          565,
          2638,
          17630,
          51314
        ]
      },
      {
        "avg_logprob": -0.2623786649842193,
        "compression_ratio": 1.5346534653465347,
        "end": 4149.780000000001,
        "id": 1448,
        "no_speech_prob": 0.0005357746849767864,
        "seek": 412926,
        "start": 4148.26,
        "temperature": 0,
        "text": " with LSTM or current neural network?",
        "tokens": [
          51314,
          365,
          441,
          6840,
          44,
          420,
          2190,
          18161,
          3209,
          30,
          51390
        ]
      },
      {
        "avg_logprob": -0.2623786649842193,
        "compression_ratio": 1.5346534653465347,
        "end": 4152.06,
        "id": 1449,
        "no_speech_prob": 0.0005357746849767864,
        "seek": 412926,
        "start": 4149.780000000001,
        "temperature": 0,
        "text": " See, an example of how I don't know everything.",
        "tokens": [
          51390,
          3008,
          11,
          364,
          1365,
          295,
          577,
          286,
          500,
          380,
          458,
          1203,
          13,
          51504
        ]
      },
      {
        "avg_logprob": -0.2623786649842193,
        "compression_ratio": 1.5346534653465347,
        "end": 4154.1,
        "id": 1450,
        "no_speech_prob": 0.0005357746849767864,
        "seek": 412926,
        "start": 4152.06,
        "temperature": 0,
        "text": " Yeah, but I gotta figure that out.",
        "tokens": [
          51504,
          865,
          11,
          457,
          286,
          3428,
          2573,
          300,
          484,
          13,
          51606
        ]
      },
      {
        "avg_logprob": -0.2623786649842193,
        "compression_ratio": 1.5346534653465347,
        "end": 4155.34,
        "id": 1451,
        "no_speech_prob": 0.0005357746849767864,
        "seek": 412926,
        "start": 4154.1,
        "temperature": 0,
        "text": " All right, thanks everybody.",
        "tokens": [
          51606,
          1057,
          558,
          11,
          3231,
          2201,
          13,
          51668
        ]
      },
      {
        "avg_logprob": -0.2623786649842193,
        "compression_ratio": 1.5346534653465347,
        "end": 4156.74,
        "id": 1452,
        "no_speech_prob": 0.0005357746849767864,
        "seek": 412926,
        "start": 4155.34,
        "temperature": 0,
        "text": " Thanks for watching.",
        "tokens": [
          51668,
          2561,
          337,
          1976,
          13,
          51738
        ]
      },
      {
        "avg_logprob": -0.2623786649842193,
        "compression_ratio": 1.5346534653465347,
        "end": 4158.9800000000005,
        "id": 1453,
        "no_speech_prob": 0.0005357746849767864,
        "seek": 412926,
        "start": 4156.74,
        "temperature": 0,
        "text": " I kiss, my fingers.",
        "tokens": [
          51738,
          286,
          7704,
          11,
          452,
          7350,
          13,
          51850
        ]
      },
      {
        "avg_logprob": -0.27285042129644826,
        "compression_ratio": 1.565217391304348,
        "end": 4160.58,
        "id": 1454,
        "no_speech_prob": 0.00008220127347158268,
        "seek": 415898,
        "start": 4159.74,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          50402,
          286,
          500,
          380,
          458,
          13,
          50444
        ]
      },
      {
        "avg_logprob": -0.27285042129644826,
        "compression_ratio": 1.565217391304348,
        "end": 4163.339999999999,
        "id": 1455,
        "no_speech_prob": 0.00008220127347158268,
        "seek": 415898,
        "start": 4160.58,
        "temperature": 0,
        "text": " It's a sort of expression that I've adopted",
        "tokens": [
          50444,
          467,
          311,
          257,
          1333,
          295,
          6114,
          300,
          286,
          600,
          12175,
          50582
        ]
      },
      {
        "avg_logprob": -0.27285042129644826,
        "compression_ratio": 1.565217391304348,
        "end": 4164.179999999999,
        "id": 1456,
        "no_speech_prob": 0.00008220127347158268,
        "seek": 415898,
        "start": 4163.339999999999,
        "temperature": 0,
        "text": " from somebody else.",
        "tokens": [
          50582,
          490,
          2618,
          1646,
          13,
          50624
        ]
      },
      {
        "avg_logprob": -0.27285042129644826,
        "compression_ratio": 1.565217391304348,
        "end": 4165.78,
        "id": 1457,
        "no_speech_prob": 0.00008220127347158268,
        "seek": 415898,
        "start": 4164.179999999999,
        "temperature": 0,
        "text": " If anybody knows what that reference is,",
        "tokens": [
          50624,
          759,
          4472,
          3255,
          437,
          300,
          6408,
          307,
          11,
          50704
        ]
      },
      {
        "avg_logprob": -0.27285042129644826,
        "compression_ratio": 1.565217391304348,
        "end": 4167.54,
        "id": 1458,
        "no_speech_prob": 0.00008220127347158268,
        "seek": 415898,
        "start": 4165.78,
        "temperature": 0,
        "text": " that's crazy to me.",
        "tokens": [
          50704,
          300,
          311,
          3219,
          281,
          385,
          13,
          50792
        ]
      },
      {
        "avg_logprob": -0.27285042129644826,
        "compression_ratio": 1.565217391304348,
        "end": 4173.0199999999995,
        "id": 1459,
        "no_speech_prob": 0.00008220127347158268,
        "seek": 415898,
        "start": 4171.219999999999,
        "temperature": 0,
        "text": " Did I like the Lost ending?",
        "tokens": [
          50976,
          2589,
          286,
          411,
          264,
          23422,
          8121,
          30,
          51066
        ]
      },
      {
        "avg_logprob": -0.27285042129644826,
        "compression_ratio": 1.565217391304348,
        "end": 4177.099999999999,
        "id": 1460,
        "no_speech_prob": 0.00008220127347158268,
        "seek": 415898,
        "start": 4175.78,
        "temperature": 0,
        "text": " Not so much to be honest.",
        "tokens": [
          51204,
          1726,
          370,
          709,
          281,
          312,
          3245,
          13,
          51270
        ]
      },
      {
        "avg_logprob": -0.27285042129644826,
        "compression_ratio": 1.565217391304348,
        "end": 4179.9,
        "id": 1461,
        "no_speech_prob": 0.00008220127347158268,
        "seek": 415898,
        "start": 4177.099999999999,
        "temperature": 0,
        "text": " But when I think back about that show,",
        "tokens": [
          51270,
          583,
          562,
          286,
          519,
          646,
          466,
          300,
          855,
          11,
          51410
        ]
      },
      {
        "avg_logprob": -0.27285042129644826,
        "compression_ratio": 1.565217391304348,
        "end": 4183.299999999999,
        "id": 1462,
        "no_speech_prob": 0.00008220127347158268,
        "seek": 415898,
        "start": 4179.9,
        "temperature": 0,
        "text": " it fills me with such like amazing memories.",
        "tokens": [
          51410,
          309,
          22498,
          385,
          365,
          1270,
          411,
          2243,
          8495,
          13,
          51580
        ]
      },
      {
        "avg_logprob": -0.27285042129644826,
        "compression_ratio": 1.565217391304348,
        "end": 4185.299999999999,
        "id": 1463,
        "no_speech_prob": 0.00008220127347158268,
        "seek": 415898,
        "start": 4183.299999999999,
        "temperature": 0,
        "text": " I was really interested in it, listened to the podcast.",
        "tokens": [
          51580,
          286,
          390,
          534,
          3102,
          294,
          309,
          11,
          13207,
          281,
          264,
          7367,
          13,
          51680
        ]
      },
      {
        "avg_logprob": -0.27285042129644826,
        "compression_ratio": 1.565217391304348,
        "end": 4188.099999999999,
        "id": 1464,
        "no_speech_prob": 0.00008220127347158268,
        "seek": 415898,
        "start": 4185.299999999999,
        "temperature": 0,
        "text": " So the ending, I forgive you Lost for that ending.",
        "tokens": [
          51680,
          407,
          264,
          8121,
          11,
          286,
          10718,
          291,
          23422,
          337,
          300,
          8121,
          13,
          51820
        ]
      },
      {
        "avg_logprob": -0.27285042129644826,
        "compression_ratio": 1.565217391304348,
        "end": 4188.94,
        "id": 1465,
        "no_speech_prob": 0.00008220127347158268,
        "seek": 415898,
        "start": 4188.099999999999,
        "temperature": 0,
        "text": " It was fine.",
        "tokens": [
          51820,
          467,
          390,
          2489,
          13,
          51862
        ]
      },
      {
        "avg_logprob": -0.24439701112378545,
        "compression_ratio": 1.5551470588235294,
        "end": 4190.74,
        "id": 1466,
        "no_speech_prob": 0.0000018738583094091155,
        "seek": 418894,
        "start": 4189.74,
        "temperature": 0,
        "text": " You did your best.",
        "tokens": [
          50404,
          509,
          630,
          428,
          1151,
          13,
          50454
        ]
      },
      {
        "avg_logprob": -0.24439701112378545,
        "compression_ratio": 1.5551470588235294,
        "end": 4193.179999999999,
        "id": 1467,
        "no_speech_prob": 0.0000018738583094091155,
        "seek": 418894,
        "start": 4190.74,
        "temperature": 0,
        "text": " I couldn't have done any better, that's for sure.",
        "tokens": [
          50454,
          286,
          2809,
          380,
          362,
          1096,
          604,
          1101,
          11,
          300,
          311,
          337,
          988,
          13,
          50576
        ]
      },
      {
        "avg_logprob": -0.24439701112378545,
        "compression_ratio": 1.5551470588235294,
        "end": 4196.46,
        "id": 1468,
        "no_speech_prob": 0.0000018738583094091155,
        "seek": 418894,
        "start": 4194.98,
        "temperature": 0,
        "text": " That was not my favorite season of Lost.",
        "tokens": [
          50666,
          663,
          390,
          406,
          452,
          2954,
          3196,
          295,
          23422,
          13,
          50740
        ]
      },
      {
        "avg_logprob": -0.24439701112378545,
        "compression_ratio": 1.5551470588235294,
        "end": 4198.82,
        "id": 1469,
        "no_speech_prob": 0.0000018738583094091155,
        "seek": 418894,
        "start": 4196.46,
        "temperature": 0,
        "text": " Sentiment analysis, I definitely wanna do.",
        "tokens": [
          50740,
          23652,
          2328,
          5215,
          11,
          286,
          2138,
          1948,
          360,
          13,
          50858
        ]
      },
      {
        "avg_logprob": -0.24439701112378545,
        "compression_ratio": 1.5551470588235294,
        "end": 4201.259999999999,
        "id": 1470,
        "no_speech_prob": 0.0000018738583094091155,
        "seek": 418894,
        "start": 4200.379999999999,
        "temperature": 0,
        "text": " Yeah, all right.",
        "tokens": [
          50936,
          865,
          11,
          439,
          558,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.24439701112378545,
        "compression_ratio": 1.5551470588235294,
        "end": 4204.379999999999,
        "id": 1471,
        "no_speech_prob": 0.0000018738583094091155,
        "seek": 418894,
        "start": 4201.259999999999,
        "temperature": 0,
        "text": " So there's gonna be a lot of edited tutorials coming out.",
        "tokens": [
          50980,
          407,
          456,
          311,
          799,
          312,
          257,
          688,
          295,
          23016,
          17616,
          1348,
          484,
          13,
          51136
        ]
      },
      {
        "avg_logprob": -0.24439701112378545,
        "compression_ratio": 1.5551470588235294,
        "end": 4207.339999999999,
        "id": 1472,
        "no_speech_prob": 0.0000018738583094091155,
        "seek": 418894,
        "start": 4204.379999999999,
        "temperature": 0,
        "text": " Just to recap, there's I think five or six tutorials",
        "tokens": [
          51136,
          1449,
          281,
          20928,
          11,
          456,
          311,
          286,
          519,
          1732,
          420,
          2309,
          17616,
          51284
        ]
      },
      {
        "avg_logprob": -0.24439701112378545,
        "compression_ratio": 1.5551470588235294,
        "end": 4209.299999999999,
        "id": 1473,
        "no_speech_prob": 0.0000018738583094091155,
        "seek": 418894,
        "start": 4207.339999999999,
        "temperature": 0,
        "text": " on promises, async and await.",
        "tokens": [
          51284,
          322,
          16403,
          11,
          382,
          34015,
          293,
          19670,
          13,
          51382
        ]
      },
      {
        "avg_logprob": -0.24439701112378545,
        "compression_ratio": 1.5551470588235294,
        "end": 4212.139999999999,
        "id": 1474,
        "no_speech_prob": 0.0000018738583094091155,
        "seek": 418894,
        "start": 4209.299999999999,
        "temperature": 0,
        "text": " And now this coding challenge of linear regression",
        "tokens": [
          51382,
          400,
          586,
          341,
          17720,
          3430,
          295,
          8213,
          24590,
          51524
        ]
      },
      {
        "avg_logprob": -0.24439701112378545,
        "compression_ratio": 1.5551470588235294,
        "end": 4213.179999999999,
        "id": 1475,
        "no_speech_prob": 0.0000018738583094091155,
        "seek": 418894,
        "start": 4212.139999999999,
        "temperature": 0,
        "text": " with gradient descent.",
        "tokens": [
          51524,
          365,
          16235,
          23475,
          13,
          51576
        ]
      },
      {
        "avg_logprob": -0.24439701112378545,
        "compression_ratio": 1.5551470588235294,
        "end": 4215.66,
        "id": 1476,
        "no_speech_prob": 0.0000018738583094091155,
        "seek": 418894,
        "start": 4213.179999999999,
        "temperature": 0,
        "text": " I will see you all next week sometime.",
        "tokens": [
          51576,
          286,
          486,
          536,
          291,
          439,
          958,
          1243,
          15053,
          13,
          51700
        ]
      },
      {
        "avg_logprob": -0.20668724323141163,
        "compression_ratio": 1.7601476014760147,
        "end": 4218.98,
        "id": 1477,
        "no_speech_prob": 0.002251822967082262,
        "seek": 421566,
        "start": 4215.7,
        "temperature": 0,
        "text": " Stay tuned to...",
        "tokens": [
          50366,
          8691,
          10870,
          281,
          485,
          50530
        ]
      },
      {
        "avg_logprob": -0.20668724323141163,
        "compression_ratio": 1.7601476014760147,
        "end": 4220.62,
        "id": 1478,
        "no_speech_prob": 0.002251822967082262,
        "seek": 421566,
        "start": 4218.98,
        "temperature": 0,
        "text": " Oh, hi Coding Garden.",
        "tokens": [
          50530,
          876,
          11,
          4879,
          383,
          8616,
          19429,
          13,
          50612
        ]
      },
      {
        "avg_logprob": -0.20668724323141163,
        "compression_ratio": 1.7601476014760147,
        "end": 4222.62,
        "id": 1479,
        "no_speech_prob": 0.002251822967082262,
        "seek": 421566,
        "start": 4220.62,
        "temperature": 0,
        "text": " Coding Garden was live streaming at the same time",
        "tokens": [
          50612,
          383,
          8616,
          19429,
          390,
          1621,
          11791,
          412,
          264,
          912,
          565,
          50712
        ]
      },
      {
        "avg_logprob": -0.20668724323141163,
        "compression_ratio": 1.7601476014760147,
        "end": 4223.94,
        "id": 1480,
        "no_speech_prob": 0.002251822967082262,
        "seek": 421566,
        "start": 4222.62,
        "temperature": 0,
        "text": " as me earlier today.",
        "tokens": [
          50712,
          382,
          385,
          3071,
          965,
          13,
          50778
        ]
      },
      {
        "avg_logprob": -0.20668724323141163,
        "compression_ratio": 1.7601476014760147,
        "end": 4228.58,
        "id": 1481,
        "no_speech_prob": 0.002251822967082262,
        "seek": 421566,
        "start": 4223.94,
        "temperature": 0,
        "text": " Coding Garden seems to live stream like 12 hours a day.",
        "tokens": [
          50778,
          383,
          8616,
          19429,
          2544,
          281,
          1621,
          4309,
          411,
          2272,
          2496,
          257,
          786,
          13,
          51010
        ]
      },
      {
        "avg_logprob": -0.20668724323141163,
        "compression_ratio": 1.7601476014760147,
        "end": 4229.58,
        "id": 1482,
        "no_speech_prob": 0.002251822967082262,
        "seek": 421566,
        "start": 4228.58,
        "temperature": 0,
        "text": " I don't know how that's possible.",
        "tokens": [
          51010,
          286,
          500,
          380,
          458,
          577,
          300,
          311,
          1944,
          13,
          51060
        ]
      },
      {
        "avg_logprob": -0.20668724323141163,
        "compression_ratio": 1.7601476014760147,
        "end": 4230.5,
        "id": 1483,
        "no_speech_prob": 0.002251822967082262,
        "seek": 421566,
        "start": 4229.58,
        "temperature": 0,
        "text": " It's probably not that much,",
        "tokens": [
          51060,
          467,
          311,
          1391,
          406,
          300,
          709,
          11,
          51106
        ]
      },
      {
        "avg_logprob": -0.20668724323141163,
        "compression_ratio": 1.7601476014760147,
        "end": 4232.3,
        "id": 1484,
        "no_speech_prob": 0.002251822967082262,
        "seek": 421566,
        "start": 4230.5,
        "temperature": 0,
        "text": " but there's a lot of Coding Garden live streams.",
        "tokens": [
          51106,
          457,
          456,
          311,
          257,
          688,
          295,
          383,
          8616,
          19429,
          1621,
          15842,
          13,
          51196
        ]
      },
      {
        "avg_logprob": -0.20668724323141163,
        "compression_ratio": 1.7601476014760147,
        "end": 4233.74,
        "id": 1485,
        "no_speech_prob": 0.002251822967082262,
        "seek": 421566,
        "start": 4232.3,
        "temperature": 0,
        "text": " So everybody check out Coding Garden,",
        "tokens": [
          51196,
          407,
          2201,
          1520,
          484,
          383,
          8616,
          19429,
          11,
          51268
        ]
      },
      {
        "avg_logprob": -0.20668724323141163,
        "compression_ratio": 1.7601476014760147,
        "end": 4237.139999999999,
        "id": 1486,
        "no_speech_prob": 0.002251822967082262,
        "seek": 421566,
        "start": 4233.74,
        "temperature": 0,
        "text": " a sponsor of the Coding Train.",
        "tokens": [
          51268,
          257,
          16198,
          295,
          264,
          383,
          8616,
          28029,
          13,
          51438
        ]
      },
      {
        "avg_logprob": -0.20668724323141163,
        "compression_ratio": 1.7601476014760147,
        "end": 4238.26,
        "id": 1487,
        "no_speech_prob": 0.002251822967082262,
        "seek": 421566,
        "start": 4237.139999999999,
        "temperature": 0,
        "text": " Oh, I can't put on my music",
        "tokens": [
          51438,
          876,
          11,
          286,
          393,
          380,
          829,
          322,
          452,
          1318,
          51494
        ]
      },
      {
        "avg_logprob": -0.20668724323141163,
        "compression_ratio": 1.7601476014760147,
        "end": 4240.86,
        "id": 1488,
        "no_speech_prob": 0.002251822967082262,
        "seek": 421566,
        "start": 4238.26,
        "temperature": 0,
        "text": " and do my goofy sponsor advertisement again.",
        "tokens": [
          51494,
          293,
          360,
          452,
          42995,
          16198,
          31370,
          797,
          13,
          51624
        ]
      },
      {
        "avg_logprob": -0.20668724323141163,
        "compression_ratio": 1.7601476014760147,
        "end": 4243.7,
        "id": 1489,
        "no_speech_prob": 0.002251822967082262,
        "seek": 421566,
        "start": 4240.86,
        "temperature": 0,
        "text": " See everybody, I'm gonna play out the outro now.",
        "tokens": [
          51624,
          3008,
          2201,
          11,
          286,
          478,
          799,
          862,
          484,
          264,
          13170,
          586,
          13,
          51766
        ]
      },
      {
        "avg_logprob": -0.20668724323141163,
        "compression_ratio": 1.7601476014760147,
        "end": 4244.54,
        "id": 1490,
        "no_speech_prob": 0.002251822967082262,
        "seek": 421566,
        "start": 4243.7,
        "temperature": 0,
        "text": " Why not?",
        "tokens": [
          51766,
          1545,
          406,
          30,
          51808
        ]
      },
      {
        "avg_logprob": -0.38990428305079794,
        "compression_ratio": 1.6127659574468085,
        "end": 4245.62,
        "id": 1491,
        "no_speech_prob": 0.12762081623077393,
        "seek": 424454,
        "start": 4244.58,
        "temperature": 0,
        "text": " It's the end of the day.",
        "tokens": [
          50366,
          467,
          311,
          264,
          917,
          295,
          264,
          786,
          13,
          50418
        ]
      },
      {
        "avg_logprob": -0.38990428305079794,
        "compression_ratio": 1.6127659574468085,
        "end": 4246.62,
        "id": 1492,
        "no_speech_prob": 0.12762081623077393,
        "seek": 424454,
        "start": 4245.62,
        "temperature": 0,
        "text": " See you all later.",
        "tokens": [
          50418,
          3008,
          291,
          439,
          1780,
          13,
          50468
        ]
      },
      {
        "avg_logprob": -0.38990428305079794,
        "compression_ratio": 1.6127659574468085,
        "end": 4251.94,
        "id": 1493,
        "no_speech_prob": 0.12762081623077393,
        "seek": 424454,
        "start": 4248.46,
        "temperature": 0,
        "text": " Let's find something we wanna make, some crazy idea.",
        "tokens": [
          50560,
          220,
          8373,
          311,
          915,
          746,
          321,
          1948,
          652,
          11,
          512,
          3219,
          1558,
          13,
          50734
        ]
      },
      {
        "avg_logprob": -0.38990428305079794,
        "compression_ratio": 1.6127659574468085,
        "end": 4254.94,
        "id": 1494,
        "no_speech_prob": 0.12762081623077393,
        "seek": 424454,
        "start": 4253.38,
        "temperature": 0,
        "text": " By the way, my microphone is still going.",
        "tokens": [
          50806,
          3146,
          264,
          636,
          11,
          452,
          10952,
          307,
          920,
          516,
          13,
          50884
        ]
      },
      {
        "avg_logprob": -0.38990428305079794,
        "compression_ratio": 1.6127659574468085,
        "end": 4256.34,
        "id": 1495,
        "no_speech_prob": 0.12762081623077393,
        "seek": 424454,
        "start": 4254.94,
        "temperature": 0,
        "text": " I can't seem to figure out how to use it.",
        "tokens": [
          50884,
          286,
          393,
          380,
          1643,
          281,
          2573,
          484,
          577,
          281,
          764,
          309,
          13,
          50954
        ]
      },
      {
        "avg_logprob": -0.38990428305079794,
        "compression_ratio": 1.6127659574468085,
        "end": 4259.38,
        "id": 1496,
        "no_speech_prob": 0.12762081623077393,
        "seek": 424454,
        "start": 4256.34,
        "temperature": 0,
        "text": " We'll try to understand now as we ride along again.",
        "tokens": [
          50954,
          492,
          603,
          853,
          281,
          1223,
          586,
          382,
          321,
          5077,
          2051,
          797,
          13,
          51106
        ]
      },
      {
        "avg_logprob": -0.38990428305079794,
        "compression_ratio": 1.6127659574468085,
        "end": 4264.38,
        "id": 1497,
        "no_speech_prob": 0.12762081623077393,
        "seek": 424454,
        "start": 4259.38,
        "temperature": 0,
        "text": " Now hop on the Coding Train, Coding Train, Coding Train.",
        "tokens": [
          51106,
          823,
          3818,
          322,
          264,
          383,
          8616,
          28029,
          11,
          383,
          8616,
          28029,
          11,
          383,
          8616,
          28029,
          13,
          51356
        ]
      },
      {
        "avg_logprob": -0.38990428305079794,
        "compression_ratio": 1.6127659574468085,
        "end": 4269.9,
        "id": 1498,
        "no_speech_prob": 0.12762081623077393,
        "seek": 424454,
        "start": 4266.1,
        "temperature": 0,
        "text": " Come along and join us as we light it up in gold.",
        "tokens": [
          51442,
          2492,
          2051,
          293,
          3917,
          505,
          382,
          321,
          1442,
          309,
          493,
          294,
          3821,
          13,
          51632
        ]
      },
      {
        "avg_logprob": -0.38990428305079794,
        "compression_ratio": 1.6127659574468085,
        "end": 4273.38,
        "id": 1499,
        "no_speech_prob": 0.12762081623077393,
        "seek": 424454,
        "start": 4269.9,
        "temperature": 0,
        "text": " Using only our imagination as the road.",
        "tokens": [
          51632,
          11142,
          787,
          527,
          12938,
          382,
          264,
          3060,
          13,
          51806
        ]
      },
      {
        "avg_logprob": -0.3715791260169831,
        "compression_ratio": 1.8435114503816794,
        "end": 4274.900000000001,
        "id": 1500,
        "no_speech_prob": 0.09132156521081924,
        "seek": 427338,
        "start": 4273.42,
        "temperature": 0,
        "text": " Whenever you're conceiving,",
        "tokens": [
          50366,
          14159,
          291,
          434,
          10413,
          2123,
          11,
          50440
        ]
      },
      {
        "avg_logprob": -0.3715791260169831,
        "compression_ratio": 1.8435114503816794,
        "end": 4276.74,
        "id": 1501,
        "no_speech_prob": 0.09132156521081924,
        "seek": 427338,
        "start": 4274.900000000001,
        "temperature": 0,
        "text": " you'll start seeing what you're believing.",
        "tokens": [
          50440,
          291,
          603,
          722,
          2577,
          437,
          291,
          434,
          16594,
          13,
          50532
        ]
      },
      {
        "avg_logprob": -0.3715791260169831,
        "compression_ratio": 1.8435114503816794,
        "end": 4281.74,
        "id": 1502,
        "no_speech_prob": 0.09132156521081924,
        "seek": 427338,
        "start": 4276.74,
        "temperature": 0,
        "text": " Just hop on the Coding Train, Coding Train, Coding Train.",
        "tokens": [
          50532,
          1449,
          3818,
          322,
          264,
          383,
          8616,
          28029,
          11,
          383,
          8616,
          28029,
          11,
          383,
          8616,
          28029,
          13,
          50782
        ]
      },
      {
        "avg_logprob": -0.3715791260169831,
        "compression_ratio": 1.8435114503816794,
        "end": 4285.06,
        "id": 1503,
        "no_speech_prob": 0.09132156521081924,
        "seek": 427338,
        "start": 4283.26,
        "temperature": 0,
        "text": " Pick you all up at the station.",
        "tokens": [
          50858,
          14129,
          291,
          439,
          493,
          412,
          264,
          5214,
          13,
          50948
        ]
      },
      {
        "avg_logprob": -0.3715791260169831,
        "compression_ratio": 1.8435114503816794,
        "end": 4286.78,
        "id": 1504,
        "no_speech_prob": 0.09132156521081924,
        "seek": 427338,
        "start": 4285.06,
        "temperature": 0,
        "text": " We'll make things of our own creation.",
        "tokens": [
          50948,
          492,
          603,
          652,
          721,
          295,
          527,
          1065,
          8016,
          13,
          51034
        ]
      },
      {
        "avg_logprob": -0.3715791260169831,
        "compression_ratio": 1.8435114503816794,
        "end": 4287.62,
        "id": 1505,
        "no_speech_prob": 0.09132156521081924,
        "seek": 427338,
        "start": 4286.78,
        "temperature": 0,
        "text": " Fireworks.",
        "tokens": [
          51034,
          7652,
          18357,
          13,
          51076
        ]
      },
      {
        "avg_logprob": -0.3715791260169831,
        "compression_ratio": 1.8435114503816794,
        "end": 4288.46,
        "id": 1506,
        "no_speech_prob": 0.09132156521081924,
        "seek": 427338,
        "start": 4287.62,
        "temperature": 0,
        "text": " Medi-balls.",
        "tokens": [
          51076,
          3982,
          72,
          12,
          19194,
          13,
          51118
        ]
      },
      {
        "avg_logprob": -0.3715791260169831,
        "compression_ratio": 1.8435114503816794,
        "end": 4289.3,
        "id": 1507,
        "no_speech_prob": 0.09132156521081924,
        "seek": 427338,
        "start": 4288.46,
        "temperature": 0,
        "text": " Super ships.",
        "tokens": [
          51118,
          4548,
          11434,
          13,
          51160
        ]
      },
      {
        "avg_logprob": -0.3715791260169831,
        "compression_ratio": 1.8435114503816794,
        "end": 4290.5,
        "id": 1508,
        "no_speech_prob": 0.09132156521081924,
        "seek": 427338,
        "start": 4289.3,
        "temperature": 0,
        "text": " We can jump to anything in the outer space.",
        "tokens": [
          51160,
          492,
          393,
          3012,
          281,
          1340,
          294,
          264,
          10847,
          1901,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.3715791260169831,
        "compression_ratio": 1.8435114503816794,
        "end": 4292.54,
        "id": 1509,
        "no_speech_prob": 0.09132156521081924,
        "seek": 427338,
        "start": 4290.5,
        "temperature": 0,
        "text": " We can generate sounds or trees or mazes.",
        "tokens": [
          51220,
          492,
          393,
          8460,
          3263,
          420,
          5852,
          420,
          463,
          12214,
          13,
          51322
        ]
      },
      {
        "avg_logprob": -0.3715791260169831,
        "compression_ratio": 1.8435114503816794,
        "end": 4294.38,
        "id": 1510,
        "no_speech_prob": 0.09132156521081924,
        "seek": 427338,
        "start": 4292.54,
        "temperature": 0,
        "text": " Make a butterfly or reflect our faces.",
        "tokens": [
          51322,
          4387,
          257,
          22140,
          420,
          5031,
          527,
          8475,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.3715791260169831,
        "compression_ratio": 1.8435114503816794,
        "end": 4295.22,
        "id": 1511,
        "no_speech_prob": 0.09132156521081924,
        "seek": 427338,
        "start": 4294.38,
        "temperature": 0,
        "text": " A retro game.",
        "tokens": [
          51414,
          316,
          18820,
          1216,
          13,
          51456
        ]
      },
      {
        "avg_logprob": -0.3715791260169831,
        "compression_ratio": 1.8435114503816794,
        "end": 4296.14,
        "id": 1512,
        "no_speech_prob": 0.09132156521081924,
        "seek": 427338,
        "start": 4295.22,
        "temperature": 0,
        "text": " Or a Twitter bot.",
        "tokens": [
          51456,
          1610,
          257,
          5794,
          10592,
          13,
          51502
        ]
      },
      {
        "avg_logprob": -0.3715791260169831,
        "compression_ratio": 1.8435114503816794,
        "end": 4297.54,
        "id": 1513,
        "no_speech_prob": 0.09132156521081924,
        "seek": 427338,
        "start": 4296.14,
        "temperature": 0,
        "text": " And never forget that there's a.",
        "tokens": [
          51502,
          400,
          1128,
          2870,
          300,
          456,
          311,
          257,
          13,
          51572
        ]
      },
      {
        "avg_logprob": -0.3715791260169831,
        "compression_ratio": 1.8435114503816794,
        "end": 4302.54,
        "id": 1514,
        "no_speech_prob": 0.09132156521081924,
        "seek": 427338,
        "start": 4297.54,
        "temperature": 0,
        "text": " Just hop on the Coding Train, Coding Train, Coding Train.",
        "tokens": [
          51572,
          1449,
          3818,
          322,
          264,
          383,
          8616,
          28029,
          11,
          383,
          8616,
          28029,
          11,
          383,
          8616,
          28029,
          13,
          51822
        ]
      },
      {
        "avg_logprob": -0.8252620697021484,
        "compression_ratio": 0.6190476190476191,
        "end": 4304.58,
        "id": 1515,
        "no_speech_prob": 0.9083268046379089,
        "seek": 430338,
        "start": 4303.38,
        "temperature": 0,
        "text": " Coding Train.",
        "tokens": [
          50366,
          383,
          8616,
          28029,
          13,
          50424
        ]
      }
    ],
    "transcription": " My event has started, which means that it is me, Dan Shiffman, coming to you again for the second time today, for the third time in two days. This is probably really not so advisable, there's a lot of reasons why I shouldn't be here, but I am here. And I am going to, I have about one hour, so I'm really going to jump right in. I have, I think I might actually even call this, dare I say, a coding challenge. The thing about this, it's okay. I don't, this is not the important thing to talk about. This is the topic for today. Linear regression using TensorFlow.js. Now before you all start going and running away, which would be completely understandable, I'm really doing this for a couple of reasons. Number one is I have started a series of TensorFlow.js tutorials, just looking at some of the basic features of the API. And I want to at least get into an example where we're actually using this stuff for some purpose. Now, what kind of, you know, this is really foundational knowledge, it's kind of like a classic example of like the beginning stages of machine learning. I have actually made some videos about this already. In notably, notably, this linear regression with gradient descent video that I made just with plain JavaScript. I also made this ill-advised video about the mathematics of, oh, underlying audio is not working. All right, well, hold on, I won't worry about that. Let me just check the chat here. Okay. This video about the sort of mathematics of gradient descent. So these would be two pieces of background. You're watching this live, so you probably don't want to stop and go watch those, but you could. Okay. And so I think this is going to be helpful in terms of, first of all, thank you. I'm going to be saying all this stuff again in a second, because I'm going to, but just bear with me, please. Thank you. You're very kind. Thank you to Ol Podkar on Twitter, who posted this code for an interactive simulation of linear regression with TensorFlow and P5.js. This gave me the idea. You can read in this thread. Oh, great work. I wonder if a video tutorial redoing my linear regression example in a similar fashion would be useful. And then the reply was, thanks. Yes. And some other people replied and thought this would be useful as well. So that's what I'm going to do. This is foundational knowledge. So let me see. Where, oh, where does this appear? Where, oh, where? Under here, this is all my neural networks and machine learning playlists. We're looking for this one, session six. So this is what I've done so far. And the thing that I really want to get to, which is going to come next week, is the layers API. And this is where I'm going to actually begin building some neural network examples and remaking some previous things I've done on this channel without TensorFlow.js. But I think before we get there, I want to just look at some other features of the TensorFlow.js library in the context of linear regression. So that's the plan for today. OK. So I think I just want to get going. So I need to reference all these things. I guess I will just tab my way through them. I'm going to move this here. And I haven't implemented this. I scanned over this GitHub user's code. So I do have that a little bit in the back of my head, but I have not tried to implement this myself. I've got the Slack channel going here for patrons and YouTube sponsors. Thank you. So you'll be keeping me in check. And I've got until about 5.30 PM. I'm just trying to decide, does this sit as 6.5 linear regression with gradient descent? Or is this a coding challenge? So I'm seeing in the chat that a chat user says, if you want to do interactive stuff with TF.js, you should check out TF next frame. OK, hold on. I was not aware of this. So let me have a look at next frame. Returns a promise that resolves when a request animation frame has completed. Oh, fascinating. Oh, interesting. So that's really interesting. I think I'm going to do this is right. So what I'm doing is so incredibly, well, it's comparably simple. And I can probably do it with pulling the, yeah, let's see how this goes. Let me try to build it. And thank you for this note. I'm going to try to do it probably in a less correct way and just get it kind of working. Let the threads kind of like, the amount of computation that I'm going to do for linear regression is so simple that even if it locks up for a second, it's going to be fine to let the animation keep going. But this is absolutely something that I will need to pay attention to more later, for sure. OK. Can anyone help me with the pronunciation of this name? Calstube Old Pod Car? Calstube Old Pod Car? Any chance that that was kind of close? OK. We will be getting going in just a second. I'm waiting for the live chat to maybe catch up to me and somebody might help me pronounce this name correctly. All right. Close enough, I think. Well, that's what it's going to have to be. Where's my marker? Here we go. And I'm going to get started. I wish I could just call and pronounce it. That's a good point. Let's move on. There's probably some fancy technological way we can make that happen. Everybody should stretch. Stretch. This really, this extra live stream towards the end of the day, trying to do something with machine learning and TensorFlow.js, this really needs some space melon. But I don't have any space melon with me, so I'm just going to have to try my best. Kustub. Thank you. Kustub. Kustub Old Pod Car. OK. Thank you. Calstube Old Pod Car. OK. Now people are just trolling me in the chat by saying it's pronounced with the actual spelling of the name. I will do my best. Hello. You are here watching another coding challenge. And this coding challenge, maybe this should just fit and be in one of my tutorial videos. But I'm going to make it a coding challenge because I'm going to attempt to do it in one video. And what I'm doing is recreating something that I've done before in some of my machine learning tutorials. And it was suggested here. I don't know if it was suggested exactly, but a Twitter user, Calstube Old Pod Car, apologies if I'm pronouncing the name incorrectly, created this interactive simulation of linear regression using TensorFlow.js. And so this is very similar to something that I've done previously. I have this video, Linear Regression with Gradient Descent, where I just did this with plain JavaScript. And then you could also look at this other video, which I go through the mathematics of gradient descent a little bit. But here's the thing. Going through the mathematics, making this video where I implement the mathematics in JavaScript while useful, and perhaps background for this video, one of the exciting things about doing this with TensorFlow.js is TensorFlow.js has a nice API for optimizing loss functions with the gradient descent algorithm built into it. So I could just do things. So let's make a list. I got to come back here, but let's make a list. Oh, hold on. Hold on. Hold on. OK. The things that I'm going to need, right? I need to have. OK. So what's going on here? What is linear regression, first of all? And of course, you can compute the eq- Let me do that again. I was going to do this as a coding challenge with no editing, but so much for that. All right. So first of all, what is linear regression anyway? So let's say we have a space. And I drew this as like a canvas, but really I should be talking just about a generic kind of two-dimensional Cartesian plane. And in that plane, there are a lot of points. And I don't like the way I just drew that. In that plane, there are a bunch of points. The idea of linear regression is to figure out, can we fit? Oh, this is a time for another colored marker. Can we fit a line into this two-dimensional space that approximates all of these points as best we can? And I can visually just kind of make myself do this like this. So I can eyeball it and say, this line kind of gets close. What we're trying to do is minimize all of these. This is the most beautiful diagram I've ever made. All of these distances of all of the points to the line. The idea here then is that we can make some predictions. If this data, if this x-axis represents height, we might predict on the y-axis weight. You can think of kinds of data sets, simple 2D data sets, where there's a linear relationship between one field of data and another field of data. So if we pick a new height, we can kind of make a guess approximately what that weight is going to be. That's the idea of linear regression. It's incredibly simple. A lot of data isn't two-dimensional. A lot of data doesn't fit a line. Maybe a curve fits it better. And this is more complex scenarios will come as we move forward and make more scenarios with complex polynomial equations, or neural network-based learning, and other types of machine learning algorithms. But this is a good place for us to start. So what do we need? We need a data set. So we need a set of x's and y's. This is the data set. We need x's and y's. And I'm going to create that data set through interactive clicking. Interactive clicking is the way I'm going to create that data set with the mouse. I need to have something called a loss function. The loss function is a way of computing the error. And there are a bunch of different loss functions. And we'll see these as I use TensorFlow.js in more tutorials. I can select different kinds of loss functions for different scenarios. But in this scenario, I'm going to use a simple basic one, which I believe is called root mean squared error. Did I say that correctly? Is that the right name of it? But the idea is that I want to look at all of those distances. And I want to minimize them. So that number, if I find all these distances, the difference, and by the way, I totally, oh, I botched this. Time out. Vertical distance. It's even in the chat. So the good news is you can barely see it. I'm looking over here on my monitor. And I can't see it. You can barely see it. But I really botched what I was drawing there. So let me fix that. I don't think I'm going to go back and redo this video. I think I'm just going to get a different pen color, since you can't see it anyway, and just fix that. So I'm going to go back. So a little editing point here. OK. I'm back, because I started talking about the loss function. I realized I really didn't draw. I'm not actually looking for the distance from the point to that line, which would be perpendicular. I'm looking for this vertical distance, which is, so this is what I'm trying to minimize. I'm trying to minimize and get a line that has, and this, that is the least, the sum of all these distances is the smallest number, minimizing the loss. So I have a loss function. I need that. I also need, in TensorFlow.js, something called an optimizer. And the optimizer is the thing that allows me to minimize the loss function. And in order to do that, I also need to have a learning rate. So these are all, I actually missed something very important here, but these are all the pieces. I need the data. I need to define a loss function. I need to define an optimizer. I say, hey, optimizer, minimize the loss function with this learning rate. So keep tweaking the parameters, tweaking the parameters. So that's the thing I forgot. What are those parameters? Well, the formula for a line is y equals mx plus b. m is often referred to as the slope, b as the offset. What's the name for that? You'll tell me in the chat. What's the name of that formula for a line? See, this is why I shouldn't do these live streams at the end of the day. I was so with it when I was talking about promises this morning, wasn't I? y-intercept. There we go. y-intercept. OK. I'm back because I looked it up. m is the slope, and b referred to as the y-intercept. Kind of like bias, by the way, if you've watched some of my other neural network tutorials. This is like the thing we're doing with all the neurons. Oh, it's all so connected. But we're just living in this very simple place. So I need these parameters. I need these variables because that's what's going to allow me to create the predictions that are on the line to compare with the actual points and compute the loss, minimize it, tweaking these values. So tweak these values, minimizing the loss. This is what we're doing. And I've done this before in great detail. This is going to be in less detail because TensorFlow.js is going to do a lot of this for us. The thing that's a little extra complicated is we can't just work with arrays of numbers and variables in the way that we're used to in JavaScript. And so this is what brings me to, if you haven't looked at these particular videos that I've made already, what's a TensorFlow tensor? What's a variable? What's an operation? How's the memory management stuff? This is stuff we're going to have to lean on while I build this example. And this should be, by the way, an actual practical example of where I need a tf variable. So I kind of, in this video, explained what a tf variable is, but just kind of moved on and didn't use it for anything. So hopefully, this will show us that. How about we write some code now? I'm pausing for a second, taking a look at the chat. The root shouldn't be there. I don't know what that means. Offset is fine. Y intersect or intercept. What's the root? Oh, so what's the, let me look this up on the, what's the wire mess? Oh, in the back of my, yeah, let me fix that. What's the, why did I say root? Let me look at loss square. Oh, because I don't have to square root it. Mean squared. Yeah, so I'm going to just use mean squared error. Thank you. Thank you. Simon in the chat, in the Slack group, makes a good point. So maybe I should correct that really quickly. I am not going to be doing partial derivatives again. Definitely not, asked Kenneth. So maybe I should go back and define that better. Root mean squared is, oh, OK. So actually, I magically appeared over here for a second, because instead of, I did make a little mistake here. I mean, root mean squared is a perfectly legitimate loss function. But most linear regression with gradient descent examples will not bother with the root. And the root refers to square root. We just want the mean squared error, which means if I say that this value is y, and this value is the guess, the error is guess minus y and squared. And if I do that for all of these, that's the mean. I average them. It's the mean. So I can really sum them or mean them. Well, it's going to take care of that for us. So we're just going to use the mean squared error. But that's the idea. We take the differences. The reason why we have to square it, well, for a variety of reasons. One, it has to do with the derivative stuff that's in my other videos, but also just because positive or negative, it's the distance, the size of the error, whether it's up or down, which is key. All right. So I need to start the coding, but the microphone is making me crazy right now. I need to tape it to my ear. So hold on. I just need to get a little piece of tape. It really distracts me when the microphone starts. Yeah, by the way, Ricardo in the chat is mentioning the Coding Train hoodie. This is a new Coding Train hoodie that will be available later today. All right. Am I good to start coding? Any last comments before I start coding? This feels, it's staying on my ear now. OK. And maybe next time, I'll get the lapel mic back. How are we, 451? We're doing pretty well. To check my, I'm just going to keep going. All right. I think I'm good. I think we're ready to start writing some code. All right. Where's my marker in case I need it? Over here. All right. So here's the amount of code we're going to start with. I'm using p5 so that I can draw stuff. I'm making a canvas, and the background is 0, which means it's black. And this is what I have so far. So let's look at our list over here. And let's first add the data set, the x's and y's. So this is going to be easy because I just want to have x's be an array, y's be a list, and z's be a list. So x's be an array, y's also be an array. And then whenever I click the mouse, I want to say, oh, you know what I could do? I could make those vectors, let's make them separate arrays. I think we're going to, actually, I know we're going to want to do that for a variety of reasons. We're going to keep those as separate arrays. So every time I click the mouse, I'm going to say x's, push mouse x, y's, push mouse y. Ah, OK. Here's a little thing. So this is our canvas. This is my drawing of the canvas. Now I'm having a deja vu thing. I totally talked about this in the other video. The width is 400. The height is 400. But I really want to think of this as, I really want to think of 0, 0 down here, and maybe 1 being over here. I want to normalize everything between 0 and 1. Everything is just going to work better if we do that. So with y pointing up. So I'm going to do a mapping. So every y value, that's pixel value between 0 and height, I'm going to map between 1 and 0. And every x value that's between 0 and width, I'm going to map between 0 and 1. So let's do that. So I'm going to say let x equal map mouse x, which goes between 0 and width, to between 0 and 1. Let y, which is mouse y, between 0 and height, and have that go between 1 and 0, and then push x and push y. The other thing I want to do is I just want to, you know, I'm going to add a draw loop, and I want to draw all those points. So I'm also now going to say stroke 255, stroke weight 4, for let i equal, what? Let i equal 0, i is less than x dot length, i plus plus. And those are actually called x's, x's dot length. And what I'm going to do is I'm going to say let pixel x equal map. I really should make just like, I'm probably going to do this a lot, so I should probably make a function that just like normalize and un-normalize or de-normalize. Px equals map x's index i, which goes between 0 and 1, back to 0 and width. So this is the reverse. Py, which maps y, which goes between 0 and 1 to height, comma, 0. And then I want to say point px py. So I haven't done any, I'm not even using TensorFlow.js yet. I'm just kind of doing the stuff with p5 to draw things. So let's see if I'm getting the results that I want, which is whenever I click, I get the point there. Perfect. And I kind of want to see them a bit more. Let's like really make it bigger. Great, that's like too big. OK, great. So we can see those are the points I'm clicking on. OK. Pause, pause, edit, edit, pause, pause, edit, edit. I'm like drunk with power with the editing. I just take a break. It'll get edited later. I used to say that, and it didn't. It does. I think it was probably better when I didn't stop in the middle. All right. All right. So what's next? I need a loss function. I need an optimizer. Ah, oh, I need these. Let's make these. So because I'm looking for somewhere I need to get some TensorFlow.js stuff working. So what I need is I need to have m and b. So let's figure that out. So I'm going to create an m and a b. And I'm not going to initialize them up here. And I probably should be using const in various places here just to protect myself from reassigning something by accident. But I'm going to be loosey-goosey and just use let. You know, these could be const. But anyway, I'm not going to get into the whole let versus const thing because it makes me crazy. I'm going to say up here m equals tf scalar random 1. So I'm going to use the p5 random function to give me a random number between 0 and 1 because I've got to start somewhere. So this is kind of like initializing the weights of a neural network. There is no neural network. I'm just kind of optimizing this function y equals mx plus b. But those are like weights, m and b. So I'm going to initialize them randomly and scalar because it's a single number. So go back to my TensorFlow.js intro videos, and you'll see. Then b, I'm going to say the same thing. Ah, but. These are the things that have to change, right? The data never changes. It's sort of fixed. m and b change over time. I need to tweak those, which means they have to be variable. They have to be able to change, which means when I over here, I think what I write is tf variable. I wrap them in the tf variable. So now I have m and b as tf variable, right? Isn't it crazy? You see this kind of code, and you're like, that looks like the craziest, scariest thing. But you realize it's just like, make a number. And because we're in this kind of lower level, working on the GPU land, I've got to be very specific. This is a single number, and it's going to be variable. But really, it's just a random number. OK, now what do we need to do? I don't think I actually said this, but I need to write a function called predict maybe, which takes in all of the x's, just the x's, and gives me the y predictions based on where the line is, right? Because I need to compare the y predictions to the actual y values to get the mean squared error. So let's write that function. So I'm just going to, I'm putting these in like arbitrary places, but I'm going to write a function called predict. And there, what I need to do is I need to have some x's, and I need to return some y's. I think that's the idea, right? Yes. So I don't want to just predict one value. I want to predict a bunch. So the x's, here's the thing. So if I call this function, the x's, if they're just a plain array, I need to make it into a tensor. So I'm going to call it const tf x's. That might be a bad. It's tensor. And this is a 1D tensor. Tensor 1D. Oh, tf. Tensor 1D. I think this will do it. x's, right? I need to turn it into a tensor. And then I need to have the formula for a line. So I need to say, which is y equals mx plus b. So what I would be doing is I would be saying tf x's multiplied. Is it mul or mult? Multiplied by m plus b. Right? This is the idea. If I'm getting just a plain array of numbers, I turn them into a tensor. Then I apply the formula for a line. And these are the predictions, the y's. I guess I don't like my naming here. I'm just going to call this x. And maybe I'll call this x's. I don't know. I have to think about. I'll come back to this later. OK. So I have that. Now, let's go back and look at the things that I need. So I have this predict function. I have a data set. I need a loss function. I need a loss function. And I need a, oh, before we do the loss function, let's create the optimizer and the learning rate. So this is what's wonderful about working with TensorFlow.js. When I say make the optimizer, I just mean make a tf.optimizer. It exists. It'll do this math for us. So let's go to the, this is not something that I covered in my other videos. So let's go look for optimizer. And I want an optimizer. Now, there's all these different kinds of optimizers. SGD, stochastic gradient descent. This means the idea of slowly adjusting m and b to minimize the loss function. And I've covered this in more detail in the other videos. So I'm going to click on that. And I'm going to look here. And this is basically what I need to do. All right. We got the code right here. Look, there's even a, look at this. Oh my goodness. There's like some stuff here we can really use. So I'm going to grab this. And I'm going to put this up here. So I want a learning rate. And I'm going to have a much bigger learning rate to start with. And I want an optimizer. So now I have a learning rate and an optimizer. And the optimizer is doing stochastic gradient descent. So I have learning rate, optimizer. Now I need that loss function. I need the loss function. The loss function is something I'm going to write, loss. And actually, let's go back to here. So look at this. So this is the fancy ES6 way of writing a function. But I'm going to write it in a less fancy way. And I'm going to do this. So what I want is I need the loss function. I have some predictions. And I have some labels. So these are, the predictions are the y values I'm getting from the predict function. The labels are the actual y values that are part of this. And by the way, I'm going to have to do memory management. Don't worry. If you're screaming at me that I haven't worked out memory management, I'm going to do that. I'm just going to do that later. So what I want to do is say return the predictions minus the labels. That makes sense, right? Because I said here, when I said mean squared error, is the predictions, like the guess, minus the labels, which is the actual y, squared. And so predictions minus the labels squared. And then take the mean of them. Look at this. All of these mathematical operations are inside of TensorFlow.js. And you can chain them. So predictions is a tensor. Labels is a tensor. All of these, remember, they're just going to keep producing new tensors. And I'm going to have to tidy and clean all this stuff up for memory management. But again, I'll worry about that later. So now I have the loss function. All right. Well, what is it that I want to do? Every time, so let's say, I think I'm actually like, I have everything. I have the loss function. I have the data. I have the optimizer. I have a predict function. I have a learning rate. I can minimize. Well, oh, this I haven't done. So the training, the actual training, what does it mean to train it? To train it, I'm going to have to do To train it means minimize the loss function with the optimizer and adjusting m and b based on that. All right. So let's see if we can make that. I have a feeling that was in that page that I went to. So maybe I could just copy it from there. This is like very, so it totally is. That's fine. I'm going to happily cheat here. It was in that example. Thank you very much. Thank you, TensorFlow.js documentation. And so I'm going to just put this in draw. Every time through draw, I'm going to minimize. So let's look at this. Oh, look at this. OK, so this is a little different. So first of all, this is using nice, fancy ES6 arrow notation, which I'm somewhat happy about. But let me just write a function here called train. And the idea of the train function is to execute the loss with the predictions and the actual y's. OK, so here, what I'm really doing is minimizing the train. That's weird. This isn't really, no, training would be doing this. So this is a terrible name for this. And actually, this is silly for me to even name this. It really makes sense for me to just make this an anonymous function and that what I'm minimizing is this, right? This is what I want to minimize, the loss function. But if I want to be nice and ES6-like with my arrow notation, which I think by the fact that I'm using TensorFlow.js, and you can watch my arrow notation function if I can kind of get rid of a lot of the extra stuff here. And this should be good. So I just want to minimize the loss function. Now, here's the thing. These have to be tensors, right? The loss function requires predictions and labels. They have to be tensors. And if you remember, my x's and y's aren't tensors. When I call the predict function with the x's, it gives me back a tensor. I can't believe I haven't run this code yet. This is a terrible thing. Usually, I try to run my code incrementally all the time. I guess I've forgotten to do that. So probably people in the chat are telling me about mistakes I'm making. So this is a tensor, but this is still a plain array. So what I need to do is say constant. And I got to rethink the naming. Maybe somebody in the chat has an idea for me. I think what I actually should do, I have an idea. Permit me a moment of refactoring. x valves, y valves. So I think when it's not a tensor, I'm just going to call it x underscore valves, because that's going to help me remember. So x valves, y valves. And then whenever I say, and this should be x, whenever I say xs or ys, that's really a tensor. I guess I could have done txs. So here, what I'm doing is predicting from the x valves. And then ys is tf tensor. Shoot. Somehow I went past a half an hour. ys is tf.tensor1dy valves. So I need to create that tensor. And now I can minimize the loss with predicting from the x valves and the y valves. OK. So this is good. Let's just run this, see what errors we get. OK. predict.sub.squared is not a function at loss at optimize or minimize. So what do I have wrong here? In my loss function, sub labels.squared.mean. Hmm. So let me put no loop in here because I just want to run this once. And let me say, I just want to console log. Oh, actually, I can just do ys.print. Oh, you know what it is? There's nothing in the arrays at the beginning. They have zero things in them. So a couple of things. One is I could put something in it. But I think I probably should just say, I shouldn't do it only if x.length is greater than 0. So this is definitely, do I want to bother with doing any of this? If there's no values in there, like calling predict and stuff with an empty array, I think it's going to cause problems. That makes sense. All right, let's try this. x is not defined. x valves, my naming. OK, sketch 45. Ah, this is x valves. And this is x valves, y valves. OK, that should be good. All right, let's try this. All right, I think I have frozen the world. Oh, this is not square. I'm being told in the chat, breaking news, that this is actually dot square, not dot squared. Is that right? Operations, square. Whoa, this I might be able to use. Computes the mean squared error between two tensors. So I could also use this probably, but that's not what I'm looking for. Yeah, oh, it's square. A dot square. OK. Hold on. So what's going on? Let's comment this out. Oh, I put no loop. I put no loop in there. Silly me. OK, everything's fine. I put no loop when I was trying to console log stuff. There we go. OK, so things are going. And there's no, I don't have any, like I could look at. That's m, m, m dot print. So you can see it's changing. It's actually like training it. Like the value of m is changing. So everything's going and working. The problem is I'm not seeing the results. Let's just check b. And I haven't done any memory cleanup. So if I say memory dot num tensors, is that what it is? What is it again? So let's look under memory management. Memory, oh, memory num, oh, this, tf. So I know you can't see this, but this is what I want. I want to check how much, I want to check and see like how if I have cleaned up stuff. You can see I have 1,147 tensors. So I need to do the memory cleanup. I don't know, probably better practice would be for me to clean up as I'm going, but I'm kind of going to clean up at the end. All right, so let's, I just want to click back here for a second. Oops. No, I'm just going to click no loop to shut this off. And let's go here. So what do I need to do? Ah, I need to visualize what's going on. All right, so how do I do that? So I need to draw a line. So the way that I would draw the line is first what I would do is all I really need is to give myself the x value of 0 and the x value of 1, get the two y values, and draw a line between those two points. So if I were to say, let x equal tf scalar. This is silly for me to use the predict function. Why not? Why not? Let's use the predict function. tf scalar is 0. So x1 is tf scalar 0. y1 equals tf equals predict x1. x2 equals tf scalar 1. y2 equals predict x2. So this should give me, I mean, it's a little bit silly for me to not just do this, keep an extra copy of like m and b as regular numbers. But let's keep going with this. Will this work? Is it going to be able to take a scalar and make a 1D tensor? I think so. So let me just see here. Let me do x1.print, y1.print. So let's see that. Tensor 1D requires values to be a flat typed array. So I could reshape. Yes, good point. Minimize. Sorry. Sorry, I started looking at the chat, which I shouldn't do. Pause for a second for a little edit point. Alex Prats Ferrer writes, you need to average the squared error. I don't think I need to average it because I have the dot mean function. So that takes the average automatically, I think. So let me think. What might be better is for me to just, should I just, I should just bite the bullet and get the m and b values back. Yeah. I could reshape this. Oh, no, this is silly. I can just do this. Hold on. So one thing I could do is instead of making it a scalar, I can make it a 1D tensor. That's what it wants. And do the same thing here. And I have to put it in as an array then, but it's just one value. Oh, this is so silly. Why am I doing x1 and, I could just do this, right? Xs, once again, can I use xs? Yeah, yeah, yeah. So I could just do it with 0 and 1. Constant xs and then constant ys equals predict xs. So I could have both these points now. Then let's say xs.print, ys.print. Let's look at that. Let's see if this works. Predict is not defined because my E key doesn't work, and I have to type it several times. Tensor 1D requires values to be a flat typed array. Oh, silly, silly me. Predict doesn't want a tensor. Oh, it wants this. So line x equal, let me just, this is a little bit silly, but I'm going to do this. So I'm going to make the, oh, but I don't need to know the xs. I don't need to have the xs as a tensor because, yeah. Sorry, everybody. There we go. My predict function, I totally forgot. Already, see, this is just, there's so many different ways you could do this. I could enforce you to convert to a tensor before you pass it into predict, but I've just, a lot of these decisions are completely arbitrary. So you might have a better way of doing it, but still I'm going to do this. So now I have the xs and the ys, and I don't even need to say xs.print. So we can see, OK, great. So I'm getting these points. Kate Wieckmann in the chat makes an excellent point, which is that I should think about actually mapping it between negative 1 and 1 with 0, 0 in the center. That's not such a bad idea. Let me just keep going with this, and then maybe I'll change that after the fact because this should work anyway. So now here's the thing. Here's the awkward thing. In order for me, all I need to do now is basically say this. Let x1 equal map x's 0, which goes between 0 and 1, between 0 and width. And this is kind of silly because I could just multiply it times width. But I'm going to just go with the normalizing, the full normalizing. y1 equals map x, oh, sorry, x2, which map x's index 1. So this gives me x1, which is just 0 and width. Now, y1 and y2, I want to map ys, the y values between height and 0 because I'm flipping it. The problem is, and then I just want to say line, x1, y1, x2, y2. So this is really all I need to do. I just want to get the sort of two points on the line and then draw a line between them. This is fine because my x's are not tensors. And I can use plain numbers right here, x1, x2. But my y's, and here, but my y's are tensors. So for me to be able to, I really need to get the values back. And a way to do that is with the function called data. So I'm going to say let line y equal ys.data. And I'm just going to say data sync right now. And let me comment all this out. And let me console log that and see if this comes. So this is kind of a bad idea for a variety of reasons. But I think it's going to work OK. So you can see I'm getting those numbers back as a float array. So here's the thing. This really requires not a callback, but a promise. And I'm so happy I just did a whole video series on promises. I really should be saying data.then. And there's even something called tf.nextframe, which allows me to sort of think about the asynchronous nature of pulling the data out of a tensor into a number that I can use in an animation. These are key things. I'm definitely going to have to get to them. But here's the thing. This is just two numbers. I think my animation can handle using data sync. And maybe somebody from the TensorFlow.js team is going to want to say, actually, this is not just a bad idea, but a really bad idea. I'm not so sure. But I think it's going to let's just get it to work and see if this demonstrates the idea. So now, I'm going to call this line y. I should be able to say y1, y2. And I should get 0 and 1 from line y. And now, we should see, we should be done. Line y is not defined. Where? Sketch.js line 61. 61. I think I just didn't hit Save. Yeah. Oh, I haven't clicked any points. Hey, look at that. Oh, hey, look. It's working. Oh, that's so exciting. Oh, that's so exciting. All right, for a couple of things. Number one is, let's say, stroke weight 2. And by the way, we can now start to play with the learning rate. I don't have to clean up the memory stuff. I can play with the learning rate. Like, let's make this 0.01. So you can see what happens with this lower learning rate. I don't know if it's. Um, let's see. Is it really working? Well, I shouldn't use such a low learning rate. Let's make it 0.5. Yeah, it's definitely happy. OK, so this is working. Linear regression with gradient descent. But I have a severe problem. I am just filling the GPU with tensors and tensors and tensors and tensors and never cleaning them up. So now it's my job to go through and find every place I'm creating a tensor and dispose of it. So I can use tftidy to do that automatically, or I can just use the actual dispose function, which I might be inclined to do at first. All right, so let's go through. So here, these, I do not, I always want to keep them. m and b are variables that I need to keep throughout the course of this program. Loss, do I just put tidy in here? Or should I? Let's predict. So do I put tidy in here, or do I wrap tidy here? What if I just put tidy here? Like, what if I say tf.tidy and put all of this? Will this do it? And then here, I also need to, well, here maybe what I'm going to do is just dispose these. There's no logic to what I'm doing, but I'm just going to dispose these manually. Oh, and that's just the y's, right? Line y is just, ys is the only thing that's a tensor here. So this should tidy everything, but hopefully not the variables that I need to keep, rather than individually figuring out what to dispose of. And down here, I kind of know that this is my only tensor. This, by the way, I should call this like line x, just to be consistent with my variable naming. You know, I'm only using the ys and xs variable name when I have something that's actually a tensor, which helps me remember what I need to clean up and not. Let's see if this goes. It's still running. 221. Oh, no. OK. So I'm better. There's fewer tensors, but I haven't cleaned up everything. So what could I be missing? Maybe the call to predict. Wouldn't tidy clean that up? You know, we need a I'm going to have to think about this for a little bit. Farrink asked, just joined in, is it being recorded and posted later on YouTube? Yes. Anybody see what tensors I'm missing? This is like the laziest thing ever. Anybody see what tensors I'm missing? This is like the laziest thing ever. There's got to be a good way to debug this. So this definitely gets cleaned up. The question, does everything that's made inside of the loss and the predict function get cleaned up? It would seem not. Oh, hold on. Let's comment this out. It's not working, but no. OK. That's good to know. OK. Hold on. All right. I need to debug this somehow. One thing I could do is start commenting stuff out to see where is the memory leak. So one worry I have, I really think loss and predict, those functions generate a lot of tensors. I believe tftidy should clean up anything. But let's just, for the sake of argument, comment this out. And now, of course, the learning is no longer happening. And what I might as well do is console log the amount of tensors, not have to ask for it. Whoops. What did I do wrong? tfmemory numtensors? What is it? How come I can't remember what it is? Numtensors. No. Yes. It's not a function. It's just numtensors. Sorry, everybody. OK. And I need another parentheses here. A little digression there. All right. All right. So we can see it's growing. So let's keep commenting stuff out to see what's causing the memory leak. Let's comment out this whole area down here. Ah. Good news, everybody. The memory leak is in that part. Let's put this back just to be sure. OK. Ah. So the memory leak is definitely down here. And I'm probably creating. Oh my goodness. Oh my goodness. No, I'm not sure. Well, let's put this back in. I thought I saw it, but then I didn't again. So this is a tensor. And I'm disposing it. Oh, predict. Aha. The predict function makes other tensors. And predict got cleaned up because it was in tidy, but I'm just manually disposing the y's down there. That's what it is. So let me use tidy. I guess. So let me do this. Let me put this up here. So this is really what I need to tidy. So instead of disposing manually, I kind of like disposing things manually. The tidy thing kind of freaks me out. But the problem with this is I have a scope issue, which is that line y, no matter what I do, if I take this out here, this is going to tidy everything. So I guess it's not the biggest deal, at the moment at least, for me to just put everything inside the tidy. Well, let's put everything inside the tidy for right now. There's probably a way I could simplify that, but this should work. Let's give this a try. There we go. There's only ever five tensors all the time. So there's no more memory leak, five tensors, linear regression with gradient descent, TensorFlow.js, interactive. Here it is. So what's left here? So number one, things that could be improved. Pause. Oh. So I could say, ah, all right. So line y, ys. So I could actually just put a tidy here and have it return. So I wanted to talk through some things that could be improved, but already, meiamsami in the chat made a very good suggestion. This is very awkward, how I put everything in tidy. So unnecessary. Let me take that out. Because predict returns something, I can actually just put the tidy right here. I don't know why I didn't think of that. I can actually just, it's only this predict function. So I can actually put the tidy right here. And I can use my fancy ES6 arrow syntax. And the return is now assumed. And then I can just say ys.dispose. So this should work. Tidy is not going to tidy up this y value, but I can dispose that manually once I have the values. So I think this will do the trick. Let me just take a look at this. Yeah. So this I like better. And there's probably other styles or ways you could do it. The point is, you've got to keep track of all the tensors you're making and dispose them. OK, pause, edit, point. Let me see, what are some other things? I could use the data sync in there, but I'm going to keep that as a separate line. All right. Ah, interesting. All right, let's add a few more things. Riza in the chat asks, can you print the loss? That would be really useful for us to see the loss. I could even graph it. So I'm sure there's a way for me to do that. I need to grab the loss somewhere. So the loss, I think the loss would come out here, right? I wonder if it would get returned. Let's just take a look at that. Whoops. No, hold on. I mean, I could call the loss function, but I'm not sure. But maybe let's not. The return is implied sounds better than assumed. Yes, thank you. That's a good point. Hello, Izumi, Coding Train sponsor. Outliers. Hold on. What are some things that I can do to improve this? Adding the loss, I'm going to leave that as an exercise. So Mathieu, we're at the edit point where I was about to add some improvements. Anything else? TensorBoard to visualize the training graph. It's 5.30, so I also have to go. I do think I completed this. I just want to check. I just want to just check. The reason why I have to go is because I have to be home at a certain time, and I just want to make sure it's not an emergency for me to be home. OK. All right. So I've got like 5 or 10 minutes, I think. I'm good. Try another optimizer. All right, so these are things I want. I think I want this video to be over. So you get the loss with a callback. Interesting. All right. Print mean squared error. All right. All right, so let me, why don't you tidy the tensors inside the predict? Yeah, that would have been another way to do it. There's just so many different ways. All right, so here. OK. OK, so I think I'm going to wrap this video up. I'm getting all these great suggestions from the chat. I could have tidied the tensors here in predict. So number one is, this code is going to get posted to the Coding Train website and coding challenges. Make your improvements and add them as community contributions. Some things that I would love to see. Visualize, graph the loss value. I think there's a way to get the loss. I'm sure there's a way to get the loss value out of that function. That's one idea. There was another good one. There was another good one that I forgot. Oh, yes. K. Wieckmann suggested maybe trying some of the other optimizers. So what happens if I go to the TensorFlow.js documentation and just use some of these other optimizers? What are they? What will they do? Do you get better or worse results? Can you make the learning rate somehow interactive? Adjust the learning rate? I don't know if you could come up with any really clever visual ideas with this. But anyway. So but I think I'm good. I think I have the basic idea. So if you really want to dive as deeply as you can into linear regression with gradient descent, you can go back and watch my other videos where I did this with just JavaScript and p5.js. Now you've seen it with JavaScript, p5.js, and TensorFlow.js. So I look forward to your feedback and hearing more about it. More TensorFlow.js videos to come. I want to get to some actual more practical things that you might want to do for interactive creative arts projects. But I'm still in the weeds here of just trying to understand the nuts and bolts of how the library works. So I hope you're enjoying that, and I look forward to seeing you in future videos. All right. Put on hold. I am reading your comment. All right. So I am done for the day. I have done a lot of live streaming this week. Pat myself on the back. At least five hours of live streaming this week, which is pretty good. Hopefully that makes up for the weeks that I've missed. Next week, I think I might actually not be live streaming on Fridays this summer. I think I'm going to be doing Wednesdays and Thursdays during the day, which is my New York time. But it's going to be kind of game time decision each week. Stay tuned. So what's the stuff you need to know about? So if you go to thecodingtrain.com and you click here to subscribe on YouTube, it will take you to the channel. Hey, yeah, I totally want to subscribe. I may not. Why not? I'm so close to 500,000, which is nuts. You can get 50,000 subscribers in the next 10 minutes. That would be exciting. So look, it says I'm live now, which is this. But when I schedule a live stream, I'm getting some important messages I really got to go. Putting on my goodbye song. Let me just send a little text message back here. Yes, will do. Try asking it now. I missed it. There was a question. Show us the hoodie. So this hoodie, I don't know if the hoodie available yet. Oh, the music's not working. Sorry about that, everybody. I forgot. I turned it off. The hoodie will soon be available. The store is codingtrain.store. nv.com. So this is the URL for the Coding Train store, for those of you who are interested. But right now, if you go here, hoodie, that's a different hoodie, zip up hoodie. I think, is this the new one or not? Interesting question. I think this, I have to see. Let's click on this. It's expensive. Yeah, no, this is the old one. So you could get this, but I'm going to change it. This is a new American Apparel hoodie. I like it better. And it also has the Coding Train on the back. Although, this was the sample. So I'm going to, we're moving, I'm going to move it down to about here. If anybody has any suggestions or ideas. By the way, all of this is fulfilled through a website called printful.com. So in theory, I have the capability to produce any, like a ton of other things. But it's just not my priority, merchandise. I don't really know what I'm doing with that. But people were asking me about the hoodie. Yeah, Printful ships internationally. It's not me who's sending it out. It's done through a print on demand service. It is marked up. So there's like a shipping and a slight markup. So if you buy the hoodie, I probably make like $4 or $5 or something. I don't know what the exact amount is. It sort of depends on what the, there's all these weird taxes and shipping things. But I don't, it's actually no, the Patreon stuff, I actually mail myself. If you're funding through Patreon or whatever. But the merchandise stuff just gets fulfilled through the Printful store. I don't have to do anything. Um, do you know, ah, the Nair Engineer question. Do you know any reference how to link processing-java to Atom? Yes. So what you want to look at is, a commander, processing command line. So you want to look at, command, hold on, don't worry. I know the camera went off, everybody. There we go. I think somebody's already done this with like an Atom plugin. But if you go here to this wiki, command line processing, there is a command line tool that you can install. And, then you can have Atom like execute the sketch via a command line. So you have to like configure Atom in a goofy way. This has been done. I know it was done with Sublime. Atom editor processing.org. Yeah, so like, yeah. So I have a feeling, yeah. So you can see somebody's already done this already. And figured it out. So you have to install processing-java. And this is, so these are the instructions. Then you have to add stuff to your path and that sort of thing. Okay. Let's look at the chat. Dan, why do you know everything? Asks Melon Goggles. It is absolutely an illusion. I definitely do not know everything. And I just know, I just know like, just enough to like get through the tutorial. And then like, if I were to go two steps further, there'd be like a hundred things I don't know. And you've, all of you have I'm sure seen my disastrous live streams where I get completely lost. If any of you try to watch some of my tutorials where I try to explain calculus stuff, you would see that I don't know everything. Okay. Um, all right. So thank you for all the questions in the chat. I'll answer the last question. Justine asks, what's up with the camera going off every 30 minutes? Have you ever watched the TV show Lost? Basically this is the, what's the thing called? The hatch. I'm in the like Swan station. And if I don't press the button every 30 minutes, the world will end. That's why I press the button every 30 minutes. No, the cameras have, these cameras are set to go to sleep. And there are, I've been, many people have given me many suggestions to get them not to do that. And I have not successfully been able to implement any of them. So I, that's kind of a goal I have for the summer for sure. Oh, did I just spoil Lost for people? I'm terribly sorry. The thing is that didn't really spoil anything. A little bit. Lost is one of my favorite television shows. I need some, what am I? I'm trying to watch some stuff this summer. But anyway. Oh, blockchain. I don't think you're gonna find me doing any blockchain tutorials. Sorry to disappoint. Would you possibly do a time series prediction with LSTM or current neural network? See, an example of how I don't know everything. Yeah, but I gotta figure that out. All right, thanks everybody. Thanks for watching. I kiss, my fingers. I don't know. It's a sort of expression that I've adopted from somebody else. If anybody knows what that reference is, that's crazy to me. Did I like the Lost ending? Not so much to be honest. But when I think back about that show, it fills me with such like amazing memories. I was really interested in it, listened to the podcast. So the ending, I forgive you Lost for that ending. It was fine. You did your best. I couldn't have done any better, that's for sure. That was not my favorite season of Lost. Sentiment analysis, I definitely wanna do. Yeah, all right. So there's gonna be a lot of edited tutorials coming out. Just to recap, there's I think five or six tutorials on promises, async and await. And now this coding challenge of linear regression with gradient descent. I will see you all next week sometime. Stay tuned to... Oh, hi Coding Garden. Coding Garden was live streaming at the same time as me earlier today. Coding Garden seems to live stream like 12 hours a day. I don't know how that's possible. It's probably not that much, but there's a lot of Coding Garden live streams. So everybody check out Coding Garden, a sponsor of the Coding Train. Oh, I can't put on my music and do my goofy sponsor advertisement again. See everybody, I'm gonna play out the outro now. Why not? It's the end of the day. See you all later. Let's find something we wanna make, some crazy idea. By the way, my microphone is still going. I can't seem to figure out how to use it. We'll try to understand now as we ride along again. Now hop on the Coding Train, Coding Train, Coding Train. Come along and join us as we light it up in gold. Using only our imagination as the road. Whenever you're conceiving, you'll start seeing what you're believing. Just hop on the Coding Train, Coding Train, Coding Train. Pick you all up at the station. We'll make things of our own creation. Fireworks. Medi-balls. Super ships. We can jump to anything in the outer space. We can generate sounds or trees or mazes. Make a butterfly or reflect our faces. A retro game. Or a Twitter bot. And never forget that there's a. Just hop on the Coding Train, Coding Train, Coding Train. Coding Train.",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:04:01.900616Z",
  "started_at": "2023-09-26T21:32:34.906076Z",
  "completed_at": "2023-09-26T21:50:53.822176Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=NZR-N_dhK2M",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 1098.9161
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/2fmjjjbbzslqxdlasc6hjmp27a/cancel",
    "get": "https://api.replicate.com/v1/predictions/2fmjjjbbzslqxdlasc6hjmp27a"
  }
}