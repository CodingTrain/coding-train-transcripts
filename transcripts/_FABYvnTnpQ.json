{
  "id": "cyrfjhzbu5gba7p2wjrfjao55y",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/_FABYvnTnpQ.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/528994 [00:00<?, ?frames/s]\n  1%|          | 2996/528994 [00:01<03:44, 2340.82frames/s]\n  1%|          | 5564/528994 [00:06<10:44, 812.70frames/s] \n  2%|▏         | 8428/528994 [00:13<16:21, 530.24frames/s]\n  2%|▏         | 11060/528994 [00:16<13:08, 656.61frames/s]\n  3%|▎         | 13836/528994 [00:25<18:26, 465.55frames/s]\n  3%|▎         | 16572/528994 [00:33<20:43, 412.19frames/s]\n  4%|▎         | 19372/528994 [00:40<21:01, 403.86frames/s]\n  4%|▍         | 22084/528994 [00:46<20:18, 415.92frames/s]\n  5%|▍         | 24668/528994 [00:54<21:49, 384.98frames/s]\n  5%|▌         | 26708/528994 [00:59<21:32, 388.69frames/s]\n  6%|▌         | 29428/528994 [01:05<20:01, 415.71frames/s]\n  6%|▌         | 31996/528994 [01:12<20:50, 397.57frames/s]\n  7%|▋         | 34996/528994 [01:19<20:47, 396.13frames/s]\n  7%|▋         | 37868/528994 [01:28<22:03, 371.00frames/s]\n  8%|▊         | 39964/528994 [01:34<22:19, 364.98frames/s]\n  8%|▊         | 42772/528994 [01:42<22:46, 355.79frames/s]\n  9%|▊         | 45692/528994 [01:51<22:44, 354.31frames/s]\n  9%|▊         | 45692/528994 [02:10<22:44, 354.31frames/s]\n  9%|▉         | 48692/528994 [02:15<36:17, 220.57frames/s]\n 10%|▉         | 51612/528994 [02:24<32:11, 247.10frames/s]\n 10%|█         | 54516/528994 [02:32<28:43, 275.34frames/s]\n 11%|█         | 57466/528994 [02:39<25:44, 305.35frames/s]\n 11%|█▏        | 60086/528994 [02:45<23:39, 330.28frames/s]\n 12%|█▏        | 63086/528994 [02:54<23:01, 337.16frames/s]\n 12%|█▏        | 66006/528994 [03:01<22:01, 350.28frames/s]\n 13%|█▎        | 68950/528994 [03:08<20:44, 369.62frames/s]\n 14%|█▎        | 71902/528994 [03:16<20:16, 375.76frames/s]\n 14%|█▍        | 74846/528994 [03:24<20:12, 374.48frames/s]\n 15%|█▍        | 77454/528994 [03:31<20:09, 373.46frames/s]\n 15%|█▌        | 80334/528994 [03:38<19:16, 387.95frames/s]\n 16%|█▌        | 83246/528994 [03:46<19:48, 374.95frames/s]\n 16%|█▋        | 86146/528994 [03:54<20:00, 369.01frames/s]\n 17%|█▋        | 89110/528994 [04:02<19:45, 371.01frames/s]\n 17%|█▋        | 91586/528994 [04:09<20:08, 361.86frames/s]\n 18%|█▊        | 94430/528994 [04:17<20:06, 360.21frames/s]\n 18%|█▊        | 97250/528994 [04:25<19:42, 365.14frames/s]\n 19%|█▉        | 100146/528994 [04:32<19:12, 372.23frames/s]\n 19%|█▉        | 102922/528994 [04:40<19:17, 368.19frames/s]\n 20%|█▉        | 105726/528994 [04:50<20:42, 340.62frames/s]\n 21%|██        | 108634/528994 [04:58<20:47, 336.84frames/s]\n 21%|██        | 111358/528994 [05:08<21:35, 322.45frames/s]\n 22%|██▏       | 114322/528994 [05:17<21:41, 318.50frames/s]\n 22%|██▏       | 117186/528994 [05:25<20:33, 333.76frames/s]\n 23%|██▎       | 120014/528994 [05:32<19:38, 346.90frames/s]\n 23%|██▎       | 122882/528994 [05:38<17:47, 380.41frames/s]\n 24%|██▎       | 125606/528994 [05:43<16:15, 413.41frames/s]\n 24%|██▍       | 128538/528994 [05:52<17:00, 392.55frames/s]\n 25%|██▍       | 131470/528994 [06:00<17:16, 383.48frames/s]\n 25%|██▌       | 133930/528994 [06:06<17:08, 384.10frames/s]\n 26%|██▌       | 136786/528994 [06:15<18:19, 356.65frames/s]\n 26%|██▋       | 139582/528994 [06:24<18:34, 349.54frames/s]\n 27%|██▋       | 142274/528994 [06:32<18:32, 347.61frames/s]\n 27%|██▋       | 145214/528994 [06:39<17:58, 355.71frames/s]\n 28%|██▊       | 148126/528994 [06:47<17:31, 362.13frames/s]\n 29%|██▊       | 151118/528994 [06:55<17:03, 369.07frames/s]\n 29%|██▉       | 153974/528994 [07:04<17:41, 353.16frames/s]\n 30%|██▉       | 156938/528994 [07:13<17:54, 346.10frames/s]\n 30%|███       | 159314/528994 [07:18<16:38, 370.05frames/s]\n 30%|███       | 159314/528994 [07:30<16:38, 370.05frames/s]\n 31%|███       | 162314/528994 [07:39<24:42, 247.33frames/s]\n 31%|███       | 164942/528994 [07:44<21:17, 285.00frames/s]\n 32%|███▏      | 167814/528994 [07:52<19:15, 312.71frames/s]\n 32%|███▏      | 170738/528994 [08:00<18:37, 320.57frames/s]\n 33%|███▎      | 173662/528994 [08:10<18:44, 316.03frames/s]\n 33%|███▎      | 176442/528994 [08:18<18:17, 321.11frames/s]\n 34%|███▍      | 179418/528994 [08:28<18:19, 317.87frames/s]\n 34%|███▍      | 182326/528994 [08:37<18:14, 316.64frames/s]\n 35%|███▍      | 184906/528994 [08:46<18:39, 307.43frames/s]\n 36%|███▌      | 187898/528994 [08:55<18:01, 315.49frames/s]\n 36%|███▌      | 190830/528994 [09:04<17:31, 321.46frames/s]\n 37%|███▋      | 193754/528994 [09:13<17:23, 321.41frames/s]\n 37%|███▋      | 196678/528994 [09:23<17:45, 311.79frames/s]\n 38%|███▊      | 199642/528994 [09:30<16:34, 331.28frames/s]\n 38%|███▊      | 202474/528994 [09:38<15:57, 341.16frames/s]\n 39%|███▉      | 205430/528994 [09:46<15:27, 349.00frames/s]\n 39%|███▉      | 208430/528994 [09:56<15:55, 335.45frames/s]\n 40%|███▉      | 211258/528994 [10:06<16:57, 312.32frames/s]\n 41%|████      | 214258/528994 [10:13<15:20, 341.82frames/s]\n 41%|████      | 217138/528994 [10:23<15:49, 328.53frames/s]\n 42%|████▏     | 220054/528994 [10:32<15:46, 326.39frames/s]\n 42%|████▏     | 222906/528994 [10:40<15:21, 331.98frames/s]\n 43%|████▎     | 225170/528994 [10:48<15:35, 324.64frames/s]\n 43%|████▎     | 228058/528994 [10:55<14:29, 346.03frames/s]\n 44%|████▎     | 230678/528994 [10:59<12:24, 400.71frames/s]\n 44%|████▍     | 233598/528994 [11:06<12:18, 400.19frames/s]\n 45%|████▍     | 236534/528994 [11:14<12:39, 385.01frames/s]\n 45%|████▌     | 239486/528994 [11:21<12:01, 401.20frames/s]\n 46%|████▌     | 242318/528994 [11:25<10:34, 451.79frames/s]\n 46%|████▋     | 245190/528994 [11:32<10:22, 455.63frames/s]\n 47%|████▋     | 248178/528994 [11:36<09:25, 496.99frames/s]\n 47%|████▋     | 251030/528994 [11:48<11:56, 388.09frames/s]\n 48%|████▊     | 253886/528994 [11:55<11:52, 386.28frames/s]\n 49%|████▊     | 256774/528994 [12:03<11:55, 380.22frames/s]\n 49%|████▉     | 259538/528994 [12:11<12:11, 368.34frames/s]\n 50%|████▉     | 262310/528994 [12:16<10:57, 405.83frames/s]\n 50%|█████     | 265120/528994 [12:23<11:01, 399.19frames/s]\n 51%|█████     | 268064/528994 [12:33<11:56, 364.05frames/s]\n 51%|█████     | 270960/528994 [12:40<11:28, 374.68frames/s]\n 52%|█████▏    | 273848/528994 [12:46<10:32, 403.22frames/s]\n 52%|█████▏    | 276668/528994 [12:54<10:41, 393.39frames/s]\n 53%|█████▎    | 279500/528994 [13:01<10:33, 394.01frames/s]\n 53%|█████▎    | 282180/528994 [13:08<10:23, 395.65frames/s]\n 54%|█████▍    | 285060/528994 [13:16<10:45, 377.89frames/s]\n 54%|█████▍    | 287812/528994 [13:22<10:02, 400.35frames/s]\n 55%|█████▍    | 290494/528994 [13:28<09:34, 415.15frames/s]\n 55%|█████▌    | 293322/528994 [13:33<08:43, 450.00frames/s]\n 56%|█████▌    | 296270/528994 [13:38<07:57, 486.92frames/s]\n 57%|█████▋    | 299254/528994 [13:47<08:53, 430.71frames/s]\n 57%|█████▋    | 302158/528994 [13:53<08:47, 429.78frames/s]\n 58%|█████▊    | 305022/528994 [14:01<09:05, 410.74frames/s]\n 58%|█████▊    | 307962/528994 [14:07<08:27, 435.95frames/s]\n 59%|█████▉    | 310880/528994 [14:15<08:47, 413.27frames/s]\n 59%|█████▉    | 313502/528994 [14:22<08:57, 401.15frames/s]\n 60%|█████▉    | 315134/528994 [14:25<08:35, 414.54frames/s]\n 60%|██████    | 318134/528994 [14:29<07:02, 498.99frames/s]\n 61%|██████    | 320942/528994 [14:34<06:45, 512.63frames/s]\n 61%|██████    | 323594/528994 [14:39<06:36, 518.54frames/s]\n 62%|██████▏   | 325862/528994 [14:44<06:41, 506.43frames/s]\n 62%|██████▏   | 328230/528994 [14:47<06:11, 540.79frames/s]\n 63%|██████▎   | 331158/528994 [14:54<06:33, 502.90frames/s]\n 63%|██████▎   | 334158/528994 [15:00<06:34, 493.76frames/s]\n 64%|██████▎   | 336974/528994 [15:07<06:49, 469.18frames/s]\n 64%|██████▍   | 339780/528994 [15:15<07:15, 434.20frames/s]\n 65%|██████▍   | 342654/528994 [15:20<06:42, 463.33frames/s]\n 65%|██████▌   | 345634/528994 [15:26<06:34, 464.86frames/s]\n 66%|██████▌   | 348302/528994 [15:34<07:02, 428.09frames/s]\n 66%|██████▋   | 350842/528994 [15:39<06:39, 446.15frames/s]\n 67%|██████▋   | 353526/528994 [15:45<06:29, 450.46frames/s]\n 67%|██████▋   | 356358/528994 [15:51<06:31, 440.61frames/s]\n 68%|██████▊   | 358942/528994 [15:58<06:32, 433.36frames/s]\n 68%|██████▊   | 361590/528994 [16:04<06:35, 422.94frames/s]\n 69%|██████▉   | 364502/528994 [16:11<06:21, 431.63frames/s]\n 69%|██████▉   | 367386/528994 [16:17<06:13, 432.42frames/s]\n 70%|███████   | 370382/528994 [16:27<06:47, 388.89frames/s]\n 71%|███████   | 373382/528994 [16:34<06:39, 389.33frames/s]\n 71%|███████   | 376118/528994 [16:41<06:31, 390.04frames/s]\n 72%|███████▏  | 378844/528994 [16:48<06:20, 394.94frames/s]\n 72%|███████▏  | 381720/528994 [16:51<05:06, 480.75frames/s]\n 73%|███████▎  | 384552/528994 [16:58<05:11, 463.52frames/s]\n 73%|███████▎  | 387552/528994 [17:02<04:34, 514.38frames/s]\n 74%|███████▍  | 390520/528994 [17:10<04:55, 469.06frames/s]\n 74%|███████▍  | 393520/528994 [17:15<04:30, 499.91frames/s]\n 75%|███████▍  | 396464/528994 [17:18<03:48, 579.46frames/s]\n 75%|███████▌  | 398928/528994 [17:22<03:38, 594.63frames/s]\n 76%|███████▌  | 401720/528994 [17:26<03:27, 612.04frames/s]\n 76%|███████▋  | 403976/528994 [17:33<04:05, 509.63frames/s]\n 77%|███████▋  | 406952/528994 [17:37<03:45, 541.10frames/s]\n 77%|███████▋  | 409822/528994 [17:47<04:36, 431.20frames/s]\n 78%|███████▊  | 412702/528994 [17:54<04:30, 430.08frames/s]\n 79%|███████▊  | 415578/528994 [18:02<04:46, 395.60frames/s]\n 79%|███████▉  | 418146/528994 [18:08<04:28, 412.74frames/s]\n 79%|███████▉  | 420534/528994 [18:14<04:30, 400.67frames/s]\n 80%|███████▉  | 422818/528994 [18:19<04:13, 419.47frames/s]\n 80%|████████  | 425658/528994 [18:28<04:33, 377.20frames/s]\n 81%|████████  | 428494/528994 [18:36<04:34, 366.53frames/s]\n 82%|████████▏ | 431286/528994 [18:43<04:14, 384.51frames/s]\n 82%|████████▏ | 434242/528994 [18:51<04:09, 379.26frames/s]\n 83%|████████▎ | 437158/528994 [18:58<03:55, 390.09frames/s]\n 83%|████████▎ | 440010/528994 [19:03<03:31, 420.81frames/s]\n 84%|████████▎ | 442678/528994 [19:09<03:17, 437.20frames/s]\n 84%|████████▍ | 445310/528994 [19:16<03:24, 409.33frames/s]\n 85%|████████▍ | 448286/528994 [19:25<03:29, 385.79frames/s]\n 85%|████████▌ | 451286/528994 [19:31<03:06, 415.70frames/s]\n 86%|████████▌ | 454286/528994 [19:40<03:10, 392.19frames/s]\n 86%|████████▋ | 456278/528994 [19:45<03:09, 384.47frames/s]\n 87%|████████▋ | 459090/528994 [19:51<02:48, 414.23frames/s]\n 87%|████████▋ | 461938/528994 [19:59<02:48, 397.37frames/s]\n 88%|████████▊ | 464890/528994 [20:06<02:42, 393.97frames/s]\n 88%|████████▊ | 467698/528994 [20:16<02:51, 356.53frames/s]\n 89%|████████▉ | 470590/528994 [20:25<02:46, 349.84frames/s]\n 90%|████████▉ | 473562/528994 [20:33<02:40, 346.05frames/s]\n 90%|█████████ | 476474/528994 [20:41<02:25, 359.83frames/s]\n 91%|█████████ | 479294/528994 [20:47<02:11, 378.68frames/s]\n 91%|█████████ | 482074/528994 [20:54<02:01, 386.69frames/s]\n 92%|█████████▏| 485006/528994 [21:03<01:58, 369.72frames/s]\n 92%|█████████▏| 487514/528994 [21:10<01:53, 364.47frames/s]\n 93%|█████████▎| 490306/528994 [21:18<01:46, 363.65frames/s]\n 93%|█████████▎| 493160/528994 [21:25<01:36, 371.37frames/s]\n 94%|█████████▎| 495864/528994 [21:34<01:35, 346.97frames/s]\n 94%|█████████▍| 498548/528994 [21:40<01:22, 368.59frames/s]\n 95%|█████████▍| 501408/528994 [21:49<01:17, 355.18frames/s]\n 95%|█████████▌| 504260/528994 [21:57<01:10, 352.00frames/s]\n 96%|█████████▌| 507236/528994 [22:05<01:00, 360.85frames/s]\n 96%|█████████▋| 510184/528994 [22:16<00:57, 326.07frames/s]\n 97%|█████████▋| 513160/528994 [22:25<00:48, 329.81frames/s]\n 97%|█████████▋| 515378/528994 [22:32<00:42, 321.70frames/s]\n 98%|█████████▊| 517978/528994 [22:38<00:31, 344.65frames/s]\n 98%|█████████▊| 520930/528994 [22:48<00:24, 334.85frames/s]\n 99%|█████████▉| 523906/528994 [22:57<00:15, 328.90frames/s]\n100%|█████████▉| 526758/528994 [23:05<00:06, 333.88frames/s]\n100%|██████████| 528994/528994 [23:12<00:00, 336.49frames/s]\n100%|██████████| 528994/528994 [23:12<00:00, 379.94frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.5967858632405599,
        "compression_ratio": 0.9344262295081968,
        "end": 29.96,
        "id": 0,
        "no_speech_prob": 0.5532964468002319,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " Did you think that learning coding would be really rough?",
        "tokens": [
          50364,
          2589,
          291,
          519,
          300,
          2539,
          17720,
          576,
          312,
          534,
          5903,
          30,
          51862
        ]
      },
      {
        "avg_logprob": -0.4487396876017253,
        "compression_ratio": 1.5371428571428571,
        "end": 33.32,
        "id": 1,
        "no_speech_prob": 0.1731651872396469,
        "seek": 2996,
        "start": 29.96,
        "temperature": 0,
        "text": " Throw your hands up in the air and say enough's enough!",
        "tokens": [
          50364,
          22228,
          428,
          2377,
          493,
          294,
          264,
          1988,
          293,
          584,
          1547,
          311,
          1547,
          0,
          50532
        ]
      },
      {
        "avg_logprob": -0.4487396876017253,
        "compression_ratio": 1.5371428571428571,
        "end": 36.36,
        "id": 2,
        "no_speech_prob": 0.1731651872396469,
        "seek": 2996,
        "start": 33.32,
        "temperature": 0,
        "text": " Do you want to learn to code and make some awesome stuff?",
        "tokens": [
          50532,
          1144,
          291,
          528,
          281,
          1466,
          281,
          3089,
          293,
          652,
          512,
          3476,
          1507,
          30,
          50684
        ]
      },
      {
        "avg_logprob": -0.4487396876017253,
        "compression_ratio": 1.5371428571428571,
        "end": 46.519999999999996,
        "id": 3,
        "no_speech_prob": 0.1731651872396469,
        "seek": 2996,
        "start": 36.36,
        "temperature": 0,
        "text": " Learn that anyone can when you're coding with Dan on!",
        "tokens": [
          50684,
          17216,
          300,
          2878,
          393,
          562,
          291,
          434,
          17720,
          365,
          3394,
          322,
          0,
          51192
        ]
      },
      {
        "avg_logprob": -0.4487396876017253,
        "compression_ratio": 1.5371428571428571,
        "end": 52.519999999999996,
        "id": 4,
        "no_speech_prob": 0.1731651872396469,
        "seek": 2996,
        "start": 46.519999999999996,
        "temperature": 0,
        "text": " Whether you're a pro or this is all brand new,",
        "tokens": [
          51192,
          8503,
          291,
          434,
          257,
          447,
          420,
          341,
          307,
          439,
          3360,
          777,
          11,
          51492
        ]
      },
      {
        "avg_logprob": -0.4487396876017253,
        "compression_ratio": 1.5371428571428571,
        "end": 55.64,
        "id": 5,
        "no_speech_prob": 0.1731651872396469,
        "seek": 2996,
        "start": 52.519999999999996,
        "temperature": 0,
        "text": " Learn the overarching concepts and some fun stuff too!",
        "tokens": [
          51492,
          17216,
          264,
          45501,
          10392,
          293,
          512,
          1019,
          1507,
          886,
          0,
          51648
        ]
      },
      {
        "avg_logprob": -0.22230678692198635,
        "compression_ratio": 1.71900826446281,
        "end": 61.96,
        "id": 6,
        "no_speech_prob": 0.02128417417407036,
        "seek": 5564,
        "start": 55.64,
        "temperature": 0,
        "text": " And with Dan as your guide, come along for the ride on!",
        "tokens": [
          50364,
          400,
          365,
          3394,
          382,
          428,
          5934,
          11,
          808,
          2051,
          337,
          264,
          5077,
          322,
          0,
          50680
        ]
      },
      {
        "avg_logprob": -0.22230678692198635,
        "compression_ratio": 1.71900826446281,
        "end": 65.24,
        "id": 7,
        "no_speech_prob": 0.02128417417407036,
        "seek": 5564,
        "start": 61.96,
        "temperature": 0,
        "text": " Make a crazy pixel mirror to reflect your face,",
        "tokens": [
          50680,
          4387,
          257,
          3219,
          19261,
          8013,
          281,
          5031,
          428,
          1851,
          11,
          50844
        ]
      },
      {
        "avg_logprob": -0.22230678692198635,
        "compression_ratio": 1.71900826446281,
        "end": 68.44,
        "id": 8,
        "no_speech_prob": 0.02128417417407036,
        "seek": 5564,
        "start": 65.24,
        "temperature": 0,
        "text": " You can make a jump to light speed into outer space,",
        "tokens": [
          50844,
          509,
          393,
          652,
          257,
          3012,
          281,
          1442,
          3073,
          666,
          10847,
          1901,
          11,
          51004
        ]
      },
      {
        "avg_logprob": -0.22230678692198635,
        "compression_ratio": 1.71900826446281,
        "end": 71.64,
        "id": 9,
        "no_speech_prob": 0.02128417417407036,
        "seek": 5564,
        "start": 68.44,
        "temperature": 0,
        "text": " You can generate a maze that can go on for days,",
        "tokens": [
          51004,
          509,
          393,
          8460,
          257,
          33032,
          300,
          393,
          352,
          322,
          337,
          1708,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.22230678692198635,
        "compression_ratio": 1.71900826446281,
        "end": 74.84,
        "id": 10,
        "no_speech_prob": 0.02128417417407036,
        "seek": 5564,
        "start": 71.64,
        "temperature": 0,
        "text": " You can make your own terrain and some purple rain,",
        "tokens": [
          51164,
          509,
          393,
          652,
          428,
          1065,
          17674,
          293,
          512,
          9656,
          4830,
          11,
          51324
        ]
      },
      {
        "avg_logprob": -0.22230678692198635,
        "compression_ratio": 1.71900826446281,
        "end": 78.04,
        "id": 11,
        "no_speech_prob": 0.02128417417407036,
        "seek": 5564,
        "start": 74.84,
        "temperature": 0,
        "text": " You can make a retro game to see how it's done,",
        "tokens": [
          51324,
          509,
          393,
          652,
          257,
          18820,
          1216,
          281,
          536,
          577,
          309,
          311,
          1096,
          11,
          51484
        ]
      },
      {
        "avg_logprob": -0.22230678692198635,
        "compression_ratio": 1.71900826446281,
        "end": 81.24000000000001,
        "id": 12,
        "no_speech_prob": 0.02128417417407036,
        "seek": 5564,
        "start": 78.04,
        "temperature": 0,
        "text": " And then tweak a piece to make it yours for everyone,",
        "tokens": [
          51484,
          400,
          550,
          29879,
          257,
          2522,
          281,
          652,
          309,
          6342,
          337,
          1518,
          11,
          51644
        ]
      },
      {
        "avg_logprob": -0.22230678692198635,
        "compression_ratio": 1.71900826446281,
        "end": 84.28,
        "id": 13,
        "no_speech_prob": 0.02128417417407036,
        "seek": 5564,
        "start": 81.24000000000001,
        "temperature": 0,
        "text": " Make some fractally trees or twitter bots if you please,",
        "tokens": [
          51644,
          4387,
          512,
          17948,
          379,
          5852,
          420,
          21439,
          35410,
          498,
          291,
          1767,
          11,
          51796
        ]
      },
      {
        "avg_logprob": -0.3760248729160854,
        "compression_ratio": 1.2637362637362637,
        "end": 94.04,
        "id": 14,
        "no_speech_prob": 0.06460344046354294,
        "seek": 8428,
        "start": 84.28,
        "temperature": 0,
        "text": " And when the seeds are all sown, you can make them your own!",
        "tokens": [
          50364,
          400,
          562,
          264,
          9203,
          366,
          439,
          262,
          648,
          11,
          291,
          393,
          652,
          552,
          428,
          1065,
          0,
          50852
        ]
      },
      {
        "avg_logprob": -0.3760248729160854,
        "compression_ratio": 1.2637362637362637,
        "end": 110.6,
        "id": 15,
        "no_speech_prob": 0.06460344046354294,
        "seek": 8428,
        "start": 94.04,
        "temperature": 0,
        "text": " Write the colors of code, you can follow the road too!",
        "tokens": [
          50852,
          23499,
          264,
          4577,
          295,
          3089,
          11,
          291,
          393,
          1524,
          264,
          3060,
          886,
          0,
          51680
        ]
      },
      {
        "avg_logprob": -0.2588593346732003,
        "compression_ratio": 1.6923076923076923,
        "end": 114.11999999999999,
        "id": 16,
        "no_speech_prob": 0.8382942080497742,
        "seek": 11060,
        "start": 110.6,
        "temperature": 0,
        "text": " Hello! Ah, okay, hello! I think I'm broadcasting live.",
        "tokens": [
          50364,
          2425,
          0,
          2438,
          11,
          1392,
          11,
          7751,
          0,
          286,
          519,
          286,
          478,
          30024,
          1621,
          13,
          50540
        ]
      },
      {
        "avg_logprob": -0.2588593346732003,
        "compression_ratio": 1.6923076923076923,
        "end": 117.96,
        "id": 17,
        "no_speech_prob": 0.8382942080497742,
        "seek": 11060,
        "start": 114.11999999999999,
        "temperature": 0,
        "text": " I had the microphone muted, which I often do while I'm getting set up",
        "tokens": [
          50540,
          286,
          632,
          264,
          10952,
          32808,
          11,
          597,
          286,
          2049,
          360,
          1339,
          286,
          478,
          1242,
          992,
          493,
          50732
        ]
      },
      {
        "avg_logprob": -0.2588593346732003,
        "compression_ratio": 1.6923076923076923,
        "end": 122.67999999999999,
        "id": 18,
        "no_speech_prob": 0.8382942080497742,
        "seek": 11060,
        "start": 117.96,
        "temperature": 0,
        "text": " to not record myself by accident, but I would like to hear from the chat.",
        "tokens": [
          50732,
          281,
          406,
          2136,
          2059,
          538,
          6398,
          11,
          457,
          286,
          576,
          411,
          281,
          1568,
          490,
          264,
          5081,
          13,
          50968
        ]
      },
      {
        "avg_logprob": -0.2588593346732003,
        "compression_ratio": 1.6923076923076923,
        "end": 126.75999999999999,
        "id": 19,
        "no_speech_prob": 0.8382942080497742,
        "seek": 11060,
        "start": 122.67999999999999,
        "temperature": 0,
        "text": " I know I've been sort of on a big delay today, so I would like to hear in the chat.",
        "tokens": [
          50968,
          286,
          458,
          286,
          600,
          668,
          1333,
          295,
          322,
          257,
          955,
          8577,
          965,
          11,
          370,
          286,
          576,
          411,
          281,
          1568,
          294,
          264,
          5081,
          13,
          51172
        ]
      },
      {
        "avg_logprob": -0.2588593346732003,
        "compression_ratio": 1.6923076923076923,
        "end": 130.84,
        "id": 20,
        "no_speech_prob": 0.8382942080497742,
        "seek": 11060,
        "start": 126.75999999999999,
        "temperature": 0,
        "text": " So I don't know how many people are there, because I'm kind of much",
        "tokens": [
          51172,
          407,
          286,
          500,
          380,
          458,
          577,
          867,
          561,
          366,
          456,
          11,
          570,
          286,
          478,
          733,
          295,
          709,
          51376
        ]
      },
      {
        "avg_logprob": -0.2588593346732003,
        "compression_ratio": 1.6923076923076923,
        "end": 135.07999999999998,
        "id": 21,
        "no_speech_prob": 0.8382942080497742,
        "seek": 11060,
        "start": 130.84,
        "temperature": 0,
        "text": " later than I said I would originally be, but if the sound is working, if you can",
        "tokens": [
          51376,
          1780,
          813,
          286,
          848,
          286,
          576,
          7993,
          312,
          11,
          457,
          498,
          264,
          1626,
          307,
          1364,
          11,
          498,
          291,
          393,
          51588
        ]
      },
      {
        "avg_logprob": -0.2588593346732003,
        "compression_ratio": 1.6923076923076923,
        "end": 138.35999999999999,
        "id": 22,
        "no_speech_prob": 0.8382942080497742,
        "seek": 11060,
        "start": 135.07999999999998,
        "temperature": 0,
        "text": " hear me and see me okay. Otherwise I'm going to kind of get started rather",
        "tokens": [
          51588,
          1568,
          385,
          293,
          536,
          385,
          1392,
          13,
          10328,
          286,
          478,
          516,
          281,
          733,
          295,
          483,
          1409,
          2831,
          51752
        ]
      },
      {
        "avg_logprob": -0.190660037691631,
        "compression_ratio": 1.6666666666666667,
        "end": 143,
        "id": 23,
        "no_speech_prob": 0.0367533415555954,
        "seek": 13836,
        "start": 138.36,
        "temperature": 0,
        "text": " quickly. I'm going to try to forego all of my introductory stuff beyond",
        "tokens": [
          50364,
          2661,
          13,
          286,
          478,
          516,
          281,
          853,
          281,
          2091,
          1571,
          439,
          295,
          452,
          39048,
          1507,
          4399,
          50596
        ]
      },
      {
        "avg_logprob": -0.190660037691631,
        "compression_ratio": 1.6666666666666667,
        "end": 146.84,
        "id": 24,
        "no_speech_prob": 0.0367533415555954,
        "seek": 13836,
        "start": 143,
        "temperature": 0,
        "text": " two or three sentences. So please, if you are actually watching this live",
        "tokens": [
          50596,
          732,
          420,
          1045,
          16579,
          13,
          407,
          1767,
          11,
          498,
          291,
          366,
          767,
          1976,
          341,
          1621,
          50788
        ]
      },
      {
        "avg_logprob": -0.190660037691631,
        "compression_ratio": 1.6666666666666667,
        "end": 150.12,
        "id": 25,
        "no_speech_prob": 0.0367533415555954,
        "seek": 13836,
        "start": 146.84,
        "temperature": 0,
        "text": " and you can hear me and there's no static and the sound seems fine,",
        "tokens": [
          50788,
          293,
          291,
          393,
          1568,
          385,
          293,
          456,
          311,
          572,
          13437,
          293,
          264,
          1626,
          2544,
          2489,
          11,
          50952
        ]
      },
      {
        "avg_logprob": -0.190660037691631,
        "compression_ratio": 1.6666666666666667,
        "end": 154.04000000000002,
        "id": 26,
        "no_speech_prob": 0.0367533415555954,
        "seek": 13836,
        "start": 150.12,
        "temperature": 0,
        "text": " please let me know in the chat. I don't see a single message in the chat,",
        "tokens": [
          50952,
          1767,
          718,
          385,
          458,
          294,
          264,
          5081,
          13,
          286,
          500,
          380,
          536,
          257,
          2167,
          3636,
          294,
          264,
          5081,
          11,
          51148
        ]
      },
      {
        "avg_logprob": -0.190660037691631,
        "compression_ratio": 1.6666666666666667,
        "end": 157.4,
        "id": 27,
        "no_speech_prob": 0.0367533415555954,
        "seek": 13836,
        "start": 154.04000000000002,
        "temperature": 0,
        "text": " so I'm just going to keep going. My name is Dan Schiffman.",
        "tokens": [
          51148,
          370,
          286,
          478,
          445,
          516,
          281,
          1066,
          516,
          13,
          1222,
          1315,
          307,
          3394,
          2065,
          3661,
          1601,
          13,
          51316
        ]
      },
      {
        "avg_logprob": -0.190660037691631,
        "compression_ratio": 1.6666666666666667,
        "end": 162.28000000000003,
        "id": 28,
        "no_speech_prob": 0.0367533415555954,
        "seek": 13836,
        "start": 157.4,
        "temperature": 0,
        "text": " This is a live stream that I do every week, typically Tuesday afternoons",
        "tokens": [
          51316,
          639,
          307,
          257,
          1621,
          4309,
          300,
          286,
          360,
          633,
          1243,
          11,
          5850,
          10017,
          934,
          1771,
          892,
          51560
        ]
      },
      {
        "avg_logprob": -0.190660037691631,
        "compression_ratio": 1.6666666666666667,
        "end": 165.72000000000003,
        "id": 29,
        "no_speech_prob": 0.0367533415555954,
        "seek": 13836,
        "start": 162.28000000000003,
        "temperature": 0,
        "text": " about creative coding, and creative coding is kind of a",
        "tokens": [
          51560,
          466,
          5880,
          17720,
          11,
          293,
          5880,
          17720,
          307,
          733,
          295,
          257,
          51732
        ]
      },
      {
        "avg_logprob": -0.20079887519448492,
        "compression_ratio": 1.641025641025641,
        "end": 172.6,
        "id": 30,
        "no_speech_prob": 0.004609285853803158,
        "seek": 16572,
        "start": 165.72,
        "temperature": 0,
        "text": " broad term, but to think about creative ways to... I'm still looking in the chat",
        "tokens": [
          50364,
          4152,
          1433,
          11,
          457,
          281,
          519,
          466,
          5880,
          2098,
          281,
          485,
          286,
          478,
          920,
          1237,
          294,
          264,
          5081,
          50708
        ]
      },
      {
        "avg_logprob": -0.20079887519448492,
        "compression_ratio": 1.641025641025641,
        "end": 175.88,
        "id": 31,
        "no_speech_prob": 0.004609285853803158,
        "seek": 16572,
        "start": 172.6,
        "temperature": 0,
        "text": " and I don't see a message. I feel like I'm just here by myself and",
        "tokens": [
          50708,
          293,
          286,
          500,
          380,
          536,
          257,
          3636,
          13,
          286,
          841,
          411,
          286,
          478,
          445,
          510,
          538,
          2059,
          293,
          50872
        ]
      },
      {
        "avg_logprob": -0.20079887519448492,
        "compression_ratio": 1.641025641025641,
        "end": 178.68,
        "id": 32,
        "no_speech_prob": 0.004609285853803158,
        "seek": 16572,
        "start": 175.88,
        "temperature": 0,
        "text": " there's no one out there in the world. I'm going to see if there's anyone...",
        "tokens": [
          50872,
          456,
          311,
          572,
          472,
          484,
          456,
          294,
          264,
          1002,
          13,
          286,
          478,
          516,
          281,
          536,
          498,
          456,
          311,
          2878,
          485,
          51012
        ]
      },
      {
        "avg_logprob": -0.20079887519448492,
        "compression_ratio": 1.641025641025641,
        "end": 181.88,
        "id": 33,
        "no_speech_prob": 0.004609285853803158,
        "seek": 16572,
        "start": 178.68,
        "temperature": 0,
        "text": " It does say 73 people are watching, which is kind of unbelievable.",
        "tokens": [
          51012,
          467,
          775,
          584,
          28387,
          561,
          366,
          1976,
          11,
          597,
          307,
          733,
          295,
          16605,
          13,
          51172
        ]
      },
      {
        "avg_logprob": -0.20079887519448492,
        "compression_ratio": 1.641025641025641,
        "end": 187,
        "id": 34,
        "no_speech_prob": 0.004609285853803158,
        "seek": 16572,
        "start": 181.88,
        "temperature": 0,
        "text": " Okay, I'm still keeping an eye on the chat. So I do a lot of different topics",
        "tokens": [
          51172,
          1033,
          11,
          286,
          478,
          920,
          5145,
          364,
          3313,
          322,
          264,
          5081,
          13,
          407,
          286,
          360,
          257,
          688,
          295,
          819,
          8378,
          51428
        ]
      },
      {
        "avg_logprob": -0.20079887519448492,
        "compression_ratio": 1.641025641025641,
        "end": 193.72,
        "id": 35,
        "no_speech_prob": 0.004609285853803158,
        "seek": 16572,
        "start": 187,
        "temperature": 0,
        "text": " from animation and physics simulation, but this fall I have been going through",
        "tokens": [
          51428,
          490,
          9603,
          293,
          10649,
          16575,
          11,
          457,
          341,
          2100,
          286,
          362,
          668,
          516,
          807,
          51764
        ]
      },
      {
        "avg_logprob": -0.19239726211085464,
        "compression_ratio": 1.549800796812749,
        "end": 198.04,
        "id": 36,
        "no_speech_prob": 0.07693753391504288,
        "seek": 19372,
        "start": 193.72,
        "temperature": 0,
        "text": " a series of video tutorials all about programming with text,",
        "tokens": [
          50364,
          257,
          2638,
          295,
          960,
          17616,
          439,
          466,
          9410,
          365,
          2487,
          11,
          50580
        ]
      },
      {
        "avg_logprob": -0.19239726211085464,
        "compression_ratio": 1.549800796812749,
        "end": 200.92,
        "id": 37,
        "no_speech_prob": 0.07693753391504288,
        "seek": 19372,
        "start": 198.04,
        "temperature": 0,
        "text": " generating text, analyzing text, that type of thing.",
        "tokens": [
          50580,
          17746,
          2487,
          11,
          23663,
          2487,
          11,
          300,
          2010,
          295,
          551,
          13,
          50724
        ]
      },
      {
        "avg_logprob": -0.19239726211085464,
        "compression_ratio": 1.549800796812749,
        "end": 207.32,
        "id": 38,
        "no_speech_prob": 0.07693753391504288,
        "seek": 19372,
        "start": 200.92,
        "temperature": 0,
        "text": " If you would like to know more or I just want to point you out to",
        "tokens": [
          50724,
          759,
          291,
          576,
          411,
          281,
          458,
          544,
          420,
          286,
          445,
          528,
          281,
          935,
          291,
          484,
          281,
          51044
        ]
      },
      {
        "avg_logprob": -0.19239726211085464,
        "compression_ratio": 1.549800796812749,
        "end": 212.76,
        "id": 39,
        "no_speech_prob": 0.07693753391504288,
        "seek": 19372,
        "start": 207.32,
        "temperature": 0,
        "text": " a couple resources, codingrainbow.com, you can subscribe.",
        "tokens": [
          51044,
          257,
          1916,
          3593,
          11,
          17720,
          7146,
          8202,
          13,
          1112,
          11,
          291,
          393,
          3022,
          13,
          51316
        ]
      },
      {
        "avg_logprob": -0.19239726211085464,
        "compression_ratio": 1.549800796812749,
        "end": 216.84,
        "id": 40,
        "no_speech_prob": 0.07693753391504288,
        "seek": 19372,
        "start": 212.76,
        "temperature": 0,
        "text": " There is also... I have a Patreon running, which is a way that you can fund",
        "tokens": [
          51316,
          821,
          307,
          611,
          485,
          286,
          362,
          257,
          15692,
          2614,
          11,
          597,
          307,
          257,
          636,
          300,
          291,
          393,
          2374,
          51520
        ]
      },
      {
        "avg_logprob": -0.19239726211085464,
        "compression_ratio": 1.549800796812749,
        "end": 220.84,
        "id": 41,
        "no_speech_prob": 0.07693753391504288,
        "seek": 19372,
        "start": 216.84,
        "temperature": 0,
        "text": " what I'm doing and get membership into a Slack channel for more discussion,",
        "tokens": [
          51520,
          437,
          286,
          478,
          884,
          293,
          483,
          16560,
          666,
          257,
          37211,
          2269,
          337,
          544,
          5017,
          11,
          51720
        ]
      },
      {
        "avg_logprob": -0.2158808117070474,
        "compression_ratio": 1.6555555555555554,
        "end": 225,
        "id": 42,
        "no_speech_prob": 0.022970421239733696,
        "seek": 22084,
        "start": 220.84,
        "temperature": 0,
        "text": " and I do send out email announcements when I'm doing the live streams here as well.",
        "tokens": [
          50364,
          293,
          286,
          360,
          2845,
          484,
          3796,
          23785,
          562,
          286,
          478,
          884,
          264,
          1621,
          15842,
          510,
          382,
          731,
          13,
          50572
        ]
      },
      {
        "avg_logprob": -0.2158808117070474,
        "compression_ratio": 1.6555555555555554,
        "end": 227.56,
        "id": 43,
        "no_speech_prob": 0.022970421239733696,
        "seek": 22084,
        "start": 225,
        "temperature": 0,
        "text": " So I encourage you to sign up for any of those things.",
        "tokens": [
          50572,
          407,
          286,
          5373,
          291,
          281,
          1465,
          493,
          337,
          604,
          295,
          729,
          721,
          13,
          50700
        ]
      },
      {
        "avg_logprob": -0.2158808117070474,
        "compression_ratio": 1.6555555555555554,
        "end": 230.12,
        "id": 44,
        "no_speech_prob": 0.022970421239733696,
        "seek": 22084,
        "start": 227.56,
        "temperature": 0,
        "text": " I still don't see a single message in the chat.",
        "tokens": [
          50700,
          286,
          920,
          500,
          380,
          536,
          257,
          2167,
          3636,
          294,
          264,
          5081,
          13,
          50828
        ]
      },
      {
        "avg_logprob": -0.2158808117070474,
        "compression_ratio": 1.6555555555555554,
        "end": 237.64000000000001,
        "id": 45,
        "no_speech_prob": 0.022970421239733696,
        "seek": 22084,
        "start": 230.12,
        "temperature": 0,
        "text": " It's just kind of disturbing me. I'm going to have to tweet because...",
        "tokens": [
          50828,
          467,
          311,
          445,
          733,
          295,
          21903,
          385,
          13,
          286,
          478,
          516,
          281,
          362,
          281,
          15258,
          570,
          485,
          51204
        ]
      },
      {
        "avg_logprob": -0.2158808117070474,
        "compression_ratio": 1.6555555555555554,
        "end": 240.44,
        "id": 46,
        "no_speech_prob": 0.022970421239733696,
        "seek": 22084,
        "start": 237.64000000000001,
        "temperature": 0,
        "text": " Maybe I'm going to reload my preview here because I just want to make sure",
        "tokens": [
          51204,
          2704,
          286,
          478,
          516,
          281,
          25628,
          452,
          14281,
          510,
          570,
          286,
          445,
          528,
          281,
          652,
          988,
          51344
        ]
      },
      {
        "avg_logprob": -0.2158808117070474,
        "compression_ratio": 1.6555555555555554,
        "end": 244.04,
        "id": 47,
        "no_speech_prob": 0.022970421239733696,
        "seek": 22084,
        "start": 240.44,
        "temperature": 0,
        "text": " this is working and I'm not talking to no one in thin air.",
        "tokens": [
          51344,
          341,
          307,
          1364,
          293,
          286,
          478,
          406,
          1417,
          281,
          572,
          472,
          294,
          5862,
          1988,
          13,
          51524
        ]
      },
      {
        "avg_logprob": -0.2158808117070474,
        "compression_ratio": 1.6555555555555554,
        "end": 246.68,
        "id": 48,
        "no_speech_prob": 0.022970421239733696,
        "seek": 22084,
        "start": 244.04,
        "temperature": 0,
        "text": " So I'm going to... It does say 100 people are watching.",
        "tokens": [
          51524,
          407,
          286,
          478,
          516,
          281,
          485,
          467,
          775,
          584,
          2319,
          561,
          366,
          1976,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.18703853309928598,
        "compression_ratio": 1.5058823529411764,
        "end": 251.32,
        "id": 49,
        "no_speech_prob": 0.0041985176503658295,
        "seek": 24668,
        "start": 246.68,
        "temperature": 0,
        "text": " I'm going to refresh my dashboard and see if anyone comes.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          15134,
          452,
          18342,
          293,
          536,
          498,
          2878,
          1487,
          13,
          50596
        ]
      },
      {
        "avg_logprob": -0.18703853309928598,
        "compression_ratio": 1.5058823529411764,
        "end": 254.04000000000002,
        "id": 50,
        "no_speech_prob": 0.0041985176503658295,
        "seek": 24668,
        "start": 251.32,
        "temperature": 0,
        "text": " Ah! Now I see all sorts of messages.",
        "tokens": [
          50596,
          2438,
          0,
          823,
          286,
          536,
          439,
          7527,
          295,
          7897,
          13,
          50732
        ]
      },
      {
        "avg_logprob": -0.18703853309928598,
        "compression_ratio": 1.5058823529411764,
        "end": 259.48,
        "id": 51,
        "no_speech_prob": 0.0041985176503658295,
        "seek": 24668,
        "start": 254.04000000000002,
        "temperature": 0,
        "text": " So somehow the chat had gotten stuck.",
        "tokens": [
          50732,
          407,
          6063,
          264,
          5081,
          632,
          5768,
          5541,
          13,
          51004
        ]
      },
      {
        "avg_logprob": -0.18703853309928598,
        "compression_ratio": 1.5058823529411764,
        "end": 262.44,
        "id": 52,
        "no_speech_prob": 0.0041985176503658295,
        "seek": 24668,
        "start": 260.04,
        "temperature": 0,
        "text": " Okay. So now I see there are a ton of messages.",
        "tokens": [
          51032,
          1033,
          13,
          407,
          586,
          286,
          536,
          456,
          366,
          257,
          2952,
          295,
          7897,
          13,
          51152
        ]
      },
      {
        "avg_logprob": -0.18703853309928598,
        "compression_ratio": 1.5058823529411764,
        "end": 265,
        "id": 53,
        "no_speech_prob": 0.0041985176503658295,
        "seek": 24668,
        "start": 263.48,
        "temperature": 0,
        "text": " So much for my awkward opening.",
        "tokens": [
          51204,
          407,
          709,
          337,
          452,
          11411,
          5193,
          13,
          51280
        ]
      },
      {
        "avg_logprob": -0.18703853309928598,
        "compression_ratio": 1.5058823529411764,
        "end": 267.08,
        "id": 54,
        "no_speech_prob": 0.0041985176503658295,
        "seek": 24668,
        "start": 265,
        "temperature": 0,
        "text": " All right. So what am I going to do today?",
        "tokens": [
          51280,
          1057,
          558,
          13,
          407,
          437,
          669,
          286,
          516,
          281,
          360,
          965,
          30,
          51384
        ]
      },
      {
        "avg_logprob": -0.18173392800723806,
        "compression_ratio": 1.4975124378109452,
        "end": 277.32,
        "id": 55,
        "no_speech_prob": 0.0015730258310213685,
        "seek": 26708,
        "start": 267.08,
        "temperature": 0,
        "text": " So topic-wise, I am here, and it says week 9 here on this syllabus,",
        "tokens": [
          50364,
          407,
          4829,
          12,
          3711,
          11,
          286,
          669,
          510,
          11,
          293,
          309,
          1619,
          1243,
          1722,
          510,
          322,
          341,
          48077,
          11,
          50876
        ]
      },
      {
        "avg_logprob": -0.18173392800723806,
        "compression_ratio": 1.4975124378109452,
        "end": 279.32,
        "id": 56,
        "no_speech_prob": 0.0015730258310213685,
        "seek": 26708,
        "start": 277.32,
        "temperature": 0,
        "text": " but really I'm on session 8.",
        "tokens": [
          50876,
          457,
          534,
          286,
          478,
          322,
          5481,
          1649,
          13,
          50976
        ]
      },
      {
        "avg_logprob": -0.18173392800723806,
        "compression_ratio": 1.4975124378109452,
        "end": 284.59999999999997,
        "id": 57,
        "no_speech_prob": 0.0015730258310213685,
        "seek": 26708,
        "start": 279.32,
        "temperature": 0,
        "text": " And so the topic for today is how to build your own API in Node.",
        "tokens": [
          50976,
          400,
          370,
          264,
          4829,
          337,
          965,
          307,
          577,
          281,
          1322,
          428,
          1065,
          9362,
          294,
          38640,
          13,
          51240
        ]
      },
      {
        "avg_logprob": -0.18173392800723806,
        "compression_ratio": 1.4975124378109452,
        "end": 290.84,
        "id": 58,
        "no_speech_prob": 0.0015730258310213685,
        "seek": 26708,
        "start": 284.59999999999997,
        "temperature": 0,
        "text": " So if you have been following this course over however many weeks I've been doing it,",
        "tokens": [
          51240,
          407,
          498,
          291,
          362,
          668,
          3480,
          341,
          1164,
          670,
          4461,
          867,
          3259,
          286,
          600,
          668,
          884,
          309,
          11,
          51552
        ]
      },
      {
        "avg_logprob": -0.18173392800723806,
        "compression_ratio": 1.4975124378109452,
        "end": 294.28,
        "id": 59,
        "no_speech_prob": 0.0015730258310213685,
        "seek": 26708,
        "start": 290.84,
        "temperature": 0,
        "text": " I spent a week looking at working with data and APIs.",
        "tokens": [
          51552,
          286,
          4418,
          257,
          1243,
          1237,
          412,
          1364,
          365,
          1412,
          293,
          21445,
          13,
          51724
        ]
      },
      {
        "avg_logprob": -0.2000546542080966,
        "compression_ratio": 1.6962025316455696,
        "end": 299.55999999999995,
        "id": 60,
        "no_speech_prob": 0.0003006035985890776,
        "seek": 29428,
        "start": 294.35999999999996,
        "temperature": 0,
        "text": " So, for example, how to grab dictionary information from an API called Wordnik,",
        "tokens": [
          50368,
          407,
          11,
          337,
          1365,
          11,
          577,
          281,
          4444,
          25890,
          1589,
          490,
          364,
          9362,
          1219,
          8725,
          13123,
          11,
          50628
        ]
      },
      {
        "avg_logprob": -0.2000546542080966,
        "compression_ratio": 1.6962025316455696,
        "end": 301.96,
        "id": 61,
        "no_speech_prob": 0.0003006035985890776,
        "seek": 29428,
        "start": 299.55999999999995,
        "temperature": 0,
        "text": " how to get news articles from an API called New York Times...",
        "tokens": [
          50628,
          577,
          281,
          483,
          2583,
          11290,
          490,
          364,
          9362,
          1219,
          1873,
          3609,
          11366,
          485,
          50748
        ]
      },
      {
        "avg_logprob": -0.2000546542080966,
        "compression_ratio": 1.6962025316455696,
        "end": 303.88,
        "id": 62,
        "no_speech_prob": 0.0003006035985890776,
        "seek": 29428,
        "start": 302.67999999999995,
        "temperature": 0,
        "text": " API called New York Times.",
        "tokens": [
          50784,
          9362,
          1219,
          1873,
          3609,
          11366,
          13,
          50844
        ]
      },
      {
        "avg_logprob": -0.2000546542080966,
        "compression_ratio": 1.6962025316455696,
        "end": 309.47999999999996,
        "id": 63,
        "no_speech_prob": 0.0003006035985890776,
        "seek": 29428,
        "start": 304.91999999999996,
        "temperature": 0,
        "text": " But what if you have data and you want to expose that data to other people?",
        "tokens": [
          50896,
          583,
          437,
          498,
          291,
          362,
          1412,
          293,
          291,
          528,
          281,
          19219,
          300,
          1412,
          281,
          661,
          561,
          30,
          51124
        ]
      },
      {
        "avg_logprob": -0.2000546542080966,
        "compression_ratio": 1.6962025316455696,
        "end": 315.32,
        "id": 64,
        "no_speech_prob": 0.0003006035985890776,
        "seek": 29428,
        "start": 309.47999999999996,
        "temperature": 0,
        "text": " Or what if you want to collect data and then make that data open?",
        "tokens": [
          51124,
          1610,
          437,
          498,
          291,
          528,
          281,
          2500,
          1412,
          293,
          550,
          652,
          300,
          1412,
          1269,
          30,
          51416
        ]
      },
      {
        "avg_logprob": -0.2000546542080966,
        "compression_ratio": 1.6962025316455696,
        "end": 317,
        "id": 65,
        "no_speech_prob": 0.0003006035985890776,
        "seek": 29428,
        "start": 315.32,
        "temperature": 0,
        "text": " So there are a variety of...",
        "tokens": [
          51416,
          407,
          456,
          366,
          257,
          5673,
          295,
          485,
          51500
        ]
      },
      {
        "avg_logprob": -0.2000546542080966,
        "compression_ratio": 1.6962025316455696,
        "end": 319.15999999999997,
        "id": 66,
        "no_speech_prob": 0.0003006035985890776,
        "seek": 29428,
        "start": 317,
        "temperature": 0,
        "text": " Okay. Possibilities. Hold on a second.",
        "tokens": [
          51500,
          1033,
          13,
          33112,
          8261,
          13,
          6962,
          322,
          257,
          1150,
          13,
          51608
        ]
      },
      {
        "avg_logprob": -0.2000546542080966,
        "compression_ratio": 1.6962025316455696,
        "end": 319.96,
        "id": 67,
        "no_speech_prob": 0.0003006035985890776,
        "seek": 29428,
        "start": 319.15999999999997,
        "temperature": 0,
        "text": " I'm going to have to...",
        "tokens": [
          51608,
          286,
          478,
          516,
          281,
          362,
          281,
          485,
          51648
        ]
      },
      {
        "avg_logprob": -0.1890987909140707,
        "compression_ratio": 1.684873949579832,
        "end": 321.96,
        "id": 68,
        "no_speech_prob": 0.05748014897108078,
        "seek": 31996,
        "start": 320.52,
        "temperature": 0,
        "text": " Please, if you can...",
        "tokens": [
          50392,
          2555,
          11,
          498,
          291,
          393,
          485,
          50464
        ]
      },
      {
        "avg_logprob": -0.1890987909140707,
        "compression_ratio": 1.684873949579832,
        "end": 329.32,
        "id": 69,
        "no_speech_prob": 0.05748014897108078,
        "seek": 31996,
        "start": 325.08,
        "temperature": 0,
        "text": " If you can try not to post the same message over and over and over again.",
        "tokens": [
          50620,
          759,
          291,
          393,
          853,
          406,
          281,
          2183,
          264,
          912,
          3636,
          670,
          293,
          670,
          293,
          670,
          797,
          13,
          50832
        ]
      },
      {
        "avg_logprob": -0.1890987909140707,
        "compression_ratio": 1.684873949579832,
        "end": 334.03999999999996,
        "id": 70,
        "no_speech_prob": 0.05748014897108078,
        "seek": 31996,
        "start": 331.88,
        "temperature": 0,
        "text": " Abby is asking if I can go over modularity,",
        "tokens": [
          50960,
          27726,
          307,
          3365,
          498,
          286,
          393,
          352,
          670,
          31111,
          507,
          11,
          51068
        ]
      },
      {
        "avg_logprob": -0.1890987909140707,
        "compression_ratio": 1.684873949579832,
        "end": 335.88,
        "id": 71,
        "no_speech_prob": 0.05748014897108078,
        "seek": 31996,
        "start": 334.03999999999996,
        "temperature": 0,
        "text": " which I don't know what that means specifically.",
        "tokens": [
          51068,
          597,
          286,
          500,
          380,
          458,
          437,
          300,
          1355,
          4682,
          13,
          51160
        ]
      },
      {
        "avg_logprob": -0.1890987909140707,
        "compression_ratio": 1.684873949579832,
        "end": 340.84,
        "id": 72,
        "no_speech_prob": 0.05748014897108078,
        "seek": 31996,
        "start": 335.88,
        "temperature": 0,
        "text": " But chat-wise, I can't catch every message in the chat,",
        "tokens": [
          51160,
          583,
          5081,
          12,
          3711,
          11,
          286,
          393,
          380,
          3745,
          633,
          3636,
          294,
          264,
          5081,
          11,
          51408
        ]
      },
      {
        "avg_logprob": -0.1890987909140707,
        "compression_ratio": 1.684873949579832,
        "end": 342.84,
        "id": 73,
        "no_speech_prob": 0.05748014897108078,
        "seek": 31996,
        "start": 340.84,
        "temperature": 0,
        "text": " but I do look at it periodically.",
        "tokens": [
          51408,
          457,
          286,
          360,
          574,
          412,
          309,
          38916,
          13,
          51508
        ]
      },
      {
        "avg_logprob": -0.1890987909140707,
        "compression_ratio": 1.684873949579832,
        "end": 345.88,
        "id": 74,
        "no_speech_prob": 0.05748014897108078,
        "seek": 31996,
        "start": 342.84,
        "temperature": 0,
        "text": " And I will try to answer them as I go.",
        "tokens": [
          51508,
          400,
          286,
          486,
          853,
          281,
          1867,
          552,
          382,
          286,
          352,
          13,
          51660
        ]
      },
      {
        "avg_logprob": -0.1890987909140707,
        "compression_ratio": 1.684873949579832,
        "end": 348.28,
        "id": 75,
        "no_speech_prob": 0.05748014897108078,
        "seek": 31996,
        "start": 345.88,
        "temperature": 0,
        "text": " Nikolai asks, what about the new channel name?",
        "tokens": [
          51660,
          13969,
          401,
          1301,
          8962,
          11,
          437,
          466,
          264,
          777,
          2269,
          1315,
          30,
          51780
        ]
      },
      {
        "avg_logprob": -0.1890987909140707,
        "compression_ratio": 1.684873949579832,
        "end": 349.71999999999997,
        "id": 76,
        "no_speech_prob": 0.05748014897108078,
        "seek": 31996,
        "start": 348.28,
        "temperature": 0,
        "text": " I don't have a new channel name yet.",
        "tokens": [
          51780,
          286,
          500,
          380,
          362,
          257,
          777,
          2269,
          1315,
          1939,
          13,
          51852
        ]
      },
      {
        "avg_logprob": -0.1901098839322427,
        "compression_ratio": 1.5993150684931507,
        "end": 355.23999999999995,
        "id": 77,
        "no_speech_prob": 0.00022692089260090142,
        "seek": 34996,
        "start": 350.35999999999996,
        "temperature": 0,
        "text": " I have to admit that things are just incredibly busy these days with the NYU semester.",
        "tokens": [
          50384,
          286,
          362,
          281,
          9796,
          300,
          721,
          366,
          445,
          6252,
          5856,
          613,
          1708,
          365,
          264,
          42682,
          11894,
          13,
          50628
        ]
      },
      {
        "avg_logprob": -0.1901098839322427,
        "compression_ratio": 1.5993150684931507,
        "end": 356.59999999999997,
        "id": 78,
        "no_speech_prob": 0.00022692089260090142,
        "seek": 34996,
        "start": 355.23999999999995,
        "temperature": 0,
        "text": " And I hope to...",
        "tokens": [
          50628,
          400,
          286,
          1454,
          281,
          485,
          50696
        ]
      },
      {
        "avg_logprob": -0.1901098839322427,
        "compression_ratio": 1.5993150684931507,
        "end": 362.12,
        "id": 79,
        "no_speech_prob": 0.00022692089260090142,
        "seek": 34996,
        "start": 356.59999999999997,
        "temperature": 0,
        "text": " I've been talking to some designers and coming up with different ideas and brainstorming things.",
        "tokens": [
          50696,
          286,
          600,
          668,
          1417,
          281,
          512,
          16196,
          293,
          1348,
          493,
          365,
          819,
          3487,
          293,
          35245,
          278,
          721,
          13,
          50972
        ]
      },
      {
        "avg_logprob": -0.1901098839322427,
        "compression_ratio": 1.5993150684931507,
        "end": 364.44,
        "id": 80,
        "no_speech_prob": 0.00022692089260090142,
        "seek": 34996,
        "start": 362.12,
        "temperature": 0,
        "text": " And I hope to have something by the end of the year.",
        "tokens": [
          50972,
          400,
          286,
          1454,
          281,
          362,
          746,
          538,
          264,
          917,
          295,
          264,
          1064,
          13,
          51088
        ]
      },
      {
        "avg_logprob": -0.1901098839322427,
        "compression_ratio": 1.5993150684931507,
        "end": 367.96,
        "id": 81,
        "no_speech_prob": 0.00022692089260090142,
        "seek": 34996,
        "start": 364.44,
        "temperature": 0,
        "text": " It's my goal and kind of relaunch in 2017 with a new name.",
        "tokens": [
          51088,
          467,
          311,
          452,
          3387,
          293,
          733,
          295,
          5195,
          1680,
          294,
          6591,
          365,
          257,
          777,
          1315,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1901098839322427,
        "compression_ratio": 1.5993150684931507,
        "end": 370.84,
        "id": 82,
        "no_speech_prob": 0.00022692089260090142,
        "seek": 34996,
        "start": 367.96,
        "temperature": 0,
        "text": " Yes, if it's hearts and rainbows, that you can spam.",
        "tokens": [
          51264,
          1079,
          11,
          498,
          309,
          311,
          8852,
          293,
          4830,
          21118,
          11,
          300,
          291,
          393,
          24028,
          13,
          51408
        ]
      },
      {
        "avg_logprob": -0.1901098839322427,
        "compression_ratio": 1.5993150684931507,
        "end": 374.52,
        "id": 83,
        "no_speech_prob": 0.00022692089260090142,
        "seek": 34996,
        "start": 372.59999999999997,
        "temperature": 0,
        "text": " And can you explain a REST API?",
        "tokens": [
          51496,
          400,
          393,
          291,
          2903,
          257,
          497,
          14497,
          9362,
          30,
          51592
        ]
      },
      {
        "avg_logprob": -0.1901098839322427,
        "compression_ratio": 1.5993150684931507,
        "end": 376.35999999999996,
        "id": 84,
        "no_speech_prob": 0.00022692089260090142,
        "seek": 34996,
        "start": 374.52,
        "temperature": 0,
        "text": " That is what I hope to do today.",
        "tokens": [
          51592,
          663,
          307,
          437,
          286,
          1454,
          281,
          360,
          965,
          13,
          51684
        ]
      },
      {
        "avg_logprob": -0.1901098839322427,
        "compression_ratio": 1.5993150684931507,
        "end": 378.67999999999995,
        "id": 85,
        "no_speech_prob": 0.00022692089260090142,
        "seek": 34996,
        "start": 376.35999999999996,
        "temperature": 0,
        "text": " Now, unfortunately, it's about 3.10.",
        "tokens": [
          51684,
          823,
          11,
          7015,
          11,
          309,
          311,
          466,
          805,
          13,
          3279,
          13,
          51800
        ]
      },
      {
        "avg_logprob": -0.2150371637237206,
        "compression_ratio": 1.4722222222222223,
        "end": 381.08,
        "id": 86,
        "no_speech_prob": 0.010488634929060936,
        "seek": 37868,
        "start": 378.68,
        "temperature": 0,
        "text": " I only have till 4.30 PM.",
        "tokens": [
          50364,
          286,
          787,
          362,
          4288,
          1017,
          13,
          3446,
          12499,
          13,
          50484
        ]
      },
      {
        "avg_logprob": -0.2150371637237206,
        "compression_ratio": 1.4722222222222223,
        "end": 381.8,
        "id": 87,
        "no_speech_prob": 0.010488634929060936,
        "seek": 37868,
        "start": 381.08,
        "temperature": 0,
        "text": " It's Eastern time.",
        "tokens": [
          50484,
          467,
          311,
          12901,
          565,
          13,
          50520
        ]
      },
      {
        "avg_logprob": -0.2150371637237206,
        "compression_ratio": 1.4722222222222223,
        "end": 383.64,
        "id": 88,
        "no_speech_prob": 0.010488634929060936,
        "seek": 37868,
        "start": 381.8,
        "temperature": 0,
        "text": " So I have about an hour and 20 minutes.",
        "tokens": [
          50520,
          407,
          286,
          362,
          466,
          364,
          1773,
          293,
          945,
          2077,
          13,
          50612
        ]
      },
      {
        "avg_logprob": -0.2150371637237206,
        "compression_ratio": 1.4722222222222223,
        "end": 386.6,
        "id": 89,
        "no_speech_prob": 0.010488634929060936,
        "seek": 37868,
        "start": 383.64,
        "temperature": 0,
        "text": " And I have this absurd list of topics.",
        "tokens": [
          50612,
          400,
          286,
          362,
          341,
          19774,
          1329,
          295,
          8378,
          13,
          50760
        ]
      },
      {
        "avg_logprob": -0.2150371637237206,
        "compression_ratio": 1.4722222222222223,
        "end": 392.2,
        "id": 90,
        "no_speech_prob": 0.010488634929060936,
        "seek": 37868,
        "start": 386.6,
        "temperature": 0,
        "text": " So I'm making a commitment to at some point making videos around all these things on this list.",
        "tokens": [
          50760,
          407,
          286,
          478,
          1455,
          257,
          8371,
          281,
          412,
          512,
          935,
          1455,
          2145,
          926,
          439,
          613,
          721,
          322,
          341,
          1329,
          13,
          51040
        ]
      },
      {
        "avg_logprob": -0.2150371637237206,
        "compression_ratio": 1.4722222222222223,
        "end": 399.64,
        "id": 91,
        "no_speech_prob": 0.010488634929060936,
        "seek": 37868,
        "start": 392.76,
        "temperature": 0,
        "text": " But today, I'll be happy if I can talk about the basics of using something called express in Node.",
        "tokens": [
          51068,
          583,
          965,
          11,
          286,
          603,
          312,
          2055,
          498,
          286,
          393,
          751,
          466,
          264,
          14688,
          295,
          1228,
          746,
          1219,
          5109,
          294,
          38640,
          13,
          51412
        ]
      },
      {
        "avg_logprob": -0.20939409451221858,
        "compression_ratio": 1.6014760147601477,
        "end": 409.24,
        "id": 92,
        "no_speech_prob": 0.11754180490970612,
        "seek": 39964,
        "start": 400.59999999999997,
        "temperature": 0,
        "text": " And as well as what a REST API is and how to set up a route to return information to somebody",
        "tokens": [
          50412,
          400,
          382,
          731,
          382,
          437,
          257,
          497,
          14497,
          9362,
          307,
          293,
          577,
          281,
          992,
          493,
          257,
          7955,
          281,
          2736,
          1589,
          281,
          2618,
          50844
        ]
      },
      {
        "avg_logprob": -0.20939409451221858,
        "compression_ratio": 1.6014760147601477,
        "end": 411,
        "id": 93,
        "no_speech_prob": 0.11754180490970612,
        "seek": 39964,
        "start": 409.24,
        "temperature": 0,
        "text": " who's querying that API.",
        "tokens": [
          50844,
          567,
          311,
          7083,
          1840,
          300,
          9362,
          13,
          50932
        ]
      },
      {
        "avg_logprob": -0.20939409451221858,
        "compression_ratio": 1.6014760147601477,
        "end": 415.96,
        "id": 94,
        "no_speech_prob": 0.11754180490970612,
        "seek": 39964,
        "start": 411,
        "temperature": 0,
        "text": " And then I would like to see if I can make a sentiment analysis API example.",
        "tokens": [
          50932,
          400,
          550,
          286,
          576,
          411,
          281,
          536,
          498,
          286,
          393,
          652,
          257,
          16149,
          5215,
          9362,
          1365,
          13,
          51180
        ]
      },
      {
        "avg_logprob": -0.20939409451221858,
        "compression_ratio": 1.6014760147601477,
        "end": 418.28,
        "id": 95,
        "no_speech_prob": 0.11754180490970612,
        "seek": 39964,
        "start": 415.96,
        "temperature": 0,
        "text": " Whoo, that's going to be difficult.",
        "tokens": [
          51180,
          23381,
          11,
          300,
          311,
          516,
          281,
          312,
          2252,
          13,
          51296
        ]
      },
      {
        "avg_logprob": -0.20939409451221858,
        "compression_ratio": 1.6014760147601477,
        "end": 420.03999999999996,
        "id": 96,
        "no_speech_prob": 0.11754180490970612,
        "seek": 39964,
        "start": 418.28,
        "temperature": 0,
        "text": " But that I'm so I'm just going to get started.",
        "tokens": [
          51296,
          583,
          300,
          286,
          478,
          370,
          286,
          478,
          445,
          516,
          281,
          483,
          1409,
          13,
          51384
        ]
      },
      {
        "avg_logprob": -0.20939409451221858,
        "compression_ratio": 1.6014760147601477,
        "end": 422.12,
        "id": 97,
        "no_speech_prob": 0.11754180490970612,
        "seek": 39964,
        "start": 420.76,
        "temperature": 0,
        "text": " This is what we're going to do today.",
        "tokens": [
          51420,
          639,
          307,
          437,
          321,
          434,
          516,
          281,
          360,
          965,
          13,
          51488
        ]
      },
      {
        "avg_logprob": -0.20939409451221858,
        "compression_ratio": 1.6014760147601477,
        "end": 424.44,
        "id": 98,
        "no_speech_prob": 0.11754180490970612,
        "seek": 39964,
        "start": 422.12,
        "temperature": 0,
        "text": " And then, you know, at some point, I...",
        "tokens": [
          51488,
          400,
          550,
          11,
          291,
          458,
          11,
          412,
          512,
          935,
          11,
          286,
          485,
          51604
        ]
      },
      {
        "avg_logprob": -0.20939409451221858,
        "compression_ratio": 1.6014760147601477,
        "end": 427.71999999999997,
        "id": 99,
        "no_speech_prob": 0.11754180490970612,
        "seek": 39964,
        "start": 424.44,
        "temperature": 0,
        "text": " And next week, by the way, I hope to be back to talk about Chrome extensions.",
        "tokens": [
          51604,
          400,
          958,
          1243,
          11,
          538,
          264,
          636,
          11,
          286,
          1454,
          281,
          312,
          646,
          281,
          751,
          466,
          15327,
          25129,
          13,
          51768
        ]
      },
      {
        "avg_logprob": -0.20994135827729196,
        "compression_ratio": 1.6934306569343065,
        "end": 430.12,
        "id": 100,
        "no_speech_prob": 0.007458784151822329,
        "seek": 42772,
        "start": 427.8,
        "temperature": 0,
        "text": " And at some point, I am going to...",
        "tokens": [
          50368,
          400,
          412,
          512,
          935,
          11,
          286,
          669,
          516,
          281,
          485,
          50484
        ]
      },
      {
        "avg_logprob": -0.20994135827729196,
        "compression_ratio": 1.6934306569343065,
        "end": 437.56,
        "id": 101,
        "no_speech_prob": 0.007458784151822329,
        "seek": 42772,
        "start": 433.48,
        "temperature": 0,
        "text": " You know, I'm planning to get to everything on this list in terms of videos.",
        "tokens": [
          50652,
          509,
          458,
          11,
          286,
          478,
          5038,
          281,
          483,
          281,
          1203,
          322,
          341,
          1329,
          294,
          2115,
          295,
          2145,
          13,
          50856
        ]
      },
      {
        "avg_logprob": -0.20994135827729196,
        "compression_ratio": 1.6934306569343065,
        "end": 440.76000000000005,
        "id": 102,
        "no_speech_prob": 0.007458784151822329,
        "seek": 42772,
        "start": 437.56,
        "temperature": 0,
        "text": " One thing that's been I've been making examples of recently is how to use Firebase,",
        "tokens": [
          50856,
          1485,
          551,
          300,
          311,
          668,
          286,
          600,
          668,
          1455,
          5110,
          295,
          3938,
          307,
          577,
          281,
          764,
          35173,
          11,
          51016
        ]
      },
      {
        "avg_logprob": -0.20994135827729196,
        "compression_ratio": 1.6934306569343065,
        "end": 442.44000000000005,
        "id": 103,
        "no_speech_prob": 0.007458784151822329,
        "seek": 42772,
        "start": 440.76000000000005,
        "temperature": 0,
        "text": " which is a database as service.",
        "tokens": [
          51016,
          597,
          307,
          257,
          8149,
          382,
          2643,
          13,
          51100
        ]
      },
      {
        "avg_logprob": -0.20994135827729196,
        "compression_ratio": 1.6934306569343065,
        "end": 443.56,
        "id": 104,
        "no_speech_prob": 0.007458784151822329,
        "seek": 42772,
        "start": 442.44000000000005,
        "temperature": 0,
        "text": " So I want to talk about that.",
        "tokens": [
          51100,
          407,
          286,
          528,
          281,
          751,
          466,
          300,
          13,
          51156
        ]
      },
      {
        "avg_logprob": -0.20994135827729196,
        "compression_ratio": 1.6934306569343065,
        "end": 448.28000000000003,
        "id": 105,
        "no_speech_prob": 0.007458784151822329,
        "seek": 42772,
        "start": 443.56,
        "temperature": 0,
        "text": " These emoji hearts in the chat are just the most wonderful things I've ever seen.",
        "tokens": [
          51156,
          1981,
          31595,
          8852,
          294,
          264,
          5081,
          366,
          445,
          264,
          881,
          3715,
          721,
          286,
          600,
          1562,
          1612,
          13,
          51392
        ]
      },
      {
        "avg_logprob": -0.20994135827729196,
        "compression_ratio": 1.6934306569343065,
        "end": 449.56,
        "id": 106,
        "no_speech_prob": 0.007458784151822329,
        "seek": 42772,
        "start": 448.28000000000003,
        "temperature": 0,
        "text": " They make me so happy.",
        "tokens": [
          51392,
          814,
          652,
          385,
          370,
          2055,
          13,
          51456
        ]
      },
      {
        "avg_logprob": -0.20994135827729196,
        "compression_ratio": 1.6934306569343065,
        "end": 452.28000000000003,
        "id": 107,
        "no_speech_prob": 0.007458784151822329,
        "seek": 42772,
        "start": 449.56,
        "temperature": 0,
        "text": " Okay, let's put on some music.",
        "tokens": [
          51456,
          1033,
          11,
          718,
          311,
          829,
          322,
          512,
          1318,
          13,
          51592
        ]
      },
      {
        "avg_logprob": -0.20994135827729196,
        "compression_ratio": 1.6934306569343065,
        "end": 456.92,
        "id": 108,
        "no_speech_prob": 0.007458784151822329,
        "seek": 42772,
        "start": 453.40000000000003,
        "temperature": 0,
        "text": " As always, I always forget to this dot, this dot, this dot, this dot.",
        "tokens": [
          51648,
          1018,
          1009,
          11,
          286,
          1009,
          2870,
          281,
          341,
          5893,
          11,
          341,
          5893,
          11,
          341,
          5893,
          11,
          341,
          5893,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.7952889601389567,
        "compression_ratio": 1.4444444444444444,
        "end": 459.16,
        "id": 109,
        "no_speech_prob": 0.41821616888046265,
        "seek": 45692,
        "start": 457.88,
        "temperature": 0.6000000000000001,
        "text": " I want to keep this here.",
        "tokens": [
          50412,
          286,
          528,
          281,
          1066,
          341,
          510,
          13,
          50476
        ]
      },
      {
        "avg_logprob": -0.7952889601389567,
        "compression_ratio": 1.4444444444444444,
        "end": 473.56,
        "id": 110,
        "no_speech_prob": 0.41821616888046265,
        "seek": 45692,
        "start": 459.16,
        "temperature": 0.6000000000000001,
        "text": " This dot, this dot, this dot, this dot.",
        "tokens": [
          50476,
          639,
          5893,
          11,
          341,
          5893,
          11,
          341,
          5893,
          11,
          341,
          5893,
          13,
          51196
        ]
      },
      {
        "avg_logprob": -0.2441416949760623,
        "compression_ratio": 1.6838235294117647,
        "end": 491.6,
        "id": 111,
        "no_speech_prob": 0.16852180659770966,
        "seek": 48692,
        "start": 487.92,
        "temperature": 0,
        "text": " OK, so I'm going to get started with the first video, which",
        "tokens": [
          50414,
          2264,
          11,
          370,
          286,
          478,
          516,
          281,
          483,
          1409,
          365,
          264,
          700,
          960,
          11,
          597,
          50598
        ]
      },
      {
        "avg_logprob": -0.2441416949760623,
        "compression_ratio": 1.6838235294117647,
        "end": 492.64000000000004,
        "id": 112,
        "no_speech_prob": 0.16852180659770966,
        "seek": 48692,
        "start": 491.6,
        "temperature": 0,
        "text": " typically what I do.",
        "tokens": [
          50598,
          5850,
          437,
          286,
          360,
          13,
          50650
        ]
      },
      {
        "avg_logprob": -0.2441416949760623,
        "compression_ratio": 1.6838235294117647,
        "end": 495.16,
        "id": 113,
        "no_speech_prob": 0.16852180659770966,
        "seek": 48692,
        "start": 492.64000000000004,
        "temperature": 0,
        "text": " So if you haven't watched these before, what I do is",
        "tokens": [
          50650,
          407,
          498,
          291,
          2378,
          380,
          6337,
          613,
          949,
          11,
          437,
          286,
          360,
          307,
          50776
        ]
      },
      {
        "avg_logprob": -0.2441416949760623,
        "compression_ratio": 1.6838235294117647,
        "end": 498.92,
        "id": 114,
        "no_speech_prob": 0.16852180659770966,
        "seek": 48692,
        "start": 495.16,
        "temperature": 0,
        "text": " I do a session, which is a longer session, which",
        "tokens": [
          50776,
          286,
          360,
          257,
          5481,
          11,
          597,
          307,
          257,
          2854,
          5481,
          11,
          597,
          50964
        ]
      },
      {
        "avg_logprob": -0.2441416949760623,
        "compression_ratio": 1.6838235294117647,
        "end": 502.08000000000004,
        "id": 115,
        "no_speech_prob": 0.16852180659770966,
        "seek": 48692,
        "start": 498.92,
        "temperature": 0,
        "text": " has all of my fumbling around and trying to answer questions",
        "tokens": [
          50964,
          575,
          439,
          295,
          452,
          283,
          14188,
          926,
          293,
          1382,
          281,
          1867,
          1651,
          51122
        ]
      },
      {
        "avg_logprob": -0.2441416949760623,
        "compression_ratio": 1.6838235294117647,
        "end": 502.92,
        "id": 116,
        "no_speech_prob": 0.16852180659770966,
        "seek": 48692,
        "start": 502.08000000000004,
        "temperature": 0,
        "text": " in the chat.",
        "tokens": [
          51122,
          294,
          264,
          5081,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2441416949760623,
        "compression_ratio": 1.6838235294117647,
        "end": 506.72,
        "id": 117,
        "no_speech_prob": 0.16852180659770966,
        "seek": 48692,
        "start": 502.92,
        "temperature": 0,
        "text": " And then the wonderful Mathieu takes this longer session,",
        "tokens": [
          51164,
          400,
          550,
          264,
          3715,
          15776,
          19347,
          2516,
          341,
          2854,
          5481,
          11,
          51354
        ]
      },
      {
        "avg_logprob": -0.2441416949760623,
        "compression_ratio": 1.6838235294117647,
        "end": 509.88,
        "id": 118,
        "no_speech_prob": 0.16852180659770966,
        "seek": 48692,
        "start": 506.72,
        "temperature": 0,
        "text": " which today will be only an hour and 20 minutes,",
        "tokens": [
          51354,
          597,
          965,
          486,
          312,
          787,
          364,
          1773,
          293,
          945,
          2077,
          11,
          51512
        ]
      },
      {
        "avg_logprob": -0.2441416949760623,
        "compression_ratio": 1.6838235294117647,
        "end": 512.12,
        "id": 119,
        "no_speech_prob": 0.16852180659770966,
        "seek": 48692,
        "start": 509.88,
        "temperature": 0,
        "text": " and edits it into shorter tutorial videos.",
        "tokens": [
          51512,
          293,
          41752,
          309,
          666,
          11639,
          7073,
          2145,
          13,
          51624
        ]
      },
      {
        "avg_logprob": -0.2441416949760623,
        "compression_ratio": 1.6838235294117647,
        "end": 516.12,
        "id": 120,
        "no_speech_prob": 0.16852180659770966,
        "seek": 48692,
        "start": 512.12,
        "temperature": 0,
        "text": " So it cuts out some of my longer debugging problems",
        "tokens": [
          51624,
          407,
          309,
          9992,
          484,
          512,
          295,
          452,
          2854,
          45592,
          2740,
          51824
        ]
      },
      {
        "avg_logprob": -0.25656258570004814,
        "compression_ratio": 1.6966666666666668,
        "end": 517.36,
        "id": 121,
        "no_speech_prob": 0.00023411432630382478,
        "seek": 51612,
        "start": 516.12,
        "temperature": 0,
        "text": " and also it's helpful.",
        "tokens": [
          50364,
          293,
          611,
          309,
          311,
          4961,
          13,
          50426
        ]
      },
      {
        "avg_logprob": -0.25656258570004814,
        "compression_ratio": 1.6966666666666668,
        "end": 520.24,
        "id": 122,
        "no_speech_prob": 0.00023411432630382478,
        "seek": 51612,
        "start": 517.36,
        "temperature": 0,
        "text": " I think people find having the shorter video chunks more",
        "tokens": [
          50426,
          286,
          519,
          561,
          915,
          1419,
          264,
          11639,
          960,
          24004,
          544,
          50570
        ]
      },
      {
        "avg_logprob": -0.25656258570004814,
        "compression_ratio": 1.6966666666666668,
        "end": 522.52,
        "id": 123,
        "no_speech_prob": 0.00023411432630382478,
        "seek": 51612,
        "start": 520.24,
        "temperature": 0,
        "text": " searchable and easily findable on YouTube.",
        "tokens": [
          50570,
          3164,
          712,
          293,
          3612,
          915,
          712,
          322,
          3088,
          13,
          50684
        ]
      },
      {
        "avg_logprob": -0.25656258570004814,
        "compression_ratio": 1.6966666666666668,
        "end": 524.5600000000001,
        "id": 124,
        "no_speech_prob": 0.00023411432630382478,
        "seek": 51612,
        "start": 522.52,
        "temperature": 0,
        "text": " OK, the hearts are wonderful.",
        "tokens": [
          50684,
          2264,
          11,
          264,
          8852,
          366,
          3715,
          13,
          50786
        ]
      },
      {
        "avg_logprob": -0.25656258570004814,
        "compression_ratio": 1.6966666666666668,
        "end": 526.0600000000001,
        "id": 125,
        "no_speech_prob": 0.00023411432630382478,
        "seek": 51612,
        "start": 524.5600000000001,
        "temperature": 0,
        "text": " Actually, I'm actually just enjoying them.",
        "tokens": [
          50786,
          5135,
          11,
          286,
          478,
          767,
          445,
          9929,
          552,
          13,
          50861
        ]
      },
      {
        "avg_logprob": -0.25656258570004814,
        "compression_ratio": 1.6966666666666668,
        "end": 527.64,
        "id": 126,
        "no_speech_prob": 0.00023411432630382478,
        "seek": 51612,
        "start": 526.0600000000001,
        "temperature": 0,
        "text": " I was going to tell you to stop, but I",
        "tokens": [
          50861,
          286,
          390,
          516,
          281,
          980,
          291,
          281,
          1590,
          11,
          457,
          286,
          50940
        ]
      },
      {
        "avg_logprob": -0.25656258570004814,
        "compression_ratio": 1.6966666666666668,
        "end": 530.5600000000001,
        "id": 127,
        "no_speech_prob": 0.00023411432630382478,
        "seek": 51612,
        "start": 527.64,
        "temperature": 0,
        "text": " don't know, I'm kind of just enjoying them anyway.",
        "tokens": [
          50940,
          500,
          380,
          458,
          11,
          286,
          478,
          733,
          295,
          445,
          9929,
          552,
          4033,
          13,
          51086
        ]
      },
      {
        "avg_logprob": -0.25656258570004814,
        "compression_ratio": 1.6966666666666668,
        "end": 533.2,
        "id": 128,
        "no_speech_prob": 0.00023411432630382478,
        "seek": 51612,
        "start": 530.5600000000001,
        "temperature": 0,
        "text": " OK, so the first thing that I do usually is,",
        "tokens": [
          51086,
          2264,
          11,
          370,
          264,
          700,
          551,
          300,
          286,
          360,
          2673,
          307,
          11,
          51218
        ]
      },
      {
        "avg_logprob": -0.25656258570004814,
        "compression_ratio": 1.6966666666666668,
        "end": 535.88,
        "id": 129,
        "no_speech_prob": 0.00023411432630382478,
        "seek": 51612,
        "start": 533.2,
        "temperature": 0,
        "text": " since this is part, I'm a little bit confused about this",
        "tokens": [
          51218,
          1670,
          341,
          307,
          644,
          11,
          286,
          478,
          257,
          707,
          857,
          9019,
          466,
          341,
          51352
        ]
      },
      {
        "avg_logprob": -0.25656258570004814,
        "compression_ratio": 1.6966666666666668,
        "end": 538.28,
        "id": 130,
        "no_speech_prob": 0.00023411432630382478,
        "seek": 51612,
        "start": 535.88,
        "temperature": 0,
        "text": " actually, and I don't know if Mathieu is there in the chat.",
        "tokens": [
          51352,
          767,
          11,
          293,
          286,
          500,
          380,
          458,
          498,
          15776,
          19347,
          307,
          456,
          294,
          264,
          5081,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -0.25656258570004814,
        "compression_ratio": 1.6966666666666668,
        "end": 543.36,
        "id": 131,
        "no_speech_prob": 0.00023411432630382478,
        "seek": 51612,
        "start": 538.28,
        "temperature": 0,
        "text": " But this is session nine of eight",
        "tokens": [
          51472,
          583,
          341,
          307,
          5481,
          4949,
          295,
          3180,
          51726
        ]
      },
      {
        "avg_logprob": -0.25656258570004814,
        "compression_ratio": 1.6966666666666668,
        "end": 545.16,
        "id": 132,
        "no_speech_prob": 0.00023411432630382478,
        "seek": 51612,
        "start": 543.36,
        "temperature": 0,
        "text": " of programming from A to Z.",
        "tokens": [
          51726,
          295,
          9410,
          490,
          316,
          281,
          1176,
          13,
          51816
        ]
      },
      {
        "avg_logprob": -0.2194490950236949,
        "compression_ratio": 1.7228464419475655,
        "end": 551.24,
        "id": 133,
        "no_speech_prob": 0.00003647781704785302,
        "seek": 54516,
        "start": 545.16,
        "temperature": 0,
        "text": " But in a way, this can operate as its own standalone tutorial",
        "tokens": [
          50364,
          583,
          294,
          257,
          636,
          11,
          341,
          393,
          9651,
          382,
          1080,
          1065,
          37454,
          7073,
          50668
        ]
      },
      {
        "avg_logprob": -0.2194490950236949,
        "compression_ratio": 1.7228464419475655,
        "end": 553.28,
        "id": 134,
        "no_speech_prob": 0.00003647781704785302,
        "seek": 54516,
        "start": 551.24,
        "temperature": 0,
        "text": " about making an API with Node.",
        "tokens": [
          50668,
          466,
          1455,
          364,
          9362,
          365,
          38640,
          13,
          50770
        ]
      },
      {
        "avg_logprob": -0.2194490950236949,
        "compression_ratio": 1.7228464419475655,
        "end": 557.1999999999999,
        "id": 135,
        "no_speech_prob": 0.00003647781704785302,
        "seek": 54516,
        "start": 553.28,
        "temperature": 0,
        "text": " So I think what I'm going to do is I'm not sure yet.",
        "tokens": [
          50770,
          407,
          286,
          519,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          406,
          988,
          1939,
          13,
          50966
        ]
      },
      {
        "avg_logprob": -0.2194490950236949,
        "compression_ratio": 1.7228464419475655,
        "end": 559,
        "id": 136,
        "no_speech_prob": 0.00003647781704785302,
        "seek": 54516,
        "start": 557.1999999999999,
        "temperature": 0,
        "text": " So I'm just going to record these videos",
        "tokens": [
          50966,
          407,
          286,
          478,
          445,
          516,
          281,
          2136,
          613,
          2145,
          51056
        ]
      },
      {
        "avg_logprob": -0.2194490950236949,
        "compression_ratio": 1.7228464419475655,
        "end": 560.92,
        "id": 137,
        "no_speech_prob": 0.00003647781704785302,
        "seek": 54516,
        "start": 559,
        "temperature": 0,
        "text": " and I'll figure out how to organize it later.",
        "tokens": [
          51056,
          293,
          286,
          603,
          2573,
          484,
          577,
          281,
          13859,
          309,
          1780,
          13,
          51152
        ]
      },
      {
        "avg_logprob": -0.2194490950236949,
        "compression_ratio": 1.7228464419475655,
        "end": 563.68,
        "id": 138,
        "no_speech_prob": 0.00003647781704785302,
        "seek": 54516,
        "start": 560.92,
        "temperature": 0,
        "text": " But this first video will be just kind of an introduction",
        "tokens": [
          51152,
          583,
          341,
          700,
          960,
          486,
          312,
          445,
          733,
          295,
          364,
          9339,
          51290
        ]
      },
      {
        "avg_logprob": -0.2194490950236949,
        "compression_ratio": 1.7228464419475655,
        "end": 566.52,
        "id": 139,
        "no_speech_prob": 0.00003647781704785302,
        "seek": 54516,
        "start": 563.68,
        "temperature": 0,
        "text": " to this session and all of the topics in the session.",
        "tokens": [
          51290,
          281,
          341,
          5481,
          293,
          439,
          295,
          264,
          8378,
          294,
          264,
          5481,
          13,
          51432
        ]
      },
      {
        "avg_logprob": -0.2194490950236949,
        "compression_ratio": 1.7228464419475655,
        "end": 570.04,
        "id": 140,
        "no_speech_prob": 0.00003647781704785302,
        "seek": 54516,
        "start": 566.52,
        "temperature": 0,
        "text": " And then I want to make sure I have a marker.",
        "tokens": [
          51432,
          400,
          550,
          286,
          528,
          281,
          652,
          988,
          286,
          362,
          257,
          15247,
          13,
          51608
        ]
      },
      {
        "avg_logprob": -0.2194490950236949,
        "compression_ratio": 1.7228464419475655,
        "end": 572.52,
        "id": 141,
        "no_speech_prob": 0.00003647781704785302,
        "seek": 54516,
        "start": 570.04,
        "temperature": 0,
        "text": " And then the second video will start",
        "tokens": [
          51608,
          400,
          550,
          264,
          1150,
          960,
          486,
          722,
          51732
        ]
      },
      {
        "avg_logprob": -0.2194490950236949,
        "compression_ratio": 1.7228464419475655,
        "end": 574.66,
        "id": 142,
        "no_speech_prob": 0.00003647781704785302,
        "seek": 54516,
        "start": 572.52,
        "temperature": 0,
        "text": " with how to make an API in Node.",
        "tokens": [
          51732,
          365,
          577,
          281,
          652,
          364,
          9362,
          294,
          38640,
          13,
          51839
        ]
      },
      {
        "avg_logprob": -0.2640712115229393,
        "compression_ratio": 1.5159817351598173,
        "end": 577.38,
        "id": 143,
        "no_speech_prob": 0.0001313413813477382,
        "seek": 57466,
        "start": 574.66,
        "temperature": 0,
        "text": " And that might end up being its own playlist as well about Node.",
        "tokens": [
          50364,
          400,
          300,
          1062,
          917,
          493,
          885,
          1080,
          1065,
          16788,
          382,
          731,
          466,
          38640,
          13,
          50500
        ]
      },
      {
        "avg_logprob": -0.2640712115229393,
        "compression_ratio": 1.5159817351598173,
        "end": 578.9,
        "id": 144,
        "no_speech_prob": 0.0001313413813477382,
        "seek": 57466,
        "start": 577.38,
        "temperature": 0,
        "text": " But we'll figure that out later.",
        "tokens": [
          50500,
          583,
          321,
          603,
          2573,
          300,
          484,
          1780,
          13,
          50576
        ]
      },
      {
        "avg_logprob": -0.2640712115229393,
        "compression_ratio": 1.5159817351598173,
        "end": 582.54,
        "id": 145,
        "no_speech_prob": 0.0001313413813477382,
        "seek": 57466,
        "start": 578.9,
        "temperature": 0,
        "text": " OK, so thanks all of you for being here.",
        "tokens": [
          50576,
          2264,
          11,
          370,
          3231,
          439,
          295,
          291,
          337,
          885,
          510,
          13,
          50758
        ]
      },
      {
        "avg_logprob": -0.2640712115229393,
        "compression_ratio": 1.5159817351598173,
        "end": 584.5799999999999,
        "id": 146,
        "no_speech_prob": 0.0001313413813477382,
        "seek": 57466,
        "start": 582.54,
        "temperature": 0,
        "text": " I see so many wonderful messages in the chat,",
        "tokens": [
          50758,
          286,
          536,
          370,
          867,
          3715,
          7897,
          294,
          264,
          5081,
          11,
          50860
        ]
      },
      {
        "avg_logprob": -0.2640712115229393,
        "compression_ratio": 1.5159817351598173,
        "end": 585.98,
        "id": 147,
        "no_speech_prob": 0.0001313413813477382,
        "seek": 57466,
        "start": 584.5799999999999,
        "temperature": 0,
        "text": " supportive messages.",
        "tokens": [
          50860,
          14435,
          7897,
          13,
          50930
        ]
      },
      {
        "avg_logprob": -0.2640712115229393,
        "compression_ratio": 1.5159817351598173,
        "end": 588.2199999999999,
        "id": 148,
        "no_speech_prob": 0.0001313413813477382,
        "seek": 57466,
        "start": 585.98,
        "temperature": 0,
        "text": " And I'm going to get started right now.",
        "tokens": [
          50930,
          400,
          286,
          478,
          516,
          281,
          483,
          1409,
          558,
          586,
          13,
          51042
        ]
      },
      {
        "avg_logprob": -0.2640712115229393,
        "compression_ratio": 1.5159817351598173,
        "end": 594.86,
        "id": 149,
        "no_speech_prob": 0.0001313413813477382,
        "seek": 57466,
        "start": 591.3399999999999,
        "temperature": 0,
        "text": " I'm a little worried about a light that I have here.",
        "tokens": [
          51198,
          286,
          478,
          257,
          707,
          5804,
          466,
          257,
          1442,
          300,
          286,
          362,
          510,
          13,
          51374
        ]
      },
      {
        "avg_logprob": -0.2640712115229393,
        "compression_ratio": 1.5159817351598173,
        "end": 595.98,
        "id": 150,
        "no_speech_prob": 0.0001313413813477382,
        "seek": 57466,
        "start": 594.86,
        "temperature": 0,
        "text": " Turn this off for a second.",
        "tokens": [
          51374,
          7956,
          341,
          766,
          337,
          257,
          1150,
          13,
          51430
        ]
      },
      {
        "avg_logprob": -0.2640712115229393,
        "compression_ratio": 1.5159817351598173,
        "end": 600.86,
        "id": 151,
        "no_speech_prob": 0.0001313413813477382,
        "seek": 57466,
        "start": 598.78,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51570,
          865,
          13,
          51674
        ]
      },
      {
        "avg_logprob": -0.23197313455434945,
        "compression_ratio": 1.6392156862745098,
        "end": 605.1,
        "id": 152,
        "no_speech_prob": 0.00045119895366951823,
        "seek": 60086,
        "start": 600.86,
        "temperature": 0,
        "text": " So I have to turn this light off, unfortunately,",
        "tokens": [
          50364,
          407,
          286,
          362,
          281,
          1261,
          341,
          1442,
          766,
          11,
          7015,
          11,
          50576
        ]
      },
      {
        "avg_logprob": -0.23197313455434945,
        "compression_ratio": 1.6392156862745098,
        "end": 608.58,
        "id": 153,
        "no_speech_prob": 0.00045119895366951823,
        "seek": 60086,
        "start": 605.1,
        "temperature": 0,
        "text": " because I just turned one of the halogen lights off.",
        "tokens": [
          50576,
          570,
          286,
          445,
          3574,
          472,
          295,
          264,
          7523,
          8799,
          5811,
          766,
          13,
          50750
        ]
      },
      {
        "avg_logprob": -0.23197313455434945,
        "compression_ratio": 1.6392156862745098,
        "end": 611.54,
        "id": 154,
        "no_speech_prob": 0.00045119895366951823,
        "seek": 60086,
        "start": 608.58,
        "temperature": 0,
        "text": " I also just looked at it and now I can't see anything.",
        "tokens": [
          50750,
          286,
          611,
          445,
          2956,
          412,
          309,
          293,
          586,
          286,
          393,
          380,
          536,
          1340,
          13,
          50898
        ]
      },
      {
        "avg_logprob": -0.23197313455434945,
        "compression_ratio": 1.6392156862745098,
        "end": 612.78,
        "id": 155,
        "no_speech_prob": 0.00045119895366951823,
        "seek": 60086,
        "start": 611.54,
        "temperature": 0,
        "text": " I'm blinded by it.",
        "tokens": [
          50898,
          286,
          478,
          6865,
          292,
          538,
          309,
          13,
          50960
        ]
      },
      {
        "avg_logprob": -0.23197313455434945,
        "compression_ratio": 1.6392156862745098,
        "end": 614.98,
        "id": 156,
        "no_speech_prob": 0.00045119895366951823,
        "seek": 60086,
        "start": 612.78,
        "temperature": 0,
        "text": " I'm a little bit darker, unfortunately, right?",
        "tokens": [
          50960,
          286,
          478,
          257,
          707,
          857,
          12741,
          11,
          7015,
          11,
          558,
          30,
          51070
        ]
      },
      {
        "avg_logprob": -0.23197313455434945,
        "compression_ratio": 1.6392156862745098,
        "end": 617.14,
        "id": 157,
        "no_speech_prob": 0.00045119895366951823,
        "seek": 60086,
        "start": 614.98,
        "temperature": 0,
        "text": " But there's a problem with this light.",
        "tokens": [
          51070,
          583,
          456,
          311,
          257,
          1154,
          365,
          341,
          1442,
          13,
          51178
        ]
      },
      {
        "avg_logprob": -0.23197313455434945,
        "compression_ratio": 1.6392156862745098,
        "end": 619.5,
        "id": 158,
        "no_speech_prob": 0.00045119895366951823,
        "seek": 60086,
        "start": 617.14,
        "temperature": 0,
        "text": " And it's burning.",
        "tokens": [
          51178,
          400,
          309,
          311,
          9488,
          13,
          51296
        ]
      },
      {
        "avg_logprob": -0.23197313455434945,
        "compression_ratio": 1.6392156862745098,
        "end": 621.58,
        "id": 159,
        "no_speech_prob": 0.00045119895366951823,
        "seek": 60086,
        "start": 619.5,
        "temperature": 0,
        "text": " And I don't want it to catch on fire.",
        "tokens": [
          51296,
          400,
          286,
          500,
          380,
          528,
          309,
          281,
          3745,
          322,
          2610,
          13,
          51400
        ]
      },
      {
        "avg_logprob": -0.23197313455434945,
        "compression_ratio": 1.6392156862745098,
        "end": 623.02,
        "id": 160,
        "no_speech_prob": 0.00045119895366951823,
        "seek": 60086,
        "start": 621.58,
        "temperature": 0,
        "text": " So I'm turning it off.",
        "tokens": [
          51400,
          407,
          286,
          478,
          6246,
          309,
          766,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -0.23197313455434945,
        "compression_ratio": 1.6392156862745098,
        "end": 625.74,
        "id": 161,
        "no_speech_prob": 0.00045119895366951823,
        "seek": 60086,
        "start": 623.02,
        "temperature": 0,
        "text": " We will be in slight darkness today.",
        "tokens": [
          51472,
          492,
          486,
          312,
          294,
          4036,
          11262,
          965,
          13,
          51608
        ]
      },
      {
        "avg_logprob": -0.23197313455434945,
        "compression_ratio": 1.6392156862745098,
        "end": 628.1,
        "id": 162,
        "no_speech_prob": 0.00045119895366951823,
        "seek": 60086,
        "start": 625.74,
        "temperature": 0,
        "text": " But I think you guys can see me OK, yes?",
        "tokens": [
          51608,
          583,
          286,
          519,
          291,
          1074,
          393,
          536,
          385,
          2264,
          11,
          2086,
          30,
          51726
        ]
      },
      {
        "avg_logprob": -0.2353191375732422,
        "compression_ratio": 1.5044247787610618,
        "end": 634.9,
        "id": 163,
        "no_speech_prob": 0.00010390582610853016,
        "seek": 63086,
        "start": 631.86,
        "temperature": 0,
        "text": " OK, so that's how it's going to be.",
        "tokens": [
          50414,
          2264,
          11,
          370,
          300,
          311,
          577,
          309,
          311,
          516,
          281,
          312,
          13,
          50566
        ]
      },
      {
        "avg_logprob": -0.2353191375732422,
        "compression_ratio": 1.5044247787610618,
        "end": 637.1,
        "id": 164,
        "no_speech_prob": 0.00010390582610853016,
        "seek": 63086,
        "start": 634.9,
        "temperature": 0,
        "text": " OK, so let me get started here.",
        "tokens": [
          50566,
          2264,
          11,
          370,
          718,
          385,
          483,
          1409,
          510,
          13,
          50676
        ]
      },
      {
        "avg_logprob": -0.2353191375732422,
        "compression_ratio": 1.5044247787610618,
        "end": 638.1800000000001,
        "id": 165,
        "no_speech_prob": 0.00010390582610853016,
        "seek": 63086,
        "start": 637.1,
        "temperature": 0,
        "text": " Did I cycle the cameras?",
        "tokens": [
          50676,
          2589,
          286,
          6586,
          264,
          8622,
          30,
          50730
        ]
      },
      {
        "avg_logprob": -0.2353191375732422,
        "compression_ratio": 1.5044247787610618,
        "end": 638.9,
        "id": 166,
        "no_speech_prob": 0.00010390582610853016,
        "seek": 63086,
        "start": 638.1800000000001,
        "temperature": 0,
        "text": " I can't remember.",
        "tokens": [
          50730,
          286,
          393,
          380,
          1604,
          13,
          50766
        ]
      },
      {
        "avg_logprob": -0.2353191375732422,
        "compression_ratio": 1.5044247787610618,
        "end": 644.0600000000001,
        "id": 167,
        "no_speech_prob": 0.00010390582610853016,
        "seek": 63086,
        "start": 642.82,
        "temperature": 0,
        "text": " That's too bad.",
        "tokens": [
          50962,
          663,
          311,
          886,
          1578,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.2353191375732422,
        "compression_ratio": 1.5044247787610618,
        "end": 648.1,
        "id": 168,
        "no_speech_prob": 0.00010390582610853016,
        "seek": 63086,
        "start": 644.0600000000001,
        "temperature": 0,
        "text": " I brought an extra light, but something is wrong.",
        "tokens": [
          51024,
          286,
          3038,
          364,
          2857,
          1442,
          11,
          457,
          746,
          307,
          2085,
          13,
          51226
        ]
      },
      {
        "avg_logprob": -0.2353191375732422,
        "compression_ratio": 1.5044247787610618,
        "end": 651.1,
        "id": 169,
        "no_speech_prob": 0.00010390582610853016,
        "seek": 63086,
        "start": 648.1,
        "temperature": 0,
        "text": " I wonder if there's a way for me to dim it.",
        "tokens": [
          51226,
          286,
          2441,
          498,
          456,
          311,
          257,
          636,
          337,
          385,
          281,
          5013,
          309,
          13,
          51376
        ]
      },
      {
        "avg_logprob": -0.2353191375732422,
        "compression_ratio": 1.5044247787610618,
        "end": 653.3000000000001,
        "id": 170,
        "no_speech_prob": 0.00010390582610853016,
        "seek": 63086,
        "start": 651.1,
        "temperature": 0,
        "text": " Is there a dimmer on it?",
        "tokens": [
          51376,
          1119,
          456,
          257,
          5013,
          936,
          322,
          309,
          30,
          51486
        ]
      },
      {
        "avg_logprob": -0.2353191375732422,
        "compression_ratio": 1.5044247787610618,
        "end": 655.38,
        "id": 171,
        "no_speech_prob": 0.00010390582610853016,
        "seek": 63086,
        "start": 653.3000000000001,
        "temperature": 0,
        "text": " And then it won't overheat.",
        "tokens": [
          51486,
          400,
          550,
          309,
          1582,
          380,
          29807,
          267,
          13,
          51590
        ]
      },
      {
        "avg_logprob": -0.2353191375732422,
        "compression_ratio": 1.5044247787610618,
        "end": 658.1800000000001,
        "id": 172,
        "no_speech_prob": 0.00010390582610853016,
        "seek": 63086,
        "start": 655.38,
        "temperature": 0,
        "text": " But I'm just not going to worry about it.",
        "tokens": [
          51590,
          583,
          286,
          478,
          445,
          406,
          516,
          281,
          3292,
          466,
          309,
          13,
          51730
        ]
      },
      {
        "avg_logprob": -0.2353191375732422,
        "compression_ratio": 1.5044247787610618,
        "end": 660.0600000000001,
        "id": 173,
        "no_speech_prob": 0.00010390582610853016,
        "seek": 63086,
        "start": 658.1800000000001,
        "temperature": 0,
        "text": " Safety first, everybody.",
        "tokens": [
          51730,
          21340,
          700,
          11,
          2201,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.3589548020135789,
        "compression_ratio": 1.6310160427807487,
        "end": 662.02,
        "id": 174,
        "no_speech_prob": 0.00017674014088697731,
        "seek": 66006,
        "start": 660.3399999999999,
        "temperature": 0,
        "text": " OK, it's fine.",
        "tokens": [
          50378,
          2264,
          11,
          309,
          311,
          2489,
          13,
          50462
        ]
      },
      {
        "avg_logprob": -0.3589548020135789,
        "compression_ratio": 1.6310160427807487,
        "end": 662.8599999999999,
        "id": 175,
        "no_speech_prob": 0.00017674014088697731,
        "seek": 66006,
        "start": 662.02,
        "temperature": 0,
        "text": " OK, here we go.",
        "tokens": [
          50462,
          2264,
          11,
          510,
          321,
          352,
          13,
          50504
        ]
      },
      {
        "avg_logprob": -0.3589548020135789,
        "compression_ratio": 1.6310160427807487,
        "end": 668.6999999999999,
        "id": 176,
        "no_speech_prob": 0.00017674014088697731,
        "seek": 66006,
        "start": 667.66,
        "temperature": 0,
        "text": " I still can't see.",
        "tokens": [
          50744,
          286,
          920,
          393,
          380,
          536,
          13,
          50796
        ]
      },
      {
        "avg_logprob": -0.3589548020135789,
        "compression_ratio": 1.6310160427807487,
        "end": 671.14,
        "id": 177,
        "no_speech_prob": 0.00017674014088697731,
        "seek": 66006,
        "start": 668.6999999999999,
        "temperature": 0,
        "text": " You know when you look at the sun and you see all the spots?",
        "tokens": [
          50796,
          509,
          458,
          562,
          291,
          574,
          412,
          264,
          3295,
          293,
          291,
          536,
          439,
          264,
          10681,
          30,
          50918
        ]
      },
      {
        "avg_logprob": -0.3589548020135789,
        "compression_ratio": 1.6310160427807487,
        "end": 673.2199999999999,
        "id": 178,
        "no_speech_prob": 0.00017674014088697731,
        "seek": 66006,
        "start": 671.14,
        "temperature": 0,
        "text": " I went over to look at the light because it",
        "tokens": [
          50918,
          286,
          1437,
          670,
          281,
          574,
          412,
          264,
          1442,
          570,
          309,
          51022
        ]
      },
      {
        "avg_logprob": -0.3589548020135789,
        "compression_ratio": 1.6310160427807487,
        "end": 674.8599999999999,
        "id": 179,
        "no_speech_prob": 0.00017674014088697731,
        "seek": 66006,
        "start": 673.2199999999999,
        "temperature": 0,
        "text": " looked like it was smoking a little bit.",
        "tokens": [
          51022,
          2956,
          411,
          309,
          390,
          14055,
          257,
          707,
          857,
          13,
          51104
        ]
      },
      {
        "avg_logprob": -0.3589548020135789,
        "compression_ratio": 1.6310160427807487,
        "end": 676.4599999999999,
        "id": 180,
        "no_speech_prob": 0.00017674014088697731,
        "seek": 66006,
        "start": 674.8599999999999,
        "temperature": 0,
        "text": " And I stared straight into it.",
        "tokens": [
          51104,
          400,
          286,
          44738,
          2997,
          666,
          309,
          13,
          51184
        ]
      },
      {
        "avg_logprob": -0.3589548020135789,
        "compression_ratio": 1.6310160427807487,
        "end": 680.66,
        "id": 181,
        "no_speech_prob": 0.00017674014088697731,
        "seek": 66006,
        "start": 680.14,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          51368,
          1692,
          321,
          352,
          13,
          51394
        ]
      },
      {
        "avg_logprob": -0.3589548020135789,
        "compression_ratio": 1.6310160427807487,
        "end": 687.54,
        "id": 182,
        "no_speech_prob": 0.00017674014088697731,
        "seek": 66006,
        "start": 684.6199999999999,
        "temperature": 0,
        "text": " Hello, welcome to session nine.",
        "tokens": [
          51592,
          2425,
          11,
          2928,
          281,
          5481,
          4949,
          13,
          51738
        ]
      },
      {
        "avg_logprob": -0.3589548020135789,
        "compression_ratio": 1.6310160427807487,
        "end": 689.5,
        "id": 183,
        "no_speech_prob": 0.00017674014088697731,
        "seek": 66006,
        "start": 687.54,
        "temperature": 0,
        "text": " Oh, no, no, no, no, session eight.",
        "tokens": [
          51738,
          876,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          5481,
          3180,
          13,
          51836
        ]
      },
      {
        "avg_logprob": -0.2232800691024117,
        "compression_ratio": 1.5719557195571956,
        "end": 691.22,
        "id": 184,
        "no_speech_prob": 0.0004802851181011647,
        "seek": 68950,
        "start": 689.5,
        "temperature": 0,
        "text": " Let's try that again.",
        "tokens": [
          50364,
          961,
          311,
          853,
          300,
          797,
          13,
          50450
        ]
      },
      {
        "avg_logprob": -0.2232800691024117,
        "compression_ratio": 1.5719557195571956,
        "end": 693.22,
        "id": 185,
        "no_speech_prob": 0.0004802851181011647,
        "seek": 68950,
        "start": 691.22,
        "temperature": 0,
        "text": " Hello, and welcome to session eight",
        "tokens": [
          50450,
          2425,
          11,
          293,
          2928,
          281,
          5481,
          3180,
          50550
        ]
      },
      {
        "avg_logprob": -0.2232800691024117,
        "compression_ratio": 1.5719557195571956,
        "end": 696.5,
        "id": 186,
        "no_speech_prob": 0.0004802851181011647,
        "seek": 68950,
        "start": 693.22,
        "temperature": 0,
        "text": " of programming from A to Z. In this session,",
        "tokens": [
          50550,
          295,
          9410,
          490,
          316,
          281,
          1176,
          13,
          682,
          341,
          5481,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.2232800691024117,
        "compression_ratio": 1.5719557195571956,
        "end": 700.5,
        "id": 187,
        "no_speech_prob": 0.0004802851181011647,
        "seek": 68950,
        "start": 696.5,
        "temperature": 0,
        "text": " I want to talk about and look at more deeply how",
        "tokens": [
          50714,
          286,
          528,
          281,
          751,
          466,
          293,
          574,
          412,
          544,
          8760,
          577,
          50914
        ]
      },
      {
        "avg_logprob": -0.2232800691024117,
        "compression_ratio": 1.5719557195571956,
        "end": 703.02,
        "id": 188,
        "no_speech_prob": 0.0004802851181011647,
        "seek": 68950,
        "start": 700.5,
        "temperature": 0,
        "text": " to build an API using Node.",
        "tokens": [
          50914,
          281,
          1322,
          364,
          9362,
          1228,
          38640,
          13,
          51040
        ]
      },
      {
        "avg_logprob": -0.2232800691024117,
        "compression_ratio": 1.5719557195571956,
        "end": 708.22,
        "id": 189,
        "no_speech_prob": 0.0004802851181011647,
        "seek": 68950,
        "start": 703.02,
        "temperature": 0,
        "text": " So this whole course has focused on working with text,",
        "tokens": [
          51040,
          407,
          341,
          1379,
          1164,
          575,
          5178,
          322,
          1364,
          365,
          2487,
          11,
          51300
        ]
      },
      {
        "avg_logprob": -0.2232800691024117,
        "compression_ratio": 1.5719557195571956,
        "end": 711.98,
        "id": 190,
        "no_speech_prob": 0.0004802851181011647,
        "seek": 68950,
        "start": 708.22,
        "temperature": 0,
        "text": " reading text, analyzing text, generating text.",
        "tokens": [
          51300,
          3760,
          2487,
          11,
          23663,
          2487,
          11,
          17746,
          2487,
          13,
          51488
        ]
      },
      {
        "avg_logprob": -0.2232800691024117,
        "compression_ratio": 1.5719557195571956,
        "end": 714.72,
        "id": 191,
        "no_speech_prob": 0.0004802851181011647,
        "seek": 68950,
        "start": 711.98,
        "temperature": 0,
        "text": " And most of the stuff, almost everything that I've shown you,",
        "tokens": [
          51488,
          400,
          881,
          295,
          264,
          1507,
          11,
          1920,
          1203,
          300,
          286,
          600,
          4898,
          291,
          11,
          51625
        ]
      },
      {
        "avg_logprob": -0.2232800691024117,
        "compression_ratio": 1.5719557195571956,
        "end": 717.06,
        "id": 192,
        "no_speech_prob": 0.0004802851181011647,
        "seek": 68950,
        "start": 714.72,
        "temperature": 0,
        "text": " happens in client-side JavaScript.",
        "tokens": [
          51625,
          2314,
          294,
          6423,
          12,
          1812,
          15778,
          13,
          51742
        ]
      },
      {
        "avg_logprob": -0.2232800691024117,
        "compression_ratio": 1.5719557195571956,
        "end": 719.02,
        "id": 193,
        "no_speech_prob": 0.0004802851181011647,
        "seek": 68950,
        "start": 717.06,
        "temperature": 0,
        "text": " So let's talk about a little bit just generally",
        "tokens": [
          51742,
          407,
          718,
          311,
          751,
          466,
          257,
          707,
          857,
          445,
          5101,
          51840
        ]
      },
      {
        "avg_logprob": -0.23428206247826144,
        "compression_ratio": 1.6564625850340136,
        "end": 720.34,
        "id": 194,
        "no_speech_prob": 0.0007916195900179446,
        "seek": 71902,
        "start": 719.02,
        "temperature": 0,
        "text": " what the difference is.",
        "tokens": [
          50364,
          437,
          264,
          2649,
          307,
          13,
          50430
        ]
      },
      {
        "avg_logprob": -0.23428206247826144,
        "compression_ratio": 1.6564625850340136,
        "end": 723.8199999999999,
        "id": 195,
        "no_speech_prob": 0.0007916195900179446,
        "seek": 71902,
        "start": 720.34,
        "temperature": 0,
        "text": " So if you have a laptop that you're working on",
        "tokens": [
          50430,
          407,
          498,
          291,
          362,
          257,
          10732,
          300,
          291,
          434,
          1364,
          322,
          50604
        ]
      },
      {
        "avg_logprob": -0.23428206247826144,
        "compression_ratio": 1.6564625850340136,
        "end": 725.9,
        "id": 196,
        "no_speech_prob": 0.0007916195900179446,
        "seek": 71902,
        "start": 723.8199999999999,
        "temperature": 0,
        "text": " and it has a web browser in it, you",
        "tokens": [
          50604,
          293,
          309,
          575,
          257,
          3670,
          11185,
          294,
          309,
          11,
          291,
          50708
        ]
      },
      {
        "avg_logprob": -0.23428206247826144,
        "compression_ratio": 1.6564625850340136,
        "end": 729.9399999999999,
        "id": 197,
        "no_speech_prob": 0.0007916195900179446,
        "seek": 71902,
        "start": 725.9,
        "temperature": 0,
        "text": " might be running your p5.js sketch right there",
        "tokens": [
          50708,
          1062,
          312,
          2614,
          428,
          280,
          20,
          13,
          25530,
          12325,
          558,
          456,
          50910
        ]
      },
      {
        "avg_logprob": -0.23428206247826144,
        "compression_ratio": 1.6564625850340136,
        "end": 731.62,
        "id": 198,
        "no_speech_prob": 0.0007916195900179446,
        "seek": 71902,
        "start": 729.9399999999999,
        "temperature": 0,
        "text": " in the browser itself.",
        "tokens": [
          50910,
          294,
          264,
          11185,
          2564,
          13,
          50994
        ]
      },
      {
        "avg_logprob": -0.23428206247826144,
        "compression_ratio": 1.6564625850340136,
        "end": 734.02,
        "id": 199,
        "no_speech_prob": 0.0007916195900179446,
        "seek": 71902,
        "start": 731.62,
        "temperature": 0,
        "text": " So this is going to get you very far.",
        "tokens": [
          50994,
          407,
          341,
          307,
          516,
          281,
          483,
          291,
          588,
          1400,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.23428206247826144,
        "compression_ratio": 1.6564625850340136,
        "end": 737.38,
        "id": 200,
        "no_speech_prob": 0.0007916195900179446,
        "seek": 71902,
        "start": 734.02,
        "temperature": 0,
        "text": " There is so much you can do with just this, as we've seen.",
        "tokens": [
          51114,
          821,
          307,
          370,
          709,
          291,
          393,
          360,
          365,
          445,
          341,
          11,
          382,
          321,
          600,
          1612,
          13,
          51282
        ]
      },
      {
        "avg_logprob": -0.23428206247826144,
        "compression_ratio": 1.6564625850340136,
        "end": 740.26,
        "id": 201,
        "no_speech_prob": 0.0007916195900179446,
        "seek": 71902,
        "start": 737.38,
        "temperature": 0,
        "text": " Now, you can do word counting and Markov chains",
        "tokens": [
          51282,
          823,
          11,
          291,
          393,
          360,
          1349,
          13251,
          293,
          3934,
          5179,
          12626,
          51426
        ]
      },
      {
        "avg_logprob": -0.23428206247826144,
        "compression_ratio": 1.6564625850340136,
        "end": 741.6999999999999,
        "id": 202,
        "no_speech_prob": 0.0007916195900179446,
        "seek": 71902,
        "start": 740.26,
        "temperature": 0,
        "text": " and all sorts of projects.",
        "tokens": [
          51426,
          293,
          439,
          7527,
          295,
          4455,
          13,
          51498
        ]
      },
      {
        "avg_logprob": -0.23428206247826144,
        "compression_ratio": 1.6564625850340136,
        "end": 743.54,
        "id": 203,
        "no_speech_prob": 0.0007916195900179446,
        "seek": 71902,
        "start": 741.6999999999999,
        "temperature": 0,
        "text": " But there are some limitations here.",
        "tokens": [
          51498,
          583,
          456,
          366,
          512,
          15705,
          510,
          13,
          51590
        ]
      },
      {
        "avg_logprob": -0.23428206247826144,
        "compression_ratio": 1.6564625850340136,
        "end": 745.9399999999999,
        "id": 204,
        "no_speech_prob": 0.0007916195900179446,
        "seek": 71902,
        "start": 743.54,
        "temperature": 0,
        "text": " So for example, let's just go back and think about word",
        "tokens": [
          51590,
          407,
          337,
          1365,
          11,
          718,
          311,
          445,
          352,
          646,
          293,
          519,
          466,
          1349,
          51710
        ]
      },
      {
        "avg_logprob": -0.23428206247826144,
        "compression_ratio": 1.6564625850340136,
        "end": 746.86,
        "id": 205,
        "no_speech_prob": 0.0007916195900179446,
        "seek": 71902,
        "start": 745.9399999999999,
        "temperature": 0,
        "text": " counting.",
        "tokens": [
          51710,
          13251,
          13,
          51756
        ]
      },
      {
        "avg_logprob": -0.23428206247826144,
        "compression_ratio": 1.6564625850340136,
        "end": 748.46,
        "id": 206,
        "no_speech_prob": 0.0007916195900179446,
        "seek": 71902,
        "start": 746.86,
        "temperature": 0,
        "text": " So one of the things we did is, OK,",
        "tokens": [
          51756,
          407,
          472,
          295,
          264,
          721,
          321,
          630,
          307,
          11,
          2264,
          11,
          51836
        ]
      },
      {
        "avg_logprob": -0.21419231448553305,
        "compression_ratio": 1.6099585062240664,
        "end": 752.1,
        "id": 207,
        "no_speech_prob": 0.00013135054905433208,
        "seek": 74846,
        "start": 748.46,
        "temperature": 0,
        "text": " so you have some text document.",
        "tokens": [
          50364,
          370,
          291,
          362,
          512,
          2487,
          4166,
          13,
          50546
        ]
      },
      {
        "avg_logprob": -0.21419231448553305,
        "compression_ratio": 1.6099585062240664,
        "end": 754.82,
        "id": 208,
        "no_speech_prob": 0.00013135054905433208,
        "seek": 74846,
        "start": 752.1,
        "temperature": 0,
        "text": " And you want to count how many times each word appears",
        "tokens": [
          50546,
          400,
          291,
          528,
          281,
          1207,
          577,
          867,
          1413,
          1184,
          1349,
          7038,
          50682
        ]
      },
      {
        "avg_logprob": -0.21419231448553305,
        "compression_ratio": 1.6099585062240664,
        "end": 757.98,
        "id": 209,
        "no_speech_prob": 0.00013135054905433208,
        "seek": 74846,
        "start": 754.82,
        "temperature": 0,
        "text": " in that text document and visualize it in some way",
        "tokens": [
          50682,
          294,
          300,
          2487,
          4166,
          293,
          23273,
          309,
          294,
          512,
          636,
          50840
        ]
      },
      {
        "avg_logprob": -0.21419231448553305,
        "compression_ratio": 1.6099585062240664,
        "end": 759.6600000000001,
        "id": 210,
        "no_speech_prob": 0.00013135054905433208,
        "seek": 74846,
        "start": 757.98,
        "temperature": 0,
        "text": " with your p5.js sketch.",
        "tokens": [
          50840,
          365,
          428,
          280,
          20,
          13,
          25530,
          12325,
          13,
          50924
        ]
      },
      {
        "avg_logprob": -0.21419231448553305,
        "compression_ratio": 1.6099585062240664,
        "end": 762.6600000000001,
        "id": 211,
        "no_speech_prob": 0.00013135054905433208,
        "seek": 74846,
        "start": 759.6600000000001,
        "temperature": 0,
        "text": " This will work just fine all client-side,",
        "tokens": [
          50924,
          639,
          486,
          589,
          445,
          2489,
          439,
          6423,
          12,
          1812,
          11,
          51074
        ]
      },
      {
        "avg_logprob": -0.21419231448553305,
        "compression_ratio": 1.6099585062240664,
        "end": 766.9000000000001,
        "id": 212,
        "no_speech_prob": 0.00013135054905433208,
        "seek": 74846,
        "start": 762.6600000000001,
        "temperature": 0,
        "text": " unless a couple of things.",
        "tokens": [
          51074,
          5969,
          257,
          1916,
          295,
          721,
          13,
          51286
        ]
      },
      {
        "avg_logprob": -0.21419231448553305,
        "compression_ratio": 1.6099585062240664,
        "end": 768.74,
        "id": 213,
        "no_speech_prob": 0.00013135054905433208,
        "seek": 74846,
        "start": 766.9000000000001,
        "temperature": 0,
        "text": " One is, where is this data coming from?",
        "tokens": [
          51286,
          1485,
          307,
          11,
          689,
          307,
          341,
          1412,
          1348,
          490,
          30,
          51378
        ]
      },
      {
        "avg_logprob": -0.21419231448553305,
        "compression_ratio": 1.6099585062240664,
        "end": 770.58,
        "id": 214,
        "no_speech_prob": 0.00013135054905433208,
        "seek": 74846,
        "start": 768.74,
        "temperature": 0,
        "text": " If you have a little text file that you",
        "tokens": [
          51378,
          759,
          291,
          362,
          257,
          707,
          2487,
          3991,
          300,
          291,
          51470
        ]
      },
      {
        "avg_logprob": -0.21419231448553305,
        "compression_ratio": 1.6099585062240664,
        "end": 772.1,
        "id": 215,
        "no_speech_prob": 0.00013135054905433208,
        "seek": 74846,
        "start": 770.58,
        "temperature": 0,
        "text": " can put on your server, great.",
        "tokens": [
          51470,
          393,
          829,
          322,
          428,
          7154,
          11,
          869,
          13,
          51546
        ]
      },
      {
        "avg_logprob": -0.21419231448553305,
        "compression_ratio": 1.6099585062240664,
        "end": 774.5400000000001,
        "id": 216,
        "no_speech_prob": 0.00013135054905433208,
        "seek": 74846,
        "start": 772.1,
        "temperature": 0,
        "text": " But what if this is, instead of one text file,",
        "tokens": [
          51546,
          583,
          437,
          498,
          341,
          307,
          11,
          2602,
          295,
          472,
          2487,
          3991,
          11,
          51668
        ]
      },
      {
        "avg_logprob": -0.2454321339445294,
        "compression_ratio": 1.5523012552301256,
        "end": 780.8199999999999,
        "id": 217,
        "no_speech_prob": 0.00005064466313342564,
        "seek": 77454,
        "start": 774.54,
        "temperature": 0,
        "text": " what if this is 1,000 or 100,000 or 1 million?",
        "tokens": [
          50364,
          437,
          498,
          341,
          307,
          502,
          11,
          1360,
          420,
          2319,
          11,
          1360,
          420,
          502,
          2459,
          30,
          50678
        ]
      },
      {
        "avg_logprob": -0.2454321339445294,
        "compression_ratio": 1.5523012552301256,
        "end": 786.26,
        "id": 218,
        "no_speech_prob": 0.00005064466313342564,
        "seek": 77454,
        "start": 780.8199999999999,
        "temperature": 0,
        "text": " I need that Austin Powers music, 1 million text files.",
        "tokens": [
          50678,
          286,
          643,
          300,
          15356,
          47278,
          1318,
          11,
          502,
          2459,
          2487,
          7098,
          13,
          50950
        ]
      },
      {
        "avg_logprob": -0.2454321339445294,
        "compression_ratio": 1.5523012552301256,
        "end": 789.14,
        "id": 219,
        "no_speech_prob": 0.00005064466313342564,
        "seek": 77454,
        "start": 786.26,
        "temperature": 0,
        "text": " It's going to be kind of unreasonable to expect",
        "tokens": [
          50950,
          467,
          311,
          516,
          281,
          312,
          733,
          295,
          41730,
          281,
          2066,
          51094
        ]
      },
      {
        "avg_logprob": -0.2454321339445294,
        "compression_ratio": 1.5523012552301256,
        "end": 792.18,
        "id": 220,
        "no_speech_prob": 0.00005064466313342564,
        "seek": 77454,
        "start": 789.14,
        "temperature": 0,
        "text": " the client-side, just your p5.js sketch in the browser,",
        "tokens": [
          51094,
          264,
          6423,
          12,
          1812,
          11,
          445,
          428,
          280,
          20,
          13,
          25530,
          12325,
          294,
          264,
          11185,
          11,
          51246
        ]
      },
      {
        "avg_logprob": -0.2454321339445294,
        "compression_ratio": 1.5523012552301256,
        "end": 794.5,
        "id": 221,
        "no_speech_prob": 0.00005064466313342564,
        "seek": 77454,
        "start": 792.18,
        "temperature": 0,
        "text": " to sit there and churn through millions of text files",
        "tokens": [
          51246,
          281,
          1394,
          456,
          293,
          417,
          925,
          807,
          6803,
          295,
          2487,
          7098,
          51362
        ]
      },
      {
        "avg_logprob": -0.2454321339445294,
        "compression_ratio": 1.5523012552301256,
        "end": 798.38,
        "id": 222,
        "no_speech_prob": 0.00005064466313342564,
        "seek": 77454,
        "start": 794.5,
        "temperature": 0,
        "text": " for 10 minutes, a half an hour, and then produce the result.",
        "tokens": [
          51362,
          337,
          1266,
          2077,
          11,
          257,
          1922,
          364,
          1773,
          11,
          293,
          550,
          5258,
          264,
          1874,
          13,
          51556
        ]
      },
      {
        "avg_logprob": -0.2454321339445294,
        "compression_ratio": 1.5523012552301256,
        "end": 803.3399999999999,
        "id": 223,
        "no_speech_prob": 0.00005064466313342564,
        "seek": 77454,
        "start": 798.38,
        "temperature": 0,
        "text": " This is where server-side programming can come in.",
        "tokens": [
          51556,
          639,
          307,
          689,
          7154,
          12,
          1812,
          9410,
          393,
          808,
          294,
          13,
          51804
        ]
      },
      {
        "avg_logprob": -0.24009292070255722,
        "compression_ratio": 1.7376425855513309,
        "end": 805.6600000000001,
        "id": 224,
        "no_speech_prob": 0.000013007066627324093,
        "seek": 80334,
        "start": 803.34,
        "temperature": 0,
        "text": " And now, the platform that I'm going",
        "tokens": [
          50364,
          400,
          586,
          11,
          264,
          3663,
          300,
          286,
          478,
          516,
          50480
        ]
      },
      {
        "avg_logprob": -0.24009292070255722,
        "compression_ratio": 1.7376425855513309,
        "end": 809.38,
        "id": 225,
        "no_speech_prob": 0.000013007066627324093,
        "seek": 80334,
        "start": 805.6600000000001,
        "temperature": 0,
        "text": " to use for server-side programming is node.js.",
        "tokens": [
          50480,
          281,
          764,
          337,
          7154,
          12,
          1812,
          9410,
          307,
          9984,
          13,
          25530,
          13,
          50666
        ]
      },
      {
        "avg_logprob": -0.24009292070255722,
        "compression_ratio": 1.7376425855513309,
        "end": 811.5400000000001,
        "id": 226,
        "no_speech_prob": 0.000013007066627324093,
        "seek": 80334,
        "start": 809.38,
        "temperature": 0,
        "text": " Of course, there are a variety of ways you can approach",
        "tokens": [
          50666,
          2720,
          1164,
          11,
          456,
          366,
          257,
          5673,
          295,
          2098,
          291,
          393,
          3109,
          50774
        ]
      },
      {
        "avg_logprob": -0.24009292070255722,
        "compression_ratio": 1.7376425855513309,
        "end": 812.74,
        "id": 227,
        "no_speech_prob": 0.000013007066627324093,
        "seek": 80334,
        "start": 811.5400000000001,
        "temperature": 0,
        "text": " server-side programming.",
        "tokens": [
          50774,
          7154,
          12,
          1812,
          9410,
          13,
          50834
        ]
      },
      {
        "avg_logprob": -0.24009292070255722,
        "compression_ratio": 1.7376425855513309,
        "end": 814.7800000000001,
        "id": 228,
        "no_speech_prob": 0.000013007066627324093,
        "seek": 80334,
        "start": 812.74,
        "temperature": 0,
        "text": " So OK, so there's a lot of pieces to this.",
        "tokens": [
          50834,
          407,
          2264,
          11,
          370,
          456,
          311,
          257,
          688,
          295,
          3755,
          281,
          341,
          13,
          50936
        ]
      },
      {
        "avg_logprob": -0.24009292070255722,
        "compression_ratio": 1.7376425855513309,
        "end": 816.7800000000001,
        "id": 229,
        "no_speech_prob": 0.000013007066627324093,
        "seek": 80334,
        "start": 814.7800000000001,
        "temperature": 0,
        "text": " So one thing that we've established",
        "tokens": [
          50936,
          407,
          472,
          551,
          300,
          321,
          600,
          7545,
          51036
        ]
      },
      {
        "avg_logprob": -0.24009292070255722,
        "compression_ratio": 1.7376425855513309,
        "end": 819.82,
        "id": 230,
        "no_speech_prob": 0.000013007066627324093,
        "seek": 80334,
        "start": 816.7800000000001,
        "temperature": 0,
        "text": " is, if you have a really large data set,",
        "tokens": [
          51036,
          307,
          11,
          498,
          291,
          362,
          257,
          534,
          2416,
          1412,
          992,
          11,
          51188
        ]
      },
      {
        "avg_logprob": -0.24009292070255722,
        "compression_ratio": 1.7376425855513309,
        "end": 823.58,
        "id": 231,
        "no_speech_prob": 0.000013007066627324093,
        "seek": 80334,
        "start": 819.82,
        "temperature": 0,
        "text": " perhaps server-side programming is going to help you.",
        "tokens": [
          51188,
          4317,
          7154,
          12,
          1812,
          9410,
          307,
          516,
          281,
          854,
          291,
          13,
          51376
        ]
      },
      {
        "avg_logprob": -0.24009292070255722,
        "compression_ratio": 1.7376425855513309,
        "end": 824.74,
        "id": 232,
        "no_speech_prob": 0.000013007066627324093,
        "seek": 80334,
        "start": 823.58,
        "temperature": 0,
        "text": " Here's another thing.",
        "tokens": [
          51376,
          1692,
          311,
          1071,
          551,
          13,
          51434
        ]
      },
      {
        "avg_logprob": -0.24009292070255722,
        "compression_ratio": 1.7376425855513309,
        "end": 829.5,
        "id": 233,
        "no_speech_prob": 0.000013007066627324093,
        "seek": 80334,
        "start": 824.74,
        "temperature": 0,
        "text": " What if you have users entering in their favorite words?",
        "tokens": [
          51434,
          708,
          498,
          291,
          362,
          5022,
          11104,
          294,
          641,
          2954,
          2283,
          30,
          51672
        ]
      },
      {
        "avg_logprob": -0.24009292070255722,
        "compression_ratio": 1.7376425855513309,
        "end": 832.46,
        "id": 234,
        "no_speech_prob": 0.000013007066627324093,
        "seek": 80334,
        "start": 829.5,
        "temperature": 0,
        "text": " And you have your Mad Libs application.",
        "tokens": [
          51672,
          400,
          291,
          362,
          428,
          5326,
          15834,
          82,
          3861,
          13,
          51820
        ]
      },
      {
        "avg_logprob": -0.27679770762526146,
        "compression_ratio": 1.7126436781609196,
        "end": 834.7800000000001,
        "id": 235,
        "no_speech_prob": 0.00009028003114508465,
        "seek": 83246,
        "start": 832.5400000000001,
        "temperature": 0,
        "text": " They're entering in words, nouns, adjectives",
        "tokens": [
          50368,
          814,
          434,
          11104,
          294,
          2283,
          11,
          48184,
          11,
          29378,
          1539,
          50480
        ]
      },
      {
        "avg_logprob": -0.27679770762526146,
        "compression_ratio": 1.7126436781609196,
        "end": 837.6600000000001,
        "id": 236,
        "no_speech_prob": 0.00009028003114508465,
        "seek": 83246,
        "start": 834.7800000000001,
        "temperature": 0,
        "text": " to generate stories.",
        "tokens": [
          50480,
          281,
          8460,
          3676,
          13,
          50624
        ]
      },
      {
        "avg_logprob": -0.27679770762526146,
        "compression_ratio": 1.7126436781609196,
        "end": 840.9000000000001,
        "id": 237,
        "no_speech_prob": 0.00009028003114508465,
        "seek": 83246,
        "start": 837.6600000000001,
        "temperature": 0,
        "text": " What if you want, every time the user comes back,",
        "tokens": [
          50624,
          708,
          498,
          291,
          528,
          11,
          633,
          565,
          264,
          4195,
          1487,
          646,
          11,
          50786
        ]
      },
      {
        "avg_logprob": -0.27679770762526146,
        "compression_ratio": 1.7126436781609196,
        "end": 842.7,
        "id": 238,
        "no_speech_prob": 0.00009028003114508465,
        "seek": 83246,
        "start": 840.9000000000001,
        "temperature": 0,
        "text": " to be able to see what they entered before?",
        "tokens": [
          50786,
          281,
          312,
          1075,
          281,
          536,
          437,
          436,
          9065,
          949,
          30,
          50876
        ]
      },
      {
        "avg_logprob": -0.27679770762526146,
        "compression_ratio": 1.7126436781609196,
        "end": 845.34,
        "id": 239,
        "no_speech_prob": 0.00009028003114508465,
        "seek": 83246,
        "start": 842.7,
        "temperature": 0,
        "text": " Or what if you want, when a user comes to the page,",
        "tokens": [
          50876,
          1610,
          437,
          498,
          291,
          528,
          11,
          562,
          257,
          4195,
          1487,
          281,
          264,
          3028,
          11,
          51008
        ]
      },
      {
        "avg_logprob": -0.27679770762526146,
        "compression_ratio": 1.7126436781609196,
        "end": 847.4200000000001,
        "id": 240,
        "no_speech_prob": 0.00009028003114508465,
        "seek": 83246,
        "start": 845.34,
        "temperature": 0,
        "text": " to be able to see what everybody has entered?",
        "tokens": [
          51008,
          281,
          312,
          1075,
          281,
          536,
          437,
          2201,
          575,
          9065,
          30,
          51112
        ]
      },
      {
        "avg_logprob": -0.27679770762526146,
        "compression_ratio": 1.7126436781609196,
        "end": 849.34,
        "id": 241,
        "no_speech_prob": 0.00009028003114508465,
        "seek": 83246,
        "start": 847.4200000000001,
        "temperature": 0,
        "text": " This is also so large.",
        "tokens": [
          51112,
          639,
          307,
          611,
          370,
          2416,
          13,
          51208
        ]
      },
      {
        "avg_logprob": -0.27679770762526146,
        "compression_ratio": 1.7126436781609196,
        "end": 851.4200000000001,
        "id": 242,
        "no_speech_prob": 0.00009028003114508465,
        "seek": 83246,
        "start": 849.34,
        "temperature": 0,
        "text": " There's some reasons for server-side programming is",
        "tokens": [
          51208,
          821,
          311,
          512,
          4112,
          337,
          7154,
          12,
          1812,
          9410,
          307,
          51312
        ]
      },
      {
        "avg_logprob": -0.27679770762526146,
        "compression_ratio": 1.7126436781609196,
        "end": 853.86,
        "id": 243,
        "no_speech_prob": 0.00009028003114508465,
        "seek": 83246,
        "start": 851.4200000000001,
        "temperature": 0,
        "text": " large data sets.",
        "tokens": [
          51312,
          2416,
          1412,
          6352,
          13,
          51434
        ]
      },
      {
        "avg_logprob": -0.27679770762526146,
        "compression_ratio": 1.7126436781609196,
        "end": 857.3000000000001,
        "id": 244,
        "no_speech_prob": 0.00009028003114508465,
        "seek": 83246,
        "start": 853.86,
        "temperature": 0,
        "text": " Another one is persistence.",
        "tokens": [
          51434,
          3996,
          472,
          307,
          37617,
          13,
          51606
        ]
      },
      {
        "avg_logprob": -0.27679770762526146,
        "compression_ratio": 1.7126436781609196,
        "end": 859.86,
        "id": 245,
        "no_speech_prob": 0.00009028003114508465,
        "seek": 83246,
        "start": 857.3000000000001,
        "temperature": 0,
        "text": " And I don't know how to spell that, persistence,",
        "tokens": [
          51606,
          400,
          286,
          500,
          380,
          458,
          577,
          281,
          9827,
          300,
          11,
          37617,
          11,
          51734
        ]
      },
      {
        "avg_logprob": -0.27679770762526146,
        "compression_ratio": 1.7126436781609196,
        "end": 861.46,
        "id": 246,
        "no_speech_prob": 0.00009028003114508465,
        "seek": 83246,
        "start": 859.86,
        "temperature": 0,
        "text": " meaning saving data.",
        "tokens": [
          51734,
          3620,
          6816,
          1412,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.17966328430175782,
        "compression_ratio": 1.7137546468401488,
        "end": 863.86,
        "id": 247,
        "no_speech_prob": 0.00003219229984097183,
        "seek": 86146,
        "start": 861.46,
        "temperature": 0,
        "text": " And there's a variety of ways you can save data.",
        "tokens": [
          50364,
          400,
          456,
          311,
          257,
          5673,
          295,
          2098,
          291,
          393,
          3155,
          1412,
          13,
          50484
        ]
      },
      {
        "avg_logprob": -0.17966328430175782,
        "compression_ratio": 1.7137546468401488,
        "end": 865.94,
        "id": 248,
        "no_speech_prob": 0.00003219229984097183,
        "seek": 86146,
        "start": 863.86,
        "temperature": 0,
        "text": " But with client-side JavaScript only,",
        "tokens": [
          50484,
          583,
          365,
          6423,
          12,
          1812,
          15778,
          787,
          11,
          50588
        ]
      },
      {
        "avg_logprob": -0.17966328430175782,
        "compression_ratio": 1.7137546468401488,
        "end": 869.34,
        "id": 249,
        "no_speech_prob": 0.00003219229984097183,
        "seek": 86146,
        "start": 865.94,
        "temperature": 0,
        "text": " while you can download data to that user's local computer,",
        "tokens": [
          50588,
          1339,
          291,
          393,
          5484,
          1412,
          281,
          300,
          4195,
          311,
          2654,
          3820,
          11,
          50758
        ]
      },
      {
        "avg_logprob": -0.17966328430175782,
        "compression_ratio": 1.7137546468401488,
        "end": 873.5,
        "id": 250,
        "no_speech_prob": 0.00003219229984097183,
        "seek": 86146,
        "start": 869.34,
        "temperature": 0,
        "text": " there's no way to save data across multiple sessions using",
        "tokens": [
          50758,
          456,
          311,
          572,
          636,
          281,
          3155,
          1412,
          2108,
          3866,
          11081,
          1228,
          50966
        ]
      },
      {
        "avg_logprob": -0.17966328430175782,
        "compression_ratio": 1.7137546468401488,
        "end": 875.38,
        "id": 251,
        "no_speech_prob": 0.00003219229984097183,
        "seek": 86146,
        "start": 873.5,
        "temperature": 0,
        "text": " a particular web application.",
        "tokens": [
          50966,
          257,
          1729,
          3670,
          3861,
          13,
          51060
        ]
      },
      {
        "avg_logprob": -0.17966328430175782,
        "compression_ratio": 1.7137546468401488,
        "end": 877.3000000000001,
        "id": 252,
        "no_speech_prob": 0.00003219229984097183,
        "seek": 86146,
        "start": 875.38,
        "temperature": 0,
        "text": " So this server is a place where, if we",
        "tokens": [
          51060,
          407,
          341,
          7154,
          307,
          257,
          1081,
          689,
          11,
          498,
          321,
          51156
        ]
      },
      {
        "avg_logprob": -0.17966328430175782,
        "compression_ratio": 1.7137546468401488,
        "end": 878.9000000000001,
        "id": 253,
        "no_speech_prob": 0.00003219229984097183,
        "seek": 86146,
        "start": 877.3000000000001,
        "temperature": 0,
        "text": " could send data to the server, it",
        "tokens": [
          51156,
          727,
          2845,
          1412,
          281,
          264,
          7154,
          11,
          309,
          51236
        ]
      },
      {
        "avg_logprob": -0.17966328430175782,
        "compression_ratio": 1.7137546468401488,
        "end": 882.7800000000001,
        "id": 254,
        "no_speech_prob": 0.00003219229984097183,
        "seek": 86146,
        "start": 878.9000000000001,
        "temperature": 0,
        "text": " could be saved on the server in what's known as a database.",
        "tokens": [
          51236,
          727,
          312,
          6624,
          322,
          264,
          7154,
          294,
          437,
          311,
          2570,
          382,
          257,
          8149,
          13,
          51430
        ]
      },
      {
        "avg_logprob": -0.17966328430175782,
        "compression_ratio": 1.7137546468401488,
        "end": 884.46,
        "id": 255,
        "no_speech_prob": 0.00003219229984097183,
        "seek": 86146,
        "start": 882.7800000000001,
        "temperature": 0,
        "text": " So these are some pieces to why you",
        "tokens": [
          51430,
          407,
          613,
          366,
          512,
          3755,
          281,
          983,
          291,
          51514
        ]
      },
      {
        "avg_logprob": -0.17966328430175782,
        "compression_ratio": 1.7137546468401488,
        "end": 886.7,
        "id": 256,
        "no_speech_prob": 0.00003219229984097183,
        "seek": 86146,
        "start": 884.46,
        "temperature": 0,
        "text": " need server-side programming.",
        "tokens": [
          51514,
          643,
          7154,
          12,
          1812,
          9410,
          13,
          51626
        ]
      },
      {
        "avg_logprob": -0.17966328430175782,
        "compression_ratio": 1.7137546468401488,
        "end": 891.1,
        "id": 257,
        "no_speech_prob": 0.00003219229984097183,
        "seek": 86146,
        "start": 886.7,
        "temperature": 0,
        "text": " Now, here's another reason.",
        "tokens": [
          51626,
          823,
          11,
          510,
          311,
          1071,
          1778,
          13,
          51846
        ]
      },
      {
        "avg_logprob": -0.24250669737119931,
        "compression_ratio": 1.6260504201680672,
        "end": 895.86,
        "id": 258,
        "no_speech_prob": 0.00019411224639043212,
        "seek": 89110,
        "start": 891.1,
        "temperature": 0,
        "text": " What if you want to expose everything, your data,",
        "tokens": [
          50364,
          708,
          498,
          291,
          528,
          281,
          19219,
          1203,
          11,
          428,
          1412,
          11,
          50602
        ]
      },
      {
        "avg_logprob": -0.24250669737119931,
        "compression_ratio": 1.6260504201680672,
        "end": 898.58,
        "id": 259,
        "no_speech_prob": 0.00019411224639043212,
        "seek": 89110,
        "start": 895.86,
        "temperature": 0,
        "text": " or your algorithm, or the thing you're working on,",
        "tokens": [
          50602,
          420,
          428,
          9284,
          11,
          420,
          264,
          551,
          291,
          434,
          1364,
          322,
          11,
          50738
        ]
      },
      {
        "avg_logprob": -0.24250669737119931,
        "compression_ratio": 1.6260504201680672,
        "end": 902.98,
        "id": 260,
        "no_speech_prob": 0.00019411224639043212,
        "seek": 89110,
        "start": 898.58,
        "temperature": 0,
        "text": " to other users as an API?",
        "tokens": [
          50738,
          281,
          661,
          5022,
          382,
          364,
          9362,
          30,
          50958
        ]
      },
      {
        "avg_logprob": -0.24250669737119931,
        "compression_ratio": 1.6260504201680672,
        "end": 904.58,
        "id": 261,
        "no_speech_prob": 0.00019411224639043212,
        "seek": 89110,
        "start": 902.98,
        "temperature": 0,
        "text": " This is another reason why you might",
        "tokens": [
          50958,
          639,
          307,
          1071,
          1778,
          983,
          291,
          1062,
          51038
        ]
      },
      {
        "avg_logprob": -0.24250669737119931,
        "compression_ratio": 1.6260504201680672,
        "end": 905.78,
        "id": 262,
        "no_speech_prob": 0.00019411224639043212,
        "seek": 89110,
        "start": 904.58,
        "temperature": 0,
        "text": " want server-side programming.",
        "tokens": [
          51038,
          528,
          7154,
          12,
          1812,
          9410,
          13,
          51098
        ]
      },
      {
        "avg_logprob": -0.24250669737119931,
        "compression_ratio": 1.6260504201680672,
        "end": 907.12,
        "id": 263,
        "no_speech_prob": 0.00019411224639043212,
        "seek": 89110,
        "start": 905.78,
        "temperature": 0,
        "text": " And this is mostly what I'm going",
        "tokens": [
          51098,
          400,
          341,
          307,
          5240,
          437,
          286,
          478,
          516,
          51165
        ]
      },
      {
        "avg_logprob": -0.24250669737119931,
        "compression_ratio": 1.6260504201680672,
        "end": 911.1,
        "id": 264,
        "no_speech_prob": 0.00019411224639043212,
        "seek": 89110,
        "start": 907.12,
        "temperature": 0,
        "text": " to focus on in this particular week eight session, session",
        "tokens": [
          51165,
          281,
          1879,
          322,
          294,
          341,
          1729,
          1243,
          3180,
          5481,
          11,
          5481,
          51364
        ]
      },
      {
        "avg_logprob": -0.24250669737119931,
        "compression_ratio": 1.6260504201680672,
        "end": 911.66,
        "id": 265,
        "no_speech_prob": 0.00019411224639043212,
        "seek": 89110,
        "start": 911.1,
        "temperature": 0,
        "text": " eight.",
        "tokens": [
          51364,
          3180,
          13,
          51392
        ]
      },
      {
        "avg_logprob": -0.24250669737119931,
        "compression_ratio": 1.6260504201680672,
        "end": 914.0600000000001,
        "id": 266,
        "no_speech_prob": 0.00019411224639043212,
        "seek": 89110,
        "start": 911.66,
        "temperature": 0,
        "text": " However, I'm going to kind of look at all of these pieces",
        "tokens": [
          51392,
          2908,
          11,
          286,
          478,
          516,
          281,
          733,
          295,
          574,
          412,
          439,
          295,
          613,
          3755,
          51512
        ]
      },
      {
        "avg_logprob": -0.24250669737119931,
        "compression_ratio": 1.6260504201680672,
        "end": 915.86,
        "id": 267,
        "no_speech_prob": 0.00019411224639043212,
        "seek": 89110,
        "start": 914.0600000000001,
        "temperature": 0,
        "text": " by the time I get to the end of it.",
        "tokens": [
          51512,
          538,
          264,
          565,
          286,
          483,
          281,
          264,
          917,
          295,
          309,
          13,
          51602
        ]
      },
      {
        "avg_logprob": -0.2748962210006073,
        "compression_ratio": 1.7519685039370079,
        "end": 921.78,
        "id": 268,
        "no_speech_prob": 0.1347634494304657,
        "seek": 91586,
        "start": 916.02,
        "temperature": 0,
        "text": " This idea of maybe you have this wonderful spreadsheet of all",
        "tokens": [
          50372,
          639,
          1558,
          295,
          1310,
          291,
          362,
          341,
          3715,
          27733,
          295,
          439,
          50660
        ]
      },
      {
        "avg_logprob": -0.2748962210006073,
        "compression_ratio": 1.7519685039370079,
        "end": 923.74,
        "id": 269,
        "no_speech_prob": 0.1347634494304657,
        "seek": 91586,
        "start": 921.78,
        "temperature": 0,
        "text": " of this information about flowers,",
        "tokens": [
          50660,
          295,
          341,
          1589,
          466,
          8085,
          11,
          50758
        ]
      },
      {
        "avg_logprob": -0.2748962210006073,
        "compression_ratio": 1.7519685039370079,
        "end": 926.62,
        "id": 270,
        "no_speech_prob": 0.1347634494304657,
        "seek": 91586,
        "start": 923.74,
        "temperature": 0,
        "text": " and you want to allow other people to make queries,",
        "tokens": [
          50758,
          293,
          291,
          528,
          281,
          2089,
          661,
          561,
          281,
          652,
          24109,
          11,
          50902
        ]
      },
      {
        "avg_logprob": -0.2748962210006073,
        "compression_ratio": 1.7519685039370079,
        "end": 930.02,
        "id": 271,
        "no_speech_prob": 0.1347634494304657,
        "seek": 91586,
        "start": 926.62,
        "temperature": 0,
        "text": " go to flowerapi.com slash chrysanthemum,",
        "tokens": [
          50902,
          352,
          281,
          8617,
          35891,
          13,
          1112,
          17330,
          417,
          627,
          11491,
          47959,
          449,
          11,
          51072
        ]
      },
      {
        "avg_logprob": -0.2748962210006073,
        "compression_ratio": 1.7519685039370079,
        "end": 932.86,
        "id": 272,
        "no_speech_prob": 0.1347634494304657,
        "seek": 91586,
        "start": 930.02,
        "temperature": 0,
        "text": " or flowerapi.com slash sunflower,",
        "tokens": [
          51072,
          420,
          8617,
          35891,
          13,
          1112,
          17330,
          48215,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.2748962210006073,
        "compression_ratio": 1.7519685039370079,
        "end": 936.02,
        "id": 273,
        "no_speech_prob": 0.1347634494304657,
        "seek": 91586,
        "start": 932.86,
        "temperature": 0,
        "text": " and receive JSON back with all this information about flowers.",
        "tokens": [
          51214,
          293,
          4774,
          31828,
          646,
          365,
          439,
          341,
          1589,
          466,
          8085,
          13,
          51372
        ]
      },
      {
        "avg_logprob": -0.2748962210006073,
        "compression_ratio": 1.7519685039370079,
        "end": 938.5600000000001,
        "id": 274,
        "no_speech_prob": 0.1347634494304657,
        "seek": 91586,
        "start": 936.02,
        "temperature": 0,
        "text": " This is something you're going to want server-side programming",
        "tokens": [
          51372,
          639,
          307,
          746,
          291,
          434,
          516,
          281,
          528,
          7154,
          12,
          1812,
          9410,
          51499
        ]
      },
      {
        "avg_logprob": -0.2748962210006073,
        "compression_ratio": 1.7519685039370079,
        "end": 939.26,
        "id": 275,
        "no_speech_prob": 0.1347634494304657,
        "seek": 91586,
        "start": 938.5600000000001,
        "temperature": 0,
        "text": " for as well.",
        "tokens": [
          51499,
          337,
          382,
          731,
          13,
          51534
        ]
      },
      {
        "avg_logprob": -0.2748962210006073,
        "compression_ratio": 1.7519685039370079,
        "end": 941.9,
        "id": 276,
        "no_speech_prob": 0.1347634494304657,
        "seek": 91586,
        "start": 939.26,
        "temperature": 0,
        "text": " And this is going to be the focus here.",
        "tokens": [
          51534,
          400,
          341,
          307,
          516,
          281,
          312,
          264,
          1879,
          510,
          13,
          51666
        ]
      },
      {
        "avg_logprob": -0.2748962210006073,
        "compression_ratio": 1.7519685039370079,
        "end": 944.3000000000001,
        "id": 277,
        "no_speech_prob": 0.1347634494304657,
        "seek": 91586,
        "start": 941.9,
        "temperature": 0,
        "text": " Now, there was one other thing on my mind,",
        "tokens": [
          51666,
          823,
          11,
          456,
          390,
          472,
          661,
          551,
          322,
          452,
          1575,
          11,
          51786
        ]
      },
      {
        "avg_logprob": -0.28163296243418817,
        "compression_ratio": 1.721311475409836,
        "end": 948.5799999999999,
        "id": 278,
        "no_speech_prob": 0.00002144491190847475,
        "seek": 94430,
        "start": 944.3,
        "temperature": 0,
        "text": " and I'm trying to kind of come up with it.",
        "tokens": [
          50364,
          293,
          286,
          478,
          1382,
          281,
          733,
          295,
          808,
          493,
          365,
          309,
          13,
          50578
        ]
      },
      {
        "avg_logprob": -0.28163296243418817,
        "compression_ratio": 1.721311475409836,
        "end": 952.26,
        "id": 279,
        "no_speech_prob": 0.00002144491190847475,
        "seek": 94430,
        "start": 948.5799999999999,
        "temperature": 0,
        "text": " API persistent large data set.",
        "tokens": [
          50578,
          9362,
          24315,
          2416,
          1412,
          992,
          13,
          50762
        ]
      },
      {
        "avg_logprob": -0.28163296243418817,
        "compression_ratio": 1.721311475409836,
        "end": 955.3399999999999,
        "id": 280,
        "no_speech_prob": 0.00002144491190847475,
        "seek": 94430,
        "start": 952.26,
        "temperature": 0,
        "text": " Aha, I thought of it.",
        "tokens": [
          50762,
          27448,
          11,
          286,
          1194,
          295,
          309,
          13,
          50916
        ]
      },
      {
        "avg_logprob": -0.28163296243418817,
        "compression_ratio": 1.721311475409836,
        "end": 956.9399999999999,
        "id": 281,
        "no_speech_prob": 0.00002144491190847475,
        "seek": 94430,
        "start": 955.3399999999999,
        "temperature": 0,
        "text": " I'm going to just say scraping.",
        "tokens": [
          50916,
          286,
          478,
          516,
          281,
          445,
          584,
          43738,
          13,
          50996
        ]
      },
      {
        "avg_logprob": -0.28163296243418817,
        "compression_ratio": 1.721311475409836,
        "end": 961.62,
        "id": 282,
        "no_speech_prob": 0.00002144491190847475,
        "seek": 94430,
        "start": 959.9399999999999,
        "temperature": 0,
        "text": " And with persistence, by the way,",
        "tokens": [
          51146,
          400,
          365,
          37617,
          11,
          538,
          264,
          636,
          11,
          51230
        ]
      },
      {
        "avg_logprob": -0.28163296243418817,
        "compression_ratio": 1.721311475409836,
        "end": 963.26,
        "id": 283,
        "no_speech_prob": 0.00002144491190847475,
        "seek": 94430,
        "start": 961.62,
        "temperature": 0,
        "text": " it could be kind of like user accounts",
        "tokens": [
          51230,
          309,
          727,
          312,
          733,
          295,
          411,
          4195,
          9402,
          51312
        ]
      },
      {
        "avg_logprob": -0.28163296243418817,
        "compression_ratio": 1.721311475409836,
        "end": 964.06,
        "id": 284,
        "no_speech_prob": 0.00002144491190847475,
        "seek": 94430,
        "start": 963.26,
        "temperature": 0,
        "text": " and all that sort of stuff.",
        "tokens": [
          51312,
          293,
          439,
          300,
          1333,
          295,
          1507,
          13,
          51352
        ]
      },
      {
        "avg_logprob": -0.28163296243418817,
        "compression_ratio": 1.721311475409836,
        "end": 965.5799999999999,
        "id": 285,
        "no_speech_prob": 0.00002144491190847475,
        "seek": 94430,
        "start": 964.06,
        "temperature": 0,
        "text": " But I'm kind of staying away mostly",
        "tokens": [
          51352,
          583,
          286,
          478,
          733,
          295,
          7939,
          1314,
          5240,
          51428
        ]
      },
      {
        "avg_logprob": -0.28163296243418817,
        "compression_ratio": 1.721311475409836,
        "end": 967.5,
        "id": 286,
        "no_speech_prob": 0.00002144491190847475,
        "seek": 94430,
        "start": 965.5799999999999,
        "temperature": 0,
        "text": " from traditional web development here",
        "tokens": [
          51428,
          490,
          5164,
          3670,
          3250,
          510,
          51524
        ]
      },
      {
        "avg_logprob": -0.28163296243418817,
        "compression_ratio": 1.721311475409836,
        "end": 970.06,
        "id": 287,
        "no_speech_prob": 0.00002144491190847475,
        "seek": 94430,
        "start": 967.5,
        "temperature": 0,
        "text": " and looking at kinds of creative applications of this stuff.",
        "tokens": [
          51524,
          293,
          1237,
          412,
          3685,
          295,
          5880,
          5821,
          295,
          341,
          1507,
          13,
          51652
        ]
      },
      {
        "avg_logprob": -0.28163296243418817,
        "compression_ratio": 1.721311475409836,
        "end": 972.5,
        "id": 288,
        "no_speech_prob": 0.00002144491190847475,
        "seek": 94430,
        "start": 970.06,
        "temperature": 0,
        "text": " But I'm saying scraping because one thing you might have",
        "tokens": [
          51652,
          583,
          286,
          478,
          1566,
          43738,
          570,
          472,
          551,
          291,
          1062,
          362,
          51774
        ]
      },
      {
        "avg_logprob": -0.24636293367575143,
        "compression_ratio": 1.602189781021898,
        "end": 976.18,
        "id": 289,
        "no_speech_prob": 0.00009915225382428616,
        "seek": 97250,
        "start": 972.54,
        "temperature": 0,
        "text": " noticed is in p5.js, if you try to,",
        "tokens": [
          50366,
          5694,
          307,
          294,
          280,
          20,
          13,
          25530,
          11,
          498,
          291,
          853,
          281,
          11,
          50548
        ]
      },
      {
        "avg_logprob": -0.24636293367575143,
        "compression_ratio": 1.602189781021898,
        "end": 980.74,
        "id": 290,
        "no_speech_prob": 0.00009915225382428616,
        "seek": 97250,
        "start": 976.18,
        "temperature": 0,
        "text": " the bane of your existence might be this thing called cores.",
        "tokens": [
          50548,
          264,
          272,
          1929,
          295,
          428,
          9123,
          1062,
          312,
          341,
          551,
          1219,
          24826,
          13,
          50776
        ]
      },
      {
        "avg_logprob": -0.24636293367575143,
        "compression_ratio": 1.602189781021898,
        "end": 984.06,
        "id": 291,
        "no_speech_prob": 0.00009915225382428616,
        "seek": 97250,
        "start": 980.74,
        "temperature": 0,
        "text": " Or you might see it as like XML HTTP request error.",
        "tokens": [
          50776,
          1610,
          291,
          1062,
          536,
          309,
          382,
          411,
          43484,
          33283,
          5308,
          6713,
          13,
          50942
        ]
      },
      {
        "avg_logprob": -0.24636293367575143,
        "compression_ratio": 1.602189781021898,
        "end": 987.42,
        "id": 292,
        "no_speech_prob": 0.00009915225382428616,
        "seek": 97250,
        "start": 984.06,
        "temperature": 0,
        "text": " You might have tried to load image from some URL",
        "tokens": [
          50942,
          509,
          1062,
          362,
          3031,
          281,
          3677,
          3256,
          490,
          512,
          12905,
          51110
        ]
      },
      {
        "avg_logprob": -0.24636293367575143,
        "compression_ratio": 1.602189781021898,
        "end": 989.26,
        "id": 293,
        "no_speech_prob": 0.00009915225382428616,
        "seek": 97250,
        "start": 987.42,
        "temperature": 0,
        "text": " or load strings or load JSON.",
        "tokens": [
          51110,
          420,
          3677,
          13985,
          420,
          3677,
          31828,
          13,
          51202
        ]
      },
      {
        "avg_logprob": -0.24636293367575143,
        "compression_ratio": 1.602189781021898,
        "end": 990.02,
        "id": 294,
        "no_speech_prob": 0.00009915225382428616,
        "seek": 97250,
        "start": 989.26,
        "temperature": 0,
        "text": " You get this error.",
        "tokens": [
          51202,
          509,
          483,
          341,
          6713,
          13,
          51240
        ]
      },
      {
        "avg_logprob": -0.24636293367575143,
        "compression_ratio": 1.602189781021898,
        "end": 990.78,
        "id": 295,
        "no_speech_prob": 0.00009915225382428616,
        "seek": 97250,
        "start": 990.02,
        "temperature": 0,
        "text": " I can't do it.",
        "tokens": [
          51240,
          286,
          393,
          380,
          360,
          309,
          13,
          51278
        ]
      },
      {
        "avg_logprob": -0.24636293367575143,
        "compression_ratio": 1.602189781021898,
        "end": 993.62,
        "id": 296,
        "no_speech_prob": 0.00009915225382428616,
        "seek": 97250,
        "start": 990.78,
        "temperature": 0,
        "text": " Security, cross-origin resources sharing not allowed,",
        "tokens": [
          51278,
          11164,
          11,
          3278,
          12,
          20632,
          259,
          3593,
          5414,
          406,
          4350,
          11,
          51420
        ]
      },
      {
        "avg_logprob": -0.24636293367575143,
        "compression_ratio": 1.602189781021898,
        "end": 995.2,
        "id": 297,
        "no_speech_prob": 0.00009915225382428616,
        "seek": 97250,
        "start": 993.62,
        "temperature": 0,
        "text": " inaccessible, stop, stop, stop.",
        "tokens": [
          51420,
          33230,
          780,
          964,
          11,
          1590,
          11,
          1590,
          11,
          1590,
          13,
          51499
        ]
      },
      {
        "avg_logprob": -0.24636293367575143,
        "compression_ratio": 1.602189781021898,
        "end": 999.42,
        "id": 298,
        "no_speech_prob": 0.00009915225382428616,
        "seek": 97250,
        "start": 995.2,
        "temperature": 0,
        "text": " So there's a lot of times where the client side,",
        "tokens": [
          51499,
          407,
          456,
          311,
          257,
          688,
          295,
          1413,
          689,
          264,
          6423,
          1252,
          11,
          51710
        ]
      },
      {
        "avg_logprob": -0.24636293367575143,
        "compression_ratio": 1.602189781021898,
        "end": 1001.46,
        "id": 299,
        "no_speech_prob": 0.00009915225382428616,
        "seek": 97250,
        "start": 999.42,
        "temperature": 0,
        "text": " for security, very good security reasons,",
        "tokens": [
          51710,
          337,
          3825,
          11,
          588,
          665,
          3825,
          4112,
          11,
          51812
        ]
      },
      {
        "avg_logprob": -0.23455000705406315,
        "compression_ratio": 1.72265625,
        "end": 1003.98,
        "id": 300,
        "no_speech_prob": 0.00005064449942437932,
        "seek": 100146,
        "start": 1001.46,
        "temperature": 0,
        "text": " is not allowed to reach to another server and request",
        "tokens": [
          50364,
          307,
          406,
          4350,
          281,
          2524,
          281,
          1071,
          7154,
          293,
          5308,
          50490
        ]
      },
      {
        "avg_logprob": -0.23455000705406315,
        "compression_ratio": 1.72265625,
        "end": 1004.7,
        "id": 301,
        "no_speech_prob": 0.00005064449942437932,
        "seek": 100146,
        "start": 1003.98,
        "temperature": 0,
        "text": " data.",
        "tokens": [
          50490,
          1412,
          13,
          50526
        ]
      },
      {
        "avg_logprob": -0.23455000705406315,
        "compression_ratio": 1.72265625,
        "end": 1007.7,
        "id": 302,
        "no_speech_prob": 0.00005064449942437932,
        "seek": 100146,
        "start": 1004.7,
        "temperature": 0,
        "text": " But your server side program is allowed to do that.",
        "tokens": [
          50526,
          583,
          428,
          7154,
          1252,
          1461,
          307,
          4350,
          281,
          360,
          300,
          13,
          50676
        ]
      },
      {
        "avg_logprob": -0.23455000705406315,
        "compression_ratio": 1.72265625,
        "end": 1010.34,
        "id": 303,
        "no_speech_prob": 0.00005064449942437932,
        "seek": 100146,
        "start": 1007.7,
        "temperature": 0,
        "text": " So for web scraping, for example,",
        "tokens": [
          50676,
          407,
          337,
          3670,
          43738,
          11,
          337,
          1365,
          11,
          50808
        ]
      },
      {
        "avg_logprob": -0.23455000705406315,
        "compression_ratio": 1.72265625,
        "end": 1013.62,
        "id": 304,
        "no_speech_prob": 0.00005064449942437932,
        "seek": 100146,
        "start": 1010.34,
        "temperature": 0,
        "text": " if you want to look at a web page, download all of its HTML,",
        "tokens": [
          50808,
          498,
          291,
          528,
          281,
          574,
          412,
          257,
          3670,
          3028,
          11,
          5484,
          439,
          295,
          1080,
          17995,
          11,
          50972
        ]
      },
      {
        "avg_logprob": -0.23455000705406315,
        "compression_ratio": 1.72265625,
        "end": 1015.72,
        "id": 305,
        "no_speech_prob": 0.00005064449942437932,
        "seek": 100146,
        "start": 1013.62,
        "temperature": 0,
        "text": " parse it out, pull out some things you want,",
        "tokens": [
          50972,
          48377,
          309,
          484,
          11,
          2235,
          484,
          512,
          721,
          291,
          528,
          11,
          51077
        ]
      },
      {
        "avg_logprob": -0.23455000705406315,
        "compression_ratio": 1.72265625,
        "end": 1018.5,
        "id": 306,
        "no_speech_prob": 0.00005064449942437932,
        "seek": 100146,
        "start": 1015.72,
        "temperature": 0,
        "text": " you can do that from server side and pass that",
        "tokens": [
          51077,
          291,
          393,
          360,
          300,
          490,
          7154,
          1252,
          293,
          1320,
          300,
          51216
        ]
      },
      {
        "avg_logprob": -0.23455000705406315,
        "compression_ratio": 1.72265625,
        "end": 1019.5,
        "id": 307,
        "no_speech_prob": 0.00005064449942437932,
        "seek": 100146,
        "start": 1018.5,
        "temperature": 0,
        "text": " to the client side.",
        "tokens": [
          51216,
          281,
          264,
          6423,
          1252,
          13,
          51266
        ]
      },
      {
        "avg_logprob": -0.23455000705406315,
        "compression_ratio": 1.72265625,
        "end": 1021.74,
        "id": 308,
        "no_speech_prob": 0.00005064449942437932,
        "seek": 100146,
        "start": 1019.5,
        "temperature": 0,
        "text": " So these are kind of four reasons",
        "tokens": [
          51266,
          407,
          613,
          366,
          733,
          295,
          1451,
          4112,
          51378
        ]
      },
      {
        "avg_logprob": -0.23455000705406315,
        "compression_ratio": 1.72265625,
        "end": 1026.56,
        "id": 309,
        "no_speech_prob": 0.00005064449942437932,
        "seek": 100146,
        "start": 1021.74,
        "temperature": 0,
        "text": " why you might want to use server side programming.",
        "tokens": [
          51378,
          983,
          291,
          1062,
          528,
          281,
          764,
          7154,
          1252,
          9410,
          13,
          51619
        ]
      },
      {
        "avg_logprob": -0.23455000705406315,
        "compression_ratio": 1.72265625,
        "end": 1029.22,
        "id": 310,
        "no_speech_prob": 0.00005064449942437932,
        "seek": 100146,
        "start": 1026.56,
        "temperature": 0,
        "text": " Number three being make your own API.",
        "tokens": [
          51619,
          5118,
          1045,
          885,
          652,
          428,
          1065,
          9362,
          13,
          51752
        ]
      },
      {
        "avg_logprob": -0.2448660184259284,
        "compression_ratio": 1.696551724137931,
        "end": 1032.8600000000001,
        "id": 311,
        "no_speech_prob": 0.00009610134293325245,
        "seek": 102922,
        "start": 1029.22,
        "temperature": 0,
        "text": " This is where, in many ways, I want to start.",
        "tokens": [
          50364,
          639,
          307,
          689,
          11,
          294,
          867,
          2098,
          11,
          286,
          528,
          281,
          722,
          13,
          50546
        ]
      },
      {
        "avg_logprob": -0.2448660184259284,
        "compression_ratio": 1.696551724137931,
        "end": 1035.1000000000001,
        "id": 312,
        "no_speech_prob": 0.00009610134293325245,
        "seek": 102922,
        "start": 1032.8600000000001,
        "temperature": 0,
        "text": " OK, so what are the pieces of this?",
        "tokens": [
          50546,
          2264,
          11,
          370,
          437,
          366,
          264,
          3755,
          295,
          341,
          30,
          50658
        ]
      },
      {
        "avg_logprob": -0.2448660184259284,
        "compression_ratio": 1.696551724137931,
        "end": 1036.74,
        "id": 313,
        "no_speech_prob": 0.00009610134293325245,
        "seek": 102922,
        "start": 1035.1000000000001,
        "temperature": 0,
        "text": " The first thing that I want, so I'm",
        "tokens": [
          50658,
          440,
          700,
          551,
          300,
          286,
          528,
          11,
          370,
          286,
          478,
          50740
        ]
      },
      {
        "avg_logprob": -0.2448660184259284,
        "compression_ratio": 1.696551724137931,
        "end": 1038.66,
        "id": 314,
        "no_speech_prob": 0.00009610134293325245,
        "seek": 102922,
        "start": 1036.74,
        "temperature": 0,
        "text": " going to make a bunch of videos.",
        "tokens": [
          50740,
          516,
          281,
          652,
          257,
          3840,
          295,
          2145,
          13,
          50836
        ]
      },
      {
        "avg_logprob": -0.2448660184259284,
        "compression_ratio": 1.696551724137931,
        "end": 1042.1000000000001,
        "id": 315,
        "no_speech_prob": 0.00009610134293325245,
        "seek": 102922,
        "start": 1038.66,
        "temperature": 0,
        "text": " They will eventually be here on YouTube for you to watch.",
        "tokens": [
          50836,
          814,
          486,
          4728,
          312,
          510,
          322,
          3088,
          337,
          291,
          281,
          1159,
          13,
          51008
        ]
      },
      {
        "avg_logprob": -0.2448660184259284,
        "compression_ratio": 1.696551724137931,
        "end": 1044.22,
        "id": 316,
        "no_speech_prob": 0.00009610134293325245,
        "seek": 102922,
        "start": 1042.1000000000001,
        "temperature": 0,
        "text": " Or I don't know what the platform of the future is",
        "tokens": [
          51008,
          1610,
          286,
          500,
          380,
          458,
          437,
          264,
          3663,
          295,
          264,
          2027,
          307,
          51114
        ]
      },
      {
        "avg_logprob": -0.2448660184259284,
        "compression_ratio": 1.696551724137931,
        "end": 1045.26,
        "id": 317,
        "no_speech_prob": 0.00009610134293325245,
        "seek": 102922,
        "start": 1044.22,
        "temperature": 0,
        "text": " when YouTube goes away.",
        "tokens": [
          51114,
          562,
          3088,
          1709,
          1314,
          13,
          51166
        ]
      },
      {
        "avg_logprob": -0.2448660184259284,
        "compression_ratio": 1.696551724137931,
        "end": 1047.6200000000001,
        "id": 318,
        "no_speech_prob": 0.00009610134293325245,
        "seek": 102922,
        "start": 1045.26,
        "temperature": 0,
        "text": " But hopefully, the videos will still exist.",
        "tokens": [
          51166,
          583,
          4696,
          11,
          264,
          2145,
          486,
          920,
          2514,
          13,
          51284
        ]
      },
      {
        "avg_logprob": -0.2448660184259284,
        "compression_ratio": 1.696551724137931,
        "end": 1050.22,
        "id": 319,
        "no_speech_prob": 0.00009610134293325245,
        "seek": 102922,
        "start": 1047.6200000000001,
        "temperature": 0,
        "text": " Number one, I'm going to talk about,",
        "tokens": [
          51284,
          5118,
          472,
          11,
          286,
          478,
          516,
          281,
          751,
          466,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.2448660184259284,
        "compression_ratio": 1.696551724137931,
        "end": 1052.58,
        "id": 320,
        "no_speech_prob": 0.00009610134293325245,
        "seek": 102922,
        "start": 1050.22,
        "temperature": 0,
        "text": " I have a bunch of videos that I will link to",
        "tokens": [
          51414,
          286,
          362,
          257,
          3840,
          295,
          2145,
          300,
          286,
          486,
          2113,
          281,
          51532
        ]
      },
      {
        "avg_logprob": -0.2448660184259284,
        "compression_ratio": 1.696551724137931,
        "end": 1054.6200000000001,
        "id": 321,
        "no_speech_prob": 0.00009610134293325245,
        "seek": 102922,
        "start": 1052.58,
        "temperature": 0,
        "text": " in this playlist of kind of what is node",
        "tokens": [
          51532,
          294,
          341,
          16788,
          295,
          733,
          295,
          437,
          307,
          9984,
          51634
        ]
      },
      {
        "avg_logprob": -0.2448660184259284,
        "compression_ratio": 1.696551724137931,
        "end": 1057.26,
        "id": 322,
        "no_speech_prob": 0.00009610134293325245,
        "seek": 102922,
        "start": 1054.6200000000001,
        "temperature": 0,
        "text": " and what is NPM for Node Package Manager.",
        "tokens": [
          51634,
          293,
          437,
          307,
          426,
          18819,
          337,
          38640,
          18466,
          609,
          13821,
          13,
          51766
        ]
      },
      {
        "avg_logprob": -0.2504426506674214,
        "compression_ratio": 1.7098765432098766,
        "end": 1059.62,
        "id": 323,
        "no_speech_prob": 0.0000916999124456197,
        "seek": 105726,
        "start": 1057.26,
        "temperature": 0,
        "text": " So you need to install Node and get up and running",
        "tokens": [
          50364,
          407,
          291,
          643,
          281,
          3625,
          38640,
          293,
          483,
          493,
          293,
          2614,
          50482
        ]
      },
      {
        "avg_logprob": -0.2504426506674214,
        "compression_ratio": 1.7098765432098766,
        "end": 1061.3,
        "id": 324,
        "no_speech_prob": 0.0000916999124456197,
        "seek": 105726,
        "start": 1059.62,
        "temperature": 0,
        "text": " with something called NPM first.",
        "tokens": [
          50482,
          365,
          746,
          1219,
          426,
          18819,
          700,
          13,
          50566
        ]
      },
      {
        "avg_logprob": -0.2504426506674214,
        "compression_ratio": 1.7098765432098766,
        "end": 1062.7,
        "id": 325,
        "no_speech_prob": 0.0000916999124456197,
        "seek": 105726,
        "start": 1061.3,
        "temperature": 0,
        "text": " And I already have the videos made",
        "tokens": [
          50566,
          400,
          286,
          1217,
          362,
          264,
          2145,
          1027,
          50636
        ]
      },
      {
        "avg_logprob": -0.2504426506674214,
        "compression_ratio": 1.7098765432098766,
        "end": 1066.1,
        "id": 326,
        "no_speech_prob": 0.0000916999124456197,
        "seek": 105726,
        "start": 1062.7,
        "temperature": 0,
        "text": " for that, which I will reference and link to somehow.",
        "tokens": [
          50636,
          337,
          300,
          11,
          597,
          286,
          486,
          6408,
          293,
          2113,
          281,
          6063,
          13,
          50806
        ]
      },
      {
        "avg_logprob": -0.2504426506674214,
        "compression_ratio": 1.7098765432098766,
        "end": 1068.42,
        "id": 327,
        "no_speech_prob": 0.0000916999124456197,
        "seek": 105726,
        "start": 1066.1,
        "temperature": 0,
        "text": " But here, I'm going to start with a node package called",
        "tokens": [
          50806,
          583,
          510,
          11,
          286,
          478,
          516,
          281,
          722,
          365,
          257,
          9984,
          7372,
          1219,
          50922
        ]
      },
      {
        "avg_logprob": -0.2504426506674214,
        "compression_ratio": 1.7098765432098766,
        "end": 1071.34,
        "id": 328,
        "no_speech_prob": 0.0000916999124456197,
        "seek": 105726,
        "start": 1068.42,
        "temperature": 0,
        "text": " Express, which makes building a web server, which",
        "tokens": [
          50922,
          20212,
          11,
          597,
          1669,
          2390,
          257,
          3670,
          7154,
          11,
          597,
          51068
        ]
      },
      {
        "avg_logprob": -0.2504426506674214,
        "compression_ratio": 1.7098765432098766,
        "end": 1073.1,
        "id": 329,
        "no_speech_prob": 0.0000916999124456197,
        "seek": 105726,
        "start": 1071.34,
        "temperature": 0,
        "text": " is what you're going to need at its core.",
        "tokens": [
          51068,
          307,
          437,
          291,
          434,
          516,
          281,
          643,
          412,
          1080,
          4965,
          13,
          51156
        ]
      },
      {
        "avg_logprob": -0.2504426506674214,
        "compression_ratio": 1.7098765432098766,
        "end": 1074.52,
        "id": 330,
        "no_speech_prob": 0.0000916999124456197,
        "seek": 105726,
        "start": 1073.1,
        "temperature": 0,
        "text": " The web server is the thing that's",
        "tokens": [
          51156,
          440,
          3670,
          7154,
          307,
          264,
          551,
          300,
          311,
          51227
        ]
      },
      {
        "avg_logprob": -0.2504426506674214,
        "compression_ratio": 1.7098765432098766,
        "end": 1077.86,
        "id": 331,
        "no_speech_prob": 0.0000916999124456197,
        "seek": 105726,
        "start": 1074.52,
        "temperature": 0,
        "text": " going to pass information to your client, your p5.js sketch,",
        "tokens": [
          51227,
          516,
          281,
          1320,
          1589,
          281,
          428,
          6423,
          11,
          428,
          280,
          20,
          13,
          25530,
          12325,
          11,
          51394
        ]
      },
      {
        "avg_logprob": -0.2504426506674214,
        "compression_ratio": 1.7098765432098766,
        "end": 1080.14,
        "id": 332,
        "no_speech_prob": 0.0000916999124456197,
        "seek": 105726,
        "start": 1077.86,
        "temperature": 0,
        "text": " or somebody else is making an API query.",
        "tokens": [
          51394,
          420,
          2618,
          1646,
          307,
          1455,
          364,
          9362,
          14581,
          13,
          51508
        ]
      },
      {
        "avg_logprob": -0.2504426506674214,
        "compression_ratio": 1.7098765432098766,
        "end": 1082.22,
        "id": 333,
        "no_speech_prob": 0.0000916999124456197,
        "seek": 105726,
        "start": 1080.14,
        "temperature": 0,
        "text": " So we need to look at Express.",
        "tokens": [
          51508,
          407,
          321,
          643,
          281,
          574,
          412,
          20212,
          13,
          51612
        ]
      },
      {
        "avg_logprob": -0.2504426506674214,
        "compression_ratio": 1.7098765432098766,
        "end": 1083.7,
        "id": 334,
        "no_speech_prob": 0.0000916999124456197,
        "seek": 105726,
        "start": 1082.22,
        "temperature": 0,
        "text": " I want to look at saving data.",
        "tokens": [
          51612,
          286,
          528,
          281,
          574,
          412,
          6816,
          1412,
          13,
          51686
        ]
      },
      {
        "avg_logprob": -0.2504426506674214,
        "compression_ratio": 1.7098765432098766,
        "end": 1086.34,
        "id": 335,
        "no_speech_prob": 0.0000916999124456197,
        "seek": 105726,
        "start": 1083.7,
        "temperature": 0,
        "text": " And I've got a secret to tell you,",
        "tokens": [
          51686,
          400,
          286,
          600,
          658,
          257,
          4054,
          281,
          980,
          291,
          11,
          51818
        ]
      },
      {
        "avg_logprob": -0.2523086961493435,
        "compression_ratio": 1.7655786350148368,
        "end": 1087.4599999999998,
        "id": 336,
        "no_speech_prob": 0.0003006017941515893,
        "seek": 108634,
        "start": 1086.34,
        "temperature": 0,
        "text": " which is one of the easiest way.",
        "tokens": [
          50364,
          597,
          307,
          472,
          295,
          264,
          12889,
          636,
          13,
          50420
        ]
      },
      {
        "avg_logprob": -0.2523086961493435,
        "compression_ratio": 1.7655786350148368,
        "end": 1088.5,
        "id": 337,
        "no_speech_prob": 0.0003006017941515893,
        "seek": 108634,
        "start": 1087.4599999999998,
        "temperature": 0,
        "text": " I'm sure someone, like, I'm going",
        "tokens": [
          50420,
          286,
          478,
          988,
          1580,
          11,
          411,
          11,
          286,
          478,
          516,
          50472
        ]
      },
      {
        "avg_logprob": -0.2523086961493435,
        "compression_ratio": 1.7655786350148368,
        "end": 1090.62,
        "id": 338,
        "no_speech_prob": 0.0003006017941515893,
        "seek": 108634,
        "start": 1088.5,
        "temperature": 0,
        "text": " to get struck by lightning for doing it this way.",
        "tokens": [
          50472,
          281,
          483,
          13159,
          538,
          16589,
          337,
          884,
          309,
          341,
          636,
          13,
          50578
        ]
      },
      {
        "avg_logprob": -0.2523086961493435,
        "compression_ratio": 1.7655786350148368,
        "end": 1093.02,
        "id": 339,
        "no_speech_prob": 0.0003006017941515893,
        "seek": 108634,
        "start": 1090.62,
        "temperature": 0,
        "text": " But a really easy way to have a database",
        "tokens": [
          50578,
          583,
          257,
          534,
          1858,
          636,
          281,
          362,
          257,
          8149,
          50698
        ]
      },
      {
        "avg_logprob": -0.2523086961493435,
        "compression_ratio": 1.7655786350148368,
        "end": 1094.34,
        "id": 340,
        "no_speech_prob": 0.0003006017941515893,
        "seek": 108634,
        "start": 1093.02,
        "temperature": 0,
        "text": " is just save a JSON file.",
        "tokens": [
          50698,
          307,
          445,
          3155,
          257,
          31828,
          3991,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2523086961493435,
        "compression_ratio": 1.7655786350148368,
        "end": 1097.58,
        "id": 341,
        "no_speech_prob": 0.0003006017941515893,
        "seek": 108634,
        "start": 1094.34,
        "temperature": 0,
        "text": " Save a text file to the hard drive of the computer",
        "tokens": [
          50764,
          15541,
          257,
          2487,
          3991,
          281,
          264,
          1152,
          3332,
          295,
          264,
          3820,
          50926
        ]
      },
      {
        "avg_logprob": -0.2523086961493435,
        "compression_ratio": 1.7655786350148368,
        "end": 1099.4199999999998,
        "id": 342,
        "no_speech_prob": 0.0003006017941515893,
        "seek": 108634,
        "start": 1097.58,
        "temperature": 0,
        "text": " and then load it every time the server runs.",
        "tokens": [
          50926,
          293,
          550,
          3677,
          309,
          633,
          565,
          264,
          7154,
          6676,
          13,
          51018
        ]
      },
      {
        "avg_logprob": -0.2523086961493435,
        "compression_ratio": 1.7655786350148368,
        "end": 1100.86,
        "id": 343,
        "no_speech_prob": 0.0003006017941515893,
        "seek": 108634,
        "start": 1099.4199999999998,
        "temperature": 0,
        "text": " So I'm going to look at the simplest way you",
        "tokens": [
          51018,
          407,
          286,
          478,
          516,
          281,
          574,
          412,
          264,
          22811,
          636,
          291,
          51090
        ]
      },
      {
        "avg_logprob": -0.2523086961493435,
        "compression_ratio": 1.7655786350148368,
        "end": 1103.34,
        "id": 344,
        "no_speech_prob": 0.0003006017941515893,
        "seek": 108634,
        "start": 1100.86,
        "temperature": 0,
        "text": " can have a database and then some other more complex ways,",
        "tokens": [
          51090,
          393,
          362,
          257,
          8149,
          293,
          550,
          512,
          661,
          544,
          3997,
          2098,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.2523086961493435,
        "compression_ratio": 1.7655786350148368,
        "end": 1106.5,
        "id": 345,
        "no_speech_prob": 0.0003006017941515893,
        "seek": 108634,
        "start": 1103.34,
        "temperature": 0,
        "text": " maybe using a database system like CouchDB or MongoDB,",
        "tokens": [
          51214,
          1310,
          1228,
          257,
          8149,
          1185,
          411,
          383,
          2220,
          27735,
          420,
          48380,
          27735,
          11,
          51372
        ]
      },
      {
        "avg_logprob": -0.2523086961493435,
        "compression_ratio": 1.7655786350148368,
        "end": 1108.06,
        "id": 346,
        "no_speech_prob": 0.0003006017941515893,
        "seek": 108634,
        "start": 1106.5,
        "temperature": 0,
        "text": " and then something called Firebase,",
        "tokens": [
          51372,
          293,
          550,
          746,
          1219,
          35173,
          11,
          51450
        ]
      },
      {
        "avg_logprob": -0.2523086961493435,
        "compression_ratio": 1.7655786350148368,
        "end": 1110.4199999999998,
        "id": 347,
        "no_speech_prob": 0.0003006017941515893,
        "seek": 108634,
        "start": 1108.06,
        "temperature": 0,
        "text": " which is a Google product that allows you to just send them",
        "tokens": [
          51450,
          597,
          307,
          257,
          3329,
          1674,
          300,
          4045,
          291,
          281,
          445,
          2845,
          552,
          51568
        ]
      },
      {
        "avg_logprob": -0.2523086961493435,
        "compression_ratio": 1.7655786350148368,
        "end": 1110.9399999999998,
        "id": 348,
        "no_speech_prob": 0.0003006017941515893,
        "seek": 108634,
        "start": 1110.4199999999998,
        "temperature": 0,
        "text": " information.",
        "tokens": [
          51568,
          1589,
          13,
          51594
        ]
      },
      {
        "avg_logprob": -0.2523086961493435,
        "compression_ratio": 1.7655786350148368,
        "end": 1111.82,
        "id": 349,
        "no_speech_prob": 0.0003006017941515893,
        "seek": 108634,
        "start": 1110.9399999999998,
        "temperature": 0,
        "text": " They save it for you.",
        "tokens": [
          51594,
          814,
          3155,
          309,
          337,
          291,
          13,
          51638
        ]
      },
      {
        "avg_logprob": -0.2523086961493435,
        "compression_ratio": 1.7655786350148368,
        "end": 1113.58,
        "id": 350,
        "no_speech_prob": 0.0003006017941515893,
        "seek": 108634,
        "start": 1111.82,
        "temperature": 0,
        "text": " You can request it later.",
        "tokens": [
          51638,
          509,
          393,
          5308,
          309,
          1780,
          13,
          51726
        ]
      },
      {
        "avg_logprob": -0.21621602052336286,
        "compression_ratio": 1.6910828025477707,
        "end": 1116.5,
        "id": 351,
        "no_speech_prob": 0.02262728475034237,
        "seek": 111358,
        "start": 1113.58,
        "temperature": 0,
        "text": " I want to look at some point at scraping other web pages.",
        "tokens": [
          50364,
          286,
          528,
          281,
          574,
          412,
          512,
          935,
          412,
          43738,
          661,
          3670,
          7183,
          13,
          50510
        ]
      },
      {
        "avg_logprob": -0.21621602052336286,
        "compression_ratio": 1.6910828025477707,
        "end": 1120.26,
        "id": 352,
        "no_speech_prob": 0.02262728475034237,
        "seek": 111358,
        "start": 1116.5,
        "temperature": 0,
        "text": " So how could you grab an image and then pass that to p5.js",
        "tokens": [
          50510,
          407,
          577,
          727,
          291,
          4444,
          364,
          3256,
          293,
          550,
          1320,
          300,
          281,
          280,
          20,
          13,
          25530,
          50698
        ]
      },
      {
        "avg_logprob": -0.21621602052336286,
        "compression_ratio": 1.6910828025477707,
        "end": 1123.34,
        "id": 353,
        "no_speech_prob": 0.02262728475034237,
        "seek": 111358,
        "start": 1120.26,
        "temperature": 0,
        "text": " or an HTML page and pass that to p5.js?",
        "tokens": [
          50698,
          420,
          364,
          17995,
          3028,
          293,
          1320,
          300,
          281,
          280,
          20,
          13,
          25530,
          30,
          50852
        ]
      },
      {
        "avg_logprob": -0.21621602052336286,
        "compression_ratio": 1.6910828025477707,
        "end": 1125.78,
        "id": 354,
        "no_speech_prob": 0.02262728475034237,
        "seek": 111358,
        "start": 1123.34,
        "temperature": 0,
        "text": " There's a lot of topics here about making an API.",
        "tokens": [
          50852,
          821,
          311,
          257,
          688,
          295,
          8378,
          510,
          466,
          1455,
          364,
          9362,
          13,
          50974
        ]
      },
      {
        "avg_logprob": -0.21621602052336286,
        "compression_ratio": 1.6910828025477707,
        "end": 1127.54,
        "id": 355,
        "no_speech_prob": 0.02262728475034237,
        "seek": 111358,
        "start": 1125.78,
        "temperature": 0,
        "text": " There's this thing called REST.",
        "tokens": [
          50974,
          821,
          311,
          341,
          551,
          1219,
          497,
          14497,
          13,
          51062
        ]
      },
      {
        "avg_logprob": -0.21621602052336286,
        "compression_ratio": 1.6910828025477707,
        "end": 1128.86,
        "id": 356,
        "no_speech_prob": 0.02262728475034237,
        "seek": 111358,
        "start": 1127.54,
        "temperature": 0,
        "text": " I don't even know what that is.",
        "tokens": [
          51062,
          286,
          500,
          380,
          754,
          458,
          437,
          300,
          307,
          13,
          51128
        ]
      },
      {
        "avg_logprob": -0.21621602052336286,
        "compression_ratio": 1.6910828025477707,
        "end": 1130.6999999999998,
        "id": 357,
        "no_speech_prob": 0.02262728475034237,
        "seek": 111358,
        "start": 1128.86,
        "temperature": 0,
        "text": " We'll try to figure it out together.",
        "tokens": [
          51128,
          492,
          603,
          853,
          281,
          2573,
          309,
          484,
          1214,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.21621602052336286,
        "compression_ratio": 1.6910828025477707,
        "end": 1133.46,
        "id": 358,
        "no_speech_prob": 0.02262728475034237,
        "seek": 111358,
        "start": 1130.6999999999998,
        "temperature": 0,
        "text": " There's the thing called CORS, cross-origin resource sharing,",
        "tokens": [
          51220,
          821,
          311,
          264,
          551,
          1219,
          43137,
          50,
          11,
          3278,
          12,
          20632,
          259,
          7684,
          5414,
          11,
          51358
        ]
      },
      {
        "avg_logprob": -0.21621602052336286,
        "compression_ratio": 1.6910828025477707,
        "end": 1135.6,
        "id": 359,
        "no_speech_prob": 0.02262728475034237,
        "seek": 111358,
        "start": 1133.46,
        "temperature": 0,
        "text": " which I think I do know what it is.",
        "tokens": [
          51358,
          597,
          286,
          519,
          286,
          360,
          458,
          437,
          309,
          307,
          13,
          51465
        ]
      },
      {
        "avg_logprob": -0.21621602052336286,
        "compression_ratio": 1.6910828025477707,
        "end": 1139.46,
        "id": 360,
        "no_speech_prob": 0.02262728475034237,
        "seek": 111358,
        "start": 1135.6,
        "temperature": 0,
        "text": " And then I want to look at a bunch of different examples,",
        "tokens": [
          51465,
          400,
          550,
          286,
          528,
          281,
          574,
          412,
          257,
          3840,
          295,
          819,
          5110,
          11,
          51658
        ]
      },
      {
        "avg_logprob": -0.21621602052336286,
        "compression_ratio": 1.6910828025477707,
        "end": 1141.9399999999998,
        "id": 361,
        "no_speech_prob": 0.02262728475034237,
        "seek": 111358,
        "start": 1139.46,
        "temperature": 0,
        "text": " mostly around working with text to follow",
        "tokens": [
          51658,
          5240,
          926,
          1364,
          365,
          2487,
          281,
          1524,
          51782
        ]
      },
      {
        "avg_logprob": -0.21621602052336286,
        "compression_ratio": 1.6910828025477707,
        "end": 1143.22,
        "id": 362,
        "no_speech_prob": 0.02262728475034237,
        "seek": 111358,
        "start": 1141.9399999999998,
        "temperature": 0,
        "text": " the theme of this course.",
        "tokens": [
          51782,
          264,
          6314,
          295,
          341,
          1164,
          13,
          51846
        ]
      },
      {
        "avg_logprob": -0.29869220131321955,
        "compression_ratio": 1.6454183266932272,
        "end": 1146.78,
        "id": 363,
        "no_speech_prob": 0.000004495120265346486,
        "seek": 114322,
        "start": 1144.1000000000001,
        "temperature": 0,
        "text": " What if you had the big data scenario",
        "tokens": [
          50408,
          708,
          498,
          291,
          632,
          264,
          955,
          1412,
          9005,
          50542
        ]
      },
      {
        "avg_logprob": -0.29869220131321955,
        "compression_ratio": 1.6454183266932272,
        "end": 1149.22,
        "id": 364,
        "no_speech_prob": 0.000004495120265346486,
        "seek": 114322,
        "start": 1146.78,
        "temperature": 0,
        "text": " where you need to load massive amounts of text",
        "tokens": [
          50542,
          689,
          291,
          643,
          281,
          3677,
          5994,
          11663,
          295,
          2487,
          50664
        ]
      },
      {
        "avg_logprob": -0.29869220131321955,
        "compression_ratio": 1.6454183266932272,
        "end": 1152.26,
        "id": 365,
        "no_speech_prob": 0.000004495120265346486,
        "seek": 114322,
        "start": 1149.22,
        "temperature": 0,
        "text": " and you want to pass to a user a word counting info,",
        "tokens": [
          50664,
          293,
          291,
          528,
          281,
          1320,
          281,
          257,
          4195,
          257,
          1349,
          13251,
          294,
          16931,
          11,
          50816
        ]
      },
      {
        "avg_logprob": -0.29869220131321955,
        "compression_ratio": 1.6454183266932272,
        "end": 1156.1000000000001,
        "id": 366,
        "no_speech_prob": 0.000004495120265346486,
        "seek": 114322,
        "start": 1152.26,
        "temperature": 0,
        "text": " you want to pass to make an API for word counting information?",
        "tokens": [
          50816,
          291,
          528,
          281,
          1320,
          281,
          652,
          364,
          9362,
          337,
          1349,
          13251,
          1589,
          30,
          51008
        ]
      },
      {
        "avg_logprob": -0.29869220131321955,
        "compression_ratio": 1.6454183266932272,
        "end": 1159.18,
        "id": 367,
        "no_speech_prob": 0.000004495120265346486,
        "seek": 114322,
        "start": 1156.1000000000001,
        "temperature": 0,
        "text": " So that's something that I'll look at, as well as I",
        "tokens": [
          51008,
          407,
          300,
          311,
          746,
          300,
          286,
          603,
          574,
          412,
          11,
          382,
          731,
          382,
          286,
          51162
        ]
      },
      {
        "avg_logprob": -0.29869220131321955,
        "compression_ratio": 1.6454183266932272,
        "end": 1161.6200000000001,
        "id": 368,
        "no_speech_prob": 0.000004495120265346486,
        "seek": 114322,
        "start": 1159.18,
        "temperature": 0,
        "text": " want to build an API for sentiment analysis",
        "tokens": [
          51162,
          528,
          281,
          1322,
          364,
          9362,
          337,
          16149,
          5215,
          51284
        ]
      },
      {
        "avg_logprob": -0.29869220131321955,
        "compression_ratio": 1.6454183266932272,
        "end": 1165.46,
        "id": 369,
        "no_speech_prob": 0.000004495120265346486,
        "seek": 114322,
        "start": 1161.6200000000001,
        "temperature": 0,
        "text": " using this AFIN111 list of words.",
        "tokens": [
          51284,
          1228,
          341,
          20389,
          1464,
          5348,
          16,
          1329,
          295,
          2283,
          13,
          51476
        ]
      },
      {
        "avg_logprob": -0.29869220131321955,
        "compression_ratio": 1.6454183266932272,
        "end": 1169.3,
        "id": 370,
        "no_speech_prob": 0.000004495120265346486,
        "seek": 114322,
        "start": 1165.46,
        "temperature": 0,
        "text": " And I have a couple of examples that",
        "tokens": [
          51476,
          400,
          286,
          362,
          257,
          1916,
          295,
          5110,
          300,
          51668
        ]
      },
      {
        "avg_logprob": -0.29869220131321955,
        "compression_ratio": 1.6454183266932272,
        "end": 1171.8600000000001,
        "id": 371,
        "no_speech_prob": 0.000004495120265346486,
        "seek": 114322,
        "start": 1169.3,
        "temperature": 0,
        "text": " use a node package called node-natural, which",
        "tokens": [
          51668,
          764,
          257,
          9984,
          7372,
          1219,
          9984,
          12,
          16296,
          11,
          597,
          51796
        ]
      },
      {
        "avg_logprob": -0.22368626634613806,
        "compression_ratio": 1.632183908045977,
        "end": 1176.6599999999999,
        "id": 372,
        "no_speech_prob": 0.000039442311390303075,
        "seek": 117186,
        "start": 1171.86,
        "temperature": 0,
        "text": " is another text analysis, natural language processing",
        "tokens": [
          50364,
          307,
          1071,
          2487,
          5215,
          11,
          3303,
          2856,
          9007,
          50604
        ]
      },
      {
        "avg_logprob": -0.22368626634613806,
        "compression_ratio": 1.632183908045977,
        "end": 1178.6599999999999,
        "id": 373,
        "no_speech_prob": 0.000039442311390303075,
        "seek": 117186,
        "start": 1176.6599999999999,
        "temperature": 0,
        "text": " node package, which has a lot of great features.",
        "tokens": [
          50604,
          9984,
          7372,
          11,
          597,
          575,
          257,
          688,
          295,
          869,
          4122,
          13,
          50704
        ]
      },
      {
        "avg_logprob": -0.22368626634613806,
        "compression_ratio": 1.632183908045977,
        "end": 1180.86,
        "id": 374,
        "no_speech_prob": 0.000039442311390303075,
        "seek": 117186,
        "start": 1178.6599999999999,
        "temperature": 0,
        "text": " And I'll show you a couple of them here.",
        "tokens": [
          50704,
          400,
          286,
          603,
          855,
          291,
          257,
          1916,
          295,
          552,
          510,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.22368626634613806,
        "compression_ratio": 1.632183908045977,
        "end": 1183.9399999999998,
        "id": 375,
        "no_speech_prob": 0.000039442311390303075,
        "seek": 117186,
        "start": 1180.86,
        "temperature": 0,
        "text": " So I'm going to get started in the next video.",
        "tokens": [
          50814,
          407,
          286,
          478,
          516,
          281,
          483,
          1409,
          294,
          264,
          958,
          960,
          13,
          50968
        ]
      },
      {
        "avg_logprob": -0.22368626634613806,
        "compression_ratio": 1.632183908045977,
        "end": 1185.78,
        "id": 376,
        "no_speech_prob": 0.000039442311390303075,
        "seek": 117186,
        "start": 1183.9399999999998,
        "temperature": 0,
        "text": " This isn't the order that I'm going to go in.",
        "tokens": [
          50968,
          639,
          1943,
          380,
          264,
          1668,
          300,
          286,
          478,
          516,
          281,
          352,
          294,
          13,
          51060
        ]
      },
      {
        "avg_logprob": -0.22368626634613806,
        "compression_ratio": 1.632183908045977,
        "end": 1188.9399999999998,
        "id": 377,
        "no_speech_prob": 0.000039442311390303075,
        "seek": 117186,
        "start": 1185.78,
        "temperature": 0,
        "text": " I'm really going to focus on working with Express,",
        "tokens": [
          51060,
          286,
          478,
          534,
          516,
          281,
          1879,
          322,
          1364,
          365,
          20212,
          11,
          51218
        ]
      },
      {
        "avg_logprob": -0.22368626634613806,
        "compression_ratio": 1.632183908045977,
        "end": 1192.08,
        "id": 378,
        "no_speech_prob": 0.000039442311390303075,
        "seek": 117186,
        "start": 1188.9399999999998,
        "temperature": 0,
        "text": " setting up this idea of an API, and then",
        "tokens": [
          51218,
          3287,
          493,
          341,
          1558,
          295,
          364,
          9362,
          11,
          293,
          550,
          51375
        ]
      },
      {
        "avg_logprob": -0.22368626634613806,
        "compression_ratio": 1.632183908045977,
        "end": 1195.6599999999999,
        "id": 379,
        "no_speech_prob": 0.000039442311390303075,
        "seek": 117186,
        "start": 1192.08,
        "temperature": 0,
        "text": " see if I can transition that into a simple sentiment",
        "tokens": [
          51375,
          536,
          498,
          286,
          393,
          6034,
          300,
          666,
          257,
          2199,
          16149,
          51554
        ]
      },
      {
        "avg_logprob": -0.22368626634613806,
        "compression_ratio": 1.632183908045977,
        "end": 1197.6,
        "id": 380,
        "no_speech_prob": 0.000039442311390303075,
        "seek": 117186,
        "start": 1195.6599999999999,
        "temperature": 0,
        "text": " analysis API.",
        "tokens": [
          51554,
          5215,
          9362,
          13,
          51651
        ]
      },
      {
        "avg_logprob": -0.22368626634613806,
        "compression_ratio": 1.632183908045977,
        "end": 1200.1399999999999,
        "id": 381,
        "no_speech_prob": 0.000039442311390303075,
        "seek": 117186,
        "start": 1197.6,
        "temperature": 0,
        "text": " And we will see how that goes.",
        "tokens": [
          51651,
          400,
          321,
          486,
          536,
          577,
          300,
          1709,
          13,
          51778
        ]
      },
      {
        "avg_logprob": -0.2810139550103082,
        "compression_ratio": 1.6867469879518073,
        "end": 1201.26,
        "id": 382,
        "no_speech_prob": 0.00045830331509932876,
        "seek": 120014,
        "start": 1200.14,
        "temperature": 0,
        "text": " See you next video.",
        "tokens": [
          50364,
          3008,
          291,
          958,
          960,
          13,
          50420
        ]
      },
      {
        "avg_logprob": -0.2810139550103082,
        "compression_ratio": 1.6867469879518073,
        "end": 1207.1000000000001,
        "id": 383,
        "no_speech_prob": 0.00045830331509932876,
        "seek": 120014,
        "start": 1205.18,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50616,
          2264,
          13,
          50712
        ]
      },
      {
        "avg_logprob": -0.2810139550103082,
        "compression_ratio": 1.6867469879518073,
        "end": 1209.8200000000002,
        "id": 384,
        "no_speech_prob": 0.00045830331509932876,
        "seek": 120014,
        "start": 1207.1000000000001,
        "temperature": 0,
        "text": " Why would I want to make an API?",
        "tokens": [
          50712,
          1545,
          576,
          286,
          528,
          281,
          652,
          364,
          9362,
          30,
          50848
        ]
      },
      {
        "avg_logprob": -0.2810139550103082,
        "compression_ratio": 1.6867469879518073,
        "end": 1212.5800000000002,
        "id": 385,
        "no_speech_prob": 0.00045830331509932876,
        "seek": 120014,
        "start": 1209.8200000000002,
        "temperature": 0,
        "text": " Yayitsryan asks a really, really good question.",
        "tokens": [
          50848,
          13268,
          1208,
          627,
          282,
          8962,
          257,
          534,
          11,
          534,
          665,
          1168,
          13,
          50986
        ]
      },
      {
        "avg_logprob": -0.2810139550103082,
        "compression_ratio": 1.6867469879518073,
        "end": 1218.3400000000001,
        "id": 386,
        "no_speech_prob": 0.00045830331509932876,
        "seek": 120014,
        "start": 1215.38,
        "temperature": 0,
        "text": " Why would I want to make an API?",
        "tokens": [
          51126,
          1545,
          576,
          286,
          528,
          281,
          652,
          364,
          9362,
          30,
          51274
        ]
      },
      {
        "avg_logprob": -0.2810139550103082,
        "compression_ratio": 1.6867469879518073,
        "end": 1220.6200000000001,
        "id": 387,
        "no_speech_prob": 0.00045830331509932876,
        "seek": 120014,
        "start": 1218.3400000000001,
        "temperature": 0,
        "text": " I guess I wanted to address that in this,",
        "tokens": [
          51274,
          286,
          2041,
          286,
          1415,
          281,
          2985,
          300,
          294,
          341,
          11,
          51388
        ]
      },
      {
        "avg_logprob": -0.2810139550103082,
        "compression_ratio": 1.6867469879518073,
        "end": 1225.98,
        "id": 388,
        "no_speech_prob": 0.00045830331509932876,
        "seek": 120014,
        "start": 1220.6200000000001,
        "temperature": 0,
        "text": " but maybe I will address that in the next video.",
        "tokens": [
          51388,
          457,
          1310,
          286,
          486,
          2985,
          300,
          294,
          264,
          958,
          960,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.2810139550103082,
        "compression_ratio": 1.6867469879518073,
        "end": 1228.8200000000002,
        "id": 389,
        "no_speech_prob": 0.00045830331509932876,
        "seek": 120014,
        "start": 1225.98,
        "temperature": 0,
        "text": " So I would say, I would like to hear from the chat.",
        "tokens": [
          51656,
          407,
          286,
          576,
          584,
          11,
          286,
          576,
          411,
          281,
          1568,
          490,
          264,
          5081,
          13,
          51798
        ]
      },
      {
        "avg_logprob": -0.30090811139061335,
        "compression_ratio": 1.3854166666666667,
        "end": 1230.62,
        "id": 390,
        "no_speech_prob": 0.00027801544638350606,
        "seek": 122882,
        "start": 1228.82,
        "temperature": 0,
        "text": " Why would you want to make an API?",
        "tokens": [
          50364,
          1545,
          576,
          291,
          528,
          281,
          652,
          364,
          9362,
          30,
          50454
        ]
      },
      {
        "avg_logprob": -0.30090811139061335,
        "compression_ratio": 1.3854166666666667,
        "end": 1232.98,
        "id": 391,
        "no_speech_prob": 0.00027801544638350606,
        "seek": 122882,
        "start": 1230.62,
        "temperature": 0,
        "text": " Let's see if we have some good suggestions from the chat",
        "tokens": [
          50454,
          961,
          311,
          536,
          498,
          321,
          362,
          512,
          665,
          13396,
          490,
          264,
          5081,
          50572
        ]
      },
      {
        "avg_logprob": -0.30090811139061335,
        "compression_ratio": 1.3854166666666667,
        "end": 1234.6599999999999,
        "id": 392,
        "no_speech_prob": 0.00027801544638350606,
        "seek": 122882,
        "start": 1232.98,
        "temperature": 0,
        "text": " while I get set up here.",
        "tokens": [
          50572,
          1339,
          286,
          483,
          992,
          493,
          510,
          13,
          50656
        ]
      },
      {
        "avg_logprob": -0.30090811139061335,
        "compression_ratio": 1.3854166666666667,
        "end": 1235.1399999999999,
        "id": 393,
        "no_speech_prob": 0.00027801544638350606,
        "seek": 122882,
        "start": 1234.6599999999999,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50656,
          2264,
          13,
          50680
        ]
      },
      {
        "avg_logprob": -0.30090811139061335,
        "compression_ratio": 1.3854166666666667,
        "end": 1242.6399999999999,
        "id": 394,
        "no_speech_prob": 0.00027801544638350606,
        "seek": 122882,
        "start": 1242.1399999999999,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51030,
          2264,
          13,
          51055
        ]
      },
      {
        "avg_logprob": -0.30090811139061335,
        "compression_ratio": 1.3854166666666667,
        "end": 1250.26,
        "id": 395,
        "no_speech_prob": 0.00027801544638350606,
        "seek": 122882,
        "start": 1246.98,
        "temperature": 0,
        "text": " Max Musterman writes, basically, to allow communication",
        "tokens": [
          51272,
          7402,
          13252,
          11821,
          13657,
          11,
          1936,
          11,
          281,
          2089,
          6101,
          51436
        ]
      },
      {
        "avg_logprob": -0.30090811139061335,
        "compression_ratio": 1.3854166666666667,
        "end": 1251.62,
        "id": 396,
        "no_speech_prob": 0.00027801544638350606,
        "seek": 122882,
        "start": 1250.26,
        "temperature": 0,
        "text": " between two parts of a system.",
        "tokens": [
          51436,
          1296,
          732,
          3166,
          295,
          257,
          1185,
          13,
          51504
        ]
      },
      {
        "avg_logprob": -0.30090811139061335,
        "compression_ratio": 1.3854166666666667,
        "end": 1253.98,
        "id": 397,
        "no_speech_prob": 0.00027801544638350606,
        "seek": 122882,
        "start": 1251.62,
        "temperature": 0,
        "text": " And that's right.",
        "tokens": [
          51504,
          400,
          300,
          311,
          558,
          13,
          51622
        ]
      },
      {
        "avg_logprob": -0.30090811139061335,
        "compression_ratio": 1.3854166666666667,
        "end": 1256.06,
        "id": 398,
        "no_speech_prob": 0.00027801544638350606,
        "seek": 122882,
        "start": 1253.98,
        "temperature": 0,
        "text": " I have sort of two ideas in my head.",
        "tokens": [
          51622,
          286,
          362,
          1333,
          295,
          732,
          3487,
          294,
          452,
          1378,
          13,
          51726
        ]
      },
      {
        "avg_logprob": -0.2541593763563368,
        "compression_ratio": 1.5487364620938628,
        "end": 1261.22,
        "id": 399,
        "no_speech_prob": 0.00015117925067897886,
        "seek": 125606,
        "start": 1256.06,
        "temperature": 0,
        "text": " And I think, hopefully, it'll become clear",
        "tokens": [
          50364,
          400,
          286,
          519,
          11,
          4696,
          11,
          309,
          603,
          1813,
          1850,
          50622
        ]
      },
      {
        "avg_logprob": -0.2541593763563368,
        "compression_ratio": 1.5487364620938628,
        "end": 1262.78,
        "id": 400,
        "no_speech_prob": 0.00015117925067897886,
        "seek": 125606,
        "start": 1261.22,
        "temperature": 0,
        "text": " as I start to make this example.",
        "tokens": [
          50622,
          382,
          286,
          722,
          281,
          652,
          341,
          1365,
          13,
          50700
        ]
      },
      {
        "avg_logprob": -0.2541593763563368,
        "compression_ratio": 1.5487364620938628,
        "end": 1263.4199999999998,
        "id": 401,
        "no_speech_prob": 0.00015117925067897886,
        "seek": 125606,
        "start": 1262.78,
        "temperature": 0,
        "text": " Where are we at?",
        "tokens": [
          50700,
          2305,
          366,
          321,
          412,
          30,
          50732
        ]
      },
      {
        "avg_logprob": -0.2541593763563368,
        "compression_ratio": 1.5487364620938628,
        "end": 1264.06,
        "id": 402,
        "no_speech_prob": 0.00015117925067897886,
        "seek": 125606,
        "start": 1263.4199999999998,
        "temperature": 0,
        "text": " 325.",
        "tokens": [
          50732,
          805,
          6074,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2541593763563368,
        "compression_ratio": 1.5487364620938628,
        "end": 1265.5,
        "id": 403,
        "no_speech_prob": 0.00015117925067897886,
        "seek": 125606,
        "start": 1264.06,
        "temperature": 0,
        "text": " I really have so little time.",
        "tokens": [
          50764,
          286,
          534,
          362,
          370,
          707,
          565,
          13,
          50836
        ]
      },
      {
        "avg_logprob": -0.2541593763563368,
        "compression_ratio": 1.5487364620938628,
        "end": 1267.62,
        "id": 404,
        "no_speech_prob": 0.00015117925067897886,
        "seek": 125606,
        "start": 1265.5,
        "temperature": 0,
        "text": " I'm just letting you guys know that this is probably",
        "tokens": [
          50836,
          286,
          478,
          445,
          8295,
          291,
          1074,
          458,
          300,
          341,
          307,
          1391,
          50942
        ]
      },
      {
        "avg_logprob": -0.2541593763563368,
        "compression_ratio": 1.5487364620938628,
        "end": 1270.1399999999999,
        "id": 405,
        "no_speech_prob": 0.00015117925067897886,
        "seek": 125606,
        "start": 1267.62,
        "temperature": 0,
        "text": " going to only be partially completed by the end of today.",
        "tokens": [
          50942,
          516,
          281,
          787,
          312,
          18886,
          7365,
          538,
          264,
          917,
          295,
          965,
          13,
          51068
        ]
      },
      {
        "avg_logprob": -0.2541593763563368,
        "compression_ratio": 1.5487364620938628,
        "end": 1274.7,
        "id": 406,
        "no_speech_prob": 0.00015117925067897886,
        "seek": 125606,
        "start": 1270.1399999999999,
        "temperature": 0,
        "text": " And I apologize for the sort of late, shorter livestream",
        "tokens": [
          51068,
          400,
          286,
          12328,
          337,
          264,
          1333,
          295,
          3469,
          11,
          11639,
          29782,
          51296
        ]
      },
      {
        "avg_logprob": -0.2541593763563368,
        "compression_ratio": 1.5487364620938628,
        "end": 1275.46,
        "id": 407,
        "no_speech_prob": 0.00015117925067897886,
        "seek": 125606,
        "start": 1274.7,
        "temperature": 0,
        "text": " that I have going.",
        "tokens": [
          51296,
          300,
          286,
          362,
          516,
          13,
          51334
        ]
      },
      {
        "avg_logprob": -0.2541593763563368,
        "compression_ratio": 1.5487364620938628,
        "end": 1275.96,
        "id": 408,
        "no_speech_prob": 0.00015117925067897886,
        "seek": 125606,
        "start": 1275.46,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51334,
          2264,
          13,
          51359
        ]
      },
      {
        "avg_logprob": -0.2541593763563368,
        "compression_ratio": 1.5487364620938628,
        "end": 1277.98,
        "id": 409,
        "no_speech_prob": 0.00015117925067897886,
        "seek": 125606,
        "start": 1275.96,
        "temperature": 0,
        "text": " But I just want to keep on moving here.",
        "tokens": [
          51359,
          583,
          286,
          445,
          528,
          281,
          1066,
          322,
          2684,
          510,
          13,
          51460
        ]
      },
      {
        "avg_logprob": -0.2541593763563368,
        "compression_ratio": 1.5487364620938628,
        "end": 1280.1,
        "id": 410,
        "no_speech_prob": 0.00015117925067897886,
        "seek": 125606,
        "start": 1277.98,
        "temperature": 0,
        "text": " So I have terminal.",
        "tokens": [
          51460,
          407,
          286,
          362,
          14709,
          13,
          51566
        ]
      },
      {
        "avg_logprob": -0.2541593763563368,
        "compression_ratio": 1.5487364620938628,
        "end": 1282.06,
        "id": 411,
        "no_speech_prob": 0.00015117925067897886,
        "seek": 125606,
        "start": 1280.1,
        "temperature": 0,
        "text": " Let me get terminal up.",
        "tokens": [
          51566,
          961,
          385,
          483,
          14709,
          493,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2541593763563368,
        "compression_ratio": 1.5487364620938628,
        "end": 1283.7,
        "id": 412,
        "no_speech_prob": 0.00015117925067897886,
        "seek": 125606,
        "start": 1282.06,
        "temperature": 0,
        "text": " Here's terminal.",
        "tokens": [
          51664,
          1692,
          311,
          14709,
          13,
          51746
        ]
      },
      {
        "avg_logprob": -0.2541593763563368,
        "compression_ratio": 1.5487364620938628,
        "end": 1285.3799999999999,
        "id": 413,
        "no_speech_prob": 0.00015117925067897886,
        "seek": 125606,
        "start": 1283.7,
        "temperature": 0,
        "text": " I'm good.",
        "tokens": [
          51746,
          286,
          478,
          665,
          13,
          51830
        ]
      },
      {
        "avg_logprob": -0.23305934475314233,
        "compression_ratio": 1.5875,
        "end": 1287.98,
        "id": 414,
        "no_speech_prob": 0.00023412564769387245,
        "seek": 128538,
        "start": 1286.2600000000002,
        "temperature": 0,
        "text": " I want to get Adam here.",
        "tokens": [
          50408,
          286,
          528,
          281,
          483,
          7938,
          510,
          13,
          50494
        ]
      },
      {
        "avg_logprob": -0.23305934475314233,
        "compression_ratio": 1.5875,
        "end": 1289.6200000000001,
        "id": 415,
        "no_speech_prob": 0.00023412564769387245,
        "seek": 128538,
        "start": 1287.98,
        "temperature": 0,
        "text": " Here's my code.",
        "tokens": [
          50494,
          1692,
          311,
          452,
          3089,
          13,
          50576
        ]
      },
      {
        "avg_logprob": -0.23305934475314233,
        "compression_ratio": 1.5875,
        "end": 1292.6200000000001,
        "id": 416,
        "no_speech_prob": 0.00023412564769387245,
        "seek": 128538,
        "start": 1289.6200000000001,
        "temperature": 0,
        "text": " I want to make sure I have my notes.",
        "tokens": [
          50576,
          286,
          528,
          281,
          652,
          988,
          286,
          362,
          452,
          5570,
          13,
          50726
        ]
      },
      {
        "avg_logprob": -0.23305934475314233,
        "compression_ratio": 1.5875,
        "end": 1297.22,
        "id": 417,
        "no_speech_prob": 0.00023412564769387245,
        "seek": 128538,
        "start": 1292.6200000000001,
        "temperature": 0,
        "text": " And I'm going to keep this page open.",
        "tokens": [
          50726,
          400,
          286,
          478,
          516,
          281,
          1066,
          341,
          3028,
          1269,
          13,
          50956
        ]
      },
      {
        "avg_logprob": -0.23305934475314233,
        "compression_ratio": 1.5875,
        "end": 1298.3000000000002,
        "id": 418,
        "no_speech_prob": 0.00023412564769387245,
        "seek": 128538,
        "start": 1297.22,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50956,
          2264,
          13,
          51010
        ]
      },
      {
        "avg_logprob": -0.23305934475314233,
        "compression_ratio": 1.5875,
        "end": 1300.98,
        "id": 419,
        "no_speech_prob": 0.00023412564769387245,
        "seek": 128538,
        "start": 1298.3000000000002,
        "temperature": 0,
        "text": " Basically, back from making popcorn.",
        "tokens": [
          51010,
          8537,
          11,
          646,
          490,
          1455,
          25334,
          13,
          51144
        ]
      },
      {
        "avg_logprob": -0.23305934475314233,
        "compression_ratio": 1.5875,
        "end": 1301.7,
        "id": 420,
        "no_speech_prob": 0.00023412564769387245,
        "seek": 128538,
        "start": 1300.98,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51144,
          2264,
          13,
          51180
        ]
      },
      {
        "avg_logprob": -0.23305934475314233,
        "compression_ratio": 1.5875,
        "end": 1303.0200000000002,
        "id": 421,
        "no_speech_prob": 0.00023412564769387245,
        "seek": 128538,
        "start": 1301.7,
        "temperature": 0,
        "text": " Good way to share communication.",
        "tokens": [
          51180,
          2205,
          636,
          281,
          2073,
          6101,
          13,
          51246
        ]
      },
      {
        "avg_logprob": -0.23305934475314233,
        "compression_ratio": 1.5875,
        "end": 1304.94,
        "id": 422,
        "no_speech_prob": 0.00023412564769387245,
        "seek": 128538,
        "start": 1303.0200000000002,
        "temperature": 0,
        "text": " Easily share your data with your developers.",
        "tokens": [
          51246,
          46879,
          953,
          2073,
          428,
          1412,
          365,
          428,
          8849,
          13,
          51342
        ]
      },
      {
        "avg_logprob": -0.23305934475314233,
        "compression_ratio": 1.5875,
        "end": 1308.22,
        "id": 423,
        "no_speech_prob": 0.00023412564769387245,
        "seek": 128538,
        "start": 1304.94,
        "temperature": 0,
        "text": " These are all great, great, great suggestions about why",
        "tokens": [
          51342,
          1981,
          366,
          439,
          869,
          11,
          869,
          11,
          869,
          13396,
          466,
          983,
          51506
        ]
      },
      {
        "avg_logprob": -0.23305934475314233,
        "compression_ratio": 1.5875,
        "end": 1309.6200000000001,
        "id": 424,
        "no_speech_prob": 0.00023412564769387245,
        "seek": 128538,
        "start": 1308.22,
        "temperature": 0,
        "text": " you'd want to make an API.",
        "tokens": [
          51506,
          291,
          1116,
          528,
          281,
          652,
          364,
          9362,
          13,
          51576
        ]
      },
      {
        "avg_logprob": -0.23305934475314233,
        "compression_ratio": 1.5875,
        "end": 1310.1200000000001,
        "id": 425,
        "no_speech_prob": 0.00023412564769387245,
        "seek": 128538,
        "start": 1309.6200000000001,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51576,
          2264,
          13,
          51601
        ]
      },
      {
        "avg_logprob": -0.23305934475314233,
        "compression_ratio": 1.5875,
        "end": 1310.98,
        "id": 426,
        "no_speech_prob": 0.00023412564769387245,
        "seek": 128538,
        "start": 1310.1200000000001,
        "temperature": 0,
        "text": " So here we go.",
        "tokens": [
          51601,
          407,
          510,
          321,
          352,
          13,
          51644
        ]
      },
      {
        "avg_logprob": -0.23305934475314233,
        "compression_ratio": 1.5875,
        "end": 1314.7,
        "id": 427,
        "no_speech_prob": 0.00023412564769387245,
        "seek": 128538,
        "start": 1310.98,
        "temperature": 0,
        "text": " I am going to, for no particular reason,",
        "tokens": [
          51644,
          286,
          669,
          516,
          281,
          11,
          337,
          572,
          1729,
          1778,
          11,
          51830
        ]
      },
      {
        "avg_logprob": -0.2226547279743233,
        "compression_ratio": 1.852760736196319,
        "end": 1316.38,
        "id": 428,
        "no_speech_prob": 0.00004469366103876382,
        "seek": 131470,
        "start": 1314.7,
        "temperature": 0,
        "text": " cycle these cameras.",
        "tokens": [
          50364,
          6586,
          613,
          8622,
          13,
          50448
        ]
      },
      {
        "avg_logprob": -0.2226547279743233,
        "compression_ratio": 1.852760736196319,
        "end": 1318.7,
        "id": 429,
        "no_speech_prob": 0.00004469366103876382,
        "seek": 131470,
        "start": 1316.38,
        "temperature": 0,
        "text": " And I think I'm going to do this in multiple parts.",
        "tokens": [
          50448,
          400,
          286,
          519,
          286,
          478,
          516,
          281,
          360,
          341,
          294,
          3866,
          3166,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2226547279743233,
        "compression_ratio": 1.852760736196319,
        "end": 1323.14,
        "id": 430,
        "no_speech_prob": 0.00004469366103876382,
        "seek": 131470,
        "start": 1318.7,
        "temperature": 0,
        "text": " So this is going to be building your own API in Node.",
        "tokens": [
          50564,
          407,
          341,
          307,
          516,
          281,
          312,
          2390,
          428,
          1065,
          9362,
          294,
          38640,
          13,
          50786
        ]
      },
      {
        "avg_logprob": -0.2226547279743233,
        "compression_ratio": 1.852760736196319,
        "end": 1326.06,
        "id": 431,
        "no_speech_prob": 0.00004469366103876382,
        "seek": 131470,
        "start": 1323.14,
        "temperature": 0,
        "text": " And I think in this first part, I'm",
        "tokens": [
          50786,
          400,
          286,
          519,
          294,
          341,
          700,
          644,
          11,
          286,
          478,
          50932
        ]
      },
      {
        "avg_logprob": -0.2226547279743233,
        "compression_ratio": 1.852760736196319,
        "end": 1332.54,
        "id": 432,
        "no_speech_prob": 0.00004469366103876382,
        "seek": 131470,
        "start": 1326.06,
        "temperature": 0,
        "text": " going to get as far as having a route.",
        "tokens": [
          50932,
          516,
          281,
          483,
          382,
          1400,
          382,
          1419,
          257,
          7955,
          13,
          51256
        ]
      },
      {
        "avg_logprob": -0.2226547279743233,
        "compression_ratio": 1.852760736196319,
        "end": 1334.3400000000001,
        "id": 433,
        "no_speech_prob": 0.00004469366103876382,
        "seek": 131470,
        "start": 1332.54,
        "temperature": 0,
        "text": " And then I'm going to do routes with, OK.",
        "tokens": [
          51256,
          400,
          550,
          286,
          478,
          516,
          281,
          360,
          18242,
          365,
          11,
          2264,
          13,
          51346
        ]
      },
      {
        "avg_logprob": -0.2226547279743233,
        "compression_ratio": 1.852760736196319,
        "end": 1336.54,
        "id": 434,
        "no_speech_prob": 0.00004469366103876382,
        "seek": 131470,
        "start": 1334.3400000000001,
        "temperature": 0,
        "text": " So I'm going to do this in multiple parts.",
        "tokens": [
          51346,
          407,
          286,
          478,
          516,
          281,
          360,
          341,
          294,
          3866,
          3166,
          13,
          51456
        ]
      },
      {
        "avg_logprob": -0.2226547279743233,
        "compression_ratio": 1.852760736196319,
        "end": 1338.6200000000001,
        "id": 435,
        "no_speech_prob": 0.00004469366103876382,
        "seek": 131470,
        "start": 1336.54,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51456,
          2264,
          13,
          51560
        ]
      },
      {
        "avg_logprob": -0.2226547279743233,
        "compression_ratio": 1.852760736196319,
        "end": 1339.3,
        "id": 436,
        "no_speech_prob": 0.00004469366103876382,
        "seek": 131470,
        "start": 1338.6200000000001,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          51560,
          1692,
          321,
          352,
          13,
          51594
        ]
      },
      {
        "avg_logprob": -0.37354337056477865,
        "compression_ratio": 1.6868686868686869,
        "end": 1340.68,
        "id": 437,
        "no_speech_prob": 0.0002694733557291329,
        "seek": 133930,
        "start": 1340.18,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50408,
          2264,
          13,
          50433
        ]
      },
      {
        "avg_logprob": -0.37354337056477865,
        "compression_ratio": 1.6868686868686869,
        "end": 1342.98,
        "id": 438,
        "no_speech_prob": 0.0002694733557291329,
        "seek": 133930,
        "start": 1340.68,
        "temperature": 0,
        "text": " Welcome to a first video in a little series",
        "tokens": [
          50433,
          4027,
          281,
          257,
          700,
          960,
          294,
          257,
          707,
          2638,
          50548
        ]
      },
      {
        "avg_logprob": -0.37354337056477865,
        "compression_ratio": 1.6868686868686869,
        "end": 1345.18,
        "id": 439,
        "no_speech_prob": 0.0002694733557291329,
        "seek": 133930,
        "start": 1342.98,
        "temperature": 0,
        "text": " about building an API with Node.",
        "tokens": [
          50548,
          466,
          2390,
          364,
          9362,
          365,
          38640,
          13,
          50658
        ]
      },
      {
        "avg_logprob": -0.37354337056477865,
        "compression_ratio": 1.6868686868686869,
        "end": 1347.02,
        "id": 440,
        "no_speech_prob": 0.0002694733557291329,
        "seek": 133930,
        "start": 1345.18,
        "temperature": 0,
        "text": " So the question was asked in the live chat.",
        "tokens": [
          50658,
          407,
          264,
          1168,
          390,
          2351,
          294,
          264,
          1621,
          5081,
          13,
          50750
        ]
      },
      {
        "avg_logprob": -0.37354337056477865,
        "compression_ratio": 1.6868686868686869,
        "end": 1348.46,
        "id": 441,
        "no_speech_prob": 0.0002694733557291329,
        "seek": 133930,
        "start": 1347.02,
        "temperature": 0,
        "text": " By the way, you're probably watching",
        "tokens": [
          50750,
          3146,
          264,
          636,
          11,
          291,
          434,
          1391,
          1976,
          50822
        ]
      },
      {
        "avg_logprob": -0.37354337056477865,
        "compression_ratio": 1.6868686868686869,
        "end": 1349.58,
        "id": 442,
        "no_speech_prob": 0.0002694733557291329,
        "seek": 133930,
        "start": 1348.46,
        "temperature": 0,
        "text": " this as a recorded archive.",
        "tokens": [
          50822,
          341,
          382,
          257,
          8287,
          23507,
          13,
          50878
        ]
      },
      {
        "avg_logprob": -0.37354337056477865,
        "compression_ratio": 1.6868686868686869,
        "end": 1352.1399999999999,
        "id": 443,
        "no_speech_prob": 0.0002694733557291329,
        "seek": 133930,
        "start": 1349.58,
        "temperature": 0,
        "text": " But in the live chat, why would you want to make an API?",
        "tokens": [
          50878,
          583,
          294,
          264,
          1621,
          5081,
          11,
          983,
          576,
          291,
          528,
          281,
          652,
          364,
          9362,
          30,
          51006
        ]
      },
      {
        "avg_logprob": -0.37354337056477865,
        "compression_ratio": 1.6868686868686869,
        "end": 1354.46,
        "id": 444,
        "no_speech_prob": 0.0002694733557291329,
        "seek": 133930,
        "start": 1352.1399999999999,
        "temperature": 0,
        "text": " And so I mostly write in the comments.",
        "tokens": [
          51006,
          400,
          370,
          286,
          5240,
          2464,
          294,
          264,
          3053,
          13,
          51122
        ]
      },
      {
        "avg_logprob": -0.37354337056477865,
        "compression_ratio": 1.6868686868686869,
        "end": 1356.46,
        "id": 445,
        "no_speech_prob": 0.0002694733557291329,
        "seek": 133930,
        "start": 1354.46,
        "temperature": 0,
        "text": " I'd love to hear what your idea for an API",
        "tokens": [
          51122,
          286,
          1116,
          959,
          281,
          1568,
          437,
          428,
          1558,
          337,
          364,
          9362,
          51222
        ]
      },
      {
        "avg_logprob": -0.37354337056477865,
        "compression_ratio": 1.6868686868686869,
        "end": 1358.62,
        "id": 446,
        "no_speech_prob": 0.0002694733557291329,
        "seek": 133930,
        "start": 1356.46,
        "temperature": 0,
        "text": " and why you would like to make an API is.",
        "tokens": [
          51222,
          293,
          983,
          291,
          576,
          411,
          281,
          652,
          364,
          9362,
          307,
          13,
          51330
        ]
      },
      {
        "avg_logprob": -0.37354337056477865,
        "compression_ratio": 1.6868686868686869,
        "end": 1360.54,
        "id": 447,
        "no_speech_prob": 0.0002694733557291329,
        "seek": 133930,
        "start": 1358.62,
        "temperature": 0,
        "text": " But there's a couple of reasons that I think",
        "tokens": [
          51330,
          583,
          456,
          311,
          257,
          1916,
          295,
          4112,
          300,
          286,
          519,
          51426
        ]
      },
      {
        "avg_logprob": -0.37354337056477865,
        "compression_ratio": 1.6868686868686869,
        "end": 1362.26,
        "id": 448,
        "no_speech_prob": 0.0002694733557291329,
        "seek": 133930,
        "start": 1360.54,
        "temperature": 0,
        "text": " I could kind of start with here.",
        "tokens": [
          51426,
          286,
          727,
          733,
          295,
          722,
          365,
          510,
          13,
          51512
        ]
      },
      {
        "avg_logprob": -0.37354337056477865,
        "compression_ratio": 1.6868686868686869,
        "end": 1366.4199999999998,
        "id": 449,
        "no_speech_prob": 0.0002694733557291329,
        "seek": 133930,
        "start": 1362.26,
        "temperature": 0,
        "text": " Number one is you have data.",
        "tokens": [
          51512,
          5118,
          472,
          307,
          291,
          362,
          1412,
          13,
          51720
        ]
      },
      {
        "avg_logprob": -0.37354337056477865,
        "compression_ratio": 1.6868686868686869,
        "end": 1367.86,
        "id": 450,
        "no_speech_prob": 0.0002694733557291329,
        "seek": 133930,
        "start": 1366.4199999999998,
        "temperature": 0,
        "text": " And you want to use it.",
        "tokens": [
          51720,
          400,
          291,
          528,
          281,
          764,
          309,
          13,
          51792
        ]
      },
      {
        "avg_logprob": -0.23088194831969247,
        "compression_ratio": 1.751908396946565,
        "end": 1371.78,
        "id": 451,
        "no_speech_prob": 0.0009399303235113621,
        "seek": 136786,
        "start": 1368.6599999999999,
        "temperature": 0,
        "text": " And you want to allow other people to use that data.",
        "tokens": [
          50404,
          400,
          291,
          528,
          281,
          2089,
          661,
          561,
          281,
          764,
          300,
          1412,
          13,
          50560
        ]
      },
      {
        "avg_logprob": -0.23088194831969247,
        "compression_ratio": 1.751908396946565,
        "end": 1374.86,
        "id": 452,
        "no_speech_prob": 0.0009399303235113621,
        "seek": 136786,
        "start": 1371.78,
        "temperature": 0,
        "text": " So this is a way of you kind of making a transaction,",
        "tokens": [
          50560,
          407,
          341,
          307,
          257,
          636,
          295,
          291,
          733,
          295,
          1455,
          257,
          14425,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.23088194831969247,
        "compression_ratio": 1.751908396946565,
        "end": 1376.78,
        "id": 453,
        "no_speech_prob": 0.0009399303235113621,
        "seek": 136786,
        "start": 1374.86,
        "temperature": 0,
        "text": " a sort of handshake, and saying, hey,",
        "tokens": [
          50714,
          257,
          1333,
          295,
          2377,
          34593,
          11,
          293,
          1566,
          11,
          4177,
          11,
          50810
        ]
      },
      {
        "avg_logprob": -0.23088194831969247,
        "compression_ratio": 1.751908396946565,
        "end": 1379.3799999999999,
        "id": 454,
        "no_speech_prob": 0.0009399303235113621,
        "seek": 136786,
        "start": 1376.78,
        "temperature": 0,
        "text": " there is this means for you to access this data.",
        "tokens": [
          50810,
          456,
          307,
          341,
          1355,
          337,
          291,
          281,
          2105,
          341,
          1412,
          13,
          50940
        ]
      },
      {
        "avg_logprob": -0.23088194831969247,
        "compression_ratio": 1.751908396946565,
        "end": 1381.3,
        "id": 455,
        "no_speech_prob": 0.0009399303235113621,
        "seek": 136786,
        "start": 1379.3799999999999,
        "temperature": 0,
        "text": " And I intend for you to be able to do so.",
        "tokens": [
          50940,
          400,
          286,
          19759,
          337,
          291,
          281,
          312,
          1075,
          281,
          360,
          370,
          13,
          51036
        ]
      },
      {
        "avg_logprob": -0.23088194831969247,
        "compression_ratio": 1.751908396946565,
        "end": 1384.2199999999998,
        "id": 456,
        "no_speech_prob": 0.0009399303235113621,
        "seek": 136786,
        "start": 1381.3,
        "temperature": 0,
        "text": " An API stands for Application Programming Interface.",
        "tokens": [
          51036,
          1107,
          9362,
          7382,
          337,
          39512,
          8338,
          2810,
          5751,
          2868,
          13,
          51182
        ]
      },
      {
        "avg_logprob": -0.23088194831969247,
        "compression_ratio": 1.751908396946565,
        "end": 1386.9399999999998,
        "id": 457,
        "no_speech_prob": 0.0009399303235113621,
        "seek": 136786,
        "start": 1384.2199999999998,
        "temperature": 0,
        "text": " It's a way for two different applications",
        "tokens": [
          51182,
          467,
          311,
          257,
          636,
          337,
          732,
          819,
          5821,
          51318
        ]
      },
      {
        "avg_logprob": -0.23088194831969247,
        "compression_ratio": 1.751908396946565,
        "end": 1387.9799999999998,
        "id": 458,
        "no_speech_prob": 0.0009399303235113621,
        "seek": 136786,
        "start": 1386.9399999999998,
        "temperature": 0,
        "text": " to talk to each other.",
        "tokens": [
          51318,
          281,
          751,
          281,
          1184,
          661,
          13,
          51370
        ]
      },
      {
        "avg_logprob": -0.23088194831969247,
        "compression_ratio": 1.751908396946565,
        "end": 1390.62,
        "id": 459,
        "no_speech_prob": 0.0009399303235113621,
        "seek": 136786,
        "start": 1387.9799999999998,
        "temperature": 0,
        "text": " So we're going to build an application, a Node",
        "tokens": [
          51370,
          407,
          321,
          434,
          516,
          281,
          1322,
          364,
          3861,
          11,
          257,
          38640,
          51502
        ]
      },
      {
        "avg_logprob": -0.23088194831969247,
        "compression_ratio": 1.751908396946565,
        "end": 1395.82,
        "id": 460,
        "no_speech_prob": 0.0009399303235113621,
        "seek": 136786,
        "start": 1390.62,
        "temperature": 0,
        "text": " application that has data or something associated with it.",
        "tokens": [
          51502,
          3861,
          300,
          575,
          1412,
          420,
          746,
          6615,
          365,
          309,
          13,
          51762
        ]
      },
      {
        "avg_logprob": -0.227259185579088,
        "compression_ratio": 1.6360759493670887,
        "end": 1399.34,
        "id": 461,
        "no_speech_prob": 0.0003859631542582065,
        "seek": 139582,
        "start": 1395.82,
        "temperature": 0,
        "text": " And other applications will be able to talk to it.",
        "tokens": [
          50364,
          400,
          661,
          5821,
          486,
          312,
          1075,
          281,
          751,
          281,
          309,
          13,
          50540
        ]
      },
      {
        "avg_logprob": -0.227259185579088,
        "compression_ratio": 1.6360759493670887,
        "end": 1400.86,
        "id": 462,
        "no_speech_prob": 0.0003859631542582065,
        "seek": 139582,
        "start": 1399.34,
        "temperature": 0,
        "text": " So that's kind of the main reason.",
        "tokens": [
          50540,
          407,
          300,
          311,
          733,
          295,
          264,
          2135,
          1778,
          13,
          50616
        ]
      },
      {
        "avg_logprob": -0.227259185579088,
        "compression_ratio": 1.6360759493670887,
        "end": 1402.46,
        "id": 463,
        "no_speech_prob": 0.0003859631542582065,
        "seek": 139582,
        "start": 1400.86,
        "temperature": 0,
        "text": " Now, there is sort of this scenario,",
        "tokens": [
          50616,
          823,
          11,
          456,
          307,
          1333,
          295,
          341,
          9005,
          11,
          50696
        ]
      },
      {
        "avg_logprob": -0.227259185579088,
        "compression_ratio": 1.6360759493670887,
        "end": 1404.08,
        "id": 464,
        "no_speech_prob": 0.0003859631542582065,
        "seek": 139582,
        "start": 1402.46,
        "temperature": 0,
        "text": " which I also am going to show you with.",
        "tokens": [
          50696,
          597,
          286,
          611,
          669,
          516,
          281,
          855,
          291,
          365,
          13,
          50777
        ]
      },
      {
        "avg_logprob": -0.227259185579088,
        "compression_ratio": 1.6360759493670887,
        "end": 1407.34,
        "id": 465,
        "no_speech_prob": 0.0003859631542582065,
        "seek": 139582,
        "start": 1404.08,
        "temperature": 0,
        "text": " You might be making an API for one person in the world,",
        "tokens": [
          50777,
          509,
          1062,
          312,
          1455,
          364,
          9362,
          337,
          472,
          954,
          294,
          264,
          1002,
          11,
          50940
        ]
      },
      {
        "avg_logprob": -0.227259185579088,
        "compression_ratio": 1.6360759493670887,
        "end": 1409.46,
        "id": 466,
        "no_speech_prob": 0.0003859631542582065,
        "seek": 139582,
        "start": 1407.34,
        "temperature": 0,
        "text": " one wonderful singular person.",
        "tokens": [
          50940,
          472,
          3715,
          20010,
          954,
          13,
          51046
        ]
      },
      {
        "avg_logprob": -0.227259185579088,
        "compression_ratio": 1.6360759493670887,
        "end": 1410.4199999999998,
        "id": 467,
        "no_speech_prob": 0.0003859631542582065,
        "seek": 139582,
        "start": 1409.46,
        "temperature": 0,
        "text": " And who is that person?",
        "tokens": [
          51046,
          400,
          567,
          307,
          300,
          954,
          30,
          51094
        ]
      },
      {
        "avg_logprob": -0.227259185579088,
        "compression_ratio": 1.6360759493670887,
        "end": 1411.9399999999998,
        "id": 468,
        "no_speech_prob": 0.0003859631542582065,
        "seek": 139582,
        "start": 1410.4199999999998,
        "temperature": 0,
        "text": " It's you, right?",
        "tokens": [
          51094,
          467,
          311,
          291,
          11,
          558,
          30,
          51170
        ]
      },
      {
        "avg_logprob": -0.227259185579088,
        "compression_ratio": 1.6360759493670887,
        "end": 1413.74,
        "id": 469,
        "no_speech_prob": 0.0003859631542582065,
        "seek": 139582,
        "start": 1411.9399999999998,
        "temperature": 0,
        "text": " So there are lots of projects where",
        "tokens": [
          51170,
          407,
          456,
          366,
          3195,
          295,
          4455,
          689,
          51260
        ]
      },
      {
        "avg_logprob": -0.227259185579088,
        "compression_ratio": 1.6360759493670887,
        "end": 1416.54,
        "id": 470,
        "no_speech_prob": 0.0003859631542582065,
        "seek": 139582,
        "start": 1413.74,
        "temperature": 0,
        "text": " you're writing a front end, a client-side JavaScript thing.",
        "tokens": [
          51260,
          291,
          434,
          3579,
          257,
          1868,
          917,
          11,
          257,
          6423,
          12,
          1812,
          15778,
          551,
          13,
          51400
        ]
      },
      {
        "avg_logprob": -0.227259185579088,
        "compression_ratio": 1.6360759493670887,
        "end": 1418.46,
        "id": 471,
        "no_speech_prob": 0.0003859631542582065,
        "seek": 139582,
        "start": 1416.54,
        "temperature": 0,
        "text": " You're making pretty pictures and drawing text",
        "tokens": [
          51400,
          509,
          434,
          1455,
          1238,
          5242,
          293,
          6316,
          2487,
          51496
        ]
      },
      {
        "avg_logprob": -0.227259185579088,
        "compression_ratio": 1.6360759493670887,
        "end": 1420.58,
        "id": 472,
        "no_speech_prob": 0.0003859631542582065,
        "seek": 139582,
        "start": 1418.46,
        "temperature": 0,
        "text": " and all sorts of interaction stuff on the page.",
        "tokens": [
          51496,
          293,
          439,
          7527,
          295,
          9285,
          1507,
          322,
          264,
          3028,
          13,
          51602
        ]
      },
      {
        "avg_logprob": -0.227259185579088,
        "compression_ratio": 1.6360759493670887,
        "end": 1422.74,
        "id": 473,
        "no_speech_prob": 0.0003859631542582065,
        "seek": 139582,
        "start": 1420.58,
        "temperature": 0,
        "text": " But you need some server-side stuff",
        "tokens": [
          51602,
          583,
          291,
          643,
          512,
          7154,
          12,
          1812,
          1507,
          51710
        ]
      },
      {
        "avg_logprob": -0.24459180377778553,
        "compression_ratio": 1.7435897435897436,
        "end": 1426.26,
        "id": 474,
        "no_speech_prob": 0.00016346362826880068,
        "seek": 142274,
        "start": 1422.74,
        "temperature": 0,
        "text": " to connect, to download images, to run long, complicated",
        "tokens": [
          50364,
          281,
          1745,
          11,
          281,
          5484,
          5267,
          11,
          281,
          1190,
          938,
          11,
          6179,
          50540
        ]
      },
      {
        "avg_logprob": -0.24459180377778553,
        "compression_ratio": 1.7435897435897436,
        "end": 1429.02,
        "id": 475,
        "no_speech_prob": 0.00016346362826880068,
        "seek": 142274,
        "start": 1426.26,
        "temperature": 0,
        "text": " processes, to use other Node packages.",
        "tokens": [
          50540,
          7555,
          11,
          281,
          764,
          661,
          38640,
          17401,
          13,
          50678
        ]
      },
      {
        "avg_logprob": -0.24459180377778553,
        "compression_ratio": 1.7435897435897436,
        "end": 1432.34,
        "id": 476,
        "no_speech_prob": 0.00016346362826880068,
        "seek": 142274,
        "start": 1429.02,
        "temperature": 0,
        "text": " So you might make an API just for your own project itself.",
        "tokens": [
          50678,
          407,
          291,
          1062,
          652,
          364,
          9362,
          445,
          337,
          428,
          1065,
          1716,
          2564,
          13,
          50844
        ]
      },
      {
        "avg_logprob": -0.24459180377778553,
        "compression_ratio": 1.7435897435897436,
        "end": 1434.46,
        "id": 477,
        "no_speech_prob": 0.00016346362826880068,
        "seek": 142274,
        "start": 1432.34,
        "temperature": 0,
        "text": " And actually, that's what we might see in some",
        "tokens": [
          50844,
          400,
          767,
          11,
          300,
          311,
          437,
          321,
          1062,
          536,
          294,
          512,
          50950
        ]
      },
      {
        "avg_logprob": -0.24459180377778553,
        "compression_ratio": 1.7435897435897436,
        "end": 1436.22,
        "id": 478,
        "no_speech_prob": 0.00016346362826880068,
        "seek": 142274,
        "start": 1434.46,
        "temperature": 0,
        "text": " of the examples I have to show you.",
        "tokens": [
          50950,
          295,
          264,
          5110,
          286,
          362,
          281,
          855,
          291,
          13,
          51038
        ]
      },
      {
        "avg_logprob": -0.24459180377778553,
        "compression_ratio": 1.7435897435897436,
        "end": 1439.1,
        "id": 479,
        "no_speech_prob": 0.00016346362826880068,
        "seek": 142274,
        "start": 1436.22,
        "temperature": 0,
        "text": " So that's kind of, number one, you might just want to,",
        "tokens": [
          51038,
          407,
          300,
          311,
          733,
          295,
          11,
          1230,
          472,
          11,
          291,
          1062,
          445,
          528,
          281,
          11,
          51182
        ]
      },
      {
        "avg_logprob": -0.24459180377778553,
        "compression_ratio": 1.7435897435897436,
        "end": 1441.78,
        "id": 480,
        "no_speech_prob": 0.00016346362826880068,
        "seek": 142274,
        "start": 1439.1,
        "temperature": 0,
        "text": " you know, you have something and you",
        "tokens": [
          51182,
          291,
          458,
          11,
          291,
          362,
          746,
          293,
          291,
          51316
        ]
      },
      {
        "avg_logprob": -0.24459180377778553,
        "compression_ratio": 1.7435897435897436,
        "end": 1444.26,
        "id": 481,
        "no_speech_prob": 0.00016346362826880068,
        "seek": 142274,
        "start": 1441.78,
        "temperature": 0,
        "text": " want to allow other applications to connect.",
        "tokens": [
          51316,
          528,
          281,
          2089,
          661,
          5821,
          281,
          1745,
          13,
          51440
        ]
      },
      {
        "avg_logprob": -0.24459180377778553,
        "compression_ratio": 1.7435897435897436,
        "end": 1447.98,
        "id": 482,
        "no_speech_prob": 0.00016346362826880068,
        "seek": 142274,
        "start": 1444.26,
        "temperature": 0,
        "text": " Or you might actually want other things being mainly yourself.",
        "tokens": [
          51440,
          1610,
          291,
          1062,
          767,
          528,
          661,
          721,
          885,
          8704,
          1803,
          13,
          51626
        ]
      },
      {
        "avg_logprob": -0.24459180377778553,
        "compression_ratio": 1.7435897435897436,
        "end": 1452.14,
        "id": 483,
        "no_speech_prob": 0.00016346362826880068,
        "seek": 142274,
        "start": 1447.98,
        "temperature": 0,
        "text": " OK, so hopefully, that made some sense",
        "tokens": [
          51626,
          2264,
          11,
          370,
          4696,
          11,
          300,
          1027,
          512,
          2020,
          51834
        ]
      },
      {
        "avg_logprob": -0.22883931102368654,
        "compression_ratio": 1.7414965986394557,
        "end": 1453.5,
        "id": 484,
        "no_speech_prob": 0.0004373313277028501,
        "seek": 145214,
        "start": 1452.14,
        "temperature": 0,
        "text": " of why you might make an API.",
        "tokens": [
          50364,
          295,
          983,
          291,
          1062,
          652,
          364,
          9362,
          13,
          50432
        ]
      },
      {
        "avg_logprob": -0.22883931102368654,
        "compression_ratio": 1.7414965986394557,
        "end": 1455.74,
        "id": 485,
        "no_speech_prob": 0.0004373313277028501,
        "seek": 145214,
        "start": 1453.5,
        "temperature": 0,
        "text": " But really, you know what the answer to that is?",
        "tokens": [
          50432,
          583,
          534,
          11,
          291,
          458,
          437,
          264,
          1867,
          281,
          300,
          307,
          30,
          50544
        ]
      },
      {
        "avg_logprob": -0.22883931102368654,
        "compression_ratio": 1.7414965986394557,
        "end": 1458.7,
        "id": 486,
        "no_speech_prob": 0.0004373313277028501,
        "seek": 145214,
        "start": 1455.74,
        "temperature": 0,
        "text": " Let's try to make an API, talk about it, get to the end.",
        "tokens": [
          50544,
          961,
          311,
          853,
          281,
          652,
          364,
          9362,
          11,
          751,
          466,
          309,
          11,
          483,
          281,
          264,
          917,
          13,
          50692
        ]
      },
      {
        "avg_logprob": -0.22883931102368654,
        "compression_ratio": 1.7414965986394557,
        "end": 1461.7,
        "id": 487,
        "no_speech_prob": 0.0004373313277028501,
        "seek": 145214,
        "start": 1458.7,
        "temperature": 0,
        "text": " And hopefully, some creative ideas",
        "tokens": [
          50692,
          400,
          4696,
          11,
          512,
          5880,
          3487,
          50842
        ]
      },
      {
        "avg_logprob": -0.22883931102368654,
        "compression_ratio": 1.7414965986394557,
        "end": 1466.42,
        "id": 488,
        "no_speech_prob": 0.0004373313277028501,
        "seek": 145214,
        "start": 1461.7,
        "temperature": 0,
        "text": " will emerge in your head as you're watching these videos.",
        "tokens": [
          50842,
          486,
          21511,
          294,
          428,
          1378,
          382,
          291,
          434,
          1976,
          613,
          2145,
          13,
          51078
        ]
      },
      {
        "avg_logprob": -0.22883931102368654,
        "compression_ratio": 1.7414965986394557,
        "end": 1467.98,
        "id": 489,
        "no_speech_prob": 0.0004373313277028501,
        "seek": 145214,
        "start": 1466.42,
        "temperature": 0,
        "text": " OK, so first, I want to point you",
        "tokens": [
          51078,
          2264,
          11,
          370,
          700,
          11,
          286,
          528,
          281,
          935,
          291,
          51156
        ]
      },
      {
        "avg_logprob": -0.22883931102368654,
        "compression_ratio": 1.7414965986394557,
        "end": 1471.1000000000001,
        "id": 490,
        "no_speech_prob": 0.0004373313277028501,
        "seek": 145214,
        "start": 1467.98,
        "temperature": 0,
        "text": " to this web page, which is part of the course.",
        "tokens": [
          51156,
          281,
          341,
          3670,
          3028,
          11,
          597,
          307,
          644,
          295,
          264,
          1164,
          13,
          51312
        ]
      },
      {
        "avg_logprob": -0.22883931102368654,
        "compression_ratio": 1.7414965986394557,
        "end": 1473.24,
        "id": 491,
        "no_speech_prob": 0.0004373313277028501,
        "seek": 145214,
        "start": 1471.1000000000001,
        "temperature": 0,
        "text": " The things that you will need before you're",
        "tokens": [
          51312,
          440,
          721,
          300,
          291,
          486,
          643,
          949,
          291,
          434,
          51419
        ]
      },
      {
        "avg_logprob": -0.22883931102368654,
        "compression_ratio": 1.7414965986394557,
        "end": 1476.6200000000001,
        "id": 492,
        "no_speech_prob": 0.0004373313277028501,
        "seek": 145214,
        "start": 1473.24,
        "temperature": 0,
        "text": " watching this video is what is Node.js and what is NPM.",
        "tokens": [
          51419,
          1976,
          341,
          960,
          307,
          437,
          307,
          38640,
          13,
          25530,
          293,
          437,
          307,
          426,
          18819,
          13,
          51588
        ]
      },
      {
        "avg_logprob": -0.22883931102368654,
        "compression_ratio": 1.7414965986394557,
        "end": 1479.22,
        "id": 493,
        "no_speech_prob": 0.0004373313277028501,
        "seek": 145214,
        "start": 1476.6200000000001,
        "temperature": 0,
        "text": " So you're going to need to have both of those things downloaded.",
        "tokens": [
          51588,
          407,
          291,
          434,
          516,
          281,
          643,
          281,
          362,
          1293,
          295,
          729,
          721,
          21748,
          13,
          51718
        ]
      },
      {
        "avg_logprob": -0.22883931102368654,
        "compression_ratio": 1.7414965986394557,
        "end": 1481.26,
        "id": 494,
        "no_speech_prob": 0.0004373313277028501,
        "seek": 145214,
        "start": 1479.22,
        "temperature": 0,
        "text": " And in this video, I'm going to start",
        "tokens": [
          51718,
          400,
          294,
          341,
          960,
          11,
          286,
          478,
          516,
          281,
          722,
          51820
        ]
      },
      {
        "avg_logprob": -0.22146351657696625,
        "compression_ratio": 1.6298932384341638,
        "end": 1483.54,
        "id": 495,
        "no_speech_prob": 0.0022518166806548834,
        "seek": 148126,
        "start": 1481.3,
        "temperature": 0,
        "text": " with adding Express.",
        "tokens": [
          50366,
          365,
          5127,
          20212,
          13,
          50478
        ]
      },
      {
        "avg_logprob": -0.22146351657696625,
        "compression_ratio": 1.6298932384341638,
        "end": 1486.58,
        "id": 496,
        "no_speech_prob": 0.0022518166806548834,
        "seek": 148126,
        "start": 1483.54,
        "temperature": 0,
        "text": " So I want to use this Express package, which",
        "tokens": [
          50478,
          407,
          286,
          528,
          281,
          764,
          341,
          20212,
          7372,
          11,
          597,
          50630
        ]
      },
      {
        "avg_logprob": -0.22146351657696625,
        "compression_ratio": 1.6298932384341638,
        "end": 1490.78,
        "id": 497,
        "no_speech_prob": 0.0022518166806548834,
        "seek": 148126,
        "start": 1486.58,
        "temperature": 0,
        "text": " is a fast, unopinionated, minimalist web framework",
        "tokens": [
          50630,
          307,
          257,
          2370,
          11,
          517,
          404,
          259,
          313,
          770,
          11,
          50192,
          3670,
          8388,
          50840
        ]
      },
      {
        "avg_logprob": -0.22146351657696625,
        "compression_ratio": 1.6298932384341638,
        "end": 1491.78,
        "id": 498,
        "no_speech_prob": 0.0022518166806548834,
        "seek": 148126,
        "start": 1490.78,
        "temperature": 0,
        "text": " for Node.js.",
        "tokens": [
          50840,
          337,
          38640,
          13,
          25530,
          13,
          50890
        ]
      },
      {
        "avg_logprob": -0.22146351657696625,
        "compression_ratio": 1.6298932384341638,
        "end": 1493.86,
        "id": 499,
        "no_speech_prob": 0.0022518166806548834,
        "seek": 148126,
        "start": 1491.78,
        "temperature": 0,
        "text": " So first of all, I just love anything",
        "tokens": [
          50890,
          407,
          700,
          295,
          439,
          11,
          286,
          445,
          959,
          1340,
          50994
        ]
      },
      {
        "avg_logprob": -0.22146351657696625,
        "compression_ratio": 1.6298932384341638,
        "end": 1496.42,
        "id": 500,
        "no_speech_prob": 0.0022518166806548834,
        "seek": 148126,
        "start": 1493.86,
        "temperature": 0,
        "text": " that says minimalist, because programming",
        "tokens": [
          50994,
          300,
          1619,
          50192,
          11,
          570,
          9410,
          51122
        ]
      },
      {
        "avg_logprob": -0.22146351657696625,
        "compression_ratio": 1.6298932384341638,
        "end": 1497.92,
        "id": 501,
        "no_speech_prob": 0.0022518166806548834,
        "seek": 148126,
        "start": 1496.42,
        "temperature": 0,
        "text": " gets really complicated.",
        "tokens": [
          51122,
          2170,
          534,
          6179,
          13,
          51197
        ]
      },
      {
        "avg_logprob": -0.22146351657696625,
        "compression_ratio": 1.6298932384341638,
        "end": 1499.98,
        "id": 502,
        "no_speech_prob": 0.0022518166806548834,
        "seek": 148126,
        "start": 1497.92,
        "temperature": 0,
        "text": " And looking through documentation and APIs",
        "tokens": [
          51197,
          400,
          1237,
          807,
          14333,
          293,
          21445,
          51300
        ]
      },
      {
        "avg_logprob": -0.22146351657696625,
        "compression_ratio": 1.6298932384341638,
        "end": 1500.94,
        "id": 503,
        "no_speech_prob": 0.0022518166806548834,
        "seek": 148126,
        "start": 1499.98,
        "temperature": 0,
        "text": " is like, ugh.",
        "tokens": [
          51300,
          307,
          411,
          11,
          38560,
          13,
          51348
        ]
      },
      {
        "avg_logprob": -0.22146351657696625,
        "compression_ratio": 1.6298932384341638,
        "end": 1503.14,
        "id": 504,
        "no_speech_prob": 0.0022518166806548834,
        "seek": 148126,
        "start": 1500.94,
        "temperature": 0,
        "text": " So it's nice that a lot of the things",
        "tokens": [
          51348,
          407,
          309,
          311,
          1481,
          300,
          257,
          688,
          295,
          264,
          721,
          51458
        ]
      },
      {
        "avg_logprob": -0.22146351657696625,
        "compression_ratio": 1.6298932384341638,
        "end": 1504.9,
        "id": 505,
        "no_speech_prob": 0.0022518166806548834,
        "seek": 148126,
        "start": 1503.14,
        "temperature": 0,
        "text": " that I want to do in this application",
        "tokens": [
          51458,
          300,
          286,
          528,
          281,
          360,
          294,
          341,
          3861,
          51546
        ]
      },
      {
        "avg_logprob": -0.22146351657696625,
        "compression_ratio": 1.6298932384341638,
        "end": 1508.26,
        "id": 506,
        "no_speech_prob": 0.0022518166806548834,
        "seek": 148126,
        "start": 1504.9,
        "temperature": 0,
        "text": " that I'm going to build is like, oh, host some files.",
        "tokens": [
          51546,
          300,
          286,
          478,
          516,
          281,
          1322,
          307,
          411,
          11,
          1954,
          11,
          3975,
          512,
          7098,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.22146351657696625,
        "compression_ratio": 1.6298932384341638,
        "end": 1511.18,
        "id": 507,
        "no_speech_prob": 0.0022518166806548834,
        "seek": 148126,
        "start": 1508.26,
        "temperature": 0,
        "text": " Or, oh, receive a query from a user.",
        "tokens": [
          51714,
          1610,
          11,
          1954,
          11,
          4774,
          257,
          14581,
          490,
          257,
          4195,
          13,
          51860
        ]
      },
      {
        "avg_logprob": -0.19975081673503792,
        "compression_ratio": 1.6846153846153846,
        "end": 1515.02,
        "id": 508,
        "no_speech_prob": 0.000023923137632664293,
        "seek": 151118,
        "start": 1511.6200000000001,
        "temperature": 0,
        "text": " And Express is going to have a simple function for each",
        "tokens": [
          50386,
          400,
          20212,
          307,
          516,
          281,
          362,
          257,
          2199,
          2445,
          337,
          1184,
          50556
        ]
      },
      {
        "avg_logprob": -0.19975081673503792,
        "compression_ratio": 1.6846153846153846,
        "end": 1517.46,
        "id": 509,
        "no_speech_prob": 0.000023923137632664293,
        "seek": 151118,
        "start": 1515.02,
        "temperature": 0,
        "text": " of those, as opposed to writing all the code for that",
        "tokens": [
          50556,
          295,
          729,
          11,
          382,
          8851,
          281,
          3579,
          439,
          264,
          3089,
          337,
          300,
          50678
        ]
      },
      {
        "avg_logprob": -0.19975081673503792,
        "compression_ratio": 1.6846153846153846,
        "end": 1519.54,
        "id": 510,
        "no_speech_prob": 0.000023923137632664293,
        "seek": 151118,
        "start": 1517.46,
        "temperature": 0,
        "text": " in raw Node, so to speak.",
        "tokens": [
          50678,
          294,
          8936,
          38640,
          11,
          370,
          281,
          1710,
          13,
          50782
        ]
      },
      {
        "avg_logprob": -0.19975081673503792,
        "compression_ratio": 1.6846153846153846,
        "end": 1521.8600000000001,
        "id": 511,
        "no_speech_prob": 0.000023923137632664293,
        "seek": 151118,
        "start": 1519.54,
        "temperature": 0,
        "text": " So the first thing I need to do, which is right here,",
        "tokens": [
          50782,
          407,
          264,
          700,
          551,
          286,
          643,
          281,
          360,
          11,
          597,
          307,
          558,
          510,
          11,
          50898
        ]
      },
      {
        "avg_logprob": -0.19975081673503792,
        "compression_ratio": 1.6846153846153846,
        "end": 1523.42,
        "id": 512,
        "no_speech_prob": 0.000023923137632664293,
        "seek": 151118,
        "start": 1521.8600000000001,
        "temperature": 0,
        "text": " is install Express.",
        "tokens": [
          50898,
          307,
          3625,
          20212,
          13,
          50976
        ]
      },
      {
        "avg_logprob": -0.19975081673503792,
        "compression_ratio": 1.6846153846153846,
        "end": 1525.94,
        "id": 513,
        "no_speech_prob": 0.000023923137632664293,
        "seek": 151118,
        "start": 1523.42,
        "temperature": 0,
        "text": " So just so you know, I happen to be",
        "tokens": [
          50976,
          407,
          445,
          370,
          291,
          458,
          11,
          286,
          1051,
          281,
          312,
          51102
        ]
      },
      {
        "avg_logprob": -0.19975081673503792,
        "compression_ratio": 1.6846153846153846,
        "end": 1529.3,
        "id": 514,
        "no_speech_prob": 0.000023923137632664293,
        "seek": 151118,
        "start": 1525.94,
        "temperature": 0,
        "text": " in a project, which is right here.",
        "tokens": [
          51102,
          294,
          257,
          1716,
          11,
          597,
          307,
          558,
          510,
          13,
          51270
        ]
      },
      {
        "avg_logprob": -0.19975081673503792,
        "compression_ratio": 1.6846153846153846,
        "end": 1530.22,
        "id": 515,
        "no_speech_prob": 0.000023923137632664293,
        "seek": 151118,
        "start": 1529.3,
        "temperature": 0,
        "text": " It's just a folder.",
        "tokens": [
          51270,
          467,
          311,
          445,
          257,
          10820,
          13,
          51316
        ]
      },
      {
        "avg_logprob": -0.19975081673503792,
        "compression_ratio": 1.6846153846153846,
        "end": 1532.3400000000001,
        "id": 516,
        "no_speech_prob": 0.000023923137632664293,
        "seek": 151118,
        "start": 1530.22,
        "temperature": 0,
        "text": " And it has nothing in it.",
        "tokens": [
          51316,
          400,
          309,
          575,
          1825,
          294,
          309,
          13,
          51422
        ]
      },
      {
        "avg_logprob": -0.19975081673503792,
        "compression_ratio": 1.6846153846153846,
        "end": 1535.38,
        "id": 517,
        "no_speech_prob": 0.000023923137632664293,
        "seek": 151118,
        "start": 1532.3400000000001,
        "temperature": 0,
        "text": " All it has so far is a server.js file,",
        "tokens": [
          51422,
          1057,
          309,
          575,
          370,
          1400,
          307,
          257,
          7154,
          13,
          25530,
          3991,
          11,
          51574
        ]
      },
      {
        "avg_logprob": -0.19975081673503792,
        "compression_ratio": 1.6846153846153846,
        "end": 1538.26,
        "id": 518,
        "no_speech_prob": 0.000023923137632664293,
        "seek": 151118,
        "start": 1535.38,
        "temperature": 0,
        "text": " which is going to be the Node program I intend to write.",
        "tokens": [
          51574,
          597,
          307,
          516,
          281,
          312,
          264,
          38640,
          1461,
          286,
          19759,
          281,
          2464,
          13,
          51718
        ]
      },
      {
        "avg_logprob": -0.19975081673503792,
        "compression_ratio": 1.6846153846153846,
        "end": 1539.74,
        "id": 519,
        "no_speech_prob": 0.000023923137632664293,
        "seek": 151118,
        "start": 1538.26,
        "temperature": 0,
        "text": " But it's empty.",
        "tokens": [
          51718,
          583,
          309,
          311,
          6707,
          13,
          51792
        ]
      },
      {
        "avg_logprob": -0.2008190866726548,
        "compression_ratio": 1.5958333333333334,
        "end": 1542.1,
        "id": 520,
        "no_speech_prob": 0.00010554550681263208,
        "seek": 153974,
        "start": 1539.74,
        "temperature": 0,
        "text": " So let's go over here.",
        "tokens": [
          50364,
          407,
          718,
          311,
          352,
          670,
          510,
          13,
          50482
        ]
      },
      {
        "avg_logprob": -0.2008190866726548,
        "compression_ratio": 1.5958333333333334,
        "end": 1543.78,
        "id": 521,
        "no_speech_prob": 0.00010554550681263208,
        "seek": 153974,
        "start": 1542.1,
        "temperature": 0,
        "text": " And I'm going to go to Terminal.",
        "tokens": [
          50482,
          400,
          286,
          478,
          516,
          281,
          352,
          281,
          19835,
          2071,
          13,
          50566
        ]
      },
      {
        "avg_logprob": -0.2008190866726548,
        "compression_ratio": 1.5958333333333334,
        "end": 1547.86,
        "id": 522,
        "no_speech_prob": 0.00010554550681263208,
        "seek": 153974,
        "start": 1543.78,
        "temperature": 0,
        "text": " And I am in that directory right now, which is session 8, API 1.",
        "tokens": [
          50566,
          400,
          286,
          669,
          294,
          300,
          21120,
          558,
          586,
          11,
          597,
          307,
          5481,
          1649,
          11,
          9362,
          502,
          13,
          50770
        ]
      },
      {
        "avg_logprob": -0.2008190866726548,
        "compression_ratio": 1.5958333333333334,
        "end": 1550.14,
        "id": 523,
        "no_speech_prob": 0.00010554550681263208,
        "seek": 153974,
        "start": 1547.86,
        "temperature": 0,
        "text": " And I'm going to install Express.",
        "tokens": [
          50770,
          400,
          286,
          478,
          516,
          281,
          3625,
          20212,
          13,
          50884
        ]
      },
      {
        "avg_logprob": -0.2008190866726548,
        "compression_ratio": 1.5958333333333334,
        "end": 1552.94,
        "id": 524,
        "no_speech_prob": 0.00010554550681263208,
        "seek": 153974,
        "start": 1550.14,
        "temperature": 0,
        "text": " I want to make sure that my, oh, and you",
        "tokens": [
          50884,
          286,
          528,
          281,
          652,
          988,
          300,
          452,
          11,
          1954,
          11,
          293,
          291,
          51024
        ]
      },
      {
        "avg_logprob": -0.2008190866726548,
        "compression_ratio": 1.5958333333333334,
        "end": 1554.14,
        "id": 525,
        "no_speech_prob": 0.00010554550681263208,
        "seek": 153974,
        "start": 1552.94,
        "temperature": 0,
        "text": " know what I didn't do yet?",
        "tokens": [
          51024,
          458,
          437,
          286,
          994,
          380,
          360,
          1939,
          30,
          51084
        ]
      },
      {
        "avg_logprob": -0.2008190866726548,
        "compression_ratio": 1.5958333333333334,
        "end": 1556.34,
        "id": 526,
        "no_speech_prob": 0.00010554550681263208,
        "seek": 153974,
        "start": 1554.14,
        "temperature": 0,
        "text": " I need to have a package.json file.",
        "tokens": [
          51084,
          286,
          643,
          281,
          362,
          257,
          7372,
          13,
          73,
          3015,
          3991,
          13,
          51194
        ]
      },
      {
        "avg_logprob": -0.2008190866726548,
        "compression_ratio": 1.5958333333333334,
        "end": 1559.06,
        "id": 527,
        "no_speech_prob": 0.00010554550681263208,
        "seek": 153974,
        "start": 1556.34,
        "temperature": 0,
        "text": " So the package.json file for a Node project",
        "tokens": [
          51194,
          407,
          264,
          7372,
          13,
          73,
          3015,
          3991,
          337,
          257,
          38640,
          1716,
          51330
        ]
      },
      {
        "avg_logprob": -0.2008190866726548,
        "compression_ratio": 1.5958333333333334,
        "end": 1560.78,
        "id": 528,
        "no_speech_prob": 0.00010554550681263208,
        "seek": 153974,
        "start": 1559.06,
        "temperature": 0,
        "text": " is the kind of configuration file.",
        "tokens": [
          51330,
          307,
          264,
          733,
          295,
          11694,
          3991,
          13,
          51416
        ]
      },
      {
        "avg_logprob": -0.2008190866726548,
        "compression_ratio": 1.5958333333333334,
        "end": 1563.02,
        "id": 529,
        "no_speech_prob": 0.00010554550681263208,
        "seek": 153974,
        "start": 1560.78,
        "temperature": 0,
        "text": " So I'm going to say npm init.",
        "tokens": [
          51416,
          407,
          286,
          478,
          516,
          281,
          584,
          297,
          14395,
          3157,
          13,
          51528
        ]
      },
      {
        "avg_logprob": -0.2008190866726548,
        "compression_ratio": 1.5958333333333334,
        "end": 1568.26,
        "id": 530,
        "no_speech_prob": 0.00010554550681263208,
        "seek": 153974,
        "start": 1563.02,
        "temperature": 0,
        "text": " And yes.",
        "tokens": [
          51528,
          400,
          2086,
          13,
          51790
        ]
      },
      {
        "avg_logprob": -0.2008190866726548,
        "compression_ratio": 1.5958333333333334,
        "end": 1569.38,
        "id": 531,
        "no_speech_prob": 0.00010554550681263208,
        "seek": 153974,
        "start": 1568.26,
        "temperature": 0,
        "text": " Uh-oh.",
        "tokens": [
          51790,
          4019,
          12,
          1445,
          13,
          51846
        ]
      },
      {
        "avg_logprob": -0.3477760569254557,
        "compression_ratio": 1.4484848484848485,
        "end": 1571.98,
        "id": 532,
        "no_speech_prob": 0.00004069414717378095,
        "seek": 156938,
        "start": 1569.42,
        "temperature": 0,
        "text": " This is bad.",
        "tokens": [
          50366,
          639,
          307,
          1578,
          13,
          50494
        ]
      },
      {
        "avg_logprob": -0.3477760569254557,
        "compression_ratio": 1.4484848484848485,
        "end": 1574.42,
        "id": 533,
        "no_speech_prob": 0.00004069414717378095,
        "seek": 156938,
        "start": 1571.98,
        "temperature": 0,
        "text": " Time out.",
        "tokens": [
          50494,
          6161,
          484,
          13,
          50616
        ]
      },
      {
        "avg_logprob": -0.3477760569254557,
        "compression_ratio": 1.4484848484848485,
        "end": 1577.74,
        "id": 534,
        "no_speech_prob": 0.00004069414717378095,
        "seek": 156938,
        "start": 1574.42,
        "temperature": 0,
        "text": " Is something wrong with my Node installation?",
        "tokens": [
          50616,
          1119,
          746,
          2085,
          365,
          452,
          38640,
          13260,
          30,
          50782
        ]
      },
      {
        "avg_logprob": -0.3477760569254557,
        "compression_ratio": 1.4484848484848485,
        "end": 1579.46,
        "id": 535,
        "no_speech_prob": 0.00004069414717378095,
        "seek": 156938,
        "start": 1577.74,
        "temperature": 0,
        "text": " That really would suck.",
        "tokens": [
          50782,
          663,
          534,
          576,
          9967,
          13,
          50868
        ]
      },
      {
        "avg_logprob": -0.3477760569254557,
        "compression_ratio": 1.4484848484848485,
        "end": 1581.38,
        "id": 536,
        "no_speech_prob": 0.00004069414717378095,
        "seek": 156938,
        "start": 1579.46,
        "temperature": 0,
        "text": " Why did that?",
        "tokens": [
          50868,
          1545,
          630,
          300,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.3477760569254557,
        "compression_ratio": 1.4484848484848485,
        "end": 1583.8600000000001,
        "id": 537,
        "no_speech_prob": 0.00004069414717378095,
        "seek": 156938,
        "start": 1581.38,
        "temperature": 0,
        "text": " I'm just going to do something.",
        "tokens": [
          50964,
          286,
          478,
          445,
          516,
          281,
          360,
          746,
          13,
          51088
        ]
      },
      {
        "avg_logprob": -0.3477760569254557,
        "compression_ratio": 1.4484848484848485,
        "end": 1590.9,
        "id": 538,
        "no_speech_prob": 0.00004069414717378095,
        "seek": 156938,
        "start": 1588.14,
        "temperature": 0,
        "text": " I know this is like the worst thing ever to do.",
        "tokens": [
          51302,
          286,
          458,
          341,
          307,
          411,
          264,
          5855,
          551,
          1562,
          281,
          360,
          13,
          51440
        ]
      },
      {
        "avg_logprob": -0.3477760569254557,
        "compression_ratio": 1.4484848484848485,
        "end": 1593.14,
        "id": 539,
        "no_speech_prob": 0.00004069414717378095,
        "seek": 156938,
        "start": 1590.9,
        "temperature": 0,
        "text": " Wait, let me actually look at the error I'm getting.",
        "tokens": [
          51440,
          3802,
          11,
          718,
          385,
          767,
          574,
          412,
          264,
          6713,
          286,
          478,
          1242,
          13,
          51552
        ]
      },
      {
        "avg_logprob": -0.3546641701146176,
        "compression_ratio": 1.4904458598726114,
        "end": 1601.9,
        "id": 540,
        "no_speech_prob": 0.0001823498314479366,
        "seek": 159314,
        "start": 1593.5400000000002,
        "temperature": 0.2,
        "text": " Um, cannot find module SPDX.",
        "tokens": [
          50384,
          3301,
          11,
          2644,
          915,
          10088,
          19572,
          55,
          13,
          50802
        ]
      },
      {
        "avg_logprob": -0.3546641701146176,
        "compression_ratio": 1.4904458598726114,
        "end": 1604.14,
        "id": 541,
        "no_speech_prob": 0.0001823498314479366,
        "seek": 159314,
        "start": 1601.9,
        "temperature": 0.2,
        "text": " Oh, did I upgrade Node?",
        "tokens": [
          50802,
          876,
          11,
          630,
          286,
          11484,
          38640,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.3546641701146176,
        "compression_ratio": 1.4904458598726114,
        "end": 1609.42,
        "id": 542,
        "no_speech_prob": 0.0001823498314479366,
        "seek": 159314,
        "start": 1604.14,
        "temperature": 0.2,
        "text": " And oh, buh, buh, buh, buh, buh, buh, buh, buh, buh.",
        "tokens": [
          50914,
          400,
          1954,
          11,
          758,
          71,
          11,
          758,
          71,
          11,
          758,
          71,
          11,
          758,
          71,
          11,
          758,
          71,
          11,
          758,
          71,
          11,
          758,
          71,
          11,
          758,
          71,
          11,
          758,
          71,
          13,
          51178
        ]
      },
      {
        "avg_logprob": -0.3546641701146176,
        "compression_ratio": 1.4904458598726114,
        "end": 1612.3000000000002,
        "id": 543,
        "no_speech_prob": 0.0001823498314479366,
        "seek": 159314,
        "start": 1609.42,
        "temperature": 0.2,
        "text": " Oh, dear.",
        "tokens": [
          51178,
          876,
          11,
          6875,
          13,
          51322
        ]
      },
      {
        "avg_logprob": -0.3546641701146176,
        "compression_ratio": 1.4904458598726114,
        "end": 1614.3400000000001,
        "id": 544,
        "no_speech_prob": 0.0001823498314479366,
        "seek": 159314,
        "start": 1612.3000000000002,
        "temperature": 0.2,
        "text": " This is very sad.",
        "tokens": [
          51322,
          639,
          307,
          588,
          4227,
          13,
          51424
        ]
      },
      {
        "avg_logprob": -0.3546641701146176,
        "compression_ratio": 1.4904458598726114,
        "end": 1617.22,
        "id": 545,
        "no_speech_prob": 0.0001823498314479366,
        "seek": 159314,
        "start": 1614.3400000000001,
        "temperature": 0.2,
        "text": " My Node is messed up on this computer.",
        "tokens": [
          51424,
          1222,
          38640,
          307,
          16507,
          493,
          322,
          341,
          3820,
          13,
          51568
        ]
      },
      {
        "avg_logprob": -0.3546641701146176,
        "compression_ratio": 1.4904458598726114,
        "end": 1622.3400000000001,
        "id": 546,
        "no_speech_prob": 0.0001823498314479366,
        "seek": 159314,
        "start": 1617.22,
        "temperature": 0.2,
        "text": " I wonder if, um, let me just see if I can power through this.",
        "tokens": [
          51568,
          286,
          2441,
          498,
          11,
          1105,
          11,
          718,
          385,
          445,
          536,
          498,
          286,
          393,
          1347,
          807,
          341,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.2466770518909801,
        "compression_ratio": 1.4733727810650887,
        "end": 1625.3400000000001,
        "id": 547,
        "no_speech_prob": 0.0007553900359198451,
        "seek": 162314,
        "start": 1623.46,
        "temperature": 0,
        "text": " For a second and see what's in here.",
        "tokens": [
          50380,
          1171,
          257,
          1150,
          293,
          536,
          437,
          311,
          294,
          510,
          13,
          50474
        ]
      },
      {
        "avg_logprob": -0.2466770518909801,
        "compression_ratio": 1.4733727810650887,
        "end": 1627.5,
        "id": 548,
        "no_speech_prob": 0.0007553900359198451,
        "seek": 162314,
        "start": 1625.3400000000001,
        "temperature": 0,
        "text": " Yeah, that's pretty good.",
        "tokens": [
          50474,
          865,
          11,
          300,
          311,
          1238,
          665,
          13,
          50582
        ]
      },
      {
        "avg_logprob": -0.2466770518909801,
        "compression_ratio": 1.4733727810650887,
        "end": 1628.3000000000002,
        "id": 549,
        "no_speech_prob": 0.0007553900359198451,
        "seek": 162314,
        "start": 1627.5,
        "temperature": 0,
        "text": " Now let's see.",
        "tokens": [
          50582,
          823,
          718,
          311,
          536,
          13,
          50622
        ]
      },
      {
        "avg_logprob": -0.2466770518909801,
        "compression_ratio": 1.4733727810650887,
        "end": 1630.26,
        "id": 550,
        "no_speech_prob": 0.0007553900359198451,
        "seek": 162314,
        "start": 1628.3000000000002,
        "temperature": 0,
        "text": " Oops, no, no, no, don't delete that.",
        "tokens": [
          50622,
          21726,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          500,
          380,
          12097,
          300,
          13,
          50720
        ]
      },
      {
        "avg_logprob": -0.2466770518909801,
        "compression_ratio": 1.4733727810650887,
        "end": 1633.9,
        "id": 551,
        "no_speech_prob": 0.0007553900359198451,
        "seek": 162314,
        "start": 1630.26,
        "temperature": 0,
        "text": " I want to delete the debug log.",
        "tokens": [
          50720,
          286,
          528,
          281,
          12097,
          264,
          24083,
          3565,
          13,
          50902
        ]
      },
      {
        "avg_logprob": -0.2466770518909801,
        "compression_ratio": 1.4733727810650887,
        "end": 1645.38,
        "id": 552,
        "no_speech_prob": 0.0007553900359198451,
        "seek": 162314,
        "start": 1633.9,
        "temperature": 0,
        "text": " And I'm going to just say npm install express-c.",
        "tokens": [
          50902,
          400,
          286,
          478,
          516,
          281,
          445,
          584,
          297,
          14395,
          3625,
          5109,
          12,
          66,
          13,
          51476
        ]
      },
      {
        "avg_logprob": -0.2466770518909801,
        "compression_ratio": 1.4733727810650887,
        "end": 1649.42,
        "id": 553,
        "no_speech_prob": 0.0007553900359198451,
        "seek": 162314,
        "start": 1645.38,
        "temperature": 0,
        "text": " OK, so I just have something screwy with my npm init.",
        "tokens": [
          51476,
          2264,
          11,
          370,
          286,
          445,
          362,
          746,
          5630,
          88,
          365,
          452,
          297,
          14395,
          3157,
          13,
          51678
        ]
      },
      {
        "avg_logprob": -0.2643911157335554,
        "compression_ratio": 1.5636363636363637,
        "end": 1654.3400000000001,
        "id": 554,
        "no_speech_prob": 0.000060140882851555943,
        "seek": 164942,
        "start": 1649.46,
        "temperature": 0,
        "text": " So I'm going to double back and just skip that in this video.",
        "tokens": [
          50366,
          407,
          286,
          478,
          516,
          281,
          3834,
          646,
          293,
          445,
          10023,
          300,
          294,
          341,
          960,
          13,
          50610
        ]
      },
      {
        "avg_logprob": -0.2643911157335554,
        "compression_ratio": 1.5636363636363637,
        "end": 1663.66,
        "id": 555,
        "no_speech_prob": 0.000060140882851555943,
        "seek": 164942,
        "start": 1654.3400000000001,
        "temperature": 0,
        "text": " And I'll just have a package.json file API test.",
        "tokens": [
          50610,
          400,
          286,
          603,
          445,
          362,
          257,
          7372,
          13,
          73,
          3015,
          3991,
          9362,
          1500,
          13,
          51076
        ]
      },
      {
        "avg_logprob": -0.2643911157335554,
        "compression_ratio": 1.5636363636363637,
        "end": 1667.74,
        "id": 556,
        "no_speech_prob": 0.000060140882851555943,
        "seek": 164942,
        "start": 1663.66,
        "temperature": 0,
        "text": " I'm just going to pretend I made it by myself.",
        "tokens": [
          51076,
          286,
          478,
          445,
          516,
          281,
          11865,
          286,
          1027,
          309,
          538,
          2059,
          13,
          51280
        ]
      },
      {
        "avg_logprob": -0.2643911157335554,
        "compression_ratio": 1.5636363636363637,
        "end": 1670.8200000000002,
        "id": 557,
        "no_speech_prob": 0.000060140882851555943,
        "seek": 164942,
        "start": 1667.74,
        "temperature": 0,
        "text": " Mattheo, this will be a, um, yeah, I need to reinstall Node.",
        "tokens": [
          51280,
          6789,
          3322,
          78,
          11,
          341,
          486,
          312,
          257,
          11,
          1105,
          11,
          1338,
          11,
          286,
          643,
          281,
          35056,
          336,
          38640,
          13,
          51434
        ]
      },
      {
        "avg_logprob": -0.2643911157335554,
        "compression_ratio": 1.5636363636363637,
        "end": 1671.54,
        "id": 558,
        "no_speech_prob": 0.000060140882851555943,
        "seek": 164942,
        "start": 1670.8200000000002,
        "temperature": 0,
        "text": " Thank you, guys.",
        "tokens": [
          51434,
          1044,
          291,
          11,
          1074,
          13,
          51470
        ]
      },
      {
        "avg_logprob": -0.2643911157335554,
        "compression_ratio": 1.5636363636363637,
        "end": 1673.94,
        "id": 559,
        "no_speech_prob": 0.000060140882851555943,
        "seek": 164942,
        "start": 1671.54,
        "temperature": 0,
        "text": " Mattheo, this will be a little bit of a challenge for you.",
        "tokens": [
          51470,
          6789,
          3322,
          78,
          11,
          341,
          486,
          312,
          257,
          707,
          857,
          295,
          257,
          3430,
          337,
          291,
          13,
          51590
        ]
      },
      {
        "avg_logprob": -0.2643911157335554,
        "compression_ratio": 1.5636363636363637,
        "end": 1678.14,
        "id": 560,
        "no_speech_prob": 0.000060140882851555943,
        "seek": 164942,
        "start": 1673.94,
        "temperature": 0,
        "text": " But I don't think it'll be too much of a problem.",
        "tokens": [
          51590,
          583,
          286,
          500,
          380,
          519,
          309,
          603,
          312,
          886,
          709,
          295,
          257,
          1154,
          13,
          51800
        ]
      },
      {
        "avg_logprob": -0.2045481688994214,
        "compression_ratio": 1.8075313807531381,
        "end": 1680.7,
        "id": 561,
        "no_speech_prob": 0.00008614621037850156,
        "seek": 167814,
        "start": 1678.14,
        "temperature": 0,
        "text": " I'm going to delete this.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          12097,
          341,
          13,
          50492
        ]
      },
      {
        "avg_logprob": -0.2045481688994214,
        "compression_ratio": 1.8075313807531381,
        "end": 1685.6200000000001,
        "id": 562,
        "no_speech_prob": 0.00008614621037850156,
        "seek": 167814,
        "start": 1680.7,
        "temperature": 0,
        "text": " So I'm going to go back to where I said I have,",
        "tokens": [
          50492,
          407,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          689,
          286,
          848,
          286,
          362,
          11,
          50738
        ]
      },
      {
        "avg_logprob": -0.2045481688994214,
        "compression_ratio": 1.8075313807531381,
        "end": 1688.22,
        "id": 563,
        "no_speech_prob": 0.00008614621037850156,
        "seek": 167814,
        "start": 1685.6200000000001,
        "temperature": 0,
        "text": " all I have is server and package.json.",
        "tokens": [
          50738,
          439,
          286,
          362,
          307,
          7154,
          293,
          7372,
          13,
          73,
          3015,
          13,
          50868
        ]
      },
      {
        "avg_logprob": -0.2045481688994214,
        "compression_ratio": 1.8075313807531381,
        "end": 1690.5,
        "id": 564,
        "no_speech_prob": 0.00008614621037850156,
        "seek": 167814,
        "start": 1688.22,
        "temperature": 0,
        "text": " And it's going to have to get edited together somehow.",
        "tokens": [
          50868,
          400,
          309,
          311,
          516,
          281,
          362,
          281,
          483,
          23016,
          1214,
          6063,
          13,
          50982
        ]
      },
      {
        "avg_logprob": -0.2045481688994214,
        "compression_ratio": 1.8075313807531381,
        "end": 1693,
        "id": 565,
        "no_speech_prob": 0.00008614621037850156,
        "seek": 167814,
        "start": 1690.5,
        "temperature": 0,
        "text": " I don't remember what I was in, but probably I was over here.",
        "tokens": [
          50982,
          286,
          500,
          380,
          1604,
          437,
          286,
          390,
          294,
          11,
          457,
          1391,
          286,
          390,
          670,
          510,
          13,
          51107
        ]
      },
      {
        "avg_logprob": -0.2045481688994214,
        "compression_ratio": 1.8075313807531381,
        "end": 1697.74,
        "id": 566,
        "no_speech_prob": 0.00008614621037850156,
        "seek": 167814,
        "start": 1696.0600000000002,
        "temperature": 0,
        "text": " So I'm going to look at my directory",
        "tokens": [
          51260,
          407,
          286,
          478,
          516,
          281,
          574,
          412,
          452,
          21120,
          51344
        ]
      },
      {
        "avg_logprob": -0.2045481688994214,
        "compression_ratio": 1.8075313807531381,
        "end": 1700.3000000000002,
        "id": 567,
        "no_speech_prob": 0.00008614621037850156,
        "seek": 167814,
        "start": 1697.74,
        "temperature": 0,
        "text": " where I have the project.",
        "tokens": [
          51344,
          689,
          286,
          362,
          264,
          1716,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -0.2045481688994214,
        "compression_ratio": 1.8075313807531381,
        "end": 1702.3000000000002,
        "id": 568,
        "no_speech_prob": 0.00008614621037850156,
        "seek": 167814,
        "start": 1700.3000000000002,
        "temperature": 0,
        "text": " And all I have is two things.",
        "tokens": [
          51472,
          400,
          439,
          286,
          362,
          307,
          732,
          721,
          13,
          51572
        ]
      },
      {
        "avg_logprob": -0.2045481688994214,
        "compression_ratio": 1.8075313807531381,
        "end": 1704.5800000000002,
        "id": 569,
        "no_speech_prob": 0.00008614621037850156,
        "seek": 167814,
        "start": 1702.3000000000002,
        "temperature": 0,
        "text": " I have a server.js file, which is actually,",
        "tokens": [
          51572,
          286,
          362,
          257,
          7154,
          13,
          25530,
          3991,
          11,
          597,
          307,
          767,
          11,
          51686
        ]
      },
      {
        "avg_logprob": -0.2045481688994214,
        "compression_ratio": 1.8075313807531381,
        "end": 1707.38,
        "id": 570,
        "no_speech_prob": 0.00008614621037850156,
        "seek": 167814,
        "start": 1704.5800000000002,
        "temperature": 0,
        "text": " that's where I'm going to put my JavaScript code, which is empty.",
        "tokens": [
          51686,
          300,
          311,
          689,
          286,
          478,
          516,
          281,
          829,
          452,
          15778,
          3089,
          11,
          597,
          307,
          6707,
          13,
          51826
        ]
      },
      {
        "avg_logprob": -0.23090707470556934,
        "compression_ratio": 1.7337461300309598,
        "end": 1709.22,
        "id": 571,
        "no_speech_prob": 0.0005033256020396948,
        "seek": 170738,
        "start": 1707.38,
        "temperature": 0,
        "text": " And then I have this package.json file,",
        "tokens": [
          50364,
          400,
          550,
          286,
          362,
          341,
          7372,
          13,
          73,
          3015,
          3991,
          11,
          50456
        ]
      },
      {
        "avg_logprob": -0.23090707470556934,
        "compression_ratio": 1.7337461300309598,
        "end": 1711.46,
        "id": 572,
        "no_speech_prob": 0.0005033256020396948,
        "seek": 170738,
        "start": 1709.22,
        "temperature": 0,
        "text": " which you can make with npm init.",
        "tokens": [
          50456,
          597,
          291,
          393,
          652,
          365,
          297,
          14395,
          3157,
          13,
          50568
        ]
      },
      {
        "avg_logprob": -0.23090707470556934,
        "compression_ratio": 1.7337461300309598,
        "end": 1712.7,
        "id": 573,
        "no_speech_prob": 0.0005033256020396948,
        "seek": 170738,
        "start": 1711.46,
        "temperature": 0,
        "text": " But I already have one there.",
        "tokens": [
          50568,
          583,
          286,
          1217,
          362,
          472,
          456,
          13,
          50630
        ]
      },
      {
        "avg_logprob": -0.23090707470556934,
        "compression_ratio": 1.7337461300309598,
        "end": 1715.42,
        "id": 574,
        "no_speech_prob": 0.0005033256020396948,
        "seek": 170738,
        "start": 1712.7,
        "temperature": 0,
        "text": " That's your configuration file for the project.",
        "tokens": [
          50630,
          663,
          311,
          428,
          11694,
          3991,
          337,
          264,
          1716,
          13,
          50766
        ]
      },
      {
        "avg_logprob": -0.23090707470556934,
        "compression_ratio": 1.7337461300309598,
        "end": 1716.96,
        "id": 575,
        "no_speech_prob": 0.0005033256020396948,
        "seek": 170738,
        "start": 1715.42,
        "temperature": 0,
        "text": " And there's lots of important details",
        "tokens": [
          50766,
          400,
          456,
          311,
          3195,
          295,
          1021,
          4365,
          50843
        ]
      },
      {
        "avg_logprob": -0.23090707470556934,
        "compression_ratio": 1.7337461300309598,
        "end": 1719.7,
        "id": 576,
        "no_speech_prob": 0.0005033256020396948,
        "seek": 170738,
        "start": 1716.96,
        "temperature": 0,
        "text": " about that if you go to publish your thing as a Node package",
        "tokens": [
          50843,
          466,
          300,
          498,
          291,
          352,
          281,
          11374,
          428,
          551,
          382,
          257,
          38640,
          7372,
          50980
        ]
      },
      {
        "avg_logprob": -0.23090707470556934,
        "compression_ratio": 1.7337461300309598,
        "end": 1720.94,
        "id": 577,
        "no_speech_prob": 0.0005033256020396948,
        "seek": 170738,
        "start": 1719.7,
        "temperature": 0,
        "text": " or an open source project.",
        "tokens": [
          50980,
          420,
          364,
          1269,
          4009,
          1716,
          13,
          51042
        ]
      },
      {
        "avg_logprob": -0.23090707470556934,
        "compression_ratio": 1.7337461300309598,
        "end": 1723.1000000000001,
        "id": 578,
        "no_speech_prob": 0.0005033256020396948,
        "seek": 170738,
        "start": 1720.94,
        "temperature": 0,
        "text": " But for now, we can mostly ignore",
        "tokens": [
          51042,
          583,
          337,
          586,
          11,
          321,
          393,
          5240,
          11200,
          51150
        ]
      },
      {
        "avg_logprob": -0.23090707470556934,
        "compression_ratio": 1.7337461300309598,
        "end": 1725.66,
        "id": 579,
        "no_speech_prob": 0.0005033256020396948,
        "seek": 170738,
        "start": 1723.1000000000001,
        "temperature": 0,
        "text": " the contents of package.json.",
        "tokens": [
          51150,
          264,
          15768,
          295,
          7372,
          13,
          73,
          3015,
          13,
          51278
        ]
      },
      {
        "avg_logprob": -0.23090707470556934,
        "compression_ratio": 1.7337461300309598,
        "end": 1727.98,
        "id": 580,
        "no_speech_prob": 0.0005033256020396948,
        "seek": 170738,
        "start": 1725.66,
        "temperature": 0,
        "text": " I'll come back to it maybe another time.",
        "tokens": [
          51278,
          286,
          603,
          808,
          646,
          281,
          309,
          1310,
          1071,
          565,
          13,
          51394
        ]
      },
      {
        "avg_logprob": -0.23090707470556934,
        "compression_ratio": 1.7337461300309598,
        "end": 1729.14,
        "id": 581,
        "no_speech_prob": 0.0005033256020396948,
        "seek": 170738,
        "start": 1727.98,
        "temperature": 0,
        "text": " So you can see what's in it.",
        "tokens": [
          51394,
          407,
          291,
          393,
          536,
          437,
          311,
          294,
          309,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.23090707470556934,
        "compression_ratio": 1.7337461300309598,
        "end": 1730.94,
        "id": 582,
        "no_speech_prob": 0.0005033256020396948,
        "seek": 170738,
        "start": 1729.14,
        "temperature": 0,
        "text": " It's just like a little bit of stuff saying,",
        "tokens": [
          51452,
          467,
          311,
          445,
          411,
          257,
          707,
          857,
          295,
          1507,
          1566,
          11,
          51542
        ]
      },
      {
        "avg_logprob": -0.23090707470556934,
        "compression_ratio": 1.7337461300309598,
        "end": 1732.14,
        "id": 583,
        "no_speech_prob": 0.0005033256020396948,
        "seek": 170738,
        "start": 1730.94,
        "temperature": 0,
        "text": " hey, this is the name of my project,",
        "tokens": [
          51542,
          4177,
          11,
          341,
          307,
          264,
          1315,
          295,
          452,
          1716,
          11,
          51602
        ]
      },
      {
        "avg_logprob": -0.23090707470556934,
        "compression_ratio": 1.7337461300309598,
        "end": 1733.2600000000002,
        "id": 584,
        "no_speech_prob": 0.0005033256020396948,
        "seek": 170738,
        "start": 1732.14,
        "temperature": 0,
        "text": " and this is the version.",
        "tokens": [
          51602,
          293,
          341,
          307,
          264,
          3037,
          13,
          51658
        ]
      },
      {
        "avg_logprob": -0.23090707470556934,
        "compression_ratio": 1.7337461300309598,
        "end": 1736.6200000000001,
        "id": 585,
        "no_speech_prob": 0.0005033256020396948,
        "seek": 170738,
        "start": 1733.2600000000002,
        "temperature": 0,
        "text": " But what I want to do is go and grab this",
        "tokens": [
          51658,
          583,
          437,
          286,
          528,
          281,
          360,
          307,
          352,
          293,
          4444,
          341,
          51826
        ]
      },
      {
        "avg_logprob": -0.23169610964371853,
        "compression_ratio": 1.800796812749004,
        "end": 1739.5,
        "id": 586,
        "no_speech_prob": 0.00032503274269402027,
        "seek": 173662,
        "start": 1736.62,
        "temperature": 0,
        "text": " and now install Express with this project.",
        "tokens": [
          50364,
          293,
          586,
          3625,
          20212,
          365,
          341,
          1716,
          13,
          50508
        ]
      },
      {
        "avg_logprob": -0.23169610964371853,
        "compression_ratio": 1.800796812749004,
        "end": 1742.54,
        "id": 587,
        "no_speech_prob": 0.00032503274269402027,
        "seek": 173662,
        "start": 1739.5,
        "temperature": 0,
        "text": " So I'm going to say, and you can see I'm in that directory.",
        "tokens": [
          50508,
          407,
          286,
          478,
          516,
          281,
          584,
          11,
          293,
          291,
          393,
          536,
          286,
          478,
          294,
          300,
          21120,
          13,
          50660
        ]
      },
      {
        "avg_logprob": -0.23169610964371853,
        "compression_ratio": 1.800796812749004,
        "end": 1744.1399999999999,
        "id": 588,
        "no_speech_prob": 0.00032503274269402027,
        "seek": 173662,
        "start": 1742.54,
        "temperature": 0,
        "text": " And I'm going to say npm install.",
        "tokens": [
          50660,
          400,
          286,
          478,
          516,
          281,
          584,
          297,
          14395,
          3625,
          13,
          50740
        ]
      },
      {
        "avg_logprob": -0.23169610964371853,
        "compression_ratio": 1.800796812749004,
        "end": 1746.2199999999998,
        "id": 589,
        "no_speech_prob": 0.00032503274269402027,
        "seek": 173662,
        "start": 1744.1399999999999,
        "temperature": 0,
        "text": " Oh, actually, I'm just going to paste it in there.",
        "tokens": [
          50740,
          876,
          11,
          767,
          11,
          286,
          478,
          445,
          516,
          281,
          9163,
          309,
          294,
          456,
          13,
          50844
        ]
      },
      {
        "avg_logprob": -0.23169610964371853,
        "compression_ratio": 1.800796812749004,
        "end": 1747.9799999999998,
        "id": 590,
        "no_speech_prob": 0.00032503274269402027,
        "seek": 173662,
        "start": 1746.2199999999998,
        "temperature": 0,
        "text": " npm install express dash dash save.",
        "tokens": [
          50844,
          297,
          14395,
          3625,
          5109,
          8240,
          8240,
          3155,
          13,
          50932
        ]
      },
      {
        "avg_logprob": -0.23169610964371853,
        "compression_ratio": 1.800796812749004,
        "end": 1750.3799999999999,
        "id": 591,
        "no_speech_prob": 0.00032503274269402027,
        "seek": 173662,
        "start": 1747.9799999999998,
        "temperature": 0,
        "text": " Ah!",
        "tokens": [
          50932,
          2438,
          0,
          51052
        ]
      },
      {
        "avg_logprob": -0.23169610964371853,
        "compression_ratio": 1.800796812749004,
        "end": 1752.02,
        "id": 592,
        "no_speech_prob": 0.00032503274269402027,
        "seek": 173662,
        "start": 1750.3799999999999,
        "temperature": 0,
        "text": " Oh, I have an error in parse.",
        "tokens": [
          51052,
          876,
          11,
          286,
          362,
          364,
          6713,
          294,
          48377,
          13,
          51134
        ]
      },
      {
        "avg_logprob": -0.23169610964371853,
        "compression_ratio": 1.800796812749004,
        "end": 1753.06,
        "id": 593,
        "no_speech_prob": 0.00032503274269402027,
        "seek": 173662,
        "start": 1752.02,
        "temperature": 0,
        "text": " So I messed up.",
        "tokens": [
          51134,
          407,
          286,
          16507,
          493,
          13,
          51186
        ]
      },
      {
        "avg_logprob": -0.23169610964371853,
        "compression_ratio": 1.800796812749004,
        "end": 1754.4599999999998,
        "id": 594,
        "no_speech_prob": 0.00032503274269402027,
        "seek": 173662,
        "start": 1753.06,
        "temperature": 0,
        "text": " I have an error here.",
        "tokens": [
          51186,
          286,
          362,
          364,
          6713,
          510,
          13,
          51256
        ]
      },
      {
        "avg_logprob": -0.23169610964371853,
        "compression_ratio": 1.800796812749004,
        "end": 1755.82,
        "id": 595,
        "no_speech_prob": 0.00032503274269402027,
        "seek": 173662,
        "start": 1754.4599999999998,
        "temperature": 0,
        "text": " I wrote that package.",
        "tokens": [
          51256,
          286,
          4114,
          300,
          7372,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.23169610964371853,
        "compression_ratio": 1.800796812749004,
        "end": 1759.54,
        "id": 596,
        "no_speech_prob": 0.00032503274269402027,
        "seek": 173662,
        "start": 1755.82,
        "temperature": 0,
        "text": " So by the way, if that happens to you, let that happen.",
        "tokens": [
          51324,
          407,
          538,
          264,
          636,
          11,
          498,
          300,
          2314,
          281,
          291,
          11,
          718,
          300,
          1051,
          13,
          51510
        ]
      },
      {
        "avg_logprob": -0.23169610964371853,
        "compression_ratio": 1.800796812749004,
        "end": 1763.02,
        "id": 597,
        "no_speech_prob": 0.00032503274269402027,
        "seek": 173662,
        "start": 1759.54,
        "temperature": 0,
        "text": " Trailing comma, I got an error in my package.json file.",
        "tokens": [
          51510,
          5403,
          4883,
          22117,
          11,
          286,
          658,
          364,
          6713,
          294,
          452,
          7372,
          13,
          73,
          3015,
          3991,
          13,
          51684
        ]
      },
      {
        "avg_logprob": -0.23169610964371853,
        "compression_ratio": 1.800796812749004,
        "end": 1764.4199999999998,
        "id": 598,
        "no_speech_prob": 0.00032503274269402027,
        "seek": 173662,
        "start": 1763.02,
        "temperature": 0,
        "text": " So that should fix it.",
        "tokens": [
          51684,
          407,
          300,
          820,
          3191,
          309,
          13,
          51754
        ]
      },
      {
        "avg_logprob": -0.25744163567292777,
        "compression_ratio": 1.8275862068965518,
        "end": 1767.78,
        "id": 599,
        "no_speech_prob": 0.0001273100497201085,
        "seek": 176442,
        "start": 1764.42,
        "temperature": 0,
        "text": " I'm going to say clear and try this again.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          584,
          1850,
          293,
          853,
          341,
          797,
          13,
          50532
        ]
      },
      {
        "avg_logprob": -0.25744163567292777,
        "compression_ratio": 1.8275862068965518,
        "end": 1769.18,
        "id": 600,
        "no_speech_prob": 0.0001273100497201085,
        "seek": 176442,
        "start": 1767.78,
        "temperature": 0,
        "text": " Oh, yay, that looks much better.",
        "tokens": [
          50532,
          876,
          11,
          23986,
          11,
          300,
          1542,
          709,
          1101,
          13,
          50602
        ]
      },
      {
        "avg_logprob": -0.25744163567292777,
        "compression_ratio": 1.8275862068965518,
        "end": 1773.14,
        "id": 601,
        "no_speech_prob": 0.0001273100497201085,
        "seek": 176442,
        "start": 1769.18,
        "temperature": 0,
        "text": " So you can see it should now I should have a new directory",
        "tokens": [
          50602,
          407,
          291,
          393,
          536,
          309,
          820,
          586,
          286,
          820,
          362,
          257,
          777,
          21120,
          50800
        ]
      },
      {
        "avg_logprob": -0.25744163567292777,
        "compression_ratio": 1.8275862068965518,
        "end": 1774.3000000000002,
        "id": 602,
        "no_speech_prob": 0.0001273100497201085,
        "seek": 176442,
        "start": 1773.14,
        "temperature": 0,
        "text": " called node modules.",
        "tokens": [
          50800,
          1219,
          9984,
          16679,
          13,
          50858
        ]
      },
      {
        "avg_logprob": -0.25744163567292777,
        "compression_ratio": 1.8275862068965518,
        "end": 1775.98,
        "id": 603,
        "no_speech_prob": 0.0001273100497201085,
        "seek": 176442,
        "start": 1774.3000000000002,
        "temperature": 0,
        "text": " And you can see, oh, there's all this stuff installed in there.",
        "tokens": [
          50858,
          400,
          291,
          393,
          536,
          11,
          1954,
          11,
          456,
          311,
          439,
          341,
          1507,
          8899,
          294,
          456,
          13,
          50942
        ]
      },
      {
        "avg_logprob": -0.25744163567292777,
        "compression_ratio": 1.8275862068965518,
        "end": 1778.9,
        "id": 604,
        "no_speech_prob": 0.0001273100497201085,
        "seek": 176442,
        "start": 1775.98,
        "temperature": 0,
        "text": " I'm just going to have to trust that Express installed",
        "tokens": [
          50942,
          286,
          478,
          445,
          516,
          281,
          362,
          281,
          3361,
          300,
          20212,
          8899,
          51088
        ]
      },
      {
        "avg_logprob": -0.25744163567292777,
        "compression_ratio": 1.8275862068965518,
        "end": 1779.74,
        "id": 605,
        "no_speech_prob": 0.0001273100497201085,
        "seek": 176442,
        "start": 1778.9,
        "temperature": 0,
        "text": " correctly.",
        "tokens": [
          51088,
          8944,
          13,
          51130
        ]
      },
      {
        "avg_logprob": -0.25744163567292777,
        "compression_ratio": 1.8275862068965518,
        "end": 1781.6200000000001,
        "id": 606,
        "no_speech_prob": 0.0001273100497201085,
        "seek": 176442,
        "start": 1779.74,
        "temperature": 0,
        "text": " So let's make sure everything's working.",
        "tokens": [
          51130,
          407,
          718,
          311,
          652,
          988,
          1203,
          311,
          1364,
          13,
          51224
        ]
      },
      {
        "avg_logprob": -0.25744163567292777,
        "compression_ratio": 1.8275862068965518,
        "end": 1783.26,
        "id": 607,
        "no_speech_prob": 0.0001273100497201085,
        "seek": 176442,
        "start": 1781.6200000000001,
        "temperature": 0,
        "text": " I'm going to go into my server.",
        "tokens": [
          51224,
          286,
          478,
          516,
          281,
          352,
          666,
          452,
          7154,
          13,
          51306
        ]
      },
      {
        "avg_logprob": -0.25744163567292777,
        "compression_ratio": 1.8275862068965518,
        "end": 1789.78,
        "id": 608,
        "no_speech_prob": 0.0001273100497201085,
        "seek": 176442,
        "start": 1783.26,
        "temperature": 0,
        "text": " And I'm just going to say console.log server is starting.",
        "tokens": [
          51306,
          400,
          286,
          478,
          445,
          516,
          281,
          584,
          11076,
          13,
          4987,
          7154,
          307,
          2891,
          13,
          51632
        ]
      },
      {
        "avg_logprob": -0.25744163567292777,
        "compression_ratio": 1.8275862068965518,
        "end": 1792.5,
        "id": 609,
        "no_speech_prob": 0.0001273100497201085,
        "seek": 176442,
        "start": 1789.78,
        "temperature": 0,
        "text": " And I'm going to say node server.",
        "tokens": [
          51632,
          400,
          286,
          478,
          516,
          281,
          584,
          9984,
          7154,
          13,
          51768
        ]
      },
      {
        "avg_logprob": -0.25744163567292777,
        "compression_ratio": 1.8275862068965518,
        "end": 1793.66,
        "id": 610,
        "no_speech_prob": 0.0001273100497201085,
        "seek": 176442,
        "start": 1792.5,
        "temperature": 0,
        "text": " Server is starting.",
        "tokens": [
          51768,
          25684,
          307,
          2891,
          13,
          51826
        ]
      },
      {
        "avg_logprob": -0.25744163567292777,
        "compression_ratio": 1.8275862068965518,
        "end": 1794.18,
        "id": 611,
        "no_speech_prob": 0.0001273100497201085,
        "seek": 176442,
        "start": 1793.66,
        "temperature": 0,
        "text": " Great.",
        "tokens": [
          51826,
          3769,
          13,
          51852
        ]
      },
      {
        "avg_logprob": -0.23657613152625576,
        "compression_ratio": 1.77491961414791,
        "end": 1797.38,
        "id": 612,
        "no_speech_prob": 0.00020342404604889452,
        "seek": 179418,
        "start": 1794.42,
        "temperature": 0,
        "text": " So a node program is just like a program",
        "tokens": [
          50376,
          407,
          257,
          9984,
          1461,
          307,
          445,
          411,
          257,
          1461,
          50524
        ]
      },
      {
        "avg_logprob": -0.23657613152625576,
        "compression_ratio": 1.77491961414791,
        "end": 1800.0600000000002,
        "id": 613,
        "no_speech_prob": 0.00020342404604889452,
        "seek": 179418,
        "start": 1797.38,
        "temperature": 0,
        "text": " that's written in JavaScript that just runs on your computer.",
        "tokens": [
          50524,
          300,
          311,
          3720,
          294,
          15778,
          300,
          445,
          6676,
          322,
          428,
          3820,
          13,
          50658
        ]
      },
      {
        "avg_logprob": -0.23657613152625576,
        "compression_ratio": 1.77491961414791,
        "end": 1802.98,
        "id": 614,
        "no_speech_prob": 0.00020342404604889452,
        "seek": 179418,
        "start": 1800.0600000000002,
        "temperature": 0,
        "text": " And it runs without graphics, without a window.",
        "tokens": [
          50658,
          400,
          309,
          6676,
          1553,
          11837,
          11,
          1553,
          257,
          4910,
          13,
          50804
        ]
      },
      {
        "avg_logprob": -0.23657613152625576,
        "compression_ratio": 1.77491961414791,
        "end": 1805.94,
        "id": 615,
        "no_speech_prob": 0.00020342404604889452,
        "seek": 179418,
        "start": 1802.98,
        "temperature": 0,
        "text": " And actually, there's a lot of stuff you can do with node.",
        "tokens": [
          50804,
          400,
          767,
          11,
          456,
          311,
          257,
          688,
          295,
          1507,
          291,
          393,
          360,
          365,
          9984,
          13,
          50952
        ]
      },
      {
        "avg_logprob": -0.23657613152625576,
        "compression_ratio": 1.77491961414791,
        "end": 1809.94,
        "id": 616,
        "no_speech_prob": 0.00020342404604889452,
        "seek": 179418,
        "start": 1805.94,
        "temperature": 0,
        "text": " I mean, I should probably really learn Python one of these days.",
        "tokens": [
          50952,
          286,
          914,
          11,
          286,
          820,
          1391,
          534,
          1466,
          15329,
          472,
          295,
          613,
          1708,
          13,
          51152
        ]
      },
      {
        "avg_logprob": -0.23657613152625576,
        "compression_ratio": 1.77491961414791,
        "end": 1812.26,
        "id": 617,
        "no_speech_prob": 0.00020342404604889452,
        "seek": 179418,
        "start": 1809.94,
        "temperature": 0,
        "text": " But I use node a lot to do a lot of batch processes",
        "tokens": [
          51152,
          583,
          286,
          764,
          9984,
          257,
          688,
          281,
          360,
          257,
          688,
          295,
          15245,
          7555,
          51268
        ]
      },
      {
        "avg_logprob": -0.23657613152625576,
        "compression_ratio": 1.77491961414791,
        "end": 1812.8600000000001,
        "id": 618,
        "no_speech_prob": 0.00020342404604889452,
        "seek": 179418,
        "start": 1812.26,
        "temperature": 0,
        "text": " on my computer.",
        "tokens": [
          51268,
          322,
          452,
          3820,
          13,
          51298
        ]
      },
      {
        "avg_logprob": -0.23657613152625576,
        "compression_ratio": 1.77491961414791,
        "end": 1814.98,
        "id": 619,
        "no_speech_prob": 0.00020342404604889452,
        "seek": 179418,
        "start": 1812.8600000000001,
        "temperature": 0,
        "text": " Like, oh, I could just write a little node program",
        "tokens": [
          51298,
          1743,
          11,
          1954,
          11,
          286,
          727,
          445,
          2464,
          257,
          707,
          9984,
          1461,
          51404
        ]
      },
      {
        "avg_logprob": -0.23657613152625576,
        "compression_ratio": 1.77491961414791,
        "end": 1816.66,
        "id": 620,
        "no_speech_prob": 0.00020342404604889452,
        "seek": 179418,
        "start": 1814.98,
        "temperature": 0,
        "text": " to rename a whole directory of files.",
        "tokens": [
          51404,
          281,
          36741,
          257,
          1379,
          21120,
          295,
          7098,
          13,
          51488
        ]
      },
      {
        "avg_logprob": -0.23657613152625576,
        "compression_ratio": 1.77491961414791,
        "end": 1820.0600000000002,
        "id": 621,
        "no_speech_prob": 0.00020342404604889452,
        "seek": 179418,
        "start": 1816.66,
        "temperature": 0,
        "text": " Or I can make a request to some other API",
        "tokens": [
          51488,
          1610,
          286,
          393,
          652,
          257,
          5308,
          281,
          512,
          661,
          9362,
          51658
        ]
      },
      {
        "avg_logprob": -0.23657613152625576,
        "compression_ratio": 1.77491961414791,
        "end": 1821.5800000000002,
        "id": 622,
        "no_speech_prob": 0.00020342404604889452,
        "seek": 179418,
        "start": 1820.0600000000002,
        "temperature": 0,
        "text": " and download a whole bunch of things.",
        "tokens": [
          51658,
          293,
          5484,
          257,
          1379,
          3840,
          295,
          721,
          13,
          51734
        ]
      },
      {
        "avg_logprob": -0.23657613152625576,
        "compression_ratio": 1.77491961414791,
        "end": 1823.26,
        "id": 623,
        "no_speech_prob": 0.00020342404604889452,
        "seek": 179418,
        "start": 1821.5800000000002,
        "temperature": 0,
        "text": " So node is something that you could just",
        "tokens": [
          51734,
          407,
          9984,
          307,
          746,
          300,
          291,
          727,
          445,
          51818
        ]
      },
      {
        "avg_logprob": -0.2051956205439747,
        "compression_ratio": 1.6631205673758864,
        "end": 1824.86,
        "id": 624,
        "no_speech_prob": 0.00003480802843114361,
        "seek": 182326,
        "start": 1823.26,
        "temperature": 0,
        "text": " forget about web servers and APIs.",
        "tokens": [
          50364,
          2870,
          466,
          3670,
          15909,
          293,
          21445,
          13,
          50444
        ]
      },
      {
        "avg_logprob": -0.2051956205439747,
        "compression_ratio": 1.6631205673758864,
        "end": 1826.82,
        "id": 625,
        "no_speech_prob": 0.00003480802843114361,
        "seek": 182326,
        "start": 1824.86,
        "temperature": 0,
        "text": " You could just use as a little programming tool",
        "tokens": [
          50444,
          509,
          727,
          445,
          764,
          382,
          257,
          707,
          9410,
          2290,
          50542
        ]
      },
      {
        "avg_logprob": -0.2051956205439747,
        "compression_ratio": 1.6631205673758864,
        "end": 1828.86,
        "id": 626,
        "no_speech_prob": 0.00003480802843114361,
        "seek": 182326,
        "start": 1826.82,
        "temperature": 0,
        "text": " to do a bunch of things for yourself",
        "tokens": [
          50542,
          281,
          360,
          257,
          3840,
          295,
          721,
          337,
          1803,
          50644
        ]
      },
      {
        "avg_logprob": -0.2051956205439747,
        "compression_ratio": 1.6631205673758864,
        "end": 1830.46,
        "id": 627,
        "no_speech_prob": 0.00003480802843114361,
        "seek": 182326,
        "start": 1828.86,
        "temperature": 0,
        "text": " on your computer through code.",
        "tokens": [
          50644,
          322,
          428,
          3820,
          807,
          3089,
          13,
          50724
        ]
      },
      {
        "avg_logprob": -0.2051956205439747,
        "compression_ratio": 1.6631205673758864,
        "end": 1832.7,
        "id": 628,
        "no_speech_prob": 0.00003480802843114361,
        "seek": 182326,
        "start": 1830.46,
        "temperature": 0,
        "text": " But what I want to do, the first thing I want to do",
        "tokens": [
          50724,
          583,
          437,
          286,
          528,
          281,
          360,
          11,
          264,
          700,
          551,
          286,
          528,
          281,
          360,
          50836
        ]
      },
      {
        "avg_logprob": -0.2051956205439747,
        "compression_ratio": 1.6631205673758864,
        "end": 1834.62,
        "id": 629,
        "no_speech_prob": 0.00003480802843114361,
        "seek": 182326,
        "start": 1832.7,
        "temperature": 0,
        "text": " is create a web server.",
        "tokens": [
          50836,
          307,
          1884,
          257,
          3670,
          7154,
          13,
          50932
        ]
      },
      {
        "avg_logprob": -0.2051956205439747,
        "compression_ratio": 1.6631205673758864,
        "end": 1836.06,
        "id": 630,
        "no_speech_prob": 0.00003480802843114361,
        "seek": 182326,
        "start": 1834.62,
        "temperature": 0,
        "text": " And by web server, I mean something",
        "tokens": [
          50932,
          400,
          538,
          3670,
          7154,
          11,
          286,
          914,
          746,
          51004
        ]
      },
      {
        "avg_logprob": -0.2051956205439747,
        "compression_ratio": 1.6631205673758864,
        "end": 1840.18,
        "id": 631,
        "no_speech_prob": 0.00003480802843114361,
        "seek": 182326,
        "start": 1836.06,
        "temperature": 0,
        "text": " that opens up a port and allows browsers to connect to it.",
        "tokens": [
          51004,
          300,
          9870,
          493,
          257,
          2436,
          293,
          4045,
          36069,
          281,
          1745,
          281,
          309,
          13,
          51210
        ]
      },
      {
        "avg_logprob": -0.2051956205439747,
        "compression_ratio": 1.6631205673758864,
        "end": 1841.98,
        "id": 632,
        "no_speech_prob": 0.00003480802843114361,
        "seek": 182326,
        "start": 1840.18,
        "temperature": 0,
        "text": " And this is very easy with Express.",
        "tokens": [
          51210,
          400,
          341,
          307,
          588,
          1858,
          365,
          20212,
          13,
          51300
        ]
      },
      {
        "avg_logprob": -0.2051956205439747,
        "compression_ratio": 1.6631205673758864,
        "end": 1844.9,
        "id": 633,
        "no_speech_prob": 0.00003480802843114361,
        "seek": 182326,
        "start": 1841.98,
        "temperature": 0,
        "text": " Now, I have most of this documented on this page.",
        "tokens": [
          51300,
          823,
          11,
          286,
          362,
          881,
          295,
          341,
          23007,
          322,
          341,
          3028,
          13,
          51446
        ]
      },
      {
        "avg_logprob": -0.2051956205439747,
        "compression_ratio": 1.6631205673758864,
        "end": 1847.18,
        "id": 634,
        "no_speech_prob": 0.00003480802843114361,
        "seek": 182326,
        "start": 1844.9,
        "temperature": 0,
        "text": " So I'm going to go and copy paste",
        "tokens": [
          51446,
          407,
          286,
          478,
          516,
          281,
          352,
          293,
          5055,
          9163,
          51560
        ]
      },
      {
        "avg_logprob": -0.2051956205439747,
        "compression_ratio": 1.6631205673758864,
        "end": 1849.06,
        "id": 635,
        "no_speech_prob": 0.00003480802843114361,
        "seek": 182326,
        "start": 1847.18,
        "temperature": 0,
        "text": " some of the pieces of code.",
        "tokens": [
          51560,
          512,
          295,
          264,
          3755,
          295,
          3089,
          13,
          51654
        ]
      },
      {
        "avg_logprob": -0.21575438521290555,
        "compression_ratio": 1.8674698795180722,
        "end": 1855.3799999999999,
        "id": 636,
        "no_speech_prob": 0.00018814152281265706,
        "seek": 184906,
        "start": 1849.06,
        "temperature": 0,
        "text": " The first thing I need is I need to say var express require",
        "tokens": [
          50364,
          440,
          700,
          551,
          286,
          643,
          307,
          286,
          643,
          281,
          584,
          1374,
          5109,
          3651,
          50680
        ]
      },
      {
        "avg_logprob": -0.21575438521290555,
        "compression_ratio": 1.8674698795180722,
        "end": 1856.1399999999999,
        "id": 637,
        "no_speech_prob": 0.00018814152281265706,
        "seek": 184906,
        "start": 1855.3799999999999,
        "temperature": 0,
        "text": " express.",
        "tokens": [
          50680,
          5109,
          13,
          50718
        ]
      },
      {
        "avg_logprob": -0.21575438521290555,
        "compression_ratio": 1.8674698795180722,
        "end": 1857.94,
        "id": 638,
        "no_speech_prob": 0.00018814152281265706,
        "seek": 184906,
        "start": 1856.1399999999999,
        "temperature": 0,
        "text": " This is like an import statement.",
        "tokens": [
          50718,
          639,
          307,
          411,
          364,
          974,
          5629,
          13,
          50808
        ]
      },
      {
        "avg_logprob": -0.21575438521290555,
        "compression_ratio": 1.8674698795180722,
        "end": 1859.78,
        "id": 639,
        "no_speech_prob": 0.00018814152281265706,
        "seek": 184906,
        "start": 1857.94,
        "temperature": 0,
        "text": " Import the package express.",
        "tokens": [
          50808,
          26391,
          264,
          7372,
          5109,
          13,
          50900
        ]
      },
      {
        "avg_logprob": -0.21575438521290555,
        "compression_ratio": 1.8674698795180722,
        "end": 1861.62,
        "id": 640,
        "no_speech_prob": 0.00018814152281265706,
        "seek": 184906,
        "start": 1859.78,
        "temperature": 0,
        "text": " I want to be able to use express.",
        "tokens": [
          50900,
          286,
          528,
          281,
          312,
          1075,
          281,
          764,
          5109,
          13,
          50992
        ]
      },
      {
        "avg_logprob": -0.21575438521290555,
        "compression_ratio": 1.8674698795180722,
        "end": 1864.62,
        "id": 641,
        "no_speech_prob": 0.00018814152281265706,
        "seek": 184906,
        "start": 1861.62,
        "temperature": 0,
        "text": " Now, the funny thing about this is I get require express.",
        "tokens": [
          50992,
          823,
          11,
          264,
          4074,
          551,
          466,
          341,
          307,
          286,
          483,
          3651,
          5109,
          13,
          51142
        ]
      },
      {
        "avg_logprob": -0.21575438521290555,
        "compression_ratio": 1.8674698795180722,
        "end": 1866.3,
        "id": 642,
        "no_speech_prob": 0.00018814152281265706,
        "seek": 184906,
        "start": 1864.62,
        "temperature": 0,
        "text": " I get this into a variable.",
        "tokens": [
          51142,
          286,
          483,
          341,
          666,
          257,
          7006,
          13,
          51226
        ]
      },
      {
        "avg_logprob": -0.21575438521290555,
        "compression_ratio": 1.8674698795180722,
        "end": 1869.1399999999999,
        "id": 643,
        "no_speech_prob": 0.00018814152281265706,
        "seek": 184906,
        "start": 1866.3,
        "temperature": 0,
        "text": " This whole package is actually a function.",
        "tokens": [
          51226,
          639,
          1379,
          7372,
          307,
          767,
          257,
          2445,
          13,
          51368
        ]
      },
      {
        "avg_logprob": -0.21575438521290555,
        "compression_ratio": 1.8674698795180722,
        "end": 1871.1,
        "id": 644,
        "no_speech_prob": 0.00018814152281265706,
        "seek": 184906,
        "start": 1869.1399999999999,
        "temperature": 0,
        "text": " Express is a reference to a function.",
        "tokens": [
          51368,
          20212,
          307,
          257,
          6408,
          281,
          257,
          2445,
          13,
          51466
        ]
      },
      {
        "avg_logprob": -0.21575438521290555,
        "compression_ratio": 1.8674698795180722,
        "end": 1872.86,
        "id": 645,
        "no_speech_prob": 0.00018814152281265706,
        "seek": 184906,
        "start": 1871.1,
        "temperature": 0,
        "text": " And I can execute that function.",
        "tokens": [
          51466,
          400,
          286,
          393,
          14483,
          300,
          2445,
          13,
          51554
        ]
      },
      {
        "avg_logprob": -0.21575438521290555,
        "compression_ratio": 1.8674698795180722,
        "end": 1875.6599999999999,
        "id": 646,
        "no_speech_prob": 0.00018814152281265706,
        "seek": 184906,
        "start": 1872.86,
        "temperature": 0,
        "text": " And that's what I'm going to do here in this next line of code.",
        "tokens": [
          51554,
          400,
          300,
          311,
          437,
          286,
          478,
          516,
          281,
          360,
          510,
          294,
          341,
          958,
          1622,
          295,
          3089,
          13,
          51694
        ]
      },
      {
        "avg_logprob": -0.21575438521290555,
        "compression_ratio": 1.8674698795180722,
        "end": 1878.98,
        "id": 647,
        "no_speech_prob": 0.00018814152281265706,
        "seek": 184906,
        "start": 1875.6599999999999,
        "temperature": 0,
        "text": " I'm going to say app equals express.",
        "tokens": [
          51694,
          286,
          478,
          516,
          281,
          584,
          724,
          6915,
          5109,
          13,
          51860
        ]
      },
      {
        "avg_logprob": -0.21388825373863107,
        "compression_ratio": 1.6458333333333333,
        "end": 1880.46,
        "id": 648,
        "no_speech_prob": 0.00007484580419259146,
        "seek": 187898,
        "start": 1879.4,
        "temperature": 0,
        "text": " I execute express.",
        "tokens": [
          50385,
          286,
          14483,
          5109,
          13,
          50438
        ]
      },
      {
        "avg_logprob": -0.21388825373863107,
        "compression_ratio": 1.6458333333333333,
        "end": 1882.22,
        "id": 649,
        "no_speech_prob": 0.00007484580419259146,
        "seek": 187898,
        "start": 1880.46,
        "temperature": 0,
        "text": " And suddenly, I get this web application.",
        "tokens": [
          50438,
          400,
          5800,
          11,
          286,
          483,
          341,
          3670,
          3861,
          13,
          50526
        ]
      },
      {
        "avg_logprob": -0.21388825373863107,
        "compression_ratio": 1.6458333333333333,
        "end": 1884.82,
        "id": 650,
        "no_speech_prob": 0.00007484580419259146,
        "seek": 187898,
        "start": 1882.22,
        "temperature": 0,
        "text": " This is what I mean about how great it is to use express.",
        "tokens": [
          50526,
          639,
          307,
          437,
          286,
          914,
          466,
          577,
          869,
          309,
          307,
          281,
          764,
          5109,
          13,
          50656
        ]
      },
      {
        "avg_logprob": -0.21388825373863107,
        "compression_ratio": 1.6458333333333333,
        "end": 1886.78,
        "id": 651,
        "no_speech_prob": 0.00007484580419259146,
        "seek": 187898,
        "start": 1884.82,
        "temperature": 0,
        "text": " It's doing all this stuff behind the scenes.",
        "tokens": [
          50656,
          467,
          311,
          884,
          439,
          341,
          1507,
          2261,
          264,
          8026,
          13,
          50754
        ]
      },
      {
        "avg_logprob": -0.21388825373863107,
        "compression_ratio": 1.6458333333333333,
        "end": 1888.58,
        "id": 652,
        "no_speech_prob": 0.00007484580419259146,
        "seek": 187898,
        "start": 1886.78,
        "temperature": 0,
        "text": " And the first thing I can do is I say, hey,",
        "tokens": [
          50754,
          400,
          264,
          700,
          551,
          286,
          393,
          360,
          307,
          286,
          584,
          11,
          4177,
          11,
          50844
        ]
      },
      {
        "avg_logprob": -0.21388825373863107,
        "compression_ratio": 1.6458333333333333,
        "end": 1891.26,
        "id": 653,
        "no_speech_prob": 0.00007484580419259146,
        "seek": 187898,
        "start": 1888.58,
        "temperature": 0,
        "text": " listen for incoming connections.",
        "tokens": [
          50844,
          2140,
          337,
          22341,
          9271,
          13,
          50978
        ]
      },
      {
        "avg_logprob": -0.21388825373863107,
        "compression_ratio": 1.6458333333333333,
        "end": 1898.06,
        "id": 654,
        "no_speech_prob": 0.00007484580419259146,
        "seek": 187898,
        "start": 1891.26,
        "temperature": 0,
        "text": " So I'm going to say server equals app.listen port 3000.",
        "tokens": [
          50978,
          407,
          286,
          478,
          516,
          281,
          584,
          7154,
          6915,
          724,
          13,
          75,
          4821,
          2436,
          20984,
          13,
          51318
        ]
      },
      {
        "avg_logprob": -0.21388825373863107,
        "compression_ratio": 1.6458333333333333,
        "end": 1901.7,
        "id": 655,
        "no_speech_prob": 0.00007484580419259146,
        "seek": 187898,
        "start": 1898.06,
        "temperature": 0,
        "text": " Now, there are various default ports that servers will use.",
        "tokens": [
          51318,
          823,
          11,
          456,
          366,
          3683,
          7576,
          18160,
          300,
          15909,
          486,
          764,
          13,
          51500
        ]
      },
      {
        "avg_logprob": -0.21388825373863107,
        "compression_ratio": 1.6458333333333333,
        "end": 1904.02,
        "id": 656,
        "no_speech_prob": 0.00007484580419259146,
        "seek": 187898,
        "start": 1901.7,
        "temperature": 0,
        "text": " But since I'm just doing all of my testing,",
        "tokens": [
          51500,
          583,
          1670,
          286,
          478,
          445,
          884,
          439,
          295,
          452,
          4997,
          11,
          51616
        ]
      },
      {
        "avg_logprob": -0.21388825373863107,
        "compression_ratio": 1.6458333333333333,
        "end": 1905.8600000000001,
        "id": 657,
        "no_speech_prob": 0.00007484580419259146,
        "seek": 187898,
        "start": 1904.02,
        "temperature": 0,
        "text": " this diagram that I have over here",
        "tokens": [
          51616,
          341,
          10686,
          300,
          286,
          362,
          670,
          510,
          51708
        ]
      },
      {
        "avg_logprob": -0.21388825373863107,
        "compression_ratio": 1.6458333333333333,
        "end": 1908.3,
        "id": 658,
        "no_speech_prob": 0.00007484580419259146,
        "seek": 187898,
        "start": 1905.8600000000001,
        "temperature": 0,
        "text": " of this idea of a server and a client,",
        "tokens": [
          51708,
          295,
          341,
          1558,
          295,
          257,
          7154,
          293,
          257,
          6423,
          11,
          51830
        ]
      },
      {
        "avg_logprob": -0.2513772409858433,
        "compression_ratio": 1.6655290102389078,
        "end": 1910.78,
        "id": 659,
        "no_speech_prob": 0.00004198612805339508,
        "seek": 190830,
        "start": 1908.3,
        "temperature": 0,
        "text": " right now, all of this is happening on one computer.",
        "tokens": [
          50364,
          558,
          586,
          11,
          439,
          295,
          341,
          307,
          2737,
          322,
          472,
          3820,
          13,
          50488
        ]
      },
      {
        "avg_logprob": -0.2513772409858433,
        "compression_ratio": 1.6655290102389078,
        "end": 1912.02,
        "id": 660,
        "no_speech_prob": 0.00004198612805339508,
        "seek": 190830,
        "start": 1910.78,
        "temperature": 0,
        "text": " The server is on the computer.",
        "tokens": [
          50488,
          440,
          7154,
          307,
          322,
          264,
          3820,
          13,
          50550
        ]
      },
      {
        "avg_logprob": -0.2513772409858433,
        "compression_ratio": 1.6655290102389078,
        "end": 1913.86,
        "id": 661,
        "no_speech_prob": 0.00004198612805339508,
        "seek": 190830,
        "start": 1912.02,
        "temperature": 0,
        "text": " The client is that computer itself.",
        "tokens": [
          50550,
          440,
          6423,
          307,
          300,
          3820,
          2564,
          13,
          50642
        ]
      },
      {
        "avg_logprob": -0.2513772409858433,
        "compression_ratio": 1.6655290102389078,
        "end": 1916.22,
        "id": 662,
        "no_speech_prob": 0.00004198612805339508,
        "seek": 190830,
        "start": 1913.86,
        "temperature": 0,
        "text": " And that might actually, for a lot of projects, be all you",
        "tokens": [
          50642,
          400,
          300,
          1062,
          767,
          11,
          337,
          257,
          688,
          295,
          4455,
          11,
          312,
          439,
          291,
          50760
        ]
      },
      {
        "avg_logprob": -0.2513772409858433,
        "compression_ratio": 1.6655290102389078,
        "end": 1916.7,
        "id": 663,
        "no_speech_prob": 0.00004198612805339508,
        "seek": 190830,
        "start": 1916.22,
        "temperature": 0,
        "text": " need.",
        "tokens": [
          50760,
          643,
          13,
          50784
        ]
      },
      {
        "avg_logprob": -0.2513772409858433,
        "compression_ratio": 1.6655290102389078,
        "end": 1917.98,
        "id": 664,
        "no_speech_prob": 0.00004198612805339508,
        "seek": 190830,
        "start": 1916.7,
        "temperature": 0,
        "text": " But at some point, you also might",
        "tokens": [
          50784,
          583,
          412,
          512,
          935,
          11,
          291,
          611,
          1062,
          50848
        ]
      },
      {
        "avg_logprob": -0.2513772409858433,
        "compression_ratio": 1.6655290102389078,
        "end": 1919.82,
        "id": 665,
        "no_speech_prob": 0.00004198612805339508,
        "seek": 190830,
        "start": 1917.98,
        "temperature": 0,
        "text": " want to deploy your server somewhere else",
        "tokens": [
          50848,
          528,
          281,
          7274,
          428,
          7154,
          4079,
          1646,
          50940
        ]
      },
      {
        "avg_logprob": -0.2513772409858433,
        "compression_ratio": 1.6655290102389078,
        "end": 1921.54,
        "id": 666,
        "no_speech_prob": 0.00004198612805339508,
        "seek": 190830,
        "start": 1919.82,
        "temperature": 0,
        "text": " so that other people could connect to it.",
        "tokens": [
          50940,
          370,
          300,
          661,
          561,
          727,
          1745,
          281,
          309,
          13,
          51026
        ]
      },
      {
        "avg_logprob": -0.2513772409858433,
        "compression_ratio": 1.6655290102389078,
        "end": 1924.1,
        "id": 667,
        "no_speech_prob": 0.00004198612805339508,
        "seek": 190830,
        "start": 1921.54,
        "temperature": 0,
        "text": " And I'll have to make some videos about that as well.",
        "tokens": [
          51026,
          400,
          286,
          603,
          362,
          281,
          652,
          512,
          2145,
          466,
          300,
          382,
          731,
          13,
          51154
        ]
      },
      {
        "avg_logprob": -0.2513772409858433,
        "compression_ratio": 1.6655290102389078,
        "end": 1929.4199999999998,
        "id": 668,
        "no_speech_prob": 0.00004198612805339508,
        "seek": 190830,
        "start": 1924.1,
        "temperature": 0,
        "text": " OK, so now that I'm listening at port 3000,",
        "tokens": [
          51154,
          2264,
          11,
          370,
          586,
          300,
          286,
          478,
          4764,
          412,
          2436,
          20984,
          11,
          51420
        ]
      },
      {
        "avg_logprob": -0.2513772409858433,
        "compression_ratio": 1.6655290102389078,
        "end": 1931.5,
        "id": 669,
        "no_speech_prob": 0.00004198612805339508,
        "seek": 190830,
        "start": 1929.4199999999998,
        "temperature": 0,
        "text": " I can do a few different things.",
        "tokens": [
          51420,
          286,
          393,
          360,
          257,
          1326,
          819,
          721,
          13,
          51524
        ]
      },
      {
        "avg_logprob": -0.2513772409858433,
        "compression_ratio": 1.6655290102389078,
        "end": 1932.86,
        "id": 670,
        "no_speech_prob": 0.00004198612805339508,
        "seek": 190830,
        "start": 1931.5,
        "temperature": 0,
        "text": " So one thing, let's just run this.",
        "tokens": [
          51524,
          407,
          472,
          551,
          11,
          718,
          311,
          445,
          1190,
          341,
          13,
          51592
        ]
      },
      {
        "avg_logprob": -0.2513772409858433,
        "compression_ratio": 1.6655290102389078,
        "end": 1937.54,
        "id": 671,
        "no_speech_prob": 0.00004198612805339508,
        "seek": 190830,
        "start": 1936.3,
        "temperature": 0,
        "text": " Server is starting.",
        "tokens": [
          51764,
          25684,
          307,
          2891,
          13,
          51826
        ]
      },
      {
        "avg_logprob": -0.2494197014050606,
        "compression_ratio": 1.8754325259515572,
        "end": 1939.1,
        "id": 672,
        "no_speech_prob": 0.00006302723340922967,
        "seek": 193754,
        "start": 1937.54,
        "temperature": 0,
        "text": " And you know what would be nice?",
        "tokens": [
          50364,
          400,
          291,
          458,
          437,
          576,
          312,
          1481,
          30,
          50442
        ]
      },
      {
        "avg_logprob": -0.2494197014050606,
        "compression_ratio": 1.8754325259515572,
        "end": 1941.7,
        "id": 673,
        "no_speech_prob": 0.00006302723340922967,
        "seek": 193754,
        "start": 1939.1,
        "temperature": 0,
        "text": " It would be nice to add a little callback here.",
        "tokens": [
          50442,
          467,
          576,
          312,
          1481,
          281,
          909,
          257,
          707,
          818,
          3207,
          510,
          13,
          50572
        ]
      },
      {
        "avg_logprob": -0.2494197014050606,
        "compression_ratio": 1.8754325259515572,
        "end": 1943.22,
        "id": 674,
        "no_speech_prob": 0.00006302723340922967,
        "seek": 193754,
        "start": 1941.7,
        "temperature": 0,
        "text": " So I'm just going to write.",
        "tokens": [
          50572,
          407,
          286,
          478,
          445,
          516,
          281,
          2464,
          13,
          50648
        ]
      },
      {
        "avg_logprob": -0.2494197014050606,
        "compression_ratio": 1.8754325259515572,
        "end": 1946.3,
        "id": 675,
        "no_speech_prob": 0.00006302723340922967,
        "seek": 193754,
        "start": 1943.22,
        "temperature": 0,
        "text": " I'm going to add something called function listening.",
        "tokens": [
          50648,
          286,
          478,
          516,
          281,
          909,
          746,
          1219,
          2445,
          4764,
          13,
          50802
        ]
      },
      {
        "avg_logprob": -0.2494197014050606,
        "compression_ratio": 1.8754325259515572,
        "end": 1951.62,
        "id": 676,
        "no_speech_prob": 0.00006302723340922967,
        "seek": 193754,
        "start": 1946.3,
        "temperature": 0,
        "text": " And I'm going to say console.log listening.",
        "tokens": [
          50802,
          400,
          286,
          478,
          516,
          281,
          584,
          11076,
          13,
          4987,
          4764,
          13,
          51068
        ]
      },
      {
        "avg_logprob": -0.2494197014050606,
        "compression_ratio": 1.8754325259515572,
        "end": 1954.58,
        "id": 677,
        "no_speech_prob": 0.00006302723340922967,
        "seek": 193754,
        "start": 1951.62,
        "temperature": 0,
        "text": " So I just wrote a little callback so that,",
        "tokens": [
          51068,
          407,
          286,
          445,
          4114,
          257,
          707,
          818,
          3207,
          370,
          300,
          11,
          51216
        ]
      },
      {
        "avg_logprob": -0.2494197014050606,
        "compression_ratio": 1.8754325259515572,
        "end": 1957.26,
        "id": 678,
        "no_speech_prob": 0.00006302723340922967,
        "seek": 193754,
        "start": 1954.58,
        "temperature": 0,
        "text": " and actually, the reason I'm adding this into the code",
        "tokens": [
          51216,
          293,
          767,
          11,
          264,
          1778,
          286,
          478,
          5127,
          341,
          666,
          264,
          3089,
          51350
        ]
      },
      {
        "avg_logprob": -0.2494197014050606,
        "compression_ratio": 1.8754325259515572,
        "end": 1959.1399999999999,
        "id": 679,
        "no_speech_prob": 0.00006302723340922967,
        "seek": 193754,
        "start": 1957.26,
        "temperature": 0,
        "text": " is there are a lot of things you can do here.",
        "tokens": [
          51350,
          307,
          456,
          366,
          257,
          688,
          295,
          721,
          291,
          393,
          360,
          510,
          13,
          51444
        ]
      },
      {
        "avg_logprob": -0.2494197014050606,
        "compression_ratio": 1.8754325259515572,
        "end": 1961.86,
        "id": 680,
        "no_speech_prob": 0.00006302723340922967,
        "seek": 193754,
        "start": 1959.1399999999999,
        "temperature": 0,
        "text": " You can get the host address and the port and various things.",
        "tokens": [
          51444,
          509,
          393,
          483,
          264,
          3975,
          2985,
          293,
          264,
          2436,
          293,
          3683,
          721,
          13,
          51580
        ]
      },
      {
        "avg_logprob": -0.2494197014050606,
        "compression_ratio": 1.8754325259515572,
        "end": 1963.5,
        "id": 681,
        "no_speech_prob": 0.00006302723340922967,
        "seek": 193754,
        "start": 1961.86,
        "temperature": 0,
        "text": " But most of this stuff is unnecessary for what",
        "tokens": [
          51580,
          583,
          881,
          295,
          341,
          1507,
          307,
          19350,
          337,
          437,
          51662
        ]
      },
      {
        "avg_logprob": -0.2494197014050606,
        "compression_ratio": 1.8754325259515572,
        "end": 1964.1,
        "id": 682,
        "no_speech_prob": 0.00006302723340922967,
        "seek": 193754,
        "start": 1963.5,
        "temperature": 0,
        "text": " we want to do.",
        "tokens": [
          51662,
          321,
          528,
          281,
          360,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.2494197014050606,
        "compression_ratio": 1.8754325259515572,
        "end": 1965.78,
        "id": 683,
        "no_speech_prob": 0.00006302723340922967,
        "seek": 193754,
        "start": 1964.1,
        "temperature": 0,
        "text": " But I want to at least sort of see this callback",
        "tokens": [
          51692,
          583,
          286,
          528,
          281,
          412,
          1935,
          1333,
          295,
          536,
          341,
          818,
          3207,
          51776
        ]
      },
      {
        "avg_logprob": -0.2494197014050606,
        "compression_ratio": 1.8754325259515572,
        "end": 1966.78,
        "id": 684,
        "no_speech_prob": 0.00006302723340922967,
        "seek": 193754,
        "start": 1965.78,
        "temperature": 0,
        "text": " that it's working.",
        "tokens": [
          51776,
          300,
          309,
          311,
          1364,
          13,
          51826
        ]
      },
      {
        "avg_logprob": -0.22422702706975045,
        "compression_ratio": 1.6539923954372624,
        "end": 1969.54,
        "id": 685,
        "no_speech_prob": 0.00006922110333107412,
        "seek": 196678,
        "start": 1966.78,
        "temperature": 0,
        "text": " So I'm going to run this again.",
        "tokens": [
          50364,
          407,
          286,
          478,
          516,
          281,
          1190,
          341,
          797,
          13,
          50502
        ]
      },
      {
        "avg_logprob": -0.22422702706975045,
        "compression_ratio": 1.6539923954372624,
        "end": 1971.46,
        "id": 686,
        "no_speech_prob": 0.00006922110333107412,
        "seek": 196678,
        "start": 1969.54,
        "temperature": 0,
        "text": " Server is starting, listening.",
        "tokens": [
          50502,
          25684,
          307,
          2891,
          11,
          4764,
          13,
          50598
        ]
      },
      {
        "avg_logprob": -0.22422702706975045,
        "compression_ratio": 1.6539923954372624,
        "end": 1973.54,
        "id": 687,
        "no_speech_prob": 0.00006922110333107412,
        "seek": 196678,
        "start": 1971.46,
        "temperature": 0,
        "text": " OK, here we go.",
        "tokens": [
          50598,
          2264,
          11,
          510,
          321,
          352,
          13,
          50702
        ]
      },
      {
        "avg_logprob": -0.22422702706975045,
        "compression_ratio": 1.6539923954372624,
        "end": 1977.98,
        "id": 688,
        "no_speech_prob": 0.00006922110333107412,
        "seek": 196678,
        "start": 1973.54,
        "temperature": 0,
        "text": " Now, so let's go to localhost 3000.",
        "tokens": [
          50702,
          823,
          11,
          370,
          718,
          311,
          352,
          281,
          2654,
          6037,
          20984,
          13,
          50924
        ]
      },
      {
        "avg_logprob": -0.22422702706975045,
        "compression_ratio": 1.6539923954372624,
        "end": 1979.26,
        "id": 689,
        "no_speech_prob": 0.00006922110333107412,
        "seek": 196678,
        "start": 1977.98,
        "temperature": 0,
        "text": " This is where my server is.",
        "tokens": [
          50924,
          639,
          307,
          689,
          452,
          7154,
          307,
          13,
          50988
        ]
      },
      {
        "avg_logprob": -0.22422702706975045,
        "compression_ratio": 1.6539923954372624,
        "end": 1981.26,
        "id": 690,
        "no_speech_prob": 0.00006922110333107412,
        "seek": 196678,
        "start": 1979.26,
        "temperature": 0,
        "text": " I'm going to look at the little web page I made.",
        "tokens": [
          50988,
          286,
          478,
          516,
          281,
          574,
          412,
          264,
          707,
          3670,
          3028,
          286,
          1027,
          13,
          51088
        ]
      },
      {
        "avg_logprob": -0.22422702706975045,
        "compression_ratio": 1.6539923954372624,
        "end": 1982.8999999999999,
        "id": 691,
        "no_speech_prob": 0.00006922110333107412,
        "seek": 196678,
        "start": 1981.26,
        "temperature": 0,
        "text": " Oh, cannot get anything.",
        "tokens": [
          51088,
          876,
          11,
          2644,
          483,
          1340,
          13,
          51170
        ]
      },
      {
        "avg_logprob": -0.22422702706975045,
        "compression_ratio": 1.6539923954372624,
        "end": 1984.46,
        "id": 692,
        "no_speech_prob": 0.00006922110333107412,
        "seek": 196678,
        "start": 1982.8999999999999,
        "temperature": 0,
        "text": " So there's nothing there.",
        "tokens": [
          51170,
          407,
          456,
          311,
          1825,
          456,
          13,
          51248
        ]
      },
      {
        "avg_logprob": -0.22422702706975045,
        "compression_ratio": 1.6539923954372624,
        "end": 1986.1,
        "id": 693,
        "no_speech_prob": 0.00006922110333107412,
        "seek": 196678,
        "start": 1984.46,
        "temperature": 0,
        "text": " But you can see that this is working,",
        "tokens": [
          51248,
          583,
          291,
          393,
          536,
          300,
          341,
          307,
          1364,
          11,
          51330
        ]
      },
      {
        "avg_logprob": -0.22422702706975045,
        "compression_ratio": 1.6539923954372624,
        "end": 1988.26,
        "id": 694,
        "no_speech_prob": 0.00006922110333107412,
        "seek": 196678,
        "start": 1986.1,
        "temperature": 0,
        "text": " because at least I got the message.",
        "tokens": [
          51330,
          570,
          412,
          1935,
          286,
          658,
          264,
          3636,
          13,
          51438
        ]
      },
      {
        "avg_logprob": -0.22422702706975045,
        "compression_ratio": 1.6539923954372624,
        "end": 1991.58,
        "id": 695,
        "no_speech_prob": 0.00006922110333107412,
        "seek": 196678,
        "start": 1988.26,
        "temperature": 0,
        "text": " I'm listening, but I don't have anything to give you.",
        "tokens": [
          51438,
          286,
          478,
          4764,
          11,
          457,
          286,
          500,
          380,
          362,
          1340,
          281,
          976,
          291,
          13,
          51604
        ]
      },
      {
        "avg_logprob": -0.22422702706975045,
        "compression_ratio": 1.6539923954372624,
        "end": 1995.3,
        "id": 696,
        "no_speech_prob": 0.00006922110333107412,
        "seek": 196678,
        "start": 1991.58,
        "temperature": 0,
        "text": " Me, the web browser, right now made a get request",
        "tokens": [
          51604,
          1923,
          11,
          264,
          3670,
          11185,
          11,
          558,
          586,
          1027,
          257,
          483,
          5308,
          51790
        ]
      },
      {
        "avg_logprob": -0.22422702706975045,
        "compression_ratio": 1.6539923954372624,
        "end": 1996.42,
        "id": 697,
        "no_speech_prob": 0.00006922110333107412,
        "seek": 196678,
        "start": 1995.3,
        "temperature": 0,
        "text": " to the server.",
        "tokens": [
          51790,
          281,
          264,
          7154,
          13,
          51846
        ]
      },
      {
        "avg_logprob": -0.25634552001953126,
        "compression_ratio": 1.7509293680297398,
        "end": 1998.6200000000001,
        "id": 698,
        "no_speech_prob": 0.000008939675353758503,
        "seek": 199642,
        "start": 1996.54,
        "temperature": 0,
        "text": " And this is kind of an important concept.",
        "tokens": [
          50370,
          400,
          341,
          307,
          733,
          295,
          364,
          1021,
          3410,
          13,
          50474
        ]
      },
      {
        "avg_logprob": -0.25634552001953126,
        "compression_ratio": 1.7509293680297398,
        "end": 2000.5,
        "id": 699,
        "no_speech_prob": 0.000008939675353758503,
        "seek": 199642,
        "start": 1998.6200000000001,
        "temperature": 0,
        "text": " So one of the first things I might do,",
        "tokens": [
          50474,
          407,
          472,
          295,
          264,
          700,
          721,
          286,
          1062,
          360,
          11,
          50568
        ]
      },
      {
        "avg_logprob": -0.25634552001953126,
        "compression_ratio": 1.7509293680297398,
        "end": 2003.18,
        "id": 700,
        "no_speech_prob": 0.000008939675353758503,
        "seek": 199642,
        "start": 2000.5,
        "temperature": 0,
        "text": " although this is a little bit unnecessary for this idea",
        "tokens": [
          50568,
          4878,
          341,
          307,
          257,
          707,
          857,
          19350,
          337,
          341,
          1558,
          50702
        ]
      },
      {
        "avg_logprob": -0.25634552001953126,
        "compression_ratio": 1.7509293680297398,
        "end": 2006.22,
        "id": 701,
        "no_speech_prob": 0.000008939675353758503,
        "seek": 199642,
        "start": 2003.18,
        "temperature": 0,
        "text": " of an API, but it's kind of worth exploring right now",
        "tokens": [
          50702,
          295,
          364,
          9362,
          11,
          457,
          309,
          311,
          733,
          295,
          3163,
          12736,
          558,
          586,
          50854
        ]
      },
      {
        "avg_logprob": -0.25634552001953126,
        "compression_ratio": 1.7509293680297398,
        "end": 2008.1000000000001,
        "id": 702,
        "no_speech_prob": 0.000008939675353758503,
        "seek": 199642,
        "start": 2006.22,
        "temperature": 0,
        "text": " that we're going through this Express stuff,",
        "tokens": [
          50854,
          300,
          321,
          434,
          516,
          807,
          341,
          20212,
          1507,
          11,
          50948
        ]
      },
      {
        "avg_logprob": -0.25634552001953126,
        "compression_ratio": 1.7509293680297398,
        "end": 2015.9,
        "id": 703,
        "no_speech_prob": 0.000008939675353758503,
        "seek": 199642,
        "start": 2008.1000000000001,
        "temperature": 0,
        "text": " is I can use an aspect of Express to host static files.",
        "tokens": [
          50948,
          307,
          286,
          393,
          764,
          364,
          4171,
          295,
          20212,
          281,
          3975,
          13437,
          7098,
          13,
          51338
        ]
      },
      {
        "avg_logprob": -0.25634552001953126,
        "compression_ratio": 1.7509293680297398,
        "end": 2019.78,
        "id": 704,
        "no_speech_prob": 0.000008939675353758503,
        "seek": 199642,
        "start": 2015.9,
        "temperature": 0,
        "text": " Meaning I can make, and this idea of this word public",
        "tokens": [
          51338,
          19948,
          286,
          393,
          652,
          11,
          293,
          341,
          1558,
          295,
          341,
          1349,
          1908,
          51532
        ]
      },
      {
        "avg_logprob": -0.25634552001953126,
        "compression_ratio": 1.7509293680297398,
        "end": 2021.3400000000001,
        "id": 705,
        "no_speech_prob": 0.000008939675353758503,
        "seek": 199642,
        "start": 2019.78,
        "temperature": 0,
        "text": " in there is something I could make up.",
        "tokens": [
          51532,
          294,
          456,
          307,
          746,
          286,
          727,
          652,
          493,
          13,
          51610
        ]
      },
      {
        "avg_logprob": -0.25634552001953126,
        "compression_ratio": 1.7509293680297398,
        "end": 2023.38,
        "id": 706,
        "no_speech_prob": 0.000008939675353758503,
        "seek": 199642,
        "start": 2021.3400000000001,
        "temperature": 0,
        "text": " So I could call this website instead of public, public",
        "tokens": [
          51610,
          407,
          286,
          727,
          818,
          341,
          3144,
          2602,
          295,
          1908,
          11,
          1908,
          51712
        ]
      },
      {
        "avg_logprob": -0.25634552001953126,
        "compression_ratio": 1.7509293680297398,
        "end": 2024.74,
        "id": 707,
        "no_speech_prob": 0.000008939675353758503,
        "seek": 199642,
        "start": 2023.38,
        "temperature": 0,
        "text": " being a kind of standard thing.",
        "tokens": [
          51712,
          885,
          257,
          733,
          295,
          3832,
          551,
          13,
          51780
        ]
      },
      {
        "avg_logprob": -0.21793743871873425,
        "compression_ratio": 1.6872427983539096,
        "end": 2028.14,
        "id": 708,
        "no_speech_prob": 0.000056497709010727704,
        "seek": 202474,
        "start": 2024.74,
        "temperature": 0,
        "text": " This is saying use out of the Express package",
        "tokens": [
          50364,
          639,
          307,
          1566,
          764,
          484,
          295,
          264,
          20212,
          7372,
          50534
        ]
      },
      {
        "avg_logprob": -0.21793743871873425,
        "compression_ratio": 1.6872427983539096,
        "end": 2032.42,
        "id": 709,
        "no_speech_prob": 0.000056497709010727704,
        "seek": 202474,
        "start": 2028.14,
        "temperature": 0,
        "text": " its ability to host static files, HTML files, image files,",
        "tokens": [
          50534,
          1080,
          3485,
          281,
          3975,
          13437,
          7098,
          11,
          17995,
          7098,
          11,
          3256,
          7098,
          11,
          50748
        ]
      },
      {
        "avg_logprob": -0.21793743871873425,
        "compression_ratio": 1.6872427983539096,
        "end": 2034.38,
        "id": 710,
        "no_speech_prob": 0.000056497709010727704,
        "seek": 202474,
        "start": 2032.42,
        "temperature": 0,
        "text": " movie files, all that sort of stuff.",
        "tokens": [
          50748,
          3169,
          7098,
          11,
          439,
          300,
          1333,
          295,
          1507,
          13,
          50846
        ]
      },
      {
        "avg_logprob": -0.21793743871873425,
        "compression_ratio": 1.6872427983539096,
        "end": 2038.6200000000001,
        "id": 711,
        "no_speech_prob": 0.000056497709010727704,
        "seek": 202474,
        "start": 2034.38,
        "temperature": 0,
        "text": " So what I can do now, if I go into here, right,",
        "tokens": [
          50846,
          407,
          437,
          286,
          393,
          360,
          586,
          11,
          498,
          286,
          352,
          666,
          510,
          11,
          558,
          11,
          51058
        ]
      },
      {
        "avg_logprob": -0.21793743871873425,
        "compression_ratio": 1.6872427983539096,
        "end": 2042.26,
        "id": 712,
        "no_speech_prob": 0.000056497709010727704,
        "seek": 202474,
        "start": 2038.6200000000001,
        "temperature": 0,
        "text": " into my project, what I want to do is create a folder.",
        "tokens": [
          51058,
          666,
          452,
          1716,
          11,
          437,
          286,
          528,
          281,
          360,
          307,
          1884,
          257,
          10820,
          13,
          51240
        ]
      },
      {
        "avg_logprob": -0.21793743871873425,
        "compression_ratio": 1.6872427983539096,
        "end": 2044.34,
        "id": 713,
        "no_speech_prob": 0.000056497709010727704,
        "seek": 202474,
        "start": 2042.26,
        "temperature": 0,
        "text": " I'm going to call that folder website, which",
        "tokens": [
          51240,
          286,
          478,
          516,
          281,
          818,
          300,
          10820,
          3144,
          11,
          597,
          51344
        ]
      },
      {
        "avg_logprob": -0.21793743871873425,
        "compression_ratio": 1.6872427983539096,
        "end": 2045.34,
        "id": 714,
        "no_speech_prob": 0.000056497709010727704,
        "seek": 202474,
        "start": 2044.34,
        "temperature": 0,
        "text": " is sort of a silly name.",
        "tokens": [
          51344,
          307,
          1333,
          295,
          257,
          11774,
          1315,
          13,
          51394
        ]
      },
      {
        "avg_logprob": -0.21793743871873425,
        "compression_ratio": 1.6872427983539096,
        "end": 2049.86,
        "id": 715,
        "no_speech_prob": 0.000056497709010727704,
        "seek": 202474,
        "start": 2045.34,
        "temperature": 0,
        "text": " And I'm going to put in that folder a file called index.html.",
        "tokens": [
          51394,
          400,
          286,
          478,
          516,
          281,
          829,
          294,
          300,
          10820,
          257,
          3991,
          1219,
          8186,
          13,
          357,
          15480,
          13,
          51620
        ]
      },
      {
        "avg_logprob": -0.21793743871873425,
        "compression_ratio": 1.6872427983539096,
        "end": 2054.3,
        "id": 716,
        "no_speech_prob": 0.000056497709010727704,
        "seek": 202474,
        "start": 2049.86,
        "temperature": 0,
        "text": " And then I'm going to say, hello.",
        "tokens": [
          51620,
          400,
          550,
          286,
          478,
          516,
          281,
          584,
          11,
          7751,
          13,
          51842
        ]
      },
      {
        "avg_logprob": -0.28805624114142525,
        "compression_ratio": 1.8589211618257262,
        "end": 2057.86,
        "id": 717,
        "no_speech_prob": 0.0001007133032544516,
        "seek": 205430,
        "start": 2054.34,
        "temperature": 0,
        "text": " So in that file, it says, hello.",
        "tokens": [
          50366,
          407,
          294,
          300,
          3991,
          11,
          309,
          1619,
          11,
          7751,
          13,
          50542
        ]
      },
      {
        "avg_logprob": -0.28805624114142525,
        "compression_ratio": 1.8589211618257262,
        "end": 2061.82,
        "id": 718,
        "no_speech_prob": 0.0001007133032544516,
        "seek": 205430,
        "start": 2057.86,
        "temperature": 0,
        "text": " And then, I don't know why I'm speaking in that voice.",
        "tokens": [
          50542,
          400,
          550,
          11,
          286,
          500,
          380,
          458,
          983,
          286,
          478,
          4124,
          294,
          300,
          3177,
          13,
          50740
        ]
      },
      {
        "avg_logprob": -0.28805624114142525,
        "compression_ratio": 1.8589211618257262,
        "end": 2063.3,
        "id": 719,
        "no_speech_prob": 0.0001007133032544516,
        "seek": 205430,
        "start": 2061.82,
        "temperature": 0,
        "text": " And then, I mean, I do know who I am,",
        "tokens": [
          50740,
          400,
          550,
          11,
          286,
          914,
          11,
          286,
          360,
          458,
          567,
          286,
          669,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.28805624114142525,
        "compression_ratio": 1.8589211618257262,
        "end": 2066.6200000000003,
        "id": 720,
        "no_speech_prob": 0.0001007133032544516,
        "seek": 205430,
        "start": 2063.3,
        "temperature": 0,
        "text": " but I don't know why I am who I am.",
        "tokens": [
          50814,
          457,
          286,
          500,
          380,
          458,
          983,
          286,
          669,
          567,
          286,
          669,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.28805624114142525,
        "compression_ratio": 1.8589211618257262,
        "end": 2069.78,
        "id": 721,
        "no_speech_prob": 0.0001007133032544516,
        "seek": 205430,
        "start": 2066.6200000000003,
        "temperature": 0,
        "text": " Anyway, now if I hit refresh, now first of all,",
        "tokens": [
          50980,
          5684,
          11,
          586,
          498,
          286,
          2045,
          15134,
          11,
          586,
          700,
          295,
          439,
          11,
          51138
        ]
      },
      {
        "avg_logprob": -0.28805624114142525,
        "compression_ratio": 1.8589211618257262,
        "end": 2071.0600000000004,
        "id": 722,
        "no_speech_prob": 0.0001007133032544516,
        "seek": 205430,
        "start": 2069.78,
        "temperature": 0,
        "text": " I've got to restart the server.",
        "tokens": [
          51138,
          286,
          600,
          658,
          281,
          21022,
          264,
          7154,
          13,
          51202
        ]
      },
      {
        "avg_logprob": -0.28805624114142525,
        "compression_ratio": 1.8589211618257262,
        "end": 2072.38,
        "id": 723,
        "no_speech_prob": 0.0001007133032544516,
        "seek": 205430,
        "start": 2071.0600000000004,
        "temperature": 0,
        "text": " So here's the thing.",
        "tokens": [
          51202,
          407,
          510,
          311,
          264,
          551,
          13,
          51268
        ]
      },
      {
        "avg_logprob": -0.28805624114142525,
        "compression_ratio": 1.8589211618257262,
        "end": 2073.9,
        "id": 724,
        "no_speech_prob": 0.0001007133032544516,
        "seek": 205430,
        "start": 2072.38,
        "temperature": 0,
        "text": " There's actually a really nice tool.",
        "tokens": [
          51268,
          821,
          311,
          767,
          257,
          534,
          1481,
          2290,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.28805624114142525,
        "compression_ratio": 1.8589211618257262,
        "end": 2075.98,
        "id": 725,
        "no_speech_prob": 0.0001007133032544516,
        "seek": 205430,
        "start": 2073.9,
        "temperature": 0,
        "text": " Notice how I have to stop the server, restart it,",
        "tokens": [
          51344,
          13428,
          577,
          286,
          362,
          281,
          1590,
          264,
          7154,
          11,
          21022,
          309,
          11,
          51448
        ]
      },
      {
        "avg_logprob": -0.28805624114142525,
        "compression_ratio": 1.8589211618257262,
        "end": 2078.8,
        "id": 726,
        "no_speech_prob": 0.0001007133032544516,
        "seek": 205430,
        "start": 2075.98,
        "temperature": 0,
        "text": " stop the server, restart it every single time I",
        "tokens": [
          51448,
          1590,
          264,
          7154,
          11,
          21022,
          309,
          633,
          2167,
          565,
          286,
          51589
        ]
      },
      {
        "avg_logprob": -0.28805624114142525,
        "compression_ratio": 1.8589211618257262,
        "end": 2080.1400000000003,
        "id": 727,
        "no_speech_prob": 0.0001007133032544516,
        "seek": 205430,
        "start": 2078.8,
        "temperature": 0,
        "text": " change my code.",
        "tokens": [
          51589,
          1319,
          452,
          3089,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.28805624114142525,
        "compression_ratio": 1.8589211618257262,
        "end": 2081.54,
        "id": 728,
        "no_speech_prob": 0.0001007133032544516,
        "seek": 205430,
        "start": 2080.1400000000003,
        "temperature": 0,
        "text": " There's a nice little node module.",
        "tokens": [
          51656,
          821,
          311,
          257,
          1481,
          707,
          9984,
          10088,
          13,
          51726
        ]
      },
      {
        "avg_logprob": -0.2690457367315525,
        "compression_ratio": 1.736842105263158,
        "end": 2089.1800000000003,
        "id": 729,
        "no_speech_prob": 0.00003219227437512018,
        "seek": 208430,
        "start": 2084.9,
        "temperature": 0,
        "text": " I'm sure this is, which is called nodemon.",
        "tokens": [
          50394,
          286,
          478,
          988,
          341,
          307,
          11,
          597,
          307,
          1219,
          9984,
          3317,
          13,
          50608
        ]
      },
      {
        "avg_logprob": -0.2690457367315525,
        "compression_ratio": 1.736842105263158,
        "end": 2091.7400000000002,
        "id": 730,
        "no_speech_prob": 0.00003219227437512018,
        "seek": 208430,
        "start": 2089.1800000000003,
        "temperature": 0,
        "text": " And nodemon, like node monitor, I think,",
        "tokens": [
          50608,
          400,
          9984,
          3317,
          11,
          411,
          9984,
          6002,
          11,
          286,
          519,
          11,
          50736
        ]
      },
      {
        "avg_logprob": -0.2690457367315525,
        "compression_ratio": 1.736842105263158,
        "end": 2094.1000000000004,
        "id": 731,
        "no_speech_prob": 0.00003219227437512018,
        "seek": 208430,
        "start": 2091.7400000000002,
        "temperature": 0,
        "text": " monitors your code and restarts the server for you",
        "tokens": [
          50736,
          26518,
          428,
          3089,
          293,
          1472,
          11814,
          264,
          7154,
          337,
          291,
          50854
        ]
      },
      {
        "avg_logprob": -0.2690457367315525,
        "compression_ratio": 1.736842105263158,
        "end": 2095.38,
        "id": 732,
        "no_speech_prob": 0.00003219227437512018,
        "seek": 208430,
        "start": 2094.1000000000004,
        "temperature": 0,
        "text": " every time you change the code.",
        "tokens": [
          50854,
          633,
          565,
          291,
          1319,
          264,
          3089,
          13,
          50918
        ]
      },
      {
        "avg_logprob": -0.2690457367315525,
        "compression_ratio": 1.736842105263158,
        "end": 2096.6200000000003,
        "id": 733,
        "no_speech_prob": 0.00003219227437512018,
        "seek": 208430,
        "start": 2095.38,
        "temperature": 0,
        "text": " Now, this can be problematic.",
        "tokens": [
          50918,
          823,
          11,
          341,
          393,
          312,
          19011,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.2690457367315525,
        "compression_ratio": 1.736842105263158,
        "end": 2097.6600000000003,
        "id": 734,
        "no_speech_prob": 0.00003219227437512018,
        "seek": 208430,
        "start": 2096.6200000000003,
        "temperature": 0,
        "text": " And you don't always want to use it.",
        "tokens": [
          50980,
          400,
          291,
          500,
          380,
          1009,
          528,
          281,
          764,
          309,
          13,
          51032
        ]
      },
      {
        "avg_logprob": -0.2690457367315525,
        "compression_ratio": 1.736842105263158,
        "end": 2099.78,
        "id": 735,
        "no_speech_prob": 0.00003219227437512018,
        "seek": 208430,
        "start": 2097.6600000000003,
        "temperature": 0,
        "text": " But in this case, it would be a lot more convenient.",
        "tokens": [
          51032,
          583,
          294,
          341,
          1389,
          11,
          309,
          576,
          312,
          257,
          688,
          544,
          10851,
          13,
          51138
        ]
      },
      {
        "avg_logprob": -0.2690457367315525,
        "compression_ratio": 1.736842105263158,
        "end": 2101.86,
        "id": 736,
        "no_speech_prob": 0.00003219227437512018,
        "seek": 208430,
        "start": 2099.78,
        "temperature": 0,
        "text": " And dash g means I want this package.",
        "tokens": [
          51138,
          400,
          8240,
          290,
          1355,
          286,
          528,
          341,
          7372,
          13,
          51242
        ]
      },
      {
        "avg_logprob": -0.2690457367315525,
        "compression_ratio": 1.736842105263158,
        "end": 2104.02,
        "id": 737,
        "no_speech_prob": 0.00003219227437512018,
        "seek": 208430,
        "start": 2101.86,
        "temperature": 0,
        "text": " This isn't a package associated with this project.",
        "tokens": [
          51242,
          639,
          1943,
          380,
          257,
          7372,
          6615,
          365,
          341,
          1716,
          13,
          51350
        ]
      },
      {
        "avg_logprob": -0.2690457367315525,
        "compression_ratio": 1.736842105263158,
        "end": 2105.44,
        "id": 738,
        "no_speech_prob": 0.00003219227437512018,
        "seek": 208430,
        "start": 2104.02,
        "temperature": 0,
        "text": " I want this as just a global tool",
        "tokens": [
          51350,
          286,
          528,
          341,
          382,
          445,
          257,
          4338,
          2290,
          51421
        ]
      },
      {
        "avg_logprob": -0.2690457367315525,
        "compression_ratio": 1.736842105263158,
        "end": 2106.7000000000003,
        "id": 739,
        "no_speech_prob": 0.00003219227437512018,
        "seek": 208430,
        "start": 2105.44,
        "temperature": 0,
        "text": " that I'm using on my computer.",
        "tokens": [
          51421,
          300,
          286,
          478,
          1228,
          322,
          452,
          3820,
          13,
          51484
        ]
      },
      {
        "avg_logprob": -0.2690457367315525,
        "compression_ratio": 1.736842105263158,
        "end": 2108.54,
        "id": 740,
        "no_speech_prob": 0.00003219227437512018,
        "seek": 208430,
        "start": 2106.7000000000003,
        "temperature": 0,
        "text": " And this probably is going to fail.",
        "tokens": [
          51484,
          400,
          341,
          1391,
          307,
          516,
          281,
          3061,
          13,
          51576
        ]
      },
      {
        "avg_logprob": -0.2690457367315525,
        "compression_ratio": 1.736842105263158,
        "end": 2110.0600000000004,
        "id": 741,
        "no_speech_prob": 0.00003219227437512018,
        "seek": 208430,
        "start": 2108.54,
        "temperature": 0,
        "text": " Oh, but maybe it's not.",
        "tokens": [
          51576,
          876,
          11,
          457,
          1310,
          309,
          311,
          406,
          13,
          51652
        ]
      },
      {
        "avg_logprob": -0.2690457367315525,
        "compression_ratio": 1.736842105263158,
        "end": 2112.5800000000004,
        "id": 742,
        "no_speech_prob": 0.00003219227437512018,
        "seek": 208430,
        "start": 2110.0600000000004,
        "temperature": 0,
        "text": " I'm feeling hopeful now that actually this is going to work.",
        "tokens": [
          51652,
          286,
          478,
          2633,
          20531,
          586,
          300,
          767,
          341,
          307,
          516,
          281,
          589,
          13,
          51778
        ]
      },
      {
        "avg_logprob": -0.2718490373970258,
        "compression_ratio": 1.5585585585585586,
        "end": 2114.74,
        "id": 743,
        "no_speech_prob": 0.00006502730684587732,
        "seek": 211258,
        "start": 2112.58,
        "temperature": 0,
        "text": " So I got some error permission denied.",
        "tokens": [
          50364,
          407,
          286,
          658,
          512,
          6713,
          11226,
          17774,
          13,
          50472
        ]
      },
      {
        "avg_logprob": -0.2718490373970258,
        "compression_ratio": 1.5585585585585586,
        "end": 2117.18,
        "id": 744,
        "no_speech_prob": 0.00006502730684587732,
        "seek": 211258,
        "start": 2114.74,
        "temperature": 0,
        "text": " This is because when I'm installing a global package,",
        "tokens": [
          50472,
          639,
          307,
          570,
          562,
          286,
          478,
          20762,
          257,
          4338,
          7372,
          11,
          50594
        ]
      },
      {
        "avg_logprob": -0.2718490373970258,
        "compression_ratio": 1.5585585585585586,
        "end": 2119.9,
        "id": 745,
        "no_speech_prob": 0.00006502730684587732,
        "seek": 211258,
        "start": 2117.18,
        "temperature": 0,
        "text": " it's got to go into like user, var, local, bin,",
        "tokens": [
          50594,
          309,
          311,
          658,
          281,
          352,
          666,
          411,
          4195,
          11,
          1374,
          11,
          2654,
          11,
          5171,
          11,
          50730
        ]
      },
      {
        "avg_logprob": -0.2718490373970258,
        "compression_ratio": 1.5585585585585586,
        "end": 2122.02,
        "id": 746,
        "no_speech_prob": 0.00006502730684587732,
        "seek": 211258,
        "start": 2119.9,
        "temperature": 0,
        "text": " some secret place on my computer where",
        "tokens": [
          50730,
          512,
          4054,
          1081,
          322,
          452,
          3820,
          689,
          50836
        ]
      },
      {
        "avg_logprob": -0.2718490373970258,
        "compression_ratio": 1.5585585585585586,
        "end": 2124.02,
        "id": 747,
        "no_speech_prob": 0.00006502730684587732,
        "seek": 211258,
        "start": 2122.02,
        "temperature": 0,
        "text": " I need special permission.",
        "tokens": [
          50836,
          286,
          643,
          2121,
          11226,
          13,
          50936
        ]
      },
      {
        "avg_logprob": -0.2718490373970258,
        "compression_ratio": 1.5585585585585586,
        "end": 2130.9,
        "id": 748,
        "no_speech_prob": 0.00006502730684587732,
        "seek": 211258,
        "start": 2124.02,
        "temperature": 0,
        "text": " So I'm going to say sudo for super do npm install nodemon",
        "tokens": [
          50936,
          407,
          286,
          478,
          516,
          281,
          584,
          459,
          2595,
          337,
          1687,
          360,
          297,
          14395,
          3625,
          9984,
          3317,
          51280
        ]
      },
      {
        "avg_logprob": -0.2718490373970258,
        "compression_ratio": 1.5585585585585586,
        "end": 2132.2599999999998,
        "id": 749,
        "no_speech_prob": 0.00006502730684587732,
        "seek": 211258,
        "start": 2130.9,
        "temperature": 0,
        "text": " dash g.",
        "tokens": [
          51280,
          8240,
          290,
          13,
          51348
        ]
      },
      {
        "avg_logprob": -0.2718490373970258,
        "compression_ratio": 1.5585585585585586,
        "end": 2134.34,
        "id": 750,
        "no_speech_prob": 0.00006502730684587732,
        "seek": 211258,
        "start": 2132.2599999999998,
        "temperature": 0,
        "text": " And now I'm going to type in the password here.",
        "tokens": [
          51348,
          400,
          586,
          286,
          478,
          516,
          281,
          2010,
          294,
          264,
          11524,
          510,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.2718490373970258,
        "compression_ratio": 1.5585585585585586,
        "end": 2136.1,
        "id": 751,
        "no_speech_prob": 0.00006502730684587732,
        "seek": 211258,
        "start": 2134.34,
        "temperature": 0,
        "text": " And hopefully this works.",
        "tokens": [
          51452,
          400,
          4696,
          341,
          1985,
          13,
          51540
        ]
      },
      {
        "avg_logprob": -0.27396680925275896,
        "compression_ratio": 1.7323420074349443,
        "end": 2144.38,
        "id": 752,
        "no_speech_prob": 0.00040447540231980383,
        "seek": 214258,
        "start": 2142.58,
        "temperature": 0,
        "text": " There, that seemed to work.",
        "tokens": [
          50364,
          821,
          11,
          300,
          6576,
          281,
          589,
          13,
          50454
        ]
      },
      {
        "avg_logprob": -0.27396680925275896,
        "compression_ratio": 1.7323420074349443,
        "end": 2145.86,
        "id": 753,
        "no_speech_prob": 0.00040447540231980383,
        "seek": 214258,
        "start": 2144.38,
        "temperature": 0,
        "text": " Or I'm getting some warnings.",
        "tokens": [
          50454,
          1610,
          286,
          478,
          1242,
          512,
          30009,
          13,
          50528
        ]
      },
      {
        "avg_logprob": -0.27396680925275896,
        "compression_ratio": 1.7323420074349443,
        "end": 2147.52,
        "id": 754,
        "no_speech_prob": 0.00040447540231980383,
        "seek": 214258,
        "start": 2145.86,
        "temperature": 0,
        "text": " I'm getting some things that look scary.",
        "tokens": [
          50528,
          286,
          478,
          1242,
          512,
          721,
          300,
          574,
          6958,
          13,
          50611
        ]
      },
      {
        "avg_logprob": -0.27396680925275896,
        "compression_ratio": 1.7323420074349443,
        "end": 2148.8199999999997,
        "id": 755,
        "no_speech_prob": 0.00040447540231980383,
        "seek": 214258,
        "start": 2147.52,
        "temperature": 0,
        "text": " Oh, it's doing more stuff.",
        "tokens": [
          50611,
          876,
          11,
          309,
          311,
          884,
          544,
          1507,
          13,
          50676
        ]
      },
      {
        "avg_logprob": -0.27396680925275896,
        "compression_ratio": 1.7323420074349443,
        "end": 2150.18,
        "id": 756,
        "no_speech_prob": 0.00040447540231980383,
        "seek": 214258,
        "start": 2148.8199999999997,
        "temperature": 0,
        "text": " I think that worked.",
        "tokens": [
          50676,
          286,
          519,
          300,
          2732,
          13,
          50744
        ]
      },
      {
        "avg_logprob": -0.27396680925275896,
        "compression_ratio": 1.7323420074349443,
        "end": 2155.02,
        "id": 757,
        "no_speech_prob": 0.00040447540231980383,
        "seek": 214258,
        "start": 2150.18,
        "temperature": 0,
        "text": " So I'm now going to say nodemon server.js.",
        "tokens": [
          50744,
          407,
          286,
          478,
          586,
          516,
          281,
          584,
          9984,
          3317,
          7154,
          13,
          25530,
          13,
          50986
        ]
      },
      {
        "avg_logprob": -0.27396680925275896,
        "compression_ratio": 1.7323420074349443,
        "end": 2155.9,
        "id": 758,
        "no_speech_prob": 0.00040447540231980383,
        "seek": 214258,
        "start": 2155.02,
        "temperature": 0,
        "text": " And this is working.",
        "tokens": [
          50986,
          400,
          341,
          307,
          1364,
          13,
          51030
        ]
      },
      {
        "avg_logprob": -0.27396680925275896,
        "compression_ratio": 1.7323420074349443,
        "end": 2158.62,
        "id": 759,
        "no_speech_prob": 0.00040447540231980383,
        "seek": 214258,
        "start": 2155.9,
        "temperature": 0,
        "text": " So you can see that it is the server is starting, listening.",
        "tokens": [
          51030,
          407,
          291,
          393,
          536,
          300,
          309,
          307,
          264,
          7154,
          307,
          2891,
          11,
          4764,
          13,
          51166
        ]
      },
      {
        "avg_logprob": -0.27396680925275896,
        "compression_ratio": 1.7323420074349443,
        "end": 2162.5,
        "id": 760,
        "no_speech_prob": 0.00040447540231980383,
        "seek": 214258,
        "start": 2158.62,
        "temperature": 0,
        "text": " And watch what happens if I go back and I say go to my server",
        "tokens": [
          51166,
          400,
          1159,
          437,
          2314,
          498,
          286,
          352,
          646,
          293,
          286,
          584,
          352,
          281,
          452,
          7154,
          51360
        ]
      },
      {
        "avg_logprob": -0.27396680925275896,
        "compression_ratio": 1.7323420074349443,
        "end": 2167.2999999999997,
        "id": 761,
        "no_speech_prob": 0.00040447540231980383,
        "seek": 214258,
        "start": 2162.5,
        "temperature": 0,
        "text": " and I say, you know, I make a just do a carriage return",
        "tokens": [
          51360,
          293,
          286,
          584,
          11,
          291,
          458,
          11,
          286,
          652,
          257,
          445,
          360,
          257,
          31811,
          2736,
          51600
        ]
      },
      {
        "avg_logprob": -0.27396680925275896,
        "compression_ratio": 1.7323420074349443,
        "end": 2168.38,
        "id": 762,
        "no_speech_prob": 0.00040447540231980383,
        "seek": 214258,
        "start": 2167.2999999999997,
        "temperature": 0,
        "text": " and hit Save.",
        "tokens": [
          51600,
          293,
          2045,
          15541,
          13,
          51654
        ]
      },
      {
        "avg_logprob": -0.27396680925275896,
        "compression_ratio": 1.7323420074349443,
        "end": 2171.38,
        "id": 763,
        "no_speech_prob": 0.00040447540231980383,
        "seek": 214258,
        "start": 2168.38,
        "temperature": 0,
        "text": " You can see here, look how many times it restarted the server.",
        "tokens": [
          51654,
          509,
          393,
          536,
          510,
          11,
          574,
          577,
          867,
          1413,
          309,
          21022,
          292,
          264,
          7154,
          13,
          51804
        ]
      },
      {
        "avg_logprob": -0.21563130266526165,
        "compression_ratio": 1.677304964539007,
        "end": 2174.1,
        "id": 764,
        "no_speech_prob": 0.0000154462868522387,
        "seek": 217138,
        "start": 2171.38,
        "temperature": 0,
        "text": " So now I can kind of ignore terminal for a little while",
        "tokens": [
          50364,
          407,
          586,
          286,
          393,
          733,
          295,
          11200,
          14709,
          337,
          257,
          707,
          1339,
          50500
        ]
      },
      {
        "avg_logprob": -0.21563130266526165,
        "compression_ratio": 1.677304964539007,
        "end": 2179.26,
        "id": 765,
        "no_speech_prob": 0.0000154462868522387,
        "seek": 217138,
        "start": 2174.1,
        "temperature": 0,
        "text": " and just go from my code to when I make a change,",
        "tokens": [
          50500,
          293,
          445,
          352,
          490,
          452,
          3089,
          281,
          562,
          286,
          652,
          257,
          1319,
          11,
          50758
        ]
      },
      {
        "avg_logprob": -0.21563130266526165,
        "compression_ratio": 1.677304964539007,
        "end": 2180.34,
        "id": 766,
        "no_speech_prob": 0.0000154462868522387,
        "seek": 217138,
        "start": 2179.26,
        "temperature": 0,
        "text": " refreshing in the browser.",
        "tokens": [
          50758,
          19772,
          294,
          264,
          11185,
          13,
          50812
        ]
      },
      {
        "avg_logprob": -0.21563130266526165,
        "compression_ratio": 1.677304964539007,
        "end": 2181.62,
        "id": 767,
        "no_speech_prob": 0.0000154462868522387,
        "seek": 217138,
        "start": 2180.34,
        "temperature": 0,
        "text": " So look at that, by the way.",
        "tokens": [
          50812,
          407,
          574,
          412,
          300,
          11,
          538,
          264,
          636,
          13,
          50876
        ]
      },
      {
        "avg_logprob": -0.21563130266526165,
        "compression_ratio": 1.677304964539007,
        "end": 2186.1800000000003,
        "id": 768,
        "no_speech_prob": 0.0000154462868522387,
        "seek": 217138,
        "start": 2181.62,
        "temperature": 0,
        "text": " I now see the files that are in that directory website.",
        "tokens": [
          50876,
          286,
          586,
          536,
          264,
          7098,
          300,
          366,
          294,
          300,
          21120,
          3144,
          13,
          51104
        ]
      },
      {
        "avg_logprob": -0.21563130266526165,
        "compression_ratio": 1.677304964539007,
        "end": 2187.8,
        "id": 769,
        "no_speech_prob": 0.0000154462868522387,
        "seek": 217138,
        "start": 2186.1800000000003,
        "temperature": 0,
        "text": " So this is step one.",
        "tokens": [
          51104,
          407,
          341,
          307,
          1823,
          472,
          13,
          51185
        ]
      },
      {
        "avg_logprob": -0.21563130266526165,
        "compression_ratio": 1.677304964539007,
        "end": 2191.78,
        "id": 770,
        "no_speech_prob": 0.0000154462868522387,
        "seek": 217138,
        "start": 2187.8,
        "temperature": 0,
        "text": " We have now written a web server with like barely any code",
        "tokens": [
          51185,
          492,
          362,
          586,
          3720,
          257,
          3670,
          7154,
          365,
          411,
          10268,
          604,
          3089,
          51384
        ]
      },
      {
        "avg_logprob": -0.21563130266526165,
        "compression_ratio": 1.677304964539007,
        "end": 2192.26,
        "id": 771,
        "no_speech_prob": 0.0000154462868522387,
        "seek": 217138,
        "start": 2191.78,
        "temperature": 0,
        "text": " at all.",
        "tokens": [
          51384,
          412,
          439,
          13,
          51408
        ]
      },
      {
        "avg_logprob": -0.21563130266526165,
        "compression_ratio": 1.677304964539007,
        "end": 2194.62,
        "id": 772,
        "no_speech_prob": 0.0000154462868522387,
        "seek": 217138,
        "start": 2192.26,
        "temperature": 0,
        "text": " Look, this is like all the code for the web server.",
        "tokens": [
          51408,
          2053,
          11,
          341,
          307,
          411,
          439,
          264,
          3089,
          337,
          264,
          3670,
          7154,
          13,
          51526
        ]
      },
      {
        "avg_logprob": -0.21563130266526165,
        "compression_ratio": 1.677304964539007,
        "end": 2197.78,
        "id": 773,
        "no_speech_prob": 0.0000154462868522387,
        "seek": 217138,
        "start": 2194.62,
        "temperature": 0,
        "text": " And incidentally, if you've ever seen me or do something",
        "tokens": [
          51526,
          400,
          9348,
          379,
          11,
          498,
          291,
          600,
          1562,
          1612,
          385,
          420,
          360,
          746,
          51684
        ]
      },
      {
        "avg_logprob": -0.21563130266526165,
        "compression_ratio": 1.677304964539007,
        "end": 2200.54,
        "id": 774,
        "no_speech_prob": 0.0000154462868522387,
        "seek": 217138,
        "start": 2197.78,
        "temperature": 0,
        "text": " like this, like often I'll run a web server on my computer",
        "tokens": [
          51684,
          411,
          341,
          11,
          411,
          2049,
          286,
          603,
          1190,
          257,
          3670,
          7154,
          322,
          452,
          3820,
          51822
        ]
      },
      {
        "avg_logprob": -0.21622467041015625,
        "compression_ratio": 1.8583690987124464,
        "end": 2204.02,
        "id": 775,
        "no_speech_prob": 0.00009170174598693848,
        "seek": 220054,
        "start": 2200.58,
        "temperature": 0,
        "text": " by just saying python-m simple HTTP server.",
        "tokens": [
          50366,
          538,
          445,
          1566,
          38797,
          12,
          76,
          2199,
          33283,
          7154,
          13,
          50538
        ]
      },
      {
        "avg_logprob": -0.21622467041015625,
        "compression_ratio": 1.8583690987124464,
        "end": 2205.34,
        "id": 776,
        "no_speech_prob": 0.00009170174598693848,
        "seek": 220054,
        "start": 2204.02,
        "temperature": 0,
        "text": " That's running a web server.",
        "tokens": [
          50538,
          663,
          311,
          2614,
          257,
          3670,
          7154,
          13,
          50604
        ]
      },
      {
        "avg_logprob": -0.21622467041015625,
        "compression_ratio": 1.8583690987124464,
        "end": 2206.74,
        "id": 777,
        "no_speech_prob": 0.00009170174598693848,
        "seek": 220054,
        "start": 2205.34,
        "temperature": 0,
        "text": " There are lots of other tools.",
        "tokens": [
          50604,
          821,
          366,
          3195,
          295,
          661,
          3873,
          13,
          50674
        ]
      },
      {
        "avg_logprob": -0.21622467041015625,
        "compression_ratio": 1.8583690987124464,
        "end": 2209.38,
        "id": 778,
        "no_speech_prob": 0.00009170174598693848,
        "seek": 220054,
        "start": 2206.74,
        "temperature": 0,
        "text": " There's a node HTTP server.",
        "tokens": [
          50674,
          821,
          311,
          257,
          9984,
          33283,
          7154,
          13,
          50806
        ]
      },
      {
        "avg_logprob": -0.21622467041015625,
        "compression_ratio": 1.8583690987124464,
        "end": 2211.08,
        "id": 779,
        "no_speech_prob": 0.00009170174598693848,
        "seek": 220054,
        "start": 2209.38,
        "temperature": 0,
        "text": " There are lots of tools that just make",
        "tokens": [
          50806,
          821,
          366,
          3195,
          295,
          3873,
          300,
          445,
          652,
          50891
        ]
      },
      {
        "avg_logprob": -0.21622467041015625,
        "compression_ratio": 1.8583690987124464,
        "end": 2212.7,
        "id": 780,
        "no_speech_prob": 0.00009170174598693848,
        "seek": 220054,
        "start": 2211.08,
        "temperature": 0,
        "text": " a web server that hosts files.",
        "tokens": [
          50891,
          257,
          3670,
          7154,
          300,
          21573,
          7098,
          13,
          50972
        ]
      },
      {
        "avg_logprob": -0.21622467041015625,
        "compression_ratio": 1.8583690987124464,
        "end": 2217.46,
        "id": 781,
        "no_speech_prob": 0.00009170174598693848,
        "seek": 220054,
        "start": 2212.7,
        "temperature": 0,
        "text": " This is what we have now done in this exact program.",
        "tokens": [
          50972,
          639,
          307,
          437,
          321,
          362,
          586,
          1096,
          294,
          341,
          1900,
          1461,
          13,
          51210
        ]
      },
      {
        "avg_logprob": -0.21622467041015625,
        "compression_ratio": 1.8583690987124464,
        "end": 2219.34,
        "id": 782,
        "no_speech_prob": 0.00009170174598693848,
        "seek": 220054,
        "start": 2217.46,
        "temperature": 0,
        "text": " So step one is completed.",
        "tokens": [
          51210,
          407,
          1823,
          472,
          307,
          7365,
          13,
          51304
        ]
      },
      {
        "avg_logprob": -0.21622467041015625,
        "compression_ratio": 1.8583690987124464,
        "end": 2222.54,
        "id": 783,
        "no_speech_prob": 0.00009170174598693848,
        "seek": 220054,
        "start": 2219.34,
        "temperature": 0,
        "text": " We have written a web server that hosts files.",
        "tokens": [
          51304,
          492,
          362,
          3720,
          257,
          3670,
          7154,
          300,
          21573,
          7098,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.21622467041015625,
        "compression_ratio": 1.8583690987124464,
        "end": 2225.06,
        "id": 784,
        "no_speech_prob": 0.00009170174598693848,
        "seek": 220054,
        "start": 2222.54,
        "temperature": 0,
        "text": " In the next video, I'm going to add something",
        "tokens": [
          51464,
          682,
          264,
          958,
          960,
          11,
          286,
          478,
          516,
          281,
          909,
          746,
          51590
        ]
      },
      {
        "avg_logprob": -0.21622467041015625,
        "compression_ratio": 1.8583690987124464,
        "end": 2226.9,
        "id": 785,
        "no_speech_prob": 0.00009170174598693848,
        "seek": 220054,
        "start": 2225.06,
        "temperature": 0,
        "text": " to this called routes.",
        "tokens": [
          51590,
          281,
          341,
          1219,
          18242,
          13,
          51682
        ]
      },
      {
        "avg_logprob": -0.21622467041015625,
        "compression_ratio": 1.8583690987124464,
        "end": 2229.06,
        "id": 786,
        "no_speech_prob": 0.00009170174598693848,
        "seek": 220054,
        "start": 2226.9,
        "temperature": 0,
        "text": " So in addition to hosting files, I'm",
        "tokens": [
          51682,
          407,
          294,
          4500,
          281,
          16058,
          7098,
          11,
          286,
          478,
          51790
        ]
      },
      {
        "avg_logprob": -0.2695533548082624,
        "compression_ratio": 1.670940170940171,
        "end": 2233.2999999999997,
        "id": 787,
        "no_speech_prob": 0.000804075738415122,
        "seek": 222906,
        "start": 2229.06,
        "temperature": 0,
        "text": " going to allow the user to send information or request",
        "tokens": [
          50364,
          516,
          281,
          2089,
          264,
          4195,
          281,
          2845,
          1589,
          420,
          5308,
          50576
        ]
      },
      {
        "avg_logprob": -0.2695533548082624,
        "compression_ratio": 1.670940170940171,
        "end": 2238.18,
        "id": 788,
        "no_speech_prob": 0.000804075738415122,
        "seek": 222906,
        "start": 2233.2999999999997,
        "temperature": 0,
        "text": " information through something called a route, a RESTian route.",
        "tokens": [
          50576,
          1589,
          807,
          746,
          1219,
          257,
          7955,
          11,
          257,
          497,
          14497,
          952,
          7955,
          13,
          50820
        ]
      },
      {
        "avg_logprob": -0.2695533548082624,
        "compression_ratio": 1.670940170940171,
        "end": 2240.06,
        "id": 789,
        "no_speech_prob": 0.000804075738415122,
        "seek": 222906,
        "start": 2238.18,
        "temperature": 0,
        "text": " By RESTian, I mean you're going to want",
        "tokens": [
          50820,
          3146,
          497,
          14497,
          952,
          11,
          286,
          914,
          291,
          434,
          516,
          281,
          528,
          50914
        ]
      },
      {
        "avg_logprob": -0.2695533548082624,
        "compression_ratio": 1.670940170940171,
        "end": 2241.98,
        "id": 790,
        "no_speech_prob": 0.000804075738415122,
        "seek": 222906,
        "start": 2240.06,
        "temperature": 0,
        "text": " to take a rest after watching the video probably.",
        "tokens": [
          50914,
          281,
          747,
          257,
          1472,
          934,
          1976,
          264,
          960,
          1391,
          13,
          51010
        ]
      },
      {
        "avg_logprob": -0.2695533548082624,
        "compression_ratio": 1.670940170940171,
        "end": 2243.2999999999997,
        "id": 791,
        "no_speech_prob": 0.000804075738415122,
        "seek": 222906,
        "start": 2241.98,
        "temperature": 0,
        "text": " OK, so I'll see you in the next video.",
        "tokens": [
          51010,
          2264,
          11,
          370,
          286,
          603,
          536,
          291,
          294,
          264,
          958,
          960,
          13,
          51076
        ]
      },
      {
        "avg_logprob": -0.2695533548082624,
        "compression_ratio": 1.670940170940171,
        "end": 2245.58,
        "id": 792,
        "no_speech_prob": 0.000804075738415122,
        "seek": 222906,
        "start": 2243.2999999999997,
        "temperature": 0,
        "text": " Thanks for watching this one on setting up a basic web",
        "tokens": [
          51076,
          2561,
          337,
          1976,
          341,
          472,
          322,
          3287,
          493,
          257,
          3875,
          3670,
          51190
        ]
      },
      {
        "avg_logprob": -0.2695533548082624,
        "compression_ratio": 1.670940170940171,
        "end": 2246.46,
        "id": 793,
        "no_speech_prob": 0.000804075738415122,
        "seek": 222906,
        "start": 2245.58,
        "temperature": 0,
        "text": " server with Express.",
        "tokens": [
          51190,
          7154,
          365,
          20212,
          13,
          51234
        ]
      },
      {
        "avg_logprob": -0.2695533548082624,
        "compression_ratio": 1.670940170940171,
        "end": 2250.34,
        "id": 794,
        "no_speech_prob": 0.000804075738415122,
        "seek": 222906,
        "start": 2246.46,
        "temperature": 0,
        "text": " I'm going to take a look at the chat.",
        "tokens": [
          51234,
          286,
          478,
          516,
          281,
          747,
          257,
          574,
          412,
          264,
          5081,
          13,
          51428
        ]
      },
      {
        "avg_logprob": -0.2695533548082624,
        "compression_ratio": 1.670940170940171,
        "end": 2251.7,
        "id": 795,
        "no_speech_prob": 0.000804075738415122,
        "seek": 222906,
        "start": 2250.34,
        "temperature": 0,
        "text": " I'm taking a look at the time.",
        "tokens": [
          51428,
          286,
          478,
          1940,
          257,
          574,
          412,
          264,
          565,
          13,
          51496
        ]
      },
      {
        "avg_logprob": -0.3226076178594467,
        "compression_ratio": 1.6618357487922706,
        "end": 2259.58,
        "id": 796,
        "no_speech_prob": 0.0016229305183514953,
        "seek": 225170,
        "start": 2252.7,
        "temperature": 0,
        "text": " Oh, this computer, my computer that has the chat, died.",
        "tokens": [
          50414,
          876,
          11,
          341,
          3820,
          11,
          452,
          3820,
          300,
          575,
          264,
          5081,
          11,
          4539,
          13,
          50758
        ]
      },
      {
        "avg_logprob": -0.3226076178594467,
        "compression_ratio": 1.6618357487922706,
        "end": 2260.22,
        "id": 797,
        "no_speech_prob": 0.0016229305183514953,
        "seek": 225170,
        "start": 2259.58,
        "temperature": 0,
        "text": " I think the bad.",
        "tokens": [
          50758,
          286,
          519,
          264,
          1578,
          13,
          50790
        ]
      },
      {
        "avg_logprob": -0.3226076178594467,
        "compression_ratio": 1.6618357487922706,
        "end": 2261.9399999999996,
        "id": 798,
        "no_speech_prob": 0.0016229305183514953,
        "seek": 225170,
        "start": 2260.22,
        "temperature": 0,
        "text": " I only have one plug.",
        "tokens": [
          50790,
          286,
          787,
          362,
          472,
          5452,
          13,
          50876
        ]
      },
      {
        "avg_logprob": -0.3226076178594467,
        "compression_ratio": 1.6618357487922706,
        "end": 2264.74,
        "id": 799,
        "no_speech_prob": 0.0016229305183514953,
        "seek": 225170,
        "start": 2261.9399999999996,
        "temperature": 0,
        "text": " So I don't know if anybody's telling me anything",
        "tokens": [
          50876,
          407,
          286,
          500,
          380,
          458,
          498,
          4472,
          311,
          3585,
          385,
          1340,
          51016
        ]
      },
      {
        "avg_logprob": -0.3226076178594467,
        "compression_ratio": 1.6618357487922706,
        "end": 2268.06,
        "id": 800,
        "no_speech_prob": 0.0016229305183514953,
        "seek": 225170,
        "start": 2264.74,
        "temperature": 0,
        "text": " or if everything has gone completely kaput.",
        "tokens": [
          51016,
          420,
          498,
          1203,
          575,
          2780,
          2584,
          13816,
          325,
          13,
          51182
        ]
      },
      {
        "avg_logprob": -0.3226076178594467,
        "compression_ratio": 1.6618357487922706,
        "end": 2271.7,
        "id": 801,
        "no_speech_prob": 0.0016229305183514953,
        "seek": 225170,
        "start": 2268.06,
        "temperature": 0,
        "text": " I'm still smelling a little of the smoke from that halogen.",
        "tokens": [
          51182,
          286,
          478,
          920,
          35471,
          257,
          707,
          295,
          264,
          8439,
          490,
          300,
          7523,
          8799,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.3226076178594467,
        "compression_ratio": 1.6618357487922706,
        "end": 2273.02,
        "id": 802,
        "no_speech_prob": 0.0016229305183514953,
        "seek": 225170,
        "start": 2271.7,
        "temperature": 0,
        "text": " Come, computer, wake up.",
        "tokens": [
          51364,
          2492,
          11,
          3820,
          11,
          6634,
          493,
          13,
          51430
        ]
      },
      {
        "avg_logprob": -0.3226076178594467,
        "compression_ratio": 1.6618357487922706,
        "end": 2274.02,
        "id": 803,
        "no_speech_prob": 0.0016229305183514953,
        "seek": 225170,
        "start": 2273.02,
        "temperature": 0,
        "text": " I want to see the chat.",
        "tokens": [
          51430,
          286,
          528,
          281,
          536,
          264,
          5081,
          13,
          51480
        ]
      },
      {
        "avg_logprob": -0.3226076178594467,
        "compression_ratio": 1.6618357487922706,
        "end": 2277.66,
        "id": 804,
        "no_speech_prob": 0.0016229305183514953,
        "seek": 225170,
        "start": 2277.1,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          51634,
          286,
          500,
          380,
          458,
          13,
          51662
        ]
      },
      {
        "avg_logprob": -0.3226076178594467,
        "compression_ratio": 1.6618357487922706,
        "end": 2280.58,
        "id": 805,
        "no_speech_prob": 0.0016229305183514953,
        "seek": 225170,
        "start": 2277.66,
        "temperature": 0,
        "text": " I was going to put on some music.",
        "tokens": [
          51662,
          286,
          390,
          516,
          281,
          829,
          322,
          512,
          1318,
          13,
          51808
        ]
      },
      {
        "avg_logprob": -0.4327599709494072,
        "compression_ratio": 1.1801801801801801,
        "end": 2282.22,
        "id": 806,
        "no_speech_prob": 0.00003321393160149455,
        "seek": 228058,
        "start": 2280.94,
        "temperature": 0,
        "text": " Chat's coming back.",
        "tokens": [
          50382,
          27503,
          311,
          1348,
          646,
          13,
          50446
        ]
      },
      {
        "avg_logprob": -0.4327599709494072,
        "compression_ratio": 1.1801801801801801,
        "end": 2283.2599999999998,
        "id": 807,
        "no_speech_prob": 0.00003321393160149455,
        "seek": 228058,
        "start": 2282.22,
        "temperature": 0,
        "text": " The chat's coming back.",
        "tokens": [
          50446,
          440,
          5081,
          311,
          1348,
          646,
          13,
          50498
        ]
      },
      {
        "avg_logprob": -0.4327599709494072,
        "compression_ratio": 1.1801801801801801,
        "end": 2287.38,
        "id": 808,
        "no_speech_prob": 0.00003321393160149455,
        "seek": 228058,
        "start": 2286.1,
        "temperature": 0,
        "text": " Come on, wake up.",
        "tokens": [
          50640,
          2492,
          322,
          11,
          6634,
          493,
          13,
          50704
        ]
      },
      {
        "avg_logprob": -0.4327599709494072,
        "compression_ratio": 1.1801801801801801,
        "end": 2292.94,
        "id": 809,
        "no_speech_prob": 0.00003321393160149455,
        "seek": 228058,
        "start": 2291.98,
        "temperature": 0,
        "text": " 1%, I see.",
        "tokens": [
          50934,
          502,
          8923,
          286,
          536,
          13,
          50982
        ]
      },
      {
        "avg_logprob": -0.4327599709494072,
        "compression_ratio": 1.1801801801801801,
        "end": 2294.54,
        "id": 810,
        "no_speech_prob": 0.00003321393160149455,
        "seek": 228058,
        "start": 2292.94,
        "temperature": 0,
        "text": " I did run out of the battery life.",
        "tokens": [
          50982,
          286,
          630,
          1190,
          484,
          295,
          264,
          5809,
          993,
          13,
          51062
        ]
      },
      {
        "avg_logprob": -0.4327599709494072,
        "compression_ratio": 1.1801801801801801,
        "end": 2299.18,
        "id": 811,
        "no_speech_prob": 0.00003321393160149455,
        "seek": 228058,
        "start": 2297.14,
        "temperature": 0,
        "text": " And now cancel.",
        "tokens": [
          51192,
          400,
          586,
          10373,
          13,
          51294
        ]
      },
      {
        "avg_logprob": -0.4327599709494072,
        "compression_ratio": 1.1801801801801801,
        "end": 2299.68,
        "id": 812,
        "no_speech_prob": 0.00003321393160149455,
        "seek": 228058,
        "start": 2299.18,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51294,
          2264,
          13,
          51319
        ]
      },
      {
        "avg_logprob": -0.4327599709494072,
        "compression_ratio": 1.1801801801801801,
        "end": 2306.7799999999997,
        "id": 813,
        "no_speech_prob": 0.00003321393160149455,
        "seek": 228058,
        "start": 2304.66,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51568,
          2264,
          13,
          51674
        ]
      },
      {
        "avg_logprob": -0.23663003983036165,
        "compression_ratio": 1.4615384615384615,
        "end": 2310.5800000000004,
        "id": 814,
        "no_speech_prob": 0.0032729054801166058,
        "seek": 230678,
        "start": 2306.78,
        "temperature": 0,
        "text": " Everybody, I see a bunch of chat messages.",
        "tokens": [
          50364,
          7646,
          11,
          286,
          536,
          257,
          3840,
          295,
          5081,
          7897,
          13,
          50554
        ]
      },
      {
        "avg_logprob": -0.23663003983036165,
        "compression_ratio": 1.4615384615384615,
        "end": 2313.02,
        "id": 815,
        "no_speech_prob": 0.0032729054801166058,
        "seek": 230678,
        "start": 2310.5800000000004,
        "temperature": 0,
        "text": " Chat is coming back.",
        "tokens": [
          50554,
          27503,
          307,
          1348,
          646,
          13,
          50676
        ]
      },
      {
        "avg_logprob": -0.23663003983036165,
        "compression_ratio": 1.4615384615384615,
        "end": 2313.5400000000004,
        "id": 816,
        "no_speech_prob": 0.0032729054801166058,
        "seek": 230678,
        "start": 2313.02,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50676,
          2264,
          13,
          50702
        ]
      },
      {
        "avg_logprob": -0.23663003983036165,
        "compression_ratio": 1.4615384615384615,
        "end": 2314.82,
        "id": 817,
        "no_speech_prob": 0.0032729054801166058,
        "seek": 230678,
        "start": 2313.5400000000004,
        "temperature": 0,
        "text": " So is everything working OK?",
        "tokens": [
          50702,
          407,
          307,
          1203,
          1364,
          2264,
          30,
          50766
        ]
      },
      {
        "avg_logprob": -0.23663003983036165,
        "compression_ratio": 1.4615384615384615,
        "end": 2317.1400000000003,
        "id": 818,
        "no_speech_prob": 0.0032729054801166058,
        "seek": 230678,
        "start": 2314.82,
        "temperature": 0,
        "text": " You guys can hear me and see me.",
        "tokens": [
          50766,
          509,
          1074,
          393,
          1568,
          385,
          293,
          536,
          385,
          13,
          50882
        ]
      },
      {
        "avg_logprob": -0.23663003983036165,
        "compression_ratio": 1.4615384615384615,
        "end": 2321.26,
        "id": 819,
        "no_speech_prob": 0.0032729054801166058,
        "seek": 230678,
        "start": 2317.1400000000003,
        "temperature": 0,
        "text": " Hopefully, everything is good.",
        "tokens": [
          50882,
          10429,
          11,
          1203,
          307,
          665,
          13,
          51088
        ]
      },
      {
        "avg_logprob": -0.23663003983036165,
        "compression_ratio": 1.4615384615384615,
        "end": 2323.9,
        "id": 820,
        "no_speech_prob": 0.0032729054801166058,
        "seek": 230678,
        "start": 2321.26,
        "temperature": 0,
        "text": " Yeah, no, I'm using Mac OS X. Yes.",
        "tokens": [
          51088,
          865,
          11,
          572,
          11,
          286,
          478,
          1228,
          5707,
          12731,
          1783,
          13,
          1079,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.23663003983036165,
        "compression_ratio": 1.4615384615384615,
        "end": 2324.5,
        "id": 821,
        "no_speech_prob": 0.0032729054801166058,
        "seek": 230678,
        "start": 2323.9,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51220,
          2264,
          13,
          51250
        ]
      },
      {
        "avg_logprob": -0.23663003983036165,
        "compression_ratio": 1.4615384615384615,
        "end": 2326.2200000000003,
        "id": 822,
        "no_speech_prob": 0.0032729054801166058,
        "seek": 230678,
        "start": 2324.5,
        "temperature": 0,
        "text": " All right, so in the next video, I'm",
        "tokens": [
          51250,
          1057,
          558,
          11,
          370,
          294,
          264,
          958,
          960,
          11,
          286,
          478,
          51336
        ]
      },
      {
        "avg_logprob": -0.23663003983036165,
        "compression_ratio": 1.4615384615384615,
        "end": 2327.82,
        "id": 823,
        "no_speech_prob": 0.0032729054801166058,
        "seek": 230678,
        "start": 2326.2200000000003,
        "temperature": 0,
        "text": " going to start talking about route.",
        "tokens": [
          51336,
          516,
          281,
          722,
          1417,
          466,
          7955,
          13,
          51416
        ]
      },
      {
        "avg_logprob": -0.23663003983036165,
        "compression_ratio": 1.4615384615384615,
        "end": 2333.38,
        "id": 824,
        "no_speech_prob": 0.0032729054801166058,
        "seek": 230678,
        "start": 2327.82,
        "temperature": 0,
        "text": " Now, I've got to figure out why it's called REST.",
        "tokens": [
          51416,
          823,
          11,
          286,
          600,
          658,
          281,
          2573,
          484,
          983,
          309,
          311,
          1219,
          497,
          14497,
          13,
          51694
        ]
      },
      {
        "avg_logprob": -0.23663003983036165,
        "compression_ratio": 1.4615384615384615,
        "end": 2334.0600000000004,
        "id": 825,
        "no_speech_prob": 0.0032729054801166058,
        "seek": 230678,
        "start": 2333.38,
        "temperature": 0,
        "text": " So let's look.",
        "tokens": [
          51694,
          407,
          718,
          311,
          574,
          13,
          51728
        ]
      },
      {
        "avg_logprob": -0.23663003983036165,
        "compression_ratio": 1.4615384615384615,
        "end": 2335.98,
        "id": 826,
        "no_speech_prob": 0.0032729054801166058,
        "seek": 230678,
        "start": 2334.0600000000004,
        "temperature": 0,
        "text": " Wikipedia will tell us.",
        "tokens": [
          51728,
          28999,
          486,
          980,
          505,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.26446762705236915,
        "compression_ratio": 1.4979423868312758,
        "end": 2337.18,
        "id": 827,
        "no_speech_prob": 0.0000406945327995345,
        "seek": 233598,
        "start": 2335.98,
        "temperature": 0,
        "text": " This is me.",
        "tokens": [
          50364,
          639,
          307,
          385,
          13,
          50424
        ]
      },
      {
        "avg_logprob": -0.26446762705236915,
        "compression_ratio": 1.4979423868312758,
        "end": 2339.42,
        "id": 828,
        "no_speech_prob": 0.0000406945327995345,
        "seek": 233598,
        "start": 2337.18,
        "temperature": 0,
        "text": " I'm just like, ooh, soap.",
        "tokens": [
          50424,
          286,
          478,
          445,
          411,
          11,
          17024,
          11,
          14587,
          13,
          50536
        ]
      },
      {
        "avg_logprob": -0.26446762705236915,
        "compression_ratio": 1.4979423868312758,
        "end": 2342.42,
        "id": 829,
        "no_speech_prob": 0.0000406945327995345,
        "seek": 233598,
        "start": 2339.42,
        "temperature": 0,
        "text": " I remember there used to be soap.",
        "tokens": [
          50536,
          286,
          1604,
          456,
          1143,
          281,
          312,
          14587,
          13,
          50686
        ]
      },
      {
        "avg_logprob": -0.26446762705236915,
        "compression_ratio": 1.4979423868312758,
        "end": 2343.46,
        "id": 830,
        "no_speech_prob": 0.0000406945327995345,
        "seek": 233598,
        "start": 2342.42,
        "temperature": 0,
        "text": " Soap is a protocol.",
        "tokens": [
          50686,
          407,
          569,
          307,
          257,
          10336,
          13,
          50738
        ]
      },
      {
        "avg_logprob": -0.26446762705236915,
        "compression_ratio": 1.4979423868312758,
        "end": 2345.38,
        "id": 831,
        "no_speech_prob": 0.0000406945327995345,
        "seek": 233598,
        "start": 2343.46,
        "temperature": 0,
        "text": " REST is an architectural style.",
        "tokens": [
          50738,
          497,
          14497,
          307,
          364,
          26621,
          3758,
          13,
          50834
        ]
      },
      {
        "avg_logprob": -0.26446762705236915,
        "compression_ratio": 1.4979423868312758,
        "end": 2346.86,
        "id": 832,
        "no_speech_prob": 0.0000406945327995345,
        "seek": 233598,
        "start": 2345.38,
        "temperature": 0,
        "text": " Why is it called REST, though?",
        "tokens": [
          50834,
          1545,
          307,
          309,
          1219,
          497,
          14497,
          11,
          1673,
          30,
          50908
        ]
      },
      {
        "avg_logprob": -0.26446762705236915,
        "compression_ratio": 1.4979423868312758,
        "end": 2347.94,
        "id": 833,
        "no_speech_prob": 0.0000406945327995345,
        "seek": 233598,
        "start": 2346.86,
        "temperature": 0,
        "text": " And why is it RESTful?",
        "tokens": [
          50908,
          400,
          983,
          307,
          309,
          497,
          14497,
          906,
          30,
          50962
        ]
      },
      {
        "avg_logprob": -0.26446762705236915,
        "compression_ratio": 1.4979423868312758,
        "end": 2353.1,
        "id": 834,
        "no_speech_prob": 0.0000406945327995345,
        "seek": 233598,
        "start": 2347.94,
        "temperature": 0,
        "text": " Stands for Representational State Transfer.",
        "tokens": [
          50962,
          745,
          2967,
          337,
          19945,
          1478,
          4533,
          35025,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.26446762705236915,
        "compression_ratio": 1.4979423868312758,
        "end": 2357.02,
        "id": 835,
        "no_speech_prob": 0.0000406945327995345,
        "seek": 233598,
        "start": 2353.1,
        "temperature": 0,
        "text": " I can't bring myself to read this.",
        "tokens": [
          51220,
          286,
          393,
          380,
          1565,
          2059,
          281,
          1401,
          341,
          13,
          51416
        ]
      },
      {
        "avg_logprob": -0.26446762705236915,
        "compression_ratio": 1.4979423868312758,
        "end": 2360.06,
        "id": 836,
        "no_speech_prob": 0.0000406945327995345,
        "seek": 233598,
        "start": 2357.02,
        "temperature": 0,
        "text": " But architectural client server, stateless.",
        "tokens": [
          51416,
          583,
          26621,
          6423,
          7154,
          11,
          2219,
          4272,
          13,
          51568
        ]
      },
      {
        "avg_logprob": -0.26446762705236915,
        "compression_ratio": 1.4979423868312758,
        "end": 2362.06,
        "id": 837,
        "no_speech_prob": 0.0000406945327995345,
        "seek": 233598,
        "start": 2360.06,
        "temperature": 0,
        "text": " Oh, this is like way too much.",
        "tokens": [
          51568,
          876,
          11,
          341,
          307,
          411,
          636,
          886,
          709,
          13,
          51668
        ]
      },
      {
        "avg_logprob": -0.26446762705236915,
        "compression_ratio": 1.4979423868312758,
        "end": 2365.34,
        "id": 838,
        "no_speech_prob": 0.0000406945327995345,
        "seek": 233598,
        "start": 2362.06,
        "temperature": 0,
        "text": " So I'm going to, let's see, API.",
        "tokens": [
          51668,
          407,
          286,
          478,
          516,
          281,
          11,
          718,
          311,
          536,
          11,
          9362,
          13,
          51832
        ]
      },
      {
        "avg_logprob": -0.3017413943421607,
        "compression_ratio": 1.4615384615384615,
        "end": 2367.02,
        "id": 839,
        "no_speech_prob": 0.00003373719300725497,
        "seek": 236534,
        "start": 2365.34,
        "temperature": 0,
        "text": " Apply to web services.",
        "tokens": [
          50364,
          25264,
          281,
          3670,
          3328,
          13,
          50448
        ]
      },
      {
        "avg_logprob": -0.3017413943421607,
        "compression_ratio": 1.4615384615384615,
        "end": 2369.6600000000003,
        "id": 840,
        "no_speech_prob": 0.00003373719300725497,
        "seek": 236534,
        "start": 2367.02,
        "temperature": 0,
        "text": " Web services adhere to the REST architectural constraints",
        "tokens": [
          50448,
          9573,
          3328,
          33584,
          281,
          264,
          497,
          14497,
          26621,
          18491,
          50580
        ]
      },
      {
        "avg_logprob": -0.3017413943421607,
        "compression_ratio": 1.4615384615384615,
        "end": 2372.94,
        "id": 841,
        "no_speech_prob": 0.00003373719300725497,
        "seek": 236534,
        "start": 2369.6600000000003,
        "temperature": 0,
        "text": " are called RESTful APIs, defined with the following aspects.",
        "tokens": [
          50580,
          366,
          1219,
          497,
          14497,
          906,
          21445,
          11,
          7642,
          365,
          264,
          3480,
          7270,
          13,
          50744
        ]
      },
      {
        "avg_logprob": -0.3017413943421607,
        "compression_ratio": 1.4615384615384615,
        "end": 2375.94,
        "id": 842,
        "no_speech_prob": 0.00003373719300725497,
        "seek": 236534,
        "start": 2372.94,
        "temperature": 0,
        "text": " They have a base URL, an internet media type",
        "tokens": [
          50744,
          814,
          362,
          257,
          3096,
          12905,
          11,
          364,
          4705,
          3021,
          2010,
          50894
        ]
      },
      {
        "avg_logprob": -0.3017413943421607,
        "compression_ratio": 1.4615384615384615,
        "end": 2380.2200000000003,
        "id": 843,
        "no_speech_prob": 0.00003373719300725497,
        "seek": 236534,
        "start": 2375.94,
        "temperature": 0,
        "text": " that defines state transition data elements, URL,",
        "tokens": [
          50894,
          300,
          23122,
          1785,
          6034,
          1412,
          4959,
          11,
          12905,
          11,
          51108
        ]
      },
      {
        "avg_logprob": -0.3017413943421607,
        "compression_ratio": 1.4615384615384615,
        "end": 2381.7000000000003,
        "id": 844,
        "no_speech_prob": 0.00003373719300725497,
        "seek": 236534,
        "start": 2380.2200000000003,
        "temperature": 0,
        "text": " standard HTTP methods.",
        "tokens": [
          51108,
          3832,
          33283,
          7150,
          13,
          51182
        ]
      },
      {
        "avg_logprob": -0.3017413943421607,
        "compression_ratio": 1.4615384615384615,
        "end": 2382.9,
        "id": 845,
        "no_speech_prob": 0.00003373719300725497,
        "seek": 236534,
        "start": 2381.7000000000003,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51182,
          1057,
          558,
          13,
          51242
        ]
      },
      {
        "avg_logprob": -0.3017413943421607,
        "compression_ratio": 1.4615384615384615,
        "end": 2384.78,
        "id": 846,
        "no_speech_prob": 0.00003373719300725497,
        "seek": 236534,
        "start": 2382.9,
        "temperature": 0,
        "text": " Get, put.",
        "tokens": [
          51242,
          3240,
          11,
          829,
          13,
          51336
        ]
      },
      {
        "avg_logprob": -0.3017413943421607,
        "compression_ratio": 1.4615384615384615,
        "end": 2387.6600000000003,
        "id": 847,
        "no_speech_prob": 0.00003373719300725497,
        "seek": 236534,
        "start": 2384.78,
        "temperature": 0,
        "text": " Yeah, yeah, this makes sense to me.",
        "tokens": [
          51336,
          865,
          11,
          1338,
          11,
          341,
          1669,
          2020,
          281,
          385,
          13,
          51480
        ]
      },
      {
        "avg_logprob": -0.3017413943421607,
        "compression_ratio": 1.4615384615384615,
        "end": 2388.1600000000003,
        "id": 848,
        "no_speech_prob": 0.00003373719300725497,
        "seek": 236534,
        "start": 2387.6600000000003,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51480,
          2264,
          13,
          51505
        ]
      },
      {
        "avg_logprob": -0.3017413943421607,
        "compression_ratio": 1.4615384615384615,
        "end": 2394.86,
        "id": 849,
        "no_speech_prob": 0.00003373719300725497,
        "seek": 236534,
        "start": 2390.94,
        "temperature": 0,
        "text": " So what's the chance that I can remember",
        "tokens": [
          51644,
          407,
          437,
          311,
          264,
          2931,
          300,
          286,
          393,
          1604,
          51840
        ]
      },
      {
        "avg_logprob": -0.2973077080466531,
        "compression_ratio": 1.3333333333333333,
        "end": 2398.46,
        "id": 850,
        "no_speech_prob": 0.000028409684091457166,
        "seek": 239486,
        "start": 2394.86,
        "temperature": 0,
        "text": " representational state transfer?",
        "tokens": [
          50364,
          2906,
          1478,
          1785,
          5003,
          30,
          50544
        ]
      },
      {
        "avg_logprob": -0.2973077080466531,
        "compression_ratio": 1.3333333333333333,
        "end": 2399.02,
        "id": 851,
        "no_speech_prob": 0.000028409684091457166,
        "seek": 239486,
        "start": 2398.46,
        "temperature": 0,
        "text": " Whatever.",
        "tokens": [
          50544,
          8541,
          13,
          50572
        ]
      },
      {
        "avg_logprob": -0.2973077080466531,
        "compression_ratio": 1.3333333333333333,
        "end": 2399.52,
        "id": 852,
        "no_speech_prob": 0.000028409684091457166,
        "seek": 239486,
        "start": 2399.02,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50572,
          2264,
          13,
          50597
        ]
      },
      {
        "avg_logprob": -0.2973077080466531,
        "compression_ratio": 1.3333333333333333,
        "end": 2403.3,
        "id": 853,
        "no_speech_prob": 0.000028409684091457166,
        "seek": 239486,
        "start": 2399.52,
        "temperature": 0,
        "text": " So now what we're going to do is I'm here.",
        "tokens": [
          50597,
          407,
          586,
          437,
          321,
          434,
          516,
          281,
          360,
          307,
          286,
          478,
          510,
          13,
          50786
        ]
      },
      {
        "avg_logprob": -0.2973077080466531,
        "compression_ratio": 1.3333333333333333,
        "end": 2410.1,
        "id": 854,
        "no_speech_prob": 0.000028409684091457166,
        "seek": 239486,
        "start": 2403.3,
        "temperature": 0,
        "text": " And I am going to start talking about RESTian, RESTful,",
        "tokens": [
          50786,
          400,
          286,
          669,
          516,
          281,
          722,
          1417,
          466,
          497,
          14497,
          952,
          11,
          497,
          14497,
          906,
          11,
          51126
        ]
      },
      {
        "avg_logprob": -0.2973077080466531,
        "compression_ratio": 1.3333333333333333,
        "end": 2411.06,
        "id": 855,
        "no_speech_prob": 0.000028409684091457166,
        "seek": 239486,
        "start": 2410.1,
        "temperature": 0,
        "text": " RESTful routes.",
        "tokens": [
          51126,
          497,
          14497,
          906,
          18242,
          13,
          51174
        ]
      },
      {
        "avg_logprob": -0.2973077080466531,
        "compression_ratio": 1.3333333333333333,
        "end": 2423.1800000000003,
        "id": 856,
        "no_speech_prob": 0.000028409684091457166,
        "seek": 239486,
        "start": 2419.6600000000003,
        "temperature": 0,
        "text": " And I'm cycling these cameras.",
        "tokens": [
          51604,
          400,
          286,
          478,
          22425,
          613,
          8622,
          13,
          51780
        ]
      },
      {
        "avg_logprob": -0.32689828139085036,
        "compression_ratio": 1.4533333333333334,
        "end": 2425.7799999999997,
        "id": 857,
        "no_speech_prob": 0.00008614610123913735,
        "seek": 242318,
        "start": 2423.18,
        "temperature": 0,
        "text": " I really hope that we can kind of get,",
        "tokens": [
          50364,
          286,
          534,
          1454,
          300,
          321,
          393,
          733,
          295,
          483,
          11,
          50494
        ]
      },
      {
        "avg_logprob": -0.32689828139085036,
        "compression_ratio": 1.4533333333333334,
        "end": 2427.2999999999997,
        "id": 858,
        "no_speech_prob": 0.00008614610123913735,
        "seek": 242318,
        "start": 2425.7799999999997,
        "temperature": 0,
        "text": " still got 45 minutes today.",
        "tokens": [
          50494,
          920,
          658,
          6905,
          2077,
          965,
          13,
          50570
        ]
      },
      {
        "avg_logprob": -0.32689828139085036,
        "compression_ratio": 1.4533333333333334,
        "end": 2429.06,
        "id": 859,
        "no_speech_prob": 0.00008614610123913735,
        "seek": 242318,
        "start": 2427.2999999999997,
        "temperature": 0,
        "text": " So I think there's a good chance of getting",
        "tokens": [
          50570,
          407,
          286,
          519,
          456,
          311,
          257,
          665,
          2931,
          295,
          1242,
          50658
        ]
      },
      {
        "avg_logprob": -0.32689828139085036,
        "compression_ratio": 1.4533333333333334,
        "end": 2430.8999999999996,
        "id": 860,
        "no_speech_prob": 0.00008614610123913735,
        "seek": 242318,
        "start": 2429.06,
        "temperature": 0,
        "text": " through a decent amount of material,",
        "tokens": [
          50658,
          807,
          257,
          8681,
          2372,
          295,
          2527,
          11,
          50750
        ]
      },
      {
        "avg_logprob": -0.32689828139085036,
        "compression_ratio": 1.4533333333333334,
        "end": 2432.2599999999998,
        "id": 861,
        "no_speech_prob": 0.00008614610123913735,
        "seek": 242318,
        "start": 2430.8999999999996,
        "temperature": 0,
        "text": " but certainly not everything.",
        "tokens": [
          50750,
          457,
          3297,
          406,
          1203,
          13,
          50818
        ]
      },
      {
        "avg_logprob": -0.32689828139085036,
        "compression_ratio": 1.4533333333333334,
        "end": 2433.22,
        "id": 862,
        "no_speech_prob": 0.00008614610123913735,
        "seek": 242318,
        "start": 2432.2599999999998,
        "temperature": 0,
        "text": " OK, here we go.",
        "tokens": [
          50818,
          2264,
          11,
          510,
          321,
          352,
          13,
          50866
        ]
      },
      {
        "avg_logprob": -0.32689828139085036,
        "compression_ratio": 1.4533333333333334,
        "end": 2441.4199999999996,
        "id": 863,
        "no_speech_prob": 0.00008614610123913735,
        "seek": 242318,
        "start": 2440.4199999999996,
        "temperature": 0,
        "text": " I'm ready.",
        "tokens": [
          51226,
          286,
          478,
          1919,
          13,
          51276
        ]
      },
      {
        "avg_logprob": -0.32689828139085036,
        "compression_ratio": 1.4533333333333334,
        "end": 2442.4199999999996,
        "id": 864,
        "no_speech_prob": 0.00008614610123913735,
        "seek": 242318,
        "start": 2441.4199999999996,
        "temperature": 0,
        "text": " I'm going to start.",
        "tokens": [
          51276,
          286,
          478,
          516,
          281,
          722,
          13,
          51326
        ]
      },
      {
        "avg_logprob": -0.32689828139085036,
        "compression_ratio": 1.4533333333333334,
        "end": 2442.9199999999996,
        "id": 865,
        "no_speech_prob": 0.00008614610123913735,
        "seek": 242318,
        "start": 2442.4199999999996,
        "temperature": 0,
        "text": " Ah!",
        "tokens": [
          51326,
          2438,
          0,
          51351
        ]
      },
      {
        "avg_logprob": -0.32689828139085036,
        "compression_ratio": 1.4533333333333334,
        "end": 2449.7,
        "id": 866,
        "no_speech_prob": 0.00008614610123913735,
        "seek": 242318,
        "start": 2446.46,
        "temperature": 0,
        "text": " In the previous video, I made a simple little web server.",
        "tokens": [
          51528,
          682,
          264,
          3894,
          960,
          11,
          286,
          1027,
          257,
          2199,
          707,
          3670,
          7154,
          13,
          51690
        ]
      },
      {
        "avg_logprob": -0.32689828139085036,
        "compression_ratio": 1.4533333333333334,
        "end": 2451.8999999999996,
        "id": 867,
        "no_speech_prob": 0.00008614610123913735,
        "seek": 242318,
        "start": 2449.7,
        "temperature": 0,
        "text": " It's like only got this much code in it.",
        "tokens": [
          51690,
          467,
          311,
          411,
          787,
          658,
          341,
          709,
          3089,
          294,
          309,
          13,
          51800
        ]
      },
      {
        "avg_logprob": -0.25567842839838384,
        "compression_ratio": 1.5049019607843137,
        "end": 2457.9,
        "id": 868,
        "no_speech_prob": 0.000038831010897411034,
        "seek": 245190,
        "start": 2451.9,
        "temperature": 0,
        "text": " And all it does is, never mind.",
        "tokens": [
          50364,
          400,
          439,
          309,
          775,
          307,
          11,
          1128,
          1575,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.25567842839838384,
        "compression_ratio": 1.5049019607843137,
        "end": 2458.58,
        "id": 869,
        "no_speech_prob": 0.000038831010897411034,
        "seek": 245190,
        "start": 2457.9,
        "temperature": 0,
        "text": " Let me start over.",
        "tokens": [
          50664,
          961,
          385,
          722,
          670,
          13,
          50698
        ]
      },
      {
        "avg_logprob": -0.25567842839838384,
        "compression_ratio": 1.5049019607843137,
        "end": 2465.6600000000003,
        "id": 870,
        "no_speech_prob": 0.000038831010897411034,
        "seek": 245190,
        "start": 2463.02,
        "temperature": 0,
        "text": " In the previous video, I used Node and a Node package",
        "tokens": [
          50920,
          682,
          264,
          3894,
          960,
          11,
          286,
          1143,
          38640,
          293,
          257,
          38640,
          7372,
          51052
        ]
      },
      {
        "avg_logprob": -0.25567842839838384,
        "compression_ratio": 1.5049019607843137,
        "end": 2468.6800000000003,
        "id": 871,
        "no_speech_prob": 0.000038831010897411034,
        "seek": 245190,
        "start": 2465.6600000000003,
        "temperature": 0,
        "text": " called Express to make a very simple web server.",
        "tokens": [
          51052,
          1219,
          20212,
          281,
          652,
          257,
          588,
          2199,
          3670,
          7154,
          13,
          51203
        ]
      },
      {
        "avg_logprob": -0.25567842839838384,
        "compression_ratio": 1.5049019607843137,
        "end": 2473.08,
        "id": 872,
        "no_speech_prob": 0.000038831010897411034,
        "seek": 245190,
        "start": 2468.6800000000003,
        "temperature": 0,
        "text": " All it does is it spins up a server listening on port 3000.",
        "tokens": [
          51203,
          1057,
          309,
          775,
          307,
          309,
          31587,
          493,
          257,
          7154,
          4764,
          322,
          2436,
          20984,
          13,
          51423
        ]
      },
      {
        "avg_logprob": -0.25567842839838384,
        "compression_ratio": 1.5049019607843137,
        "end": 2478.3,
        "id": 873,
        "no_speech_prob": 0.000038831010897411034,
        "seek": 245190,
        "start": 2473.08,
        "temperature": 0,
        "text": " And if I run it, it looks, it serves up",
        "tokens": [
          51423,
          400,
          498,
          286,
          1190,
          309,
          11,
          309,
          1542,
          11,
          309,
          13451,
          493,
          51684
        ]
      },
      {
        "avg_logprob": -0.25567842839838384,
        "compression_ratio": 1.5049019607843137,
        "end": 2481.06,
        "id": 874,
        "no_speech_prob": 0.000038831010897411034,
        "seek": 245190,
        "start": 2478.3,
        "temperature": 0,
        "text": " anything that's in this directory called website.",
        "tokens": [
          51684,
          1340,
          300,
          311,
          294,
          341,
          21120,
          1219,
          3144,
          13,
          51822
        ]
      },
      {
        "avg_logprob": -0.25567842839838384,
        "compression_ratio": 1.5049019607843137,
        "end": 2481.78,
        "id": 875,
        "no_speech_prob": 0.000038831010897411034,
        "seek": 245190,
        "start": 2481.06,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51822,
          2264,
          13,
          51858
        ]
      },
      {
        "avg_logprob": -0.2321182630076912,
        "compression_ratio": 1.7235494880546076,
        "end": 2483.32,
        "id": 876,
        "no_speech_prob": 0.0005442049587145448,
        "seek": 248178,
        "start": 2481.78,
        "temperature": 0,
        "text": " And in that directory called website",
        "tokens": [
          50364,
          400,
          294,
          300,
          21120,
          1219,
          3144,
          50441
        ]
      },
      {
        "avg_logprob": -0.2321182630076912,
        "compression_ratio": 1.7235494880546076,
        "end": 2485.6600000000003,
        "id": 877,
        "no_speech_prob": 0.0005442049587145448,
        "seek": 248178,
        "start": 2483.32,
        "temperature": 0,
        "text": " is a little index.html file that says this.",
        "tokens": [
          50441,
          307,
          257,
          707,
          8186,
          13,
          357,
          15480,
          3991,
          300,
          1619,
          341,
          13,
          50558
        ]
      },
      {
        "avg_logprob": -0.2321182630076912,
        "compression_ratio": 1.7235494880546076,
        "end": 2488.6200000000003,
        "id": 878,
        "no_speech_prob": 0.0005442049587145448,
        "seek": 248178,
        "start": 2485.6600000000003,
        "temperature": 0,
        "text": " And now I see that in the web page.",
        "tokens": [
          50558,
          400,
          586,
          286,
          536,
          300,
          294,
          264,
          3670,
          3028,
          13,
          50706
        ]
      },
      {
        "avg_logprob": -0.2321182630076912,
        "compression_ratio": 1.7235494880546076,
        "end": 2489.6200000000003,
        "id": 879,
        "no_speech_prob": 0.0005442049587145448,
        "seek": 248178,
        "start": 2488.6200000000003,
        "temperature": 0,
        "text": " In the web page.",
        "tokens": [
          50706,
          682,
          264,
          3670,
          3028,
          13,
          50756
        ]
      },
      {
        "avg_logprob": -0.2321182630076912,
        "compression_ratio": 1.7235494880546076,
        "end": 2490.98,
        "id": 880,
        "no_speech_prob": 0.0005442049587145448,
        "seek": 248178,
        "start": 2489.6200000000003,
        "temperature": 0,
        "text": " I don't know if that even makes sense.",
        "tokens": [
          50756,
          286,
          500,
          380,
          458,
          498,
          300,
          754,
          1669,
          2020,
          13,
          50824
        ]
      },
      {
        "avg_logprob": -0.2321182630076912,
        "compression_ratio": 1.7235494880546076,
        "end": 2492.78,
        "id": 881,
        "no_speech_prob": 0.0005442049587145448,
        "seek": 248178,
        "start": 2490.98,
        "temperature": 0,
        "text": " OK, so what do I want to add to it?",
        "tokens": [
          50824,
          2264,
          11,
          370,
          437,
          360,
          286,
          528,
          281,
          909,
          281,
          309,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.2321182630076912,
        "compression_ratio": 1.7235494880546076,
        "end": 2497.1400000000003,
        "id": 882,
        "no_speech_prob": 0.0005442049587145448,
        "seek": 248178,
        "start": 2492.78,
        "temperature": 0,
        "text": " The goal of this video series is to make an API.",
        "tokens": [
          50914,
          440,
          3387,
          295,
          341,
          960,
          2638,
          307,
          281,
          652,
          364,
          9362,
          13,
          51132
        ]
      },
      {
        "avg_logprob": -0.2321182630076912,
        "compression_ratio": 1.7235494880546076,
        "end": 2499.7000000000003,
        "id": 883,
        "no_speech_prob": 0.0005442049587145448,
        "seek": 248178,
        "start": 2497.1400000000003,
        "temperature": 0,
        "text": " Now, there are a lot of different ways, and styles,",
        "tokens": [
          51132,
          823,
          11,
          456,
          366,
          257,
          688,
          295,
          819,
          2098,
          11,
          293,
          13273,
          11,
          51260
        ]
      },
      {
        "avg_logprob": -0.2321182630076912,
        "compression_ratio": 1.7235494880546076,
        "end": 2502.5800000000004,
        "id": 884,
        "no_speech_prob": 0.0005442049587145448,
        "seek": 248178,
        "start": 2499.7000000000003,
        "temperature": 0,
        "text": " and flavors, and designs, and kinds of ways",
        "tokens": [
          51260,
          293,
          16303,
          11,
          293,
          11347,
          11,
          293,
          3685,
          295,
          2098,
          51404
        ]
      },
      {
        "avg_logprob": -0.2321182630076912,
        "compression_ratio": 1.7235494880546076,
        "end": 2504.38,
        "id": 885,
        "no_speech_prob": 0.0005442049587145448,
        "seek": 248178,
        "start": 2502.5800000000004,
        "temperature": 0,
        "text": " you could make an API, I'm sure.",
        "tokens": [
          51404,
          291,
          727,
          652,
          364,
          9362,
          11,
          286,
          478,
          988,
          13,
          51494
        ]
      },
      {
        "avg_logprob": -0.2321182630076912,
        "compression_ratio": 1.7235494880546076,
        "end": 2507.9,
        "id": 886,
        "no_speech_prob": 0.0005442049587145448,
        "seek": 248178,
        "start": 2504.38,
        "temperature": 0,
        "text": " And the kind of API I'm going to show you is a RESTful API.",
        "tokens": [
          51494,
          400,
          264,
          733,
          295,
          9362,
          286,
          478,
          516,
          281,
          855,
          291,
          307,
          257,
          497,
          14497,
          906,
          9362,
          13,
          51670
        ]
      },
      {
        "avg_logprob": -0.2321182630076912,
        "compression_ratio": 1.7235494880546076,
        "end": 2510.3,
        "id": 887,
        "no_speech_prob": 0.0005442049587145448,
        "seek": 248178,
        "start": 2507.9,
        "temperature": 0,
        "text": " And I like to call it, I like the idea of it being RESTful",
        "tokens": [
          51670,
          400,
          286,
          411,
          281,
          818,
          309,
          11,
          286,
          411,
          264,
          1558,
          295,
          309,
          885,
          497,
          14497,
          906,
          51790
        ]
      },
      {
        "avg_logprob": -0.30412988309507016,
        "compression_ratio": 1.5245901639344261,
        "end": 2513.02,
        "id": 888,
        "no_speech_prob": 0.00003480785744613968,
        "seek": 251030,
        "start": 2510.3,
        "temperature": 0,
        "text": " because I want it to be relaxing, and enjoyable,",
        "tokens": [
          50364,
          570,
          286,
          528,
          309,
          281,
          312,
          20103,
          11,
          293,
          20305,
          11,
          50500
        ]
      },
      {
        "avg_logprob": -0.30412988309507016,
        "compression_ratio": 1.5245901639344261,
        "end": 2515.78,
        "id": 889,
        "no_speech_prob": 0.00003480785744613968,
        "seek": 251030,
        "start": 2513.02,
        "temperature": 0,
        "text": " a soothing API.",
        "tokens": [
          50500,
          257,
          40704,
          9362,
          13,
          50638
        ]
      },
      {
        "avg_logprob": -0.30412988309507016,
        "compression_ratio": 1.5245901639344261,
        "end": 2522.6600000000003,
        "id": 890,
        "no_speech_prob": 0.00003480785744613968,
        "seek": 251030,
        "start": 2515.78,
        "temperature": 0,
        "text": " But REST is essentially like a style, so to speak, of how,",
        "tokens": [
          50638,
          583,
          497,
          14497,
          307,
          4476,
          411,
          257,
          3758,
          11,
          370,
          281,
          1710,
          11,
          295,
          577,
          11,
          50982
        ]
      },
      {
        "avg_logprob": -0.30412988309507016,
        "compression_ratio": 1.5245901639344261,
        "end": 2523.46,
        "id": 891,
        "no_speech_prob": 0.00003480785744613968,
        "seek": 251030,
        "start": 2522.6600000000003,
        "temperature": 0,
        "text": " it's a broader term.",
        "tokens": [
          50982,
          309,
          311,
          257,
          13227,
          1433,
          13,
          51022
        ]
      },
      {
        "avg_logprob": -0.30412988309507016,
        "compression_ratio": 1.5245901639344261,
        "end": 2526.1400000000003,
        "id": 892,
        "no_speech_prob": 0.00003480785744613968,
        "seek": 251030,
        "start": 2523.46,
        "temperature": 0,
        "text": " It stands for representational state transfer.",
        "tokens": [
          51022,
          467,
          7382,
          337,
          2906,
          1478,
          1785,
          5003,
          13,
          51156
        ]
      },
      {
        "avg_logprob": -0.30412988309507016,
        "compression_ratio": 1.5245901639344261,
        "end": 2527.94,
        "id": 893,
        "no_speech_prob": 0.00003480785744613968,
        "seek": 251030,
        "start": 2526.1400000000003,
        "temperature": 0,
        "text": " It's a link to the Wikipedia page,",
        "tokens": [
          51156,
          467,
          311,
          257,
          2113,
          281,
          264,
          28999,
          3028,
          11,
          51246
        ]
      },
      {
        "avg_logprob": -0.30412988309507016,
        "compression_ratio": 1.5245901639344261,
        "end": 2529.3,
        "id": 894,
        "no_speech_prob": 0.00003480785744613968,
        "seek": 251030,
        "start": 2527.94,
        "temperature": 0,
        "text": " and you can read all about it.",
        "tokens": [
          51246,
          293,
          291,
          393,
          1401,
          439,
          466,
          309,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.30412988309507016,
        "compression_ratio": 1.5245901639344261,
        "end": 2533.46,
        "id": 895,
        "no_speech_prob": 0.00003480785744613968,
        "seek": 251030,
        "start": 2529.3,
        "temperature": 0,
        "text": " But it's really a style by which users of the API",
        "tokens": [
          51314,
          583,
          309,
          311,
          534,
          257,
          3758,
          538,
          597,
          5022,
          295,
          264,
          9362,
          51522
        ]
      },
      {
        "avg_logprob": -0.30412988309507016,
        "compression_ratio": 1.5245901639344261,
        "end": 2537.7000000000003,
        "id": 896,
        "no_speech_prob": 0.00003480785744613968,
        "seek": 251030,
        "start": 2533.46,
        "temperature": 0,
        "text": " can make GET requests and receive information back",
        "tokens": [
          51522,
          393,
          652,
          28091,
          12475,
          293,
          4774,
          1589,
          646,
          51734
        ]
      },
      {
        "avg_logprob": -0.30412988309507016,
        "compression_ratio": 1.5245901639344261,
        "end": 2538.86,
        "id": 897,
        "no_speech_prob": 0.00003480785744613968,
        "seek": 251030,
        "start": 2537.7000000000003,
        "temperature": 0,
        "text": " from the API.",
        "tokens": [
          51734,
          490,
          264,
          9362,
          13,
          51792
        ]
      },
      {
        "avg_logprob": -0.27399291366827294,
        "compression_ratio": 1.7053941908713692,
        "end": 2541.94,
        "id": 898,
        "no_speech_prob": 0.00028240602114237845,
        "seek": 253886,
        "start": 2538.9,
        "temperature": 0,
        "text": " And let me try to describe the basics of how it looks",
        "tokens": [
          50366,
          400,
          718,
          385,
          853,
          281,
          6786,
          264,
          14688,
          295,
          577,
          309,
          1542,
          50518
        ]
      },
      {
        "avg_logprob": -0.27399291366827294,
        "compression_ratio": 1.7053941908713692,
        "end": 2542.7400000000002,
        "id": 899,
        "no_speech_prob": 0.00028240602114237845,
        "seek": 253886,
        "start": 2541.94,
        "temperature": 0,
        "text": " and works.",
        "tokens": [
          50518,
          293,
          1985,
          13,
          50558
        ]
      },
      {
        "avg_logprob": -0.27399291366827294,
        "compression_ratio": 1.7053941908713692,
        "end": 2545.38,
        "id": 900,
        "no_speech_prob": 0.00028240602114237845,
        "seek": 253886,
        "start": 2542.7400000000002,
        "temperature": 0,
        "text": " So I'm going to erase all of my diagrams",
        "tokens": [
          50558,
          407,
          286,
          478,
          516,
          281,
          23525,
          439,
          295,
          452,
          36709,
          50690
        ]
      },
      {
        "avg_logprob": -0.27399291366827294,
        "compression_ratio": 1.7053941908713692,
        "end": 2547.86,
        "id": 901,
        "no_speech_prob": 0.00028240602114237845,
        "seek": 253886,
        "start": 2545.38,
        "temperature": 0,
        "text": " from some other previous video, and let's",
        "tokens": [
          50690,
          490,
          512,
          661,
          3894,
          960,
          11,
          293,
          718,
          311,
          50814
        ]
      },
      {
        "avg_logprob": -0.27399291366827294,
        "compression_ratio": 1.7053941908713692,
        "end": 2549.34,
        "id": 902,
        "no_speech_prob": 0.00028240602114237845,
        "seek": 253886,
        "start": 2547.86,
        "temperature": 0,
        "text": " think about what's happening.",
        "tokens": [
          50814,
          519,
          466,
          437,
          311,
          2737,
          13,
          50888
        ]
      },
      {
        "avg_logprob": -0.27399291366827294,
        "compression_ratio": 1.7053941908713692,
        "end": 2554.42,
        "id": 903,
        "no_speech_prob": 0.00028240602114237845,
        "seek": 253886,
        "start": 2549.34,
        "temperature": 0,
        "text": " So let's say you're making an API about flowers.",
        "tokens": [
          50888,
          407,
          718,
          311,
          584,
          291,
          434,
          1455,
          364,
          9362,
          466,
          8085,
          13,
          51142
        ]
      },
      {
        "avg_logprob": -0.27399291366827294,
        "compression_ratio": 1.7053941908713692,
        "end": 2555.6600000000003,
        "id": 904,
        "no_speech_prob": 0.00028240602114237845,
        "seek": 253886,
        "start": 2554.42,
        "temperature": 0,
        "text": " Maybe it's about rainbows.",
        "tokens": [
          51142,
          2704,
          309,
          311,
          466,
          4830,
          21118,
          13,
          51204
        ]
      },
      {
        "avg_logprob": -0.27399291366827294,
        "compression_ratio": 1.7053941908713692,
        "end": 2557.34,
        "id": 905,
        "no_speech_prob": 0.00028240602114237845,
        "seek": 253886,
        "start": 2555.6600000000003,
        "temperature": 0,
        "text": " Maybe it's about rainbows, but flowers,",
        "tokens": [
          51204,
          2704,
          309,
          311,
          466,
          4830,
          21118,
          11,
          457,
          8085,
          11,
          51288
        ]
      },
      {
        "avg_logprob": -0.27399291366827294,
        "compression_ratio": 1.7053941908713692,
        "end": 2559.26,
        "id": 906,
        "no_speech_prob": 0.00028240602114237845,
        "seek": 253886,
        "start": 2557.34,
        "temperature": 0,
        "text": " I'm going to use flowers right now.",
        "tokens": [
          51288,
          286,
          478,
          516,
          281,
          764,
          8085,
          558,
          586,
          13,
          51384
        ]
      },
      {
        "avg_logprob": -0.27399291366827294,
        "compression_ratio": 1.7053941908713692,
        "end": 2563.1,
        "id": 907,
        "no_speech_prob": 0.00028240602114237845,
        "seek": 253886,
        "start": 2559.26,
        "temperature": 0,
        "text": " Flowers API dot com.",
        "tokens": [
          51384,
          48194,
          9362,
          5893,
          395,
          13,
          51576
        ]
      },
      {
        "avg_logprob": -0.27399291366827294,
        "compression_ratio": 1.7053941908713692,
        "end": 2567.7400000000002,
        "id": 908,
        "no_speech_prob": 0.00028240602114237845,
        "seek": 253886,
        "start": 2563.1,
        "temperature": 0,
        "text": " So HTTP, this is your website, your web server, your domain,",
        "tokens": [
          51576,
          407,
          33283,
          11,
          341,
          307,
          428,
          3144,
          11,
          428,
          3670,
          7154,
          11,
          428,
          9274,
          11,
          51808
        ]
      },
      {
        "avg_logprob": -0.24096618160124747,
        "compression_ratio": 1.7113821138211383,
        "end": 2569.2999999999997,
        "id": 909,
        "no_speech_prob": 0.00005475961370393634,
        "seek": 256774,
        "start": 2567.74,
        "temperature": 0,
        "text": " all that stuff.",
        "tokens": [
          50364,
          439,
          300,
          1507,
          13,
          50442
        ]
      },
      {
        "avg_logprob": -0.24096618160124747,
        "compression_ratio": 1.7113821138211383,
        "end": 2571.8999999999996,
        "id": 910,
        "no_speech_prob": 0.00005475961370393634,
        "seek": 256774,
        "start": 2569.2999999999997,
        "temperature": 0,
        "text": " You might go to flowers API dot com,",
        "tokens": [
          50442,
          509,
          1062,
          352,
          281,
          8085,
          9362,
          5893,
          395,
          11,
          50572
        ]
      },
      {
        "avg_logprob": -0.24096618160124747,
        "compression_ratio": 1.7113821138211383,
        "end": 2574.5,
        "id": 911,
        "no_speech_prob": 0.00005475961370393634,
        "seek": 256774,
        "start": 2571.8999999999996,
        "temperature": 0,
        "text": " and you will see the index.html page that's there.",
        "tokens": [
          50572,
          293,
          291,
          486,
          536,
          264,
          8186,
          13,
          357,
          15480,
          3028,
          300,
          311,
          456,
          13,
          50702
        ]
      },
      {
        "avg_logprob": -0.24096618160124747,
        "compression_ratio": 1.7113821138211383,
        "end": 2576.9799999999996,
        "id": 912,
        "no_speech_prob": 0.00005475961370393634,
        "seek": 256774,
        "start": 2574.5,
        "temperature": 0,
        "text": " That's the web server we've written.",
        "tokens": [
          50702,
          663,
          311,
          264,
          3670,
          7154,
          321,
          600,
          3720,
          13,
          50826
        ]
      },
      {
        "avg_logprob": -0.24096618160124747,
        "compression_ratio": 1.7113821138211383,
        "end": 2581.18,
        "id": 913,
        "no_speech_prob": 0.00005475961370393634,
        "seek": 256774,
        "start": 2576.9799999999996,
        "temperature": 0,
        "text": " You might go and say, slash, about.",
        "tokens": [
          50826,
          509,
          1062,
          352,
          293,
          584,
          11,
          17330,
          11,
          466,
          13,
          51036
        ]
      },
      {
        "avg_logprob": -0.24096618160124747,
        "compression_ratio": 1.7113821138211383,
        "end": 2584.22,
        "id": 914,
        "no_speech_prob": 0.00005475961370393634,
        "seek": 256774,
        "start": 2581.18,
        "temperature": 0,
        "text": " And maybe, actually, you have in your website directory,",
        "tokens": [
          51036,
          400,
          1310,
          11,
          767,
          11,
          291,
          362,
          294,
          428,
          3144,
          21120,
          11,
          51188
        ]
      },
      {
        "avg_logprob": -0.24096618160124747,
        "compression_ratio": 1.7113821138211383,
        "end": 2586.2599999999998,
        "id": 915,
        "no_speech_prob": 0.00005475961370393634,
        "seek": 256774,
        "start": 2584.22,
        "temperature": 0,
        "text": " your public directory, a folder called about,",
        "tokens": [
          51188,
          428,
          1908,
          21120,
          11,
          257,
          10820,
          1219,
          466,
          11,
          51290
        ]
      },
      {
        "avg_logprob": -0.24096618160124747,
        "compression_ratio": 1.7113821138211383,
        "end": 2588.1,
        "id": 916,
        "no_speech_prob": 0.00005475961370393634,
        "seek": 256774,
        "start": 2586.2599999999998,
        "temperature": 0,
        "text": " with another index.html file.",
        "tokens": [
          51290,
          365,
          1071,
          8186,
          13,
          357,
          15480,
          3991,
          13,
          51382
        ]
      },
      {
        "avg_logprob": -0.24096618160124747,
        "compression_ratio": 1.7113821138211383,
        "end": 2589.8599999999997,
        "id": 917,
        "no_speech_prob": 0.00005475961370393634,
        "seek": 256774,
        "start": 2588.1,
        "temperature": 0,
        "text": " And when you go there, you see that one.",
        "tokens": [
          51382,
          400,
          562,
          291,
          352,
          456,
          11,
          291,
          536,
          300,
          472,
          13,
          51470
        ]
      },
      {
        "avg_logprob": -0.24096618160124747,
        "compression_ratio": 1.7113821138211383,
        "end": 2593.22,
        "id": 918,
        "no_speech_prob": 0.00005475961370393634,
        "seek": 256774,
        "start": 2589.8599999999997,
        "temperature": 0,
        "text": " So this idea of paths with slashes",
        "tokens": [
          51470,
          407,
          341,
          1558,
          295,
          14518,
          365,
          1061,
          12808,
          51638
        ]
      },
      {
        "avg_logprob": -0.24096618160124747,
        "compression_ratio": 1.7113821138211383,
        "end": 2595.3799999999997,
        "id": 919,
        "no_speech_prob": 0.00005475961370393634,
        "seek": 256774,
        "start": 2593.22,
        "temperature": 0,
        "text": " is something that you typically see",
        "tokens": [
          51638,
          307,
          746,
          300,
          291,
          5850,
          536,
          51746
        ]
      },
      {
        "avg_logprob": -0.2404343741280692,
        "compression_ratio": 1.440217391304348,
        "end": 2599.6600000000003,
        "id": 920,
        "no_speech_prob": 0.0006878498825244606,
        "seek": 259538,
        "start": 2595.42,
        "temperature": 0,
        "text": " to navigate through directories of a website.",
        "tokens": [
          50366,
          281,
          12350,
          807,
          5391,
          530,
          295,
          257,
          3144,
          13,
          50578
        ]
      },
      {
        "avg_logprob": -0.2404343741280692,
        "compression_ratio": 1.440217391304348,
        "end": 2604.1800000000003,
        "id": 921,
        "no_speech_prob": 0.0006878498825244606,
        "seek": 259538,
        "start": 2599.6600000000003,
        "temperature": 0,
        "text": " However, these slashes and the things in here",
        "tokens": [
          50578,
          2908,
          11,
          613,
          1061,
          12808,
          293,
          264,
          721,
          294,
          510,
          50804
        ]
      },
      {
        "avg_logprob": -0.2404343741280692,
        "compression_ratio": 1.440217391304348,
        "end": 2606.2400000000002,
        "id": 922,
        "no_speech_prob": 0.0006878498825244606,
        "seek": 259538,
        "start": 2604.1800000000003,
        "temperature": 0,
        "text": " don't just have to be directories.",
        "tokens": [
          50804,
          500,
          380,
          445,
          362,
          281,
          312,
          5391,
          530,
          13,
          50907
        ]
      },
      {
        "avg_logprob": -0.2404343741280692,
        "compression_ratio": 1.440217391304348,
        "end": 2608.54,
        "id": 923,
        "no_speech_prob": 0.0006878498825244606,
        "seek": 259538,
        "start": 2606.2400000000002,
        "temperature": 0,
        "text": " They can actually signify a route.",
        "tokens": [
          50907,
          814,
          393,
          767,
          1465,
          2505,
          257,
          7955,
          13,
          51022
        ]
      },
      {
        "avg_logprob": -0.2404343741280692,
        "compression_ratio": 1.440217391304348,
        "end": 2611.3,
        "id": 924,
        "no_speech_prob": 0.0006878498825244606,
        "seek": 259538,
        "start": 2608.54,
        "temperature": 0,
        "text": " So for example, what if I went to,",
        "tokens": [
          51022,
          407,
          337,
          1365,
          11,
          437,
          498,
          286,
          1437,
          281,
          11,
          51160
        ]
      },
      {
        "avg_logprob": -0.2404343741280692,
        "compression_ratio": 1.440217391304348,
        "end": 2620.26,
        "id": 925,
        "no_speech_prob": 0.0006878498825244606,
        "seek": 259538,
        "start": 2611.3,
        "temperature": 0,
        "text": " I'm just going to call it flower API dot com slash search",
        "tokens": [
          51160,
          286,
          478,
          445,
          516,
          281,
          818,
          309,
          8617,
          9362,
          5893,
          395,
          17330,
          3164,
          51608
        ]
      },
      {
        "avg_logprob": -0.2404343741280692,
        "compression_ratio": 1.440217391304348,
        "end": 2623.1,
        "id": 926,
        "no_speech_prob": 0.0006878498825244606,
        "seek": 259538,
        "start": 2620.26,
        "temperature": 0,
        "text": " sunflower.",
        "tokens": [
          51608,
          48215,
          13,
          51750
        ]
      },
      {
        "avg_logprob": -0.2129667127454603,
        "compression_ratio": 1.6234817813765183,
        "end": 2624.58,
        "id": 927,
        "no_speech_prob": 0.000013211953955760691,
        "seek": 262310,
        "start": 2623.1,
        "temperature": 0,
        "text": " What if I went to this?",
        "tokens": [
          50364,
          708,
          498,
          286,
          1437,
          281,
          341,
          30,
          50438
        ]
      },
      {
        "avg_logprob": -0.2129667127454603,
        "compression_ratio": 1.6234817813765183,
        "end": 2628.22,
        "id": 928,
        "no_speech_prob": 0.000013211953955760691,
        "seek": 262310,
        "start": 2624.58,
        "temperature": 0,
        "text": " And this isn't actually of directories.",
        "tokens": [
          50438,
          400,
          341,
          1943,
          380,
          767,
          295,
          5391,
          530,
          13,
          50620
        ]
      },
      {
        "avg_logprob": -0.2129667127454603,
        "compression_ratio": 1.6234817813765183,
        "end": 2631.14,
        "id": 929,
        "no_speech_prob": 0.000013211953955760691,
        "seek": 262310,
        "start": 2628.22,
        "temperature": 0,
        "text": " These are commands that I am issuing to the API.",
        "tokens": [
          50620,
          1981,
          366,
          16901,
          300,
          286,
          669,
          43214,
          281,
          264,
          9362,
          13,
          50766
        ]
      },
      {
        "avg_logprob": -0.2129667127454603,
        "compression_ratio": 1.6234817813765183,
        "end": 2634.5,
        "id": 930,
        "no_speech_prob": 0.000013211953955760691,
        "seek": 262310,
        "start": 2631.14,
        "temperature": 0,
        "text": " I'm saying, search for this particular flower",
        "tokens": [
          50766,
          286,
          478,
          1566,
          11,
          3164,
          337,
          341,
          1729,
          8617,
          50934
        ]
      },
      {
        "avg_logprob": -0.2129667127454603,
        "compression_ratio": 1.6234817813765183,
        "end": 2635.74,
        "id": 931,
        "no_speech_prob": 0.000013211953955760691,
        "seek": 262310,
        "start": 2634.5,
        "temperature": 0,
        "text": " called sunflower.",
        "tokens": [
          50934,
          1219,
          48215,
          13,
          50996
        ]
      },
      {
        "avg_logprob": -0.2129667127454603,
        "compression_ratio": 1.6234817813765183,
        "end": 2640.22,
        "id": 932,
        "no_speech_prob": 0.000013211953955760691,
        "seek": 262310,
        "start": 2635.74,
        "temperature": 0,
        "text": " And I want to get back maybe some big JSON,",
        "tokens": [
          50996,
          400,
          286,
          528,
          281,
          483,
          646,
          1310,
          512,
          955,
          31828,
          11,
          51220
        ]
      },
      {
        "avg_logprob": -0.2129667127454603,
        "compression_ratio": 1.6234817813765183,
        "end": 2642.7,
        "id": 933,
        "no_speech_prob": 0.000013211953955760691,
        "seek": 262310,
        "start": 2640.22,
        "temperature": 0,
        "text": " all this information about sunflowers.",
        "tokens": [
          51220,
          439,
          341,
          1589,
          466,
          3295,
          10565,
          433,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.2129667127454603,
        "compression_ratio": 1.6234817813765183,
        "end": 2645.54,
        "id": 934,
        "no_speech_prob": 0.000013211953955760691,
        "seek": 262310,
        "start": 2642.7,
        "temperature": 0,
        "text": " So this is an idea of a route.",
        "tokens": [
          51344,
          407,
          341,
          307,
          364,
          1558,
          295,
          257,
          7955,
          13,
          51486
        ]
      },
      {
        "avg_logprob": -0.2129667127454603,
        "compression_ratio": 1.6234817813765183,
        "end": 2648.66,
        "id": 935,
        "no_speech_prob": 0.000013211953955760691,
        "seek": 262310,
        "start": 2645.54,
        "temperature": 0,
        "text": " And when you build an API, you might build different routes",
        "tokens": [
          51486,
          400,
          562,
          291,
          1322,
          364,
          9362,
          11,
          291,
          1062,
          1322,
          819,
          18242,
          51642
        ]
      },
      {
        "avg_logprob": -0.2129667127454603,
        "compression_ratio": 1.6234817813765183,
        "end": 2651.2,
        "id": 936,
        "no_speech_prob": 0.000013211953955760691,
        "seek": 262310,
        "start": 2648.66,
        "temperature": 0,
        "text": " for different kinds of ways of accessing the data.",
        "tokens": [
          51642,
          337,
          819,
          3685,
          295,
          2098,
          295,
          26440,
          264,
          1412,
          13,
          51769
        ]
      },
      {
        "avg_logprob": -0.20376485102885478,
        "compression_ratio": 1.902621722846442,
        "end": 2653.7599999999998,
        "id": 937,
        "no_speech_prob": 0.000021444933736347593,
        "seek": 265120,
        "start": 2651.2,
        "temperature": 0,
        "text": " You might make a route for getting all the data",
        "tokens": [
          50364,
          509,
          1062,
          652,
          257,
          7955,
          337,
          1242,
          439,
          264,
          1412,
          50492
        ]
      },
      {
        "avg_logprob": -0.20376485102885478,
        "compression_ratio": 1.902621722846442,
        "end": 2655.6,
        "id": 938,
        "no_speech_prob": 0.000021444933736347593,
        "seek": 265120,
        "start": 2653.7599999999998,
        "temperature": 0,
        "text": " or for searching for one piece of the data",
        "tokens": [
          50492,
          420,
          337,
          10808,
          337,
          472,
          2522,
          295,
          264,
          1412,
          50584
        ]
      },
      {
        "avg_logprob": -0.20376485102885478,
        "compression_ratio": 1.902621722846442,
        "end": 2657.8399999999997,
        "id": 939,
        "no_speech_prob": 0.000021444933736347593,
        "seek": 265120,
        "start": 2655.6,
        "temperature": 0,
        "text": " or a route that signifies, I want all the data,",
        "tokens": [
          50584,
          420,
          257,
          7955,
          300,
          1465,
          11221,
          11,
          286,
          528,
          439,
          264,
          1412,
          11,
          50696
        ]
      },
      {
        "avg_logprob": -0.20376485102885478,
        "compression_ratio": 1.902621722846442,
        "end": 2659.8799999999997,
        "id": 940,
        "no_speech_prob": 0.000021444933736347593,
        "seek": 265120,
        "start": 2657.8399999999997,
        "temperature": 0,
        "text": " but I want it sorted in this manner.",
        "tokens": [
          50696,
          457,
          286,
          528,
          309,
          25462,
          294,
          341,
          9060,
          13,
          50798
        ]
      },
      {
        "avg_logprob": -0.20376485102885478,
        "compression_ratio": 1.902621722846442,
        "end": 2663.2799999999997,
        "id": 941,
        "no_speech_prob": 0.000021444933736347593,
        "seek": 265120,
        "start": 2659.8799999999997,
        "temperature": 0,
        "text": " Or I want all the data, but only if the data starts",
        "tokens": [
          50798,
          1610,
          286,
          528,
          439,
          264,
          1412,
          11,
          457,
          787,
          498,
          264,
          1412,
          3719,
          50968
        ]
      },
      {
        "avg_logprob": -0.20376485102885478,
        "compression_ratio": 1.902621722846442,
        "end": 2666.12,
        "id": 942,
        "no_speech_prob": 0.000021444933736347593,
        "seek": 265120,
        "start": 2663.2799999999997,
        "temperature": 0,
        "text": " with the letter P, for example.",
        "tokens": [
          50968,
          365,
          264,
          5063,
          430,
          11,
          337,
          1365,
          13,
          51110
        ]
      },
      {
        "avg_logprob": -0.20376485102885478,
        "compression_ratio": 1.902621722846442,
        "end": 2668.04,
        "id": 943,
        "no_speech_prob": 0.000021444933736347593,
        "seek": 265120,
        "start": 2666.12,
        "temperature": 0,
        "text": " So there's a lot of ways you can use routes.",
        "tokens": [
          51110,
          407,
          456,
          311,
          257,
          688,
          295,
          2098,
          291,
          393,
          764,
          18242,
          13,
          51206
        ]
      },
      {
        "avg_logprob": -0.20376485102885478,
        "compression_ratio": 1.902621722846442,
        "end": 2671.4199999999996,
        "id": 944,
        "no_speech_prob": 0.000021444933736347593,
        "seek": 265120,
        "start": 2668.04,
        "temperature": 0,
        "text": " So now here in the code, this is not the code,",
        "tokens": [
          51206,
          407,
          586,
          510,
          294,
          264,
          3089,
          11,
          341,
          307,
          406,
          264,
          3089,
          11,
          51375
        ]
      },
      {
        "avg_logprob": -0.20376485102885478,
        "compression_ratio": 1.902621722846442,
        "end": 2676,
        "id": 945,
        "no_speech_prob": 0.000021444933736347593,
        "seek": 265120,
        "start": 2671.4199999999996,
        "temperature": 0,
        "text": " I need to start to manage how those routes are handled.",
        "tokens": [
          51375,
          286,
          643,
          281,
          722,
          281,
          3067,
          577,
          729,
          18242,
          366,
          18033,
          13,
          51604
        ]
      },
      {
        "avg_logprob": -0.20376485102885478,
        "compression_ratio": 1.902621722846442,
        "end": 2678.48,
        "id": 946,
        "no_speech_prob": 0.000021444933736347593,
        "seek": 265120,
        "start": 2676,
        "temperature": 0,
        "text": " So right here, I'm going to start adding that code.",
        "tokens": [
          51604,
          407,
          558,
          510,
          11,
          286,
          478,
          516,
          281,
          722,
          5127,
          300,
          3089,
          13,
          51728
        ]
      },
      {
        "avg_logprob": -0.20376485102885478,
        "compression_ratio": 1.902621722846442,
        "end": 2680.64,
        "id": 947,
        "no_speech_prob": 0.000021444933736347593,
        "seek": 265120,
        "start": 2678.48,
        "temperature": 0,
        "text": " So I'm going to add a bunch of carriage returns.",
        "tokens": [
          51728,
          407,
          286,
          478,
          516,
          281,
          909,
          257,
          3840,
          295,
          31811,
          11247,
          13,
          51836
        ]
      },
      {
        "avg_logprob": -0.23182466295030382,
        "compression_ratio": 1.5130434782608695,
        "end": 2682.96,
        "id": 948,
        "no_speech_prob": 0.0006461967132054269,
        "seek": 268064,
        "start": 2680.64,
        "temperature": 0,
        "text": " And right here, I'm going to set up a route.",
        "tokens": [
          50364,
          400,
          558,
          510,
          11,
          286,
          478,
          516,
          281,
          992,
          493,
          257,
          7955,
          13,
          50480
        ]
      },
      {
        "avg_logprob": -0.23182466295030382,
        "compression_ratio": 1.5130434782608695,
        "end": 2689.4,
        "id": 949,
        "no_speech_prob": 0.0006461967132054269,
        "seek": 268064,
        "start": 2682.96,
        "temperature": 0,
        "text": " So please edit that cough out.",
        "tokens": [
          50480,
          407,
          1767,
          8129,
          300,
          22777,
          484,
          13,
          50802
        ]
      },
      {
        "avg_logprob": -0.23182466295030382,
        "compression_ratio": 1.5130434782608695,
        "end": 2692.4,
        "id": 950,
        "no_speech_prob": 0.0006461967132054269,
        "seek": 268064,
        "start": 2689.4,
        "temperature": 0,
        "text": " When a user goes to one of these routes",
        "tokens": [
          50802,
          1133,
          257,
          4195,
          1709,
          281,
          472,
          295,
          613,
          18242,
          50952
        ]
      },
      {
        "avg_logprob": -0.23182466295030382,
        "compression_ratio": 1.5130434782608695,
        "end": 2694.96,
        "id": 951,
        "no_speech_prob": 0.0006461967132054269,
        "seek": 268064,
        "start": 2692.4,
        "temperature": 0,
        "text": " or goes to in the browser, types in a URL",
        "tokens": [
          50952,
          420,
          1709,
          281,
          294,
          264,
          11185,
          11,
          3467,
          294,
          257,
          12905,
          51080
        ]
      },
      {
        "avg_logprob": -0.23182466295030382,
        "compression_ratio": 1.5130434782608695,
        "end": 2697.14,
        "id": 952,
        "no_speech_prob": 0.0006461967132054269,
        "seek": 268064,
        "start": 2694.96,
        "temperature": 0,
        "text": " or clicks on a link to a URL, they're",
        "tokens": [
          51080,
          420,
          18521,
          322,
          257,
          2113,
          281,
          257,
          12905,
          11,
          436,
          434,
          51189
        ]
      },
      {
        "avg_logprob": -0.23182466295030382,
        "compression_ratio": 1.5130434782608695,
        "end": 2699.68,
        "id": 953,
        "no_speech_prob": 0.0006461967132054269,
        "seek": 268064,
        "start": 2697.14,
        "temperature": 0,
        "text": " making something called a get request.",
        "tokens": [
          51189,
          1455,
          746,
          1219,
          257,
          483,
          5308,
          13,
          51316
        ]
      },
      {
        "avg_logprob": -0.23182466295030382,
        "compression_ratio": 1.5130434782608695,
        "end": 2704.12,
        "id": 954,
        "no_speech_prob": 0.0006461967132054269,
        "seek": 268064,
        "start": 2699.68,
        "temperature": 0,
        "text": " Please, may I have something from you server?",
        "tokens": [
          51316,
          2555,
          11,
          815,
          286,
          362,
          746,
          490,
          291,
          7154,
          30,
          51538
        ]
      },
      {
        "avg_logprob": -0.23182466295030382,
        "compression_ratio": 1.5130434782608695,
        "end": 2706.08,
        "id": 955,
        "no_speech_prob": 0.0006461967132054269,
        "seek": 268064,
        "start": 2704.12,
        "temperature": 0,
        "text": " Can I get stuff back?",
        "tokens": [
          51538,
          1664,
          286,
          483,
          1507,
          646,
          30,
          51636
        ]
      },
      {
        "avg_logprob": -0.23182466295030382,
        "compression_ratio": 1.5130434782608695,
        "end": 2708.04,
        "id": 956,
        "no_speech_prob": 0.0006461967132054269,
        "seek": 268064,
        "start": 2706.08,
        "temperature": 0,
        "text": " And you'll get images.",
        "tokens": [
          51636,
          400,
          291,
          603,
          483,
          5267,
          13,
          51734
        ]
      },
      {
        "avg_logprob": -0.23182466295030382,
        "compression_ratio": 1.5130434782608695,
        "end": 2709.6,
        "id": 957,
        "no_speech_prob": 0.0006461967132054269,
        "seek": 268064,
        "start": 2708.04,
        "temperature": 0,
        "text": " There's a dog barking.",
        "tokens": [
          51734,
          821,
          311,
          257,
          3000,
          32995,
          13,
          51812
        ]
      },
      {
        "avg_logprob": -0.30813691832802514,
        "compression_ratio": 1.382198952879581,
        "end": 2713,
        "id": 958,
        "no_speech_prob": 0.00012533704284578562,
        "seek": 270960,
        "start": 2709.6,
        "temperature": 0,
        "text": " Images, HTML files, CSS, all that sort of thing.",
        "tokens": [
          50364,
          4331,
          1660,
          11,
          17995,
          7098,
          11,
          24387,
          11,
          439,
          300,
          1333,
          295,
          551,
          13,
          50534
        ]
      },
      {
        "avg_logprob": -0.30813691832802514,
        "compression_ratio": 1.382198952879581,
        "end": 2715.2,
        "id": 959,
        "no_speech_prob": 0.00012533704284578562,
        "seek": 270960,
        "start": 2713,
        "temperature": 0,
        "text": " So if you want to handle a get request that",
        "tokens": [
          50534,
          407,
          498,
          291,
          528,
          281,
          4813,
          257,
          483,
          5308,
          300,
          50644
        ]
      },
      {
        "avg_logprob": -0.30813691832802514,
        "compression_ratio": 1.382198952879581,
        "end": 2717.72,
        "id": 960,
        "no_speech_prob": 0.00012533704284578562,
        "seek": 270960,
        "start": 2715.2,
        "temperature": 0,
        "text": " goes to a specific route, I could say app.get.",
        "tokens": [
          50644,
          1709,
          281,
          257,
          2685,
          7955,
          11,
          286,
          727,
          584,
          724,
          13,
          847,
          13,
          50770
        ]
      },
      {
        "avg_logprob": -0.30813691832802514,
        "compression_ratio": 1.382198952879581,
        "end": 2725.44,
        "id": 961,
        "no_speech_prob": 0.00012533704284578562,
        "seek": 270960,
        "start": 2722.3199999999997,
        "temperature": 0,
        "text": " Get slash.",
        "tokens": [
          51000,
          3240,
          17330,
          13,
          51156
        ]
      },
      {
        "avg_logprob": -0.30813691832802514,
        "compression_ratio": 1.382198952879581,
        "end": 2727.92,
        "id": 962,
        "no_speech_prob": 0.00012533704284578562,
        "seek": 270960,
        "start": 2725.44,
        "temperature": 0,
        "text": " I lost my train of thought.",
        "tokens": [
          51156,
          286,
          2731,
          452,
          3847,
          295,
          1194,
          13,
          51280
        ]
      },
      {
        "avg_logprob": -0.30813691832802514,
        "compression_ratio": 1.382198952879581,
        "end": 2730.08,
        "id": 963,
        "no_speech_prob": 0.00012533704284578562,
        "seek": 270960,
        "start": 2727.92,
        "temperature": 0,
        "text": " We're thinking about flowers, right?",
        "tokens": [
          51280,
          492,
          434,
          1953,
          466,
          8085,
          11,
          558,
          30,
          51388
        ]
      },
      {
        "avg_logprob": -0.30813691832802514,
        "compression_ratio": 1.382198952879581,
        "end": 2732.2799999999997,
        "id": 964,
        "no_speech_prob": 0.00012533704284578562,
        "seek": 270960,
        "start": 2730.08,
        "temperature": 0,
        "text": " Flower.",
        "tokens": [
          51388,
          34993,
          13,
          51498
        ]
      },
      {
        "avg_logprob": -0.30813691832802514,
        "compression_ratio": 1.382198952879581,
        "end": 2735.7999999999997,
        "id": 965,
        "no_speech_prob": 0.00012533704284578562,
        "seek": 270960,
        "start": 2732.2799999999997,
        "temperature": 0,
        "text": " And then I need a callback.",
        "tokens": [
          51498,
          400,
          550,
          286,
          643,
          257,
          818,
          3207,
          13,
          51674
        ]
      },
      {
        "avg_logprob": -0.30813691832802514,
        "compression_ratio": 1.382198952879581,
        "end": 2738.48,
        "id": 966,
        "no_speech_prob": 0.00012533704284578562,
        "seek": 270960,
        "start": 2735.7999999999997,
        "temperature": 0,
        "text": " Send flower.",
        "tokens": [
          51674,
          17908,
          8617,
          13,
          51808
        ]
      },
      {
        "avg_logprob": -0.23036080075983414,
        "compression_ratio": 1.7333333333333334,
        "end": 2740.04,
        "id": 967,
        "no_speech_prob": 0.00011774434824474156,
        "seek": 273848,
        "start": 2738.48,
        "temperature": 0,
        "text": " Send flower.",
        "tokens": [
          50364,
          17908,
          8617,
          13,
          50442
        ]
      },
      {
        "avg_logprob": -0.23036080075983414,
        "compression_ratio": 1.7333333333333334,
        "end": 2743.48,
        "id": 968,
        "no_speech_prob": 0.00011774434824474156,
        "seek": 273848,
        "start": 2740.04,
        "temperature": 0,
        "text": " All functions should be called send flowers.",
        "tokens": [
          50442,
          1057,
          6828,
          820,
          312,
          1219,
          2845,
          8085,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.23036080075983414,
        "compression_ratio": 1.7333333333333334,
        "end": 2746.32,
        "id": 969,
        "no_speech_prob": 0.00011774434824474156,
        "seek": 273848,
        "start": 2743.48,
        "temperature": 0,
        "text": " So I'm going to write send flower.",
        "tokens": [
          50614,
          407,
          286,
          478,
          516,
          281,
          2464,
          2845,
          8617,
          13,
          50756
        ]
      },
      {
        "avg_logprob": -0.23036080075983414,
        "compression_ratio": 1.7333333333333334,
        "end": 2748.72,
        "id": 970,
        "no_speech_prob": 0.00011774434824474156,
        "seek": 273848,
        "start": 2746.32,
        "temperature": 0,
        "text": " So the idea here is I'm now writing the code",
        "tokens": [
          50756,
          407,
          264,
          1558,
          510,
          307,
          286,
          478,
          586,
          3579,
          264,
          3089,
          50876
        ]
      },
      {
        "avg_logprob": -0.23036080075983414,
        "compression_ratio": 1.7333333333333334,
        "end": 2753.16,
        "id": 971,
        "no_speech_prob": 0.00011774434824474156,
        "seek": 273848,
        "start": 2748.72,
        "temperature": 0,
        "text": " if any user of this API, user meaning not necessarily",
        "tokens": [
          50876,
          498,
          604,
          4195,
          295,
          341,
          9362,
          11,
          4195,
          3620,
          406,
          4725,
          51098
        ]
      },
      {
        "avg_logprob": -0.23036080075983414,
        "compression_ratio": 1.7333333333333334,
        "end": 2755.12,
        "id": 972,
        "no_speech_prob": 0.00011774434824474156,
        "seek": 273848,
        "start": 2753.16,
        "temperature": 0,
        "text": " a person, but a web browser, some client that's",
        "tokens": [
          51098,
          257,
          954,
          11,
          457,
          257,
          3670,
          11185,
          11,
          512,
          6423,
          300,
          311,
          51196
        ]
      },
      {
        "avg_logprob": -0.23036080075983414,
        "compression_ratio": 1.7333333333333334,
        "end": 2758.16,
        "id": 973,
        "no_speech_prob": 0.00011774434824474156,
        "seek": 273848,
        "start": 2755.12,
        "temperature": 0,
        "text": " going to connect to it, goes to slash flower,",
        "tokens": [
          51196,
          516,
          281,
          1745,
          281,
          309,
          11,
          1709,
          281,
          17330,
          8617,
          11,
          51348
        ]
      },
      {
        "avg_logprob": -0.23036080075983414,
        "compression_ratio": 1.7333333333333334,
        "end": 2761.68,
        "id": 974,
        "no_speech_prob": 0.00011774434824474156,
        "seek": 273848,
        "start": 2758.16,
        "temperature": 0,
        "text": " then this function send flower should be executed.",
        "tokens": [
          51348,
          550,
          341,
          2445,
          2845,
          8617,
          820,
          312,
          17577,
          13,
          51524
        ]
      },
      {
        "avg_logprob": -0.23036080075983414,
        "compression_ratio": 1.7333333333333334,
        "end": 2762.54,
        "id": 975,
        "no_speech_prob": 0.00011774434824474156,
        "seek": 273848,
        "start": 2761.68,
        "temperature": 0,
        "text": " That's the callback.",
        "tokens": [
          51524,
          663,
          311,
          264,
          818,
          3207,
          13,
          51567
        ]
      },
      {
        "avg_logprob": -0.23036080075983414,
        "compression_ratio": 1.7333333333333334,
        "end": 2766.68,
        "id": 976,
        "no_speech_prob": 0.00011774434824474156,
        "seek": 273848,
        "start": 2762.54,
        "temperature": 0,
        "text": " Now, the send flower has two arguments associated with it,",
        "tokens": [
          51567,
          823,
          11,
          264,
          2845,
          8617,
          575,
          732,
          12869,
          6615,
          365,
          309,
          11,
          51774
        ]
      },
      {
        "avg_logprob": -0.206824055424443,
        "compression_ratio": 1.9209302325581394,
        "end": 2769.9199999999996,
        "id": 977,
        "no_speech_prob": 0.0000946124637266621,
        "seek": 276668,
        "start": 2766.68,
        "temperature": 0,
        "text": " a request and a response.",
        "tokens": [
          50364,
          257,
          5308,
          293,
          257,
          4134,
          13,
          50526
        ]
      },
      {
        "avg_logprob": -0.206824055424443,
        "compression_ratio": 1.9209302325581394,
        "end": 2773.08,
        "id": 978,
        "no_speech_prob": 0.0000946124637266621,
        "seek": 276668,
        "start": 2769.9199999999996,
        "temperature": 0,
        "text": " Every web transaction, so to speak,",
        "tokens": [
          50526,
          2048,
          3670,
          14425,
          11,
          370,
          281,
          1710,
          11,
          50684
        ]
      },
      {
        "avg_logprob": -0.206824055424443,
        "compression_ratio": 1.9209302325581394,
        "end": 2777.96,
        "id": 979,
        "no_speech_prob": 0.0000946124637266621,
        "seek": 276668,
        "start": 2773.08,
        "temperature": 0,
        "text": " when I go and type google.com or rainbow something something",
        "tokens": [
          50684,
          562,
          286,
          352,
          293,
          2010,
          20742,
          13,
          1112,
          420,
          18526,
          746,
          746,
          50928
        ]
      },
      {
        "avg_logprob": -0.206824055424443,
        "compression_ratio": 1.9209302325581394,
        "end": 2781.24,
        "id": 980,
        "no_speech_prob": 0.0000946124637266621,
        "seek": 276668,
        "start": 2777.96,
        "temperature": 0,
        "text": " dot com, I'm making a request to the server.",
        "tokens": [
          50928,
          5893,
          395,
          11,
          286,
          478,
          1455,
          257,
          5308,
          281,
          264,
          7154,
          13,
          51092
        ]
      },
      {
        "avg_logprob": -0.206824055424443,
        "compression_ratio": 1.9209302325581394,
        "end": 2783.2799999999997,
        "id": 981,
        "no_speech_prob": 0.0000946124637266621,
        "seek": 276668,
        "start": 2781.24,
        "temperature": 0,
        "text": " So all the information about me is",
        "tokens": [
          51092,
          407,
          439,
          264,
          1589,
          466,
          385,
          307,
          51194
        ]
      },
      {
        "avg_logprob": -0.206824055424443,
        "compression_ratio": 1.9209302325581394,
        "end": 2785.14,
        "id": 982,
        "no_speech_prob": 0.0000946124637266621,
        "seek": 276668,
        "start": 2783.2799999999997,
        "temperature": 0,
        "text": " in that variable called request.",
        "tokens": [
          51194,
          294,
          300,
          7006,
          1219,
          5308,
          13,
          51287
        ]
      },
      {
        "avg_logprob": -0.206824055424443,
        "compression_ratio": 1.9209302325581394,
        "end": 2788.12,
        "id": 983,
        "no_speech_prob": 0.0000946124637266621,
        "seek": 276668,
        "start": 2785.14,
        "temperature": 0,
        "text": " The server then sends back a response.",
        "tokens": [
          51287,
          440,
          7154,
          550,
          14790,
          646,
          257,
          4134,
          13,
          51436
        ]
      },
      {
        "avg_logprob": -0.206824055424443,
        "compression_ratio": 1.9209302325581394,
        "end": 2790.6,
        "id": 984,
        "no_speech_prob": 0.0000946124637266621,
        "seek": 276668,
        "start": 2788.12,
        "temperature": 0,
        "text": " All the information about the server's response",
        "tokens": [
          51436,
          1057,
          264,
          1589,
          466,
          264,
          7154,
          311,
          4134,
          51560
        ]
      },
      {
        "avg_logprob": -0.206824055424443,
        "compression_ratio": 1.9209302325581394,
        "end": 2792.3599999999997,
        "id": 985,
        "no_speech_prob": 0.0000946124637266621,
        "seek": 276668,
        "start": 2790.6,
        "temperature": 0,
        "text": " is in that variable response.",
        "tokens": [
          51560,
          307,
          294,
          300,
          7006,
          4134,
          13,
          51648
        ]
      },
      {
        "avg_logprob": -0.206824055424443,
        "compression_ratio": 1.9209302325581394,
        "end": 2795,
        "id": 986,
        "no_speech_prob": 0.0000946124637266621,
        "seek": 276668,
        "start": 2792.3599999999997,
        "temperature": 0,
        "text": " And I'm using this idea of all the information very loosely.",
        "tokens": [
          51648,
          400,
          286,
          478,
          1228,
          341,
          1558,
          295,
          439,
          264,
          1589,
          588,
          37966,
          13,
          51780
        ]
      },
      {
        "avg_logprob": -0.26658777236938475,
        "compression_ratio": 1.6571428571428573,
        "end": 2799.44,
        "id": 987,
        "no_speech_prob": 0.000002948014753201278,
        "seek": 279500,
        "start": 2795.96,
        "temperature": 0,
        "text": " In request, you can find what was the operating system?",
        "tokens": [
          50412,
          682,
          5308,
          11,
          291,
          393,
          915,
          437,
          390,
          264,
          7447,
          1185,
          30,
          50586
        ]
      },
      {
        "avg_logprob": -0.26658777236938475,
        "compression_ratio": 1.6571428571428573,
        "end": 2800.36,
        "id": 988,
        "no_speech_prob": 0.000002948014753201278,
        "seek": 279500,
        "start": 2799.44,
        "temperature": 0,
        "text": " What was the browser?",
        "tokens": [
          50586,
          708,
          390,
          264,
          11185,
          30,
          50632
        ]
      },
      {
        "avg_logprob": -0.26658777236938475,
        "compression_ratio": 1.6571428571428573,
        "end": 2802.16,
        "id": 989,
        "no_speech_prob": 0.000002948014753201278,
        "seek": 279500,
        "start": 2800.36,
        "temperature": 0,
        "text": " What are the headers?",
        "tokens": [
          50632,
          708,
          366,
          264,
          45101,
          30,
          50722
        ]
      },
      {
        "avg_logprob": -0.26658777236938475,
        "compression_ratio": 1.6571428571428573,
        "end": 2804.84,
        "id": 990,
        "no_speech_prob": 0.000002948014753201278,
        "seek": 279500,
        "start": 2802.16,
        "temperature": 0,
        "text": " You're going to see were there any parameters sent also.",
        "tokens": [
          50722,
          509,
          434,
          516,
          281,
          536,
          645,
          456,
          604,
          9834,
          2279,
          611,
          13,
          50856
        ]
      },
      {
        "avg_logprob": -0.26658777236938475,
        "compression_ratio": 1.6571428571428573,
        "end": 2808.52,
        "id": 991,
        "no_speech_prob": 0.000002948014753201278,
        "seek": 279500,
        "start": 2804.84,
        "temperature": 0,
        "text": " The response has things like, ah, I can send back some data.",
        "tokens": [
          50856,
          440,
          4134,
          575,
          721,
          411,
          11,
          3716,
          11,
          286,
          393,
          2845,
          646,
          512,
          1412,
          13,
          51040
        ]
      },
      {
        "avg_logprob": -0.26658777236938475,
        "compression_ratio": 1.6571428571428573,
        "end": 2811.4,
        "id": 992,
        "no_speech_prob": 0.000002948014753201278,
        "seek": 279500,
        "start": 2808.52,
        "temperature": 0,
        "text": " So what I'm going to do is I'm going to now say right here,",
        "tokens": [
          51040,
          407,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          586,
          584,
          558,
          510,
          11,
          51184
        ]
      },
      {
        "avg_logprob": -0.26658777236938475,
        "compression_ratio": 1.6571428571428573,
        "end": 2817.72,
        "id": 993,
        "no_speech_prob": 0.000002948014753201278,
        "seek": 279500,
        "start": 2811.4,
        "temperature": 0,
        "text": " response send I love flowers too.",
        "tokens": [
          51184,
          4134,
          2845,
          286,
          959,
          8085,
          886,
          13,
          51500
        ]
      },
      {
        "avg_logprob": -0.26658777236938475,
        "compression_ratio": 1.6571428571428573,
        "end": 2821.8,
        "id": 994,
        "no_speech_prob": 0.000002948014753201278,
        "seek": 279500,
        "start": 2817.72,
        "temperature": 0,
        "text": " So if the user goes to slash flower,",
        "tokens": [
          51500,
          407,
          498,
          264,
          4195,
          1709,
          281,
          17330,
          8617,
          11,
          51704
        ]
      },
      {
        "avg_logprob": -0.23351194658352217,
        "compression_ratio": 1.691119691119691,
        "end": 2825.6000000000004,
        "id": 995,
        "no_speech_prob": 0.00012533715926110744,
        "seek": 282180,
        "start": 2821.8,
        "temperature": 0,
        "text": " rather than look for a directory of HTML, CSS,",
        "tokens": [
          50364,
          2831,
          813,
          574,
          337,
          257,
          21120,
          295,
          17995,
          11,
          24387,
          11,
          50554
        ]
      },
      {
        "avg_logprob": -0.23351194658352217,
        "compression_ratio": 1.691119691119691,
        "end": 2827.4,
        "id": 996,
        "no_speech_prob": 0.00012533715926110744,
        "seek": 282180,
        "start": 2825.6000000000004,
        "temperature": 0,
        "text": " JavaScript files along that path,",
        "tokens": [
          50554,
          15778,
          7098,
          2051,
          300,
          3100,
          11,
          50644
        ]
      },
      {
        "avg_logprob": -0.23351194658352217,
        "compression_ratio": 1.691119691119691,
        "end": 2829.76,
        "id": 997,
        "no_speech_prob": 0.00012533715926110744,
        "seek": 282180,
        "start": 2827.4,
        "temperature": 0,
        "text": " this is a route that I'm going to handle programmatically.",
        "tokens": [
          50644,
          341,
          307,
          257,
          7955,
          300,
          286,
          478,
          516,
          281,
          4813,
          37648,
          5030,
          13,
          50762
        ]
      },
      {
        "avg_logprob": -0.23351194658352217,
        "compression_ratio": 1.691119691119691,
        "end": 2832.36,
        "id": 998,
        "no_speech_prob": 0.00012533715926110744,
        "seek": 282180,
        "start": 2829.76,
        "temperature": 0,
        "text": " And I'm going to say, I love flowers too.",
        "tokens": [
          50762,
          400,
          286,
          478,
          516,
          281,
          584,
          11,
          286,
          959,
          8085,
          886,
          13,
          50892
        ]
      },
      {
        "avg_logprob": -0.23351194658352217,
        "compression_ratio": 1.691119691119691,
        "end": 2834.44,
        "id": 999,
        "no_speech_prob": 0.00012533715926110744,
        "seek": 282180,
        "start": 2832.36,
        "temperature": 0,
        "text": " So let's hit refresh.",
        "tokens": [
          50892,
          407,
          718,
          311,
          2045,
          15134,
          13,
          50996
        ]
      },
      {
        "avg_logprob": -0.23351194658352217,
        "compression_ratio": 1.691119691119691,
        "end": 2835.52,
        "id": 1000,
        "no_speech_prob": 0.00012533715926110744,
        "seek": 282180,
        "start": 2834.44,
        "temperature": 0,
        "text": " The server's still running.",
        "tokens": [
          50996,
          440,
          7154,
          311,
          920,
          2614,
          13,
          51050
        ]
      },
      {
        "avg_logprob": -0.23351194658352217,
        "compression_ratio": 1.691119691119691,
        "end": 2837.6600000000003,
        "id": 1001,
        "no_speech_prob": 0.00012533715926110744,
        "seek": 282180,
        "start": 2835.52,
        "temperature": 0,
        "text": " I am now up here going to change this to say,",
        "tokens": [
          51050,
          286,
          669,
          586,
          493,
          510,
          516,
          281,
          1319,
          341,
          281,
          584,
          11,
          51157
        ]
      },
      {
        "avg_logprob": -0.23351194658352217,
        "compression_ratio": 1.691119691119691,
        "end": 2840.36,
        "id": 1002,
        "no_speech_prob": 0.00012533715926110744,
        "seek": 282180,
        "start": 2837.6600000000003,
        "temperature": 0,
        "text": " go to the route slash flower.",
        "tokens": [
          51157,
          352,
          281,
          264,
          7955,
          17330,
          8617,
          13,
          51292
        ]
      },
      {
        "avg_logprob": -0.23351194658352217,
        "compression_ratio": 1.691119691119691,
        "end": 2842.36,
        "id": 1003,
        "no_speech_prob": 0.00012533715926110744,
        "seek": 282180,
        "start": 2840.36,
        "temperature": 0,
        "text": " And I see I love flowers too.",
        "tokens": [
          51292,
          400,
          286,
          536,
          286,
          959,
          8085,
          886,
          13,
          51392
        ]
      },
      {
        "avg_logprob": -0.23351194658352217,
        "compression_ratio": 1.691119691119691,
        "end": 2844.96,
        "id": 1004,
        "no_speech_prob": 0.00012533715926110744,
        "seek": 282180,
        "start": 2842.36,
        "temperature": 0,
        "text": " Now, there's no HTML page.",
        "tokens": [
          51392,
          823,
          11,
          456,
          311,
          572,
          17995,
          3028,
          13,
          51522
        ]
      },
      {
        "avg_logprob": -0.23351194658352217,
        "compression_ratio": 1.691119691119691,
        "end": 2845.96,
        "id": 1005,
        "no_speech_prob": 0.00012533715926110744,
        "seek": 282180,
        "start": 2844.96,
        "temperature": 0,
        "text": " There's nothing.",
        "tokens": [
          51522,
          821,
          311,
          1825,
          13,
          51572
        ]
      },
      {
        "avg_logprob": -0.23351194658352217,
        "compression_ratio": 1.691119691119691,
        "end": 2850.6000000000004,
        "id": 1006,
        "no_speech_prob": 0.00012533715926110744,
        "seek": 282180,
        "start": 2845.96,
        "temperature": 0,
        "text": " There's just code and a response sent back the response.",
        "tokens": [
          51572,
          821,
          311,
          445,
          3089,
          293,
          257,
          4134,
          2279,
          646,
          264,
          4134,
          13,
          51804
        ]
      },
      {
        "avg_logprob": -0.2826897704485551,
        "compression_ratio": 1.6359223300970873,
        "end": 2852.24,
        "id": 1007,
        "no_speech_prob": 0.00001805847932700999,
        "seek": 285060,
        "start": 2851.08,
        "temperature": 0,
        "text": " So this is part one.",
        "tokens": [
          50388,
          407,
          341,
          307,
          644,
          472,
          13,
          50446
        ]
      },
      {
        "avg_logprob": -0.2826897704485551,
        "compression_ratio": 1.6359223300970873,
        "end": 2855.64,
        "id": 1008,
        "no_speech_prob": 0.00001805847932700999,
        "seek": 285060,
        "start": 2852.24,
        "temperature": 0,
        "text": " But remember this idea of searching,",
        "tokens": [
          50446,
          583,
          1604,
          341,
          1558,
          295,
          10808,
          11,
          50616
        ]
      },
      {
        "avg_logprob": -0.2826897704485551,
        "compression_ratio": 1.6359223300970873,
        "end": 2857.88,
        "id": 1009,
        "no_speech_prob": 0.00001805847932700999,
        "seek": 285060,
        "start": 2855.64,
        "temperature": 0,
        "text": " the idea of using an API to search?",
        "tokens": [
          50616,
          264,
          1558,
          295,
          1228,
          364,
          9362,
          281,
          3164,
          30,
          50728
        ]
      },
      {
        "avg_logprob": -0.2826897704485551,
        "compression_ratio": 1.6359223300970873,
        "end": 2860.64,
        "id": 1010,
        "no_speech_prob": 0.00001805847932700999,
        "seek": 285060,
        "start": 2857.88,
        "temperature": 0,
        "text": " What I want to do is have a, well,",
        "tokens": [
          50728,
          708,
          286,
          528,
          281,
          360,
          307,
          362,
          257,
          11,
          731,
          11,
          50866
        ]
      },
      {
        "avg_logprob": -0.2826897704485551,
        "compression_ratio": 1.6359223300970873,
        "end": 2862,
        "id": 1011,
        "no_speech_prob": 0.00001805847932700999,
        "seek": 285060,
        "start": 2860.64,
        "temperature": 0,
        "text": " there's a lot of things I can do.",
        "tokens": [
          50866,
          456,
          311,
          257,
          688,
          295,
          721,
          286,
          393,
          360,
          13,
          50934
        ]
      },
      {
        "avg_logprob": -0.2826897704485551,
        "compression_ratio": 1.6359223300970873,
        "end": 2864.44,
        "id": 1012,
        "no_speech_prob": 0.00001805847932700999,
        "seek": 285060,
        "start": 2862,
        "temperature": 0,
        "text": " But something that at least to get started with",
        "tokens": [
          50934,
          583,
          746,
          300,
          412,
          1935,
          281,
          483,
          1409,
          365,
          51056
        ]
      },
      {
        "avg_logprob": -0.2826897704485551,
        "compression_ratio": 1.6359223300970873,
        "end": 2872.08,
        "id": 1013,
        "no_speech_prob": 0.00001805847932700999,
        "seek": 285060,
        "start": 2864.44,
        "temperature": 0,
        "text": " is what if I were to search at a second, I",
        "tokens": [
          51056,
          307,
          437,
          498,
          286,
          645,
          281,
          3164,
          412,
          257,
          1150,
          11,
          286,
          51438
        ]
      },
      {
        "avg_logprob": -0.2826897704485551,
        "compression_ratio": 1.6359223300970873,
        "end": 2875.88,
        "id": 1014,
        "no_speech_prob": 0.00001805847932700999,
        "seek": 285060,
        "start": 2872.08,
        "temperature": 0,
        "text": " don't know what to call it, a second element to this route,",
        "tokens": [
          51438,
          500,
          380,
          458,
          437,
          281,
          818,
          309,
          11,
          257,
          1150,
          4478,
          281,
          341,
          7955,
          11,
          51628
        ]
      },
      {
        "avg_logprob": -0.2826897704485551,
        "compression_ratio": 1.6359223300970873,
        "end": 2878.12,
        "id": 1015,
        "no_speech_prob": 0.00001805847932700999,
        "seek": 285060,
        "start": 2875.88,
        "temperature": 0,
        "text": " search slash sunflower.",
        "tokens": [
          51628,
          3164,
          17330,
          48215,
          13,
          51740
        ]
      },
      {
        "avg_logprob": -0.26756931387859845,
        "compression_ratio": 1.6,
        "end": 2880.52,
        "id": 1016,
        "no_speech_prob": 0.000004029453521070536,
        "seek": 287812,
        "start": 2878.12,
        "temperature": 0,
        "text": " But rather than, oh, I'm going to come back over here.",
        "tokens": [
          50364,
          583,
          2831,
          813,
          11,
          1954,
          11,
          286,
          478,
          516,
          281,
          808,
          646,
          670,
          510,
          13,
          50484
        ]
      },
      {
        "avg_logprob": -0.26756931387859845,
        "compression_ratio": 1.6,
        "end": 2890.7999999999997,
        "id": 1017,
        "no_speech_prob": 0.000004029453521070536,
        "seek": 287812,
        "start": 2883.3199999999997,
        "temperature": 0,
        "text": " Rather than say, search slash sunflower, what I actually",
        "tokens": [
          50624,
          16571,
          813,
          584,
          11,
          3164,
          17330,
          48215,
          11,
          437,
          286,
          767,
          50998
        ]
      },
      {
        "avg_logprob": -0.26756931387859845,
        "compression_ratio": 1.6,
        "end": 2894.2,
        "id": 1018,
        "no_speech_prob": 0.000004029453521070536,
        "seek": 287812,
        "start": 2890.7999999999997,
        "temperature": 0,
        "text": " want to handle is not the specific route.",
        "tokens": [
          50998,
          528,
          281,
          4813,
          307,
          406,
          264,
          2685,
          7955,
          13,
          51168
        ]
      },
      {
        "avg_logprob": -0.26756931387859845,
        "compression_ratio": 1.6,
        "end": 2896.24,
        "id": 1019,
        "no_speech_prob": 0.000004029453521070536,
        "seek": 287812,
        "start": 2894.2,
        "temperature": 0,
        "text": " I want, if they go to search, I then",
        "tokens": [
          51168,
          286,
          528,
          11,
          498,
          436,
          352,
          281,
          3164,
          11,
          286,
          550,
          51270
        ]
      },
      {
        "avg_logprob": -0.26756931387859845,
        "compression_ratio": 1.6,
        "end": 2900.04,
        "id": 1020,
        "no_speech_prob": 0.000004029453521070536,
        "seek": 287812,
        "start": 2896.24,
        "temperature": 0,
        "text": " want the second element to be a variable, so to speak,",
        "tokens": [
          51270,
          528,
          264,
          1150,
          4478,
          281,
          312,
          257,
          7006,
          11,
          370,
          281,
          1710,
          11,
          51460
        ]
      },
      {
        "avg_logprob": -0.26756931387859845,
        "compression_ratio": 1.6,
        "end": 2902.3199999999997,
        "id": 1021,
        "no_speech_prob": 0.000004029453521070536,
        "seek": 287812,
        "start": 2900.04,
        "temperature": 0,
        "text": " something that changes every time.",
        "tokens": [
          51460,
          746,
          300,
          2962,
          633,
          565,
          13,
          51574
        ]
      },
      {
        "avg_logprob": -0.26756931387859845,
        "compression_ratio": 1.6,
        "end": 2904.94,
        "id": 1022,
        "no_speech_prob": 0.000004029453521070536,
        "seek": 287812,
        "start": 2902.3199999999997,
        "temperature": 0,
        "text": " So here, I'm going to say colon flower.",
        "tokens": [
          51574,
          407,
          510,
          11,
          286,
          478,
          516,
          281,
          584,
          8255,
          8617,
          13,
          51705
        ]
      },
      {
        "avg_logprob": -0.21279361683835266,
        "compression_ratio": 1.6310679611650485,
        "end": 2910.26,
        "id": 1023,
        "no_speech_prob": 3.011595595125982e-7,
        "seek": 290494,
        "start": 2904.94,
        "temperature": 0,
        "text": " So that indicates that this search, that search",
        "tokens": [
          50364,
          407,
          300,
          16203,
          300,
          341,
          3164,
          11,
          300,
          3164,
          50630
        ]
      },
      {
        "avg_logprob": -0.21279361683835266,
        "compression_ratio": 1.6310679611650485,
        "end": 2914.2200000000003,
        "id": 1024,
        "no_speech_prob": 3.011595595125982e-7,
        "seek": 290494,
        "start": 2910.26,
        "temperature": 0,
        "text": " is the route followed by something that the user enters.",
        "tokens": [
          50630,
          307,
          264,
          7955,
          6263,
          538,
          746,
          300,
          264,
          4195,
          18780,
          13,
          50828
        ]
      },
      {
        "avg_logprob": -0.21279361683835266,
        "compression_ratio": 1.6310679611650485,
        "end": 2917.94,
        "id": 1025,
        "no_speech_prob": 3.011595595125982e-7,
        "seek": 290494,
        "start": 2914.2200000000003,
        "temperature": 0,
        "text": " And that will be here found in the request.",
        "tokens": [
          50828,
          400,
          300,
          486,
          312,
          510,
          1352,
          294,
          264,
          5308,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.21279361683835266,
        "compression_ratio": 1.6310679611650485,
        "end": 2925.7000000000003,
        "id": 1026,
        "no_speech_prob": 3.011595595125982e-7,
        "seek": 290494,
        "start": 2917.94,
        "temperature": 0,
        "text": " So in other words, I'm now going to go to search slash sunflower.",
        "tokens": [
          51014,
          407,
          294,
          661,
          2283,
          11,
          286,
          478,
          586,
          516,
          281,
          352,
          281,
          3164,
          17330,
          48215,
          13,
          51402
        ]
      },
      {
        "avg_logprob": -0.21279361683835266,
        "compression_ratio": 1.6310679611650485,
        "end": 2928.78,
        "id": 1027,
        "no_speech_prob": 3.011595595125982e-7,
        "seek": 290494,
        "start": 2925.7000000000003,
        "temperature": 0,
        "text": " And you're going to see it still says, I love flowers too.",
        "tokens": [
          51402,
          400,
          291,
          434,
          516,
          281,
          536,
          309,
          920,
          1619,
          11,
          286,
          959,
          8085,
          886,
          13,
          51556
        ]
      },
      {
        "avg_logprob": -0.21279361683835266,
        "compression_ratio": 1.6310679611650485,
        "end": 2930.7400000000002,
        "id": 1028,
        "no_speech_prob": 3.011595595125982e-7,
        "seek": 290494,
        "start": 2928.78,
        "temperature": 0,
        "text": " That's what I'm sending back.",
        "tokens": [
          51556,
          663,
          311,
          437,
          286,
          478,
          7750,
          646,
          13,
          51654
        ]
      },
      {
        "avg_logprob": -0.21279361683835266,
        "compression_ratio": 1.6310679611650485,
        "end": 2933.2200000000003,
        "id": 1029,
        "no_speech_prob": 3.011595595125982e-7,
        "seek": 290494,
        "start": 2930.7400000000002,
        "temperature": 0,
        "text": " But now I can do something more.",
        "tokens": [
          51654,
          583,
          586,
          286,
          393,
          360,
          746,
          544,
          13,
          51778
        ]
      },
      {
        "avg_logprob": -0.20964907361315444,
        "compression_ratio": 1.567251461988304,
        "end": 2938.18,
        "id": 1030,
        "no_speech_prob": 0.00000533815500602941,
        "seek": 293322,
        "start": 2933.22,
        "temperature": 0,
        "text": " I can say, there's some data associated with this request.",
        "tokens": [
          50364,
          286,
          393,
          584,
          11,
          456,
          311,
          512,
          1412,
          6615,
          365,
          341,
          5308,
          13,
          50612
        ]
      },
      {
        "avg_logprob": -0.20964907361315444,
        "compression_ratio": 1.567251461988304,
        "end": 2942.14,
        "id": 1031,
        "no_speech_prob": 0.00000533815500602941,
        "seek": 293322,
        "start": 2938.18,
        "temperature": 0,
        "text": " Something came in beyond just search, some type of flower.",
        "tokens": [
          50612,
          6595,
          1361,
          294,
          4399,
          445,
          3164,
          11,
          512,
          2010,
          295,
          8617,
          13,
          50810
        ]
      },
      {
        "avg_logprob": -0.20964907361315444,
        "compression_ratio": 1.567251461988304,
        "end": 2945.98,
        "id": 1032,
        "no_speech_prob": 0.00000533815500602941,
        "seek": 293322,
        "start": 2942.14,
        "temperature": 0,
        "text": " I can say request dot params.",
        "tokens": [
          50810,
          286,
          393,
          584,
          5308,
          5893,
          971,
          4070,
          13,
          51002
        ]
      },
      {
        "avg_logprob": -0.20964907361315444,
        "compression_ratio": 1.567251461988304,
        "end": 2947.02,
        "id": 1033,
        "no_speech_prob": 0.00000533815500602941,
        "seek": 293322,
        "start": 2945.98,
        "temperature": 0,
        "text": " There are parameters.",
        "tokens": [
          51002,
          821,
          366,
          9834,
          13,
          51054
        ]
      },
      {
        "avg_logprob": -0.20964907361315444,
        "compression_ratio": 1.567251461988304,
        "end": 2949.06,
        "id": 1034,
        "no_speech_prob": 0.00000533815500602941,
        "seek": 293322,
        "start": 2947.02,
        "temperature": 0,
        "text": " Flower is a parameter.",
        "tokens": [
          51054,
          34993,
          307,
          257,
          13075,
          13,
          51156
        ]
      },
      {
        "avg_logprob": -0.20964907361315444,
        "compression_ratio": 1.567251461988304,
        "end": 2952.8199999999997,
        "id": 1035,
        "no_speech_prob": 0.00000533815500602941,
        "seek": 293322,
        "start": 2949.06,
        "temperature": 0,
        "text": " And now I can say here, send the response back.",
        "tokens": [
          51156,
          400,
          586,
          286,
          393,
          584,
          510,
          11,
          2845,
          264,
          4134,
          646,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.20964907361315444,
        "compression_ratio": 1.567251461988304,
        "end": 2962.7,
        "id": 1036,
        "no_speech_prob": 0.00000533815500602941,
        "seek": 293322,
        "start": 2952.8199999999997,
        "temperature": 0,
        "text": " I love data dot flower too.",
        "tokens": [
          51344,
          286,
          959,
          1412,
          5893,
          8617,
          886,
          13,
          51838
        ]
      },
      {
        "avg_logprob": -0.224053928769868,
        "compression_ratio": 1.7602996254681649,
        "end": 2964.98,
        "id": 1037,
        "no_speech_prob": 0.00004133527181693353,
        "seek": 296270,
        "start": 2962.7,
        "temperature": 0,
        "text": " So I'm kind of, I don't like this amount of space",
        "tokens": [
          50364,
          407,
          286,
          478,
          733,
          295,
          11,
          286,
          500,
          380,
          411,
          341,
          2372,
          295,
          1901,
          50478
        ]
      },
      {
        "avg_logprob": -0.224053928769868,
        "compression_ratio": 1.7602996254681649,
        "end": 2966.4199999999996,
        "id": 1038,
        "no_speech_prob": 0.00004133527181693353,
        "seek": 296270,
        "start": 2964.98,
        "temperature": 0,
        "text": " that I have here.",
        "tokens": [
          50478,
          300,
          286,
          362,
          510,
          13,
          50550
        ]
      },
      {
        "avg_logprob": -0.224053928769868,
        "compression_ratio": 1.7602996254681649,
        "end": 2969.02,
        "id": 1039,
        "no_speech_prob": 0.00004133527181693353,
        "seek": 296270,
        "start": 2966.4199999999996,
        "temperature": 0,
        "text": " I'm going to fix this and make this a little smaller.",
        "tokens": [
          50550,
          286,
          478,
          516,
          281,
          3191,
          341,
          293,
          652,
          341,
          257,
          707,
          4356,
          13,
          50680
        ]
      },
      {
        "avg_logprob": -0.224053928769868,
        "compression_ratio": 1.7602996254681649,
        "end": 2971.14,
        "id": 1040,
        "no_speech_prob": 0.00004133527181693353,
        "seek": 296270,
        "start": 2969.02,
        "temperature": 0,
        "text": " No, no, way too small.",
        "tokens": [
          50680,
          883,
          11,
          572,
          11,
          636,
          886,
          1359,
          13,
          50786
        ]
      },
      {
        "avg_logprob": -0.224053928769868,
        "compression_ratio": 1.7602996254681649,
        "end": 2976.06,
        "id": 1041,
        "no_speech_prob": 0.00004133527181693353,
        "seek": 296270,
        "start": 2971.14,
        "temperature": 0,
        "text": " Maybe this will get edited for flow.",
        "tokens": [
          50786,
          2704,
          341,
          486,
          483,
          23016,
          337,
          3095,
          13,
          51032
        ]
      },
      {
        "avg_logprob": -0.224053928769868,
        "compression_ratio": 1.7602996254681649,
        "end": 2979.8399999999997,
        "id": 1042,
        "no_speech_prob": 0.00004133527181693353,
        "seek": 296270,
        "start": 2976.06,
        "temperature": 0,
        "text": " So here, you can see that in the response,",
        "tokens": [
          51032,
          407,
          510,
          11,
          291,
          393,
          536,
          300,
          294,
          264,
          4134,
          11,
          51221
        ]
      },
      {
        "avg_logprob": -0.224053928769868,
        "compression_ratio": 1.7602996254681649,
        "end": 2982.5,
        "id": 1043,
        "no_speech_prob": 0.00004133527181693353,
        "seek": 296270,
        "start": 2979.8399999999997,
        "temperature": 0,
        "text": " I'm actually going to send back something that was sent.",
        "tokens": [
          51221,
          286,
          478,
          767,
          516,
          281,
          2845,
          646,
          746,
          300,
          390,
          2279,
          13,
          51354
        ]
      },
      {
        "avg_logprob": -0.224053928769868,
        "compression_ratio": 1.7602996254681649,
        "end": 2985.06,
        "id": 1044,
        "no_speech_prob": 0.00004133527181693353,
        "seek": 296270,
        "start": 2982.5,
        "temperature": 0,
        "text": " Now, what I'm doing here has no, there's no point to it.",
        "tokens": [
          51354,
          823,
          11,
          437,
          286,
          478,
          884,
          510,
          575,
          572,
          11,
          456,
          311,
          572,
          935,
          281,
          309,
          13,
          51482
        ]
      },
      {
        "avg_logprob": -0.224053928769868,
        "compression_ratio": 1.7602996254681649,
        "end": 2987.1,
        "id": 1045,
        "no_speech_prob": 0.00004133527181693353,
        "seek": 296270,
        "start": 2985.06,
        "temperature": 0,
        "text": " I'm just showing you the pieces of how things work",
        "tokens": [
          51482,
          286,
          478,
          445,
          4099,
          291,
          264,
          3755,
          295,
          577,
          721,
          589,
          51584
        ]
      },
      {
        "avg_logprob": -0.224053928769868,
        "compression_ratio": 1.7602996254681649,
        "end": 2989.7,
        "id": 1046,
        "no_speech_prob": 0.00004133527181693353,
        "seek": 296270,
        "start": 2987.1,
        "temperature": 0,
        "text": " so we can get to the place where it has a point.",
        "tokens": [
          51584,
          370,
          321,
          393,
          483,
          281,
          264,
          1081,
          689,
          309,
          575,
          257,
          935,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.224053928769868,
        "compression_ratio": 1.7602996254681649,
        "end": 2992.54,
        "id": 1047,
        "no_speech_prob": 0.00004133527181693353,
        "seek": 296270,
        "start": 2989.7,
        "temperature": 0,
        "text": " So let's see now if this works.",
        "tokens": [
          51714,
          407,
          718,
          311,
          536,
          586,
          498,
          341,
          1985,
          13,
          51856
        ]
      },
      {
        "avg_logprob": -0.20354820365336404,
        "compression_ratio": 1.7590361445783131,
        "end": 2995.3,
        "id": 1048,
        "no_speech_prob": 0.000029773094865959138,
        "seek": 299254,
        "start": 2992.54,
        "temperature": 0,
        "text": " If I refresh here, I love sunflower too.",
        "tokens": [
          50364,
          759,
          286,
          15134,
          510,
          11,
          286,
          959,
          48215,
          886,
          13,
          50502
        ]
      },
      {
        "avg_logprob": -0.20354820365336404,
        "compression_ratio": 1.7590361445783131,
        "end": 2997.7,
        "id": 1049,
        "no_speech_prob": 0.000029773094865959138,
        "seek": 299254,
        "start": 2995.3,
        "temperature": 0,
        "text": " And I can put daisy.",
        "tokens": [
          50502,
          400,
          286,
          393,
          829,
          1120,
          14169,
          13,
          50622
        ]
      },
      {
        "avg_logprob": -0.20354820365336404,
        "compression_ratio": 1.7590361445783131,
        "end": 2998.82,
        "id": 1050,
        "no_speech_prob": 0.000029773094865959138,
        "seek": 299254,
        "start": 2997.7,
        "temperature": 0,
        "text": " I love daisy too.",
        "tokens": [
          50622,
          286,
          959,
          1120,
          14169,
          886,
          13,
          50678
        ]
      },
      {
        "avg_logprob": -0.20354820365336404,
        "compression_ratio": 1.7590361445783131,
        "end": 3000.18,
        "id": 1051,
        "no_speech_prob": 0.000029773094865959138,
        "seek": 299254,
        "start": 2998.82,
        "temperature": 0,
        "text": " And I can put rainbow.",
        "tokens": [
          50678,
          400,
          286,
          393,
          829,
          18526,
          13,
          50746
        ]
      },
      {
        "avg_logprob": -0.20354820365336404,
        "compression_ratio": 1.7590361445783131,
        "end": 3001.34,
        "id": 1052,
        "no_speech_prob": 0.000029773094865959138,
        "seek": 299254,
        "start": 3000.18,
        "temperature": 0,
        "text": " Doesn't have to be a flower.",
        "tokens": [
          50746,
          12955,
          380,
          362,
          281,
          312,
          257,
          8617,
          13,
          50804
        ]
      },
      {
        "avg_logprob": -0.20354820365336404,
        "compression_ratio": 1.7590361445783131,
        "end": 3003.22,
        "id": 1053,
        "no_speech_prob": 0.000029773094865959138,
        "seek": 299254,
        "start": 3001.34,
        "temperature": 0,
        "text": " And I can put, so in other words,",
        "tokens": [
          50804,
          400,
          286,
          393,
          829,
          11,
          370,
          294,
          661,
          2283,
          11,
          50898
        ]
      },
      {
        "avg_logprob": -0.20354820365336404,
        "compression_ratio": 1.7590361445783131,
        "end": 3004.9,
        "id": 1054,
        "no_speech_prob": 0.000029773094865959138,
        "seek": 299254,
        "start": 3003.22,
        "temperature": 0,
        "text": " there's a round trip happening.",
        "tokens": [
          50898,
          456,
          311,
          257,
          3098,
          4931,
          2737,
          13,
          50982
        ]
      },
      {
        "avg_logprob": -0.20354820365336404,
        "compression_ratio": 1.7590361445783131,
        "end": 3007.58,
        "id": 1055,
        "no_speech_prob": 0.000029773094865959138,
        "seek": 299254,
        "start": 3004.9,
        "temperature": 0,
        "text": " I'm making a get request with this route,",
        "tokens": [
          50982,
          286,
          478,
          1455,
          257,
          483,
          5308,
          365,
          341,
          7955,
          11,
          51116
        ]
      },
      {
        "avg_logprob": -0.20354820365336404,
        "compression_ratio": 1.7590361445783131,
        "end": 3010.22,
        "id": 1056,
        "no_speech_prob": 0.000029773094865959138,
        "seek": 299254,
        "start": 3007.58,
        "temperature": 0,
        "text": " search slash something.",
        "tokens": [
          51116,
          3164,
          17330,
          746,
          13,
          51248
        ]
      },
      {
        "avg_logprob": -0.20354820365336404,
        "compression_ratio": 1.7590361445783131,
        "end": 3013.58,
        "id": 1057,
        "no_speech_prob": 0.000029773094865959138,
        "seek": 299254,
        "start": 3010.22,
        "temperature": 0,
        "text": " The server gets that something as a parameter",
        "tokens": [
          51248,
          440,
          7154,
          2170,
          300,
          746,
          382,
          257,
          13075,
          51416
        ]
      },
      {
        "avg_logprob": -0.20354820365336404,
        "compression_ratio": 1.7590361445783131,
        "end": 3016.94,
        "id": 1058,
        "no_speech_prob": 0.000029773094865959138,
        "seek": 299254,
        "start": 3013.58,
        "temperature": 0,
        "text": " part of the request and looks at it,",
        "tokens": [
          51416,
          644,
          295,
          264,
          5308,
          293,
          1542,
          412,
          309,
          11,
          51584
        ]
      },
      {
        "avg_logprob": -0.20354820365336404,
        "compression_ratio": 1.7590361445783131,
        "end": 3019.66,
        "id": 1059,
        "no_speech_prob": 0.000029773094865959138,
        "seek": 299254,
        "start": 3016.94,
        "temperature": 0,
        "text": " puts it in this variable data, and pulls out flower.",
        "tokens": [
          51584,
          8137,
          309,
          294,
          341,
          7006,
          1412,
          11,
          293,
          16982,
          484,
          8617,
          13,
          51720
        ]
      },
      {
        "avg_logprob": -0.20354820365336404,
        "compression_ratio": 1.7590361445783131,
        "end": 3021.58,
        "id": 1060,
        "no_speech_prob": 0.000029773094865959138,
        "seek": 299254,
        "start": 3019.66,
        "temperature": 0,
        "text": " So there could be a lot of parameters.",
        "tokens": [
          51720,
          407,
          456,
          727,
          312,
          257,
          688,
          295,
          9834,
          13,
          51816
        ]
      },
      {
        "avg_logprob": -0.2119348576638551,
        "compression_ratio": 1.645933014354067,
        "end": 3023.34,
        "id": 1061,
        "no_speech_prob": 0.000018631682905834168,
        "seek": 302158,
        "start": 3021.58,
        "temperature": 0,
        "text": " So I can add another one.",
        "tokens": [
          50364,
          407,
          286,
          393,
          909,
          1071,
          472,
          13,
          50452
        ]
      },
      {
        "avg_logprob": -0.2119348576638551,
        "compression_ratio": 1.645933014354067,
        "end": 3027.18,
        "id": 1062,
        "no_speech_prob": 0.000018631682905834168,
        "seek": 302158,
        "start": 3023.34,
        "temperature": 0,
        "text": " I could say slash num.",
        "tokens": [
          50452,
          286,
          727,
          584,
          17330,
          1031,
          13,
          50644
        ]
      },
      {
        "avg_logprob": -0.2119348576638551,
        "compression_ratio": 1.645933014354067,
        "end": 3032.22,
        "id": 1063,
        "no_speech_prob": 0.000018631682905834168,
        "seek": 302158,
        "start": 3027.18,
        "temperature": 0,
        "text": " And then I can say var num equals data.num.",
        "tokens": [
          50644,
          400,
          550,
          286,
          393,
          584,
          1374,
          1031,
          6915,
          1412,
          13,
          77,
          449,
          13,
          50896
        ]
      },
      {
        "avg_logprob": -0.2119348576638551,
        "compression_ratio": 1.645933014354067,
        "end": 3035.62,
        "id": 1064,
        "no_speech_prob": 0.000018631682905834168,
        "seek": 302158,
        "start": 3032.22,
        "temperature": 0,
        "text": " And I can then have, I was going to do a for loop or something",
        "tokens": [
          50896,
          400,
          286,
          393,
          550,
          362,
          11,
          286,
          390,
          516,
          281,
          360,
          257,
          337,
          6367,
          420,
          746,
          51066
        ]
      },
      {
        "avg_logprob": -0.2119348576638551,
        "compression_ratio": 1.645933014354067,
        "end": 3039.46,
        "id": 1065,
        "no_speech_prob": 0.000018631682905834168,
        "seek": 302158,
        "start": 3035.62,
        "temperature": 0,
        "text": " and have it say I love data.flower so many times.",
        "tokens": [
          51066,
          293,
          362,
          309,
          584,
          286,
          959,
          1412,
          13,
          30794,
          370,
          867,
          1413,
          13,
          51258
        ]
      },
      {
        "avg_logprob": -0.2119348576638551,
        "compression_ratio": 1.645933014354067,
        "end": 3040.2999999999997,
        "id": 1066,
        "no_speech_prob": 0.000018631682905834168,
        "seek": 302158,
        "start": 3039.46,
        "temperature": 0,
        "text": " Let's just do that.",
        "tokens": [
          51258,
          961,
          311,
          445,
          360,
          300,
          13,
          51300
        ]
      },
      {
        "avg_logprob": -0.2119348576638551,
        "compression_ratio": 1.645933014354067,
        "end": 3042.38,
        "id": 1067,
        "no_speech_prob": 0.000018631682905834168,
        "seek": 302158,
        "start": 3040.2999999999997,
        "temperature": 0,
        "text": " That's sort of silly, but why not?",
        "tokens": [
          51300,
          663,
          311,
          1333,
          295,
          11774,
          11,
          457,
          983,
          406,
          30,
          51404
        ]
      },
      {
        "avg_logprob": -0.2119348576638551,
        "compression_ratio": 1.645933014354067,
        "end": 3045.18,
        "id": 1068,
        "no_speech_prob": 0.000018631682905834168,
        "seek": 302158,
        "start": 3042.38,
        "temperature": 0,
        "text": " So I can say response equals this.",
        "tokens": [
          51404,
          407,
          286,
          393,
          584,
          4134,
          6915,
          341,
          13,
          51544
        ]
      },
      {
        "avg_logprob": -0.2119348576638551,
        "compression_ratio": 1.645933014354067,
        "end": 3050.22,
        "id": 1069,
        "no_speech_prob": 0.000018631682905834168,
        "seek": 302158,
        "start": 3045.18,
        "temperature": 0,
        "text": " And then for var i equals 0, i is less than num.",
        "tokens": [
          51544,
          400,
          550,
          337,
          1374,
          741,
          6915,
          1958,
          11,
          741,
          307,
          1570,
          813,
          1031,
          13,
          51796
        ]
      },
      {
        "avg_logprob": -0.23090612663412993,
        "compression_ratio": 1.6009852216748768,
        "end": 3053.5,
        "id": 1070,
        "no_speech_prob": 0.00008750250708544627,
        "seek": 305022,
        "start": 3050.22,
        "temperature": 0,
        "text": " i plus plus.",
        "tokens": [
          50364,
          741,
          1804,
          1804,
          13,
          50528
        ]
      },
      {
        "avg_logprob": -0.23090612663412993,
        "compression_ratio": 1.6009852216748768,
        "end": 3055.22,
        "id": 1071,
        "no_speech_prob": 0.00008750250708544627,
        "seek": 305022,
        "start": 3053.5,
        "temperature": 0,
        "text": " I can't call this response.",
        "tokens": [
          50528,
          286,
          393,
          380,
          818,
          341,
          4134,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.23090612663412993,
        "compression_ratio": 1.6009852216748768,
        "end": 3062.9399999999996,
        "id": 1072,
        "no_speech_prob": 0.00008750250708544627,
        "seek": 305022,
        "start": 3055.22,
        "temperature": 0,
        "text": " Reply, I'll call it reply plus equal this.",
        "tokens": [
          50614,
          3696,
          356,
          11,
          286,
          603,
          818,
          309,
          16972,
          1804,
          2681,
          341,
          13,
          51000
        ]
      },
      {
        "avg_logprob": -0.23090612663412993,
        "compression_ratio": 1.6009852216748768,
        "end": 3066.58,
        "id": 1073,
        "no_speech_prob": 0.00008750250708544627,
        "seek": 305022,
        "start": 3062.9399999999996,
        "temperature": 0,
        "text": " And then I'm going to send back that reply.",
        "tokens": [
          51000,
          400,
          550,
          286,
          478,
          516,
          281,
          2845,
          646,
          300,
          16972,
          13,
          51182
        ]
      },
      {
        "avg_logprob": -0.23090612663412993,
        "compression_ratio": 1.6009852216748768,
        "end": 3067.9399999999996,
        "id": 1074,
        "no_speech_prob": 0.00008750250708544627,
        "seek": 305022,
        "start": 3066.58,
        "temperature": 0,
        "text": " So I've added a little logic.",
        "tokens": [
          51182,
          407,
          286,
          600,
          3869,
          257,
          707,
          9952,
          13,
          51250
        ]
      },
      {
        "avg_logprob": -0.23090612663412993,
        "compression_ratio": 1.6009852216748768,
        "end": 3069.98,
        "id": 1075,
        "no_speech_prob": 0.00008750250708544627,
        "seek": 305022,
        "start": 3067.9399999999996,
        "temperature": 0,
        "text": " So based on whatever number I get in,",
        "tokens": [
          51250,
          407,
          2361,
          322,
          2035,
          1230,
          286,
          483,
          294,
          11,
          51352
        ]
      },
      {
        "avg_logprob": -0.23090612663412993,
        "compression_ratio": 1.6009852216748768,
        "end": 3071.62,
        "id": 1076,
        "no_speech_prob": 0.00008750250708544627,
        "seek": 305022,
        "start": 3069.98,
        "temperature": 0,
        "text": " I do that a bunch of times.",
        "tokens": [
          51352,
          286,
          360,
          300,
          257,
          3840,
          295,
          1413,
          13,
          51434
        ]
      },
      {
        "avg_logprob": -0.23090612663412993,
        "compression_ratio": 1.6009852216748768,
        "end": 3075.2599999999998,
        "id": 1077,
        "no_speech_prob": 0.00008750250708544627,
        "seek": 305022,
        "start": 3071.62,
        "temperature": 0,
        "text": " And now we can see I'm getting both a flower and a number.",
        "tokens": [
          51434,
          400,
          586,
          321,
          393,
          536,
          286,
          478,
          1242,
          1293,
          257,
          8617,
          293,
          257,
          1230,
          13,
          51616
        ]
      },
      {
        "avg_logprob": -0.23090612663412993,
        "compression_ratio": 1.6009852216748768,
        "end": 3079.62,
        "id": 1078,
        "no_speech_prob": 0.00008750250708544627,
        "seek": 305022,
        "start": 3075.2599999999998,
        "temperature": 0,
        "text": " And if I go search rainbow five, I get it.",
        "tokens": [
          51616,
          400,
          498,
          286,
          352,
          3164,
          18526,
          1732,
          11,
          286,
          483,
          309,
          13,
          51834
        ]
      },
      {
        "avg_logprob": -0.24697765774197047,
        "compression_ratio": 1.689922480620155,
        "end": 3082.94,
        "id": 1079,
        "no_speech_prob": 0.000015689533029217273,
        "seek": 307962,
        "start": 3079.62,
        "temperature": 0,
        "text": " If I do it slash 50, I get it 50 times.",
        "tokens": [
          50364,
          759,
          286,
          360,
          309,
          17330,
          2625,
          11,
          286,
          483,
          309,
          2625,
          1413,
          13,
          50530
        ]
      },
      {
        "avg_logprob": -0.24697765774197047,
        "compression_ratio": 1.689922480620155,
        "end": 3086.18,
        "id": 1080,
        "no_speech_prob": 0.000015689533029217273,
        "seek": 307962,
        "start": 3082.94,
        "temperature": 0,
        "text": " So the reply is now based on what",
        "tokens": [
          50530,
          407,
          264,
          16972,
          307,
          586,
          2361,
          322,
          437,
          50692
        ]
      },
      {
        "avg_logprob": -0.24697765774197047,
        "compression_ratio": 1.689922480620155,
        "end": 3088.7799999999997,
        "id": 1081,
        "no_speech_prob": 0.000015689533029217273,
        "seek": 307962,
        "start": 3086.18,
        "temperature": 0,
        "text": " has been sent into the server.",
        "tokens": [
          50692,
          575,
          668,
          2279,
          666,
          264,
          7154,
          13,
          50822
        ]
      },
      {
        "avg_logprob": -0.24697765774197047,
        "compression_ratio": 1.689922480620155,
        "end": 3095.7,
        "id": 1082,
        "no_speech_prob": 0.000015689533029217273,
        "seek": 307962,
        "start": 3088.7799999999997,
        "temperature": 0,
        "text": " So this is the basic idea of how a route works",
        "tokens": [
          50822,
          407,
          341,
          307,
          264,
          3875,
          1558,
          295,
          577,
          257,
          7955,
          1985,
          51168
        ]
      },
      {
        "avg_logprob": -0.24697765774197047,
        "compression_ratio": 1.689922480620155,
        "end": 3096.66,
        "id": 1083,
        "no_speech_prob": 0.000015689533029217273,
        "seek": 307962,
        "start": 3095.7,
        "temperature": 0,
        "text": " with a get request.",
        "tokens": [
          51168,
          365,
          257,
          483,
          5308,
          13,
          51216
        ]
      },
      {
        "avg_logprob": -0.24697765774197047,
        "compression_ratio": 1.689922480620155,
        "end": 3098.38,
        "id": 1084,
        "no_speech_prob": 0.000015689533029217273,
        "seek": 307962,
        "start": 3096.66,
        "temperature": 0,
        "text": " Now, of course, there's something later",
        "tokens": [
          51216,
          823,
          11,
          295,
          1164,
          11,
          456,
          311,
          746,
          1780,
          51302
        ]
      },
      {
        "avg_logprob": -0.24697765774197047,
        "compression_ratio": 1.689922480620155,
        "end": 3100.38,
        "id": 1085,
        "no_speech_prob": 0.000015689533029217273,
        "seek": 307962,
        "start": 3098.38,
        "temperature": 0,
        "text": " you're going to see there's also a post request.",
        "tokens": [
          51302,
          291,
          434,
          516,
          281,
          536,
          456,
          311,
          611,
          257,
          2183,
          5308,
          13,
          51402
        ]
      },
      {
        "avg_logprob": -0.24697765774197047,
        "compression_ratio": 1.689922480620155,
        "end": 3101.2999999999997,
        "id": 1086,
        "no_speech_prob": 0.000015689533029217273,
        "seek": 307962,
        "start": 3100.38,
        "temperature": 0,
        "text": " I can say app.post.",
        "tokens": [
          51402,
          286,
          393,
          584,
          724,
          13,
          23744,
          13,
          51448
        ]
      },
      {
        "avg_logprob": -0.24697765774197047,
        "compression_ratio": 1.689922480620155,
        "end": 3103.14,
        "id": 1087,
        "no_speech_prob": 0.000015689533029217273,
        "seek": 307962,
        "start": 3101.2999999999997,
        "temperature": 0,
        "text": " And we're going to need that for this example",
        "tokens": [
          51448,
          400,
          321,
          434,
          516,
          281,
          643,
          300,
          337,
          341,
          1365,
          51540
        ]
      },
      {
        "avg_logprob": -0.24697765774197047,
        "compression_ratio": 1.689922480620155,
        "end": 3105.14,
        "id": 1088,
        "no_speech_prob": 0.000015689533029217273,
        "seek": 307962,
        "start": 3103.14,
        "temperature": 0,
        "text": " that I hope to ultimately build.",
        "tokens": [
          51540,
          300,
          286,
          1454,
          281,
          6284,
          1322,
          13,
          51640
        ]
      },
      {
        "avg_logprob": -0.24697765774197047,
        "compression_ratio": 1.689922480620155,
        "end": 3107.2999999999997,
        "id": 1089,
        "no_speech_prob": 0.000015689533029217273,
        "seek": 307962,
        "start": 3105.14,
        "temperature": 0,
        "text": " But in the next example, what I want to,",
        "tokens": [
          51640,
          583,
          294,
          264,
          958,
          1365,
          11,
          437,
          286,
          528,
          281,
          11,
          51748
        ]
      },
      {
        "avg_logprob": -0.24697765774197047,
        "compression_ratio": 1.689922480620155,
        "end": 3108.7999999999997,
        "id": 1090,
        "no_speech_prob": 0.000015689533029217273,
        "seek": 307962,
        "start": 3107.2999999999997,
        "temperature": 0,
        "text": " what the next video I want to do is",
        "tokens": [
          51748,
          437,
          264,
          958,
          960,
          286,
          528,
          281,
          360,
          307,
          51823
        ]
      },
      {
        "avg_logprob": -0.24859170655946475,
        "compression_ratio": 1.6186046511627907,
        "end": 3111.2400000000002,
        "id": 1091,
        "no_speech_prob": 0.0001442584180040285,
        "seek": 310880,
        "start": 3108.8,
        "temperature": 0,
        "text": " add a little bit of persistence to this.",
        "tokens": [
          50364,
          909,
          257,
          707,
          857,
          295,
          37617,
          281,
          341,
          13,
          50486
        ]
      },
      {
        "avg_logprob": -0.24859170655946475,
        "compression_ratio": 1.6186046511627907,
        "end": 3115.52,
        "id": 1092,
        "no_speech_prob": 0.0001442584180040285,
        "seek": 310880,
        "start": 3111.2400000000002,
        "temperature": 0,
        "text": " So what I want to do is create a set of routes",
        "tokens": [
          50486,
          407,
          437,
          286,
          528,
          281,
          360,
          307,
          1884,
          257,
          992,
          295,
          18242,
          50700
        ]
      },
      {
        "avg_logprob": -0.24859170655946475,
        "compression_ratio": 1.6186046511627907,
        "end": 3118.32,
        "id": 1093,
        "no_speech_prob": 0.0001442584180040285,
        "seek": 310880,
        "start": 3115.52,
        "temperature": 0,
        "text": " where the user can retrieve data and then contribute",
        "tokens": [
          50700,
          689,
          264,
          4195,
          393,
          30254,
          1412,
          293,
          550,
          10586,
          50840
        ]
      },
      {
        "avg_logprob": -0.24859170655946475,
        "compression_ratio": 1.6186046511627907,
        "end": 3120.7200000000003,
        "id": 1094,
        "no_speech_prob": 0.0001442584180040285,
        "seek": 310880,
        "start": 3118.32,
        "temperature": 0,
        "text": " to that data as well.",
        "tokens": [
          50840,
          281,
          300,
          1412,
          382,
          731,
          13,
          50960
        ]
      },
      {
        "avg_logprob": -0.24859170655946475,
        "compression_ratio": 1.6186046511627907,
        "end": 3122.5600000000004,
        "id": 1095,
        "no_speech_prob": 0.0001442584180040285,
        "seek": 310880,
        "start": 3120.7200000000003,
        "temperature": 0,
        "text": " So we'll see that in the next video.",
        "tokens": [
          50960,
          407,
          321,
          603,
          536,
          300,
          294,
          264,
          958,
          960,
          13,
          51052
        ]
      },
      {
        "avg_logprob": -0.24859170655946475,
        "compression_ratio": 1.6186046511627907,
        "end": 3129.76,
        "id": 1096,
        "no_speech_prob": 0.0001442584180040285,
        "seek": 310880,
        "start": 3127.44,
        "temperature": 0,
        "text": " All of a sudden, I have my cough is back.",
        "tokens": [
          51296,
          1057,
          295,
          257,
          3990,
          11,
          286,
          362,
          452,
          22777,
          307,
          646,
          13,
          51412
        ]
      },
      {
        "avg_logprob": -0.24859170655946475,
        "compression_ratio": 1.6186046511627907,
        "end": 3131.0800000000004,
        "id": 1097,
        "no_speech_prob": 0.0001442584180040285,
        "seek": 310880,
        "start": 3129.76,
        "temperature": 0,
        "text": " It is 5 of 4.",
        "tokens": [
          51412,
          467,
          307,
          1025,
          295,
          1017,
          13,
          51478
        ]
      },
      {
        "avg_logprob": -0.24859170655946475,
        "compression_ratio": 1.6186046511627907,
        "end": 3132.2000000000003,
        "id": 1098,
        "no_speech_prob": 0.0001442584180040285,
        "seek": 310880,
        "start": 3131.0800000000004,
        "temperature": 0,
        "text": " It's very hot in this room.",
        "tokens": [
          51478,
          467,
          311,
          588,
          2368,
          294,
          341,
          1808,
          13,
          51534
        ]
      },
      {
        "avg_logprob": -0.24859170655946475,
        "compression_ratio": 1.6186046511627907,
        "end": 3133.6400000000003,
        "id": 1099,
        "no_speech_prob": 0.0001442584180040285,
        "seek": 310880,
        "start": 3132.2000000000003,
        "temperature": 0,
        "text": " Again, I think the heat is on.",
        "tokens": [
          51534,
          3764,
          11,
          286,
          519,
          264,
          3738,
          307,
          322,
          13,
          51606
        ]
      },
      {
        "avg_logprob": -0.24859170655946475,
        "compression_ratio": 1.6186046511627907,
        "end": 3135.02,
        "id": 1100,
        "no_speech_prob": 0.0001442584180040285,
        "seek": 310880,
        "start": 3133.6400000000003,
        "temperature": 0,
        "text": " And then I have these hot lights.",
        "tokens": [
          51606,
          400,
          550,
          286,
          362,
          613,
          2368,
          5811,
          13,
          51675
        ]
      },
      {
        "avg_logprob": -0.3522287328192528,
        "compression_ratio": 1.2727272727272727,
        "end": 3141.7,
        "id": 1101,
        "no_speech_prob": 0.000005422191861725878,
        "seek": 313502,
        "start": 3135.98,
        "temperature": 0,
        "text": " Is this making sense, everybody?",
        "tokens": [
          50412,
          1119,
          341,
          1455,
          2020,
          11,
          2201,
          30,
          50698
        ]
      },
      {
        "avg_logprob": -0.3522287328192528,
        "compression_ratio": 1.2727272727272727,
        "end": 3142.2599999999998,
        "id": 1102,
        "no_speech_prob": 0.000005422191861725878,
        "seek": 313502,
        "start": 3141.7,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          50698,
          286,
          500,
          380,
          458,
          13,
          50726
        ]
      },
      {
        "avg_logprob": -0.3522287328192528,
        "compression_ratio": 1.2727272727272727,
        "end": 3145.62,
        "id": 1103,
        "no_speech_prob": 0.000005422191861725878,
        "seek": 313502,
        "start": 3142.2599999999998,
        "temperature": 0,
        "text": " I'm kind of making these really, really short.",
        "tokens": [
          50726,
          286,
          478,
          733,
          295,
          1455,
          613,
          534,
          11,
          534,
          2099,
          13,
          50894
        ]
      },
      {
        "avg_logprob": -0.3522287328192528,
        "compression_ratio": 1.2727272727272727,
        "end": 3151.34,
        "id": 1104,
        "no_speech_prob": 0.000005422191861725878,
        "seek": 313502,
        "start": 3145.62,
        "temperature": 0,
        "text": " Yeah, this cold that I've had has just been lasting forever.",
        "tokens": [
          50894,
          865,
          11,
          341,
          3554,
          300,
          286,
          600,
          632,
          575,
          445,
          668,
          20714,
          5680,
          13,
          51180
        ]
      },
      {
        "avg_logprob": -0.2730377469744001,
        "compression_ratio": 1.4066666666666667,
        "end": 3155.1000000000004,
        "id": 1105,
        "no_speech_prob": 0.000086146334069781,
        "seek": 315134,
        "start": 3152.34,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50414,
          2264,
          13,
          50552
        ]
      },
      {
        "avg_logprob": -0.2730377469744001,
        "compression_ratio": 1.4066666666666667,
        "end": 3166.86,
        "id": 1106,
        "no_speech_prob": 0.000086146334069781,
        "seek": 315134,
        "start": 3155.1000000000004,
        "temperature": 0,
        "text": " So what I want to do next is I'm going to create a, OK, good.",
        "tokens": [
          50552,
          407,
          437,
          286,
          528,
          281,
          360,
          958,
          307,
          286,
          478,
          516,
          281,
          1884,
          257,
          11,
          2264,
          11,
          665,
          13,
          51140
        ]
      },
      {
        "avg_logprob": -0.2730377469744001,
        "compression_ratio": 1.4066666666666667,
        "end": 3168.86,
        "id": 1107,
        "no_speech_prob": 0.000086146334069781,
        "seek": 315134,
        "start": 3166.86,
        "temperature": 0,
        "text": " I'm trying to think of what, I mean,",
        "tokens": [
          51140,
          286,
          478,
          1382,
          281,
          519,
          295,
          437,
          11,
          286,
          914,
          11,
          51240
        ]
      },
      {
        "avg_logprob": -0.2730377469744001,
        "compression_ratio": 1.4066666666666667,
        "end": 3172.54,
        "id": 1108,
        "no_speech_prob": 0.000086146334069781,
        "seek": 315134,
        "start": 3168.86,
        "temperature": 0,
        "text": " I was going towards doing sentiment analysis.",
        "tokens": [
          51240,
          286,
          390,
          516,
          3030,
          884,
          16149,
          5215,
          13,
          51424
        ]
      },
      {
        "avg_logprob": -0.2730377469744001,
        "compression_ratio": 1.4066666666666667,
        "end": 3178.3,
        "id": 1109,
        "no_speech_prob": 0.000086146334069781,
        "seek": 315134,
        "start": 3172.54,
        "temperature": 0,
        "text": " So I think, sorry, I hope the cough didn't blow out",
        "tokens": [
          51424,
          407,
          286,
          519,
          11,
          2597,
          11,
          286,
          1454,
          264,
          22777,
          994,
          380,
          6327,
          484,
          51712
        ]
      },
      {
        "avg_logprob": -0.2730377469744001,
        "compression_ratio": 1.4066666666666667,
        "end": 3178.9,
        "id": 1110,
        "no_speech_prob": 0.000086146334069781,
        "seek": 315134,
        "start": 3178.3,
        "temperature": 0,
        "text": " your ears.",
        "tokens": [
          51712,
          428,
          8798,
          13,
          51742
        ]
      },
      {
        "avg_logprob": -0.23329984794542627,
        "compression_ratio": 1.6227272727272728,
        "end": 3182.9,
        "id": 1111,
        "no_speech_prob": 0.000004029454430565238,
        "seek": 318134,
        "start": 3181.6200000000003,
        "temperature": 0,
        "text": " Search is sort of silly.",
        "tokens": [
          50378,
          17180,
          307,
          1333,
          295,
          11774,
          13,
          50442
        ]
      },
      {
        "avg_logprob": -0.23329984794542627,
        "compression_ratio": 1.6227272727272728,
        "end": 3184.1400000000003,
        "id": 1112,
        "no_speech_prob": 0.000004029454430565238,
        "seek": 318134,
        "start": 3182.9,
        "temperature": 0,
        "text": " Search is meaningless.",
        "tokens": [
          50442,
          17180,
          307,
          33232,
          13,
          50504
        ]
      },
      {
        "avg_logprob": -0.23329984794542627,
        "compression_ratio": 1.6227272727272728,
        "end": 3185.46,
        "id": 1113,
        "no_speech_prob": 0.000004029454430565238,
        "seek": 318134,
        "start": 3184.1400000000003,
        "temperature": 0,
        "text": " It's something that I made up.",
        "tokens": [
          50504,
          467,
          311,
          746,
          300,
          286,
          1027,
          493,
          13,
          50570
        ]
      },
      {
        "avg_logprob": -0.23329984794542627,
        "compression_ratio": 1.6227272727272728,
        "end": 3188.7000000000003,
        "id": 1114,
        "no_speech_prob": 0.000004029454430565238,
        "seek": 318134,
        "start": 3185.46,
        "temperature": 0,
        "text": " So I'm going to change this.",
        "tokens": [
          50570,
          407,
          286,
          478,
          516,
          281,
          1319,
          341,
          13,
          50732
        ]
      },
      {
        "avg_logprob": -0.23329984794542627,
        "compression_ratio": 1.6227272727272728,
        "end": 3191.1000000000004,
        "id": 1115,
        "no_speech_prob": 0.000004029454430565238,
        "seek": 318134,
        "start": 3188.7000000000003,
        "temperature": 0,
        "text": " I'm going to go towards the sentiment analysis example",
        "tokens": [
          50732,
          286,
          478,
          516,
          281,
          352,
          3030,
          264,
          16149,
          5215,
          1365,
          50852
        ]
      },
      {
        "avg_logprob": -0.23329984794542627,
        "compression_ratio": 1.6227272727272728,
        "end": 3192.9,
        "id": 1116,
        "no_speech_prob": 0.000004029454430565238,
        "seek": 318134,
        "start": 3191.1000000000004,
        "temperature": 0,
        "text": " that I'm ultimately going to make,",
        "tokens": [
          50852,
          300,
          286,
          478,
          6284,
          516,
          281,
          652,
          11,
          50942
        ]
      },
      {
        "avg_logprob": -0.23329984794542627,
        "compression_ratio": 1.6227272727272728,
        "end": 3195.7000000000003,
        "id": 1117,
        "no_speech_prob": 0.000004029454430565238,
        "seek": 318134,
        "start": 3192.9,
        "temperature": 0,
        "text": " although I was kind of going to do that all from scratch.",
        "tokens": [
          50942,
          4878,
          286,
          390,
          733,
          295,
          516,
          281,
          360,
          300,
          439,
          490,
          8459,
          13,
          51082
        ]
      },
      {
        "avg_logprob": -0.23329984794542627,
        "compression_ratio": 1.6227272727272728,
        "end": 3202.9,
        "id": 1118,
        "no_speech_prob": 0.000004029454430565238,
        "seek": 318134,
        "start": 3198.58,
        "temperature": 0,
        "text": " But can we have, yeah, you can have optional variables.",
        "tokens": [
          51226,
          583,
          393,
          321,
          362,
          11,
          1338,
          11,
          291,
          393,
          362,
          17312,
          9102,
          13,
          51442
        ]
      },
      {
        "avg_logprob": -0.23329984794542627,
        "compression_ratio": 1.6227272727272728,
        "end": 3203.94,
        "id": 1119,
        "no_speech_prob": 0.000004029454430565238,
        "seek": 318134,
        "start": 3202.9,
        "temperature": 0,
        "text": " Absolutely.",
        "tokens": [
          51442,
          7021,
          13,
          51494
        ]
      },
      {
        "avg_logprob": -0.23329984794542627,
        "compression_ratio": 1.6227272727272728,
        "end": 3209.42,
        "id": 1120,
        "no_speech_prob": 0.000004029454430565238,
        "seek": 318134,
        "start": 3203.94,
        "temperature": 0,
        "text": " So let me add some stuff to this.",
        "tokens": [
          51494,
          407,
          718,
          385,
          909,
          512,
          1507,
          281,
          341,
          13,
          51768
        ]
      },
      {
        "avg_logprob": -0.22470418689320387,
        "compression_ratio": 1.471311475409836,
        "end": 3212.66,
        "id": 1121,
        "no_speech_prob": 0.000015206796888378449,
        "seek": 320942,
        "start": 3209.42,
        "temperature": 0,
        "text": " And I think I will go towards the sentiment analysis",
        "tokens": [
          50364,
          400,
          286,
          519,
          286,
          486,
          352,
          3030,
          264,
          16149,
          5215,
          50526
        ]
      },
      {
        "avg_logprob": -0.22470418689320387,
        "compression_ratio": 1.471311475409836,
        "end": 3213.54,
        "id": 1122,
        "no_speech_prob": 0.000015206796888378449,
        "seek": 320942,
        "start": 3212.66,
        "temperature": 0,
        "text": " example.",
        "tokens": [
          50526,
          1365,
          13,
          50570
        ]
      },
      {
        "avg_logprob": -0.22470418689320387,
        "compression_ratio": 1.471311475409836,
        "end": 3215.98,
        "id": 1123,
        "no_speech_prob": 0.000015206796888378449,
        "seek": 320942,
        "start": 3213.54,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50570,
          2264,
          13,
          50692
        ]
      },
      {
        "avg_logprob": -0.22470418689320387,
        "compression_ratio": 1.471311475409836,
        "end": 3217.62,
        "id": 1124,
        "no_speech_prob": 0.000015206796888378449,
        "seek": 320942,
        "start": 3215.98,
        "temperature": 0,
        "text": " Use Baker cat as an example.",
        "tokens": [
          50692,
          8278,
          25780,
          3857,
          382,
          364,
          1365,
          13,
          50774
        ]
      },
      {
        "avg_logprob": -0.22470418689320387,
        "compression_ratio": 1.471311475409836,
        "end": 3220.38,
        "id": 1125,
        "no_speech_prob": 0.000015206796888378449,
        "seek": 320942,
        "start": 3217.62,
        "temperature": 0,
        "text": " I don't know what that is, but I appreciate the,",
        "tokens": [
          50774,
          286,
          500,
          380,
          458,
          437,
          300,
          307,
          11,
          457,
          286,
          4449,
          264,
          11,
          50912
        ]
      },
      {
        "avg_logprob": -0.22470418689320387,
        "compression_ratio": 1.471311475409836,
        "end": 3223.54,
        "id": 1126,
        "no_speech_prob": 0.000015206796888378449,
        "seek": 320942,
        "start": 3220.38,
        "temperature": 0,
        "text": " how to manage a slash inside the search query.",
        "tokens": [
          50912,
          577,
          281,
          3067,
          257,
          17330,
          1854,
          264,
          3164,
          14581,
          13,
          51070
        ]
      },
      {
        "avg_logprob": -0.22470418689320387,
        "compression_ratio": 1.471311475409836,
        "end": 3225.82,
        "id": 1127,
        "no_speech_prob": 0.000015206796888378449,
        "seek": 320942,
        "start": 3223.54,
        "temperature": 0,
        "text": " Yeah, Alessandro, that's a good question.",
        "tokens": [
          51070,
          865,
          11,
          967,
          442,
          29173,
          11,
          300,
          311,
          257,
          665,
          1168,
          13,
          51184
        ]
      },
      {
        "avg_logprob": -0.22470418689320387,
        "compression_ratio": 1.471311475409836,
        "end": 3231.7400000000002,
        "id": 1128,
        "no_speech_prob": 0.000015206796888378449,
        "seek": 320942,
        "start": 3225.82,
        "temperature": 0,
        "text": " There are ways of URL encoding various kinds of characters",
        "tokens": [
          51184,
          821,
          366,
          2098,
          295,
          12905,
          43430,
          3683,
          3685,
          295,
          4342,
          51480
        ]
      },
      {
        "avg_logprob": -0.22470418689320387,
        "compression_ratio": 1.471311475409836,
        "end": 3233.86,
        "id": 1129,
        "no_speech_prob": 0.000015206796888378449,
        "seek": 320942,
        "start": 3231.7400000000002,
        "temperature": 0,
        "text": " that cause a problem.",
        "tokens": [
          51480,
          300,
          3082,
          257,
          1154,
          13,
          51586
        ]
      },
      {
        "avg_logprob": -0.22470418689320387,
        "compression_ratio": 1.471311475409836,
        "end": 3235.94,
        "id": 1130,
        "no_speech_prob": 0.000015206796888378449,
        "seek": 320942,
        "start": 3233.86,
        "temperature": 0,
        "text": " So I would have to look at that specifically,",
        "tokens": [
          51586,
          407,
          286,
          576,
          362,
          281,
          574,
          412,
          300,
          4682,
          11,
          51690
        ]
      },
      {
        "avg_logprob": -0.23031821149460813,
        "compression_ratio": 1.49746192893401,
        "end": 3239.98,
        "id": 1131,
        "no_speech_prob": 0.000002026141146416194,
        "seek": 323594,
        "start": 3235.94,
        "temperature": 0,
        "text": " but of course, there's always a way around it.",
        "tokens": [
          50364,
          457,
          295,
          1164,
          11,
          456,
          311,
          1009,
          257,
          636,
          926,
          309,
          13,
          50566
        ]
      },
      {
        "avg_logprob": -0.23031821149460813,
        "compression_ratio": 1.49746192893401,
        "end": 3242.42,
        "id": 1132,
        "no_speech_prob": 0.000002026141146416194,
        "seek": 323594,
        "start": 3239.98,
        "temperature": 0,
        "text": " Optional variables in the middle of a URL is hard.",
        "tokens": [
          50566,
          29284,
          304,
          9102,
          294,
          264,
          2808,
          295,
          257,
          12905,
          307,
          1152,
          13,
          50688
        ]
      },
      {
        "avg_logprob": -0.23031821149460813,
        "compression_ratio": 1.49746192893401,
        "end": 3243.7000000000003,
        "id": 1133,
        "no_speech_prob": 0.000002026141146416194,
        "seek": 323594,
        "start": 3242.42,
        "temperature": 0,
        "text": " Yes, definitely hard.",
        "tokens": [
          50688,
          1079,
          11,
          2138,
          1152,
          13,
          50752
        ]
      },
      {
        "avg_logprob": -0.23031821149460813,
        "compression_ratio": 1.49746192893401,
        "end": 3246.02,
        "id": 1134,
        "no_speech_prob": 0.000002026141146416194,
        "seek": 323594,
        "start": 3243.7000000000003,
        "temperature": 0,
        "text": " It's at the end that kind of works best.",
        "tokens": [
          50752,
          467,
          311,
          412,
          264,
          917,
          300,
          733,
          295,
          1985,
          1151,
          13,
          50868
        ]
      },
      {
        "avg_logprob": -0.23031821149460813,
        "compression_ratio": 1.49746192893401,
        "end": 3249.58,
        "id": 1135,
        "no_speech_prob": 0.000002026141146416194,
        "seek": 323594,
        "start": 3246.02,
        "temperature": 0,
        "text": " OK, so I'm going to try to get one step further here",
        "tokens": [
          50868,
          2264,
          11,
          370,
          286,
          478,
          516,
          281,
          853,
          281,
          483,
          472,
          1823,
          3052,
          510,
          51046
        ]
      },
      {
        "avg_logprob": -0.23031821149460813,
        "compression_ratio": 1.49746192893401,
        "end": 3253.7000000000003,
        "id": 1136,
        "no_speech_prob": 0.000002026141146416194,
        "seek": 323594,
        "start": 3249.58,
        "temperature": 0,
        "text": " with this, at least, if not two.",
        "tokens": [
          51046,
          365,
          341,
          11,
          412,
          1935,
          11,
          498,
          406,
          732,
          13,
          51252
        ]
      },
      {
        "avg_logprob": -0.23031821149460813,
        "compression_ratio": 1.49746192893401,
        "end": 3258.62,
        "id": 1137,
        "no_speech_prob": 0.000002026141146416194,
        "seek": 323594,
        "start": 3253.7000000000003,
        "temperature": 0,
        "text": " And that's all I'm going to be able to do today.",
        "tokens": [
          51252,
          400,
          300,
          311,
          439,
          286,
          478,
          516,
          281,
          312,
          1075,
          281,
          360,
          965,
          13,
          51498
        ]
      },
      {
        "avg_logprob": -0.5377767974255132,
        "compression_ratio": 1.2155172413793103,
        "end": 3259.12,
        "id": 1138,
        "no_speech_prob": 0.0006263292743824422,
        "seek": 325862,
        "start": 3258.62,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50364,
          2264,
          13,
          50389
        ]
      },
      {
        "avg_logprob": -0.5377767974255132,
        "compression_ratio": 1.2155172413793103,
        "end": 3269.62,
        "id": 1139,
        "no_speech_prob": 0.0006263292743824422,
        "seek": 325862,
        "start": 3265.7,
        "temperature": 0,
        "text": " And what I want to do is just add this.",
        "tokens": [
          50718,
          400,
          437,
          286,
          528,
          281,
          360,
          307,
          445,
          909,
          341,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.5377767974255132,
        "compression_ratio": 1.2155172413793103,
        "end": 3277.14,
        "id": 1140,
        "no_speech_prob": 0.0006263292743824422,
        "seek": 325862,
        "start": 3273.06,
        "temperature": 0,
        "text": " Really, I guess it's, is it rendering it as HTML?",
        "tokens": [
          51086,
          4083,
          11,
          286,
          2041,
          309,
          311,
          11,
          307,
          309,
          22407,
          309,
          382,
          17995,
          30,
          51290
        ]
      },
      {
        "avg_logprob": -0.5377767974255132,
        "compression_ratio": 1.2155172413793103,
        "end": 3279.98,
        "id": 1141,
        "no_speech_prob": 0.0006263292743824422,
        "seek": 325862,
        "start": 3277.14,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51290,
          865,
          13,
          51432
        ]
      },
      {
        "avg_logprob": -0.5377767974255132,
        "compression_ratio": 1.2155172413793103,
        "end": 3282.2999999999997,
        "id": 1142,
        "no_speech_prob": 0.0006263292743824422,
        "seek": 325862,
        "start": 3279.98,
        "temperature": 0,
        "text": " And I wanted to actually have it be this.",
        "tokens": [
          51432,
          400,
          286,
          1415,
          281,
          767,
          362,
          309,
          312,
          341,
          13,
          51548
        ]
      },
      {
        "avg_logprob": -0.2638620396250302,
        "compression_ratio": 1.5765306122448979,
        "end": 3283.8,
        "id": 1143,
        "no_speech_prob": 0.000039442536944989115,
        "seek": 328230,
        "start": 3283.3,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50414,
          2264,
          13,
          50439
        ]
      },
      {
        "avg_logprob": -0.2638620396250302,
        "compression_ratio": 1.5765306122448979,
        "end": 3290.78,
        "id": 1144,
        "no_speech_prob": 0.000039442536944989115,
        "seek": 328230,
        "start": 3287.02,
        "temperature": 0,
        "text": " So I am looking at my phone, which is no reason.",
        "tokens": [
          50600,
          407,
          286,
          669,
          1237,
          412,
          452,
          2593,
          11,
          597,
          307,
          572,
          1778,
          13,
          50788
        ]
      },
      {
        "avg_logprob": -0.2638620396250302,
        "compression_ratio": 1.5765306122448979,
        "end": 3294.1400000000003,
        "id": 1145,
        "no_speech_prob": 0.000039442536944989115,
        "seek": 328230,
        "start": 3290.78,
        "temperature": 0,
        "text": " OK, so I got to get to the next stage.",
        "tokens": [
          50788,
          2264,
          11,
          370,
          286,
          658,
          281,
          483,
          281,
          264,
          958,
          3233,
          13,
          50956
        ]
      },
      {
        "avg_logprob": -0.2638620396250302,
        "compression_ratio": 1.5765306122448979,
        "end": 3300.38,
        "id": 1146,
        "no_speech_prob": 0.000039442536944989115,
        "seek": 328230,
        "start": 3294.1400000000003,
        "temperature": 0,
        "text": " The next stage of this is I want to take input from a user",
        "tokens": [
          50956,
          440,
          958,
          3233,
          295,
          341,
          307,
          286,
          528,
          281,
          747,
          4846,
          490,
          257,
          4195,
          51268
        ]
      },
      {
        "avg_logprob": -0.2638620396250302,
        "compression_ratio": 1.5765306122448979,
        "end": 3304.34,
        "id": 1147,
        "no_speech_prob": 0.000039442536944989115,
        "seek": 328230,
        "start": 3300.38,
        "temperature": 0,
        "text": " and essentially save it to a database, which is going to,",
        "tokens": [
          51268,
          293,
          4476,
          3155,
          309,
          281,
          257,
          8149,
          11,
          597,
          307,
          516,
          281,
          11,
          51466
        ]
      },
      {
        "avg_logprob": -0.2638620396250302,
        "compression_ratio": 1.5765306122448979,
        "end": 3306.46,
        "id": 1148,
        "no_speech_prob": 0.000039442536944989115,
        "seek": 328230,
        "start": 3304.34,
        "temperature": 0,
        "text": " I'm going to do it in two stages.",
        "tokens": [
          51466,
          286,
          478,
          516,
          281,
          360,
          309,
          294,
          732,
          10232,
          13,
          51572
        ]
      },
      {
        "avg_logprob": -0.2638620396250302,
        "compression_ratio": 1.5765306122448979,
        "end": 3307.9,
        "id": 1149,
        "no_speech_prob": 0.000039442536944989115,
        "seek": 328230,
        "start": 3306.46,
        "temperature": 0,
        "text": " And then I also want to look at how",
        "tokens": [
          51572,
          400,
          550,
          286,
          611,
          528,
          281,
          574,
          412,
          577,
          51644
        ]
      },
      {
        "avg_logprob": -0.2638620396250302,
        "compression_ratio": 1.5765306122448979,
        "end": 3311.5800000000004,
        "id": 1150,
        "no_speech_prob": 0.000039442536944989115,
        "seek": 328230,
        "start": 3307.9,
        "temperature": 0,
        "text": " to send that information back.",
        "tokens": [
          51644,
          281,
          2845,
          300,
          1589,
          646,
          13,
          51828
        ]
      },
      {
        "avg_logprob": -0.345646721976144,
        "compression_ratio": 1.447674418604651,
        "end": 3312.08,
        "id": 1151,
        "no_speech_prob": 0.000010616062354529276,
        "seek": 331158,
        "start": 3311.58,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50364,
          2264,
          13,
          50389
        ]
      },
      {
        "avg_logprob": -0.345646721976144,
        "compression_ratio": 1.447674418604651,
        "end": 3316.4,
        "id": 1152,
        "no_speech_prob": 0.000010616062354529276,
        "seek": 331158,
        "start": 3315.9,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50580,
          2264,
          13,
          50605
        ]
      },
      {
        "avg_logprob": -0.345646721976144,
        "compression_ratio": 1.447674418604651,
        "end": 3320.94,
        "id": 1153,
        "no_speech_prob": 0.000010616062354529276,
        "seek": 331158,
        "start": 3320.22,
        "temperature": 0,
        "text": " Where am I here?",
        "tokens": [
          50796,
          2305,
          669,
          286,
          510,
          30,
          50832
        ]
      },
      {
        "avg_logprob": -0.345646721976144,
        "compression_ratio": 1.447674418604651,
        "end": 3321.66,
        "id": 1154,
        "no_speech_prob": 0.000010616062354529276,
        "seek": 331158,
        "start": 3320.94,
        "temperature": 0,
        "text": " I'll start here.",
        "tokens": [
          50832,
          286,
          603,
          722,
          510,
          13,
          50868
        ]
      },
      {
        "avg_logprob": -0.345646721976144,
        "compression_ratio": 1.447674418604651,
        "end": 3325.74,
        "id": 1155,
        "no_speech_prob": 0.000010616062354529276,
        "seek": 331158,
        "start": 3324.22,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50996,
          2264,
          13,
          51072
        ]
      },
      {
        "avg_logprob": -0.345646721976144,
        "compression_ratio": 1.447674418604651,
        "end": 3326.7799999999997,
        "id": 1156,
        "no_speech_prob": 0.000010616062354529276,
        "seek": 331158,
        "start": 3325.74,
        "temperature": 0,
        "text": " Sorry, YLive.",
        "tokens": [
          51072,
          4919,
          11,
          398,
          43,
          592,
          68,
          13,
          51124
        ]
      },
      {
        "avg_logprob": -0.345646721976144,
        "compression_ratio": 1.447674418604651,
        "end": 3330.02,
        "id": 1157,
        "no_speech_prob": 0.000010616062354529276,
        "seek": 331158,
        "start": 3326.7799999999997,
        "temperature": 0,
        "text": " I've got lots of, this has the default YouTube",
        "tokens": [
          51124,
          286,
          600,
          658,
          3195,
          295,
          11,
          341,
          575,
          264,
          7576,
          3088,
          51286
        ]
      },
      {
        "avg_logprob": -0.345646721976144,
        "compression_ratio": 1.447674418604651,
        "end": 3331.38,
        "id": 1158,
        "no_speech_prob": 0.000010616062354529276,
        "seek": 331158,
        "start": 3330.02,
        "temperature": 0,
        "text": " clean language settings.",
        "tokens": [
          51286,
          2541,
          2856,
          6257,
          13,
          51354
        ]
      },
      {
        "avg_logprob": -0.345646721976144,
        "compression_ratio": 1.447674418604651,
        "end": 3334.1,
        "id": 1159,
        "no_speech_prob": 0.000010616062354529276,
        "seek": 331158,
        "start": 3331.38,
        "temperature": 0,
        "text": " I think you'll come, I think it'll let you back in, YLive,",
        "tokens": [
          51354,
          286,
          519,
          291,
          603,
          808,
          11,
          286,
          519,
          309,
          603,
          718,
          291,
          646,
          294,
          11,
          398,
          43,
          488,
          11,
          51490
        ]
      },
      {
        "avg_logprob": -0.345646721976144,
        "compression_ratio": 1.447674418604651,
        "end": 3336.66,
        "id": 1160,
        "no_speech_prob": 0.000010616062354529276,
        "seek": 331158,
        "start": 3334.1,
        "temperature": 0,
        "text": " if anybody knows how to let YLive back in.",
        "tokens": [
          51490,
          498,
          4472,
          3255,
          577,
          281,
          718,
          398,
          43,
          488,
          646,
          294,
          13,
          51618
        ]
      },
      {
        "avg_logprob": -0.345646721976144,
        "compression_ratio": 1.447674418604651,
        "end": 3337.42,
        "id": 1161,
        "no_speech_prob": 0.000010616062354529276,
        "seek": 331158,
        "start": 3336.66,
        "temperature": 0,
        "text": " OK, here we go.",
        "tokens": [
          51618,
          2264,
          11,
          510,
          321,
          352,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.23640490994595065,
        "compression_ratio": 1.663716814159292,
        "end": 3348.46,
        "id": 1162,
        "no_speech_prob": 0.0005193004035390913,
        "seek": 334158,
        "start": 3342.58,
        "temperature": 0,
        "text": " In the previous video, I got as far as defining",
        "tokens": [
          50414,
          682,
          264,
          3894,
          960,
          11,
          286,
          658,
          382,
          1400,
          382,
          17827,
          50708
        ]
      },
      {
        "avg_logprob": -0.23640490994595065,
        "compression_ratio": 1.663716814159292,
        "end": 3350.54,
        "id": 1163,
        "no_speech_prob": 0.0005193004035390913,
        "seek": 334158,
        "start": 3348.46,
        "temperature": 0,
        "text": " a route with parameters.",
        "tokens": [
          50708,
          257,
          7955,
          365,
          9834,
          13,
          50812
        ]
      },
      {
        "avg_logprob": -0.23640490994595065,
        "compression_ratio": 1.663716814159292,
        "end": 3355.2599999999998,
        "id": 1164,
        "no_speech_prob": 0.0005193004035390913,
        "seek": 334158,
        "start": 3350.54,
        "temperature": 0,
        "text": " The route is search slash some keyword slash some number.",
        "tokens": [
          50812,
          440,
          7955,
          307,
          3164,
          17330,
          512,
          20428,
          17330,
          512,
          1230,
          13,
          51048
        ]
      },
      {
        "avg_logprob": -0.23640490994595065,
        "compression_ratio": 1.663716814159292,
        "end": 3357.7799999999997,
        "id": 1165,
        "no_speech_prob": 0.0005193004035390913,
        "seek": 334158,
        "start": 3355.2599999999998,
        "temperature": 0,
        "text": " And the response from the server that comes back",
        "tokens": [
          51048,
          400,
          264,
          4134,
          490,
          264,
          7154,
          300,
          1487,
          646,
          51174
        ]
      },
      {
        "avg_logprob": -0.23640490994595065,
        "compression_ratio": 1.663716814159292,
        "end": 3360.5,
        "id": 1166,
        "no_speech_prob": 0.0005193004035390913,
        "seek": 334158,
        "start": 3357.7799999999997,
        "temperature": 0,
        "text": " is always I love whatever word, however many times",
        "tokens": [
          51174,
          307,
          1009,
          286,
          959,
          2035,
          1349,
          11,
          4461,
          867,
          1413,
          51310
        ]
      },
      {
        "avg_logprob": -0.23640490994595065,
        "compression_ratio": 1.663716814159292,
        "end": 3361.18,
        "id": 1167,
        "no_speech_prob": 0.0005193004035390913,
        "seek": 334158,
        "start": 3360.5,
        "temperature": 0,
        "text": " the number is.",
        "tokens": [
          51310,
          264,
          1230,
          307,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.23640490994595065,
        "compression_ratio": 1.663716814159292,
        "end": 3365.42,
        "id": 1168,
        "no_speech_prob": 0.0005193004035390913,
        "seek": 334158,
        "start": 3361.18,
        "temperature": 0,
        "text": " So if I were to change this to unicorn and unicorn",
        "tokens": [
          51344,
          407,
          498,
          286,
          645,
          281,
          1319,
          341,
          281,
          28122,
          293,
          28122,
          51556
        ]
      },
      {
        "avg_logprob": -0.23640490994595065,
        "compression_ratio": 1.663716814159292,
        "end": 3367.36,
        "id": 1169,
        "no_speech_prob": 0.0005193004035390913,
        "seek": 334158,
        "start": 3365.42,
        "temperature": 0,
        "text": " and put it just with slash three,",
        "tokens": [
          51556,
          293,
          829,
          309,
          445,
          365,
          17330,
          1045,
          11,
          51653
        ]
      },
      {
        "avg_logprob": -0.23640490994595065,
        "compression_ratio": 1.663716814159292,
        "end": 3369.74,
        "id": 1170,
        "no_speech_prob": 0.0005193004035390913,
        "seek": 334158,
        "start": 3367.36,
        "temperature": 0,
        "text": " I would see I love unicorns two, three times.",
        "tokens": [
          51653,
          286,
          576,
          536,
          286,
          959,
          28122,
          82,
          732,
          11,
          1045,
          1413,
          13,
          51772
        ]
      },
      {
        "avg_logprob": -0.21008376492798783,
        "compression_ratio": 1.6881720430107527,
        "end": 3371.62,
        "id": 1171,
        "no_speech_prob": 0.00000826785708341049,
        "seek": 336974,
        "start": 3369.7799999999997,
        "temperature": 0,
        "text": " So this is, while fun, and I like",
        "tokens": [
          50366,
          407,
          341,
          307,
          11,
          1339,
          1019,
          11,
          293,
          286,
          411,
          50458
        ]
      },
      {
        "avg_logprob": -0.21008376492798783,
        "compression_ratio": 1.6881720430107527,
        "end": 3373.9399999999996,
        "id": 1172,
        "no_speech_prob": 0.00000826785708341049,
        "seek": 336974,
        "start": 3371.62,
        "temperature": 0,
        "text": " to see how much you love unicorns and rainbows,",
        "tokens": [
          50458,
          281,
          536,
          577,
          709,
          291,
          959,
          28122,
          82,
          293,
          4830,
          21118,
          11,
          50574
        ]
      },
      {
        "avg_logprob": -0.21008376492798783,
        "compression_ratio": 1.6881720430107527,
        "end": 3375.54,
        "id": 1173,
        "no_speech_prob": 0.00000826785708341049,
        "seek": 336974,
        "start": 3373.9399999999996,
        "temperature": 0,
        "text": " do you love them as much as me?",
        "tokens": [
          50574,
          360,
          291,
          959,
          552,
          382,
          709,
          382,
          385,
          30,
          50654
        ]
      },
      {
        "avg_logprob": -0.21008376492798783,
        "compression_ratio": 1.6881720430107527,
        "end": 3377.02,
        "id": 1174,
        "no_speech_prob": 0.00000826785708341049,
        "seek": 336974,
        "start": 3375.54,
        "temperature": 0,
        "text": " I don't know, probably not, which",
        "tokens": [
          50654,
          286,
          500,
          380,
          458,
          11,
          1391,
          406,
          11,
          597,
          50728
        ]
      },
      {
        "avg_logprob": -0.21008376492798783,
        "compression_ratio": 1.6881720430107527,
        "end": 3380.74,
        "id": 1175,
        "no_speech_prob": 0.00000826785708341049,
        "seek": 336974,
        "start": 3377.02,
        "temperature": 0,
        "text": " is a very healthy, probably much healthier than however I am.",
        "tokens": [
          50728,
          307,
          257,
          588,
          4627,
          11,
          1391,
          709,
          19580,
          813,
          4461,
          286,
          669,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.21008376492798783,
        "compression_ratio": 1.6881720430107527,
        "end": 3384.4199999999996,
        "id": 1176,
        "no_speech_prob": 0.00000826785708341049,
        "seek": 336974,
        "start": 3380.74,
        "temperature": 0,
        "text": " But the point of what I'm saying is this is kind of useless.",
        "tokens": [
          50914,
          583,
          264,
          935,
          295,
          437,
          286,
          478,
          1566,
          307,
          341,
          307,
          733,
          295,
          14115,
          13,
          51098
        ]
      },
      {
        "avg_logprob": -0.21008376492798783,
        "compression_ratio": 1.6881720430107527,
        "end": 3386.8599999999997,
        "id": 1177,
        "no_speech_prob": 0.00000826785708341049,
        "seek": 336974,
        "start": 3384.4199999999996,
        "temperature": 0,
        "text": " Let's turn this into something useful.",
        "tokens": [
          51098,
          961,
          311,
          1261,
          341,
          666,
          746,
          4420,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.21008376492798783,
        "compression_ratio": 1.6881720430107527,
        "end": 3389.4199999999996,
        "id": 1178,
        "no_speech_prob": 0.00000826785708341049,
        "seek": 336974,
        "start": 3386.8599999999997,
        "temperature": 0,
        "text": " And so the example that I'm ultimately building here",
        "tokens": [
          51220,
          400,
          370,
          264,
          1365,
          300,
          286,
          478,
          6284,
          2390,
          510,
          51348
        ]
      },
      {
        "avg_logprob": -0.21008376492798783,
        "compression_ratio": 1.6881720430107527,
        "end": 3392.54,
        "id": 1179,
        "no_speech_prob": 0.00000826785708341049,
        "seek": 336974,
        "start": 3389.4199999999996,
        "temperature": 0,
        "text": " is a sentiment analysis API.",
        "tokens": [
          51348,
          307,
          257,
          16149,
          5215,
          9362,
          13,
          51504
        ]
      },
      {
        "avg_logprob": -0.21008376492798783,
        "compression_ratio": 1.6881720430107527,
        "end": 3395.4799999999996,
        "id": 1180,
        "no_speech_prob": 0.00000826785708341049,
        "seek": 336974,
        "start": 3392.54,
        "temperature": 0,
        "text": " And so one approach to sentiment analysis",
        "tokens": [
          51504,
          400,
          370,
          472,
          3109,
          281,
          16149,
          5215,
          51651
        ]
      },
      {
        "avg_logprob": -0.21008376492798783,
        "compression_ratio": 1.6881720430107527,
        "end": 3397.7999999999997,
        "id": 1181,
        "no_speech_prob": 0.00000826785708341049,
        "seek": 336974,
        "start": 3395.4799999999996,
        "temperature": 0,
        "text": " is to keep a dictionary of words that",
        "tokens": [
          51651,
          307,
          281,
          1066,
          257,
          25890,
          295,
          2283,
          300,
          51767
        ]
      },
      {
        "avg_logprob": -0.20394093135617813,
        "compression_ratio": 1.87292817679558,
        "end": 3401.76,
        "id": 1182,
        "no_speech_prob": 0.00026118976529687643,
        "seek": 339780,
        "start": 3397.8,
        "temperature": 0,
        "text": " either have a positive or negative score associated",
        "tokens": [
          50364,
          2139,
          362,
          257,
          3353,
          420,
          3671,
          6175,
          6615,
          50562
        ]
      },
      {
        "avg_logprob": -0.20394093135617813,
        "compression_ratio": 1.87292817679558,
        "end": 3402.96,
        "id": 1183,
        "no_speech_prob": 0.00026118976529687643,
        "seek": 339780,
        "start": 3401.76,
        "temperature": 0,
        "text": " with them.",
        "tokens": [
          50562,
          365,
          552,
          13,
          50622
        ]
      },
      {
        "avg_logprob": -0.20394093135617813,
        "compression_ratio": 1.87292817679558,
        "end": 3405.92,
        "id": 1184,
        "no_speech_prob": 0.00026118976529687643,
        "seek": 339780,
        "start": 3402.96,
        "temperature": 0,
        "text": " So I'm going to go to the code.",
        "tokens": [
          50622,
          407,
          286,
          478,
          516,
          281,
          352,
          281,
          264,
          3089,
          13,
          50770
        ]
      },
      {
        "avg_logprob": -0.20394093135617813,
        "compression_ratio": 1.87292817679558,
        "end": 3408.8,
        "id": 1185,
        "no_speech_prob": 0.00026118976529687643,
        "seek": 339780,
        "start": 3405.92,
        "temperature": 0,
        "text": " And I'm just going to, right here at the top,",
        "tokens": [
          50770,
          400,
          286,
          478,
          445,
          516,
          281,
          11,
          558,
          510,
          412,
          264,
          1192,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.20394093135617813,
        "compression_ratio": 1.87292817679558,
        "end": 3410.7200000000003,
        "id": 1186,
        "no_speech_prob": 0.00026118976529687643,
        "seek": 339780,
        "start": 3408.8,
        "temperature": 0,
        "text": " I'm going to create a variable.",
        "tokens": [
          50914,
          286,
          478,
          516,
          281,
          1884,
          257,
          7006,
          13,
          51010
        ]
      },
      {
        "avg_logprob": -0.20394093135617813,
        "compression_ratio": 1.87292817679558,
        "end": 3414.46,
        "id": 1187,
        "no_speech_prob": 0.00026118976529687643,
        "seek": 339780,
        "start": 3410.7200000000003,
        "temperature": 0,
        "text": " And I'm going to call it words.",
        "tokens": [
          51010,
          400,
          286,
          478,
          516,
          281,
          818,
          309,
          2283,
          13,
          51197
        ]
      },
      {
        "avg_logprob": -0.20394093135617813,
        "compression_ratio": 1.87292817679558,
        "end": 3417.4,
        "id": 1188,
        "no_speech_prob": 0.00026118976529687643,
        "seek": 339780,
        "start": 3414.46,
        "temperature": 0,
        "text": " And I'm going to put some words in it with a score.",
        "tokens": [
          51197,
          400,
          286,
          478,
          516,
          281,
          829,
          512,
          2283,
          294,
          309,
          365,
          257,
          6175,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.20394093135617813,
        "compression_ratio": 1.87292817679558,
        "end": 3422.6800000000003,
        "id": 1189,
        "no_speech_prob": 0.00026118976529687643,
        "seek": 339780,
        "start": 3417.4,
        "temperature": 0,
        "text": " So I'm going to say rainbow has a score of five.",
        "tokens": [
          51344,
          407,
          286,
          478,
          516,
          281,
          584,
          18526,
          575,
          257,
          6175,
          295,
          1732,
          13,
          51608
        ]
      },
      {
        "avg_logprob": -0.20394093135617813,
        "compression_ratio": 1.87292817679558,
        "end": 3426.54,
        "id": 1190,
        "no_speech_prob": 0.00026118976529687643,
        "seek": 339780,
        "start": 3422.6800000000003,
        "temperature": 0,
        "text": " And unicorn has a score of three.",
        "tokens": [
          51608,
          400,
          28122,
          575,
          257,
          6175,
          295,
          1045,
          13,
          51801
        ]
      },
      {
        "avg_logprob": -0.2137625752663126,
        "compression_ratio": 1.624413145539906,
        "end": 3429.94,
        "id": 1191,
        "no_speech_prob": 0.00004611271288013086,
        "seek": 342654,
        "start": 3426.54,
        "temperature": 0,
        "text": " What are some sad words?",
        "tokens": [
          50364,
          708,
          366,
          512,
          4227,
          2283,
          30,
          50534
        ]
      },
      {
        "avg_logprob": -0.2137625752663126,
        "compression_ratio": 1.624413145539906,
        "end": 3433.94,
        "id": 1192,
        "no_speech_prob": 0.00004611271288013086,
        "seek": 342654,
        "start": 3429.94,
        "temperature": 0,
        "text": " Doom has a score of negative three.",
        "tokens": [
          50534,
          30168,
          575,
          257,
          6175,
          295,
          3671,
          1045,
          13,
          50734
        ]
      },
      {
        "avg_logprob": -0.2137625752663126,
        "compression_ratio": 1.624413145539906,
        "end": 3437.62,
        "id": 1193,
        "no_speech_prob": 0.00004611271288013086,
        "seek": 342654,
        "start": 3433.94,
        "temperature": 0,
        "text": " So this is my very basic sentiment analysis dictionary.",
        "tokens": [
          50734,
          407,
          341,
          307,
          452,
          588,
          3875,
          16149,
          5215,
          25890,
          13,
          50918
        ]
      },
      {
        "avg_logprob": -0.2137625752663126,
        "compression_ratio": 1.624413145539906,
        "end": 3440.82,
        "id": 1194,
        "no_speech_prob": 0.00004611271288013086,
        "seek": 342654,
        "start": 3437.62,
        "temperature": 0,
        "text": " I've got three words in it and what their score is.",
        "tokens": [
          50918,
          286,
          600,
          658,
          1045,
          2283,
          294,
          309,
          293,
          437,
          641,
          6175,
          307,
          13,
          51078
        ]
      },
      {
        "avg_logprob": -0.2137625752663126,
        "compression_ratio": 1.624413145539906,
        "end": 3444.68,
        "id": 1195,
        "no_speech_prob": 0.00004611271288013086,
        "seek": 342654,
        "start": 3440.82,
        "temperature": 0,
        "text": " So first thing that I want to do in making a sentiment analysis",
        "tokens": [
          51078,
          407,
          700,
          551,
          300,
          286,
          528,
          281,
          360,
          294,
          1455,
          257,
          16149,
          5215,
          51271
        ]
      },
      {
        "avg_logprob": -0.2137625752663126,
        "compression_ratio": 1.624413145539906,
        "end": 3447.7,
        "id": 1196,
        "no_speech_prob": 0.00004611271288013086,
        "seek": 342654,
        "start": 3444.68,
        "temperature": 0,
        "text": " API is expose this data.",
        "tokens": [
          51271,
          9362,
          307,
          19219,
          341,
          1412,
          13,
          51422
        ]
      },
      {
        "avg_logprob": -0.2137625752663126,
        "compression_ratio": 1.624413145539906,
        "end": 3450.22,
        "id": 1197,
        "no_speech_prob": 0.00004611271288013086,
        "seek": 342654,
        "start": 3447.7,
        "temperature": 0,
        "text": " So I'm going to actually add another route here.",
        "tokens": [
          51422,
          407,
          286,
          478,
          516,
          281,
          767,
          909,
          1071,
          7955,
          510,
          13,
          51548
        ]
      },
      {
        "avg_logprob": -0.2137625752663126,
        "compression_ratio": 1.624413145539906,
        "end": 3456.34,
        "id": 1198,
        "no_speech_prob": 0.00004611271288013086,
        "seek": 342654,
        "start": 3450.22,
        "temperature": 0,
        "text": " I'm going to say app.get all, send all.",
        "tokens": [
          51548,
          286,
          478,
          516,
          281,
          584,
          724,
          13,
          847,
          439,
          11,
          2845,
          439,
          13,
          51854
        ]
      },
      {
        "avg_logprob": -0.20513227344614215,
        "compression_ratio": 1.638655462184874,
        "end": 3460.5,
        "id": 1199,
        "no_speech_prob": 0.000006144170583866071,
        "seek": 345634,
        "start": 3456.34,
        "temperature": 0,
        "text": " And then I'm going to say function send all.",
        "tokens": [
          50364,
          400,
          550,
          286,
          478,
          516,
          281,
          584,
          2445,
          2845,
          439,
          13,
          50572
        ]
      },
      {
        "avg_logprob": -0.20513227344614215,
        "compression_ratio": 1.638655462184874,
        "end": 3463.98,
        "id": 1200,
        "no_speech_prob": 0.000006144170583866071,
        "seek": 345634,
        "start": 3460.5,
        "temperature": 0,
        "text": " And this is the callback, which has a request and a response.",
        "tokens": [
          50572,
          400,
          341,
          307,
          264,
          818,
          3207,
          11,
          597,
          575,
          257,
          5308,
          293,
          257,
          4134,
          13,
          50746
        ]
      },
      {
        "avg_logprob": -0.20513227344614215,
        "compression_ratio": 1.638655462184874,
        "end": 3467.5,
        "id": 1201,
        "no_speech_prob": 0.000006144170583866071,
        "seek": 345634,
        "start": 3463.98,
        "temperature": 0,
        "text": " And all I'm going to do is say response.send words.",
        "tokens": [
          50746,
          400,
          439,
          286,
          478,
          516,
          281,
          360,
          307,
          584,
          4134,
          13,
          82,
          521,
          2283,
          13,
          50922
        ]
      },
      {
        "avg_logprob": -0.20513227344614215,
        "compression_ratio": 1.638655462184874,
        "end": 3469.54,
        "id": 1202,
        "no_speech_prob": 0.000006144170583866071,
        "seek": 345634,
        "start": 3467.5,
        "temperature": 0,
        "text": " Now, notice what I did up here.",
        "tokens": [
          50922,
          823,
          11,
          3449,
          437,
          286,
          630,
          493,
          510,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.20513227344614215,
        "compression_ratio": 1.638655462184874,
        "end": 3472.7400000000002,
        "id": 1203,
        "no_speech_prob": 0.000006144170583866071,
        "seek": 345634,
        "start": 3469.54,
        "temperature": 0,
        "text": " In this reply, I just created this string.",
        "tokens": [
          51024,
          682,
          341,
          16972,
          11,
          286,
          445,
          2942,
          341,
          6798,
          13,
          51184
        ]
      },
      {
        "avg_logprob": -0.20513227344614215,
        "compression_ratio": 1.638655462184874,
        "end": 3475.7400000000002,
        "id": 1204,
        "no_speech_prob": 0.000006144170583866071,
        "seek": 345634,
        "start": 3472.7400000000002,
        "temperature": 0,
        "text": " And this string just kind of spit itself out",
        "tokens": [
          51184,
          400,
          341,
          6798,
          445,
          733,
          295,
          22127,
          2564,
          484,
          51334
        ]
      },
      {
        "avg_logprob": -0.20513227344614215,
        "compression_ratio": 1.638655462184874,
        "end": 3476.82,
        "id": 1205,
        "no_speech_prob": 0.000006144170583866071,
        "seek": 345634,
        "start": 3475.7400000000002,
        "temperature": 0,
        "text": " into the browser.",
        "tokens": [
          51334,
          666,
          264,
          11185,
          13,
          51388
        ]
      },
      {
        "avg_logprob": -0.20513227344614215,
        "compression_ratio": 1.638655462184874,
        "end": 3479.6600000000003,
        "id": 1206,
        "no_speech_prob": 0.000006144170583866071,
        "seek": 345634,
        "start": 3476.82,
        "temperature": 0,
        "text": " But somebody using the API is probably",
        "tokens": [
          51388,
          583,
          2618,
          1228,
          264,
          9362,
          307,
          1391,
          51530
        ]
      },
      {
        "avg_logprob": -0.20513227344614215,
        "compression_ratio": 1.638655462184874,
        "end": 3483.02,
        "id": 1207,
        "no_speech_prob": 0.000006144170583866071,
        "seek": 345634,
        "start": 3479.6600000000003,
        "temperature": 0,
        "text": " going to want to get the reply back formatted as JSON.",
        "tokens": [
          51530,
          516,
          281,
          528,
          281,
          483,
          264,
          16972,
          646,
          1254,
          32509,
          382,
          31828,
          13,
          51698
        ]
      },
      {
        "avg_logprob": -0.2387592114900288,
        "compression_ratio": 1.645933014354067,
        "end": 3486.46,
        "id": 1208,
        "no_speech_prob": 0.0001253373484360054,
        "seek": 348302,
        "start": 3483.02,
        "temperature": 0,
        "text": " So I better do something to format this as JSON.",
        "tokens": [
          50364,
          407,
          286,
          1101,
          360,
          746,
          281,
          7877,
          341,
          382,
          31828,
          13,
          50536
        ]
      },
      {
        "avg_logprob": -0.2387592114900288,
        "compression_ratio": 1.645933014354067,
        "end": 3488.34,
        "id": 1209,
        "no_speech_prob": 0.0001253373484360054,
        "seek": 348302,
        "start": 3486.46,
        "temperature": 0,
        "text": " Well, what is words?",
        "tokens": [
          50536,
          1042,
          11,
          437,
          307,
          2283,
          30,
          50630
        ]
      },
      {
        "avg_logprob": -0.2387592114900288,
        "compression_ratio": 1.645933014354067,
        "end": 3490.02,
        "id": 1210,
        "no_speech_prob": 0.0001253373484360054,
        "seek": 348302,
        "start": 3488.34,
        "temperature": 0,
        "text": " It's a JavaScript object.",
        "tokens": [
          50630,
          467,
          311,
          257,
          15778,
          2657,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2387592114900288,
        "compression_ratio": 1.645933014354067,
        "end": 3491.18,
        "id": 1211,
        "no_speech_prob": 0.0001253373484360054,
        "seek": 348302,
        "start": 3490.02,
        "temperature": 0,
        "text": " What is JSON?",
        "tokens": [
          50714,
          708,
          307,
          31828,
          30,
          50772
        ]
      },
      {
        "avg_logprob": -0.2387592114900288,
        "compression_ratio": 1.645933014354067,
        "end": 3492.78,
        "id": 1212,
        "no_speech_prob": 0.0001253373484360054,
        "seek": 348302,
        "start": 3491.18,
        "temperature": 0,
        "text": " JavaScript object notation.",
        "tokens": [
          50772,
          15778,
          2657,
          24657,
          13,
          50852
        ]
      },
      {
        "avg_logprob": -0.2387592114900288,
        "compression_ratio": 1.645933014354067,
        "end": 3495.42,
        "id": 1213,
        "no_speech_prob": 0.0001253373484360054,
        "seek": 348302,
        "start": 3492.78,
        "temperature": 0,
        "text": " So one of the magical things about using Express",
        "tokens": [
          50852,
          407,
          472,
          295,
          264,
          12066,
          721,
          466,
          1228,
          20212,
          50984
        ]
      },
      {
        "avg_logprob": -0.2387592114900288,
        "compression_ratio": 1.645933014354067,
        "end": 3499.42,
        "id": 1214,
        "no_speech_prob": 0.0001253373484360054,
        "seek": 348302,
        "start": 3495.42,
        "temperature": 0,
        "text": " is Express will automatically format your JavaScript object",
        "tokens": [
          50984,
          307,
          20212,
          486,
          6772,
          7877,
          428,
          15778,
          2657,
          51184
        ]
      },
      {
        "avg_logprob": -0.2387592114900288,
        "compression_ratio": 1.645933014354067,
        "end": 3502.84,
        "id": 1215,
        "no_speech_prob": 0.0001253373484360054,
        "seek": 348302,
        "start": 3499.42,
        "temperature": 0,
        "text": " that you send out into the world as JSON.",
        "tokens": [
          51184,
          300,
          291,
          2845,
          484,
          666,
          264,
          1002,
          382,
          31828,
          13,
          51355
        ]
      },
      {
        "avg_logprob": -0.2387592114900288,
        "compression_ratio": 1.645933014354067,
        "end": 3504.42,
        "id": 1216,
        "no_speech_prob": 0.0001253373484360054,
        "seek": 348302,
        "start": 3502.84,
        "temperature": 0,
        "text": " So this is actually done.",
        "tokens": [
          51355,
          407,
          341,
          307,
          767,
          1096,
          13,
          51434
        ]
      },
      {
        "avg_logprob": -0.2387592114900288,
        "compression_ratio": 1.645933014354067,
        "end": 3508.42,
        "id": 1217,
        "no_speech_prob": 0.0001253373484360054,
        "seek": 348302,
        "start": 3504.42,
        "temperature": 0,
        "text": " So I can now go to slash all.",
        "tokens": [
          51434,
          407,
          286,
          393,
          586,
          352,
          281,
          17330,
          439,
          13,
          51634
        ]
      },
      {
        "avg_logprob": -0.1856342585740891,
        "compression_ratio": 1.6073059360730593,
        "end": 3513.38,
        "id": 1218,
        "no_speech_prob": 0.0015978302108123899,
        "seek": 350842,
        "start": 3508.42,
        "temperature": 0,
        "text": " And I can see this is now me making an API request to my API.",
        "tokens": [
          50364,
          400,
          286,
          393,
          536,
          341,
          307,
          586,
          385,
          1455,
          364,
          9362,
          5308,
          281,
          452,
          9362,
          13,
          50612
        ]
      },
      {
        "avg_logprob": -0.1856342585740891,
        "compression_ratio": 1.6073059360730593,
        "end": 3515.26,
        "id": 1219,
        "no_speech_prob": 0.0015978302108123899,
        "seek": 350842,
        "start": 3513.38,
        "temperature": 0,
        "text": " And I'm getting the list of words.",
        "tokens": [
          50612,
          400,
          286,
          478,
          1242,
          264,
          1329,
          295,
          2283,
          13,
          50706
        ]
      },
      {
        "avg_logprob": -0.1856342585740891,
        "compression_ratio": 1.6073059360730593,
        "end": 3524.54,
        "id": 1220,
        "no_speech_prob": 0.0015978302108123899,
        "seek": 350842,
        "start": 3515.26,
        "temperature": 0,
        "text": " And if I add another word to it, like gloom, doom and gloom,",
        "tokens": [
          50706,
          400,
          498,
          286,
          909,
          1071,
          1349,
          281,
          309,
          11,
          411,
          3114,
          298,
          11,
          37131,
          293,
          3114,
          298,
          11,
          51170
        ]
      },
      {
        "avg_logprob": -0.1856342585740891,
        "compression_ratio": 1.6073059360730593,
        "end": 3527.7000000000003,
        "id": 1221,
        "no_speech_prob": 0.0015978302108123899,
        "seek": 350842,
        "start": 3524.54,
        "temperature": 0,
        "text": " now I have another word there with a score of negative 2.",
        "tokens": [
          51170,
          586,
          286,
          362,
          1071,
          1349,
          456,
          365,
          257,
          6175,
          295,
          3671,
          568,
          13,
          51328
        ]
      },
      {
        "avg_logprob": -0.1856342585740891,
        "compression_ratio": 1.6073059360730593,
        "end": 3528.54,
        "id": 1222,
        "no_speech_prob": 0.0015978302108123899,
        "seek": 350842,
        "start": 3527.7000000000003,
        "temperature": 0,
        "text": " I hit refresh.",
        "tokens": [
          51328,
          286,
          2045,
          15134,
          13,
          51370
        ]
      },
      {
        "avg_logprob": -0.1856342585740891,
        "compression_ratio": 1.6073059360730593,
        "end": 3530.2200000000003,
        "id": 1223,
        "no_speech_prob": 0.0015978302108123899,
        "seek": 350842,
        "start": 3528.54,
        "temperature": 0,
        "text": " I see that as well.",
        "tokens": [
          51370,
          286,
          536,
          300,
          382,
          731,
          13,
          51454
        ]
      },
      {
        "avg_logprob": -0.1856342585740891,
        "compression_ratio": 1.6073059360730593,
        "end": 3532.02,
        "id": 1224,
        "no_speech_prob": 0.0015978302108123899,
        "seek": 350842,
        "start": 3530.2200000000003,
        "temperature": 0,
        "text": " So what I want to do, in addition",
        "tokens": [
          51454,
          407,
          437,
          286,
          528,
          281,
          360,
          11,
          294,
          4500,
          51544
        ]
      },
      {
        "avg_logprob": -0.1856342585740891,
        "compression_ratio": 1.6073059360730593,
        "end": 3534.02,
        "id": 1225,
        "no_speech_prob": 0.0015978302108123899,
        "seek": 350842,
        "start": 3532.02,
        "temperature": 0,
        "text": " to having this be an API, so there's",
        "tokens": [
          51544,
          281,
          1419,
          341,
          312,
          364,
          9362,
          11,
          370,
          456,
          311,
          51644
        ]
      },
      {
        "avg_logprob": -0.1856342585740891,
        "compression_ratio": 1.6073059360730593,
        "end": 3535.26,
        "id": 1226,
        "no_speech_prob": 0.0015978302108123899,
        "seek": 350842,
        "start": 3534.02,
        "temperature": 0,
        "text": " a couple of things I could do.",
        "tokens": [
          51644,
          257,
          1916,
          295,
          721,
          286,
          727,
          360,
          13,
          51706
        ]
      },
      {
        "avg_logprob": -0.21261461964853995,
        "compression_ratio": 1.697080291970803,
        "end": 3538.5800000000004,
        "id": 1227,
        "no_speech_prob": 0.0002415643393760547,
        "seek": 353526,
        "start": 3535.26,
        "temperature": 0,
        "text": " One is that I might want to search for a particular word",
        "tokens": [
          50364,
          1485,
          307,
          300,
          286,
          1062,
          528,
          281,
          3164,
          337,
          257,
          1729,
          1349,
          50530
        ]
      },
      {
        "avg_logprob": -0.21261461964853995,
        "compression_ratio": 1.697080291970803,
        "end": 3539.94,
        "id": 1228,
        "no_speech_prob": 0.0002415643393760547,
        "seek": 353526,
        "start": 3538.5800000000004,
        "temperature": 0,
        "text": " to see if it's in the API.",
        "tokens": [
          50530,
          281,
          536,
          498,
          309,
          311,
          294,
          264,
          9362,
          13,
          50598
        ]
      },
      {
        "avg_logprob": -0.21261461964853995,
        "compression_ratio": 1.697080291970803,
        "end": 3541.6200000000003,
        "id": 1229,
        "no_speech_prob": 0.0002415643393760547,
        "seek": 353526,
        "start": 3539.94,
        "temperature": 0,
        "text": " If it is, get the score.",
        "tokens": [
          50598,
          759,
          309,
          307,
          11,
          483,
          264,
          6175,
          13,
          50682
        ]
      },
      {
        "avg_logprob": -0.21261461964853995,
        "compression_ratio": 1.697080291970803,
        "end": 3544.1800000000003,
        "id": 1230,
        "no_speech_prob": 0.0002415643393760547,
        "seek": 353526,
        "start": 3541.6200000000003,
        "temperature": 0,
        "text": " Or I might also want to be able to, as a user,",
        "tokens": [
          50682,
          1610,
          286,
          1062,
          611,
          528,
          281,
          312,
          1075,
          281,
          11,
          382,
          257,
          4195,
          11,
          50810
        ]
      },
      {
        "avg_logprob": -0.21261461964853995,
        "compression_ratio": 1.697080291970803,
        "end": 3545.82,
        "id": 1231,
        "no_speech_prob": 0.0002415643393760547,
        "seek": 353526,
        "start": 3544.1800000000003,
        "temperature": 0,
        "text": " add words to the API.",
        "tokens": [
          50810,
          909,
          2283,
          281,
          264,
          9362,
          13,
          50892
        ]
      },
      {
        "avg_logprob": -0.21261461964853995,
        "compression_ratio": 1.697080291970803,
        "end": 3548.34,
        "id": 1232,
        "no_speech_prob": 0.0002415643393760547,
        "seek": 353526,
        "start": 3545.82,
        "temperature": 0,
        "text": " So this is a sort of design decision.",
        "tokens": [
          50892,
          407,
          341,
          307,
          257,
          1333,
          295,
          1715,
          3537,
          13,
          51018
        ]
      },
      {
        "avg_logprob": -0.21261461964853995,
        "compression_ratio": 1.697080291970803,
        "end": 3549.6600000000003,
        "id": 1233,
        "no_speech_prob": 0.0002415643393760547,
        "seek": 353526,
        "start": 3548.34,
        "temperature": 0,
        "text": " What are you doing here?",
        "tokens": [
          51018,
          708,
          366,
          291,
          884,
          510,
          30,
          51084
        ]
      },
      {
        "avg_logprob": -0.21261461964853995,
        "compression_ratio": 1.697080291970803,
        "end": 3551.1800000000003,
        "id": 1234,
        "no_speech_prob": 0.0002415643393760547,
        "seek": 353526,
        "start": 3549.6600000000003,
        "temperature": 0,
        "text": " I'm just making a demonstration.",
        "tokens": [
          51084,
          286,
          478,
          445,
          1455,
          257,
          16520,
          13,
          51160
        ]
      },
      {
        "avg_logprob": -0.21261461964853995,
        "compression_ratio": 1.697080291970803,
        "end": 3553.1000000000004,
        "id": 1235,
        "no_speech_prob": 0.0002415643393760547,
        "seek": 353526,
        "start": 3551.1800000000003,
        "temperature": 0,
        "text": " I think it would be useful to see how can you",
        "tokens": [
          51160,
          286,
          519,
          309,
          576,
          312,
          4420,
          281,
          536,
          577,
          393,
          291,
          51256
        ]
      },
      {
        "avg_logprob": -0.21261461964853995,
        "compression_ratio": 1.697080291970803,
        "end": 3557.78,
        "id": 1236,
        "no_speech_prob": 0.0002415643393760547,
        "seek": 353526,
        "start": 3553.1000000000004,
        "temperature": 0,
        "text": " create a route where a user can insert data into the database.",
        "tokens": [
          51256,
          1884,
          257,
          7955,
          689,
          257,
          4195,
          393,
          8969,
          1412,
          666,
          264,
          8149,
          13,
          51490
        ]
      },
      {
        "avg_logprob": -0.21261461964853995,
        "compression_ratio": 1.697080291970803,
        "end": 3560.78,
        "id": 1237,
        "no_speech_prob": 0.0002415643393760547,
        "seek": 353526,
        "start": 3557.78,
        "temperature": 0,
        "text": " And by the way, that's my database right now.",
        "tokens": [
          51490,
          400,
          538,
          264,
          636,
          11,
          300,
          311,
          452,
          8149,
          558,
          586,
          13,
          51640
        ]
      },
      {
        "avg_logprob": -0.21261461964853995,
        "compression_ratio": 1.697080291970803,
        "end": 3563.5800000000004,
        "id": 1238,
        "no_speech_prob": 0.0002415643393760547,
        "seek": 353526,
        "start": 3560.78,
        "temperature": 0,
        "text": " So as I go through these videos, I'm",
        "tokens": [
          51640,
          407,
          382,
          286,
          352,
          807,
          613,
          2145,
          11,
          286,
          478,
          51780
        ]
      },
      {
        "avg_logprob": -0.22581628921928756,
        "compression_ratio": 1.654708520179372,
        "end": 3566.62,
        "id": 1239,
        "no_speech_prob": 0.00013135161134414375,
        "seek": 356358,
        "start": 3563.62,
        "temperature": 0,
        "text": " going to get into persistence, working with databases.",
        "tokens": [
          50366,
          516,
          281,
          483,
          666,
          37617,
          11,
          1364,
          365,
          22380,
          13,
          50516
        ]
      },
      {
        "avg_logprob": -0.22581628921928756,
        "compression_ratio": 1.654708520179372,
        "end": 3569.1,
        "id": 1240,
        "no_speech_prob": 0.00013135161134414375,
        "seek": 356358,
        "start": 3566.62,
        "temperature": 0,
        "text": " And there are various levels of that.",
        "tokens": [
          50516,
          400,
          456,
          366,
          3683,
          4358,
          295,
          300,
          13,
          50640
        ]
      },
      {
        "avg_logprob": -0.22581628921928756,
        "compression_ratio": 1.654708520179372,
        "end": 3571.18,
        "id": 1241,
        "no_speech_prob": 0.00013135161134414375,
        "seek": 356358,
        "start": 3569.1,
        "temperature": 0,
        "text": " On the one hand, this will persist.",
        "tokens": [
          50640,
          1282,
          264,
          472,
          1011,
          11,
          341,
          486,
          13233,
          13,
          50744
        ]
      },
      {
        "avg_logprob": -0.22581628921928756,
        "compression_ratio": 1.654708520179372,
        "end": 3572.46,
        "id": 1242,
        "no_speech_prob": 0.00013135161134414375,
        "seek": 356358,
        "start": 3571.18,
        "temperature": 0,
        "text": " It will never go away.",
        "tokens": [
          50744,
          467,
          486,
          1128,
          352,
          1314,
          13,
          50808
        ]
      },
      {
        "avg_logprob": -0.22581628921928756,
        "compression_ratio": 1.654708520179372,
        "end": 3574.86,
        "id": 1243,
        "no_speech_prob": 0.00013135161134414375,
        "seek": 356358,
        "start": 3572.46,
        "temperature": 0,
        "text": " It's written there into the code.",
        "tokens": [
          50808,
          467,
          311,
          3720,
          456,
          666,
          264,
          3089,
          13,
          50928
        ]
      },
      {
        "avg_logprob": -0.22581628921928756,
        "compression_ratio": 1.654708520179372,
        "end": 3576.2599999999998,
        "id": 1244,
        "no_speech_prob": 0.00013135161134414375,
        "seek": 356358,
        "start": 3574.86,
        "temperature": 0,
        "text": " My database is hard-coded.",
        "tokens": [
          50928,
          1222,
          8149,
          307,
          1152,
          12,
          66,
          12340,
          13,
          50998
        ]
      },
      {
        "avg_logprob": -0.22581628921928756,
        "compression_ratio": 1.654708520179372,
        "end": 3578.7799999999997,
        "id": 1245,
        "no_speech_prob": 0.00013135161134414375,
        "seek": 356358,
        "start": 3576.2599999999998,
        "temperature": 0,
        "text": " Not the best solution, but it's a good starting point.",
        "tokens": [
          50998,
          1726,
          264,
          1151,
          3827,
          11,
          457,
          309,
          311,
          257,
          665,
          2891,
          935,
          13,
          51124
        ]
      },
      {
        "avg_logprob": -0.22581628921928756,
        "compression_ratio": 1.654708520179372,
        "end": 3581.98,
        "id": 1246,
        "no_speech_prob": 0.00013135161134414375,
        "seek": 356358,
        "start": 3578.7799999999997,
        "temperature": 0,
        "text": " So I'm going to change this particular route.",
        "tokens": [
          51124,
          407,
          286,
          478,
          516,
          281,
          1319,
          341,
          1729,
          7955,
          13,
          51284
        ]
      },
      {
        "avg_logprob": -0.22581628921928756,
        "compression_ratio": 1.654708520179372,
        "end": 3588.2999999999997,
        "id": 1247,
        "no_speech_prob": 0.00013135161134414375,
        "seek": 356358,
        "start": 3581.98,
        "temperature": 0,
        "text": " And I'm going to change it to add word score.",
        "tokens": [
          51284,
          400,
          286,
          478,
          516,
          281,
          1319,
          309,
          281,
          909,
          1349,
          6175,
          13,
          51600
        ]
      },
      {
        "avg_logprob": -0.22581628921928756,
        "compression_ratio": 1.654708520179372,
        "end": 3589.42,
        "id": 1248,
        "no_speech_prob": 0.00013135161134414375,
        "seek": 356358,
        "start": 3588.2999999999997,
        "temperature": 0,
        "text": " Add word.",
        "tokens": [
          51600,
          5349,
          1349,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.2601138329019352,
        "compression_ratio": 1.5759162303664922,
        "end": 3594.38,
        "id": 1249,
        "no_speech_prob": 0.00012339437671471387,
        "seek": 358942,
        "start": 3589.42,
        "temperature": 0,
        "text": " So I want a route where if the user adds a word with a score,",
        "tokens": [
          50364,
          407,
          286,
          528,
          257,
          7955,
          689,
          498,
          264,
          4195,
          10860,
          257,
          1349,
          365,
          257,
          6175,
          11,
          50612
        ]
      },
      {
        "avg_logprob": -0.2601138329019352,
        "compression_ratio": 1.5759162303664922,
        "end": 3596.42,
        "id": 1250,
        "no_speech_prob": 0.00012339437671471387,
        "seek": 358942,
        "start": 3594.38,
        "temperature": 0,
        "text": " it goes into the database.",
        "tokens": [
          50612,
          309,
          1709,
          666,
          264,
          8149,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2601138329019352,
        "compression_ratio": 1.5759162303664922,
        "end": 3599.94,
        "id": 1251,
        "no_speech_prob": 0.00012339437671471387,
        "seek": 358942,
        "start": 3596.42,
        "temperature": 0,
        "text": " So I'm going to change this to add word.",
        "tokens": [
          50714,
          407,
          286,
          478,
          516,
          281,
          1319,
          341,
          281,
          909,
          1349,
          13,
          50890
        ]
      },
      {
        "avg_logprob": -0.2601138329019352,
        "compression_ratio": 1.5759162303664922,
        "end": 3601.98,
        "id": 1252,
        "no_speech_prob": 0.00012339437671471387,
        "seek": 358942,
        "start": 3599.94,
        "temperature": 0,
        "text": " Here are the parameters.",
        "tokens": [
          50890,
          1692,
          366,
          264,
          9834,
          13,
          50992
        ]
      },
      {
        "avg_logprob": -0.2601138329019352,
        "compression_ratio": 1.5759162303664922,
        "end": 3607.9,
        "id": 1253,
        "no_speech_prob": 0.00012339437671471387,
        "seek": 358942,
        "start": 3601.98,
        "temperature": 0,
        "text": " The word is data.word.",
        "tokens": [
          50992,
          440,
          1349,
          307,
          1412,
          13,
          7462,
          13,
          51288
        ]
      },
      {
        "avg_logprob": -0.2601138329019352,
        "compression_ratio": 1.5759162303664922,
        "end": 3610.86,
        "id": 1254,
        "no_speech_prob": 0.00012339437671471387,
        "seek": 358942,
        "start": 3607.9,
        "temperature": 0,
        "text": " The score is, and this is, I'm kind of being",
        "tokens": [
          51288,
          440,
          6175,
          307,
          11,
          293,
          341,
          307,
          11,
          286,
          478,
          733,
          295,
          885,
          51436
        ]
      },
      {
        "avg_logprob": -0.2601138329019352,
        "compression_ratio": 1.5759162303664922,
        "end": 3612.02,
        "id": 1255,
        "no_speech_prob": 0.00012339437671471387,
        "seek": 358942,
        "start": 3610.86,
        "temperature": 0,
        "text": " very long-winded about this.",
        "tokens": [
          51436,
          588,
          938,
          12,
          12199,
          292,
          466,
          341,
          13,
          51494
        ]
      },
      {
        "avg_logprob": -0.2601138329019352,
        "compression_ratio": 1.5759162303664922,
        "end": 3615.9,
        "id": 1256,
        "no_speech_prob": 0.00012339437671471387,
        "seek": 358942,
        "start": 3612.02,
        "temperature": 0,
        "text": " I can't just say word equals request.params.word.",
        "tokens": [
          51494,
          286,
          393,
          380,
          445,
          584,
          1349,
          6915,
          5308,
          13,
          2181,
          4070,
          13,
          7462,
          13,
          51688
        ]
      },
      {
        "avg_logprob": -0.23602441787719727,
        "compression_ratio": 1.7322404371584699,
        "end": 3619.34,
        "id": 1257,
        "no_speech_prob": 0.00006605212547583506,
        "seek": 361590,
        "start": 3616.82,
        "temperature": 0,
        "text": " Data.score.",
        "tokens": [
          50410,
          11888,
          13,
          4417,
          418,
          13,
          50536
        ]
      },
      {
        "avg_logprob": -0.23602441787719727,
        "compression_ratio": 1.7322404371584699,
        "end": 3628.78,
        "id": 1258,
        "no_speech_prob": 0.00006605212547583506,
        "seek": 361590,
        "start": 3619.34,
        "temperature": 0,
        "text": " And then what I want to do is say words.word equals score.",
        "tokens": [
          50536,
          400,
          550,
          437,
          286,
          528,
          281,
          360,
          307,
          584,
          2283,
          13,
          7462,
          6915,
          6175,
          13,
          51008
        ]
      },
      {
        "avg_logprob": -0.23602441787719727,
        "compression_ratio": 1.7322404371584699,
        "end": 3629.5,
        "id": 1259,
        "no_speech_prob": 0.00006605212547583506,
        "seek": 361590,
        "start": 3628.78,
        "temperature": 0,
        "text": " Look at this.",
        "tokens": [
          51008,
          2053,
          412,
          341,
          13,
          51044
        ]
      },
      {
        "avg_logprob": -0.23602441787719727,
        "compression_ratio": 1.7322404371584699,
        "end": 3632.7400000000002,
        "id": 1260,
        "no_speech_prob": 0.00006605212547583506,
        "seek": 361590,
        "start": 3629.5,
        "temperature": 0,
        "text": " This is me taking in the data from the user, the word",
        "tokens": [
          51044,
          639,
          307,
          385,
          1940,
          294,
          264,
          1412,
          490,
          264,
          4195,
          11,
          264,
          1349,
          51206
        ]
      },
      {
        "avg_logprob": -0.23602441787719727,
        "compression_ratio": 1.7322404371584699,
        "end": 3635.7400000000002,
        "id": 1261,
        "no_speech_prob": 0.00006605212547583506,
        "seek": 361590,
        "start": 3632.7400000000002,
        "temperature": 0,
        "text": " and the score, and putting it into that object,",
        "tokens": [
          51206,
          293,
          264,
          6175,
          11,
          293,
          3372,
          309,
          666,
          300,
          2657,
          11,
          51356
        ]
      },
      {
        "avg_logprob": -0.23602441787719727,
        "compression_ratio": 1.7322404371584699,
        "end": 3639.9,
        "id": 1262,
        "no_speech_prob": 0.00006605212547583506,
        "seek": 361590,
        "start": 3635.7400000000002,
        "temperature": 0,
        "text": " putting it into that object with a key value pair.",
        "tokens": [
          51356,
          3372,
          309,
          666,
          300,
          2657,
          365,
          257,
          2141,
          2158,
          6119,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.23602441787719727,
        "compression_ratio": 1.7322404371584699,
        "end": 3641.26,
        "id": 1263,
        "no_speech_prob": 0.00006605212547583506,
        "seek": 361590,
        "start": 3639.9,
        "temperature": 0,
        "text": " The word is the key.",
        "tokens": [
          51564,
          440,
          1349,
          307,
          264,
          2141,
          13,
          51632
        ]
      },
      {
        "avg_logprob": -0.23602441787719727,
        "compression_ratio": 1.7322404371584699,
        "end": 3642.7000000000003,
        "id": 1264,
        "no_speech_prob": 0.00006605212547583506,
        "seek": 361590,
        "start": 3641.26,
        "temperature": 0,
        "text": " The score is the value.",
        "tokens": [
          51632,
          440,
          6175,
          307,
          264,
          2158,
          13,
          51704
        ]
      },
      {
        "avg_logprob": -0.23602441787719727,
        "compression_ratio": 1.7322404371584699,
        "end": 3645.02,
        "id": 1265,
        "no_speech_prob": 0.00006605212547583506,
        "seek": 361590,
        "start": 3642.7000000000003,
        "temperature": 0,
        "text": " And then I need to create a reply.",
        "tokens": [
          51704,
          400,
          550,
          286,
          643,
          281,
          1884,
          257,
          16972,
          13,
          51820
        ]
      },
      {
        "avg_logprob": -0.23091006515049697,
        "compression_ratio": 1.5526315789473684,
        "end": 3649.18,
        "id": 1266,
        "no_speech_prob": 0.00000966608331509633,
        "seek": 364502,
        "start": 3645.1,
        "temperature": 0,
        "text": " And all of my replies, I want them to be written as an object.",
        "tokens": [
          50368,
          400,
          439,
          295,
          452,
          42289,
          11,
          286,
          528,
          552,
          281,
          312,
          3720,
          382,
          364,
          2657,
          13,
          50572
        ]
      },
      {
        "avg_logprob": -0.23091006515049697,
        "compression_ratio": 1.5526315789473684,
        "end": 3655.22,
        "id": 1267,
        "no_speech_prob": 0.00000966608331509633,
        "seek": 364502,
        "start": 3649.18,
        "temperature": 0,
        "text": " So I'm going to say message, thank you for your word.",
        "tokens": [
          50572,
          407,
          286,
          478,
          516,
          281,
          584,
          3636,
          11,
          1309,
          291,
          337,
          428,
          1349,
          13,
          50874
        ]
      },
      {
        "avg_logprob": -0.23091006515049697,
        "compression_ratio": 1.5526315789473684,
        "end": 3655.78,
        "id": 1268,
        "no_speech_prob": 0.00000966608331509633,
        "seek": 364502,
        "start": 3655.22,
        "temperature": 0,
        "text": " OK?",
        "tokens": [
          50874,
          2264,
          30,
          50902
        ]
      },
      {
        "avg_logprob": -0.23091006515049697,
        "compression_ratio": 1.5526315789473684,
        "end": 3656.78,
        "id": 1269,
        "no_speech_prob": 0.00000966608331509633,
        "seek": 364502,
        "start": 3655.78,
        "temperature": 0,
        "text": " So there we go.",
        "tokens": [
          50902,
          407,
          456,
          321,
          352,
          13,
          50952
        ]
      },
      {
        "avg_logprob": -0.23091006515049697,
        "compression_ratio": 1.5526315789473684,
        "end": 3663.42,
        "id": 1270,
        "no_speech_prob": 0.00000966608331509633,
        "seek": 364502,
        "start": 3656.78,
        "temperature": 0,
        "text": " So now if I run this and I go here to all,",
        "tokens": [
          50952,
          407,
          586,
          498,
          286,
          1190,
          341,
          293,
          286,
          352,
          510,
          281,
          439,
          11,
          51284
        ]
      },
      {
        "avg_logprob": -0.23091006515049697,
        "compression_ratio": 1.5526315789473684,
        "end": 3665.58,
        "id": 1271,
        "no_speech_prob": 0.00000966608331509633,
        "seek": 364502,
        "start": 3663.42,
        "temperature": 0,
        "text": " we can see all of the data is there.",
        "tokens": [
          51284,
          321,
          393,
          536,
          439,
          295,
          264,
          1412,
          307,
          456,
          13,
          51392
        ]
      },
      {
        "avg_logprob": -0.23091006515049697,
        "compression_ratio": 1.5526315789473684,
        "end": 3668.18,
        "id": 1272,
        "no_speech_prob": 0.00000966608331509633,
        "seek": 364502,
        "start": 3665.58,
        "temperature": 0,
        "text": " Now I'm going to go to one more window.",
        "tokens": [
          51392,
          823,
          286,
          478,
          516,
          281,
          352,
          281,
          472,
          544,
          4910,
          13,
          51522
        ]
      },
      {
        "avg_logprob": -0.23091006515049697,
        "compression_ratio": 1.5526315789473684,
        "end": 3673.86,
        "id": 1273,
        "no_speech_prob": 0.00000966608331509633,
        "seek": 364502,
        "start": 3668.18,
        "temperature": 0,
        "text": " And I'm going to go to add a purple 5.",
        "tokens": [
          51522,
          400,
          286,
          478,
          516,
          281,
          352,
          281,
          909,
          257,
          9656,
          1025,
          13,
          51806
        ]
      },
      {
        "avg_logprob": -0.21971285343170166,
        "compression_ratio": 1.7201492537313432,
        "end": 3675.7000000000003,
        "id": 1274,
        "no_speech_prob": 0.000007889257176429965,
        "seek": 367386,
        "start": 3673.86,
        "temperature": 0,
        "text": " Purple is a very happy word.",
        "tokens": [
          50364,
          28483,
          307,
          257,
          588,
          2055,
          1349,
          13,
          50456
        ]
      },
      {
        "avg_logprob": -0.21971285343170166,
        "compression_ratio": 1.7201492537313432,
        "end": 3677.1400000000003,
        "id": 1275,
        "no_speech_prob": 0.000007889257176429965,
        "seek": 367386,
        "start": 3675.7000000000003,
        "temperature": 0,
        "text": " I'm going to hit Enter.",
        "tokens": [
          50456,
          286,
          478,
          516,
          281,
          2045,
          10399,
          13,
          50528
        ]
      },
      {
        "avg_logprob": -0.21971285343170166,
        "compression_ratio": 1.7201492537313432,
        "end": 3680.06,
        "id": 1276,
        "no_speech_prob": 0.000007889257176429965,
        "seek": 367386,
        "start": 3677.1400000000003,
        "temperature": 0,
        "text": " It's going to say message, thank you for your word.",
        "tokens": [
          50528,
          467,
          311,
          516,
          281,
          584,
          3636,
          11,
          1309,
          291,
          337,
          428,
          1349,
          13,
          50674
        ]
      },
      {
        "avg_logprob": -0.21971285343170166,
        "compression_ratio": 1.7201492537313432,
        "end": 3681.7000000000003,
        "id": 1277,
        "no_speech_prob": 0.000007889257176429965,
        "seek": 367386,
        "start": 3680.06,
        "temperature": 0,
        "text": " So I got that message back.",
        "tokens": [
          50674,
          407,
          286,
          658,
          300,
          3636,
          646,
          13,
          50756
        ]
      },
      {
        "avg_logprob": -0.21971285343170166,
        "compression_ratio": 1.7201492537313432,
        "end": 3684.9,
        "id": 1278,
        "no_speech_prob": 0.000007889257176429965,
        "seek": 367386,
        "start": 3681.7000000000003,
        "temperature": 0,
        "text": " And if I go to all, we can see purple.",
        "tokens": [
          50756,
          400,
          498,
          286,
          352,
          281,
          439,
          11,
          321,
          393,
          536,
          9656,
          13,
          50916
        ]
      },
      {
        "avg_logprob": -0.21971285343170166,
        "compression_ratio": 1.7201492537313432,
        "end": 3686.26,
        "id": 1279,
        "no_speech_prob": 0.000007889257176429965,
        "seek": 367386,
        "start": 3684.9,
        "temperature": 0,
        "text": " Oh, and look at that.",
        "tokens": [
          50916,
          876,
          11,
          293,
          574,
          412,
          300,
          13,
          50984
        ]
      },
      {
        "avg_logprob": -0.21971285343170166,
        "compression_ratio": 1.7201492537313432,
        "end": 3689.98,
        "id": 1280,
        "no_speech_prob": 0.000007889257176429965,
        "seek": 367386,
        "start": 3686.26,
        "temperature": 0,
        "text": " It got the, of course, the way that it's working",
        "tokens": [
          50984,
          467,
          658,
          264,
          11,
          295,
          1164,
          11,
          264,
          636,
          300,
          309,
          311,
          1364,
          51170
        ]
      },
      {
        "avg_logprob": -0.21971285343170166,
        "compression_ratio": 1.7201492537313432,
        "end": 3692.94,
        "id": 1281,
        "no_speech_prob": 0.000007889257176429965,
        "seek": 367386,
        "start": 3689.98,
        "temperature": 0,
        "text": " is it came in as a string, not a number.",
        "tokens": [
          51170,
          307,
          309,
          1361,
          294,
          382,
          257,
          6798,
          11,
          406,
          257,
          1230,
          13,
          51318
        ]
      },
      {
        "avg_logprob": -0.21971285343170166,
        "compression_ratio": 1.7201492537313432,
        "end": 3694.46,
        "id": 1282,
        "no_speech_prob": 0.000007889257176429965,
        "seek": 367386,
        "start": 3692.94,
        "temperature": 0,
        "text": " So I could correct that if I want.",
        "tokens": [
          51318,
          407,
          286,
          727,
          3006,
          300,
          498,
          286,
          528,
          13,
          51394
        ]
      },
      {
        "avg_logprob": -0.21971285343170166,
        "compression_ratio": 1.7201492537313432,
        "end": 3696.6600000000003,
        "id": 1283,
        "no_speech_prob": 0.000007889257176429965,
        "seek": 367386,
        "start": 3694.46,
        "temperature": 0,
        "text": " Let's correct that.",
        "tokens": [
          51394,
          961,
          311,
          3006,
          300,
          13,
          51504
        ]
      },
      {
        "avg_logprob": -0.21971285343170166,
        "compression_ratio": 1.7201492537313432,
        "end": 3701.2200000000003,
        "id": 1284,
        "no_speech_prob": 0.000007889257176429965,
        "seek": 367386,
        "start": 3696.6600000000003,
        "temperature": 0,
        "text": " So I could say, let's make sure that is actually a number.",
        "tokens": [
          51504,
          407,
          286,
          727,
          584,
          11,
          718,
          311,
          652,
          988,
          300,
          307,
          767,
          257,
          1230,
          13,
          51732
        ]
      },
      {
        "avg_logprob": -0.21971285343170166,
        "compression_ratio": 1.7201492537313432,
        "end": 3703.82,
        "id": 1285,
        "no_speech_prob": 0.000007889257176429965,
        "seek": 367386,
        "start": 3701.2200000000003,
        "temperature": 0,
        "text": " Because I might want to do some mathematical operations with it",
        "tokens": [
          51732,
          1436,
          286,
          1062,
          528,
          281,
          360,
          512,
          18894,
          7705,
          365,
          309,
          51862
        ]
      },
      {
        "avg_logprob": -0.30941560889492514,
        "compression_ratio": 1.6380090497737556,
        "end": 3705.3,
        "id": 1286,
        "no_speech_prob": 0.000055621901992708445,
        "seek": 370382,
        "start": 3704.78,
        "temperature": 0,
        "text": " later.",
        "tokens": [
          50412,
          1780,
          13,
          50438
        ]
      },
      {
        "avg_logprob": -0.30941560889492514,
        "compression_ratio": 1.6380090497737556,
        "end": 3707.26,
        "id": 1287,
        "no_speech_prob": 0.000055621901992708445,
        "seek": 370382,
        "start": 3705.3,
        "temperature": 0,
        "text": " So let's convert that to a number.",
        "tokens": [
          50438,
          407,
          718,
          311,
          7620,
          300,
          281,
          257,
          1230,
          13,
          50536
        ]
      },
      {
        "avg_logprob": -0.30941560889492514,
        "compression_ratio": 1.6380090497737556,
        "end": 3711.78,
        "id": 1288,
        "no_speech_prob": 0.000055621901992708445,
        "seek": 370382,
        "start": 3707.26,
        "temperature": 0,
        "text": " And I'm going to add the word again, hit refresh.",
        "tokens": [
          50536,
          400,
          286,
          478,
          516,
          281,
          909,
          264,
          1349,
          797,
          11,
          2045,
          15134,
          13,
          50762
        ]
      },
      {
        "avg_logprob": -0.30941560889492514,
        "compression_ratio": 1.6380090497737556,
        "end": 3713.46,
        "id": 1289,
        "no_speech_prob": 0.000055621901992708445,
        "seek": 370382,
        "start": 3711.78,
        "temperature": 0,
        "text": " And now you can see I got purple 5.",
        "tokens": [
          50762,
          400,
          586,
          291,
          393,
          536,
          286,
          658,
          9656,
          1025,
          13,
          50846
        ]
      },
      {
        "avg_logprob": -0.30941560889492514,
        "compression_ratio": 1.6380090497737556,
        "end": 3714.38,
        "id": 1290,
        "no_speech_prob": 0.000055621901992708445,
        "seek": 370382,
        "start": 3713.46,
        "temperature": 0,
        "text": " So there we go.",
        "tokens": [
          50846,
          407,
          456,
          321,
          352,
          13,
          50892
        ]
      },
      {
        "avg_logprob": -0.30941560889492514,
        "compression_ratio": 1.6380090497737556,
        "end": 3718.94,
        "id": 1291,
        "no_speech_prob": 0.000055621901992708445,
        "seek": 370382,
        "start": 3714.38,
        "temperature": 0,
        "text": " I have saved this word forevermore in the API.",
        "tokens": [
          50892,
          286,
          362,
          6624,
          341,
          1349,
          5680,
          3138,
          294,
          264,
          9362,
          13,
          51120
        ]
      },
      {
        "avg_logprob": -0.30941560889492514,
        "compression_ratio": 1.6380090497737556,
        "end": 3722.5800000000004,
        "id": 1292,
        "no_speech_prob": 0.000055621901992708445,
        "seek": 370382,
        "start": 3718.94,
        "temperature": 0,
        "text": " Now, there's a couple of things I want to add to this.",
        "tokens": [
          51120,
          823,
          11,
          456,
          311,
          257,
          1916,
          295,
          721,
          286,
          528,
          281,
          909,
          281,
          341,
          13,
          51302
        ]
      },
      {
        "avg_logprob": -0.30941560889492514,
        "compression_ratio": 1.6380090497737556,
        "end": 3724.7000000000003,
        "id": 1293,
        "no_speech_prob": 0.000055621901992708445,
        "seek": 370382,
        "start": 3722.5800000000004,
        "temperature": 0,
        "text": " Number one is, what if I just go to add purple",
        "tokens": [
          51302,
          5118,
          472,
          307,
          11,
          437,
          498,
          286,
          445,
          352,
          281,
          909,
          9656,
          51408
        ]
      },
      {
        "avg_logprob": -0.30941560889492514,
        "compression_ratio": 1.6380090497737556,
        "end": 3726.9,
        "id": 1294,
        "no_speech_prob": 0.000055621901992708445,
        "seek": 370382,
        "start": 3724.7000000000003,
        "temperature": 0,
        "text": " and I forget to add a number?",
        "tokens": [
          51408,
          293,
          286,
          2870,
          281,
          909,
          257,
          1230,
          30,
          51518
        ]
      },
      {
        "avg_logprob": -0.30941560889492514,
        "compression_ratio": 1.6380090497737556,
        "end": 3727.5,
        "id": 1295,
        "no_speech_prob": 0.000055621901992708445,
        "seek": 370382,
        "start": 3726.9,
        "temperature": 0,
        "text": " I run this.",
        "tokens": [
          51518,
          286,
          1190,
          341,
          13,
          51548
        ]
      },
      {
        "avg_logprob": -0.30941560889492514,
        "compression_ratio": 1.6380090497737556,
        "end": 3729.98,
        "id": 1296,
        "no_speech_prob": 0.000055621901992708445,
        "seek": 370382,
        "start": 3727.5,
        "temperature": 0,
        "text": " It says it cannot get that.",
        "tokens": [
          51548,
          467,
          1619,
          309,
          2644,
          483,
          300,
          13,
          51672
        ]
      },
      {
        "avg_logprob": -0.28344583940935564,
        "compression_ratio": 1.595,
        "end": 3735.2200000000003,
        "id": 1297,
        "no_speech_prob": 0.00004400112447910942,
        "seek": 373382,
        "start": 3734.02,
        "temperature": 0,
        "text": " Time out.",
        "tokens": [
          50374,
          6161,
          484,
          13,
          50434
        ]
      },
      {
        "avg_logprob": -0.28344583940935564,
        "compression_ratio": 1.595,
        "end": 3736.7200000000003,
        "id": 1298,
        "no_speech_prob": 0.00004400112447910942,
        "seek": 373382,
        "start": 3735.2200000000003,
        "temperature": 0,
        "text": " OK, I have to look up in my example.",
        "tokens": [
          50434,
          2264,
          11,
          286,
          362,
          281,
          574,
          493,
          294,
          452,
          1365,
          13,
          50509
        ]
      },
      {
        "avg_logprob": -0.28344583940935564,
        "compression_ratio": 1.595,
        "end": 3738.5800000000004,
        "id": 1299,
        "no_speech_prob": 0.00004400112447910942,
        "seek": 373382,
        "start": 3736.7200000000003,
        "temperature": 0,
        "text": " I thought it was going to get this,",
        "tokens": [
          50509,
          286,
          1194,
          309,
          390,
          516,
          281,
          483,
          341,
          11,
          50602
        ]
      },
      {
        "avg_logprob": -0.28344583940935564,
        "compression_ratio": 1.595,
        "end": 3740.7000000000003,
        "id": 1300,
        "no_speech_prob": 0.00004400112447910942,
        "seek": 373382,
        "start": 3738.5800000000004,
        "temperature": 0,
        "text": " but give me an error on the server side.",
        "tokens": [
          50602,
          457,
          976,
          385,
          364,
          6713,
          322,
          264,
          7154,
          1252,
          13,
          50708
        ]
      },
      {
        "avg_logprob": -0.28344583940935564,
        "compression_ratio": 1.595,
        "end": 3746.46,
        "id": 1301,
        "no_speech_prob": 0.00004400112447910942,
        "seek": 373382,
        "start": 3740.7000000000003,
        "temperature": 0,
        "text": " Like, if the last one can be optional.",
        "tokens": [
          50708,
          1743,
          11,
          498,
          264,
          1036,
          472,
          393,
          312,
          17312,
          13,
          50996
        ]
      },
      {
        "avg_logprob": -0.28344583940935564,
        "compression_ratio": 1.595,
        "end": 3749.34,
        "id": 1302,
        "no_speech_prob": 0.00004400112447910942,
        "seek": 373382,
        "start": 3746.46,
        "temperature": 0,
        "text": " I did this, I thought, in one of my pre-made examples.",
        "tokens": [
          50996,
          286,
          630,
          341,
          11,
          286,
          1194,
          11,
          294,
          472,
          295,
          452,
          659,
          12,
          10341,
          5110,
          13,
          51140
        ]
      },
      {
        "avg_logprob": -0.28344583940935564,
        "compression_ratio": 1.595,
        "end": 3751.06,
        "id": 1303,
        "no_speech_prob": 0.00004400112447910942,
        "seek": 373382,
        "start": 3749.34,
        "temperature": 0,
        "text": " So I'm paused now.",
        "tokens": [
          51140,
          407,
          286,
          478,
          46860,
          586,
          13,
          51226
        ]
      },
      {
        "avg_logprob": -0.28344583940935564,
        "compression_ratio": 1.595,
        "end": 3756.1000000000004,
        "id": 1304,
        "no_speech_prob": 0.00004400112447910942,
        "seek": 373382,
        "start": 3751.06,
        "temperature": 0,
        "text": " I'm going to go look at my pre-made examples.",
        "tokens": [
          51226,
          286,
          478,
          516,
          281,
          352,
          574,
          412,
          452,
          659,
          12,
          10341,
          5110,
          13,
          51478
        ]
      },
      {
        "avg_logprob": -0.28344583940935564,
        "compression_ratio": 1.595,
        "end": 3756.82,
        "id": 1305,
        "no_speech_prob": 0.00004400112447910942,
        "seek": 373382,
        "start": 3756.1000000000004,
        "temperature": 0,
        "text": " Oops, not here.",
        "tokens": [
          51478,
          21726,
          11,
          406,
          510,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.28344583940935564,
        "compression_ratio": 1.595,
        "end": 3761.1800000000003,
        "id": 1306,
        "no_speech_prob": 0.00004400112447910942,
        "seek": 373382,
        "start": 3760.34,
        "temperature": 0,
        "text": " Where did I do this?",
        "tokens": [
          51690,
          2305,
          630,
          286,
          360,
          341,
          30,
          51732
        ]
      },
      {
        "avg_logprob": -0.3543882464418317,
        "compression_ratio": 1.507177033492823,
        "end": 3763.8999999999996,
        "id": 1307,
        "no_speech_prob": 0.0007436918676830828,
        "seek": 376118,
        "start": 3761.18,
        "temperature": 0,
        "text": " Simple API express, probably here.",
        "tokens": [
          50364,
          21532,
          9362,
          5109,
          11,
          1391,
          510,
          13,
          50500
        ]
      },
      {
        "avg_logprob": -0.3543882464418317,
        "compression_ratio": 1.507177033492823,
        "end": 3764.8199999999997,
        "id": 1308,
        "no_speech_prob": 0.0007436918676830828,
        "seek": 376118,
        "start": 3763.8999999999996,
        "temperature": 0,
        "text": " Did I do it here?",
        "tokens": [
          50500,
          2589,
          286,
          360,
          309,
          510,
          30,
          50546
        ]
      },
      {
        "avg_logprob": -0.3543882464418317,
        "compression_ratio": 1.507177033492823,
        "end": 3766.4199999999996,
        "id": 1309,
        "no_speech_prob": 0.0007436918676830828,
        "seek": 376118,
        "start": 3764.8199999999997,
        "temperature": 0,
        "text": " Oh, no, no, this is not what I did.",
        "tokens": [
          50546,
          876,
          11,
          572,
          11,
          572,
          11,
          341,
          307,
          406,
          437,
          286,
          630,
          13,
          50626
        ]
      },
      {
        "avg_logprob": -0.3543882464418317,
        "compression_ratio": 1.507177033492823,
        "end": 3772.5,
        "id": 1310,
        "no_speech_prob": 0.0007436918676830828,
        "seek": 376118,
        "start": 3769.06,
        "temperature": 0,
        "text": " I thought there was a way to determine to make it optional.",
        "tokens": [
          50758,
          286,
          1194,
          456,
          390,
          257,
          636,
          281,
          6997,
          281,
          652,
          309,
          17312,
          13,
          50930
        ]
      },
      {
        "avg_logprob": -0.3543882464418317,
        "compression_ratio": 1.507177033492823,
        "end": 3778.74,
        "id": 1311,
        "no_speech_prob": 0.0007436918676830828,
        "seek": 376118,
        "start": 3772.5,
        "temperature": 0,
        "text": " Somebody in the chat might tell me before I figure it out.",
        "tokens": [
          50930,
          13463,
          294,
          264,
          5081,
          1062,
          980,
          385,
          949,
          286,
          2573,
          309,
          484,
          13,
          51242
        ]
      },
      {
        "avg_logprob": -0.3543882464418317,
        "compression_ratio": 1.507177033492823,
        "end": 3781.54,
        "id": 1312,
        "no_speech_prob": 0.0007436918676830828,
        "seek": 376118,
        "start": 3778.74,
        "temperature": 0,
        "text": " I'm going to look at routes rest.",
        "tokens": [
          51242,
          286,
          478,
          516,
          281,
          574,
          412,
          18242,
          1472,
          13,
          51382
        ]
      },
      {
        "avg_logprob": -0.3543882464418317,
        "compression_ratio": 1.507177033492823,
        "end": 3784.8199999999997,
        "id": 1313,
        "no_speech_prob": 0.0007436918676830828,
        "seek": 376118,
        "start": 3781.54,
        "temperature": 0,
        "text": " Can I do that in here?",
        "tokens": [
          51382,
          1664,
          286,
          360,
          300,
          294,
          510,
          30,
          51546
        ]
      },
      {
        "avg_logprob": -0.3543882464418317,
        "compression_ratio": 1.507177033492823,
        "end": 3786.66,
        "id": 1314,
        "no_speech_prob": 0.0007436918676830828,
        "seek": 376118,
        "start": 3784.8199999999997,
        "temperature": 0,
        "text": " Yeah, do that.",
        "tokens": [
          51546,
          865,
          11,
          360,
          300,
          13,
          51638
        ]
      },
      {
        "avg_logprob": -0.3543882464418317,
        "compression_ratio": 1.507177033492823,
        "end": 3788.44,
        "id": 1315,
        "no_speech_prob": 0.0007436918676830828,
        "seek": 376118,
        "start": 3786.66,
        "temperature": 0,
        "text": " So the last one should be optional.",
        "tokens": [
          51638,
          407,
          264,
          1036,
          472,
          820,
          312,
          17312,
          13,
          51727
        ]
      },
      {
        "avg_logprob": -0.2761075648855656,
        "compression_ratio": 1.158878504672897,
        "end": 3790.08,
        "id": 1316,
        "no_speech_prob": 0.0019569979049265385,
        "seek": 378844,
        "start": 3788.44,
        "temperature": 0,
        "text": " That's the way I did it.",
        "tokens": [
          50364,
          663,
          311,
          264,
          636,
          286,
          630,
          309,
          13,
          50446
        ]
      },
      {
        "avg_logprob": -0.2761075648855656,
        "compression_ratio": 1.158878504672897,
        "end": 3796.68,
        "id": 1317,
        "no_speech_prob": 0.0019569979049265385,
        "seek": 378844,
        "start": 3790.08,
        "temperature": 0,
        "text": " If it doesn't exist, then just set it to 1.",
        "tokens": [
          50446,
          759,
          309,
          1177,
          380,
          2514,
          11,
          550,
          445,
          992,
          309,
          281,
          502,
          13,
          50776
        ]
      },
      {
        "avg_logprob": -0.2761075648855656,
        "compression_ratio": 1.158878504672897,
        "end": 3798.4,
        "id": 1318,
        "no_speech_prob": 0.0019569979049265385,
        "seek": 378844,
        "start": 3796.68,
        "temperature": 0,
        "text": " How come that didn't work for me?",
        "tokens": [
          50776,
          1012,
          808,
          300,
          994,
          380,
          589,
          337,
          385,
          30,
          50862
        ]
      },
      {
        "avg_logprob": -0.2761075648855656,
        "compression_ratio": 1.158878504672897,
        "end": 3817.2000000000003,
        "id": 1319,
        "no_speech_prob": 0.0019569979049265385,
        "seek": 378844,
        "start": 3815.88,
        "temperature": 0,
        "text": " Can't I just do this?",
        "tokens": [
          51736,
          1664,
          380,
          286,
          445,
          360,
          341,
          30,
          51802
        ]
      },
      {
        "avg_logprob": -0.3069942021133876,
        "compression_ratio": 1.508108108108108,
        "end": 3819.4399999999996,
        "id": 1320,
        "no_speech_prob": 0.001081709866411984,
        "seek": 381720,
        "start": 3817.24,
        "temperature": 0,
        "text": " Didn't get a 0.",
        "tokens": [
          50366,
          11151,
          380,
          483,
          257,
          1958,
          13,
          50476
        ]
      },
      {
        "avg_logprob": -0.3069942021133876,
        "compression_ratio": 1.508108108108108,
        "end": 3822.72,
        "id": 1321,
        "no_speech_prob": 0.001081709866411984,
        "seek": 381720,
        "start": 3819.4399999999996,
        "temperature": 0,
        "text": " I guess I'm not going to add this feature to this program",
        "tokens": [
          50476,
          286,
          2041,
          286,
          478,
          406,
          516,
          281,
          909,
          341,
          4111,
          281,
          341,
          1461,
          50640
        ]
      },
      {
        "avg_logprob": -0.3069942021133876,
        "compression_ratio": 1.508108108108108,
        "end": 3823.24,
        "id": 1322,
        "no_speech_prob": 0.001081709866411984,
        "seek": 381720,
        "start": 3822.72,
        "temperature": 0,
        "text": " right now.",
        "tokens": [
          50640,
          558,
          586,
          13,
          50666
        ]
      },
      {
        "avg_logprob": -0.3069942021133876,
        "compression_ratio": 1.508108108108108,
        "end": 3824.3999999999996,
        "id": 1323,
        "no_speech_prob": 0.001081709866411984,
        "seek": 381720,
        "start": 3823.24,
        "temperature": 0,
        "text": " I'll come back to it later.",
        "tokens": [
          50666,
          286,
          603,
          808,
          646,
          281,
          309,
          1780,
          13,
          50724
        ]
      },
      {
        "avg_logprob": -0.3069942021133876,
        "compression_ratio": 1.508108108108108,
        "end": 3828.4399999999996,
        "id": 1324,
        "no_speech_prob": 0.001081709866411984,
        "seek": 381720,
        "start": 3827.3199999999997,
        "temperature": 0,
        "text": " Hold on, let's see.",
        "tokens": [
          50870,
          6962,
          322,
          11,
          718,
          311,
          536,
          13,
          50926
        ]
      },
      {
        "avg_logprob": -0.3069942021133876,
        "compression_ratio": 1.508108108108108,
        "end": 3830.64,
        "id": 1325,
        "no_speech_prob": 0.001081709866411984,
        "seek": 381720,
        "start": 3828.4399999999996,
        "temperature": 0,
        "text": " Console.",
        "tokens": [
          50926,
          44152,
          13,
          51036
        ]
      },
      {
        "avg_logprob": -0.3069942021133876,
        "compression_ratio": 1.508108108108108,
        "end": 3833.68,
        "id": 1326,
        "no_speech_prob": 0.001081709866411984,
        "seek": 381720,
        "start": 3830.64,
        "temperature": 0,
        "text": " Did I add an extra?",
        "tokens": [
          51036,
          2589,
          286,
          909,
          364,
          2857,
          30,
          51188
        ]
      },
      {
        "avg_logprob": -0.3069942021133876,
        "compression_ratio": 1.508108108108108,
        "end": 3835.08,
        "id": 1327,
        "no_speech_prob": 0.001081709866411984,
        "seek": 381720,
        "start": 3833.68,
        "temperature": 0,
        "text": " I thought.",
        "tokens": [
          51188,
          286,
          1194,
          13,
          51258
        ]
      },
      {
        "avg_logprob": -0.3069942021133876,
        "compression_ratio": 1.508108108108108,
        "end": 3837.16,
        "id": 1328,
        "no_speech_prob": 0.001081709866411984,
        "seek": 381720,
        "start": 3835.08,
        "temperature": 0,
        "text": " I mean, I know I could just do a route without it.",
        "tokens": [
          51258,
          286,
          914,
          11,
          286,
          458,
          286,
          727,
          445,
          360,
          257,
          7955,
          1553,
          309,
          13,
          51362
        ]
      },
      {
        "avg_logprob": -0.3069942021133876,
        "compression_ratio": 1.508108108108108,
        "end": 3843.7999999999997,
        "id": 1329,
        "no_speech_prob": 0.001081709866411984,
        "seek": 381720,
        "start": 3840.3999999999996,
        "temperature": 0,
        "text": " Nobody in the chat knows this.",
        "tokens": [
          51524,
          9297,
          294,
          264,
          5081,
          3255,
          341,
          13,
          51694
        ]
      },
      {
        "avg_logprob": -0.3069942021133876,
        "compression_ratio": 1.508108108108108,
        "end": 3845.52,
        "id": 1330,
        "no_speech_prob": 0.001081709866411984,
        "seek": 381720,
        "start": 3843.7999999999997,
        "temperature": 0,
        "text": " Hold on, let's see here.",
        "tokens": [
          51694,
          6962,
          322,
          11,
          718,
          311,
          536,
          510,
          13,
          51780
        ]
      },
      {
        "avg_logprob": -0.31463956197102866,
        "compression_ratio": 1.4565217391304348,
        "end": 3850.28,
        "id": 1331,
        "no_speech_prob": 0.002082942984998226,
        "seek": 384552,
        "start": 3845.52,
        "temperature": 0,
        "text": " Console.log, am I here?",
        "tokens": [
          50364,
          44152,
          13,
          4987,
          11,
          669,
          286,
          510,
          30,
          50602
        ]
      },
      {
        "avg_logprob": -0.31463956197102866,
        "compression_ratio": 1.4565217391304348,
        "end": 3858.52,
        "id": 1332,
        "no_speech_prob": 0.002082942984998226,
        "seek": 384552,
        "start": 3850.28,
        "temperature": 0,
        "text": " So if I go to here, what if I do a slash?",
        "tokens": [
          50602,
          407,
          498,
          286,
          352,
          281,
          510,
          11,
          437,
          498,
          286,
          360,
          257,
          17330,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.31463956197102866,
        "compression_ratio": 1.4565217391304348,
        "end": 3859.52,
        "id": 1333,
        "no_speech_prob": 0.002082942984998226,
        "seek": 384552,
        "start": 3858.52,
        "temperature": 0,
        "text": " I guess I could do it.",
        "tokens": [
          51014,
          286,
          2041,
          286,
          727,
          360,
          309,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.31463956197102866,
        "compression_ratio": 1.4565217391304348,
        "end": 3867.2,
        "id": 1334,
        "no_speech_prob": 0.002082942984998226,
        "seek": 384552,
        "start": 3863.6,
        "temperature": 0,
        "text": " I don't want to get too stuck on this.",
        "tokens": [
          51268,
          286,
          500,
          380,
          528,
          281,
          483,
          886,
          5541,
          322,
          341,
          13,
          51448
        ]
      },
      {
        "avg_logprob": -0.31463956197102866,
        "compression_ratio": 1.4565217391304348,
        "end": 3872.72,
        "id": 1335,
        "no_speech_prob": 0.002082942984998226,
        "seek": 384552,
        "start": 3867.2,
        "temperature": 0,
        "text": " I mean, I can do something where if I do this, right?",
        "tokens": [
          51448,
          286,
          914,
          11,
          286,
          393,
          360,
          746,
          689,
          498,
          286,
          360,
          341,
          11,
          558,
          30,
          51724
        ]
      },
      {
        "avg_logprob": -0.31463956197102866,
        "compression_ratio": 1.4565217391304348,
        "end": 3873.6,
        "id": 1336,
        "no_speech_prob": 0.002082942984998226,
        "seek": 384552,
        "start": 3872.72,
        "temperature": 0,
        "text": " Yeah, I don't know.",
        "tokens": [
          51724,
          865,
          11,
          286,
          500,
          380,
          458,
          13,
          51768
        ]
      },
      {
        "avg_logprob": -0.2878821365476593,
        "compression_ratio": 1.6124031007751938,
        "end": 3880.2,
        "id": 1337,
        "no_speech_prob": 0.00001696440995146986,
        "seek": 387552,
        "start": 3876.52,
        "temperature": 0,
        "text": " Am I here?",
        "tokens": [
          50414,
          2012,
          286,
          510,
          30,
          50598
        ]
      },
      {
        "avg_logprob": -0.2878821365476593,
        "compression_ratio": 1.6124031007751938,
        "end": 3883.48,
        "id": 1338,
        "no_speech_prob": 0.00001696440995146986,
        "seek": 387552,
        "start": 3880.2,
        "temperature": 0,
        "text": " No, OK.",
        "tokens": [
          50598,
          883,
          11,
          2264,
          13,
          50762
        ]
      },
      {
        "avg_logprob": -0.2878821365476593,
        "compression_ratio": 1.6124031007751938,
        "end": 3887.2,
        "id": 1339,
        "no_speech_prob": 0.00001696440995146986,
        "seek": 387552,
        "start": 3883.48,
        "temperature": 0,
        "text": " And not you destroy if there is any try.",
        "tokens": [
          50762,
          400,
          406,
          291,
          5293,
          498,
          456,
          307,
          604,
          853,
          13,
          50948
        ]
      },
      {
        "avg_logprob": -0.2878821365476593,
        "compression_ratio": 1.6124031007751938,
        "end": 3888.48,
        "id": 1340,
        "no_speech_prob": 0.00001696440995146986,
        "seek": 387552,
        "start": 3887.2,
        "temperature": 0,
        "text": " Yeah, I know this.",
        "tokens": [
          50948,
          865,
          11,
          286,
          458,
          341,
          13,
          51012
        ]
      },
      {
        "avg_logprob": -0.2878821365476593,
        "compression_ratio": 1.6124031007751938,
        "end": 3890.96,
        "id": 1341,
        "no_speech_prob": 0.00001696440995146986,
        "seek": 387552,
        "start": 3888.48,
        "temperature": 0,
        "text": " Do you add a question mark for an optional one?",
        "tokens": [
          51012,
          1144,
          291,
          909,
          257,
          1168,
          1491,
          337,
          364,
          17312,
          472,
          30,
          51136
        ]
      },
      {
        "avg_logprob": -0.2878821365476593,
        "compression_ratio": 1.6124031007751938,
        "end": 3893.68,
        "id": 1342,
        "no_speech_prob": 0.00001696440995146986,
        "seek": 387552,
        "start": 3890.96,
        "temperature": 0,
        "text": " I'm going to just not worry about the optional thing,",
        "tokens": [
          51136,
          286,
          478,
          516,
          281,
          445,
          406,
          3292,
          466,
          264,
          17312,
          551,
          11,
          51272
        ]
      },
      {
        "avg_logprob": -0.2878821365476593,
        "compression_ratio": 1.6124031007751938,
        "end": 3895.48,
        "id": 1343,
        "no_speech_prob": 0.00001696440995146986,
        "seek": 387552,
        "start": 3893.68,
        "temperature": 0,
        "text": " because it's not that fundamental to this.",
        "tokens": [
          51272,
          570,
          309,
          311,
          406,
          300,
          8088,
          281,
          341,
          13,
          51362
        ]
      },
      {
        "avg_logprob": -0.2878821365476593,
        "compression_ratio": 1.6124031007751938,
        "end": 3896.68,
        "id": 1344,
        "no_speech_prob": 0.00001696440995146986,
        "seek": 387552,
        "start": 3895.48,
        "temperature": 0,
        "text": " I can bring that back later.",
        "tokens": [
          51362,
          286,
          393,
          1565,
          300,
          646,
          1780,
          13,
          51422
        ]
      },
      {
        "avg_logprob": -0.2878821365476593,
        "compression_ratio": 1.6124031007751938,
        "end": 3898.18,
        "id": 1345,
        "no_speech_prob": 0.00001696440995146986,
        "seek": 387552,
        "start": 3896.68,
        "temperature": 0,
        "text": " I just was going to do it because it",
        "tokens": [
          51422,
          286,
          445,
          390,
          516,
          281,
          360,
          309,
          570,
          309,
          51497
        ]
      },
      {
        "avg_logprob": -0.2878821365476593,
        "compression_ratio": 1.6124031007751938,
        "end": 3900.48,
        "id": 1346,
        "no_speech_prob": 0.00001696440995146986,
        "seek": 387552,
        "start": 3898.18,
        "temperature": 0,
        "text": " seemed like an obvious thing to look at right now.",
        "tokens": [
          51497,
          6576,
          411,
          364,
          6322,
          551,
          281,
          574,
          412,
          558,
          586,
          13,
          51612
        ]
      },
      {
        "avg_logprob": -0.2878821365476593,
        "compression_ratio": 1.6124031007751938,
        "end": 3902.08,
        "id": 1347,
        "no_speech_prob": 0.00001696440995146986,
        "seek": 387552,
        "start": 3900.48,
        "temperature": 0,
        "text": " Mostly because I'm in a time crunch",
        "tokens": [
          51612,
          29035,
          570,
          286,
          478,
          294,
          257,
          565,
          13386,
          51692
        ]
      },
      {
        "avg_logprob": -0.2878821365476593,
        "compression_ratio": 1.6124031007751938,
        "end": 3905.2,
        "id": 1348,
        "no_speech_prob": 0.00001696440995146986,
        "seek": 387552,
        "start": 3902.08,
        "temperature": 0,
        "text": " and I have to leave in like 15 minutes.",
        "tokens": [
          51692,
          293,
          286,
          362,
          281,
          1856,
          294,
          411,
          2119,
          2077,
          13,
          51848
        ]
      },
      {
        "avg_logprob": -0.2804933592330578,
        "compression_ratio": 1.5869565217391304,
        "end": 3907.7999999999997,
        "id": 1349,
        "no_speech_prob": 0.00003647849371191114,
        "seek": 390520,
        "start": 3905.2,
        "temperature": 0,
        "text": " And I want to get this thing finished.",
        "tokens": [
          50364,
          400,
          286,
          528,
          281,
          483,
          341,
          551,
          4335,
          13,
          50494
        ]
      },
      {
        "avg_logprob": -0.2804933592330578,
        "compression_ratio": 1.5869565217391304,
        "end": 3913,
        "id": 1350,
        "no_speech_prob": 0.00003647849371191114,
        "seek": 390520,
        "start": 3907.7999999999997,
        "temperature": 0,
        "text": " So I am going to go back and not worry about that.",
        "tokens": [
          50494,
          407,
          286,
          669,
          516,
          281,
          352,
          646,
          293,
          406,
          3292,
          466,
          300,
          13,
          50754
        ]
      },
      {
        "avg_logprob": -0.2804933592330578,
        "compression_ratio": 1.5869565217391304,
        "end": 3915.7999999999997,
        "id": 1351,
        "no_speech_prob": 0.00003647849371191114,
        "seek": 390520,
        "start": 3913,
        "temperature": 0,
        "text": " I'm trying to think where I left off before I tried doing that.",
        "tokens": [
          50754,
          286,
          478,
          1382,
          281,
          519,
          689,
          286,
          1411,
          766,
          949,
          286,
          3031,
          884,
          300,
          13,
          50894
        ]
      },
      {
        "avg_logprob": -0.2804933592330578,
        "compression_ratio": 1.5869565217391304,
        "end": 3927.9199999999996,
        "id": 1352,
        "no_speech_prob": 0.00003647849371191114,
        "seek": 390520,
        "start": 3918.6,
        "temperature": 0,
        "text": " I want to get to the, so there's the optional thing that I did.",
        "tokens": [
          51034,
          286,
          528,
          281,
          483,
          281,
          264,
          11,
          370,
          456,
          311,
          264,
          17312,
          551,
          300,
          286,
          630,
          13,
          51500
        ]
      },
      {
        "avg_logprob": -0.2804933592330578,
        "compression_ratio": 1.5869565217391304,
        "end": 3931.72,
        "id": 1353,
        "no_speech_prob": 0.00003647849371191114,
        "seek": 390520,
        "start": 3927.9199999999996,
        "temperature": 0,
        "text": " I'm losing my train of thought.",
        "tokens": [
          51500,
          286,
          478,
          7027,
          452,
          3847,
          295,
          1194,
          13,
          51690
        ]
      },
      {
        "avg_logprob": -0.2804933592330578,
        "compression_ratio": 1.5869565217391304,
        "end": 3933.64,
        "id": 1354,
        "no_speech_prob": 0.00003647849371191114,
        "seek": 390520,
        "start": 3931.72,
        "temperature": 0,
        "text": " Oh, is it a question mark for an optional?",
        "tokens": [
          51690,
          876,
          11,
          307,
          309,
          257,
          1168,
          1491,
          337,
          364,
          17312,
          30,
          51786
        ]
      },
      {
        "avg_logprob": -0.4482835272084112,
        "compression_ratio": 1.1929824561403508,
        "end": 3941.3199999999997,
        "id": 1355,
        "no_speech_prob": 0.00021654331067111343,
        "seek": 393520,
        "start": 3936.08,
        "temperature": 0,
        "text": " Optional param express.",
        "tokens": [
          50408,
          29284,
          304,
          6220,
          5109,
          13,
          50670
        ]
      },
      {
        "avg_logprob": -0.4482835272084112,
        "compression_ratio": 1.1929824561403508,
        "end": 3951.9199999999996,
        "id": 1356,
        "no_speech_prob": 0.00021654331067111343,
        "seek": 393520,
        "start": 3949.12,
        "temperature": 0,
        "text": " Curious here.",
        "tokens": [
          51060,
          7907,
          851,
          510,
          13,
          51200
        ]
      },
      {
        "avg_logprob": -0.4482835272084112,
        "compression_ratio": 1.1929824561403508,
        "end": 3953.72,
        "id": 1357,
        "no_speech_prob": 0.00021654331067111343,
        "seek": 393520,
        "start": 3951.9199999999996,
        "temperature": 0,
        "text": " I don't want to get too lost with this key.",
        "tokens": [
          51200,
          286,
          500,
          380,
          528,
          281,
          483,
          886,
          2731,
          365,
          341,
          2141,
          13,
          51290
        ]
      },
      {
        "avg_logprob": -0.4482835272084112,
        "compression_ratio": 1.1929824561403508,
        "end": 3962.2,
        "id": 1358,
        "no_speech_prob": 0.00021654331067111343,
        "seek": 393520,
        "start": 3959.64,
        "temperature": 0,
        "text": " Oh, question mark.",
        "tokens": [
          51586,
          876,
          11,
          1168,
          1491,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.4482835272084112,
        "compression_ratio": 1.1929824561403508,
        "end": 3964.64,
        "id": 1359,
        "no_speech_prob": 0.00021654331067111343,
        "seek": 393520,
        "start": 3962.2,
        "temperature": 0,
        "text": " So does that make it optional here?",
        "tokens": [
          51714,
          407,
          775,
          300,
          652,
          309,
          17312,
          510,
          30,
          51836
        ]
      },
      {
        "avg_logprob": -0.4431847266431125,
        "compression_ratio": 1.2457627118644068,
        "end": 3966.8399999999997,
        "id": 1360,
        "no_speech_prob": 0.00019110389985144138,
        "seek": 396464,
        "start": 3965.4,
        "temperature": 0,
        "text": " Yeah, after the parameter name.",
        "tokens": [
          50402,
          865,
          11,
          934,
          264,
          13075,
          1315,
          13,
          50474
        ]
      },
      {
        "avg_logprob": -0.4431847266431125,
        "compression_ratio": 1.2457627118644068,
        "end": 3981.12,
        "id": 1361,
        "no_speech_prob": 0.00019110389985144138,
        "seek": 396464,
        "start": 3970.8799999999997,
        "temperature": 0,
        "text": " So I think if I add this now, and I take this out.",
        "tokens": [
          50676,
          407,
          286,
          519,
          498,
          286,
          909,
          341,
          586,
          11,
          293,
          286,
          747,
          341,
          484,
          13,
          51188
        ]
      },
      {
        "avg_logprob": -0.4431847266431125,
        "compression_ratio": 1.2457627118644068,
        "end": 3986.8799999999997,
        "id": 1362,
        "no_speech_prob": 0.00019110389985144138,
        "seek": 396464,
        "start": 3984.2799999999997,
        "temperature": 0,
        "text": " And then, right, it's giving me no.",
        "tokens": [
          51346,
          400,
          550,
          11,
          558,
          11,
          309,
          311,
          2902,
          385,
          572,
          13,
          51476
        ]
      },
      {
        "avg_logprob": -0.4431847266431125,
        "compression_ratio": 1.2457627118644068,
        "end": 3987.8799999999997,
        "id": 1363,
        "no_speech_prob": 0.00019110389985144138,
        "seek": 396464,
        "start": 3986.8799999999997,
        "temperature": 0,
        "text": " OK, great.",
        "tokens": [
          51476,
          2264,
          11,
          869,
          13,
          51526
        ]
      },
      {
        "avg_logprob": -0.4431847266431125,
        "compression_ratio": 1.2457627118644068,
        "end": 3989.2799999999997,
        "id": 1364,
        "no_speech_prob": 0.00019110389985144138,
        "seek": 396464,
        "start": 3987.8799999999997,
        "temperature": 0,
        "text": " Sorry about that.",
        "tokens": [
          51526,
          4919,
          466,
          300,
          13,
          51596
        ]
      },
      {
        "avg_logprob": -0.19419144802406185,
        "compression_ratio": 1.4172661870503598,
        "end": 3995.92,
        "id": 1365,
        "no_speech_prob": 0.0000016028102436393965,
        "seek": 398928,
        "start": 3989.32,
        "temperature": 0,
        "text": " So wherever that was, I will be coming back to that now.",
        "tokens": [
          50366,
          407,
          8660,
          300,
          390,
          11,
          286,
          486,
          312,
          1348,
          646,
          281,
          300,
          586,
          13,
          50696
        ]
      },
      {
        "avg_logprob": -0.19419144802406185,
        "compression_ratio": 1.4172661870503598,
        "end": 3999.6400000000003,
        "id": 1366,
        "no_speech_prob": 0.0000016028102436393965,
        "seek": 398928,
        "start": 3995.92,
        "temperature": 0,
        "text": " So wherever I was, I was here.",
        "tokens": [
          50696,
          407,
          8660,
          286,
          390,
          11,
          286,
          390,
          510,
          13,
          50882
        ]
      },
      {
        "avg_logprob": -0.19419144802406185,
        "compression_ratio": 1.4172661870503598,
        "end": 4011.84,
        "id": 1367,
        "no_speech_prob": 0.0000016028102436393965,
        "seek": 398928,
        "start": 3999.6400000000003,
        "temperature": 0,
        "text": " And I was saying, OK, this is where I was.",
        "tokens": [
          50882,
          400,
          286,
          390,
          1566,
          11,
          2264,
          11,
          341,
          307,
          689,
          286,
          390,
          13,
          51492
        ]
      },
      {
        "avg_logprob": -0.19419144802406185,
        "compression_ratio": 1.4172661870503598,
        "end": 4015.84,
        "id": 1368,
        "no_speech_prob": 0.0000016028102436393965,
        "seek": 398928,
        "start": 4011.84,
        "temperature": 0,
        "text": " It cannot add this because it's looking",
        "tokens": [
          51492,
          467,
          2644,
          909,
          341,
          570,
          309,
          311,
          1237,
          51692
        ]
      },
      {
        "avg_logprob": -0.19419144802406185,
        "compression_ratio": 1.4172661870503598,
        "end": 4017.2000000000003,
        "id": 1369,
        "no_speech_prob": 0.0000016028102436393965,
        "seek": 398928,
        "start": 4015.84,
        "temperature": 0,
        "text": " for this particular route.",
        "tokens": [
          51692,
          337,
          341,
          1729,
          7955,
          13,
          51760
        ]
      },
      {
        "avg_logprob": -0.26086375178123006,
        "compression_ratio": 1.5954545454545455,
        "end": 4020,
        "id": 1370,
        "no_speech_prob": 0.000018342885596212,
        "seek": 401720,
        "start": 4017.24,
        "temperature": 0,
        "text": " And the route requires also a score.",
        "tokens": [
          50366,
          400,
          264,
          7955,
          7029,
          611,
          257,
          6175,
          13,
          50504
        ]
      },
      {
        "avg_logprob": -0.26086375178123006,
        "compression_ratio": 1.5954545454545455,
        "end": 4022.2,
        "id": 1371,
        "no_speech_prob": 0.000018342885596212,
        "seek": 401720,
        "start": 4020,
        "temperature": 0,
        "text": " However, there is a way to make that score optional,",
        "tokens": [
          50504,
          2908,
          11,
          456,
          307,
          257,
          636,
          281,
          652,
          300,
          6175,
          17312,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.26086375178123006,
        "compression_ratio": 1.5954545454545455,
        "end": 4024.48,
        "id": 1372,
        "no_speech_prob": 0.000018342885596212,
        "seek": 401720,
        "start": 4022.2,
        "temperature": 0,
        "text": " which could be useful for something you might do,",
        "tokens": [
          50614,
          597,
          727,
          312,
          4420,
          337,
          746,
          291,
          1062,
          360,
          11,
          50728
        ]
      },
      {
        "avg_logprob": -0.26086375178123006,
        "compression_ratio": 1.5954545454545455,
        "end": 4026.96,
        "id": 1373,
        "no_speech_prob": 0.000018342885596212,
        "seek": 401720,
        "start": 4024.48,
        "temperature": 0,
        "text": " which is adding just a question mark to,",
        "tokens": [
          50728,
          597,
          307,
          5127,
          445,
          257,
          1168,
          1491,
          281,
          11,
          50852
        ]
      },
      {
        "avg_logprob": -0.26086375178123006,
        "compression_ratio": 1.5954545454545455,
        "end": 4029.16,
        "id": 1374,
        "no_speech_prob": 0.000018342885596212,
        "seek": 401720,
        "start": 4026.96,
        "temperature": 0,
        "text": " and this really only works for the last one,",
        "tokens": [
          50852,
          293,
          341,
          534,
          787,
          1985,
          337,
          264,
          1036,
          472,
          11,
          50962
        ]
      },
      {
        "avg_logprob": -0.26086375178123006,
        "compression_ratio": 1.5954545454545455,
        "end": 4031.56,
        "id": 1375,
        "no_speech_prob": 0.000018342885596212,
        "seek": 401720,
        "start": 4029.16,
        "temperature": 0,
        "text": " although I'm sure there's some fancy ways around that.",
        "tokens": [
          50962,
          4878,
          286,
          478,
          988,
          456,
          311,
          512,
          10247,
          2098,
          926,
          300,
          13,
          51082
        ]
      },
      {
        "avg_logprob": -0.26086375178123006,
        "compression_ratio": 1.5954545454545455,
        "end": 4037.64,
        "id": 1376,
        "no_speech_prob": 0.000018342885596212,
        "seek": 401720,
        "start": 4031.56,
        "temperature": 0,
        "text": " And then what I could do is I could say, if not score,",
        "tokens": [
          51082,
          400,
          550,
          437,
          286,
          727,
          360,
          307,
          286,
          727,
          584,
          11,
          498,
          406,
          6175,
          11,
          51386
        ]
      },
      {
        "avg_logprob": -0.26086375178123006,
        "compression_ratio": 1.5954545454545455,
        "end": 4039.7599999999998,
        "id": 1377,
        "no_speech_prob": 0.000018342885596212,
        "seek": 401720,
        "start": 4037.64,
        "temperature": 0,
        "text": " score equals 5.",
        "tokens": [
          51386,
          6175,
          6915,
          1025,
          13,
          51492
        ]
      },
      {
        "avg_logprob": -0.2679119939389436,
        "compression_ratio": 1.6013986013986015,
        "end": 4047.2400000000002,
        "id": 1378,
        "no_speech_prob": 0.00001983335823751986,
        "seek": 403976,
        "start": 4039.76,
        "temperature": 0,
        "text": " Or I could actually say, score is required.",
        "tokens": [
          50364,
          1610,
          286,
          727,
          767,
          584,
          11,
          6175,
          307,
          4739,
          13,
          50738
        ]
      },
      {
        "avg_logprob": -0.2679119939389436,
        "compression_ratio": 1.6013986013986015,
        "end": 4049.1600000000003,
        "id": 1379,
        "no_speech_prob": 0.00001983335823751986,
        "seek": 403976,
        "start": 4047.2400000000002,
        "temperature": 0,
        "text": " So let's say score is required.",
        "tokens": [
          50738,
          407,
          718,
          311,
          584,
          6175,
          307,
          4739,
          13,
          50834
        ]
      },
      {
        "avg_logprob": -0.2679119939389436,
        "compression_ratio": 1.6013986013986015,
        "end": 4051.28,
        "id": 1380,
        "no_speech_prob": 0.00001983335823751986,
        "seek": 403976,
        "start": 4049.1600000000003,
        "temperature": 0,
        "text": " I could add some error handling here.",
        "tokens": [
          50834,
          286,
          727,
          909,
          512,
          6713,
          13175,
          510,
          13,
          50940
        ]
      },
      {
        "avg_logprob": -0.2679119939389436,
        "compression_ratio": 1.6013986013986015,
        "end": 4061.1600000000003,
        "id": 1381,
        "no_speech_prob": 0.00001983335823751986,
        "seek": 403976,
        "start": 4051.28,
        "temperature": 0,
        "text": " Like I could say, var reply, score is required.",
        "tokens": [
          50940,
          1743,
          286,
          727,
          584,
          11,
          1374,
          16972,
          11,
          6175,
          307,
          4739,
          13,
          51434
        ]
      },
      {
        "avg_logprob": -0.2679119939389436,
        "compression_ratio": 1.6013986013986015,
        "end": 4066.48,
        "id": 1382,
        "no_speech_prob": 0.00001983335823751986,
        "seek": 403976,
        "start": 4061.1600000000003,
        "temperature": 0,
        "text": " Else, all of this.",
        "tokens": [
          51434,
          45472,
          11,
          439,
          295,
          341,
          13,
          51700
        ]
      },
      {
        "avg_logprob": -0.2679119939389436,
        "compression_ratio": 1.6013986013986015,
        "end": 4069.5200000000004,
        "id": 1383,
        "no_speech_prob": 0.00001983335823751986,
        "seek": 403976,
        "start": 4066.48,
        "temperature": 0,
        "text": " So I'm basically saying, whatever word comes in,",
        "tokens": [
          51700,
          407,
          286,
          478,
          1936,
          1566,
          11,
          2035,
          1349,
          1487,
          294,
          11,
          51852
        ]
      },
      {
        "avg_logprob": -0.2214230164786838,
        "compression_ratio": 1.8803088803088803,
        "end": 4071.88,
        "id": 1384,
        "no_speech_prob": 0.00014425943663809448,
        "seek": 406952,
        "start": 4070.28,
        "temperature": 0,
        "text": " if I get a score, so if not score.",
        "tokens": [
          50402,
          498,
          286,
          483,
          257,
          6175,
          11,
          370,
          498,
          406,
          6175,
          13,
          50482
        ]
      },
      {
        "avg_logprob": -0.2214230164786838,
        "compression_ratio": 1.8803088803088803,
        "end": 4073.36,
        "id": 1385,
        "no_speech_prob": 0.00014425943663809448,
        "seek": 406952,
        "start": 4071.88,
        "temperature": 0,
        "text": " And also, I should probably check.",
        "tokens": [
          50482,
          400,
          611,
          11,
          286,
          820,
          1391,
          1520,
          13,
          50556
        ]
      },
      {
        "avg_logprob": -0.2214230164786838,
        "compression_ratio": 1.8803088803088803,
        "end": 4074.44,
        "id": 1386,
        "no_speech_prob": 0.00014425943663809448,
        "seek": 406952,
        "start": 4073.36,
        "temperature": 0,
        "text": " And I'm not going to do all this.",
        "tokens": [
          50556,
          400,
          286,
          478,
          406,
          516,
          281,
          360,
          439,
          341,
          13,
          50610
        ]
      },
      {
        "avg_logprob": -0.2214230164786838,
        "compression_ratio": 1.8803088803088803,
        "end": 4076.48,
        "id": 1387,
        "no_speech_prob": 0.00014425943663809448,
        "seek": 406952,
        "start": 4074.44,
        "temperature": 0,
        "text": " But if I want to be really serious about this,",
        "tokens": [
          50610,
          583,
          498,
          286,
          528,
          281,
          312,
          534,
          3156,
          466,
          341,
          11,
          50712
        ]
      },
      {
        "avg_logprob": -0.2214230164786838,
        "compression_ratio": 1.8803088803088803,
        "end": 4079.7599999999998,
        "id": 1388,
        "no_speech_prob": 0.00014425943663809448,
        "seek": 406952,
        "start": 4076.48,
        "temperature": 0,
        "text": " I would also check to make sure score is a number.",
        "tokens": [
          50712,
          286,
          576,
          611,
          1520,
          281,
          652,
          988,
          6175,
          307,
          257,
          1230,
          13,
          50876
        ]
      },
      {
        "avg_logprob": -0.2214230164786838,
        "compression_ratio": 1.8803088803088803,
        "end": 4084.28,
        "id": 1389,
        "no_speech_prob": 0.00014425943663809448,
        "seek": 406952,
        "start": 4079.7599999999998,
        "temperature": 0,
        "text": " And if you sent me the score as friendship,",
        "tokens": [
          50876,
          400,
          498,
          291,
          2279,
          385,
          264,
          6175,
          382,
          13216,
          11,
          51102
        ]
      },
      {
        "avg_logprob": -0.2214230164786838,
        "compression_ratio": 1.8803088803088803,
        "end": 4086.32,
        "id": 1390,
        "no_speech_prob": 0.00014425943663809448,
        "seek": 406952,
        "start": 4084.28,
        "temperature": 0,
        "text": " I would say the score has to be a number.",
        "tokens": [
          51102,
          286,
          576,
          584,
          264,
          6175,
          575,
          281,
          312,
          257,
          1230,
          13,
          51204
        ]
      },
      {
        "avg_logprob": -0.2214230164786838,
        "compression_ratio": 1.8803088803088803,
        "end": 4090.52,
        "id": 1391,
        "no_speech_prob": 0.00014425943663809448,
        "seek": 406952,
        "start": 4086.32,
        "temperature": 0,
        "text": " But here, I can just create this variable var reply.",
        "tokens": [
          51204,
          583,
          510,
          11,
          286,
          393,
          445,
          1884,
          341,
          7006,
          1374,
          16972,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2214230164786838,
        "compression_ratio": 1.8803088803088803,
        "end": 4091.48,
        "id": 1392,
        "no_speech_prob": 0.00014425943663809448,
        "seek": 406952,
        "start": 4090.52,
        "temperature": 0,
        "text": " I can fill it.",
        "tokens": [
          51414,
          286,
          393,
          2836,
          309,
          13,
          51462
        ]
      },
      {
        "avg_logprob": -0.2214230164786838,
        "compression_ratio": 1.8803088803088803,
        "end": 4094.04,
        "id": 1393,
        "no_speech_prob": 0.00014425943663809448,
        "seek": 406952,
        "start": 4091.48,
        "temperature": 0,
        "text": " If there is no score, I can say score is required.",
        "tokens": [
          51462,
          759,
          456,
          307,
          572,
          6175,
          11,
          286,
          393,
          584,
          6175,
          307,
          4739,
          13,
          51590
        ]
      },
      {
        "avg_logprob": -0.2214230164786838,
        "compression_ratio": 1.8803088803088803,
        "end": 4096.2,
        "id": 1394,
        "no_speech_prob": 0.00014425943663809448,
        "seek": 406952,
        "start": 4094.04,
        "temperature": 0,
        "text": " If there is a score, I can add it to the table",
        "tokens": [
          51590,
          759,
          456,
          307,
          257,
          6175,
          11,
          286,
          393,
          909,
          309,
          281,
          264,
          3199,
          51698
        ]
      },
      {
        "avg_logprob": -0.2214230164786838,
        "compression_ratio": 1.8803088803088803,
        "end": 4098.22,
        "id": 1395,
        "no_speech_prob": 0.00014425943663809448,
        "seek": 406952,
        "start": 4096.2,
        "temperature": 0,
        "text": " and say, thank you for your word,",
        "tokens": [
          51698,
          293,
          584,
          11,
          1309,
          291,
          337,
          428,
          1349,
          11,
          51799
        ]
      },
      {
        "avg_logprob": -0.22280041764422162,
        "compression_ratio": 1.6973684210526316,
        "end": 4100.14,
        "id": 1396,
        "no_speech_prob": 0.00011235298734391108,
        "seek": 409822,
        "start": 4098.22,
        "temperature": 0,
        "text": " and then send the response.",
        "tokens": [
          50364,
          293,
          550,
          2845,
          264,
          4134,
          13,
          50460
        ]
      },
      {
        "avg_logprob": -0.22280041764422162,
        "compression_ratio": 1.6973684210526316,
        "end": 4103.06,
        "id": 1397,
        "no_speech_prob": 0.00011235298734391108,
        "seek": 409822,
        "start": 4100.14,
        "temperature": 0,
        "text": " So this is one extra thing that I'm adding to this.",
        "tokens": [
          50460,
          407,
          341,
          307,
          472,
          2857,
          551,
          300,
          286,
          478,
          5127,
          281,
          341,
          13,
          50606
        ]
      },
      {
        "avg_logprob": -0.22280041764422162,
        "compression_ratio": 1.6973684210526316,
        "end": 4105.54,
        "id": 1398,
        "no_speech_prob": 0.00011235298734391108,
        "seek": 409822,
        "start": 4103.06,
        "temperature": 0,
        "text": " And if I now run this, it's going to say,",
        "tokens": [
          50606,
          400,
          498,
          286,
          586,
          1190,
          341,
          11,
          309,
          311,
          516,
          281,
          584,
          11,
          50730
        ]
      },
      {
        "avg_logprob": -0.22280041764422162,
        "compression_ratio": 1.6973684210526316,
        "end": 4107.38,
        "id": 1399,
        "no_speech_prob": 0.00011235298734391108,
        "seek": 409822,
        "start": 4105.54,
        "temperature": 0,
        "text": " hey, score is required.",
        "tokens": [
          50730,
          4177,
          11,
          6175,
          307,
          4739,
          13,
          50822
        ]
      },
      {
        "avg_logprob": -0.22280041764422162,
        "compression_ratio": 1.6973684210526316,
        "end": 4110.5,
        "id": 1400,
        "no_speech_prob": 0.00011235298734391108,
        "seek": 409822,
        "start": 4107.38,
        "temperature": 0,
        "text": " So I can say now 5, thank you for your word.",
        "tokens": [
          50822,
          407,
          286,
          393,
          584,
          586,
          1025,
          11,
          1309,
          291,
          337,
          428,
          1349,
          13,
          50978
        ]
      },
      {
        "avg_logprob": -0.22280041764422162,
        "compression_ratio": 1.6973684210526316,
        "end": 4112.02,
        "id": 1401,
        "no_speech_prob": 0.00011235298734391108,
        "seek": 409822,
        "start": 4110.5,
        "temperature": 0,
        "text": " And we can go back here.",
        "tokens": [
          50978,
          400,
          321,
          393,
          352,
          646,
          510,
          13,
          51054
        ]
      },
      {
        "avg_logprob": -0.22280041764422162,
        "compression_ratio": 1.6973684210526316,
        "end": 4115.56,
        "id": 1402,
        "no_speech_prob": 0.00011235298734391108,
        "seek": 409822,
        "start": 4112.02,
        "temperature": 0,
        "text": " And we can see purple is there with a score of 5.",
        "tokens": [
          51054,
          400,
          321,
          393,
          536,
          9656,
          307,
          456,
          365,
          257,
          6175,
          295,
          1025,
          13,
          51231
        ]
      },
      {
        "avg_logprob": -0.22280041764422162,
        "compression_ratio": 1.6973684210526316,
        "end": 4119.34,
        "id": 1403,
        "no_speech_prob": 0.00011235298734391108,
        "seek": 409822,
        "start": 4115.56,
        "temperature": 0,
        "text": " So there are a lot of ways to sort of check and see",
        "tokens": [
          51231,
          407,
          456,
          366,
          257,
          688,
          295,
          2098,
          281,
          1333,
          295,
          1520,
          293,
          536,
          51420
        ]
      },
      {
        "avg_logprob": -0.22280041764422162,
        "compression_ratio": 1.6973684210526316,
        "end": 4123.5,
        "id": 1404,
        "no_speech_prob": 0.00011235298734391108,
        "seek": 409822,
        "start": 4119.34,
        "temperature": 0,
        "text": " what's coming in and determine whether something",
        "tokens": [
          51420,
          437,
          311,
          1348,
          294,
          293,
          6997,
          1968,
          746,
          51628
        ]
      },
      {
        "avg_logprob": -0.22280041764422162,
        "compression_ratio": 1.6973684210526316,
        "end": 4125.26,
        "id": 1405,
        "no_speech_prob": 0.00011235298734391108,
        "seek": 409822,
        "start": 4123.5,
        "temperature": 0,
        "text": " is there or not.",
        "tokens": [
          51628,
          307,
          456,
          420,
          406,
          13,
          51716
        ]
      },
      {
        "avg_logprob": -0.22280041764422162,
        "compression_ratio": 1.6973684210526316,
        "end": 4127.02,
        "id": 1406,
        "no_speech_prob": 0.00011235298734391108,
        "seek": 409822,
        "start": 4125.26,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51716,
          2264,
          13,
          51804
        ]
      },
      {
        "avg_logprob": -0.22239303588867188,
        "compression_ratio": 1.9539170506912442,
        "end": 4129.700000000001,
        "id": 1407,
        "no_speech_prob": 0.00003269916487624869,
        "seek": 412702,
        "start": 4127.02,
        "temperature": 0,
        "text": " So let's add one more thing to this.",
        "tokens": [
          50364,
          407,
          718,
          311,
          909,
          472,
          544,
          551,
          281,
          341,
          13,
          50498
        ]
      },
      {
        "avg_logprob": -0.22239303588867188,
        "compression_ratio": 1.9539170506912442,
        "end": 4133.620000000001,
        "id": 1408,
        "no_speech_prob": 0.00003269916487624869,
        "seek": 412702,
        "start": 4129.700000000001,
        "temperature": 0,
        "text": " Let's add a search route so that if the user of this API",
        "tokens": [
          50498,
          961,
          311,
          909,
          257,
          3164,
          7955,
          370,
          300,
          498,
          264,
          4195,
          295,
          341,
          9362,
          50694
        ]
      },
      {
        "avg_logprob": -0.22239303588867188,
        "compression_ratio": 1.9539170506912442,
        "end": 4136.740000000001,
        "id": 1409,
        "no_speech_prob": 0.00003269916487624869,
        "seek": 412702,
        "start": 4133.620000000001,
        "temperature": 0,
        "text": " wants to query for a particular word and get the score back,",
        "tokens": [
          50694,
          2738,
          281,
          14581,
          337,
          257,
          1729,
          1349,
          293,
          483,
          264,
          6175,
          646,
          11,
          50850
        ]
      },
      {
        "avg_logprob": -0.22239303588867188,
        "compression_ratio": 1.9539170506912442,
        "end": 4138.18,
        "id": 1410,
        "no_speech_prob": 0.00003269916487624869,
        "seek": 412702,
        "start": 4136.740000000001,
        "temperature": 0,
        "text": " let's see how that would work.",
        "tokens": [
          50850,
          718,
          311,
          536,
          577,
          300,
          576,
          589,
          13,
          50922
        ]
      },
      {
        "avg_logprob": -0.22239303588867188,
        "compression_ratio": 1.9539170506912442,
        "end": 4141.26,
        "id": 1411,
        "no_speech_prob": 0.00003269916487624869,
        "seek": 412702,
        "start": 4138.18,
        "temperature": 0,
        "text": " So I'm going to add another route.",
        "tokens": [
          50922,
          407,
          286,
          478,
          516,
          281,
          909,
          1071,
          7955,
          13,
          51076
        ]
      },
      {
        "avg_logprob": -0.22239303588867188,
        "compression_ratio": 1.9539170506912442,
        "end": 4142.26,
        "id": 1412,
        "no_speech_prob": 0.00003269916487624869,
        "seek": 412702,
        "start": 4141.26,
        "temperature": 0,
        "text": " And I'm going to call it.",
        "tokens": [
          51076,
          400,
          286,
          478,
          516,
          281,
          818,
          309,
          13,
          51126
        ]
      },
      {
        "avg_logprob": -0.22239303588867188,
        "compression_ratio": 1.9539170506912442,
        "end": 4144.5,
        "id": 1413,
        "no_speech_prob": 0.00003269916487624869,
        "seek": 412702,
        "start": 4142.26,
        "temperature": 0,
        "text": " I'm just going to go down here to the bottom.",
        "tokens": [
          51126,
          286,
          478,
          445,
          516,
          281,
          352,
          760,
          510,
          281,
          264,
          2767,
          13,
          51238
        ]
      },
      {
        "avg_logprob": -0.22239303588867188,
        "compression_ratio": 1.9539170506912442,
        "end": 4149.660000000001,
        "id": 1414,
        "no_speech_prob": 0.00003269916487624869,
        "seek": 412702,
        "start": 4144.5,
        "temperature": 0,
        "text": " I'm going to call it a search for a word.",
        "tokens": [
          51238,
          286,
          478,
          516,
          281,
          818,
          309,
          257,
          3164,
          337,
          257,
          1349,
          13,
          51496
        ]
      },
      {
        "avg_logprob": -0.22239303588867188,
        "compression_ratio": 1.9539170506912442,
        "end": 4153.22,
        "id": 1415,
        "no_speech_prob": 0.00003269916487624869,
        "seek": 412702,
        "start": 4149.660000000001,
        "temperature": 0,
        "text": " And I'm going to say search, search word.",
        "tokens": [
          51496,
          400,
          286,
          478,
          516,
          281,
          584,
          3164,
          11,
          3164,
          1349,
          13,
          51674
        ]
      },
      {
        "avg_logprob": -0.22239303588867188,
        "compression_ratio": 1.9539170506912442,
        "end": 4155.780000000001,
        "id": 1416,
        "no_speech_prob": 0.00003269916487624869,
        "seek": 412702,
        "start": 4153.22,
        "temperature": 0,
        "text": " I'm going to add that callback now, search word",
        "tokens": [
          51674,
          286,
          478,
          516,
          281,
          909,
          300,
          818,
          3207,
          586,
          11,
          3164,
          1349,
          51802
        ]
      },
      {
        "avg_logprob": -0.24355409203506098,
        "compression_ratio": 1.5662650602409638,
        "end": 4158.259999999999,
        "id": 1417,
        "no_speech_prob": 0.00003591292988858186,
        "seek": 415578,
        "start": 4155.82,
        "temperature": 0,
        "text": " with a request and a response.",
        "tokens": [
          50366,
          365,
          257,
          5308,
          293,
          257,
          4134,
          13,
          50488
        ]
      },
      {
        "avg_logprob": -0.24355409203506098,
        "compression_ratio": 1.5662650602409638,
        "end": 4160.34,
        "id": 1418,
        "no_speech_prob": 0.00003591292988858186,
        "seek": 415578,
        "start": 4158.259999999999,
        "temperature": 0,
        "text": " And I'm going to say the word you're searching",
        "tokens": [
          50488,
          400,
          286,
          478,
          516,
          281,
          584,
          264,
          1349,
          291,
          434,
          10808,
          50592
        ]
      },
      {
        "avg_logprob": -0.24355409203506098,
        "compression_ratio": 1.5662650602409638,
        "end": 4164.38,
        "id": 1419,
        "no_speech_prob": 0.00003591292988858186,
        "seek": 415578,
        "start": 4160.34,
        "temperature": 0,
        "text": " for is request params word.",
        "tokens": [
          50592,
          337,
          307,
          5308,
          971,
          4070,
          1349,
          13,
          50794
        ]
      },
      {
        "avg_logprob": -0.24355409203506098,
        "compression_ratio": 1.5662650602409638,
        "end": 4168.139999999999,
        "id": 1420,
        "no_speech_prob": 0.00003591292988858186,
        "seek": 415578,
        "start": 4164.38,
        "temperature": 0,
        "text": " And now what I want to do is see, does that word exist?",
        "tokens": [
          50794,
          400,
          586,
          437,
          286,
          528,
          281,
          360,
          307,
          536,
          11,
          775,
          300,
          1349,
          2514,
          30,
          50982
        ]
      },
      {
        "avg_logprob": -0.24355409203506098,
        "compression_ratio": 1.5662650602409638,
        "end": 4174.0599999999995,
        "id": 1421,
        "no_speech_prob": 0.00003591292988858186,
        "seek": 415578,
        "start": 4171.219999999999,
        "temperature": 0,
        "text": " If that word is part of our words table,",
        "tokens": [
          51136,
          759,
          300,
          1349,
          307,
          644,
          295,
          527,
          2283,
          3199,
          11,
          51278
        ]
      },
      {
        "avg_logprob": -0.24355409203506098,
        "compression_ratio": 1.5662650602409638,
        "end": 4176.34,
        "id": 1422,
        "no_speech_prob": 0.00003591292988858186,
        "seek": 415578,
        "start": 4174.0599999999995,
        "temperature": 0,
        "text": " I need to make a reply.",
        "tokens": [
          51278,
          286,
          643,
          281,
          652,
          257,
          16972,
          13,
          51392
        ]
      },
      {
        "avg_logprob": -0.24355409203506098,
        "compression_ratio": 1.5662650602409638,
        "end": 4181.46,
        "id": 1423,
        "no_speech_prob": 0.00003591292988858186,
        "seek": 415578,
        "start": 4176.34,
        "temperature": 0,
        "text": " I'm going to send back a message.",
        "tokens": [
          51392,
          286,
          478,
          516,
          281,
          2845,
          646,
          257,
          3636,
          13,
          51648
        ]
      },
      {
        "avg_logprob": -0.2612711985905965,
        "compression_ratio": 1.7751479289940828,
        "end": 4190.06,
        "id": 1424,
        "no_speech_prob": 0.0001609303872101009,
        "seek": 418146,
        "start": 4181.46,
        "temperature": 0,
        "text": " I'm going to say status found, word, word.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          584,
          6558,
          1352,
          11,
          1349,
          11,
          1349,
          13,
          50794
        ]
      },
      {
        "avg_logprob": -0.2612711985905965,
        "compression_ratio": 1.7751479289940828,
        "end": 4193.58,
        "id": 1425,
        "no_speech_prob": 0.0001609303872101009,
        "seek": 418146,
        "start": 4190.06,
        "temperature": 0,
        "text": " That's kind of probably a little awkward what I'm doing.",
        "tokens": [
          50794,
          663,
          311,
          733,
          295,
          1391,
          257,
          707,
          11411,
          437,
          286,
          478,
          884,
          13,
          50970
        ]
      },
      {
        "avg_logprob": -0.2612711985905965,
        "compression_ratio": 1.7751479289940828,
        "end": 4194.74,
        "id": 1426,
        "no_speech_prob": 0.0001609303872101009,
        "seek": 418146,
        "start": 4193.58,
        "temperature": 0,
        "text": " I'm just going to call this.",
        "tokens": [
          50970,
          286,
          478,
          445,
          516,
          281,
          818,
          341,
          13,
          51028
        ]
      },
      {
        "avg_logprob": -0.2612711985905965,
        "compression_ratio": 1.7751479289940828,
        "end": 4195.74,
        "id": 1427,
        "no_speech_prob": 0.0001609303872101009,
        "seek": 418146,
        "start": 4194.74,
        "temperature": 0,
        "text": " It's fine.",
        "tokens": [
          51028,
          467,
          311,
          2489,
          13,
          51078
        ]
      },
      {
        "avg_logprob": -0.2612711985905965,
        "compression_ratio": 1.7751479289940828,
        "end": 4198.32,
        "id": 1428,
        "no_speech_prob": 0.0001609303872101009,
        "seek": 418146,
        "start": 4195.74,
        "temperature": 0,
        "text": " It's a little awkward what I'm doing with these variable names",
        "tokens": [
          51078,
          467,
          311,
          257,
          707,
          11411,
          437,
          286,
          478,
          884,
          365,
          613,
          7006,
          5288,
          51207
        ]
      },
      {
        "avg_logprob": -0.2612711985905965,
        "compression_ratio": 1.7751479289940828,
        "end": 4198.9,
        "id": 1429,
        "no_speech_prob": 0.0001609303872101009,
        "seek": 418146,
        "start": 4198.32,
        "temperature": 0,
        "text": " and then score.",
        "tokens": [
          51207,
          293,
          550,
          6175,
          13,
          51236
        ]
      },
      {
        "avg_logprob": -0.2612711985905965,
        "compression_ratio": 1.7751479289940828,
        "end": 4200.94,
        "id": 1430,
        "no_speech_prob": 0.0001609303872101009,
        "seek": 418146,
        "start": 4198.9,
        "temperature": 0,
        "text": " I'm going to say words, word.",
        "tokens": [
          51236,
          286,
          478,
          516,
          281,
          584,
          2283,
          11,
          1349,
          13,
          51338
        ]
      },
      {
        "avg_logprob": -0.2612711985905965,
        "compression_ratio": 1.7751479289940828,
        "end": 4205.34,
        "id": 1431,
        "no_speech_prob": 0.0001609303872101009,
        "seek": 418146,
        "start": 4200.94,
        "temperature": 0,
        "text": " So what I'm doing here is I'm saying if it's found,",
        "tokens": [
          51338,
          407,
          437,
          286,
          478,
          884,
          510,
          307,
          286,
          478,
          1566,
          498,
          309,
          311,
          1352,
          11,
          51558
        ]
      },
      {
        "avg_logprob": -0.23993620191301618,
        "compression_ratio": 1.6170212765957446,
        "end": 4208.900000000001,
        "id": 1432,
        "no_speech_prob": 0.00003822908183792606,
        "seek": 420534,
        "start": 4205.34,
        "temperature": 0,
        "text": " then the reply equals this particular object.",
        "tokens": [
          50364,
          550,
          264,
          16972,
          6915,
          341,
          1729,
          2657,
          13,
          50542
        ]
      },
      {
        "avg_logprob": -0.23993620191301618,
        "compression_ratio": 1.6170212765957446,
        "end": 4214.62,
        "id": 1433,
        "no_speech_prob": 0.00003822908183792606,
        "seek": 420534,
        "start": 4211.58,
        "temperature": 0,
        "text": " So if it's found, the status is found, here's the word,",
        "tokens": [
          50676,
          407,
          498,
          309,
          311,
          1352,
          11,
          264,
          6558,
          307,
          1352,
          11,
          510,
          311,
          264,
          1349,
          11,
          50828
        ]
      },
      {
        "avg_logprob": -0.23993620191301618,
        "compression_ratio": 1.6170212765957446,
        "end": 4217.62,
        "id": 1434,
        "no_speech_prob": 0.00003822908183792606,
        "seek": 420534,
        "start": 4214.62,
        "temperature": 0,
        "text": " here's the score.",
        "tokens": [
          50828,
          510,
          311,
          264,
          6175,
          13,
          50978
        ]
      },
      {
        "avg_logprob": -0.23993620191301618,
        "compression_ratio": 1.6170212765957446,
        "end": 4224.02,
        "id": 1435,
        "no_speech_prob": 0.00003822908183792606,
        "seek": 420534,
        "start": 4217.62,
        "temperature": 0,
        "text": " Otherwise, the reply is status not found.",
        "tokens": [
          50978,
          10328,
          11,
          264,
          16972,
          307,
          6558,
          406,
          1352,
          13,
          51298
        ]
      },
      {
        "avg_logprob": -0.23993620191301618,
        "compression_ratio": 1.6170212765957446,
        "end": 4226.74,
        "id": 1436,
        "no_speech_prob": 0.00003822908183792606,
        "seek": 420534,
        "start": 4224.02,
        "temperature": 0,
        "text": " And then there is no, I can send back the word,",
        "tokens": [
          51298,
          400,
          550,
          456,
          307,
          572,
          11,
          286,
          393,
          2845,
          646,
          264,
          1349,
          11,
          51434
        ]
      },
      {
        "avg_logprob": -0.23993620191301618,
        "compression_ratio": 1.6170212765957446,
        "end": 4228.18,
        "id": 1437,
        "no_speech_prob": 0.00003822908183792606,
        "seek": 420534,
        "start": 4226.74,
        "temperature": 0,
        "text": " there is no score.",
        "tokens": [
          51434,
          456,
          307,
          572,
          6175,
          13,
          51506
        ]
      },
      {
        "avg_logprob": -0.19803460439046225,
        "compression_ratio": 1.6292134831460674,
        "end": 4235.38,
        "id": 1438,
        "no_speech_prob": 0.00022693301434628665,
        "seek": 422818,
        "start": 4228.18,
        "temperature": 0,
        "text": " And I can say response.sendReply.",
        "tokens": [
          50364,
          400,
          286,
          393,
          584,
          4134,
          13,
          82,
          521,
          25554,
          356,
          13,
          50724
        ]
      },
      {
        "avg_logprob": -0.19803460439046225,
        "compression_ratio": 1.6292134831460674,
        "end": 4238.5,
        "id": 1439,
        "no_speech_prob": 0.00022693301434628665,
        "seek": 422818,
        "start": 4235.38,
        "temperature": 0,
        "text": " So the idea here is that I'm just showing you an example.",
        "tokens": [
          50724,
          407,
          264,
          1558,
          510,
          307,
          300,
          286,
          478,
          445,
          4099,
          291,
          364,
          1365,
          13,
          50880
        ]
      },
      {
        "avg_logprob": -0.19803460439046225,
        "compression_ratio": 1.6292134831460674,
        "end": 4241.9400000000005,
        "id": 1440,
        "no_speech_prob": 0.00022693301434628665,
        "seek": 422818,
        "start": 4238.5,
        "temperature": 0,
        "text": " Now I'm making a route for the API where a user could say,",
        "tokens": [
          50880,
          823,
          286,
          478,
          1455,
          257,
          7955,
          337,
          264,
          9362,
          689,
          257,
          4195,
          727,
          584,
          11,
          51052
        ]
      },
      {
        "avg_logprob": -0.19803460439046225,
        "compression_ratio": 1.6292134831460674,
        "end": 4244.38,
        "id": 1441,
        "no_speech_prob": 0.00022693301434628665,
        "seek": 422818,
        "start": 4241.9400000000005,
        "temperature": 0,
        "text": " hey, do you have this word rainbow in your database?",
        "tokens": [
          51052,
          4177,
          11,
          360,
          291,
          362,
          341,
          1349,
          18526,
          294,
          428,
          8149,
          30,
          51174
        ]
      },
      {
        "avg_logprob": -0.19803460439046225,
        "compression_ratio": 1.6292134831460674,
        "end": 4246.38,
        "id": 1442,
        "no_speech_prob": 0.00022693301434628665,
        "seek": 422818,
        "start": 4244.38,
        "temperature": 0,
        "text": " If you do, could you give me its score?",
        "tokens": [
          51174,
          759,
          291,
          360,
          11,
          727,
          291,
          976,
          385,
          1080,
          6175,
          30,
          51274
        ]
      },
      {
        "avg_logprob": -0.19803460439046225,
        "compression_ratio": 1.6292134831460674,
        "end": 4248.9400000000005,
        "id": 1443,
        "no_speech_prob": 0.00022693301434628665,
        "seek": 422818,
        "start": 4246.38,
        "temperature": 0,
        "text": " If you don't, will you tell me that you don't have it?",
        "tokens": [
          51274,
          759,
          291,
          500,
          380,
          11,
          486,
          291,
          980,
          385,
          300,
          291,
          500,
          380,
          362,
          309,
          30,
          51402
        ]
      },
      {
        "avg_logprob": -0.19803460439046225,
        "compression_ratio": 1.6292134831460674,
        "end": 4250.38,
        "id": 1444,
        "no_speech_prob": 0.00022693301434628665,
        "seek": 422818,
        "start": 4248.9400000000005,
        "temperature": 0,
        "text": " So this is yet another thing.",
        "tokens": [
          51402,
          407,
          341,
          307,
          1939,
          1071,
          551,
          13,
          51474
        ]
      },
      {
        "avg_logprob": -0.19803460439046225,
        "compression_ratio": 1.6292134831460674,
        "end": 4253.860000000001,
        "id": 1445,
        "no_speech_prob": 0.00022693301434628665,
        "seek": 422818,
        "start": 4250.38,
        "temperature": 0,
        "text": " Search word, check to see what word did the user set in.",
        "tokens": [
          51474,
          17180,
          1349,
          11,
          1520,
          281,
          536,
          437,
          1349,
          630,
          264,
          4195,
          992,
          294,
          13,
          51648
        ]
      },
      {
        "avg_logprob": -0.19803460439046225,
        "compression_ratio": 1.6292134831460674,
        "end": 4255.06,
        "id": 1446,
        "no_speech_prob": 0.00022693301434628665,
        "seek": 422818,
        "start": 4253.860000000001,
        "temperature": 0,
        "text": " Is it part of the data?",
        "tokens": [
          51648,
          1119,
          309,
          644,
          295,
          264,
          1412,
          30,
          51708
        ]
      },
      {
        "avg_logprob": -0.19803460439046225,
        "compression_ratio": 1.6292134831460674,
        "end": 4256.58,
        "id": 1447,
        "no_speech_prob": 0.00022693301434628665,
        "seek": 422818,
        "start": 4255.06,
        "temperature": 0,
        "text": " If it is, say it's found.",
        "tokens": [
          51708,
          759,
          309,
          307,
          11,
          584,
          309,
          311,
          1352,
          13,
          51784
        ]
      },
      {
        "avg_logprob": -0.2327228273664202,
        "compression_ratio": 1.6278195488721805,
        "end": 4258.66,
        "id": 1448,
        "no_speech_prob": 0.00006108837260399014,
        "seek": 425658,
        "start": 4256.58,
        "temperature": 0,
        "text": " And this is often a good technique.",
        "tokens": [
          50364,
          400,
          341,
          307,
          2049,
          257,
          665,
          6532,
          13,
          50468
        ]
      },
      {
        "avg_logprob": -0.2327228273664202,
        "compression_ratio": 1.6278195488721805,
        "end": 4261.14,
        "id": 1449,
        "no_speech_prob": 0.00006108837260399014,
        "seek": 425658,
        "start": 4258.66,
        "temperature": 0,
        "text": " Let me give you back the data you asked for.",
        "tokens": [
          50468,
          961,
          385,
          976,
          291,
          646,
          264,
          1412,
          291,
          2351,
          337,
          13,
          50592
        ]
      },
      {
        "avg_logprob": -0.2327228273664202,
        "compression_ratio": 1.6278195488721805,
        "end": 4263.26,
        "id": 1450,
        "no_speech_prob": 0.00006108837260399014,
        "seek": 425658,
        "start": 4261.14,
        "temperature": 0,
        "text": " Because a user of this API might be",
        "tokens": [
          50592,
          1436,
          257,
          4195,
          295,
          341,
          9362,
          1062,
          312,
          50698
        ]
      },
      {
        "avg_logprob": -0.2327228273664202,
        "compression_ratio": 1.6278195488721805,
        "end": 4264.98,
        "id": 1451,
        "no_speech_prob": 0.00006108837260399014,
        "seek": 425658,
        "start": 4263.26,
        "temperature": 0,
        "text": " querying like 1,000 different words",
        "tokens": [
          50698,
          7083,
          1840,
          411,
          502,
          11,
          1360,
          819,
          2283,
          50784
        ]
      },
      {
        "avg_logprob": -0.2327228273664202,
        "compression_ratio": 1.6278195488721805,
        "end": 4267.3,
        "id": 1452,
        "no_speech_prob": 0.00006108837260399014,
        "seek": 425658,
        "start": 4264.98,
        "temperature": 0,
        "text": " and all the responses are coming back.",
        "tokens": [
          50784,
          293,
          439,
          264,
          13019,
          366,
          1348,
          646,
          13,
          50900
        ]
      },
      {
        "avg_logprob": -0.2327228273664202,
        "compression_ratio": 1.6278195488721805,
        "end": 4269.86,
        "id": 1453,
        "no_speech_prob": 0.00006108837260399014,
        "seek": 425658,
        "start": 4267.3,
        "temperature": 0,
        "text": " And if the data that came with the request",
        "tokens": [
          50900,
          400,
          498,
          264,
          1412,
          300,
          1361,
          365,
          264,
          5308,
          51028
        ]
      },
      {
        "avg_logprob": -0.2327228273664202,
        "compression_ratio": 1.6278195488721805,
        "end": 4271.42,
        "id": 1454,
        "no_speech_prob": 0.00006108837260399014,
        "seek": 425658,
        "start": 4269.86,
        "temperature": 0,
        "text": " also comes back with a response, it's",
        "tokens": [
          51028,
          611,
          1487,
          646,
          365,
          257,
          4134,
          11,
          309,
          311,
          51106
        ]
      },
      {
        "avg_logprob": -0.2327228273664202,
        "compression_ratio": 1.6278195488721805,
        "end": 4273.46,
        "id": 1455,
        "no_speech_prob": 0.00006108837260399014,
        "seek": 425658,
        "start": 4271.42,
        "temperature": 0,
        "text": " going to make it easier for the user to manage.",
        "tokens": [
          51106,
          516,
          281,
          652,
          309,
          3571,
          337,
          264,
          4195,
          281,
          3067,
          13,
          51208
        ]
      },
      {
        "avg_logprob": -0.2327228273664202,
        "compression_ratio": 1.6278195488721805,
        "end": 4275.94,
        "id": 1456,
        "no_speech_prob": 0.00006108837260399014,
        "seek": 425658,
        "start": 4273.46,
        "temperature": 0,
        "text": " So now let's run this.",
        "tokens": [
          51208,
          407,
          586,
          718,
          311,
          1190,
          341,
          13,
          51332
        ]
      },
      {
        "avg_logprob": -0.2327228273664202,
        "compression_ratio": 1.6278195488721805,
        "end": 4283.42,
        "id": 1457,
        "no_speech_prob": 0.00006108837260399014,
        "seek": 425658,
        "start": 4275.94,
        "temperature": 0,
        "text": " And I can see here, I'm going to go now to search slash rainbow.",
        "tokens": [
          51332,
          400,
          286,
          393,
          536,
          510,
          11,
          286,
          478,
          516,
          281,
          352,
          586,
          281,
          3164,
          17330,
          18526,
          13,
          51706
        ]
      },
      {
        "avg_logprob": -0.2327228273664202,
        "compression_ratio": 1.6278195488721805,
        "end": 4284.94,
        "id": 1458,
        "no_speech_prob": 0.00006108837260399014,
        "seek": 425658,
        "start": 4283.42,
        "temperature": 0,
        "text": " We can see status found.",
        "tokens": [
          51706,
          492,
          393,
          536,
          6558,
          1352,
          13,
          51782
        ]
      },
      {
        "avg_logprob": -0.26014365363366826,
        "compression_ratio": 1.5737704918032787,
        "end": 4285.78,
        "id": 1459,
        "no_speech_prob": 0.00008349618292413652,
        "seek": 428494,
        "start": 4284.94,
        "temperature": 0,
        "text": " The word is rainbow.",
        "tokens": [
          50364,
          440,
          1349,
          307,
          18526,
          13,
          50406
        ]
      },
      {
        "avg_logprob": -0.26014365363366826,
        "compression_ratio": 1.5737704918032787,
        "end": 4286.86,
        "id": 1460,
        "no_speech_prob": 0.00008349618292413652,
        "seek": 428494,
        "start": 4285.78,
        "temperature": 0,
        "text": " The score is 5.",
        "tokens": [
          50406,
          440,
          6175,
          307,
          1025,
          13,
          50460
        ]
      },
      {
        "avg_logprob": -0.26014365363366826,
        "compression_ratio": 1.5737704918032787,
        "end": 4291.86,
        "id": 1461,
        "no_speech_prob": 0.00008349618292413652,
        "seek": 428494,
        "start": 4286.86,
        "temperature": 0,
        "text": " Search unicorn.",
        "tokens": [
          50460,
          17180,
          28122,
          13,
          50710
        ]
      },
      {
        "avg_logprob": -0.26014365363366826,
        "compression_ratio": 1.5737704918032787,
        "end": 4292.78,
        "id": 1462,
        "no_speech_prob": 0.00008349618292413652,
        "seek": 428494,
        "start": 4291.86,
        "temperature": 0,
        "text": " Status found.",
        "tokens": [
          50710,
          47409,
          1352,
          13,
          50756
        ]
      },
      {
        "avg_logprob": -0.26014365363366826,
        "compression_ratio": 1.5737704918032787,
        "end": 4294.66,
        "id": 1463,
        "no_speech_prob": 0.00008349618292413652,
        "seek": 428494,
        "start": 4292.78,
        "temperature": 0,
        "text": " Word unicorn score 3.",
        "tokens": [
          50756,
          8725,
          28122,
          6175,
          805,
          13,
          50850
        ]
      },
      {
        "avg_logprob": -0.26014365363366826,
        "compression_ratio": 1.5737704918032787,
        "end": 4296.46,
        "id": 1464,
        "no_speech_prob": 0.00008349618292413652,
        "seek": 428494,
        "start": 4294.66,
        "temperature": 0,
        "text": " Search kitten.",
        "tokens": [
          50850,
          17180,
          39696,
          13,
          50940
        ]
      },
      {
        "avg_logprob": -0.26014365363366826,
        "compression_ratio": 1.5737704918032787,
        "end": 4300.339999999999,
        "id": 1465,
        "no_speech_prob": 0.00008349618292413652,
        "seek": 428494,
        "start": 4299.099999999999,
        "temperature": 0,
        "text": " Status not found.",
        "tokens": [
          51072,
          47409,
          406,
          1352,
          13,
          51134
        ]
      },
      {
        "avg_logprob": -0.26014365363366826,
        "compression_ratio": 1.5737704918032787,
        "end": 4301.259999999999,
        "id": 1466,
        "no_speech_prob": 0.00008349618292413652,
        "seek": 428494,
        "start": 4300.339999999999,
        "temperature": 0,
        "text": " Word kitten.",
        "tokens": [
          51134,
          8725,
          39696,
          13,
          51180
        ]
      },
      {
        "avg_logprob": -0.26014365363366826,
        "compression_ratio": 1.5737704918032787,
        "end": 4305.0599999999995,
        "id": 1467,
        "no_speech_prob": 0.00008349618292413652,
        "seek": 428494,
        "start": 4301.259999999999,
        "temperature": 0,
        "text": " So this is how I am now making an API that allows",
        "tokens": [
          51180,
          407,
          341,
          307,
          577,
          286,
          669,
          586,
          1455,
          364,
          9362,
          300,
          4045,
          51370
        ]
      },
      {
        "avg_logprob": -0.26014365363366826,
        "compression_ratio": 1.5737704918032787,
        "end": 4307.5,
        "id": 1468,
        "no_speech_prob": 0.00008349618292413652,
        "seek": 428494,
        "start": 4305.0599999999995,
        "temperature": 0,
        "text": " a user to query the database.",
        "tokens": [
          51370,
          257,
          4195,
          281,
          14581,
          264,
          8149,
          13,
          51492
        ]
      },
      {
        "avg_logprob": -0.26014365363366826,
        "compression_ratio": 1.5737704918032787,
        "end": 4308.82,
        "id": 1469,
        "no_speech_prob": 0.00008349618292413652,
        "seek": 428494,
        "start": 4307.5,
        "temperature": 0,
        "text": " So we have the ability.",
        "tokens": [
          51492,
          407,
          321,
          362,
          264,
          3485,
          13,
          51558
        ]
      },
      {
        "avg_logprob": -0.26014365363366826,
        "compression_ratio": 1.5737704918032787,
        "end": 4312.86,
        "id": 1470,
        "no_speech_prob": 0.00008349618292413652,
        "seek": 428494,
        "start": 4308.82,
        "temperature": 0,
        "text": " And then, by the way, now I can say add kitten 5.",
        "tokens": [
          51558,
          400,
          550,
          11,
          538,
          264,
          636,
          11,
          586,
          286,
          393,
          584,
          909,
          39696,
          1025,
          13,
          51760
        ]
      },
      {
        "avg_logprob": -0.20393293485866756,
        "compression_ratio": 1.6113074204946995,
        "end": 4317.46,
        "id": 1471,
        "no_speech_prob": 0.000006854310868220637,
        "seek": 431286,
        "start": 4312.9,
        "temperature": 0,
        "text": " And then I can say search kitten.",
        "tokens": [
          50366,
          400,
          550,
          286,
          393,
          584,
          3164,
          39696,
          13,
          50594
        ]
      },
      {
        "avg_logprob": -0.20393293485866756,
        "compression_ratio": 1.6113074204946995,
        "end": 4319.9,
        "id": 1472,
        "no_speech_prob": 0.000006854310868220637,
        "seek": 431286,
        "start": 4317.46,
        "temperature": 0,
        "text": " And now it's found with a score of 5.",
        "tokens": [
          50594,
          400,
          586,
          309,
          311,
          1352,
          365,
          257,
          6175,
          295,
          1025,
          13,
          50716
        ]
      },
      {
        "avg_logprob": -0.20393293485866756,
        "compression_ratio": 1.6113074204946995,
        "end": 4323.42,
        "id": 1473,
        "no_speech_prob": 0.000006854310868220637,
        "seek": 431286,
        "start": 4319.9,
        "temperature": 0,
        "text": " So notice how I'm only interacting with this API",
        "tokens": [
          50716,
          407,
          3449,
          577,
          286,
          478,
          787,
          18017,
          365,
          341,
          9362,
          50892
        ]
      },
      {
        "avg_logprob": -0.20393293485866756,
        "compression_ratio": 1.6113074204946995,
        "end": 4325.299999999999,
        "id": 1474,
        "no_speech_prob": 0.000006854310868220637,
        "seek": 431286,
        "start": 4323.42,
        "temperature": 0,
        "text": " via the URL address bar.",
        "tokens": [
          50892,
          5766,
          264,
          12905,
          2985,
          2159,
          13,
          50986
        ]
      },
      {
        "avg_logprob": -0.20393293485866756,
        "compression_ratio": 1.6113074204946995,
        "end": 4327.82,
        "id": 1475,
        "no_speech_prob": 0.000006854310868220637,
        "seek": 431286,
        "start": 4325.299999999999,
        "temperature": 0,
        "text": " And ultimately, as I get through more videos here,",
        "tokens": [
          50986,
          400,
          6284,
          11,
          382,
          286,
          483,
          807,
          544,
          2145,
          510,
          11,
          51112
        ]
      },
      {
        "avg_logprob": -0.20393293485866756,
        "compression_ratio": 1.6113074204946995,
        "end": 4330.0599999999995,
        "id": 1476,
        "no_speech_prob": 0.000006854310868220637,
        "seek": 431286,
        "start": 4327.82,
        "temperature": 0,
        "text": " I'm going to look at how do I actually interact with it",
        "tokens": [
          51112,
          286,
          478,
          516,
          281,
          574,
          412,
          577,
          360,
          286,
          767,
          4648,
          365,
          309,
          51224
        ]
      },
      {
        "avg_logprob": -0.20393293485866756,
        "compression_ratio": 1.6113074204946995,
        "end": 4332.7,
        "id": 1477,
        "no_speech_prob": 0.000006854310868220637,
        "seek": 431286,
        "start": 4330.0599999999995,
        "temperature": 0,
        "text": " from my client side JavaScript code, which will really",
        "tokens": [
          51224,
          490,
          452,
          6423,
          1252,
          15778,
          3089,
          11,
          597,
          486,
          534,
          51356
        ]
      },
      {
        "avg_logprob": -0.20393293485866756,
        "compression_ratio": 1.6113074204946995,
        "end": 4334.46,
        "id": 1478,
        "no_speech_prob": 0.000006854310868220637,
        "seek": 431286,
        "start": 4332.7,
        "temperature": 0,
        "text": " open up a lot of possibilities.",
        "tokens": [
          51356,
          1269,
          493,
          257,
          688,
          295,
          12178,
          13,
          51444
        ]
      },
      {
        "avg_logprob": -0.20393293485866756,
        "compression_ratio": 1.6113074204946995,
        "end": 4338.0199999999995,
        "id": 1479,
        "no_speech_prob": 0.000006854310868220637,
        "seek": 431286,
        "start": 4334.46,
        "temperature": 0,
        "text": " So I now have an API which has three features.",
        "tokens": [
          51444,
          407,
          286,
          586,
          362,
          364,
          9362,
          597,
          575,
          1045,
          4122,
          13,
          51622
        ]
      },
      {
        "avg_logprob": -0.20393293485866756,
        "compression_ratio": 1.6113074204946995,
        "end": 4340.299999999999,
        "id": 1480,
        "no_speech_prob": 0.000006854310868220637,
        "seek": 431286,
        "start": 4338.0199999999995,
        "temperature": 0,
        "text": " I can look at all the words that are",
        "tokens": [
          51622,
          286,
          393,
          574,
          412,
          439,
          264,
          2283,
          300,
          366,
          51736
        ]
      },
      {
        "avg_logprob": -0.20393293485866756,
        "compression_ratio": 1.6113074204946995,
        "end": 4342.42,
        "id": 1481,
        "no_speech_prob": 0.000006854310868220637,
        "seek": 431286,
        "start": 4340.299999999999,
        "temperature": 0,
        "text": " in the database and their score.",
        "tokens": [
          51736,
          294,
          264,
          8149,
          293,
          641,
          6175,
          13,
          51842
        ]
      },
      {
        "avg_logprob": -0.23310646257902445,
        "compression_ratio": 1.6073059360730593,
        "end": 4347.58,
        "id": 1482,
        "no_speech_prob": 0.000005173909357836237,
        "seek": 434242,
        "start": 4342.5,
        "temperature": 0,
        "text": " I can add a word like purple.",
        "tokens": [
          50368,
          286,
          393,
          909,
          257,
          1349,
          411,
          9656,
          13,
          50622
        ]
      },
      {
        "avg_logprob": -0.23310646257902445,
        "compression_ratio": 1.6073059360730593,
        "end": 4348.86,
        "id": 1483,
        "no_speech_prob": 0.000005173909357836237,
        "seek": 434242,
        "start": 4347.58,
        "temperature": 0,
        "text": " Didn't I already add purple?",
        "tokens": [
          50622,
          11151,
          380,
          286,
          1217,
          909,
          9656,
          30,
          50686
        ]
      },
      {
        "avg_logprob": -0.23310646257902445,
        "compression_ratio": 1.6073059360730593,
        "end": 4350.3,
        "id": 1484,
        "no_speech_prob": 0.000005173909357836237,
        "seek": 434242,
        "start": 4348.86,
        "temperature": 0,
        "text": " So we're going to have to talk about that.",
        "tokens": [
          50686,
          407,
          321,
          434,
          516,
          281,
          362,
          281,
          751,
          466,
          300,
          13,
          50758
        ]
      },
      {
        "avg_logprob": -0.23310646257902445,
        "compression_ratio": 1.6073059360730593,
        "end": 4351.42,
        "id": 1485,
        "no_speech_prob": 0.000005173909357836237,
        "seek": 434242,
        "start": 4350.3,
        "temperature": 0,
        "text": " And oh, purple is positive.",
        "tokens": [
          50758,
          400,
          1954,
          11,
          9656,
          307,
          3353,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.23310646257902445,
        "compression_ratio": 1.6073059360730593,
        "end": 4352.18,
        "id": 1486,
        "no_speech_prob": 0.000005173909357836237,
        "seek": 434242,
        "start": 4351.42,
        "temperature": 0,
        "text": " Give it 3.",
        "tokens": [
          50814,
          5303,
          309,
          805,
          13,
          50852
        ]
      },
      {
        "avg_logprob": -0.23310646257902445,
        "compression_ratio": 1.6073059360730593,
        "end": 4353.42,
        "id": 1487,
        "no_speech_prob": 0.000005173909357836237,
        "seek": 434242,
        "start": 4352.18,
        "temperature": 0,
        "text": " So I can add a word.",
        "tokens": [
          50852,
          407,
          286,
          393,
          909,
          257,
          1349,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.23310646257902445,
        "compression_ratio": 1.6073059360730593,
        "end": 4359.42,
        "id": 1488,
        "no_speech_prob": 0.000005173909357836237,
        "seek": 434242,
        "start": 4353.42,
        "temperature": 0,
        "text": " And I can also search and see if a word is in there.",
        "tokens": [
          50914,
          400,
          286,
          393,
          611,
          3164,
          293,
          536,
          498,
          257,
          1349,
          307,
          294,
          456,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.23310646257902445,
        "compression_ratio": 1.6073059360730593,
        "end": 4364.54,
        "id": 1489,
        "no_speech_prob": 0.000005173909357836237,
        "seek": 434242,
        "start": 4359.42,
        "temperature": 0,
        "text": " Purple is in there, but perhaps pink is not.",
        "tokens": [
          51214,
          28483,
          307,
          294,
          456,
          11,
          457,
          4317,
          7022,
          307,
          406,
          13,
          51470
        ]
      },
      {
        "avg_logprob": -0.23310646257902445,
        "compression_ratio": 1.6073059360730593,
        "end": 4366.86,
        "id": 1490,
        "no_speech_prob": 0.000005173909357836237,
        "seek": 434242,
        "start": 4364.54,
        "temperature": 0,
        "text": " So this is a good start.",
        "tokens": [
          51470,
          407,
          341,
          307,
          257,
          665,
          722,
          13,
          51586
        ]
      },
      {
        "avg_logprob": -0.23310646257902445,
        "compression_ratio": 1.6073059360730593,
        "end": 4368.9800000000005,
        "id": 1491,
        "no_speech_prob": 0.000005173909357836237,
        "seek": 434242,
        "start": 4366.86,
        "temperature": 0,
        "text": " I have this idea of persistence.",
        "tokens": [
          51586,
          286,
          362,
          341,
          1558,
          295,
          37617,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.23310646257902445,
        "compression_ratio": 1.6073059360730593,
        "end": 4371.58,
        "id": 1492,
        "no_speech_prob": 0.000005173909357836237,
        "seek": 434242,
        "start": 4368.9800000000005,
        "temperature": 0,
        "text": " There's a database of information.",
        "tokens": [
          51692,
          821,
          311,
          257,
          8149,
          295,
          1589,
          13,
          51822
        ]
      },
      {
        "avg_logprob": -0.2330524765442465,
        "compression_ratio": 1.786046511627907,
        "end": 4373.34,
        "id": 1493,
        "no_speech_prob": 0.000040694452764000744,
        "seek": 437158,
        "start": 4371.58,
        "temperature": 0,
        "text": " Users can add to that database.",
        "tokens": [
          50364,
          47092,
          393,
          909,
          281,
          300,
          8149,
          13,
          50452
        ]
      },
      {
        "avg_logprob": -0.2330524765442465,
        "compression_ratio": 1.786046511627907,
        "end": 4375.82,
        "id": 1494,
        "no_speech_prob": 0.000040694452764000744,
        "seek": 437158,
        "start": 4373.34,
        "temperature": 0,
        "text": " Users can request all of the data from the database,",
        "tokens": [
          50452,
          47092,
          393,
          5308,
          439,
          295,
          264,
          1412,
          490,
          264,
          8149,
          11,
          50576
        ]
      },
      {
        "avg_logprob": -0.2330524765442465,
        "compression_ratio": 1.786046511627907,
        "end": 4378.5,
        "id": 1495,
        "no_speech_prob": 0.000040694452764000744,
        "seek": 437158,
        "start": 4375.82,
        "temperature": 0,
        "text": " or they can request one item from the database.",
        "tokens": [
          50576,
          420,
          436,
          393,
          5308,
          472,
          3174,
          490,
          264,
          8149,
          13,
          50710
        ]
      },
      {
        "avg_logprob": -0.2330524765442465,
        "compression_ratio": 1.786046511627907,
        "end": 4383.62,
        "id": 1496,
        "no_speech_prob": 0.000040694452764000744,
        "seek": 437158,
        "start": 4378.5,
        "temperature": 0,
        "text": " But you'll notice here I have this wonderful thing where",
        "tokens": [
          50710,
          583,
          291,
          603,
          3449,
          510,
          286,
          362,
          341,
          3715,
          551,
          689,
          50966
        ]
      },
      {
        "avg_logprob": -0.2330524765442465,
        "compression_ratio": 1.786046511627907,
        "end": 4385.78,
        "id": 1497,
        "no_speech_prob": 0.000040694452764000744,
        "seek": 437158,
        "start": 4383.62,
        "temperature": 0,
        "text": " I add kitten in purple.",
        "tokens": [
          50966,
          286,
          909,
          39696,
          294,
          9656,
          13,
          51074
        ]
      },
      {
        "avg_logprob": -0.2330524765442465,
        "compression_ratio": 1.786046511627907,
        "end": 4389.58,
        "id": 1498,
        "no_speech_prob": 0.000040694452764000744,
        "seek": 437158,
        "start": 4385.78,
        "temperature": 0,
        "text": " So now what I'm going to do is I'm going to quit the server,",
        "tokens": [
          51074,
          407,
          586,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          10366,
          264,
          7154,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.2330524765442465,
        "compression_ratio": 1.786046511627907,
        "end": 4392.9,
        "id": 1499,
        "no_speech_prob": 0.000040694452764000744,
        "seek": 437158,
        "start": 4389.58,
        "temperature": 0,
        "text": " and I'm going to restart it.",
        "tokens": [
          51264,
          293,
          286,
          478,
          516,
          281,
          21022,
          309,
          13,
          51430
        ]
      },
      {
        "avg_logprob": -0.2330524765442465,
        "compression_ratio": 1.786046511627907,
        "end": 4395.38,
        "id": 1500,
        "no_speech_prob": 0.000040694452764000744,
        "seek": 437158,
        "start": 4392.9,
        "temperature": 0,
        "text": " And I don't have kitten in purple anymore.",
        "tokens": [
          51430,
          400,
          286,
          500,
          380,
          362,
          39696,
          294,
          9656,
          3602,
          13,
          51554
        ]
      },
      {
        "avg_logprob": -0.2330524765442465,
        "compression_ratio": 1.786046511627907,
        "end": 4400.1,
        "id": 1501,
        "no_speech_prob": 0.000040694452764000744,
        "seek": 437158,
        "start": 4395.38,
        "temperature": 0,
        "text": " So while there is persistence across.",
        "tokens": [
          51554,
          407,
          1339,
          456,
          307,
          37617,
          2108,
          13,
          51790
        ]
      },
      {
        "avg_logprob": -0.20232684923254926,
        "compression_ratio": 1.6692307692307693,
        "end": 4403.1,
        "id": 1502,
        "no_speech_prob": 0.0005112524377182126,
        "seek": 440010,
        "start": 4400.1,
        "temperature": 0,
        "text": " Do you hear the puppies barking about my wonderful API",
        "tokens": [
          50364,
          1144,
          291,
          1568,
          264,
          33734,
          32995,
          466,
          452,
          3715,
          9362,
          50514
        ]
      },
      {
        "avg_logprob": -0.20232684923254926,
        "compression_ratio": 1.6692307692307693,
        "end": 4404.740000000001,
        "id": 1503,
        "no_speech_prob": 0.0005112524377182126,
        "seek": 440010,
        "start": 4403.1,
        "temperature": 0,
        "text": " discussion?",
        "tokens": [
          50514,
          5017,
          30,
          50596
        ]
      },
      {
        "avg_logprob": -0.20232684923254926,
        "compression_ratio": 1.6692307692307693,
        "end": 4407.42,
        "id": 1504,
        "no_speech_prob": 0.0005112524377182126,
        "seek": 440010,
        "start": 4404.740000000001,
        "temperature": 0,
        "text": " While there is this idea of persistence",
        "tokens": [
          50596,
          3987,
          456,
          307,
          341,
          1558,
          295,
          37617,
          50730
        ]
      },
      {
        "avg_logprob": -0.20232684923254926,
        "compression_ratio": 1.6692307692307693,
        "end": 4410.38,
        "id": 1505,
        "no_speech_prob": 0.0005112524377182126,
        "seek": 440010,
        "start": 4407.42,
        "temperature": 0,
        "text": " while the server is running, as soon as I quit the server",
        "tokens": [
          50730,
          1339,
          264,
          7154,
          307,
          2614,
          11,
          382,
          2321,
          382,
          286,
          10366,
          264,
          7154,
          50878
        ]
      },
      {
        "avg_logprob": -0.20232684923254926,
        "compression_ratio": 1.6692307692307693,
        "end": 4412.22,
        "id": 1506,
        "no_speech_prob": 0.0005112524377182126,
        "seek": 440010,
        "start": 4410.38,
        "temperature": 0,
        "text": " and restart the server, I've lost",
        "tokens": [
          50878,
          293,
          21022,
          264,
          7154,
          11,
          286,
          600,
          2731,
          50970
        ]
      },
      {
        "avg_logprob": -0.20232684923254926,
        "compression_ratio": 1.6692307692307693,
        "end": 4415.660000000001,
        "id": 1507,
        "no_speech_prob": 0.0005112524377182126,
        "seek": 440010,
        "start": 4412.22,
        "temperature": 0,
        "text": " any new data that wasn't just part of what was originally",
        "tokens": [
          50970,
          604,
          777,
          1412,
          300,
          2067,
          380,
          445,
          644,
          295,
          437,
          390,
          7993,
          51142
        ]
      },
      {
        "avg_logprob": -0.20232684923254926,
        "compression_ratio": 1.6692307692307693,
        "end": 4416.740000000001,
        "id": 1508,
        "no_speech_prob": 0.0005112524377182126,
        "seek": 440010,
        "start": 4415.660000000001,
        "temperature": 0,
        "text": " written in here.",
        "tokens": [
          51142,
          3720,
          294,
          510,
          13,
          51196
        ]
      },
      {
        "avg_logprob": -0.20232684923254926,
        "compression_ratio": 1.6692307692307693,
        "end": 4419.38,
        "id": 1509,
        "no_speech_prob": 0.0005112524377182126,
        "seek": 440010,
        "start": 4416.740000000001,
        "temperature": 0,
        "text": " So in the next video, what I'm going to show you",
        "tokens": [
          51196,
          407,
          294,
          264,
          958,
          960,
          11,
          437,
          286,
          478,
          516,
          281,
          855,
          291,
          51328
        ]
      },
      {
        "avg_logprob": -0.20232684923254926,
        "compression_ratio": 1.6692307692307693,
        "end": 4423.740000000001,
        "id": 1510,
        "no_speech_prob": 0.0005112524377182126,
        "seek": 440010,
        "start": 4419.38,
        "temperature": 0,
        "text": " is how to keep persistence across multiple times running",
        "tokens": [
          51328,
          307,
          577,
          281,
          1066,
          37617,
          2108,
          3866,
          1413,
          2614,
          51546
        ]
      },
      {
        "avg_logprob": -0.20232684923254926,
        "compression_ratio": 1.6692307692307693,
        "end": 4424.620000000001,
        "id": 1511,
        "no_speech_prob": 0.0005112524377182126,
        "seek": 440010,
        "start": 4423.740000000001,
        "temperature": 0,
        "text": " the server.",
        "tokens": [
          51546,
          264,
          7154,
          13,
          51590
        ]
      },
      {
        "avg_logprob": -0.20232684923254926,
        "compression_ratio": 1.6692307692307693,
        "end": 4426.780000000001,
        "id": 1512,
        "no_speech_prob": 0.0005112524377182126,
        "seek": 440010,
        "start": 4424.620000000001,
        "temperature": 0,
        "text": " How do I take what's here and actually not",
        "tokens": [
          51590,
          1012,
          360,
          286,
          747,
          437,
          311,
          510,
          293,
          767,
          406,
          51698
        ]
      },
      {
        "avg_logprob": -0.29737779014130944,
        "compression_ratio": 1.4954128440366972,
        "end": 4430.42,
        "id": 1513,
        "no_speech_prob": 0.010013419203460217,
        "seek": 442678,
        "start": 4426.78,
        "temperature": 0,
        "text": " have it be hard coded, but save it to a database?",
        "tokens": [
          50364,
          362,
          309,
          312,
          1152,
          34874,
          11,
          457,
          3155,
          309,
          281,
          257,
          8149,
          30,
          50546
        ]
      },
      {
        "avg_logprob": -0.29737779014130944,
        "compression_ratio": 1.4954128440366972,
        "end": 4432.139999999999,
        "id": 1514,
        "no_speech_prob": 0.010013419203460217,
        "seek": 442678,
        "start": 4430.42,
        "temperature": 0,
        "text": " And I'll see you in the next video.",
        "tokens": [
          50546,
          400,
          286,
          603,
          536,
          291,
          294,
          264,
          958,
          960,
          13,
          50632
        ]
      },
      {
        "avg_logprob": -0.29737779014130944,
        "compression_ratio": 1.4954128440366972,
        "end": 4434.9,
        "id": 1515,
        "no_speech_prob": 0.010013419203460217,
        "seek": 442678,
        "start": 4432.139999999999,
        "temperature": 0,
        "text": " I'll do that.",
        "tokens": [
          50632,
          286,
          603,
          360,
          300,
          13,
          50770
        ]
      },
      {
        "avg_logprob": -0.29737779014130944,
        "compression_ratio": 1.4954128440366972,
        "end": 4436.7,
        "id": 1516,
        "no_speech_prob": 0.010013419203460217,
        "seek": 442678,
        "start": 4434.9,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50770,
          2264,
          13,
          50860
        ]
      },
      {
        "avg_logprob": -0.29737779014130944,
        "compression_ratio": 1.4954128440366972,
        "end": 4438.139999999999,
        "id": 1517,
        "no_speech_prob": 0.010013419203460217,
        "seek": 442678,
        "start": 4436.7,
        "temperature": 0,
        "text": " You guys can hear the dog barking.",
        "tokens": [
          50860,
          509,
          1074,
          393,
          1568,
          264,
          3000,
          32995,
          13,
          50932
        ]
      },
      {
        "avg_logprob": -0.29737779014130944,
        "compression_ratio": 1.4954128440366972,
        "end": 4439.219999999999,
        "id": 1518,
        "no_speech_prob": 0.010013419203460217,
        "seek": 442678,
        "start": 4438.139999999999,
        "temperature": 0,
        "text": " OK, that's going to be wonderful.",
        "tokens": [
          50932,
          2264,
          11,
          300,
          311,
          516,
          281,
          312,
          3715,
          13,
          50986
        ]
      },
      {
        "avg_logprob": -0.29737779014130944,
        "compression_ratio": 1.4954128440366972,
        "end": 4440.139999999999,
        "id": 1519,
        "no_speech_prob": 0.010013419203460217,
        "seek": 442678,
        "start": 4439.219999999999,
        "temperature": 0,
        "text": " That's all I see here.",
        "tokens": [
          50986,
          663,
          311,
          439,
          286,
          536,
          510,
          13,
          51032
        ]
      },
      {
        "avg_logprob": -0.29737779014130944,
        "compression_ratio": 1.4954128440366972,
        "end": 4444.0599999999995,
        "id": 1520,
        "no_speech_prob": 0.010013419203460217,
        "seek": 442678,
        "start": 4440.139999999999,
        "temperature": 0,
        "text": " OK, it's 418.",
        "tokens": [
          51032,
          2264,
          11,
          309,
          311,
          1017,
          6494,
          13,
          51228
        ]
      },
      {
        "avg_logprob": -0.29737779014130944,
        "compression_ratio": 1.4954128440366972,
        "end": 4446.86,
        "id": 1521,
        "no_speech_prob": 0.010013419203460217,
        "seek": 442678,
        "start": 4444.0599999999995,
        "temperature": 0,
        "text": " Unfortunately, I'm just going to check to make sure there was no",
        "tokens": [
          51228,
          8590,
          11,
          286,
          478,
          445,
          516,
          281,
          1520,
          281,
          652,
          988,
          456,
          390,
          572,
          51368
        ]
      },
      {
        "avg_logprob": -0.29737779014130944,
        "compression_ratio": 1.4954128440366972,
        "end": 4449.74,
        "id": 1522,
        "no_speech_prob": 0.010013419203460217,
        "seek": 442678,
        "start": 4446.86,
        "temperature": 0,
        "text": " change in my schedule.",
        "tokens": [
          51368,
          1319,
          294,
          452,
          7567,
          13,
          51512
        ]
      },
      {
        "avg_logprob": -0.29737779014130944,
        "compression_ratio": 1.4954128440366972,
        "end": 4450.7,
        "id": 1523,
        "no_speech_prob": 0.010013419203460217,
        "seek": 442678,
        "start": 4449.74,
        "temperature": 0,
        "text": " Oh, OK.",
        "tokens": [
          51512,
          876,
          11,
          2264,
          13,
          51560
        ]
      },
      {
        "avg_logprob": -0.29737779014130944,
        "compression_ratio": 1.4954128440366972,
        "end": 4453.099999999999,
        "id": 1524,
        "no_speech_prob": 0.010013419203460217,
        "seek": 442678,
        "start": 4450.7,
        "temperature": 0,
        "text": " Oh, I have to check.",
        "tokens": [
          51560,
          876,
          11,
          286,
          362,
          281,
          1520,
          13,
          51680
        ]
      },
      {
        "avg_logprob": -0.25296442436449457,
        "compression_ratio": 1.5886524822695036,
        "end": 4457.14,
        "id": 1525,
        "no_speech_prob": 0.00017130767810158432,
        "seek": 445310,
        "start": 4453.1,
        "temperature": 0,
        "text": " I have to live check to see if I won the Hamilton lottery.",
        "tokens": [
          50364,
          286,
          362,
          281,
          1621,
          1520,
          281,
          536,
          498,
          286,
          1582,
          264,
          18484,
          27391,
          13,
          50566
        ]
      },
      {
        "avg_logprob": -0.25296442436449457,
        "compression_ratio": 1.5886524822695036,
        "end": 4458.68,
        "id": 1526,
        "no_speech_prob": 0.00017130767810158432,
        "seek": 445310,
        "start": 4457.14,
        "temperature": 0,
        "text": " That's really going to change my day.",
        "tokens": [
          50566,
          663,
          311,
          534,
          516,
          281,
          1319,
          452,
          786,
          13,
          50643
        ]
      },
      {
        "avg_logprob": -0.25296442436449457,
        "compression_ratio": 1.5886524822695036,
        "end": 4461.02,
        "id": 1527,
        "no_speech_prob": 0.00017130767810158432,
        "seek": 445310,
        "start": 4458.68,
        "temperature": 0,
        "text": " Hamilton, New York, lottery results.",
        "tokens": [
          50643,
          18484,
          11,
          1873,
          3609,
          11,
          27391,
          3542,
          13,
          50760
        ]
      },
      {
        "avg_logprob": -0.25296442436449457,
        "compression_ratio": 1.5886524822695036,
        "end": 4463.1,
        "id": 1528,
        "no_speech_prob": 0.00017130767810158432,
        "seek": 445310,
        "start": 4461.02,
        "temperature": 0,
        "text": " Unfortunately, you were not selected",
        "tokens": [
          50760,
          8590,
          11,
          291,
          645,
          406,
          8209,
          50864
        ]
      },
      {
        "avg_logprob": -0.25296442436449457,
        "compression_ratio": 1.5886524822695036,
        "end": 4465.26,
        "id": 1529,
        "no_speech_prob": 0.00017130767810158432,
        "seek": 445310,
        "start": 4463.1,
        "temperature": 0,
        "text": " to receive tickets to the November 1st 7pm performance",
        "tokens": [
          50864,
          281,
          4774,
          12628,
          281,
          264,
          7674,
          502,
          372,
          1614,
          14395,
          3389,
          50972
        ]
      },
      {
        "avg_logprob": -0.25296442436449457,
        "compression_ratio": 1.5886524822695036,
        "end": 4465.780000000001,
        "id": 1530,
        "no_speech_prob": 0.00017130767810158432,
        "seek": 445310,
        "start": 4465.26,
        "temperature": 0,
        "text": " at Hamilton.",
        "tokens": [
          50972,
          412,
          18484,
          13,
          50998
        ]
      },
      {
        "avg_logprob": -0.25296442436449457,
        "compression_ratio": 1.5886524822695036,
        "end": 4468.820000000001,
        "id": 1531,
        "no_speech_prob": 0.00017130767810158432,
        "seek": 445310,
        "start": 4465.780000000001,
        "temperature": 0,
        "text": " That's good to know.",
        "tokens": [
          50998,
          663,
          311,
          665,
          281,
          458,
          13,
          51150
        ]
      },
      {
        "avg_logprob": -0.25296442436449457,
        "compression_ratio": 1.5886524822695036,
        "end": 4471.22,
        "id": 1532,
        "no_speech_prob": 0.00017130767810158432,
        "seek": 445310,
        "start": 4468.820000000001,
        "temperature": 0,
        "text": " So because I have to leave in about 10 minutes,",
        "tokens": [
          51150,
          407,
          570,
          286,
          362,
          281,
          1856,
          294,
          466,
          1266,
          2077,
          11,
          51270
        ]
      },
      {
        "avg_logprob": -0.25296442436449457,
        "compression_ratio": 1.5886524822695036,
        "end": 4472.900000000001,
        "id": 1533,
        "no_speech_prob": 0.00017130767810158432,
        "seek": 445310,
        "start": 4471.22,
        "temperature": 0,
        "text": " I would like to keep going through this.",
        "tokens": [
          51270,
          286,
          576,
          411,
          281,
          1066,
          516,
          807,
          341,
          13,
          51354
        ]
      },
      {
        "avg_logprob": -0.25296442436449457,
        "compression_ratio": 1.5886524822695036,
        "end": 4474.900000000001,
        "id": 1534,
        "no_speech_prob": 0.00017130767810158432,
        "seek": 445310,
        "start": 4472.900000000001,
        "temperature": 0,
        "text": " But I also just don't want to rush it.",
        "tokens": [
          51354,
          583,
          286,
          611,
          445,
          500,
          380,
          528,
          281,
          9300,
          309,
          13,
          51454
        ]
      },
      {
        "avg_logprob": -0.25296442436449457,
        "compression_ratio": 1.5886524822695036,
        "end": 4480.700000000001,
        "id": 1535,
        "no_speech_prob": 0.00017130767810158432,
        "seek": 445310,
        "start": 4474.900000000001,
        "temperature": 0,
        "text": " I feel like this is a good, meaty, vegetarian, tofu-y",
        "tokens": [
          51454,
          286,
          841,
          411,
          341,
          307,
          257,
          665,
          11,
          4615,
          88,
          11,
          25739,
          11,
          21419,
          12,
          88,
          51744
        ]
      },
      {
        "avg_logprob": -0.25296442436449457,
        "compression_ratio": 1.5886524822695036,
        "end": 4482.860000000001,
        "id": 1536,
        "no_speech_prob": 0.00017130767810158432,
        "seek": 445310,
        "start": 4480.700000000001,
        "temperature": 0,
        "text": " topic.",
        "tokens": [
          51744,
          4829,
          13,
          51852
        ]
      },
      {
        "avg_logprob": -0.34487983617889745,
        "compression_ratio": 1.5544041450777202,
        "end": 4486.299999999999,
        "id": 1537,
        "no_speech_prob": 0.000002769401817204198,
        "seek": 448286,
        "start": 4483.38,
        "temperature": 0,
        "text": " Let me go back to my list and think about how far we really",
        "tokens": [
          50390,
          961,
          385,
          352,
          646,
          281,
          452,
          1329,
          293,
          519,
          466,
          577,
          1400,
          321,
          534,
          50536
        ]
      },
      {
        "avg_logprob": -0.34487983617889745,
        "compression_ratio": 1.5544041450777202,
        "end": 4490.74,
        "id": 1538,
        "no_speech_prob": 0.000002769401817204198,
        "seek": 448286,
        "start": 4486.299999999999,
        "temperature": 0,
        "text": " got, which I have to admit is not very far.",
        "tokens": [
          50536,
          658,
          11,
          597,
          286,
          362,
          281,
          9796,
          307,
          406,
          588,
          1400,
          13,
          50758
        ]
      },
      {
        "avg_logprob": -0.34487983617889745,
        "compression_ratio": 1.5544041450777202,
        "end": 4495.66,
        "id": 1539,
        "no_speech_prob": 0.000002769401817204198,
        "seek": 448286,
        "start": 4490.74,
        "temperature": 0,
        "text": " And where was my main?",
        "tokens": [
          50758,
          400,
          689,
          390,
          452,
          2135,
          30,
          51004
        ]
      },
      {
        "avg_logprob": -0.34487983617889745,
        "compression_ratio": 1.5544041450777202,
        "end": 4496.9,
        "id": 1540,
        "no_speech_prob": 0.000002769401817204198,
        "seek": 448286,
        "start": 4495.66,
        "temperature": 0,
        "text": " Let me go back to here.",
        "tokens": [
          51004,
          961,
          385,
          352,
          646,
          281,
          510,
          13,
          51066
        ]
      },
      {
        "avg_logprob": -0.34487983617889745,
        "compression_ratio": 1.5544041450777202,
        "end": 4504.139999999999,
        "id": 1541,
        "no_speech_prob": 0.000002769401817204198,
        "seek": 448286,
        "start": 4499.98,
        "temperature": 0,
        "text": " So I was able to get really through.",
        "tokens": [
          51220,
          407,
          286,
          390,
          1075,
          281,
          483,
          534,
          807,
          13,
          51428
        ]
      },
      {
        "avg_logprob": -0.34487983617889745,
        "compression_ratio": 1.5544041450777202,
        "end": 4505.78,
        "id": 1542,
        "no_speech_prob": 0.000002769401817204198,
        "seek": 448286,
        "start": 4504.139999999999,
        "temperature": 0,
        "text": " The things that I would check off here,",
        "tokens": [
          51428,
          440,
          721,
          300,
          286,
          576,
          1520,
          766,
          510,
          11,
          51510
        ]
      },
      {
        "avg_logprob": -0.34487983617889745,
        "compression_ratio": 1.5544041450777202,
        "end": 4508.42,
        "id": 1543,
        "no_speech_prob": 0.000002769401817204198,
        "seek": 448286,
        "start": 4505.78,
        "temperature": 0,
        "text": " if I were checking things off, would be using Express",
        "tokens": [
          51510,
          498,
          286,
          645,
          8568,
          721,
          766,
          11,
          576,
          312,
          1228,
          20212,
          51642
        ]
      },
      {
        "avg_logprob": -0.34487983617889745,
        "compression_ratio": 1.5544041450777202,
        "end": 4509.299999999999,
        "id": 1544,
        "no_speech_prob": 0.000002769401817204198,
        "seek": 448286,
        "start": 4508.42,
        "temperature": 0,
        "text": " and serving files.",
        "tokens": [
          51642,
          293,
          8148,
          7098,
          13,
          51686
        ]
      },
      {
        "avg_logprob": -0.2887660264968872,
        "compression_ratio": 1.6264591439688716,
        "end": 4516.099999999999,
        "id": 1545,
        "no_speech_prob": 0.00015356176299974322,
        "seek": 451286,
        "start": 4512.86,
        "temperature": 0,
        "text": " A query string.",
        "tokens": [
          50364,
          316,
          14581,
          6798,
          13,
          50526
        ]
      },
      {
        "avg_logprob": -0.2887660264968872,
        "compression_ratio": 1.6264591439688716,
        "end": 4517.799999999999,
        "id": 1546,
        "no_speech_prob": 0.00015356176299974322,
        "seek": 451286,
        "start": 4516.099999999999,
        "temperature": 0,
        "text": " Actually, I didn't do the query string.",
        "tokens": [
          50526,
          5135,
          11,
          286,
          994,
          380,
          360,
          264,
          14581,
          6798,
          13,
          50611
        ]
      },
      {
        "avg_logprob": -0.2887660264968872,
        "compression_ratio": 1.6264591439688716,
        "end": 4520.7,
        "id": 1547,
        "no_speech_prob": 0.00015356176299974322,
        "seek": 451286,
        "start": 4517.799999999999,
        "temperature": 0,
        "text": " Looking at a RESTful routes, RESTian routes.",
        "tokens": [
          50611,
          11053,
          412,
          257,
          497,
          14497,
          906,
          18242,
          11,
          497,
          14497,
          952,
          18242,
          13,
          50756
        ]
      },
      {
        "avg_logprob": -0.2887660264968872,
        "compression_ratio": 1.6264591439688716,
        "end": 4522.299999999999,
        "id": 1548,
        "no_speech_prob": 0.00015356176299974322,
        "seek": 451286,
        "start": 4520.7,
        "temperature": 0,
        "text": " I didn't really talk about CORS, which",
        "tokens": [
          50756,
          286,
          994,
          380,
          534,
          751,
          466,
          43137,
          50,
          11,
          597,
          50836
        ]
      },
      {
        "avg_logprob": -0.2887660264968872,
        "compression_ratio": 1.6264591439688716,
        "end": 4524.04,
        "id": 1549,
        "no_speech_prob": 0.00015356176299974322,
        "seek": 451286,
        "start": 4522.299999999999,
        "temperature": 0,
        "text": " is something I'm going to have to mention,",
        "tokens": [
          50836,
          307,
          746,
          286,
          478,
          516,
          281,
          362,
          281,
          2152,
          11,
          50923
        ]
      },
      {
        "avg_logprob": -0.2887660264968872,
        "compression_ratio": 1.6264591439688716,
        "end": 4525.9,
        "id": 1550,
        "no_speech_prob": 0.00015356176299974322,
        "seek": 451286,
        "start": 4524.04,
        "temperature": 0,
        "text": " and sending back JSON.",
        "tokens": [
          50923,
          293,
          7750,
          646,
          31828,
          13,
          51016
        ]
      },
      {
        "avg_logprob": -0.2887660264968872,
        "compression_ratio": 1.6264591439688716,
        "end": 4530.0199999999995,
        "id": 1551,
        "no_speech_prob": 0.00015356176299974322,
        "seek": 451286,
        "start": 4525.9,
        "temperature": 0,
        "text": " I wish there was a way I could annotate this.",
        "tokens": [
          51016,
          286,
          3172,
          456,
          390,
          257,
          636,
          286,
          727,
          25339,
          473,
          341,
          13,
          51222
        ]
      },
      {
        "avg_logprob": -0.2887660264968872,
        "compression_ratio": 1.6264591439688716,
        "end": 4534.54,
        "id": 1552,
        "no_speech_prob": 0.00015356176299974322,
        "seek": 451286,
        "start": 4530.0199999999995,
        "temperature": 0,
        "text": " So when I come back for another live stream, which, gosh,",
        "tokens": [
          51222,
          407,
          562,
          286,
          808,
          646,
          337,
          1071,
          1621,
          4309,
          11,
          597,
          11,
          6502,
          11,
          51448
        ]
      },
      {
        "avg_logprob": -0.2887660264968872,
        "compression_ratio": 1.6264591439688716,
        "end": 4538.42,
        "id": 1553,
        "no_speech_prob": 0.00015356176299974322,
        "seek": 451286,
        "start": 4534.54,
        "temperature": 0,
        "text": " I really wish it could happen this week, but it won't.",
        "tokens": [
          51448,
          286,
          534,
          3172,
          309,
          727,
          1051,
          341,
          1243,
          11,
          457,
          309,
          1582,
          380,
          13,
          51642
        ]
      },
      {
        "avg_logprob": -0.2887660264968872,
        "compression_ratio": 1.6264591439688716,
        "end": 4540.0599999999995,
        "id": 1554,
        "no_speech_prob": 0.00015356176299974322,
        "seek": 451286,
        "start": 4538.42,
        "temperature": 0,
        "text": " Maybe it could happen over the weekend.",
        "tokens": [
          51642,
          2704,
          309,
          727,
          1051,
          670,
          264,
          6711,
          13,
          51724
        ]
      },
      {
        "avg_logprob": -0.2887660264968872,
        "compression_ratio": 1.6264591439688716,
        "end": 4540.62,
        "id": 1555,
        "no_speech_prob": 0.00015356176299974322,
        "seek": 451286,
        "start": 4540.0599999999995,
        "temperature": 0,
        "text": " I'm not sure.",
        "tokens": [
          51724,
          286,
          478,
          406,
          988,
          13,
          51752
        ]
      },
      {
        "avg_logprob": -0.2942694286967433,
        "compression_ratio": 1.63,
        "end": 4547.46,
        "id": 1556,
        "no_speech_prob": 0.00002931150265794713,
        "seek": 454286,
        "start": 4543.339999999999,
        "temperature": 0,
        "text": " In terms of the time I have and just the amount of the",
        "tokens": [
          50388,
          682,
          2115,
          295,
          264,
          565,
          286,
          362,
          293,
          445,
          264,
          2372,
          295,
          264,
          50594
        ]
      },
      {
        "avg_logprob": -0.2942694286967433,
        "compression_ratio": 1.63,
        "end": 4551.78,
        "id": 1557,
        "no_speech_prob": 0.00002931150265794713,
        "seek": 454286,
        "start": 4547.46,
        "temperature": 0,
        "text": " availability of this space, but I will continue this.",
        "tokens": [
          50594,
          17945,
          295,
          341,
          1901,
          11,
          457,
          286,
          486,
          2354,
          341,
          13,
          50810
        ]
      },
      {
        "avg_logprob": -0.2942694286967433,
        "compression_ratio": 1.63,
        "end": 4554.54,
        "id": 1558,
        "no_speech_prob": 0.00002931150265794713,
        "seek": 454286,
        "start": 4551.78,
        "temperature": 0,
        "text": " I want to get all the way through building out this API",
        "tokens": [
          50810,
          286,
          528,
          281,
          483,
          439,
          264,
          636,
          807,
          2390,
          484,
          341,
          9362,
          50948
        ]
      },
      {
        "avg_logprob": -0.2942694286967433,
        "compression_ratio": 1.63,
        "end": 4556.38,
        "id": 1559,
        "no_speech_prob": 0.00002931150265794713,
        "seek": 454286,
        "start": 4554.54,
        "temperature": 0,
        "text": " and saving the data to a database,",
        "tokens": [
          50948,
          293,
          6816,
          264,
          1412,
          281,
          257,
          8149,
          11,
          51040
        ]
      },
      {
        "avg_logprob": -0.2942694286967433,
        "compression_ratio": 1.63,
        "end": 4558.9,
        "id": 1560,
        "no_speech_prob": 0.00002931150265794713,
        "seek": 454286,
        "start": 4556.38,
        "temperature": 0,
        "text": " and then actually starting to use it to do sentiment",
        "tokens": [
          51040,
          293,
          550,
          767,
          2891,
          281,
          764,
          309,
          281,
          360,
          16149,
          51166
        ]
      },
      {
        "avg_logprob": -0.2942694286967433,
        "compression_ratio": 1.63,
        "end": 4562.0199999999995,
        "id": 1561,
        "no_speech_prob": 0.00002931150265794713,
        "seek": 454286,
        "start": 4558.9,
        "temperature": 0,
        "text": " analysis, and then loading a pre-existing list of words",
        "tokens": [
          51166,
          5215,
          11,
          293,
          550,
          15114,
          257,
          659,
          12,
          36447,
          1329,
          295,
          2283,
          51322
        ]
      },
      {
        "avg_logprob": -0.2942694286967433,
        "compression_ratio": 1.63,
        "end": 4562.78,
        "id": 1562,
        "no_speech_prob": 0.00002931150265794713,
        "seek": 454286,
        "start": 4562.0199999999995,
        "temperature": 0,
        "text": " and their scores.",
        "tokens": [
          51322,
          293,
          641,
          13444,
          13,
          51360
        ]
      },
      {
        "avg_logprob": -0.30619062860328033,
        "compression_ratio": 1.467741935483871,
        "end": 4576.42,
        "id": 1563,
        "no_speech_prob": 0.000018342885596212,
        "seek": 456278,
        "start": 4563.179999999999,
        "temperature": 0,
        "text": " So I'm actually not vegetarian, but in spirit, I feel like a,",
        "tokens": [
          50384,
          407,
          286,
          478,
          767,
          406,
          25739,
          11,
          457,
          294,
          3797,
          11,
          286,
          841,
          411,
          257,
          11,
          51046
        ]
      },
      {
        "avg_logprob": -0.30619062860328033,
        "compression_ratio": 1.467741935483871,
        "end": 4579.179999999999,
        "id": 1564,
        "no_speech_prob": 0.000018342885596212,
        "seek": 456278,
        "start": 4576.42,
        "temperature": 0,
        "text": " you know, we should, anyway, I don't",
        "tokens": [
          51046,
          291,
          458,
          11,
          321,
          820,
          11,
          4033,
          11,
          286,
          500,
          380,
          51184
        ]
      },
      {
        "avg_logprob": -0.30619062860328033,
        "compression_ratio": 1.467741935483871,
        "end": 4580.42,
        "id": 1565,
        "no_speech_prob": 0.000018342885596212,
        "seek": 456278,
        "start": 4579.179999999999,
        "temperature": 0,
        "text": " know what I'm discussing here.",
        "tokens": [
          51184,
          458,
          437,
          286,
          478,
          10850,
          510,
          13,
          51246
        ]
      },
      {
        "avg_logprob": -0.30619062860328033,
        "compression_ratio": 1.467741935483871,
        "end": 4582.139999999999,
        "id": 1566,
        "no_speech_prob": 0.000018342885596212,
        "seek": 456278,
        "start": 4580.42,
        "temperature": 0,
        "text": " I've lost my mind.",
        "tokens": [
          51246,
          286,
          600,
          2731,
          452,
          1575,
          13,
          51332
        ]
      },
      {
        "avg_logprob": -0.30619062860328033,
        "compression_ratio": 1.467741935483871,
        "end": 4583.099999999999,
        "id": 1567,
        "no_speech_prob": 0.000018342885596212,
        "seek": 456278,
        "start": 4582.139999999999,
        "temperature": 0,
        "text": " Yes, sorry.",
        "tokens": [
          51332,
          1079,
          11,
          2597,
          13,
          51380
        ]
      },
      {
        "avg_logprob": -0.30619062860328033,
        "compression_ratio": 1.467741935483871,
        "end": 4585.54,
        "id": 1568,
        "no_speech_prob": 0.000018342885596212,
        "seek": 456278,
        "start": 4583.099999999999,
        "temperature": 0,
        "text": " Someone's asking an important question",
        "tokens": [
          51380,
          8734,
          311,
          3365,
          364,
          1021,
          1168,
          51502
        ]
      },
      {
        "avg_logprob": -0.30619062860328033,
        "compression_ratio": 1.467741935483871,
        "end": 4588.139999999999,
        "id": 1569,
        "no_speech_prob": 0.000018342885596212,
        "seek": 456278,
        "start": 4585.54,
        "temperature": 0,
        "text": " that this would actually look like this",
        "tokens": [
          51502,
          300,
          341,
          576,
          767,
          574,
          411,
          341,
          51632
        ]
      },
      {
        "avg_logprob": -0.30619062860328033,
        "compression_ratio": 1.467741935483871,
        "end": 4590.9,
        "id": 1570,
        "no_speech_prob": 0.000018342885596212,
        "seek": 456278,
        "start": 4588.139999999999,
        "temperature": 0,
        "text": " if you were coding along with me,",
        "tokens": [
          51632,
          498,
          291,
          645,
          17720,
          2051,
          365,
          385,
          11,
          51770
        ]
      },
      {
        "avg_logprob": -0.25744252412215524,
        "compression_ratio": 1.5680933852140078,
        "end": 4594.0599999999995,
        "id": 1571,
        "no_speech_prob": 0.00008349543350050226,
        "seek": 459090,
        "start": 4591.0199999999995,
        "temperature": 0,
        "text": " and that I actually am using a Chrome extension that formats",
        "tokens": [
          50370,
          293,
          300,
          286,
          767,
          669,
          1228,
          257,
          15327,
          10320,
          300,
          25879,
          50522
        ]
      },
      {
        "avg_logprob": -0.25744252412215524,
        "compression_ratio": 1.5680933852140078,
        "end": 4596.94,
        "id": 1572,
        "no_speech_prob": 0.00008349543350050226,
        "seek": 459090,
        "start": 4594.0599999999995,
        "temperature": 0,
        "text": " the JSON that you get back kind of nicely, which is just",
        "tokens": [
          50522,
          264,
          31828,
          300,
          291,
          483,
          646,
          733,
          295,
          9594,
          11,
          597,
          307,
          445,
          50666
        ]
      },
      {
        "avg_logprob": -0.25744252412215524,
        "compression_ratio": 1.5680933852140078,
        "end": 4598.179999999999,
        "id": 1573,
        "no_speech_prob": 0.00008349543350050226,
        "seek": 459090,
        "start": 4596.94,
        "temperature": 0,
        "text": " very convenient to use.",
        "tokens": [
          50666,
          588,
          10851,
          281,
          764,
          13,
          50728
        ]
      },
      {
        "avg_logprob": -0.25744252412215524,
        "compression_ratio": 1.5680933852140078,
        "end": 4604.62,
        "id": 1574,
        "no_speech_prob": 0.00008349543350050226,
        "seek": 459090,
        "start": 4602.94,
        "temperature": 0,
        "text": " So anyway, I have 10 minutes.",
        "tokens": [
          50966,
          407,
          4033,
          11,
          286,
          362,
          1266,
          2077,
          13,
          51050
        ]
      },
      {
        "avg_logprob": -0.25744252412215524,
        "compression_ratio": 1.5680933852140078,
        "end": 4607.42,
        "id": 1575,
        "no_speech_prob": 0.00008349543350050226,
        "seek": 459090,
        "start": 4604.62,
        "temperature": 0,
        "text": " I would like to take some questions from the chat",
        "tokens": [
          51050,
          286,
          576,
          411,
          281,
          747,
          512,
          1651,
          490,
          264,
          5081,
          51190
        ]
      },
      {
        "avg_logprob": -0.25744252412215524,
        "compression_ratio": 1.5680933852140078,
        "end": 4608.7,
        "id": 1576,
        "no_speech_prob": 0.00008349543350050226,
        "seek": 459090,
        "start": 4607.42,
        "temperature": 0,
        "text": " about anything, really.",
        "tokens": [
          51190,
          466,
          1340,
          11,
          534,
          13,
          51254
        ]
      },
      {
        "avg_logprob": -0.25744252412215524,
        "compression_ratio": 1.5680933852140078,
        "end": 4610.7,
        "id": 1577,
        "no_speech_prob": 0.00008349543350050226,
        "seek": 459090,
        "start": 4608.7,
        "temperature": 0,
        "text": " I can do that for about 5 or 10 minutes,",
        "tokens": [
          51254,
          286,
          393,
          360,
          300,
          337,
          466,
          1025,
          420,
          1266,
          2077,
          11,
          51354
        ]
      },
      {
        "avg_logprob": -0.25744252412215524,
        "compression_ratio": 1.5680933852140078,
        "end": 4612.42,
        "id": 1578,
        "no_speech_prob": 0.00008349543350050226,
        "seek": 459090,
        "start": 4610.7,
        "temperature": 0,
        "text": " and then I'm going to have to say goodbye.",
        "tokens": [
          51354,
          293,
          550,
          286,
          478,
          516,
          281,
          362,
          281,
          584,
          12084,
          13,
          51440
        ]
      },
      {
        "avg_logprob": -0.25744252412215524,
        "compression_ratio": 1.5680933852140078,
        "end": 4616.0199999999995,
        "id": 1579,
        "no_speech_prob": 0.00008349543350050226,
        "seek": 459090,
        "start": 4612.42,
        "temperature": 0,
        "text": " I apologize for the short session today.",
        "tokens": [
          51440,
          286,
          12328,
          337,
          264,
          2099,
          5481,
          965,
          13,
          51620
        ]
      },
      {
        "avg_logprob": -0.25744252412215524,
        "compression_ratio": 1.5680933852140078,
        "end": 4617.299999999999,
        "id": 1580,
        "no_speech_prob": 0.00008349543350050226,
        "seek": 459090,
        "start": 4616.0199999999995,
        "temperature": 0,
        "text": " I will be back next Tuesday.",
        "tokens": [
          51620,
          286,
          486,
          312,
          646,
          958,
          10017,
          13,
          51684
        ]
      },
      {
        "avg_logprob": -0.25744252412215524,
        "compression_ratio": 1.5680933852140078,
        "end": 4619.379999999999,
        "id": 1581,
        "no_speech_prob": 0.00008349543350050226,
        "seek": 459090,
        "start": 4617.299999999999,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51684,
          2264,
          13,
          51788
        ]
      },
      {
        "avg_logprob": -0.21653739337263436,
        "compression_ratio": 1.588,
        "end": 4621.900000000001,
        "id": 1582,
        "no_speech_prob": 0.006192826200276613,
        "seek": 461938,
        "start": 4619.38,
        "temperature": 0,
        "text": " Schiffman, do you know something about Golang?",
        "tokens": [
          50364,
          2065,
          3661,
          1601,
          11,
          360,
          291,
          458,
          746,
          466,
          36319,
          656,
          30,
          50490
        ]
      },
      {
        "avg_logprob": -0.21653739337263436,
        "compression_ratio": 1.588,
        "end": 4624.78,
        "id": 1583,
        "no_speech_prob": 0.006192826200276613,
        "seek": 461938,
        "start": 4621.900000000001,
        "temperature": 0,
        "text": " No, I don't.",
        "tokens": [
          50490,
          883,
          11,
          286,
          500,
          380,
          13,
          50634
        ]
      },
      {
        "avg_logprob": -0.21653739337263436,
        "compression_ratio": 1.588,
        "end": 4627.66,
        "id": 1584,
        "no_speech_prob": 0.006192826200276613,
        "seek": 461938,
        "start": 4624.78,
        "temperature": 0,
        "text": " But that's an interesting idea for me to investigate.",
        "tokens": [
          50634,
          583,
          300,
          311,
          364,
          1880,
          1558,
          337,
          385,
          281,
          15013,
          13,
          50778
        ]
      },
      {
        "avg_logprob": -0.21653739337263436,
        "compression_ratio": 1.588,
        "end": 4630.34,
        "id": 1585,
        "no_speech_prob": 0.006192826200276613,
        "seek": 461938,
        "start": 4627.66,
        "temperature": 0,
        "text": " Schiffman, why not use a MySQL server for this?",
        "tokens": [
          50778,
          2065,
          3661,
          1601,
          11,
          983,
          406,
          764,
          257,
          1222,
          39934,
          7154,
          337,
          341,
          30,
          50912
        ]
      },
      {
        "avg_logprob": -0.21653739337263436,
        "compression_ratio": 1.588,
        "end": 4633.06,
        "id": 1586,
        "no_speech_prob": 0.006192826200276613,
        "seek": 461938,
        "start": 4630.34,
        "temperature": 0,
        "text": " So this is the discussion I want to have when I get",
        "tokens": [
          50912,
          407,
          341,
          307,
          264,
          5017,
          286,
          528,
          281,
          362,
          562,
          286,
          483,
          51048
        ]
      },
      {
        "avg_logprob": -0.21653739337263436,
        "compression_ratio": 1.588,
        "end": 4637.06,
        "id": 1587,
        "no_speech_prob": 0.006192826200276613,
        "seek": 461938,
        "start": 4633.06,
        "temperature": 0,
        "text": " to this idea of persistence.",
        "tokens": [
          51048,
          281,
          341,
          1558,
          295,
          37617,
          13,
          51248
        ]
      },
      {
        "avg_logprob": -0.21653739337263436,
        "compression_ratio": 1.588,
        "end": 4640.86,
        "id": 1588,
        "no_speech_prob": 0.006192826200276613,
        "seek": 461938,
        "start": 4637.06,
        "temperature": 0,
        "text": " So there are a lot of ways that you can store your data.",
        "tokens": [
          51248,
          407,
          456,
          366,
          257,
          688,
          295,
          2098,
          300,
          291,
          393,
          3531,
          428,
          1412,
          13,
          51438
        ]
      },
      {
        "avg_logprob": -0.21653739337263436,
        "compression_ratio": 1.588,
        "end": 4643.9400000000005,
        "id": 1589,
        "no_speech_prob": 0.006192826200276613,
        "seek": 461938,
        "start": 4640.86,
        "temperature": 0,
        "text": " And probably the most sophisticated, robust,",
        "tokens": [
          51438,
          400,
          1391,
          264,
          881,
          16950,
          11,
          13956,
          11,
          51592
        ]
      },
      {
        "avg_logprob": -0.21653739337263436,
        "compression_ratio": 1.588,
        "end": 4648.900000000001,
        "id": 1590,
        "no_speech_prob": 0.006192826200276613,
        "seek": 461938,
        "start": 4643.9400000000005,
        "temperature": 0,
        "text": " scalable way is to use a database, a MySQL database,",
        "tokens": [
          51592,
          38481,
          636,
          307,
          281,
          764,
          257,
          8149,
          11,
          257,
          1222,
          39934,
          8149,
          11,
          51840
        ]
      },
      {
        "avg_logprob": -0.25845916647660105,
        "compression_ratio": 1.7492063492063492,
        "end": 4650.219999999999,
        "id": 1591,
        "no_speech_prob": 0.00031015221611596644,
        "seek": 464890,
        "start": 4649.42,
        "temperature": 0,
        "text": " SQL database.",
        "tokens": [
          50390,
          19200,
          8149,
          13,
          50430
        ]
      },
      {
        "avg_logprob": -0.25845916647660105,
        "compression_ratio": 1.7492063492063492,
        "end": 4651.54,
        "id": 1592,
        "no_speech_prob": 0.00031015221611596644,
        "seek": 464890,
        "start": 4650.219999999999,
        "temperature": 0,
        "text": " That's kind of the same thing.",
        "tokens": [
          50430,
          663,
          311,
          733,
          295,
          264,
          912,
          551,
          13,
          50496
        ]
      },
      {
        "avg_logprob": -0.25845916647660105,
        "compression_ratio": 1.7492063492063492,
        "end": 4656.0199999999995,
        "id": 1593,
        "no_speech_prob": 0.00031015221611596644,
        "seek": 464890,
        "start": 4651.54,
        "temperature": 0,
        "text": " MongoDB, CouchDB, there are a lot of systems for doing that.",
        "tokens": [
          50496,
          48380,
          27735,
          11,
          383,
          2220,
          27735,
          11,
          456,
          366,
          257,
          688,
          295,
          3652,
          337,
          884,
          300,
          13,
          50720
        ]
      },
      {
        "avg_logprob": -0.25845916647660105,
        "compression_ratio": 1.7492063492063492,
        "end": 4659.74,
        "id": 1594,
        "no_speech_prob": 0.00031015221611596644,
        "seek": 464890,
        "start": 4656.0199999999995,
        "temperature": 0,
        "text": " I'm here teaching about kind of creative projects",
        "tokens": [
          50720,
          286,
          478,
          510,
          4571,
          466,
          733,
          295,
          5880,
          4455,
          50906
        ]
      },
      {
        "avg_logprob": -0.25845916647660105,
        "compression_ratio": 1.7492063492063492,
        "end": 4661.66,
        "id": 1595,
        "no_speech_prob": 0.00031015221611596644,
        "seek": 464890,
        "start": 4659.74,
        "temperature": 0,
        "text": " and rapid prototyping for a lot of things",
        "tokens": [
          50906,
          293,
          7558,
          46219,
          3381,
          337,
          257,
          688,
          295,
          721,
          51002
        ]
      },
      {
        "avg_logprob": -0.25845916647660105,
        "compression_ratio": 1.7492063492063492,
        "end": 4663.16,
        "id": 1596,
        "no_speech_prob": 0.00031015221611596644,
        "seek": 464890,
        "start": 4661.66,
        "temperature": 0,
        "text": " where you're just sort of stitching stuff together",
        "tokens": [
          51002,
          689,
          291,
          434,
          445,
          1333,
          295,
          30714,
          1507,
          1214,
          51077
        ]
      },
      {
        "avg_logprob": -0.25845916647660105,
        "compression_ratio": 1.7492063492063492,
        "end": 4664.46,
        "id": 1597,
        "no_speech_prob": 0.00031015221611596644,
        "seek": 464890,
        "start": 4663.16,
        "temperature": 0,
        "text": " and making an example.",
        "tokens": [
          51077,
          293,
          1455,
          364,
          1365,
          13,
          51142
        ]
      },
      {
        "avg_logprob": -0.25845916647660105,
        "compression_ratio": 1.7492063492063492,
        "end": 4667.259999999999,
        "id": 1598,
        "no_speech_prob": 0.00031015221611596644,
        "seek": 464890,
        "start": 4664.46,
        "temperature": 0,
        "text": " Learning a whole database system could be kind of overkill",
        "tokens": [
          51142,
          15205,
          257,
          1379,
          8149,
          1185,
          727,
          312,
          733,
          295,
          670,
          34213,
          51282
        ]
      },
      {
        "avg_logprob": -0.25845916647660105,
        "compression_ratio": 1.7492063492063492,
        "end": 4669.86,
        "id": 1599,
        "no_speech_prob": 0.00031015221611596644,
        "seek": 464890,
        "start": 4667.259999999999,
        "temperature": 0,
        "text": " when you could just save the data to a JSON file.",
        "tokens": [
          51282,
          562,
          291,
          727,
          445,
          3155,
          264,
          1412,
          281,
          257,
          31828,
          3991,
          13,
          51412
        ]
      },
      {
        "avg_logprob": -0.25845916647660105,
        "compression_ratio": 1.7492063492063492,
        "end": 4672.0199999999995,
        "id": 1600,
        "no_speech_prob": 0.00031015221611596644,
        "seek": 464890,
        "start": 4669.86,
        "temperature": 0,
        "text": " So I'm kind of going to, that's where the next step that I'm",
        "tokens": [
          51412,
          407,
          286,
          478,
          733,
          295,
          516,
          281,
          11,
          300,
          311,
          689,
          264,
          958,
          1823,
          300,
          286,
          478,
          51520
        ]
      },
      {
        "avg_logprob": -0.25845916647660105,
        "compression_ratio": 1.7492063492063492,
        "end": 4674.46,
        "id": 1601,
        "no_speech_prob": 0.00031015221611596644,
        "seek": 464890,
        "start": 4672.0199999999995,
        "temperature": 0,
        "text": " going to take, which is actually quite easy and works quite",
        "tokens": [
          51520,
          516,
          281,
          747,
          11,
          597,
          307,
          767,
          1596,
          1858,
          293,
          1985,
          1596,
          51642
        ]
      },
      {
        "avg_logprob": -0.25845916647660105,
        "compression_ratio": 1.7492063492063492,
        "end": 4675.299999999999,
        "id": 1602,
        "no_speech_prob": 0.00031015221611596644,
        "seek": 464890,
        "start": 4674.46,
        "temperature": 0,
        "text": " well.",
        "tokens": [
          51642,
          731,
          13,
          51684
        ]
      },
      {
        "avg_logprob": -0.25845916647660105,
        "compression_ratio": 1.7492063492063492,
        "end": 4676.98,
        "id": 1603,
        "no_speech_prob": 0.00031015221611596644,
        "seek": 464890,
        "start": 4675.299999999999,
        "temperature": 0,
        "text": " Of course, if there's scalability concerns,",
        "tokens": [
          51684,
          2720,
          1164,
          11,
          498,
          456,
          311,
          15664,
          2310,
          7389,
          11,
          51768
        ]
      },
      {
        "avg_logprob": -0.23635126939460413,
        "compression_ratio": 1.6666666666666667,
        "end": 4679.419999999999,
        "id": 1604,
        "no_speech_prob": 0.0003353484207764268,
        "seek": 467698,
        "start": 4676.98,
        "temperature": 0,
        "text": " massive data, lots of relational data,",
        "tokens": [
          50364,
          5994,
          1412,
          11,
          3195,
          295,
          38444,
          1412,
          11,
          50486
        ]
      },
      {
        "avg_logprob": -0.23635126939460413,
        "compression_ratio": 1.6666666666666667,
        "end": 4682.58,
        "id": 1605,
        "no_speech_prob": 0.0003353484207764268,
        "seek": 467698,
        "start": 4679.419999999999,
        "temperature": 0,
        "text": " if there's privacy and security issues,",
        "tokens": [
          50486,
          498,
          456,
          311,
          11427,
          293,
          3825,
          2663,
          11,
          50644
        ]
      },
      {
        "avg_logprob": -0.23635126939460413,
        "compression_ratio": 1.6666666666666667,
        "end": 4685.299999999999,
        "id": 1606,
        "no_speech_prob": 0.0003353484207764268,
        "seek": 467698,
        "start": 4682.58,
        "temperature": 0,
        "text": " you're going to need something more than just a JSON file.",
        "tokens": [
          50644,
          291,
          434,
          516,
          281,
          643,
          746,
          544,
          813,
          445,
          257,
          31828,
          3991,
          13,
          50780
        ]
      },
      {
        "avg_logprob": -0.23635126939460413,
        "compression_ratio": 1.6666666666666667,
        "end": 4687.62,
        "id": 1607,
        "no_speech_prob": 0.0003353484207764268,
        "seek": 467698,
        "start": 4685.299999999999,
        "temperature": 0,
        "text": " But that's actually going to be pretty powerful to use.",
        "tokens": [
          50780,
          583,
          300,
          311,
          767,
          516,
          281,
          312,
          1238,
          4005,
          281,
          764,
          13,
          50896
        ]
      },
      {
        "avg_logprob": -0.23635126939460413,
        "compression_ratio": 1.6666666666666667,
        "end": 4692.139999999999,
        "id": 1608,
        "no_speech_prob": 0.0003353484207764268,
        "seek": 467698,
        "start": 4687.62,
        "temperature": 0,
        "text": " I also want to show you, and I do have all these examples",
        "tokens": [
          50896,
          286,
          611,
          528,
          281,
          855,
          291,
          11,
          293,
          286,
          360,
          362,
          439,
          613,
          5110,
          51122
        ]
      },
      {
        "avg_logprob": -0.23635126939460413,
        "compression_ratio": 1.6666666666666667,
        "end": 4694.9,
        "id": 1609,
        "no_speech_prob": 0.0003353484207764268,
        "seek": 467698,
        "start": 4692.139999999999,
        "temperature": 0,
        "text": " already, I just haven't gotten a chance to go over it.",
        "tokens": [
          51122,
          1217,
          11,
          286,
          445,
          2378,
          380,
          5768,
          257,
          2931,
          281,
          352,
          670,
          309,
          13,
          51260
        ]
      },
      {
        "avg_logprob": -0.23635126939460413,
        "compression_ratio": 1.6666666666666667,
        "end": 4697.139999999999,
        "id": 1610,
        "no_speech_prob": 0.0003353484207764268,
        "seek": 467698,
        "start": 4694.9,
        "temperature": 0,
        "text": " But I'm going to show you something called Firebase,",
        "tokens": [
          51260,
          583,
          286,
          478,
          516,
          281,
          855,
          291,
          746,
          1219,
          35173,
          11,
          51372
        ]
      },
      {
        "avg_logprob": -0.23635126939460413,
        "compression_ratio": 1.6666666666666667,
        "end": 4701.299999999999,
        "id": 1611,
        "no_speech_prob": 0.0003353484207764268,
        "seek": 467698,
        "start": 4697.139999999999,
        "temperature": 0,
        "text": " which is a database as service, essentially, where you can just",
        "tokens": [
          51372,
          597,
          307,
          257,
          8149,
          382,
          2643,
          11,
          4476,
          11,
          689,
          291,
          393,
          445,
          51580
        ]
      },
      {
        "avg_logprob": -0.23635126939460413,
        "compression_ratio": 1.6666666666666667,
        "end": 4702.259999999999,
        "id": 1612,
        "no_speech_prob": 0.0003353484207764268,
        "seek": 467698,
        "start": 4701.299999999999,
        "temperature": 0,
        "text": " sign up for an account.",
        "tokens": [
          51580,
          1465,
          493,
          337,
          364,
          2696,
          13,
          51628
        ]
      },
      {
        "avg_logprob": -0.23635126939460413,
        "compression_ratio": 1.6666666666666667,
        "end": 4705.9,
        "id": 1613,
        "no_speech_prob": 0.0003353484207764268,
        "seek": 467698,
        "start": 4702.259999999999,
        "temperature": 0,
        "text": " And I've been able to do everything for free so far,",
        "tokens": [
          51628,
          400,
          286,
          600,
          668,
          1075,
          281,
          360,
          1203,
          337,
          1737,
          370,
          1400,
          11,
          51810
        ]
      },
      {
        "avg_logprob": -0.23288136503122148,
        "compression_ratio": 1.570469798657718,
        "end": 4708.339999999999,
        "id": 1614,
        "no_speech_prob": 0.000026688376237871125,
        "seek": 470590,
        "start": 4705.9,
        "temperature": 0,
        "text": " at least with my examples, and sort of send the data",
        "tokens": [
          50364,
          412,
          1935,
          365,
          452,
          5110,
          11,
          293,
          1333,
          295,
          2845,
          264,
          1412,
          50486
        ]
      },
      {
        "avg_logprob": -0.23288136503122148,
        "compression_ratio": 1.570469798657718,
        "end": 4709.0199999999995,
        "id": 1615,
        "no_speech_prob": 0.000026688376237871125,
        "seek": 470590,
        "start": 4708.339999999999,
        "temperature": 0,
        "text": " to Firebase.",
        "tokens": [
          50486,
          281,
          35173,
          13,
          50520
        ]
      },
      {
        "avg_logprob": -0.23288136503122148,
        "compression_ratio": 1.570469798657718,
        "end": 4710.7,
        "id": 1616,
        "no_speech_prob": 0.000026688376237871125,
        "seek": 470590,
        "start": 4709.0199999999995,
        "temperature": 0,
        "text": " Firebase will save it for you, and you can always",
        "tokens": [
          50520,
          35173,
          486,
          3155,
          309,
          337,
          291,
          11,
          293,
          291,
          393,
          1009,
          50604
        ]
      },
      {
        "avg_logprob": -0.23288136503122148,
        "compression_ratio": 1.570469798657718,
        "end": 4711.66,
        "id": 1617,
        "no_speech_prob": 0.000026688376237871125,
        "seek": 470590,
        "start": 4710.7,
        "temperature": 0,
        "text": " request it back.",
        "tokens": [
          50604,
          5308,
          309,
          646,
          13,
          50652
        ]
      },
      {
        "avg_logprob": -0.23288136503122148,
        "compression_ratio": 1.570469798657718,
        "end": 4713.98,
        "id": 1618,
        "no_speech_prob": 0.000026688376237871125,
        "seek": 470590,
        "start": 4711.66,
        "temperature": 0,
        "text": " And actually, you don't even need Node to use Firebase.",
        "tokens": [
          50652,
          400,
          767,
          11,
          291,
          500,
          380,
          754,
          643,
          38640,
          281,
          764,
          35173,
          13,
          50768
        ]
      },
      {
        "avg_logprob": -0.23288136503122148,
        "compression_ratio": 1.570469798657718,
        "end": 4715.78,
        "id": 1619,
        "no_speech_prob": 0.000026688376237871125,
        "seek": 470590,
        "start": 4713.98,
        "temperature": 0,
        "text": " You can do everything from the client side,",
        "tokens": [
          50768,
          509,
          393,
          360,
          1203,
          490,
          264,
          6423,
          1252,
          11,
          50858
        ]
      },
      {
        "avg_logprob": -0.23288136503122148,
        "compression_ratio": 1.570469798657718,
        "end": 4718.179999999999,
        "id": 1620,
        "no_speech_prob": 0.000026688376237871125,
        "seek": 470590,
        "start": 4715.78,
        "temperature": 0,
        "text": " which is quite nice.",
        "tokens": [
          50858,
          597,
          307,
          1596,
          1481,
          13,
          50978
        ]
      },
      {
        "avg_logprob": -0.23288136503122148,
        "compression_ratio": 1.570469798657718,
        "end": 4723.62,
        "id": 1621,
        "no_speech_prob": 0.000026688376237871125,
        "seek": 470590,
        "start": 4718.179999999999,
        "temperature": 0,
        "text": " OK, Mac Brick asks, Schiffman, how long have you coded?",
        "tokens": [
          50978,
          2264,
          11,
          5707,
          1603,
          618,
          8962,
          11,
          2065,
          3661,
          1601,
          11,
          577,
          938,
          362,
          291,
          34874,
          30,
          51250
        ]
      },
      {
        "avg_logprob": -0.23288136503122148,
        "compression_ratio": 1.570469798657718,
        "end": 4727.5,
        "id": 1622,
        "no_speech_prob": 0.000026688376237871125,
        "seek": 470590,
        "start": 4723.62,
        "temperature": 0,
        "text": " I think I probably started programming really in 2001.",
        "tokens": [
          51250,
          286,
          519,
          286,
          1391,
          1409,
          9410,
          534,
          294,
          16382,
          13,
          51444
        ]
      },
      {
        "avg_logprob": -0.23288136503122148,
        "compression_ratio": 1.570469798657718,
        "end": 4730.82,
        "id": 1623,
        "no_speech_prob": 0.000026688376237871125,
        "seek": 470590,
        "start": 4727.5,
        "temperature": 0,
        "text": " So that would be, I don't know, you do the math.",
        "tokens": [
          51444,
          407,
          300,
          576,
          312,
          11,
          286,
          500,
          380,
          458,
          11,
          291,
          360,
          264,
          5221,
          13,
          51610
        ]
      },
      {
        "avg_logprob": -0.23288136503122148,
        "compression_ratio": 1.570469798657718,
        "end": 4735.62,
        "id": 1624,
        "no_speech_prob": 0.000026688376237871125,
        "seek": 470590,
        "start": 4730.82,
        "temperature": 0,
        "text": " But it was sort of later in life than a lot of people.",
        "tokens": [
          51610,
          583,
          309,
          390,
          1333,
          295,
          1780,
          294,
          993,
          813,
          257,
          688,
          295,
          561,
          13,
          51850
        ]
      },
      {
        "avg_logprob": -0.2401126403808594,
        "compression_ratio": 1.602076124567474,
        "end": 4738.14,
        "id": 1625,
        "no_speech_prob": 0.00002429997402941808,
        "seek": 473562,
        "start": 4735.82,
        "temperature": 0,
        "text": " There's no time where you can't start coding.",
        "tokens": [
          50374,
          821,
          311,
          572,
          565,
          689,
          291,
          393,
          380,
          722,
          17720,
          13,
          50490
        ]
      },
      {
        "avg_logprob": -0.2401126403808594,
        "compression_ratio": 1.602076124567474,
        "end": 4743.34,
        "id": 1626,
        "no_speech_prob": 0.00002429997402941808,
        "seek": 473562,
        "start": 4738.14,
        "temperature": 0,
        "text": " But I was in my later 20s around then, I think, if that's right.",
        "tokens": [
          50490,
          583,
          286,
          390,
          294,
          452,
          1780,
          945,
          82,
          926,
          550,
          11,
          286,
          519,
          11,
          498,
          300,
          311,
          558,
          13,
          50750
        ]
      },
      {
        "avg_logprob": -0.2401126403808594,
        "compression_ratio": 1.602076124567474,
        "end": 4745.66,
        "id": 1627,
        "no_speech_prob": 0.00002429997402941808,
        "seek": 473562,
        "start": 4743.34,
        "temperature": 0,
        "text": " I did a little bit of programming in middle school",
        "tokens": [
          50750,
          286,
          630,
          257,
          707,
          857,
          295,
          9410,
          294,
          2808,
          1395,
          50866
        ]
      },
      {
        "avg_logprob": -0.2401126403808594,
        "compression_ratio": 1.602076124567474,
        "end": 4747.98,
        "id": 1628,
        "no_speech_prob": 0.00002429997402941808,
        "seek": 473562,
        "start": 4745.66,
        "temperature": 0,
        "text": " using the basic programming language and also assembly",
        "tokens": [
          50866,
          1228,
          264,
          3875,
          9410,
          2856,
          293,
          611,
          12103,
          50982
        ]
      },
      {
        "avg_logprob": -0.2401126403808594,
        "compression_ratio": 1.602076124567474,
        "end": 4748.62,
        "id": 1629,
        "no_speech_prob": 0.00002429997402941808,
        "seek": 473562,
        "start": 4747.98,
        "temperature": 0,
        "text": " language.",
        "tokens": [
          50982,
          2856,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2401126403808594,
        "compression_ratio": 1.602076124567474,
        "end": 4753.099999999999,
        "id": 1630,
        "no_speech_prob": 0.00002429997402941808,
        "seek": 473562,
        "start": 4748.62,
        "temperature": 0,
        "text": " And I maybe took one course on C++ when I was in college.",
        "tokens": [
          51014,
          400,
          286,
          1310,
          1890,
          472,
          1164,
          322,
          383,
          25472,
          562,
          286,
          390,
          294,
          3859,
          13,
          51238
        ]
      },
      {
        "avg_logprob": -0.2401126403808594,
        "compression_ratio": 1.602076124567474,
        "end": 4757.0599999999995,
        "id": 1631,
        "no_speech_prob": 0.00002429997402941808,
        "seek": 473562,
        "start": 4753.099999999999,
        "temperature": 0,
        "text": " But I never really started programming until about 2001.",
        "tokens": [
          51238,
          583,
          286,
          1128,
          534,
          1409,
          9410,
          1826,
          466,
          16382,
          13,
          51436
        ]
      },
      {
        "avg_logprob": -0.2401126403808594,
        "compression_ratio": 1.602076124567474,
        "end": 4761.5,
        "id": 1632,
        "no_speech_prob": 0.00002429997402941808,
        "seek": 473562,
        "start": 4757.0599999999995,
        "temperature": 0,
        "text": " OK, trying to think if there are other important announcements.",
        "tokens": [
          51436,
          2264,
          11,
          1382,
          281,
          519,
          498,
          456,
          366,
          661,
          1021,
          23785,
          13,
          51658
        ]
      },
      {
        "avg_logprob": -0.2401126403808594,
        "compression_ratio": 1.602076124567474,
        "end": 4764.74,
        "id": 1633,
        "no_speech_prob": 0.00002429997402941808,
        "seek": 473562,
        "start": 4761.5,
        "temperature": 0,
        "text": " Let me look at, I'm kind of nearing the end, so to speak,",
        "tokens": [
          51658,
          961,
          385,
          574,
          412,
          11,
          286,
          478,
          733,
          295,
          408,
          1921,
          264,
          917,
          11,
          370,
          281,
          1710,
          11,
          51820
        ]
      },
      {
        "avg_logprob": -0.26625193197896163,
        "compression_ratio": 1.6182432432432432,
        "end": 4766.46,
        "id": 1634,
        "no_speech_prob": 0.0005112362559884787,
        "seek": 476474,
        "start": 4764.82,
        "temperature": 0,
        "text": " of this course.",
        "tokens": [
          50368,
          295,
          341,
          1164,
          13,
          50450
        ]
      },
      {
        "avg_logprob": -0.26625193197896163,
        "compression_ratio": 1.6182432432432432,
        "end": 4767.92,
        "id": 1635,
        "no_speech_prob": 0.0005112362559884787,
        "seek": 476474,
        "start": 4766.46,
        "temperature": 0,
        "text": " So there's a lot more that I want",
        "tokens": [
          50450,
          407,
          456,
          311,
          257,
          688,
          544,
          300,
          286,
          528,
          50523
        ]
      },
      {
        "avg_logprob": -0.26625193197896163,
        "compression_ratio": 1.6182432432432432,
        "end": 4771.46,
        "id": 1636,
        "no_speech_prob": 0.0005112362559884787,
        "seek": 476474,
        "start": 4767.92,
        "temperature": 0,
        "text": " to look at building APIs and using these Node packages",
        "tokens": [
          50523,
          281,
          574,
          412,
          2390,
          21445,
          293,
          1228,
          613,
          38640,
          17401,
          50700
        ]
      },
      {
        "avg_logprob": -0.26625193197896163,
        "compression_ratio": 1.6182432432432432,
        "end": 4775.0199999999995,
        "id": 1637,
        "no_speech_prob": 0.0005112362559884787,
        "seek": 476474,
        "start": 4771.46,
        "temperature": 0,
        "text": " for doing some other text classification, text generation",
        "tokens": [
          50700,
          337,
          884,
          512,
          661,
          2487,
          21538,
          11,
          2487,
          5125,
          50878
        ]
      },
      {
        "avg_logprob": -0.26625193197896163,
        "compression_ratio": 1.6182432432432432,
        "end": 4775.86,
        "id": 1638,
        "no_speech_prob": 0.0005112362559884787,
        "seek": 476474,
        "start": 4775.0199999999995,
        "temperature": 0,
        "text": " analysis stuff.",
        "tokens": [
          50878,
          5215,
          1507,
          13,
          50920
        ]
      },
      {
        "avg_logprob": -0.26625193197896163,
        "compression_ratio": 1.6182432432432432,
        "end": 4777.9,
        "id": 1639,
        "no_speech_prob": 0.0005112362559884787,
        "seek": 476474,
        "start": 4775.86,
        "temperature": 0,
        "text": " I want to do a whole session on Chrome extensions.",
        "tokens": [
          50920,
          286,
          528,
          281,
          360,
          257,
          1379,
          5481,
          322,
          15327,
          25129,
          13,
          51022
        ]
      },
      {
        "avg_logprob": -0.26625193197896163,
        "compression_ratio": 1.6182432432432432,
        "end": 4780.62,
        "id": 1640,
        "no_speech_prob": 0.0005112362559884787,
        "seek": 476474,
        "start": 4777.9,
        "temperature": 0,
        "text": " That probably might take a two-week period as well.",
        "tokens": [
          51022,
          663,
          1391,
          1062,
          747,
          257,
          732,
          12,
          23188,
          2896,
          382,
          731,
          13,
          51158
        ]
      },
      {
        "avg_logprob": -0.26625193197896163,
        "compression_ratio": 1.6182432432432432,
        "end": 4782.7,
        "id": 1641,
        "no_speech_prob": 0.0005112362559884787,
        "seek": 476474,
        "start": 4780.62,
        "temperature": 0,
        "text": " This is taking two weeks.",
        "tokens": [
          51158,
          639,
          307,
          1940,
          732,
          3259,
          13,
          51262
        ]
      },
      {
        "avg_logprob": -0.26625193197896163,
        "compression_ratio": 1.6182432432432432,
        "end": 4785.42,
        "id": 1642,
        "no_speech_prob": 0.0005112362559884787,
        "seek": 476474,
        "start": 4782.7,
        "temperature": 0,
        "text": " And then there's this time in my actual course",
        "tokens": [
          51262,
          400,
          550,
          456,
          311,
          341,
          565,
          294,
          452,
          3539,
          1164,
          51398
        ]
      },
      {
        "avg_logprob": -0.26625193197896163,
        "compression_ratio": 1.6182432432432432,
        "end": 4788.42,
        "id": 1643,
        "no_speech_prob": 0.0005112362559884787,
        "seek": 476474,
        "start": 4785.42,
        "temperature": 0,
        "text": " at ITP at NYU where students are for over four weeks",
        "tokens": [
          51398,
          412,
          6783,
          47,
          412,
          42682,
          689,
          1731,
          366,
          337,
          670,
          1451,
          3259,
          51548
        ]
      },
      {
        "avg_logprob": -0.26625193197896163,
        "compression_ratio": 1.6182432432432432,
        "end": 4790.099999999999,
        "id": 1644,
        "no_speech_prob": 0.0005112362559884787,
        "seek": 476474,
        "start": 4788.42,
        "temperature": 0,
        "text": " are working on final projects.",
        "tokens": [
          51548,
          366,
          1364,
          322,
          2572,
          4455,
          13,
          51632
        ]
      },
      {
        "avg_logprob": -0.26625193197896163,
        "compression_ratio": 1.6182432432432432,
        "end": 4792.94,
        "id": 1645,
        "no_speech_prob": 0.0005112362559884787,
        "seek": 476474,
        "start": 4790.099999999999,
        "temperature": 0,
        "text": " So any of you who are interested in kind",
        "tokens": [
          51632,
          407,
          604,
          295,
          291,
          567,
          366,
          3102,
          294,
          733,
          51774
        ]
      },
      {
        "avg_logprob": -0.26473921058821853,
        "compression_ratio": 1.7046979865771812,
        "end": 4795.0199999999995,
        "id": 1646,
        "no_speech_prob": 0.003945284988731146,
        "seek": 479294,
        "start": 4793.219999999999,
        "temperature": 0,
        "text": " of thinking about watching these videos",
        "tokens": [
          50378,
          295,
          1953,
          466,
          1976,
          613,
          2145,
          50468
        ]
      },
      {
        "avg_logprob": -0.26473921058821853,
        "compression_ratio": 1.7046979865771812,
        "end": 4796.58,
        "id": 1647,
        "no_speech_prob": 0.003945284988731146,
        "seek": 479294,
        "start": 4795.0199999999995,
        "temperature": 0,
        "text": " and as if you're taking a course,",
        "tokens": [
          50468,
          293,
          382,
          498,
          291,
          434,
          1940,
          257,
          1164,
          11,
          50546
        ]
      },
      {
        "avg_logprob": -0.26473921058821853,
        "compression_ratio": 1.7046979865771812,
        "end": 4798.82,
        "id": 1648,
        "no_speech_prob": 0.003945284988731146,
        "seek": 479294,
        "start": 4796.58,
        "temperature": 0,
        "text": " you could just do that and share with me on Twitter",
        "tokens": [
          50546,
          291,
          727,
          445,
          360,
          300,
          293,
          2073,
          365,
          385,
          322,
          5794,
          50658
        ]
      },
      {
        "avg_logprob": -0.26473921058821853,
        "compression_ratio": 1.7046979865771812,
        "end": 4801.0599999999995,
        "id": 1649,
        "no_speech_prob": 0.003945284988731146,
        "seek": 479294,
        "start": 4798.82,
        "temperature": 0,
        "text": " or in the comments any projects you make.",
        "tokens": [
          50658,
          420,
          294,
          264,
          3053,
          604,
          4455,
          291,
          652,
          13,
          50770
        ]
      },
      {
        "avg_logprob": -0.26473921058821853,
        "compression_ratio": 1.7046979865771812,
        "end": 4806.5,
        "id": 1650,
        "no_speech_prob": 0.003945284988731146,
        "seek": 479294,
        "start": 4801.0599999999995,
        "temperature": 0,
        "text": " But I will say you can also subscribe to my Patreon,",
        "tokens": [
          50770,
          583,
          286,
          486,
          584,
          291,
          393,
          611,
          3022,
          281,
          452,
          15692,
          11,
          51042
        ]
      },
      {
        "avg_logprob": -0.26473921058821853,
        "compression_ratio": 1.7046979865771812,
        "end": 4809.139999999999,
        "id": 1651,
        "no_speech_prob": 0.003945284988731146,
        "seek": 479294,
        "start": 4806.5,
        "temperature": 0,
        "text": " patreon.com slash coding rainbow.",
        "tokens": [
          51042,
          33161,
          13,
          1112,
          17330,
          17720,
          18526,
          13,
          51174
        ]
      },
      {
        "avg_logprob": -0.26473921058821853,
        "compression_ratio": 1.7046979865771812,
        "end": 4811.96,
        "id": 1652,
        "no_speech_prob": 0.003945284988731146,
        "seek": 479294,
        "start": 4809.139999999999,
        "temperature": 0,
        "text": " And there, if you join that, there's",
        "tokens": [
          51174,
          400,
          456,
          11,
          498,
          291,
          3917,
          300,
          11,
          456,
          311,
          51315
        ]
      },
      {
        "avg_logprob": -0.26473921058821853,
        "compression_ratio": 1.7046979865771812,
        "end": 4814.0599999999995,
        "id": 1653,
        "no_speech_prob": 0.003945284988731146,
        "seek": 479294,
        "start": 4811.96,
        "temperature": 0,
        "text": " a Slack channel where it's kind of trailed off.",
        "tokens": [
          51315,
          257,
          37211,
          2269,
          689,
          309,
          311,
          733,
          295,
          944,
          7292,
          766,
          13,
          51420
        ]
      },
      {
        "avg_logprob": -0.26473921058821853,
        "compression_ratio": 1.7046979865771812,
        "end": 4815.139999999999,
        "id": 1654,
        "no_speech_prob": 0.003945284988731146,
        "seek": 479294,
        "start": 4814.0599999999995,
        "temperature": 0,
        "text": " I think people are busy.",
        "tokens": [
          51420,
          286,
          519,
          561,
          366,
          5856,
          13,
          51474
        ]
      },
      {
        "avg_logprob": -0.26473921058821853,
        "compression_ratio": 1.7046979865771812,
        "end": 4817.62,
        "id": 1655,
        "no_speech_prob": 0.003945284988731146,
        "seek": 479294,
        "start": 4815.139999999999,
        "temperature": 0,
        "text": " But I'm hoping that we can kind of revive it a little bit,",
        "tokens": [
          51474,
          583,
          286,
          478,
          7159,
          300,
          321,
          393,
          733,
          295,
          36292,
          309,
          257,
          707,
          857,
          11,
          51598
        ]
      },
      {
        "avg_logprob": -0.26473921058821853,
        "compression_ratio": 1.7046979865771812,
        "end": 4819.339999999999,
        "id": 1656,
        "no_speech_prob": 0.003945284988731146,
        "seek": 479294,
        "start": 4817.62,
        "temperature": 0,
        "text": " where people are discussing assignments and asking",
        "tokens": [
          51598,
          689,
          561,
          366,
          10850,
          22546,
          293,
          3365,
          51684
        ]
      },
      {
        "avg_logprob": -0.26473921058821853,
        "compression_ratio": 1.7046979865771812,
        "end": 4820.74,
        "id": 1657,
        "no_speech_prob": 0.003945284988731146,
        "seek": 479294,
        "start": 4819.339999999999,
        "temperature": 0,
        "text": " questions and that sort of thing.",
        "tokens": [
          51684,
          1651,
          293,
          300,
          1333,
          295,
          551,
          13,
          51754
        ]
      },
      {
        "avg_logprob": -0.2445971965789795,
        "compression_ratio": 1.7610921501706485,
        "end": 4822.74,
        "id": 1658,
        "no_speech_prob": 0.000058280616940464824,
        "seek": 482074,
        "start": 4820.82,
        "temperature": 0,
        "text": " Ah.",
        "tokens": [
          50368,
          2438,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2445971965789795,
        "compression_ratio": 1.7610921501706485,
        "end": 4825.5,
        "id": 1659,
        "no_speech_prob": 0.000058280616940464824,
        "seek": 482074,
        "start": 4822.74,
        "temperature": 0,
        "text": " So oh, yeah, using Excel for a database",
        "tokens": [
          50464,
          407,
          1954,
          11,
          1338,
          11,
          1228,
          19060,
          337,
          257,
          8149,
          50602
        ]
      },
      {
        "avg_logprob": -0.2445971965789795,
        "compression_ratio": 1.7610921501706485,
        "end": 4828.179999999999,
        "id": 1660,
        "no_speech_prob": 0.000058280616940464824,
        "seek": 482074,
        "start": 4825.5,
        "temperature": 0,
        "text": " or a spreadsheet for a database is quite useful.",
        "tokens": [
          50602,
          420,
          257,
          27733,
          337,
          257,
          8149,
          307,
          1596,
          4420,
          13,
          50736
        ]
      },
      {
        "avg_logprob": -0.2445971965789795,
        "compression_ratio": 1.7610921501706485,
        "end": 4829.78,
        "id": 1661,
        "no_speech_prob": 0.000058280616940464824,
        "seek": 482074,
        "start": 4828.179999999999,
        "temperature": 0,
        "text": " And in fact, over that, I would say,",
        "tokens": [
          50736,
          400,
          294,
          1186,
          11,
          670,
          300,
          11,
          286,
          576,
          584,
          11,
          50816
        ]
      },
      {
        "avg_logprob": -0.2445971965789795,
        "compression_ratio": 1.7610921501706485,
        "end": 4832.42,
        "id": 1662,
        "no_speech_prob": 0.000058280616940464824,
        "seek": 482074,
        "start": 4829.78,
        "temperature": 0,
        "text": " and I have an example that I made previously",
        "tokens": [
          50816,
          293,
          286,
          362,
          364,
          1365,
          300,
          286,
          1027,
          8046,
          50948
        ]
      },
      {
        "avg_logprob": -0.2445971965789795,
        "compression_ratio": 1.7610921501706485,
        "end": 4833.94,
        "id": 1663,
        "no_speech_prob": 0.000058280616940464824,
        "seek": 482074,
        "start": 4832.42,
        "temperature": 0,
        "text": " of just using a Google Sheet.",
        "tokens": [
          50948,
          295,
          445,
          1228,
          257,
          3329,
          1240,
          302,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.2445971965789795,
        "compression_ratio": 1.7610921501706485,
        "end": 4838.179999999999,
        "id": 1664,
        "no_speech_prob": 0.000058280616940464824,
        "seek": 482074,
        "start": 4833.94,
        "temperature": 0,
        "text": " So you can actually, and there is something called Sheetsu.",
        "tokens": [
          51024,
          407,
          291,
          393,
          767,
          11,
          293,
          456,
          307,
          746,
          1219,
          1240,
          1385,
          84,
          13,
          51236
        ]
      },
      {
        "avg_logprob": -0.2445971965789795,
        "compression_ratio": 1.7610921501706485,
        "end": 4839.42,
        "id": 1665,
        "no_speech_prob": 0.000058280616940464824,
        "seek": 482074,
        "start": 4838.179999999999,
        "temperature": 0,
        "text": " Sheetsu.com, I believe.",
        "tokens": [
          51236,
          1240,
          1385,
          84,
          13,
          1112,
          11,
          286,
          1697,
          13,
          51298
        ]
      },
      {
        "avg_logprob": -0.2445971965789795,
        "compression_ratio": 1.7610921501706485,
        "end": 4840.9,
        "id": 1666,
        "no_speech_prob": 0.000058280616940464824,
        "seek": 482074,
        "start": 4839.42,
        "temperature": 0,
        "text": " This is a commercial service.",
        "tokens": [
          51298,
          639,
          307,
          257,
          6841,
          2643,
          13,
          51372
        ]
      },
      {
        "avg_logprob": -0.2445971965789795,
        "compression_ratio": 1.7610921501706485,
        "end": 4842.219999999999,
        "id": 1667,
        "no_speech_prob": 0.000058280616940464824,
        "seek": 482074,
        "start": 4840.9,
        "temperature": 0,
        "text": " I think you can use it for free.",
        "tokens": [
          51372,
          286,
          519,
          291,
          393,
          764,
          309,
          337,
          1737,
          13,
          51438
        ]
      },
      {
        "avg_logprob": -0.2445971965789795,
        "compression_ratio": 1.7610921501706485,
        "end": 4844.82,
        "id": 1668,
        "no_speech_prob": 0.000058280616940464824,
        "seek": 482074,
        "start": 4842.219999999999,
        "temperature": 0,
        "text": " But it turns a Google spreadsheet into a REST API.",
        "tokens": [
          51438,
          583,
          309,
          4523,
          257,
          3329,
          27733,
          666,
          257,
          497,
          14497,
          9362,
          13,
          51568
        ]
      },
      {
        "avg_logprob": -0.2445971965789795,
        "compression_ratio": 1.7610921501706485,
        "end": 4846.86,
        "id": 1669,
        "no_speech_prob": 0.000058280616940464824,
        "seek": 482074,
        "start": 4844.82,
        "temperature": 0,
        "text": " Hey, maybe you know what a REST API is now,",
        "tokens": [
          51568,
          1911,
          11,
          1310,
          291,
          458,
          437,
          257,
          497,
          14497,
          9362,
          307,
          586,
          11,
          51670
        ]
      },
      {
        "avg_logprob": -0.2445971965789795,
        "compression_ratio": 1.7610921501706485,
        "end": 4848.219999999999,
        "id": 1670,
        "no_speech_prob": 0.000058280616940464824,
        "seek": 482074,
        "start": 4846.86,
        "temperature": 0,
        "text": " Spreadsheet as Database.",
        "tokens": [
          51670,
          30308,
          9611,
          302,
          382,
          40461,
          651,
          13,
          51738
        ]
      },
      {
        "avg_logprob": -0.2445971965789795,
        "compression_ratio": 1.7610921501706485,
        "end": 4850.0599999999995,
        "id": 1671,
        "no_speech_prob": 0.000058280616940464824,
        "seek": 482074,
        "start": 4848.219999999999,
        "temperature": 0,
        "text": " So this is something I should add to my list",
        "tokens": [
          51738,
          407,
          341,
          307,
          746,
          286,
          820,
          909,
          281,
          452,
          1329,
          51830
        ]
      },
      {
        "avg_logprob": -0.2571786046028137,
        "compression_ratio": 1.731060606060606,
        "end": 4854.1,
        "id": 1672,
        "no_speech_prob": 0.0003006142214871943,
        "seek": 485006,
        "start": 4850.1,
        "temperature": 0,
        "text": " to maybe do a video about in particular.",
        "tokens": [
          50366,
          281,
          1310,
          360,
          257,
          960,
          466,
          294,
          1729,
          13,
          50566
        ]
      },
      {
        "avg_logprob": -0.2571786046028137,
        "compression_ratio": 1.731060606060606,
        "end": 4856.26,
        "id": 1673,
        "no_speech_prob": 0.0003006142214871943,
        "seek": 485006,
        "start": 4854.1,
        "temperature": 0,
        "text": " I've gotten a lot of requests for more kind",
        "tokens": [
          50566,
          286,
          600,
          5768,
          257,
          688,
          295,
          12475,
          337,
          544,
          733,
          50674
        ]
      },
      {
        "avg_logprob": -0.2571786046028137,
        "compression_ratio": 1.731060606060606,
        "end": 4859.1,
        "id": 1674,
        "no_speech_prob": 0.0003006142214871943,
        "seek": 485006,
        "start": 4856.26,
        "temperature": 0,
        "text": " of like classic arcade game coding challenges.",
        "tokens": [
          50674,
          295,
          411,
          7230,
          25664,
          1216,
          17720,
          4759,
          13,
          50816
        ]
      },
      {
        "avg_logprob": -0.2571786046028137,
        "compression_ratio": 1.731060606060606,
        "end": 4861.02,
        "id": 1675,
        "no_speech_prob": 0.0003006142214871943,
        "seek": 485006,
        "start": 4859.1,
        "temperature": 0,
        "text": " And I think what I might do is when",
        "tokens": [
          50816,
          400,
          286,
          519,
          437,
          286,
          1062,
          360,
          307,
          562,
          50912
        ]
      },
      {
        "avg_logprob": -0.2571786046028137,
        "compression_ratio": 1.731060606060606,
        "end": 4863.820000000001,
        "id": 1676,
        "no_speech_prob": 0.0003006142214871943,
        "seek": 485006,
        "start": 4861.02,
        "temperature": 0,
        "text": " I have time towards the end of the NYU semester,",
        "tokens": [
          50912,
          286,
          362,
          565,
          3030,
          264,
          917,
          295,
          264,
          42682,
          11894,
          11,
          51052
        ]
      },
      {
        "avg_logprob": -0.2571786046028137,
        "compression_ratio": 1.731060606060606,
        "end": 4865.34,
        "id": 1677,
        "no_speech_prob": 0.0003006142214871943,
        "seek": 485006,
        "start": 4863.820000000001,
        "temperature": 0,
        "text": " where I'm done with these topics,",
        "tokens": [
          51052,
          689,
          286,
          478,
          1096,
          365,
          613,
          8378,
          11,
          51128
        ]
      },
      {
        "avg_logprob": -0.2571786046028137,
        "compression_ratio": 1.731060606060606,
        "end": 4866.700000000001,
        "id": 1678,
        "no_speech_prob": 0.0003006142214871943,
        "seek": 485006,
        "start": 4865.34,
        "temperature": 0,
        "text": " I might just do a couple of weeks",
        "tokens": [
          51128,
          286,
          1062,
          445,
          360,
          257,
          1916,
          295,
          3259,
          51196
        ]
      },
      {
        "avg_logprob": -0.2571786046028137,
        "compression_ratio": 1.731060606060606,
        "end": 4868.900000000001,
        "id": 1679,
        "no_speech_prob": 0.0003006142214871943,
        "seek": 485006,
        "start": 4866.700000000001,
        "temperature": 0,
        "text": " where I just do those arcade game coding challenges.",
        "tokens": [
          51196,
          689,
          286,
          445,
          360,
          729,
          25664,
          1216,
          17720,
          4759,
          13,
          51306
        ]
      },
      {
        "avg_logprob": -0.2571786046028137,
        "compression_ratio": 1.731060606060606,
        "end": 4870.780000000001,
        "id": 1680,
        "no_speech_prob": 0.0003006142214871943,
        "seek": 485006,
        "start": 4868.900000000001,
        "temperature": 0,
        "text": " Because I find them to be a lot of fun.",
        "tokens": [
          51306,
          1436,
          286,
          915,
          552,
          281,
          312,
          257,
          688,
          295,
          1019,
          13,
          51400
        ]
      },
      {
        "avg_logprob": -0.2571786046028137,
        "compression_ratio": 1.731060606060606,
        "end": 4873.46,
        "id": 1681,
        "no_speech_prob": 0.0003006142214871943,
        "seek": 485006,
        "start": 4870.780000000001,
        "temperature": 0,
        "text": " And to be honest, the snake one that I made,",
        "tokens": [
          51400,
          400,
          281,
          312,
          3245,
          11,
          264,
          12650,
          472,
          300,
          286,
          1027,
          11,
          51534
        ]
      },
      {
        "avg_logprob": -0.2571786046028137,
        "compression_ratio": 1.731060606060606,
        "end": 4875.14,
        "id": 1682,
        "no_speech_prob": 0.0003006142214871943,
        "seek": 485006,
        "start": 4873.46,
        "temperature": 0,
        "text": " which isn't really even that good,",
        "tokens": [
          51534,
          597,
          1943,
          380,
          534,
          754,
          300,
          665,
          11,
          51618
        ]
      },
      {
        "avg_logprob": -0.2995387806611903,
        "compression_ratio": 1.7007299270072993,
        "end": 4880.820000000001,
        "id": 1683,
        "no_speech_prob": 0.20425567030906677,
        "seek": 487514,
        "start": 4875.14,
        "temperature": 0,
        "text": " has like 100 times more views than any of my other videos.",
        "tokens": [
          50364,
          575,
          411,
          2319,
          1413,
          544,
          6809,
          813,
          604,
          295,
          452,
          661,
          2145,
          13,
          50648
        ]
      },
      {
        "avg_logprob": -0.2995387806611903,
        "compression_ratio": 1.7007299270072993,
        "end": 4882.54,
        "id": 1684,
        "no_speech_prob": 0.20425567030906677,
        "seek": 487514,
        "start": 4880.820000000001,
        "temperature": 0,
        "text": " What do you think about making a project",
        "tokens": [
          50648,
          708,
          360,
          291,
          519,
          466,
          1455,
          257,
          1716,
          50734
        ]
      },
      {
        "avg_logprob": -0.2995387806611903,
        "compression_ratio": 1.7007299270072993,
        "end": 4884.02,
        "id": 1685,
        "no_speech_prob": 0.20425567030906677,
        "seek": 487514,
        "start": 4882.54,
        "temperature": 0,
        "text": " in the type of a big collaboration",
        "tokens": [
          50734,
          294,
          264,
          2010,
          295,
          257,
          955,
          9363,
          50808
        ]
      },
      {
        "avg_logprob": -0.2995387806611903,
        "compression_ratio": 1.7007299270072993,
        "end": 4885.06,
        "id": 1686,
        "no_speech_prob": 0.20425567030906677,
        "seek": 487514,
        "start": 4884.02,
        "temperature": 0,
        "text": " of the whole community?",
        "tokens": [
          50808,
          295,
          264,
          1379,
          1768,
          30,
          50860
        ]
      },
      {
        "avg_logprob": -0.2995387806611903,
        "compression_ratio": 1.7007299270072993,
        "end": 4888.46,
        "id": 1687,
        "no_speech_prob": 0.20425567030906677,
        "seek": 487514,
        "start": 4885.06,
        "temperature": 0,
        "text": " I would be thrilled for something like that.",
        "tokens": [
          50860,
          286,
          576,
          312,
          18744,
          337,
          746,
          411,
          300,
          13,
          51030
        ]
      },
      {
        "avg_logprob": -0.2995387806611903,
        "compression_ratio": 1.7007299270072993,
        "end": 4890.26,
        "id": 1688,
        "no_speech_prob": 0.20425567030906677,
        "seek": 487514,
        "start": 4888.46,
        "temperature": 0,
        "text": " I would be glad to support that.",
        "tokens": [
          51030,
          286,
          576,
          312,
          5404,
          281,
          1406,
          300,
          13,
          51120
        ]
      },
      {
        "avg_logprob": -0.2995387806611903,
        "compression_ratio": 1.7007299270072993,
        "end": 4893.26,
        "id": 1689,
        "no_speech_prob": 0.20425567030906677,
        "seek": 487514,
        "start": 4890.26,
        "temperature": 0,
        "text": " And I would hope that that community would include people",
        "tokens": [
          51120,
          400,
          286,
          576,
          1454,
          300,
          300,
          1768,
          576,
          4090,
          561,
          51270
        ]
      },
      {
        "avg_logprob": -0.2995387806611903,
        "compression_ratio": 1.7007299270072993,
        "end": 4898.18,
        "id": 1690,
        "no_speech_prob": 0.20425567030906677,
        "seek": 487514,
        "start": 4893.26,
        "temperature": 0,
        "text": " from all sorts of backgrounds, and genders, and ethnicities.",
        "tokens": [
          51270,
          490,
          439,
          7527,
          295,
          17336,
          11,
          293,
          290,
          16292,
          11,
          293,
          14363,
          1088,
          13,
          51516
        ]
      },
      {
        "avg_logprob": -0.2995387806611903,
        "compression_ratio": 1.7007299270072993,
        "end": 4900.62,
        "id": 1691,
        "no_speech_prob": 0.20425567030906677,
        "seek": 487514,
        "start": 4898.18,
        "temperature": 0,
        "text": " It would be terrific if we could make a community project like",
        "tokens": [
          51516,
          467,
          576,
          312,
          20899,
          498,
          321,
          727,
          652,
          257,
          1768,
          1716,
          411,
          51638
        ]
      },
      {
        "avg_logprob": -0.2995387806611903,
        "compression_ratio": 1.7007299270072993,
        "end": 4901.46,
        "id": 1692,
        "no_speech_prob": 0.20425567030906677,
        "seek": 487514,
        "start": 4900.62,
        "temperature": 0,
        "text": " that.",
        "tokens": [
          51638,
          300,
          13,
          51680
        ]
      },
      {
        "avg_logprob": -0.2995387806611903,
        "compression_ratio": 1.7007299270072993,
        "end": 4903.06,
        "id": 1693,
        "no_speech_prob": 0.20425567030906677,
        "seek": 487514,
        "start": 4901.46,
        "temperature": 0,
        "text": " Joining the Patreon and the Slack channel",
        "tokens": [
          51680,
          40229,
          264,
          15692,
          293,
          264,
          37211,
          2269,
          51760
        ]
      },
      {
        "avg_logprob": -0.2899927961716958,
        "compression_ratio": 1.556910569105691,
        "end": 4905.5,
        "id": 1694,
        "no_speech_prob": 0.00008219997835112736,
        "seek": 490306,
        "start": 4903.06,
        "temperature": 0,
        "text": " would be a good place to start with a smaller community.",
        "tokens": [
          50364,
          576,
          312,
          257,
          665,
          1081,
          281,
          722,
          365,
          257,
          4356,
          1768,
          13,
          50486
        ]
      },
      {
        "avg_logprob": -0.2899927961716958,
        "compression_ratio": 1.556910569105691,
        "end": 4908.02,
        "id": 1695,
        "no_speech_prob": 0.00008219997835112736,
        "seek": 490306,
        "start": 4905.5,
        "temperature": 0,
        "text": " There are other more open Slack channels.",
        "tokens": [
          50486,
          821,
          366,
          661,
          544,
          1269,
          37211,
          9235,
          13,
          50612
        ]
      },
      {
        "avg_logprob": -0.2899927961716958,
        "compression_ratio": 1.556910569105691,
        "end": 4910.660000000001,
        "id": 1696,
        "no_speech_prob": 0.00008219997835112736,
        "seek": 490306,
        "start": 4908.02,
        "temperature": 0,
        "text": " I believe there's a creative coding one.",
        "tokens": [
          50612,
          286,
          1697,
          456,
          311,
          257,
          5880,
          17720,
          472,
          13,
          50744
        ]
      },
      {
        "avg_logprob": -0.2899927961716958,
        "compression_ratio": 1.556910569105691,
        "end": 4915.5,
        "id": 1697,
        "no_speech_prob": 0.00008219997835112736,
        "seek": 490306,
        "start": 4910.660000000001,
        "temperature": 0,
        "text": " And certainly, send me a tweet.",
        "tokens": [
          50744,
          400,
          3297,
          11,
          2845,
          385,
          257,
          15258,
          13,
          50986
        ]
      },
      {
        "avg_logprob": -0.2899927961716958,
        "compression_ratio": 1.556910569105691,
        "end": 4918,
        "id": 1698,
        "no_speech_prob": 0.00008219997835112736,
        "seek": 490306,
        "start": 4915.5,
        "temperature": 0,
        "text": " I'll retweet it if you want people to get in touch with you",
        "tokens": [
          50986,
          286,
          603,
          1533,
          10354,
          309,
          498,
          291,
          528,
          561,
          281,
          483,
          294,
          2557,
          365,
          291,
          51111
        ]
      },
      {
        "avg_logprob": -0.2899927961716958,
        "compression_ratio": 1.556910569105691,
        "end": 4918.620000000001,
        "id": 1699,
        "no_speech_prob": 0.00008219997835112736,
        "seek": 490306,
        "start": 4918,
        "temperature": 0,
        "text": " about a project.",
        "tokens": [
          51111,
          466,
          257,
          1716,
          13,
          51142
        ]
      },
      {
        "avg_logprob": -0.2899927961716958,
        "compression_ratio": 1.556910569105691,
        "end": 4925.34,
        "id": 1700,
        "no_speech_prob": 0.00008219997835112736,
        "seek": 490306,
        "start": 4921.740000000001,
        "temperature": 0,
        "text": " John is asking something about install NodeDaemon.",
        "tokens": [
          51298,
          2619,
          307,
          3365,
          746,
          466,
          3625,
          38640,
          35,
          64,
          36228,
          13,
          51478
        ]
      },
      {
        "avg_logprob": -0.2899927961716958,
        "compression_ratio": 1.556910569105691,
        "end": 4929.22,
        "id": 1701,
        "no_speech_prob": 0.00008219997835112736,
        "seek": 490306,
        "start": 4925.34,
        "temperature": 0,
        "text": " I don't know what that is.",
        "tokens": [
          51478,
          286,
          500,
          380,
          458,
          437,
          300,
          307,
          13,
          51672
        ]
      },
      {
        "avg_logprob": -0.2899927961716958,
        "compression_ratio": 1.556910569105691,
        "end": 4931.6,
        "id": 1702,
        "no_speech_prob": 0.00008219997835112736,
        "seek": 490306,
        "start": 4929.22,
        "temperature": 0,
        "text": " But I'm using something called NodeMon, which you don't.",
        "tokens": [
          51672,
          583,
          286,
          478,
          1228,
          746,
          1219,
          38640,
          32498,
          11,
          597,
          291,
          500,
          380,
          13,
          51791
        ]
      },
      {
        "avg_logprob": -0.24848295660579905,
        "compression_ratio": 1.598639455782313,
        "end": 4934.8,
        "id": 1703,
        "no_speech_prob": 0.00047284617903642356,
        "seek": 493160,
        "start": 4931.64,
        "temperature": 0,
        "text": " Just use npm install NodeMon.",
        "tokens": [
          50366,
          1449,
          764,
          297,
          14395,
          3625,
          38640,
          32498,
          13,
          50524
        ]
      },
      {
        "avg_logprob": -0.24848295660579905,
        "compression_ratio": 1.598639455782313,
        "end": 4937.4400000000005,
        "id": 1704,
        "no_speech_prob": 0.00047284617903642356,
        "seek": 493160,
        "start": 4934.8,
        "temperature": 0,
        "text": " Are we called creative coding now?",
        "tokens": [
          50524,
          2014,
          321,
          1219,
          5880,
          17720,
          586,
          30,
          50656
        ]
      },
      {
        "avg_logprob": -0.24848295660579905,
        "compression_ratio": 1.598639455782313,
        "end": 4939.4800000000005,
        "id": 1705,
        "no_speech_prob": 0.00047284617903642356,
        "seek": 493160,
        "start": 4937.4400000000005,
        "temperature": 0,
        "text": " But I don't have a short answer to that question.",
        "tokens": [
          50656,
          583,
          286,
          500,
          380,
          362,
          257,
          2099,
          1867,
          281,
          300,
          1168,
          13,
          50758
        ]
      },
      {
        "avg_logprob": -0.24848295660579905,
        "compression_ratio": 1.598639455782313,
        "end": 4942.160000000001,
        "id": 1706,
        "no_speech_prob": 0.00047284617903642356,
        "seek": 493160,
        "start": 4939.4800000000005,
        "temperature": 0,
        "text": " And I have four minutes before I said I was going to go.",
        "tokens": [
          50758,
          400,
          286,
          362,
          1451,
          2077,
          949,
          286,
          848,
          286,
          390,
          516,
          281,
          352,
          13,
          50892
        ]
      },
      {
        "avg_logprob": -0.24848295660579905,
        "compression_ratio": 1.598639455782313,
        "end": 4943.68,
        "id": 1707,
        "no_speech_prob": 0.00047284617903642356,
        "seek": 493160,
        "start": 4942.160000000001,
        "temperature": 0,
        "text": " Will I do more generative art stuff?",
        "tokens": [
          50892,
          3099,
          286,
          360,
          544,
          1337,
          1166,
          1523,
          1507,
          30,
          50968
        ]
      },
      {
        "avg_logprob": -0.24848295660579905,
        "compression_ratio": 1.598639455782313,
        "end": 4944.18,
        "id": 1708,
        "no_speech_prob": 0.00047284617903642356,
        "seek": 493160,
        "start": 4943.68,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          50968,
          1079,
          13,
          50993
        ]
      },
      {
        "avg_logprob": -0.24848295660579905,
        "compression_ratio": 1.598639455782313,
        "end": 4947.52,
        "id": 1709,
        "no_speech_prob": 0.00047284617903642356,
        "seek": 493160,
        "start": 4944.18,
        "temperature": 0,
        "text": " So by the way, this spring, I'm going to, at NYU,",
        "tokens": [
          50993,
          407,
          538,
          264,
          636,
          11,
          341,
          5587,
          11,
          286,
          478,
          516,
          281,
          11,
          412,
          42682,
          11,
          51160
        ]
      },
      {
        "avg_logprob": -0.24848295660579905,
        "compression_ratio": 1.598639455782313,
        "end": 4949.68,
        "id": 1710,
        "no_speech_prob": 0.00047284617903642356,
        "seek": 493160,
        "start": 4947.52,
        "temperature": 0,
        "text": " be teaching a couple of courses based",
        "tokens": [
          51160,
          312,
          4571,
          257,
          1916,
          295,
          7712,
          2361,
          51268
        ]
      },
      {
        "avg_logprob": -0.24848295660579905,
        "compression_ratio": 1.598639455782313,
        "end": 4951.4800000000005,
        "id": 1711,
        "no_speech_prob": 0.00047284617903642356,
        "seek": 493160,
        "start": 4949.68,
        "temperature": 0,
        "text": " on my nature of code materials, which",
        "tokens": [
          51268,
          322,
          452,
          3687,
          295,
          3089,
          5319,
          11,
          597,
          51358
        ]
      },
      {
        "avg_logprob": -0.24848295660579905,
        "compression_ratio": 1.598639455782313,
        "end": 4954.280000000001,
        "id": 1712,
        "no_speech_prob": 0.00047284617903642356,
        "seek": 493160,
        "start": 4951.4800000000005,
        "temperature": 0,
        "text": " have generative algorithms, physics simulation,",
        "tokens": [
          51358,
          362,
          1337,
          1166,
          14642,
          11,
          10649,
          16575,
          11,
          51498
        ]
      },
      {
        "avg_logprob": -0.24848295660579905,
        "compression_ratio": 1.598639455782313,
        "end": 4955.88,
        "id": 1713,
        "no_speech_prob": 0.00047284617903642356,
        "seek": 493160,
        "start": 4954.280000000001,
        "temperature": 0,
        "text": " back to sort of graphic stuff.",
        "tokens": [
          51498,
          646,
          281,
          1333,
          295,
          14089,
          1507,
          13,
          51578
        ]
      },
      {
        "avg_logprob": -0.24848295660579905,
        "compression_ratio": 1.598639455782313,
        "end": 4958.64,
        "id": 1714,
        "no_speech_prob": 0.00047284617903642356,
        "seek": 493160,
        "start": 4955.88,
        "temperature": 0,
        "text": " And so I expect that once I get back up and running",
        "tokens": [
          51578,
          400,
          370,
          286,
          2066,
          300,
          1564,
          286,
          483,
          646,
          493,
          293,
          2614,
          51716
        ]
      },
      {
        "avg_logprob": -0.28880758599920586,
        "compression_ratio": 1.609442060085837,
        "end": 4962.52,
        "id": 1715,
        "no_speech_prob": 0.00017674422997515649,
        "seek": 495864,
        "start": 4958.64,
        "temperature": 0,
        "text": " with videos in 2017, after this fall and winter finishes,",
        "tokens": [
          50364,
          365,
          2145,
          294,
          6591,
          11,
          934,
          341,
          2100,
          293,
          6355,
          23615,
          11,
          50558
        ]
      },
      {
        "avg_logprob": -0.28880758599920586,
        "compression_ratio": 1.609442060085837,
        "end": 4965.6,
        "id": 1716,
        "no_speech_prob": 0.00017674422997515649,
        "seek": 495864,
        "start": 4962.52,
        "temperature": 0,
        "text": " you'll see a lot more graphics and generative algorithm stuff",
        "tokens": [
          50558,
          291,
          603,
          536,
          257,
          688,
          544,
          11837,
          293,
          1337,
          1166,
          9284,
          1507,
          50712
        ]
      },
      {
        "avg_logprob": -0.28880758599920586,
        "compression_ratio": 1.609442060085837,
        "end": 4969.240000000001,
        "id": 1717,
        "no_speech_prob": 0.00017674422997515649,
        "seek": 495864,
        "start": 4965.6,
        "temperature": 0,
        "text": " on the channel.",
        "tokens": [
          50712,
          322,
          264,
          2269,
          13,
          50894
        ]
      },
      {
        "avg_logprob": -0.28880758599920586,
        "compression_ratio": 1.609442060085837,
        "end": 4972.08,
        "id": 1718,
        "no_speech_prob": 0.00017674422997515649,
        "seek": 495864,
        "start": 4969.240000000001,
        "temperature": 0,
        "text": " Creative coding is a strange term.",
        "tokens": [
          50894,
          26598,
          17720,
          307,
          257,
          5861,
          1433,
          13,
          51036
        ]
      },
      {
        "avg_logprob": -0.28880758599920586,
        "compression_ratio": 1.609442060085837,
        "end": 4976.320000000001,
        "id": 1719,
        "no_speech_prob": 0.00017674422997515649,
        "seek": 495864,
        "start": 4972.08,
        "temperature": 0,
        "text": " I personally kind of like it to signify that the idea here",
        "tokens": [
          51036,
          286,
          5665,
          733,
          295,
          411,
          309,
          281,
          1465,
          2505,
          300,
          264,
          1558,
          510,
          51248
        ]
      },
      {
        "avg_logprob": -0.28880758599920586,
        "compression_ratio": 1.609442060085837,
        "end": 4980.52,
        "id": 1720,
        "no_speech_prob": 0.00017674422997515649,
        "seek": 495864,
        "start": 4976.320000000001,
        "temperature": 0,
        "text": " is that we're doing that this is different than computer",
        "tokens": [
          51248,
          307,
          300,
          321,
          434,
          884,
          300,
          341,
          307,
          819,
          813,
          3820,
          51458
        ]
      },
      {
        "avg_logprob": -0.28880758599920586,
        "compression_ratio": 1.609442060085837,
        "end": 4982.64,
        "id": 1721,
        "no_speech_prob": 0.00017674422997515649,
        "seek": 495864,
        "start": 4980.52,
        "temperature": 0,
        "text": " science in the sense that computer science really",
        "tokens": [
          51458,
          3497,
          294,
          264,
          2020,
          300,
          3820,
          3497,
          534,
          51564
        ]
      },
      {
        "avg_logprob": -0.28880758599920586,
        "compression_ratio": 1.609442060085837,
        "end": 4985.4800000000005,
        "id": 1722,
        "no_speech_prob": 0.00017674422997515649,
        "seek": 495864,
        "start": 4982.64,
        "temperature": 0,
        "text": " about systems thinking and algorithms.",
        "tokens": [
          51564,
          466,
          3652,
          1953,
          293,
          14642,
          13,
          51706
        ]
      },
      {
        "avg_logprob": -0.2733698887611503,
        "compression_ratio": 1.7310344827586206,
        "end": 4989.4,
        "id": 1723,
        "no_speech_prob": 0.0000067477540142135695,
        "seek": 498548,
        "start": 4985.48,
        "temperature": 0,
        "text": " And this is really about kind of playful experiments",
        "tokens": [
          50364,
          400,
          341,
          307,
          534,
          466,
          733,
          295,
          30730,
          12050,
          50560
        ]
      },
      {
        "avg_logprob": -0.2733698887611503,
        "compression_ratio": 1.7310344827586206,
        "end": 4991.4,
        "id": 1724,
        "no_speech_prob": 0.0000067477540142135695,
        "seek": 498548,
        "start": 4989.4,
        "temperature": 0,
        "text": " and applications.",
        "tokens": [
          50560,
          293,
          5821,
          13,
          50660
        ]
      },
      {
        "avg_logprob": -0.2733698887611503,
        "compression_ratio": 1.7310344827586206,
        "end": 4993.5199999999995,
        "id": 1725,
        "no_speech_prob": 0.0000067477540142135695,
        "seek": 498548,
        "start": 4991.4,
        "temperature": 0,
        "text": " And I think of it similarly to, you know,",
        "tokens": [
          50660,
          400,
          286,
          519,
          295,
          309,
          14138,
          281,
          11,
          291,
          458,
          11,
          50766
        ]
      },
      {
        "avg_logprob": -0.2733698887611503,
        "compression_ratio": 1.7310344827586206,
        "end": 4995.839999999999,
        "id": 1726,
        "no_speech_prob": 0.0000067477540142135695,
        "seek": 498548,
        "start": 4993.5199999999995,
        "temperature": 0,
        "text": " there's a little bit of a problem, which make,",
        "tokens": [
          50766,
          456,
          311,
          257,
          707,
          857,
          295,
          257,
          1154,
          11,
          597,
          652,
          11,
          50882
        ]
      },
      {
        "avg_logprob": -0.2733698887611503,
        "compression_ratio": 1.7310344827586206,
        "end": 4999.08,
        "id": 1727,
        "no_speech_prob": 0.0000067477540142135695,
        "seek": 498548,
        "start": 4995.839999999999,
        "temperature": 0,
        "text": " is it implying that other coding is not creative, which I would",
        "tokens": [
          50882,
          307,
          309,
          704,
          7310,
          300,
          661,
          17720,
          307,
          406,
          5880,
          11,
          597,
          286,
          576,
          51044
        ]
      },
      {
        "avg_logprob": -0.2733698887611503,
        "compression_ratio": 1.7310344827586206,
        "end": 5000.32,
        "id": 1728,
        "no_speech_prob": 0.0000067477540142135695,
        "seek": 498548,
        "start": 4999.08,
        "temperature": 0,
        "text": " say is absolutely not true.",
        "tokens": [
          51044,
          584,
          307,
          3122,
          406,
          2074,
          13,
          51106
        ]
      },
      {
        "avg_logprob": -0.2733698887611503,
        "compression_ratio": 1.7310344827586206,
        "end": 5003.44,
        "id": 1729,
        "no_speech_prob": 0.0000067477540142135695,
        "seek": 498548,
        "start": 5000.32,
        "temperature": 0,
        "text": " I mean, all coding is creative.",
        "tokens": [
          51106,
          286,
          914,
          11,
          439,
          17720,
          307,
          5880,
          13,
          51262
        ]
      },
      {
        "avg_logprob": -0.2733698887611503,
        "compression_ratio": 1.7310344827586206,
        "end": 5005.2,
        "id": 1730,
        "no_speech_prob": 0.0000067477540142135695,
        "seek": 498548,
        "start": 5003.44,
        "temperature": 0,
        "text": " But there's a certain distinction",
        "tokens": [
          51262,
          583,
          456,
          311,
          257,
          1629,
          16844,
          51350
        ]
      },
      {
        "avg_logprob": -0.2733698887611503,
        "compression_ratio": 1.7310344827586206,
        "end": 5007.08,
        "id": 1731,
        "no_speech_prob": 0.0000067477540142135695,
        "seek": 498548,
        "start": 5005.2,
        "temperature": 0,
        "text": " that is similar if you say creative writing.",
        "tokens": [
          51350,
          300,
          307,
          2531,
          498,
          291,
          584,
          5880,
          3579,
          13,
          51444
        ]
      },
      {
        "avg_logprob": -0.2733698887611503,
        "compression_ratio": 1.7310344827586206,
        "end": 5009.12,
        "id": 1732,
        "no_speech_prob": 0.0000067477540142135695,
        "seek": 498548,
        "start": 5007.08,
        "temperature": 0,
        "text": " You kind of get a sense of like, oh, maybe you're",
        "tokens": [
          51444,
          509,
          733,
          295,
          483,
          257,
          2020,
          295,
          411,
          11,
          1954,
          11,
          1310,
          291,
          434,
          51546
        ]
      },
      {
        "avg_logprob": -0.2733698887611503,
        "compression_ratio": 1.7310344827586206,
        "end": 5011.919999999999,
        "id": 1733,
        "no_speech_prob": 0.0000067477540142135695,
        "seek": 498548,
        "start": 5009.12,
        "temperature": 0,
        "text": " writing poems or novels or fiction, which",
        "tokens": [
          51546,
          3579,
          24014,
          420,
          24574,
          420,
          13266,
          11,
          597,
          51686
        ]
      },
      {
        "avg_logprob": -0.2733698887611503,
        "compression_ratio": 1.7310344827586206,
        "end": 5014.08,
        "id": 1734,
        "no_speech_prob": 0.0000067477540142135695,
        "seek": 498548,
        "start": 5011.919999999999,
        "temperature": 0,
        "text": " is different than maybe writing for journalism.",
        "tokens": [
          51686,
          307,
          819,
          813,
          1310,
          3579,
          337,
          23191,
          13,
          51794
        ]
      },
      {
        "avg_logprob": -0.25933139580340425,
        "compression_ratio": 1.547244094488189,
        "end": 5016.68,
        "id": 1735,
        "no_speech_prob": 0.00003373699291842058,
        "seek": 501408,
        "start": 5014.08,
        "temperature": 0,
        "text": " But writing for journalism is a creative as well.",
        "tokens": [
          50364,
          583,
          3579,
          337,
          23191,
          307,
          257,
          5880,
          382,
          731,
          13,
          50494
        ]
      },
      {
        "avg_logprob": -0.25933139580340425,
        "compression_ratio": 1.547244094488189,
        "end": 5019.5599999999995,
        "id": 1736,
        "no_speech_prob": 0.00003373699291842058,
        "seek": 501408,
        "start": 5016.68,
        "temperature": 0,
        "text": " But it just kind of codifies at least,",
        "tokens": [
          50494,
          583,
          309,
          445,
          733,
          295,
          17656,
          11221,
          412,
          1935,
          11,
          50638
        ]
      },
      {
        "avg_logprob": -0.25933139580340425,
        "compression_ratio": 1.547244094488189,
        "end": 5023.36,
        "id": 1737,
        "no_speech_prob": 0.00003373699291842058,
        "seek": 501408,
        "start": 5019.5599999999995,
        "temperature": 0,
        "text": " gives some context to what the context is.",
        "tokens": [
          50638,
          2709,
          512,
          4319,
          281,
          437,
          264,
          4319,
          307,
          13,
          50828
        ]
      },
      {
        "avg_logprob": -0.25933139580340425,
        "compression_ratio": 1.547244094488189,
        "end": 5026.92,
        "id": 1738,
        "no_speech_prob": 0.00003373699291842058,
        "seek": 501408,
        "start": 5023.36,
        "temperature": 0,
        "text": " And so I like to use creative coding as a term.",
        "tokens": [
          50828,
          400,
          370,
          286,
          411,
          281,
          764,
          5880,
          17720,
          382,
          257,
          1433,
          13,
          51006
        ]
      },
      {
        "avg_logprob": -0.25933139580340425,
        "compression_ratio": 1.547244094488189,
        "end": 5027.72,
        "id": 1739,
        "no_speech_prob": 0.00003373699291842058,
        "seek": 501408,
        "start": 5026.92,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51006,
          865,
          13,
          51046
        ]
      },
      {
        "avg_logprob": -0.25933139580340425,
        "compression_ratio": 1.547244094488189,
        "end": 5029.5599999999995,
        "id": 1740,
        "no_speech_prob": 0.00003373699291842058,
        "seek": 501408,
        "start": 5027.72,
        "temperature": 0,
        "text": " What did I miss?",
        "tokens": [
          51046,
          708,
          630,
          286,
          1713,
          30,
          51138
        ]
      },
      {
        "avg_logprob": -0.25933139580340425,
        "compression_ratio": 1.547244094488189,
        "end": 5030.12,
        "id": 1741,
        "no_speech_prob": 0.00003373699291842058,
        "seek": 501408,
        "start": 5029.5599999999995,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51138,
          2264,
          13,
          51166
        ]
      },
      {
        "avg_logprob": -0.25933139580340425,
        "compression_ratio": 1.547244094488189,
        "end": 5033.04,
        "id": 1742,
        "no_speech_prob": 0.00003373699291842058,
        "seek": 501408,
        "start": 5030.12,
        "temperature": 0,
        "text": " So thank you, everyone, for tuning in.",
        "tokens": [
          51166,
          407,
          1309,
          291,
          11,
          1518,
          11,
          337,
          15164,
          294,
          13,
          51312
        ]
      },
      {
        "avg_logprob": -0.25933139580340425,
        "compression_ratio": 1.547244094488189,
        "end": 5038,
        "id": 1743,
        "no_speech_prob": 0.00003373699291842058,
        "seek": 501408,
        "start": 5033.04,
        "temperature": 0,
        "text": " Again, I apologize that this was kind of a shorter session",
        "tokens": [
          51312,
          3764,
          11,
          286,
          12328,
          300,
          341,
          390,
          733,
          295,
          257,
          11639,
          5481,
          51560
        ]
      },
      {
        "avg_logprob": -0.25933139580340425,
        "compression_ratio": 1.547244094488189,
        "end": 5038.48,
        "id": 1744,
        "no_speech_prob": 0.00003373699291842058,
        "seek": 501408,
        "start": 5038,
        "temperature": 0,
        "text": " today.",
        "tokens": [
          51560,
          965,
          13,
          51584
        ]
      },
      {
        "avg_logprob": -0.25933139580340425,
        "compression_ratio": 1.547244094488189,
        "end": 5041.2,
        "id": 1745,
        "no_speech_prob": 0.00003373699291842058,
        "seek": 501408,
        "start": 5038.48,
        "temperature": 0,
        "text": " I can see that it was an hour and 23 minutes long.",
        "tokens": [
          51584,
          286,
          393,
          536,
          300,
          309,
          390,
          364,
          1773,
          293,
          6673,
          2077,
          938,
          13,
          51720
        ]
      },
      {
        "avg_logprob": -0.25933139580340425,
        "compression_ratio": 1.547244094488189,
        "end": 5042.6,
        "id": 1746,
        "no_speech_prob": 0.00003373699291842058,
        "seek": 501408,
        "start": 5041.2,
        "temperature": 0,
        "text": " I did have a live stream once.",
        "tokens": [
          51720,
          286,
          630,
          362,
          257,
          1621,
          4309,
          1564,
          13,
          51790
        ]
      },
      {
        "avg_logprob": -0.23984182076375993,
        "compression_ratio": 1.6115107913669064,
        "end": 5044.72,
        "id": 1747,
        "no_speech_prob": 0.1580691784620285,
        "seek": 504260,
        "start": 5042.64,
        "temperature": 0,
        "text": " That was four hours long.",
        "tokens": [
          50366,
          663,
          390,
          1451,
          2496,
          938,
          13,
          50470
        ]
      },
      {
        "avg_logprob": -0.23984182076375993,
        "compression_ratio": 1.6115107913669064,
        "end": 5048.52,
        "id": 1748,
        "no_speech_prob": 0.1580691784620285,
        "seek": 504260,
        "start": 5044.72,
        "temperature": 0,
        "text": " I will be back next week, next Tuesday.",
        "tokens": [
          50470,
          286,
          486,
          312,
          646,
          958,
          1243,
          11,
          958,
          10017,
          13,
          50660
        ]
      },
      {
        "avg_logprob": -0.23984182076375993,
        "compression_ratio": 1.6115107913669064,
        "end": 5050.76,
        "id": 1749,
        "no_speech_prob": 0.1580691784620285,
        "seek": 504260,
        "start": 5048.52,
        "temperature": 0,
        "text": " If I can squeeze a time in before then,",
        "tokens": [
          50660,
          759,
          286,
          393,
          13578,
          257,
          565,
          294,
          949,
          550,
          11,
          50772
        ]
      },
      {
        "avg_logprob": -0.23984182076375993,
        "compression_ratio": 1.6115107913669064,
        "end": 5052.92,
        "id": 1750,
        "no_speech_prob": 0.1580691784620285,
        "seek": 504260,
        "start": 5050.76,
        "temperature": 0,
        "text": " I would absolutely love to.",
        "tokens": [
          50772,
          286,
          576,
          3122,
          959,
          281,
          13,
          50880
        ]
      },
      {
        "avg_logprob": -0.23984182076375993,
        "compression_ratio": 1.6115107913669064,
        "end": 5056,
        "id": 1751,
        "no_speech_prob": 0.1580691784620285,
        "seek": 504260,
        "start": 5052.92,
        "temperature": 0,
        "text": " I'm trying to figure out ways to have more time to do this,",
        "tokens": [
          50880,
          286,
          478,
          1382,
          281,
          2573,
          484,
          2098,
          281,
          362,
          544,
          565,
          281,
          360,
          341,
          11,
          51034
        ]
      },
      {
        "avg_logprob": -0.23984182076375993,
        "compression_ratio": 1.6115107913669064,
        "end": 5058.4800000000005,
        "id": 1752,
        "no_speech_prob": 0.1580691784620285,
        "seek": 504260,
        "start": 5056,
        "temperature": 0,
        "text": " because I quite enjoy it.",
        "tokens": [
          51034,
          570,
          286,
          1596,
          2103,
          309,
          13,
          51158
        ]
      },
      {
        "avg_logprob": -0.23984182076375993,
        "compression_ratio": 1.6115107913669064,
        "end": 5060.240000000001,
        "id": 1753,
        "no_speech_prob": 0.1580691784620285,
        "seek": 504260,
        "start": 5058.4800000000005,
        "temperature": 0,
        "text": " But it does take a lot of time and energy.",
        "tokens": [
          51158,
          583,
          309,
          775,
          747,
          257,
          688,
          295,
          565,
          293,
          2281,
          13,
          51246
        ]
      },
      {
        "avg_logprob": -0.23984182076375993,
        "compression_ratio": 1.6115107913669064,
        "end": 5062.200000000001,
        "id": 1754,
        "no_speech_prob": 0.1580691784620285,
        "seek": 504260,
        "start": 5060.240000000001,
        "temperature": 0,
        "text": " And certainly having the support,",
        "tokens": [
          51246,
          400,
          3297,
          1419,
          264,
          1406,
          11,
          51344
        ]
      },
      {
        "avg_logprob": -0.23984182076375993,
        "compression_ratio": 1.6115107913669064,
        "end": 5065.320000000001,
        "id": 1755,
        "no_speech_prob": 0.1580691784620285,
        "seek": 504260,
        "start": 5062.200000000001,
        "temperature": 0,
        "text": " the friendly feedback, the constructive feedback,",
        "tokens": [
          51344,
          264,
          9208,
          5824,
          11,
          264,
          30223,
          5824,
          11,
          51500
        ]
      },
      {
        "avg_logprob": -0.23984182076375993,
        "compression_ratio": 1.6115107913669064,
        "end": 5069.84,
        "id": 1756,
        "no_speech_prob": 0.1580691784620285,
        "seek": 504260,
        "start": 5065.320000000001,
        "temperature": 0,
        "text": " the critical feedback is always helpful and appreciated.",
        "tokens": [
          51500,
          264,
          4924,
          5824,
          307,
          1009,
          4961,
          293,
          17169,
          13,
          51726
        ]
      },
      {
        "avg_logprob": -0.23984182076375993,
        "compression_ratio": 1.6115107913669064,
        "end": 5072.360000000001,
        "id": 1757,
        "no_speech_prob": 0.1580691784620285,
        "seek": 504260,
        "start": 5069.84,
        "temperature": 0,
        "text": " Please, if you feel so inclined, and there's",
        "tokens": [
          51726,
          2555,
          11,
          498,
          291,
          841,
          370,
          28173,
          11,
          293,
          456,
          311,
          51852
        ]
      },
      {
        "avg_logprob": -0.3167992568597561,
        "compression_ratio": 1.6625386996904026,
        "end": 5075.839999999999,
        "id": 1758,
        "no_speech_prob": 0.3309279680252075,
        "seek": 507236,
        "start": 5073.12,
        "temperature": 0,
        "text": " a place to write a review, honest reviews only,",
        "tokens": [
          50402,
          257,
          1081,
          281,
          2464,
          257,
          3131,
          11,
          3245,
          10229,
          787,
          11,
          50538
        ]
      },
      {
        "avg_logprob": -0.3167992568597561,
        "compression_ratio": 1.6625386996904026,
        "end": 5076.679999999999,
        "id": 1759,
        "no_speech_prob": 0.3309279680252075,
        "seek": 507236,
        "start": 5075.839999999999,
        "temperature": 0,
        "text": " I would tell you to.",
        "tokens": [
          50538,
          286,
          576,
          980,
          291,
          281,
          13,
          50580
        ]
      },
      {
        "avg_logprob": -0.3167992568597561,
        "compression_ratio": 1.6625386996904026,
        "end": 5079.16,
        "id": 1760,
        "no_speech_prob": 0.3309279680252075,
        "seek": 507236,
        "start": 5076.679999999999,
        "temperature": 0,
        "text": " But I don't think you can write reviews of YouTube channels.",
        "tokens": [
          50580,
          583,
          286,
          500,
          380,
          519,
          291,
          393,
          2464,
          10229,
          295,
          3088,
          9235,
          13,
          50704
        ]
      },
      {
        "avg_logprob": -0.3167992568597561,
        "compression_ratio": 1.6625386996904026,
        "end": 5081.5199999999995,
        "id": 1761,
        "no_speech_prob": 0.3309279680252075,
        "seek": 507236,
        "start": 5079.16,
        "temperature": 0,
        "text": " But share if you have a chance to share,",
        "tokens": [
          50704,
          583,
          2073,
          498,
          291,
          362,
          257,
          2931,
          281,
          2073,
          11,
          50822
        ]
      },
      {
        "avg_logprob": -0.3167992568597561,
        "compression_ratio": 1.6625386996904026,
        "end": 5082.88,
        "id": 1762,
        "no_speech_prob": 0.3309279680252075,
        "seek": 507236,
        "start": 5081.5199999999995,
        "temperature": 0,
        "text": " if you like what I'm doing.",
        "tokens": [
          50822,
          498,
          291,
          411,
          437,
          286,
          478,
          884,
          13,
          50890
        ]
      },
      {
        "avg_logprob": -0.3167992568597561,
        "compression_ratio": 1.6625386996904026,
        "end": 5085.32,
        "id": 1763,
        "no_speech_prob": 0.3309279680252075,
        "seek": 507236,
        "start": 5082.88,
        "temperature": 0,
        "text": " Or hit the Like button, that kind of thing.",
        "tokens": [
          50890,
          1610,
          2045,
          264,
          1743,
          2960,
          11,
          300,
          733,
          295,
          551,
          13,
          51012
        ]
      },
      {
        "avg_logprob": -0.3167992568597561,
        "compression_ratio": 1.6625386996904026,
        "end": 5088.12,
        "id": 1764,
        "no_speech_prob": 0.3309279680252075,
        "seek": 507236,
        "start": 5085.32,
        "temperature": 0,
        "text": " It certainly helps other people find the channel,",
        "tokens": [
          51012,
          467,
          3297,
          3665,
          661,
          561,
          915,
          264,
          2269,
          11,
          51152
        ]
      },
      {
        "avg_logprob": -0.3167992568597561,
        "compression_ratio": 1.6625386996904026,
        "end": 5091.4,
        "id": 1765,
        "no_speech_prob": 0.3309279680252075,
        "seek": 507236,
        "start": 5088.12,
        "temperature": 0,
        "text": " which makes it easier for me to do this stuff with more things.",
        "tokens": [
          51152,
          597,
          1669,
          309,
          3571,
          337,
          385,
          281,
          360,
          341,
          1507,
          365,
          544,
          721,
          13,
          51316
        ]
      },
      {
        "avg_logprob": -0.3167992568597561,
        "compression_ratio": 1.6625386996904026,
        "end": 5092,
        "id": 1766,
        "no_speech_prob": 0.3309279680252075,
        "seek": 507236,
        "start": 5091.4,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51316,
          865,
          13,
          51346
        ]
      },
      {
        "avg_logprob": -0.3167992568597561,
        "compression_ratio": 1.6625386996904026,
        "end": 5095.44,
        "id": 1767,
        "no_speech_prob": 0.3309279680252075,
        "seek": 507236,
        "start": 5092,
        "temperature": 0,
        "text": " Oh, by the way, next Tuesday, oh my, is election day.",
        "tokens": [
          51346,
          876,
          11,
          538,
          264,
          636,
          11,
          958,
          10017,
          11,
          1954,
          452,
          11,
          307,
          6618,
          786,
          13,
          51518
        ]
      },
      {
        "avg_logprob": -0.3167992568597561,
        "compression_ratio": 1.6625386996904026,
        "end": 5097.32,
        "id": 1768,
        "no_speech_prob": 0.3309279680252075,
        "seek": 507236,
        "start": 5095.44,
        "temperature": 0,
        "text": " And I'm about to have, I'm going to seriously,",
        "tokens": [
          51518,
          400,
          286,
          478,
          466,
          281,
          362,
          11,
          286,
          478,
          516,
          281,
          6638,
          11,
          51612
        ]
      },
      {
        "avg_logprob": -0.3167992568597561,
        "compression_ratio": 1.6625386996904026,
        "end": 5100.32,
        "id": 1769,
        "no_speech_prob": 0.3309279680252075,
        "seek": 507236,
        "start": 5097.32,
        "temperature": 0,
        "text": " where's my anti-anxiety medication?",
        "tokens": [
          51612,
          689,
          311,
          452,
          6061,
          12,
          282,
          87,
          4014,
          13851,
          30,
          51762
        ]
      },
      {
        "avg_logprob": -0.3167992568597561,
        "compression_ratio": 1.6625386996904026,
        "end": 5101.32,
        "id": 1770,
        "no_speech_prob": 0.3309279680252075,
        "seek": 507236,
        "start": 5100.32,
        "temperature": 0,
        "text": " Oh, the camera went off.",
        "tokens": [
          51762,
          876,
          11,
          264,
          2799,
          1437,
          766,
          13,
          51812
        ]
      },
      {
        "avg_logprob": -0.3167992568597561,
        "compression_ratio": 1.6625386996904026,
        "end": 5101.839999999999,
        "id": 1771,
        "no_speech_prob": 0.3309279680252075,
        "seek": 507236,
        "start": 5101.32,
        "temperature": 0,
        "text": " That's good.",
        "tokens": [
          51812,
          663,
          311,
          665,
          13,
          51838
        ]
      },
      {
        "avg_logprob": -0.24857894234035327,
        "compression_ratio": 1.6666666666666667,
        "end": 5104.4400000000005,
        "id": 1772,
        "no_speech_prob": 0.020962629467248917,
        "seek": 510184,
        "start": 5101.84,
        "temperature": 0,
        "text": " So I think I will be broadcasting live",
        "tokens": [
          50364,
          407,
          286,
          519,
          286,
          486,
          312,
          30024,
          1621,
          50494
        ]
      },
      {
        "avg_logprob": -0.24857894234035327,
        "compression_ratio": 1.6666666666666667,
        "end": 5105.88,
        "id": 1773,
        "no_speech_prob": 0.020962629467248917,
        "seek": 510184,
        "start": 5104.4400000000005,
        "temperature": 0,
        "text": " on election day.",
        "tokens": [
          50494,
          322,
          6618,
          786,
          13,
          50566
        ]
      },
      {
        "avg_logprob": -0.24857894234035327,
        "compression_ratio": 1.6666666666666667,
        "end": 5108.16,
        "id": 1774,
        "no_speech_prob": 0.020962629467248917,
        "seek": 510184,
        "start": 5105.88,
        "temperature": 0,
        "text": " I don't think I'm going to do any sort of election themed",
        "tokens": [
          50566,
          286,
          500,
          380,
          519,
          286,
          478,
          516,
          281,
          360,
          604,
          1333,
          295,
          6618,
          33920,
          50680
        ]
      },
      {
        "avg_logprob": -0.24857894234035327,
        "compression_ratio": 1.6666666666666667,
        "end": 5109.28,
        "id": 1775,
        "no_speech_prob": 0.020962629467248917,
        "seek": 510184,
        "start": 5108.16,
        "temperature": 0,
        "text": " content.",
        "tokens": [
          50680,
          2701,
          13,
          50736
        ]
      },
      {
        "avg_logprob": -0.24857894234035327,
        "compression_ratio": 1.6666666666666667,
        "end": 5111.88,
        "id": 1776,
        "no_speech_prob": 0.020962629467248917,
        "seek": 510184,
        "start": 5109.28,
        "temperature": 0,
        "text": " It is, by the way, I forgot to mention",
        "tokens": [
          50736,
          467,
          307,
          11,
          538,
          264,
          636,
          11,
          286,
          5298,
          281,
          2152,
          50866
        ]
      },
      {
        "avg_logprob": -0.24857894234035327,
        "compression_ratio": 1.6666666666666667,
        "end": 5114.16,
        "id": 1777,
        "no_speech_prob": 0.020962629467248917,
        "seek": 510184,
        "start": 5111.88,
        "temperature": 0,
        "text": " that it is nano-genmo, which I think,",
        "tokens": [
          50866,
          300,
          309,
          307,
          30129,
          12,
          1766,
          3280,
          11,
          597,
          286,
          519,
          11,
          50980
        ]
      },
      {
        "avg_logprob": -0.24857894234035327,
        "compression_ratio": 1.6666666666666667,
        "end": 5117.08,
        "id": 1778,
        "no_speech_prob": 0.020962629467248917,
        "seek": 510184,
        "start": 5114.16,
        "temperature": 0,
        "text": " did I say that right, which is generate a novel month.",
        "tokens": [
          50980,
          630,
          286,
          584,
          300,
          558,
          11,
          597,
          307,
          8460,
          257,
          7613,
          1618,
          13,
          51126
        ]
      },
      {
        "avg_logprob": -0.24857894234035327,
        "compression_ratio": 1.6666666666666667,
        "end": 5118.92,
        "id": 1779,
        "no_speech_prob": 0.020962629467248917,
        "seek": 510184,
        "start": 5117.08,
        "temperature": 0,
        "text": " So all the stuff that I'm doing, I maybe",
        "tokens": [
          51126,
          407,
          439,
          264,
          1507,
          300,
          286,
          478,
          884,
          11,
          286,
          1310,
          51218
        ]
      },
      {
        "avg_logprob": -0.24857894234035327,
        "compression_ratio": 1.6666666666666667,
        "end": 5122.08,
        "id": 1780,
        "no_speech_prob": 0.020962629467248917,
        "seek": 510184,
        "start": 5118.92,
        "temperature": 0,
        "text": " should give that as a challenge.",
        "tokens": [
          51218,
          820,
          976,
          300,
          382,
          257,
          3430,
          13,
          51376
        ]
      },
      {
        "avg_logprob": -0.24857894234035327,
        "compression_ratio": 1.6666666666666667,
        "end": 5124.32,
        "id": 1781,
        "no_speech_prob": 0.020962629467248917,
        "seek": 510184,
        "start": 5122.08,
        "temperature": 0,
        "text": " My Twitter is at Schiffman.",
        "tokens": [
          51376,
          1222,
          5794,
          307,
          412,
          2065,
          3661,
          1601,
          13,
          51488
        ]
      },
      {
        "avg_logprob": -0.24857894234035327,
        "compression_ratio": 1.6666666666666667,
        "end": 5127.56,
        "id": 1782,
        "no_speech_prob": 0.020962629467248917,
        "seek": 510184,
        "start": 5124.32,
        "temperature": 0,
        "text": " Maybe I'll think of something election related.",
        "tokens": [
          51488,
          2704,
          286,
          603,
          519,
          295,
          746,
          6618,
          4077,
          13,
          51650
        ]
      },
      {
        "avg_logprob": -0.24857894234035327,
        "compression_ratio": 1.6666666666666667,
        "end": 5131.6,
        "id": 1783,
        "no_speech_prob": 0.020962629467248917,
        "seek": 510184,
        "start": 5127.56,
        "temperature": 0,
        "text": " But I think I'll probably just continue with this API thing.",
        "tokens": [
          51650,
          583,
          286,
          519,
          286,
          603,
          1391,
          445,
          2354,
          365,
          341,
          9362,
          551,
          13,
          51852
        ]
      },
      {
        "avg_logprob": -0.27651806200964973,
        "compression_ratio": 1.6235294117647059,
        "end": 5132.56,
        "id": 1784,
        "no_speech_prob": 0.005554551258683205,
        "seek": 513160,
        "start": 5131.6,
        "temperature": 0,
        "text": " We'll see how it goes.",
        "tokens": [
          50364,
          492,
          603,
          536,
          577,
          309,
          1709,
          13,
          50412
        ]
      },
      {
        "avg_logprob": -0.27651806200964973,
        "compression_ratio": 1.6235294117647059,
        "end": 5133.92,
        "id": 1785,
        "no_speech_prob": 0.005554551258683205,
        "seek": 513160,
        "start": 5132.56,
        "temperature": 0,
        "text": " So thank you guys for tuning in.",
        "tokens": [
          50412,
          407,
          1309,
          291,
          1074,
          337,
          15164,
          294,
          13,
          50480
        ]
      },
      {
        "avg_logprob": -0.27651806200964973,
        "compression_ratio": 1.6235294117647059,
        "end": 5136.04,
        "id": 1786,
        "no_speech_prob": 0.005554551258683205,
        "seek": 513160,
        "start": 5133.92,
        "temperature": 0,
        "text": " I'm sorry, again, today was a little bit shorter.",
        "tokens": [
          50480,
          286,
          478,
          2597,
          11,
          797,
          11,
          965,
          390,
          257,
          707,
          857,
          11639,
          13,
          50586
        ]
      },
      {
        "avg_logprob": -0.27651806200964973,
        "compression_ratio": 1.6235294117647059,
        "end": 5137.46,
        "id": 1787,
        "no_speech_prob": 0.005554551258683205,
        "seek": 513160,
        "start": 5136.04,
        "temperature": 0,
        "text": " I would love to have a conference.",
        "tokens": [
          50586,
          286,
          576,
          959,
          281,
          362,
          257,
          7586,
          13,
          50657
        ]
      },
      {
        "avg_logprob": -0.27651806200964973,
        "compression_ratio": 1.6235294117647059,
        "end": 5140.68,
        "id": 1788,
        "no_speech_prob": 0.005554551258683205,
        "seek": 513160,
        "start": 5137.46,
        "temperature": 0,
        "text": " Oh, let me just plug something for no apparent reason.",
        "tokens": [
          50657,
          876,
          11,
          718,
          385,
          445,
          5452,
          746,
          337,
          572,
          18335,
          1778,
          13,
          50818
        ]
      },
      {
        "avg_logprob": -0.27651806200964973,
        "compression_ratio": 1.6235294117647059,
        "end": 5142.08,
        "id": 1789,
        "no_speech_prob": 0.005554551258683205,
        "seek": 513160,
        "start": 5140.68,
        "temperature": 0,
        "text": " But someone mentioned conference.",
        "tokens": [
          50818,
          583,
          1580,
          2835,
          7586,
          13,
          50888
        ]
      },
      {
        "avg_logprob": -0.27651806200964973,
        "compression_ratio": 1.6235294117647059,
        "end": 5145.6,
        "id": 1790,
        "no_speech_prob": 0.005554551258683205,
        "seek": 513160,
        "start": 5142.08,
        "temperature": 0,
        "text": " There is a conference coming up called Code Land, which",
        "tokens": [
          50888,
          821,
          307,
          257,
          7586,
          1348,
          493,
          1219,
          15549,
          6607,
          11,
          597,
          51064
        ]
      },
      {
        "avg_logprob": -0.27651806200964973,
        "compression_ratio": 1.6235294117647059,
        "end": 5149.120000000001,
        "id": 1791,
        "no_speech_prob": 0.005554551258683205,
        "seek": 513160,
        "start": 5145.6,
        "temperature": 0,
        "text": " is the Code Newbies Conference.",
        "tokens": [
          51064,
          307,
          264,
          15549,
          1873,
          23177,
          22131,
          13,
          51240
        ]
      },
      {
        "avg_logprob": -0.27651806200964973,
        "compression_ratio": 1.6235294117647059,
        "end": 5152.200000000001,
        "id": 1792,
        "no_speech_prob": 0.005554551258683205,
        "seek": 513160,
        "start": 5149.120000000001,
        "temperature": 0,
        "text": " Maybe it is not, maybe there is not a website for it yet.",
        "tokens": [
          51240,
          2704,
          309,
          307,
          406,
          11,
          1310,
          456,
          307,
          406,
          257,
          3144,
          337,
          309,
          1939,
          13,
          51394
        ]
      },
      {
        "avg_logprob": -0.27651806200964973,
        "compression_ratio": 1.6235294117647059,
        "end": 5153.780000000001,
        "id": 1793,
        "no_speech_prob": 0.005554551258683205,
        "seek": 513160,
        "start": 5152.200000000001,
        "temperature": 0,
        "text": " But I'm going to look here on Twitter.",
        "tokens": [
          51394,
          583,
          286,
          478,
          516,
          281,
          574,
          510,
          322,
          5794,
          13,
          51473
        ]
      },
      {
        "avg_logprob": -0.31635149905556126,
        "compression_ratio": 1.431924882629108,
        "end": 5161.9,
        "id": 1794,
        "no_speech_prob": 0.021946702152490616,
        "seek": 515378,
        "start": 5154.78,
        "temperature": 0,
        "text": " So this is April 21st and 22nd, 2017 in New York City.",
        "tokens": [
          50414,
          407,
          341,
          307,
          6929,
          5080,
          372,
          293,
          5853,
          273,
          11,
          6591,
          294,
          1873,
          3609,
          4392,
          13,
          50770
        ]
      },
      {
        "avg_logprob": -0.31635149905556126,
        "compression_ratio": 1.431924882629108,
        "end": 5164.82,
        "id": 1795,
        "no_speech_prob": 0.021946702152490616,
        "seek": 515378,
        "start": 5161.9,
        "temperature": 0,
        "text": " The reason why I mentioned it is I don't want to be so bold.",
        "tokens": [
          50770,
          440,
          1778,
          983,
          286,
          2835,
          309,
          307,
          286,
          500,
          380,
          528,
          281,
          312,
          370,
          11928,
          13,
          50916
        ]
      },
      {
        "avg_logprob": -0.31635149905556126,
        "compression_ratio": 1.431924882629108,
        "end": 5168.82,
        "id": 1796,
        "no_speech_prob": 0.021946702152490616,
        "seek": 515378,
        "start": 5164.82,
        "temperature": 0,
        "text": " But I feel like I've gone to some Code Newbies event.",
        "tokens": [
          50916,
          583,
          286,
          841,
          411,
          286,
          600,
          2780,
          281,
          512,
          15549,
          1873,
          23177,
          2280,
          13,
          51116
        ]
      },
      {
        "avg_logprob": -0.31635149905556126,
        "compression_ratio": 1.431924882629108,
        "end": 5171.099999999999,
        "id": 1797,
        "no_speech_prob": 0.021946702152490616,
        "seek": 515378,
        "start": 5168.82,
        "temperature": 0,
        "text": " I listened to the Code Newbies podcast.",
        "tokens": [
          51116,
          286,
          13207,
          281,
          264,
          15549,
          1873,
          23177,
          7367,
          13,
          51230
        ]
      },
      {
        "avg_logprob": -0.31635149905556126,
        "compression_ratio": 1.431924882629108,
        "end": 5174.099999999999,
        "id": 1798,
        "no_speech_prob": 0.021946702152490616,
        "seek": 515378,
        "start": 5171.099999999999,
        "temperature": 0,
        "text": " Saren, I think I just said her name incorrectly.",
        "tokens": [
          51230,
          318,
          4484,
          11,
          286,
          519,
          286,
          445,
          848,
          720,
          1315,
          42892,
          13,
          51380
        ]
      },
      {
        "avg_logprob": -0.31635149905556126,
        "compression_ratio": 1.431924882629108,
        "end": 5179.78,
        "id": 1799,
        "no_speech_prob": 0.021946702152490616,
        "seek": 515378,
        "start": 5177.42,
        "temperature": 0,
        "text": " Saron, oh my goodness, I'm just like blanking.",
        "tokens": [
          51546,
          318,
          6372,
          11,
          1954,
          452,
          8387,
          11,
          286,
          478,
          445,
          411,
          8247,
          278,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.26040974863759286,
        "compression_ratio": 1.6560509554140128,
        "end": 5184.139999999999,
        "id": 1800,
        "no_speech_prob": 0.008845317177474499,
        "seek": 517978,
        "start": 5180.219999999999,
        "temperature": 0,
        "text": " The woman who runs Code Newbies is absolutely wonderful.",
        "tokens": [
          50386,
          440,
          3059,
          567,
          6676,
          15549,
          1873,
          23177,
          307,
          3122,
          3715,
          13,
          50582
        ]
      },
      {
        "avg_logprob": -0.26040974863759286,
        "compression_ratio": 1.6560509554140128,
        "end": 5186.139999999999,
        "id": 1801,
        "no_speech_prob": 0.008845317177474499,
        "seek": 517978,
        "start": 5184.139999999999,
        "temperature": 0,
        "text": " She's created an amazing community.",
        "tokens": [
          50582,
          1240,
          311,
          2942,
          364,
          2243,
          1768,
          13,
          50682
        ]
      },
      {
        "avg_logprob": -0.26040974863759286,
        "compression_ratio": 1.6560509554140128,
        "end": 5188.0199999999995,
        "id": 1802,
        "no_speech_prob": 0.008845317177474499,
        "seek": 517978,
        "start": 5186.139999999999,
        "temperature": 0,
        "text": " So I feel like if I were to run a conference,",
        "tokens": [
          50682,
          407,
          286,
          841,
          411,
          498,
          286,
          645,
          281,
          1190,
          257,
          7586,
          11,
          50776
        ]
      },
      {
        "avg_logprob": -0.26040974863759286,
        "compression_ratio": 1.6560509554140128,
        "end": 5190.259999999999,
        "id": 1803,
        "no_speech_prob": 0.008845317177474499,
        "seek": 517978,
        "start": 5188.0199999999995,
        "temperature": 0,
        "text": " I would hope that it would have the spirit and community",
        "tokens": [
          50776,
          286,
          576,
          1454,
          300,
          309,
          576,
          362,
          264,
          3797,
          293,
          1768,
          50888
        ]
      },
      {
        "avg_logprob": -0.26040974863759286,
        "compression_ratio": 1.6560509554140128,
        "end": 5193.179999999999,
        "id": 1804,
        "no_speech_prob": 0.008845317177474499,
        "seek": 517978,
        "start": 5190.259999999999,
        "temperature": 0,
        "text": " that I expect this conference to have.",
        "tokens": [
          50888,
          300,
          286,
          2066,
          341,
          7586,
          281,
          362,
          13,
          51034
        ]
      },
      {
        "avg_logprob": -0.26040974863759286,
        "compression_ratio": 1.6560509554140128,
        "end": 5195.219999999999,
        "id": 1805,
        "no_speech_prob": 0.008845317177474499,
        "seek": 517978,
        "start": 5193.179999999999,
        "temperature": 0,
        "text": " And so I would encourage you to think about that.",
        "tokens": [
          51034,
          400,
          370,
          286,
          576,
          5373,
          291,
          281,
          519,
          466,
          300,
          13,
          51136
        ]
      },
      {
        "avg_logprob": -0.26040974863759286,
        "compression_ratio": 1.6560509554140128,
        "end": 5197.98,
        "id": 1806,
        "no_speech_prob": 0.008845317177474499,
        "seek": 517978,
        "start": 5195.219999999999,
        "temperature": 0,
        "text": " I hope to attend, although I'm not sure 100%.",
        "tokens": [
          51136,
          286,
          1454,
          281,
          6888,
          11,
          4878,
          286,
          478,
          406,
          988,
          2319,
          6856,
          51274
        ]
      },
      {
        "avg_logprob": -0.26040974863759286,
        "compression_ratio": 1.6560509554140128,
        "end": 5202,
        "id": 1807,
        "no_speech_prob": 0.008845317177474499,
        "seek": 517978,
        "start": 5197.98,
        "temperature": 0,
        "text": " But I would love to see any of you if you're in New York City",
        "tokens": [
          51274,
          583,
          286,
          576,
          959,
          281,
          536,
          604,
          295,
          291,
          498,
          291,
          434,
          294,
          1873,
          3609,
          4392,
          51475
        ]
      },
      {
        "avg_logprob": -0.26040974863759286,
        "compression_ratio": 1.6560509554140128,
        "end": 5204.46,
        "id": 1808,
        "no_speech_prob": 0.008845317177474499,
        "seek": 517978,
        "start": 5202,
        "temperature": 0,
        "text": " and meet some of you who are watching.",
        "tokens": [
          51475,
          293,
          1677,
          512,
          295,
          291,
          567,
          366,
          1976,
          13,
          51598
        ]
      },
      {
        "avg_logprob": -0.26040974863759286,
        "compression_ratio": 1.6560509554140128,
        "end": 5207.0599999999995,
        "id": 1809,
        "no_speech_prob": 0.008845317177474499,
        "seek": 517978,
        "start": 5204.46,
        "temperature": 0,
        "text": " OK, yes, it's a bit too far away.",
        "tokens": [
          51598,
          2264,
          11,
          2086,
          11,
          309,
          311,
          257,
          857,
          886,
          1400,
          1314,
          13,
          51728
        ]
      },
      {
        "avg_logprob": -0.26040974863759286,
        "compression_ratio": 1.6560509554140128,
        "end": 5209.3,
        "id": 1810,
        "no_speech_prob": 0.008845317177474499,
        "seek": 517978,
        "start": 5207.0599999999995,
        "temperature": 0,
        "text": " Hopefully, there'll be some conferences in other parts",
        "tokens": [
          51728,
          10429,
          11,
          456,
          603,
          312,
          512,
          22032,
          294,
          661,
          3166,
          51840
        ]
      },
      {
        "avg_logprob": -0.2424884770540583,
        "compression_ratio": 1.6212624584717608,
        "end": 5211.58,
        "id": 1811,
        "no_speech_prob": 0.0032729576341807842,
        "seek": 520930,
        "start": 5209.3,
        "temperature": 0,
        "text": " of the world that we can meet or have a.",
        "tokens": [
          50364,
          295,
          264,
          1002,
          300,
          321,
          393,
          1677,
          420,
          362,
          257,
          13,
          50478
        ]
      },
      {
        "avg_logprob": -0.2424884770540583,
        "compression_ratio": 1.6212624584717608,
        "end": 5214.14,
        "id": 1812,
        "no_speech_prob": 0.0032729576341807842,
        "seek": 520930,
        "start": 5211.58,
        "temperature": 0,
        "text": " Maybe I could do like a, I was about to say coding rain,",
        "tokens": [
          50478,
          2704,
          286,
          727,
          360,
          411,
          257,
          11,
          286,
          390,
          466,
          281,
          584,
          17720,
          4830,
          11,
          50606
        ]
      },
      {
        "avg_logprob": -0.2424884770540583,
        "compression_ratio": 1.6212624584717608,
        "end": 5215.9800000000005,
        "id": 1813,
        "no_speech_prob": 0.0032729576341807842,
        "seek": 520930,
        "start": 5214.14,
        "temperature": 0,
        "text": " but I could do some sort of world tour.",
        "tokens": [
          50606,
          457,
          286,
          727,
          360,
          512,
          1333,
          295,
          1002,
          3512,
          13,
          50698
        ]
      },
      {
        "avg_logprob": -0.2424884770540583,
        "compression_ratio": 1.6212624584717608,
        "end": 5218.26,
        "id": 1814,
        "no_speech_prob": 0.0032729576341807842,
        "seek": 520930,
        "start": 5215.9800000000005,
        "temperature": 0,
        "text": " OK, MacBrick says I have a question.",
        "tokens": [
          50698,
          2264,
          11,
          5707,
          33,
          9323,
          1619,
          286,
          362,
          257,
          1168,
          13,
          50812
        ]
      },
      {
        "avg_logprob": -0.2424884770540583,
        "compression_ratio": 1.6212624584717608,
        "end": 5222.62,
        "id": 1815,
        "no_speech_prob": 0.0032729576341807842,
        "seek": 520930,
        "start": 5218.26,
        "temperature": 0,
        "text": " So I'm waiting for that one question before I go.",
        "tokens": [
          50812,
          407,
          286,
          478,
          3806,
          337,
          300,
          472,
          1168,
          949,
          286,
          352,
          13,
          51030
        ]
      },
      {
        "avg_logprob": -0.2424884770540583,
        "compression_ratio": 1.6212624584717608,
        "end": 5223.46,
        "id": 1816,
        "no_speech_prob": 0.0032729576341807842,
        "seek": 520930,
        "start": 5222.62,
        "temperature": 0,
        "text": " My song ended.",
        "tokens": [
          51030,
          1222,
          2153,
          4590,
          13,
          51072
        ]
      },
      {
        "avg_logprob": -0.2424884770540583,
        "compression_ratio": 1.6212624584717608,
        "end": 5226.62,
        "id": 1817,
        "no_speech_prob": 0.0032729576341807842,
        "seek": 520930,
        "start": 5223.46,
        "temperature": 0,
        "text": " This is usually where I hit Stop the live stream.",
        "tokens": [
          51072,
          639,
          307,
          2673,
          689,
          286,
          2045,
          5535,
          264,
          1621,
          4309,
          13,
          51230
        ]
      },
      {
        "avg_logprob": -0.2424884770540583,
        "compression_ratio": 1.6212624584717608,
        "end": 5228.38,
        "id": 1818,
        "no_speech_prob": 0.0032729576341807842,
        "seek": 520930,
        "start": 5226.62,
        "temperature": 0,
        "text": " But the chat seems to be restful.",
        "tokens": [
          51230,
          583,
          264,
          5081,
          2544,
          281,
          312,
          1472,
          906,
          13,
          51318
        ]
      },
      {
        "avg_logprob": -0.2424884770540583,
        "compression_ratio": 1.6212624584717608,
        "end": 5231.38,
        "id": 1819,
        "no_speech_prob": 0.0032729576341807842,
        "seek": 520930,
        "start": 5228.38,
        "temperature": 0,
        "text": " Yes, that's actually great advice from Coder for Life.",
        "tokens": [
          51318,
          1079,
          11,
          300,
          311,
          767,
          869,
          5192,
          490,
          383,
          19866,
          337,
          7720,
          13,
          51468
        ]
      },
      {
        "avg_logprob": -0.2424884770540583,
        "compression_ratio": 1.6212624584717608,
        "end": 5234.9800000000005,
        "id": 1820,
        "no_speech_prob": 0.0032729576341807842,
        "seek": 520930,
        "start": 5231.38,
        "temperature": 0,
        "text": " Everyone, sleep is really important.",
        "tokens": [
          51468,
          5198,
          11,
          2817,
          307,
          534,
          1021,
          13,
          51648
        ]
      },
      {
        "avg_logprob": -0.2424884770540583,
        "compression_ratio": 1.6212624584717608,
        "end": 5236.26,
        "id": 1821,
        "no_speech_prob": 0.0032729576341807842,
        "seek": 520930,
        "start": 5234.9800000000005,
        "temperature": 0,
        "text": " Your health is really important.",
        "tokens": [
          51648,
          2260,
          1585,
          307,
          534,
          1021,
          13,
          51712
        ]
      },
      {
        "avg_logprob": -0.2424884770540583,
        "compression_ratio": 1.6212624584717608,
        "end": 5237.22,
        "id": 1822,
        "no_speech_prob": 0.0032729576341807842,
        "seek": 520930,
        "start": 5236.26,
        "temperature": 0,
        "text": " Take it easy.",
        "tokens": [
          51712,
          3664,
          309,
          1858,
          13,
          51760
        ]
      },
      {
        "avg_logprob": -0.2424884770540583,
        "compression_ratio": 1.6212624584717608,
        "end": 5239.06,
        "id": 1823,
        "no_speech_prob": 0.0032729576341807842,
        "seek": 520930,
        "start": 5237.22,
        "temperature": 0,
        "text": " Don't try to do too much.",
        "tokens": [
          51760,
          1468,
          380,
          853,
          281,
          360,
          886,
          709,
          13,
          51852
        ]
      },
      {
        "avg_logprob": -0.2895959777832031,
        "compression_ratio": 1.5285714285714285,
        "end": 5240.660000000001,
        "id": 1824,
        "no_speech_prob": 0.000954640912823379,
        "seek": 523906,
        "start": 5239.900000000001,
        "temperature": 0,
        "text": " Give people hugs.",
        "tokens": [
          50406,
          5303,
          561,
          42149,
          13,
          50444
        ]
      },
      {
        "avg_logprob": -0.2895959777832031,
        "compression_ratio": 1.5285714285714285,
        "end": 5246.580000000001,
        "id": 1825,
        "no_speech_prob": 0.000954640912823379,
        "seek": 523906,
        "start": 5243.54,
        "temperature": 0,
        "text": " So yeah, world tour would be great.",
        "tokens": [
          50588,
          407,
          1338,
          11,
          1002,
          3512,
          576,
          312,
          869,
          13,
          50740
        ]
      },
      {
        "avg_logprob": -0.2895959777832031,
        "compression_ratio": 1.5285714285714285,
        "end": 5247.700000000001,
        "id": 1826,
        "no_speech_prob": 0.000954640912823379,
        "seek": 523906,
        "start": 5246.580000000001,
        "temperature": 0,
        "text": " All of you have questions.",
        "tokens": [
          50740,
          1057,
          295,
          291,
          362,
          1651,
          13,
          50796
        ]
      },
      {
        "avg_logprob": -0.2895959777832031,
        "compression_ratio": 1.5285714285714285,
        "end": 5251.3,
        "id": 1827,
        "no_speech_prob": 0.000954640912823379,
        "seek": 523906,
        "start": 5247.700000000001,
        "temperature": 0,
        "text": " So tweet at me your questions at Schiffman.",
        "tokens": [
          50796,
          407,
          15258,
          412,
          385,
          428,
          1651,
          412,
          2065,
          3661,
          1601,
          13,
          50976
        ]
      },
      {
        "avg_logprob": -0.2895959777832031,
        "compression_ratio": 1.5285714285714285,
        "end": 5254.740000000001,
        "id": 1828,
        "no_speech_prob": 0.000954640912823379,
        "seek": 523906,
        "start": 5251.3,
        "temperature": 0,
        "text": " Unfortunately, I'm going to have to say goodbye right now.",
        "tokens": [
          50976,
          8590,
          11,
          286,
          478,
          516,
          281,
          362,
          281,
          584,
          12084,
          558,
          586,
          13,
          51148
        ]
      },
      {
        "avg_logprob": -0.2895959777832031,
        "compression_ratio": 1.5285714285714285,
        "end": 5257.54,
        "id": 1829,
        "no_speech_prob": 0.000954640912823379,
        "seek": 523906,
        "start": 5254.740000000001,
        "temperature": 0,
        "text": " I have to go and pick up some small children",
        "tokens": [
          51148,
          286,
          362,
          281,
          352,
          293,
          1888,
          493,
          512,
          1359,
          2227,
          51288
        ]
      },
      {
        "avg_logprob": -0.2895959777832031,
        "compression_ratio": 1.5285714285714285,
        "end": 5259.620000000001,
        "id": 1830,
        "no_speech_prob": 0.000954640912823379,
        "seek": 523906,
        "start": 5257.54,
        "temperature": 0,
        "text": " from their after school activities.",
        "tokens": [
          51288,
          490,
          641,
          934,
          1395,
          5354,
          13,
          51392
        ]
      },
      {
        "avg_logprob": -0.2895959777832031,
        "compression_ratio": 1.5285714285714285,
        "end": 5260.900000000001,
        "id": 1831,
        "no_speech_prob": 0.000954640912823379,
        "seek": 523906,
        "start": 5259.620000000001,
        "temperature": 0,
        "text": " And I don't want to be late.",
        "tokens": [
          51392,
          400,
          286,
          500,
          380,
          528,
          281,
          312,
          3469,
          13,
          51456
        ]
      },
      {
        "avg_logprob": -0.2895959777832031,
        "compression_ratio": 1.5285714285714285,
        "end": 5263.9400000000005,
        "id": 1832,
        "no_speech_prob": 0.000954640912823379,
        "seek": 523906,
        "start": 5260.900000000001,
        "temperature": 0,
        "text": " Great, John says NPL install NodeMon worked for me.",
        "tokens": [
          51456,
          3769,
          11,
          2619,
          1619,
          426,
          21593,
          3625,
          38640,
          32498,
          2732,
          337,
          385,
          13,
          51608
        ]
      },
      {
        "avg_logprob": -0.2895959777832031,
        "compression_ratio": 1.5285714285714285,
        "end": 5265.38,
        "id": 1833,
        "no_speech_prob": 0.000954640912823379,
        "seek": 523906,
        "start": 5263.9400000000005,
        "temperature": 0,
        "text": " Did you include the dash G?",
        "tokens": [
          51608,
          2589,
          291,
          4090,
          264,
          8240,
          460,
          30,
          51680
        ]
      },
      {
        "avg_logprob": -0.2895959777832031,
        "compression_ratio": 1.5285714285714285,
        "end": 5267.580000000001,
        "id": 1834,
        "no_speech_prob": 0.000954640912823379,
        "seek": 523906,
        "start": 5265.38,
        "temperature": 0,
        "text": " Because you're going to need it to be a global module.",
        "tokens": [
          51680,
          1436,
          291,
          434,
          516,
          281,
          643,
          309,
          281,
          312,
          257,
          4338,
          10088,
          13,
          51790
        ]
      },
      {
        "avg_logprob": -0.23834647384344362,
        "compression_ratio": 1.558139534883721,
        "end": 5269.38,
        "id": 1835,
        "no_speech_prob": 0.0335775651037693,
        "seek": 526758,
        "start": 5267.62,
        "temperature": 0,
        "text": " So I hope to see you guys next week",
        "tokens": [
          50366,
          407,
          286,
          1454,
          281,
          536,
          291,
          1074,
          958,
          1243,
          50454
        ]
      },
      {
        "avg_logprob": -0.23834647384344362,
        "compression_ratio": 1.558139534883721,
        "end": 5272.0199999999995,
        "id": 1836,
        "no_speech_prob": 0.0335775651037693,
        "seek": 526758,
        "start": 5269.38,
        "temperature": 0,
        "text": " or on the internet in some other fashion.",
        "tokens": [
          50454,
          420,
          322,
          264,
          4705,
          294,
          512,
          661,
          6700,
          13,
          50586
        ]
      },
      {
        "avg_logprob": -0.23834647384344362,
        "compression_ratio": 1.558139534883721,
        "end": 5274.62,
        "id": 1837,
        "no_speech_prob": 0.0335775651037693,
        "seek": 526758,
        "start": 5272.0199999999995,
        "temperature": 0,
        "text": " And thanks again for tuning in.",
        "tokens": [
          50586,
          400,
          3231,
          797,
          337,
          15164,
          294,
          13,
          50716
        ]
      },
      {
        "avg_logprob": -0.23834647384344362,
        "compression_ratio": 1.558139534883721,
        "end": 5278.38,
        "id": 1838,
        "no_speech_prob": 0.0335775651037693,
        "seek": 526758,
        "start": 5274.62,
        "temperature": 0,
        "text": " And thanks for School for Poetic Computation",
        "tokens": [
          50716,
          400,
          3231,
          337,
          5070,
          337,
          6165,
          3532,
          37804,
          399,
          50904
        ]
      },
      {
        "avg_logprob": -0.23834647384344362,
        "compression_ratio": 1.558139534883721,
        "end": 5281.26,
        "id": 1839,
        "no_speech_prob": 0.0335775651037693,
        "seek": 526758,
        "start": 5278.38,
        "temperature": 0,
        "text": " for having me in their space, sfpc.io.",
        "tokens": [
          50904,
          337,
          1419,
          385,
          294,
          641,
          1901,
          11,
          47095,
          79,
          66,
          13,
          1004,
          13,
          51048
        ]
      },
      {
        "avg_logprob": -0.23834647384344362,
        "compression_ratio": 1.558139534883721,
        "end": 5285.0199999999995,
        "id": 1840,
        "no_speech_prob": 0.0335775651037693,
        "seek": 526758,
        "start": 5281.26,
        "temperature": 0,
        "text": " Thank you, ITP, itp.nyu.edu, for the students",
        "tokens": [
          51048,
          1044,
          291,
          11,
          6783,
          47,
          11,
          309,
          79,
          13,
          1634,
          84,
          13,
          22938,
          11,
          337,
          264,
          1731,
          51236
        ]
      },
      {
        "avg_logprob": -0.23834647384344362,
        "compression_ratio": 1.558139534883721,
        "end": 5287.46,
        "id": 1841,
        "no_speech_prob": 0.0335775651037693,
        "seek": 526758,
        "start": 5285.0199999999995,
        "temperature": 0,
        "text": " that I wasn't having office hours this afternoon with.",
        "tokens": [
          51236,
          300,
          286,
          2067,
          380,
          1419,
          3398,
          2496,
          341,
          6499,
          365,
          13,
          51358
        ]
      },
      {
        "avg_logprob": -0.23834647384344362,
        "compression_ratio": 1.558139534883721,
        "end": 5290.62,
        "id": 1842,
        "no_speech_prob": 0.0335775651037693,
        "seek": 526758,
        "start": 5287.46,
        "temperature": 0,
        "text": " And I'll see you guys all sometime soon.",
        "tokens": [
          51358,
          400,
          286,
          603,
          536,
          291,
          1074,
          439,
          15053,
          2321,
          13,
          51516
        ]
      }
    ],
    "transcription": " Did you think that learning coding would be really rough? Throw your hands up in the air and say enough's enough! Do you want to learn to code and make some awesome stuff? Learn that anyone can when you're coding with Dan on! Whether you're a pro or this is all brand new, Learn the overarching concepts and some fun stuff too! And with Dan as your guide, come along for the ride on! Make a crazy pixel mirror to reflect your face, You can make a jump to light speed into outer space, You can generate a maze that can go on for days, You can make your own terrain and some purple rain, You can make a retro game to see how it's done, And then tweak a piece to make it yours for everyone, Make some fractally trees or twitter bots if you please, And when the seeds are all sown, you can make them your own! Write the colors of code, you can follow the road too! Hello! Ah, okay, hello! I think I'm broadcasting live. I had the microphone muted, which I often do while I'm getting set up to not record myself by accident, but I would like to hear from the chat. I know I've been sort of on a big delay today, so I would like to hear in the chat. So I don't know how many people are there, because I'm kind of much later than I said I would originally be, but if the sound is working, if you can hear me and see me okay. Otherwise I'm going to kind of get started rather quickly. I'm going to try to forego all of my introductory stuff beyond two or three sentences. So please, if you are actually watching this live and you can hear me and there's no static and the sound seems fine, please let me know in the chat. I don't see a single message in the chat, so I'm just going to keep going. My name is Dan Schiffman. This is a live stream that I do every week, typically Tuesday afternoons about creative coding, and creative coding is kind of a broad term, but to think about creative ways to... I'm still looking in the chat and I don't see a message. I feel like I'm just here by myself and there's no one out there in the world. I'm going to see if there's anyone... It does say 73 people are watching, which is kind of unbelievable. Okay, I'm still keeping an eye on the chat. So I do a lot of different topics from animation and physics simulation, but this fall I have been going through a series of video tutorials all about programming with text, generating text, analyzing text, that type of thing. If you would like to know more or I just want to point you out to a couple resources, codingrainbow.com, you can subscribe. There is also... I have a Patreon running, which is a way that you can fund what I'm doing and get membership into a Slack channel for more discussion, and I do send out email announcements when I'm doing the live streams here as well. So I encourage you to sign up for any of those things. I still don't see a single message in the chat. It's just kind of disturbing me. I'm going to have to tweet because... Maybe I'm going to reload my preview here because I just want to make sure this is working and I'm not talking to no one in thin air. So I'm going to... It does say 100 people are watching. I'm going to refresh my dashboard and see if anyone comes. Ah! Now I see all sorts of messages. So somehow the chat had gotten stuck. Okay. So now I see there are a ton of messages. So much for my awkward opening. All right. So what am I going to do today? So topic-wise, I am here, and it says week 9 here on this syllabus, but really I'm on session 8. And so the topic for today is how to build your own API in Node. So if you have been following this course over however many weeks I've been doing it, I spent a week looking at working with data and APIs. So, for example, how to grab dictionary information from an API called Wordnik, how to get news articles from an API called New York Times... API called New York Times. But what if you have data and you want to expose that data to other people? Or what if you want to collect data and then make that data open? So there are a variety of... Okay. Possibilities. Hold on a second. I'm going to have to... Please, if you can... If you can try not to post the same message over and over and over again. Abby is asking if I can go over modularity, which I don't know what that means specifically. But chat-wise, I can't catch every message in the chat, but I do look at it periodically. And I will try to answer them as I go. Nikolai asks, what about the new channel name? I don't have a new channel name yet. I have to admit that things are just incredibly busy these days with the NYU semester. And I hope to... I've been talking to some designers and coming up with different ideas and brainstorming things. And I hope to have something by the end of the year. It's my goal and kind of relaunch in 2017 with a new name. Yes, if it's hearts and rainbows, that you can spam. And can you explain a REST API? That is what I hope to do today. Now, unfortunately, it's about 3.10. I only have till 4.30 PM. It's Eastern time. So I have about an hour and 20 minutes. And I have this absurd list of topics. So I'm making a commitment to at some point making videos around all these things on this list. But today, I'll be happy if I can talk about the basics of using something called express in Node. And as well as what a REST API is and how to set up a route to return information to somebody who's querying that API. And then I would like to see if I can make a sentiment analysis API example. Whoo, that's going to be difficult. But that I'm so I'm just going to get started. This is what we're going to do today. And then, you know, at some point, I... And next week, by the way, I hope to be back to talk about Chrome extensions. And at some point, I am going to... You know, I'm planning to get to everything on this list in terms of videos. One thing that's been I've been making examples of recently is how to use Firebase, which is a database as service. So I want to talk about that. These emoji hearts in the chat are just the most wonderful things I've ever seen. They make me so happy. Okay, let's put on some music. As always, I always forget to this dot, this dot, this dot, this dot. I want to keep this here. This dot, this dot, this dot, this dot. OK, so I'm going to get started with the first video, which typically what I do. So if you haven't watched these before, what I do is I do a session, which is a longer session, which has all of my fumbling around and trying to answer questions in the chat. And then the wonderful Mathieu takes this longer session, which today will be only an hour and 20 minutes, and edits it into shorter tutorial videos. So it cuts out some of my longer debugging problems and also it's helpful. I think people find having the shorter video chunks more searchable and easily findable on YouTube. OK, the hearts are wonderful. Actually, I'm actually just enjoying them. I was going to tell you to stop, but I don't know, I'm kind of just enjoying them anyway. OK, so the first thing that I do usually is, since this is part, I'm a little bit confused about this actually, and I don't know if Mathieu is there in the chat. But this is session nine of eight of programming from A to Z. But in a way, this can operate as its own standalone tutorial about making an API with Node. So I think what I'm going to do is I'm not sure yet. So I'm just going to record these videos and I'll figure out how to organize it later. But this first video will be just kind of an introduction to this session and all of the topics in the session. And then I want to make sure I have a marker. And then the second video will start with how to make an API in Node. And that might end up being its own playlist as well about Node. But we'll figure that out later. OK, so thanks all of you for being here. I see so many wonderful messages in the chat, supportive messages. And I'm going to get started right now. I'm a little worried about a light that I have here. Turn this off for a second. Yeah. So I have to turn this light off, unfortunately, because I just turned one of the halogen lights off. I also just looked at it and now I can't see anything. I'm blinded by it. I'm a little bit darker, unfortunately, right? But there's a problem with this light. And it's burning. And I don't want it to catch on fire. So I'm turning it off. We will be in slight darkness today. But I think you guys can see me OK, yes? OK, so that's how it's going to be. OK, so let me get started here. Did I cycle the cameras? I can't remember. That's too bad. I brought an extra light, but something is wrong. I wonder if there's a way for me to dim it. Is there a dimmer on it? And then it won't overheat. But I'm just not going to worry about it. Safety first, everybody. OK, it's fine. OK, here we go. I still can't see. You know when you look at the sun and you see all the spots? I went over to look at the light because it looked like it was smoking a little bit. And I stared straight into it. Here we go. Hello, welcome to session nine. Oh, no, no, no, no, session eight. Let's try that again. Hello, and welcome to session eight of programming from A to Z. In this session, I want to talk about and look at more deeply how to build an API using Node. So this whole course has focused on working with text, reading text, analyzing text, generating text. And most of the stuff, almost everything that I've shown you, happens in client-side JavaScript. So let's talk about a little bit just generally what the difference is. So if you have a laptop that you're working on and it has a web browser in it, you might be running your p5.js sketch right there in the browser itself. So this is going to get you very far. There is so much you can do with just this, as we've seen. Now, you can do word counting and Markov chains and all sorts of projects. But there are some limitations here. So for example, let's just go back and think about word counting. So one of the things we did is, OK, so you have some text document. And you want to count how many times each word appears in that text document and visualize it in some way with your p5.js sketch. This will work just fine all client-side, unless a couple of things. One is, where is this data coming from? If you have a little text file that you can put on your server, great. But what if this is, instead of one text file, what if this is 1,000 or 100,000 or 1 million? I need that Austin Powers music, 1 million text files. It's going to be kind of unreasonable to expect the client-side, just your p5.js sketch in the browser, to sit there and churn through millions of text files for 10 minutes, a half an hour, and then produce the result. This is where server-side programming can come in. And now, the platform that I'm going to use for server-side programming is node.js. Of course, there are a variety of ways you can approach server-side programming. So OK, so there's a lot of pieces to this. So one thing that we've established is, if you have a really large data set, perhaps server-side programming is going to help you. Here's another thing. What if you have users entering in their favorite words? And you have your Mad Libs application. They're entering in words, nouns, adjectives to generate stories. What if you want, every time the user comes back, to be able to see what they entered before? Or what if you want, when a user comes to the page, to be able to see what everybody has entered? This is also so large. There's some reasons for server-side programming is large data sets. Another one is persistence. And I don't know how to spell that, persistence, meaning saving data. And there's a variety of ways you can save data. But with client-side JavaScript only, while you can download data to that user's local computer, there's no way to save data across multiple sessions using a particular web application. So this server is a place where, if we could send data to the server, it could be saved on the server in what's known as a database. So these are some pieces to why you need server-side programming. Now, here's another reason. What if you want to expose everything, your data, or your algorithm, or the thing you're working on, to other users as an API? This is another reason why you might want server-side programming. And this is mostly what I'm going to focus on in this particular week eight session, session eight. However, I'm going to kind of look at all of these pieces by the time I get to the end of it. This idea of maybe you have this wonderful spreadsheet of all of this information about flowers, and you want to allow other people to make queries, go to flowerapi.com slash chrysanthemum, or flowerapi.com slash sunflower, and receive JSON back with all this information about flowers. This is something you're going to want server-side programming for as well. And this is going to be the focus here. Now, there was one other thing on my mind, and I'm trying to kind of come up with it. API persistent large data set. Aha, I thought of it. I'm going to just say scraping. And with persistence, by the way, it could be kind of like user accounts and all that sort of stuff. But I'm kind of staying away mostly from traditional web development here and looking at kinds of creative applications of this stuff. But I'm saying scraping because one thing you might have noticed is in p5.js, if you try to, the bane of your existence might be this thing called cores. Or you might see it as like XML HTTP request error. You might have tried to load image from some URL or load strings or load JSON. You get this error. I can't do it. Security, cross-origin resources sharing not allowed, inaccessible, stop, stop, stop. So there's a lot of times where the client side, for security, very good security reasons, is not allowed to reach to another server and request data. But your server side program is allowed to do that. So for web scraping, for example, if you want to look at a web page, download all of its HTML, parse it out, pull out some things you want, you can do that from server side and pass that to the client side. So these are kind of four reasons why you might want to use server side programming. Number three being make your own API. This is where, in many ways, I want to start. OK, so what are the pieces of this? The first thing that I want, so I'm going to make a bunch of videos. They will eventually be here on YouTube for you to watch. Or I don't know what the platform of the future is when YouTube goes away. But hopefully, the videos will still exist. Number one, I'm going to talk about, I have a bunch of videos that I will link to in this playlist of kind of what is node and what is NPM for Node Package Manager. So you need to install Node and get up and running with something called NPM first. And I already have the videos made for that, which I will reference and link to somehow. But here, I'm going to start with a node package called Express, which makes building a web server, which is what you're going to need at its core. The web server is the thing that's going to pass information to your client, your p5.js sketch, or somebody else is making an API query. So we need to look at Express. I want to look at saving data. And I've got a secret to tell you, which is one of the easiest way. I'm sure someone, like, I'm going to get struck by lightning for doing it this way. But a really easy way to have a database is just save a JSON file. Save a text file to the hard drive of the computer and then load it every time the server runs. So I'm going to look at the simplest way you can have a database and then some other more complex ways, maybe using a database system like CouchDB or MongoDB, and then something called Firebase, which is a Google product that allows you to just send them information. They save it for you. You can request it later. I want to look at some point at scraping other web pages. So how could you grab an image and then pass that to p5.js or an HTML page and pass that to p5.js? There's a lot of topics here about making an API. There's this thing called REST. I don't even know what that is. We'll try to figure it out together. There's the thing called CORS, cross-origin resource sharing, which I think I do know what it is. And then I want to look at a bunch of different examples, mostly around working with text to follow the theme of this course. What if you had the big data scenario where you need to load massive amounts of text and you want to pass to a user a word counting info, you want to pass to make an API for word counting information? So that's something that I'll look at, as well as I want to build an API for sentiment analysis using this AFIN111 list of words. And I have a couple of examples that use a node package called node-natural, which is another text analysis, natural language processing node package, which has a lot of great features. And I'll show you a couple of them here. So I'm going to get started in the next video. This isn't the order that I'm going to go in. I'm really going to focus on working with Express, setting up this idea of an API, and then see if I can transition that into a simple sentiment analysis API. And we will see how that goes. See you next video. OK. Why would I want to make an API? Yayitsryan asks a really, really good question. Why would I want to make an API? I guess I wanted to address that in this, but maybe I will address that in the next video. So I would say, I would like to hear from the chat. Why would you want to make an API? Let's see if we have some good suggestions from the chat while I get set up here. OK. OK. Max Musterman writes, basically, to allow communication between two parts of a system. And that's right. I have sort of two ideas in my head. And I think, hopefully, it'll become clear as I start to make this example. Where are we at? 325. I really have so little time. I'm just letting you guys know that this is probably going to only be partially completed by the end of today. And I apologize for the sort of late, shorter livestream that I have going. OK. But I just want to keep on moving here. So I have terminal. Let me get terminal up. Here's terminal. I'm good. I want to get Adam here. Here's my code. I want to make sure I have my notes. And I'm going to keep this page open. OK. Basically, back from making popcorn. OK. Good way to share communication. Easily share your data with your developers. These are all great, great, great suggestions about why you'd want to make an API. OK. So here we go. I am going to, for no particular reason, cycle these cameras. And I think I'm going to do this in multiple parts. So this is going to be building your own API in Node. And I think in this first part, I'm going to get as far as having a route. And then I'm going to do routes with, OK. So I'm going to do this in multiple parts. OK. Here we go. OK. Welcome to a first video in a little series about building an API with Node. So the question was asked in the live chat. By the way, you're probably watching this as a recorded archive. But in the live chat, why would you want to make an API? And so I mostly write in the comments. I'd love to hear what your idea for an API and why you would like to make an API is. But there's a couple of reasons that I think I could kind of start with here. Number one is you have data. And you want to use it. And you want to allow other people to use that data. So this is a way of you kind of making a transaction, a sort of handshake, and saying, hey, there is this means for you to access this data. And I intend for you to be able to do so. An API stands for Application Programming Interface. It's a way for two different applications to talk to each other. So we're going to build an application, a Node application that has data or something associated with it. And other applications will be able to talk to it. So that's kind of the main reason. Now, there is sort of this scenario, which I also am going to show you with. You might be making an API for one person in the world, one wonderful singular person. And who is that person? It's you, right? So there are lots of projects where you're writing a front end, a client-side JavaScript thing. You're making pretty pictures and drawing text and all sorts of interaction stuff on the page. But you need some server-side stuff to connect, to download images, to run long, complicated processes, to use other Node packages. So you might make an API just for your own project itself. And actually, that's what we might see in some of the examples I have to show you. So that's kind of, number one, you might just want to, you know, you have something and you want to allow other applications to connect. Or you might actually want other things being mainly yourself. OK, so hopefully, that made some sense of why you might make an API. But really, you know what the answer to that is? Let's try to make an API, talk about it, get to the end. And hopefully, some creative ideas will emerge in your head as you're watching these videos. OK, so first, I want to point you to this web page, which is part of the course. The things that you will need before you're watching this video is what is Node.js and what is NPM. So you're going to need to have both of those things downloaded. And in this video, I'm going to start with adding Express. So I want to use this Express package, which is a fast, unopinionated, minimalist web framework for Node.js. So first of all, I just love anything that says minimalist, because programming gets really complicated. And looking through documentation and APIs is like, ugh. So it's nice that a lot of the things that I want to do in this application that I'm going to build is like, oh, host some files. Or, oh, receive a query from a user. And Express is going to have a simple function for each of those, as opposed to writing all the code for that in raw Node, so to speak. So the first thing I need to do, which is right here, is install Express. So just so you know, I happen to be in a project, which is right here. It's just a folder. And it has nothing in it. All it has so far is a server.js file, which is going to be the Node program I intend to write. But it's empty. So let's go over here. And I'm going to go to Terminal. And I am in that directory right now, which is session 8, API 1. And I'm going to install Express. I want to make sure that my, oh, and you know what I didn't do yet? I need to have a package.json file. So the package.json file for a Node project is the kind of configuration file. So I'm going to say npm init. And yes. Uh-oh. This is bad. Time out. Is something wrong with my Node installation? That really would suck. Why did that? I'm just going to do something. I know this is like the worst thing ever to do. Wait, let me actually look at the error I'm getting. Um, cannot find module SPDX. Oh, did I upgrade Node? And oh, buh, buh, buh, buh, buh, buh, buh, buh, buh. Oh, dear. This is very sad. My Node is messed up on this computer. I wonder if, um, let me just see if I can power through this. For a second and see what's in here. Yeah, that's pretty good. Now let's see. Oops, no, no, no, don't delete that. I want to delete the debug log. And I'm going to just say npm install express-c. OK, so I just have something screwy with my npm init. So I'm going to double back and just skip that in this video. And I'll just have a package.json file API test. I'm just going to pretend I made it by myself. Mattheo, this will be a, um, yeah, I need to reinstall Node. Thank you, guys. Mattheo, this will be a little bit of a challenge for you. But I don't think it'll be too much of a problem. I'm going to delete this. So I'm going to go back to where I said I have, all I have is server and package.json. And it's going to have to get edited together somehow. I don't remember what I was in, but probably I was over here. So I'm going to look at my directory where I have the project. And all I have is two things. I have a server.js file, which is actually, that's where I'm going to put my JavaScript code, which is empty. And then I have this package.json file, which you can make with npm init. But I already have one there. That's your configuration file for the project. And there's lots of important details about that if you go to publish your thing as a Node package or an open source project. But for now, we can mostly ignore the contents of package.json. I'll come back to it maybe another time. So you can see what's in it. It's just like a little bit of stuff saying, hey, this is the name of my project, and this is the version. But what I want to do is go and grab this and now install Express with this project. So I'm going to say, and you can see I'm in that directory. And I'm going to say npm install. Oh, actually, I'm just going to paste it in there. npm install express dash dash save. Ah! Oh, I have an error in parse. So I messed up. I have an error here. I wrote that package. So by the way, if that happens to you, let that happen. Trailing comma, I got an error in my package.json file. So that should fix it. I'm going to say clear and try this again. Oh, yay, that looks much better. So you can see it should now I should have a new directory called node modules. And you can see, oh, there's all this stuff installed in there. I'm just going to have to trust that Express installed correctly. So let's make sure everything's working. I'm going to go into my server. And I'm just going to say console.log server is starting. And I'm going to say node server. Server is starting. Great. So a node program is just like a program that's written in JavaScript that just runs on your computer. And it runs without graphics, without a window. And actually, there's a lot of stuff you can do with node. I mean, I should probably really learn Python one of these days. But I use node a lot to do a lot of batch processes on my computer. Like, oh, I could just write a little node program to rename a whole directory of files. Or I can make a request to some other API and download a whole bunch of things. So node is something that you could just forget about web servers and APIs. You could just use as a little programming tool to do a bunch of things for yourself on your computer through code. But what I want to do, the first thing I want to do is create a web server. And by web server, I mean something that opens up a port and allows browsers to connect to it. And this is very easy with Express. Now, I have most of this documented on this page. So I'm going to go and copy paste some of the pieces of code. The first thing I need is I need to say var express require express. This is like an import statement. Import the package express. I want to be able to use express. Now, the funny thing about this is I get require express. I get this into a variable. This whole package is actually a function. Express is a reference to a function. And I can execute that function. And that's what I'm going to do here in this next line of code. I'm going to say app equals express. I execute express. And suddenly, I get this web application. This is what I mean about how great it is to use express. It's doing all this stuff behind the scenes. And the first thing I can do is I say, hey, listen for incoming connections. So I'm going to say server equals app.listen port 3000. Now, there are various default ports that servers will use. But since I'm just doing all of my testing, this diagram that I have over here of this idea of a server and a client, right now, all of this is happening on one computer. The server is on the computer. The client is that computer itself. And that might actually, for a lot of projects, be all you need. But at some point, you also might want to deploy your server somewhere else so that other people could connect to it. And I'll have to make some videos about that as well. OK, so now that I'm listening at port 3000, I can do a few different things. So one thing, let's just run this. Server is starting. And you know what would be nice? It would be nice to add a little callback here. So I'm just going to write. I'm going to add something called function listening. And I'm going to say console.log listening. So I just wrote a little callback so that, and actually, the reason I'm adding this into the code is there are a lot of things you can do here. You can get the host address and the port and various things. But most of this stuff is unnecessary for what we want to do. But I want to at least sort of see this callback that it's working. So I'm going to run this again. Server is starting, listening. OK, here we go. Now, so let's go to localhost 3000. This is where my server is. I'm going to look at the little web page I made. Oh, cannot get anything. So there's nothing there. But you can see that this is working, because at least I got the message. I'm listening, but I don't have anything to give you. Me, the web browser, right now made a get request to the server. And this is kind of an important concept. So one of the first things I might do, although this is a little bit unnecessary for this idea of an API, but it's kind of worth exploring right now that we're going through this Express stuff, is I can use an aspect of Express to host static files. Meaning I can make, and this idea of this word public in there is something I could make up. So I could call this website instead of public, public being a kind of standard thing. This is saying use out of the Express package its ability to host static files, HTML files, image files, movie files, all that sort of stuff. So what I can do now, if I go into here, right, into my project, what I want to do is create a folder. I'm going to call that folder website, which is sort of a silly name. And I'm going to put in that folder a file called index.html. And then I'm going to say, hello. So in that file, it says, hello. And then, I don't know why I'm speaking in that voice. And then, I mean, I do know who I am, but I don't know why I am who I am. Anyway, now if I hit refresh, now first of all, I've got to restart the server. So here's the thing. There's actually a really nice tool. Notice how I have to stop the server, restart it, stop the server, restart it every single time I change my code. There's a nice little node module. I'm sure this is, which is called nodemon. And nodemon, like node monitor, I think, monitors your code and restarts the server for you every time you change the code. Now, this can be problematic. And you don't always want to use it. But in this case, it would be a lot more convenient. And dash g means I want this package. This isn't a package associated with this project. I want this as just a global tool that I'm using on my computer. And this probably is going to fail. Oh, but maybe it's not. I'm feeling hopeful now that actually this is going to work. So I got some error permission denied. This is because when I'm installing a global package, it's got to go into like user, var, local, bin, some secret place on my computer where I need special permission. So I'm going to say sudo for super do npm install nodemon dash g. And now I'm going to type in the password here. And hopefully this works. There, that seemed to work. Or I'm getting some warnings. I'm getting some things that look scary. Oh, it's doing more stuff. I think that worked. So I'm now going to say nodemon server.js. And this is working. So you can see that it is the server is starting, listening. And watch what happens if I go back and I say go to my server and I say, you know, I make a just do a carriage return and hit Save. You can see here, look how many times it restarted the server. So now I can kind of ignore terminal for a little while and just go from my code to when I make a change, refreshing in the browser. So look at that, by the way. I now see the files that are in that directory website. So this is step one. We have now written a web server with like barely any code at all. Look, this is like all the code for the web server. And incidentally, if you've ever seen me or do something like this, like often I'll run a web server on my computer by just saying python-m simple HTTP server. That's running a web server. There are lots of other tools. There's a node HTTP server. There are lots of tools that just make a web server that hosts files. This is what we have now done in this exact program. So step one is completed. We have written a web server that hosts files. In the next video, I'm going to add something to this called routes. So in addition to hosting files, I'm going to allow the user to send information or request information through something called a route, a RESTian route. By RESTian, I mean you're going to want to take a rest after watching the video probably. OK, so I'll see you in the next video. Thanks for watching this one on setting up a basic web server with Express. I'm going to take a look at the chat. I'm taking a look at the time. Oh, this computer, my computer that has the chat, died. I think the bad. I only have one plug. So I don't know if anybody's telling me anything or if everything has gone completely kaput. I'm still smelling a little of the smoke from that halogen. Come, computer, wake up. I want to see the chat. I don't know. I was going to put on some music. Chat's coming back. The chat's coming back. Come on, wake up. 1%, I see. I did run out of the battery life. And now cancel. OK. OK. Everybody, I see a bunch of chat messages. Chat is coming back. OK. So is everything working OK? You guys can hear me and see me. Hopefully, everything is good. Yeah, no, I'm using Mac OS X. Yes. OK. All right, so in the next video, I'm going to start talking about route. Now, I've got to figure out why it's called REST. So let's look. Wikipedia will tell us. This is me. I'm just like, ooh, soap. I remember there used to be soap. Soap is a protocol. REST is an architectural style. Why is it called REST, though? And why is it RESTful? Stands for Representational State Transfer. I can't bring myself to read this. But architectural client server, stateless. Oh, this is like way too much. So I'm going to, let's see, API. Apply to web services. Web services adhere to the REST architectural constraints are called RESTful APIs, defined with the following aspects. They have a base URL, an internet media type that defines state transition data elements, URL, standard HTTP methods. All right. Get, put. Yeah, yeah, this makes sense to me. OK. So what's the chance that I can remember representational state transfer? Whatever. OK. So now what we're going to do is I'm here. And I am going to start talking about RESTian, RESTful, RESTful routes. And I'm cycling these cameras. I really hope that we can kind of get, still got 45 minutes today. So I think there's a good chance of getting through a decent amount of material, but certainly not everything. OK, here we go. I'm ready. I'm going to start. Ah! In the previous video, I made a simple little web server. It's like only got this much code in it. And all it does is, never mind. Let me start over. In the previous video, I used Node and a Node package called Express to make a very simple web server. All it does is it spins up a server listening on port 3000. And if I run it, it looks, it serves up anything that's in this directory called website. OK. And in that directory called website is a little index.html file that says this. And now I see that in the web page. In the web page. I don't know if that even makes sense. OK, so what do I want to add to it? The goal of this video series is to make an API. Now, there are a lot of different ways, and styles, and flavors, and designs, and kinds of ways you could make an API, I'm sure. And the kind of API I'm going to show you is a RESTful API. And I like to call it, I like the idea of it being RESTful because I want it to be relaxing, and enjoyable, a soothing API. But REST is essentially like a style, so to speak, of how, it's a broader term. It stands for representational state transfer. It's a link to the Wikipedia page, and you can read all about it. But it's really a style by which users of the API can make GET requests and receive information back from the API. And let me try to describe the basics of how it looks and works. So I'm going to erase all of my diagrams from some other previous video, and let's think about what's happening. So let's say you're making an API about flowers. Maybe it's about rainbows. Maybe it's about rainbows, but flowers, I'm going to use flowers right now. Flowers API dot com. So HTTP, this is your website, your web server, your domain, all that stuff. You might go to flowers API dot com, and you will see the index.html page that's there. That's the web server we've written. You might go and say, slash, about. And maybe, actually, you have in your website directory, your public directory, a folder called about, with another index.html file. And when you go there, you see that one. So this idea of paths with slashes is something that you typically see to navigate through directories of a website. However, these slashes and the things in here don't just have to be directories. They can actually signify a route. So for example, what if I went to, I'm just going to call it flower API dot com slash search sunflower. What if I went to this? And this isn't actually of directories. These are commands that I am issuing to the API. I'm saying, search for this particular flower called sunflower. And I want to get back maybe some big JSON, all this information about sunflowers. So this is an idea of a route. And when you build an API, you might build different routes for different kinds of ways of accessing the data. You might make a route for getting all the data or for searching for one piece of the data or a route that signifies, I want all the data, but I want it sorted in this manner. Or I want all the data, but only if the data starts with the letter P, for example. So there's a lot of ways you can use routes. So now here in the code, this is not the code, I need to start to manage how those routes are handled. So right here, I'm going to start adding that code. So I'm going to add a bunch of carriage returns. And right here, I'm going to set up a route. So please edit that cough out. When a user goes to one of these routes or goes to in the browser, types in a URL or clicks on a link to a URL, they're making something called a get request. Please, may I have something from you server? Can I get stuff back? And you'll get images. There's a dog barking. Images, HTML files, CSS, all that sort of thing. So if you want to handle a get request that goes to a specific route, I could say app.get. Get slash. I lost my train of thought. We're thinking about flowers, right? Flower. And then I need a callback. Send flower. Send flower. All functions should be called send flowers. So I'm going to write send flower. So the idea here is I'm now writing the code if any user of this API, user meaning not necessarily a person, but a web browser, some client that's going to connect to it, goes to slash flower, then this function send flower should be executed. That's the callback. Now, the send flower has two arguments associated with it, a request and a response. Every web transaction, so to speak, when I go and type google.com or rainbow something something dot com, I'm making a request to the server. So all the information about me is in that variable called request. The server then sends back a response. All the information about the server's response is in that variable response. And I'm using this idea of all the information very loosely. In request, you can find what was the operating system? What was the browser? What are the headers? You're going to see were there any parameters sent also. The response has things like, ah, I can send back some data. So what I'm going to do is I'm going to now say right here, response send I love flowers too. So if the user goes to slash flower, rather than look for a directory of HTML, CSS, JavaScript files along that path, this is a route that I'm going to handle programmatically. And I'm going to say, I love flowers too. So let's hit refresh. The server's still running. I am now up here going to change this to say, go to the route slash flower. And I see I love flowers too. Now, there's no HTML page. There's nothing. There's just code and a response sent back the response. So this is part one. But remember this idea of searching, the idea of using an API to search? What I want to do is have a, well, there's a lot of things I can do. But something that at least to get started with is what if I were to search at a second, I don't know what to call it, a second element to this route, search slash sunflower. But rather than, oh, I'm going to come back over here. Rather than say, search slash sunflower, what I actually want to handle is not the specific route. I want, if they go to search, I then want the second element to be a variable, so to speak, something that changes every time. So here, I'm going to say colon flower. So that indicates that this search, that search is the route followed by something that the user enters. And that will be here found in the request. So in other words, I'm now going to go to search slash sunflower. And you're going to see it still says, I love flowers too. That's what I'm sending back. But now I can do something more. I can say, there's some data associated with this request. Something came in beyond just search, some type of flower. I can say request dot params. There are parameters. Flower is a parameter. And now I can say here, send the response back. I love data dot flower too. So I'm kind of, I don't like this amount of space that I have here. I'm going to fix this and make this a little smaller. No, no, way too small. Maybe this will get edited for flow. So here, you can see that in the response, I'm actually going to send back something that was sent. Now, what I'm doing here has no, there's no point to it. I'm just showing you the pieces of how things work so we can get to the place where it has a point. So let's see now if this works. If I refresh here, I love sunflower too. And I can put daisy. I love daisy too. And I can put rainbow. Doesn't have to be a flower. And I can put, so in other words, there's a round trip happening. I'm making a get request with this route, search slash something. The server gets that something as a parameter part of the request and looks at it, puts it in this variable data, and pulls out flower. So there could be a lot of parameters. So I can add another one. I could say slash num. And then I can say var num equals data.num. And I can then have, I was going to do a for loop or something and have it say I love data.flower so many times. Let's just do that. That's sort of silly, but why not? So I can say response equals this. And then for var i equals 0, i is less than num. i plus plus. I can't call this response. Reply, I'll call it reply plus equal this. And then I'm going to send back that reply. So I've added a little logic. So based on whatever number I get in, I do that a bunch of times. And now we can see I'm getting both a flower and a number. And if I go search rainbow five, I get it. If I do it slash 50, I get it 50 times. So the reply is now based on what has been sent into the server. So this is the basic idea of how a route works with a get request. Now, of course, there's something later you're going to see there's also a post request. I can say app.post. And we're going to need that for this example that I hope to ultimately build. But in the next example, what I want to, what the next video I want to do is add a little bit of persistence to this. So what I want to do is create a set of routes where the user can retrieve data and then contribute to that data as well. So we'll see that in the next video. All of a sudden, I have my cough is back. It is 5 of 4. It's very hot in this room. Again, I think the heat is on. And then I have these hot lights. Is this making sense, everybody? I don't know. I'm kind of making these really, really short. Yeah, this cold that I've had has just been lasting forever. OK. So what I want to do next is I'm going to create a, OK, good. I'm trying to think of what, I mean, I was going towards doing sentiment analysis. So I think, sorry, I hope the cough didn't blow out your ears. Search is sort of silly. Search is meaningless. It's something that I made up. So I'm going to change this. I'm going to go towards the sentiment analysis example that I'm ultimately going to make, although I was kind of going to do that all from scratch. But can we have, yeah, you can have optional variables. Absolutely. So let me add some stuff to this. And I think I will go towards the sentiment analysis example. OK. Use Baker cat as an example. I don't know what that is, but I appreciate the, how to manage a slash inside the search query. Yeah, Alessandro, that's a good question. There are ways of URL encoding various kinds of characters that cause a problem. So I would have to look at that specifically, but of course, there's always a way around it. Optional variables in the middle of a URL is hard. Yes, definitely hard. It's at the end that kind of works best. OK, so I'm going to try to get one step further here with this, at least, if not two. And that's all I'm going to be able to do today. OK. And what I want to do is just add this. Really, I guess it's, is it rendering it as HTML? Yeah. And I wanted to actually have it be this. OK. So I am looking at my phone, which is no reason. OK, so I got to get to the next stage. The next stage of this is I want to take input from a user and essentially save it to a database, which is going to, I'm going to do it in two stages. And then I also want to look at how to send that information back. OK. OK. Where am I here? I'll start here. OK. Sorry, YLive. I've got lots of, this has the default YouTube clean language settings. I think you'll come, I think it'll let you back in, YLive, if anybody knows how to let YLive back in. OK, here we go. In the previous video, I got as far as defining a route with parameters. The route is search slash some keyword slash some number. And the response from the server that comes back is always I love whatever word, however many times the number is. So if I were to change this to unicorn and unicorn and put it just with slash three, I would see I love unicorns two, three times. So this is, while fun, and I like to see how much you love unicorns and rainbows, do you love them as much as me? I don't know, probably not, which is a very healthy, probably much healthier than however I am. But the point of what I'm saying is this is kind of useless. Let's turn this into something useful. And so the example that I'm ultimately building here is a sentiment analysis API. And so one approach to sentiment analysis is to keep a dictionary of words that either have a positive or negative score associated with them. So I'm going to go to the code. And I'm just going to, right here at the top, I'm going to create a variable. And I'm going to call it words. And I'm going to put some words in it with a score. So I'm going to say rainbow has a score of five. And unicorn has a score of three. What are some sad words? Doom has a score of negative three. So this is my very basic sentiment analysis dictionary. I've got three words in it and what their score is. So first thing that I want to do in making a sentiment analysis API is expose this data. So I'm going to actually add another route here. I'm going to say app.get all, send all. And then I'm going to say function send all. And this is the callback, which has a request and a response. And all I'm going to do is say response.send words. Now, notice what I did up here. In this reply, I just created this string. And this string just kind of spit itself out into the browser. But somebody using the API is probably going to want to get the reply back formatted as JSON. So I better do something to format this as JSON. Well, what is words? It's a JavaScript object. What is JSON? JavaScript object notation. So one of the magical things about using Express is Express will automatically format your JavaScript object that you send out into the world as JSON. So this is actually done. So I can now go to slash all. And I can see this is now me making an API request to my API. And I'm getting the list of words. And if I add another word to it, like gloom, doom and gloom, now I have another word there with a score of negative 2. I hit refresh. I see that as well. So what I want to do, in addition to having this be an API, so there's a couple of things I could do. One is that I might want to search for a particular word to see if it's in the API. If it is, get the score. Or I might also want to be able to, as a user, add words to the API. So this is a sort of design decision. What are you doing here? I'm just making a demonstration. I think it would be useful to see how can you create a route where a user can insert data into the database. And by the way, that's my database right now. So as I go through these videos, I'm going to get into persistence, working with databases. And there are various levels of that. On the one hand, this will persist. It will never go away. It's written there into the code. My database is hard-coded. Not the best solution, but it's a good starting point. So I'm going to change this particular route. And I'm going to change it to add word score. Add word. So I want a route where if the user adds a word with a score, it goes into the database. So I'm going to change this to add word. Here are the parameters. The word is data.word. The score is, and this is, I'm kind of being very long-winded about this. I can't just say word equals request.params.word. Data.score. And then what I want to do is say words.word equals score. Look at this. This is me taking in the data from the user, the word and the score, and putting it into that object, putting it into that object with a key value pair. The word is the key. The score is the value. And then I need to create a reply. And all of my replies, I want them to be written as an object. So I'm going to say message, thank you for your word. OK? So there we go. So now if I run this and I go here to all, we can see all of the data is there. Now I'm going to go to one more window. And I'm going to go to add a purple 5. Purple is a very happy word. I'm going to hit Enter. It's going to say message, thank you for your word. So I got that message back. And if I go to all, we can see purple. Oh, and look at that. It got the, of course, the way that it's working is it came in as a string, not a number. So I could correct that if I want. Let's correct that. So I could say, let's make sure that is actually a number. Because I might want to do some mathematical operations with it later. So let's convert that to a number. And I'm going to add the word again, hit refresh. And now you can see I got purple 5. So there we go. I have saved this word forevermore in the API. Now, there's a couple of things I want to add to this. Number one is, what if I just go to add purple and I forget to add a number? I run this. It says it cannot get that. Time out. OK, I have to look up in my example. I thought it was going to get this, but give me an error on the server side. Like, if the last one can be optional. I did this, I thought, in one of my pre-made examples. So I'm paused now. I'm going to go look at my pre-made examples. Oops, not here. Where did I do this? Simple API express, probably here. Did I do it here? Oh, no, no, this is not what I did. I thought there was a way to determine to make it optional. Somebody in the chat might tell me before I figure it out. I'm going to look at routes rest. Can I do that in here? Yeah, do that. So the last one should be optional. That's the way I did it. If it doesn't exist, then just set it to 1. How come that didn't work for me? Can't I just do this? Didn't get a 0. I guess I'm not going to add this feature to this program right now. I'll come back to it later. Hold on, let's see. Console. Did I add an extra? I thought. I mean, I know I could just do a route without it. Nobody in the chat knows this. Hold on, let's see here. Console.log, am I here? So if I go to here, what if I do a slash? I guess I could do it. I don't want to get too stuck on this. I mean, I can do something where if I do this, right? Yeah, I don't know. Am I here? No, OK. And not you destroy if there is any try. Yeah, I know this. Do you add a question mark for an optional one? I'm going to just not worry about the optional thing, because it's not that fundamental to this. I can bring that back later. I just was going to do it because it seemed like an obvious thing to look at right now. Mostly because I'm in a time crunch and I have to leave in like 15 minutes. And I want to get this thing finished. So I am going to go back and not worry about that. I'm trying to think where I left off before I tried doing that. I want to get to the, so there's the optional thing that I did. I'm losing my train of thought. Oh, is it a question mark for an optional? Optional param express. Curious here. I don't want to get too lost with this key. Oh, question mark. So does that make it optional here? Yeah, after the parameter name. So I think if I add this now, and I take this out. And then, right, it's giving me no. OK, great. Sorry about that. So wherever that was, I will be coming back to that now. So wherever I was, I was here. And I was saying, OK, this is where I was. It cannot add this because it's looking for this particular route. And the route requires also a score. However, there is a way to make that score optional, which could be useful for something you might do, which is adding just a question mark to, and this really only works for the last one, although I'm sure there's some fancy ways around that. And then what I could do is I could say, if not score, score equals 5. Or I could actually say, score is required. So let's say score is required. I could add some error handling here. Like I could say, var reply, score is required. Else, all of this. So I'm basically saying, whatever word comes in, if I get a score, so if not score. And also, I should probably check. And I'm not going to do all this. But if I want to be really serious about this, I would also check to make sure score is a number. And if you sent me the score as friendship, I would say the score has to be a number. But here, I can just create this variable var reply. I can fill it. If there is no score, I can say score is required. If there is a score, I can add it to the table and say, thank you for your word, and then send the response. So this is one extra thing that I'm adding to this. And if I now run this, it's going to say, hey, score is required. So I can say now 5, thank you for your word. And we can go back here. And we can see purple is there with a score of 5. So there are a lot of ways to sort of check and see what's coming in and determine whether something is there or not. OK. So let's add one more thing to this. Let's add a search route so that if the user of this API wants to query for a particular word and get the score back, let's see how that would work. So I'm going to add another route. And I'm going to call it. I'm just going to go down here to the bottom. I'm going to call it a search for a word. And I'm going to say search, search word. I'm going to add that callback now, search word with a request and a response. And I'm going to say the word you're searching for is request params word. And now what I want to do is see, does that word exist? If that word is part of our words table, I need to make a reply. I'm going to send back a message. I'm going to say status found, word, word. That's kind of probably a little awkward what I'm doing. I'm just going to call this. It's fine. It's a little awkward what I'm doing with these variable names and then score. I'm going to say words, word. So what I'm doing here is I'm saying if it's found, then the reply equals this particular object. So if it's found, the status is found, here's the word, here's the score. Otherwise, the reply is status not found. And then there is no, I can send back the word, there is no score. And I can say response.sendReply. So the idea here is that I'm just showing you an example. Now I'm making a route for the API where a user could say, hey, do you have this word rainbow in your database? If you do, could you give me its score? If you don't, will you tell me that you don't have it? So this is yet another thing. Search word, check to see what word did the user set in. Is it part of the data? If it is, say it's found. And this is often a good technique. Let me give you back the data you asked for. Because a user of this API might be querying like 1,000 different words and all the responses are coming back. And if the data that came with the request also comes back with a response, it's going to make it easier for the user to manage. So now let's run this. And I can see here, I'm going to go now to search slash rainbow. We can see status found. The word is rainbow. The score is 5. Search unicorn. Status found. Word unicorn score 3. Search kitten. Status not found. Word kitten. So this is how I am now making an API that allows a user to query the database. So we have the ability. And then, by the way, now I can say add kitten 5. And then I can say search kitten. And now it's found with a score of 5. So notice how I'm only interacting with this API via the URL address bar. And ultimately, as I get through more videos here, I'm going to look at how do I actually interact with it from my client side JavaScript code, which will really open up a lot of possibilities. So I now have an API which has three features. I can look at all the words that are in the database and their score. I can add a word like purple. Didn't I already add purple? So we're going to have to talk about that. And oh, purple is positive. Give it 3. So I can add a word. And I can also search and see if a word is in there. Purple is in there, but perhaps pink is not. So this is a good start. I have this idea of persistence. There's a database of information. Users can add to that database. Users can request all of the data from the database, or they can request one item from the database. But you'll notice here I have this wonderful thing where I add kitten in purple. So now what I'm going to do is I'm going to quit the server, and I'm going to restart it. And I don't have kitten in purple anymore. So while there is persistence across. Do you hear the puppies barking about my wonderful API discussion? While there is this idea of persistence while the server is running, as soon as I quit the server and restart the server, I've lost any new data that wasn't just part of what was originally written in here. So in the next video, what I'm going to show you is how to keep persistence across multiple times running the server. How do I take what's here and actually not have it be hard coded, but save it to a database? And I'll see you in the next video. I'll do that. OK. You guys can hear the dog barking. OK, that's going to be wonderful. That's all I see here. OK, it's 418. Unfortunately, I'm just going to check to make sure there was no change in my schedule. Oh, OK. Oh, I have to check. I have to live check to see if I won the Hamilton lottery. That's really going to change my day. Hamilton, New York, lottery results. Unfortunately, you were not selected to receive tickets to the November 1st 7pm performance at Hamilton. That's good to know. So because I have to leave in about 10 minutes, I would like to keep going through this. But I also just don't want to rush it. I feel like this is a good, meaty, vegetarian, tofu-y topic. Let me go back to my list and think about how far we really got, which I have to admit is not very far. And where was my main? Let me go back to here. So I was able to get really through. The things that I would check off here, if I were checking things off, would be using Express and serving files. A query string. Actually, I didn't do the query string. Looking at a RESTful routes, RESTian routes. I didn't really talk about CORS, which is something I'm going to have to mention, and sending back JSON. I wish there was a way I could annotate this. So when I come back for another live stream, which, gosh, I really wish it could happen this week, but it won't. Maybe it could happen over the weekend. I'm not sure. In terms of the time I have and just the amount of the availability of this space, but I will continue this. I want to get all the way through building out this API and saving the data to a database, and then actually starting to use it to do sentiment analysis, and then loading a pre-existing list of words and their scores. So I'm actually not vegetarian, but in spirit, I feel like a, you know, we should, anyway, I don't know what I'm discussing here. I've lost my mind. Yes, sorry. Someone's asking an important question that this would actually look like this if you were coding along with me, and that I actually am using a Chrome extension that formats the JSON that you get back kind of nicely, which is just very convenient to use. So anyway, I have 10 minutes. I would like to take some questions from the chat about anything, really. I can do that for about 5 or 10 minutes, and then I'm going to have to say goodbye. I apologize for the short session today. I will be back next Tuesday. OK. Schiffman, do you know something about Golang? No, I don't. But that's an interesting idea for me to investigate. Schiffman, why not use a MySQL server for this? So this is the discussion I want to have when I get to this idea of persistence. So there are a lot of ways that you can store your data. And probably the most sophisticated, robust, scalable way is to use a database, a MySQL database, SQL database. That's kind of the same thing. MongoDB, CouchDB, there are a lot of systems for doing that. I'm here teaching about kind of creative projects and rapid prototyping for a lot of things where you're just sort of stitching stuff together and making an example. Learning a whole database system could be kind of overkill when you could just save the data to a JSON file. So I'm kind of going to, that's where the next step that I'm going to take, which is actually quite easy and works quite well. Of course, if there's scalability concerns, massive data, lots of relational data, if there's privacy and security issues, you're going to need something more than just a JSON file. But that's actually going to be pretty powerful to use. I also want to show you, and I do have all these examples already, I just haven't gotten a chance to go over it. But I'm going to show you something called Firebase, which is a database as service, essentially, where you can just sign up for an account. And I've been able to do everything for free so far, at least with my examples, and sort of send the data to Firebase. Firebase will save it for you, and you can always request it back. And actually, you don't even need Node to use Firebase. You can do everything from the client side, which is quite nice. OK, Mac Brick asks, Schiffman, how long have you coded? I think I probably started programming really in 2001. So that would be, I don't know, you do the math. But it was sort of later in life than a lot of people. There's no time where you can't start coding. But I was in my later 20s around then, I think, if that's right. I did a little bit of programming in middle school using the basic programming language and also assembly language. And I maybe took one course on C++ when I was in college. But I never really started programming until about 2001. OK, trying to think if there are other important announcements. Let me look at, I'm kind of nearing the end, so to speak, of this course. So there's a lot more that I want to look at building APIs and using these Node packages for doing some other text classification, text generation analysis stuff. I want to do a whole session on Chrome extensions. That probably might take a two-week period as well. This is taking two weeks. And then there's this time in my actual course at ITP at NYU where students are for over four weeks are working on final projects. So any of you who are interested in kind of thinking about watching these videos and as if you're taking a course, you could just do that and share with me on Twitter or in the comments any projects you make. But I will say you can also subscribe to my Patreon, patreon.com slash coding rainbow. And there, if you join that, there's a Slack channel where it's kind of trailed off. I think people are busy. But I'm hoping that we can kind of revive it a little bit, where people are discussing assignments and asking questions and that sort of thing. Ah. So oh, yeah, using Excel for a database or a spreadsheet for a database is quite useful. And in fact, over that, I would say, and I have an example that I made previously of just using a Google Sheet. So you can actually, and there is something called Sheetsu. Sheetsu.com, I believe. This is a commercial service. I think you can use it for free. But it turns a Google spreadsheet into a REST API. Hey, maybe you know what a REST API is now, Spreadsheet as Database. So this is something I should add to my list to maybe do a video about in particular. I've gotten a lot of requests for more kind of like classic arcade game coding challenges. And I think what I might do is when I have time towards the end of the NYU semester, where I'm done with these topics, I might just do a couple of weeks where I just do those arcade game coding challenges. Because I find them to be a lot of fun. And to be honest, the snake one that I made, which isn't really even that good, has like 100 times more views than any of my other videos. What do you think about making a project in the type of a big collaboration of the whole community? I would be thrilled for something like that. I would be glad to support that. And I would hope that that community would include people from all sorts of backgrounds, and genders, and ethnicities. It would be terrific if we could make a community project like that. Joining the Patreon and the Slack channel would be a good place to start with a smaller community. There are other more open Slack channels. I believe there's a creative coding one. And certainly, send me a tweet. I'll retweet it if you want people to get in touch with you about a project. John is asking something about install NodeDaemon. I don't know what that is. But I'm using something called NodeMon, which you don't. Just use npm install NodeMon. Are we called creative coding now? But I don't have a short answer to that question. And I have four minutes before I said I was going to go. Will I do more generative art stuff? Yes. So by the way, this spring, I'm going to, at NYU, be teaching a couple of courses based on my nature of code materials, which have generative algorithms, physics simulation, back to sort of graphic stuff. And so I expect that once I get back up and running with videos in 2017, after this fall and winter finishes, you'll see a lot more graphics and generative algorithm stuff on the channel. Creative coding is a strange term. I personally kind of like it to signify that the idea here is that we're doing that this is different than computer science in the sense that computer science really about systems thinking and algorithms. And this is really about kind of playful experiments and applications. And I think of it similarly to, you know, there's a little bit of a problem, which make, is it implying that other coding is not creative, which I would say is absolutely not true. I mean, all coding is creative. But there's a certain distinction that is similar if you say creative writing. You kind of get a sense of like, oh, maybe you're writing poems or novels or fiction, which is different than maybe writing for journalism. But writing for journalism is a creative as well. But it just kind of codifies at least, gives some context to what the context is. And so I like to use creative coding as a term. Yeah. What did I miss? OK. So thank you, everyone, for tuning in. Again, I apologize that this was kind of a shorter session today. I can see that it was an hour and 23 minutes long. I did have a live stream once. That was four hours long. I will be back next week, next Tuesday. If I can squeeze a time in before then, I would absolutely love to. I'm trying to figure out ways to have more time to do this, because I quite enjoy it. But it does take a lot of time and energy. And certainly having the support, the friendly feedback, the constructive feedback, the critical feedback is always helpful and appreciated. Please, if you feel so inclined, and there's a place to write a review, honest reviews only, I would tell you to. But I don't think you can write reviews of YouTube channels. But share if you have a chance to share, if you like what I'm doing. Or hit the Like button, that kind of thing. It certainly helps other people find the channel, which makes it easier for me to do this stuff with more things. Yeah. Oh, by the way, next Tuesday, oh my, is election day. And I'm about to have, I'm going to seriously, where's my anti-anxiety medication? Oh, the camera went off. That's good. So I think I will be broadcasting live on election day. I don't think I'm going to do any sort of election themed content. It is, by the way, I forgot to mention that it is nano-genmo, which I think, did I say that right, which is generate a novel month. So all the stuff that I'm doing, I maybe should give that as a challenge. My Twitter is at Schiffman. Maybe I'll think of something election related. But I think I'll probably just continue with this API thing. We'll see how it goes. So thank you guys for tuning in. I'm sorry, again, today was a little bit shorter. I would love to have a conference. Oh, let me just plug something for no apparent reason. But someone mentioned conference. There is a conference coming up called Code Land, which is the Code Newbies Conference. Maybe it is not, maybe there is not a website for it yet. But I'm going to look here on Twitter. So this is April 21st and 22nd, 2017 in New York City. The reason why I mentioned it is I don't want to be so bold. But I feel like I've gone to some Code Newbies event. I listened to the Code Newbies podcast. Saren, I think I just said her name incorrectly. Saron, oh my goodness, I'm just like blanking. The woman who runs Code Newbies is absolutely wonderful. She's created an amazing community. So I feel like if I were to run a conference, I would hope that it would have the spirit and community that I expect this conference to have. And so I would encourage you to think about that. I hope to attend, although I'm not sure 100%. But I would love to see any of you if you're in New York City and meet some of you who are watching. OK, yes, it's a bit too far away. Hopefully, there'll be some conferences in other parts of the world that we can meet or have a. Maybe I could do like a, I was about to say coding rain, but I could do some sort of world tour. OK, MacBrick says I have a question. So I'm waiting for that one question before I go. My song ended. This is usually where I hit Stop the live stream. But the chat seems to be restful. Yes, that's actually great advice from Coder for Life. Everyone, sleep is really important. Your health is really important. Take it easy. Don't try to do too much. Give people hugs. So yeah, world tour would be great. All of you have questions. So tweet at me your questions at Schiffman. Unfortunately, I'm going to have to say goodbye right now. I have to go and pick up some small children from their after school activities. And I don't want to be late. Great, John says NPL install NodeMon worked for me. Did you include the dash G? Because you're going to need it to be a global module. So I hope to see you guys next week or on the internet in some other fashion. And thanks again for tuning in. And thanks for School for Poetic Computation for having me in their space, sfpc.io. Thank you, ITP, itp.nyu.edu, for the students that I wasn't having office hours this afternoon with. And I'll see you guys all sometime soon.",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:03:53.121004Z",
  "started_at": "2023-09-26T21:20:22.04116Z",
  "completed_at": "2023-09-26T21:43:57.705961Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=_FABYvnTnpQ",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 1415.664801
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/cyrfjhzbu5gba7p2wjrfjao55y/cancel",
    "get": "https://api.replicate.com/v1/predictions/cyrfjhzbu5gba7p2wjrfjao55y"
  }
}