{
  "id": "h4h36wrbpwpd5crtskmvcabjsm",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/JnEH9tYLxLk.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/526336 [00:00<?, ?frames/s]\n  1%|          | 2786/526336 [00:03<10:49, 806.41frames/s]\n  1%|          | 5470/526336 [00:09<15:15, 568.89frames/s]\n  2%|▏         | 8174/526336 [00:16<18:41, 461.91frames/s]\n  2%|▏         | 10694/526336 [00:25<22:50, 376.34frames/s]\n  3%|▎         | 13390/526336 [00:31<21:40, 394.56frames/s]\n  3%|▎         | 15870/526336 [00:38<22:51, 372.27frames/s]\n  3%|▎         | 17882/526336 [00:46<24:53, 340.43frames/s]\n  4%|▍         | 20566/526336 [00:49<20:20, 414.34frames/s]\n  4%|▍         | 23470/526336 [00:55<19:01, 440.52frames/s]\n  5%|▍         | 26070/526336 [01:02<20:05, 415.16frames/s]\n  5%|▌         | 28754/526336 [01:08<19:42, 420.69frames/s]\n  6%|▌         | 31430/526336 [01:15<19:27, 424.08frames/s]\n  6%|▋         | 33942/526336 [01:21<19:24, 422.85frames/s]\n  7%|▋         | 36418/526336 [01:27<20:15, 403.16frames/s]\n  7%|▋         | 39018/526336 [01:33<19:40, 412.81frames/s]\n  8%|▊         | 41234/526336 [01:39<19:56, 405.59frames/s]\n  8%|▊         | 43726/526336 [01:46<20:46, 387.19frames/s]\n  9%|▉         | 46366/526336 [01:52<19:33, 409.09frames/s]\n  9%|▉         | 48806/526336 [01:59<21:01, 378.42frames/s]\n 10%|▉         | 51802/526336 [02:05<19:00, 416.12frames/s]\n 10%|█         | 54230/526336 [02:11<19:09, 410.55frames/s]\n 11%|█         | 57146/526336 [02:19<19:07, 408.94frames/s]\n 11%|█▏        | 60082/526336 [02:25<18:10, 427.37frames/s]\n 12%|█▏        | 62382/526336 [02:31<18:41, 413.82frames/s]\n 12%|█▏        | 65250/526336 [02:39<19:23, 396.26frames/s]\n 13%|█▎        | 67962/526336 [02:45<18:28, 413.62frames/s]\n 13%|█▎        | 70926/526336 [02:51<17:31, 433.11frames/s]\n 14%|█▍        | 73062/526336 [02:56<17:18, 436.51frames/s]\n 14%|█▍        | 75746/526336 [03:01<16:59, 442.16frames/s]\n 15%|█▍        | 78374/526336 [03:08<17:29, 426.77frames/s]\n 15%|█▌        | 81194/526336 [03:15<17:42, 418.95frames/s]\n 16%|█▌        | 83858/526336 [03:20<16:14, 454.00frames/s]\n 16%|█▋        | 86506/526336 [03:26<16:47, 436.47frames/s]\n 17%|█▋        | 89298/526336 [03:35<18:47, 387.68frames/s]\n 18%|█▊        | 92142/526336 [03:41<17:26, 414.82frames/s]\n 18%|█▊        | 95126/526336 [03:47<16:29, 435.57frames/s]\n 19%|█▊        | 97486/526336 [03:53<16:22, 436.57frames/s]\n 19%|█▉        | 99818/526336 [03:57<15:47, 450.16frames/s]\n 19%|█▉        | 101990/526336 [04:04<16:49, 420.27frames/s]\n 20%|█▉        | 104102/526336 [04:08<16:31, 425.64frames/s]\n 20%|██        | 106182/526336 [04:13<16:22, 427.73frames/s]\n 21%|██        | 108638/526336 [04:19<15:54, 437.69frames/s]\n 21%|██        | 111070/526336 [04:24<15:49, 437.39frames/s]\n 22%|██▏       | 113766/526336 [04:32<17:09, 400.66frames/s]\n 22%|██▏       | 116018/526336 [04:38<17:23, 393.10frames/s]\n 22%|██▏       | 118098/526336 [04:43<16:45, 406.00frames/s]\n 23%|██▎       | 120314/526336 [04:48<16:42, 404.97frames/s]\n 23%|██▎       | 122778/526336 [04:53<15:35, 431.44frames/s]\n 24%|██▍       | 125086/526336 [04:58<14:59, 445.97frames/s]\n 24%|██▍       | 127558/526336 [05:06<16:55, 392.62frames/s]\n 25%|██▍       | 130066/526336 [05:13<17:37, 374.72frames/s]\n 25%|██▌       | 132438/526336 [05:18<16:42, 392.99frames/s]\n 26%|██▌       | 134950/526336 [05:25<17:04, 382.03frames/s]\n 26%|██▌       | 137314/526336 [05:32<17:19, 374.20frames/s]\n 27%|██▋       | 139838/526336 [05:40<17:47, 362.05frames/s]\n 27%|██▋       | 142686/526336 [05:47<17:12, 371.67frames/s]\n 28%|██▊       | 144814/526336 [05:53<17:26, 364.70frames/s]\n 28%|██▊       | 146954/526336 [05:59<17:30, 361.07frames/s]\n 28%|██▊       | 149774/526336 [06:06<16:44, 374.72frames/s]\n 29%|██▊       | 150826/526336 [06:09<16:47, 372.66frames/s]\n 29%|██▊       | 150958/526336 [06:13<22:04, 283.43frames/s]\n 29%|██▉       | 153528/526336 [06:17<16:44, 371.06frames/s]\n 30%|██▉       | 156344/526336 [06:25<16:21, 376.92frames/s]\n 30%|███       | 159184/526336 [06:31<15:09, 403.90frames/s]\n 31%|███       | 162006/526336 [06:41<17:15, 351.98frames/s]\n 31%|███▏      | 164818/526336 [06:49<17:18, 348.09frames/s]\n 32%|███▏      | 167666/526336 [06:56<16:02, 372.82frames/s]\n 32%|███▏      | 170514/526336 [07:04<16:07, 367.67frames/s]\n 33%|███▎      | 173126/526336 [07:10<15:25, 381.53frames/s]\n 33%|███▎      | 175790/526336 [07:17<15:24, 379.20frames/s]\n 34%|███▍      | 178262/526336 [07:22<14:29, 400.45frames/s]\n 34%|███▍      | 181158/526336 [07:30<14:40, 392.16frames/s]\n 35%|███▍      | 184096/526336 [07:38<14:49, 384.77frames/s]\n 36%|███▌      | 186980/526336 [07:48<16:03, 352.22frames/s]\n 36%|███▌      | 189724/526336 [07:56<15:57, 351.68frames/s]\n 37%|███▋      | 192638/526336 [08:04<15:48, 351.68frames/s]\n 37%|███▋      | 195248/526336 [08:10<15:13, 362.41frames/s]\n 38%|███▊      | 198072/526336 [08:19<15:16, 358.29frames/s]\n 38%|███▊      | 200832/526336 [08:27<15:18, 354.51frames/s]\n 39%|███▊      | 203740/526336 [08:33<14:10, 379.28frames/s]\n 39%|███▉      | 206544/526336 [08:40<14:02, 379.45frames/s]\n 40%|███▉      | 209324/526336 [08:48<13:56, 378.81frames/s]\n 40%|████      | 212276/526336 [08:55<13:30, 387.47frames/s]\n 41%|████      | 215152/526336 [09:02<13:19, 389.04frames/s]\n 41%|████▏     | 217864/526336 [09:10<13:31, 380.29frames/s]\n 42%|████▏     | 220784/526336 [09:18<13:35, 374.83frames/s]\n 43%|████▎     | 223700/526336 [09:27<13:58, 361.03frames/s]\n 43%|████▎     | 226516/526336 [09:37<15:02, 332.25frames/s]\n 44%|████▎     | 229424/526336 [09:45<14:52, 332.54frames/s]\n 44%|████▍     | 232234/526336 [09:53<14:24, 340.06frames/s]\n 45%|████▍     | 235154/526336 [10:01<13:36, 356.55frames/s]\n 45%|████▌     | 237818/526336 [10:09<13:49, 347.94frames/s]\n 46%|████▌     | 240738/526336 [10:17<13:40, 348.09frames/s]\n 46%|████▋     | 243562/526336 [10:26<13:50, 340.40frames/s]\n 47%|████▋     | 246110/526336 [10:32<12:57, 360.59frames/s]\n 47%|████▋     | 249096/526336 [10:40<12:50, 359.74frames/s]\n 48%|████▊     | 251920/526336 [10:48<12:36, 362.61frames/s]\n 48%|████▊     | 254832/526336 [10:58<13:30, 335.11frames/s]\n 49%|████▉     | 257708/526336 [11:07<13:22, 334.59frames/s]\n 49%|████▉     | 260464/526336 [11:14<13:05, 338.35frames/s]\n 50%|█████     | 263312/526336 [11:23<13:07, 333.99frames/s]\n 51%|█████     | 266200/526336 [11:34<13:44, 315.47frames/s]\n 51%|█████     | 268764/526336 [11:43<14:16, 300.75frames/s]\n 52%|█████▏    | 271652/526336 [11:51<13:16, 319.85frames/s]\n 52%|█████▏    | 274576/526336 [12:01<13:26, 312.21frames/s]\n 53%|█████▎    | 277492/526336 [12:08<12:14, 339.00frames/s]\n 53%|█████▎    | 280320/526336 [12:16<12:12, 335.68frames/s]\n 54%|█████▍    | 283160/526336 [12:26<12:33, 322.77frames/s]\n 54%|█████▍    | 286120/526336 [12:33<11:34, 345.78frames/s]\n 55%|█████▍    | 288884/526336 [12:40<11:07, 355.75frames/s]\n 55%|█████▌    | 291848/526336 [12:50<11:39, 335.36frames/s]\n 56%|█████▌    | 294676/526336 [12:59<11:33, 333.92frames/s]\n 57%|█████▋    | 297636/526336 [13:07<11:15, 338.50frames/s]\n 57%|█████▋    | 300252/526336 [13:14<10:47, 349.11frames/s]\n 58%|█████▊    | 303236/526336 [13:22<10:21, 359.21frames/s]\n 58%|█████▊    | 306236/526336 [13:30<10:12, 359.33frames/s]\n 59%|█████▊    | 309076/526336 [13:40<10:37, 340.97frames/s]\n 59%|█████▉    | 311984/526336 [13:48<10:34, 337.83frames/s]\n 60%|█████▉    | 314936/526336 [13:58<10:53, 323.54frames/s]\n 60%|██████    | 317900/526336 [14:07<10:31, 330.17frames/s]\n 61%|██████    | 320676/526336 [14:16<10:43, 319.65frames/s]\n 61%|██████▏   | 323670/526336 [14:25<10:10, 331.96frames/s]\n 62%|██████▏   | 326468/526336 [14:33<10:05, 330.02frames/s]\n 63%|██████▎   | 329208/526336 [14:41<09:55, 331.28frames/s]\n 63%|██████▎   | 332146/526336 [14:48<09:06, 355.46frames/s]\n 64%|██████▎   | 335084/526336 [14:56<08:47, 362.49frames/s]\n 64%|██████▍   | 337994/526336 [15:04<08:46, 357.45frames/s]\n 65%|██████▍   | 340976/526336 [15:11<07:58, 387.71frames/s]\n 65%|██████▌   | 343748/526336 [15:19<08:14, 368.99frames/s]\n 65%|██████▌   | 343748/526336 [15:30<08:14, 368.99frames/s]\n 66%|██████▌   | 346708/526336 [15:30<09:03, 330.74frames/s]\n 66%|██████▋   | 349460/526336 [15:39<09:07, 322.79frames/s]\n 67%|██████▋   | 352426/526336 [15:48<08:47, 329.46frames/s]\n 68%|██████▊   | 355368/526336 [15:57<08:48, 323.31frames/s]\n 68%|██████▊   | 358262/526336 [16:06<08:34, 326.93frames/s]\n 69%|██████▊   | 361262/526336 [16:13<07:48, 352.17frames/s]\n 69%|██████▉   | 364262/526336 [16:22<07:44, 348.99frames/s]\n 70%|██████▉   | 367112/526336 [16:32<08:08, 325.95frames/s]\n 70%|███████   | 369934/526336 [16:39<07:28, 348.87frames/s]\n 71%|███████   | 372764/526336 [16:48<07:38, 335.14frames/s]\n 71%|███████▏  | 375526/526336 [16:54<06:56, 362.34frames/s]\n 72%|███████▏  | 378480/526336 [17:04<07:25, 331.88frames/s]\n 72%|███████▏  | 381298/526336 [17:13<07:24, 326.07frames/s]\n 73%|███████▎  | 384156/526336 [17:23<07:34, 312.92frames/s]\n 74%|███████▎  | 387002/526336 [17:33<07:36, 304.96frames/s]\n 74%|███████▍  | 389964/526336 [17:41<07:02, 322.93frames/s]\n 75%|███████▍  | 392726/526336 [17:49<06:37, 335.76frames/s]\n 75%|███████▌  | 395488/526336 [17:54<05:51, 372.74frames/s]\n 76%|███████▌  | 398488/526336 [18:02<05:39, 376.79frames/s]\n 76%|███████▋  | 401366/526336 [18:11<05:49, 358.02frames/s]\n 77%|███████▋  | 404148/526336 [18:23<06:39, 305.77frames/s]\n 77%|███████▋  | 406884/526336 [18:33<06:41, 297.33frames/s]\n 78%|███████▊  | 409514/526336 [18:41<06:23, 304.40frames/s]\n 78%|███████▊  | 412360/526336 [18:50<06:04, 312.94frames/s]\n 79%|███████▉  | 414922/526336 [18:56<05:28, 338.75frames/s]\n 79%|███████▉  | 417568/526336 [19:02<05:02, 359.70frames/s]\n 80%|███████▉  | 420294/526336 [19:08<04:37, 381.97frames/s]\n 80%|████████  | 423280/526336 [19:13<04:02, 424.62frames/s]\n 81%|████████  | 426090/526336 [19:24<04:33, 366.24frames/s]\n 81%|████████▏ | 428888/526336 [19:34<04:51, 333.75frames/s]\n 82%|████████▏ | 431512/526336 [19:43<04:54, 321.60frames/s]\n 83%|████████▎ | 434270/526336 [19:50<04:31, 339.21frames/s]\n 83%|████████▎ | 437196/526336 [19:59<04:25, 336.09frames/s]\n 84%|████████▎ | 440196/526336 [20:06<04:06, 349.31frames/s]\n 84%|████████▍ | 443118/526336 [20:14<03:55, 353.75frames/s]\n 85%|████████▍ | 446002/526336 [20:24<03:58, 336.89frames/s]\n 85%|████████▌ | 448888/526336 [20:35<04:10, 309.65frames/s]\n 86%|████████▌ | 451718/526336 [20:43<03:54, 317.94frames/s]\n 86%|████████▋ | 454718/526336 [20:51<03:28, 342.87frames/s]\n 87%|████████▋ | 457460/526336 [20:58<03:17, 348.23frames/s]\n 87%|████████▋ | 460284/526336 [21:05<03:03, 359.20frames/s]\n 88%|████████▊ | 463278/526336 [21:11<02:40, 392.17frames/s]\n 89%|████████▊ | 466140/526336 [21:21<02:44, 365.33frames/s]\n 89%|████████▉ | 468806/526336 [21:26<02:28, 387.37frames/s]\n 90%|████████▉ | 471740/526336 [21:36<02:34, 353.86frames/s]\n 90%|█████████ | 474694/526336 [21:44<02:24, 356.69frames/s]\n 91%|█████████ | 477668/526336 [21:53<02:15, 359.01frames/s]\n 91%|█████████▏| 480542/526336 [22:03<02:18, 331.06frames/s]\n 92%|█████████▏| 483442/526336 [22:13<02:14, 319.01frames/s]\n 92%|█████████▏| 486346/526336 [22:24<02:12, 300.84frames/s]\n 93%|█████████▎| 489196/526336 [22:33<02:01, 306.29frames/s]\n 93%|█████████▎| 492078/526336 [22:41<01:49, 312.47frames/s]\n 94%|█████████▍| 495064/526336 [22:50<01:38, 316.63frames/s]\n 95%|█████████▍| 497842/526336 [23:02<01:38, 290.14frames/s]\n 95%|█████████▌| 500824/526336 [23:12<01:27, 292.41frames/s]\n 96%|█████████▌| 503786/526336 [23:22<01:16, 295.60frames/s]\n 96%|█████████▌| 506468/526336 [23:30<01:04, 308.19frames/s]\n 97%|█████████▋| 509454/526336 [23:40<00:55, 303.24frames/s]\n 97%|█████████▋| 512072/526336 [23:49<00:47, 299.09frames/s]\n 98%|█████████▊| 514786/526336 [23:57<00:37, 310.47frames/s]\n 98%|█████████▊| 517592/526336 [24:07<00:28, 301.98frames/s]\n 99%|█████████▉| 520358/526336 [24:17<00:20, 288.73frames/s]\n 99%|█████████▉| 523252/526336 [24:27<00:10, 289.18frames/s]\n100%|█████████▉| 526030/526336 [24:36<00:01, 297.39frames/s]\n100%|██████████| 526336/526336 [24:37<00:00, 297.07frames/s]\n100%|██████████| 526336/526336 [24:37<00:00, 356.24frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.34266261200406656,
        "compression_ratio": 1.446808510638298,
        "end": 15.36,
        "id": 0,
        "no_speech_prob": 0.00884524080902338,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " Yes, I unmuted myself. Okay. I'm getting okay. This is streaming. Hello, welcome to a very",
        "tokens": [
          50364,
          1079,
          11,
          286,
          19334,
          4866,
          2059,
          13,
          1033,
          13,
          286,
          478,
          1242,
          1392,
          13,
          639,
          307,
          11791,
          13,
          2425,
          11,
          2928,
          281,
          257,
          588,
          51132
        ]
      },
      {
        "avg_logprob": -0.34266261200406656,
        "compression_ratio": 1.446808510638298,
        "end": 22.52,
        "id": 1,
        "no_speech_prob": 0.00884524080902338,
        "seek": 0,
        "start": 15.36,
        "temperature": 0,
        "text": " special Coding Train episode with a slightly different looking Coding Train logo. Hopefully",
        "tokens": [
          51132,
          2121,
          383,
          8616,
          28029,
          3500,
          365,
          257,
          4748,
          819,
          1237,
          383,
          8616,
          28029,
          9699,
          13,
          10429,
          51490
        ]
      },
      {
        "avg_logprob": -0.34266261200406656,
        "compression_ratio": 1.446808510638298,
        "end": 27.86,
        "id": 2,
        "no_speech_prob": 0.00884524080902338,
        "seek": 0,
        "start": 22.52,
        "temperature": 0,
        "text": " some plants and flowers and things will start growing from here. I'm kind of vamping here",
        "tokens": [
          51490,
          512,
          5972,
          293,
          8085,
          293,
          721,
          486,
          722,
          4194,
          490,
          510,
          13,
          286,
          478,
          733,
          295,
          20017,
          278,
          510,
          51757
        ]
      },
      {
        "avg_logprob": -0.2530212932162815,
        "compression_ratio": 1.6397058823529411,
        "end": 34.18,
        "id": 3,
        "no_speech_prob": 0.1258804053068161,
        "seek": 2786,
        "start": 27.86,
        "temperature": 0,
        "text": " to see if people in the chat start to say hi, that the sound is working and everything.",
        "tokens": [
          50364,
          281,
          536,
          498,
          561,
          294,
          264,
          5081,
          722,
          281,
          584,
          4879,
          11,
          300,
          264,
          1626,
          307,
          1364,
          293,
          1203,
          13,
          50680
        ]
      },
      {
        "avg_logprob": -0.2530212932162815,
        "compression_ratio": 1.6397058823529411,
        "end": 38.1,
        "id": 4,
        "no_speech_prob": 0.1258804053068161,
        "seek": 2786,
        "start": 34.18,
        "temperature": 0,
        "text": " I'm on time today and the reason is because it's not actually me who will be presenting",
        "tokens": [
          50680,
          286,
          478,
          322,
          565,
          965,
          293,
          264,
          1778,
          307,
          570,
          309,
          311,
          406,
          767,
          385,
          567,
          486,
          312,
          15578,
          50876
        ]
      },
      {
        "avg_logprob": -0.2530212932162815,
        "compression_ratio": 1.6397058823529411,
        "end": 45.04,
        "id": 5,
        "no_speech_prob": 0.1258804053068161,
        "seek": 2786,
        "start": 38.1,
        "temperature": 0,
        "text": " to you. I'm very excited to introduce to you a guest, CJ from the Coding Garden. The Coding",
        "tokens": [
          50876,
          281,
          291,
          13,
          286,
          478,
          588,
          2919,
          281,
          5366,
          281,
          291,
          257,
          8341,
          11,
          42285,
          490,
          264,
          383,
          8616,
          19429,
          13,
          440,
          383,
          8616,
          51223
        ]
      },
      {
        "avg_logprob": -0.2530212932162815,
        "compression_ratio": 1.6397058823529411,
        "end": 49.3,
        "id": 6,
        "no_speech_prob": 0.1258804053068161,
        "seek": 2786,
        "start": 45.04,
        "temperature": 0,
        "text": " Garden is another YouTube channel that you should definitely subscribe to if you like",
        "tokens": [
          51223,
          19429,
          307,
          1071,
          3088,
          2269,
          300,
          291,
          820,
          2138,
          3022,
          281,
          498,
          291,
          411,
          51436
        ]
      },
      {
        "avg_logprob": -0.2530212932162815,
        "compression_ratio": 1.6397058823529411,
        "end": 54.7,
        "id": 7,
        "no_speech_prob": 0.1258804053068161,
        "seek": 2786,
        "start": 49.3,
        "temperature": 0,
        "text": " coding tutorials, watching them live streamed on YouTube. We'll put links and all that stuff",
        "tokens": [
          51436,
          17720,
          17616,
          11,
          1976,
          552,
          1621,
          4309,
          292,
          322,
          3088,
          13,
          492,
          603,
          829,
          6123,
          293,
          439,
          300,
          1507,
          51706
        ]
      },
      {
        "avg_logprob": -0.23654487541129998,
        "compression_ratio": 1.6666666666666667,
        "end": 59.980000000000004,
        "id": 8,
        "no_speech_prob": 0.025175534188747406,
        "seek": 5470,
        "start": 54.7,
        "temperature": 0,
        "text": " in the video description. I'm sure you can find it just by typing Coding Garden into",
        "tokens": [
          50364,
          294,
          264,
          960,
          3855,
          13,
          286,
          478,
          988,
          291,
          393,
          915,
          309,
          445,
          538,
          18444,
          383,
          8616,
          19429,
          666,
          50628
        ]
      },
      {
        "avg_logprob": -0.23654487541129998,
        "compression_ratio": 1.6666666666666667,
        "end": 67.42,
        "id": 9,
        "no_speech_prob": 0.025175534188747406,
        "seek": 5470,
        "start": 59.980000000000004,
        "temperature": 0,
        "text": " the search bar. CJ is an educator, a maker, and a full stack web developer. So somebody",
        "tokens": [
          50628,
          264,
          3164,
          2159,
          13,
          42285,
          307,
          364,
          31237,
          11,
          257,
          17127,
          11,
          293,
          257,
          1577,
          8630,
          3670,
          10754,
          13,
          407,
          2618,
          51000
        ]
      },
      {
        "avg_logprob": -0.23654487541129998,
        "compression_ratio": 1.6666666666666667,
        "end": 72.7,
        "id": 10,
        "no_speech_prob": 0.025175534188747406,
        "seek": 5470,
        "start": 67.42,
        "temperature": 0,
        "text": " who actually knows about proper full stack web development, which is something that I",
        "tokens": [
          51000,
          567,
          767,
          3255,
          466,
          2296,
          1577,
          8630,
          3670,
          3250,
          11,
          597,
          307,
          746,
          300,
          286,
          51264
        ]
      },
      {
        "avg_logprob": -0.23654487541129998,
        "compression_ratio": 1.6666666666666667,
        "end": 78.78,
        "id": 11,
        "no_speech_prob": 0.025175534188747406,
        "seek": 5470,
        "start": 72.7,
        "temperature": 0,
        "text": " definitely do not know about. So I'm excited to have CJ here for about an hour to do a",
        "tokens": [
          51264,
          2138,
          360,
          406,
          458,
          466,
          13,
          407,
          286,
          478,
          2919,
          281,
          362,
          42285,
          510,
          337,
          466,
          364,
          1773,
          281,
          360,
          257,
          51568
        ]
      },
      {
        "avg_logprob": -0.23654487541129998,
        "compression_ratio": 1.6666666666666667,
        "end": 81.74000000000001,
        "id": 12,
        "no_speech_prob": 0.025175534188747406,
        "seek": 5470,
        "start": 78.78,
        "temperature": 0,
        "text": " tutorial. I mean, he'll tell you all about it. I don't need to try to tell you about",
        "tokens": [
          51568,
          7073,
          13,
          286,
          914,
          11,
          415,
          603,
          980,
          291,
          439,
          466,
          309,
          13,
          286,
          500,
          380,
          643,
          281,
          853,
          281,
          980,
          291,
          466,
          51716
        ]
      },
      {
        "avg_logprob": -0.2742904609357807,
        "compression_ratio": 1.6847457627118645,
        "end": 87.82,
        "id": 13,
        "no_speech_prob": 0.6511120796203613,
        "seek": 8174,
        "start": 81.74,
        "temperature": 0,
        "text": " it. I'm sure I'm going to learn a ton watching it. So this will be a live stream. I am going",
        "tokens": [
          50364,
          309,
          13,
          286,
          478,
          988,
          286,
          478,
          516,
          281,
          1466,
          257,
          2952,
          1976,
          309,
          13,
          407,
          341,
          486,
          312,
          257,
          1621,
          4309,
          13,
          286,
          669,
          516,
          50668
        ]
      },
      {
        "avg_logprob": -0.2742904609357807,
        "compression_ratio": 1.6847457627118645,
        "end": 93.06,
        "id": 14,
        "no_speech_prob": 0.6511120796203613,
        "seek": 8174,
        "start": 87.82,
        "temperature": 0,
        "text": " to tiptoe off to the side and sit with the laptop looking at the chat. So if you have",
        "tokens": [
          50668,
          281,
          4125,
          1353,
          68,
          766,
          281,
          264,
          1252,
          293,
          1394,
          365,
          264,
          10732,
          1237,
          412,
          264,
          5081,
          13,
          407,
          498,
          291,
          362,
          50930
        ]
      },
      {
        "avg_logprob": -0.2742904609357807,
        "compression_ratio": 1.6847457627118645,
        "end": 97.89999999999999,
        "id": 15,
        "no_speech_prob": 0.6511120796203613,
        "seek": 8174,
        "start": 93.06,
        "temperature": 0,
        "text": " questions, ask them there. I'll kind of compile them. We can interrupt CJ if we need to, but",
        "tokens": [
          50930,
          1651,
          11,
          1029,
          552,
          456,
          13,
          286,
          603,
          733,
          295,
          31413,
          552,
          13,
          492,
          393,
          12729,
          42285,
          498,
          321,
          643,
          281,
          11,
          457,
          51172
        ]
      },
      {
        "avg_logprob": -0.2742904609357807,
        "compression_ratio": 1.6847457627118645,
        "end": 100.94,
        "id": 16,
        "no_speech_prob": 0.6511120796203613,
        "seek": 8174,
        "start": 97.89999999999999,
        "temperature": 0,
        "text": " otherwise we'll let him kind of present and then ask some more questions at the end as",
        "tokens": [
          51172,
          5911,
          321,
          603,
          718,
          796,
          733,
          295,
          1974,
          293,
          550,
          1029,
          512,
          544,
          1651,
          412,
          264,
          917,
          382,
          51324
        ]
      },
      {
        "avg_logprob": -0.2742904609357807,
        "compression_ratio": 1.6847457627118645,
        "end": 101.94,
        "id": 17,
        "no_speech_prob": 0.6511120796203613,
        "seek": 8174,
        "start": 100.94,
        "temperature": 0,
        "text": " well. Did I miss anything?",
        "tokens": [
          51324,
          731,
          13,
          2589,
          286,
          1713,
          1340,
          30,
          51374
        ]
      },
      {
        "avg_logprob": -0.2742904609357807,
        "compression_ratio": 1.6847457627118645,
        "end": 102.94,
        "id": 18,
        "no_speech_prob": 0.6511120796203613,
        "seek": 8174,
        "start": 101.94,
        "temperature": 0,
        "text": " I think that's it.",
        "tokens": [
          51374,
          286,
          519,
          300,
          311,
          309,
          13,
          51424
        ]
      },
      {
        "avg_logprob": -0.2742904609357807,
        "compression_ratio": 1.6847457627118645,
        "end": 106.94,
        "id": 19,
        "no_speech_prob": 0.6511120796203613,
        "seek": 8174,
        "start": 102.94,
        "temperature": 0,
        "text": " Okay. Can you hear CJ? You can hear his voice. So we're going to do the awkward shuffle now.",
        "tokens": [
          51424,
          1033,
          13,
          1664,
          291,
          1568,
          42285,
          30,
          509,
          393,
          1568,
          702,
          3177,
          13,
          407,
          321,
          434,
          516,
          281,
          360,
          264,
          11411,
          39426,
          586,
          13,
          51624
        ]
      },
      {
        "avg_logprob": -0.3209056854248047,
        "compression_ratio": 1.5316455696202531,
        "end": 113.66,
        "id": 20,
        "no_speech_prob": 0.16020381450653076,
        "seek": 10694,
        "start": 106.94,
        "temperature": 0,
        "text": " I'm not like a professional talk show kind of like coding host thing where, welcome,",
        "tokens": [
          50364,
          286,
          478,
          406,
          411,
          257,
          4843,
          751,
          855,
          733,
          295,
          411,
          17720,
          3975,
          551,
          689,
          11,
          2928,
          11,
          50700
        ]
      },
      {
        "avg_logprob": -0.3209056854248047,
        "compression_ratio": 1.5316455696202531,
        "end": 116.94,
        "id": 21,
        "no_speech_prob": 0.16020381450653076,
        "seek": 10694,
        "start": 113.66,
        "temperature": 0,
        "text": " and then I'm going to mute my microphone so I don't by accident make too much noise. Welcome",
        "tokens": [
          50700,
          293,
          550,
          286,
          478,
          516,
          281,
          24523,
          452,
          10952,
          370,
          286,
          500,
          380,
          538,
          6398,
          652,
          886,
          709,
          5658,
          13,
          4027,
          50864
        ]
      },
      {
        "avg_logprob": -0.3209056854248047,
        "compression_ratio": 1.5316455696202531,
        "end": 117.94,
        "id": 22,
        "no_speech_prob": 0.16020381450653076,
        "seek": 10694,
        "start": 116.94,
        "temperature": 0,
        "text": " CJ.",
        "tokens": [
          50864,
          42285,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.3209056854248047,
        "compression_ratio": 1.5316455696202531,
        "end": 126.94,
        "id": 23,
        "no_speech_prob": 0.16020381450653076,
        "seek": 10694,
        "start": 117.94,
        "temperature": 0,
        "text": " Thanks so much, Dan. First off, just huge, huge thanks to Dan and the Coding Train community.",
        "tokens": [
          50914,
          2561,
          370,
          709,
          11,
          3394,
          13,
          2386,
          766,
          11,
          445,
          2603,
          11,
          2603,
          3231,
          281,
          3394,
          293,
          264,
          383,
          8616,
          28029,
          1768,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.3209056854248047,
        "compression_ratio": 1.5316455696202531,
        "end": 133.9,
        "id": 24,
        "no_speech_prob": 0.16020381450653076,
        "seek": 10694,
        "start": 126.94,
        "temperature": 0,
        "text": " Yes, thank you. And this is going to be a lot of fun. So the plan for today is to build",
        "tokens": [
          51364,
          1079,
          11,
          1309,
          291,
          13,
          400,
          341,
          307,
          516,
          281,
          312,
          257,
          688,
          295,
          1019,
          13,
          407,
          264,
          1393,
          337,
          965,
          307,
          281,
          1322,
          51712
        ]
      },
      {
        "avg_logprob": -0.2481042258759849,
        "compression_ratio": 1.8264462809917354,
        "end": 140.06,
        "id": 25,
        "no_speech_prob": 0.7928491234779358,
        "seek": 13390,
        "start": 133.9,
        "temperature": 0,
        "text": " a full stack application. And the idea is I'm going to build a very basic Twitter clone",
        "tokens": [
          50364,
          257,
          1577,
          8630,
          3861,
          13,
          400,
          264,
          1558,
          307,
          286,
          478,
          516,
          281,
          1322,
          257,
          588,
          3875,
          5794,
          26506,
          50672
        ]
      },
      {
        "avg_logprob": -0.2481042258759849,
        "compression_ratio": 1.8264462809917354,
        "end": 144.82,
        "id": 26,
        "no_speech_prob": 0.7928491234779358,
        "seek": 13390,
        "start": 140.06,
        "temperature": 0,
        "text": " to demonstrate all the parts and pieces of the full stack. So the idea is we're going",
        "tokens": [
          50672,
          281,
          11698,
          439,
          264,
          3166,
          293,
          3755,
          295,
          264,
          1577,
          8630,
          13,
          407,
          264,
          1558,
          307,
          321,
          434,
          516,
          50910
        ]
      },
      {
        "avg_logprob": -0.2481042258759849,
        "compression_ratio": 1.8264462809917354,
        "end": 149.86,
        "id": 27,
        "no_speech_prob": 0.7928491234779358,
        "seek": 13390,
        "start": 144.82,
        "temperature": 0,
        "text": " to be building Meower, which is Twitter for cats. And it will have two features. Cats",
        "tokens": [
          50910,
          281,
          312,
          2390,
          376,
          68,
          305,
          260,
          11,
          597,
          307,
          5794,
          337,
          11111,
          13,
          400,
          309,
          486,
          362,
          732,
          4122,
          13,
          40902,
          51162
        ]
      },
      {
        "avg_logprob": -0.2481042258759849,
        "compression_ratio": 1.8264462809917354,
        "end": 155.22,
        "id": 28,
        "no_speech_prob": 0.7928491234779358,
        "seek": 13390,
        "start": 149.86,
        "temperature": 0,
        "text": " can send a mew, which is like a tweet, and cats can see all the mews that they have sent.",
        "tokens": [
          51162,
          393,
          2845,
          257,
          385,
          86,
          11,
          597,
          307,
          411,
          257,
          15258,
          11,
          293,
          11111,
          393,
          536,
          439,
          264,
          385,
          14358,
          300,
          436,
          362,
          2279,
          13,
          51430
        ]
      },
      {
        "avg_logprob": -0.2481042258759849,
        "compression_ratio": 1.8264462809917354,
        "end": 158.70000000000002,
        "id": 29,
        "no_speech_prob": 0.7928491234779358,
        "seek": 13390,
        "start": 155.22,
        "temperature": 0,
        "text": " So you can see a simple little animation here of what we're going to be building. Basically,",
        "tokens": [
          51430,
          407,
          291,
          393,
          536,
          257,
          2199,
          707,
          9603,
          510,
          295,
          437,
          321,
          434,
          516,
          281,
          312,
          2390,
          13,
          8537,
          11,
          51604
        ]
      },
      {
        "avg_logprob": -0.2558711397964343,
        "compression_ratio": 1.6865079365079365,
        "end": 163.45999999999998,
        "id": 30,
        "no_speech_prob": 0.18238568305969238,
        "seek": 15870,
        "start": 158.7,
        "temperature": 0,
        "text": " we have a form. You put in your mew. And then when you click send, it gets sent to",
        "tokens": [
          50364,
          321,
          362,
          257,
          1254,
          13,
          509,
          829,
          294,
          428,
          385,
          86,
          13,
          400,
          550,
          562,
          291,
          2052,
          2845,
          11,
          309,
          2170,
          2279,
          281,
          50602
        ]
      },
      {
        "avg_logprob": -0.2558711397964343,
        "compression_ratio": 1.6865079365079365,
        "end": 166.73999999999998,
        "id": 31,
        "no_speech_prob": 0.18238568305969238,
        "seek": 15870,
        "start": 163.45999999999998,
        "temperature": 0,
        "text": " the server. It gets put in the database. Then the front end requests all of them. It all",
        "tokens": [
          50602,
          264,
          7154,
          13,
          467,
          2170,
          829,
          294,
          264,
          8149,
          13,
          1396,
          264,
          1868,
          917,
          12475,
          439,
          295,
          552,
          13,
          467,
          439,
          50766
        ]
      },
      {
        "avg_logprob": -0.2558711397964343,
        "compression_ratio": 1.6865079365079365,
        "end": 170.61999999999998,
        "id": 32,
        "no_speech_prob": 0.18238568305969238,
        "seek": 15870,
        "start": 166.73999999999998,
        "temperature": 0,
        "text": " comes back and you see it all. And we're going to build that today from scratch.",
        "tokens": [
          50766,
          1487,
          646,
          293,
          291,
          536,
          309,
          439,
          13,
          400,
          321,
          434,
          516,
          281,
          1322,
          300,
          965,
          490,
          8459,
          13,
          50960
        ]
      },
      {
        "avg_logprob": -0.2558711397964343,
        "compression_ratio": 1.6865079365079365,
        "end": 175.45999999999998,
        "id": 33,
        "no_speech_prob": 0.18238568305969238,
        "seek": 15870,
        "start": 170.61999999999998,
        "temperature": 0,
        "text": " So I have all of our objectives here. The first one is to diagram the full stack. So",
        "tokens": [
          50960,
          407,
          286,
          362,
          439,
          295,
          527,
          15961,
          510,
          13,
          440,
          700,
          472,
          307,
          281,
          10686,
          264,
          1577,
          8630,
          13,
          407,
          51202
        ]
      },
      {
        "avg_logprob": -0.2558711397964343,
        "compression_ratio": 1.6865079365079365,
        "end": 178.82,
        "id": 34,
        "no_speech_prob": 0.18238568305969238,
        "seek": 15870,
        "start": 175.45999999999998,
        "temperature": 0,
        "text": " we're going to draw a picture and talk about the different parts and pieces and how all",
        "tokens": [
          51202,
          321,
          434,
          516,
          281,
          2642,
          257,
          3036,
          293,
          751,
          466,
          264,
          819,
          3166,
          293,
          3755,
          293,
          577,
          439,
          51370
        ]
      },
      {
        "avg_logprob": -0.30064721303443387,
        "compression_ratio": 1.4829545454545454,
        "end": 188.85999999999999,
        "id": 35,
        "no_speech_prob": 0.8263622522354126,
        "seek": 17882,
        "start": 178.82,
        "temperature": 0,
        "text": " of this interacts together. So let's do that. So the full stack is typically split up into",
        "tokens": [
          50364,
          295,
          341,
          43582,
          1214,
          13,
          407,
          718,
          311,
          360,
          300,
          13,
          407,
          264,
          1577,
          8630,
          307,
          5850,
          7472,
          493,
          666,
          50866
        ]
      },
      {
        "avg_logprob": -0.30064721303443387,
        "compression_ratio": 1.4829545454545454,
        "end": 193.85999999999999,
        "id": 36,
        "no_speech_prob": 0.8263622522354126,
        "seek": 17882,
        "start": 188.85999999999999,
        "temperature": 0,
        "text": " two pieces. More pieces than that in each piece. But you have the front end and the",
        "tokens": [
          50866,
          732,
          3755,
          13,
          5048,
          3755,
          813,
          300,
          294,
          1184,
          2522,
          13,
          583,
          291,
          362,
          264,
          1868,
          917,
          293,
          264,
          51116
        ]
      },
      {
        "avg_logprob": -0.30064721303443387,
        "compression_ratio": 1.4829545454545454,
        "end": 205.66,
        "id": 37,
        "no_speech_prob": 0.8263622522354126,
        "seek": 17882,
        "start": 193.85999999999999,
        "temperature": 0,
        "text": " back end. What is this? I think that's your head. It was in the camera. No, it's fine.",
        "tokens": [
          51116,
          646,
          917,
          13,
          708,
          307,
          341,
          30,
          286,
          519,
          300,
          311,
          428,
          1378,
          13,
          467,
          390,
          294,
          264,
          2799,
          13,
          883,
          11,
          309,
          311,
          2489,
          13,
          51706
        ]
      },
      {
        "avg_logprob": -0.3039695141362209,
        "compression_ratio": 1.805,
        "end": 213.38,
        "id": 38,
        "no_speech_prob": 0.01518816314637661,
        "seek": 20566,
        "start": 205.7,
        "temperature": 0,
        "text": " But front end and back end. So here I'm going to draw the front end. And then we also have",
        "tokens": [
          50366,
          583,
          1868,
          917,
          293,
          646,
          917,
          13,
          407,
          510,
          286,
          478,
          516,
          281,
          2642,
          264,
          1868,
          917,
          13,
          400,
          550,
          321,
          611,
          362,
          50750
        ]
      },
      {
        "avg_logprob": -0.3039695141362209,
        "compression_ratio": 1.805,
        "end": 222.06,
        "id": 39,
        "no_speech_prob": 0.01518816314637661,
        "seek": 20566,
        "start": 213.38,
        "temperature": 0,
        "text": " the back end. And when we talk about the front end, this is what the user sees. So I'll also",
        "tokens": [
          50750,
          264,
          646,
          917,
          13,
          400,
          562,
          321,
          751,
          466,
          264,
          1868,
          917,
          11,
          341,
          307,
          437,
          264,
          4195,
          8194,
          13,
          407,
          286,
          603,
          611,
          51184
        ]
      },
      {
        "avg_logprob": -0.3039695141362209,
        "compression_ratio": 1.805,
        "end": 230.14,
        "id": 40,
        "no_speech_prob": 0.01518816314637661,
        "seek": 20566,
        "start": 222.06,
        "temperature": 0,
        "text": " be referring to this as the client. But this is what the user sees. So the user uses a",
        "tokens": [
          51184,
          312,
          13761,
          281,
          341,
          382,
          264,
          6423,
          13,
          583,
          341,
          307,
          437,
          264,
          4195,
          8194,
          13,
          407,
          264,
          4195,
          4960,
          257,
          51588
        ]
      },
      {
        "avg_logprob": -0.3039695141362209,
        "compression_ratio": 1.805,
        "end": 234.7,
        "id": 41,
        "no_speech_prob": 0.01518816314637661,
        "seek": 20566,
        "start": 230.14,
        "temperature": 0,
        "text": " web browser. So you can think of it like it's a little box here. And they type in the URL.",
        "tokens": [
          51588,
          3670,
          11185,
          13,
          407,
          291,
          393,
          519,
          295,
          309,
          411,
          309,
          311,
          257,
          707,
          2424,
          510,
          13,
          400,
          436,
          2010,
          294,
          264,
          12905,
          13,
          51816
        ]
      },
      {
        "avg_logprob": -0.2544038315449864,
        "compression_ratio": 1.8433734939759037,
        "end": 239.22,
        "id": 42,
        "no_speech_prob": 0.0001088950812118128,
        "seek": 23470,
        "start": 235.42,
        "temperature": 0,
        "text": " And they'll have some place to type. And they'll have a button that they can press. But the",
        "tokens": [
          50400,
          400,
          436,
          603,
          362,
          512,
          1081,
          281,
          2010,
          13,
          400,
          436,
          603,
          362,
          257,
          2960,
          300,
          436,
          393,
          1886,
          13,
          583,
          264,
          50590
        ]
      },
      {
        "avg_logprob": -0.2544038315449864,
        "compression_ratio": 1.8433734939759037,
        "end": 243.5,
        "id": 43,
        "no_speech_prob": 0.0001088950812118128,
        "seek": 23470,
        "start": 239.22,
        "temperature": 0,
        "text": " front end is what the user actually sees. And this gets loaded into a browser. And so you can",
        "tokens": [
          50590,
          1868,
          917,
          307,
          437,
          264,
          4195,
          767,
          8194,
          13,
          400,
          341,
          2170,
          13210,
          666,
          257,
          11185,
          13,
          400,
          370,
          291,
          393,
          50804
        ]
      },
      {
        "avg_logprob": -0.2544038315449864,
        "compression_ratio": 1.8433734939759037,
        "end": 250.17999999999998,
        "id": 44,
        "no_speech_prob": 0.0001088950812118128,
        "seek": 23470,
        "start": 243.5,
        "temperature": 0,
        "text": " think of this on a laptop, on a desktop, on a mobile phone. Anything that has a web browser,",
        "tokens": [
          50804,
          519,
          295,
          341,
          322,
          257,
          10732,
          11,
          322,
          257,
          14502,
          11,
          322,
          257,
          6013,
          2593,
          13,
          11998,
          300,
          575,
          257,
          3670,
          11185,
          11,
          51138
        ]
      },
      {
        "avg_logprob": -0.2544038315449864,
        "compression_ratio": 1.8433734939759037,
        "end": 256.74,
        "id": 45,
        "no_speech_prob": 0.0001088950812118128,
        "seek": 23470,
        "start": 250.17999999999998,
        "temperature": 0,
        "text": " that is the client. And that is the front end. So there's also the back end. And here we're",
        "tokens": [
          51138,
          300,
          307,
          264,
          6423,
          13,
          400,
          300,
          307,
          264,
          1868,
          917,
          13,
          407,
          456,
          311,
          611,
          264,
          646,
          917,
          13,
          400,
          510,
          321,
          434,
          51466
        ]
      },
      {
        "avg_logprob": -0.2544038315449864,
        "compression_ratio": 1.8433734939759037,
        "end": 260.7,
        "id": 46,
        "no_speech_prob": 0.0001088950812118128,
        "seek": 23470,
        "start": 256.74,
        "temperature": 0,
        "text": " going to have a couple different back end servers. So the first one will be known as the",
        "tokens": [
          51466,
          516,
          281,
          362,
          257,
          1916,
          819,
          646,
          917,
          15909,
          13,
          407,
          264,
          700,
          472,
          486,
          312,
          2570,
          382,
          264,
          51664
        ]
      },
      {
        "avg_logprob": -0.23774633602220185,
        "compression_ratio": 1.7162162162162162,
        "end": 274.38,
        "id": 47,
        "no_speech_prob": 0.00016603538824710995,
        "seek": 26070,
        "start": 260.7,
        "temperature": 0,
        "text": " static file server. And this is where all of the files that we write to run inside of a client",
        "tokens": [
          50364,
          13437,
          3991,
          7154,
          13,
          400,
          341,
          307,
          689,
          439,
          295,
          264,
          7098,
          300,
          321,
          2464,
          281,
          1190,
          1854,
          295,
          257,
          6423,
          51048
        ]
      },
      {
        "avg_logprob": -0.23774633602220185,
        "compression_ratio": 1.7162162162162162,
        "end": 278.58,
        "id": 48,
        "no_speech_prob": 0.00016603538824710995,
        "seek": 26070,
        "start": 274.53999999999996,
        "temperature": 0,
        "text": " will live. And I guess it's important to note that there are a lot of different ways you could",
        "tokens": [
          51056,
          486,
          1621,
          13,
          400,
          286,
          2041,
          309,
          311,
          1021,
          281,
          3637,
          300,
          456,
          366,
          257,
          688,
          295,
          819,
          2098,
          291,
          727,
          51258
        ]
      },
      {
        "avg_logprob": -0.23774633602220185,
        "compression_ratio": 1.7162162162162162,
        "end": 283.02,
        "id": 49,
        "no_speech_prob": 0.00016603538824710995,
        "seek": 26070,
        "start": 278.58,
        "temperature": 0,
        "text": " build a full stack application. But the way I'm going to build it today kind of splits things up",
        "tokens": [
          51258,
          1322,
          257,
          1577,
          8630,
          3861,
          13,
          583,
          264,
          636,
          286,
          478,
          516,
          281,
          1322,
          309,
          965,
          733,
          295,
          37741,
          721,
          493,
          51480
        ]
      },
      {
        "avg_logprob": -0.23774633602220185,
        "compression_ratio": 1.7162162162162162,
        "end": 287.53999999999996,
        "id": 50,
        "no_speech_prob": 0.00016603538824710995,
        "seek": 26070,
        "start": 283.02,
        "temperature": 0,
        "text": " in this way. But let me know. There are a lot of other ways you could do this. And on the back",
        "tokens": [
          51480,
          294,
          341,
          636,
          13,
          583,
          718,
          385,
          458,
          13,
          821,
          366,
          257,
          688,
          295,
          661,
          2098,
          291,
          727,
          360,
          341,
          13,
          400,
          322,
          264,
          646,
          51706
        ]
      },
      {
        "avg_logprob": -0.24297134163453407,
        "compression_ratio": 1.6768558951965065,
        "end": 297.3,
        "id": 51,
        "no_speech_prob": 0.0002913664502557367,
        "seek": 28754,
        "start": 287.54,
        "temperature": 0,
        "text": " end, you also might have more of a dynamic server. Dynamic server. And today we're going to be",
        "tokens": [
          50364,
          917,
          11,
          291,
          611,
          1062,
          362,
          544,
          295,
          257,
          8546,
          7154,
          13,
          45440,
          7154,
          13,
          400,
          965,
          321,
          434,
          516,
          281,
          312,
          50852
        ]
      },
      {
        "avg_logprob": -0.24297134163453407,
        "compression_ratio": 1.6768558951965065,
        "end": 304.78000000000003,
        "id": 52,
        "no_speech_prob": 0.0002913664502557367,
        "seek": 28754,
        "start": 297.3,
        "temperature": 0,
        "text": " using Node.js for that. But there are a lot of other things you could use. And specifically, we",
        "tokens": [
          50852,
          1228,
          38640,
          13,
          25530,
          337,
          300,
          13,
          583,
          456,
          366,
          257,
          688,
          295,
          661,
          721,
          291,
          727,
          764,
          13,
          400,
          4682,
          11,
          321,
          51226
        ]
      },
      {
        "avg_logprob": -0.24297134163453407,
        "compression_ratio": 1.6768558951965065,
        "end": 309.3,
        "id": 53,
        "no_speech_prob": 0.0002913664502557367,
        "seek": 28754,
        "start": 304.78000000000003,
        "temperature": 0,
        "text": " are going to be using JavaScript for this dynamic server. But you've probably heard of PHP or C",
        "tokens": [
          51226,
          366,
          516,
          281,
          312,
          1228,
          15778,
          337,
          341,
          8546,
          7154,
          13,
          583,
          291,
          600,
          1391,
          2198,
          295,
          47298,
          420,
          383,
          51452
        ]
      },
      {
        "avg_logprob": -0.24297134163453407,
        "compression_ratio": 1.6768558951965065,
        "end": 314.3,
        "id": 54,
        "no_speech_prob": 0.0002913664502557367,
        "seek": 28754,
        "start": 309.3,
        "temperature": 0,
        "text": " Sharp or Java. Those different things could be running on the server here. At the end of the day,",
        "tokens": [
          51452,
          31654,
          420,
          10745,
          13,
          3950,
          819,
          721,
          727,
          312,
          2614,
          322,
          264,
          7154,
          510,
          13,
          1711,
          264,
          917,
          295,
          264,
          786,
          11,
          51702
        ]
      },
      {
        "avg_logprob": -0.2808677919449345,
        "compression_ratio": 1.5971563981042654,
        "end": 323.18,
        "id": 55,
        "no_speech_prob": 0.00038596114609390497,
        "seek": 31430,
        "start": 314.98,
        "temperature": 0,
        "text": " whatever is running on here will return JSON data. So this is we're going to be building a JSON API.",
        "tokens": [
          50398,
          2035,
          307,
          2614,
          322,
          510,
          486,
          2736,
          31828,
          1412,
          13,
          407,
          341,
          307,
          321,
          434,
          516,
          281,
          312,
          2390,
          257,
          31828,
          9362,
          13,
          50808
        ]
      },
      {
        "avg_logprob": -0.2808677919449345,
        "compression_ratio": 1.5971563981042654,
        "end": 330.42,
        "id": 56,
        "no_speech_prob": 0.00038596114609390497,
        "seek": 31430,
        "start": 323.18,
        "temperature": 0,
        "text": " So if you've heard of API, if you've heard the word cloud, or I guess, yeah, cloud, that's really",
        "tokens": [
          50808,
          407,
          498,
          291,
          600,
          2198,
          295,
          9362,
          11,
          498,
          291,
          600,
          2198,
          264,
          1349,
          4588,
          11,
          420,
          286,
          2041,
          11,
          1338,
          11,
          4588,
          11,
          300,
          311,
          534,
          51170
        ]
      },
      {
        "avg_logprob": -0.2808677919449345,
        "compression_ratio": 1.5971563981042654,
        "end": 334.86,
        "id": 57,
        "no_speech_prob": 0.00038596114609390497,
        "seek": 31430,
        "start": 330.42,
        "temperature": 0,
        "text": " when we're talking about the back when you when you say it's in the cloud, it's some back end type",
        "tokens": [
          51170,
          562,
          321,
          434,
          1417,
          466,
          264,
          646,
          562,
          291,
          562,
          291,
          584,
          309,
          311,
          294,
          264,
          4588,
          11,
          309,
          311,
          512,
          646,
          917,
          2010,
          51392
        ]
      },
      {
        "avg_logprob": -0.2808677919449345,
        "compression_ratio": 1.5971563981042654,
        "end": 335.42,
        "id": 58,
        "no_speech_prob": 0.00038596114609390497,
        "seek": 31430,
        "start": 334.86,
        "temperature": 0,
        "text": " of server.",
        "tokens": [
          51392,
          295,
          7154,
          13,
          51420
        ]
      },
      {
        "avg_logprob": -0.2808677919449345,
        "compression_ratio": 1.5971563981042654,
        "end": 339.42,
        "id": 59,
        "no_speech_prob": 0.00038596114609390497,
        "seek": 31430,
        "start": 338.26,
        "temperature": 0,
        "text": " Real professional operation.",
        "tokens": [
          51562,
          8467,
          4843,
          6916,
          13,
          51620
        ]
      },
      {
        "avg_logprob": -0.22623913243131819,
        "compression_ratio": 1.6824034334763949,
        "end": 347.02000000000004,
        "id": 60,
        "no_speech_prob": 0.01495334506034851,
        "seek": 33942,
        "start": 339.66,
        "temperature": 0,
        "text": " No, it's great. Cool. So we have the client. That's the front end, we have the back end. So we will",
        "tokens": [
          50376,
          883,
          11,
          309,
          311,
          869,
          13,
          8561,
          13,
          407,
          321,
          362,
          264,
          6423,
          13,
          663,
          311,
          264,
          1868,
          917,
          11,
          321,
          362,
          264,
          646,
          917,
          13,
          407,
          321,
          486,
          50744
        ]
      },
      {
        "avg_logprob": -0.22623913243131819,
        "compression_ratio": 1.6824034334763949,
        "end": 351.62,
        "id": 61,
        "no_speech_prob": 0.01495334506034851,
        "seek": 33942,
        "start": 347.02000000000004,
        "temperature": 0,
        "text": " call this the dynamic server. This is where Node.js will be running. For our static file server,",
        "tokens": [
          50744,
          818,
          341,
          264,
          8546,
          7154,
          13,
          639,
          307,
          689,
          38640,
          13,
          25530,
          486,
          312,
          2614,
          13,
          1171,
          527,
          13437,
          3991,
          7154,
          11,
          50974
        ]
      },
      {
        "avg_logprob": -0.22623913243131819,
        "compression_ratio": 1.6824034334763949,
        "end": 357.54,
        "id": 62,
        "no_speech_prob": 0.01495334506034851,
        "seek": 33942,
        "start": 351.62,
        "temperature": 0,
        "text": " we're going to be using something called live server. I believe Dan set up this the other day on",
        "tokens": [
          50974,
          321,
          434,
          516,
          281,
          312,
          1228,
          746,
          1219,
          1621,
          7154,
          13,
          286,
          1697,
          3394,
          992,
          493,
          341,
          264,
          661,
          786,
          322,
          51270
        ]
      },
      {
        "avg_logprob": -0.22623913243131819,
        "compression_ratio": 1.6824034334763949,
        "end": 364.18,
        "id": 63,
        "no_speech_prob": 0.01495334506034851,
        "seek": 33942,
        "start": 357.54,
        "temperature": 0,
        "text": " your setup stream. So he shows how you can install that. I'm just going to be using it to serve up",
        "tokens": [
          51270,
          428,
          8657,
          4309,
          13,
          407,
          415,
          3110,
          577,
          291,
          393,
          3625,
          300,
          13,
          286,
          478,
          445,
          516,
          281,
          312,
          1228,
          309,
          281,
          4596,
          493,
          51602
        ]
      },
      {
        "avg_logprob": -0.2965219173025578,
        "compression_ratio": 1.6682926829268292,
        "end": 370.46,
        "id": 64,
        "no_speech_prob": 0.03621440753340721,
        "seek": 36418,
        "start": 364.18,
        "temperature": 0,
        "text": " our client. And then another part of the back end is the database. And that usually is drawn like",
        "tokens": [
          50364,
          527,
          6423,
          13,
          400,
          550,
          1071,
          644,
          295,
          264,
          646,
          917,
          307,
          264,
          8149,
          13,
          400,
          300,
          2673,
          307,
          10117,
          411,
          50678
        ]
      },
      {
        "avg_logprob": -0.2965219173025578,
        "compression_ratio": 1.6682926829268292,
        "end": 371.14,
        "id": 65,
        "no_speech_prob": 0.03621440753340721,
        "seek": 36418,
        "start": 370.46,
        "temperature": 0,
        "text": " this.",
        "tokens": [
          50678,
          341,
          13,
          50712
        ]
      },
      {
        "avg_logprob": -0.2965219173025578,
        "compression_ratio": 1.6682926829268292,
        "end": 378.1,
        "id": 66,
        "no_speech_prob": 0.03621440753340721,
        "seek": 36418,
        "start": 372.38,
        "temperature": 0,
        "text": " The database, and there are lots of different things you can use for your database. There's might",
        "tokens": [
          50774,
          440,
          8149,
          11,
          293,
          456,
          366,
          3195,
          295,
          819,
          721,
          291,
          393,
          764,
          337,
          428,
          8149,
          13,
          821,
          311,
          1062,
          51060
        ]
      },
      {
        "avg_logprob": -0.2965219173025578,
        "compression_ratio": 1.6682926829268292,
        "end": 382.3,
        "id": 67,
        "no_speech_prob": 0.03621440753340721,
        "seek": 36418,
        "start": 378.1,
        "temperature": 0,
        "text": " have heard of SQL, you might have heard of NoSQL. Today, specifically, we're going to be using a",
        "tokens": [
          51060,
          362,
          2198,
          295,
          19200,
          11,
          291,
          1062,
          362,
          2198,
          295,
          883,
          39934,
          13,
          2692,
          11,
          4682,
          11,
          321,
          434,
          516,
          281,
          312,
          1228,
          257,
          51270
        ]
      },
      {
        "avg_logprob": -0.2965219173025578,
        "compression_ratio": 1.6682926829268292,
        "end": 385.14,
        "id": 68,
        "no_speech_prob": 0.03621440753340721,
        "seek": 36418,
        "start": 382.3,
        "temperature": 0,
        "text": " NoSQL database called MongoDB.",
        "tokens": [
          51270,
          883,
          39934,
          8149,
          1219,
          48380,
          27735,
          13,
          51412
        ]
      },
      {
        "avg_logprob": -0.2965219173025578,
        "compression_ratio": 1.6682926829268292,
        "end": 388.1,
        "id": 69,
        "no_speech_prob": 0.03621440753340721,
        "seek": 36418,
        "start": 387.22,
        "temperature": 0,
        "text": " MongoDB.",
        "tokens": [
          51516,
          48380,
          27735,
          13,
          51560
        ]
      },
      {
        "avg_logprob": -0.2965219173025578,
        "compression_ratio": 1.6682926829268292,
        "end": 390.18,
        "id": 70,
        "no_speech_prob": 0.03621440753340721,
        "seek": 36418,
        "start": 389.5,
        "temperature": 0,
        "text": " And",
        "tokens": [
          51630,
          400,
          51664
        ]
      },
      {
        "avg_logprob": -0.359048757660255,
        "compression_ratio": 1.6515837104072397,
        "end": 396.74,
        "id": 71,
        "no_speech_prob": 0.00008480581891490147,
        "seek": 39018,
        "start": 390.22,
        "temperature": 0,
        "text": " you might choose a different database depending on the application that you're building. But today, we",
        "tokens": [
          50366,
          291,
          1062,
          2826,
          257,
          819,
          8149,
          5413,
          322,
          264,
          3861,
          300,
          291,
          434,
          2390,
          13,
          583,
          965,
          11,
          321,
          50692
        ]
      },
      {
        "avg_logprob": -0.359048757660255,
        "compression_ratio": 1.6515837104072397,
        "end": 400.7,
        "id": 72,
        "no_speech_prob": 0.00008480581891490147,
        "seek": 39018,
        "start": 396.74,
        "temperature": 0,
        "text": " are going to be using MongoDB. And really, when you build an application, you pick and choose maybe",
        "tokens": [
          50692,
          366,
          516,
          281,
          312,
          1228,
          48380,
          27735,
          13,
          400,
          534,
          11,
          562,
          291,
          1322,
          364,
          3861,
          11,
          291,
          1888,
          293,
          2826,
          1310,
          50890
        ]
      },
      {
        "avg_logprob": -0.359048757660255,
        "compression_ratio": 1.6515837104072397,
        "end": 406.34000000000003,
        "id": 73,
        "no_speech_prob": 0.00008480581891490147,
        "seek": 39018,
        "start": 400.7,
        "temperature": 0,
        "text": " what's the best type of database. But the main idea with a database is that it is persistent storage.",
        "tokens": [
          50890,
          437,
          311,
          264,
          1151,
          2010,
          295,
          8149,
          13,
          583,
          264,
          2135,
          1558,
          365,
          257,
          8149,
          307,
          300,
          309,
          307,
          24315,
          6725,
          13,
          51172
        ]
      },
      {
        "avg_logprob": -0.359048757660255,
        "compression_ratio": 1.6515837104072397,
        "end": 408.38,
        "id": 74,
        "no_speech_prob": 0.00008480581891490147,
        "seek": 39018,
        "start": 406.82,
        "temperature": 0,
        "text": " Persistent...",
        "tokens": [
          51196,
          14006,
          25367,
          485,
          51274
        ]
      },
      {
        "avg_logprob": -0.359048757660255,
        "compression_ratio": 1.6515837104072397,
        "end": 412.34000000000003,
        "id": 75,
        "no_speech_prob": 0.00008480581891490147,
        "seek": 39018,
        "start": 409.82,
        "temperature": 0,
        "text": " That might not be how you spell that. Storage.",
        "tokens": [
          51346,
          663,
          1062,
          406,
          312,
          577,
          291,
          9827,
          300,
          13,
          36308,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -0.21129145188765092,
        "compression_ratio": 1.626984126984127,
        "end": 420.94,
        "id": 76,
        "no_speech_prob": 0.001838439842686057,
        "seek": 41234,
        "start": 413.34,
        "temperature": 0,
        "text": " But let's take an example. So when you visit twitter.com, a web page loads, and it's very dynamic.",
        "tokens": [
          50414,
          583,
          718,
          311,
          747,
          364,
          1365,
          13,
          407,
          562,
          291,
          3441,
          21439,
          13,
          1112,
          11,
          257,
          3670,
          3028,
          12668,
          11,
          293,
          309,
          311,
          588,
          8546,
          13,
          50794
        ]
      },
      {
        "avg_logprob": -0.21129145188765092,
        "compression_ratio": 1.626984126984127,
        "end": 424.7,
        "id": 77,
        "no_speech_prob": 0.001838439842686057,
        "seek": 41234,
        "start": 420.94,
        "temperature": 0,
        "text": " There's a lot of stuff in it. You have your tweets, you have other people's tweets, you have a place",
        "tokens": [
          50794,
          821,
          311,
          257,
          688,
          295,
          1507,
          294,
          309,
          13,
          509,
          362,
          428,
          25671,
          11,
          291,
          362,
          661,
          561,
          311,
          25671,
          11,
          291,
          362,
          257,
          1081,
          50982
        ]
      },
      {
        "avg_logprob": -0.21129145188765092,
        "compression_ratio": 1.626984126984127,
        "end": 430.46,
        "id": 78,
        "no_speech_prob": 0.001838439842686057,
        "seek": 41234,
        "start": 424.7,
        "temperature": 0,
        "text": " where you can search and you have all of this stuff. But what really happens is when you type a URL into",
        "tokens": [
          50982,
          689,
          291,
          393,
          3164,
          293,
          291,
          362,
          439,
          295,
          341,
          1507,
          13,
          583,
          437,
          534,
          2314,
          307,
          562,
          291,
          2010,
          257,
          12905,
          666,
          51270
        ]
      },
      {
        "avg_logprob": -0.21129145188765092,
        "compression_ratio": 1.626984126984127,
        "end": 437.26,
        "id": 79,
        "no_speech_prob": 0.001838439842686057,
        "seek": 41234,
        "start": 430.46,
        "temperature": 0,
        "text": " your browser and hit enter, that makes a request to, in this case, we'll say a static file server. So the",
        "tokens": [
          51270,
          428,
          11185,
          293,
          2045,
          3242,
          11,
          300,
          1669,
          257,
          5308,
          281,
          11,
          294,
          341,
          1389,
          11,
          321,
          603,
          584,
          257,
          13437,
          3991,
          7154,
          13,
          407,
          264,
          51610
        ]
      },
      {
        "avg_logprob": -0.24946534231807407,
        "compression_ratio": 1.5727699530516432,
        "end": 444.38,
        "id": 80,
        "no_speech_prob": 0.00003591251515899785,
        "seek": 43726,
        "start": 437.26,
        "temperature": 0,
        "text": " moment you type in a URL, this will make a get request for some file. In this case, it's going to request",
        "tokens": [
          50364,
          1623,
          291,
          2010,
          294,
          257,
          12905,
          11,
          341,
          486,
          652,
          257,
          483,
          5308,
          337,
          512,
          3991,
          13,
          682,
          341,
          1389,
          11,
          309,
          311,
          516,
          281,
          5308,
          50720
        ]
      },
      {
        "avg_logprob": -0.24946534231807407,
        "compression_ratio": 1.5727699530516432,
        "end": 453.65999999999997,
        "id": 81,
        "no_speech_prob": 0.00003591251515899785,
        "seek": 43726,
        "start": 444.7,
        "temperature": 0,
        "text": " index.html. And the static file server will then respond with that file, which contains all of the HTML",
        "tokens": [
          50736,
          8186,
          13,
          357,
          15480,
          13,
          400,
          264,
          13437,
          3991,
          7154,
          486,
          550,
          4196,
          365,
          300,
          3991,
          11,
          597,
          8306,
          439,
          295,
          264,
          17995,
          51184
        ]
      },
      {
        "avg_logprob": -0.24946534231807407,
        "compression_ratio": 1.5727699530516432,
        "end": 456.02,
        "id": 82,
        "no_speech_prob": 0.00003591251515899785,
        "seek": 43726,
        "start": 453.65999999999997,
        "temperature": 0,
        "text": " contents. HTML.",
        "tokens": [
          51184,
          15768,
          13,
          17995,
          13,
          51302
        ]
      },
      {
        "avg_logprob": -0.24946534231807407,
        "compression_ratio": 1.5727699530516432,
        "end": 463.65999999999997,
        "id": 83,
        "no_speech_prob": 0.00003591251515899785,
        "seek": 43726,
        "start": 458.5,
        "temperature": 0,
        "text": " And this is the code that we write, and it will get loaded into the browser and then the user will see it. So",
        "tokens": [
          51426,
          400,
          341,
          307,
          264,
          3089,
          300,
          321,
          2464,
          11,
          293,
          309,
          486,
          483,
          13210,
          666,
          264,
          11185,
          293,
          550,
          264,
          4195,
          486,
          536,
          309,
          13,
          407,
          51684
        ]
      },
      {
        "avg_logprob": -0.2501995937883361,
        "compression_ratio": 1.6339622641509435,
        "end": 467.66,
        "id": 84,
        "no_speech_prob": 0.00039818533696234226,
        "seek": 46366,
        "start": 463.82000000000005,
        "temperature": 0,
        "text": " this is kind of the first part of what's happening in the full stack. Let's write some code.",
        "tokens": [
          50372,
          341,
          307,
          733,
          295,
          264,
          700,
          644,
          295,
          437,
          311,
          2737,
          294,
          264,
          1577,
          8630,
          13,
          961,
          311,
          2464,
          512,
          3089,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2501995937883361,
        "compression_ratio": 1.6339622641509435,
        "end": 476.78000000000003,
        "id": 85,
        "no_speech_prob": 0.00039818533696234226,
        "seek": 46366,
        "start": 469.78000000000003,
        "temperature": 0,
        "text": " Okay, so the first thing we'll do is set up the client side. So in this directory here, oh, and before I forget,",
        "tokens": [
          50670,
          1033,
          11,
          370,
          264,
          700,
          551,
          321,
          603,
          360,
          307,
          992,
          493,
          264,
          6423,
          1252,
          13,
          407,
          294,
          341,
          21120,
          510,
          11,
          1954,
          11,
          293,
          949,
          286,
          2870,
          11,
          51020
        ]
      },
      {
        "avg_logprob": -0.2501995937883361,
        "compression_ratio": 1.6339622641509435,
        "end": 483.02000000000004,
        "id": 86,
        "no_speech_prob": 0.00039818533696234226,
        "seek": 46366,
        "start": 476.78000000000003,
        "temperature": 0,
        "text": " I did, all of this is on GitHub right now. It's just a checklist. But as I code, I'll push it up to GitHub. One of",
        "tokens": [
          51020,
          286,
          630,
          11,
          439,
          295,
          341,
          307,
          322,
          23331,
          558,
          586,
          13,
          467,
          311,
          445,
          257,
          30357,
          13,
          583,
          382,
          286,
          3089,
          11,
          286,
          603,
          2944,
          309,
          493,
          281,
          23331,
          13,
          1485,
          295,
          51332
        ]
      },
      {
        "avg_logprob": -0.2501995937883361,
        "compression_ratio": 1.6339622641509435,
        "end": 488.06,
        "id": 87,
        "no_speech_prob": 0.00039818533696234226,
        "seek": 46366,
        "start": 483.02000000000004,
        "temperature": 0,
        "text": " the mods can potentially share this link. I put it in the Slack, you can share it in the chat, if people want to",
        "tokens": [
          51332,
          264,
          30899,
          393,
          7263,
          2073,
          341,
          2113,
          13,
          286,
          829,
          309,
          294,
          264,
          37211,
          11,
          291,
          393,
          2073,
          309,
          294,
          264,
          5081,
          11,
          498,
          561,
          528,
          281,
          51584
        ]
      },
      {
        "avg_logprob": -0.23132855241948908,
        "compression_ratio": 1.5495049504950495,
        "end": 496.06,
        "id": 88,
        "no_speech_prob": 0.07262589037418365,
        "seek": 48806,
        "start": 488.06,
        "temperature": 0,
        "text": " click on it. But the first thing is we'll create a client folder. And inside of that client folder, here in VS",
        "tokens": [
          50364,
          2052,
          322,
          309,
          13,
          583,
          264,
          700,
          551,
          307,
          321,
          603,
          1884,
          257,
          6423,
          10820,
          13,
          400,
          1854,
          295,
          300,
          6423,
          10820,
          11,
          510,
          294,
          25091,
          50764
        ]
      },
      {
        "avg_logprob": -0.23132855241948908,
        "compression_ratio": 1.5495049504950495,
        "end": 505.18,
        "id": 89,
        "no_speech_prob": 0.07262589037418365,
        "seek": 48806,
        "start": 496.06,
        "temperature": 0,
        "text": " Code, we'll create a new file and call it index.html. I'll create a basic HTML document. The title will be",
        "tokens": [
          50764,
          15549,
          11,
          321,
          603,
          1884,
          257,
          777,
          3991,
          293,
          818,
          309,
          8186,
          13,
          357,
          15480,
          13,
          286,
          603,
          1884,
          257,
          3875,
          17995,
          4166,
          13,
          440,
          4876,
          486,
          312,
          51220
        ]
      },
      {
        "avg_logprob": -0.23132855241948908,
        "compression_ratio": 1.5495049504950495,
        "end": 518.02,
        "id": 90,
        "no_speech_prob": 0.07262589037418365,
        "seek": 48806,
        "start": 506.54,
        "temperature": 0,
        "text": " Twitter for cats. And let's put like a little cat emoji. There we go. For now, I'm going to get",
        "tokens": [
          51288,
          5794,
          337,
          11111,
          13,
          400,
          718,
          311,
          829,
          411,
          257,
          707,
          3857,
          31595,
          13,
          821,
          321,
          352,
          13,
          1171,
          586,
          11,
          286,
          478,
          516,
          281,
          483,
          51862
        ]
      },
      {
        "avg_logprob": -0.21540478578547842,
        "compression_ratio": 1.5475113122171946,
        "end": 524.6999999999999,
        "id": 91,
        "no_speech_prob": 0.0005703053902834654,
        "seek": 51802,
        "start": 518.02,
        "temperature": 0,
        "text": " rid of this link in the script. Here in the body, we'll add a header. And inside the header, I'll have an h1 that",
        "tokens": [
          50364,
          3973,
          295,
          341,
          2113,
          294,
          264,
          5755,
          13,
          1692,
          294,
          264,
          1772,
          11,
          321,
          603,
          909,
          257,
          23117,
          13,
          400,
          1854,
          264,
          23117,
          11,
          286,
          603,
          362,
          364,
          276,
          16,
          300,
          50698
        ]
      },
      {
        "avg_logprob": -0.21540478578547842,
        "compression_ratio": 1.5475113122171946,
        "end": 535.54,
        "id": 92,
        "no_speech_prob": 0.0005703053902834654,
        "seek": 51802,
        "start": 524.6999999999999,
        "temperature": 0,
        "text": " just says, same thing, meower, Twitter for cats. Okay, so I have a basic HTML file. This is what the user will see.",
        "tokens": [
          50698,
          445,
          1619,
          11,
          912,
          551,
          11,
          45132,
          260,
          11,
          5794,
          337,
          11111,
          13,
          1033,
          11,
          370,
          286,
          362,
          257,
          3875,
          17995,
          3991,
          13,
          639,
          307,
          437,
          264,
          4195,
          486,
          536,
          13,
          51240
        ]
      },
      {
        "avg_logprob": -0.21540478578547842,
        "compression_ratio": 1.5475113122171946,
        "end": 542.3,
        "id": 93,
        "no_speech_prob": 0.0005703053902834654,
        "seek": 51802,
        "start": 535.54,
        "temperature": 0,
        "text": " So in my terminal, I am currently in the client folder. And here is where I'll run the live server. So this will",
        "tokens": [
          51240,
          407,
          294,
          452,
          14709,
          11,
          286,
          669,
          4362,
          294,
          264,
          6423,
          10820,
          13,
          400,
          510,
          307,
          689,
          286,
          603,
          1190,
          264,
          1621,
          7154,
          13,
          407,
          341,
          486,
          51578
        ]
      },
      {
        "avg_logprob": -0.20759620974140783,
        "compression_ratio": 1.710144927536232,
        "end": 549.0999999999999,
        "id": 94,
        "no_speech_prob": 0.09533937275409698,
        "seek": 54230,
        "start": 542.3,
        "temperature": 0,
        "text": " start up a static file server. And then when the browser loads, it loads that file that I created. So if I change that",
        "tokens": [
          50364,
          722,
          493,
          257,
          13437,
          3991,
          7154,
          13,
          400,
          550,
          562,
          264,
          11185,
          12668,
          11,
          309,
          12668,
          300,
          3991,
          300,
          286,
          2942,
          13,
          407,
          498,
          286,
          1319,
          300,
          50704
        ]
      },
      {
        "avg_logprob": -0.20759620974140783,
        "compression_ratio": 1.710144927536232,
        "end": 558.02,
        "id": 95,
        "no_speech_prob": 0.09533937275409698,
        "seek": 54230,
        "start": 549.0999999999999,
        "temperature": 0,
        "text": " file, let's add more emojis, cat, another cat, and save it, live server automatically refresh. But the browser will",
        "tokens": [
          50704,
          3991,
          11,
          718,
          311,
          909,
          544,
          19611,
          40371,
          11,
          3857,
          11,
          1071,
          3857,
          11,
          293,
          3155,
          309,
          11,
          1621,
          7154,
          6772,
          15134,
          13,
          583,
          264,
          11185,
          486,
          51150
        ]
      },
      {
        "avg_logprob": -0.20759620974140783,
        "compression_ratio": 1.710144927536232,
        "end": 565.14,
        "id": 96,
        "no_speech_prob": 0.09533937275409698,
        "seek": 54230,
        "start": 558.02,
        "temperature": 0,
        "text": " make a get request for this file. So let's just see it happen. I put this URL in, I hit enter, that's a get request to",
        "tokens": [
          51150,
          652,
          257,
          483,
          5308,
          337,
          341,
          3991,
          13,
          407,
          718,
          311,
          445,
          536,
          309,
          1051,
          13,
          286,
          829,
          341,
          12905,
          294,
          11,
          286,
          2045,
          3242,
          11,
          300,
          311,
          257,
          483,
          5308,
          281,
          51506
        ]
      },
      {
        "avg_logprob": -0.20759620974140783,
        "compression_ratio": 1.710144927536232,
        "end": 571.4599999999999,
        "id": 97,
        "no_speech_prob": 0.09533937275409698,
        "seek": 54230,
        "start": 565.14,
        "temperature": 0,
        "text": " get the HTML, the browser receives it, parses it into the DOM, lots of stuff happens. But ultimately, this is what the",
        "tokens": [
          51506,
          483,
          264,
          17995,
          11,
          264,
          11185,
          20717,
          309,
          11,
          21156,
          279,
          309,
          666,
          264,
          35727,
          11,
          3195,
          295,
          1507,
          2314,
          13,
          583,
          6284,
          11,
          341,
          307,
          437,
          264,
          51822
        ]
      },
      {
        "avg_logprob": -0.20627986590067546,
        "compression_ratio": 1.6618705035971224,
        "end": 578.9000000000001,
        "id": 98,
        "no_speech_prob": 0.0004655212687794119,
        "seek": 57146,
        "start": 571.46,
        "temperature": 0,
        "text": " user sees. So, so far, we're at that first line in the diagram. Okay, and let's set up like a basic skeleton of a",
        "tokens": [
          50364,
          4195,
          8194,
          13,
          407,
          11,
          370,
          1400,
          11,
          321,
          434,
          412,
          300,
          700,
          1622,
          294,
          264,
          10686,
          13,
          1033,
          11,
          293,
          718,
          311,
          992,
          493,
          411,
          257,
          3875,
          25204,
          295,
          257,
          50736
        ]
      },
      {
        "avg_logprob": -0.20627986590067546,
        "compression_ratio": 1.6618705035971224,
        "end": 585.6600000000001,
        "id": 99,
        "no_speech_prob": 0.0004655212687794119,
        "seek": 57146,
        "start": 578.9000000000001,
        "temperature": 0,
        "text": " website. So for this skeleton, I'm going to be using this thing called skeleton CSS is a very basic CSS framework.",
        "tokens": [
          50736,
          3144,
          13,
          407,
          337,
          341,
          25204,
          11,
          286,
          478,
          516,
          281,
          312,
          1228,
          341,
          551,
          1219,
          25204,
          24387,
          307,
          257,
          588,
          3875,
          24387,
          8388,
          13,
          51074
        ]
      },
      {
        "avg_logprob": -0.20627986590067546,
        "compression_ratio": 1.6618705035971224,
        "end": 591.98,
        "id": 100,
        "no_speech_prob": 0.0004655212687794119,
        "seek": 57146,
        "start": 585.7,
        "temperature": 0,
        "text": " There are a lot of other CSS frameworks out there. Bootstrap is a really popular one or materialize. Basically, it",
        "tokens": [
          51076,
          821,
          366,
          257,
          688,
          295,
          661,
          24387,
          29834,
          484,
          456,
          13,
          37263,
          372,
          4007,
          307,
          257,
          534,
          3743,
          472,
          420,
          2527,
          1125,
          13,
          8537,
          11,
          309,
          51390
        ]
      },
      {
        "avg_logprob": -0.20627986590067546,
        "compression_ratio": 1.6618705035971224,
        "end": 600.82,
        "id": 101,
        "no_speech_prob": 0.0004655212687794119,
        "seek": 57146,
        "start": 591.98,
        "temperature": 0,
        "text": " gives us some default styles so that our site looks good by default. It's not like this ugly font. So let's grab this.",
        "tokens": [
          51390,
          2709,
          505,
          512,
          7576,
          13273,
          370,
          300,
          527,
          3621,
          1542,
          665,
          538,
          7576,
          13,
          467,
          311,
          406,
          411,
          341,
          12246,
          10703,
          13,
          407,
          718,
          311,
          4444,
          341,
          13,
          51832
        ]
      },
      {
        "avg_logprob": -0.19136212796581034,
        "compression_ratio": 1.6591928251121075,
        "end": 609.1,
        "id": 102,
        "no_speech_prob": 0.00019716762471944094,
        "seek": 60082,
        "start": 600.82,
        "temperature": 0,
        "text": " So I can just grab this CSS file. And then in here, I'll add a link to it, throw that in, save it. And if we go back to the",
        "tokens": [
          50364,
          407,
          286,
          393,
          445,
          4444,
          341,
          24387,
          3991,
          13,
          400,
          550,
          294,
          510,
          11,
          286,
          603,
          909,
          257,
          2113,
          281,
          309,
          11,
          3507,
          300,
          294,
          11,
          3155,
          309,
          13,
          400,
          498,
          321,
          352,
          646,
          281,
          264,
          50778
        ]
      },
      {
        "avg_logprob": -0.19136212796581034,
        "compression_ratio": 1.6591928251121075,
        "end": 616.34,
        "id": 103,
        "no_speech_prob": 0.00019716762471944094,
        "seek": 60082,
        "start": 609.1,
        "temperature": 0,
        "text": " browser, looks a little bit nicer. So this CSS framework automatically adds in fonts and different styles to make it look a",
        "tokens": [
          50778,
          11185,
          11,
          1542,
          257,
          707,
          857,
          22842,
          13,
          407,
          341,
          24387,
          8388,
          6772,
          10860,
          294,
          35316,
          293,
          819,
          13273,
          281,
          652,
          309,
          574,
          257,
          51140
        ]
      },
      {
        "avg_logprob": -0.19136212796581034,
        "compression_ratio": 1.6591928251121075,
        "end": 623.82,
        "id": 104,
        "no_speech_prob": 0.00019716762471944094,
        "seek": 60082,
        "start": 616.34,
        "temperature": 0,
        "text": " little bit better inside of the browser. Let's add our own styles as well. So right below here, I'm going to add a link to",
        "tokens": [
          51140,
          707,
          857,
          1101,
          1854,
          295,
          264,
          11185,
          13,
          961,
          311,
          909,
          527,
          1065,
          13273,
          382,
          731,
          13,
          407,
          558,
          2507,
          510,
          11,
          286,
          478,
          516,
          281,
          909,
          257,
          2113,
          281,
          51514
        ]
      },
      {
        "avg_logprob": -0.17652501097512902,
        "compression_ratio": 1.7655502392344498,
        "end": 633.0200000000001,
        "id": 105,
        "no_speech_prob": 0.1329469531774521,
        "seek": 62382,
        "start": 623.82,
        "temperature": 0,
        "text": " styles.css. And then in the folder, I'll create a new file called styles.css. And let's just say the header, let's give it a",
        "tokens": [
          50364,
          13273,
          13,
          66,
          3810,
          13,
          400,
          550,
          294,
          264,
          10820,
          11,
          286,
          603,
          1884,
          257,
          777,
          3991,
          1219,
          13273,
          13,
          66,
          3810,
          13,
          400,
          718,
          311,
          445,
          584,
          264,
          23117,
          11,
          718,
          311,
          976,
          309,
          257,
          50824
        ]
      },
      {
        "avg_logprob": -0.17652501097512902,
        "compression_ratio": 1.7655502392344498,
        "end": 647.5400000000001,
        "id": 106,
        "no_speech_prob": 0.1329469531774521,
        "seek": 62382,
        "start": 633.0200000000001,
        "temperature": 0,
        "text": " class. So this h1, we'll give this a class of title. And then in our CSS, we'll say title has text align of center. And that",
        "tokens": [
          50824,
          1508,
          13,
          407,
          341,
          276,
          16,
          11,
          321,
          603,
          976,
          341,
          257,
          1508,
          295,
          4876,
          13,
          400,
          550,
          294,
          527,
          24387,
          11,
          321,
          603,
          584,
          4876,
          575,
          2487,
          7975,
          295,
          3056,
          13,
          400,
          300,
          51550
        ]
      },
      {
        "avg_logprob": -0.17652501097512902,
        "compression_ratio": 1.7655502392344498,
        "end": 652.5,
        "id": 107,
        "no_speech_prob": 0.1329469531774521,
        "seek": 62382,
        "start": 647.5400000000001,
        "temperature": 0,
        "text": " should center the text. And if we go back to the browser, there it is, it's in the center. So just to talk about what's",
        "tokens": [
          51550,
          820,
          3056,
          264,
          2487,
          13,
          400,
          498,
          321,
          352,
          646,
          281,
          264,
          11185,
          11,
          456,
          309,
          307,
          11,
          309,
          311,
          294,
          264,
          3056,
          13,
          407,
          445,
          281,
          751,
          466,
          437,
          311,
          51798
        ]
      },
      {
        "avg_logprob": -0.22908262411753336,
        "compression_ratio": 1.7627906976744185,
        "end": 660.42,
        "id": 108,
        "no_speech_prob": 0.014728213660418987,
        "seek": 65250,
        "start": 652.5,
        "temperature": 0,
        "text": " happening so far in the diagram, you'll notice that our HTML file has a link to a CSS file and a link to another CSS file. So",
        "tokens": [
          50364,
          2737,
          370,
          1400,
          294,
          264,
          10686,
          11,
          291,
          603,
          3449,
          300,
          527,
          17995,
          3991,
          575,
          257,
          2113,
          281,
          257,
          24387,
          3991,
          293,
          257,
          2113,
          281,
          1071,
          24387,
          3991,
          13,
          407,
          50760
        ]
      },
      {
        "avg_logprob": -0.22908262411753336,
        "compression_ratio": 1.7627906976744185,
        "end": 668.74,
        "id": 109,
        "no_speech_prob": 0.014728213660418987,
        "seek": 65250,
        "start": 660.54,
        "temperature": 0,
        "text": " what happens is the browser will load the file, and then it will see those links. And then it has to go out and request more",
        "tokens": [
          50766,
          437,
          2314,
          307,
          264,
          11185,
          486,
          3677,
          264,
          3991,
          11,
          293,
          550,
          309,
          486,
          536,
          729,
          6123,
          13,
          400,
          550,
          309,
          575,
          281,
          352,
          484,
          293,
          5308,
          544,
          51176
        ]
      },
      {
        "avg_logprob": -0.22908262411753336,
        "compression_ratio": 1.7627906976744185,
        "end": 679.62,
        "id": 110,
        "no_speech_prob": 0.014728213660418987,
        "seek": 65250,
        "start": 668.98,
        "temperature": 0,
        "text": " files. So let's look at the diagram here. And so basically, it first loaded the request made was made for the HTML file, then it",
        "tokens": [
          51188,
          7098,
          13,
          407,
          718,
          311,
          574,
          412,
          264,
          10686,
          510,
          13,
          400,
          370,
          1936,
          11,
          309,
          700,
          13210,
          264,
          5308,
          1027,
          390,
          1027,
          337,
          264,
          17995,
          3991,
          11,
          550,
          309,
          51720
        ]
      },
      {
        "avg_logprob": -0.2056734638829385,
        "compression_ratio": 1.8185185185185184,
        "end": 685.26,
        "id": 111,
        "no_speech_prob": 0.009708263911306858,
        "seek": 67962,
        "start": 679.62,
        "temperature": 0,
        "text": " needed more things. Basically, the browser parsed it and said, Oh, you want a CSS file from get skeleton? Oh, you want",
        "tokens": [
          50364,
          2978,
          544,
          721,
          13,
          8537,
          11,
          264,
          11185,
          21156,
          292,
          309,
          293,
          848,
          11,
          876,
          11,
          291,
          528,
          257,
          24387,
          3991,
          490,
          483,
          25204,
          30,
          876,
          11,
          291,
          528,
          50646
        ]
      },
      {
        "avg_logprob": -0.2056734638829385,
        "compression_ratio": 1.8185185185185184,
        "end": 696.1,
        "id": 112,
        "no_speech_prob": 0.009708263911306858,
        "seek": 67962,
        "start": 685.26,
        "temperature": 0,
        "text": " styles.css. So more requests went out. So there was a request here to get the styles.css. And then the static file server,",
        "tokens": [
          50646,
          13273,
          13,
          66,
          3810,
          13,
          407,
          544,
          12475,
          1437,
          484,
          13,
          407,
          456,
          390,
          257,
          5308,
          510,
          281,
          483,
          264,
          13273,
          13,
          66,
          3810,
          13,
          400,
          550,
          264,
          13437,
          3991,
          7154,
          11,
          51188
        ]
      },
      {
        "avg_logprob": -0.2056734638829385,
        "compression_ratio": 1.8185185185185184,
        "end": 702.94,
        "id": 113,
        "no_speech_prob": 0.009708263911306858,
        "seek": 67962,
        "start": 696.1,
        "temperature": 0,
        "text": " which is live server responds, the browser takes that and then loads it in and we see some beautiful styles and they're applied",
        "tokens": [
          51188,
          597,
          307,
          1621,
          7154,
          27331,
          11,
          264,
          11185,
          2516,
          300,
          293,
          550,
          12668,
          309,
          294,
          293,
          321,
          536,
          512,
          2238,
          13273,
          293,
          436,
          434,
          6456,
          51530
        ]
      },
      {
        "avg_logprob": -0.2056734638829385,
        "compression_ratio": 1.8185185185185184,
        "end": 709.26,
        "id": 114,
        "no_speech_prob": 0.009708263911306858,
        "seek": 67962,
        "start": 702.94,
        "temperature": 0,
        "text": " to the document. So every single thing that's happening in here is part of a request that's going out to a server. So now",
        "tokens": [
          51530,
          281,
          264,
          4166,
          13,
          407,
          633,
          2167,
          551,
          300,
          311,
          2737,
          294,
          510,
          307,
          644,
          295,
          257,
          5308,
          300,
          311,
          516,
          484,
          281,
          257,
          7154,
          13,
          407,
          586,
          51846
        ]
      },
      {
        "avg_logprob": -0.20160931879931157,
        "compression_ratio": 1.7904761904761906,
        "end": 715.14,
        "id": 115,
        "no_speech_prob": 0.002631610259413719,
        "seek": 70926,
        "start": 709.26,
        "temperature": 0,
        "text": " that the page is loaded, it the at this point, it's just static, it's just sitting there, we're seeing what we see, it's not",
        "tokens": [
          50364,
          300,
          264,
          3028,
          307,
          13210,
          11,
          309,
          264,
          412,
          341,
          935,
          11,
          309,
          311,
          445,
          13437,
          11,
          309,
          311,
          445,
          3798,
          456,
          11,
          321,
          434,
          2577,
          437,
          321,
          536,
          11,
          309,
          311,
          406,
          50658
        ]
      },
      {
        "avg_logprob": -0.20160931879931157,
        "compression_ratio": 1.7904761904761906,
        "end": 721.26,
        "id": 116,
        "no_speech_prob": 0.002631610259413719,
        "seek": 70926,
        "start": 715.14,
        "temperature": 0,
        "text": " communicating to any servers anymore. So what we want to do is we want to make it so that the user can type in their view and",
        "tokens": [
          50658,
          17559,
          281,
          604,
          15909,
          3602,
          13,
          407,
          437,
          321,
          528,
          281,
          360,
          307,
          321,
          528,
          281,
          652,
          309,
          370,
          300,
          264,
          4195,
          393,
          2010,
          294,
          641,
          1910,
          293,
          50964
        ]
      },
      {
        "avg_logprob": -0.20160931879931157,
        "compression_ratio": 1.7904761904761906,
        "end": 730.62,
        "id": 117,
        "no_speech_prob": 0.002631610259413719,
        "seek": 70926,
        "start": 721.26,
        "temperature": 0,
        "text": " then send it off to the server. So let's get that going. Here. So we created a header, we created the form, we brought in our",
        "tokens": [
          50964,
          550,
          2845,
          309,
          766,
          281,
          264,
          7154,
          13,
          407,
          718,
          311,
          483,
          300,
          516,
          13,
          1692,
          13,
          407,
          321,
          2942,
          257,
          23117,
          11,
          321,
          2942,
          264,
          1254,
          11,
          321,
          3038,
          294,
          527,
          51432
        ]
      },
      {
        "avg_logprob": -0.21981651669456845,
        "compression_ratio": 1.6266094420600858,
        "end": 743.18,
        "id": 118,
        "no_speech_prob": 0.10969594866037369,
        "seek": 73062,
        "start": 730.62,
        "temperature": 0,
        "text": " CSS. Oh, haven't created the form, we will create the form. Any lingering questions or anything like that? Okay, cool. Okay, so",
        "tokens": [
          50364,
          24387,
          13,
          876,
          11,
          2378,
          380,
          2942,
          264,
          1254,
          11,
          321,
          486,
          1884,
          264,
          1254,
          13,
          2639,
          49542,
          1651,
          420,
          1340,
          411,
          300,
          30,
          1033,
          11,
          1627,
          13,
          1033,
          11,
          370,
          50992
        ]
      },
      {
        "avg_logprob": -0.21981651669456845,
        "compression_ratio": 1.6266094420600858,
        "end": 749.74,
        "id": 119,
        "no_speech_prob": 0.10969594866037369,
        "seek": 73062,
        "start": 743.18,
        "temperature": 0,
        "text": " in here, I'm going to add a main area. And here I'll add the form. Typically forms are what we use to get user input. So if",
        "tokens": [
          50992,
          294,
          510,
          11,
          286,
          478,
          516,
          281,
          909,
          257,
          2135,
          1859,
          13,
          400,
          510,
          286,
          603,
          909,
          264,
          1254,
          13,
          23129,
          6422,
          366,
          437,
          321,
          764,
          281,
          483,
          4195,
          4846,
          13,
          407,
          498,
          51320
        ]
      },
      {
        "avg_logprob": -0.21981651669456845,
        "compression_ratio": 1.6266094420600858,
        "end": 757.46,
        "id": 120,
        "no_speech_prob": 0.10969594866037369,
        "seek": 73062,
        "start": 749.74,
        "temperature": 0,
        "text": " you've ever typed into a text box or something like that, it is a form. So on this form, I want a label, this will be for users",
        "tokens": [
          51320,
          291,
          600,
          1562,
          33941,
          666,
          257,
          2487,
          2424,
          420,
          746,
          411,
          300,
          11,
          309,
          307,
          257,
          1254,
          13,
          407,
          322,
          341,
          1254,
          11,
          286,
          528,
          257,
          7645,
          11,
          341,
          486,
          312,
          337,
          5022,
          51706
        ]
      },
      {
        "avg_logprob": -0.21942942610410887,
        "compression_ratio": 1.7219730941704037,
        "end": 767.58,
        "id": 121,
        "no_speech_prob": 0.005554670933634043,
        "seek": 75746,
        "start": 757.46,
        "temperature": 0,
        "text": " name. And then I'll add an input. And this will be a text and we'll give it an ID of name. And we'll give it a name of name.",
        "tokens": [
          50364,
          1315,
          13,
          400,
          550,
          286,
          603,
          909,
          364,
          4846,
          13,
          400,
          341,
          486,
          312,
          257,
          2487,
          293,
          321,
          603,
          976,
          309,
          364,
          7348,
          295,
          1315,
          13,
          400,
          321,
          603,
          976,
          309,
          257,
          1315,
          295,
          1315,
          13,
          50870
        ]
      },
      {
        "avg_logprob": -0.21942942610410887,
        "compression_ratio": 1.7219730941704037,
        "end": 774.62,
        "id": 122,
        "no_speech_prob": 0.005554670933634043,
        "seek": 75746,
        "start": 768.14,
        "temperature": 0,
        "text": " And let's see what we get. So by default, we get a nice little input box on the screen. Let's give it some styles. So built into",
        "tokens": [
          50898,
          400,
          718,
          311,
          536,
          437,
          321,
          483,
          13,
          407,
          538,
          7576,
          11,
          321,
          483,
          257,
          1481,
          707,
          4846,
          2424,
          322,
          264,
          2568,
          13,
          961,
          311,
          976,
          309,
          512,
          13273,
          13,
          407,
          3094,
          666,
          51222
        ]
      },
      {
        "avg_logprob": -0.21942942610410887,
        "compression_ratio": 1.7219730941704037,
        "end": 783.74,
        "id": 123,
        "no_speech_prob": 0.005554670933634043,
        "seek": 75746,
        "start": 774.62,
        "temperature": 0,
        "text": " skeleton is this class named you full width. And you'll notice that the input went all the way across. But I don't want it to take",
        "tokens": [
          51222,
          25204,
          307,
          341,
          1508,
          4926,
          291,
          1577,
          11402,
          13,
          400,
          291,
          603,
          3449,
          300,
          264,
          4846,
          1437,
          439,
          264,
          636,
          2108,
          13,
          583,
          286,
          500,
          380,
          528,
          309,
          281,
          747,
          51678
        ]
      },
      {
        "avg_logprob": -0.20293533255200868,
        "compression_ratio": 1.7180616740088106,
        "end": 793.26,
        "id": 124,
        "no_speech_prob": 0.009558693505823612,
        "seek": 78374,
        "start": 783.74,
        "temperature": 0,
        "text": " up the whole screen. So let's add some more styles. Let's call this form, let's give it a class of like new form. And in here in the",
        "tokens": [
          50364,
          493,
          264,
          1379,
          2568,
          13,
          407,
          718,
          311,
          909,
          512,
          544,
          13273,
          13,
          961,
          311,
          818,
          341,
          1254,
          11,
          718,
          311,
          976,
          309,
          257,
          1508,
          295,
          411,
          777,
          1254,
          13,
          400,
          294,
          510,
          294,
          264,
          50840
        ]
      },
      {
        "avg_logprob": -0.20293533255200868,
        "compression_ratio": 1.7180616740088106,
        "end": 806.14,
        "id": 125,
        "no_speech_prob": 0.009558693505823612,
        "seek": 78374,
        "start": 793.26,
        "temperature": 0,
        "text": " styles, I'll add a new one for new form. Let's say the width is like 50%. And it has margin zero and auto. So it should center",
        "tokens": [
          50840,
          13273,
          11,
          286,
          603,
          909,
          257,
          777,
          472,
          337,
          777,
          1254,
          13,
          961,
          311,
          584,
          264,
          11402,
          307,
          411,
          2625,
          6856,
          400,
          309,
          575,
          10270,
          4018,
          293,
          8399,
          13,
          407,
          309,
          820,
          3056,
          51484
        ]
      },
      {
        "avg_logprob": -0.20293533255200868,
        "compression_ratio": 1.7180616740088106,
        "end": 811.94,
        "id": 126,
        "no_speech_prob": 0.009558693505823612,
        "seek": 78374,
        "start": 806.14,
        "temperature": 0,
        "text": " there we go. So our form is like nice and center on the screen. And that's for the name. And then we also need a text area for the",
        "tokens": [
          51484,
          456,
          321,
          352,
          13,
          407,
          527,
          1254,
          307,
          411,
          1481,
          293,
          3056,
          322,
          264,
          2568,
          13,
          400,
          300,
          311,
          337,
          264,
          1315,
          13,
          400,
          550,
          321,
          611,
          643,
          257,
          2487,
          1859,
          337,
          264,
          51774
        ]
      },
      {
        "avg_logprob": -0.2266655233171251,
        "compression_ratio": 1.6273291925465838,
        "end": 825.0600000000001,
        "id": 127,
        "no_speech_prob": 0.014728049747645855,
        "seek": 81194,
        "start": 811.94,
        "temperature": 0,
        "text": " new. Okay, so the four here will be called this content. We'll say this new, the ID will be content, the name will be new, sorry,",
        "tokens": [
          50364,
          777,
          13,
          1033,
          11,
          370,
          264,
          1451,
          510,
          486,
          312,
          1219,
          341,
          2701,
          13,
          492,
          603,
          584,
          341,
          777,
          11,
          264,
          7348,
          486,
          312,
          2701,
          11,
          264,
          1315,
          486,
          312,
          777,
          11,
          2597,
          11,
          51020
        ]
      },
      {
        "avg_logprob": -0.2266655233171251,
        "compression_ratio": 1.6273291925465838,
        "end": 838.58,
        "id": 128,
        "no_speech_prob": 0.014728049747645855,
        "seek": 81194,
        "start": 825.1,
        "temperature": 0,
        "text": " content. And instead of an input, we want a text area. And that gives us an area where they can type in their content as well. Okay,",
        "tokens": [
          51022,
          2701,
          13,
          400,
          2602,
          295,
          364,
          4846,
          11,
          321,
          528,
          257,
          2487,
          1859,
          13,
          400,
          300,
          2709,
          505,
          364,
          1859,
          689,
          436,
          393,
          2010,
          294,
          641,
          2701,
          382,
          731,
          13,
          1033,
          11,
          51696
        ]
      },
      {
        "avg_logprob": -0.2502755841005196,
        "compression_ratio": 1.8177777777777777,
        "end": 847.7800000000001,
        "id": 129,
        "no_speech_prob": 0.136586531996727,
        "seek": 83858,
        "start": 838.58,
        "temperature": 0,
        "text": " last thing we need is a button so that they can submit this form and send the data to the server. So we'll just say send your new input,",
        "tokens": [
          50364,
          1036,
          551,
          321,
          643,
          307,
          257,
          2960,
          370,
          300,
          436,
          393,
          10315,
          341,
          1254,
          293,
          2845,
          264,
          1412,
          281,
          264,
          7154,
          13,
          407,
          321,
          603,
          445,
          584,
          2845,
          428,
          777,
          4846,
          11,
          50824
        ]
      },
      {
        "avg_logprob": -0.2502755841005196,
        "compression_ratio": 1.8177777777777777,
        "end": 856.1,
        "id": 130,
        "no_speech_prob": 0.136586531996727,
        "seek": 83858,
        "start": 847.86,
        "temperature": 0,
        "text": " a nice little cat in there, like that, we get a nice little button. Another thing built into skeleton is this button primary class, and",
        "tokens": [
          50828,
          257,
          1481,
          707,
          3857,
          294,
          456,
          11,
          411,
          300,
          11,
          321,
          483,
          257,
          1481,
          707,
          2960,
          13,
          3996,
          551,
          3094,
          666,
          25204,
          307,
          341,
          2960,
          6194,
          1508,
          11,
          293,
          51240
        ]
      },
      {
        "avg_logprob": -0.2502755841005196,
        "compression_ratio": 1.8177777777777777,
        "end": 865.0600000000001,
        "id": 131,
        "no_speech_prob": 0.136586531996727,
        "seek": 83858,
        "start": 856.1,
        "temperature": 0,
        "text": " we'll give it a nice blue color. So let's make this button dash primary, then we get a nice little button, we can click cool. So we have",
        "tokens": [
          51240,
          321,
          603,
          976,
          309,
          257,
          1481,
          3344,
          2017,
          13,
          407,
          718,
          311,
          652,
          341,
          2960,
          8240,
          6194,
          11,
          550,
          321,
          483,
          257,
          1481,
          707,
          2960,
          11,
          321,
          393,
          2052,
          1627,
          13,
          407,
          321,
          362,
          51688
        ]
      },
      {
        "avg_logprob": -0.18379622655557404,
        "compression_ratio": 1.8175675675675675,
        "end": 871.5,
        "id": 132,
        "no_speech_prob": 0.09399741888046265,
        "seek": 86506,
        "start": 865.06,
        "temperature": 0,
        "text": " this form, the user can type in here, but now we actually want to send this data somewhere. But let's look back at our checklist. So we",
        "tokens": [
          50364,
          341,
          1254,
          11,
          264,
          4195,
          393,
          2010,
          294,
          510,
          11,
          457,
          586,
          321,
          767,
          528,
          281,
          2845,
          341,
          1412,
          4079,
          13,
          583,
          718,
          311,
          574,
          646,
          412,
          527,
          30357,
          13,
          407,
          321,
          50686
        ]
      },
      {
        "avg_logprob": -0.18379622655557404,
        "compression_ratio": 1.8175675675675675,
        "end": 878.6999999999999,
        "id": 133,
        "no_speech_prob": 0.09399741888046265,
        "seek": 86506,
        "start": 871.5,
        "temperature": 0,
        "text": " created a form, we have name, we have content, we've listened, we've set up full width and all the inputs. But now we actually need",
        "tokens": [
          50686,
          2942,
          257,
          1254,
          11,
          321,
          362,
          1315,
          11,
          321,
          362,
          2701,
          11,
          321,
          600,
          13207,
          11,
          321,
          600,
          992,
          493,
          1577,
          11402,
          293,
          439,
          264,
          15743,
          13,
          583,
          586,
          321,
          767,
          643,
          51046
        ]
      },
      {
        "avg_logprob": -0.18379622655557404,
        "compression_ratio": 1.8175675675675675,
        "end": 887.5799999999999,
        "id": 134,
        "no_speech_prob": 0.09399741888046265,
        "seek": 86506,
        "start": 878.6999999999999,
        "temperature": 0,
        "text": " JavaScript to listen for when this form is submitted. So here's what I'll do. I'll create a new file, let's call this client.js. I'm",
        "tokens": [
          51046,
          15778,
          281,
          2140,
          337,
          562,
          341,
          1254,
          307,
          14405,
          13,
          407,
          510,
          311,
          437,
          286,
          603,
          360,
          13,
          286,
          603,
          1884,
          257,
          777,
          3991,
          11,
          718,
          311,
          818,
          341,
          6423,
          13,
          25530,
          13,
          286,
          478,
          51490
        ]
      },
      {
        "avg_logprob": -0.18379622655557404,
        "compression_ratio": 1.8175675675675675,
        "end": 892.9799999999999,
        "id": 135,
        "no_speech_prob": 0.09399741888046265,
        "seek": 86506,
        "start": 887.5799999999999,
        "temperature": 0,
        "text": " going to be creating other JavaScript files. So just to make sure we're clear as to where we are when we're working on them, I'm going to",
        "tokens": [
          51490,
          516,
          281,
          312,
          4084,
          661,
          15778,
          7098,
          13,
          407,
          445,
          281,
          652,
          988,
          321,
          434,
          1850,
          382,
          281,
          689,
          321,
          366,
          562,
          321,
          434,
          1364,
          322,
          552,
          11,
          286,
          478,
          516,
          281,
          51760
        ]
      },
      {
        "avg_logprob": -0.21561333792550222,
        "compression_ratio": 1.670940170940171,
        "end": 904.1,
        "id": 136,
        "no_speech_prob": 0.018544169142842293,
        "seek": 89298,
        "start": 892.98,
        "temperature": 0,
        "text": " call this one client.js. And I'm going to go ahead before I forget, we'll add a script at the bottom here that will bring in our",
        "tokens": [
          50364,
          818,
          341,
          472,
          6423,
          13,
          25530,
          13,
          400,
          286,
          478,
          516,
          281,
          352,
          2286,
          949,
          286,
          2870,
          11,
          321,
          603,
          909,
          257,
          5755,
          412,
          264,
          2767,
          510,
          300,
          486,
          1565,
          294,
          527,
          50920
        ]
      },
      {
        "avg_logprob": -0.21561333792550222,
        "compression_ratio": 1.670940170940171,
        "end": 914.1800000000001,
        "id": 137,
        "no_speech_prob": 0.018544169142842293,
        "seek": 89298,
        "start": 904.1,
        "temperature": 0,
        "text": " client.js. And just to make sure it's working, let's just log hello world. And back to the browser, open the dev tools, and it is",
        "tokens": [
          50920,
          6423,
          13,
          25530,
          13,
          400,
          445,
          281,
          652,
          988,
          309,
          311,
          1364,
          11,
          718,
          311,
          445,
          3565,
          7751,
          1002,
          13,
          400,
          646,
          281,
          264,
          11185,
          11,
          1269,
          264,
          1905,
          3873,
          11,
          293,
          309,
          307,
          51424
        ]
      },
      {
        "avg_logprob": -0.21561333792550222,
        "compression_ratio": 1.670940170940171,
        "end": 921.4200000000001,
        "id": 138,
        "no_speech_prob": 0.018544169142842293,
        "seek": 89298,
        "start": 914.1800000000001,
        "temperature": 0,
        "text": " working, we get to the hello world log. Cool. So now we actually want to listen for when the user clicks this button, so that way we",
        "tokens": [
          51424,
          1364,
          11,
          321,
          483,
          281,
          264,
          7751,
          1002,
          3565,
          13,
          8561,
          13,
          407,
          586,
          321,
          767,
          528,
          281,
          2140,
          337,
          562,
          264,
          4195,
          18521,
          341,
          2960,
          11,
          370,
          300,
          636,
          321,
          51786
        ]
      },
      {
        "avg_logprob": -0.19982188996814546,
        "compression_ratio": 1.7834101382488479,
        "end": 934.38,
        "id": 139,
        "no_speech_prob": 0.02064504101872444,
        "seek": 92142,
        "start": 921.42,
        "temperature": 0,
        "text": " can grab all of the data that's in the form. So first thing I'll do is get a reference to the form by using document.query",
        "tokens": [
          50364,
          393,
          4444,
          439,
          295,
          264,
          1412,
          300,
          311,
          294,
          264,
          1254,
          13,
          407,
          700,
          551,
          286,
          603,
          360,
          307,
          483,
          257,
          6408,
          281,
          264,
          1254,
          538,
          1228,
          4166,
          13,
          358,
          2109,
          51012
        ]
      },
      {
        "avg_logprob": -0.19982188996814546,
        "compression_ratio": 1.7834101382488479,
        "end": 942.9,
        "id": 140,
        "no_speech_prob": 0.02064504101872444,
        "seek": 92142,
        "start": 934.38,
        "temperature": 0,
        "text": " selector. And then with query selector, you can pass in any valid CSS selector to choose some element on the page. So in this case, I",
        "tokens": [
          51012,
          23264,
          1672,
          13,
          400,
          550,
          365,
          14581,
          23264,
          1672,
          11,
          291,
          393,
          1320,
          294,
          604,
          7363,
          24387,
          23264,
          1672,
          281,
          2826,
          512,
          4478,
          322,
          264,
          3028,
          13,
          407,
          294,
          341,
          1389,
          11,
          286,
          51438
        ]
      },
      {
        "avg_logprob": -0.19982188996814546,
        "compression_ratio": 1.7834101382488479,
        "end": 951.26,
        "id": 141,
        "no_speech_prob": 0.02064504101872444,
        "seek": 92142,
        "start": 942.9,
        "temperature": 0,
        "text": " want to select this form. So a valid CSS selector for that is just to pass in form. And that will give me the form. So part of our",
        "tokens": [
          51438,
          528,
          281,
          3048,
          341,
          1254,
          13,
          407,
          257,
          7363,
          24387,
          23264,
          1672,
          337,
          300,
          307,
          445,
          281,
          1320,
          294,
          1254,
          13,
          400,
          300,
          486,
          976,
          385,
          264,
          1254,
          13,
          407,
          644,
          295,
          527,
          51856
        ]
      },
      {
        "avg_logprob": -0.2521400670895631,
        "compression_ratio": 1.7692307692307692,
        "end": 958.38,
        "id": 142,
        "no_speech_prob": 0.001264397636987269,
        "seek": 95126,
        "start": 951.26,
        "temperature": 0,
        "text": " objectives were to differentiate between client-side JavaScript and server-side JavaScript. Anytime you see document, that is",
        "tokens": [
          50364,
          15961,
          645,
          281,
          23203,
          1296,
          6423,
          12,
          1812,
          15778,
          293,
          7154,
          12,
          1812,
          15778,
          13,
          39401,
          291,
          536,
          4166,
          11,
          300,
          307,
          50720
        ]
      },
      {
        "avg_logprob": -0.2521400670895631,
        "compression_ratio": 1.7692307692307692,
        "end": 966.9,
        "id": 143,
        "no_speech_prob": 0.001264397636987269,
        "seek": 95126,
        "start": 958.38,
        "temperature": 0,
        "text": " client-side JavaScript, because we're actually interacting with the web page, with the thing that the user is interacting with. So we",
        "tokens": [
          50720,
          6423,
          12,
          1812,
          15778,
          11,
          570,
          321,
          434,
          767,
          18017,
          365,
          264,
          3670,
          3028,
          11,
          365,
          264,
          551,
          300,
          264,
          4195,
          307,
          18017,
          365,
          13,
          407,
          321,
          51146
        ]
      },
      {
        "avg_logprob": -0.2521400670895631,
        "compression_ratio": 1.7692307692307692,
        "end": 974.86,
        "id": 144,
        "no_speech_prob": 0.001264397636987269,
        "seek": 95126,
        "start": 966.9,
        "temperature": 0,
        "text": " have the form, now we want to listen for when the user clicks submit. So we're going to add an event listener for the submit event.",
        "tokens": [
          51146,
          362,
          264,
          1254,
          11,
          586,
          321,
          528,
          281,
          2140,
          337,
          562,
          264,
          4195,
          18521,
          10315,
          13,
          407,
          321,
          434,
          516,
          281,
          909,
          364,
          2280,
          31569,
          337,
          264,
          10315,
          2280,
          13,
          51544
        ]
      },
      {
        "avg_logprob": -0.29345369974772134,
        "compression_ratio": 1.5307262569832403,
        "end": 988.5,
        "id": 145,
        "no_speech_prob": 0.028433959931135178,
        "seek": 97486,
        "start": 975.0600000000001,
        "temperature": 0,
        "text": " We'll get access to the event. And then for now, let's just log out form was submitted. Cool, let's see what happens. So my name is CJ, my",
        "tokens": [
          50374,
          492,
          603,
          483,
          2105,
          281,
          264,
          2280,
          13,
          400,
          550,
          337,
          586,
          11,
          718,
          311,
          445,
          3565,
          484,
          1254,
          390,
          14405,
          13,
          8561,
          11,
          718,
          311,
          536,
          437,
          2314,
          13,
          407,
          452,
          1315,
          307,
          42285,
          11,
          452,
          51046
        ]
      },
      {
        "avg_logprob": -0.29345369974772134,
        "compression_ratio": 1.5307262569832403,
        "end": 998.1800000000001,
        "id": 146,
        "no_speech_prob": 0.028433959931135178,
        "seek": 97486,
        "start": 988.5,
        "temperature": 0,
        "text": " view is hello world, world, world, go. And you'll notice it tried to log but then the page refreshed. And you'll notice the URL changed",
        "tokens": [
          51046,
          1910,
          307,
          7751,
          1002,
          11,
          1002,
          11,
          1002,
          11,
          352,
          13,
          400,
          291,
          603,
          3449,
          309,
          3031,
          281,
          3565,
          457,
          550,
          264,
          3028,
          46330,
          13,
          400,
          291,
          603,
          3449,
          264,
          12905,
          3105,
          51530
        ]
      },
      {
        "avg_logprob": -0.22081677457119556,
        "compression_ratio": 1.7747747747747749,
        "end": 1006.9399999999999,
        "id": 147,
        "no_speech_prob": 0.3310701549053192,
        "seek": 99818,
        "start": 998.18,
        "temperature": 0,
        "text": " here. So by default, when a form is submitted, the browser automatically tries to send the data somewhere. But we don't want that we",
        "tokens": [
          50364,
          510,
          13,
          407,
          538,
          7576,
          11,
          562,
          257,
          1254,
          307,
          14405,
          11,
          264,
          11185,
          6772,
          9898,
          281,
          2845,
          264,
          1412,
          4079,
          13,
          583,
          321,
          500,
          380,
          528,
          300,
          321,
          50802
        ]
      },
      {
        "avg_logprob": -0.22081677457119556,
        "compression_ratio": 1.7747747747747749,
        "end": 1015.26,
        "id": 148,
        "no_speech_prob": 0.3310701549053192,
        "seek": 99818,
        "start": 1006.9399999999999,
        "temperature": 0,
        "text": " want to stop it from happening so that we can handle it with JavaScript. And for this we can do prevent default. And now that we're",
        "tokens": [
          50802,
          528,
          281,
          1590,
          309,
          490,
          2737,
          370,
          300,
          321,
          393,
          4813,
          309,
          365,
          15778,
          13,
          400,
          337,
          341,
          321,
          393,
          360,
          4871,
          7576,
          13,
          400,
          586,
          300,
          321,
          434,
          51218
        ]
      },
      {
        "avg_logprob": -0.22081677457119556,
        "compression_ratio": 1.7747747747747749,
        "end": 1019.9,
        "id": 149,
        "no_speech_prob": 0.3310701549053192,
        "seek": 99818,
        "start": 1015.26,
        "temperature": 0,
        "text": " preventing the default action, the data won't go anywhere, we're basically telling the browser, well, now we want to do this with",
        "tokens": [
          51218,
          19965,
          264,
          7576,
          3069,
          11,
          264,
          1412,
          1582,
          380,
          352,
          4992,
          11,
          321,
          434,
          1936,
          3585,
          264,
          11185,
          11,
          731,
          11,
          586,
          321,
          528,
          281,
          360,
          341,
          365,
          51450
        ]
      },
      {
        "avg_logprob": -0.24554805755615233,
        "compression_ratio": 1.4725274725274726,
        "end": 1033.46,
        "id": 150,
        "no_speech_prob": 0.10817868262529373,
        "seek": 101990,
        "start": 1019.9,
        "temperature": 0,
        "text": " JavaScript. So here, let's try to log form submitted. And then hello world, click submit, and it says form submitted. Cool. So we've",
        "tokens": [
          50364,
          15778,
          13,
          407,
          510,
          11,
          718,
          311,
          853,
          281,
          3565,
          1254,
          14405,
          13,
          400,
          550,
          7751,
          1002,
          11,
          2052,
          10315,
          11,
          293,
          309,
          1619,
          1254,
          14405,
          13,
          8561,
          13,
          407,
          321,
          600,
          51042
        ]
      },
      {
        "avg_logprob": -0.24554805755615233,
        "compression_ratio": 1.4725274725274726,
        "end": 1041.02,
        "id": 151,
        "no_speech_prob": 0.10817868262529373,
        "seek": 101990,
        "start": 1033.46,
        "temperature": 0,
        "text": " tapped into when the user clicks this button. Now we actually want to grab the data from the page. So to do that, I'm going to use form",
        "tokens": [
          51042,
          38693,
          666,
          562,
          264,
          4195,
          18521,
          341,
          2960,
          13,
          823,
          321,
          767,
          528,
          281,
          4444,
          264,
          1412,
          490,
          264,
          3028,
          13,
          407,
          281,
          360,
          300,
          11,
          286,
          478,
          516,
          281,
          764,
          1254,
          51420
        ]
      },
      {
        "avg_logprob": -0.20905599329206678,
        "compression_ratio": 1.5786516853932584,
        "end": 1051.3799999999999,
        "id": 152,
        "no_speech_prob": 0.26280421018600464,
        "seek": 104102,
        "start": 1041.02,
        "temperature": 0,
        "text": " data. So form data is built into the web browser. And it works by passing in a reference to the form. So because I already have this form",
        "tokens": [
          50364,
          1412,
          13,
          407,
          1254,
          1412,
          307,
          3094,
          666,
          264,
          3670,
          11185,
          13,
          400,
          309,
          1985,
          538,
          8437,
          294,
          257,
          6408,
          281,
          264,
          1254,
          13,
          407,
          570,
          286,
          1217,
          362,
          341,
          1254,
          50882
        ]
      },
      {
        "avg_logprob": -0.20905599329206678,
        "compression_ratio": 1.5786516853932584,
        "end": 1061.82,
        "id": 153,
        "no_speech_prob": 0.26280421018600464,
        "seek": 104102,
        "start": 1051.3799999999999,
        "temperature": 0,
        "text": " variable, we can pass it in here to form data. And now we can grab some of the user input from the page. So specifically, if I want to grab the",
        "tokens": [
          50882,
          7006,
          11,
          321,
          393,
          1320,
          309,
          294,
          510,
          281,
          1254,
          1412,
          13,
          400,
          586,
          321,
          393,
          4444,
          512,
          295,
          264,
          4195,
          4846,
          490,
          264,
          3028,
          13,
          407,
          4682,
          11,
          498,
          286,
          528,
          281,
          4444,
          264,
          51404
        ]
      },
      {
        "avg_logprob": -0.2279292345046997,
        "compression_ratio": 1.7361963190184049,
        "end": 1073.86,
        "id": 154,
        "no_speech_prob": 0.2508535087108612,
        "seek": 106182,
        "start": 1061.82,
        "temperature": 0,
        "text": " name here, because I have the name set up as name, I can say, let's say name is equal to form data.get and pass in name. And if I also want the",
        "tokens": [
          50364,
          1315,
          510,
          11,
          570,
          286,
          362,
          264,
          1315,
          992,
          493,
          382,
          1315,
          11,
          286,
          393,
          584,
          11,
          718,
          311,
          584,
          1315,
          307,
          2681,
          281,
          1254,
          1412,
          13,
          847,
          293,
          1320,
          294,
          1315,
          13,
          400,
          498,
          286,
          611,
          528,
          264,
          50966
        ]
      },
      {
        "avg_logprob": -0.2279292345046997,
        "compression_ratio": 1.7361963190184049,
        "end": 1086.3799999999999,
        "id": 155,
        "no_speech_prob": 0.2508535087108612,
        "seek": 106182,
        "start": 1073.86,
        "temperature": 0,
        "text": " content, I set up the name here to be content. So I can say, content is form data.get content. And now I have what the user typed into both",
        "tokens": [
          50966,
          2701,
          11,
          286,
          992,
          493,
          264,
          1315,
          510,
          281,
          312,
          2701,
          13,
          407,
          286,
          393,
          584,
          11,
          2701,
          307,
          1254,
          1412,
          13,
          847,
          2701,
          13,
          400,
          586,
          286,
          362,
          437,
          264,
          4195,
          33941,
          666,
          1293,
          51592
        ]
      },
      {
        "avg_logprob": -0.2189873318339503,
        "compression_ratio": 1.5736040609137056,
        "end": 1099.0600000000002,
        "id": 156,
        "no_speech_prob": 0.21203994750976562,
        "seek": 108638,
        "start": 1086.6200000000001,
        "temperature": 0,
        "text": " input boxes. And so let's just create an object called a mu. And inside of it, I'll have the name and the content. And let's just log it out. Cool. So now when the",
        "tokens": [
          50376,
          4846,
          9002,
          13,
          400,
          370,
          718,
          311,
          445,
          1884,
          364,
          2657,
          1219,
          257,
          2992,
          13,
          400,
          1854,
          295,
          309,
          11,
          286,
          603,
          362,
          264,
          1315,
          293,
          264,
          2701,
          13,
          400,
          718,
          311,
          445,
          3565,
          309,
          484,
          13,
          8561,
          13,
          407,
          586,
          562,
          264,
          50998
        ]
      },
      {
        "avg_logprob": -0.2189873318339503,
        "compression_ratio": 1.5736040609137056,
        "end": 1110.7,
        "id": 157,
        "no_speech_prob": 0.21203994750976562,
        "seek": 108638,
        "start": 1099.0600000000002,
        "temperature": 0,
        "text": " form is submitted, we should see an object. Hello world. Go. Nice. So we have the object. But remember, we're still on the client side, we haven't",
        "tokens": [
          50998,
          1254,
          307,
          14405,
          11,
          321,
          820,
          536,
          364,
          2657,
          13,
          2425,
          1002,
          13,
          1037,
          13,
          5490,
          13,
          407,
          321,
          362,
          264,
          2657,
          13,
          583,
          1604,
          11,
          321,
          434,
          920,
          322,
          264,
          6423,
          1252,
          11,
          321,
          2378,
          380,
          51580
        ]
      },
      {
        "avg_logprob": -0.19121869943909725,
        "compression_ratio": 1.7148014440433212,
        "end": 1120.06,
        "id": 158,
        "no_speech_prob": 0.2479184865951538,
        "seek": 111070,
        "start": 1110.7,
        "temperature": 0,
        "text": " actually interacted with our dynamic server just yet. So let's go back to our checklist. We are listening for the submit, I guess one thing we'll do is when the",
        "tokens": [
          50364,
          767,
          49621,
          365,
          527,
          8546,
          7154,
          445,
          1939,
          13,
          407,
          718,
          311,
          352,
          646,
          281,
          527,
          30357,
          13,
          492,
          366,
          4764,
          337,
          264,
          10315,
          11,
          286,
          2041,
          472,
          551,
          321,
          603,
          360,
          307,
          562,
          264,
          50832
        ]
      },
      {
        "avg_logprob": -0.19121869943909725,
        "compression_ratio": 1.7148014440433212,
        "end": 1127.14,
        "id": 159,
        "no_speech_prob": 0.2479184865951538,
        "seek": 111070,
        "start": 1120.06,
        "temperature": 0,
        "text": " form is submitted, we want the user to know that something is happening, like the data is going somewhere. So I'm actually going to show a little loading",
        "tokens": [
          50832,
          1254,
          307,
          14405,
          11,
          321,
          528,
          264,
          4195,
          281,
          458,
          300,
          746,
          307,
          2737,
          11,
          411,
          264,
          1412,
          307,
          516,
          4079,
          13,
          407,
          286,
          478,
          767,
          516,
          281,
          855,
          257,
          707,
          15114,
          51186
        ]
      },
      {
        "avg_logprob": -0.19121869943909725,
        "compression_ratio": 1.7148014440433212,
        "end": 1137.66,
        "id": 160,
        "no_speech_prob": 0.2479184865951538,
        "seek": 111070,
        "start": 1127.14,
        "temperature": 0,
        "text": " image. So I have this loading GIF here, let me put it in the client. And in the HTML, I'm going to have a div right below the form. Let's just give this a class",
        "tokens": [
          51186,
          3256,
          13,
          407,
          286,
          362,
          341,
          15114,
          460,
          12775,
          510,
          11,
          718,
          385,
          829,
          309,
          294,
          264,
          6423,
          13,
          400,
          294,
          264,
          17995,
          11,
          286,
          478,
          516,
          281,
          362,
          257,
          3414,
          558,
          2507,
          264,
          1254,
          13,
          961,
          311,
          445,
          976,
          341,
          257,
          1508,
          51712
        ]
      },
      {
        "avg_logprob": -0.20906895531548395,
        "compression_ratio": 1.5211267605633803,
        "end": 1148.42,
        "id": 161,
        "no_speech_prob": 0.030672697350382805,
        "seek": 113766,
        "start": 1137.7,
        "temperature": 0,
        "text": " of loading. And inside of here, I'll have an image, its source will be loading.gif. And by default, it should like show on the page. There it is. But I want to",
        "tokens": [
          50366,
          295,
          15114,
          13,
          400,
          1854,
          295,
          510,
          11,
          286,
          603,
          362,
          364,
          3256,
          11,
          1080,
          4009,
          486,
          312,
          15114,
          13,
          70,
          351,
          13,
          400,
          538,
          7576,
          11,
          309,
          820,
          411,
          855,
          322,
          264,
          3028,
          13,
          821,
          309,
          307,
          13,
          583,
          286,
          528,
          281,
          50902
        ]
      },
      {
        "avg_logprob": -0.20906895531548395,
        "compression_ratio": 1.5211267605633803,
        "end": 1160.18,
        "id": 162,
        "no_speech_prob": 0.030672697350382805,
        "seek": 113766,
        "start": 1148.42,
        "temperature": 0,
        "text": " like center it first. So in my CSS, I'll say loading. Actually, let's just give it the same 50% width as the new form. So that way it should automatically pop up in",
        "tokens": [
          50902,
          411,
          3056,
          309,
          700,
          13,
          407,
          294,
          452,
          24387,
          11,
          286,
          603,
          584,
          15114,
          13,
          5135,
          11,
          718,
          311,
          445,
          976,
          309,
          264,
          912,
          2625,
          4,
          11402,
          382,
          264,
          777,
          1254,
          13,
          407,
          300,
          636,
          309,
          820,
          6772,
          1665,
          493,
          294,
          51490
        ]
      },
      {
        "avg_logprob": -0.2466283925374349,
        "compression_ratio": 1.619289340101523,
        "end": 1172.3400000000001,
        "id": 163,
        "no_speech_prob": 0.29093149304389954,
        "seek": 116018,
        "start": 1160.18,
        "temperature": 0,
        "text": " the middle. Almost good enough for me. So the this is showing automatically when the page loads, but I actually want to hide it the moment the page loads and",
        "tokens": [
          50364,
          264,
          2808,
          13,
          12627,
          665,
          1547,
          337,
          385,
          13,
          407,
          264,
          341,
          307,
          4099,
          6772,
          562,
          264,
          3028,
          12668,
          11,
          457,
          286,
          767,
          528,
          281,
          6479,
          309,
          264,
          1623,
          264,
          3028,
          12668,
          293,
          50972
        ]
      },
      {
        "avg_logprob": -0.2466283925374349,
        "compression_ratio": 1.619289340101523,
        "end": 1180.98,
        "id": 164,
        "no_speech_prob": 0.29093149304389954,
        "seek": 116018,
        "start": 1172.3400000000001,
        "temperature": 0,
        "text": " then only show it whenever we've submitted the form. So let's grab a reference to it. So I'm gonna call this the loading element, this will be document dot query",
        "tokens": [
          50972,
          550,
          787,
          855,
          309,
          5699,
          321,
          600,
          14405,
          264,
          1254,
          13,
          407,
          718,
          311,
          4444,
          257,
          6408,
          281,
          309,
          13,
          407,
          286,
          478,
          799,
          818,
          341,
          264,
          15114,
          4478,
          11,
          341,
          486,
          312,
          4166,
          5893,
          14581,
          51404
        ]
      },
      {
        "avg_logprob": -0.1850335570587509,
        "compression_ratio": 1.7258064516129032,
        "end": 1191.78,
        "id": 165,
        "no_speech_prob": 0.1847369521856308,
        "seek": 118098,
        "start": 1180.98,
        "temperature": 0,
        "text": " selector. And we need to pass in some selector to get access to this div. In this case, I can tell it to grab the element with the loading class. And when the",
        "tokens": [
          50364,
          23264,
          1672,
          13,
          400,
          321,
          643,
          281,
          1320,
          294,
          512,
          23264,
          1672,
          281,
          483,
          2105,
          281,
          341,
          3414,
          13,
          682,
          341,
          1389,
          11,
          286,
          393,
          980,
          309,
          281,
          4444,
          264,
          4478,
          365,
          264,
          15114,
          1508,
          13,
          400,
          562,
          264,
          50904
        ]
      },
      {
        "avg_logprob": -0.1850335570587509,
        "compression_ratio": 1.7258064516129032,
        "end": 1203.14,
        "id": 166,
        "no_speech_prob": 0.1847369521856308,
        "seek": 118098,
        "start": 1191.78,
        "temperature": 0,
        "text": " page loads, I'm just going to hide it. So to do that, I can access its style. So loading element dot style, and set its display to none. Okay, and so now when the",
        "tokens": [
          50904,
          3028,
          12668,
          11,
          286,
          478,
          445,
          516,
          281,
          6479,
          309,
          13,
          407,
          281,
          360,
          300,
          11,
          286,
          393,
          2105,
          1080,
          3758,
          13,
          407,
          15114,
          4478,
          5893,
          3758,
          11,
          293,
          992,
          1080,
          4674,
          281,
          6022,
          13,
          1033,
          11,
          293,
          370,
          586,
          562,
          264,
          51472
        ]
      },
      {
        "avg_logprob": -0.2135207494099935,
        "compression_ratio": 1.6989795918367347,
        "end": 1213.7,
        "id": 167,
        "no_speech_prob": 0.2974008023738861,
        "seek": 120314,
        "start": 1203.14,
        "temperature": 0,
        "text": " page loads, the loading actually hides. But what we want is when we submit the form, we will hide the form and show the loading. So here's what I'll do. I'll set the",
        "tokens": [
          50364,
          3028,
          12668,
          11,
          264,
          15114,
          767,
          35953,
          13,
          583,
          437,
          321,
          528,
          307,
          562,
          321,
          10315,
          264,
          1254,
          11,
          321,
          486,
          6479,
          264,
          1254,
          293,
          855,
          264,
          15114,
          13,
          407,
          510,
          311,
          437,
          286,
          603,
          360,
          13,
          286,
          603,
          992,
          264,
          50892
        ]
      },
      {
        "avg_logprob": -0.2135207494099935,
        "compression_ratio": 1.6989795918367347,
        "end": 1227.7800000000002,
        "id": 168,
        "no_speech_prob": 0.2974008023738861,
        "seek": 120314,
        "start": 1213.7,
        "temperature": 0,
        "text": " loading to be displayed, and then I'll set the form to be hidden. Okay, so my name is CJ, my name is Hello World. And then when I click submit, we're logging it to the",
        "tokens": [
          50892,
          15114,
          281,
          312,
          16372,
          11,
          293,
          550,
          286,
          603,
          992,
          264,
          1254,
          281,
          312,
          7633,
          13,
          1033,
          11,
          370,
          452,
          1315,
          307,
          42285,
          11,
          452,
          1315,
          307,
          2425,
          3937,
          13,
          400,
          550,
          562,
          286,
          2052,
          10315,
          11,
          321,
          434,
          27991,
          309,
          281,
          264,
          51596
        ]
      },
      {
        "avg_logprob": -0.2768870622683794,
        "compression_ratio": 1.5888324873096447,
        "end": 1238.66,
        "id": 169,
        "no_speech_prob": 0.7278273701667786,
        "seek": 122778,
        "start": 1227.78,
        "temperature": 0,
        "text": " console, we're showing this loading image. But now we actually need to send the data somewhere. Someone is giving me a tip. Noel is saying center the GIF with text align center on the",
        "tokens": [
          50364,
          11076,
          11,
          321,
          434,
          4099,
          341,
          15114,
          3256,
          13,
          583,
          586,
          321,
          767,
          643,
          281,
          2845,
          264,
          1412,
          4079,
          13,
          8734,
          307,
          2902,
          385,
          257,
          4125,
          13,
          38824,
          307,
          1566,
          3056,
          264,
          460,
          12775,
          365,
          2487,
          7975,
          3056,
          322,
          264,
          50908
        ]
      },
      {
        "avg_logprob": -0.2768870622683794,
        "compression_ratio": 1.5888324873096447,
        "end": 1250.86,
        "id": 170,
        "no_speech_prob": 0.7278273701667786,
        "seek": 122778,
        "start": 1238.66,
        "temperature": 0,
        "text": " container. Let's do it. So in here, well, actually, I specifically want to say loading has text align center. Yeah, thanks, Noel.",
        "tokens": [
          50908,
          10129,
          13,
          961,
          311,
          360,
          309,
          13,
          407,
          294,
          510,
          11,
          731,
          11,
          767,
          11,
          286,
          4682,
          528,
          281,
          584,
          15114,
          575,
          2487,
          7975,
          3056,
          13,
          865,
          11,
          3231,
          11,
          38824,
          13,
          51518
        ]
      },
      {
        "avg_logprob": -0.2335365980099409,
        "compression_ratio": 1.681159420289855,
        "end": 1261.4199999999998,
        "id": 171,
        "no_speech_prob": 0.18473653495311737,
        "seek": 125086,
        "start": 1251.82,
        "temperature": 0,
        "text": " Actually, I just turned my mic back on a couple interesting questions. I noticed you using using query selector. Yes. And somebody asked, well, why don't you use on click or I know",
        "tokens": [
          50412,
          5135,
          11,
          286,
          445,
          3574,
          452,
          3123,
          646,
          322,
          257,
          1916,
          1880,
          1651,
          13,
          286,
          5694,
          291,
          1228,
          1228,
          14581,
          23264,
          1672,
          13,
          1079,
          13,
          400,
          2618,
          2351,
          11,
          731,
          11,
          983,
          500,
          380,
          291,
          764,
          322,
          2052,
          420,
          286,
          458,
          50892
        ]
      },
      {
        "avg_logprob": -0.2335365980099409,
        "compression_ratio": 1.681159420289855,
        "end": 1267.9399999999998,
        "id": 172,
        "no_speech_prob": 0.18473653495311737,
        "seek": 125086,
        "start": 1261.4199999999998,
        "temperature": 0,
        "text": " there's like document dot get element by etc. So can you talk a bit about why you'd use a query selector?",
        "tokens": [
          50892,
          456,
          311,
          411,
          4166,
          5893,
          483,
          4478,
          538,
          5183,
          13,
          407,
          393,
          291,
          751,
          257,
          857,
          466,
          983,
          291,
          1116,
          764,
          257,
          14581,
          23264,
          1672,
          30,
          51218
        ]
      },
      {
        "avg_logprob": -0.2335365980099409,
        "compression_ratio": 1.681159420289855,
        "end": 1275.58,
        "id": 173,
        "no_speech_prob": 0.18473653495311737,
        "seek": 125086,
        "start": 1267.9799999999998,
        "temperature": 0,
        "text": " Definitely. So ultimately, what I want to do with this line of code is select some element on the page. So there are a lot of different ways to do it. There's get element by ID,",
        "tokens": [
          51220,
          12151,
          13,
          407,
          6284,
          11,
          437,
          286,
          528,
          281,
          360,
          365,
          341,
          1622,
          295,
          3089,
          307,
          3048,
          512,
          4478,
          322,
          264,
          3028,
          13,
          407,
          456,
          366,
          257,
          688,
          295,
          819,
          2098,
          281,
          360,
          309,
          13,
          821,
          311,
          483,
          4478,
          538,
          7348,
          11,
          51600
        ]
      },
      {
        "avg_logprob": -0.2016556132923473,
        "compression_ratio": 1.647940074906367,
        "end": 1285.98,
        "id": 174,
        "no_speech_prob": 0.04271898418664932,
        "seek": 127558,
        "start": 1275.58,
        "temperature": 0,
        "text": " there's get elements by class name, get elements by tag name. There's if you've ever used jQuery, it's just like dollar sign and putting the selector you want in there. I",
        "tokens": [
          50364,
          456,
          311,
          483,
          4959,
          538,
          1508,
          1315,
          11,
          483,
          4959,
          538,
          6162,
          1315,
          13,
          821,
          311,
          498,
          291,
          600,
          1562,
          1143,
          361,
          35550,
          11,
          309,
          311,
          445,
          411,
          7241,
          1465,
          293,
          3372,
          264,
          23264,
          1672,
          291,
          528,
          294,
          456,
          13,
          286,
          50884
        ]
      },
      {
        "avg_logprob": -0.2016556132923473,
        "compression_ratio": 1.647940074906367,
        "end": 1295.26,
        "id": 175,
        "no_speech_prob": 0.04271898418664932,
        "seek": 127558,
        "start": 1285.98,
        "temperature": 0,
        "text": " mainly use this because it's convenient. Like I know what specifically what selector to use to select it. But at the end of the day, this is just grabbing an element on the",
        "tokens": [
          50884,
          8704,
          764,
          341,
          570,
          309,
          311,
          10851,
          13,
          1743,
          286,
          458,
          437,
          4682,
          437,
          23264,
          1672,
          281,
          764,
          281,
          3048,
          309,
          13,
          583,
          412,
          264,
          917,
          295,
          264,
          786,
          11,
          341,
          307,
          445,
          23771,
          364,
          4478,
          322,
          264,
          51348
        ]
      },
      {
        "avg_logprob": -0.2016556132923473,
        "compression_ratio": 1.647940074906367,
        "end": 1300.6599999999999,
        "id": 176,
        "no_speech_prob": 0.04271898418664932,
        "seek": 127558,
        "start": 1295.26,
        "temperature": 0,
        "text": " page. So you can use whatever you're comfortable with. Cool. That's a good question. Other ones?",
        "tokens": [
          51348,
          3028,
          13,
          407,
          291,
          393,
          764,
          2035,
          291,
          434,
          4619,
          365,
          13,
          8561,
          13,
          663,
          311,
          257,
          665,
          1168,
          13,
          5358,
          2306,
          30,
          51618
        ]
      },
      {
        "avg_logprob": -0.3457479989656838,
        "compression_ratio": 1.6340425531914893,
        "end": 1311.26,
        "id": 177,
        "no_speech_prob": 0.0293060801923275,
        "seek": 130066,
        "start": 1301.66,
        "temperature": 0,
        "text": " There were some more I was trying to keep them like slightly. Let me see. Okay, well, one person asked does use you know, I think they were referring to this is",
        "tokens": [
          50414,
          821,
          645,
          512,
          544,
          286,
          390,
          1382,
          281,
          1066,
          552,
          411,
          4748,
          13,
          961,
          385,
          536,
          13,
          1033,
          11,
          731,
          11,
          472,
          954,
          2351,
          775,
          764,
          291,
          458,
          11,
          286,
          519,
          436,
          645,
          13761,
          281,
          341,
          307,
          50894
        ]
      },
      {
        "avg_logprob": -0.3457479989656838,
        "compression_ratio": 1.6340425531914893,
        "end": 1322.46,
        "id": 178,
        "no_speech_prob": 0.0293060801923275,
        "seek": 130066,
        "start": 1311.3000000000002,
        "temperature": 0,
        "text": " Ahmad in the chat as does using a framework affect performance. And I think that was referring to the CSS framework. So like, is it like a big thing to load? Does it make the",
        "tokens": [
          50896,
          35911,
          294,
          264,
          5081,
          382,
          775,
          1228,
          257,
          8388,
          3345,
          3389,
          13,
          400,
          286,
          519,
          300,
          390,
          13761,
          281,
          264,
          24387,
          8388,
          13,
          407,
          411,
          11,
          307,
          309,
          411,
          257,
          955,
          551,
          281,
          3677,
          30,
          4402,
          309,
          652,
          264,
          51454
        ]
      },
      {
        "avg_logprob": -0.3457479989656838,
        "compression_ratio": 1.6340425531914893,
        "end": 1324.38,
        "id": 179,
        "no_speech_prob": 0.0293060801923275,
        "seek": 130066,
        "start": 1322.46,
        "temperature": 0,
        "text": " page run slower? Are there considerations there?",
        "tokens": [
          51454,
          3028,
          1190,
          14009,
          30,
          2014,
          456,
          24070,
          456,
          30,
          51550
        ]
      },
      {
        "avg_logprob": -0.21873873089431622,
        "compression_ratio": 1.6551724137931034,
        "end": 1334.98,
        "id": 180,
        "no_speech_prob": 0.026350222527980804,
        "seek": 132438,
        "start": 1324.42,
        "temperature": 0,
        "text": " Definitely. So I wouldn't say it makes the page run slow, but there will be a little bit of time before the styles will kick in because the browser does have to download the CSS",
        "tokens": [
          50366,
          12151,
          13,
          407,
          286,
          2759,
          380,
          584,
          309,
          1669,
          264,
          3028,
          1190,
          2964,
          11,
          457,
          456,
          486,
          312,
          257,
          707,
          857,
          295,
          565,
          949,
          264,
          13273,
          486,
          4437,
          294,
          570,
          264,
          11185,
          775,
          362,
          281,
          5484,
          264,
          24387,
          50894
        ]
      },
      {
        "avg_logprob": -0.21873873089431622,
        "compression_ratio": 1.6551724137931034,
        "end": 1340.14,
        "id": 181,
        "no_speech_prob": 0.026350222527980804,
        "seek": 132438,
        "start": 1334.98,
        "temperature": 0,
        "text": " file. But once it's downloaded the CSS file, and it's up and going, you're good to go there.",
        "tokens": [
          50894,
          3991,
          13,
          583,
          1564,
          309,
          311,
          21748,
          264,
          24387,
          3991,
          11,
          293,
          309,
          311,
          493,
          293,
          516,
          11,
          291,
          434,
          665,
          281,
          352,
          456,
          13,
          51152
        ]
      },
      {
        "avg_logprob": -0.21873873089431622,
        "compression_ratio": 1.6551724137931034,
        "end": 1349.5,
        "id": 182,
        "no_speech_prob": 0.026350222527980804,
        "seek": 132438,
        "start": 1341.14,
        "temperature": 0,
        "text": " And a mental note, I don't think we need to do this now. But people are in love with your color themes. I noticed your the console on the browser was like a dark",
        "tokens": [
          51202,
          400,
          257,
          4973,
          3637,
          11,
          286,
          500,
          380,
          519,
          321,
          643,
          281,
          360,
          341,
          586,
          13,
          583,
          561,
          366,
          294,
          959,
          365,
          428,
          2017,
          13544,
          13,
          286,
          5694,
          428,
          264,
          11076,
          322,
          264,
          11185,
          390,
          411,
          257,
          2877,
          51620
        ]
      },
      {
        "avg_logprob": -0.23395255759910302,
        "compression_ratio": 1.643939393939394,
        "end": 1355.14,
        "id": 183,
        "no_speech_prob": 0.585024356842041,
        "seek": 134950,
        "start": 1349.5,
        "temperature": 0,
        "text": " theme. So maybe a little bit at the end, maybe you could show us like, what fonts, theme settings and stuff.",
        "tokens": [
          50364,
          6314,
          13,
          407,
          1310,
          257,
          707,
          857,
          412,
          264,
          917,
          11,
          1310,
          291,
          727,
          855,
          505,
          411,
          11,
          437,
          35316,
          11,
          6314,
          6257,
          293,
          1507,
          13,
          50646
        ]
      },
      {
        "avg_logprob": -0.23395255759910302,
        "compression_ratio": 1.643939393939394,
        "end": 1364.22,
        "id": 184,
        "no_speech_prob": 0.585024356842041,
        "seek": 134950,
        "start": 1355.14,
        "temperature": 0,
        "text": " Definitely, definitely. And so I totally glossed over this. So on my channel, I talk about Vue.js, I talk about React, I talk about a lot of other front end",
        "tokens": [
          50646,
          12151,
          11,
          2138,
          13,
          400,
          370,
          286,
          3879,
          19574,
          292,
          670,
          341,
          13,
          407,
          322,
          452,
          2269,
          11,
          286,
          751,
          466,
          691,
          622,
          13,
          25530,
          11,
          286,
          751,
          466,
          30644,
          11,
          286,
          751,
          466,
          257,
          688,
          295,
          661,
          1868,
          917,
          51100
        ]
      },
      {
        "avg_logprob": -0.23395255759910302,
        "compression_ratio": 1.643939393939394,
        "end": 1373.14,
        "id": 185,
        "no_speech_prob": 0.585024356842041,
        "seek": 134950,
        "start": 1364.22,
        "temperature": 0,
        "text": " frameworks. And right now I'm doing all of this with what we call vanilla JavaScript, meaning I haven't added any JavaScript libraries, really to just show how all this",
        "tokens": [
          51100,
          29834,
          13,
          400,
          558,
          586,
          286,
          478,
          884,
          439,
          295,
          341,
          365,
          437,
          321,
          818,
          17528,
          15778,
          11,
          3620,
          286,
          2378,
          380,
          3869,
          604,
          15778,
          15148,
          11,
          534,
          281,
          445,
          855,
          577,
          439,
          341,
          51546
        ]
      },
      {
        "avg_logprob": -0.23901905119419098,
        "compression_ratio": 1.7114754098360656,
        "end": 1381.66,
        "id": 186,
        "no_speech_prob": 0.2909180521965027,
        "seek": 137314,
        "start": 1373.14,
        "temperature": 0,
        "text": " stuff is done manually. But typically, I'll use something like Vue.js, which which fits in here on the on the diagram will kind of show where specific technologies fit in.",
        "tokens": [
          50364,
          1507,
          307,
          1096,
          16945,
          13,
          583,
          5850,
          11,
          286,
          603,
          764,
          746,
          411,
          691,
          622,
          13,
          25530,
          11,
          597,
          597,
          9001,
          294,
          510,
          322,
          264,
          322,
          264,
          10686,
          486,
          733,
          295,
          855,
          689,
          2685,
          7943,
          3318,
          294,
          13,
          50790
        ]
      },
      {
        "avg_logprob": -0.23901905119419098,
        "compression_ratio": 1.7114754098360656,
        "end": 1389.98,
        "id": 187,
        "no_speech_prob": 0.2909180521965027,
        "seek": 137314,
        "start": 1381.66,
        "temperature": 0,
        "text": " And if you have any questions about like, where does this technology live? Throw that in the chat. And we can put it in the diagram too. Okay, let's look at our checklist.",
        "tokens": [
          50790,
          400,
          498,
          291,
          362,
          604,
          1651,
          466,
          411,
          11,
          689,
          775,
          341,
          2899,
          1621,
          30,
          22228,
          300,
          294,
          264,
          5081,
          13,
          400,
          321,
          393,
          829,
          309,
          294,
          264,
          10686,
          886,
          13,
          1033,
          11,
          718,
          311,
          574,
          412,
          527,
          30357,
          13,
          51206
        ]
      },
      {
        "avg_logprob": -0.23901905119419098,
        "compression_ratio": 1.7114754098360656,
        "end": 1398.38,
        "id": 188,
        "no_speech_prob": 0.2909180521965027,
        "seek": 137314,
        "start": 1390.0200000000002,
        "temperature": 0,
        "text": " We're hiding the form, we're showing the loading, we got the data form, we've logged it. And now we have completed two objectives, we have gotten user input on the client, and we",
        "tokens": [
          51208,
          492,
          434,
          10596,
          264,
          1254,
          11,
          321,
          434,
          4099,
          264,
          15114,
          11,
          321,
          658,
          264,
          1412,
          1254,
          11,
          321,
          600,
          27231,
          309,
          13,
          400,
          586,
          321,
          362,
          7365,
          732,
          15961,
          11,
          321,
          362,
          5768,
          4195,
          4846,
          322,
          264,
          6423,
          11,
          293,
          321,
          51626
        ]
      },
      {
        "avg_logprob": -0.24092701968983707,
        "compression_ratio": 1.7333333333333334,
        "end": 1406.18,
        "id": 189,
        "no_speech_prob": 0.2146580070257187,
        "seek": 139838,
        "start": 1398.38,
        "temperature": 0,
        "text": " have hidden and shown elements on the client. So this is typically how we get user input when you're dealing with some sort of form. And when you're dealing with vanilla",
        "tokens": [
          50364,
          362,
          7633,
          293,
          4898,
          4959,
          322,
          264,
          6423,
          13,
          407,
          341,
          307,
          5850,
          577,
          321,
          483,
          4195,
          4846,
          562,
          291,
          434,
          6260,
          365,
          512,
          1333,
          295,
          1254,
          13,
          400,
          562,
          291,
          434,
          6260,
          365,
          17528,
          50754
        ]
      },
      {
        "avg_logprob": -0.24092701968983707,
        "compression_ratio": 1.7333333333333334,
        "end": 1417.74,
        "id": 190,
        "no_speech_prob": 0.2146580070257187,
        "seek": 139838,
        "start": 1406.18,
        "temperature": 0,
        "text": " JavaScript, just manipulating the display property of style is how you hide and show something. So we're doing that. Now, we move on to the back end. So before, in the code",
        "tokens": [
          50754,
          15778,
          11,
          445,
          40805,
          264,
          4674,
          4707,
          295,
          3758,
          307,
          577,
          291,
          6479,
          293,
          855,
          746,
          13,
          407,
          321,
          434,
          884,
          300,
          13,
          823,
          11,
          321,
          1286,
          322,
          281,
          264,
          646,
          917,
          13,
          407,
          949,
          11,
          294,
          264,
          3089,
          51332
        ]
      },
      {
        "avg_logprob": -0.24092701968983707,
        "compression_ratio": 1.7333333333333334,
        "end": 1418.7,
        "id": 191,
        "no_speech_prob": 0.2146580070257187,
        "seek": 139838,
        "start": 1417.7800000000002,
        "temperature": 0,
        "text": " that we just wrote,",
        "tokens": [
          51334,
          300,
          321,
          445,
          4114,
          11,
          51380
        ]
      },
      {
        "avg_logprob": -0.24092701968983707,
        "compression_ratio": 1.7333333333333334,
        "end": 1426.8600000000001,
        "id": 192,
        "no_speech_prob": 0.2146580070257187,
        "seek": 139838,
        "start": 1420.46,
        "temperature": 0,
        "text": " if you click into the chat, you have to click back into the OBS window. Oh, this is this is me over here.",
        "tokens": [
          51468,
          498,
          291,
          2052,
          666,
          264,
          5081,
          11,
          291,
          362,
          281,
          2052,
          646,
          666,
          264,
          422,
          8176,
          4910,
          13,
          876,
          11,
          341,
          307,
          341,
          307,
          385,
          670,
          510,
          13,
          51788
        ]
      },
      {
        "avg_logprob": -0.23373818648488898,
        "compression_ratio": 1.7523364485981308,
        "end": 1438.6999999999998,
        "id": 193,
        "no_speech_prob": 0.00026947230799123645,
        "seek": 142686,
        "start": 1427.6599999999999,
        "temperature": 0,
        "text": " So the code, the code that we just wrote is very important note is is running right now it's running inside of the browser. I don't know if you can see that right, let me grab a different",
        "tokens": [
          50404,
          407,
          264,
          3089,
          11,
          264,
          3089,
          300,
          321,
          445,
          4114,
          307,
          588,
          1021,
          3637,
          307,
          307,
          2614,
          558,
          586,
          309,
          311,
          2614,
          1854,
          295,
          264,
          11185,
          13,
          286,
          500,
          380,
          458,
          498,
          291,
          393,
          536,
          300,
          558,
          11,
          718,
          385,
          4444,
          257,
          819,
          50956
        ]
      },
      {
        "avg_logprob": -0.23373818648488898,
        "compression_ratio": 1.7523364485981308,
        "end": 1448.1399999999999,
        "id": 194,
        "no_speech_prob": 0.00026947230799123645,
        "seek": 142686,
        "start": 1438.6999999999998,
        "temperature": 0,
        "text": " color. So we just created that index dot HTML, it's running in here. So what we're about to do is we're going to jump to the back end and write some code that's going to be running on our",
        "tokens": [
          50956,
          2017,
          13,
          407,
          321,
          445,
          2942,
          300,
          8186,
          5893,
          17995,
          11,
          309,
          311,
          2614,
          294,
          510,
          13,
          407,
          437,
          321,
          434,
          466,
          281,
          360,
          307,
          321,
          434,
          516,
          281,
          3012,
          281,
          264,
          646,
          917,
          293,
          2464,
          512,
          3089,
          300,
          311,
          516,
          281,
          312,
          2614,
          322,
          527,
          51428
        ]
      },
      {
        "avg_logprob": -0.19714991251627603,
        "compression_ratio": 1.7,
        "end": 1458.42,
        "id": 195,
        "no_speech_prob": 0.16024120151996613,
        "seek": 144814,
        "start": 1448.14,
        "temperature": 0,
        "text": " dynamic server over here. So let's do that. Okay, so first step, let's create the server folder. Now, as I mentioned, there's a lot of different ways to do this, you technically could put the client",
        "tokens": [
          50364,
          8546,
          7154,
          670,
          510,
          13,
          407,
          718,
          311,
          360,
          300,
          13,
          1033,
          11,
          370,
          700,
          1823,
          11,
          718,
          311,
          1884,
          264,
          7154,
          10820,
          13,
          823,
          11,
          382,
          286,
          2835,
          11,
          456,
          311,
          257,
          688,
          295,
          819,
          2098,
          281,
          360,
          341,
          11,
          291,
          12120,
          727,
          829,
          264,
          6423,
          50878
        ]
      },
      {
        "avg_logprob": -0.19714991251627603,
        "compression_ratio": 1.7,
        "end": 1469.5400000000002,
        "id": 196,
        "no_speech_prob": 0.16024120151996613,
        "seek": 144814,
        "start": 1458.42,
        "temperature": 0,
        "text": " folder inside of the server folder, but I'm just going to show them completely separate just to really differentiate between like what they are. So here, let's make a server folder. And in the",
        "tokens": [
          50878,
          10820,
          1854,
          295,
          264,
          7154,
          10820,
          11,
          457,
          286,
          478,
          445,
          516,
          281,
          855,
          552,
          2584,
          4994,
          445,
          281,
          534,
          23203,
          1296,
          411,
          437,
          436,
          366,
          13,
          407,
          510,
          11,
          718,
          311,
          652,
          257,
          7154,
          10820,
          13,
          400,
          294,
          264,
          51434
        ]
      },
      {
        "avg_logprob": -0.24360189705251534,
        "compression_ratio": 1.657992565055762,
        "end": 1482.86,
        "id": 197,
        "no_speech_prob": 0.38852569460868835,
        "seek": 146954,
        "start": 1469.54,
        "temperature": 0,
        "text": " server folder, this is going to be a node project. So I'm going to initialize this with a package JSON. So npm init dash y just gives it all of my defaults, it tells it my name gives it my default license. And then we need a",
        "tokens": [
          50364,
          7154,
          10820,
          11,
          341,
          307,
          516,
          281,
          312,
          257,
          9984,
          1716,
          13,
          407,
          286,
          478,
          516,
          281,
          5883,
          1125,
          341,
          365,
          257,
          7372,
          31828,
          13,
          407,
          297,
          14395,
          3157,
          8240,
          288,
          445,
          2709,
          309,
          439,
          295,
          452,
          7576,
          82,
          11,
          309,
          5112,
          309,
          452,
          1315,
          2709,
          309,
          452,
          7576,
          10476,
          13,
          400,
          550,
          321,
          643,
          257,
          51030
        ]
      },
      {
        "avg_logprob": -0.24360189705251534,
        "compression_ratio": 1.657992565055762,
        "end": 1497.74,
        "id": 198,
        "no_speech_prob": 0.38852569460868835,
        "seek": 146954,
        "start": 1482.86,
        "temperature": 0,
        "text": " couple of packages. So specifically, we're going to be using Express as our framework to listen for requests that come from the client, and then respond with the appropriate data. We're also going to be using a middleware",
        "tokens": [
          51030,
          1916,
          295,
          17401,
          13,
          407,
          4682,
          11,
          321,
          434,
          516,
          281,
          312,
          1228,
          20212,
          382,
          527,
          8388,
          281,
          2140,
          337,
          12475,
          300,
          808,
          490,
          264,
          6423,
          11,
          293,
          550,
          4196,
          365,
          264,
          6854,
          1412,
          13,
          492,
          434,
          611,
          516,
          281,
          312,
          1228,
          257,
          2808,
          3039,
          51774
        ]
      },
      {
        "avg_logprob": -0.2295154571533203,
        "compression_ratio": 1.3203125,
        "end": 1508.26,
        "id": 199,
        "no_speech_prob": 0.27199438214302063,
        "seek": 149774,
        "start": 1497.74,
        "temperature": 0,
        "text": " library called Morgan, which will log all of the incoming requests. So we can kind of debug what's happening on the server. So we're going to install Express and Morgan.",
        "tokens": [
          50364,
          6405,
          1219,
          16724,
          11,
          597,
          486,
          3565,
          439,
          295,
          264,
          22341,
          12475,
          13,
          407,
          321,
          393,
          733,
          295,
          24083,
          437,
          311,
          2737,
          322,
          264,
          7154,
          13,
          407,
          321,
          434,
          516,
          281,
          3625,
          20212,
          293,
          16724,
          13,
          50890
        ]
      },
      {
        "avg_logprob": -1.2948767344156902,
        "compression_ratio": 0.38461538461538464,
        "end": 1509.58,
        "id": 200,
        "no_speech_prob": 0.4299865961074829,
        "seek": 150826,
        "start": 1509.1,
        "temperature": 1,
        "text": " Cool.",
        "tokens": [
          50406,
          8561,
          13,
          50430
        ]
      },
      {
        "avg_logprob": -0.2791102503387021,
        "compression_ratio": 1.4539877300613497,
        "end": 1521.74,
        "id": 201,
        "no_speech_prob": 0.03208114951848984,
        "seek": 150958,
        "start": 1509.58,
        "temperature": 0,
        "text": " Awesome.",
        "tokens": [
          50364,
          10391,
          13,
          50972
        ]
      },
      {
        "avg_logprob": -0.2791102503387021,
        "compression_ratio": 1.4539877300613497,
        "end": 1523.24,
        "id": 202,
        "no_speech_prob": 0.03208114951848984,
        "seek": 150958,
        "start": 1521.74,
        "temperature": 0,
        "text": " So those two things installed.",
        "tokens": [
          50972,
          407,
          729,
          732,
          721,
          8899,
          13,
          51047
        ]
      },
      {
        "avg_logprob": -0.2791102503387021,
        "compression_ratio": 1.4539877300613497,
        "end": 1524.4199999999998,
        "id": 203,
        "no_speech_prob": 0.03208114951848984,
        "seek": 150958,
        "start": 1523.24,
        "temperature": 0,
        "text": " Now we can set up our server.",
        "tokens": [
          51047,
          823,
          321,
          393,
          992,
          493,
          527,
          7154,
          13,
          51106
        ]
      },
      {
        "avg_logprob": -0.2791102503387021,
        "compression_ratio": 1.4539877300613497,
        "end": 1529.22,
        "id": 204,
        "no_speech_prob": 0.03208114951848984,
        "seek": 150958,
        "start": 1524.4199999999998,
        "temperature": 0,
        "text": " So on the server, new file, let's call this index.js.",
        "tokens": [
          51106,
          407,
          322,
          264,
          7154,
          11,
          777,
          3991,
          11,
          718,
          311,
          818,
          341,
          8186,
          13,
          25530,
          13,
          51346
        ]
      },
      {
        "avg_logprob": -0.2791102503387021,
        "compression_ratio": 1.4539877300613497,
        "end": 1533.6399999999999,
        "id": 205,
        "no_speech_prob": 0.03208114951848984,
        "seek": 150958,
        "start": 1529.22,
        "temperature": 0,
        "text": " And inside of here, we're going to create our dynamic server, our backend application.",
        "tokens": [
          51346,
          400,
          1854,
          295,
          510,
          11,
          321,
          434,
          516,
          281,
          1884,
          527,
          8546,
          7154,
          11,
          527,
          38087,
          3861,
          13,
          51567
        ]
      },
      {
        "avg_logprob": -0.2791102503387021,
        "compression_ratio": 1.4539877300613497,
        "end": 1535.28,
        "id": 206,
        "no_speech_prob": 0.03208114951848984,
        "seek": 150958,
        "start": 1533.6399999999999,
        "temperature": 0,
        "text": " So let's bring in Express.",
        "tokens": [
          51567,
          407,
          718,
          311,
          1565,
          294,
          20212,
          13,
          51649
        ]
      },
      {
        "avg_logprob": -0.2361615124870749,
        "compression_ratio": 1.6756756756756757,
        "end": 1539.6,
        "id": 207,
        "no_speech_prob": 0.005469104275107384,
        "seek": 153528,
        "start": 1535.28,
        "temperature": 0,
        "text": " So if you're familiar with Node.js, this is how we bring in a library that we've installed",
        "tokens": [
          50364,
          407,
          498,
          291,
          434,
          4963,
          365,
          38640,
          13,
          25530,
          11,
          341,
          307,
          577,
          321,
          1565,
          294,
          257,
          6405,
          300,
          321,
          600,
          8899,
          50580
        ]
      },
      {
        "avg_logprob": -0.2361615124870749,
        "compression_ratio": 1.6756756756756757,
        "end": 1541.32,
        "id": 208,
        "no_speech_prob": 0.005469104275107384,
        "seek": 153528,
        "start": 1539.6,
        "temperature": 0,
        "text": " with NPM.",
        "tokens": [
          50580,
          365,
          426,
          18819,
          13,
          50666
        ]
      },
      {
        "avg_logprob": -0.2361615124870749,
        "compression_ratio": 1.6756756756756757,
        "end": 1542.6,
        "id": 209,
        "no_speech_prob": 0.005469104275107384,
        "seek": 153528,
        "start": 1541.32,
        "temperature": 0,
        "text": " So I brought in the Express library.",
        "tokens": [
          50666,
          407,
          286,
          3038,
          294,
          264,
          20212,
          6405,
          13,
          50730
        ]
      },
      {
        "avg_logprob": -0.2361615124870749,
        "compression_ratio": 1.6756756756756757,
        "end": 1544.96,
        "id": 210,
        "no_speech_prob": 0.005469104275107384,
        "seek": 153528,
        "start": 1542.6,
        "temperature": 0,
        "text": " And the first thing we do is create an application.",
        "tokens": [
          50730,
          400,
          264,
          700,
          551,
          321,
          360,
          307,
          1884,
          364,
          3861,
          13,
          50848
        ]
      },
      {
        "avg_logprob": -0.2361615124870749,
        "compression_ratio": 1.6756756756756757,
        "end": 1548.8,
        "id": 211,
        "no_speech_prob": 0.005469104275107384,
        "seek": 153528,
        "start": 1544.96,
        "temperature": 0,
        "text": " And this is just equal to app equals Express invoked.",
        "tokens": [
          50848,
          400,
          341,
          307,
          445,
          2681,
          281,
          724,
          6915,
          20212,
          1048,
          9511,
          13,
          51040
        ]
      },
      {
        "avg_logprob": -0.2361615124870749,
        "compression_ratio": 1.6756756756756757,
        "end": 1551.6,
        "id": 212,
        "no_speech_prob": 0.005469104275107384,
        "seek": 153528,
        "start": 1548.8,
        "temperature": 0,
        "text": " So now I have an Express application.",
        "tokens": [
          51040,
          407,
          586,
          286,
          362,
          364,
          20212,
          3861,
          13,
          51180
        ]
      },
      {
        "avg_logprob": -0.2361615124870749,
        "compression_ratio": 1.6756756756756757,
        "end": 1553.5,
        "id": 213,
        "no_speech_prob": 0.005469104275107384,
        "seek": 153528,
        "start": 1551.6,
        "temperature": 0,
        "text": " And now we want it to actually start listening.",
        "tokens": [
          51180,
          400,
          586,
          321,
          528,
          309,
          281,
          767,
          722,
          4764,
          13,
          51275
        ]
      },
      {
        "avg_logprob": -0.2361615124870749,
        "compression_ratio": 1.6756756756756757,
        "end": 1558.8,
        "id": 214,
        "no_speech_prob": 0.005469104275107384,
        "seek": 153528,
        "start": 1553.5,
        "temperature": 0,
        "text": " So if you saw before, right now I'm using this static file server, which is live server.",
        "tokens": [
          51275,
          407,
          498,
          291,
          1866,
          949,
          11,
          558,
          586,
          286,
          478,
          1228,
          341,
          13437,
          3991,
          7154,
          11,
          597,
          307,
          1621,
          7154,
          13,
          51540
        ]
      },
      {
        "avg_logprob": -0.2361615124870749,
        "compression_ratio": 1.6756756756756757,
        "end": 1561.12,
        "id": 215,
        "no_speech_prob": 0.005469104275107384,
        "seek": 153528,
        "start": 1558.8,
        "temperature": 0,
        "text": " And it's running on port 8080.",
        "tokens": [
          51540,
          400,
          309,
          311,
          2614,
          322,
          2436,
          4688,
          4702,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.2361615124870749,
        "compression_ratio": 1.6756756756756757,
        "end": 1563.44,
        "id": 216,
        "no_speech_prob": 0.005469104275107384,
        "seek": 153528,
        "start": 1561.12,
        "temperature": 0,
        "text": " Every computer has many, many different ports.",
        "tokens": [
          51656,
          2048,
          3820,
          575,
          867,
          11,
          867,
          819,
          18160,
          13,
          51772
        ]
      },
      {
        "avg_logprob": -0.24406956403683394,
        "compression_ratio": 1.6260504201680672,
        "end": 1566.04,
        "id": 217,
        "no_speech_prob": 0.0021489346399903297,
        "seek": 156344,
        "start": 1563.44,
        "temperature": 0,
        "text": " And so we're going to have two servers running on my computer.",
        "tokens": [
          50364,
          400,
          370,
          321,
          434,
          516,
          281,
          362,
          732,
          15909,
          2614,
          322,
          452,
          3820,
          13,
          50494
        ]
      },
      {
        "avg_logprob": -0.24406956403683394,
        "compression_ratio": 1.6260504201680672,
        "end": 1568.96,
        "id": 218,
        "no_speech_prob": 0.0021489346399903297,
        "seek": 156344,
        "start": 1566.04,
        "temperature": 0,
        "text": " One will be on 8080, and the other one will be on 5000.",
        "tokens": [
          50494,
          1485,
          486,
          312,
          322,
          4688,
          4702,
          11,
          293,
          264,
          661,
          472,
          486,
          312,
          322,
          23777,
          13,
          50640
        ]
      },
      {
        "avg_logprob": -0.24406956403683394,
        "compression_ratio": 1.6260504201680672,
        "end": 1570.72,
        "id": 219,
        "no_speech_prob": 0.0021489346399903297,
        "seek": 156344,
        "start": 1568.96,
        "temperature": 0,
        "text": " So I want to start up this backend server.",
        "tokens": [
          50640,
          407,
          286,
          528,
          281,
          722,
          493,
          341,
          38087,
          7154,
          13,
          50728
        ]
      },
      {
        "avg_logprob": -0.24406956403683394,
        "compression_ratio": 1.6260504201680672,
        "end": 1574.44,
        "id": 220,
        "no_speech_prob": 0.0021489346399903297,
        "seek": 156344,
        "start": 1570.72,
        "temperature": 0,
        "text": " And I'm going to tell it to listen on port 5000.",
        "tokens": [
          50728,
          400,
          286,
          478,
          516,
          281,
          980,
          309,
          281,
          2140,
          322,
          2436,
          23777,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.24406956403683394,
        "compression_ratio": 1.6260504201680672,
        "end": 1578.8,
        "id": 221,
        "no_speech_prob": 0.0021489346399903297,
        "seek": 156344,
        "start": 1574.44,
        "temperature": 0,
        "text": " And when it's ready to go, I'm going to just log out.",
        "tokens": [
          50914,
          400,
          562,
          309,
          311,
          1919,
          281,
          352,
          11,
          286,
          478,
          516,
          281,
          445,
          3565,
          484,
          13,
          51132
        ]
      },
      {
        "avg_logprob": -0.24406956403683394,
        "compression_ratio": 1.6260504201680672,
        "end": 1584.28,
        "id": 222,
        "no_speech_prob": 0.0021489346399903297,
        "seek": 156344,
        "start": 1578.8,
        "temperature": 0,
        "text": " Listening on HTTP://localhost 5000.",
        "tokens": [
          51132,
          49321,
          322,
          33283,
          21492,
          5842,
          304,
          6037,
          23777,
          13,
          51406
        ]
      },
      {
        "avg_logprob": -0.24406956403683394,
        "compression_ratio": 1.6260504201680672,
        "end": 1586.44,
        "id": 223,
        "no_speech_prob": 0.0021489346399903297,
        "seek": 156344,
        "start": 1584.28,
        "temperature": 0,
        "text": " Cool.",
        "tokens": [
          51406,
          8561,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.24406956403683394,
        "compression_ratio": 1.6260504201680672,
        "end": 1591.8400000000001,
        "id": 224,
        "no_speech_prob": 0.0021489346399903297,
        "seek": 156344,
        "start": 1586.44,
        "temperature": 0,
        "text": " And so if I run this, we should get a server that starts listening on port 5000.",
        "tokens": [
          51514,
          400,
          370,
          498,
          286,
          1190,
          341,
          11,
          321,
          820,
          483,
          257,
          7154,
          300,
          3719,
          4764,
          322,
          2436,
          23777,
          13,
          51784
        ]
      },
      {
        "avg_logprob": -0.1852713937628759,
        "compression_ratio": 1.6466666666666667,
        "end": 1596.24,
        "id": 225,
        "no_speech_prob": 0.021613916382193565,
        "seek": 159184,
        "start": 1591.84,
        "temperature": 0,
        "text": " So before I start it, in my package JSON, I'm going to add a start script.",
        "tokens": [
          50364,
          407,
          949,
          286,
          722,
          309,
          11,
          294,
          452,
          7372,
          31828,
          11,
          286,
          478,
          516,
          281,
          909,
          257,
          722,
          5755,
          13,
          50584
        ]
      },
      {
        "avg_logprob": -0.1852713937628759,
        "compression_ratio": 1.6466666666666667,
        "end": 1601.3999999999999,
        "id": 226,
        "no_speech_prob": 0.021613916382193565,
        "seek": 159184,
        "start": 1596.24,
        "temperature": 0,
        "text": " So this is basically where you can put the command that should actually start up your",
        "tokens": [
          50584,
          407,
          341,
          307,
          1936,
          689,
          291,
          393,
          829,
          264,
          5622,
          300,
          820,
          767,
          722,
          493,
          428,
          50842
        ]
      },
      {
        "avg_logprob": -0.1852713937628759,
        "compression_ratio": 1.6466666666666667,
        "end": 1602.3999999999999,
        "id": 227,
        "no_speech_prob": 0.021613916382193565,
        "seek": 159184,
        "start": 1601.3999999999999,
        "temperature": 0,
        "text": " server.",
        "tokens": [
          50842,
          7154,
          13,
          50892
        ]
      },
      {
        "avg_logprob": -0.1852713937628759,
        "compression_ratio": 1.6466666666666667,
        "end": 1604.8,
        "id": 228,
        "no_speech_prob": 0.021613916382193565,
        "seek": 159184,
        "start": 1602.3999999999999,
        "temperature": 0,
        "text": " In this case, it's node index.js.",
        "tokens": [
          50892,
          682,
          341,
          1389,
          11,
          309,
          311,
          9984,
          8186,
          13,
          25530,
          13,
          51012
        ]
      },
      {
        "avg_logprob": -0.1852713937628759,
        "compression_ratio": 1.6466666666666667,
        "end": 1608.48,
        "id": 229,
        "no_speech_prob": 0.021613916382193565,
        "seek": 159184,
        "start": 1604.8,
        "temperature": 0,
        "text": " And by doing this, now in the terminal, I can just do NPM start.",
        "tokens": [
          51012,
          400,
          538,
          884,
          341,
          11,
          586,
          294,
          264,
          14709,
          11,
          286,
          393,
          445,
          360,
          426,
          18819,
          722,
          13,
          51196
        ]
      },
      {
        "avg_logprob": -0.1852713937628759,
        "compression_ratio": 1.6466666666666667,
        "end": 1610.72,
        "id": 230,
        "no_speech_prob": 0.021613916382193565,
        "seek": 159184,
        "start": 1608.48,
        "temperature": 0,
        "text": " And that will start up my server on port 5000.",
        "tokens": [
          51196,
          400,
          300,
          486,
          722,
          493,
          452,
          7154,
          322,
          2436,
          23777,
          13,
          51308
        ]
      },
      {
        "avg_logprob": -0.1852713937628759,
        "compression_ratio": 1.6466666666666667,
        "end": 1613.32,
        "id": 231,
        "no_speech_prob": 0.021613916382193565,
        "seek": 159184,
        "start": 1610.72,
        "temperature": 0,
        "text": " So if we take a look at it, right now it's nothing.",
        "tokens": [
          51308,
          407,
          498,
          321,
          747,
          257,
          574,
          412,
          309,
          11,
          558,
          586,
          309,
          311,
          1825,
          13,
          51438
        ]
      },
      {
        "avg_logprob": -0.1852713937628759,
        "compression_ratio": 1.6466666666666667,
        "end": 1615.8799999999999,
        "id": 232,
        "no_speech_prob": 0.021613916382193565,
        "seek": 159184,
        "start": 1613.32,
        "temperature": 0,
        "text": " So we have a blank backend application.",
        "tokens": [
          51438,
          407,
          321,
          362,
          257,
          8247,
          38087,
          3861,
          13,
          51566
        ]
      },
      {
        "avg_logprob": -0.1852713937628759,
        "compression_ratio": 1.6466666666666667,
        "end": 1617.1599999999999,
        "id": 233,
        "no_speech_prob": 0.021613916382193565,
        "seek": 159184,
        "start": 1615.8799999999999,
        "temperature": 0,
        "text": " It doesn't have any routes.",
        "tokens": [
          51566,
          467,
          1177,
          380,
          362,
          604,
          18242,
          13,
          51630
        ]
      },
      {
        "avg_logprob": -0.1852713937628759,
        "compression_ratio": 1.6466666666666667,
        "end": 1620.06,
        "id": 234,
        "no_speech_prob": 0.021613916382193565,
        "seek": 159184,
        "start": 1617.1599999999999,
        "temperature": 0,
        "text": " So when I try to request it, it just says, cannot get that.",
        "tokens": [
          51630,
          407,
          562,
          286,
          853,
          281,
          5308,
          309,
          11,
          309,
          445,
          1619,
          11,
          2644,
          483,
          300,
          13,
          51775
        ]
      },
      {
        "avg_logprob": -0.1902015944172565,
        "compression_ratio": 1.7118055555555556,
        "end": 1623.82,
        "id": 235,
        "no_speech_prob": 0.004829613491892815,
        "seek": 162006,
        "start": 1620.06,
        "temperature": 0,
        "text": " And so basically, we're going to start defining what happens when a client makes requests",
        "tokens": [
          50364,
          400,
          370,
          1936,
          11,
          321,
          434,
          516,
          281,
          722,
          17827,
          437,
          2314,
          562,
          257,
          6423,
          1669,
          12475,
          50552
        ]
      },
      {
        "avg_logprob": -0.1902015944172565,
        "compression_ratio": 1.7118055555555556,
        "end": 1625.78,
        "id": 236,
        "no_speech_prob": 0.004829613491892815,
        "seek": 162006,
        "start": 1623.82,
        "temperature": 0,
        "text": " to this server.",
        "tokens": [
          50552,
          281,
          341,
          7154,
          13,
          50650
        ]
      },
      {
        "avg_logprob": -0.1902015944172565,
        "compression_ratio": 1.7118055555555556,
        "end": 1627.86,
        "id": 237,
        "no_speech_prob": 0.004829613491892815,
        "seek": 162006,
        "start": 1625.78,
        "temperature": 0,
        "text": " So let's look at our checklist.",
        "tokens": [
          50650,
          407,
          718,
          311,
          574,
          412,
          527,
          30357,
          13,
          50754
        ]
      },
      {
        "avg_logprob": -0.1902015944172565,
        "compression_ratio": 1.7118055555555556,
        "end": 1629.3,
        "id": 238,
        "no_speech_prob": 0.004829613491892815,
        "seek": 162006,
        "start": 1627.86,
        "temperature": 0,
        "text": " We created the server folder.",
        "tokens": [
          50754,
          492,
          2942,
          264,
          7154,
          10820,
          13,
          50826
        ]
      },
      {
        "avg_logprob": -0.1902015944172565,
        "compression_ratio": 1.7118055555555556,
        "end": 1630.3,
        "id": 239,
        "no_speech_prob": 0.004829613491892815,
        "seek": 162006,
        "start": 1629.3,
        "temperature": 0,
        "text": " We initialized it.",
        "tokens": [
          50826,
          492,
          5883,
          1602,
          309,
          13,
          50876
        ]
      },
      {
        "avg_logprob": -0.1902015944172565,
        "compression_ratio": 1.7118055555555556,
        "end": 1631.3,
        "id": 240,
        "no_speech_prob": 0.004829613491892815,
        "seek": 162006,
        "start": 1630.3,
        "temperature": 0,
        "text": " We installed dependencies.",
        "tokens": [
          50876,
          492,
          8899,
          36606,
          13,
          50926
        ]
      },
      {
        "avg_logprob": -0.1902015944172565,
        "compression_ratio": 1.7118055555555556,
        "end": 1632.7,
        "id": 241,
        "no_speech_prob": 0.004829613491892815,
        "seek": 162006,
        "start": 1631.3,
        "temperature": 0,
        "text": " We have our basic setup.",
        "tokens": [
          50926,
          492,
          362,
          527,
          3875,
          8657,
          13,
          50996
        ]
      },
      {
        "avg_logprob": -0.1902015944172565,
        "compression_ratio": 1.7118055555555556,
        "end": 1637.78,
        "id": 242,
        "no_speech_prob": 0.004829613491892815,
        "seek": 162006,
        "start": 1632.7,
        "temperature": 0,
        "text": " Now I'm going to add a listener for when a get request comes in on the slash route.",
        "tokens": [
          50996,
          823,
          286,
          478,
          516,
          281,
          909,
          257,
          31569,
          337,
          562,
          257,
          483,
          5308,
          1487,
          294,
          322,
          264,
          17330,
          7955,
          13,
          51250
        ]
      },
      {
        "avg_logprob": -0.1902015944172565,
        "compression_ratio": 1.7118055555555556,
        "end": 1642.3,
        "id": 243,
        "no_speech_prob": 0.004829613491892815,
        "seek": 162006,
        "start": 1637.78,
        "temperature": 0,
        "text": " So as I mentioned earlier, when you just put something in your browser and hit Enter, that",
        "tokens": [
          51250,
          407,
          382,
          286,
          2835,
          3071,
          11,
          562,
          291,
          445,
          829,
          746,
          294,
          428,
          11185,
          293,
          2045,
          10399,
          11,
          300,
          51476
        ]
      },
      {
        "avg_logprob": -0.1902015944172565,
        "compression_ratio": 1.7118055555555556,
        "end": 1643.8799999999999,
        "id": 244,
        "no_speech_prob": 0.004829613491892815,
        "seek": 162006,
        "start": 1642.3,
        "temperature": 0,
        "text": " is a get request.",
        "tokens": [
          51476,
          307,
          257,
          483,
          5308,
          13,
          51555
        ]
      },
      {
        "avg_logprob": -0.1902015944172565,
        "compression_ratio": 1.7118055555555556,
        "end": 1648.1799999999998,
        "id": 245,
        "no_speech_prob": 0.004829613491892815,
        "seek": 162006,
        "start": 1643.8799999999999,
        "temperature": 0,
        "text": " And by default, it's making a get request to the slash route.",
        "tokens": [
          51555,
          400,
          538,
          7576,
          11,
          309,
          311,
          1455,
          257,
          483,
          5308,
          281,
          264,
          17330,
          7955,
          13,
          51770
        ]
      },
      {
        "avg_logprob": -0.22323442213606126,
        "compression_ratio": 1.6283185840707965,
        "end": 1651.98,
        "id": 246,
        "no_speech_prob": 0.00009314568160334602,
        "seek": 164818,
        "start": 1648.3,
        "temperature": 0,
        "text": " So what I'm going to do on my server is say, hey, server, when you get a get request on",
        "tokens": [
          50370,
          407,
          437,
          286,
          478,
          516,
          281,
          360,
          322,
          452,
          7154,
          307,
          584,
          11,
          4177,
          11,
          7154,
          11,
          562,
          291,
          483,
          257,
          483,
          5308,
          322,
          50554
        ]
      },
      {
        "avg_logprob": -0.22323442213606126,
        "compression_ratio": 1.6283185840707965,
        "end": 1655.74,
        "id": 247,
        "no_speech_prob": 0.00009314568160334602,
        "seek": 164818,
        "start": 1651.98,
        "temperature": 0,
        "text": " the slash route, run this function.",
        "tokens": [
          50554,
          264,
          17330,
          7955,
          11,
          1190,
          341,
          2445,
          13,
          50742
        ]
      },
      {
        "avg_logprob": -0.22323442213606126,
        "compression_ratio": 1.6283185840707965,
        "end": 1657.5,
        "id": 248,
        "no_speech_prob": 0.00009314568160334602,
        "seek": 164818,
        "start": 1655.74,
        "temperature": 0,
        "text": " And we have two variables in here.",
        "tokens": [
          50742,
          400,
          321,
          362,
          732,
          9102,
          294,
          510,
          13,
          50830
        ]
      },
      {
        "avg_logprob": -0.22323442213606126,
        "compression_ratio": 1.6283185840707965,
        "end": 1660.3,
        "id": 249,
        "no_speech_prob": 0.00009314568160334602,
        "seek": 164818,
        "start": 1657.5,
        "temperature": 0,
        "text": " Typically, they're abbreviated rec and res, which I like to do.",
        "tokens": [
          50830,
          23129,
          11,
          436,
          434,
          35839,
          770,
          850,
          293,
          725,
          11,
          597,
          286,
          411,
          281,
          360,
          13,
          50970
        ]
      },
      {
        "avg_logprob": -0.22323442213606126,
        "compression_ratio": 1.6283185840707965,
        "end": 1665.64,
        "id": 250,
        "no_speech_prob": 0.00009314568160334602,
        "seek": 164818,
        "start": 1660.3,
        "temperature": 0,
        "text": " But they really stand for request and response.",
        "tokens": [
          50970,
          583,
          436,
          534,
          1463,
          337,
          5308,
          293,
          4134,
          13,
          51237
        ]
      },
      {
        "avg_logprob": -0.22323442213606126,
        "compression_ratio": 1.6283185840707965,
        "end": 1668.6200000000001,
        "id": 251,
        "no_speech_prob": 0.00009314568160334602,
        "seek": 164818,
        "start": 1665.64,
        "temperature": 0,
        "text": " And these are two variables that exactly correspond to our diagram.",
        "tokens": [
          51237,
          400,
          613,
          366,
          732,
          9102,
          300,
          2293,
          6805,
          281,
          527,
          10686,
          13,
          51386
        ]
      },
      {
        "avg_logprob": -0.22323442213606126,
        "compression_ratio": 1.6283185840707965,
        "end": 1676.66,
        "id": 252,
        "no_speech_prob": 0.00009314568160334602,
        "seek": 164818,
        "start": 1668.6200000000001,
        "temperature": 0,
        "text": " So here, this is the request.",
        "tokens": [
          51386,
          407,
          510,
          11,
          341,
          307,
          264,
          5308,
          13,
          51788
        ]
      },
      {
        "avg_logprob": -0.23336108256194552,
        "compression_ratio": 1.8114754098360655,
        "end": 1678.8200000000002,
        "id": 253,
        "no_speech_prob": 0.0004305527836550027,
        "seek": 167666,
        "start": 1676.66,
        "temperature": 0,
        "text": " It's what the server is asking for.",
        "tokens": [
          50364,
          467,
          311,
          437,
          264,
          7154,
          307,
          3365,
          337,
          13,
          50472
        ]
      },
      {
        "avg_logprob": -0.23336108256194552,
        "compression_ratio": 1.8114754098360655,
        "end": 1685.98,
        "id": 254,
        "no_speech_prob": 0.0004305527836550027,
        "seek": 167666,
        "start": 1678.8200000000002,
        "temperature": 0,
        "text": " And then this arrow going from the back end to the front end, this is the response.",
        "tokens": [
          50472,
          400,
          550,
          341,
          11610,
          516,
          490,
          264,
          646,
          917,
          281,
          264,
          1868,
          917,
          11,
          341,
          307,
          264,
          4134,
          13,
          50830
        ]
      },
      {
        "avg_logprob": -0.23336108256194552,
        "compression_ratio": 1.8114754098360655,
        "end": 1688.42,
        "id": 255,
        "no_speech_prob": 0.0004305527836550027,
        "seek": 167666,
        "start": 1685.98,
        "temperature": 0,
        "text": " Now in this diagram, that's with our static file server.",
        "tokens": [
          50830,
          823,
          294,
          341,
          10686,
          11,
          300,
          311,
          365,
          527,
          13437,
          3991,
          7154,
          13,
          50952
        ]
      },
      {
        "avg_logprob": -0.23336108256194552,
        "compression_ratio": 1.8114754098360655,
        "end": 1691.42,
        "id": 256,
        "no_speech_prob": 0.0004305527836550027,
        "seek": 167666,
        "start": 1688.42,
        "temperature": 0,
        "text": " But the exact same thing is going to happen with our back end server.",
        "tokens": [
          50952,
          583,
          264,
          1900,
          912,
          551,
          307,
          516,
          281,
          1051,
          365,
          527,
          646,
          917,
          7154,
          13,
          51102
        ]
      },
      {
        "avg_logprob": -0.23336108256194552,
        "compression_ratio": 1.8114754098360655,
        "end": 1697.8600000000001,
        "id": 257,
        "no_speech_prob": 0.0004305527836550027,
        "seek": 167666,
        "start": 1691.42,
        "temperature": 0,
        "text": " So our client eventually will be making a get request to our dynamic server.",
        "tokens": [
          51102,
          407,
          527,
          6423,
          4728,
          486,
          312,
          1455,
          257,
          483,
          5308,
          281,
          527,
          8546,
          7154,
          13,
          51424
        ]
      },
      {
        "avg_logprob": -0.23336108256194552,
        "compression_ratio": 1.8114754098360655,
        "end": 1701.98,
        "id": 258,
        "no_speech_prob": 0.0004305527836550027,
        "seek": 167666,
        "start": 1697.8600000000001,
        "temperature": 0,
        "text": " It's going to say, I want to get all news.",
        "tokens": [
          51424,
          467,
          311,
          516,
          281,
          584,
          11,
          286,
          528,
          281,
          483,
          439,
          2583,
          13,
          51630
        ]
      },
      {
        "avg_logprob": -0.23336108256194552,
        "compression_ratio": 1.8114754098360655,
        "end": 1703.78,
        "id": 259,
        "no_speech_prob": 0.0004305527836550027,
        "seek": 167666,
        "start": 1701.98,
        "temperature": 0,
        "text": " And the dynamic server will do some processing.",
        "tokens": [
          51630,
          400,
          264,
          8546,
          7154,
          486,
          360,
          512,
          9007,
          13,
          51720
        ]
      },
      {
        "avg_logprob": -0.23336108256194552,
        "compression_ratio": 1.8114754098360655,
        "end": 1705.14,
        "id": 260,
        "no_speech_prob": 0.0004305527836550027,
        "seek": 167666,
        "start": 1703.78,
        "temperature": 0,
        "text": " It'll talk to the database.",
        "tokens": [
          51720,
          467,
          603,
          751,
          281,
          264,
          8149,
          13,
          51788
        ]
      },
      {
        "avg_logprob": -0.3008979879399782,
        "compression_ratio": 1.7033492822966507,
        "end": 1709.22,
        "id": 261,
        "no_speech_prob": 0.0012643999652937055,
        "seek": 170514,
        "start": 1705.14,
        "temperature": 0,
        "text": " And then ultimately, this thing will respond with a big JSON object.",
        "tokens": [
          50364,
          400,
          550,
          6284,
          11,
          341,
          551,
          486,
          4196,
          365,
          257,
          955,
          31828,
          2657,
          13,
          50568
        ]
      },
      {
        "avg_logprob": -0.3008979879399782,
        "compression_ratio": 1.7033492822966507,
        "end": 1710.22,
        "id": 262,
        "no_speech_prob": 0.0012643999652937055,
        "seek": 170514,
        "start": 1709.22,
        "temperature": 0,
        "text": " Actually, an array.",
        "tokens": [
          50568,
          5135,
          11,
          364,
          10225,
          13,
          50618
        ]
      },
      {
        "avg_logprob": -0.3008979879399782,
        "compression_ratio": 1.7033492822966507,
        "end": 1716.5400000000002,
        "id": 263,
        "no_speech_prob": 0.0012643999652937055,
        "seek": 170514,
        "start": 1710.22,
        "temperature": 0,
        "text": " It'll respond with an array of JSON objects.",
        "tokens": [
          50618,
          467,
          603,
          4196,
          365,
          364,
          10225,
          295,
          31828,
          6565,
          13,
          50934
        ]
      },
      {
        "avg_logprob": -0.3008979879399782,
        "compression_ratio": 1.7033492822966507,
        "end": 1718.18,
        "id": 264,
        "no_speech_prob": 0.0012643999652937055,
        "seek": 170514,
        "start": 1716.5400000000002,
        "temperature": 0,
        "text": " Various things inside of them.",
        "tokens": [
          50934,
          14662,
          851,
          721,
          1854,
          295,
          552,
          13,
          51016
        ]
      },
      {
        "avg_logprob": -0.3008979879399782,
        "compression_ratio": 1.7033492822966507,
        "end": 1725.42,
        "id": 265,
        "no_speech_prob": 0.0012643999652937055,
        "seek": 170514,
        "start": 1718.18,
        "temperature": 0,
        "text": " But specifically, the request that the client will make here is the request.",
        "tokens": [
          51016,
          583,
          4682,
          11,
          264,
          5308,
          300,
          264,
          6423,
          486,
          652,
          510,
          307,
          264,
          5308,
          13,
          51378
        ]
      },
      {
        "avg_logprob": -0.3008979879399782,
        "compression_ratio": 1.7033492822966507,
        "end": 1728.7800000000002,
        "id": 266,
        "no_speech_prob": 0.0012643999652937055,
        "seek": 170514,
        "start": 1725.42,
        "temperature": 0,
        "text": " And the response that the server gives here is the response.",
        "tokens": [
          51378,
          400,
          264,
          4134,
          300,
          264,
          7154,
          2709,
          510,
          307,
          264,
          4134,
          13,
          51546
        ]
      },
      {
        "avg_logprob": -0.3008979879399782,
        "compression_ratio": 1.7033492822966507,
        "end": 1731.26,
        "id": 267,
        "no_speech_prob": 0.0012643999652937055,
        "seek": 170514,
        "start": 1728.7800000000002,
        "temperature": 0,
        "text": " I guess I'm using the word in what I'm talking about.",
        "tokens": [
          51546,
          286,
          2041,
          286,
          478,
          1228,
          264,
          1349,
          294,
          437,
          286,
          478,
          1417,
          466,
          13,
          51670
        ]
      },
      {
        "avg_logprob": -0.25728572498668323,
        "compression_ratio": 1.6703296703296704,
        "end": 1735.62,
        "id": 268,
        "no_speech_prob": 0.2281382530927658,
        "seek": 173126,
        "start": 1732.26,
        "temperature": 0,
        "text": " Inside of Express, those two variables mean exactly that.",
        "tokens": [
          50414,
          15123,
          295,
          20212,
          11,
          729,
          732,
          9102,
          914,
          2293,
          300,
          13,
          50582
        ]
      },
      {
        "avg_logprob": -0.25728572498668323,
        "compression_ratio": 1.6703296703296704,
        "end": 1736.34,
        "id": 269,
        "no_speech_prob": 0.2281382530927658,
        "seek": 173126,
        "start": 1735.62,
        "temperature": 0,
        "text": " Yes, go for it.",
        "tokens": [
          50582,
          1079,
          11,
          352,
          337,
          309,
          13,
          50618
        ]
      },
      {
        "avg_logprob": -0.25728572498668323,
        "compression_ratio": 1.6703296703296704,
        "end": 1737.78,
        "id": 270,
        "no_speech_prob": 0.2281382530927658,
        "seek": 173126,
        "start": 1736.34,
        "temperature": 0,
        "text": " I have a question.",
        "tokens": [
          50618,
          286,
          362,
          257,
          1168,
          13,
          50690
        ]
      },
      {
        "avg_logprob": -0.25728572498668323,
        "compression_ratio": 1.6703296703296704,
        "end": 1741.34,
        "id": 271,
        "no_speech_prob": 0.2281382530927658,
        "seek": 173126,
        "start": 1737.78,
        "temperature": 0,
        "text": " So I'm curious as to why, or if it matters,",
        "tokens": [
          50690,
          407,
          286,
          478,
          6369,
          382,
          281,
          983,
          11,
          420,
          498,
          309,
          7001,
          11,
          50868
        ]
      },
      {
        "avg_logprob": -0.25728572498668323,
        "compression_ratio": 1.6703296703296704,
        "end": 1744.18,
        "id": 272,
        "no_speech_prob": 0.2281382530927658,
        "seek": 173126,
        "start": 1741.34,
        "temperature": 0,
        "text": " you're still using the live server for the static files.",
        "tokens": [
          50868,
          291,
          434,
          920,
          1228,
          264,
          1621,
          7154,
          337,
          264,
          13437,
          7098,
          13,
          51010
        ]
      },
      {
        "avg_logprob": -0.25728572498668323,
        "compression_ratio": 1.6703296703296704,
        "end": 1747.94,
        "id": 273,
        "no_speech_prob": 0.2281382530927658,
        "seek": 173126,
        "start": 1744.18,
        "temperature": 0,
        "text": " Is the idea that you would eventually move the static files also?",
        "tokens": [
          51010,
          1119,
          264,
          1558,
          300,
          291,
          576,
          4728,
          1286,
          264,
          13437,
          7098,
          611,
          30,
          51198
        ]
      },
      {
        "avg_logprob": -0.25728572498668323,
        "compression_ratio": 1.6703296703296704,
        "end": 1751.7,
        "id": 274,
        "no_speech_prob": 0.2281382530927658,
        "seek": 173126,
        "start": 1747.94,
        "temperature": 0,
        "text": " Why not have the dynamic server also host those static files?",
        "tokens": [
          51198,
          1545,
          406,
          362,
          264,
          8546,
          7154,
          611,
          3975,
          729,
          13437,
          7098,
          30,
          51386
        ]
      },
      {
        "avg_logprob": -0.25728572498668323,
        "compression_ratio": 1.6703296703296704,
        "end": 1754.1,
        "id": 275,
        "no_speech_prob": 0.2281382530927658,
        "seek": 173126,
        "start": 1751.7,
        "temperature": 0,
        "text": " Yes, so there are a lot of ways to do it.",
        "tokens": [
          51386,
          1079,
          11,
          370,
          456,
          366,
          257,
          688,
          295,
          2098,
          281,
          360,
          309,
          13,
          51506
        ]
      },
      {
        "avg_logprob": -0.25728572498668323,
        "compression_ratio": 1.6703296703296704,
        "end": 1754.9,
        "id": 276,
        "no_speech_prob": 0.2281382530927658,
        "seek": 173126,
        "start": 1754.1,
        "temperature": 0,
        "text": " You could do that.",
        "tokens": [
          51506,
          509,
          727,
          360,
          300,
          13,
          51546
        ]
      },
      {
        "avg_logprob": -0.25728572498668323,
        "compression_ratio": 1.6703296703296704,
        "end": 1757.9,
        "id": 277,
        "no_speech_prob": 0.2281382530927658,
        "seek": 173126,
        "start": 1754.9,
        "temperature": 0,
        "text": " But I am actually, at the end, I'll show how we put this on the internet.",
        "tokens": [
          51546,
          583,
          286,
          669,
          767,
          11,
          412,
          264,
          917,
          11,
          286,
          603,
          855,
          577,
          321,
          829,
          341,
          322,
          264,
          4705,
          13,
          51696
        ]
      },
      {
        "avg_logprob": -0.2690169369732892,
        "compression_ratio": 1.630952380952381,
        "end": 1761.3000000000002,
        "id": 278,
        "no_speech_prob": 0.0018672688165679574,
        "seek": 175790,
        "start": 1757.94,
        "temperature": 0,
        "text": " And the idea with keeping these on a separate server",
        "tokens": [
          50366,
          400,
          264,
          1558,
          365,
          5145,
          613,
          322,
          257,
          4994,
          7154,
          50534
        ]
      },
      {
        "avg_logprob": -0.2690169369732892,
        "compression_ratio": 1.630952380952381,
        "end": 1766.46,
        "id": 279,
        "no_speech_prob": 0.0018672688165679574,
        "seek": 175790,
        "start": 1761.3000000000002,
        "temperature": 0,
        "text": " is that we can benefit from things like a CDN, like Content Delivery Network.",
        "tokens": [
          50534,
          307,
          300,
          321,
          393,
          5121,
          490,
          721,
          411,
          257,
          6743,
          45,
          11,
          411,
          30078,
          5831,
          8549,
          12640,
          13,
          50792
        ]
      },
      {
        "avg_logprob": -0.2690169369732892,
        "compression_ratio": 1.630952380952381,
        "end": 1770.5400000000002,
        "id": 280,
        "no_speech_prob": 0.0018672688165679574,
        "seek": 175790,
        "start": 1766.46,
        "temperature": 0,
        "text": " And so let's say you get thousands of users to your website.",
        "tokens": [
          50792,
          400,
          370,
          718,
          311,
          584,
          291,
          483,
          5383,
          295,
          5022,
          281,
          428,
          3144,
          13,
          50996
        ]
      },
      {
        "avg_logprob": -0.2690169369732892,
        "compression_ratio": 1.630952380952381,
        "end": 1774.02,
        "id": 281,
        "no_speech_prob": 0.0018672688165679574,
        "seek": 175790,
        "start": 1770.5400000000002,
        "temperature": 0,
        "text": " They're all going to be requesting the home page from this CDN, which",
        "tokens": [
          50996,
          814,
          434,
          439,
          516,
          281,
          312,
          31937,
          264,
          1280,
          3028,
          490,
          341,
          6743,
          45,
          11,
          597,
          51170
        ]
      },
      {
        "avg_logprob": -0.2690169369732892,
        "compression_ratio": 1.630952380952381,
        "end": 1777.02,
        "id": 282,
        "no_speech_prob": 0.0018672688165679574,
        "seek": 175790,
        "start": 1774.02,
        "temperature": 0,
        "text": " has it cached on thousands of servers all over the world.",
        "tokens": [
          51170,
          575,
          309,
          269,
          15095,
          322,
          5383,
          295,
          15909,
          439,
          670,
          264,
          1002,
          13,
          51320
        ]
      },
      {
        "avg_logprob": -0.2690169369732892,
        "compression_ratio": 1.630952380952381,
        "end": 1780.22,
        "id": 283,
        "no_speech_prob": 0.0018672688165679574,
        "seek": 175790,
        "start": 1777.02,
        "temperature": 0,
        "text": " And so the initial web page will load really well.",
        "tokens": [
          51320,
          400,
          370,
          264,
          5883,
          3670,
          3028,
          486,
          3677,
          534,
          731,
          13,
          51480
        ]
      },
      {
        "avg_logprob": -0.2690169369732892,
        "compression_ratio": 1.630952380952381,
        "end": 1782.6200000000001,
        "id": 284,
        "no_speech_prob": 0.0018672688165679574,
        "seek": 175790,
        "start": 1780.22,
        "temperature": 0,
        "text": " It's good timing that it turned off now.",
        "tokens": [
          51480,
          467,
          311,
          665,
          10822,
          300,
          309,
          3574,
          766,
          586,
          13,
          51600
        ]
      },
      {
        "avg_logprob": -0.31890121964383716,
        "compression_ratio": 1.6746987951807228,
        "end": 1787.8999999999999,
        "id": 285,
        "no_speech_prob": 0.00011060810356866568,
        "seek": 178262,
        "start": 1782.62,
        "temperature": 0,
        "text": " And so by having it on a separate server,",
        "tokens": [
          50364,
          400,
          370,
          538,
          1419,
          309,
          322,
          257,
          4994,
          7154,
          11,
          50628
        ]
      },
      {
        "avg_logprob": -0.31890121964383716,
        "compression_ratio": 1.6746987951807228,
        "end": 1793.06,
        "id": 286,
        "no_speech_prob": 0.00011060810356866568,
        "seek": 178262,
        "start": 1787.8999999999999,
        "temperature": 0,
        "text": " it makes the incoming requests go to different servers.",
        "tokens": [
          50628,
          309,
          1669,
          264,
          22341,
          12475,
          352,
          281,
          819,
          15909,
          13,
          50886
        ]
      },
      {
        "avg_logprob": -0.31890121964383716,
        "compression_ratio": 1.6746987951807228,
        "end": 1795.7399999999998,
        "id": 287,
        "no_speech_prob": 0.00011060810356866568,
        "seek": 178262,
        "start": 1793.06,
        "temperature": 0,
        "text": " So the request for actual data will be to this server.",
        "tokens": [
          50886,
          407,
          264,
          5308,
          337,
          3539,
          1412,
          486,
          312,
          281,
          341,
          7154,
          13,
          51020
        ]
      },
      {
        "avg_logprob": -0.31890121964383716,
        "compression_ratio": 1.6746987951807228,
        "end": 1797.86,
        "id": 288,
        "no_speech_prob": 0.00011060810356866568,
        "seek": 178262,
        "start": 1795.7399999999998,
        "temperature": 0,
        "text": " But when people are loading the page, it'll load there.",
        "tokens": [
          51020,
          583,
          562,
          561,
          366,
          15114,
          264,
          3028,
          11,
          309,
          603,
          3677,
          456,
          13,
          51126
        ]
      },
      {
        "avg_logprob": -0.31890121964383716,
        "compression_ratio": 1.6746987951807228,
        "end": 1799.26,
        "id": 289,
        "no_speech_prob": 0.00011060810356866568,
        "seek": 178262,
        "start": 1797.86,
        "temperature": 0,
        "text": " And I will show how to put it on two different servers.",
        "tokens": [
          51126,
          400,
          286,
          486,
          855,
          577,
          281,
          829,
          309,
          322,
          732,
          819,
          15909,
          13,
          51196
        ]
      },
      {
        "avg_logprob": -0.31890121964383716,
        "compression_ratio": 1.6746987951807228,
        "end": 1800.4199999999998,
        "id": 290,
        "no_speech_prob": 0.00011060810356866568,
        "seek": 178262,
        "start": 1799.26,
        "temperature": 0,
        "text": " No, it totally makes sense.",
        "tokens": [
          51196,
          883,
          11,
          309,
          3879,
          1669,
          2020,
          13,
          51254
        ]
      },
      {
        "avg_logprob": -0.31890121964383716,
        "compression_ratio": 1.6746987951807228,
        "end": 1804.3,
        "id": 291,
        "no_speech_prob": 0.00011060810356866568,
        "seek": 178262,
        "start": 1800.4199999999998,
        "temperature": 0,
        "text": " Let me flip this camera back.",
        "tokens": [
          51254,
          961,
          385,
          7929,
          341,
          2799,
          646,
          13,
          51448
        ]
      },
      {
        "avg_logprob": -0.31890121964383716,
        "compression_ratio": 1.6746987951807228,
        "end": 1805.4599999999998,
        "id": 292,
        "no_speech_prob": 0.00011060810356866568,
        "seek": 178262,
        "start": 1804.3,
        "temperature": 0,
        "text": " It'll be so seamless.",
        "tokens": [
          51448,
          467,
          603,
          312,
          370,
          28677,
          13,
          51506
        ]
      },
      {
        "avg_logprob": -0.31890121964383716,
        "compression_ratio": 1.6746987951807228,
        "end": 1808.3,
        "id": 293,
        "no_speech_prob": 0.00011060810356866568,
        "seek": 178262,
        "start": 1805.4599999999998,
        "temperature": 0,
        "text": " No one will even know.",
        "tokens": [
          51506,
          883,
          472,
          486,
          754,
          458,
          13,
          51648
        ]
      },
      {
        "avg_logprob": -0.31890121964383716,
        "compression_ratio": 1.6746987951807228,
        "end": 1809.5,
        "id": 294,
        "no_speech_prob": 0.00011060810356866568,
        "seek": 178262,
        "start": 1808.3,
        "temperature": 0,
        "text": " Were there other questions?",
        "tokens": [
          51648,
          12448,
          456,
          661,
          1651,
          30,
          51708
        ]
      },
      {
        "avg_logprob": -0.31890121964383716,
        "compression_ratio": 1.6746987951807228,
        "end": 1811.58,
        "id": 295,
        "no_speech_prob": 0.00011060810356866568,
        "seek": 178262,
        "start": 1809.5,
        "temperature": 0,
        "text": " No, I don't think so.",
        "tokens": [
          51708,
          883,
          11,
          286,
          500,
          380,
          519,
          370,
          13,
          51812
        ]
      },
      {
        "avg_logprob": -0.2573734252683578,
        "compression_ratio": 1.6254980079681276,
        "end": 1812.8999999999999,
        "id": 296,
        "no_speech_prob": 0.00029595071100629866,
        "seek": 181158,
        "start": 1811.58,
        "temperature": 0,
        "text": " OK, let's do it.",
        "tokens": [
          50364,
          2264,
          11,
          718,
          311,
          360,
          309,
          13,
          50430
        ]
      },
      {
        "avg_logprob": -0.2573734252683578,
        "compression_ratio": 1.6254980079681276,
        "end": 1815.8999999999999,
        "id": 297,
        "no_speech_prob": 0.00029595071100629866,
        "seek": 181158,
        "start": 1812.8999999999999,
        "temperature": 0,
        "text": " So as I was mentioning, these two variables",
        "tokens": [
          50430,
          407,
          382,
          286,
          390,
          18315,
          11,
          613,
          732,
          9102,
          50580
        ]
      },
      {
        "avg_logprob": -0.2573734252683578,
        "compression_ratio": 1.6254980079681276,
        "end": 1818.6599999999999,
        "id": 298,
        "no_speech_prob": 0.00029595071100629866,
        "seek": 181158,
        "start": 1815.8999999999999,
        "temperature": 0,
        "text": " represent that incoming request and the outgoing response.",
        "tokens": [
          50580,
          2906,
          300,
          22341,
          5308,
          293,
          264,
          41565,
          4134,
          13,
          50718
        ]
      },
      {
        "avg_logprob": -0.2573734252683578,
        "compression_ratio": 1.6254980079681276,
        "end": 1822.74,
        "id": 299,
        "no_speech_prob": 0.00029595071100629866,
        "seek": 181158,
        "start": 1818.6599999999999,
        "temperature": 0,
        "text": " So I'm going to rename these to rec and res.",
        "tokens": [
          50718,
          407,
          286,
          478,
          516,
          281,
          36741,
          613,
          281,
          850,
          293,
          725,
          13,
          50922
        ]
      },
      {
        "avg_logprob": -0.2573734252683578,
        "compression_ratio": 1.6254980079681276,
        "end": 1824.1399999999999,
        "id": 300,
        "no_speech_prob": 0.00029595071100629866,
        "seek": 181158,
        "start": 1822.74,
        "temperature": 0,
        "text": " And here's what we say.",
        "tokens": [
          50922,
          400,
          510,
          311,
          437,
          321,
          584,
          13,
          50992
        ]
      },
      {
        "avg_logprob": -0.2573734252683578,
        "compression_ratio": 1.6254980079681276,
        "end": 1828.3799999999999,
        "id": 301,
        "no_speech_prob": 0.00029595071100629866,
        "seek": 181158,
        "start": 1824.1399999999999,
        "temperature": 0,
        "text": " So when the client makes a get request on the slash route,",
        "tokens": [
          50992,
          407,
          562,
          264,
          6423,
          1669,
          257,
          483,
          5308,
          322,
          264,
          17330,
          7955,
          11,
          51204
        ]
      },
      {
        "avg_logprob": -0.2573734252683578,
        "compression_ratio": 1.6254980079681276,
        "end": 1830.54,
        "id": 302,
        "no_speech_prob": 0.00029595071100629866,
        "seek": 181158,
        "start": 1828.3799999999999,
        "temperature": 0,
        "text": " we want to respond with some JSON.",
        "tokens": [
          51204,
          321,
          528,
          281,
          4196,
          365,
          512,
          31828,
          13,
          51312
        ]
      },
      {
        "avg_logprob": -0.2573734252683578,
        "compression_ratio": 1.6254980079681276,
        "end": 1832.62,
        "id": 303,
        "no_speech_prob": 0.00029595071100629866,
        "seek": 181158,
        "start": 1830.54,
        "temperature": 0,
        "text": " In this case, I'm just going to pass in a message.",
        "tokens": [
          51312,
          682,
          341,
          1389,
          11,
          286,
          478,
          445,
          516,
          281,
          1320,
          294,
          257,
          3636,
          13,
          51416
        ]
      },
      {
        "avg_logprob": -0.2573734252683578,
        "compression_ratio": 1.6254980079681276,
        "end": 1836.9399999999998,
        "id": 304,
        "no_speech_prob": 0.00029595071100629866,
        "seek": 181158,
        "start": 1832.62,
        "temperature": 0,
        "text": " And it says, meow.",
        "tokens": [
          51416,
          400,
          309,
          1619,
          11,
          45132,
          13,
          51632
        ]
      },
      {
        "avg_logprob": -0.2573734252683578,
        "compression_ratio": 1.6254980079681276,
        "end": 1840.46,
        "id": 305,
        "no_speech_prob": 0.00029595071100629866,
        "seek": 181158,
        "start": 1836.9399999999998,
        "temperature": 0,
        "text": " And we'll throw in an emoji, like a laughing cat.",
        "tokens": [
          51632,
          400,
          321,
          603,
          3507,
          294,
          364,
          31595,
          11,
          411,
          257,
          5059,
          3857,
          13,
          51808
        ]
      },
      {
        "avg_logprob": -0.2573734252683578,
        "compression_ratio": 1.6254980079681276,
        "end": 1840.96,
        "id": 306,
        "no_speech_prob": 0.00029595071100629866,
        "seek": 181158,
        "start": 1840.46,
        "temperature": 0,
        "text": " Cool.",
        "tokens": [
          51808,
          8561,
          13,
          51833
        ]
      },
      {
        "avg_logprob": -0.2679313860441509,
        "compression_ratio": 1.6806451612903226,
        "end": 1842.76,
        "id": 307,
        "no_speech_prob": 0.0005357721820473671,
        "seek": 184096,
        "start": 1840.96,
        "temperature": 0,
        "text": " So we now have our server set up.",
        "tokens": [
          50364,
          407,
          321,
          586,
          362,
          527,
          7154,
          992,
          493,
          13,
          50454
        ]
      },
      {
        "avg_logprob": -0.2679313860441509,
        "compression_ratio": 1.6806451612903226,
        "end": 1844.72,
        "id": 308,
        "no_speech_prob": 0.0005357721820473671,
        "seek": 184096,
        "start": 1842.76,
        "temperature": 0,
        "text": " When it receives a get request on slash,",
        "tokens": [
          50454,
          1133,
          309,
          20717,
          257,
          483,
          5308,
          322,
          17330,
          11,
          50552
        ]
      },
      {
        "avg_logprob": -0.2679313860441509,
        "compression_ratio": 1.6806451612903226,
        "end": 1846.44,
        "id": 309,
        "no_speech_prob": 0.0005357721820473671,
        "seek": 184096,
        "start": 1844.72,
        "temperature": 0,
        "text": " respond with a JSON object.",
        "tokens": [
          50552,
          4196,
          365,
          257,
          31828,
          2657,
          13,
          50638
        ]
      },
      {
        "avg_logprob": -0.2679313860441509,
        "compression_ratio": 1.6806451612903226,
        "end": 1847.16,
        "id": 310,
        "no_speech_prob": 0.0005357721820473671,
        "seek": 184096,
        "start": 1846.44,
        "temperature": 0,
        "text": " Let's try it.",
        "tokens": [
          50638,
          961,
          311,
          853,
          309,
          13,
          50674
        ]
      },
      {
        "avg_logprob": -0.2679313860441509,
        "compression_ratio": 1.6806451612903226,
        "end": 1848.16,
        "id": 311,
        "no_speech_prob": 0.0005357721820473671,
        "seek": 184096,
        "start": 1847.16,
        "temperature": 0,
        "text": " So we go to the browser.",
        "tokens": [
          50674,
          407,
          321,
          352,
          281,
          264,
          11185,
          13,
          50724
        ]
      },
      {
        "avg_logprob": -0.2679313860441509,
        "compression_ratio": 1.6806451612903226,
        "end": 1851.88,
        "id": 312,
        "no_speech_prob": 0.0005357721820473671,
        "seek": 184096,
        "start": 1848.16,
        "temperature": 0,
        "text": " We now request the data from our server, which is on port 5000.",
        "tokens": [
          50724,
          492,
          586,
          5308,
          264,
          1412,
          490,
          527,
          7154,
          11,
          597,
          307,
          322,
          2436,
          23777,
          13,
          50910
        ]
      },
      {
        "avg_logprob": -0.2679313860441509,
        "compression_ratio": 1.6806451612903226,
        "end": 1852.6000000000001,
        "id": 313,
        "no_speech_prob": 0.0005357721820473671,
        "seek": 184096,
        "start": 1851.88,
        "temperature": 0,
        "text": " Nothing happens.",
        "tokens": [
          50910,
          6693,
          2314,
          13,
          50946
        ]
      },
      {
        "avg_logprob": -0.2679313860441509,
        "compression_ratio": 1.6806451612903226,
        "end": 1855.4,
        "id": 314,
        "no_speech_prob": 0.0005357721820473671,
        "seek": 184096,
        "start": 1852.6000000000001,
        "temperature": 0,
        "text": " So when you're working with Node.js,",
        "tokens": [
          50946,
          407,
          562,
          291,
          434,
          1364,
          365,
          38640,
          13,
          25530,
          11,
          51086
        ]
      },
      {
        "avg_logprob": -0.2679313860441509,
        "compression_ratio": 1.6806451612903226,
        "end": 1856.88,
        "id": 315,
        "no_speech_prob": 0.0005357721820473671,
        "seek": 184096,
        "start": 1855.4,
        "temperature": 0,
        "text": " if you ever modify the files, you",
        "tokens": [
          51086,
          498,
          291,
          1562,
          16927,
          264,
          7098,
          11,
          291,
          51160
        ]
      },
      {
        "avg_logprob": -0.2679313860441509,
        "compression_ratio": 1.6806451612903226,
        "end": 1860,
        "id": 316,
        "no_speech_prob": 0.0005357721820473671,
        "seek": 184096,
        "start": 1856.88,
        "temperature": 0,
        "text": " have to actually kill the server and then restart it.",
        "tokens": [
          51160,
          362,
          281,
          767,
          1961,
          264,
          7154,
          293,
          550,
          21022,
          309,
          13,
          51316
        ]
      },
      {
        "avg_logprob": -0.2679313860441509,
        "compression_ratio": 1.6806451612903226,
        "end": 1861.16,
        "id": 317,
        "no_speech_prob": 0.0005357721820473671,
        "seek": 184096,
        "start": 1860,
        "temperature": 0,
        "text": " And then it should work.",
        "tokens": [
          51316,
          400,
          550,
          309,
          820,
          589,
          13,
          51374
        ]
      },
      {
        "avg_logprob": -0.2679313860441509,
        "compression_ratio": 1.6806451612903226,
        "end": 1863.8,
        "id": 318,
        "no_speech_prob": 0.0005357721820473671,
        "seek": 184096,
        "start": 1861.16,
        "temperature": 0,
        "text": " So we make the request, and we get the data back.",
        "tokens": [
          51374,
          407,
          321,
          652,
          264,
          5308,
          11,
          293,
          321,
          483,
          264,
          1412,
          646,
          13,
          51506
        ]
      },
      {
        "avg_logprob": -0.2679313860441509,
        "compression_ratio": 1.6806451612903226,
        "end": 1865.46,
        "id": 319,
        "no_speech_prob": 0.0005357721820473671,
        "seek": 184096,
        "start": 1863.8,
        "temperature": 0,
        "text": " But while I'm thinking about it, there's",
        "tokens": [
          51506,
          583,
          1339,
          286,
          478,
          1953,
          466,
          309,
          11,
          456,
          311,
          51589
        ]
      },
      {
        "avg_logprob": -0.2679313860441509,
        "compression_ratio": 1.6806451612903226,
        "end": 1869.8,
        "id": 320,
        "no_speech_prob": 0.0005357721820473671,
        "seek": 184096,
        "start": 1865.46,
        "temperature": 0,
        "text": " this handy tool called Node Mom, which will automatically",
        "tokens": [
          51589,
          341,
          13239,
          2290,
          1219,
          38640,
          5576,
          11,
          597,
          486,
          6772,
          51806
        ]
      },
      {
        "avg_logprob": -0.22617002868652344,
        "compression_ratio": 1.7838983050847457,
        "end": 1872.76,
        "id": 321,
        "no_speech_prob": 0.0001881410280475393,
        "seek": 186980,
        "start": 1869.8,
        "temperature": 0,
        "text": " refresh every time I change the server.",
        "tokens": [
          50364,
          15134,
          633,
          565,
          286,
          1319,
          264,
          7154,
          13,
          50512
        ]
      },
      {
        "avg_logprob": -0.22617002868652344,
        "compression_ratio": 1.7838983050847457,
        "end": 1874.32,
        "id": 322,
        "no_speech_prob": 0.0001881410280475393,
        "seek": 186980,
        "start": 1872.76,
        "temperature": 0,
        "text": " And I'll install that.",
        "tokens": [
          50512,
          400,
          286,
          603,
          3625,
          300,
          13,
          50590
        ]
      },
      {
        "avg_logprob": -0.22617002868652344,
        "compression_ratio": 1.7838983050847457,
        "end": 1875.96,
        "id": 323,
        "no_speech_prob": 0.0001881410280475393,
        "seek": 186980,
        "start": 1874.32,
        "temperature": 0,
        "text": " And basically, I'll run it.",
        "tokens": [
          50590,
          400,
          1936,
          11,
          286,
          603,
          1190,
          309,
          13,
          50672
        ]
      },
      {
        "avg_logprob": -0.22617002868652344,
        "compression_ratio": 1.7838983050847457,
        "end": 1878.1599999999999,
        "id": 324,
        "no_speech_prob": 0.0001881410280475393,
        "seek": 186980,
        "start": 1875.96,
        "temperature": 0,
        "text": " And any time I change files on the server,",
        "tokens": [
          50672,
          400,
          604,
          565,
          286,
          1319,
          7098,
          322,
          264,
          7154,
          11,
          50782
        ]
      },
      {
        "avg_logprob": -0.22617002868652344,
        "compression_ratio": 1.7838983050847457,
        "end": 1879.32,
        "id": 325,
        "no_speech_prob": 0.0001881410280475393,
        "seek": 186980,
        "start": 1878.1599999999999,
        "temperature": 0,
        "text": " it'll automatically restart.",
        "tokens": [
          50782,
          309,
          603,
          6772,
          21022,
          13,
          50840
        ]
      },
      {
        "avg_logprob": -0.22617002868652344,
        "compression_ratio": 1.7838983050847457,
        "end": 1882.96,
        "id": 326,
        "no_speech_prob": 0.0001881410280475393,
        "seek": 186980,
        "start": 1879.32,
        "temperature": 0,
        "text": " And we should see those changes when we make a request to it.",
        "tokens": [
          50840,
          400,
          321,
          820,
          536,
          729,
          2962,
          562,
          321,
          652,
          257,
          5308,
          281,
          309,
          13,
          51022
        ]
      },
      {
        "avg_logprob": -0.22617002868652344,
        "compression_ratio": 1.7838983050847457,
        "end": 1884.9199999999998,
        "id": 327,
        "no_speech_prob": 0.0001881410280475393,
        "seek": 186980,
        "start": 1882.96,
        "temperature": 0,
        "text": " So Node Mom is installed.",
        "tokens": [
          51022,
          407,
          38640,
          5576,
          307,
          8899,
          13,
          51120
        ]
      },
      {
        "avg_logprob": -0.22617002868652344,
        "compression_ratio": 1.7838983050847457,
        "end": 1887.24,
        "id": 328,
        "no_speech_prob": 0.0001881410280475393,
        "seek": 186980,
        "start": 1884.9199999999998,
        "temperature": 0,
        "text": " I'm going to add a new script in my package JSON.",
        "tokens": [
          51120,
          286,
          478,
          516,
          281,
          909,
          257,
          777,
          5755,
          294,
          452,
          7372,
          31828,
          13,
          51236
        ]
      },
      {
        "avg_logprob": -0.22617002868652344,
        "compression_ratio": 1.7838983050847457,
        "end": 1891.12,
        "id": 329,
        "no_speech_prob": 0.0001881410280475393,
        "seek": 186980,
        "start": 1887.24,
        "temperature": 0,
        "text": " So I'm going to create a dev script, Node Mom.",
        "tokens": [
          51236,
          407,
          286,
          478,
          516,
          281,
          1884,
          257,
          1905,
          5755,
          11,
          38640,
          5576,
          13,
          51430
        ]
      },
      {
        "avg_logprob": -0.22617002868652344,
        "compression_ratio": 1.7838983050847457,
        "end": 1894.76,
        "id": 330,
        "no_speech_prob": 0.0001881410280475393,
        "seek": 186980,
        "start": 1891.12,
        "temperature": 0,
        "text": " And we just do the same thing.",
        "tokens": [
          51430,
          400,
          321,
          445,
          360,
          264,
          912,
          551,
          13,
          51612
        ]
      },
      {
        "avg_logprob": -0.22617002868652344,
        "compression_ratio": 1.7838983050847457,
        "end": 1897.24,
        "id": 331,
        "no_speech_prob": 0.0001881410280475393,
        "seek": 186980,
        "start": 1894.76,
        "temperature": 0,
        "text": " So tell Node Mom to run against that file.",
        "tokens": [
          51612,
          407,
          980,
          38640,
          5576,
          281,
          1190,
          1970,
          300,
          3991,
          13,
          51736
        ]
      },
      {
        "avg_logprob": -0.23940457088846556,
        "compression_ratio": 1.637630662020906,
        "end": 1900.68,
        "id": 332,
        "no_speech_prob": 0.00003591285349102691,
        "seek": 189724,
        "start": 1897.24,
        "temperature": 0,
        "text": " And now if I do npm run dev, that starts up Node Mom.",
        "tokens": [
          50364,
          400,
          586,
          498,
          286,
          360,
          297,
          14395,
          1190,
          1905,
          11,
          300,
          3719,
          493,
          38640,
          5576,
          13,
          50536
        ]
      },
      {
        "avg_logprob": -0.23940457088846556,
        "compression_ratio": 1.637630662020906,
        "end": 1903.4,
        "id": 333,
        "no_speech_prob": 0.00003591285349102691,
        "seek": 189724,
        "start": 1900.68,
        "temperature": 0,
        "text": " And any time I make changes, it should restart the server.",
        "tokens": [
          50536,
          400,
          604,
          565,
          286,
          652,
          2962,
          11,
          309,
          820,
          21022,
          264,
          7154,
          13,
          50672
        ]
      },
      {
        "avg_logprob": -0.23940457088846556,
        "compression_ratio": 1.637630662020906,
        "end": 1905.16,
        "id": 334,
        "no_speech_prob": 0.00003591285349102691,
        "seek": 189724,
        "start": 1903.4,
        "temperature": 0,
        "text": " So this loads.",
        "tokens": [
          50672,
          407,
          341,
          12668,
          13,
          50760
        ]
      },
      {
        "avg_logprob": -0.23940457088846556,
        "compression_ratio": 1.637630662020906,
        "end": 1907.44,
        "id": 335,
        "no_speech_prob": 0.00003591285349102691,
        "seek": 189724,
        "start": 1905.16,
        "temperature": 0,
        "text": " But if I go back to my server code",
        "tokens": [
          50760,
          583,
          498,
          286,
          352,
          646,
          281,
          452,
          7154,
          3089,
          50874
        ]
      },
      {
        "avg_logprob": -0.23940457088846556,
        "compression_ratio": 1.637630662020906,
        "end": 1913.84,
        "id": 336,
        "no_speech_prob": 0.00003591285349102691,
        "seek": 189724,
        "start": 1907.44,
        "temperature": 0,
        "text": " and add a new emoji, like the regular cat,",
        "tokens": [
          50874,
          293,
          909,
          257,
          777,
          31595,
          11,
          411,
          264,
          3890,
          3857,
          11,
          51194
        ]
      },
      {
        "avg_logprob": -0.23940457088846556,
        "compression_ratio": 1.637630662020906,
        "end": 1915.64,
        "id": 337,
        "no_speech_prob": 0.00003591285349102691,
        "seek": 189724,
        "start": 1913.84,
        "temperature": 0,
        "text": " and I, again, make the request.",
        "tokens": [
          51194,
          293,
          286,
          11,
          797,
          11,
          652,
          264,
          5308,
          13,
          51284
        ]
      },
      {
        "avg_logprob": -0.23940457088846556,
        "compression_ratio": 1.637630662020906,
        "end": 1918.36,
        "id": 338,
        "no_speech_prob": 0.00003591285349102691,
        "seek": 189724,
        "start": 1915.64,
        "temperature": 0,
        "text": " And so you might not be seeing this, but I'm pressing Command-R.",
        "tokens": [
          51284,
          400,
          370,
          291,
          1062,
          406,
          312,
          2577,
          341,
          11,
          457,
          286,
          478,
          12417,
          17901,
          12,
          49,
          13,
          51420
        ]
      },
      {
        "avg_logprob": -0.23940457088846556,
        "compression_ratio": 1.637630662020906,
        "end": 1919.82,
        "id": 339,
        "no_speech_prob": 0.00003591285349102691,
        "seek": 189724,
        "start": 1918.36,
        "temperature": 0,
        "text": " So I'm refreshing the page, which",
        "tokens": [
          51420,
          407,
          286,
          478,
          19772,
          264,
          3028,
          11,
          597,
          51493
        ]
      },
      {
        "avg_logprob": -0.23940457088846556,
        "compression_ratio": 1.637630662020906,
        "end": 1922.48,
        "id": 340,
        "no_speech_prob": 0.00003591285349102691,
        "seek": 189724,
        "start": 1919.82,
        "temperature": 0,
        "text": " is making another get request to the server on slash.",
        "tokens": [
          51493,
          307,
          1455,
          1071,
          483,
          5308,
          281,
          264,
          7154,
          322,
          17330,
          13,
          51626
        ]
      },
      {
        "avg_logprob": -0.23940457088846556,
        "compression_ratio": 1.637630662020906,
        "end": 1924.52,
        "id": 341,
        "no_speech_prob": 0.00003591285349102691,
        "seek": 189724,
        "start": 1922.48,
        "temperature": 0,
        "text": " And then I see the latest result. Cool.",
        "tokens": [
          51626,
          400,
          550,
          286,
          536,
          264,
          6792,
          1874,
          13,
          8561,
          13,
          51728
        ]
      },
      {
        "avg_logprob": -0.23940457088846556,
        "compression_ratio": 1.637630662020906,
        "end": 1926.38,
        "id": 342,
        "no_speech_prob": 0.00003591285349102691,
        "seek": 189724,
        "start": 1924.52,
        "temperature": 0,
        "text": " So we have a basic server set up that's",
        "tokens": [
          51728,
          407,
          321,
          362,
          257,
          3875,
          7154,
          992,
          493,
          300,
          311,
          51821
        ]
      },
      {
        "avg_logprob": -0.3580144771859666,
        "compression_ratio": 1.5769230769230769,
        "end": 1929.2600000000002,
        "id": 343,
        "no_speech_prob": 0.00006401987775461748,
        "seek": 192638,
        "start": 1926.42,
        "temperature": 0,
        "text": " responding to incoming requests.",
        "tokens": [
          50366,
          16670,
          281,
          22341,
          12475,
          13,
          50508
        ]
      },
      {
        "avg_logprob": -0.3580144771859666,
        "compression_ratio": 1.5769230769230769,
        "end": 1932.5400000000002,
        "id": 344,
        "no_speech_prob": 0.00006401987775461748,
        "seek": 192638,
        "start": 1929.2600000000002,
        "temperature": 0,
        "text": " Before I move on to this next thing, any other lingering",
        "tokens": [
          50508,
          4546,
          286,
          1286,
          322,
          281,
          341,
          958,
          551,
          11,
          604,
          661,
          49542,
          50672
        ]
      },
      {
        "avg_logprob": -0.3580144771859666,
        "compression_ratio": 1.5769230769230769,
        "end": 1935.5,
        "id": 345,
        "no_speech_prob": 0.00006401987775461748,
        "seek": 192638,
        "start": 1932.5400000000002,
        "temperature": 0,
        "text": " questions?",
        "tokens": [
          50672,
          1651,
          30,
          50820
        ]
      },
      {
        "avg_logprob": -0.3580144771859666,
        "compression_ratio": 1.5769230769230769,
        "end": 1937.66,
        "id": 346,
        "no_speech_prob": 0.00006401987775461748,
        "seek": 192638,
        "start": 1935.5,
        "temperature": 0,
        "text": " There were some semi-off-topic questions.",
        "tokens": [
          50820,
          821,
          645,
          512,
          12909,
          12,
          4506,
          12,
          19337,
          299,
          1651,
          13,
          50928
        ]
      },
      {
        "avg_logprob": -0.3580144771859666,
        "compression_ratio": 1.5769230769230769,
        "end": 1939.46,
        "id": 347,
        "no_speech_prob": 0.00006401987775461748,
        "seek": 192638,
        "start": 1937.66,
        "temperature": 0,
        "text": " I mean, they're related to web development,",
        "tokens": [
          50928,
          286,
          914,
          11,
          436,
          434,
          4077,
          281,
          3670,
          3250,
          11,
          51018
        ]
      },
      {
        "avg_logprob": -0.3580144771859666,
        "compression_ratio": 1.5769230769230769,
        "end": 1940.66,
        "id": 348,
        "no_speech_prob": 0.00006401987775461748,
        "seek": 192638,
        "start": 1939.46,
        "temperature": 0,
        "text": " but not exactly what you're coding.",
        "tokens": [
          51018,
          457,
          406,
          2293,
          437,
          291,
          434,
          17720,
          13,
          51078
        ]
      },
      {
        "avg_logprob": -0.3580144771859666,
        "compression_ratio": 1.5769230769230769,
        "end": 1942.46,
        "id": 349,
        "no_speech_prob": 0.00006401987775461748,
        "seek": 192638,
        "start": 1940.66,
        "temperature": 0,
        "text": " So we can save those to the end, I think.",
        "tokens": [
          51078,
          407,
          321,
          393,
          3155,
          729,
          281,
          264,
          917,
          11,
          286,
          519,
          13,
          51168
        ]
      },
      {
        "avg_logprob": -0.3580144771859666,
        "compression_ratio": 1.5769230769230769,
        "end": 1942.96,
        "id": 350,
        "no_speech_prob": 0.00006401987775461748,
        "seek": 192638,
        "start": 1942.46,
        "temperature": 0,
        "text": " Awesome.",
        "tokens": [
          51168,
          10391,
          13,
          51193
        ]
      },
      {
        "avg_logprob": -0.3580144771859666,
        "compression_ratio": 1.5769230769230769,
        "end": 1943.8200000000002,
        "id": 351,
        "no_speech_prob": 0.00006401987775461748,
        "seek": 192638,
        "start": 1942.96,
        "temperature": 0,
        "text": " I've cataloged.",
        "tokens": [
          51193,
          286,
          600,
          19746,
          292,
          13,
          51236
        ]
      },
      {
        "avg_logprob": -0.3580144771859666,
        "compression_ratio": 1.5769230769230769,
        "end": 1945.98,
        "id": 352,
        "no_speech_prob": 0.00006401987775461748,
        "seek": 192638,
        "start": 1943.8200000000002,
        "temperature": 0,
        "text": " Cool.",
        "tokens": [
          51236,
          8561,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.3580144771859666,
        "compression_ratio": 1.5769230769230769,
        "end": 1950.0600000000002,
        "id": 353,
        "no_speech_prob": 0.00006401987775461748,
        "seek": 192638,
        "start": 1945.98,
        "temperature": 0,
        "text": " So let's now work on the route for receiving the email.",
        "tokens": [
          51344,
          407,
          718,
          311,
          586,
          589,
          322,
          264,
          7955,
          337,
          10040,
          264,
          3796,
          13,
          51548
        ]
      },
      {
        "avg_logprob": -0.3580144771859666,
        "compression_ratio": 1.5769230769230769,
        "end": 1952.48,
        "id": 354,
        "no_speech_prob": 0.00006401987775461748,
        "seek": 192638,
        "start": 1950.0600000000002,
        "temperature": 0,
        "text": " So if we can remind ourselves what's about to happen here.",
        "tokens": [
          51548,
          407,
          498,
          321,
          393,
          4160,
          4175,
          437,
          311,
          466,
          281,
          1051,
          510,
          13,
          51669
        ]
      },
      {
        "avg_logprob": -0.24414550280961833,
        "compression_ratio": 1.7208333333333334,
        "end": 1960.2,
        "id": 355,
        "no_speech_prob": 0.00019716747920028865,
        "seek": 195248,
        "start": 1952.84,
        "temperature": 0,
        "text": " On the client, when we type in CJ and we type in some message",
        "tokens": [
          50382,
          1282,
          264,
          6423,
          11,
          562,
          321,
          2010,
          294,
          42285,
          293,
          321,
          2010,
          294,
          512,
          3636,
          50750
        ]
      },
      {
        "avg_logprob": -0.24414550280961833,
        "compression_ratio": 1.7208333333333334,
        "end": 1962.28,
        "id": 356,
        "no_speech_prob": 0.00019716747920028865,
        "seek": 195248,
        "start": 1960.2,
        "temperature": 0,
        "text": " like, hello world, and click Send,",
        "tokens": [
          50750,
          411,
          11,
          7751,
          1002,
          11,
          293,
          2052,
          17908,
          11,
          50854
        ]
      },
      {
        "avg_logprob": -0.24414550280961833,
        "compression_ratio": 1.7208333333333334,
        "end": 1963.7,
        "id": 357,
        "no_speech_prob": 0.00019716747920028865,
        "seek": 195248,
        "start": 1962.28,
        "temperature": 0,
        "text": " that has to send it to the server.",
        "tokens": [
          50854,
          300,
          575,
          281,
          2845,
          309,
          281,
          264,
          7154,
          13,
          50925
        ]
      },
      {
        "avg_logprob": -0.24414550280961833,
        "compression_ratio": 1.7208333333333334,
        "end": 1965.32,
        "id": 358,
        "no_speech_prob": 0.00019716747920028865,
        "seek": 195248,
        "start": 1963.7,
        "temperature": 0,
        "text": " So we're going to create a route that's",
        "tokens": [
          50925,
          407,
          321,
          434,
          516,
          281,
          1884,
          257,
          7955,
          300,
          311,
          51006
        ]
      },
      {
        "avg_logprob": -0.24414550280961833,
        "compression_ratio": 1.7208333333333334,
        "end": 1967.28,
        "id": 359,
        "no_speech_prob": 0.00019716747920028865,
        "seek": 195248,
        "start": 1965.32,
        "temperature": 0,
        "text": " waiting for that incoming data.",
        "tokens": [
          51006,
          3806,
          337,
          300,
          22341,
          1412,
          13,
          51104
        ]
      },
      {
        "avg_logprob": -0.24414550280961833,
        "compression_ratio": 1.7208333333333334,
        "end": 1969.68,
        "id": 360,
        "no_speech_prob": 0.00019716747920028865,
        "seek": 195248,
        "start": 1967.28,
        "temperature": 0,
        "text": " And we'll actually then insert it into our database.",
        "tokens": [
          51104,
          400,
          321,
          603,
          767,
          550,
          8969,
          309,
          666,
          527,
          8149,
          13,
          51224
        ]
      },
      {
        "avg_logprob": -0.24414550280961833,
        "compression_ratio": 1.7208333333333334,
        "end": 1971.52,
        "id": 361,
        "no_speech_prob": 0.00019716747920028865,
        "seek": 195248,
        "start": 1969.68,
        "temperature": 0,
        "text": " So let's create the post route.",
        "tokens": [
          51224,
          407,
          718,
          311,
          1884,
          264,
          2183,
          7955,
          13,
          51316
        ]
      },
      {
        "avg_logprob": -0.24414550280961833,
        "compression_ratio": 1.7208333333333334,
        "end": 1974.4,
        "id": 362,
        "no_speech_prob": 0.00019716747920028865,
        "seek": 195248,
        "start": 1971.52,
        "temperature": 0,
        "text": " So here, I'll do an app.post.",
        "tokens": [
          51316,
          407,
          510,
          11,
          286,
          603,
          360,
          364,
          724,
          13,
          23744,
          13,
          51460
        ]
      },
      {
        "avg_logprob": -0.24414550280961833,
        "compression_ratio": 1.7208333333333334,
        "end": 1976.64,
        "id": 363,
        "no_speech_prob": 0.00019716747920028865,
        "seek": 195248,
        "start": 1974.4,
        "temperature": 0,
        "text": " And we'll make the route slash Muse.",
        "tokens": [
          51460,
          400,
          321,
          603,
          652,
          264,
          7955,
          17330,
          47293,
          13,
          51572
        ]
      },
      {
        "avg_logprob": -0.24414550280961833,
        "compression_ratio": 1.7208333333333334,
        "end": 1980.72,
        "id": 364,
        "no_speech_prob": 0.00019716747920028865,
        "seek": 195248,
        "start": 1976.64,
        "temperature": 0,
        "text": " So when the server receives a post request on slash Muse,",
        "tokens": [
          51572,
          407,
          562,
          264,
          7154,
          20717,
          257,
          2183,
          5308,
          322,
          17330,
          47293,
          11,
          51776
        ]
      },
      {
        "avg_logprob": -0.22064685821533203,
        "compression_ratio": 1.7458333333333333,
        "end": 1983.92,
        "id": 365,
        "no_speech_prob": 0.00003120176188531332,
        "seek": 198072,
        "start": 1980.72,
        "temperature": 0,
        "text": " we are going to run this request handler.",
        "tokens": [
          50364,
          321,
          366,
          516,
          281,
          1190,
          341,
          5308,
          41967,
          13,
          50524
        ]
      },
      {
        "avg_logprob": -0.22064685821533203,
        "compression_ratio": 1.7458333333333333,
        "end": 1987.48,
        "id": 366,
        "no_speech_prob": 0.00003120176188531332,
        "seek": 198072,
        "start": 1983.92,
        "temperature": 0,
        "text": " And for now, I am just going to log the request body,",
        "tokens": [
          50524,
          400,
          337,
          586,
          11,
          286,
          669,
          445,
          516,
          281,
          3565,
          264,
          5308,
          1772,
          11,
          50702
        ]
      },
      {
        "avg_logprob": -0.22064685821533203,
        "compression_ratio": 1.7458333333333333,
        "end": 1988.44,
        "id": 367,
        "no_speech_prob": 0.00003120176188531332,
        "seek": 198072,
        "start": 1987.48,
        "temperature": 0,
        "text": " rec.body.",
        "tokens": [
          50702,
          850,
          13,
          1067,
          13,
          50750
        ]
      },
      {
        "avg_logprob": -0.22064685821533203,
        "compression_ratio": 1.7458333333333333,
        "end": 1990.72,
        "id": 368,
        "no_speech_prob": 0.00003120176188531332,
        "seek": 198072,
        "start": 1988.44,
        "temperature": 0,
        "text": " Let's log it.",
        "tokens": [
          50750,
          961,
          311,
          3565,
          309,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.22064685821533203,
        "compression_ratio": 1.7458333333333333,
        "end": 1994.1200000000001,
        "id": 369,
        "no_speech_prob": 0.00003120176188531332,
        "seek": 198072,
        "start": 1990.72,
        "temperature": 0,
        "text": " And what should happen is when some incoming post request",
        "tokens": [
          50864,
          400,
          437,
          820,
          1051,
          307,
          562,
          512,
          22341,
          2183,
          5308,
          51034
        ]
      },
      {
        "avg_logprob": -0.22064685821533203,
        "compression_ratio": 1.7458333333333333,
        "end": 1996.48,
        "id": 370,
        "no_speech_prob": 0.00003120176188531332,
        "seek": 198072,
        "start": 1994.1200000000001,
        "temperature": 0,
        "text": " happens to my server, it will log out",
        "tokens": [
          51034,
          2314,
          281,
          452,
          7154,
          11,
          309,
          486,
          3565,
          484,
          51152
        ]
      },
      {
        "avg_logprob": -0.22064685821533203,
        "compression_ratio": 1.7458333333333333,
        "end": 1998.52,
        "id": 371,
        "no_speech_prob": 0.00003120176188531332,
        "seek": 198072,
        "start": 1996.48,
        "temperature": 0,
        "text": " whatever the client sent to us.",
        "tokens": [
          51152,
          2035,
          264,
          6423,
          2279,
          281,
          505,
          13,
          51254
        ]
      },
      {
        "avg_logprob": -0.22064685821533203,
        "compression_ratio": 1.7458333333333333,
        "end": 2000,
        "id": 372,
        "no_speech_prob": 0.00003120176188531332,
        "seek": 198072,
        "start": 1998.52,
        "temperature": 0,
        "text": " Cool.",
        "tokens": [
          51254,
          8561,
          13,
          51328
        ]
      },
      {
        "avg_logprob": -0.22064685821533203,
        "compression_ratio": 1.7458333333333333,
        "end": 2002.76,
        "id": 373,
        "no_speech_prob": 0.00003120176188531332,
        "seek": 198072,
        "start": 2000,
        "temperature": 0,
        "text": " So now, let's get that going on the client side.",
        "tokens": [
          51328,
          407,
          586,
          11,
          718,
          311,
          483,
          300,
          516,
          322,
          264,
          6423,
          1252,
          13,
          51466
        ]
      },
      {
        "avg_logprob": -0.22064685821533203,
        "compression_ratio": 1.7458333333333333,
        "end": 2003.96,
        "id": 374,
        "no_speech_prob": 0.00003120176188531332,
        "seek": 198072,
        "start": 2002.76,
        "temperature": 0,
        "text": " So we're just logging it.",
        "tokens": [
          51466,
          407,
          321,
          434,
          445,
          27991,
          309,
          13,
          51526
        ]
      },
      {
        "avg_logprob": -0.22064685821533203,
        "compression_ratio": 1.7458333333333333,
        "end": 2006.64,
        "id": 375,
        "no_speech_prob": 0.00003120176188531332,
        "seek": 198072,
        "start": 2003.96,
        "temperature": 0,
        "text": " But now, we're going to go back to the front end",
        "tokens": [
          51526,
          583,
          586,
          11,
          321,
          434,
          516,
          281,
          352,
          646,
          281,
          264,
          1868,
          917,
          51660
        ]
      },
      {
        "avg_logprob": -0.22064685821533203,
        "compression_ratio": 1.7458333333333333,
        "end": 2008.32,
        "id": 376,
        "no_speech_prob": 0.00003120176188531332,
        "seek": 198072,
        "start": 2006.64,
        "temperature": 0,
        "text": " and actually send the data to the server.",
        "tokens": [
          51660,
          293,
          767,
          2845,
          264,
          1412,
          281,
          264,
          7154,
          13,
          51744
        ]
      },
      {
        "avg_logprob": -0.252040400649562,
        "compression_ratio": 1.5296610169491525,
        "end": 2012.08,
        "id": 377,
        "no_speech_prob": 0.00010071360156871378,
        "seek": 200832,
        "start": 2008.32,
        "temperature": 0,
        "text": " So on our front end, we're going to use something called fetch.",
        "tokens": [
          50364,
          407,
          322,
          527,
          1868,
          917,
          11,
          321,
          434,
          516,
          281,
          764,
          746,
          1219,
          23673,
          13,
          50552
        ]
      },
      {
        "avg_logprob": -0.252040400649562,
        "compression_ratio": 1.5296610169491525,
        "end": 2017.1599999999999,
        "id": 378,
        "no_speech_prob": 0.00010071360156871378,
        "seek": 200832,
        "start": 2012.08,
        "temperature": 0,
        "text": " So right here, instead of just logging out to the console,",
        "tokens": [
          50552,
          407,
          558,
          510,
          11,
          2602,
          295,
          445,
          27991,
          484,
          281,
          264,
          11076,
          11,
          50806
        ]
      },
      {
        "avg_logprob": -0.252040400649562,
        "compression_ratio": 1.5296610169491525,
        "end": 2019.1599999999999,
        "id": 379,
        "no_speech_prob": 0.00010071360156871378,
        "seek": 200832,
        "start": 2017.1599999999999,
        "temperature": 0,
        "text": " we're going to actually send that data somewhere.",
        "tokens": [
          50806,
          321,
          434,
          516,
          281,
          767,
          2845,
          300,
          1412,
          4079,
          13,
          50906
        ]
      },
      {
        "avg_logprob": -0.252040400649562,
        "compression_ratio": 1.5296610169491525,
        "end": 2021.12,
        "id": 380,
        "no_speech_prob": 0.00010071360156871378,
        "seek": 200832,
        "start": 2019.1599999999999,
        "temperature": 0,
        "text": " So first thing is I need a variable",
        "tokens": [
          50906,
          407,
          700,
          551,
          307,
          286,
          643,
          257,
          7006,
          51004
        ]
      },
      {
        "avg_logprob": -0.252040400649562,
        "compression_ratio": 1.5296610169491525,
        "end": 2024.04,
        "id": 381,
        "no_speech_prob": 0.00010071360156871378,
        "seek": 200832,
        "start": 2021.12,
        "temperature": 0,
        "text": " to hold onto where is the server that I'm making requests to.",
        "tokens": [
          51004,
          281,
          1797,
          3911,
          689,
          307,
          264,
          7154,
          300,
          286,
          478,
          1455,
          12475,
          281,
          13,
          51150
        ]
      },
      {
        "avg_logprob": -0.252040400649562,
        "compression_ratio": 1.5296610169491525,
        "end": 2027.6,
        "id": 382,
        "no_speech_prob": 0.00010071360156871378,
        "seek": 200832,
        "start": 2024.04,
        "temperature": 0,
        "text": " So we'll call this API URL.",
        "tokens": [
          51150,
          407,
          321,
          603,
          818,
          341,
          9362,
          12905,
          13,
          51328
        ]
      },
      {
        "avg_logprob": -0.252040400649562,
        "compression_ratio": 1.5296610169491525,
        "end": 2037.3999999999999,
        "id": 383,
        "no_speech_prob": 0.00010071360156871378,
        "seek": 200832,
        "start": 2027.6,
        "temperature": 0,
        "text": " And this will be HTTP colon slash slash local host port 5,000.",
        "tokens": [
          51328,
          400,
          341,
          486,
          312,
          33283,
          8255,
          17330,
          17330,
          2654,
          3975,
          2436,
          1025,
          11,
          1360,
          13,
          51818
        ]
      },
      {
        "avg_logprob": -0.21814753866603231,
        "compression_ratio": 1.7639484978540771,
        "end": 2040.16,
        "id": 384,
        "no_speech_prob": 0.00008888012962415814,
        "seek": 203740,
        "start": 2037.4,
        "temperature": 0,
        "text": " And slash mus.",
        "tokens": [
          50364,
          400,
          17330,
          1038,
          13,
          50502
        ]
      },
      {
        "avg_logprob": -0.21814753866603231,
        "compression_ratio": 1.7639484978540771,
        "end": 2043.76,
        "id": 385,
        "no_speech_prob": 0.00008888012962415814,
        "seek": 203740,
        "start": 2040.16,
        "temperature": 0,
        "text": " So I'm going to be making a post request against this URL",
        "tokens": [
          50502,
          407,
          286,
          478,
          516,
          281,
          312,
          1455,
          257,
          2183,
          5308,
          1970,
          341,
          12905,
          50682
        ]
      },
      {
        "avg_logprob": -0.21814753866603231,
        "compression_ratio": 1.7639484978540771,
        "end": 2047.16,
        "id": 386,
        "no_speech_prob": 0.00008888012962415814,
        "seek": 203740,
        "start": 2043.76,
        "temperature": 0,
        "text": " to actually send this object to our dynamic server.",
        "tokens": [
          50682,
          281,
          767,
          2845,
          341,
          2657,
          281,
          527,
          8546,
          7154,
          13,
          50852
        ]
      },
      {
        "avg_logprob": -0.21814753866603231,
        "compression_ratio": 1.7639484978540771,
        "end": 2049.92,
        "id": 387,
        "no_speech_prob": 0.00008888012962415814,
        "seek": 203740,
        "start": 2047.16,
        "temperature": 0,
        "text": " So here, we'll use fetch.",
        "tokens": [
          50852,
          407,
          510,
          11,
          321,
          603,
          764,
          23673,
          13,
          50990
        ]
      },
      {
        "avg_logprob": -0.21814753866603231,
        "compression_ratio": 1.7639484978540771,
        "end": 2054.08,
        "id": 388,
        "no_speech_prob": 0.00008888012962415814,
        "seek": 203740,
        "start": 2049.92,
        "temperature": 0,
        "text": " We'll pass in the URL that we're making the request against.",
        "tokens": [
          50990,
          492,
          603,
          1320,
          294,
          264,
          12905,
          300,
          321,
          434,
          1455,
          264,
          5308,
          1970,
          13,
          51198
        ]
      },
      {
        "avg_logprob": -0.21814753866603231,
        "compression_ratio": 1.7639484978540771,
        "end": 2056.28,
        "id": 389,
        "no_speech_prob": 0.00008888012962415814,
        "seek": 203740,
        "start": 2054.08,
        "temperature": 0,
        "text": " And then we have to specify a few different options.",
        "tokens": [
          51198,
          400,
          550,
          321,
          362,
          281,
          16500,
          257,
          1326,
          819,
          3956,
          13,
          51308
        ]
      },
      {
        "avg_logprob": -0.21814753866603231,
        "compression_ratio": 1.7639484978540771,
        "end": 2060.28,
        "id": 390,
        "no_speech_prob": 0.00008888012962415814,
        "seek": 203740,
        "start": 2056.28,
        "temperature": 0,
        "text": " So in this case, we need to tell it that the method is post.",
        "tokens": [
          51308,
          407,
          294,
          341,
          1389,
          11,
          321,
          643,
          281,
          980,
          309,
          300,
          264,
          3170,
          307,
          2183,
          13,
          51508
        ]
      },
      {
        "avg_logprob": -0.21814753866603231,
        "compression_ratio": 1.7639484978540771,
        "end": 2063.6800000000003,
        "id": 391,
        "no_speech_prob": 0.00008888012962415814,
        "seek": 203740,
        "start": 2060.28,
        "temperature": 0,
        "text": " We need to say what is the body of the request.",
        "tokens": [
          51508,
          492,
          643,
          281,
          584,
          437,
          307,
          264,
          1772,
          295,
          264,
          5308,
          13,
          51678
        ]
      },
      {
        "avg_logprob": -0.21814753866603231,
        "compression_ratio": 1.7639484978540771,
        "end": 2065.44,
        "id": 392,
        "no_speech_prob": 0.00008888012962415814,
        "seek": 203740,
        "start": 2063.6800000000003,
        "temperature": 0,
        "text": " In this case, the body of the request",
        "tokens": [
          51678,
          682,
          341,
          1389,
          11,
          264,
          1772,
          295,
          264,
          5308,
          51766
        ]
      },
      {
        "avg_logprob": -0.22519220226872577,
        "compression_ratio": 1.793774319066148,
        "end": 2067.16,
        "id": 393,
        "no_speech_prob": 0.00011774399899877608,
        "seek": 206544,
        "start": 2065.44,
        "temperature": 0,
        "text": " or the thing we're sending to the server",
        "tokens": [
          50364,
          420,
          264,
          551,
          321,
          434,
          7750,
          281,
          264,
          7154,
          50450
        ]
      },
      {
        "avg_logprob": -0.22519220226872577,
        "compression_ratio": 1.793774319066148,
        "end": 2070.36,
        "id": 394,
        "no_speech_prob": 0.00011774399899877608,
        "seek": 206544,
        "start": 2067.16,
        "temperature": 0,
        "text": " is the mu itself, this object with name and content.",
        "tokens": [
          50450,
          307,
          264,
          2992,
          2564,
          11,
          341,
          2657,
          365,
          1315,
          293,
          2701,
          13,
          50610
        ]
      },
      {
        "avg_logprob": -0.22519220226872577,
        "compression_ratio": 1.793774319066148,
        "end": 2073.04,
        "id": 395,
        "no_speech_prob": 0.00011774399899877608,
        "seek": 206544,
        "start": 2070.36,
        "temperature": 0,
        "text": " So we're going to set body to be mu.",
        "tokens": [
          50610,
          407,
          321,
          434,
          516,
          281,
          992,
          1772,
          281,
          312,
          2992,
          13,
          50744
        ]
      },
      {
        "avg_logprob": -0.22519220226872577,
        "compression_ratio": 1.793774319066148,
        "end": 2075.76,
        "id": 396,
        "no_speech_prob": 0.00011774399899877608,
        "seek": 206544,
        "start": 2073.04,
        "temperature": 0,
        "text": " And then also, we need to specify some headers.",
        "tokens": [
          50744,
          400,
          550,
          611,
          11,
          321,
          643,
          281,
          16500,
          512,
          45101,
          13,
          50880
        ]
      },
      {
        "avg_logprob": -0.22519220226872577,
        "compression_ratio": 1.793774319066148,
        "end": 2078.84,
        "id": 397,
        "no_speech_prob": 0.00011774399899877608,
        "seek": 206544,
        "start": 2075.76,
        "temperature": 0,
        "text": " So we need to tell it what are we sending it.",
        "tokens": [
          50880,
          407,
          321,
          643,
          281,
          980,
          309,
          437,
          366,
          321,
          7750,
          309,
          13,
          51034
        ]
      },
      {
        "avg_logprob": -0.22519220226872577,
        "compression_ratio": 1.793774319066148,
        "end": 2082,
        "id": 398,
        "no_speech_prob": 0.00011774399899877608,
        "seek": 206544,
        "start": 2078.84,
        "temperature": 0,
        "text": " In this case, we'll specify the content type header.",
        "tokens": [
          51034,
          682,
          341,
          1389,
          11,
          321,
          603,
          16500,
          264,
          2701,
          2010,
          23117,
          13,
          51192
        ]
      },
      {
        "avg_logprob": -0.22519220226872577,
        "compression_ratio": 1.793774319066148,
        "end": 2084.84,
        "id": 399,
        "no_speech_prob": 0.00011774399899877608,
        "seek": 206544,
        "start": 2082,
        "temperature": 0,
        "text": " And we'll say application JSON.",
        "tokens": [
          51192,
          400,
          321,
          603,
          584,
          3861,
          31828,
          13,
          51334
        ]
      },
      {
        "avg_logprob": -0.22519220226872577,
        "compression_ratio": 1.793774319066148,
        "end": 2087.92,
        "id": 400,
        "no_speech_prob": 0.00011774399899877608,
        "seek": 206544,
        "start": 2084.84,
        "temperature": 0,
        "text": " So we're telling the server, hey, server,",
        "tokens": [
          51334,
          407,
          321,
          434,
          3585,
          264,
          7154,
          11,
          4177,
          11,
          7154,
          11,
          51488
        ]
      },
      {
        "avg_logprob": -0.22519220226872577,
        "compression_ratio": 1.793774319066148,
        "end": 2090,
        "id": 401,
        "no_speech_prob": 0.00011774399899877608,
        "seek": 206544,
        "start": 2087.92,
        "temperature": 0,
        "text": " in the body of my request is JSON.",
        "tokens": [
          51488,
          294,
          264,
          1772,
          295,
          452,
          5308,
          307,
          31828,
          13,
          51592
        ]
      },
      {
        "avg_logprob": -0.22519220226872577,
        "compression_ratio": 1.793774319066148,
        "end": 2091.36,
        "id": 402,
        "no_speech_prob": 0.00011774399899877608,
        "seek": 206544,
        "start": 2090,
        "temperature": 0,
        "text": " But right now, it's actually not.",
        "tokens": [
          51592,
          583,
          558,
          586,
          11,
          309,
          311,
          767,
          406,
          13,
          51660
        ]
      },
      {
        "avg_logprob": -0.22519220226872577,
        "compression_ratio": 1.793774319066148,
        "end": 2093.2400000000002,
        "id": 403,
        "no_speech_prob": 0.00011774399899877608,
        "seek": 206544,
        "start": 2091.36,
        "temperature": 0,
        "text": " So right now, it is a JavaScript object.",
        "tokens": [
          51660,
          407,
          558,
          586,
          11,
          309,
          307,
          257,
          15778,
          2657,
          13,
          51754
        ]
      },
      {
        "avg_logprob": -0.23970848549413318,
        "compression_ratio": 1.752808988764045,
        "end": 2097.64,
        "id": 404,
        "no_speech_prob": 0.000014738910067535471,
        "seek": 209324,
        "start": 2093.24,
        "temperature": 0,
        "text": " But to turn it into JSON, we have to use JSON.stringify.",
        "tokens": [
          50364,
          583,
          281,
          1261,
          309,
          666,
          31828,
          11,
          321,
          362,
          281,
          764,
          31828,
          13,
          37045,
          2505,
          13,
          50584
        ]
      },
      {
        "avg_logprob": -0.23970848549413318,
        "compression_ratio": 1.752808988764045,
        "end": 2099.56,
        "id": 405,
        "no_speech_prob": 0.000014738910067535471,
        "seek": 209324,
        "start": 2097.64,
        "temperature": 0,
        "text": " And this will actually take that object,",
        "tokens": [
          50584,
          400,
          341,
          486,
          767,
          747,
          300,
          2657,
          11,
          50680
        ]
      },
      {
        "avg_logprob": -0.23970848549413318,
        "compression_ratio": 1.752808988764045,
        "end": 2102.56,
        "id": 406,
        "no_speech_prob": 0.000014738910067535471,
        "seek": 209324,
        "start": 2099.56,
        "temperature": 0,
        "text": " turn it into something that the server can parse and understand.",
        "tokens": [
          50680,
          1261,
          309,
          666,
          746,
          300,
          264,
          7154,
          393,
          48377,
          293,
          1223,
          13,
          50830
        ]
      },
      {
        "avg_logprob": -0.23970848549413318,
        "compression_ratio": 1.752808988764045,
        "end": 2104.8399999999997,
        "id": 407,
        "no_speech_prob": 0.000014738910067535471,
        "seek": 209324,
        "start": 2102.56,
        "temperature": 0,
        "text": " And then we should be able to see it on the server side.",
        "tokens": [
          50830,
          400,
          550,
          321,
          820,
          312,
          1075,
          281,
          536,
          309,
          322,
          264,
          7154,
          1252,
          13,
          50944
        ]
      },
      {
        "avg_logprob": -0.23970848549413318,
        "compression_ratio": 1.752808988764045,
        "end": 2107.72,
        "id": 408,
        "no_speech_prob": 0.000014738910067535471,
        "seek": 209324,
        "start": 2104.8399999999997,
        "temperature": 0,
        "text": " So essentially, what's happening here",
        "tokens": [
          50944,
          407,
          4476,
          11,
          437,
          311,
          2737,
          510,
          51088
        ]
      },
      {
        "avg_logprob": -0.23970848549413318,
        "compression_ratio": 1.752808988764045,
        "end": 2110.64,
        "id": 409,
        "no_speech_prob": 0.000014738910067535471,
        "seek": 209324,
        "start": 2107.72,
        "temperature": 0,
        "text": " is when the form is submitted, we grab the stuff",
        "tokens": [
          51088,
          307,
          562,
          264,
          1254,
          307,
          14405,
          11,
          321,
          4444,
          264,
          1507,
          51234
        ]
      },
      {
        "avg_logprob": -0.23970848549413318,
        "compression_ratio": 1.752808988764045,
        "end": 2111.3199999999997,
        "id": 410,
        "no_speech_prob": 0.000014738910067535471,
        "seek": 209324,
        "start": 2110.64,
        "temperature": 0,
        "text": " from the form.",
        "tokens": [
          51234,
          490,
          264,
          1254,
          13,
          51268
        ]
      },
      {
        "avg_logprob": -0.23970848549413318,
        "compression_ratio": 1.752808988764045,
        "end": 2112.72,
        "id": 411,
        "no_speech_prob": 0.000014738910067535471,
        "seek": 209324,
        "start": 2111.3199999999997,
        "temperature": 0,
        "text": " We put it in an object.",
        "tokens": [
          51268,
          492,
          829,
          309,
          294,
          364,
          2657,
          13,
          51338
        ]
      },
      {
        "avg_logprob": -0.23970848549413318,
        "compression_ratio": 1.752808988764045,
        "end": 2114.2799999999997,
        "id": 412,
        "no_speech_prob": 0.000014738910067535471,
        "seek": 209324,
        "start": 2112.72,
        "temperature": 0,
        "text": " We show that loading spinner.",
        "tokens": [
          51338,
          492,
          855,
          300,
          15114,
          44849,
          13,
          51416
        ]
      },
      {
        "avg_logprob": -0.23970848549413318,
        "compression_ratio": 1.752808988764045,
        "end": 2119.16,
        "id": 413,
        "no_speech_prob": 0.000014738910067535471,
        "seek": 209324,
        "start": 2114.2799999999997,
        "temperature": 0,
        "text": " And then we attempt to send this data off to our back end server.",
        "tokens": [
          51416,
          400,
          550,
          321,
          5217,
          281,
          2845,
          341,
          1412,
          766,
          281,
          527,
          646,
          917,
          7154,
          13,
          51660
        ]
      },
      {
        "avg_logprob": -0.23970848549413318,
        "compression_ratio": 1.752808988764045,
        "end": 2122.7599999999998,
        "id": 414,
        "no_speech_prob": 0.000014738910067535471,
        "seek": 209324,
        "start": 2119.16,
        "temperature": 0,
        "text": " So let's see what happens.",
        "tokens": [
          51660,
          407,
          718,
          311,
          536,
          437,
          2314,
          13,
          51840
        ]
      },
      {
        "avg_logprob": -0.31177952106182394,
        "compression_ratio": 1.6260504201680672,
        "end": 2125.36,
        "id": 415,
        "no_speech_prob": 0.00003480786472209729,
        "seek": 212276,
        "start": 2123.76,
        "temperature": 0,
        "text": " And actually, let's set up.",
        "tokens": [
          50414,
          400,
          767,
          11,
          718,
          311,
          992,
          493,
          13,
          50494
        ]
      },
      {
        "avg_logprob": -0.31177952106182394,
        "compression_ratio": 1.6260504201680672,
        "end": 2126.6000000000004,
        "id": 416,
        "no_speech_prob": 0.00003480786472209729,
        "seek": 212276,
        "start": 2125.36,
        "temperature": 0,
        "text": " OK, I have the back end route.",
        "tokens": [
          50494,
          2264,
          11,
          286,
          362,
          264,
          646,
          917,
          7955,
          13,
          50556
        ]
      },
      {
        "avg_logprob": -0.31177952106182394,
        "compression_ratio": 1.6260504201680672,
        "end": 2127.2400000000002,
        "id": 417,
        "no_speech_prob": 0.00003480786472209729,
        "seek": 212276,
        "start": 2126.6000000000004,
        "temperature": 0,
        "text": " I have the form.",
        "tokens": [
          50556,
          286,
          362,
          264,
          1254,
          13,
          50588
        ]
      },
      {
        "avg_logprob": -0.31177952106182394,
        "compression_ratio": 1.6260504201680672,
        "end": 2128.32,
        "id": 418,
        "no_speech_prob": 0.00003480786472209729,
        "seek": 212276,
        "start": 2127.2400000000002,
        "temperature": 0,
        "text": " Let's see what happens.",
        "tokens": [
          50588,
          961,
          311,
          536,
          437,
          2314,
          13,
          50642
        ]
      },
      {
        "avg_logprob": -0.31177952106182394,
        "compression_ratio": 1.6260504201680672,
        "end": 2131.6800000000003,
        "id": 419,
        "no_speech_prob": 0.00003480786472209729,
        "seek": 212276,
        "start": 2128.32,
        "temperature": 0,
        "text": " We're going to watch the server side logs,",
        "tokens": [
          50642,
          492,
          434,
          516,
          281,
          1159,
          264,
          7154,
          1252,
          20820,
          11,
          50810
        ]
      },
      {
        "avg_logprob": -0.31177952106182394,
        "compression_ratio": 1.6260504201680672,
        "end": 2133.6800000000003,
        "id": 420,
        "no_speech_prob": 0.00003480786472209729,
        "seek": 212276,
        "start": 2131.6800000000003,
        "temperature": 0,
        "text": " because we want to make sure that we're actually",
        "tokens": [
          50810,
          570,
          321,
          528,
          281,
          652,
          988,
          300,
          321,
          434,
          767,
          50910
        ]
      },
      {
        "avg_logprob": -0.31177952106182394,
        "compression_ratio": 1.6260504201680672,
        "end": 2137.8,
        "id": 421,
        "no_speech_prob": 0.00003480786472209729,
        "seek": 212276,
        "start": 2133.6800000000003,
        "temperature": 0,
        "text": " seeing that incoming thing that the client is sending us.",
        "tokens": [
          50910,
          2577,
          300,
          22341,
          551,
          300,
          264,
          6423,
          307,
          7750,
          505,
          13,
          51116
        ]
      },
      {
        "avg_logprob": -0.31177952106182394,
        "compression_ratio": 1.6260504201680672,
        "end": 2138.48,
        "id": 422,
        "no_speech_prob": 0.00003480786472209729,
        "seek": 212276,
        "start": 2137.8,
        "temperature": 0,
        "text": " Let's see.",
        "tokens": [
          51116,
          961,
          311,
          536,
          13,
          51150
        ]
      },
      {
        "avg_logprob": -0.31177952106182394,
        "compression_ratio": 1.6260504201680672,
        "end": 2140.32,
        "id": 423,
        "no_speech_prob": 0.00003480786472209729,
        "seek": 212276,
        "start": 2138.48,
        "temperature": 0,
        "text": " OK, so my name is CJ.",
        "tokens": [
          51150,
          2264,
          11,
          370,
          452,
          1315,
          307,
          42285,
          13,
          51242
        ]
      },
      {
        "avg_logprob": -0.31177952106182394,
        "compression_ratio": 1.6260504201680672,
        "end": 2143.2400000000002,
        "id": 424,
        "no_speech_prob": 0.00003480786472209729,
        "seek": 212276,
        "start": 2140.32,
        "temperature": 0,
        "text": " My mu is hello world.",
        "tokens": [
          51242,
          1222,
          2992,
          307,
          7751,
          1002,
          13,
          51388
        ]
      },
      {
        "avg_logprob": -0.31177952106182394,
        "compression_ratio": 1.6260504201680672,
        "end": 2144.36,
        "id": 425,
        "no_speech_prob": 0.00003480786472209729,
        "seek": 212276,
        "start": 2143.2400000000002,
        "temperature": 0,
        "text": " And I throw in a cat.",
        "tokens": [
          51388,
          400,
          286,
          3507,
          294,
          257,
          3857,
          13,
          51444
        ]
      },
      {
        "avg_logprob": -0.31177952106182394,
        "compression_ratio": 1.6260504201680672,
        "end": 2149.6800000000003,
        "id": 426,
        "no_speech_prob": 0.00003480786472209729,
        "seek": 212276,
        "start": 2147.4,
        "temperature": 0,
        "text": " And then we try to send it.",
        "tokens": [
          51596,
          400,
          550,
          321,
          853,
          281,
          2845,
          309,
          13,
          51710
        ]
      },
      {
        "avg_logprob": -0.31177952106182394,
        "compression_ratio": 1.6260504201680672,
        "end": 2151.5200000000004,
        "id": 427,
        "no_speech_prob": 0.00003480786472209729,
        "seek": 212276,
        "start": 2149.6800000000003,
        "temperature": 0,
        "text": " Oh, no, the dreaded cores error.",
        "tokens": [
          51710,
          876,
          11,
          572,
          11,
          264,
          22236,
          292,
          24826,
          6713,
          13,
          51802
        ]
      },
      {
        "avg_logprob": -0.2923120096189166,
        "compression_ratio": 1.6796536796536796,
        "end": 2155.04,
        "id": 428,
        "no_speech_prob": 0.00008480990800308064,
        "seek": 215152,
        "start": 2152.52,
        "temperature": 0,
        "text": " You may have seen this before, but right now it's",
        "tokens": [
          50414,
          509,
          815,
          362,
          1612,
          341,
          949,
          11,
          457,
          558,
          586,
          309,
          311,
          50540
        ]
      },
      {
        "avg_logprob": -0.2923120096189166,
        "compression_ratio": 1.6796536796536796,
        "end": 2156.52,
        "id": 429,
        "no_speech_prob": 0.00008480990800308064,
        "seek": 215152,
        "start": 2155.04,
        "temperature": 0,
        "text": " saying response to preflight request",
        "tokens": [
          50540,
          1566,
          4134,
          281,
          18417,
          2764,
          5308,
          50614
        ]
      },
      {
        "avg_logprob": -0.2923120096189166,
        "compression_ratio": 1.6796536796536796,
        "end": 2158.4,
        "id": 430,
        "no_speech_prob": 0.00008480990800308064,
        "seek": 215152,
        "start": 2156.52,
        "temperature": 0,
        "text": " doesn't pass access control check.",
        "tokens": [
          50614,
          1177,
          380,
          1320,
          2105,
          1969,
          1520,
          13,
          50708
        ]
      },
      {
        "avg_logprob": -0.2923120096189166,
        "compression_ratio": 1.6796536796536796,
        "end": 2161.28,
        "id": 431,
        "no_speech_prob": 0.00008480990800308064,
        "seek": 215152,
        "start": 2158.4,
        "temperature": 0,
        "text": " No access control allow origin header",
        "tokens": [
          50708,
          883,
          2105,
          1969,
          2089,
          4957,
          23117,
          50852
        ]
      },
      {
        "avg_logprob": -0.2923120096189166,
        "compression_ratio": 1.6796536796536796,
        "end": 2163.12,
        "id": 432,
        "no_speech_prob": 0.00008480990800308064,
        "seek": 215152,
        "start": 2161.28,
        "temperature": 0,
        "text": " is present on the requested resource.",
        "tokens": [
          50852,
          307,
          1974,
          322,
          264,
          16436,
          7684,
          13,
          50944
        ]
      },
      {
        "avg_logprob": -0.2923120096189166,
        "compression_ratio": 1.6796536796536796,
        "end": 2166.8,
        "id": 433,
        "no_speech_prob": 0.00008480990800308064,
        "seek": 215152,
        "start": 2163.12,
        "temperature": 0,
        "text": " So therefore, origin 127.00.0180.",
        "tokens": [
          50944,
          407,
          4412,
          11,
          4957,
          47561,
          13,
          628,
          13,
          15,
          37078,
          13,
          51128
        ]
      },
      {
        "avg_logprob": -0.2923120096189166,
        "compression_ratio": 1.6796536796536796,
        "end": 2171.6,
        "id": 434,
        "no_speech_prob": 0.00008480990800308064,
        "seek": 215152,
        "start": 2166.8,
        "temperature": 0,
        "text": " So you'll notice the web page is currently on 127.00.0180.",
        "tokens": [
          51128,
          407,
          291,
          603,
          3449,
          264,
          3670,
          3028,
          307,
          4362,
          322,
          47561,
          13,
          628,
          13,
          15,
          37078,
          13,
          51368
        ]
      },
      {
        "avg_logprob": -0.2923120096189166,
        "compression_ratio": 1.6796536796536796,
        "end": 2173.4,
        "id": 435,
        "no_speech_prob": 0.00008480990800308064,
        "seek": 215152,
        "start": 2171.6,
        "temperature": 0,
        "text": " That is the current origin.",
        "tokens": [
          51368,
          663,
          307,
          264,
          2190,
          4957,
          13,
          51458
        ]
      },
      {
        "avg_logprob": -0.2923120096189166,
        "compression_ratio": 1.6796536796536796,
        "end": 2176.32,
        "id": 436,
        "no_speech_prob": 0.00008480990800308064,
        "seek": 215152,
        "start": 2173.4,
        "temperature": 0,
        "text": " Is therefore not allowed access to the origin,",
        "tokens": [
          51458,
          1119,
          4412,
          406,
          4350,
          2105,
          281,
          264,
          4957,
          11,
          51604
        ]
      },
      {
        "avg_logprob": -0.2923120096189166,
        "compression_ratio": 1.6796536796536796,
        "end": 2178.64,
        "id": 437,
        "no_speech_prob": 0.00008480990800308064,
        "seek": 215152,
        "start": 2176.32,
        "temperature": 0,
        "text": " which is on port 5000.",
        "tokens": [
          51604,
          597,
          307,
          322,
          2436,
          23777,
          13,
          51720
        ]
      },
      {
        "avg_logprob": -0.1959735281099149,
        "compression_ratio": 1.654275092936803,
        "end": 2183.64,
        "id": 438,
        "no_speech_prob": 0.000021112440663273446,
        "seek": 217864,
        "start": 2178.64,
        "temperature": 0,
        "text": " So essentially, the browser is trying to protect us.",
        "tokens": [
          50364,
          407,
          4476,
          11,
          264,
          11185,
          307,
          1382,
          281,
          2371,
          505,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1959735281099149,
        "compression_ratio": 1.654275092936803,
        "end": 2184.92,
        "id": 439,
        "no_speech_prob": 0.000021112440663273446,
        "seek": 217864,
        "start": 2183.64,
        "temperature": 0,
        "text": " It's doing this on our behalf.",
        "tokens": [
          50614,
          467,
          311,
          884,
          341,
          322,
          527,
          9490,
          13,
          50678
        ]
      },
      {
        "avg_logprob": -0.1959735281099149,
        "compression_ratio": 1.654275092936803,
        "end": 2187.2799999999997,
        "id": 440,
        "no_speech_prob": 0.000021112440663273446,
        "seek": 217864,
        "start": 2184.92,
        "temperature": 0,
        "text": " It doesn't want JavaScript to be able to talk",
        "tokens": [
          50678,
          467,
          1177,
          380,
          528,
          15778,
          281,
          312,
          1075,
          281,
          751,
          50796
        ]
      },
      {
        "avg_logprob": -0.1959735281099149,
        "compression_ratio": 1.654275092936803,
        "end": 2190.04,
        "id": 441,
        "no_speech_prob": 0.000021112440663273446,
        "seek": 217864,
        "start": 2187.2799999999997,
        "temperature": 0,
        "text": " to just any server in the world unless those servers actually",
        "tokens": [
          50796,
          281,
          445,
          604,
          7154,
          294,
          264,
          1002,
          5969,
          729,
          15909,
          767,
          50934
        ]
      },
      {
        "avg_logprob": -0.1959735281099149,
        "compression_ratio": 1.654275092936803,
        "end": 2190.7599999999998,
        "id": 442,
        "no_speech_prob": 0.000021112440663273446,
        "seek": 217864,
        "start": 2190.04,
        "temperature": 0,
        "text": " allow it.",
        "tokens": [
          50934,
          2089,
          309,
          13,
          50970
        ]
      },
      {
        "avg_logprob": -0.1959735281099149,
        "compression_ratio": 1.654275092936803,
        "end": 2192.52,
        "id": 443,
        "no_speech_prob": 0.000021112440663273446,
        "seek": 217864,
        "start": 2190.7599999999998,
        "temperature": 0,
        "text": " So what we can do on our back end",
        "tokens": [
          50970,
          407,
          437,
          321,
          393,
          360,
          322,
          527,
          646,
          917,
          51058
        ]
      },
      {
        "avg_logprob": -0.1959735281099149,
        "compression_ratio": 1.654275092936803,
        "end": 2197.96,
        "id": 444,
        "no_speech_prob": 0.000021112440663273446,
        "seek": 217864,
        "start": 2192.52,
        "temperature": 0,
        "text": " is say, I will allow incoming requests from any other origin.",
        "tokens": [
          51058,
          307,
          584,
          11,
          286,
          486,
          2089,
          22341,
          12475,
          490,
          604,
          661,
          4957,
          13,
          51330
        ]
      },
      {
        "avg_logprob": -0.1959735281099149,
        "compression_ratio": 1.654275092936803,
        "end": 2200.6,
        "id": 445,
        "no_speech_prob": 0.000021112440663273446,
        "seek": 217864,
        "start": 2197.96,
        "temperature": 0,
        "text": " So to fix this specifically, we're",
        "tokens": [
          51330,
          407,
          281,
          3191,
          341,
          4682,
          11,
          321,
          434,
          51462
        ]
      },
      {
        "avg_logprob": -0.1959735281099149,
        "compression_ratio": 1.654275092936803,
        "end": 2202.4,
        "id": 446,
        "no_speech_prob": 0.000021112440663273446,
        "seek": 217864,
        "start": 2200.6,
        "temperature": 0,
        "text": " going to install something on the back end.",
        "tokens": [
          51462,
          516,
          281,
          3625,
          746,
          322,
          264,
          646,
          917,
          13,
          51552
        ]
      },
      {
        "avg_logprob": -0.1959735281099149,
        "compression_ratio": 1.654275092936803,
        "end": 2206.96,
        "id": 447,
        "no_speech_prob": 0.000021112440663273446,
        "seek": 217864,
        "start": 2202.4,
        "temperature": 0,
        "text": " Now, if you get this error, you may not always",
        "tokens": [
          51552,
          823,
          11,
          498,
          291,
          483,
          341,
          6713,
          11,
          291,
          815,
          406,
          1009,
          51780
        ]
      },
      {
        "avg_logprob": -0.1959735281099149,
        "compression_ratio": 1.654275092936803,
        "end": 2207.8399999999997,
        "id": 448,
        "no_speech_prob": 0.000021112440663273446,
        "seek": 217864,
        "start": 2206.96,
        "temperature": 0,
        "text": " have your own server.",
        "tokens": [
          51780,
          362,
          428,
          1065,
          7154,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.24073711661405342,
        "compression_ratio": 1.7058823529411764,
        "end": 2208.76,
        "id": 449,
        "no_speech_prob": 0.00003120163455605507,
        "seek": 220784,
        "start": 2207.84,
        "temperature": 0,
        "text": " You might get this error because you're",
        "tokens": [
          50364,
          509,
          1062,
          483,
          341,
          6713,
          570,
          291,
          434,
          50410
        ]
      },
      {
        "avg_logprob": -0.24073711661405342,
        "compression_ratio": 1.7058823529411764,
        "end": 2210.6400000000003,
        "id": 450,
        "no_speech_prob": 0.00003120163455605507,
        "seek": 220784,
        "start": 2208.76,
        "temperature": 0,
        "text": " trying to talk to some other server.",
        "tokens": [
          50410,
          1382,
          281,
          751,
          281,
          512,
          661,
          7154,
          13,
          50504
        ]
      },
      {
        "avg_logprob": -0.24073711661405342,
        "compression_ratio": 1.7058823529411764,
        "end": 2212.2200000000003,
        "id": 451,
        "no_speech_prob": 0.00003120163455605507,
        "seek": 220784,
        "start": 2210.6400000000003,
        "temperature": 0,
        "text": " And in that case, there are other ways",
        "tokens": [
          50504,
          400,
          294,
          300,
          1389,
          11,
          456,
          366,
          661,
          2098,
          50583
        ]
      },
      {
        "avg_logprob": -0.24073711661405342,
        "compression_ratio": 1.7058823529411764,
        "end": 2214.56,
        "id": 452,
        "no_speech_prob": 0.00003120163455605507,
        "seek": 220784,
        "start": 2212.2200000000003,
        "temperature": 0,
        "text": " to get around it or fix it.",
        "tokens": [
          50583,
          281,
          483,
          926,
          309,
          420,
          3191,
          309,
          13,
          50700
        ]
      },
      {
        "avg_logprob": -0.24073711661405342,
        "compression_ratio": 1.7058823529411764,
        "end": 2217.32,
        "id": 453,
        "no_speech_prob": 0.00003120163455605507,
        "seek": 220784,
        "start": 2214.56,
        "temperature": 0,
        "text": " But in this case, we are going to use",
        "tokens": [
          50700,
          583,
          294,
          341,
          1389,
          11,
          321,
          366,
          516,
          281,
          764,
          50838
        ]
      },
      {
        "avg_logprob": -0.24073711661405342,
        "compression_ratio": 1.7058823529411764,
        "end": 2219.36,
        "id": 454,
        "no_speech_prob": 0.00003120163455605507,
        "seek": 220784,
        "start": 2217.32,
        "temperature": 0,
        "text": " a package on the back end which will automatically",
        "tokens": [
          50838,
          257,
          7372,
          322,
          264,
          646,
          917,
          597,
          486,
          6772,
          50940
        ]
      },
      {
        "avg_logprob": -0.24073711661405342,
        "compression_ratio": 1.7058823529411764,
        "end": 2222.28,
        "id": 455,
        "no_speech_prob": 0.00003120163455605507,
        "seek": 220784,
        "start": 2219.36,
        "temperature": 0,
        "text": " add this header, this access control allow origin header.",
        "tokens": [
          50940,
          909,
          341,
          23117,
          11,
          341,
          2105,
          1969,
          2089,
          4957,
          23117,
          13,
          51086
        ]
      },
      {
        "avg_logprob": -0.24073711661405342,
        "compression_ratio": 1.7058823529411764,
        "end": 2228.44,
        "id": 456,
        "no_speech_prob": 0.00003120163455605507,
        "seek": 220784,
        "start": 2222.28,
        "temperature": 0,
        "text": " So in our server folder here, I'm going to install cores.",
        "tokens": [
          51086,
          407,
          294,
          527,
          7154,
          10820,
          510,
          11,
          286,
          478,
          516,
          281,
          3625,
          24826,
          13,
          51394
        ]
      },
      {
        "avg_logprob": -0.24073711661405342,
        "compression_ratio": 1.7058823529411764,
        "end": 2232.92,
        "id": 457,
        "no_speech_prob": 0.00003120163455605507,
        "seek": 220784,
        "start": 2228.44,
        "temperature": 0,
        "text": " So this is a npm package, which is an Express middleware.",
        "tokens": [
          51394,
          407,
          341,
          307,
          257,
          297,
          14395,
          7372,
          11,
          597,
          307,
          364,
          20212,
          2808,
          3039,
          13,
          51618
        ]
      },
      {
        "avg_logprob": -0.24073711661405342,
        "compression_ratio": 1.7058823529411764,
        "end": 2237,
        "id": 458,
        "no_speech_prob": 0.00003120163455605507,
        "seek": 220784,
        "start": 2232.92,
        "temperature": 0,
        "text": " And then in our server side, so first, before we move on,",
        "tokens": [
          51618,
          400,
          550,
          294,
          527,
          7154,
          1252,
          11,
          370,
          700,
          11,
          949,
          321,
          1286,
          322,
          11,
          51822
        ]
      },
      {
        "avg_logprob": -0.2461581616788297,
        "compression_ratio": 1.8407407407407408,
        "end": 2239.4,
        "id": 459,
        "no_speech_prob": 0.000040694474591873586,
        "seek": 223700,
        "start": 2237.16,
        "temperature": 0,
        "text": " let's clarify where we are.",
        "tokens": [
          50372,
          718,
          311,
          17594,
          689,
          321,
          366,
          13,
          50484
        ]
      },
      {
        "avg_logprob": -0.2461581616788297,
        "compression_ratio": 1.8407407407407408,
        "end": 2241.16,
        "id": 460,
        "no_speech_prob": 0.000040694474591873586,
        "seek": 223700,
        "start": 2239.4,
        "temperature": 0,
        "text": " See the cores error revel in this moment.",
        "tokens": [
          50484,
          3008,
          264,
          24826,
          6713,
          15262,
          294,
          341,
          1623,
          13,
          50572
        ]
      },
      {
        "avg_logprob": -0.2461581616788297,
        "compression_ratio": 1.8407407407407408,
        "end": 2242.4,
        "id": 461,
        "no_speech_prob": 0.000040694474591873586,
        "seek": 223700,
        "start": 2241.16,
        "temperature": 0,
        "text": " You'll see this error a lot.",
        "tokens": [
          50572,
          509,
          603,
          536,
          341,
          6713,
          257,
          688,
          13,
          50634
        ]
      },
      {
        "avg_logprob": -0.2461581616788297,
        "compression_ratio": 1.8407407407407408,
        "end": 2243.9,
        "id": 462,
        "no_speech_prob": 0.000040694474591873586,
        "seek": 223700,
        "start": 2242.4,
        "temperature": 0,
        "text": " There are different ways to fix it.",
        "tokens": [
          50634,
          821,
          366,
          819,
          2098,
          281,
          3191,
          309,
          13,
          50709
        ]
      },
      {
        "avg_logprob": -0.2461581616788297,
        "compression_ratio": 1.8407407407407408,
        "end": 2246.2,
        "id": 463,
        "no_speech_prob": 0.000040694474591873586,
        "seek": 223700,
        "start": 2243.9,
        "temperature": 0,
        "text": " But specifically, if you're in control of the server,",
        "tokens": [
          50709,
          583,
          4682,
          11,
          498,
          291,
          434,
          294,
          1969,
          295,
          264,
          7154,
          11,
          50824
        ]
      },
      {
        "avg_logprob": -0.2461581616788297,
        "compression_ratio": 1.8407407407407408,
        "end": 2247.52,
        "id": 464,
        "no_speech_prob": 0.000040694474591873586,
        "seek": 223700,
        "start": 2246.2,
        "temperature": 0,
        "text": " you can install the cores module.",
        "tokens": [
          50824,
          291,
          393,
          3625,
          264,
          24826,
          10088,
          13,
          50890
        ]
      },
      {
        "avg_logprob": -0.2461581616788297,
        "compression_ratio": 1.8407407407407408,
        "end": 2249.16,
        "id": 465,
        "no_speech_prob": 0.000040694474591873586,
        "seek": 223700,
        "start": 2247.52,
        "temperature": 0,
        "text": " So we saw it.",
        "tokens": [
          50890,
          407,
          321,
          1866,
          309,
          13,
          50972
        ]
      },
      {
        "avg_logprob": -0.2461581616788297,
        "compression_ratio": 1.8407407407407408,
        "end": 2249.92,
        "id": 466,
        "no_speech_prob": 0.000040694474591873586,
        "seek": 223700,
        "start": 2249.16,
        "temperature": 0,
        "text": " We recognized it.",
        "tokens": [
          50972,
          492,
          9823,
          309,
          13,
          51010
        ]
      },
      {
        "avg_logprob": -0.2461581616788297,
        "compression_ratio": 1.8407407407407408,
        "end": 2251.62,
        "id": 467,
        "no_speech_prob": 0.000040694474591873586,
        "seek": 223700,
        "start": 2249.92,
        "temperature": 0,
        "text": " We remembered pretty much how to fix it",
        "tokens": [
          51010,
          492,
          13745,
          1238,
          709,
          577,
          281,
          3191,
          309,
          51095
        ]
      },
      {
        "avg_logprob": -0.2461581616788297,
        "compression_ratio": 1.8407407407407408,
        "end": 2253.4,
        "id": 468,
        "no_speech_prob": 0.000040694474591873586,
        "seek": 223700,
        "start": 2251.62,
        "temperature": 0,
        "text": " if we're in control of the server.",
        "tokens": [
          51095,
          498,
          321,
          434,
          294,
          1969,
          295,
          264,
          7154,
          13,
          51184
        ]
      },
      {
        "avg_logprob": -0.2461581616788297,
        "compression_ratio": 1.8407407407407408,
        "end": 2254.36,
        "id": 469,
        "no_speech_prob": 0.000040694474591873586,
        "seek": 223700,
        "start": 2253.4,
        "temperature": 0,
        "text": " That was the front end.",
        "tokens": [
          51184,
          663,
          390,
          264,
          1868,
          917,
          13,
          51232
        ]
      },
      {
        "avg_logprob": -0.2461581616788297,
        "compression_ratio": 1.8407407407407408,
        "end": 2256.68,
        "id": 470,
        "no_speech_prob": 0.000040694474591873586,
        "seek": 223700,
        "start": 2254.36,
        "temperature": 0,
        "text": " We were working on code here that's",
        "tokens": [
          51232,
          492,
          645,
          1364,
          322,
          3089,
          510,
          300,
          311,
          51348
        ]
      },
      {
        "avg_logprob": -0.2461581616788297,
        "compression_ratio": 1.8407407407407408,
        "end": 2258.2,
        "id": 471,
        "no_speech_prob": 0.000040694474591873586,
        "seek": 223700,
        "start": 2256.68,
        "temperature": 0,
        "text": " sending data to the server.",
        "tokens": [
          51348,
          7750,
          1412,
          281,
          264,
          7154,
          13,
          51424
        ]
      },
      {
        "avg_logprob": -0.2461581616788297,
        "compression_ratio": 1.8407407407407408,
        "end": 2261.56,
        "id": 472,
        "no_speech_prob": 0.000040694474591873586,
        "seek": 223700,
        "start": 2258.2,
        "temperature": 0,
        "text": " And now, we're going to transition back to the back end.",
        "tokens": [
          51424,
          400,
          586,
          11,
          321,
          434,
          516,
          281,
          6034,
          646,
          281,
          264,
          646,
          917,
          13,
          51592
        ]
      },
      {
        "avg_logprob": -0.2461581616788297,
        "compression_ratio": 1.8407407407407408,
        "end": 2265.16,
        "id": 473,
        "no_speech_prob": 0.000040694474591873586,
        "seek": 223700,
        "start": 2261.56,
        "temperature": 0,
        "text": " So we installed cores.",
        "tokens": [
          51592,
          407,
          321,
          8899,
          24826,
          13,
          51772
        ]
      },
      {
        "avg_logprob": -0.2362477693626349,
        "compression_ratio": 1.7640449438202248,
        "end": 2267.2,
        "id": 474,
        "no_speech_prob": 0.0001159179737442173,
        "seek": 226516,
        "start": 2265.16,
        "temperature": 0,
        "text": " And now, let's use it.",
        "tokens": [
          50364,
          400,
          586,
          11,
          718,
          311,
          764,
          309,
          13,
          50466
        ]
      },
      {
        "avg_logprob": -0.2362477693626349,
        "compression_ratio": 1.7640449438202248,
        "end": 2272.48,
        "id": 475,
        "no_speech_prob": 0.0001159179737442173,
        "seek": 226516,
        "start": 2267.2,
        "temperature": 0,
        "text": " So the way this works is I can bring in the cores module",
        "tokens": [
          50466,
          407,
          264,
          636,
          341,
          1985,
          307,
          286,
          393,
          1565,
          294,
          264,
          24826,
          10088,
          50730
        ]
      },
      {
        "avg_logprob": -0.2362477693626349,
        "compression_ratio": 1.7640449438202248,
        "end": 2275.12,
        "id": 476,
        "no_speech_prob": 0.0001159179737442173,
        "seek": 226516,
        "start": 2272.48,
        "temperature": 0,
        "text": " and then do what's called using it.",
        "tokens": [
          50730,
          293,
          550,
          360,
          437,
          311,
          1219,
          1228,
          309,
          13,
          50862
        ]
      },
      {
        "avg_logprob": -0.2362477693626349,
        "compression_ratio": 1.7640449438202248,
        "end": 2277.3999999999996,
        "id": 477,
        "no_speech_prob": 0.0001159179737442173,
        "seek": 226516,
        "start": 2275.12,
        "temperature": 0,
        "text": " So I'll say app.use cores.",
        "tokens": [
          50862,
          407,
          286,
          603,
          584,
          724,
          13,
          438,
          24826,
          13,
          50976
        ]
      },
      {
        "avg_logprob": -0.2362477693626349,
        "compression_ratio": 1.7640449438202248,
        "end": 2279.64,
        "id": 478,
        "no_speech_prob": 0.0001159179737442173,
        "seek": 226516,
        "start": 2277.3999999999996,
        "temperature": 0,
        "text": " And this actually adds cores as a middleware.",
        "tokens": [
          50976,
          400,
          341,
          767,
          10860,
          24826,
          382,
          257,
          2808,
          3039,
          13,
          51088
        ]
      },
      {
        "avg_logprob": -0.2362477693626349,
        "compression_ratio": 1.7640449438202248,
        "end": 2281.92,
        "id": 479,
        "no_speech_prob": 0.0001159179737442173,
        "seek": 226516,
        "start": 2279.64,
        "temperature": 0,
        "text": " So now, any incoming request to my server",
        "tokens": [
          51088,
          407,
          586,
          11,
          604,
          22341,
          5308,
          281,
          452,
          7154,
          51202
        ]
      },
      {
        "avg_logprob": -0.2362477693626349,
        "compression_ratio": 1.7640449438202248,
        "end": 2283.64,
        "id": 480,
        "no_speech_prob": 0.0001159179737442173,
        "seek": 226516,
        "start": 2281.92,
        "temperature": 0,
        "text": " is going to pass through this middleware,",
        "tokens": [
          51202,
          307,
          516,
          281,
          1320,
          807,
          341,
          2808,
          3039,
          11,
          51288
        ]
      },
      {
        "avg_logprob": -0.2362477693626349,
        "compression_ratio": 1.7640449438202248,
        "end": 2286.92,
        "id": 481,
        "no_speech_prob": 0.0001159179737442173,
        "seek": 226516,
        "start": 2283.64,
        "temperature": 0,
        "text": " and it's going to automatically add those cores headers to it.",
        "tokens": [
          51288,
          293,
          309,
          311,
          516,
          281,
          6772,
          909,
          729,
          24826,
          45101,
          281,
          309,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.2362477693626349,
        "compression_ratio": 1.7640449438202248,
        "end": 2289,
        "id": 482,
        "no_speech_prob": 0.0001159179737442173,
        "seek": 226516,
        "start": 2286.92,
        "temperature": 0,
        "text": " So this should get rid of that error.",
        "tokens": [
          51452,
          407,
          341,
          820,
          483,
          3973,
          295,
          300,
          6713,
          13,
          51556
        ]
      },
      {
        "avg_logprob": -0.2362477693626349,
        "compression_ratio": 1.7640449438202248,
        "end": 2291.16,
        "id": 483,
        "no_speech_prob": 0.0001159179737442173,
        "seek": 226516,
        "start": 2289,
        "temperature": 0,
        "text": " And then we'll see if we're actually logging out",
        "tokens": [
          51556,
          400,
          550,
          321,
          603,
          536,
          498,
          321,
          434,
          767,
          27991,
          484,
          51664
        ]
      },
      {
        "avg_logprob": -0.2362477693626349,
        "compression_ratio": 1.7640449438202248,
        "end": 2292.6,
        "id": 484,
        "no_speech_prob": 0.0001159179737442173,
        "seek": 226516,
        "start": 2291.16,
        "temperature": 0,
        "text": " what the client is sending us.",
        "tokens": [
          51664,
          437,
          264,
          6423,
          307,
          7750,
          505,
          13,
          51736
        ]
      },
      {
        "avg_logprob": -0.2362477693626349,
        "compression_ratio": 1.7640449438202248,
        "end": 2294.24,
        "id": 485,
        "no_speech_prob": 0.0001159179737442173,
        "seek": 226516,
        "start": 2292.6,
        "temperature": 0,
        "text": " So we'll go back.",
        "tokens": [
          51736,
          407,
          321,
          603,
          352,
          646,
          13,
          51818
        ]
      },
      {
        "avg_logprob": -0.25683126831054687,
        "compression_ratio": 1.6638655462184875,
        "end": 2296.3199999999997,
        "id": 486,
        "no_speech_prob": 0.0000025612573608668754,
        "seek": 229424,
        "start": 2294.2799999999997,
        "temperature": 0,
        "text": " We'll try again.",
        "tokens": [
          50366,
          492,
          603,
          853,
          797,
          13,
          50468
        ]
      },
      {
        "avg_logprob": -0.25683126831054687,
        "compression_ratio": 1.6638655462184875,
        "end": 2297.64,
        "id": 487,
        "no_speech_prob": 0.0000025612573608668754,
        "seek": 229424,
        "start": 2296.3199999999997,
        "temperature": 0,
        "text": " My name is CJ.",
        "tokens": [
          50468,
          1222,
          1315,
          307,
          42285,
          13,
          50534
        ]
      },
      {
        "avg_logprob": -0.25683126831054687,
        "compression_ratio": 1.6638655462184875,
        "end": 2299.72,
        "id": 488,
        "no_speech_prob": 0.0000025612573608668754,
        "seek": 229424,
        "start": 2297.64,
        "temperature": 0,
        "text": " My mu is hello, world.",
        "tokens": [
          50534,
          1222,
          2992,
          307,
          7751,
          11,
          1002,
          13,
          50638
        ]
      },
      {
        "avg_logprob": -0.25683126831054687,
        "compression_ratio": 1.6638655462184875,
        "end": 2301,
        "id": 489,
        "no_speech_prob": 0.0000025612573608668754,
        "seek": 229424,
        "start": 2299.72,
        "temperature": 0,
        "text": " We'll send it.",
        "tokens": [
          50638,
          492,
          603,
          2845,
          309,
          13,
          50702
        ]
      },
      {
        "avg_logprob": -0.25683126831054687,
        "compression_ratio": 1.6638655462184875,
        "end": 2302.3999999999996,
        "id": 490,
        "no_speech_prob": 0.0000025612573608668754,
        "seek": 229424,
        "start": 2301,
        "temperature": 0,
        "text": " And we see undefined.",
        "tokens": [
          50702,
          400,
          321,
          536,
          674,
          5666,
          2001,
          13,
          50772
        ]
      },
      {
        "avg_logprob": -0.25683126831054687,
        "compression_ratio": 1.6638655462184875,
        "end": 2304.9599999999996,
        "id": 491,
        "no_speech_prob": 0.0000025612573608668754,
        "seek": 229424,
        "start": 2302.3999999999996,
        "temperature": 0,
        "text": " So another thing that you have to do on the server side",
        "tokens": [
          50772,
          407,
          1071,
          551,
          300,
          291,
          362,
          281,
          360,
          322,
          264,
          7154,
          1252,
          50900
        ]
      },
      {
        "avg_logprob": -0.25683126831054687,
        "compression_ratio": 1.6638655462184875,
        "end": 2308.64,
        "id": 492,
        "no_speech_prob": 0.0000025612573608668754,
        "seek": 229424,
        "start": 2304.9599999999996,
        "temperature": 0,
        "text": " is add a middleware that's going to parse incoming data.",
        "tokens": [
          50900,
          307,
          909,
          257,
          2808,
          3039,
          300,
          311,
          516,
          281,
          48377,
          22341,
          1412,
          13,
          51084
        ]
      },
      {
        "avg_logprob": -0.25683126831054687,
        "compression_ratio": 1.6638655462184875,
        "end": 2310.7599999999998,
        "id": 493,
        "no_speech_prob": 0.0000025612573608668754,
        "seek": 229424,
        "start": 2308.64,
        "temperature": 0,
        "text": " So right now, in the client, we can",
        "tokens": [
          51084,
          407,
          558,
          586,
          11,
          294,
          264,
          6423,
          11,
          321,
          393,
          51190
        ]
      },
      {
        "avg_logprob": -0.25683126831054687,
        "compression_ratio": 1.6638655462184875,
        "end": 2316.7999999999997,
        "id": 494,
        "no_speech_prob": 0.0000025612573608668754,
        "seek": 229424,
        "start": 2310.7599999999998,
        "temperature": 0,
        "text": " see on network that this post request is attempting to happen.",
        "tokens": [
          51190,
          536,
          322,
          3209,
          300,
          341,
          2183,
          5308,
          307,
          22001,
          281,
          1051,
          13,
          51492
        ]
      },
      {
        "avg_logprob": -0.25683126831054687,
        "compression_ratio": 1.6638655462184875,
        "end": 2318.9199999999996,
        "id": 495,
        "no_speech_prob": 0.0000025612573608668754,
        "seek": 229424,
        "start": 2316.7999999999997,
        "temperature": 0,
        "text": " So it's making a request here.",
        "tokens": [
          51492,
          407,
          309,
          311,
          1455,
          257,
          5308,
          510,
          13,
          51598
        ]
      },
      {
        "avg_logprob": -0.25683126831054687,
        "compression_ratio": 1.6638655462184875,
        "end": 2320.8399999999997,
        "id": 496,
        "no_speech_prob": 0.0000025612573608668754,
        "seek": 229424,
        "start": 2318.9199999999996,
        "temperature": 0,
        "text": " It's sending this data.",
        "tokens": [
          51598,
          467,
          311,
          7750,
          341,
          1412,
          13,
          51694
        ]
      },
      {
        "avg_logprob": -0.25683126831054687,
        "compression_ratio": 1.6638655462184875,
        "end": 2322.3399999999997,
        "id": 497,
        "no_speech_prob": 0.0000025612573608668754,
        "seek": 229424,
        "start": 2320.8399999999997,
        "temperature": 0,
        "text": " So we are sending it from the client,",
        "tokens": [
          51694,
          407,
          321,
          366,
          7750,
          309,
          490,
          264,
          6423,
          11,
          51769
        ]
      },
      {
        "avg_logprob": -0.24299779145613962,
        "compression_ratio": 1.68,
        "end": 2324.94,
        "id": 498,
        "no_speech_prob": 0.00007843751518521458,
        "seek": 232234,
        "start": 2322.44,
        "temperature": 0,
        "text": " but the server can't process it.",
        "tokens": [
          50369,
          457,
          264,
          7154,
          393,
          380,
          1399,
          309,
          13,
          50494
        ]
      },
      {
        "avg_logprob": -0.24299779145613962,
        "compression_ratio": 1.68,
        "end": 2328.34,
        "id": 499,
        "no_speech_prob": 0.00007843751518521458,
        "seek": 232234,
        "start": 2324.94,
        "temperature": 0,
        "text": " So for this, we actually need to add the body parser middleware.",
        "tokens": [
          50494,
          407,
          337,
          341,
          11,
          321,
          767,
          643,
          281,
          909,
          264,
          1772,
          21156,
          260,
          2808,
          3039,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.24299779145613962,
        "compression_ratio": 1.68,
        "end": 2329.6200000000003,
        "id": 500,
        "no_speech_prob": 0.00007843751518521458,
        "seek": 232234,
        "start": 2328.34,
        "temperature": 0,
        "text": " And this is built into Express.",
        "tokens": [
          50664,
          400,
          341,
          307,
          3094,
          666,
          20212,
          13,
          50728
        ]
      },
      {
        "avg_logprob": -0.24299779145613962,
        "compression_ratio": 1.68,
        "end": 2334.02,
        "id": 501,
        "no_speech_prob": 0.00007843751518521458,
        "seek": 232234,
        "start": 2329.6200000000003,
        "temperature": 0,
        "text": " So I can use express.json.",
        "tokens": [
          50728,
          407,
          286,
          393,
          764,
          5109,
          13,
          73,
          3015,
          13,
          50948
        ]
      },
      {
        "avg_logprob": -0.24299779145613962,
        "compression_ratio": 1.68,
        "end": 2338.9,
        "id": 502,
        "no_speech_prob": 0.00007843751518521458,
        "seek": 232234,
        "start": 2334.02,
        "temperature": 0,
        "text": " And this is a JSON body parser.",
        "tokens": [
          50948,
          400,
          341,
          307,
          257,
          31828,
          1772,
          21156,
          260,
          13,
          51192
        ]
      },
      {
        "avg_logprob": -0.24299779145613962,
        "compression_ratio": 1.68,
        "end": 2344.34,
        "id": 503,
        "no_speech_prob": 0.00007843751518521458,
        "seek": 232234,
        "start": 2338.9,
        "temperature": 0,
        "text": " So any incoming request that has a content type of application",
        "tokens": [
          51192,
          407,
          604,
          22341,
          5308,
          300,
          575,
          257,
          2701,
          2010,
          295,
          3861,
          51464
        ]
      },
      {
        "avg_logprob": -0.24299779145613962,
        "compression_ratio": 1.68,
        "end": 2346.1000000000004,
        "id": 504,
        "no_speech_prob": 0.00007843751518521458,
        "seek": 232234,
        "start": 2344.34,
        "temperature": 0,
        "text": " JSON will be parsed by this middleware",
        "tokens": [
          51464,
          31828,
          486,
          312,
          21156,
          292,
          538,
          341,
          2808,
          3039,
          51552
        ]
      },
      {
        "avg_logprob": -0.24299779145613962,
        "compression_ratio": 1.68,
        "end": 2347.1400000000003,
        "id": 505,
        "no_speech_prob": 0.00007843751518521458,
        "seek": 232234,
        "start": 2346.1000000000004,
        "temperature": 0,
        "text": " and then put on the body.",
        "tokens": [
          51552,
          293,
          550,
          829,
          322,
          264,
          1772,
          13,
          51604
        ]
      },
      {
        "avg_logprob": -0.24299779145613962,
        "compression_ratio": 1.68,
        "end": 2350.26,
        "id": 506,
        "no_speech_prob": 0.00007843751518521458,
        "seek": 232234,
        "start": 2347.1400000000003,
        "temperature": 0,
        "text": " So now, we actually should get access to rec.body.",
        "tokens": [
          51604,
          407,
          586,
          11,
          321,
          767,
          820,
          483,
          2105,
          281,
          850,
          13,
          1067,
          13,
          51760
        ]
      },
      {
        "avg_logprob": -0.24299779145613962,
        "compression_ratio": 1.68,
        "end": 2351.54,
        "id": 507,
        "no_speech_prob": 0.00007843751518521458,
        "seek": 232234,
        "start": 2350.26,
        "temperature": 0,
        "text": " Let's try.",
        "tokens": [
          51760,
          961,
          311,
          853,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.27281434195382254,
        "compression_ratio": 1.6502057613168724,
        "end": 2355.14,
        "id": 508,
        "no_speech_prob": 0.000025071478376048617,
        "seek": 235154,
        "start": 2351.58,
        "temperature": 0,
        "text": " So name is cj, mu is hello, world.",
        "tokens": [
          50366,
          407,
          1315,
          307,
          269,
          73,
          11,
          2992,
          307,
          7751,
          11,
          1002,
          13,
          50544
        ]
      },
      {
        "avg_logprob": -0.27281434195382254,
        "compression_ratio": 1.6502057613168724,
        "end": 2356.58,
        "id": 509,
        "no_speech_prob": 0.000025071478376048617,
        "seek": 235154,
        "start": 2355.14,
        "temperature": 0,
        "text": " We're going to add a cat here.",
        "tokens": [
          50544,
          492,
          434,
          516,
          281,
          909,
          257,
          3857,
          510,
          13,
          50616
        ]
      },
      {
        "avg_logprob": -0.27281434195382254,
        "compression_ratio": 1.6502057613168724,
        "end": 2358.2599999999998,
        "id": 510,
        "no_speech_prob": 0.000025071478376048617,
        "seek": 235154,
        "start": 2356.58,
        "temperature": 0,
        "text": " Oh, not that cat.",
        "tokens": [
          50616,
          876,
          11,
          406,
          300,
          3857,
          13,
          50700
        ]
      },
      {
        "avg_logprob": -0.27281434195382254,
        "compression_ratio": 1.6502057613168724,
        "end": 2359.06,
        "id": 511,
        "no_speech_prob": 0.000025071478376048617,
        "seek": 235154,
        "start": 2358.2599999999998,
        "temperature": 0,
        "text": " Cat.",
        "tokens": [
          50700,
          9565,
          13,
          50740
        ]
      },
      {
        "avg_logprob": -0.27281434195382254,
        "compression_ratio": 1.6502057613168724,
        "end": 2359.94,
        "id": 512,
        "no_speech_prob": 0.000025071478376048617,
        "seek": 235154,
        "start": 2359.06,
        "temperature": 0,
        "text": " Go.",
        "tokens": [
          50740,
          1037,
          13,
          50784
        ]
      },
      {
        "avg_logprob": -0.27281434195382254,
        "compression_ratio": 1.6502057613168724,
        "end": 2362.1,
        "id": 513,
        "no_speech_prob": 0.000025071478376048617,
        "seek": 235154,
        "start": 2359.94,
        "temperature": 0,
        "text": " And notice, the server is now receiving the data.",
        "tokens": [
          50784,
          400,
          3449,
          11,
          264,
          7154,
          307,
          586,
          10040,
          264,
          1412,
          13,
          50892
        ]
      },
      {
        "avg_logprob": -0.27281434195382254,
        "compression_ratio": 1.6502057613168724,
        "end": 2366.2599999999998,
        "id": 514,
        "no_speech_prob": 0.000025071478376048617,
        "seek": 235154,
        "start": 2362.1,
        "temperature": 0,
        "text": " So the client, the user types in their information.",
        "tokens": [
          50892,
          407,
          264,
          6423,
          11,
          264,
          4195,
          3467,
          294,
          641,
          1589,
          13,
          51100
        ]
      },
      {
        "avg_logprob": -0.27281434195382254,
        "compression_ratio": 1.6502057613168724,
        "end": 2367.46,
        "id": 515,
        "no_speech_prob": 0.000025071478376048617,
        "seek": 235154,
        "start": 2366.2599999999998,
        "temperature": 0,
        "text": " They click the Submit button.",
        "tokens": [
          51100,
          814,
          2052,
          264,
          8511,
          3508,
          2960,
          13,
          51160
        ]
      },
      {
        "avg_logprob": -0.27281434195382254,
        "compression_ratio": 1.6502057613168724,
        "end": 2368.62,
        "id": 516,
        "no_speech_prob": 0.000025071478376048617,
        "seek": 235154,
        "start": 2367.46,
        "temperature": 0,
        "text": " It gets sent to the server.",
        "tokens": [
          51160,
          467,
          2170,
          2279,
          281,
          264,
          7154,
          13,
          51218
        ]
      },
      {
        "avg_logprob": -0.27281434195382254,
        "compression_ratio": 1.6502057613168724,
        "end": 2372.38,
        "id": 517,
        "no_speech_prob": 0.000025071478376048617,
        "seek": 235154,
        "start": 2368.62,
        "temperature": 0,
        "text": " And now, the server has to actually do something with it.",
        "tokens": [
          51218,
          400,
          586,
          11,
          264,
          7154,
          575,
          281,
          767,
          360,
          746,
          365,
          309,
          13,
          51406
        ]
      },
      {
        "avg_logprob": -0.27281434195382254,
        "compression_ratio": 1.6502057613168724,
        "end": 2375.7799999999997,
        "id": 518,
        "no_speech_prob": 0.000025071478376048617,
        "seek": 235154,
        "start": 2372.38,
        "temperature": 0,
        "text": " So let's look at our checklist.",
        "tokens": [
          51406,
          407,
          718,
          311,
          574,
          412,
          527,
          30357,
          13,
          51576
        ]
      },
      {
        "avg_logprob": -0.27281434195382254,
        "compression_ratio": 1.6502057613168724,
        "end": 2378.18,
        "id": 519,
        "no_speech_prob": 0.000025071478376048617,
        "seek": 235154,
        "start": 2375.7799999999997,
        "temperature": 0,
        "text": " We have made sure that we're actually receiving that data.",
        "tokens": [
          51576,
          492,
          362,
          1027,
          988,
          300,
          321,
          434,
          767,
          10040,
          300,
          1412,
          13,
          51696
        ]
      },
      {
        "avg_logprob": -0.2361433656065614,
        "compression_ratio": 1.8076923076923077,
        "end": 2381.62,
        "id": 520,
        "no_speech_prob": 0.00033015027293004096,
        "seek": 237818,
        "start": 2378.66,
        "temperature": 0,
        "text": " The moment I press this Submit button,",
        "tokens": [
          50388,
          440,
          1623,
          286,
          1886,
          341,
          8511,
          3508,
          2960,
          11,
          50536
        ]
      },
      {
        "avg_logprob": -0.2361433656065614,
        "compression_ratio": 1.8076923076923077,
        "end": 2382.74,
        "id": 521,
        "no_speech_prob": 0.00033015027293004096,
        "seek": 237818,
        "start": 2381.62,
        "temperature": 0,
        "text": " the server is receiving it.",
        "tokens": [
          50536,
          264,
          7154,
          307,
          10040,
          309,
          13,
          50592
        ]
      },
      {
        "avg_logprob": -0.2361433656065614,
        "compression_ratio": 1.8076923076923077,
        "end": 2384.18,
        "id": 522,
        "no_speech_prob": 0.00033015027293004096,
        "seek": 237818,
        "start": 2382.74,
        "temperature": 0,
        "text": " So I can try again.",
        "tokens": [
          50592,
          407,
          286,
          393,
          853,
          797,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2361433656065614,
        "compression_ratio": 1.8076923076923077,
        "end": 2385.2999999999997,
        "id": 523,
        "no_speech_prob": 0.00033015027293004096,
        "seek": 237818,
        "start": 2384.18,
        "temperature": 0,
        "text": " What?",
        "tokens": [
          50664,
          708,
          30,
          50720
        ]
      },
      {
        "avg_logprob": -0.2361433656065614,
        "compression_ratio": 1.8076923076923077,
        "end": 2387.06,
        "id": 524,
        "no_speech_prob": 0.00033015027293004096,
        "seek": 237818,
        "start": 2385.2999999999997,
        "temperature": 0,
        "text": " And the server is actually receiving that.",
        "tokens": [
          50720,
          400,
          264,
          7154,
          307,
          767,
          10040,
          300,
          13,
          50808
        ]
      },
      {
        "avg_logprob": -0.2361433656065614,
        "compression_ratio": 1.8076923076923077,
        "end": 2388.46,
        "id": 525,
        "no_speech_prob": 0.00033015027293004096,
        "seek": 237818,
        "start": 2387.06,
        "temperature": 0,
        "text": " So we're taking it from the client",
        "tokens": [
          50808,
          407,
          321,
          434,
          1940,
          309,
          490,
          264,
          6423,
          50878
        ]
      },
      {
        "avg_logprob": -0.2361433656065614,
        "compression_ratio": 1.8076923076923077,
        "end": 2391.46,
        "id": 526,
        "no_speech_prob": 0.00033015027293004096,
        "seek": 237818,
        "start": 2388.46,
        "temperature": 0,
        "text": " and sending it to the server.",
        "tokens": [
          50878,
          293,
          7750,
          309,
          281,
          264,
          7154,
          13,
          51028
        ]
      },
      {
        "avg_logprob": -0.2361433656065614,
        "compression_ratio": 1.8076923076923077,
        "end": 2392.98,
        "id": 527,
        "no_speech_prob": 0.00033015027293004096,
        "seek": 237818,
        "start": 2391.46,
        "temperature": 0,
        "text": " So we added our middleware.",
        "tokens": [
          51028,
          407,
          321,
          3869,
          527,
          2808,
          3039,
          13,
          51104
        ]
      },
      {
        "avg_logprob": -0.2361433656065614,
        "compression_ratio": 1.8076923076923077,
        "end": 2395.66,
        "id": 528,
        "no_speech_prob": 0.00033015027293004096,
        "seek": 237818,
        "start": 2392.98,
        "temperature": 0,
        "text": " And now, we can process this incoming request.",
        "tokens": [
          51104,
          400,
          586,
          11,
          321,
          393,
          1399,
          341,
          22341,
          5308,
          13,
          51238
        ]
      },
      {
        "avg_logprob": -0.2361433656065614,
        "compression_ratio": 1.8076923076923077,
        "end": 2397.7,
        "id": 529,
        "no_speech_prob": 0.00033015027293004096,
        "seek": 237818,
        "start": 2395.66,
        "temperature": 0,
        "text": " So on the server side, we actually",
        "tokens": [
          51238,
          407,
          322,
          264,
          7154,
          1252,
          11,
          321,
          767,
          51340
        ]
      },
      {
        "avg_logprob": -0.2361433656065614,
        "compression_ratio": 1.8076923076923077,
        "end": 2398.8599999999997,
        "id": 530,
        "no_speech_prob": 0.00033015027293004096,
        "seek": 237818,
        "start": 2397.7,
        "temperature": 0,
        "text": " want to do some validation.",
        "tokens": [
          51340,
          528,
          281,
          360,
          512,
          24071,
          13,
          51398
        ]
      },
      {
        "avg_logprob": -0.2361433656065614,
        "compression_ratio": 1.8076923076923077,
        "end": 2401.4199999999996,
        "id": 531,
        "no_speech_prob": 0.00033015027293004096,
        "seek": 237818,
        "start": 2398.8599999999997,
        "temperature": 0,
        "text": " We want to make sure that the client, what they're sending us",
        "tokens": [
          51398,
          492,
          528,
          281,
          652,
          988,
          300,
          264,
          6423,
          11,
          437,
          436,
          434,
          7750,
          505,
          51526
        ]
      },
      {
        "avg_logprob": -0.2361433656065614,
        "compression_ratio": 1.8076923076923077,
        "end": 2402.94,
        "id": 532,
        "no_speech_prob": 0.00033015027293004096,
        "seek": 237818,
        "start": 2401.4199999999996,
        "temperature": 0,
        "text": " has a name, has content.",
        "tokens": [
          51526,
          575,
          257,
          1315,
          11,
          575,
          2701,
          13,
          51602
        ]
      },
      {
        "avg_logprob": -0.2361433656065614,
        "compression_ratio": 1.8076923076923077,
        "end": 2407.3799999999997,
        "id": 533,
        "no_speech_prob": 0.00033015027293004096,
        "seek": 237818,
        "start": 2402.94,
        "temperature": 0,
        "text": " So let's just do, we'll say, if is valid mu.",
        "tokens": [
          51602,
          407,
          718,
          311,
          445,
          360,
          11,
          321,
          603,
          584,
          11,
          498,
          307,
          7363,
          2992,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.20521394137678475,
        "compression_ratio": 1.641025641025641,
        "end": 2410.1800000000003,
        "id": 534,
        "no_speech_prob": 0.00008749999688006938,
        "seek": 240738,
        "start": 2407.38,
        "temperature": 0,
        "text": " And we'll pass in rec.body.",
        "tokens": [
          50364,
          400,
          321,
          603,
          1320,
          294,
          850,
          13,
          1067,
          13,
          50504
        ]
      },
      {
        "avg_logprob": -0.20521394137678475,
        "compression_ratio": 1.641025641025641,
        "end": 2413.42,
        "id": 535,
        "no_speech_prob": 0.00008749999688006938,
        "seek": 240738,
        "start": 2410.1800000000003,
        "temperature": 0,
        "text": " And if it is, then we'll insert into db.",
        "tokens": [
          50504,
          400,
          498,
          309,
          307,
          11,
          550,
          321,
          603,
          8969,
          666,
          274,
          65,
          13,
          50666
        ]
      },
      {
        "avg_logprob": -0.20521394137678475,
        "compression_ratio": 1.641025641025641,
        "end": 2414.82,
        "id": 536,
        "no_speech_prob": 0.00008749999688006938,
        "seek": 240738,
        "start": 2413.42,
        "temperature": 0,
        "text": " So we'll handle that in a bit.",
        "tokens": [
          50666,
          407,
          321,
          603,
          4813,
          300,
          294,
          257,
          857,
          13,
          50736
        ]
      },
      {
        "avg_logprob": -0.20521394137678475,
        "compression_ratio": 1.641025641025641,
        "end": 2418.1,
        "id": 537,
        "no_speech_prob": 0.00008749999688006938,
        "seek": 240738,
        "start": 2414.82,
        "temperature": 0,
        "text": " But if it's not, we actually want to respond with an error.",
        "tokens": [
          50736,
          583,
          498,
          309,
          311,
          406,
          11,
          321,
          767,
          528,
          281,
          4196,
          365,
          364,
          6713,
          13,
          50900
        ]
      },
      {
        "avg_logprob": -0.20521394137678475,
        "compression_ratio": 1.641025641025641,
        "end": 2420.4,
        "id": 538,
        "no_speech_prob": 0.00008749999688006938,
        "seek": 240738,
        "start": 2418.1,
        "temperature": 0,
        "text": " Right now, my client side, technically,",
        "tokens": [
          50900,
          1779,
          586,
          11,
          452,
          6423,
          1252,
          11,
          12120,
          11,
          51015
        ]
      },
      {
        "avg_logprob": -0.20521394137678475,
        "compression_ratio": 1.641025641025641,
        "end": 2421.82,
        "id": 539,
        "no_speech_prob": 0.00008749999688006938,
        "seek": 240738,
        "start": 2420.4,
        "temperature": 0,
        "text": " you could click that Submit button",
        "tokens": [
          51015,
          291,
          727,
          2052,
          300,
          8511,
          3508,
          2960,
          51086
        ]
      },
      {
        "avg_logprob": -0.20521394137678475,
        "compression_ratio": 1.641025641025641,
        "end": 2422.94,
        "id": 540,
        "no_speech_prob": 0.00008749999688006938,
        "seek": 240738,
        "start": 2421.82,
        "temperature": 0,
        "text": " without typing anything in.",
        "tokens": [
          51086,
          1553,
          18444,
          1340,
          294,
          13,
          51142
        ]
      },
      {
        "avg_logprob": -0.20521394137678475,
        "compression_ratio": 1.641025641025641,
        "end": 2425.98,
        "id": 541,
        "no_speech_prob": 0.00008749999688006938,
        "seek": 240738,
        "start": 2422.94,
        "temperature": 0,
        "text": " So I want to protect against people just submitting",
        "tokens": [
          51142,
          407,
          286,
          528,
          281,
          2371,
          1970,
          561,
          445,
          31836,
          51294
        ]
      },
      {
        "avg_logprob": -0.20521394137678475,
        "compression_ratio": 1.641025641025641,
        "end": 2428.06,
        "id": 542,
        "no_speech_prob": 0.00008749999688006938,
        "seek": 240738,
        "start": 2425.98,
        "temperature": 0,
        "text": " blank data to the server.",
        "tokens": [
          51294,
          8247,
          1412,
          281,
          264,
          7154,
          13,
          51398
        ]
      },
      {
        "avg_logprob": -0.20521394137678475,
        "compression_ratio": 1.641025641025641,
        "end": 2431.7000000000003,
        "id": 543,
        "no_speech_prob": 0.00008749999688006938,
        "seek": 240738,
        "start": 2428.06,
        "temperature": 0,
        "text": " So here, I'm going to just do a res.status.",
        "tokens": [
          51398,
          407,
          510,
          11,
          286,
          478,
          516,
          281,
          445,
          360,
          257,
          725,
          13,
          19435,
          301,
          13,
          51580
        ]
      },
      {
        "avg_logprob": -0.20521394137678475,
        "compression_ratio": 1.641025641025641,
        "end": 2433.42,
        "id": 544,
        "no_speech_prob": 0.00008749999688006938,
        "seek": 240738,
        "start": 2431.7000000000003,
        "temperature": 0,
        "text": " I'm going to set this to 422.",
        "tokens": [
          51580,
          286,
          478,
          516,
          281,
          992,
          341,
          281,
          1017,
          7490,
          13,
          51666
        ]
      },
      {
        "avg_logprob": -0.20521394137678475,
        "compression_ratio": 1.641025641025641,
        "end": 2435.62,
        "id": 545,
        "no_speech_prob": 0.00008749999688006938,
        "seek": 240738,
        "start": 2433.42,
        "temperature": 0,
        "text": " And then here, I'll do a res.json",
        "tokens": [
          51666,
          400,
          550,
          510,
          11,
          286,
          603,
          360,
          257,
          725,
          13,
          73,
          3015,
          51776
        ]
      },
      {
        "avg_logprob": -0.23650548699196805,
        "compression_ratio": 1.5,
        "end": 2438.8199999999997,
        "id": 546,
        "no_speech_prob": 0.00011235185957048088,
        "seek": 243562,
        "start": 2435.62,
        "temperature": 0,
        "text": " and just give them a message.",
        "tokens": [
          50364,
          293,
          445,
          976,
          552,
          257,
          3636,
          13,
          50524
        ]
      },
      {
        "avg_logprob": -0.23650548699196805,
        "compression_ratio": 1.5,
        "end": 2443.9,
        "id": 547,
        "no_speech_prob": 0.00011235185957048088,
        "seek": 243562,
        "start": 2438.8199999999997,
        "temperature": 0,
        "text": " Hey, name and content are required.",
        "tokens": [
          50524,
          1911,
          11,
          1315,
          293,
          2701,
          366,
          4739,
          13,
          50778
        ]
      },
      {
        "avg_logprob": -0.23650548699196805,
        "compression_ratio": 1.5,
        "end": 2447.1,
        "id": 548,
        "no_speech_prob": 0.00011235185957048088,
        "seek": 243562,
        "start": 2446.5,
        "temperature": 0,
        "text": " Cool.",
        "tokens": [
          50908,
          8561,
          13,
          50938
        ]
      },
      {
        "avg_logprob": -0.23650548699196805,
        "compression_ratio": 1.5,
        "end": 2449.14,
        "id": 549,
        "no_speech_prob": 0.00011235185957048088,
        "seek": 243562,
        "start": 2447.1,
        "temperature": 0,
        "text": " And now, let's write this function isValidMu.",
        "tokens": [
          50938,
          400,
          586,
          11,
          718,
          311,
          2464,
          341,
          2445,
          307,
          53,
          31509,
          44,
          84,
          13,
          51040
        ]
      },
      {
        "avg_logprob": -0.23650548699196805,
        "compression_ratio": 1.5,
        "end": 2454.1,
        "id": 550,
        "no_speech_prob": 0.00011235185957048088,
        "seek": 243562,
        "start": 2449.14,
        "temperature": 0,
        "text": " So isValidMu, nope, not that, takes in,",
        "tokens": [
          51040,
          407,
          307,
          53,
          31509,
          44,
          84,
          11,
          23444,
          11,
          406,
          300,
          11,
          2516,
          294,
          11,
          51288
        ]
      },
      {
        "avg_logprob": -0.23650548699196805,
        "compression_ratio": 1.5,
        "end": 2457.14,
        "id": 551,
        "no_speech_prob": 0.00011235185957048088,
        "seek": 243562,
        "start": 2454.1,
        "temperature": 0,
        "text": " so this is a function, it takes in a mu.",
        "tokens": [
          51288,
          370,
          341,
          307,
          257,
          2445,
          11,
          309,
          2516,
          294,
          257,
          2992,
          13,
          51440
        ]
      },
      {
        "avg_logprob": -0.23650548699196805,
        "compression_ratio": 1.5,
        "end": 2461.1,
        "id": 552,
        "no_speech_prob": 0.00011235185957048088,
        "seek": 243562,
        "start": 2457.14,
        "temperature": 0,
        "text": " And we want to make sure, so if mu.name is a thing",
        "tokens": [
          51440,
          400,
          321,
          528,
          281,
          652,
          988,
          11,
          370,
          498,
          2992,
          13,
          16344,
          307,
          257,
          551,
          51638
        ]
      },
      {
        "avg_logprob": -0.2151138452383188,
        "compression_ratio": 2.0892018779342725,
        "end": 2466.02,
        "id": 553,
        "no_speech_prob": 0.0007436840096488595,
        "seek": 246110,
        "start": 2461.1,
        "temperature": 0,
        "text": " and mu.name.toString.trim, so we're",
        "tokens": [
          50364,
          293,
          2992,
          13,
          16344,
          13,
          1353,
          4520,
          2937,
          13,
          83,
          5565,
          11,
          370,
          321,
          434,
          50610
        ]
      },
      {
        "avg_logprob": -0.2151138452383188,
        "compression_ratio": 2.0892018779342725,
        "end": 2468.74,
        "id": 554,
        "no_speech_prob": 0.0007436840096488595,
        "seek": 246110,
        "start": 2466.02,
        "temperature": 0,
        "text": " going to take the name that they're sending us,",
        "tokens": [
          50610,
          516,
          281,
          747,
          264,
          1315,
          300,
          436,
          434,
          7750,
          505,
          11,
          50746
        ]
      },
      {
        "avg_logprob": -0.2151138452383188,
        "compression_ratio": 2.0892018779342725,
        "end": 2470.94,
        "id": 555,
        "no_speech_prob": 0.0007436840096488595,
        "seek": 246110,
        "start": 2468.74,
        "temperature": 0,
        "text": " make it a string, trim it to remove all white space,",
        "tokens": [
          50746,
          652,
          309,
          257,
          6798,
          11,
          10445,
          309,
          281,
          4159,
          439,
          2418,
          1901,
          11,
          50856
        ]
      },
      {
        "avg_logprob": -0.2151138452383188,
        "compression_ratio": 2.0892018779342725,
        "end": 2475.54,
        "id": 556,
        "no_speech_prob": 0.0007436840096488595,
        "seek": 246110,
        "start": 2470.94,
        "temperature": 0,
        "text": " and make sure that that does not equal the empty string.",
        "tokens": [
          50856,
          293,
          652,
          988,
          300,
          300,
          775,
          406,
          2681,
          264,
          6707,
          6798,
          13,
          51086
        ]
      },
      {
        "avg_logprob": -0.2151138452383188,
        "compression_ratio": 2.0892018779342725,
        "end": 2477.7,
        "id": 557,
        "no_speech_prob": 0.0007436840096488595,
        "seek": 246110,
        "start": 2475.54,
        "temperature": 0,
        "text": " So we're going to make sure that they have actually",
        "tokens": [
          51086,
          407,
          321,
          434,
          516,
          281,
          652,
          988,
          300,
          436,
          362,
          767,
          51194
        ]
      },
      {
        "avg_logprob": -0.2151138452383188,
        "compression_ratio": 2.0892018779342725,
        "end": 2484.22,
        "id": 558,
        "no_speech_prob": 0.0007436840096488595,
        "seek": 246110,
        "start": 2477.7,
        "temperature": 0,
        "text": " sent us a name and this exact same thing for the content.",
        "tokens": [
          51194,
          2279,
          505,
          257,
          1315,
          293,
          341,
          1900,
          912,
          551,
          337,
          264,
          2701,
          13,
          51520
        ]
      },
      {
        "avg_logprob": -0.2151138452383188,
        "compression_ratio": 2.0892018779342725,
        "end": 2486.5,
        "id": 559,
        "no_speech_prob": 0.0007436840096488595,
        "seek": 246110,
        "start": 2484.22,
        "temperature": 0,
        "text": " So here, we'll make this content.",
        "tokens": [
          51520,
          407,
          510,
          11,
          321,
          603,
          652,
          341,
          2701,
          13,
          51634
        ]
      },
      {
        "avg_logprob": -0.2151138452383188,
        "compression_ratio": 2.0892018779342725,
        "end": 2489,
        "id": 560,
        "no_speech_prob": 0.0007436840096488595,
        "seek": 246110,
        "start": 2486.5,
        "temperature": 0,
        "text": " So we're going to make sure that they're sending us a name,",
        "tokens": [
          51634,
          407,
          321,
          434,
          516,
          281,
          652,
          988,
          300,
          436,
          434,
          7750,
          505,
          257,
          1315,
          11,
          51759
        ]
      },
      {
        "avg_logprob": -0.2151138452383188,
        "compression_ratio": 2.0892018779342725,
        "end": 2490.96,
        "id": 561,
        "no_speech_prob": 0.0007436840096488595,
        "seek": 246110,
        "start": 2489,
        "temperature": 0,
        "text": " they're sending us some content, and then we'll",
        "tokens": [
          51759,
          436,
          434,
          7750,
          505,
          512,
          2701,
          11,
          293,
          550,
          321,
          603,
          51857
        ]
      },
      {
        "avg_logprob": -0.24871253967285156,
        "compression_ratio": 1.5965665236051503,
        "end": 2492.8,
        "id": 562,
        "no_speech_prob": 0.00007254172669490799,
        "seek": 249096,
        "start": 2491.02,
        "temperature": 0,
        "text": " put it into the database.",
        "tokens": [
          50367,
          829,
          309,
          666,
          264,
          8149,
          13,
          50456
        ]
      },
      {
        "avg_logprob": -0.24871253967285156,
        "compression_ratio": 1.5965665236051503,
        "end": 2495.08,
        "id": 563,
        "no_speech_prob": 0.00007254172669490799,
        "seek": 249096,
        "start": 2492.8,
        "temperature": 0,
        "text": " And for now, let's just create an object.",
        "tokens": [
          50456,
          400,
          337,
          586,
          11,
          718,
          311,
          445,
          1884,
          364,
          2657,
          13,
          50570
        ]
      },
      {
        "avg_logprob": -0.24871253967285156,
        "compression_ratio": 1.5965665236051503,
        "end": 2498.12,
        "id": 564,
        "no_speech_prob": 0.00007254172669490799,
        "seek": 249096,
        "start": 2495.08,
        "temperature": 0,
        "text": " Let's call this mu.",
        "tokens": [
          50570,
          961,
          311,
          818,
          341,
          2992,
          13,
          50722
        ]
      },
      {
        "avg_logprob": -0.24871253967285156,
        "compression_ratio": 1.5965665236051503,
        "end": 2499.76,
        "id": 565,
        "no_speech_prob": 0.00007254172669490799,
        "seek": 249096,
        "start": 2498.12,
        "temperature": 0,
        "text": " And it will have a name, which will be",
        "tokens": [
          50722,
          400,
          309,
          486,
          362,
          257,
          1315,
          11,
          597,
          486,
          312,
          50804
        ]
      },
      {
        "avg_logprob": -0.24871253967285156,
        "compression_ratio": 1.5965665236051503,
        "end": 2503.96,
        "id": 566,
        "no_speech_prob": 0.00007254172669490799,
        "seek": 249096,
        "start": 2499.76,
        "temperature": 0,
        "text": " rec.body.name.toString.",
        "tokens": [
          50804,
          850,
          13,
          1067,
          13,
          16344,
          13,
          1353,
          4520,
          2937,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.24871253967285156,
        "compression_ratio": 1.5965665236051503,
        "end": 2506.28,
        "id": 567,
        "no_speech_prob": 0.00007254172669490799,
        "seek": 249096,
        "start": 2503.96,
        "temperature": 0,
        "text": " And then we'll also have a content,",
        "tokens": [
          51014,
          400,
          550,
          321,
          603,
          611,
          362,
          257,
          2701,
          11,
          51130
        ]
      },
      {
        "avg_logprob": -0.24871253967285156,
        "compression_ratio": 1.5965665236051503,
        "end": 2511.44,
        "id": 568,
        "no_speech_prob": 0.00007254172669490799,
        "seek": 249096,
        "start": 2506.28,
        "temperature": 0,
        "text": " and this will be rec.body.content.toString.",
        "tokens": [
          51130,
          293,
          341,
          486,
          312,
          850,
          13,
          1067,
          13,
          9000,
          317,
          13,
          1353,
          4520,
          2937,
          13,
          51388
        ]
      },
      {
        "avg_logprob": -0.24871253967285156,
        "compression_ratio": 1.5965665236051503,
        "end": 2513.4,
        "id": 569,
        "no_speech_prob": 0.00007254172669490799,
        "seek": 249096,
        "start": 2511.44,
        "temperature": 0,
        "text": " There was actually an interesting question.",
        "tokens": [
          51388,
          821,
          390,
          767,
          364,
          1880,
          1168,
          13,
          51486
        ]
      },
      {
        "avg_logprob": -0.24871253967285156,
        "compression_ratio": 1.5965665236051503,
        "end": 2515.2,
        "id": 570,
        "no_speech_prob": 0.00007254172669490799,
        "seek": 249096,
        "start": 2513.4,
        "temperature": 0,
        "text": " So I noticed you doing this validation.",
        "tokens": [
          51486,
          407,
          286,
          5694,
          291,
          884,
          341,
          24071,
          13,
          51576
        ]
      },
      {
        "avg_logprob": -0.24871253967285156,
        "compression_ratio": 1.5965665236051503,
        "end": 2519.2,
        "id": 571,
        "no_speech_prob": 0.00007254172669490799,
        "seek": 249096,
        "start": 2515.2,
        "temperature": 0,
        "text": " Do you ever use a library, or this came from Nahuel Jose,",
        "tokens": [
          51576,
          1144,
          291,
          1562,
          764,
          257,
          6405,
          11,
          420,
          341,
          1361,
          490,
          13933,
          3483,
          8635,
          11,
          51776
        ]
      },
      {
        "avg_logprob": -0.2523167208305695,
        "compression_ratio": 1.72782874617737,
        "end": 2520.8799999999997,
        "id": 572,
        "no_speech_prob": 0.0001971656020032242,
        "seek": 251920,
        "start": 2519.2,
        "temperature": 0,
        "text": " is there any library or node module",
        "tokens": [
          50364,
          307,
          456,
          604,
          6405,
          420,
          9984,
          10088,
          50448
        ]
      },
      {
        "avg_logprob": -0.2523167208305695,
        "compression_ratio": 1.72782874617737,
        "end": 2522.7999999999997,
        "id": 573,
        "no_speech_prob": 0.0001971656020032242,
        "seek": 251920,
        "start": 2520.8799999999997,
        "temperature": 0,
        "text": " that you know that helps with data validation?",
        "tokens": [
          50448,
          300,
          291,
          458,
          300,
          3665,
          365,
          1412,
          24071,
          30,
          50544
        ]
      },
      {
        "avg_logprob": -0.2523167208305695,
        "compression_ratio": 1.72782874617737,
        "end": 2523.48,
        "id": 574,
        "no_speech_prob": 0.0001971656020032242,
        "seek": 251920,
        "start": 2522.7999999999997,
        "temperature": 0,
        "text": " Yeah, absolutely.",
        "tokens": [
          50544,
          865,
          11,
          3122,
          13,
          50578
        ]
      },
      {
        "avg_logprob": -0.2523167208305695,
        "compression_ratio": 1.72782874617737,
        "end": 2525.9199999999996,
        "id": 575,
        "no_speech_prob": 0.0001971656020032242,
        "seek": 251920,
        "start": 2523.48,
        "temperature": 0,
        "text": " So you don't have to do all that code manually in your code.",
        "tokens": [
          50578,
          407,
          291,
          500,
          380,
          362,
          281,
          360,
          439,
          300,
          3089,
          16945,
          294,
          428,
          3089,
          13,
          50700
        ]
      },
      {
        "avg_logprob": -0.2523167208305695,
        "compression_ratio": 1.72782874617737,
        "end": 2526.48,
        "id": 576,
        "no_speech_prob": 0.0001971656020032242,
        "seek": 251920,
        "start": 2525.9199999999996,
        "temperature": 0,
        "text": " Definitely.",
        "tokens": [
          50700,
          12151,
          13,
          50728
        ]
      },
      {
        "avg_logprob": -0.2523167208305695,
        "compression_ratio": 1.72782874617737,
        "end": 2529.24,
        "id": 577,
        "no_speech_prob": 0.0001971656020032242,
        "seek": 251920,
        "start": 2526.48,
        "temperature": 0,
        "text": " So there is, it's literally called Express Validator.",
        "tokens": [
          50728,
          407,
          456,
          307,
          11,
          309,
          311,
          3736,
          1219,
          20212,
          7188,
          327,
          1639,
          13,
          50866
        ]
      },
      {
        "avg_logprob": -0.2523167208305695,
        "compression_ratio": 1.72782874617737,
        "end": 2530.9199999999996,
        "id": 578,
        "no_speech_prob": 0.0001971656020032242,
        "seek": 251920,
        "start": 2529.24,
        "temperature": 0,
        "text": " You can search it on NPM.",
        "tokens": [
          50866,
          509,
          393,
          3164,
          309,
          322,
          426,
          18819,
          13,
          50950
        ]
      },
      {
        "avg_logprob": -0.2523167208305695,
        "compression_ratio": 1.72782874617737,
        "end": 2533.12,
        "id": 579,
        "no_speech_prob": 0.0001971656020032242,
        "seek": 251920,
        "start": 2530.9199999999996,
        "temperature": 0,
        "text": " And there's probably a lot of other ones out there.",
        "tokens": [
          50950,
          400,
          456,
          311,
          1391,
          257,
          688,
          295,
          661,
          2306,
          484,
          456,
          13,
          51060
        ]
      },
      {
        "avg_logprob": -0.2523167208305695,
        "compression_ratio": 1.72782874617737,
        "end": 2535.2799999999997,
        "id": 580,
        "no_speech_prob": 0.0001971656020032242,
        "seek": 251920,
        "start": 2533.12,
        "temperature": 0,
        "text": " But these are various libraries that",
        "tokens": [
          51060,
          583,
          613,
          366,
          3683,
          15148,
          300,
          51168
        ]
      },
      {
        "avg_logprob": -0.2523167208305695,
        "compression_ratio": 1.72782874617737,
        "end": 2537.24,
        "id": 581,
        "no_speech_prob": 0.0001971656020032242,
        "seek": 251920,
        "start": 2535.2799999999997,
        "temperature": 0,
        "text": " just make it a little bit easier to do validation",
        "tokens": [
          51168,
          445,
          652,
          309,
          257,
          707,
          857,
          3571,
          281,
          360,
          24071,
          51266
        ]
      },
      {
        "avg_logprob": -0.2523167208305695,
        "compression_ratio": 1.72782874617737,
        "end": 2538.3599999999997,
        "id": 582,
        "no_speech_prob": 0.0001971656020032242,
        "seek": 251920,
        "start": 2537.24,
        "temperature": 0,
        "text": " on incoming requests.",
        "tokens": [
          51266,
          322,
          22341,
          12475,
          13,
          51322
        ]
      },
      {
        "avg_logprob": -0.2523167208305695,
        "compression_ratio": 1.72782874617737,
        "end": 2541.12,
        "id": 583,
        "no_speech_prob": 0.0001971656020032242,
        "seek": 251920,
        "start": 2538.3599999999997,
        "temperature": 0,
        "text": " So this is a pretty popular one.",
        "tokens": [
          51322,
          407,
          341,
          307,
          257,
          1238,
          3743,
          472,
          13,
          51460
        ]
      },
      {
        "avg_logprob": -0.2523167208305695,
        "compression_ratio": 1.72782874617737,
        "end": 2543.2799999999997,
        "id": 584,
        "no_speech_prob": 0.0001971656020032242,
        "seek": 251920,
        "start": 2541.12,
        "temperature": 0,
        "text": " Maybe this is not the one.",
        "tokens": [
          51460,
          2704,
          341,
          307,
          406,
          264,
          472,
          13,
          51568
        ]
      },
      {
        "avg_logprob": -0.2523167208305695,
        "compression_ratio": 1.72782874617737,
        "end": 2546.2799999999997,
        "id": 585,
        "no_speech_prob": 0.0001971656020032242,
        "seek": 251920,
        "start": 2543.2799999999997,
        "temperature": 0,
        "text": " But yes, there are packages that will do that for you.",
        "tokens": [
          51568,
          583,
          2086,
          11,
          456,
          366,
          17401,
          300,
          486,
          360,
          300,
          337,
          291,
          13,
          51718
        ]
      },
      {
        "avg_logprob": -0.2523167208305695,
        "compression_ratio": 1.72782874617737,
        "end": 2548.3199999999997,
        "id": 586,
        "no_speech_prob": 0.0001971656020032242,
        "seek": 251920,
        "start": 2546.2799999999997,
        "temperature": 0,
        "text": " And then also, on my stream before,",
        "tokens": [
          51718,
          400,
          550,
          611,
          11,
          322,
          452,
          4309,
          949,
          11,
          51820
        ]
      },
      {
        "avg_logprob": -0.28591540301287616,
        "compression_ratio": 1.6187290969899666,
        "end": 2553.1200000000003,
        "id": 587,
        "no_speech_prob": 0.00014425654080696404,
        "seek": 254832,
        "start": 2548.32,
        "temperature": 0,
        "text": " I've used something called Joy, which is.",
        "tokens": [
          50364,
          286,
          600,
          1143,
          746,
          1219,
          15571,
          11,
          597,
          307,
          13,
          50604
        ]
      },
      {
        "avg_logprob": -0.28591540301287616,
        "compression_ratio": 1.6187290969899666,
        "end": 2554.52,
        "id": 588,
        "no_speech_prob": 0.00014425654080696404,
        "seek": 254832,
        "start": 2553.1200000000003,
        "temperature": 0,
        "text": " It's being discussed in the chat.",
        "tokens": [
          50604,
          467,
          311,
          885,
          7152,
          294,
          264,
          5081,
          13,
          50674
        ]
      },
      {
        "avg_logprob": -0.28591540301287616,
        "compression_ratio": 1.6187290969899666,
        "end": 2557.0800000000004,
        "id": 589,
        "no_speech_prob": 0.00014425654080696404,
        "seek": 254832,
        "start": 2554.52,
        "temperature": 0,
        "text": " And I was like, I had no idea what anybody was talking about.",
        "tokens": [
          50674,
          400,
          286,
          390,
          411,
          11,
          286,
          632,
          572,
          1558,
          437,
          4472,
          390,
          1417,
          466,
          13,
          50802
        ]
      },
      {
        "avg_logprob": -0.28591540301287616,
        "compression_ratio": 1.6187290969899666,
        "end": 2561.52,
        "id": 590,
        "no_speech_prob": 0.00014425654080696404,
        "seek": 254832,
        "start": 2557.0800000000004,
        "temperature": 0,
        "text": " Yeah, so Joy is a library that comes out of the Happy team.",
        "tokens": [
          50802,
          865,
          11,
          370,
          15571,
          307,
          257,
          6405,
          300,
          1487,
          484,
          295,
          264,
          8277,
          1469,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.28591540301287616,
        "compression_ratio": 1.6187290969899666,
        "end": 2564.96,
        "id": 591,
        "no_speech_prob": 0.00014425654080696404,
        "seek": 254832,
        "start": 2561.52,
        "temperature": 0,
        "text": " So Happy is another framework, very similar to Express,",
        "tokens": [
          51024,
          407,
          8277,
          307,
          1071,
          8388,
          11,
          588,
          2531,
          281,
          20212,
          11,
          51196
        ]
      },
      {
        "avg_logprob": -0.28591540301287616,
        "compression_ratio": 1.6187290969899666,
        "end": 2566.92,
        "id": 592,
        "no_speech_prob": 0.00014425654080696404,
        "seek": 254832,
        "start": 2564.96,
        "temperature": 0,
        "text": " but you just do things a little bit differently.",
        "tokens": [
          51196,
          457,
          291,
          445,
          360,
          721,
          257,
          707,
          857,
          7614,
          13,
          51294
        ]
      },
      {
        "avg_logprob": -0.28591540301287616,
        "compression_ratio": 1.6187290969899666,
        "end": 2568.26,
        "id": 593,
        "no_speech_prob": 0.00014425654080696404,
        "seek": 254832,
        "start": 2566.92,
        "temperature": 0,
        "text": " But Joy is a really cool library,",
        "tokens": [
          51294,
          583,
          15571,
          307,
          257,
          534,
          1627,
          6405,
          11,
          51361
        ]
      },
      {
        "avg_logprob": -0.28591540301287616,
        "compression_ratio": 1.6187290969899666,
        "end": 2571,
        "id": 594,
        "no_speech_prob": 0.00014425654080696404,
        "seek": 254832,
        "start": 2568.26,
        "temperature": 0,
        "text": " because you can do object schema validation,",
        "tokens": [
          51361,
          570,
          291,
          393,
          360,
          2657,
          34078,
          24071,
          11,
          51498
        ]
      },
      {
        "avg_logprob": -0.28591540301287616,
        "compression_ratio": 1.6187290969899666,
        "end": 2574.28,
        "id": 595,
        "no_speech_prob": 0.00014425654080696404,
        "seek": 254832,
        "start": 2571,
        "temperature": 0,
        "text": " and make sure something is a string, and it's alphanumeric,",
        "tokens": [
          51498,
          293,
          652,
          988,
          746,
          307,
          257,
          6798,
          11,
          293,
          309,
          311,
          419,
          950,
          282,
          15583,
          299,
          11,
          51662
        ]
      },
      {
        "avg_logprob": -0.28591540301287616,
        "compression_ratio": 1.6187290969899666,
        "end": 2577.0800000000004,
        "id": 596,
        "no_speech_prob": 0.00014425654080696404,
        "seek": 254832,
        "start": 2574.28,
        "temperature": 0,
        "text": " and it has a very nice way of defining it.",
        "tokens": [
          51662,
          293,
          309,
          575,
          257,
          588,
          1481,
          636,
          295,
          17827,
          309,
          13,
          51802
        ]
      },
      {
        "avg_logprob": -0.29834710984002977,
        "compression_ratio": 1.556420233463035,
        "end": 2579.48,
        "id": 597,
        "no_speech_prob": 0.0014103456633165479,
        "seek": 257708,
        "start": 2577.08,
        "temperature": 0,
        "text": " I actually found one called, I think it's called Yup,",
        "tokens": [
          50364,
          286,
          767,
          1352,
          472,
          1219,
          11,
          286,
          519,
          309,
          311,
          1219,
          13593,
          11,
          50484
        ]
      },
      {
        "avg_logprob": -0.29834710984002977,
        "compression_ratio": 1.556420233463035,
        "end": 2581.48,
        "id": 598,
        "no_speech_prob": 0.0014103456633165479,
        "seek": 257708,
        "start": 2579.48,
        "temperature": 0,
        "text": " which was based on Joy.",
        "tokens": [
          50484,
          597,
          390,
          2361,
          322,
          15571,
          13,
          50584
        ]
      },
      {
        "avg_logprob": -0.29834710984002977,
        "compression_ratio": 1.556420233463035,
        "end": 2582.24,
        "id": 599,
        "no_speech_prob": 0.0014103456633165479,
        "seek": 257708,
        "start": 2581.48,
        "temperature": 0,
        "text": " It's very similar.",
        "tokens": [
          50584,
          467,
          311,
          588,
          2531,
          13,
          50622
        ]
      },
      {
        "avg_logprob": -0.29834710984002977,
        "compression_ratio": 1.556420233463035,
        "end": 2584.84,
        "id": 600,
        "no_speech_prob": 0.0014103456633165479,
        "seek": 257708,
        "start": 2582.24,
        "temperature": 0,
        "text": " But yes, there are lots of them.",
        "tokens": [
          50622,
          583,
          2086,
          11,
          456,
          366,
          3195,
          295,
          552,
          13,
          50752
        ]
      },
      {
        "avg_logprob": -0.29834710984002977,
        "compression_ratio": 1.556420233463035,
        "end": 2586.48,
        "id": 601,
        "no_speech_prob": 0.0014103456633165479,
        "seek": 257708,
        "start": 2584.84,
        "temperature": 0,
        "text": " Initially, when you're getting started,",
        "tokens": [
          50752,
          29446,
          11,
          562,
          291,
          434,
          1242,
          1409,
          11,
          50834
        ]
      },
      {
        "avg_logprob": -0.29834710984002977,
        "compression_ratio": 1.556420233463035,
        "end": 2588.7599999999998,
        "id": 602,
        "no_speech_prob": 0.0014103456633165479,
        "seek": 257708,
        "start": 2586.48,
        "temperature": 0,
        "text": " I like to just show this to show what's happening.",
        "tokens": [
          50834,
          286,
          411,
          281,
          445,
          855,
          341,
          281,
          855,
          437,
          311,
          2737,
          13,
          50948
        ]
      },
      {
        "avg_logprob": -0.29834710984002977,
        "compression_ratio": 1.556420233463035,
        "end": 2590.96,
        "id": 603,
        "no_speech_prob": 0.0014103456633165479,
        "seek": 257708,
        "start": 2588.7599999999998,
        "temperature": 0,
        "text": " But absolutely, if you have an object that",
        "tokens": [
          50948,
          583,
          3122,
          11,
          498,
          291,
          362,
          364,
          2657,
          300,
          51058
        ]
      },
      {
        "avg_logprob": -0.29834710984002977,
        "compression_ratio": 1.556420233463035,
        "end": 2592.6,
        "id": 604,
        "no_speech_prob": 0.0014103456633165479,
        "seek": 257708,
        "start": 2590.96,
        "temperature": 0,
        "text": " has 10 properties, you probably want",
        "tokens": [
          51058,
          575,
          1266,
          7221,
          11,
          291,
          1391,
          528,
          51140
        ]
      },
      {
        "avg_logprob": -0.29834710984002977,
        "compression_ratio": 1.556420233463035,
        "end": 2594.96,
        "id": 605,
        "no_speech_prob": 0.0014103456633165479,
        "seek": 257708,
        "start": 2592.6,
        "temperature": 0,
        "text": " to use some library like this.",
        "tokens": [
          51140,
          281,
          764,
          512,
          6405,
          411,
          341,
          13,
          51258
        ]
      },
      {
        "avg_logprob": -0.29834710984002977,
        "compression_ratio": 1.556420233463035,
        "end": 2596.3199999999997,
        "id": 606,
        "no_speech_prob": 0.0014103456633165479,
        "seek": 257708,
        "start": 2594.96,
        "temperature": 0,
        "text": " Oh no, did I just close Chrome?",
        "tokens": [
          51258,
          876,
          572,
          11,
          630,
          286,
          445,
          1998,
          15327,
          30,
          51326
        ]
      },
      {
        "avg_logprob": -0.29834710984002977,
        "compression_ratio": 1.556420233463035,
        "end": 2597.88,
        "id": 607,
        "no_speech_prob": 0.0014103456633165479,
        "seek": 257708,
        "start": 2596.3199999999997,
        "temperature": 0,
        "text": " I think I did.",
        "tokens": [
          51326,
          286,
          519,
          286,
          630,
          13,
          51404
        ]
      },
      {
        "avg_logprob": -0.29834710984002977,
        "compression_ratio": 1.556420233463035,
        "end": 2598.44,
        "id": 608,
        "no_speech_prob": 0.0014103456633165479,
        "seek": 257708,
        "start": 2597.88,
        "temperature": 0,
        "text": " Wait, did I?",
        "tokens": [
          51404,
          3802,
          11,
          630,
          286,
          30,
          51432
        ]
      },
      {
        "avg_logprob": -0.29834710984002977,
        "compression_ratio": 1.556420233463035,
        "end": 2604.64,
        "id": 609,
        "no_speech_prob": 0.0014103456633165479,
        "seek": 257708,
        "start": 2603.64,
        "temperature": 0,
        "text": " Oh well.",
        "tokens": [
          51692,
          876,
          731,
          13,
          51742
        ]
      },
      {
        "avg_logprob": -0.35318050099842585,
        "compression_ratio": 1.6346863468634687,
        "end": 2608.6,
        "id": 610,
        "no_speech_prob": 0.0035380315966904163,
        "seek": 260464,
        "start": 2604.64,
        "temperature": 0,
        "text": " Localhost 3000, no, 5000.",
        "tokens": [
          50364,
          22755,
          6037,
          20984,
          11,
          572,
          11,
          23777,
          13,
          50562
        ]
      },
      {
        "avg_logprob": -0.35318050099842585,
        "compression_ratio": 1.6346863468634687,
        "end": 2611.56,
        "id": 611,
        "no_speech_prob": 0.0035380315966904163,
        "seek": 260464,
        "start": 2608.6,
        "temperature": 0,
        "text": " And then localhost 8080.",
        "tokens": [
          50562,
          400,
          550,
          2654,
          6037,
          4688,
          4702,
          13,
          50710
        ]
      },
      {
        "avg_logprob": -0.35318050099842585,
        "compression_ratio": 1.6346863468634687,
        "end": 2616.04,
        "id": 612,
        "no_speech_prob": 0.0035380315966904163,
        "seek": 260464,
        "start": 2611.56,
        "temperature": 0,
        "text": " And what about, someone also asked something related",
        "tokens": [
          50710,
          400,
          437,
          466,
          11,
          1580,
          611,
          2351,
          746,
          4077,
          50934
        ]
      },
      {
        "avg_logprob": -0.35318050099842585,
        "compression_ratio": 1.6346863468634687,
        "end": 2617.08,
        "id": 613,
        "no_speech_prob": 0.0035380315966904163,
        "seek": 260464,
        "start": 2616.04,
        "temperature": 0,
        "text": " to security.",
        "tokens": [
          50934,
          281,
          3825,
          13,
          50986
        ]
      },
      {
        "avg_logprob": -0.35318050099842585,
        "compression_ratio": 1.6346863468634687,
        "end": 2618.7599999999998,
        "id": 614,
        "no_speech_prob": 0.0035380315966904163,
        "seek": 260464,
        "start": 2617.08,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          50986,
          1079,
          13,
          51070
        ]
      },
      {
        "avg_logprob": -0.35318050099842585,
        "compression_ratio": 1.6346863468634687,
        "end": 2620.72,
        "id": 615,
        "no_speech_prob": 0.0035380315966904163,
        "seek": 260464,
        "start": 2618.7599999999998,
        "temperature": 0,
        "text": " But I don't, well, they're talking about secure",
        "tokens": [
          51070,
          583,
          286,
          500,
          380,
          11,
          731,
          11,
          436,
          434,
          1417,
          466,
          7144,
          51168
        ]
      },
      {
        "avg_logprob": -0.35318050099842585,
        "compression_ratio": 1.6346863468634687,
        "end": 2622.2799999999997,
        "id": 616,
        "no_speech_prob": 0.0035380315966904163,
        "seek": 260464,
        "start": 2620.72,
        "temperature": 0,
        "text": " those routes, form validations.",
        "tokens": [
          51168,
          729,
          18242,
          11,
          1254,
          7363,
          763,
          13,
          51246
        ]
      },
      {
        "avg_logprob": -0.35318050099842585,
        "compression_ratio": 1.6346863468634687,
        "end": 2624,
        "id": 617,
        "no_speech_prob": 0.0035380315966904163,
        "seek": 260464,
        "start": 2622.2799999999997,
        "temperature": 0,
        "text": " You talked about form validation.",
        "tokens": [
          51246,
          509,
          2825,
          466,
          1254,
          24071,
          13,
          51332
        ]
      },
      {
        "avg_logprob": -0.35318050099842585,
        "compression_ratio": 1.6346863468634687,
        "end": 2625.52,
        "id": 618,
        "no_speech_prob": 0.0035380315966904163,
        "seek": 260464,
        "start": 2624,
        "temperature": 0,
        "text": " So yeah, and like, I'm.",
        "tokens": [
          51332,
          407,
          1338,
          11,
          293,
          411,
          11,
          286,
          478,
          13,
          51408
        ]
      },
      {
        "avg_logprob": -0.35318050099842585,
        "compression_ratio": 1.6346863468634687,
        "end": 2627.48,
        "id": 619,
        "no_speech_prob": 0.0035380315966904163,
        "seek": 260464,
        "start": 2625.52,
        "temperature": 0,
        "text": " What's missing here in terms of security, I guess.",
        "tokens": [
          51408,
          708,
          311,
          5361,
          510,
          294,
          2115,
          295,
          3825,
          11,
          286,
          2041,
          13,
          51506
        ]
      },
      {
        "avg_logprob": -0.35318050099842585,
        "compression_ratio": 1.6346863468634687,
        "end": 2627.98,
        "id": 620,
        "no_speech_prob": 0.0035380315966904163,
        "seek": 260464,
        "start": 2627.48,
        "temperature": 0,
        "text": " Definitely.",
        "tokens": [
          51506,
          12151,
          13,
          51531
        ]
      },
      {
        "avg_logprob": -0.35318050099842585,
        "compression_ratio": 1.6346863468634687,
        "end": 2629.56,
        "id": 621,
        "no_speech_prob": 0.0035380315966904163,
        "seek": 260464,
        "start": 2627.98,
        "temperature": 0,
        "text": " So the main thing is, you always want",
        "tokens": [
          51531,
          407,
          264,
          2135,
          551,
          307,
          11,
          291,
          1009,
          528,
          51610
        ]
      },
      {
        "avg_logprob": -0.35318050099842585,
        "compression_ratio": 1.6346863468634687,
        "end": 2631.92,
        "id": 622,
        "no_speech_prob": 0.0035380315966904163,
        "seek": 260464,
        "start": 2629.56,
        "temperature": 0,
        "text": " to validate what you're putting into your database.",
        "tokens": [
          51610,
          281,
          29562,
          437,
          291,
          434,
          3372,
          666,
          428,
          8149,
          13,
          51728
        ]
      },
      {
        "avg_logprob": -0.35318050099842585,
        "compression_ratio": 1.6346863468634687,
        "end": 2633.12,
        "id": 623,
        "no_speech_prob": 0.0035380315966904163,
        "seek": 260464,
        "start": 2631.92,
        "temperature": 0,
        "text": " And I'm doing that right here.",
        "tokens": [
          51728,
          400,
          286,
          478,
          884,
          300,
          558,
          510,
          13,
          51788
        ]
      },
      {
        "avg_logprob": -0.2422210266871482,
        "compression_ratio": 1.843450479233227,
        "end": 2635.16,
        "id": 624,
        "no_speech_prob": 0.0006771865300834179,
        "seek": 263312,
        "start": 2633.12,
        "temperature": 0,
        "text": " I'm making sure that the data they're sending us",
        "tokens": [
          50364,
          286,
          478,
          1455,
          988,
          300,
          264,
          1412,
          436,
          434,
          7750,
          505,
          50466
        ]
      },
      {
        "avg_logprob": -0.2422210266871482,
        "compression_ratio": 1.843450479233227,
        "end": 2637,
        "id": 625,
        "no_speech_prob": 0.0006771865300834179,
        "seek": 263312,
        "start": 2635.16,
        "temperature": 0,
        "text": " has a name and has some content.",
        "tokens": [
          50466,
          575,
          257,
          1315,
          293,
          575,
          512,
          2701,
          13,
          50558
        ]
      },
      {
        "avg_logprob": -0.2422210266871482,
        "compression_ratio": 1.843450479233227,
        "end": 2638.96,
        "id": 626,
        "no_speech_prob": 0.0006771865300834179,
        "seek": 263312,
        "start": 2637,
        "temperature": 0,
        "text": " And then the other thing I'm doing,",
        "tokens": [
          50558,
          400,
          550,
          264,
          661,
          551,
          286,
          478,
          884,
          11,
          50656
        ]
      },
      {
        "avg_logprob": -0.2422210266871482,
        "compression_ratio": 1.843450479233227,
        "end": 2641.5,
        "id": 627,
        "no_speech_prob": 0.0006771865300834179,
        "seek": 263312,
        "start": 2638.96,
        "temperature": 0,
        "text": " which I kind of glossed over, is whatever they're sending us,",
        "tokens": [
          50656,
          597,
          286,
          733,
          295,
          19574,
          292,
          670,
          11,
          307,
          2035,
          436,
          434,
          7750,
          505,
          11,
          50783
        ]
      },
      {
        "avg_logprob": -0.2422210266871482,
        "compression_ratio": 1.843450479233227,
        "end": 2642.56,
        "id": 628,
        "no_speech_prob": 0.0006771865300834179,
        "seek": 263312,
        "start": 2641.5,
        "temperature": 0,
        "text": " I'm saying to string.",
        "tokens": [
          50783,
          286,
          478,
          1566,
          281,
          6798,
          13,
          50836
        ]
      },
      {
        "avg_logprob": -0.2422210266871482,
        "compression_ratio": 1.843450479233227,
        "end": 2644.3199999999997,
        "id": 629,
        "no_speech_prob": 0.0006771865300834179,
        "seek": 263312,
        "start": 2642.56,
        "temperature": 0,
        "text": " So when you're dealing with a database,",
        "tokens": [
          50836,
          407,
          562,
          291,
          434,
          6260,
          365,
          257,
          8149,
          11,
          50924
        ]
      },
      {
        "avg_logprob": -0.2422210266871482,
        "compression_ratio": 1.843450479233227,
        "end": 2646.6,
        "id": 630,
        "no_speech_prob": 0.0006771865300834179,
        "seek": 263312,
        "start": 2644.3199999999997,
        "temperature": 0,
        "text": " you want to prevent what's called injection.",
        "tokens": [
          50924,
          291,
          528,
          281,
          4871,
          437,
          311,
          1219,
          22873,
          13,
          51038
        ]
      },
      {
        "avg_logprob": -0.2422210266871482,
        "compression_ratio": 1.843450479233227,
        "end": 2650.92,
        "id": 631,
        "no_speech_prob": 0.0006771865300834179,
        "seek": 263312,
        "start": 2646.6,
        "temperature": 0,
        "text": " So if they tried to send us a nested object instead of just",
        "tokens": [
          51038,
          407,
          498,
          436,
          3031,
          281,
          2845,
          505,
          257,
          15646,
          292,
          2657,
          2602,
          295,
          445,
          51254
        ]
      },
      {
        "avg_logprob": -0.2422210266871482,
        "compression_ratio": 1.843450479233227,
        "end": 2653.2799999999997,
        "id": 632,
        "no_speech_prob": 0.0006771865300834179,
        "seek": 263312,
        "start": 2650.92,
        "temperature": 0,
        "text": " a string, and I didn't say to string,",
        "tokens": [
          51254,
          257,
          6798,
          11,
          293,
          286,
          994,
          380,
          584,
          281,
          6798,
          11,
          51372
        ]
      },
      {
        "avg_logprob": -0.2422210266871482,
        "compression_ratio": 1.843450479233227,
        "end": 2655.2799999999997,
        "id": 633,
        "no_speech_prob": 0.0006771865300834179,
        "seek": 263312,
        "start": 2653.2799999999997,
        "temperature": 0,
        "text": " we could potentially put that into our database.",
        "tokens": [
          51372,
          321,
          727,
          7263,
          829,
          300,
          666,
          527,
          8149,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -0.2422210266871482,
        "compression_ratio": 1.843450479233227,
        "end": 2657.48,
        "id": 634,
        "no_speech_prob": 0.0006771865300834179,
        "seek": 263312,
        "start": 2655.2799999999997,
        "temperature": 0,
        "text": " So you want to be very careful there.",
        "tokens": [
          51472,
          407,
          291,
          528,
          281,
          312,
          588,
          5026,
          456,
          13,
          51582
        ]
      },
      {
        "avg_logprob": -0.2422210266871482,
        "compression_ratio": 1.843450479233227,
        "end": 2660.04,
        "id": 635,
        "no_speech_prob": 0.0006771865300834179,
        "seek": 263312,
        "start": 2657.48,
        "temperature": 0,
        "text": " The main thing is, if you're dealing with receiving data",
        "tokens": [
          51582,
          440,
          2135,
          551,
          307,
          11,
          498,
          291,
          434,
          6260,
          365,
          10040,
          1412,
          51710
        ]
      },
      {
        "avg_logprob": -0.2422210266871482,
        "compression_ratio": 1.843450479233227,
        "end": 2662,
        "id": 636,
        "no_speech_prob": 0.0006771865300834179,
        "seek": 263312,
        "start": 2660.04,
        "temperature": 0,
        "text": " from a client, you always want to do validation.",
        "tokens": [
          51710,
          490,
          257,
          6423,
          11,
          291,
          1009,
          528,
          281,
          360,
          24071,
          13,
          51808
        ]
      },
      {
        "avg_logprob": -0.25728240766023336,
        "compression_ratio": 1.6156351791530945,
        "end": 2663.84,
        "id": 637,
        "no_speech_prob": 0.00014883805124554783,
        "seek": 266200,
        "start": 2662,
        "temperature": 0,
        "text": " You always want to be very careful about what",
        "tokens": [
          50364,
          509,
          1009,
          528,
          281,
          312,
          588,
          5026,
          466,
          437,
          50456
        ]
      },
      {
        "avg_logprob": -0.25728240766023336,
        "compression_ratio": 1.6156351791530945,
        "end": 2665.52,
        "id": 638,
        "no_speech_prob": 0.00014883805124554783,
        "seek": 266200,
        "start": 2663.84,
        "temperature": 0,
        "text": " you're putting into your database.",
        "tokens": [
          50456,
          291,
          434,
          3372,
          666,
          428,
          8149,
          13,
          50540
        ]
      },
      {
        "avg_logprob": -0.25728240766023336,
        "compression_ratio": 1.6156351791530945,
        "end": 2667.94,
        "id": 639,
        "no_speech_prob": 0.00014883805124554783,
        "seek": 266200,
        "start": 2665.52,
        "temperature": 0,
        "text": " They are correct in that I haven't done any validation",
        "tokens": [
          50540,
          814,
          366,
          3006,
          294,
          300,
          286,
          2378,
          380,
          1096,
          604,
          24071,
          50661
        ]
      },
      {
        "avg_logprob": -0.25728240766023336,
        "compression_ratio": 1.6156351791530945,
        "end": 2668.92,
        "id": 640,
        "no_speech_prob": 0.00014883805124554783,
        "seek": 266200,
        "start": 2667.94,
        "temperature": 0,
        "text": " on the client side.",
        "tokens": [
          50661,
          322,
          264,
          6423,
          1252,
          13,
          50710
        ]
      },
      {
        "avg_logprob": -0.25728240766023336,
        "compression_ratio": 1.6156351791530945,
        "end": 2671.24,
        "id": 641,
        "no_speech_prob": 0.00014883805124554783,
        "seek": 266200,
        "start": 2668.92,
        "temperature": 0,
        "text": " But as long as I'm doing it on the server side,",
        "tokens": [
          50710,
          583,
          382,
          938,
          382,
          286,
          478,
          884,
          309,
          322,
          264,
          7154,
          1252,
          11,
          50826
        ]
      },
      {
        "avg_logprob": -0.25728240766023336,
        "compression_ratio": 1.6156351791530945,
        "end": 2674.32,
        "id": 642,
        "no_speech_prob": 0.00014883805124554783,
        "seek": 266200,
        "start": 2671.24,
        "temperature": 0,
        "text": " no one's going to be able to put bad stuff into my database.",
        "tokens": [
          50826,
          572,
          472,
          311,
          516,
          281,
          312,
          1075,
          281,
          829,
          1578,
          1507,
          666,
          452,
          8149,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.25728240766023336,
        "compression_ratio": 1.6156351791530945,
        "end": 2676.36,
        "id": 643,
        "no_speech_prob": 0.00014883805124554783,
        "seek": 266200,
        "start": 2674.32,
        "temperature": 0,
        "text": " Definitely.",
        "tokens": [
          50980,
          12151,
          13,
          51082
        ]
      },
      {
        "avg_logprob": -0.25728240766023336,
        "compression_ratio": 1.6156351791530945,
        "end": 2678.64,
        "id": 644,
        "no_speech_prob": 0.00014883805124554783,
        "seek": 266200,
        "start": 2676.36,
        "temperature": 0,
        "text": " OK, so now we're validating it.",
        "tokens": [
          51082,
          2264,
          11,
          370,
          586,
          321,
          434,
          7363,
          990,
          309,
          13,
          51196
        ]
      },
      {
        "avg_logprob": -0.25728240766023336,
        "compression_ratio": 1.6156351791530945,
        "end": 2679.32,
        "id": 645,
        "no_speech_prob": 0.00014883805124554783,
        "seek": 266200,
        "start": 2678.64,
        "temperature": 0,
        "text": " And it should.",
        "tokens": [
          51196,
          400,
          309,
          820,
          13,
          51230
        ]
      },
      {
        "avg_logprob": -0.25728240766023336,
        "compression_ratio": 1.6156351791530945,
        "end": 2682.12,
        "id": 646,
        "no_speech_prob": 0.00014883805124554783,
        "seek": 266200,
        "start": 2679.32,
        "temperature": 0,
        "text": " So actually, if I, let's look at the dev tools.",
        "tokens": [
          51230,
          407,
          767,
          11,
          498,
          286,
          11,
          718,
          311,
          574,
          412,
          264,
          1905,
          3873,
          13,
          51370
        ]
      },
      {
        "avg_logprob": -0.25728240766023336,
        "compression_ratio": 1.6156351791530945,
        "end": 2683.96,
        "id": 647,
        "no_speech_prob": 0.00014883805124554783,
        "seek": 266200,
        "start": 2682.12,
        "temperature": 0,
        "text": " And I try to send this as an empty form.",
        "tokens": [
          51370,
          400,
          286,
          853,
          281,
          2845,
          341,
          382,
          364,
          6707,
          1254,
          13,
          51462
        ]
      },
      {
        "avg_logprob": -0.25728240766023336,
        "compression_ratio": 1.6156351791530945,
        "end": 2685.32,
        "id": 648,
        "no_speech_prob": 0.00014883805124554783,
        "seek": 266200,
        "start": 2683.96,
        "temperature": 0,
        "text": " You'll notice I get back an error.",
        "tokens": [
          51462,
          509,
          603,
          3449,
          286,
          483,
          646,
          364,
          6713,
          13,
          51530
        ]
      },
      {
        "avg_logprob": -0.25728240766023336,
        "compression_ratio": 1.6156351791530945,
        "end": 2686.48,
        "id": 649,
        "no_speech_prob": 0.00014883805124554783,
        "seek": 266200,
        "start": 2685.32,
        "temperature": 0,
        "text": " I should probably handle it.",
        "tokens": [
          51530,
          286,
          820,
          1391,
          4813,
          309,
          13,
          51588
        ]
      },
      {
        "avg_logprob": -0.25728240766023336,
        "compression_ratio": 1.6156351791530945,
        "end": 2687.64,
        "id": 650,
        "no_speech_prob": 0.00014883805124554783,
        "seek": 266200,
        "start": 2686.48,
        "temperature": 0,
        "text": " We don't have time.",
        "tokens": [
          51588,
          492,
          500,
          380,
          362,
          565,
          13,
          51646
        ]
      },
      {
        "avg_logprob": -0.20196391642093658,
        "compression_ratio": 1.66798418972332,
        "end": 2693.64,
        "id": 651,
        "no_speech_prob": 0.0020189848728477955,
        "seek": 268764,
        "start": 2687.64,
        "temperature": 0,
        "text": " But if I do send it good data, then it logged it out.",
        "tokens": [
          50364,
          583,
          498,
          286,
          360,
          2845,
          309,
          665,
          1412,
          11,
          550,
          309,
          27231,
          309,
          484,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20196391642093658,
        "compression_ratio": 1.66798418972332,
        "end": 2696.6,
        "id": 652,
        "no_speech_prob": 0.0020189848728477955,
        "seek": 268764,
        "start": 2693.64,
        "temperature": 0,
        "text": " And now we're ready to insert it into a database.",
        "tokens": [
          50664,
          400,
          586,
          321,
          434,
          1919,
          281,
          8969,
          309,
          666,
          257,
          8149,
          13,
          50812
        ]
      },
      {
        "avg_logprob": -0.20196391642093658,
        "compression_ratio": 1.66798418972332,
        "end": 2698.4,
        "id": 653,
        "no_speech_prob": 0.0020189848728477955,
        "seek": 268764,
        "start": 2696.6,
        "temperature": 0,
        "text": " So let's look at our checklist.",
        "tokens": [
          50812,
          407,
          718,
          311,
          574,
          412,
          527,
          30357,
          13,
          50902
        ]
      },
      {
        "avg_logprob": -0.20196391642093658,
        "compression_ratio": 1.66798418972332,
        "end": 2700.8399999999997,
        "id": 654,
        "no_speech_prob": 0.0020189848728477955,
        "seek": 268764,
        "start": 2698.4,
        "temperature": 0,
        "text": " We have validated the name and content.",
        "tokens": [
          50902,
          492,
          362,
          40693,
          264,
          1315,
          293,
          2701,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.20196391642093658,
        "compression_ratio": 1.66798418972332,
        "end": 2701.7999999999997,
        "id": 655,
        "no_speech_prob": 0.0020189848728477955,
        "seek": 268764,
        "start": 2700.8399999999997,
        "temperature": 0,
        "text": " It must be a string.",
        "tokens": [
          51024,
          467,
          1633,
          312,
          257,
          6798,
          13,
          51072
        ]
      },
      {
        "avg_logprob": -0.20196391642093658,
        "compression_ratio": 1.66798418972332,
        "end": 2703.68,
        "id": 656,
        "no_speech_prob": 0.0020189848728477955,
        "seek": 268764,
        "start": 2701.7999999999997,
        "temperature": 0,
        "text": " It's not empty.",
        "tokens": [
          51072,
          467,
          311,
          406,
          6707,
          13,
          51166
        ]
      },
      {
        "avg_logprob": -0.20196391642093658,
        "compression_ratio": 1.66798418972332,
        "end": 2707.7999999999997,
        "id": 657,
        "no_speech_prob": 0.0020189848728477955,
        "seek": 268764,
        "start": 2703.68,
        "temperature": 0,
        "text": " If it's not valid, we're responding with a port 22 error.",
        "tokens": [
          51166,
          759,
          309,
          311,
          406,
          7363,
          11,
          321,
          434,
          16670,
          365,
          257,
          2436,
          5853,
          6713,
          13,
          51372
        ]
      },
      {
        "avg_logprob": -0.20196391642093658,
        "compression_ratio": 1.66798418972332,
        "end": 2710.64,
        "id": 658,
        "no_speech_prob": 0.0020189848728477955,
        "seek": 268764,
        "start": 2707.7999999999997,
        "temperature": 0,
        "text": " And we are making sure that it has name and content.",
        "tokens": [
          51372,
          400,
          321,
          366,
          1455,
          988,
          300,
          309,
          575,
          1315,
          293,
          2701,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20196391642093658,
        "compression_ratio": 1.66798418972332,
        "end": 2712.96,
        "id": 659,
        "no_speech_prob": 0.0020189848728477955,
        "seek": 268764,
        "start": 2710.64,
        "temperature": 0,
        "text": " Now we want to put this thing into a database.",
        "tokens": [
          51514,
          823,
          321,
          528,
          281,
          829,
          341,
          551,
          666,
          257,
          8149,
          13,
          51630
        ]
      },
      {
        "avg_logprob": -0.20196391642093658,
        "compression_ratio": 1.66798418972332,
        "end": 2716.52,
        "id": 660,
        "no_speech_prob": 0.0020189848728477955,
        "seek": 268764,
        "start": 2712.96,
        "temperature": 0,
        "text": " So for the database, I'm going to be using MongoDB.",
        "tokens": [
          51630,
          407,
          337,
          264,
          8149,
          11,
          286,
          478,
          516,
          281,
          312,
          1228,
          48380,
          27735,
          13,
          51808
        ]
      },
      {
        "avg_logprob": -0.21625312270632216,
        "compression_ratio": 1.8131147540983608,
        "end": 2718.88,
        "id": 661,
        "no_speech_prob": 0.0012643691152334213,
        "seek": 271652,
        "start": 2716.52,
        "temperature": 0,
        "text": " And there are a lot of libraries for talking to MongoDB.",
        "tokens": [
          50364,
          400,
          456,
          366,
          257,
          688,
          295,
          15148,
          337,
          1417,
          281,
          48380,
          27735,
          13,
          50482
        ]
      },
      {
        "avg_logprob": -0.21625312270632216,
        "compression_ratio": 1.8131147540983608,
        "end": 2722.64,
        "id": 662,
        "no_speech_prob": 0.0012643691152334213,
        "seek": 271652,
        "start": 2718.88,
        "temperature": 0,
        "text": " Specifically, the library I'm going to be using is called Monk.",
        "tokens": [
          50482,
          26058,
          11,
          264,
          6405,
          286,
          478,
          516,
          281,
          312,
          1228,
          307,
          1219,
          4713,
          74,
          13,
          50670
        ]
      },
      {
        "avg_logprob": -0.21625312270632216,
        "compression_ratio": 1.8131147540983608,
        "end": 2725.4,
        "id": 663,
        "no_speech_prob": 0.0012643691152334213,
        "seek": 271652,
        "start": 2722.64,
        "temperature": 0,
        "text": " It's very simple, very easy to interact with.",
        "tokens": [
          50670,
          467,
          311,
          588,
          2199,
          11,
          588,
          1858,
          281,
          4648,
          365,
          13,
          50808
        ]
      },
      {
        "avg_logprob": -0.21625312270632216,
        "compression_ratio": 1.8131147540983608,
        "end": 2727.52,
        "id": 664,
        "no_speech_prob": 0.0012643691152334213,
        "seek": 271652,
        "start": 2725.4,
        "temperature": 0,
        "text": " A really popular one people use is called Mongoose.",
        "tokens": [
          50808,
          316,
          534,
          3743,
          472,
          561,
          764,
          307,
          1219,
          48380,
          541,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.21625312270632216,
        "compression_ratio": 1.8131147540983608,
        "end": 2729.28,
        "id": 665,
        "no_speech_prob": 0.0012643691152334213,
        "seek": 271652,
        "start": 2727.52,
        "temperature": 0,
        "text": " But this is way simpler to get set up.",
        "tokens": [
          50914,
          583,
          341,
          307,
          636,
          18587,
          281,
          483,
          992,
          493,
          13,
          51002
        ]
      },
      {
        "avg_logprob": -0.21625312270632216,
        "compression_ratio": 1.8131147540983608,
        "end": 2731.68,
        "id": 666,
        "no_speech_prob": 0.0012643691152334213,
        "seek": 271652,
        "start": 2729.28,
        "temperature": 0,
        "text": " So I'm going to install a package called Monk.",
        "tokens": [
          51002,
          407,
          286,
          478,
          516,
          281,
          3625,
          257,
          7372,
          1219,
          4713,
          74,
          13,
          51122
        ]
      },
      {
        "avg_logprob": -0.21625312270632216,
        "compression_ratio": 1.8131147540983608,
        "end": 2734.84,
        "id": 667,
        "no_speech_prob": 0.0012643691152334213,
        "seek": 271652,
        "start": 2731.68,
        "temperature": 0,
        "text": " And locally, I have MongoDB installed on my computer.",
        "tokens": [
          51122,
          400,
          16143,
          11,
          286,
          362,
          48380,
          27735,
          8899,
          322,
          452,
          3820,
          13,
          51280
        ]
      },
      {
        "avg_logprob": -0.21625312270632216,
        "compression_ratio": 1.8131147540983608,
        "end": 2736.16,
        "id": 668,
        "no_speech_prob": 0.0012643691152334213,
        "seek": 271652,
        "start": 2734.84,
        "temperature": 0,
        "text": " So I can type mongo.",
        "tokens": [
          51280,
          407,
          286,
          393,
          2010,
          275,
          25729,
          13,
          51346
        ]
      },
      {
        "avg_logprob": -0.21625312270632216,
        "compression_ratio": 1.8131147540983608,
        "end": 2737.64,
        "id": 669,
        "no_speech_prob": 0.0012643691152334213,
        "seek": 271652,
        "start": 2736.16,
        "temperature": 0,
        "text": " That drops me into a mongo shell.",
        "tokens": [
          51346,
          663,
          11438,
          385,
          666,
          257,
          275,
          25729,
          8720,
          13,
          51420
        ]
      },
      {
        "avg_logprob": -0.21625312270632216,
        "compression_ratio": 1.8131147540983608,
        "end": 2740.68,
        "id": 670,
        "no_speech_prob": 0.0012643691152334213,
        "seek": 271652,
        "start": 2737.64,
        "temperature": 0,
        "text": " And I can actually query the database, insert stuff in,",
        "tokens": [
          51420,
          400,
          286,
          393,
          767,
          14581,
          264,
          8149,
          11,
          8969,
          1507,
          294,
          11,
          51572
        ]
      },
      {
        "avg_logprob": -0.21625312270632216,
        "compression_ratio": 1.8131147540983608,
        "end": 2742.96,
        "id": 671,
        "no_speech_prob": 0.0012643691152334213,
        "seek": 271652,
        "start": 2740.68,
        "temperature": 0,
        "text": " and interact with it in this way.",
        "tokens": [
          51572,
          293,
          4648,
          365,
          309,
          294,
          341,
          636,
          13,
          51686
        ]
      },
      {
        "avg_logprob": -0.21625312270632216,
        "compression_ratio": 1.8131147540983608,
        "end": 2745.7599999999998,
        "id": 672,
        "no_speech_prob": 0.0012643691152334213,
        "seek": 271652,
        "start": 2742.96,
        "temperature": 0,
        "text": " But as long as you have it installed and running,",
        "tokens": [
          51686,
          583,
          382,
          938,
          382,
          291,
          362,
          309,
          8899,
          293,
          2614,
          11,
          51826
        ]
      },
      {
        "avg_logprob": -0.21628149624528556,
        "compression_ratio": 1.9126984126984128,
        "end": 2747.44,
        "id": 673,
        "no_speech_prob": 0.000059205696743447334,
        "seek": 274576,
        "start": 2745.76,
        "temperature": 0,
        "text": " the stuff I'm showing now will allow",
        "tokens": [
          50364,
          264,
          1507,
          286,
          478,
          4099,
          586,
          486,
          2089,
          50448
        ]
      },
      {
        "avg_logprob": -0.21628149624528556,
        "compression_ratio": 1.9126984126984128,
        "end": 2750.36,
        "id": 674,
        "no_speech_prob": 0.000059205696743447334,
        "seek": 274576,
        "start": 2747.44,
        "temperature": 0,
        "text": " you to connect to your database.",
        "tokens": [
          50448,
          291,
          281,
          1745,
          281,
          428,
          8149,
          13,
          50594
        ]
      },
      {
        "avg_logprob": -0.21628149624528556,
        "compression_ratio": 1.9126984126984128,
        "end": 2751.88,
        "id": 675,
        "no_speech_prob": 0.000059205696743447334,
        "seek": 274576,
        "start": 2750.36,
        "temperature": 0,
        "text": " So I installed Monk.",
        "tokens": [
          50594,
          407,
          286,
          8899,
          4713,
          74,
          13,
          50670
        ]
      },
      {
        "avg_logprob": -0.21628149624528556,
        "compression_ratio": 1.9126984126984128,
        "end": 2753.0800000000004,
        "id": 676,
        "no_speech_prob": 0.000059205696743447334,
        "seek": 274576,
        "start": 2751.88,
        "temperature": 0,
        "text": " And let's get it going.",
        "tokens": [
          50670,
          400,
          718,
          311,
          483,
          309,
          516,
          13,
          50730
        ]
      },
      {
        "avg_logprob": -0.21628149624528556,
        "compression_ratio": 1.9126984126984128,
        "end": 2755,
        "id": 677,
        "no_speech_prob": 0.000059205696743447334,
        "seek": 274576,
        "start": 2753.0800000000004,
        "temperature": 0,
        "text": " So in my server, we're still on the server.",
        "tokens": [
          50730,
          407,
          294,
          452,
          7154,
          11,
          321,
          434,
          920,
          322,
          264,
          7154,
          13,
          50826
        ]
      },
      {
        "avg_logprob": -0.21628149624528556,
        "compression_ratio": 1.9126984126984128,
        "end": 2756.84,
        "id": 678,
        "no_speech_prob": 0.000059205696743447334,
        "seek": 274576,
        "start": 2755,
        "temperature": 0,
        "text": " Let's create a connection to the database.",
        "tokens": [
          50826,
          961,
          311,
          1884,
          257,
          4984,
          281,
          264,
          8149,
          13,
          50918
        ]
      },
      {
        "avg_logprob": -0.21628149624528556,
        "compression_ratio": 1.9126984126984128,
        "end": 2760.0200000000004,
        "id": 679,
        "no_speech_prob": 0.000059205696743447334,
        "seek": 274576,
        "start": 2756.84,
        "temperature": 0,
        "text": " First thing is we'll bring in Monk.",
        "tokens": [
          50918,
          2386,
          551,
          307,
          321,
          603,
          1565,
          294,
          4713,
          74,
          13,
          51077
        ]
      },
      {
        "avg_logprob": -0.21628149624528556,
        "compression_ratio": 1.9126984126984128,
        "end": 2764.1200000000003,
        "id": 680,
        "no_speech_prob": 0.000059205696743447334,
        "seek": 274576,
        "start": 2760.0200000000004,
        "temperature": 0,
        "text": " And then we will create a connection",
        "tokens": [
          51077,
          400,
          550,
          321,
          486,
          1884,
          257,
          4984,
          51282
        ]
      },
      {
        "avg_logprob": -0.21628149624528556,
        "compression_ratio": 1.9126984126984128,
        "end": 2765.2400000000002,
        "id": 681,
        "no_speech_prob": 0.000059205696743447334,
        "seek": 274576,
        "start": 2764.1200000000003,
        "temperature": 0,
        "text": " to the database using Monk.",
        "tokens": [
          51282,
          281,
          264,
          8149,
          1228,
          4713,
          74,
          13,
          51338
        ]
      },
      {
        "avg_logprob": -0.21628149624528556,
        "compression_ratio": 1.9126984126984128,
        "end": 2766.5600000000004,
        "id": 682,
        "no_speech_prob": 0.000059205696743447334,
        "seek": 274576,
        "start": 2765.2400000000002,
        "temperature": 0,
        "text": " So I'm going to create a variable called db.",
        "tokens": [
          51338,
          407,
          286,
          478,
          516,
          281,
          1884,
          257,
          7006,
          1219,
          274,
          65,
          13,
          51404
        ]
      },
      {
        "avg_logprob": -0.21628149624528556,
        "compression_ratio": 1.9126984126984128,
        "end": 2767.6400000000003,
        "id": 683,
        "no_speech_prob": 0.000059205696743447334,
        "seek": 274576,
        "start": 2766.5600000000004,
        "temperature": 0,
        "text": " This will be Monk.",
        "tokens": [
          51404,
          639,
          486,
          312,
          4713,
          74,
          13,
          51458
        ]
      },
      {
        "avg_logprob": -0.21628149624528556,
        "compression_ratio": 1.9126984126984128,
        "end": 2770.84,
        "id": 684,
        "no_speech_prob": 0.000059205696743447334,
        "seek": 274576,
        "start": 2767.6400000000003,
        "temperature": 0,
        "text": " And then you pass in how does it connect to the database.",
        "tokens": [
          51458,
          400,
          550,
          291,
          1320,
          294,
          577,
          775,
          309,
          1745,
          281,
          264,
          8149,
          13,
          51618
        ]
      },
      {
        "avg_logprob": -0.21628149624528556,
        "compression_ratio": 1.9126984126984128,
        "end": 2774.92,
        "id": 685,
        "no_speech_prob": 0.000059205696743447334,
        "seek": 274576,
        "start": 2770.84,
        "temperature": 0,
        "text": " In this case, my database is running on my local machine.",
        "tokens": [
          51618,
          682,
          341,
          1389,
          11,
          452,
          8149,
          307,
          2614,
          322,
          452,
          2654,
          3479,
          13,
          51822
        ]
      },
      {
        "avg_logprob": -0.23453247289863421,
        "compression_ratio": 1.6978417266187051,
        "end": 2776.16,
        "id": 686,
        "no_speech_prob": 0.00013135051995050162,
        "seek": 277492,
        "start": 2774.92,
        "temperature": 0,
        "text": " So I can do local host.",
        "tokens": [
          50364,
          407,
          286,
          393,
          360,
          2654,
          3975,
          13,
          50426
        ]
      },
      {
        "avg_logprob": -0.23453247289863421,
        "compression_ratio": 1.6978417266187051,
        "end": 2779.6800000000003,
        "id": 687,
        "no_speech_prob": 0.00013135051995050162,
        "seek": 277492,
        "start": 2776.16,
        "temperature": 0,
        "text": " And I tell it what database do I want to talk to.",
        "tokens": [
          50426,
          400,
          286,
          980,
          309,
          437,
          8149,
          360,
          286,
          528,
          281,
          751,
          281,
          13,
          50602
        ]
      },
      {
        "avg_logprob": -0.23453247289863421,
        "compression_ratio": 1.6978417266187051,
        "end": 2783.04,
        "id": 688,
        "no_speech_prob": 0.00013135051995050162,
        "seek": 277492,
        "start": 2779.6800000000003,
        "temperature": 0,
        "text": " In this case, we'll call it Meower.",
        "tokens": [
          50602,
          682,
          341,
          1389,
          11,
          321,
          603,
          818,
          309,
          42996,
          260,
          13,
          50770
        ]
      },
      {
        "avg_logprob": -0.23453247289863421,
        "compression_ratio": 1.6978417266187051,
        "end": 2785.96,
        "id": 689,
        "no_speech_prob": 0.00013135051995050162,
        "seek": 277492,
        "start": 2783.04,
        "temperature": 0,
        "text": " And right now, this just says connect",
        "tokens": [
          50770,
          400,
          558,
          586,
          11,
          341,
          445,
          1619,
          1745,
          50916
        ]
      },
      {
        "avg_logprob": -0.23453247289863421,
        "compression_ratio": 1.6978417266187051,
        "end": 2787.88,
        "id": 690,
        "no_speech_prob": 0.00013135051995050162,
        "seek": 277492,
        "start": 2785.96,
        "temperature": 0,
        "text": " to the MongoDB on my local machine",
        "tokens": [
          50916,
          281,
          264,
          48380,
          27735,
          322,
          452,
          2654,
          3479,
          51012
        ]
      },
      {
        "avg_logprob": -0.23453247289863421,
        "compression_ratio": 1.6978417266187051,
        "end": 2789.8,
        "id": 691,
        "no_speech_prob": 0.00013135051995050162,
        "seek": 277492,
        "start": 2787.88,
        "temperature": 0,
        "text": " to a database called Meower.",
        "tokens": [
          51012,
          281,
          257,
          8149,
          1219,
          42996,
          260,
          13,
          51108
        ]
      },
      {
        "avg_logprob": -0.23453247289863421,
        "compression_ratio": 1.6978417266187051,
        "end": 2791.4,
        "id": 692,
        "no_speech_prob": 0.00013135051995050162,
        "seek": 277492,
        "start": 2789.8,
        "temperature": 0,
        "text": " Simple enough.",
        "tokens": [
          51108,
          21532,
          1547,
          13,
          51188
        ]
      },
      {
        "avg_logprob": -0.23453247289863421,
        "compression_ratio": 1.6978417266187051,
        "end": 2793.44,
        "id": 693,
        "no_speech_prob": 0.00013135051995050162,
        "seek": 277492,
        "start": 2791.4,
        "temperature": 0,
        "text": " The way Mongo works is with collections.",
        "tokens": [
          51188,
          440,
          636,
          48380,
          1985,
          307,
          365,
          16641,
          13,
          51290
        ]
      },
      {
        "avg_logprob": -0.23453247289863421,
        "compression_ratio": 1.6978417266187051,
        "end": 2795.28,
        "id": 694,
        "no_speech_prob": 0.00013135051995050162,
        "seek": 277492,
        "start": 2793.44,
        "temperature": 0,
        "text": " You can have different collections of data.",
        "tokens": [
          51290,
          509,
          393,
          362,
          819,
          16641,
          295,
          1412,
          13,
          51382
        ]
      },
      {
        "avg_logprob": -0.23453247289863421,
        "compression_ratio": 1.6978417266187051,
        "end": 2797.7200000000003,
        "id": 695,
        "no_speech_prob": 0.00013135051995050162,
        "seek": 277492,
        "start": 2795.28,
        "temperature": 0,
        "text": " Think of a collection as just basically an array.",
        "tokens": [
          51382,
          6557,
          295,
          257,
          5765,
          382,
          445,
          1936,
          364,
          10225,
          13,
          51504
        ]
      },
      {
        "avg_logprob": -0.23453247289863421,
        "compression_ratio": 1.6978417266187051,
        "end": 2799.84,
        "id": 696,
        "no_speech_prob": 0.00013135051995050162,
        "seek": 277492,
        "start": 2797.7200000000003,
        "temperature": 0,
        "text": " So ultimately, what we're going to be doing",
        "tokens": [
          51504,
          407,
          6284,
          11,
          437,
          321,
          434,
          516,
          281,
          312,
          884,
          51610
        ]
      },
      {
        "avg_logprob": -0.23453247289863421,
        "compression_ratio": 1.6978417266187051,
        "end": 2800.96,
        "id": 697,
        "no_speech_prob": 0.00013135051995050162,
        "seek": 277492,
        "start": 2799.84,
        "temperature": 0,
        "text": " is we'll have an array.",
        "tokens": [
          51610,
          307,
          321,
          603,
          362,
          364,
          10225,
          13,
          51666
        ]
      },
      {
        "avg_logprob": -0.23453247289863421,
        "compression_ratio": 1.6978417266187051,
        "end": 2803.2000000000003,
        "id": 698,
        "no_speech_prob": 0.00013135051995050162,
        "seek": 277492,
        "start": 2800.96,
        "temperature": 0,
        "text": " And then every time someone submits a mew,",
        "tokens": [
          51666,
          400,
          550,
          633,
          565,
          1580,
          8286,
          1208,
          257,
          385,
          86,
          11,
          51778
        ]
      },
      {
        "avg_logprob": -0.19858057135777757,
        "compression_ratio": 1.8020134228187918,
        "end": 2805.72,
        "id": 699,
        "no_speech_prob": 0.000024682747607585043,
        "seek": 280320,
        "start": 2803.2,
        "temperature": 0,
        "text": " we'll put an object in here that has a name.",
        "tokens": [
          50364,
          321,
          603,
          829,
          364,
          2657,
          294,
          510,
          300,
          575,
          257,
          1315,
          13,
          50490
        ]
      },
      {
        "avg_logprob": -0.19858057135777757,
        "compression_ratio": 1.8020134228187918,
        "end": 2807.8799999999997,
        "id": 700,
        "no_speech_prob": 0.000024682747607585043,
        "seek": 280320,
        "start": 2805.72,
        "temperature": 0,
        "text": " And it has some content.",
        "tokens": [
          50490,
          400,
          309,
          575,
          512,
          2701,
          13,
          50598
        ]
      },
      {
        "avg_logprob": -0.19858057135777757,
        "compression_ratio": 1.8020134228187918,
        "end": 2809.96,
        "id": 701,
        "no_speech_prob": 0.000024682747607585043,
        "seek": 280320,
        "start": 2807.8799999999997,
        "temperature": 0,
        "text": " And then Mongo will automatically",
        "tokens": [
          50598,
          400,
          550,
          48380,
          486,
          6772,
          50702
        ]
      },
      {
        "avg_logprob": -0.19858057135777757,
        "compression_ratio": 1.8020134228187918,
        "end": 2812.72,
        "id": 702,
        "no_speech_prob": 0.000024682747607585043,
        "seek": 280320,
        "start": 2809.96,
        "temperature": 0,
        "text": " assign it some unique ID.",
        "tokens": [
          50702,
          6269,
          309,
          512,
          3845,
          7348,
          13,
          50840
        ]
      },
      {
        "avg_logprob": -0.19858057135777757,
        "compression_ratio": 1.8020134228187918,
        "end": 2815.48,
        "id": 703,
        "no_speech_prob": 0.000024682747607585043,
        "seek": 280320,
        "start": 2812.72,
        "temperature": 0,
        "text": " But basically, every time we put something in the database,",
        "tokens": [
          50840,
          583,
          1936,
          11,
          633,
          565,
          321,
          829,
          746,
          294,
          264,
          8149,
          11,
          50978
        ]
      },
      {
        "avg_logprob": -0.19858057135777757,
        "compression_ratio": 1.8020134228187918,
        "end": 2818.6,
        "id": 704,
        "no_speech_prob": 0.000024682747607585043,
        "seek": 280320,
        "start": 2815.48,
        "temperature": 0,
        "text": " this array is just getting bigger and bigger and bigger.",
        "tokens": [
          50978,
          341,
          10225,
          307,
          445,
          1242,
          3801,
          293,
          3801,
          293,
          3801,
          13,
          51134
        ]
      },
      {
        "avg_logprob": -0.19858057135777757,
        "compression_ratio": 1.8020134228187918,
        "end": 2821.16,
        "id": 705,
        "no_speech_prob": 0.000024682747607585043,
        "seek": 280320,
        "start": 2818.6,
        "temperature": 0,
        "text": " But the cool thing about this is it's not just an array.",
        "tokens": [
          51134,
          583,
          264,
          1627,
          551,
          466,
          341,
          307,
          309,
          311,
          406,
          445,
          364,
          10225,
          13,
          51262
        ]
      },
      {
        "avg_logprob": -0.19858057135777757,
        "compression_ratio": 1.8020134228187918,
        "end": 2822.48,
        "id": 706,
        "no_speech_prob": 0.000024682747607585043,
        "seek": 280320,
        "start": 2821.16,
        "temperature": 0,
        "text": " It's a full-fledged database.",
        "tokens": [
          51262,
          467,
          311,
          257,
          1577,
          12,
          69,
          1493,
          3004,
          8149,
          13,
          51328
        ]
      },
      {
        "avg_logprob": -0.19858057135777757,
        "compression_ratio": 1.8020134228187918,
        "end": 2824.24,
        "id": 707,
        "no_speech_prob": 0.000024682747607585043,
        "seek": 280320,
        "start": 2822.48,
        "temperature": 0,
        "text": " It keeps track of the information.",
        "tokens": [
          51328,
          467,
          5965,
          2837,
          295,
          264,
          1589,
          13,
          51416
        ]
      },
      {
        "avg_logprob": -0.19858057135777757,
        "compression_ratio": 1.8020134228187918,
        "end": 2826.48,
        "id": 708,
        "no_speech_prob": 0.000024682747607585043,
        "seek": 280320,
        "start": 2824.24,
        "temperature": 0,
        "text": " If the server ever goes down, it's all still there.",
        "tokens": [
          51416,
          759,
          264,
          7154,
          1562,
          1709,
          760,
          11,
          309,
          311,
          439,
          920,
          456,
          13,
          51528
        ]
      },
      {
        "avg_logprob": -0.19858057135777757,
        "compression_ratio": 1.8020134228187918,
        "end": 2828.64,
        "id": 709,
        "no_speech_prob": 0.000024682747607585043,
        "seek": 280320,
        "start": 2826.48,
        "temperature": 0,
        "text": " But that's pretty much what you can think of a Mongo",
        "tokens": [
          51528,
          583,
          300,
          311,
          1238,
          709,
          437,
          291,
          393,
          519,
          295,
          257,
          48380,
          51636
        ]
      },
      {
        "avg_logprob": -0.19858057135777757,
        "compression_ratio": 1.8020134228187918,
        "end": 2829.2,
        "id": 710,
        "no_speech_prob": 0.000024682747607585043,
        "seek": 280320,
        "start": 2828.64,
        "temperature": 0,
        "text": " collection as.",
        "tokens": [
          51636,
          5765,
          382,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19858057135777757,
        "compression_ratio": 1.8020134228187918,
        "end": 2831.6,
        "id": 711,
        "no_speech_prob": 0.000024682747607585043,
        "seek": 280320,
        "start": 2829.2,
        "temperature": 0,
        "text": " It's just a database or an array that we're just",
        "tokens": [
          51664,
          467,
          311,
          445,
          257,
          8149,
          420,
          364,
          10225,
          300,
          321,
          434,
          445,
          51784
        ]
      },
      {
        "avg_logprob": -0.23175431721246065,
        "compression_ratio": 2.0308370044052864,
        "end": 2833.2,
        "id": 712,
        "no_speech_prob": 0.00006302729161689058,
        "seek": 283160,
        "start": 2831.6,
        "temperature": 0,
        "text": " pushing data into.",
        "tokens": [
          50364,
          7380,
          1412,
          666,
          13,
          50444
        ]
      },
      {
        "avg_logprob": -0.23175431721246065,
        "compression_ratio": 2.0308370044052864,
        "end": 2837.12,
        "id": 713,
        "no_speech_prob": 0.00006302729161689058,
        "seek": 283160,
        "start": 2833.2,
        "temperature": 0,
        "text": " So I want a collection called mews.",
        "tokens": [
          50444,
          407,
          286,
          528,
          257,
          5765,
          1219,
          385,
          14358,
          13,
          50640
        ]
      },
      {
        "avg_logprob": -0.23175431721246065,
        "compression_ratio": 2.0308370044052864,
        "end": 2839.4,
        "id": 714,
        "no_speech_prob": 0.00006302729161689058,
        "seek": 283160,
        "start": 2837.12,
        "temperature": 0,
        "text": " So I'm going to create a variable called mews and say",
        "tokens": [
          50640,
          407,
          286,
          478,
          516,
          281,
          1884,
          257,
          7006,
          1219,
          385,
          14358,
          293,
          584,
          50754
        ]
      },
      {
        "avg_logprob": -0.23175431721246065,
        "compression_ratio": 2.0308370044052864,
        "end": 2839.88,
        "id": 715,
        "no_speech_prob": 0.00006302729161689058,
        "seek": 283160,
        "start": 2839.4,
        "temperature": 0,
        "text": " db.get.",
        "tokens": [
          50754,
          274,
          65,
          13,
          847,
          13,
          50778
        ]
      },
      {
        "avg_logprob": -0.23175431721246065,
        "compression_ratio": 2.0308370044052864,
        "end": 2841.6,
        "id": 716,
        "no_speech_prob": 0.00006302729161689058,
        "seek": 283160,
        "start": 2839.88,
        "temperature": 0,
        "text": " And we'll just pass in mews.",
        "tokens": [
          50778,
          400,
          321,
          603,
          445,
          1320,
          294,
          385,
          14358,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.23175431721246065,
        "compression_ratio": 2.0308370044052864,
        "end": 2845.2799999999997,
        "id": 717,
        "no_speech_prob": 0.00006302729161689058,
        "seek": 283160,
        "start": 2841.6,
        "temperature": 0,
        "text": " So this is now a collection.",
        "tokens": [
          50864,
          407,
          341,
          307,
          586,
          257,
          5765,
          13,
          51048
        ]
      },
      {
        "avg_logprob": -0.23175431721246065,
        "compression_ratio": 2.0308370044052864,
        "end": 2847.36,
        "id": 718,
        "no_speech_prob": 0.00006302729161689058,
        "seek": 283160,
        "start": 2845.2799999999997,
        "temperature": 0,
        "text": " And the cool thing about Mongo is",
        "tokens": [
          51048,
          400,
          264,
          1627,
          551,
          466,
          48380,
          307,
          51152
        ]
      },
      {
        "avg_logprob": -0.23175431721246065,
        "compression_ratio": 2.0308370044052864,
        "end": 2849.04,
        "id": 719,
        "no_speech_prob": 0.00006302729161689058,
        "seek": 283160,
        "start": 2847.36,
        "temperature": 0,
        "text": " if the database doesn't exist, this",
        "tokens": [
          51152,
          498,
          264,
          8149,
          1177,
          380,
          2514,
          11,
          341,
          51236
        ]
      },
      {
        "avg_logprob": -0.23175431721246065,
        "compression_ratio": 2.0308370044052864,
        "end": 2850.2,
        "id": 720,
        "no_speech_prob": 0.00006302729161689058,
        "seek": 283160,
        "start": 2849.04,
        "temperature": 0,
        "text": " will automatically create it.",
        "tokens": [
          51236,
          486,
          6772,
          1884,
          309,
          13,
          51294
        ]
      },
      {
        "avg_logprob": -0.23175431721246065,
        "compression_ratio": 2.0308370044052864,
        "end": 2851.88,
        "id": 721,
        "no_speech_prob": 0.00006302729161689058,
        "seek": 283160,
        "start": 2850.2,
        "temperature": 0,
        "text": " If the collection doesn't exist, this",
        "tokens": [
          51294,
          759,
          264,
          5765,
          1177,
          380,
          2514,
          11,
          341,
          51378
        ]
      },
      {
        "avg_logprob": -0.23175431721246065,
        "compression_ratio": 2.0308370044052864,
        "end": 2853.16,
        "id": 722,
        "no_speech_prob": 0.00006302729161689058,
        "seek": 283160,
        "start": 2851.88,
        "temperature": 0,
        "text": " will automatically create it.",
        "tokens": [
          51378,
          486,
          6772,
          1884,
          309,
          13,
          51442
        ]
      },
      {
        "avg_logprob": -0.23175431721246065,
        "compression_ratio": 2.0308370044052864,
        "end": 2856.04,
        "id": 723,
        "no_speech_prob": 0.00006302729161689058,
        "seek": 283160,
        "start": 2853.16,
        "temperature": 0,
        "text": " So we basically are just connecting directly",
        "tokens": [
          51442,
          407,
          321,
          1936,
          366,
          445,
          11015,
          3838,
          51586
        ]
      },
      {
        "avg_logprob": -0.23175431721246065,
        "compression_ratio": 2.0308370044052864,
        "end": 2856.7599999999998,
        "id": 724,
        "no_speech_prob": 0.00006302729161689058,
        "seek": 283160,
        "start": 2856.04,
        "temperature": 0,
        "text": " to the database.",
        "tokens": [
          51586,
          281,
          264,
          8149,
          13,
          51622
        ]
      },
      {
        "avg_logprob": -0.23175431721246065,
        "compression_ratio": 2.0308370044052864,
        "end": 2861.2,
        "id": 725,
        "no_speech_prob": 0.00006302729161689058,
        "seek": 283160,
        "start": 2856.7599999999998,
        "temperature": 0,
        "text": " And if it doesn't exist, we're creating that collection.",
        "tokens": [
          51622,
          400,
          498,
          309,
          1177,
          380,
          2514,
          11,
          321,
          434,
          4084,
          300,
          5765,
          13,
          51844
        ]
      },
      {
        "avg_logprob": -0.22414090599812253,
        "compression_ratio": 1.7352941176470589,
        "end": 2865.64,
        "id": 726,
        "no_speech_prob": 0.000007296364856301807,
        "seek": 286120,
        "start": 2862.08,
        "temperature": 0,
        "text": " Now, mews is a collection inside of our database.",
        "tokens": [
          50408,
          823,
          11,
          385,
          14358,
          307,
          257,
          5765,
          1854,
          295,
          527,
          8149,
          13,
          50586
        ]
      },
      {
        "avg_logprob": -0.22414090599812253,
        "compression_ratio": 1.7352941176470589,
        "end": 2868.52,
        "id": 727,
        "no_speech_prob": 0.000007296364856301807,
        "seek": 286120,
        "start": 2865.64,
        "temperature": 0,
        "text": " And here, after we've done all of our validation,",
        "tokens": [
          50586,
          400,
          510,
          11,
          934,
          321,
          600,
          1096,
          439,
          295,
          527,
          24071,
          11,
          50730
        ]
      },
      {
        "avg_logprob": -0.22414090599812253,
        "compression_ratio": 1.7352941176470589,
        "end": 2870.24,
        "id": 728,
        "no_speech_prob": 0.000007296364856301807,
        "seek": 286120,
        "start": 2868.52,
        "temperature": 0,
        "text": " we want to insert it into the database.",
        "tokens": [
          50730,
          321,
          528,
          281,
          8969,
          309,
          666,
          264,
          8149,
          13,
          50816
        ]
      },
      {
        "avg_logprob": -0.22414090599812253,
        "compression_ratio": 1.7352941176470589,
        "end": 2873.4399999999996,
        "id": 729,
        "no_speech_prob": 0.000007296364856301807,
        "seek": 286120,
        "start": 2870.24,
        "temperature": 0,
        "text": " So let's just do mews.insert.",
        "tokens": [
          50816,
          407,
          718,
          311,
          445,
          360,
          385,
          14358,
          13,
          1292,
          911,
          13,
          50976
        ]
      },
      {
        "avg_logprob": -0.22414090599812253,
        "compression_ratio": 1.7352941176470589,
        "end": 2875.8799999999997,
        "id": 730,
        "no_speech_prob": 0.000007296364856301807,
        "seek": 286120,
        "start": 2873.4399999999996,
        "temperature": 0,
        "text": " And specifically, if you want to know how to use MonkMore,",
        "tokens": [
          50976,
          400,
          4682,
          11,
          498,
          291,
          528,
          281,
          458,
          577,
          281,
          764,
          4713,
          74,
          44,
          284,
          68,
          11,
          51098
        ]
      },
      {
        "avg_logprob": -0.22414090599812253,
        "compression_ratio": 1.7352941176470589,
        "end": 2877,
        "id": 731,
        "no_speech_prob": 0.000007296364856301807,
        "seek": 286120,
        "start": 2875.8799999999997,
        "temperature": 0,
        "text": " you can look at their documentation.",
        "tokens": [
          51098,
          291,
          393,
          574,
          412,
          641,
          14333,
          13,
          51154
        ]
      },
      {
        "avg_logprob": -0.22414090599812253,
        "compression_ratio": 1.7352941176470589,
        "end": 2879.48,
        "id": 732,
        "no_speech_prob": 0.000007296364856301807,
        "seek": 286120,
        "start": 2877,
        "temperature": 0,
        "text": " There's all kinds of methods, like insert and update",
        "tokens": [
          51154,
          821,
          311,
          439,
          3685,
          295,
          7150,
          11,
          411,
          8969,
          293,
          5623,
          51278
        ]
      },
      {
        "avg_logprob": -0.22414090599812253,
        "compression_ratio": 1.7352941176470589,
        "end": 2880.2799999999997,
        "id": 733,
        "no_speech_prob": 0.000007296364856301807,
        "seek": 286120,
        "start": 2879.48,
        "temperature": 0,
        "text": " and find.",
        "tokens": [
          51278,
          293,
          915,
          13,
          51318
        ]
      },
      {
        "avg_logprob": -0.22414090599812253,
        "compression_ratio": 1.7352941176470589,
        "end": 2882.48,
        "id": 734,
        "no_speech_prob": 0.000007296364856301807,
        "seek": 286120,
        "start": 2880.2799999999997,
        "temperature": 0,
        "text": " Specifically, I'm using the insert method.",
        "tokens": [
          51318,
          26058,
          11,
          286,
          478,
          1228,
          264,
          8969,
          3170,
          13,
          51428
        ]
      },
      {
        "avg_logprob": -0.22414090599812253,
        "compression_ratio": 1.7352941176470589,
        "end": 2884.96,
        "id": 735,
        "no_speech_prob": 0.000007296364856301807,
        "seek": 286120,
        "start": 2882.48,
        "temperature": 0,
        "text": " And I'm going to pass in the mew that I want to insert.",
        "tokens": [
          51428,
          400,
          286,
          478,
          516,
          281,
          1320,
          294,
          264,
          385,
          86,
          300,
          286,
          528,
          281,
          8969,
          13,
          51552
        ]
      },
      {
        "avg_logprob": -0.22414090599812253,
        "compression_ratio": 1.7352941176470589,
        "end": 2888.8399999999997,
        "id": 736,
        "no_speech_prob": 0.000007296364856301807,
        "seek": 286120,
        "start": 2884.96,
        "temperature": 0,
        "text": " And then we should get back the created mew.",
        "tokens": [
          51552,
          400,
          550,
          321,
          820,
          483,
          646,
          264,
          2942,
          385,
          86,
          13,
          51746
        ]
      },
      {
        "avg_logprob": -0.2075934574521821,
        "compression_ratio": 1.7232472324723247,
        "end": 2890.48,
        "id": 737,
        "no_speech_prob": 0.00008888052252586931,
        "seek": 288884,
        "start": 2888.84,
        "temperature": 0,
        "text": " And in this case, I'm just going",
        "tokens": [
          50364,
          400,
          294,
          341,
          1389,
          11,
          286,
          478,
          445,
          516,
          50446
        ]
      },
      {
        "avg_logprob": -0.2075934574521821,
        "compression_ratio": 1.7232472324723247,
        "end": 2893,
        "id": 738,
        "no_speech_prob": 0.00008888052252586931,
        "seek": 288884,
        "start": 2890.48,
        "temperature": 0,
        "text": " to respond back to the client with what was just created.",
        "tokens": [
          50446,
          281,
          4196,
          646,
          281,
          264,
          6423,
          365,
          437,
          390,
          445,
          2942,
          13,
          50572
        ]
      },
      {
        "avg_logprob": -0.2075934574521821,
        "compression_ratio": 1.7232472324723247,
        "end": 2894.6000000000004,
        "id": 739,
        "no_speech_prob": 0.00008888052252586931,
        "seek": 288884,
        "start": 2893,
        "temperature": 0,
        "text": " So I'm going to do a res.json.",
        "tokens": [
          50572,
          407,
          286,
          478,
          516,
          281,
          360,
          257,
          725,
          13,
          73,
          3015,
          13,
          50652
        ]
      },
      {
        "avg_logprob": -0.2075934574521821,
        "compression_ratio": 1.7232472324723247,
        "end": 2896.88,
        "id": 740,
        "no_speech_prob": 0.00008888052252586931,
        "seek": 288884,
        "start": 2894.6000000000004,
        "temperature": 0,
        "text": " We'll pass in the created mew.",
        "tokens": [
          50652,
          492,
          603,
          1320,
          294,
          264,
          2942,
          385,
          86,
          13,
          50766
        ]
      },
      {
        "avg_logprob": -0.2075934574521821,
        "compression_ratio": 1.7232472324723247,
        "end": 2898.04,
        "id": 741,
        "no_speech_prob": 0.00008888052252586931,
        "seek": 288884,
        "start": 2896.88,
        "temperature": 0,
        "text": " And let's see what happens.",
        "tokens": [
          50766,
          400,
          718,
          311,
          536,
          437,
          2314,
          13,
          50824
        ]
      },
      {
        "avg_logprob": -0.2075934574521821,
        "compression_ratio": 1.7232472324723247,
        "end": 2902.56,
        "id": 742,
        "no_speech_prob": 0.00008888052252586931,
        "seek": 288884,
        "start": 2898.04,
        "temperature": 0,
        "text": " So let's back up a little bit.",
        "tokens": [
          50824,
          407,
          718,
          311,
          646,
          493,
          257,
          707,
          857,
          13,
          51050
        ]
      },
      {
        "avg_logprob": -0.2075934574521821,
        "compression_ratio": 1.7232472324723247,
        "end": 2906,
        "id": 743,
        "no_speech_prob": 0.00008888052252586931,
        "seek": 288884,
        "start": 2902.56,
        "temperature": 0,
        "text": " We are listening for when the client is sending",
        "tokens": [
          51050,
          492,
          366,
          4764,
          337,
          562,
          264,
          6423,
          307,
          7750,
          51222
        ]
      },
      {
        "avg_logprob": -0.2075934574521821,
        "compression_ratio": 1.7232472324723247,
        "end": 2908.48,
        "id": 744,
        "no_speech_prob": 0.00008888052252586931,
        "seek": 288884,
        "start": 2906,
        "temperature": 0,
        "text": " a POST request to this URL.",
        "tokens": [
          51222,
          257,
          430,
          28067,
          5308,
          281,
          341,
          12905,
          13,
          51346
        ]
      },
      {
        "avg_logprob": -0.2075934574521821,
        "compression_ratio": 1.7232472324723247,
        "end": 2909.52,
        "id": 745,
        "no_speech_prob": 0.00008888052252586931,
        "seek": 288884,
        "start": 2908.48,
        "temperature": 0,
        "text": " They're sending us data.",
        "tokens": [
          51346,
          814,
          434,
          7750,
          505,
          1412,
          13,
          51398
        ]
      },
      {
        "avg_logprob": -0.2075934574521821,
        "compression_ratio": 1.7232472324723247,
        "end": 2911.44,
        "id": 746,
        "no_speech_prob": 0.00008888052252586931,
        "seek": 288884,
        "start": 2909.52,
        "temperature": 0,
        "text": " We're going to validate it before we insert it",
        "tokens": [
          51398,
          492,
          434,
          516,
          281,
          29562,
          309,
          949,
          321,
          8969,
          309,
          51494
        ]
      },
      {
        "avg_logprob": -0.2075934574521821,
        "compression_ratio": 1.7232472324723247,
        "end": 2912.1600000000003,
        "id": 747,
        "no_speech_prob": 0.00008888052252586931,
        "seek": 288884,
        "start": 2911.44,
        "temperature": 0,
        "text": " into our database.",
        "tokens": [
          51494,
          666,
          527,
          8149,
          13,
          51530
        ]
      },
      {
        "avg_logprob": -0.2075934574521821,
        "compression_ratio": 1.7232472324723247,
        "end": 2913.48,
        "id": 748,
        "no_speech_prob": 0.00008888052252586931,
        "seek": 288884,
        "start": 2912.1600000000003,
        "temperature": 0,
        "text": " We'll create the object.",
        "tokens": [
          51530,
          492,
          603,
          1884,
          264,
          2657,
          13,
          51596
        ]
      },
      {
        "avg_logprob": -0.2075934574521821,
        "compression_ratio": 1.7232472324723247,
        "end": 2916.7200000000003,
        "id": 749,
        "no_speech_prob": 0.00008888052252586931,
        "seek": 288884,
        "start": 2913.48,
        "temperature": 0,
        "text": " Then, using our existing collection here,",
        "tokens": [
          51596,
          1396,
          11,
          1228,
          527,
          6741,
          5765,
          510,
          11,
          51758
        ]
      },
      {
        "avg_logprob": -0.2075934574521821,
        "compression_ratio": 1.7232472324723247,
        "end": 2918.48,
        "id": 750,
        "no_speech_prob": 0.00008888052252586931,
        "seek": 288884,
        "start": 2916.7200000000003,
        "temperature": 0,
        "text": " we will insert it in.",
        "tokens": [
          51758,
          321,
          486,
          8969,
          309,
          294,
          13,
          51846
        ]
      },
      {
        "avg_logprob": -0.26117974201231514,
        "compression_ratio": 1.7032520325203253,
        "end": 2920.12,
        "id": 751,
        "no_speech_prob": 0.000021782574549433775,
        "seek": 291848,
        "start": 2918.64,
        "temperature": 0,
        "text": " And then once it's inserted, we're",
        "tokens": [
          50372,
          400,
          550,
          1564,
          309,
          311,
          27992,
          11,
          321,
          434,
          50446
        ]
      },
      {
        "avg_logprob": -0.26117974201231514,
        "compression_ratio": 1.7032520325203253,
        "end": 2922.72,
        "id": 752,
        "no_speech_prob": 0.000021782574549433775,
        "seek": 291848,
        "start": 2920.12,
        "temperature": 0,
        "text": " going to respond with what was just inserted.",
        "tokens": [
          50446,
          516,
          281,
          4196,
          365,
          437,
          390,
          445,
          27992,
          13,
          50576
        ]
      },
      {
        "avg_logprob": -0.26117974201231514,
        "compression_ratio": 1.7032520325203253,
        "end": 2924.92,
        "id": 753,
        "no_speech_prob": 0.000021782574549433775,
        "seek": 291848,
        "start": 2922.72,
        "temperature": 0,
        "text": " So save that.",
        "tokens": [
          50576,
          407,
          3155,
          300,
          13,
          50686
        ]
      },
      {
        "avg_logprob": -0.26117974201231514,
        "compression_ratio": 1.7032520325203253,
        "end": 2926.16,
        "id": 754,
        "no_speech_prob": 0.000021782574549433775,
        "seek": 291848,
        "start": 2924.92,
        "temperature": 0,
        "text": " Let's check some boxes.",
        "tokens": [
          50686,
          961,
          311,
          1520,
          512,
          9002,
          13,
          50748
        ]
      },
      {
        "avg_logprob": -0.26117974201231514,
        "compression_ratio": 1.7032520325203253,
        "end": 2928.48,
        "id": 755,
        "no_speech_prob": 0.000021782574549433775,
        "seek": 291848,
        "start": 2926.16,
        "temperature": 0,
        "text": " And then we'll check to make sure it works.",
        "tokens": [
          50748,
          400,
          550,
          321,
          603,
          1520,
          281,
          652,
          988,
          309,
          1985,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.26117974201231514,
        "compression_ratio": 1.7032520325203253,
        "end": 2929.84,
        "id": 756,
        "no_speech_prob": 0.000021782574549433775,
        "seek": 291848,
        "start": 2928.48,
        "temperature": 0,
        "text": " Cool.",
        "tokens": [
          50864,
          8561,
          13,
          50932
        ]
      },
      {
        "avg_logprob": -0.26117974201231514,
        "compression_ratio": 1.7032520325203253,
        "end": 2932.12,
        "id": 757,
        "no_speech_prob": 0.000021782574549433775,
        "seek": 291848,
        "start": 2929.84,
        "temperature": 0,
        "text": " Oh, and one thing I forgot is before we insert it,",
        "tokens": [
          50932,
          876,
          11,
          293,
          472,
          551,
          286,
          5298,
          307,
          949,
          321,
          8969,
          309,
          11,
          51046
        ]
      },
      {
        "avg_logprob": -0.26117974201231514,
        "compression_ratio": 1.7032520325203253,
        "end": 2933.52,
        "id": 758,
        "no_speech_prob": 0.000021782574549433775,
        "seek": 291848,
        "start": 2932.12,
        "temperature": 0,
        "text": " let's also give it a created date",
        "tokens": [
          51046,
          718,
          311,
          611,
          976,
          309,
          257,
          2942,
          4002,
          51116
        ]
      },
      {
        "avg_logprob": -0.26117974201231514,
        "compression_ratio": 1.7032520325203253,
        "end": 2935.92,
        "id": 759,
        "no_speech_prob": 0.000021782574549433775,
        "seek": 291848,
        "start": 2933.52,
        "temperature": 0,
        "text": " so we can actually show whenever these mews were created.",
        "tokens": [
          51116,
          370,
          321,
          393,
          767,
          855,
          5699,
          613,
          385,
          14358,
          645,
          2942,
          13,
          51236
        ]
      },
      {
        "avg_logprob": -0.26117974201231514,
        "compression_ratio": 1.7032520325203253,
        "end": 2939.8,
        "id": 760,
        "no_speech_prob": 0.000021782574549433775,
        "seek": 291848,
        "start": 2935.92,
        "temperature": 0,
        "text": " So for this, I'm just going to say created is a new date.",
        "tokens": [
          51236,
          407,
          337,
          341,
          11,
          286,
          478,
          445,
          516,
          281,
          584,
          2942,
          307,
          257,
          777,
          4002,
          13,
          51430
        ]
      },
      {
        "avg_logprob": -0.26117974201231514,
        "compression_ratio": 1.7032520325203253,
        "end": 2941.88,
        "id": 761,
        "no_speech_prob": 0.000021782574549433775,
        "seek": 291848,
        "start": 2939.8,
        "temperature": 0,
        "text": " Cool.",
        "tokens": [
          51430,
          8561,
          13,
          51534
        ]
      },
      {
        "avg_logprob": -0.26117974201231514,
        "compression_ratio": 1.7032520325203253,
        "end": 2944.2,
        "id": 762,
        "no_speech_prob": 0.000021782574549433775,
        "seek": 291848,
        "start": 2941.88,
        "temperature": 0,
        "text": " We've inserted it.",
        "tokens": [
          51534,
          492,
          600,
          27992,
          309,
          13,
          51650
        ]
      },
      {
        "avg_logprob": -0.26117974201231514,
        "compression_ratio": 1.7032520325203253,
        "end": 2946.76,
        "id": 763,
        "no_speech_prob": 0.000021782574549433775,
        "seek": 291848,
        "start": 2944.2,
        "temperature": 0,
        "text": " We've responded with it.",
        "tokens": [
          51650,
          492,
          600,
          15806,
          365,
          309,
          13,
          51778
        ]
      },
      {
        "avg_logprob": -0.20892976992058032,
        "compression_ratio": 1.7378277153558053,
        "end": 2949.36,
        "id": 764,
        "no_speech_prob": 0.000027535574190551415,
        "seek": 294676,
        "start": 2946.76,
        "temperature": 0,
        "text": " And as long as I've done everything right,",
        "tokens": [
          50364,
          400,
          382,
          938,
          382,
          286,
          600,
          1096,
          1203,
          558,
          11,
          50494
        ]
      },
      {
        "avg_logprob": -0.20892976992058032,
        "compression_ratio": 1.7378277153558053,
        "end": 2952.2400000000002,
        "id": 765,
        "no_speech_prob": 0.000027535574190551415,
        "seek": 294676,
        "start": 2949.36,
        "temperature": 0,
        "text": " we should be actually inserting it into my database.",
        "tokens": [
          50494,
          321,
          820,
          312,
          767,
          46567,
          309,
          666,
          452,
          8149,
          13,
          50638
        ]
      },
      {
        "avg_logprob": -0.20892976992058032,
        "compression_ratio": 1.7378277153558053,
        "end": 2954.2000000000003,
        "id": 766,
        "no_speech_prob": 0.000027535574190551415,
        "seek": 294676,
        "start": 2952.2400000000002,
        "temperature": 0,
        "text": " So now, back to the front end.",
        "tokens": [
          50638,
          407,
          586,
          11,
          646,
          281,
          264,
          1868,
          917,
          13,
          50736
        ]
      },
      {
        "avg_logprob": -0.20892976992058032,
        "compression_ratio": 1.7378277153558053,
        "end": 2956.44,
        "id": 767,
        "no_speech_prob": 0.000027535574190551415,
        "seek": 294676,
        "start": 2954.2000000000003,
        "temperature": 0,
        "text": " So if you remember, this was all initiated",
        "tokens": [
          50736,
          407,
          498,
          291,
          1604,
          11,
          341,
          390,
          439,
          28578,
          50848
        ]
      },
      {
        "avg_logprob": -0.20892976992058032,
        "compression_ratio": 1.7378277153558053,
        "end": 2957.6400000000003,
        "id": 768,
        "no_speech_prob": 0.000027535574190551415,
        "seek": 294676,
        "start": 2956.44,
        "temperature": 0,
        "text": " by this POST request here.",
        "tokens": [
          50848,
          538,
          341,
          430,
          28067,
          5308,
          510,
          13,
          50908
        ]
      },
      {
        "avg_logprob": -0.20892976992058032,
        "compression_ratio": 1.7378277153558053,
        "end": 2960.44,
        "id": 769,
        "no_speech_prob": 0.000027535574190551415,
        "seek": 294676,
        "start": 2957.6400000000003,
        "temperature": 0,
        "text": " The client is sending our server some data.",
        "tokens": [
          50908,
          440,
          6423,
          307,
          7750,
          527,
          7154,
          512,
          1412,
          13,
          51048
        ]
      },
      {
        "avg_logprob": -0.20892976992058032,
        "compression_ratio": 1.7378277153558053,
        "end": 2965.32,
        "id": 770,
        "no_speech_prob": 0.000027535574190551415,
        "seek": 294676,
        "start": 2960.44,
        "temperature": 0,
        "text": " And the server is then inserting it into the database.",
        "tokens": [
          51048,
          400,
          264,
          7154,
          307,
          550,
          46567,
          309,
          666,
          264,
          8149,
          13,
          51292
        ]
      },
      {
        "avg_logprob": -0.20892976992058032,
        "compression_ratio": 1.7378277153558053,
        "end": 2968.1200000000003,
        "id": 771,
        "no_speech_prob": 0.000027535574190551415,
        "seek": 294676,
        "start": 2965.32,
        "temperature": 0,
        "text": " And then now, we actually need to do something with it.",
        "tokens": [
          51292,
          400,
          550,
          586,
          11,
          321,
          767,
          643,
          281,
          360,
          746,
          365,
          309,
          13,
          51432
        ]
      },
      {
        "avg_logprob": -0.20892976992058032,
        "compression_ratio": 1.7378277153558053,
        "end": 2971.36,
        "id": 772,
        "no_speech_prob": 0.000027535574190551415,
        "seek": 294676,
        "start": 2968.1200000000003,
        "temperature": 0,
        "text": " So here, I'm just going to do a.then.",
        "tokens": [
          51432,
          407,
          510,
          11,
          286,
          478,
          445,
          516,
          281,
          360,
          257,
          2411,
          19096,
          13,
          51594
        ]
      },
      {
        "avg_logprob": -0.20892976992058032,
        "compression_ratio": 1.7378277153558053,
        "end": 2973.0400000000004,
        "id": 773,
        "no_speech_prob": 0.000027535574190551415,
        "seek": 294676,
        "start": 2971.36,
        "temperature": 0,
        "text": " We're going to get back the response.",
        "tokens": [
          51594,
          492,
          434,
          516,
          281,
          483,
          646,
          264,
          4134,
          13,
          51678
        ]
      },
      {
        "avg_logprob": -0.20892976992058032,
        "compression_ratio": 1.7378277153558053,
        "end": 2976.36,
        "id": 774,
        "no_speech_prob": 0.000027535574190551415,
        "seek": 294676,
        "start": 2973.0400000000004,
        "temperature": 0,
        "text": " And I know that the response is JSON",
        "tokens": [
          51678,
          400,
          286,
          458,
          300,
          264,
          4134,
          307,
          31828,
          51844
        ]
      },
      {
        "avg_logprob": -0.29711585574679905,
        "compression_ratio": 1.5314009661835748,
        "end": 2979.4,
        "id": 775,
        "no_speech_prob": 0.00010720817226683721,
        "seek": 297636,
        "start": 2976.44,
        "temperature": 0,
        "text": " because my server is responding with JSON.",
        "tokens": [
          50368,
          570,
          452,
          7154,
          307,
          16670,
          365,
          31828,
          13,
          50516
        ]
      },
      {
        "avg_logprob": -0.29711585574679905,
        "compression_ratio": 1.5314009661835748,
        "end": 2982.44,
        "id": 776,
        "no_speech_prob": 0.00010720817226683721,
        "seek": 297636,
        "start": 2979.4,
        "temperature": 0,
        "text": " So on the client side, I can say res.json.",
        "tokens": [
          50516,
          407,
          322,
          264,
          6423,
          1252,
          11,
          286,
          393,
          584,
          725,
          13,
          73,
          3015,
          13,
          50668
        ]
      },
      {
        "avg_logprob": -0.29711585574679905,
        "compression_ratio": 1.5314009661835748,
        "end": 2987.08,
        "id": 777,
        "no_speech_prob": 0.00010720817226683721,
        "seek": 297636,
        "start": 2982.44,
        "temperature": 0,
        "text": " And then I get access to the created mew.",
        "tokens": [
          50668,
          400,
          550,
          286,
          483,
          2105,
          281,
          264,
          2942,
          385,
          86,
          13,
          50900
        ]
      },
      {
        "avg_logprob": -0.29711585574679905,
        "compression_ratio": 1.5314009661835748,
        "end": 2988.48,
        "id": 778,
        "no_speech_prob": 0.00010720817226683721,
        "seek": 297636,
        "start": 2987.08,
        "temperature": 0,
        "text": " And for now, let's just log it.",
        "tokens": [
          50900,
          400,
          337,
          586,
          11,
          718,
          311,
          445,
          3565,
          309,
          13,
          50970
        ]
      },
      {
        "avg_logprob": -0.29711585574679905,
        "compression_ratio": 1.5314009661835748,
        "end": 2990.6800000000003,
        "id": 779,
        "no_speech_prob": 0.00010720817226683721,
        "seek": 297636,
        "start": 2988.48,
        "temperature": 0,
        "text": " So our client will send the request.",
        "tokens": [
          50970,
          407,
          527,
          6423,
          486,
          2845,
          264,
          5308,
          13,
          51080
        ]
      },
      {
        "avg_logprob": -0.29711585574679905,
        "compression_ratio": 1.5314009661835748,
        "end": 2991.6,
        "id": 780,
        "no_speech_prob": 0.00010720817226683721,
        "seek": 297636,
        "start": 2990.6800000000003,
        "temperature": 0,
        "text": " The server will receive it.",
        "tokens": [
          51080,
          440,
          7154,
          486,
          4774,
          309,
          13,
          51126
        ]
      },
      {
        "avg_logprob": -0.29711585574679905,
        "compression_ratio": 1.5314009661835748,
        "end": 2992.8,
        "id": 781,
        "no_speech_prob": 0.00010720817226683721,
        "seek": 297636,
        "start": 2991.6,
        "temperature": 0,
        "text": " And then we'll log it out.",
        "tokens": [
          51126,
          400,
          550,
          321,
          603,
          3565,
          309,
          484,
          13,
          51186
        ]
      },
      {
        "avg_logprob": -0.29711585574679905,
        "compression_ratio": 1.5314009661835748,
        "end": 2995.8,
        "id": 782,
        "no_speech_prob": 0.00010720817226683721,
        "seek": 297636,
        "start": 2995.48,
        "temperature": 0,
        "text": " Cool.",
        "tokens": [
          51320,
          8561,
          13,
          51336
        ]
      },
      {
        "avg_logprob": -0.29711585574679905,
        "compression_ratio": 1.5314009661835748,
        "end": 2996.92,
        "id": 783,
        "no_speech_prob": 0.00010720817226683721,
        "seek": 297636,
        "start": 2995.8,
        "temperature": 0,
        "text": " Let's see what happens.",
        "tokens": [
          51336,
          961,
          311,
          536,
          437,
          2314,
          13,
          51392
        ]
      },
      {
        "avg_logprob": -0.29711585574679905,
        "compression_ratio": 1.5314009661835748,
        "end": 3002.52,
        "id": 784,
        "no_speech_prob": 0.00010720817226683721,
        "seek": 297636,
        "start": 2996.92,
        "temperature": 0,
        "text": " So now, CJ, my mew is hello, world.",
        "tokens": [
          51392,
          407,
          586,
          11,
          42285,
          11,
          452,
          385,
          86,
          307,
          7751,
          11,
          1002,
          13,
          51672
        ]
      },
      {
        "avg_logprob": -0.28256453185522257,
        "compression_ratio": 1.7104072398190044,
        "end": 3003.24,
        "id": 785,
        "no_speech_prob": 0.00015117923612706363,
        "seek": 300252,
        "start": 3002.52,
        "temperature": 0,
        "text": " Throw some emojis.",
        "tokens": [
          50364,
          22228,
          512,
          19611,
          40371,
          13,
          50400
        ]
      },
      {
        "avg_logprob": -0.28256453185522257,
        "compression_ratio": 1.7104072398190044,
        "end": 3010.8,
        "id": 786,
        "no_speech_prob": 0.00015117923612706363,
        "seek": 300252,
        "start": 3006.48,
        "temperature": 0,
        "text": " That one, that one, go.",
        "tokens": [
          50562,
          663,
          472,
          11,
          300,
          472,
          11,
          352,
          13,
          50778
        ]
      },
      {
        "avg_logprob": -0.28256453185522257,
        "compression_ratio": 1.7104072398190044,
        "end": 3012.12,
        "id": 787,
        "no_speech_prob": 0.00015117923612706363,
        "seek": 300252,
        "start": 3010.8,
        "temperature": 0,
        "text": " Cool.",
        "tokens": [
          50778,
          8561,
          13,
          50844
        ]
      },
      {
        "avg_logprob": -0.28256453185522257,
        "compression_ratio": 1.7104072398190044,
        "end": 3015.8,
        "id": 788,
        "no_speech_prob": 0.00015117923612706363,
        "seek": 300252,
        "start": 3012.12,
        "temperature": 0,
        "text": " So you'll notice that I'm actually getting back an object.",
        "tokens": [
          50844,
          407,
          291,
          603,
          3449,
          300,
          286,
          478,
          767,
          1242,
          646,
          364,
          2657,
          13,
          51028
        ]
      },
      {
        "avg_logprob": -0.28256453185522257,
        "compression_ratio": 1.7104072398190044,
        "end": 3017.28,
        "id": 789,
        "no_speech_prob": 0.00015117923612706363,
        "seek": 300252,
        "start": 3015.8,
        "temperature": 0,
        "text": " And you'll notice it has an ID.",
        "tokens": [
          51028,
          400,
          291,
          603,
          3449,
          309,
          575,
          364,
          7348,
          13,
          51102
        ]
      },
      {
        "avg_logprob": -0.28256453185522257,
        "compression_ratio": 1.7104072398190044,
        "end": 3019.92,
        "id": 790,
        "no_speech_prob": 0.00015117923612706363,
        "seek": 300252,
        "start": 3017.28,
        "temperature": 0,
        "text": " So this thing was actually inserted into the database.",
        "tokens": [
          51102,
          407,
          341,
          551,
          390,
          767,
          27992,
          666,
          264,
          8149,
          13,
          51234
        ]
      },
      {
        "avg_logprob": -0.28256453185522257,
        "compression_ratio": 1.7104072398190044,
        "end": 3022.48,
        "id": 791,
        "no_speech_prob": 0.00015117923612706363,
        "seek": 300252,
        "start": 3019.92,
        "temperature": 0,
        "text": " And then it responded with that object.",
        "tokens": [
          51234,
          400,
          550,
          309,
          15806,
          365,
          300,
          2657,
          13,
          51362
        ]
      },
      {
        "avg_logprob": -0.28256453185522257,
        "compression_ratio": 1.7104072398190044,
        "end": 3024.04,
        "id": 792,
        "no_speech_prob": 0.00015117923612706363,
        "seek": 300252,
        "start": 3022.48,
        "temperature": 0,
        "text": " So that's great.",
        "tokens": [
          51362,
          407,
          300,
          311,
          869,
          13,
          51440
        ]
      },
      {
        "avg_logprob": -0.28256453185522257,
        "compression_ratio": 1.7104072398190044,
        "end": 3025.44,
        "id": 793,
        "no_speech_prob": 0.00015117923612706363,
        "seek": 300252,
        "start": 3024.04,
        "temperature": 0,
        "text": " It's in the database.",
        "tokens": [
          51440,
          467,
          311,
          294,
          264,
          8149,
          13,
          51510
        ]
      },
      {
        "avg_logprob": -0.28256453185522257,
        "compression_ratio": 1.7104072398190044,
        "end": 3027.6,
        "id": 794,
        "no_speech_prob": 0.00015117923612706363,
        "seek": 300252,
        "start": 3025.44,
        "temperature": 0,
        "text": " Now, we actually want to show all of the mews that",
        "tokens": [
          51510,
          823,
          11,
          321,
          767,
          528,
          281,
          855,
          439,
          295,
          264,
          385,
          14358,
          300,
          51618
        ]
      },
      {
        "avg_logprob": -0.28256453185522257,
        "compression_ratio": 1.7104072398190044,
        "end": 3031.04,
        "id": 795,
        "no_speech_prob": 0.00015117923612706363,
        "seek": 300252,
        "start": 3027.6,
        "temperature": 0,
        "text": " have been created on the page here.",
        "tokens": [
          51618,
          362,
          668,
          2942,
          322,
          264,
          3028,
          510,
          13,
          51790
        ]
      },
      {
        "avg_logprob": -0.28256453185522257,
        "compression_ratio": 1.7104072398190044,
        "end": 3032.36,
        "id": 796,
        "no_speech_prob": 0.00015117923612706363,
        "seek": 300252,
        "start": 3031.04,
        "temperature": 0,
        "text": " So let's do that.",
        "tokens": [
          51790,
          407,
          718,
          311,
          360,
          300,
          13,
          51856
        ]
      },
      {
        "avg_logprob": -0.27353017980402167,
        "compression_ratio": 1.7058823529411764,
        "end": 3033.44,
        "id": 797,
        "no_speech_prob": 0.0001039096896420233,
        "seek": 303236,
        "start": 3032.36,
        "temperature": 0,
        "text": " Let's look back here.",
        "tokens": [
          50364,
          961,
          311,
          574,
          646,
          510,
          13,
          50418
        ]
      },
      {
        "avg_logprob": -0.27353017980402167,
        "compression_ratio": 1.7058823529411764,
        "end": 3036.54,
        "id": 798,
        "no_speech_prob": 0.0001039096896420233,
        "seek": 303236,
        "start": 3036.04,
        "temperature": 0,
        "text": " Cool.",
        "tokens": [
          50548,
          8561,
          13,
          50573
        ]
      },
      {
        "avg_logprob": -0.27353017980402167,
        "compression_ratio": 1.7058823529411764,
        "end": 3037.6,
        "id": 799,
        "no_speech_prob": 0.0001039096896420233,
        "seek": 303236,
        "start": 3036.54,
        "temperature": 0,
        "text": " So we've logged it out.",
        "tokens": [
          50573,
          407,
          321,
          600,
          27231,
          309,
          484,
          13,
          50626
        ]
      },
      {
        "avg_logprob": -0.27353017980402167,
        "compression_ratio": 1.7058823529411764,
        "end": 3040.2400000000002,
        "id": 800,
        "no_speech_prob": 0.0001039096896420233,
        "seek": 303236,
        "start": 3037.6,
        "temperature": 0,
        "text": " And now what we'll do is, after the POST request,",
        "tokens": [
          50626,
          400,
          586,
          437,
          321,
          603,
          360,
          307,
          11,
          934,
          264,
          430,
          28067,
          5308,
          11,
          50758
        ]
      },
      {
        "avg_logprob": -0.27353017980402167,
        "compression_ratio": 1.7058823529411764,
        "end": 3043.04,
        "id": 801,
        "no_speech_prob": 0.0001039096896420233,
        "seek": 303236,
        "start": 3040.2400000000002,
        "temperature": 0,
        "text": " we want to show the form again and hide the loading spinner.",
        "tokens": [
          50758,
          321,
          528,
          281,
          855,
          264,
          1254,
          797,
          293,
          6479,
          264,
          15114,
          44849,
          13,
          50898
        ]
      },
      {
        "avg_logprob": -0.27353017980402167,
        "compression_ratio": 1.7058823529411764,
        "end": 3045.92,
        "id": 802,
        "no_speech_prob": 0.0001039096896420233,
        "seek": 303236,
        "start": 3043.04,
        "temperature": 0,
        "text": " So on the client side, again, we're on the client,",
        "tokens": [
          50898,
          407,
          322,
          264,
          6423,
          1252,
          11,
          797,
          11,
          321,
          434,
          322,
          264,
          6423,
          11,
          51042
        ]
      },
      {
        "avg_logprob": -0.27353017980402167,
        "compression_ratio": 1.7058823529411764,
        "end": 3049.7200000000003,
        "id": 803,
        "no_speech_prob": 0.0001039096896420233,
        "seek": 303236,
        "start": 3045.92,
        "temperature": 0,
        "text": " we'll say, let's hide the loading elements.",
        "tokens": [
          51042,
          321,
          603,
          584,
          11,
          718,
          311,
          6479,
          264,
          15114,
          4959,
          13,
          51232
        ]
      },
      {
        "avg_logprob": -0.27353017980402167,
        "compression_ratio": 1.7058823529411764,
        "end": 3051.1200000000003,
        "id": 804,
        "no_speech_prob": 0.0001039096896420233,
        "seek": 303236,
        "start": 3049.7200000000003,
        "temperature": 0,
        "text": " We'll say none here.",
        "tokens": [
          51232,
          492,
          603,
          584,
          6022,
          510,
          13,
          51302
        ]
      },
      {
        "avg_logprob": -0.27353017980402167,
        "compression_ratio": 1.7058823529411764,
        "end": 3052.7200000000003,
        "id": 805,
        "no_speech_prob": 0.0001039096896420233,
        "seek": 303236,
        "start": 3051.1200000000003,
        "temperature": 0,
        "text": " And then let's show the form.",
        "tokens": [
          51302,
          400,
          550,
          718,
          311,
          855,
          264,
          1254,
          13,
          51382
        ]
      },
      {
        "avg_logprob": -0.27353017980402167,
        "compression_ratio": 1.7058823529411764,
        "end": 3055.1600000000003,
        "id": 806,
        "no_speech_prob": 0.0001039096896420233,
        "seek": 303236,
        "start": 3052.7200000000003,
        "temperature": 0,
        "text": " So basically, when you're done submitting,",
        "tokens": [
          51382,
          407,
          1936,
          11,
          562,
          291,
          434,
          1096,
          31836,
          11,
          51504
        ]
      },
      {
        "avg_logprob": -0.27353017980402167,
        "compression_ratio": 1.7058823529411764,
        "end": 3056.6800000000003,
        "id": 807,
        "no_speech_prob": 0.0001039096896420233,
        "seek": 303236,
        "start": 3055.1600000000003,
        "temperature": 0,
        "text": " re-display the form.",
        "tokens": [
          51504,
          319,
          12,
          35238,
          264,
          1254,
          13,
          51580
        ]
      },
      {
        "avg_logprob": -0.27353017980402167,
        "compression_ratio": 1.7058823529411764,
        "end": 3059.96,
        "id": 808,
        "no_speech_prob": 0.0001039096896420233,
        "seek": 303236,
        "start": 3056.6800000000003,
        "temperature": 0,
        "text": " So now if I say, CJ, hello again.",
        "tokens": [
          51580,
          407,
          586,
          498,
          286,
          584,
          11,
          42285,
          11,
          7751,
          797,
          13,
          51744
        ]
      },
      {
        "avg_logprob": -0.32543137338426376,
        "compression_ratio": 1.5719424460431655,
        "end": 3065.6400000000003,
        "id": 809,
        "no_speech_prob": 0.000013845909052179195,
        "seek": 306236,
        "start": 3063.36,
        "temperature": 0,
        "text": " More cats.",
        "tokens": [
          50414,
          5048,
          11111,
          13,
          50528
        ]
      },
      {
        "avg_logprob": -0.32543137338426376,
        "compression_ratio": 1.5719424460431655,
        "end": 3066.6,
        "id": 810,
        "no_speech_prob": 0.000013845909052179195,
        "seek": 306236,
        "start": 3065.6400000000003,
        "temperature": 0,
        "text": " Send.",
        "tokens": [
          50528,
          17908,
          13,
          50576
        ]
      },
      {
        "avg_logprob": -0.32543137338426376,
        "compression_ratio": 1.5719424460431655,
        "end": 3068,
        "id": 811,
        "no_speech_prob": 0.000013845909052179195,
        "seek": 306236,
        "start": 3066.6,
        "temperature": 0,
        "text": " You'll notice the page refreshes.",
        "tokens": [
          50576,
          509,
          603,
          3449,
          264,
          3028,
          15134,
          279,
          13,
          50646
        ]
      },
      {
        "avg_logprob": -0.32543137338426376,
        "compression_ratio": 1.5719424460431655,
        "end": 3070.56,
        "id": 812,
        "no_speech_prob": 0.000013845909052179195,
        "seek": 306236,
        "start": 3068,
        "temperature": 0,
        "text": " Probably one more thing I want to do is reset the form.",
        "tokens": [
          50646,
          9210,
          472,
          544,
          551,
          286,
          528,
          281,
          360,
          307,
          14322,
          264,
          1254,
          13,
          50774
        ]
      },
      {
        "avg_logprob": -0.32543137338426376,
        "compression_ratio": 1.5719424460431655,
        "end": 3071.7200000000003,
        "id": 813,
        "no_speech_prob": 0.000013845909052179195,
        "seek": 306236,
        "start": 3070.56,
        "temperature": 0,
        "text": " So I sent it off.",
        "tokens": [
          50774,
          407,
          286,
          2279,
          309,
          766,
          13,
          50832
        ]
      },
      {
        "avg_logprob": -0.32543137338426376,
        "compression_ratio": 1.5719424460431655,
        "end": 3072.84,
        "id": 814,
        "no_speech_prob": 0.000013845909052179195,
        "seek": 306236,
        "start": 3071.7200000000003,
        "temperature": 0,
        "text": " It got put in the database.",
        "tokens": [
          50832,
          467,
          658,
          829,
          294,
          264,
          8149,
          13,
          50888
        ]
      },
      {
        "avg_logprob": -0.32543137338426376,
        "compression_ratio": 1.5719424460431655,
        "end": 3074.92,
        "id": 815,
        "no_speech_prob": 0.000013845909052179195,
        "seek": 306236,
        "start": 3072.84,
        "temperature": 0,
        "text": " Let's clear out the form here.",
        "tokens": [
          50888,
          961,
          311,
          1850,
          484,
          264,
          1254,
          510,
          13,
          50992
        ]
      },
      {
        "avg_logprob": -0.32543137338426376,
        "compression_ratio": 1.5719424460431655,
        "end": 3075.52,
        "id": 816,
        "no_speech_prob": 0.000013845909052179195,
        "seek": 306236,
        "start": 3074.92,
        "temperature": 0,
        "text": " Easy enough.",
        "tokens": [
          50992,
          16002,
          1547,
          13,
          51022
        ]
      },
      {
        "avg_logprob": -0.32543137338426376,
        "compression_ratio": 1.5719424460431655,
        "end": 3078.6800000000003,
        "id": 817,
        "no_speech_prob": 0.000013845909052179195,
        "seek": 306236,
        "start": 3075.52,
        "temperature": 0,
        "text": " We can just say form.reset.",
        "tokens": [
          51022,
          492,
          393,
          445,
          584,
          1254,
          13,
          495,
          302,
          13,
          51180
        ]
      },
      {
        "avg_logprob": -0.32543137338426376,
        "compression_ratio": 1.5719424460431655,
        "end": 3081.76,
        "id": 818,
        "no_speech_prob": 0.000013845909052179195,
        "seek": 306236,
        "start": 3078.6800000000003,
        "temperature": 0,
        "text": " So a few people, I think one person at least,",
        "tokens": [
          51180,
          407,
          257,
          1326,
          561,
          11,
          286,
          519,
          472,
          954,
          412,
          1935,
          11,
          51334
        ]
      },
      {
        "avg_logprob": -0.32543137338426376,
        "compression_ratio": 1.5719424460431655,
        "end": 3083.52,
        "id": 819,
        "no_speech_prob": 0.000013845909052179195,
        "seek": 306236,
        "start": 3081.76,
        "temperature": 0,
        "text": " is not familiar with the fetch function.",
        "tokens": [
          51334,
          307,
          406,
          4963,
          365,
          264,
          23673,
          2445,
          13,
          51422
        ]
      },
      {
        "avg_logprob": -0.32543137338426376,
        "compression_ratio": 1.5719424460431655,
        "end": 3085.2400000000002,
        "id": 820,
        "no_speech_prob": 0.000013845909052179195,
        "seek": 306236,
        "start": 3083.52,
        "temperature": 0,
        "text": " What's the fetch function doing?",
        "tokens": [
          51422,
          708,
          311,
          264,
          23673,
          2445,
          884,
          30,
          51508
        ]
      },
      {
        "avg_logprob": -0.32543137338426376,
        "compression_ratio": 1.5719424460431655,
        "end": 3085.76,
        "id": 821,
        "no_speech_prob": 0.000013845909052179195,
        "seek": 306236,
        "start": 3085.2400000000002,
        "temperature": 0,
        "text": " Definitely.",
        "tokens": [
          51508,
          12151,
          13,
          51534
        ]
      },
      {
        "avg_logprob": -0.32543137338426376,
        "compression_ratio": 1.5719424460431655,
        "end": 3089.2000000000003,
        "id": 822,
        "no_speech_prob": 0.000013845909052179195,
        "seek": 306236,
        "start": 3085.76,
        "temperature": 0,
        "text": " So I believe in P5, is it called load JSON?",
        "tokens": [
          51534,
          407,
          286,
          1697,
          294,
          430,
          20,
          11,
          307,
          309,
          1219,
          3677,
          31828,
          30,
          51706
        ]
      },
      {
        "avg_logprob": -0.32543137338426376,
        "compression_ratio": 1.5719424460431655,
        "end": 3090.6,
        "id": 823,
        "no_speech_prob": 0.000013845909052179195,
        "seek": 306236,
        "start": 3089.2000000000003,
        "temperature": 0,
        "text": " Load JSON is equivalent, yeah.",
        "tokens": [
          51706,
          48408,
          31828,
          307,
          10344,
          11,
          1338,
          13,
          51776
        ]
      },
      {
        "avg_logprob": -0.32543137338426376,
        "compression_ratio": 1.5719424460431655,
        "end": 3090.76,
        "id": 824,
        "no_speech_prob": 0.000013845909052179195,
        "seek": 306236,
        "start": 3090.6,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51776,
          865,
          13,
          51784
        ]
      },
      {
        "avg_logprob": -0.2370549682387732,
        "compression_ratio": 1.6431372549019607,
        "end": 3093.1200000000003,
        "id": 825,
        "no_speech_prob": 0.00006605145608773455,
        "seek": 309076,
        "start": 3090.76,
        "temperature": 0,
        "text": " So if you've ever worked with P5.js,",
        "tokens": [
          50364,
          407,
          498,
          291,
          600,
          1562,
          2732,
          365,
          430,
          20,
          13,
          25530,
          11,
          50482
        ]
      },
      {
        "avg_logprob": -0.2370549682387732,
        "compression_ratio": 1.6431372549019607,
        "end": 3095.88,
        "id": 826,
        "no_speech_prob": 0.00006605145608773455,
        "seek": 309076,
        "start": 3093.1200000000003,
        "temperature": 0,
        "text": " it's a way of requesting data from a server.",
        "tokens": [
          50482,
          309,
          311,
          257,
          636,
          295,
          31937,
          1412,
          490,
          257,
          7154,
          13,
          50620
        ]
      },
      {
        "avg_logprob": -0.2370549682387732,
        "compression_ratio": 1.6431372549019607,
        "end": 3097,
        "id": 827,
        "no_speech_prob": 0.00006605145608773455,
        "seek": 309076,
        "start": 3095.88,
        "temperature": 0,
        "text": " So there's load JSON.",
        "tokens": [
          50620,
          407,
          456,
          311,
          3677,
          31828,
          13,
          50676
        ]
      },
      {
        "avg_logprob": -0.2370549682387732,
        "compression_ratio": 1.6431372549019607,
        "end": 3098.4,
        "id": 828,
        "no_speech_prob": 0.00006605145608773455,
        "seek": 309076,
        "start": 3097,
        "temperature": 0,
        "text": " If you've ever worked with jQuery,",
        "tokens": [
          50676,
          759,
          291,
          600,
          1562,
          2732,
          365,
          361,
          35550,
          11,
          50746
        ]
      },
      {
        "avg_logprob": -0.2370549682387732,
        "compression_ratio": 1.6431372549019607,
        "end": 3101.0400000000004,
        "id": 829,
        "no_speech_prob": 0.00006605145608773455,
        "seek": 309076,
        "start": 3098.4,
        "temperature": 0,
        "text": " it's $.get or $.post.",
        "tokens": [
          50746,
          309,
          311,
          1848,
          13,
          847,
          420,
          1848,
          13,
          23744,
          13,
          50878
        ]
      },
      {
        "avg_logprob": -0.2370549682387732,
        "compression_ratio": 1.6431372549019607,
        "end": 3103.4,
        "id": 830,
        "no_speech_prob": 0.00006605145608773455,
        "seek": 309076,
        "start": 3101.0400000000004,
        "temperature": 0,
        "text": " Essentially, fetch is now built into the browser.",
        "tokens": [
          50878,
          23596,
          11,
          23673,
          307,
          586,
          3094,
          666,
          264,
          11185,
          13,
          50996
        ]
      },
      {
        "avg_logprob": -0.2370549682387732,
        "compression_ratio": 1.6431372549019607,
        "end": 3108.0400000000004,
        "id": 831,
        "no_speech_prob": 0.00006605145608773455,
        "seek": 309076,
        "start": 3103.4,
        "temperature": 0,
        "text": " And it's a little bit easier way of making requests to a server.",
        "tokens": [
          50996,
          400,
          309,
          311,
          257,
          707,
          857,
          3571,
          636,
          295,
          1455,
          12475,
          281,
          257,
          7154,
          13,
          51228
        ]
      },
      {
        "avg_logprob": -0.2370549682387732,
        "compression_ratio": 1.6431372549019607,
        "end": 3113.6400000000003,
        "id": 832,
        "no_speech_prob": 0.00006605145608773455,
        "seek": 309076,
        "start": 3108.0400000000004,
        "temperature": 0,
        "text": " So this is synonymous with AJAX or requesting to a server.",
        "tokens": [
          51228,
          407,
          341,
          307,
          5451,
          18092,
          365,
          316,
          27818,
          55,
          420,
          31937,
          281,
          257,
          7154,
          13,
          51508
        ]
      },
      {
        "avg_logprob": -0.2370549682387732,
        "compression_ratio": 1.6431372549019607,
        "end": 3114.5200000000004,
        "id": 833,
        "no_speech_prob": 0.00006605145608773455,
        "seek": 309076,
        "start": 3113.6400000000003,
        "temperature": 0,
        "text": " Cool.",
        "tokens": [
          51508,
          8561,
          13,
          51552
        ]
      },
      {
        "avg_logprob": -0.2370549682387732,
        "compression_ratio": 1.6431372549019607,
        "end": 3118.2400000000002,
        "id": 834,
        "no_speech_prob": 0.00006605145608773455,
        "seek": 309076,
        "start": 3114.5200000000004,
        "temperature": 0,
        "text": " Seems like there's a lot of Coding Garden fans in the chat.",
        "tokens": [
          51552,
          22524,
          411,
          456,
          311,
          257,
          688,
          295,
          383,
          8616,
          19429,
          4499,
          294,
          264,
          5081,
          13,
          51738
        ]
      },
      {
        "avg_logprob": -0.2370549682387732,
        "compression_ratio": 1.6431372549019607,
        "end": 3119.84,
        "id": 835,
        "no_speech_prob": 0.00006605145608773455,
        "seek": 309076,
        "start": 3118.2400000000002,
        "temperature": 0,
        "text": " I appreciate that.",
        "tokens": [
          51738,
          286,
          4449,
          300,
          13,
          51818
        ]
      },
      {
        "avg_logprob": -0.2998120739201831,
        "compression_ratio": 1.7363013698630136,
        "end": 3121.56,
        "id": 836,
        "no_speech_prob": 0.00010889593249885365,
        "seek": 311984,
        "start": 3119.92,
        "temperature": 0,
        "text": " Awesome.",
        "tokens": [
          50368,
          10391,
          13,
          50450
        ]
      },
      {
        "avg_logprob": -0.2998120739201831,
        "compression_ratio": 1.7363013698630136,
        "end": 3124,
        "id": 837,
        "no_speech_prob": 0.00010889593249885365,
        "seek": 311984,
        "start": 3121.56,
        "temperature": 0,
        "text": " OK, so where are we at?",
        "tokens": [
          50450,
          2264,
          11,
          370,
          689,
          366,
          321,
          412,
          30,
          50572
        ]
      },
      {
        "avg_logprob": -0.2998120739201831,
        "compression_ratio": 1.7363013698630136,
        "end": 3124.8,
        "id": 838,
        "no_speech_prob": 0.00010889593249885365,
        "seek": 311984,
        "start": 3124,
        "temperature": 0,
        "text": " We showed the form.",
        "tokens": [
          50572,
          492,
          4712,
          264,
          1254,
          13,
          50612
        ]
      },
      {
        "avg_logprob": -0.2998120739201831,
        "compression_ratio": 1.7363013698630136,
        "end": 3126.04,
        "id": 839,
        "no_speech_prob": 0.00010889593249885365,
        "seek": 311984,
        "start": 3124.8,
        "temperature": 0,
        "text": " We hide the loading spinner.",
        "tokens": [
          50612,
          492,
          6479,
          264,
          15114,
          44849,
          13,
          50674
        ]
      },
      {
        "avg_logprob": -0.2998120739201831,
        "compression_ratio": 1.7363013698630136,
        "end": 3127.2400000000002,
        "id": 840,
        "no_speech_prob": 0.00010889593249885365,
        "seek": 311984,
        "start": 3126.04,
        "temperature": 0,
        "text": " We're in the home stretch.",
        "tokens": [
          50674,
          492,
          434,
          294,
          264,
          1280,
          1056,
          7858,
          13,
          50734
        ]
      },
      {
        "avg_logprob": -0.2998120739201831,
        "compression_ratio": 1.7363013698630136,
        "end": 3128.2000000000003,
        "id": 841,
        "no_speech_prob": 0.00010889593249885365,
        "seek": 311984,
        "start": 3127.2400000000002,
        "temperature": 0,
        "text": " We're very close here.",
        "tokens": [
          50734,
          492,
          434,
          588,
          1998,
          510,
          13,
          50782
        ]
      },
      {
        "avg_logprob": -0.2998120739201831,
        "compression_ratio": 1.7363013698630136,
        "end": 3130.76,
        "id": 842,
        "no_speech_prob": 0.00010889593249885365,
        "seek": 311984,
        "start": 3128.2000000000003,
        "temperature": 0,
        "text": " So the last thing we want to be able to do",
        "tokens": [
          50782,
          407,
          264,
          1036,
          551,
          321,
          528,
          281,
          312,
          1075,
          281,
          360,
          50910
        ]
      },
      {
        "avg_logprob": -0.2998120739201831,
        "compression_ratio": 1.7363013698630136,
        "end": 3132.6000000000004,
        "id": 843,
        "no_speech_prob": 0.00010889593249885365,
        "seek": 311984,
        "start": 3130.76,
        "temperature": 0,
        "text": " is all of the created mus we need",
        "tokens": [
          50910,
          307,
          439,
          295,
          264,
          2942,
          1038,
          321,
          643,
          51002
        ]
      },
      {
        "avg_logprob": -0.2998120739201831,
        "compression_ratio": 1.7363013698630136,
        "end": 3134.48,
        "id": 844,
        "no_speech_prob": 0.00010889593249885365,
        "seek": 311984,
        "start": 3132.6000000000004,
        "temperature": 0,
        "text": " to show them on the page here.",
        "tokens": [
          51002,
          281,
          855,
          552,
          322,
          264,
          3028,
          510,
          13,
          51096
        ]
      },
      {
        "avg_logprob": -0.2998120739201831,
        "compression_ratio": 1.7363013698630136,
        "end": 3137.1600000000003,
        "id": 845,
        "no_speech_prob": 0.00010889593249885365,
        "seek": 311984,
        "start": 3134.48,
        "temperature": 0,
        "text": " So for that, we're going to make a request.",
        "tokens": [
          51096,
          407,
          337,
          300,
          11,
          321,
          434,
          516,
          281,
          652,
          257,
          5308,
          13,
          51230
        ]
      },
      {
        "avg_logprob": -0.2998120739201831,
        "compression_ratio": 1.7363013698630136,
        "end": 3138.76,
        "id": 846,
        "no_speech_prob": 0.00010889593249885365,
        "seek": 311984,
        "start": 3137.1600000000003,
        "temperature": 0,
        "text": " We're running low on time, so I don't",
        "tokens": [
          51230,
          492,
          434,
          2614,
          2295,
          322,
          565,
          11,
          370,
          286,
          500,
          380,
          51310
        ]
      },
      {
        "avg_logprob": -0.2998120739201831,
        "compression_ratio": 1.7363013698630136,
        "end": 3140.42,
        "id": 847,
        "no_speech_prob": 0.00010889593249885365,
        "seek": 311984,
        "start": 3138.76,
        "temperature": 0,
        "text": " want to go back to the diagram just yet.",
        "tokens": [
          51310,
          528,
          281,
          352,
          646,
          281,
          264,
          10686,
          445,
          1939,
          13,
          51393
        ]
      },
      {
        "avg_logprob": -0.2998120739201831,
        "compression_ratio": 1.7363013698630136,
        "end": 3141.84,
        "id": 848,
        "no_speech_prob": 0.00010889593249885365,
        "seek": 311984,
        "start": 3140.42,
        "temperature": 0,
        "text": " But let's get it going.",
        "tokens": [
          51393,
          583,
          718,
          311,
          483,
          309,
          516,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2998120739201831,
        "compression_ratio": 1.7363013698630136,
        "end": 3146.48,
        "id": 849,
        "no_speech_prob": 0.00010889593249885365,
        "seek": 311984,
        "start": 3141.84,
        "temperature": 0,
        "text": " So basically, what should happen is an incoming get request",
        "tokens": [
          51464,
          407,
          1936,
          11,
          437,
          820,
          1051,
          307,
          364,
          22341,
          483,
          5308,
          51696
        ]
      },
      {
        "avg_logprob": -0.2998120739201831,
        "compression_ratio": 1.7363013698630136,
        "end": 3149.36,
        "id": 850,
        "no_speech_prob": 0.00010889593249885365,
        "seek": 311984,
        "start": 3146.48,
        "temperature": 0,
        "text": " to slash mus should get all of the records from the database",
        "tokens": [
          51696,
          281,
          17330,
          1038,
          820,
          483,
          439,
          295,
          264,
          7724,
          490,
          264,
          8149,
          51840
        ]
      },
      {
        "avg_logprob": -0.2197063970201798,
        "compression_ratio": 1.829268292682927,
        "end": 3151.1600000000003,
        "id": 851,
        "no_speech_prob": 0.00012148075620643795,
        "seek": 314936,
        "start": 3149.36,
        "temperature": 0,
        "text": " and just respond with them in an array.",
        "tokens": [
          50364,
          293,
          445,
          4196,
          365,
          552,
          294,
          364,
          10225,
          13,
          50454
        ]
      },
      {
        "avg_logprob": -0.2197063970201798,
        "compression_ratio": 1.829268292682927,
        "end": 3153.32,
        "id": 852,
        "no_speech_prob": 0.00012148075620643795,
        "seek": 314936,
        "start": 3151.1600000000003,
        "temperature": 0,
        "text": " So what we'll do here on the server",
        "tokens": [
          50454,
          407,
          437,
          321,
          603,
          360,
          510,
          322,
          264,
          7154,
          50562
        ]
      },
      {
        "avg_logprob": -0.2197063970201798,
        "compression_ratio": 1.829268292682927,
        "end": 3158.44,
        "id": 853,
        "no_speech_prob": 0.00012148075620643795,
        "seek": 314936,
        "start": 3153.32,
        "temperature": 0,
        "text": " is say, when the server receives a request on slash mus,",
        "tokens": [
          50562,
          307,
          584,
          11,
          562,
          264,
          7154,
          20717,
          257,
          5308,
          322,
          17330,
          1038,
          11,
          50818
        ]
      },
      {
        "avg_logprob": -0.2197063970201798,
        "compression_ratio": 1.829268292682927,
        "end": 3161.04,
        "id": 854,
        "no_speech_prob": 0.00012148075620643795,
        "seek": 314936,
        "start": 3158.44,
        "temperature": 0,
        "text": " we will then query the database.",
        "tokens": [
          50818,
          321,
          486,
          550,
          14581,
          264,
          8149,
          13,
          50948
        ]
      },
      {
        "avg_logprob": -0.2197063970201798,
        "compression_ratio": 1.829268292682927,
        "end": 3163.96,
        "id": 855,
        "no_speech_prob": 0.00012148075620643795,
        "seek": 314936,
        "start": 3161.04,
        "temperature": 0,
        "text": " So we'll just say, so if you remember,",
        "tokens": [
          50948,
          407,
          321,
          603,
          445,
          584,
          11,
          370,
          498,
          291,
          1604,
          11,
          51094
        ]
      },
      {
        "avg_logprob": -0.2197063970201798,
        "compression_ratio": 1.829268292682927,
        "end": 3168.1200000000003,
        "id": 856,
        "no_speech_prob": 0.00012148075620643795,
        "seek": 314936,
        "start": 3163.96,
        "temperature": 0,
        "text": " mus is our variable that represents the collection.",
        "tokens": [
          51094,
          1038,
          307,
          527,
          7006,
          300,
          8855,
          264,
          5765,
          13,
          51302
        ]
      },
      {
        "avg_logprob": -0.2197063970201798,
        "compression_ratio": 1.829268292682927,
        "end": 3169.84,
        "id": 857,
        "no_speech_prob": 0.00012148075620643795,
        "seek": 314936,
        "start": 3168.1200000000003,
        "temperature": 0,
        "text": " And we'll just say mus.find.",
        "tokens": [
          51302,
          400,
          321,
          603,
          445,
          584,
          1038,
          13,
          35072,
          13,
          51388
        ]
      },
      {
        "avg_logprob": -0.2197063970201798,
        "compression_ratio": 1.829268292682927,
        "end": 3171.28,
        "id": 858,
        "no_speech_prob": 0.00012148075620643795,
        "seek": 314936,
        "start": 3169.84,
        "temperature": 0,
        "text": " And if you don't pass in anything,",
        "tokens": [
          51388,
          400,
          498,
          291,
          500,
          380,
          1320,
          294,
          1340,
          11,
          51460
        ]
      },
      {
        "avg_logprob": -0.2197063970201798,
        "compression_ratio": 1.829268292682927,
        "end": 3174.52,
        "id": 859,
        "no_speech_prob": 0.00012148075620643795,
        "seek": 314936,
        "start": 3171.28,
        "temperature": 0,
        "text": " that just means find all of the things in the database.",
        "tokens": [
          51460,
          300,
          445,
          1355,
          915,
          439,
          295,
          264,
          721,
          294,
          264,
          8149,
          13,
          51622
        ]
      },
      {
        "avg_logprob": -0.2197063970201798,
        "compression_ratio": 1.829268292682927,
        "end": 3177.4,
        "id": 860,
        "no_speech_prob": 0.00012148075620643795,
        "seek": 314936,
        "start": 3174.52,
        "temperature": 0,
        "text": " And then we'll get back some mus.",
        "tokens": [
          51622,
          400,
          550,
          321,
          603,
          483,
          646,
          512,
          1038,
          13,
          51766
        ]
      },
      {
        "avg_logprob": -0.2197063970201798,
        "compression_ratio": 1.829268292682927,
        "end": 3179,
        "id": 861,
        "no_speech_prob": 0.00012148075620643795,
        "seek": 314936,
        "start": 3177.4,
        "temperature": 0,
        "text": " And with those mus, we'll just respond.",
        "tokens": [
          51766,
          400,
          365,
          729,
          1038,
          11,
          321,
          603,
          445,
          4196,
          13,
          51846
        ]
      },
      {
        "avg_logprob": -0.23995606104532877,
        "compression_ratio": 1.6774193548387097,
        "end": 3181.28,
        "id": 862,
        "no_speech_prob": 0.000023923463231767528,
        "seek": 317900,
        "start": 3179.16,
        "temperature": 0,
        "text": " So res.json mus.",
        "tokens": [
          50372,
          407,
          725,
          13,
          73,
          3015,
          1038,
          13,
          50478
        ]
      },
      {
        "avg_logprob": -0.23995606104532877,
        "compression_ratio": 1.6774193548387097,
        "end": 3184.84,
        "id": 863,
        "no_speech_prob": 0.000023923463231767528,
        "seek": 317900,
        "start": 3181.28,
        "temperature": 0,
        "text": " So now when my server receives a get request on slash mus,",
        "tokens": [
          50478,
          407,
          586,
          562,
          452,
          7154,
          20717,
          257,
          483,
          5308,
          322,
          17330,
          1038,
          11,
          50656
        ]
      },
      {
        "avg_logprob": -0.23995606104532877,
        "compression_ratio": 1.6774193548387097,
        "end": 3186.54,
        "id": 864,
        "no_speech_prob": 0.000023923463231767528,
        "seek": 317900,
        "start": 3184.84,
        "temperature": 0,
        "text": " go into the database, grab all of them,",
        "tokens": [
          50656,
          352,
          666,
          264,
          8149,
          11,
          4444,
          439,
          295,
          552,
          11,
          50741
        ]
      },
      {
        "avg_logprob": -0.23995606104532877,
        "compression_ratio": 1.6774193548387097,
        "end": 3188.56,
        "id": 865,
        "no_speech_prob": 0.000023923463231767528,
        "seek": 317900,
        "start": 3186.54,
        "temperature": 0,
        "text": " and then just respond with them as an array.",
        "tokens": [
          50741,
          293,
          550,
          445,
          4196,
          365,
          552,
          382,
          364,
          10225,
          13,
          50842
        ]
      },
      {
        "avg_logprob": -0.23995606104532877,
        "compression_ratio": 1.6774193548387097,
        "end": 3190.54,
        "id": 866,
        "no_speech_prob": 0.000023923463231767528,
        "seek": 317900,
        "start": 3188.56,
        "temperature": 0,
        "text": " So before I even test this on the client side,",
        "tokens": [
          50842,
          407,
          949,
          286,
          754,
          1500,
          341,
          322,
          264,
          6423,
          1252,
          11,
          50941
        ]
      },
      {
        "avg_logprob": -0.23995606104532877,
        "compression_ratio": 1.6774193548387097,
        "end": 3192.36,
        "id": 867,
        "no_speech_prob": 0.000023923463231767528,
        "seek": 317900,
        "start": 3190.54,
        "temperature": 0,
        "text": " I can actually try it in the browser.",
        "tokens": [
          50941,
          286,
          393,
          767,
          853,
          309,
          294,
          264,
          11185,
          13,
          51032
        ]
      },
      {
        "avg_logprob": -0.23995606104532877,
        "compression_ratio": 1.6774193548387097,
        "end": 3194.6,
        "id": 868,
        "no_speech_prob": 0.000023923463231767528,
        "seek": 317900,
        "start": 3192.36,
        "temperature": 0,
        "text": " Because if you remember, when you put in a URL,",
        "tokens": [
          51032,
          1436,
          498,
          291,
          1604,
          11,
          562,
          291,
          829,
          294,
          257,
          12905,
          11,
          51144
        ]
      },
      {
        "avg_logprob": -0.23995606104532877,
        "compression_ratio": 1.6774193548387097,
        "end": 3196.64,
        "id": 869,
        "no_speech_prob": 0.000023923463231767528,
        "seek": 317900,
        "start": 3194.6,
        "temperature": 0,
        "text": " that is a get request.",
        "tokens": [
          51144,
          300,
          307,
          257,
          483,
          5308,
          13,
          51246
        ]
      },
      {
        "avg_logprob": -0.23995606104532877,
        "compression_ratio": 1.6774193548387097,
        "end": 3199.36,
        "id": 870,
        "no_speech_prob": 0.000023923463231767528,
        "seek": 317900,
        "start": 3196.64,
        "temperature": 0,
        "text": " So if I do slash mus, there we go.",
        "tokens": [
          51246,
          407,
          498,
          286,
          360,
          17330,
          1038,
          11,
          456,
          321,
          352,
          13,
          51382
        ]
      },
      {
        "avg_logprob": -0.23995606104532877,
        "compression_ratio": 1.6774193548387097,
        "end": 3201.16,
        "id": 871,
        "no_speech_prob": 0.000023923463231767528,
        "seek": 317900,
        "start": 3199.36,
        "temperature": 0,
        "text": " Oh, wow, I put a lot of stuff in there.",
        "tokens": [
          51382,
          876,
          11,
          6076,
          11,
          286,
          829,
          257,
          688,
          295,
          1507,
          294,
          456,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -0.23995606104532877,
        "compression_ratio": 1.6774193548387097,
        "end": 3205.2,
        "id": 872,
        "no_speech_prob": 0.000023923463231767528,
        "seek": 317900,
        "start": 3201.16,
        "temperature": 0,
        "text": " But am I forgetting the created date?",
        "tokens": [
          51472,
          583,
          669,
          286,
          25428,
          264,
          2942,
          4002,
          30,
          51674
        ]
      },
      {
        "avg_logprob": -0.23995606104532877,
        "compression_ratio": 1.6774193548387097,
        "end": 3206.76,
        "id": 873,
        "no_speech_prob": 0.000023923463231767528,
        "seek": 317900,
        "start": 3205.2,
        "temperature": 0,
        "text": " Maybe that was before I added created.",
        "tokens": [
          51674,
          2704,
          300,
          390,
          949,
          286,
          3869,
          2942,
          13,
          51752
        ]
      },
      {
        "avg_logprob": -0.22760372868290654,
        "compression_ratio": 1.7372549019607844,
        "end": 3209.48,
        "id": 874,
        "no_speech_prob": 0.000011843108040920924,
        "seek": 320676,
        "start": 3206.76,
        "temperature": 0,
        "text": " But now all of the information in the database",
        "tokens": [
          50364,
          583,
          586,
          439,
          295,
          264,
          1589,
          294,
          264,
          8149,
          50500
        ]
      },
      {
        "avg_logprob": -0.22760372868290654,
        "compression_ratio": 1.7372549019607844,
        "end": 3210.4,
        "id": 875,
        "no_speech_prob": 0.000011843108040920924,
        "seek": 320676,
        "start": 3209.48,
        "temperature": 0,
        "text": " is being listed here.",
        "tokens": [
          50500,
          307,
          885,
          10052,
          510,
          13,
          50546
        ]
      },
      {
        "avg_logprob": -0.22760372868290654,
        "compression_ratio": 1.7372549019607844,
        "end": 3212.5200000000004,
        "id": 876,
        "no_speech_prob": 0.000011843108040920924,
        "seek": 320676,
        "start": 3210.4,
        "temperature": 0,
        "text": " So now I actually want to make this request",
        "tokens": [
          50546,
          407,
          586,
          286,
          767,
          528,
          281,
          652,
          341,
          5308,
          50652
        ]
      },
      {
        "avg_logprob": -0.22760372868290654,
        "compression_ratio": 1.7372549019607844,
        "end": 3215.6800000000003,
        "id": 877,
        "no_speech_prob": 0.000011843108040920924,
        "seek": 320676,
        "start": 3212.5200000000004,
        "temperature": 0,
        "text": " with my client side code so that I can show it on the page.",
        "tokens": [
          50652,
          365,
          452,
          6423,
          1252,
          3089,
          370,
          300,
          286,
          393,
          855,
          309,
          322,
          264,
          3028,
          13,
          50810
        ]
      },
      {
        "avg_logprob": -0.22760372868290654,
        "compression_ratio": 1.7372549019607844,
        "end": 3217.84,
        "id": 878,
        "no_speech_prob": 0.000011843108040920924,
        "seek": 320676,
        "start": 3215.6800000000003,
        "temperature": 0,
        "text": " So let's do just that.",
        "tokens": [
          50810,
          407,
          718,
          311,
          360,
          445,
          300,
          13,
          50918
        ]
      },
      {
        "avg_logprob": -0.22760372868290654,
        "compression_ratio": 1.7372549019607844,
        "end": 3220.88,
        "id": 879,
        "no_speech_prob": 0.000011843108040920924,
        "seek": 320676,
        "start": 3218.8,
        "temperature": 0,
        "text": " Get, respond.",
        "tokens": [
          50966,
          3240,
          11,
          4196,
          13,
          51070
        ]
      },
      {
        "avg_logprob": -0.22760372868290654,
        "compression_ratio": 1.7372549019607844,
        "end": 3221.7200000000003,
        "id": 880,
        "no_speech_prob": 0.000011843108040920924,
        "seek": 320676,
        "start": 3220.88,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51070,
          1057,
          558,
          13,
          51112
        ]
      },
      {
        "avg_logprob": -0.22760372868290654,
        "compression_ratio": 1.7372549019607844,
        "end": 3225.6800000000003,
        "id": 881,
        "no_speech_prob": 0.000011843108040920924,
        "seek": 320676,
        "start": 3222.6400000000003,
        "temperature": 0,
        "text": " So on the front end, when the page loads,",
        "tokens": [
          51158,
          407,
          322,
          264,
          1868,
          917,
          11,
          562,
          264,
          3028,
          12668,
          11,
          51310
        ]
      },
      {
        "avg_logprob": -0.22760372868290654,
        "compression_ratio": 1.7372549019607844,
        "end": 3227,
        "id": 882,
        "no_speech_prob": 0.000011843108040920924,
        "seek": 320676,
        "start": 3225.6800000000003,
        "temperature": 0,
        "text": " I want to request all of the mus.",
        "tokens": [
          51310,
          286,
          528,
          281,
          5308,
          439,
          295,
          264,
          1038,
          13,
          51376
        ]
      },
      {
        "avg_logprob": -0.22760372868290654,
        "compression_ratio": 1.7372549019607844,
        "end": 3228.5200000000004,
        "id": 883,
        "no_speech_prob": 0.000011843108040920924,
        "seek": 320676,
        "start": 3227,
        "temperature": 0,
        "text": " So I'm going to create a function.",
        "tokens": [
          51376,
          407,
          286,
          478,
          516,
          281,
          1884,
          257,
          2445,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.22760372868290654,
        "compression_ratio": 1.7372549019607844,
        "end": 3231.2400000000002,
        "id": 884,
        "no_speech_prob": 0.000011843108040920924,
        "seek": 320676,
        "start": 3228.5200000000004,
        "temperature": 0,
        "text": " Let's call it list all mus.",
        "tokens": [
          51452,
          961,
          311,
          818,
          309,
          1329,
          439,
          1038,
          13,
          51588
        ]
      },
      {
        "avg_logprob": -0.22760372868290654,
        "compression_ratio": 1.7372549019607844,
        "end": 3234.96,
        "id": 885,
        "no_speech_prob": 0.000011843108040920924,
        "seek": 320676,
        "start": 3232.1600000000003,
        "temperature": 0,
        "text": " And actually by default, I want the spinning bar",
        "tokens": [
          51634,
          400,
          767,
          538,
          7576,
          11,
          286,
          528,
          264,
          15640,
          2159,
          51774
        ]
      },
      {
        "avg_logprob": -0.22760372868290654,
        "compression_ratio": 1.7372549019607844,
        "end": 3236.7000000000003,
        "id": 886,
        "no_speech_prob": 0.000011843108040920924,
        "seek": 320676,
        "start": 3234.96,
        "temperature": 0,
        "text": " to be showing when the page loads,",
        "tokens": [
          51774,
          281,
          312,
          4099,
          562,
          264,
          3028,
          12668,
          11,
          51861
        ]
      },
      {
        "avg_logprob": -0.23359735012054444,
        "compression_ratio": 1.9304029304029304,
        "end": 3238.48,
        "id": 887,
        "no_speech_prob": 0.000025071487470995635,
        "seek": 323670,
        "start": 3237.64,
        "temperature": 0,
        "text": " because I'm going to be grabbing all of the mus.",
        "tokens": [
          50411,
          570,
          286,
          478,
          516,
          281,
          312,
          23771,
          439,
          295,
          264,
          1038,
          13,
          50453
        ]
      },
      {
        "avg_logprob": -0.23359735012054444,
        "compression_ratio": 1.9304029304029304,
        "end": 3240.7,
        "id": 888,
        "no_speech_prob": 0.000025071487470995635,
        "seek": 323670,
        "start": 3238.48,
        "temperature": 0,
        "text": " So show the loading element and then list all mus.",
        "tokens": [
          50453,
          407,
          855,
          264,
          15114,
          4478,
          293,
          550,
          1329,
          439,
          1038,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.23359735012054444,
        "compression_ratio": 1.9304029304029304,
        "end": 3243.7799999999997,
        "id": 889,
        "no_speech_prob": 0.000025071487470995635,
        "seek": 323670,
        "start": 3240.7,
        "temperature": 0,
        "text": " So I have a function, list all mus,",
        "tokens": [
          50564,
          407,
          286,
          362,
          257,
          2445,
          11,
          1329,
          439,
          1038,
          11,
          50718
        ]
      },
      {
        "avg_logprob": -0.23359735012054444,
        "compression_ratio": 1.9304029304029304,
        "end": 3245.22,
        "id": 890,
        "no_speech_prob": 0.000025071487470995635,
        "seek": 323670,
        "start": 3243.7799999999997,
        "temperature": 0,
        "text": " and we'll use fetch for this.",
        "tokens": [
          50718,
          293,
          321,
          603,
          764,
          23673,
          337,
          341,
          13,
          50790
        ]
      },
      {
        "avg_logprob": -0.23359735012054444,
        "compression_ratio": 1.9304029304029304,
        "end": 3246.98,
        "id": 891,
        "no_speech_prob": 0.000025071487470995635,
        "seek": 323670,
        "start": 3245.22,
        "temperature": 0,
        "text": " So we need to make a fetch.",
        "tokens": [
          50790,
          407,
          321,
          643,
          281,
          652,
          257,
          23673,
          13,
          50878
        ]
      },
      {
        "avg_logprob": -0.23359735012054444,
        "compression_ratio": 1.9304029304029304,
        "end": 3249.18,
        "id": 892,
        "no_speech_prob": 0.000025071487470995635,
        "seek": 323670,
        "start": 3246.98,
        "temperature": 0,
        "text": " And the URL is actually the same.",
        "tokens": [
          50878,
          400,
          264,
          12905,
          307,
          767,
          264,
          912,
          13,
          50988
        ]
      },
      {
        "avg_logprob": -0.23359735012054444,
        "compression_ratio": 1.9304029304029304,
        "end": 3250.8599999999997,
        "id": 893,
        "no_speech_prob": 0.000025071487470995635,
        "seek": 323670,
        "start": 3249.18,
        "temperature": 0,
        "text": " So you'll notice this was the URL I was putting",
        "tokens": [
          50988,
          407,
          291,
          603,
          3449,
          341,
          390,
          264,
          12905,
          286,
          390,
          3372,
          51072
        ]
      },
      {
        "avg_logprob": -0.23359735012054444,
        "compression_ratio": 1.9304029304029304,
        "end": 3254.08,
        "id": 894,
        "no_speech_prob": 0.000025071487470995635,
        "seek": 323670,
        "start": 3250.8599999999997,
        "temperature": 0,
        "text": " in my browser to request all of the mus.",
        "tokens": [
          51072,
          294,
          452,
          11185,
          281,
          5308,
          439,
          295,
          264,
          1038,
          13,
          51233
        ]
      },
      {
        "avg_logprob": -0.23359735012054444,
        "compression_ratio": 1.9304029304029304,
        "end": 3256.46,
        "id": 895,
        "no_speech_prob": 0.000025071487470995635,
        "seek": 323670,
        "start": 3254.08,
        "temperature": 0,
        "text": " So, but instead of a post request,",
        "tokens": [
          51233,
          407,
          11,
          457,
          2602,
          295,
          257,
          2183,
          5308,
          11,
          51352
        ]
      },
      {
        "avg_logprob": -0.23359735012054444,
        "compression_ratio": 1.9304029304029304,
        "end": 3258.62,
        "id": 896,
        "no_speech_prob": 0.000025071487470995635,
        "seek": 323670,
        "start": 3256.46,
        "temperature": 0,
        "text": " I want to make a get request to get all of that data.",
        "tokens": [
          51352,
          286,
          528,
          281,
          652,
          257,
          483,
          5308,
          281,
          483,
          439,
          295,
          300,
          1412,
          13,
          51460
        ]
      },
      {
        "avg_logprob": -0.23359735012054444,
        "compression_ratio": 1.9304029304029304,
        "end": 3259.8199999999997,
        "id": 897,
        "no_speech_prob": 0.000025071487470995635,
        "seek": 323670,
        "start": 3258.62,
        "temperature": 0,
        "text": " So let's do that.",
        "tokens": [
          51460,
          407,
          718,
          311,
          360,
          300,
          13,
          51520
        ]
      },
      {
        "avg_logprob": -0.23359735012054444,
        "compression_ratio": 1.9304029304029304,
        "end": 3262.3799999999997,
        "id": 898,
        "no_speech_prob": 0.000025071487470995635,
        "seek": 323670,
        "start": 3259.8199999999997,
        "temperature": 0,
        "text": " So I want to make the fetch against API URL.",
        "tokens": [
          51520,
          407,
          286,
          528,
          281,
          652,
          264,
          23673,
          1970,
          9362,
          12905,
          13,
          51648
        ]
      },
      {
        "avg_logprob": -0.23359735012054444,
        "compression_ratio": 1.9304029304029304,
        "end": 3264.68,
        "id": 899,
        "no_speech_prob": 0.000025071487470995635,
        "seek": 323670,
        "start": 3262.3799999999997,
        "temperature": 0,
        "text": " And the way fetch works is if you're making a get request,",
        "tokens": [
          51648,
          400,
          264,
          636,
          23673,
          1985,
          307,
          498,
          291,
          434,
          1455,
          257,
          483,
          5308,
          11,
          51763
        ]
      },
      {
        "avg_logprob": -0.19221387792516637,
        "compression_ratio": 1.6746031746031746,
        "end": 3267.22,
        "id": 900,
        "no_speech_prob": 0.00000517391072207829,
        "seek": 326468,
        "start": 3264.68,
        "temperature": 0,
        "text": " you don't have to specify any options.",
        "tokens": [
          50364,
          291,
          500,
          380,
          362,
          281,
          16500,
          604,
          3956,
          13,
          50491
        ]
      },
      {
        "avg_logprob": -0.19221387792516637,
        "compression_ratio": 1.6746031746031746,
        "end": 3269.62,
        "id": 901,
        "no_speech_prob": 0.00000517391072207829,
        "seek": 326468,
        "start": 3267.22,
        "temperature": 0,
        "text": " You can just say, hey, give me that data.",
        "tokens": [
          50491,
          509,
          393,
          445,
          584,
          11,
          4177,
          11,
          976,
          385,
          300,
          1412,
          13,
          50611
        ]
      },
      {
        "avg_logprob": -0.19221387792516637,
        "compression_ratio": 1.6746031746031746,
        "end": 3272.14,
        "id": 902,
        "no_speech_prob": 0.00000517391072207829,
        "seek": 326468,
        "start": 3269.62,
        "temperature": 0,
        "text": " Then we get back the response.",
        "tokens": [
          50611,
          1396,
          321,
          483,
          646,
          264,
          4134,
          13,
          50737
        ]
      },
      {
        "avg_logprob": -0.19221387792516637,
        "compression_ratio": 1.6746031746031746,
        "end": 3274.98,
        "id": 903,
        "no_speech_prob": 0.00000517391072207829,
        "seek": 326468,
        "start": 3272.14,
        "temperature": 0,
        "text": " We'll parse it as JSON because we know that's what it is.",
        "tokens": [
          50737,
          492,
          603,
          48377,
          309,
          382,
          31828,
          570,
          321,
          458,
          300,
          311,
          437,
          309,
          307,
          13,
          50879
        ]
      },
      {
        "avg_logprob": -0.19221387792516637,
        "compression_ratio": 1.6746031746031746,
        "end": 3279.18,
        "id": 904,
        "no_speech_prob": 0.00000517391072207829,
        "seek": 326468,
        "start": 3275.94,
        "temperature": 0,
        "text": " And then we get all of the mus.",
        "tokens": [
          50927,
          400,
          550,
          321,
          483,
          439,
          295,
          264,
          1038,
          13,
          51089
        ]
      },
      {
        "avg_logprob": -0.19221387792516637,
        "compression_ratio": 1.6746031746031746,
        "end": 3280.8199999999997,
        "id": 905,
        "no_speech_prob": 0.00000517391072207829,
        "seek": 326468,
        "start": 3279.18,
        "temperature": 0,
        "text": " And for now, let's just log those out.",
        "tokens": [
          51089,
          400,
          337,
          586,
          11,
          718,
          311,
          445,
          3565,
          729,
          484,
          13,
          51171
        ]
      },
      {
        "avg_logprob": -0.19221387792516637,
        "compression_ratio": 1.6746031746031746,
        "end": 3285.2599999999998,
        "id": 906,
        "no_speech_prob": 0.00000517391072207829,
        "seek": 326468,
        "start": 3280.8199999999997,
        "temperature": 0,
        "text": " So when the page loads, we'll log out all of the mus.",
        "tokens": [
          51171,
          407,
          562,
          264,
          3028,
          12668,
          11,
          321,
          603,
          3565,
          484,
          439,
          295,
          264,
          1038,
          13,
          51393
        ]
      },
      {
        "avg_logprob": -0.19221387792516637,
        "compression_ratio": 1.6746031746031746,
        "end": 3286.08,
        "id": 907,
        "no_speech_prob": 0.00000517391072207829,
        "seek": 326468,
        "start": 3285.2599999999998,
        "temperature": 0,
        "text": " And there they are.",
        "tokens": [
          51393,
          400,
          456,
          436,
          366,
          13,
          51434
        ]
      },
      {
        "avg_logprob": -0.19221387792516637,
        "compression_ratio": 1.6746031746031746,
        "end": 3288.2599999999998,
        "id": 908,
        "no_speech_prob": 0.00000517391072207829,
        "seek": 326468,
        "start": 3286.08,
        "temperature": 0,
        "text": " So now on the client side, we have an array",
        "tokens": [
          51434,
          407,
          586,
          322,
          264,
          6423,
          1252,
          11,
          321,
          362,
          364,
          10225,
          51543
        ]
      },
      {
        "avg_logprob": -0.19221387792516637,
        "compression_ratio": 1.6746031746031746,
        "end": 3289.2999999999997,
        "id": 909,
        "no_speech_prob": 0.00000517391072207829,
        "seek": 326468,
        "start": 3288.2599999999998,
        "temperature": 0,
        "text": " of all of our data.",
        "tokens": [
          51543,
          295,
          439,
          295,
          527,
          1412,
          13,
          51595
        ]
      },
      {
        "avg_logprob": -0.19221387792516637,
        "compression_ratio": 1.6746031746031746,
        "end": 3292.08,
        "id": 910,
        "no_speech_prob": 0.00000517391072207829,
        "seek": 326468,
        "start": 3289.2999999999997,
        "temperature": 0,
        "text": " Now we actually want to add it to the page.",
        "tokens": [
          51595,
          823,
          321,
          767,
          528,
          281,
          909,
          309,
          281,
          264,
          3028,
          13,
          51734
        ]
      },
      {
        "avg_logprob": -0.20835432365759096,
        "compression_ratio": 1.649402390438247,
        "end": 3296.06,
        "id": 911,
        "no_speech_prob": 0.0000010677018735805177,
        "seek": 329208,
        "start": 3292.1,
        "temperature": 0,
        "text": " So one thing I'll do is just iterate over them.",
        "tokens": [
          50365,
          407,
          472,
          551,
          286,
          603,
          360,
          307,
          445,
          44497,
          670,
          552,
          13,
          50563
        ]
      },
      {
        "avg_logprob": -0.20835432365759096,
        "compression_ratio": 1.649402390438247,
        "end": 3298.1,
        "id": 912,
        "no_speech_prob": 0.0000010677018735805177,
        "seek": 329208,
        "start": 3296.06,
        "temperature": 0,
        "text": " So I'm just going to do mus.foreach.",
        "tokens": [
          50563,
          407,
          286,
          478,
          445,
          516,
          281,
          360,
          1038,
          13,
          845,
          608,
          13,
          50665
        ]
      },
      {
        "avg_logprob": -0.20835432365759096,
        "compression_ratio": 1.649402390438247,
        "end": 3301.08,
        "id": 913,
        "no_speech_prob": 0.0000010677018735805177,
        "seek": 329208,
        "start": 3299.62,
        "temperature": 0,
        "text": " We'll get access to each mu.",
        "tokens": [
          50741,
          492,
          603,
          483,
          2105,
          281,
          1184,
          2992,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20835432365759096,
        "compression_ratio": 1.649402390438247,
        "end": 3303.14,
        "id": 914,
        "no_speech_prob": 0.0000010677018735805177,
        "seek": 329208,
        "start": 3301.08,
        "temperature": 0,
        "text": " And in order to add it to the page,",
        "tokens": [
          50814,
          400,
          294,
          1668,
          281,
          909,
          309,
          281,
          264,
          3028,
          11,
          50917
        ]
      },
      {
        "avg_logprob": -0.20835432365759096,
        "compression_ratio": 1.649402390438247,
        "end": 3304.54,
        "id": 915,
        "no_speech_prob": 0.0000010677018735805177,
        "seek": 329208,
        "start": 3303.14,
        "temperature": 0,
        "text": " I need some reference on the page",
        "tokens": [
          50917,
          286,
          643,
          512,
          6408,
          322,
          264,
          3028,
          50987
        ]
      },
      {
        "avg_logprob": -0.20835432365759096,
        "compression_ratio": 1.649402390438247,
        "end": 3305.92,
        "id": 916,
        "no_speech_prob": 0.0000010677018735805177,
        "seek": 329208,
        "start": 3304.54,
        "temperature": 0,
        "text": " of where I'm going to add it.",
        "tokens": [
          50987,
          295,
          689,
          286,
          478,
          516,
          281,
          909,
          309,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.20835432365759096,
        "compression_ratio": 1.649402390438247,
        "end": 3310.5,
        "id": 917,
        "no_speech_prob": 0.0000010677018735805177,
        "seek": 329208,
        "start": 3305.92,
        "temperature": 0,
        "text": " So in my HTML, I basically need like an X marks the spot.",
        "tokens": [
          51056,
          407,
          294,
          452,
          17995,
          11,
          286,
          1936,
          643,
          411,
          364,
          1783,
          10640,
          264,
          4008,
          13,
          51285
        ]
      },
      {
        "avg_logprob": -0.20835432365759096,
        "compression_ratio": 1.649402390438247,
        "end": 3312.7799999999997,
        "id": 918,
        "no_speech_prob": 0.0000010677018735805177,
        "seek": 329208,
        "start": 3310.5,
        "temperature": 0,
        "text": " And I'm going to put them right here.",
        "tokens": [
          51285,
          400,
          286,
          478,
          516,
          281,
          829,
          552,
          558,
          510,
          13,
          51399
        ]
      },
      {
        "avg_logprob": -0.20835432365759096,
        "compression_ratio": 1.649402390438247,
        "end": 3316.18,
        "id": 919,
        "no_speech_prob": 0.0000010677018735805177,
        "seek": 329208,
        "start": 3312.7799999999997,
        "temperature": 0,
        "text": " Let's give this a class of mus.",
        "tokens": [
          51399,
          961,
          311,
          976,
          341,
          257,
          1508,
          295,
          1038,
          13,
          51569
        ]
      },
      {
        "avg_logprob": -0.20835432365759096,
        "compression_ratio": 1.649402390438247,
        "end": 3320.06,
        "id": 920,
        "no_speech_prob": 0.0000010677018735805177,
        "seek": 329208,
        "start": 3317.14,
        "temperature": 0,
        "text": " And so in my JavaScript, I'll select this element",
        "tokens": [
          51617,
          400,
          370,
          294,
          452,
          15778,
          11,
          286,
          603,
          3048,
          341,
          4478,
          51763
        ]
      },
      {
        "avg_logprob": -0.20835432365759096,
        "compression_ratio": 1.649402390438247,
        "end": 3321.46,
        "id": 921,
        "no_speech_prob": 0.0000010677018735805177,
        "seek": 329208,
        "start": 3320.06,
        "temperature": 0,
        "text": " and keep a hold of it.",
        "tokens": [
          51763,
          293,
          1066,
          257,
          1797,
          295,
          309,
          13,
          51833
        ]
      },
      {
        "avg_logprob": -0.2299032820031998,
        "compression_ratio": 1.7245283018867925,
        "end": 3322.84,
        "id": 922,
        "no_speech_prob": 0.000009666096957516856,
        "seek": 332146,
        "start": 3321.8,
        "temperature": 0,
        "text": " And then anytime I want to add a mu,",
        "tokens": [
          50381,
          400,
          550,
          13038,
          286,
          528,
          281,
          909,
          257,
          2992,
          11,
          50433
        ]
      },
      {
        "avg_logprob": -0.2299032820031998,
        "compression_ratio": 1.7245283018867925,
        "end": 3324.52,
        "id": 923,
        "no_speech_prob": 0.000009666096957516856,
        "seek": 332146,
        "start": 3322.84,
        "temperature": 0,
        "text": " I'm going to put it into this element.",
        "tokens": [
          50433,
          286,
          478,
          516,
          281,
          829,
          309,
          666,
          341,
          4478,
          13,
          50517
        ]
      },
      {
        "avg_logprob": -0.2299032820031998,
        "compression_ratio": 1.7245283018867925,
        "end": 3325.56,
        "id": 924,
        "no_speech_prob": 0.000009666096957516856,
        "seek": 332146,
        "start": 3324.52,
        "temperature": 0,
        "text": " We're going to append the child.",
        "tokens": [
          50517,
          492,
          434,
          516,
          281,
          34116,
          264,
          1440,
          13,
          50569
        ]
      },
      {
        "avg_logprob": -0.2299032820031998,
        "compression_ratio": 1.7245283018867925,
        "end": 3330.56,
        "id": 925,
        "no_speech_prob": 0.000009666096957516856,
        "seek": 332146,
        "start": 3325.56,
        "temperature": 0,
        "text": " So in our client, let's create a variable called musElement.",
        "tokens": [
          50569,
          407,
          294,
          527,
          6423,
          11,
          718,
          311,
          1884,
          257,
          7006,
          1219,
          1038,
          36,
          3054,
          13,
          50819
        ]
      },
      {
        "avg_logprob": -0.2299032820031998,
        "compression_ratio": 1.7245283018867925,
        "end": 3334.56,
        "id": 926,
        "no_speech_prob": 0.000009666096957516856,
        "seek": 332146,
        "start": 3331.96,
        "temperature": 0,
        "text": " And we'll do again, document.querySelector.",
        "tokens": [
          50889,
          400,
          321,
          603,
          360,
          797,
          11,
          4166,
          13,
          358,
          2109,
          10637,
          306,
          1672,
          13,
          51019
        ]
      },
      {
        "avg_logprob": -0.2299032820031998,
        "compression_ratio": 1.7245283018867925,
        "end": 3338.02,
        "id": 927,
        "no_speech_prob": 0.000009666096957516856,
        "seek": 332146,
        "start": 3335.56,
        "temperature": 0,
        "text": " And because I gave it a class of mus,",
        "tokens": [
          51069,
          400,
          570,
          286,
          2729,
          309,
          257,
          1508,
          295,
          1038,
          11,
          51192
        ]
      },
      {
        "avg_logprob": -0.2299032820031998,
        "compression_ratio": 1.7245283018867925,
        "end": 3340.12,
        "id": 928,
        "no_speech_prob": 0.000009666096957516856,
        "seek": 332146,
        "start": 3338.02,
        "temperature": 0,
        "text": " we can select it like that.",
        "tokens": [
          51192,
          321,
          393,
          3048,
          309,
          411,
          300,
          13,
          51297
        ]
      },
      {
        "avg_logprob": -0.2299032820031998,
        "compression_ratio": 1.7245283018867925,
        "end": 3342.32,
        "id": 929,
        "no_speech_prob": 0.000009666096957516856,
        "seek": 332146,
        "start": 3340.12,
        "temperature": 0,
        "text": " And now that I have the mus element,",
        "tokens": [
          51297,
          400,
          586,
          300,
          286,
          362,
          264,
          1038,
          4478,
          11,
          51407
        ]
      },
      {
        "avg_logprob": -0.2299032820031998,
        "compression_ratio": 1.7245283018867925,
        "end": 3345.6,
        "id": 930,
        "no_speech_prob": 0.000009666096957516856,
        "seek": 332146,
        "start": 3343.32,
        "temperature": 0,
        "text": " for every element in this array,",
        "tokens": [
          51457,
          337,
          633,
          4478,
          294,
          341,
          10225,
          11,
          51571
        ]
      },
      {
        "avg_logprob": -0.2299032820031998,
        "compression_ratio": 1.7245283018867925,
        "end": 3348.32,
        "id": 931,
        "no_speech_prob": 0.000009666096957516856,
        "seek": 332146,
        "start": 3345.6,
        "temperature": 0,
        "text": " I want to append it to the page or put it on the page.",
        "tokens": [
          51571,
          286,
          528,
          281,
          34116,
          309,
          281,
          264,
          3028,
          420,
          829,
          309,
          322,
          264,
          3028,
          13,
          51707
        ]
      },
      {
        "avg_logprob": -0.2299032820031998,
        "compression_ratio": 1.7245283018867925,
        "end": 3350.84,
        "id": 932,
        "no_speech_prob": 0.000009666096957516856,
        "seek": 332146,
        "start": 3348.32,
        "temperature": 0,
        "text": " So first thing is I'll need to create some elements.",
        "tokens": [
          51707,
          407,
          700,
          551,
          307,
          286,
          603,
          643,
          281,
          1884,
          512,
          4959,
          13,
          51833
        ]
      },
      {
        "avg_logprob": -0.26054512508331784,
        "compression_ratio": 1.8365384615384615,
        "end": 3355.86,
        "id": 933,
        "no_speech_prob": 0.000005014721409679623,
        "seek": 335084,
        "start": 3351.2200000000003,
        "temperature": 0,
        "text": " I'm going to say like a div will be document.createElement.",
        "tokens": [
          50383,
          286,
          478,
          516,
          281,
          584,
          411,
          257,
          3414,
          486,
          312,
          4166,
          13,
          14066,
          473,
          36,
          3054,
          13,
          50615
        ]
      },
      {
        "avg_logprob": -0.26054512508331784,
        "compression_ratio": 1.8365384615384615,
        "end": 3357.1800000000003,
        "id": 934,
        "no_speech_prob": 0.000005014721409679623,
        "seek": 335084,
        "start": 3355.86,
        "temperature": 0,
        "text": " And I'll pass in div.",
        "tokens": [
          50615,
          400,
          286,
          603,
          1320,
          294,
          3414,
          13,
          50681
        ]
      },
      {
        "avg_logprob": -0.26054512508331784,
        "compression_ratio": 1.8365384615384615,
        "end": 3360.2200000000003,
        "id": 935,
        "no_speech_prob": 0.000005014721409679623,
        "seek": 335084,
        "start": 3357.1800000000003,
        "temperature": 0,
        "text": " And then we want probably a header",
        "tokens": [
          50681,
          400,
          550,
          321,
          528,
          1391,
          257,
          23117,
          50833
        ]
      },
      {
        "avg_logprob": -0.26054512508331784,
        "compression_ratio": 1.8365384615384615,
        "end": 3361.2200000000003,
        "id": 936,
        "no_speech_prob": 0.000005014721409679623,
        "seek": 335084,
        "start": 3360.2200000000003,
        "temperature": 0,
        "text": " to show the person's name.",
        "tokens": [
          50833,
          281,
          855,
          264,
          954,
          311,
          1315,
          13,
          50883
        ]
      },
      {
        "avg_logprob": -0.26054512508331784,
        "compression_ratio": 1.8365384615384615,
        "end": 3362.82,
        "id": 937,
        "no_speech_prob": 0.000005014721409679623,
        "seek": 335084,
        "start": 3361.2200000000003,
        "temperature": 0,
        "text": " So let's create a header.",
        "tokens": [
          50883,
          407,
          718,
          311,
          1884,
          257,
          23117,
          13,
          50963
        ]
      },
      {
        "avg_logprob": -0.26054512508331784,
        "compression_ratio": 1.8365384615384615,
        "end": 3365.6200000000003,
        "id": 938,
        "no_speech_prob": 0.000005014721409679623,
        "seek": 335084,
        "start": 3362.82,
        "temperature": 0,
        "text": " And this will be document.createElement.",
        "tokens": [
          50963,
          400,
          341,
          486,
          312,
          4166,
          13,
          14066,
          473,
          36,
          3054,
          13,
          51103
        ]
      },
      {
        "avg_logprob": -0.26054512508331784,
        "compression_ratio": 1.8365384615384615,
        "end": 3370.1000000000004,
        "id": 939,
        "no_speech_prob": 0.000005014721409679623,
        "seek": 335084,
        "start": 3367.7000000000003,
        "temperature": 0,
        "text": " We'll pass in like H3 maybe.",
        "tokens": [
          51207,
          492,
          603,
          1320,
          294,
          411,
          389,
          18,
          1310,
          13,
          51327
        ]
      },
      {
        "avg_logprob": -0.26054512508331784,
        "compression_ratio": 1.8365384615384615,
        "end": 3372.7400000000002,
        "id": 940,
        "no_speech_prob": 0.000005014721409679623,
        "seek": 335084,
        "start": 3370.1000000000004,
        "temperature": 0,
        "text": " And then we want to set the contents of that header.",
        "tokens": [
          51327,
          400,
          550,
          321,
          528,
          281,
          992,
          264,
          15768,
          295,
          300,
          23117,
          13,
          51459
        ]
      },
      {
        "avg_logprob": -0.26054512508331784,
        "compression_ratio": 1.8365384615384615,
        "end": 3375.38,
        "id": 941,
        "no_speech_prob": 0.000005014721409679623,
        "seek": 335084,
        "start": 3372.7400000000002,
        "temperature": 0,
        "text": " So we do header.textContent.",
        "tokens": [
          51459,
          407,
          321,
          360,
          23117,
          13,
          25111,
          29821,
          317,
          13,
          51591
        ]
      },
      {
        "avg_logprob": -0.26054512508331784,
        "compression_ratio": 1.8365384615384615,
        "end": 3377.86,
        "id": 942,
        "no_speech_prob": 0.000005014721409679623,
        "seek": 335084,
        "start": 3375.38,
        "temperature": 0,
        "text": " And this is going to be mu.name",
        "tokens": [
          51591,
          400,
          341,
          307,
          516,
          281,
          312,
          2992,
          13,
          16344,
          51715
        ]
      },
      {
        "avg_logprob": -0.26054512508331784,
        "compression_ratio": 1.8365384615384615,
        "end": 3379.94,
        "id": 943,
        "no_speech_prob": 0.000005014721409679623,
        "seek": 335084,
        "start": 3377.86,
        "temperature": 0,
        "text": " because every mu has a name.",
        "tokens": [
          51715,
          570,
          633,
          2992,
          575,
          257,
          1315,
          13,
          51819
        ]
      },
      {
        "avg_logprob": -0.2241159945118184,
        "compression_ratio": 1.6836158192090396,
        "end": 3382.6,
        "id": 944,
        "no_speech_prob": 0.000004029453521070536,
        "seek": 337994,
        "start": 3379.96,
        "temperature": 0,
        "text": " And then we also want the actual contents",
        "tokens": [
          50365,
          400,
          550,
          321,
          611,
          528,
          264,
          3539,
          15768,
          50497
        ]
      },
      {
        "avg_logprob": -0.2241159945118184,
        "compression_ratio": 1.6836158192090396,
        "end": 3383.76,
        "id": 945,
        "no_speech_prob": 0.000004029453521070536,
        "seek": 337994,
        "start": 3382.6,
        "temperature": 0,
        "text": " to be in like a paragraph tag.",
        "tokens": [
          50497,
          281,
          312,
          294,
          411,
          257,
          18865,
          6162,
          13,
          50555
        ]
      },
      {
        "avg_logprob": -0.2241159945118184,
        "compression_ratio": 1.6836158192090396,
        "end": 3385.76,
        "id": 946,
        "no_speech_prob": 0.000004029453521070536,
        "seek": 337994,
        "start": 3383.76,
        "temperature": 0,
        "text": " So let's just say contents.",
        "tokens": [
          50555,
          407,
          718,
          311,
          445,
          584,
          15768,
          13,
          50655
        ]
      },
      {
        "avg_logprob": -0.2241159945118184,
        "compression_ratio": 1.6836158192090396,
        "end": 3391.64,
        "id": 947,
        "no_speech_prob": 0.000004029453521070536,
        "seek": 337994,
        "start": 3386.64,
        "temperature": 0,
        "text": " That'll be document.createElement p tag.",
        "tokens": [
          50699,
          663,
          603,
          312,
          4166,
          13,
          14066,
          473,
          36,
          3054,
          280,
          6162,
          13,
          50949
        ]
      },
      {
        "avg_logprob": -0.2241159945118184,
        "compression_ratio": 1.6836158192090396,
        "end": 3396.7200000000003,
        "id": 948,
        "no_speech_prob": 0.000004029453521070536,
        "seek": 337994,
        "start": 3392,
        "temperature": 0,
        "text": " And then I'll say contents.textContent",
        "tokens": [
          50967,
          400,
          550,
          286,
          603,
          584,
          15768,
          13,
          25111,
          29821,
          317,
          51203
        ]
      },
      {
        "avg_logprob": -0.2241159945118184,
        "compression_ratio": 1.6836158192090396,
        "end": 3399.6,
        "id": 949,
        "no_speech_prob": 0.000004029453521070536,
        "seek": 337994,
        "start": 3396.7200000000003,
        "temperature": 0,
        "text": " will be mu.contents.",
        "tokens": [
          51203,
          486,
          312,
          2992,
          13,
          9000,
          791,
          13,
          51347
        ]
      },
      {
        "avg_logprob": -0.2241159945118184,
        "compression_ratio": 1.6836158192090396,
        "end": 3400.64,
        "id": 950,
        "no_speech_prob": 0.000004029453521070536,
        "seek": 337994,
        "start": 3399.6,
        "temperature": 0,
        "text": " Is it contents?",
        "tokens": [
          51347,
          1119,
          309,
          15768,
          30,
          51399
        ]
      },
      {
        "avg_logprob": -0.2241159945118184,
        "compression_ratio": 1.6836158192090396,
        "end": 3404.04,
        "id": 951,
        "no_speech_prob": 0.000004029453521070536,
        "seek": 337994,
        "start": 3401.88,
        "temperature": 0,
        "text": " Content with a singular.",
        "tokens": [
          51461,
          30078,
          365,
          257,
          20010,
          13,
          51569
        ]
      },
      {
        "avg_logprob": -0.2241159945118184,
        "compression_ratio": 1.6836158192090396,
        "end": 3409.76,
        "id": 952,
        "no_speech_prob": 0.000004029453521070536,
        "seek": 337994,
        "start": 3405.36,
        "temperature": 0,
        "text": " Okay, so we're setting the H3, we're setting the p tag.",
        "tokens": [
          51635,
          1033,
          11,
          370,
          321,
          434,
          3287,
          264,
          389,
          18,
          11,
          321,
          434,
          3287,
          264,
          280,
          6162,
          13,
          51855
        ]
      },
      {
        "avg_logprob": -0.21601734161376954,
        "compression_ratio": 1.8356164383561644,
        "end": 3411.4,
        "id": 953,
        "no_speech_prob": 0.000025867360818665475,
        "seek": 340976,
        "start": 3410.5800000000004,
        "temperature": 0,
        "text": " Now we have to actually put these somewhere.",
        "tokens": [
          50405,
          823,
          321,
          362,
          281,
          767,
          829,
          613,
          4079,
          13,
          50446
        ]
      },
      {
        "avg_logprob": -0.21601734161376954,
        "compression_ratio": 1.8356164383561644,
        "end": 3412.78,
        "id": 954,
        "no_speech_prob": 0.000025867360818665475,
        "seek": 340976,
        "start": 3411.4,
        "temperature": 0,
        "text": " So when you use document.createElement,",
        "tokens": [
          50446,
          407,
          562,
          291,
          764,
          4166,
          13,
          14066,
          473,
          36,
          3054,
          11,
          50515
        ]
      },
      {
        "avg_logprob": -0.21601734161376954,
        "compression_ratio": 1.8356164383561644,
        "end": 3414.1800000000003,
        "id": 955,
        "no_speech_prob": 0.000025867360818665475,
        "seek": 340976,
        "start": 3412.78,
        "temperature": 0,
        "text": " it doesn't actually put them on the page,",
        "tokens": [
          50515,
          309,
          1177,
          380,
          767,
          829,
          552,
          322,
          264,
          3028,
          11,
          50585
        ]
      },
      {
        "avg_logprob": -0.21601734161376954,
        "compression_ratio": 1.8356164383561644,
        "end": 3416.0600000000004,
        "id": 956,
        "no_speech_prob": 0.000025867360818665475,
        "seek": 340976,
        "start": 3414.1800000000003,
        "temperature": 0,
        "text": " it just creates them.",
        "tokens": [
          50585,
          309,
          445,
          7829,
          552,
          13,
          50679
        ]
      },
      {
        "avg_logprob": -0.21601734161376954,
        "compression_ratio": 1.8356164383561644,
        "end": 3420.5800000000004,
        "id": 957,
        "no_speech_prob": 0.000025867360818665475,
        "seek": 340976,
        "start": 3416.0600000000004,
        "temperature": 0,
        "text": " So what I'll do is take this H3 and append it to the div.",
        "tokens": [
          50679,
          407,
          437,
          286,
          603,
          360,
          307,
          747,
          341,
          389,
          18,
          293,
          34116,
          309,
          281,
          264,
          3414,
          13,
          50905
        ]
      },
      {
        "avg_logprob": -0.21601734161376954,
        "compression_ratio": 1.8356164383561644,
        "end": 3423.98,
        "id": 958,
        "no_speech_prob": 0.000025867360818665475,
        "seek": 340976,
        "start": 3420.5800000000004,
        "temperature": 0,
        "text": " So I'll say div.appendChild header.",
        "tokens": [
          50905,
          407,
          286,
          603,
          584,
          3414,
          13,
          1746,
          521,
          35117,
          23117,
          13,
          51075
        ]
      },
      {
        "avg_logprob": -0.21601734161376954,
        "compression_ratio": 1.8356164383561644,
        "end": 3425.7400000000002,
        "id": 959,
        "no_speech_prob": 0.000025867360818665475,
        "seek": 340976,
        "start": 3423.98,
        "temperature": 0,
        "text": " And then I'll take this p tag",
        "tokens": [
          51075,
          400,
          550,
          286,
          603,
          747,
          341,
          280,
          6162,
          51163
        ]
      },
      {
        "avg_logprob": -0.21601734161376954,
        "compression_ratio": 1.8356164383561644,
        "end": 3427.78,
        "id": 960,
        "no_speech_prob": 0.000025867360818665475,
        "seek": 340976,
        "start": 3425.7400000000002,
        "temperature": 0,
        "text": " and append it to the div as well.",
        "tokens": [
          51163,
          293,
          34116,
          309,
          281,
          264,
          3414,
          382,
          731,
          13,
          51265
        ]
      },
      {
        "avg_logprob": -0.21601734161376954,
        "compression_ratio": 1.8356164383561644,
        "end": 3431.1000000000004,
        "id": 961,
        "no_speech_prob": 0.000025867360818665475,
        "seek": 340976,
        "start": 3427.78,
        "temperature": 0,
        "text": " So div.appendChild the contents.",
        "tokens": [
          51265,
          407,
          3414,
          13,
          1746,
          521,
          35117,
          264,
          15768,
          13,
          51431
        ]
      },
      {
        "avg_logprob": -0.21601734161376954,
        "compression_ratio": 1.8356164383561644,
        "end": 3435.3,
        "id": 962,
        "no_speech_prob": 0.000025867360818665475,
        "seek": 340976,
        "start": 3432.6600000000003,
        "temperature": 0,
        "text": " And now this div has the name in it,",
        "tokens": [
          51509,
          400,
          586,
          341,
          3414,
          575,
          264,
          1315,
          294,
          309,
          11,
          51641
        ]
      },
      {
        "avg_logprob": -0.21601734161376954,
        "compression_ratio": 1.8356164383561644,
        "end": 3437.48,
        "id": 963,
        "no_speech_prob": 0.000025867360818665475,
        "seek": 340976,
        "start": 3435.3,
        "temperature": 0,
        "text": " it has the content in it.",
        "tokens": [
          51641,
          309,
          575,
          264,
          2701,
          294,
          309,
          13,
          51750
        ]
      },
      {
        "avg_logprob": -0.2917100752907238,
        "compression_ratio": 1.7491408934707904,
        "end": 3440.66,
        "id": 964,
        "no_speech_prob": 0.000007527980869781459,
        "seek": 343748,
        "start": 3437.48,
        "temperature": 0,
        "text": " Now I wanna take this div and put it on this muse element.",
        "tokens": [
          50364,
          823,
          286,
          1948,
          747,
          341,
          3414,
          293,
          829,
          309,
          322,
          341,
          1038,
          68,
          4478,
          13,
          50523
        ]
      },
      {
        "avg_logprob": -0.2917100752907238,
        "compression_ratio": 1.7491408934707904,
        "end": 3442.46,
        "id": 965,
        "no_speech_prob": 0.000007527980869781459,
        "seek": 343748,
        "start": 3440.66,
        "temperature": 0,
        "text": " Basically right here, I wanna put that element.",
        "tokens": [
          50523,
          8537,
          558,
          510,
          11,
          286,
          1948,
          829,
          300,
          4478,
          13,
          50613
        ]
      },
      {
        "avg_logprob": -0.2917100752907238,
        "compression_ratio": 1.7491408934707904,
        "end": 3445.26,
        "id": 966,
        "no_speech_prob": 0.000007527980869781459,
        "seek": 343748,
        "start": 3442.46,
        "temperature": 0,
        "text": " So I created that muse element variable",
        "tokens": [
          50613,
          407,
          286,
          2942,
          300,
          39138,
          4478,
          7006,
          50753
        ]
      },
      {
        "avg_logprob": -0.2917100752907238,
        "compression_ratio": 1.7491408934707904,
        "end": 3447.78,
        "id": 967,
        "no_speech_prob": 0.000007527980869781459,
        "seek": 343748,
        "start": 3445.26,
        "temperature": 0,
        "text": " and I'm going to append the div to it.",
        "tokens": [
          50753,
          293,
          286,
          478,
          516,
          281,
          34116,
          264,
          3414,
          281,
          309,
          13,
          50879
        ]
      },
      {
        "avg_logprob": -0.2917100752907238,
        "compression_ratio": 1.7491408934707904,
        "end": 3450.46,
        "id": 968,
        "no_speech_prob": 0.000007527980869781459,
        "seek": 343748,
        "start": 3447.78,
        "temperature": 0,
        "text": " And just like that, there they are.",
        "tokens": [
          50879,
          400,
          445,
          411,
          300,
          11,
          456,
          436,
          366,
          13,
          51013
        ]
      },
      {
        "avg_logprob": -0.2917100752907238,
        "compression_ratio": 1.7491408934707904,
        "end": 3451.5,
        "id": 969,
        "no_speech_prob": 0.000007527980869781459,
        "seek": 343748,
        "start": 3450.46,
        "temperature": 0,
        "text": " But I think I misspelled something.",
        "tokens": [
          51013,
          583,
          286,
          519,
          286,
          1713,
          33000,
          746,
          13,
          51065
        ]
      },
      {
        "avg_logprob": -0.2917100752907238,
        "compression_ratio": 1.7491408934707904,
        "end": 3452.5,
        "id": 970,
        "no_speech_prob": 0.000007527980869781459,
        "seek": 343748,
        "start": 3451.5,
        "temperature": 0,
        "text": " You've got a typo.",
        "tokens": [
          51065,
          509,
          600,
          658,
          257,
          2125,
          78,
          13,
          51115
        ]
      },
      {
        "avg_logprob": -0.2917100752907238,
        "compression_ratio": 1.7491408934707904,
        "end": 3453.94,
        "id": 971,
        "no_speech_prob": 0.000007527980869781459,
        "seek": 343748,
        "start": 3452.5,
        "temperature": 0,
        "text": " Okay, and I think I got it.",
        "tokens": [
          51115,
          1033,
          11,
          293,
          286,
          519,
          286,
          658,
          309,
          13,
          51187
        ]
      },
      {
        "avg_logprob": -0.2917100752907238,
        "compression_ratio": 1.7491408934707904,
        "end": 3456.78,
        "id": 972,
        "no_speech_prob": 0.000007527980869781459,
        "seek": 343748,
        "start": 3453.94,
        "temperature": 0,
        "text": " So where?",
        "tokens": [
          51187,
          407,
          689,
          30,
          51329
        ]
      },
      {
        "avg_logprob": -0.2917100752907238,
        "compression_ratio": 1.7491408934707904,
        "end": 3459.5,
        "id": 973,
        "no_speech_prob": 0.000007527980869781459,
        "seek": 343748,
        "start": 3456.78,
        "temperature": 0,
        "text": " CO, I think you misspelled content somewhere.",
        "tokens": [
          51329,
          3002,
          11,
          286,
          519,
          291,
          1713,
          33000,
          2701,
          4079,
          13,
          51465
        ]
      },
      {
        "avg_logprob": -0.2917100752907238,
        "compression_ratio": 1.7491408934707904,
        "end": 3460.7,
        "id": 974,
        "no_speech_prob": 0.000007527980869781459,
        "seek": 343748,
        "start": 3459.5,
        "temperature": 0,
        "text": " C-O-N-T-E-T.",
        "tokens": [
          51465,
          383,
          12,
          46,
          12,
          45,
          12,
          51,
          12,
          36,
          12,
          51,
          13,
          51525
        ]
      },
      {
        "avg_logprob": -0.2917100752907238,
        "compression_ratio": 1.7491408934707904,
        "end": 3461.7,
        "id": 975,
        "no_speech_prob": 0.000007527980869781459,
        "seek": 343748,
        "start": 3460.7,
        "temperature": 0,
        "text": " So it's the chat.",
        "tokens": [
          51525,
          407,
          309,
          311,
          264,
          5081,
          13,
          51575
        ]
      },
      {
        "avg_logprob": -0.2917100752907238,
        "compression_ratio": 1.7491408934707904,
        "end": 3462.54,
        "id": 976,
        "no_speech_prob": 0.000007527980869781459,
        "seek": 343748,
        "start": 3461.7,
        "temperature": 0,
        "text": " Look at that.",
        "tokens": [
          51575,
          2053,
          412,
          300,
          13,
          51617
        ]
      },
      {
        "avg_logprob": -0.2917100752907238,
        "compression_ratio": 1.7491408934707904,
        "end": 3463.36,
        "id": 977,
        "no_speech_prob": 0.000007527980869781459,
        "seek": 343748,
        "start": 3462.54,
        "temperature": 0,
        "text": " Okay, cool.",
        "tokens": [
          51617,
          1033,
          11,
          1627,
          13,
          51658
        ]
      },
      {
        "avg_logprob": -0.2917100752907238,
        "compression_ratio": 1.7491408934707904,
        "end": 3464.2,
        "id": 978,
        "no_speech_prob": 0.000007527980869781459,
        "seek": 343748,
        "start": 3463.36,
        "temperature": 0,
        "text": " It's funny, I'm barely watching the stream,",
        "tokens": [
          51658,
          467,
          311,
          4074,
          11,
          286,
          478,
          10268,
          1976,
          264,
          4309,
          11,
          51700
        ]
      },
      {
        "avg_logprob": -0.2917100752907238,
        "compression_ratio": 1.7491408934707904,
        "end": 3465.78,
        "id": 979,
        "no_speech_prob": 0.000007527980869781459,
        "seek": 343748,
        "start": 3464.2,
        "temperature": 0,
        "text": " I'm just watching the chat now.",
        "tokens": [
          51700,
          286,
          478,
          445,
          1976,
          264,
          5081,
          586,
          13,
          51779
        ]
      },
      {
        "avg_logprob": -0.2917100752907238,
        "compression_ratio": 1.7491408934707904,
        "end": 3467.08,
        "id": 980,
        "no_speech_prob": 0.000007527980869781459,
        "seek": 343748,
        "start": 3465.78,
        "temperature": 0,
        "text": " It's exploding.",
        "tokens": [
          51779,
          467,
          311,
          35175,
          13,
          51844
        ]
      },
      {
        "avg_logprob": -0.24243846973339161,
        "compression_ratio": 1.8458498023715415,
        "end": 3468.7,
        "id": 981,
        "no_speech_prob": 0.000077221637184266,
        "seek": 346708,
        "start": 3467.7799999999997,
        "temperature": 0,
        "text": " And it's working.",
        "tokens": [
          50399,
          400,
          309,
          311,
          1364,
          13,
          50445
        ]
      },
      {
        "avg_logprob": -0.24243846973339161,
        "compression_ratio": 1.8458498023715415,
        "end": 3472.5,
        "id": 982,
        "no_speech_prob": 0.000077221637184266,
        "seek": 346708,
        "start": 3468.7,
        "temperature": 0,
        "text": " So we see the name of the muse, sorry, not the tweet,",
        "tokens": [
          50445,
          407,
          321,
          536,
          264,
          1315,
          295,
          264,
          2992,
          405,
          11,
          2597,
          11,
          406,
          264,
          15258,
          11,
          50635
        ]
      },
      {
        "avg_logprob": -0.24243846973339161,
        "compression_ratio": 1.8458498023715415,
        "end": 3473.42,
        "id": 983,
        "no_speech_prob": 0.000077221637184266,
        "seek": 346708,
        "start": 3472.5,
        "temperature": 0,
        "text": " the contents of the tweet,",
        "tokens": [
          50635,
          264,
          15768,
          295,
          264,
          15258,
          11,
          50681
        ]
      },
      {
        "avg_logprob": -0.24243846973339161,
        "compression_ratio": 1.8458498023715415,
        "end": 3474.7,
        "id": 984,
        "no_speech_prob": 0.000077221637184266,
        "seek": 346708,
        "start": 3473.42,
        "temperature": 0,
        "text": " and they're all listed on the page here.",
        "tokens": [
          50681,
          293,
          436,
          434,
          439,
          10052,
          322,
          264,
          3028,
          510,
          13,
          50745
        ]
      },
      {
        "avg_logprob": -0.24243846973339161,
        "compression_ratio": 1.8458498023715415,
        "end": 3476.94,
        "id": 985,
        "no_speech_prob": 0.000077221637184266,
        "seek": 346708,
        "start": 3474.7,
        "temperature": 0,
        "text": " So when the page loads, it makes that request,",
        "tokens": [
          50745,
          407,
          562,
          264,
          3028,
          12668,
          11,
          309,
          1669,
          300,
          5308,
          11,
          50857
        ]
      },
      {
        "avg_logprob": -0.24243846973339161,
        "compression_ratio": 1.8458498023715415,
        "end": 3478.18,
        "id": 986,
        "no_speech_prob": 0.000077221637184266,
        "seek": 346708,
        "start": 3476.94,
        "temperature": 0,
        "text": " it adds all of them to the page.",
        "tokens": [
          50857,
          309,
          10860,
          439,
          295,
          552,
          281,
          264,
          3028,
          13,
          50919
        ]
      },
      {
        "avg_logprob": -0.24243846973339161,
        "compression_ratio": 1.8458498023715415,
        "end": 3480.02,
        "id": 987,
        "no_speech_prob": 0.000077221637184266,
        "seek": 346708,
        "start": 3478.18,
        "temperature": 0,
        "text": " So that was fixed, awesome.",
        "tokens": [
          50919,
          407,
          300,
          390,
          6806,
          11,
          3476,
          13,
          51011
        ]
      },
      {
        "avg_logprob": -0.24243846973339161,
        "compression_ratio": 1.8458498023715415,
        "end": 3483.1,
        "id": 988,
        "no_speech_prob": 0.000077221637184266,
        "seek": 346708,
        "start": 3480.02,
        "temperature": 0,
        "text": " But one thing we wanna do is also hide this loading spinner",
        "tokens": [
          51011,
          583,
          472,
          551,
          321,
          1948,
          360,
          307,
          611,
          6479,
          341,
          15114,
          44849,
          51165
        ]
      },
      {
        "avg_logprob": -0.24243846973339161,
        "compression_ratio": 1.8458498023715415,
        "end": 3484.42,
        "id": 989,
        "no_speech_prob": 0.000077221637184266,
        "seek": 346708,
        "start": 3483.1,
        "temperature": 0,
        "text": " after all of the muse loads.",
        "tokens": [
          51165,
          934,
          439,
          295,
          264,
          39138,
          12668,
          13,
          51231
        ]
      },
      {
        "avg_logprob": -0.24243846973339161,
        "compression_ratio": 1.8458498023715415,
        "end": 3489.42,
        "id": 990,
        "no_speech_prob": 0.000077221637184266,
        "seek": 346708,
        "start": 3484.42,
        "temperature": 0,
        "text": " So let's just say loading element.hide.",
        "tokens": [
          51231,
          407,
          718,
          311,
          445,
          584,
          15114,
          4478,
          13,
          71,
          482,
          13,
          51481
        ]
      },
      {
        "avg_logprob": -0.24243846973339161,
        "compression_ratio": 1.8458498023715415,
        "end": 3491.7799999999997,
        "id": 991,
        "no_speech_prob": 0.000077221637184266,
        "seek": 346708,
        "start": 3489.5,
        "temperature": 0,
        "text": " So after the page loads, we get it all there.",
        "tokens": [
          51485,
          407,
          934,
          264,
          3028,
          12668,
          11,
          321,
          483,
          309,
          439,
          456,
          13,
          51599
        ]
      },
      {
        "avg_logprob": -0.24243846973339161,
        "compression_ratio": 1.8458498023715415,
        "end": 3494.6,
        "id": 992,
        "no_speech_prob": 0.000077221637184266,
        "seek": 346708,
        "start": 3492.7,
        "temperature": 0,
        "text": " I think I wanna add a little bit of styling.",
        "tokens": [
          51645,
          286,
          519,
          286,
          1948,
          909,
          257,
          707,
          857,
          295,
          27944,
          13,
          51740
        ]
      },
      {
        "avg_logprob": -0.30056089513442097,
        "compression_ratio": 1.683206106870229,
        "end": 3499.02,
        "id": 993,
        "no_speech_prob": 0.0000017603368860363844,
        "seek": 349460,
        "start": 3494.62,
        "temperature": 0,
        "text": " Let's say the muse here has a width.",
        "tokens": [
          50365,
          961,
          311,
          584,
          264,
          39138,
          510,
          575,
          257,
          11402,
          13,
          50585
        ]
      },
      {
        "avg_logprob": -0.30056089513442097,
        "compression_ratio": 1.683206106870229,
        "end": 3502.54,
        "id": 994,
        "no_speech_prob": 0.0000017603368860363844,
        "seek": 349460,
        "start": 3499.02,
        "temperature": 0,
        "text": " So in our styles, let's say muse,",
        "tokens": [
          50585,
          407,
          294,
          527,
          13273,
          11,
          718,
          311,
          584,
          39138,
          11,
          50761
        ]
      },
      {
        "avg_logprob": -0.30056089513442097,
        "compression_ratio": 1.683206106870229,
        "end": 3505.42,
        "id": 995,
        "no_speech_prob": 0.0000017603368860363844,
        "seek": 349460,
        "start": 3502.54,
        "temperature": 0,
        "text": " let's say it has a width of like 80%.",
        "tokens": [
          50761,
          718,
          311,
          584,
          309,
          575,
          257,
          11402,
          295,
          411,
          4688,
          6856,
          50905
        ]
      },
      {
        "avg_logprob": -0.30056089513442097,
        "compression_ratio": 1.683206106870229,
        "end": 3507.14,
        "id": 996,
        "no_speech_prob": 0.0000017603368860363844,
        "seek": 349460,
        "start": 3505.42,
        "temperature": 0,
        "text": " So that should shrink it in a little bit,",
        "tokens": [
          50905,
          407,
          300,
          820,
          23060,
          309,
          294,
          257,
          707,
          857,
          11,
          50991
        ]
      },
      {
        "avg_logprob": -0.30056089513442097,
        "compression_ratio": 1.683206106870229,
        "end": 3508.94,
        "id": 997,
        "no_speech_prob": 0.0000017603368860363844,
        "seek": 349460,
        "start": 3507.14,
        "temperature": 0,
        "text": " but we also wanna give it automatic margin",
        "tokens": [
          50991,
          457,
          321,
          611,
          1948,
          976,
          309,
          12509,
          10270,
          51081
        ]
      },
      {
        "avg_logprob": -0.30056089513442097,
        "compression_ratio": 1.683206106870229,
        "end": 3509.86,
        "id": 998,
        "no_speech_prob": 0.0000017603368860363844,
        "seek": 349460,
        "start": 3508.94,
        "temperature": 0,
        "text": " so it's centered.",
        "tokens": [
          51081,
          370,
          309,
          311,
          18988,
          13,
          51127
        ]
      },
      {
        "avg_logprob": -0.30056089513442097,
        "compression_ratio": 1.683206106870229,
        "end": 3513.66,
        "id": 999,
        "no_speech_prob": 0.0000017603368860363844,
        "seek": 349460,
        "start": 3512.1,
        "temperature": 0,
        "text": " There's a good question here.",
        "tokens": [
          51239,
          821,
          311,
          257,
          665,
          1168,
          510,
          13,
          51317
        ]
      },
      {
        "avg_logprob": -0.30056089513442097,
        "compression_ratio": 1.683206106870229,
        "end": 3517.12,
        "id": 1000,
        "no_speech_prob": 0.0000017603368860363844,
        "seek": 349460,
        "start": 3513.66,
        "temperature": 0,
        "text": " What's the difference between text content and inner text?",
        "tokens": [
          51317,
          708,
          311,
          264,
          2649,
          1296,
          2487,
          2701,
          293,
          7284,
          2487,
          30,
          51490
        ]
      },
      {
        "avg_logprob": -0.30056089513442097,
        "compression_ratio": 1.683206106870229,
        "end": 3520.8199999999997,
        "id": 1001,
        "no_speech_prob": 0.0000017603368860363844,
        "seek": 349460,
        "start": 3519.18,
        "temperature": 0,
        "text": " It might be the same.",
        "tokens": [
          51593,
          467,
          1062,
          312,
          264,
          912,
          13,
          51675
        ]
      },
      {
        "avg_logprob": -0.30056089513442097,
        "compression_ratio": 1.683206106870229,
        "end": 3521.66,
        "id": 1002,
        "no_speech_prob": 0.0000017603368860363844,
        "seek": 349460,
        "start": 3520.8199999999997,
        "temperature": 0,
        "text": " We can look on the internet.",
        "tokens": [
          51675,
          492,
          393,
          574,
          322,
          264,
          4705,
          13,
          51717
        ]
      },
      {
        "avg_logprob": -0.30056089513442097,
        "compression_ratio": 1.683206106870229,
        "end": 3522.58,
        "id": 1003,
        "no_speech_prob": 0.0000017603368860363844,
        "seek": 349460,
        "start": 3521.66,
        "temperature": 0,
        "text": " I don't know, that seemed like, I was like,",
        "tokens": [
          51717,
          286,
          500,
          380,
          458,
          11,
          300,
          6576,
          411,
          11,
          286,
          390,
          411,
          11,
          51763
        ]
      },
      {
        "avg_logprob": -0.30056089513442097,
        "compression_ratio": 1.683206106870229,
        "end": 3524.2599999999998,
        "id": 1004,
        "no_speech_prob": 0.0000017603368860363844,
        "seek": 349460,
        "start": 3522.58,
        "temperature": 0,
        "text": " I have no idea, that must be a good question.",
        "tokens": [
          51763,
          286,
          362,
          572,
          1558,
          11,
          300,
          1633,
          312,
          257,
          665,
          1168,
          13,
          51847
        ]
      },
      {
        "avg_logprob": -0.26652021054868347,
        "compression_ratio": 1.8131868131868132,
        "end": 3527.8,
        "id": 1005,
        "no_speech_prob": 0.00003426841431064531,
        "seek": 352426,
        "start": 3524.96,
        "temperature": 0,
        "text": " Is it inner HTML or is there actually an inner text?",
        "tokens": [
          50399,
          1119,
          309,
          7284,
          17995,
          420,
          307,
          456,
          767,
          364,
          7284,
          2487,
          30,
          50541
        ]
      },
      {
        "avg_logprob": -0.26652021054868347,
        "compression_ratio": 1.8131868131868132,
        "end": 3531.5200000000004,
        "id": 1006,
        "no_speech_prob": 0.00003426841431064531,
        "seek": 352426,
        "start": 3527.8,
        "temperature": 0,
        "text": " It might be inner HTML, but I think inner text",
        "tokens": [
          50541,
          467,
          1062,
          312,
          7284,
          17995,
          11,
          457,
          286,
          519,
          7284,
          2487,
          50727
        ]
      },
      {
        "avg_logprob": -0.26652021054868347,
        "compression_ratio": 1.8131868131868132,
        "end": 3533.2000000000003,
        "id": 1007,
        "no_speech_prob": 0.00003426841431064531,
        "seek": 352426,
        "start": 3531.5200000000004,
        "temperature": 0,
        "text": " and text content are probably synonymous.",
        "tokens": [
          50727,
          293,
          2487,
          2701,
          366,
          1391,
          5451,
          18092,
          13,
          50811
        ]
      },
      {
        "avg_logprob": -0.26652021054868347,
        "compression_ratio": 1.8131868131868132,
        "end": 3534.6000000000004,
        "id": 1008,
        "no_speech_prob": 0.00003426841431064531,
        "seek": 352426,
        "start": 3533.2000000000003,
        "temperature": 0,
        "text": " But the main difference is,",
        "tokens": [
          50811,
          583,
          264,
          2135,
          2649,
          307,
          11,
          50881
        ]
      },
      {
        "avg_logprob": -0.26652021054868347,
        "compression_ratio": 1.8131868131868132,
        "end": 3537.2000000000003,
        "id": 1009,
        "no_speech_prob": 0.00003426841431064531,
        "seek": 352426,
        "start": 3534.6000000000004,
        "temperature": 0,
        "text": " and the one thing that I'm not using is inner HTML.",
        "tokens": [
          50881,
          293,
          264,
          472,
          551,
          300,
          286,
          478,
          406,
          1228,
          307,
          7284,
          17995,
          13,
          51011
        ]
      },
      {
        "avg_logprob": -0.26652021054868347,
        "compression_ratio": 1.8131868131868132,
        "end": 3539.6800000000003,
        "id": 1010,
        "no_speech_prob": 0.00003426841431064531,
        "seek": 352426,
        "start": 3537.2000000000003,
        "temperature": 0,
        "text": " Got it, so text content is something special.",
        "tokens": [
          51011,
          5803,
          309,
          11,
          370,
          2487,
          2701,
          307,
          746,
          2121,
          13,
          51135
        ]
      },
      {
        "avg_logprob": -0.26652021054868347,
        "compression_ratio": 1.8131868131868132,
        "end": 3541.88,
        "id": 1011,
        "no_speech_prob": 0.00003426841431064531,
        "seek": 352426,
        "start": 3539.6800000000003,
        "temperature": 0,
        "text": " You're specifically using it over inner HTML.",
        "tokens": [
          51135,
          509,
          434,
          4682,
          1228,
          309,
          670,
          7284,
          17995,
          13,
          51245
        ]
      },
      {
        "avg_logprob": -0.26652021054868347,
        "compression_ratio": 1.8131868131868132,
        "end": 3545.2400000000002,
        "id": 1012,
        "no_speech_prob": 0.00003426841431064531,
        "seek": 352426,
        "start": 3541.88,
        "temperature": 0,
        "text": " Yes, and specifically because this data right here",
        "tokens": [
          51245,
          1079,
          11,
          293,
          4682,
          570,
          341,
          1412,
          558,
          510,
          51413
        ]
      },
      {
        "avg_logprob": -0.26652021054868347,
        "compression_ratio": 1.8131868131868132,
        "end": 3546.5800000000004,
        "id": 1013,
        "no_speech_prob": 0.00003426841431064531,
        "seek": 352426,
        "start": 3545.2400000000002,
        "temperature": 0,
        "text": " is coming from users, right?",
        "tokens": [
          51413,
          307,
          1348,
          490,
          5022,
          11,
          558,
          30,
          51480
        ]
      },
      {
        "avg_logprob": -0.26652021054868347,
        "compression_ratio": 1.8131868131868132,
        "end": 3548.2000000000003,
        "id": 1014,
        "no_speech_prob": 0.00003426841431064531,
        "seek": 352426,
        "start": 3546.5800000000004,
        "temperature": 0,
        "text": " So people are entering in their names,",
        "tokens": [
          51480,
          407,
          561,
          366,
          11104,
          294,
          641,
          5288,
          11,
          51561
        ]
      },
      {
        "avg_logprob": -0.26652021054868347,
        "compression_ratio": 1.8131868131868132,
        "end": 3550.1200000000003,
        "id": 1015,
        "no_speech_prob": 0.00003426841431064531,
        "seek": 352426,
        "start": 3548.2000000000003,
        "temperature": 0,
        "text": " they're entering in their muse,",
        "tokens": [
          51561,
          436,
          434,
          11104,
          294,
          641,
          39138,
          11,
          51657
        ]
      },
      {
        "avg_logprob": -0.26652021054868347,
        "compression_ratio": 1.8131868131868132,
        "end": 3553.6800000000003,
        "id": 1016,
        "no_speech_prob": 0.00003426841431064531,
        "seek": 352426,
        "start": 3550.1200000000003,
        "temperature": 0,
        "text": " and when I add it to the page,",
        "tokens": [
          51657,
          293,
          562,
          286,
          909,
          309,
          281,
          264,
          3028,
          11,
          51835
        ]
      },
      {
        "avg_logprob": -0.23935625446376516,
        "compression_ratio": 1.7672727272727273,
        "end": 3557.1,
        "id": 1017,
        "no_speech_prob": 0.00002318745646334719,
        "seek": 355368,
        "start": 3553.7,
        "temperature": 0,
        "text": " I don't wanna potentially add some script tag",
        "tokens": [
          50365,
          286,
          500,
          380,
          1948,
          7263,
          909,
          512,
          5755,
          6162,
          50535
        ]
      },
      {
        "avg_logprob": -0.23935625446376516,
        "compression_ratio": 1.7672727272727273,
        "end": 3559.58,
        "id": 1018,
        "no_speech_prob": 0.00002318745646334719,
        "seek": 355368,
        "start": 3557.1,
        "temperature": 0,
        "text": " or something that they put and typed in.",
        "tokens": [
          50535,
          420,
          746,
          300,
          436,
          829,
          293,
          33941,
          294,
          13,
          50659
        ]
      },
      {
        "avg_logprob": -0.23935625446376516,
        "compression_ratio": 1.7672727272727273,
        "end": 3563.22,
        "id": 1019,
        "no_speech_prob": 0.00002318745646334719,
        "seek": 355368,
        "start": 3559.58,
        "temperature": 0,
        "text": " So if you use inner HTML, whatever you set as inner HTML",
        "tokens": [
          50659,
          407,
          498,
          291,
          764,
          7284,
          17995,
          11,
          2035,
          291,
          992,
          382,
          7284,
          17995,
          50841
        ]
      },
      {
        "avg_logprob": -0.23935625446376516,
        "compression_ratio": 1.7672727272727273,
        "end": 3565.2999999999997,
        "id": 1020,
        "no_speech_prob": 0.00002318745646334719,
        "seek": 355368,
        "start": 3563.22,
        "temperature": 0,
        "text": " will actually get rendered on the page.",
        "tokens": [
          50841,
          486,
          767,
          483,
          28748,
          322,
          264,
          3028,
          13,
          50945
        ]
      },
      {
        "avg_logprob": -0.23935625446376516,
        "compression_ratio": 1.7672727272727273,
        "end": 3568.58,
        "id": 1021,
        "no_speech_prob": 0.00002318745646334719,
        "seek": 355368,
        "start": 3565.2999999999997,
        "temperature": 0,
        "text": " By using text content, even if they typed in",
        "tokens": [
          50945,
          3146,
          1228,
          2487,
          2701,
          11,
          754,
          498,
          436,
          33941,
          294,
          51109
        ]
      },
      {
        "avg_logprob": -0.23935625446376516,
        "compression_ratio": 1.7672727272727273,
        "end": 3571.4199999999996,
        "id": 1022,
        "no_speech_prob": 0.00002318745646334719,
        "seek": 355368,
        "start": 3568.58,
        "temperature": 0,
        "text": " some valid HTML, you'll just see the HTML text.",
        "tokens": [
          51109,
          512,
          7363,
          17995,
          11,
          291,
          603,
          445,
          536,
          264,
          17995,
          2487,
          13,
          51251
        ]
      },
      {
        "avg_logprob": -0.23935625446376516,
        "compression_ratio": 1.7672727272727273,
        "end": 3572.3799999999997,
        "id": 1023,
        "no_speech_prob": 0.00002318745646334719,
        "seek": 355368,
        "start": 3571.4199999999996,
        "temperature": 0,
        "text": " It won't actually render.",
        "tokens": [
          51251,
          467,
          1582,
          380,
          767,
          15529,
          13,
          51299
        ]
      },
      {
        "avg_logprob": -0.23935625446376516,
        "compression_ratio": 1.7672727272727273,
        "end": 3575.2599999999998,
        "id": 1024,
        "no_speech_prob": 0.00002318745646334719,
        "seek": 355368,
        "start": 3572.3799999999997,
        "temperature": 0,
        "text": " So this is a security precaution to prevent",
        "tokens": [
          51299,
          407,
          341,
          307,
          257,
          3825,
          25651,
          1448,
          281,
          4871,
          51443
        ]
      },
      {
        "avg_logprob": -0.23935625446376516,
        "compression_ratio": 1.7672727272727273,
        "end": 3577.58,
        "id": 1025,
        "no_speech_prob": 0.00002318745646334719,
        "seek": 355368,
        "start": 3575.2599999999998,
        "temperature": 0,
        "text": " what's known as cross-site scripting.",
        "tokens": [
          51443,
          437,
          311,
          2570,
          382,
          3278,
          12,
          30417,
          5755,
          278,
          13,
          51559
        ]
      },
      {
        "avg_logprob": -0.23935625446376516,
        "compression_ratio": 1.7672727272727273,
        "end": 3578.74,
        "id": 1026,
        "no_speech_prob": 0.00002318745646334719,
        "seek": 355368,
        "start": 3577.58,
        "temperature": 0,
        "text": " But then there is, yes, so there's a difference",
        "tokens": [
          51559,
          583,
          550,
          456,
          307,
          11,
          2086,
          11,
          370,
          456,
          311,
          257,
          2649,
          51617
        ]
      },
      {
        "avg_logprob": -0.23935625446376516,
        "compression_ratio": 1.7672727272727273,
        "end": 3582.62,
        "id": 1027,
        "no_speech_prob": 0.00002318745646334719,
        "seek": 355368,
        "start": 3578.74,
        "temperature": 0,
        "text": " between text content, inner HTML, there's outer HTML.",
        "tokens": [
          51617,
          1296,
          2487,
          2701,
          11,
          7284,
          17995,
          11,
          456,
          311,
          10847,
          17995,
          13,
          51811
        ]
      },
      {
        "avg_logprob": -0.2966244437477805,
        "compression_ratio": 1.6245353159851301,
        "end": 3584.48,
        "id": 1028,
        "no_speech_prob": 0.000010289497367921285,
        "seek": 358262,
        "start": 3582.62,
        "temperature": 0,
        "text": " Inner HTML and outer HTML are the same.",
        "tokens": [
          50364,
          36705,
          17995,
          293,
          10847,
          17995,
          366,
          264,
          912,
          13,
          50457
        ]
      },
      {
        "avg_logprob": -0.2966244437477805,
        "compression_ratio": 1.6245353159851301,
        "end": 3586.72,
        "id": 1029,
        "no_speech_prob": 0.000010289497367921285,
        "seek": 358262,
        "start": 3584.48,
        "temperature": 0,
        "text": " Whatever you set it to will get rendered.",
        "tokens": [
          50457,
          8541,
          291,
          992,
          309,
          281,
          486,
          483,
          28748,
          13,
          50569
        ]
      },
      {
        "avg_logprob": -0.2966244437477805,
        "compression_ratio": 1.6245353159851301,
        "end": 3589.02,
        "id": 1030,
        "no_speech_prob": 0.000010289497367921285,
        "seek": 358262,
        "start": 3586.72,
        "temperature": 0,
        "text": " Text content and then inner text",
        "tokens": [
          50569,
          18643,
          2701,
          293,
          550,
          7284,
          2487,
          50684
        ]
      },
      {
        "avg_logprob": -0.2966244437477805,
        "compression_ratio": 1.6245353159851301,
        "end": 3590.44,
        "id": 1031,
        "no_speech_prob": 0.000010289497367921285,
        "seek": 358262,
        "start": 3589.02,
        "temperature": 0,
        "text": " probably have the same relationship.",
        "tokens": [
          50684,
          1391,
          362,
          264,
          912,
          2480,
          13,
          50755
        ]
      },
      {
        "avg_logprob": -0.2966244437477805,
        "compression_ratio": 1.6245353159851301,
        "end": 3593.18,
        "id": 1032,
        "no_speech_prob": 0.000010289497367921285,
        "seek": 358262,
        "start": 3590.44,
        "temperature": 0,
        "text": " I haven't really used inner text before.",
        "tokens": [
          50755,
          286,
          2378,
          380,
          534,
          1143,
          7284,
          2487,
          949,
          13,
          50892
        ]
      },
      {
        "avg_logprob": -0.2966244437477805,
        "compression_ratio": 1.6245353159851301,
        "end": 3594.96,
        "id": 1033,
        "no_speech_prob": 0.000010289497367921285,
        "seek": 358262,
        "start": 3593.18,
        "temperature": 0,
        "text": " Cool, but yeah, that was a good question.",
        "tokens": [
          50892,
          8561,
          11,
          457,
          1338,
          11,
          300,
          390,
          257,
          665,
          1168,
          13,
          50981
        ]
      },
      {
        "avg_logprob": -0.2966244437477805,
        "compression_ratio": 1.6245353159851301,
        "end": 3597.3199999999997,
        "id": 1034,
        "no_speech_prob": 0.000010289497367921285,
        "seek": 358262,
        "start": 3595.96,
        "temperature": 0,
        "text": " Oh wait, last thing, I'm not showing the date.",
        "tokens": [
          51031,
          876,
          1699,
          11,
          1036,
          551,
          11,
          286,
          478,
          406,
          4099,
          264,
          4002,
          13,
          51099
        ]
      },
      {
        "avg_logprob": -0.2966244437477805,
        "compression_ratio": 1.6245353159851301,
        "end": 3598.6,
        "id": 1035,
        "no_speech_prob": 0.000010289497367921285,
        "seek": 358262,
        "start": 3597.3199999999997,
        "temperature": 0,
        "text": " So let's also show the date.",
        "tokens": [
          51099,
          407,
          718,
          311,
          611,
          855,
          264,
          4002,
          13,
          51163
        ]
      },
      {
        "avg_logprob": -0.2966244437477805,
        "compression_ratio": 1.6245353159851301,
        "end": 3601.8399999999997,
        "id": 1036,
        "no_speech_prob": 0.000010289497367921285,
        "seek": 358262,
        "start": 3598.6,
        "temperature": 0,
        "text": " So let's create a date, and we'll say",
        "tokens": [
          51163,
          407,
          718,
          311,
          1884,
          257,
          4002,
          11,
          293,
          321,
          603,
          584,
          51325
        ]
      },
      {
        "avg_logprob": -0.2966244437477805,
        "compression_ratio": 1.6245353159851301,
        "end": 3603.8399999999997,
        "id": 1037,
        "no_speech_prob": 0.000010289497367921285,
        "seek": 358262,
        "start": 3601.8399999999997,
        "temperature": 0,
        "text": " document.createElementPhoto.",
        "tokens": [
          51325,
          4166,
          13,
          14066,
          473,
          36,
          3054,
          24382,
          6738,
          13,
          51425
        ]
      },
      {
        "avg_logprob": -0.2966244437477805,
        "compression_ratio": 1.6245353159851301,
        "end": 3608.2799999999997,
        "id": 1038,
        "no_speech_prob": 0.000010289497367921285,
        "seek": 358262,
        "start": 3606.88,
        "temperature": 0,
        "text": " Hold on, that's my job.",
        "tokens": [
          51577,
          6962,
          322,
          11,
          300,
          311,
          452,
          1691,
          13,
          51647
        ]
      },
      {
        "avg_logprob": -0.2966244437477805,
        "compression_ratio": 1.6245353159851301,
        "end": 3610.18,
        "id": 1039,
        "no_speech_prob": 0.000010289497367921285,
        "seek": 358262,
        "start": 3608.2799999999997,
        "temperature": 0,
        "text": " This is like my very important job.",
        "tokens": [
          51647,
          639,
          307,
          411,
          452,
          588,
          1021,
          1691,
          13,
          51742
        ]
      },
      {
        "avg_logprob": -0.39111495740485913,
        "compression_ratio": 1.6378600823045268,
        "end": 3614.48,
        "id": 1040,
        "no_speech_prob": 0.00006709114677505568,
        "seek": 361262,
        "start": 3612.72,
        "temperature": 0,
        "text": " You're good, you can force a little break.",
        "tokens": [
          50369,
          509,
          434,
          665,
          11,
          291,
          393,
          3464,
          257,
          707,
          1821,
          13,
          50457
        ]
      },
      {
        "avg_logprob": -0.39111495740485913,
        "compression_ratio": 1.6378600823045268,
        "end": 3616,
        "id": 1041,
        "no_speech_prob": 0.00006709114677505568,
        "seek": 361262,
        "start": 3614.48,
        "temperature": 0,
        "text": " I'll stay hydrated.",
        "tokens": [
          50457,
          286,
          603,
          1754,
          44960,
          13,
          50533
        ]
      },
      {
        "avg_logprob": -0.39111495740485913,
        "compression_ratio": 1.6378600823045268,
        "end": 3617.04,
        "id": 1042,
        "no_speech_prob": 0.00006709114677505568,
        "seek": 361262,
        "start": 3616,
        "temperature": 0,
        "text": " Yes, all right.",
        "tokens": [
          50533,
          1079,
          11,
          439,
          558,
          13,
          50585
        ]
      },
      {
        "avg_logprob": -0.39111495740485913,
        "compression_ratio": 1.6378600823045268,
        "end": 3620.2799999999997,
        "id": 1043,
        "no_speech_prob": 0.00006709114677505568,
        "seek": 361262,
        "start": 3617.04,
        "temperature": 0,
        "text": " Okay, so the last thing is I'll create a small tag,",
        "tokens": [
          50585,
          1033,
          11,
          370,
          264,
          1036,
          551,
          307,
          286,
          603,
          1884,
          257,
          1359,
          6162,
          11,
          50747
        ]
      },
      {
        "avg_logprob": -0.39111495740485913,
        "compression_ratio": 1.6378600823045268,
        "end": 3623.6,
        "id": 1044,
        "no_speech_prob": 0.00006709114677505568,
        "seek": 361262,
        "start": 3620.2799999999997,
        "temperature": 0,
        "text": " and then we will append it here.",
        "tokens": [
          50747,
          293,
          550,
          321,
          486,
          34116,
          309,
          510,
          13,
          50913
        ]
      },
      {
        "avg_logprob": -0.39111495740485913,
        "compression_ratio": 1.6378600823045268,
        "end": 3625,
        "id": 1045,
        "no_speech_prob": 0.00006709114677505568,
        "seek": 361262,
        "start": 3623.6,
        "temperature": 0,
        "text": " So div.",
        "tokens": [
          50913,
          407,
          3414,
          13,
          50983
        ]
      },
      {
        "avg_logprob": -0.39111495740485913,
        "compression_ratio": 1.6378600823045268,
        "end": 3626.6,
        "id": 1046,
        "no_speech_prob": 0.00006709114677505568,
        "seek": 361262,
        "start": 3625,
        "temperature": 0,
        "text": " Oh, sorry, we need to set the text content.",
        "tokens": [
          50983,
          876,
          11,
          2597,
          11,
          321,
          643,
          281,
          992,
          264,
          2487,
          2701,
          13,
          51063
        ]
      },
      {
        "avg_logprob": -0.39111495740485913,
        "compression_ratio": 1.6378600823045268,
        "end": 3631.6,
        "id": 1047,
        "no_speech_prob": 0.00006709114677505568,
        "seek": 361262,
        "start": 3626.6,
        "temperature": 0,
        "text": " So I'll say date.textContent is equal to mu.created.",
        "tokens": [
          51063,
          407,
          286,
          603,
          584,
          4002,
          13,
          25111,
          29821,
          317,
          307,
          2681,
          281,
          2992,
          13,
          66,
          26559,
          13,
          51313
        ]
      },
      {
        "avg_logprob": -0.39111495740485913,
        "compression_ratio": 1.6378600823045268,
        "end": 3634.4,
        "id": 1048,
        "no_speech_prob": 0.00006709114677505568,
        "seek": 361262,
        "start": 3632.6,
        "temperature": 0,
        "text": " And actually, I'll pass this into a new date,",
        "tokens": [
          51363,
          400,
          767,
          11,
          286,
          603,
          1320,
          341,
          666,
          257,
          777,
          4002,
          11,
          51453
        ]
      },
      {
        "avg_logprob": -0.39111495740485913,
        "compression_ratio": 1.6378600823045268,
        "end": 3636.56,
        "id": 1049,
        "no_speech_prob": 0.00006709114677505568,
        "seek": 361262,
        "start": 3634.4,
        "temperature": 0,
        "text": " so it should give it some decent formatting.",
        "tokens": [
          51453,
          370,
          309,
          820,
          976,
          309,
          512,
          8681,
          39366,
          13,
          51561
        ]
      },
      {
        "avg_logprob": -0.39111495740485913,
        "compression_ratio": 1.6378600823045268,
        "end": 3641.7999999999997,
        "id": 1050,
        "no_speech_prob": 0.00006709114677505568,
        "seek": 361262,
        "start": 3637.92,
        "temperature": 0,
        "text": " And then we'll append the, oh, oh, oh.",
        "tokens": [
          51629,
          400,
          550,
          321,
          603,
          34116,
          264,
          11,
          1954,
          11,
          1954,
          11,
          1954,
          13,
          51823
        ]
      },
      {
        "avg_logprob": -0.24343181156611943,
        "compression_ratio": 1.7038327526132404,
        "end": 3645.24,
        "id": 1051,
        "no_speech_prob": 0.00005064459764980711,
        "seek": 364262,
        "start": 3643.24,
        "temperature": 0,
        "text": " Alka writes, by the way, one difference is",
        "tokens": [
          50395,
          967,
          2330,
          13657,
          11,
          538,
          264,
          636,
          11,
          472,
          2649,
          307,
          50495
        ]
      },
      {
        "avg_logprob": -0.24343181156611943,
        "compression_ratio": 1.7038327526132404,
        "end": 3648.74,
        "id": 1052,
        "no_speech_prob": 0.00005064459764980711,
        "seek": 364262,
        "start": 3645.24,
        "temperature": 0,
        "text": " inner text returns the visible text contained in the node,",
        "tokens": [
          50495,
          7284,
          2487,
          11247,
          264,
          8974,
          2487,
          16212,
          294,
          264,
          9984,
          11,
          50670
        ]
      },
      {
        "avg_logprob": -0.24343181156611943,
        "compression_ratio": 1.7038327526132404,
        "end": 3651.04,
        "id": 1053,
        "no_speech_prob": 0.00005064459764980711,
        "seek": 364262,
        "start": 3648.74,
        "temperature": 0,
        "text": " while text content returns the full text.",
        "tokens": [
          50670,
          1339,
          2487,
          2701,
          11247,
          264,
          1577,
          2487,
          13,
          50785
        ]
      },
      {
        "avg_logprob": -0.24343181156611943,
        "compression_ratio": 1.7038327526132404,
        "end": 3651.88,
        "id": 1054,
        "no_speech_prob": 0.00005064459764980711,
        "seek": 364262,
        "start": 3651.04,
        "temperature": 0,
        "text": " Oh, okay.",
        "tokens": [
          50785,
          876,
          11,
          1392,
          13,
          50827
        ]
      },
      {
        "avg_logprob": -0.24343181156611943,
        "compression_ratio": 1.7038327526132404,
        "end": 3654.16,
        "id": 1055,
        "no_speech_prob": 0.00005064459764980711,
        "seek": 364262,
        "start": 3652.72,
        "temperature": 0,
        "text": " Cool.",
        "tokens": [
          50869,
          8561,
          13,
          50941
        ]
      },
      {
        "avg_logprob": -0.24343181156611943,
        "compression_ratio": 1.7038327526132404,
        "end": 3655.2,
        "id": 1056,
        "no_speech_prob": 0.00005064459764980711,
        "seek": 364262,
        "start": 3654.16,
        "temperature": 0,
        "text": " And now we're showing some dates.",
        "tokens": [
          50941,
          400,
          586,
          321,
          434,
          4099,
          512,
          11691,
          13,
          50993
        ]
      },
      {
        "avg_logprob": -0.24343181156611943,
        "compression_ratio": 1.7038327526132404,
        "end": 3657.3399999999997,
        "id": 1057,
        "no_speech_prob": 0.00005064459764980711,
        "seek": 364262,
        "start": 3655.2,
        "temperature": 0,
        "text": " So apparently, when I first started inserting,",
        "tokens": [
          50993,
          407,
          7970,
          11,
          562,
          286,
          700,
          1409,
          46567,
          11,
          51100
        ]
      },
      {
        "avg_logprob": -0.24343181156611943,
        "compression_ratio": 1.7038327526132404,
        "end": 3659.4,
        "id": 1058,
        "no_speech_prob": 0.00005064459764980711,
        "seek": 364262,
        "start": 3657.3399999999997,
        "temperature": 0,
        "text": " I wasn't actually adding the date.",
        "tokens": [
          51100,
          286,
          2067,
          380,
          767,
          5127,
          264,
          4002,
          13,
          51203
        ]
      },
      {
        "avg_logprob": -0.24343181156611943,
        "compression_ratio": 1.7038327526132404,
        "end": 3663.24,
        "id": 1059,
        "no_speech_prob": 0.00005064459764980711,
        "seek": 364262,
        "start": 3659.4,
        "temperature": 0,
        "text": " But on these later ones, I am.",
        "tokens": [
          51203,
          583,
          322,
          613,
          1780,
          2306,
          11,
          286,
          669,
          13,
          51395
        ]
      },
      {
        "avg_logprob": -0.24343181156611943,
        "compression_ratio": 1.7038327526132404,
        "end": 3664.88,
        "id": 1060,
        "no_speech_prob": 0.00005064459764980711,
        "seek": 364262,
        "start": 3663.24,
        "temperature": 0,
        "text": " But one thing I wanna do is I wanna show these",
        "tokens": [
          51395,
          583,
          472,
          551,
          286,
          1948,
          360,
          307,
          286,
          1948,
          855,
          613,
          51477
        ]
      },
      {
        "avg_logprob": -0.24343181156611943,
        "compression_ratio": 1.7038327526132404,
        "end": 3667.4,
        "id": 1061,
        "no_speech_prob": 0.00005064459764980711,
        "seek": 364262,
        "start": 3664.88,
        "temperature": 0,
        "text": " in reverse order, because the more recent ones",
        "tokens": [
          51477,
          294,
          9943,
          1668,
          11,
          570,
          264,
          544,
          5162,
          2306,
          51603
        ]
      },
      {
        "avg_logprob": -0.24343181156611943,
        "compression_ratio": 1.7038327526132404,
        "end": 3668.2799999999997,
        "id": 1062,
        "no_speech_prob": 0.00005064459764980711,
        "seek": 364262,
        "start": 3667.4,
        "temperature": 0,
        "text": " will appear at the top.",
        "tokens": [
          51603,
          486,
          4204,
          412,
          264,
          1192,
          13,
          51647
        ]
      },
      {
        "avg_logprob": -0.24343181156611943,
        "compression_ratio": 1.7038327526132404,
        "end": 3669.56,
        "id": 1063,
        "no_speech_prob": 0.00005064459764980711,
        "seek": 364262,
        "start": 3668.2799999999997,
        "temperature": 0,
        "text": " So all we have to do for that is",
        "tokens": [
          51647,
          407,
          439,
          321,
          362,
          281,
          360,
          337,
          300,
          307,
          51711
        ]
      },
      {
        "avg_logprob": -0.24343181156611943,
        "compression_ratio": 1.7038327526132404,
        "end": 3671.12,
        "id": 1064,
        "no_speech_prob": 0.00005064459764980711,
        "seek": 364262,
        "start": 3669.56,
        "temperature": 0,
        "text": " before we add them to the page,",
        "tokens": [
          51711,
          949,
          321,
          909,
          552,
          281,
          264,
          3028,
          11,
          51789
        ]
      },
      {
        "avg_logprob": -0.3194234275817871,
        "compression_ratio": 1.5482233502538072,
        "end": 3674.2599999999998,
        "id": 1065,
        "no_speech_prob": 0.000022125581381260417,
        "seek": 367112,
        "start": 3671.12,
        "temperature": 0,
        "text": " I'm just going to say mus.reverse.",
        "tokens": [
          50364,
          286,
          478,
          445,
          516,
          281,
          584,
          1038,
          13,
          265,
          4308,
          13,
          50521
        ]
      },
      {
        "avg_logprob": -0.3194234275817871,
        "compression_ratio": 1.5482233502538072,
        "end": 3677.2599999999998,
        "id": 1066,
        "no_speech_prob": 0.000022125581381260417,
        "seek": 367112,
        "start": 3675.2999999999997,
        "temperature": 0,
        "text": " And I guess the other thing is,",
        "tokens": [
          50573,
          400,
          286,
          2041,
          264,
          661,
          551,
          307,
          11,
          50671
        ]
      },
      {
        "avg_logprob": -0.3194234275817871,
        "compression_ratio": 1.5482233502538072,
        "end": 3681.66,
        "id": 1067,
        "no_speech_prob": 0.000022125581381260417,
        "seek": 367112,
        "start": 3678.7999999999997,
        "temperature": 0,
        "text": " reverse, reverse is not a function.",
        "tokens": [
          50748,
          9943,
          11,
          9943,
          307,
          406,
          257,
          2445,
          13,
          50891
        ]
      },
      {
        "avg_logprob": -0.3194234275817871,
        "compression_ratio": 1.5482233502538072,
        "end": 3682.5,
        "id": 1068,
        "no_speech_prob": 0.000022125581381260417,
        "seek": 367112,
        "start": 3681.66,
        "temperature": 0,
        "text": " Cool.",
        "tokens": [
          50891,
          8561,
          13,
          50933
        ]
      },
      {
        "avg_logprob": -0.3194234275817871,
        "compression_ratio": 1.5482233502538072,
        "end": 3685.98,
        "id": 1069,
        "no_speech_prob": 0.000022125581381260417,
        "seek": 367112,
        "start": 3682.5,
        "temperature": 0,
        "text": " And so the latest mus should show up at the top.",
        "tokens": [
          50933,
          400,
          370,
          264,
          6792,
          1038,
          820,
          855,
          493,
          412,
          264,
          1192,
          13,
          51107
        ]
      },
      {
        "avg_logprob": -0.3194234275817871,
        "compression_ratio": 1.5482233502538072,
        "end": 3689.8599999999997,
        "id": 1070,
        "no_speech_prob": 0.000022125581381260417,
        "seek": 367112,
        "start": 3687.96,
        "temperature": 0,
        "text": " Name, CJ.",
        "tokens": [
          51206,
          13866,
          11,
          42285,
          13,
          51301
        ]
      },
      {
        "avg_logprob": -0.3194234275817871,
        "compression_ratio": 1.5482233502538072,
        "end": 3690.7,
        "id": 1071,
        "no_speech_prob": 0.000022125581381260417,
        "seek": 367112,
        "start": 3689.8599999999997,
        "temperature": 0,
        "text": " Hello.",
        "tokens": [
          51301,
          2425,
          13,
          51343
        ]
      },
      {
        "avg_logprob": -0.3194234275817871,
        "compression_ratio": 1.5482233502538072,
        "end": 3694.66,
        "id": 1072,
        "no_speech_prob": 0.000022125581381260417,
        "seek": 367112,
        "start": 3692.08,
        "temperature": 0,
        "text": " But now, one thing I wanna do is,",
        "tokens": [
          51412,
          583,
          586,
          11,
          472,
          551,
          286,
          1948,
          360,
          307,
          11,
          51541
        ]
      },
      {
        "avg_logprob": -0.3194234275817871,
        "compression_ratio": 1.5482233502538072,
        "end": 3697.2799999999997,
        "id": 1073,
        "no_speech_prob": 0.000022125581381260417,
        "seek": 367112,
        "start": 3694.66,
        "temperature": 0,
        "text": " after I submit the form, just get all of them again,",
        "tokens": [
          51541,
          934,
          286,
          10315,
          264,
          1254,
          11,
          445,
          483,
          439,
          295,
          552,
          797,
          11,
          51672
        ]
      },
      {
        "avg_logprob": -0.3194234275817871,
        "compression_ratio": 1.5482233502538072,
        "end": 3699.3399999999997,
        "id": 1074,
        "no_speech_prob": 0.000022125581381260417,
        "seek": 367112,
        "start": 3697.2799999999997,
        "temperature": 0,
        "text": " so that after you've immediately submitted,",
        "tokens": [
          51672,
          370,
          300,
          934,
          291,
          600,
          4258,
          14405,
          11,
          51775
        ]
      },
      {
        "avg_logprob": -0.23221839852884513,
        "compression_ratio": 1.6950354609929077,
        "end": 3701.2400000000002,
        "id": 1075,
        "no_speech_prob": 0.00002212560866610147,
        "seek": 369934,
        "start": 3699.34,
        "temperature": 0,
        "text": " it is added to the top of the page.",
        "tokens": [
          50364,
          309,
          307,
          3869,
          281,
          264,
          1192,
          295,
          264,
          3028,
          13,
          50459
        ]
      },
      {
        "avg_logprob": -0.23221839852884513,
        "compression_ratio": 1.6950354609929077,
        "end": 3704.56,
        "id": 1076,
        "no_speech_prob": 0.00002212560866610147,
        "seek": 369934,
        "start": 3701.2400000000002,
        "temperature": 0,
        "text": " So getting a little sidetracked here.",
        "tokens": [
          50459,
          407,
          1242,
          257,
          707,
          20822,
          27965,
          25949,
          510,
          13,
          50625
        ]
      },
      {
        "avg_logprob": -0.23221839852884513,
        "compression_ratio": 1.6950354609929077,
        "end": 3706,
        "id": 1077,
        "no_speech_prob": 0.00002212560866610147,
        "seek": 369934,
        "start": 3704.56,
        "temperature": 0,
        "text": " Okay, we got all the mus.",
        "tokens": [
          50625,
          1033,
          11,
          321,
          658,
          439,
          264,
          1038,
          13,
          50697
        ]
      },
      {
        "avg_logprob": -0.23221839852884513,
        "compression_ratio": 1.6950354609929077,
        "end": 3707.32,
        "id": 1078,
        "no_speech_prob": 0.00002212560866610147,
        "seek": 369934,
        "start": 3706,
        "temperature": 0,
        "text": " We iterate over the array.",
        "tokens": [
          50697,
          492,
          44497,
          670,
          264,
          10225,
          13,
          50763
        ]
      },
      {
        "avg_logprob": -0.23221839852884513,
        "compression_ratio": 1.6950354609929077,
        "end": 3708.42,
        "id": 1079,
        "no_speech_prob": 0.00002212560866610147,
        "seek": 369934,
        "start": 3707.32,
        "temperature": 0,
        "text": " We appended them to the page.",
        "tokens": [
          50763,
          492,
          724,
          3502,
          552,
          281,
          264,
          3028,
          13,
          50818
        ]
      },
      {
        "avg_logprob": -0.23221839852884513,
        "compression_ratio": 1.6950354609929077,
        "end": 3710.2000000000003,
        "id": 1080,
        "no_speech_prob": 0.00002212560866610147,
        "seek": 369934,
        "start": 3708.42,
        "temperature": 0,
        "text": " We reversed them.",
        "tokens": [
          50818,
          492,
          30563,
          552,
          13,
          50907
        ]
      },
      {
        "avg_logprob": -0.23221839852884513,
        "compression_ratio": 1.6950354609929077,
        "end": 3712.04,
        "id": 1081,
        "no_speech_prob": 0.00002212560866610147,
        "seek": 369934,
        "start": 3710.2000000000003,
        "temperature": 0,
        "text": " Now we are showing the form.",
        "tokens": [
          50907,
          823,
          321,
          366,
          4099,
          264,
          1254,
          13,
          50999
        ]
      },
      {
        "avg_logprob": -0.23221839852884513,
        "compression_ratio": 1.6950354609929077,
        "end": 3713.56,
        "id": 1082,
        "no_speech_prob": 0.00002212560866610147,
        "seek": 369934,
        "start": 3712.04,
        "temperature": 0,
        "text": " We're hiding the loading spinner.",
        "tokens": [
          50999,
          492,
          434,
          10596,
          264,
          15114,
          44849,
          13,
          51075
        ]
      },
      {
        "avg_logprob": -0.23221839852884513,
        "compression_ratio": 1.6950354609929077,
        "end": 3715.8,
        "id": 1083,
        "no_speech_prob": 0.00002212560866610147,
        "seek": 369934,
        "start": 3713.56,
        "temperature": 0,
        "text": " Last thing is, after you create a mus,",
        "tokens": [
          51075,
          5264,
          551,
          307,
          11,
          934,
          291,
          1884,
          257,
          1038,
          11,
          51187
        ]
      },
      {
        "avg_logprob": -0.23221839852884513,
        "compression_ratio": 1.6950354609929077,
        "end": 3717.04,
        "id": 1084,
        "no_speech_prob": 0.00002212560866610147,
        "seek": 369934,
        "start": 3715.8,
        "temperature": 0,
        "text": " I wanna refresh that list,",
        "tokens": [
          51187,
          286,
          1948,
          15134,
          300,
          1329,
          11,
          51249
        ]
      },
      {
        "avg_logprob": -0.23221839852884513,
        "compression_ratio": 1.6950354609929077,
        "end": 3719.1600000000003,
        "id": 1085,
        "no_speech_prob": 0.00002212560866610147,
        "seek": 369934,
        "start": 3717.04,
        "temperature": 0,
        "text": " so that it actually pops up in the page.",
        "tokens": [
          51249,
          370,
          300,
          309,
          767,
          16795,
          493,
          294,
          264,
          3028,
          13,
          51355
        ]
      },
      {
        "avg_logprob": -0.23221839852884513,
        "compression_ratio": 1.6950354609929077,
        "end": 3721,
        "id": 1086,
        "no_speech_prob": 0.00002212560866610147,
        "seek": 369934,
        "start": 3720.08,
        "temperature": 0,
        "text": " And that should be easy,",
        "tokens": [
          51401,
          400,
          300,
          820,
          312,
          1858,
          11,
          51447
        ]
      },
      {
        "avg_logprob": -0.23221839852884513,
        "compression_ratio": 1.6950354609929077,
        "end": 3723.6000000000004,
        "id": 1087,
        "no_speech_prob": 0.00002212560866610147,
        "seek": 369934,
        "start": 3721,
        "temperature": 0,
        "text": " because we have this function, listAllMus.",
        "tokens": [
          51447,
          570,
          321,
          362,
          341,
          2445,
          11,
          1329,
          7868,
          22088,
          13,
          51577
        ]
      },
      {
        "avg_logprob": -0.23221839852884513,
        "compression_ratio": 1.6950354609929077,
        "end": 3726.1600000000003,
        "id": 1088,
        "no_speech_prob": 0.00002212560866610147,
        "seek": 369934,
        "start": 3723.6000000000004,
        "temperature": 0,
        "text": " And so after submitting,",
        "tokens": [
          51577,
          400,
          370,
          934,
          31836,
          11,
          51705
        ]
      },
      {
        "avg_logprob": -0.23221839852884513,
        "compression_ratio": 1.6950354609929077,
        "end": 3727.6400000000003,
        "id": 1089,
        "no_speech_prob": 0.00002212560866610147,
        "seek": 369934,
        "start": 3726.1600000000003,
        "temperature": 0,
        "text": " so this is the submitting to the server.",
        "tokens": [
          51705,
          370,
          341,
          307,
          264,
          31836,
          281,
          264,
          7154,
          13,
          51779
        ]
      },
      {
        "avg_logprob": -0.279613619265349,
        "compression_ratio": 1.4352941176470588,
        "end": 3730.58,
        "id": 1090,
        "no_speech_prob": 0.000041335337300552055,
        "seek": 372764,
        "start": 3727.66,
        "temperature": 0,
        "text": " After submitting, we'll reset the form.",
        "tokens": [
          50365,
          2381,
          31836,
          11,
          321,
          603,
          14322,
          264,
          1254,
          13,
          50511
        ]
      },
      {
        "avg_logprob": -0.279613619265349,
        "compression_ratio": 1.4352941176470588,
        "end": 3732.3399999999997,
        "id": 1091,
        "no_speech_prob": 0.000041335337300552055,
        "seek": 372764,
        "start": 3730.58,
        "temperature": 0,
        "text": " We'll show the form.",
        "tokens": [
          50511,
          492,
          603,
          855,
          264,
          1254,
          13,
          50599
        ]
      },
      {
        "avg_logprob": -0.279613619265349,
        "compression_ratio": 1.4352941176470588,
        "end": 3735.8399999999997,
        "id": 1092,
        "no_speech_prob": 0.000041335337300552055,
        "seek": 372764,
        "start": 3732.3399999999997,
        "temperature": 0,
        "text": " And then we'll list all mus.",
        "tokens": [
          50599,
          400,
          550,
          321,
          603,
          1329,
          439,
          1038,
          13,
          50774
        ]
      },
      {
        "avg_logprob": -0.279613619265349,
        "compression_ratio": 1.4352941176470588,
        "end": 3739.1,
        "id": 1093,
        "no_speech_prob": 0.000041335337300552055,
        "seek": 372764,
        "start": 3737.58,
        "temperature": 0,
        "text": " Like this, okay.",
        "tokens": [
          50861,
          1743,
          341,
          11,
          1392,
          13,
          50937
        ]
      },
      {
        "avg_logprob": -0.279613619265349,
        "compression_ratio": 1.4352941176470588,
        "end": 3741.06,
        "id": 1094,
        "no_speech_prob": 0.000041335337300552055,
        "seek": 372764,
        "start": 3739.1,
        "temperature": 0,
        "text": " So, name is CJ.",
        "tokens": [
          50937,
          407,
          11,
          1315,
          307,
          42285,
          13,
          51035
        ]
      },
      {
        "avg_logprob": -0.279613619265349,
        "compression_ratio": 1.4352941176470588,
        "end": 3742.9,
        "id": 1095,
        "no_speech_prob": 0.000041335337300552055,
        "seek": 372764,
        "start": 3741.06,
        "temperature": 0,
        "text": " Hello again again?",
        "tokens": [
          51035,
          2425,
          797,
          797,
          30,
          51127
        ]
      },
      {
        "avg_logprob": -0.279613619265349,
        "compression_ratio": 1.4352941176470588,
        "end": 3743.74,
        "id": 1096,
        "no_speech_prob": 0.000041335337300552055,
        "seek": 372764,
        "start": 3742.9,
        "temperature": 0,
        "text": " Again.",
        "tokens": [
          51127,
          3764,
          13,
          51169
        ]
      },
      {
        "avg_logprob": -0.279613619265349,
        "compression_ratio": 1.4352941176470588,
        "end": 3746.3799999999997,
        "id": 1097,
        "no_speech_prob": 0.000041335337300552055,
        "seek": 372764,
        "start": 3745.2999999999997,
        "temperature": 0,
        "text": " Like a cat.",
        "tokens": [
          51247,
          1743,
          257,
          3857,
          13,
          51301
        ]
      },
      {
        "avg_logprob": -0.279613619265349,
        "compression_ratio": 1.4352941176470588,
        "end": 3747.58,
        "id": 1098,
        "no_speech_prob": 0.000041335337300552055,
        "seek": 372764,
        "start": 3746.3799999999997,
        "temperature": 0,
        "text": " More cats.",
        "tokens": [
          51301,
          5048,
          11111,
          13,
          51361
        ]
      },
      {
        "avg_logprob": -0.279613619265349,
        "compression_ratio": 1.4352941176470588,
        "end": 3748.94,
        "id": 1099,
        "no_speech_prob": 0.000041335337300552055,
        "seek": 372764,
        "start": 3747.58,
        "temperature": 0,
        "text": " Actually, let's do a tiger.",
        "tokens": [
          51361,
          5135,
          11,
          718,
          311,
          360,
          257,
          21432,
          13,
          51429
        ]
      },
      {
        "avg_logprob": -0.279613619265349,
        "compression_ratio": 1.4352941176470588,
        "end": 3751.7799999999997,
        "id": 1100,
        "no_speech_prob": 0.000041335337300552055,
        "seek": 372764,
        "start": 3750.94,
        "temperature": 0,
        "text": " Go.",
        "tokens": [
          51529,
          1037,
          13,
          51571
        ]
      },
      {
        "avg_logprob": -0.279613619265349,
        "compression_ratio": 1.4352941176470588,
        "end": 3755.2599999999998,
        "id": 1101,
        "no_speech_prob": 0.000041335337300552055,
        "seek": 372764,
        "start": 3753.3399999999997,
        "temperature": 0,
        "text": " And, okay, something weird is happening.",
        "tokens": [
          51649,
          400,
          11,
          1392,
          11,
          746,
          3657,
          307,
          2737,
          13,
          51745
        ]
      },
      {
        "avg_logprob": -0.22691965395687547,
        "compression_ratio": 1.756183745583039,
        "end": 3757.7200000000003,
        "id": 1102,
        "no_speech_prob": 0.0001660382404224947,
        "seek": 375526,
        "start": 3755.28,
        "temperature": 0,
        "text": " So whenever I'm listing all the mus,",
        "tokens": [
          50365,
          407,
          5699,
          286,
          478,
          22161,
          439,
          264,
          1038,
          11,
          50487
        ]
      },
      {
        "avg_logprob": -0.22691965395687547,
        "compression_ratio": 1.756183745583039,
        "end": 3759.1200000000003,
        "id": 1103,
        "no_speech_prob": 0.0001660382404224947,
        "seek": 375526,
        "start": 3757.7200000000003,
        "temperature": 0,
        "text": " I'm just appending more and more",
        "tokens": [
          50487,
          286,
          478,
          445,
          724,
          2029,
          544,
          293,
          544,
          50557
        ]
      },
      {
        "avg_logprob": -0.22691965395687547,
        "compression_ratio": 1.756183745583039,
        "end": 3760.2000000000003,
        "id": 1104,
        "no_speech_prob": 0.0001660382404224947,
        "seek": 375526,
        "start": 3759.1200000000003,
        "temperature": 0,
        "text": " and more and more to the page.",
        "tokens": [
          50557,
          293,
          544,
          293,
          544,
          281,
          264,
          3028,
          13,
          50611
        ]
      },
      {
        "avg_logprob": -0.22691965395687547,
        "compression_ratio": 1.756183745583039,
        "end": 3761.4,
        "id": 1105,
        "no_speech_prob": 0.0001660382404224947,
        "seek": 375526,
        "start": 3760.2000000000003,
        "temperature": 0,
        "text": " So one thing I actually need to do",
        "tokens": [
          50611,
          407,
          472,
          551,
          286,
          767,
          643,
          281,
          360,
          50671
        ]
      },
      {
        "avg_logprob": -0.22691965395687547,
        "compression_ratio": 1.756183745583039,
        "end": 3762.84,
        "id": 1106,
        "no_speech_prob": 0.0001660382404224947,
        "seek": 375526,
        "start": 3761.4,
        "temperature": 0,
        "text": " is clear out the list,",
        "tokens": [
          50671,
          307,
          1850,
          484,
          264,
          1329,
          11,
          50743
        ]
      },
      {
        "avg_logprob": -0.22691965395687547,
        "compression_ratio": 1.756183745583039,
        "end": 3763.88,
        "id": 1107,
        "no_speech_prob": 0.0001660382404224947,
        "seek": 375526,
        "start": 3762.84,
        "temperature": 0,
        "text": " so that way I can re-add them.",
        "tokens": [
          50743,
          370,
          300,
          636,
          286,
          393,
          319,
          12,
          25224,
          552,
          13,
          50795
        ]
      },
      {
        "avg_logprob": -0.22691965395687547,
        "compression_ratio": 1.756183745583039,
        "end": 3765.0800000000004,
        "id": 1108,
        "no_speech_prob": 0.0001660382404224947,
        "seek": 375526,
        "start": 3763.88,
        "temperature": 0,
        "text": " So let's do that.",
        "tokens": [
          50795,
          407,
          718,
          311,
          360,
          300,
          13,
          50855
        ]
      },
      {
        "avg_logprob": -0.22691965395687547,
        "compression_ratio": 1.756183745583039,
        "end": 3767.0800000000004,
        "id": 1109,
        "no_speech_prob": 0.0001660382404224947,
        "seek": 375526,
        "start": 3765.0800000000004,
        "temperature": 0,
        "text": " Basically, before listing all mus,",
        "tokens": [
          50855,
          8537,
          11,
          949,
          22161,
          439,
          1038,
          11,
          50955
        ]
      },
      {
        "avg_logprob": -0.22691965395687547,
        "compression_ratio": 1.756183745583039,
        "end": 3768.6800000000003,
        "id": 1110,
        "no_speech_prob": 0.0001660382404224947,
        "seek": 375526,
        "start": 3767.0800000000004,
        "temperature": 0,
        "text": " this is where I will use innerHTML.",
        "tokens": [
          50955,
          341,
          307,
          689,
          286,
          486,
          764,
          7284,
          39,
          51,
          12683,
          13,
          51035
        ]
      },
      {
        "avg_logprob": -0.22691965395687547,
        "compression_ratio": 1.756183745583039,
        "end": 3771.1200000000003,
        "id": 1111,
        "no_speech_prob": 0.0001660382404224947,
        "seek": 375526,
        "start": 3768.6800000000003,
        "temperature": 0,
        "text": " I'll just say here,",
        "tokens": [
          51035,
          286,
          603,
          445,
          584,
          510,
          11,
          51157
        ]
      },
      {
        "avg_logprob": -0.22691965395687547,
        "compression_ratio": 1.756183745583039,
        "end": 3774.6800000000003,
        "id": 1112,
        "no_speech_prob": 0.0001660382404224947,
        "seek": 375526,
        "start": 3771.1200000000003,
        "temperature": 0,
        "text": " musElement.innerHTML is nothing.",
        "tokens": [
          51157,
          1038,
          36,
          3054,
          13,
          19166,
          39,
          51,
          12683,
          307,
          1825,
          13,
          51335
        ]
      },
      {
        "avg_logprob": -0.22691965395687547,
        "compression_ratio": 1.756183745583039,
        "end": 3778.5200000000004,
        "id": 1113,
        "no_speech_prob": 0.0001660382404224947,
        "seek": 375526,
        "start": 3774.6800000000003,
        "temperature": 0,
        "text": " So basically, blank out everything that was there before,",
        "tokens": [
          51335,
          407,
          1936,
          11,
          8247,
          484,
          1203,
          300,
          390,
          456,
          949,
          11,
          51527
        ]
      },
      {
        "avg_logprob": -0.22691965395687547,
        "compression_ratio": 1.756183745583039,
        "end": 3779.7200000000003,
        "id": 1114,
        "no_speech_prob": 0.0001660382404224947,
        "seek": 375526,
        "start": 3778.5200000000004,
        "temperature": 0,
        "text": " and then add something new.",
        "tokens": [
          51527,
          293,
          550,
          909,
          746,
          777,
          13,
          51587
        ]
      },
      {
        "avg_logprob": -0.22691965395687547,
        "compression_ratio": 1.756183745583039,
        "end": 3781,
        "id": 1115,
        "no_speech_prob": 0.0001660382404224947,
        "seek": 375526,
        "start": 3779.7200000000003,
        "temperature": 0,
        "text": " So, name.",
        "tokens": [
          51587,
          407,
          11,
          1315,
          13,
          51651
        ]
      },
      {
        "avg_logprob": -0.22691965395687547,
        "compression_ratio": 1.756183745583039,
        "end": 3782.7200000000003,
        "id": 1116,
        "no_speech_prob": 0.0001660382404224947,
        "seek": 375526,
        "start": 3781,
        "temperature": 0,
        "text": " That's a legitimate way of removing",
        "tokens": [
          51651,
          663,
          311,
          257,
          17956,
          636,
          295,
          12720,
          51737
        ]
      },
      {
        "avg_logprob": -0.22691965395687547,
        "compression_ratio": 1.756183745583039,
        "end": 3783.96,
        "id": 1117,
        "no_speech_prob": 0.0001660382404224947,
        "seek": 375526,
        "start": 3782.7200000000003,
        "temperature": 0,
        "text": " a whole set of DOM elements?",
        "tokens": [
          51737,
          257,
          1379,
          992,
          295,
          35727,
          4959,
          30,
          51799
        ]
      },
      {
        "avg_logprob": -0.22691965395687547,
        "compression_ratio": 1.756183745583039,
        "end": 3784.8,
        "id": 1118,
        "no_speech_prob": 0.0001660382404224947,
        "seek": 375526,
        "start": 3783.96,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          51799,
          1079,
          13,
          51841
        ]
      },
      {
        "avg_logprob": -0.3630854012309641,
        "compression_ratio": 1.538181818181818,
        "end": 3786.1200000000003,
        "id": 1119,
        "no_speech_prob": 0.008985253982245922,
        "seek": 378480,
        "start": 3785.3,
        "temperature": 0,
        "text": " So you could just visually iterate through them",
        "tokens": [
          50389,
          407,
          291,
          727,
          445,
          19622,
          44497,
          807,
          552,
          50430
        ]
      },
      {
        "avg_logprob": -0.3630854012309641,
        "compression_ratio": 1.538181818181818,
        "end": 3787.02,
        "id": 1120,
        "no_speech_prob": 0.008985253982245922,
        "seek": 378480,
        "start": 3786.1200000000003,
        "temperature": 0,
        "text": " and remove them from the page?",
        "tokens": [
          50430,
          293,
          4159,
          552,
          490,
          264,
          3028,
          30,
          50475
        ]
      },
      {
        "avg_logprob": -0.3630854012309641,
        "compression_ratio": 1.538181818181818,
        "end": 3787.86,
        "id": 1121,
        "no_speech_prob": 0.008985253982245922,
        "seek": 378480,
        "start": 3787.02,
        "temperature": 0,
        "text": " You could.",
        "tokens": [
          50475,
          509,
          727,
          13,
          50517
        ]
      },
      {
        "avg_logprob": -0.3630854012309641,
        "compression_ratio": 1.538181818181818,
        "end": 3788.7000000000003,
        "id": 1122,
        "no_speech_prob": 0.008985253982245922,
        "seek": 378480,
        "start": 3787.86,
        "temperature": 0,
        "text": " I'm not aware,",
        "tokens": [
          50517,
          286,
          478,
          406,
          3650,
          11,
          50559
        ]
      },
      {
        "avg_logprob": -0.3630854012309641,
        "compression_ratio": 1.538181818181818,
        "end": 3790.2200000000003,
        "id": 1123,
        "no_speech_prob": 0.008985253982245922,
        "seek": 378480,
        "start": 3788.7000000000003,
        "temperature": 0,
        "text": " I don't know of the performance implications,",
        "tokens": [
          50559,
          286,
          500,
          380,
          458,
          295,
          264,
          3389,
          16602,
          11,
          50635
        ]
      },
      {
        "avg_logprob": -0.3630854012309641,
        "compression_ratio": 1.538181818181818,
        "end": 3791.54,
        "id": 1124,
        "no_speech_prob": 0.008985253982245922,
        "seek": 378480,
        "start": 3790.2200000000003,
        "temperature": 0,
        "text": " but yes.",
        "tokens": [
          50635,
          457,
          2086,
          13,
          50701
        ]
      },
      {
        "avg_logprob": -0.3630854012309641,
        "compression_ratio": 1.538181818181818,
        "end": 3792.38,
        "id": 1125,
        "no_speech_prob": 0.008985253982245922,
        "seek": 378480,
        "start": 3791.54,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          50701,
          1079,
          13,
          50743
        ]
      },
      {
        "avg_logprob": -0.3630854012309641,
        "compression_ratio": 1.538181818181818,
        "end": 3795.0600000000004,
        "id": 1126,
        "no_speech_prob": 0.008985253982245922,
        "seek": 378480,
        "start": 3793.9,
        "temperature": 0,
        "text": " Somehow that always felt like",
        "tokens": [
          50819,
          28357,
          300,
          1009,
          2762,
          411,
          50877
        ]
      },
      {
        "avg_logprob": -0.3630854012309641,
        "compression_ratio": 1.538181818181818,
        "end": 3797.1800000000003,
        "id": 1127,
        "no_speech_prob": 0.008985253982245922,
        "seek": 378480,
        "start": 3795.0600000000004,
        "temperature": 0,
        "text": " a thing I'm not supposed to do.",
        "tokens": [
          50877,
          257,
          551,
          286,
          478,
          406,
          3442,
          281,
          360,
          13,
          50983
        ]
      },
      {
        "avg_logprob": -0.3630854012309641,
        "compression_ratio": 1.538181818181818,
        "end": 3799.02,
        "id": 1128,
        "no_speech_prob": 0.008985253982245922,
        "seek": 378480,
        "start": 3797.1800000000003,
        "temperature": 0,
        "text": " I do it all the time.",
        "tokens": [
          50983,
          286,
          360,
          309,
          439,
          264,
          565,
          13,
          51075
        ]
      },
      {
        "avg_logprob": -0.3630854012309641,
        "compression_ratio": 1.538181818181818,
        "end": 3799.86,
        "id": 1129,
        "no_speech_prob": 0.008985253982245922,
        "seek": 378480,
        "start": 3799.02,
        "temperature": 0,
        "text": " Cool, and so now,",
        "tokens": [
          51075,
          8561,
          11,
          293,
          370,
          586,
          11,
          51117
        ]
      },
      {
        "avg_logprob": -0.3630854012309641,
        "compression_ratio": 1.538181818181818,
        "end": 3801.78,
        "id": 1130,
        "no_speech_prob": 0.008985253982245922,
        "seek": 378480,
        "start": 3799.86,
        "temperature": 0,
        "text": " we'll notice, did I just type name was name?",
        "tokens": [
          51117,
          321,
          603,
          3449,
          11,
          630,
          286,
          445,
          2010,
          1315,
          390,
          1315,
          30,
          51213
        ]
      },
      {
        "avg_logprob": -0.3630854012309641,
        "compression_ratio": 1.538181818181818,
        "end": 3802.92,
        "id": 1131,
        "no_speech_prob": 0.008985253982245922,
        "seek": 378480,
        "start": 3801.78,
        "temperature": 0,
        "text": " Oh well.",
        "tokens": [
          51213,
          876,
          731,
          13,
          51270
        ]
      },
      {
        "avg_logprob": -0.3630854012309641,
        "compression_ratio": 1.538181818181818,
        "end": 3805.6200000000003,
        "id": 1132,
        "no_speech_prob": 0.008985253982245922,
        "seek": 378480,
        "start": 3802.92,
        "temperature": 0,
        "text": " But whatever you are now submitting",
        "tokens": [
          51270,
          583,
          2035,
          291,
          366,
          586,
          31836,
          51405
        ]
      },
      {
        "avg_logprob": -0.3630854012309641,
        "compression_ratio": 1.538181818181818,
        "end": 3807.78,
        "id": 1133,
        "no_speech_prob": 0.008985253982245922,
        "seek": 378480,
        "start": 3805.6200000000003,
        "temperature": 0,
        "text": " is getting inserted in here.",
        "tokens": [
          51405,
          307,
          1242,
          27992,
          294,
          510,
          13,
          51513
        ]
      },
      {
        "avg_logprob": -0.3630854012309641,
        "compression_ratio": 1.538181818181818,
        "end": 3809.3,
        "id": 1134,
        "no_speech_prob": 0.008985253982245922,
        "seek": 378480,
        "start": 3807.78,
        "temperature": 0,
        "text": " Hello world.",
        "tokens": [
          51513,
          2425,
          1002,
          13,
          51589
        ]
      },
      {
        "avg_logprob": -0.3630854012309641,
        "compression_ratio": 1.538181818181818,
        "end": 3812.98,
        "id": 1135,
        "no_speech_prob": 0.008985253982245922,
        "seek": 378480,
        "start": 3810.5,
        "temperature": 0,
        "text": " Let's do poop emoji, go.",
        "tokens": [
          51649,
          961,
          311,
          360,
          17153,
          31595,
          11,
          352,
          13,
          51773
        ]
      },
      {
        "avg_logprob": -0.21733680138221154,
        "compression_ratio": 1.7420382165605095,
        "end": 3814.88,
        "id": 1136,
        "no_speech_prob": 0.00005562175647355616,
        "seek": 381298,
        "start": 3813,
        "temperature": 0,
        "text": " And it shows up at the top of the list.",
        "tokens": [
          50365,
          400,
          309,
          3110,
          493,
          412,
          264,
          1192,
          295,
          264,
          1329,
          13,
          50459
        ]
      },
      {
        "avg_logprob": -0.21733680138221154,
        "compression_ratio": 1.7420382165605095,
        "end": 3815.72,
        "id": 1137,
        "no_speech_prob": 0.00005562175647355616,
        "seek": 381298,
        "start": 3814.88,
        "temperature": 0,
        "text": " Awesome.",
        "tokens": [
          50459,
          10391,
          13,
          50501
        ]
      },
      {
        "avg_logprob": -0.21733680138221154,
        "compression_ratio": 1.7420382165605095,
        "end": 3816.76,
        "id": 1138,
        "no_speech_prob": 0.00005562175647355616,
        "seek": 381298,
        "start": 3815.72,
        "temperature": 0,
        "text": " So this is our app.",
        "tokens": [
          50501,
          407,
          341,
          307,
          527,
          724,
          13,
          50553
        ]
      },
      {
        "avg_logprob": -0.21733680138221154,
        "compression_ratio": 1.7420382165605095,
        "end": 3819.2400000000002,
        "id": 1139,
        "no_speech_prob": 0.00005562175647355616,
        "seek": 381298,
        "start": 3816.76,
        "temperature": 0,
        "text": " I do have on the list here that I was going to deploy,",
        "tokens": [
          50553,
          286,
          360,
          362,
          322,
          264,
          1329,
          510,
          300,
          286,
          390,
          516,
          281,
          7274,
          11,
          50677
        ]
      },
      {
        "avg_logprob": -0.21733680138221154,
        "compression_ratio": 1.7420382165605095,
        "end": 3821.96,
        "id": 1140,
        "no_speech_prob": 0.00005562175647355616,
        "seek": 381298,
        "start": 3819.2400000000002,
        "temperature": 0,
        "text": " but I don't know if we have enough time for that.",
        "tokens": [
          50677,
          457,
          286,
          500,
          380,
          458,
          498,
          321,
          362,
          1547,
          565,
          337,
          300,
          13,
          50813
        ]
      },
      {
        "avg_logprob": -0.21733680138221154,
        "compression_ratio": 1.7420382165605095,
        "end": 3822.8,
        "id": 1141,
        "no_speech_prob": 0.00005562175647355616,
        "seek": 381298,
        "start": 3821.96,
        "temperature": 0,
        "text": " One thing I'll talk about",
        "tokens": [
          50813,
          1485,
          551,
          286,
          603,
          751,
          466,
          50855
        ]
      },
      {
        "avg_logprob": -0.21733680138221154,
        "compression_ratio": 1.7420382165605095,
        "end": 3824.44,
        "id": 1142,
        "no_speech_prob": 0.00005562175647355616,
        "seek": 381298,
        "start": 3822.8,
        "temperature": 0,
        "text": " in terms of security implications,",
        "tokens": [
          50855,
          294,
          2115,
          295,
          3825,
          16602,
          11,
          50937
        ]
      },
      {
        "avg_logprob": -0.21733680138221154,
        "compression_ratio": 1.7420382165605095,
        "end": 3826.9,
        "id": 1143,
        "no_speech_prob": 0.00005562175647355616,
        "seek": 381298,
        "start": 3824.44,
        "temperature": 0,
        "text": " so putting this out there in the world,",
        "tokens": [
          50937,
          370,
          3372,
          341,
          484,
          456,
          294,
          264,
          1002,
          11,
          51060
        ]
      },
      {
        "avg_logprob": -0.21733680138221154,
        "compression_ratio": 1.7420382165605095,
        "end": 3830.86,
        "id": 1144,
        "no_speech_prob": 0.00005562175647355616,
        "seek": 381298,
        "start": 3826.9,
        "temperature": 0,
        "text": " I would want to prevent people from inserting bad words",
        "tokens": [
          51060,
          286,
          576,
          528,
          281,
          4871,
          561,
          490,
          46567,
          1578,
          2283,
          51258
        ]
      },
      {
        "avg_logprob": -0.21733680138221154,
        "compression_ratio": 1.7420382165605095,
        "end": 3831.72,
        "id": 1145,
        "no_speech_prob": 0.00005562175647355616,
        "seek": 381298,
        "start": 3830.86,
        "temperature": 0,
        "text": " or different things like that.",
        "tokens": [
          51258,
          420,
          819,
          721,
          411,
          300,
          13,
          51301
        ]
      },
      {
        "avg_logprob": -0.21733680138221154,
        "compression_ratio": 1.7420382165605095,
        "end": 3834.84,
        "id": 1146,
        "no_speech_prob": 0.00005562175647355616,
        "seek": 381298,
        "start": 3831.72,
        "temperature": 0,
        "text": " So there is this package on npm called bad words,",
        "tokens": [
          51301,
          407,
          456,
          307,
          341,
          7372,
          322,
          297,
          14395,
          1219,
          1578,
          2283,
          11,
          51457
        ]
      },
      {
        "avg_logprob": -0.21733680138221154,
        "compression_ratio": 1.7420382165605095,
        "end": 3837.7400000000002,
        "id": 1147,
        "no_speech_prob": 0.00005562175647355616,
        "seek": 381298,
        "start": 3834.84,
        "temperature": 0,
        "text": " where basically before I insert it into the database,",
        "tokens": [
          51457,
          689,
          1936,
          949,
          286,
          8969,
          309,
          666,
          264,
          8149,
          11,
          51602
        ]
      },
      {
        "avg_logprob": -0.21733680138221154,
        "compression_ratio": 1.7420382165605095,
        "end": 3838.58,
        "id": 1148,
        "no_speech_prob": 0.00005562175647355616,
        "seek": 381298,
        "start": 3837.7400000000002,
        "temperature": 0,
        "text": " I could filter it,",
        "tokens": [
          51602,
          286,
          727,
          6608,
          309,
          11,
          51644
        ]
      },
      {
        "avg_logprob": -0.21733680138221154,
        "compression_ratio": 1.7420382165605095,
        "end": 3840.72,
        "id": 1149,
        "no_speech_prob": 0.00005562175647355616,
        "seek": 381298,
        "start": 3838.58,
        "temperature": 0,
        "text": " and that way get rid of any nasty words",
        "tokens": [
          51644,
          293,
          300,
          636,
          483,
          3973,
          295,
          604,
          17923,
          2283,
          51751
        ]
      },
      {
        "avg_logprob": -0.21733680138221154,
        "compression_ratio": 1.7420382165605095,
        "end": 3841.56,
        "id": 1150,
        "no_speech_prob": 0.00005562175647355616,
        "seek": 381298,
        "start": 3840.72,
        "temperature": 0,
        "text": " or anything like that.",
        "tokens": [
          51751,
          420,
          1340,
          411,
          300,
          13,
          51793
        ]
      },
      {
        "avg_logprob": -0.26203737760844986,
        "compression_ratio": 1.7160493827160495,
        "end": 3843.06,
        "id": 1151,
        "no_speech_prob": 0.0000085303081505117,
        "seek": 384156,
        "start": 3841.58,
        "temperature": 0,
        "text": " And the other thing is to prevent people",
        "tokens": [
          50365,
          400,
          264,
          661,
          551,
          307,
          281,
          4871,
          561,
          50439
        ]
      },
      {
        "avg_logprob": -0.26203737760844986,
        "compression_ratio": 1.7160493827160495,
        "end": 3846.5,
        "id": 1152,
        "no_speech_prob": 0.0000085303081505117,
        "seek": 384156,
        "start": 3843.06,
        "temperature": 0,
        "text": " from spamming my server with a bunch of different mus.",
        "tokens": [
          50439,
          490,
          24028,
          2810,
          452,
          7154,
          365,
          257,
          3840,
          295,
          819,
          1038,
          13,
          50611
        ]
      },
      {
        "avg_logprob": -0.26203737760844986,
        "compression_ratio": 1.7160493827160495,
        "end": 3849.74,
        "id": 1153,
        "no_speech_prob": 0.0000085303081505117,
        "seek": 384156,
        "start": 3846.5,
        "temperature": 0,
        "text": " They could, because I've built this API,",
        "tokens": [
          50611,
          814,
          727,
          11,
          570,
          286,
          600,
          3094,
          341,
          9362,
          11,
          50773
        ]
      },
      {
        "avg_logprob": -0.26203737760844986,
        "compression_ratio": 1.7160493827160495,
        "end": 3851.7599999999998,
        "id": 1154,
        "no_speech_prob": 0.0000085303081505117,
        "seek": 384156,
        "start": 3849.74,
        "temperature": 0,
        "text": " they technically don't have to use this form.",
        "tokens": [
          50773,
          436,
          12120,
          500,
          380,
          362,
          281,
          764,
          341,
          1254,
          13,
          50874
        ]
      },
      {
        "avg_logprob": -0.26203737760844986,
        "compression_ratio": 1.7160493827160495,
        "end": 3853.1,
        "id": 1155,
        "no_speech_prob": 0.0000085303081505117,
        "seek": 384156,
        "start": 3851.7599999999998,
        "temperature": 0,
        "text": " They could write some JavaScript",
        "tokens": [
          50874,
          814,
          727,
          2464,
          512,
          15778,
          50941
        ]
      },
      {
        "avg_logprob": -0.26203737760844986,
        "compression_ratio": 1.7160493827160495,
        "end": 3855.14,
        "id": 1156,
        "no_speech_prob": 0.0000085303081505117,
        "seek": 384156,
        "start": 3853.1,
        "temperature": 0,
        "text": " that just makes a post request to my server",
        "tokens": [
          50941,
          300,
          445,
          1669,
          257,
          2183,
          5308,
          281,
          452,
          7154,
          51043
        ]
      },
      {
        "avg_logprob": -0.26203737760844986,
        "compression_ratio": 1.7160493827160495,
        "end": 3856.52,
        "id": 1157,
        "no_speech_prob": 0.0000085303081505117,
        "seek": 384156,
        "start": 3855.14,
        "temperature": 0,
        "text": " over and over again.",
        "tokens": [
          51043,
          670,
          293,
          670,
          797,
          13,
          51112
        ]
      },
      {
        "avg_logprob": -0.26203737760844986,
        "compression_ratio": 1.7160493827160495,
        "end": 3857.48,
        "id": 1158,
        "no_speech_prob": 0.0000085303081505117,
        "seek": 384156,
        "start": 3856.52,
        "temperature": 0,
        "text": " So to prevent that,",
        "tokens": [
          51112,
          407,
          281,
          4871,
          300,
          11,
          51160
        ]
      },
      {
        "avg_logprob": -0.26203737760844986,
        "compression_ratio": 1.7160493827160495,
        "end": 3859.46,
        "id": 1159,
        "no_speech_prob": 0.0000085303081505117,
        "seek": 384156,
        "start": 3857.48,
        "temperature": 0,
        "text": " you might do something called rate limiting.",
        "tokens": [
          51160,
          291,
          1062,
          360,
          746,
          1219,
          3314,
          22083,
          13,
          51259
        ]
      },
      {
        "avg_logprob": -0.26203737760844986,
        "compression_ratio": 1.7160493827160495,
        "end": 3861.74,
        "id": 1160,
        "no_speech_prob": 0.0000085303081505117,
        "seek": 384156,
        "start": 3859.46,
        "temperature": 0,
        "text": " And so there's a package called Express Rate Limiter",
        "tokens": [
          51259,
          400,
          370,
          456,
          311,
          257,
          7372,
          1219,
          20212,
          49583,
          16406,
          1681,
          51373
        ]
      },
      {
        "avg_logprob": -0.26203737760844986,
        "compression_ratio": 1.7160493827160495,
        "end": 3864.1,
        "id": 1161,
        "no_speech_prob": 0.0000085303081505117,
        "seek": 384156,
        "start": 3861.74,
        "temperature": 0,
        "text": " that just limits the request to,",
        "tokens": [
          51373,
          300,
          445,
          10406,
          264,
          5308,
          281,
          11,
          51491
        ]
      },
      {
        "avg_logprob": -0.26203737760844986,
        "compression_ratio": 1.7160493827160495,
        "end": 3866.02,
        "id": 1162,
        "no_speech_prob": 0.0000085303081505117,
        "seek": 384156,
        "start": 3864.1,
        "temperature": 0,
        "text": " you can set it up to one every 15 seconds",
        "tokens": [
          51491,
          291,
          393,
          992,
          309,
          493,
          281,
          472,
          633,
          2119,
          3949,
          51587
        ]
      },
      {
        "avg_logprob": -0.26203737760844986,
        "compression_ratio": 1.7160493827160495,
        "end": 3867.18,
        "id": 1163,
        "no_speech_prob": 0.0000085303081505117,
        "seek": 384156,
        "start": 3866.02,
        "temperature": 0,
        "text": " or something like that.",
        "tokens": [
          51587,
          420,
          746,
          411,
          300,
          13,
          51645
        ]
      },
      {
        "avg_logprob": -0.26203737760844986,
        "compression_ratio": 1.7160493827160495,
        "end": 3868.94,
        "id": 1164,
        "no_speech_prob": 0.0000085303081505117,
        "seek": 384156,
        "start": 3868.04,
        "temperature": 0,
        "text": " I guess the last thing is,",
        "tokens": [
          51688,
          286,
          2041,
          264,
          1036,
          551,
          307,
          11,
          51733
        ]
      },
      {
        "avg_logprob": -0.26203737760844986,
        "compression_ratio": 1.7160493827160495,
        "end": 3870.02,
        "id": 1165,
        "no_speech_prob": 0.0000085303081505117,
        "seek": 384156,
        "start": 3868.94,
        "temperature": 0,
        "text": " let's just look at the diagram.",
        "tokens": [
          51733,
          718,
          311,
          445,
          574,
          412,
          264,
          10686,
          13,
          51787
        ]
      },
      {
        "avg_logprob": -0.24572594185185626,
        "compression_ratio": 1.7250996015936255,
        "end": 3872.36,
        "id": 1166,
        "no_speech_prob": 0.000003668842282422702,
        "seek": 387002,
        "start": 3870.02,
        "temperature": 0,
        "text": " Let's review what we built today.",
        "tokens": [
          50364,
          961,
          311,
          3131,
          437,
          321,
          3094,
          965,
          13,
          50481
        ]
      },
      {
        "avg_logprob": -0.24572594185185626,
        "compression_ratio": 1.7250996015936255,
        "end": 3875.64,
        "id": 1167,
        "no_speech_prob": 0.000003668842282422702,
        "seek": 387002,
        "start": 3872.36,
        "temperature": 0,
        "text": " And then we can recap, answer questions and stuff.",
        "tokens": [
          50481,
          400,
          550,
          321,
          393,
          20928,
          11,
          1867,
          1651,
          293,
          1507,
          13,
          50645
        ]
      },
      {
        "avg_logprob": -0.24572594185185626,
        "compression_ratio": 1.7250996015936255,
        "end": 3879.32,
        "id": 1168,
        "no_speech_prob": 0.000003668842282422702,
        "seek": 387002,
        "start": 3875.64,
        "temperature": 0,
        "text": " Okay, so the page loads.",
        "tokens": [
          50645,
          1033,
          11,
          370,
          264,
          3028,
          12668,
          13,
          50829
        ]
      },
      {
        "avg_logprob": -0.24572594185185626,
        "compression_ratio": 1.7250996015936255,
        "end": 3882.24,
        "id": 1169,
        "no_speech_prob": 0.000003668842282422702,
        "seek": 387002,
        "start": 3879.32,
        "temperature": 0,
        "text": " It initially makes the request to the static file server,",
        "tokens": [
          50829,
          467,
          9105,
          1669,
          264,
          5308,
          281,
          264,
          13437,
          3991,
          7154,
          11,
          50975
        ]
      },
      {
        "avg_logprob": -0.24572594185185626,
        "compression_ratio": 1.7250996015936255,
        "end": 3885.82,
        "id": 1170,
        "no_speech_prob": 0.000003668842282422702,
        "seek": 387002,
        "start": 3882.24,
        "temperature": 0,
        "text": " which is hosting all of our HTML.",
        "tokens": [
          50975,
          597,
          307,
          16058,
          439,
          295,
          527,
          17995,
          13,
          51154
        ]
      },
      {
        "avg_logprob": -0.24572594185185626,
        "compression_ratio": 1.7250996015936255,
        "end": 3888.8,
        "id": 1171,
        "no_speech_prob": 0.000003668842282422702,
        "seek": 387002,
        "start": 3885.82,
        "temperature": 0,
        "text": " And it makes the request for index.html,",
        "tokens": [
          51154,
          400,
          309,
          1669,
          264,
          5308,
          337,
          8186,
          13,
          357,
          15480,
          11,
          51303
        ]
      },
      {
        "avg_logprob": -0.24572594185185626,
        "compression_ratio": 1.7250996015936255,
        "end": 3890.84,
        "id": 1172,
        "no_speech_prob": 0.000003668842282422702,
        "seek": 387002,
        "start": 3888.8,
        "temperature": 0,
        "text": " and that gets loaded into the browser.",
        "tokens": [
          51303,
          293,
          300,
          2170,
          13210,
          666,
          264,
          11185,
          13,
          51405
        ]
      },
      {
        "avg_logprob": -0.24572594185185626,
        "compression_ratio": 1.7250996015936255,
        "end": 3894.12,
        "id": 1173,
        "no_speech_prob": 0.000003668842282422702,
        "seek": 387002,
        "start": 3890.84,
        "temperature": 0,
        "text": " And then that HTML says, I have a CSS file.",
        "tokens": [
          51405,
          400,
          550,
          300,
          17995,
          1619,
          11,
          286,
          362,
          257,
          24387,
          3991,
          13,
          51569
        ]
      },
      {
        "avg_logprob": -0.24572594185185626,
        "compression_ratio": 1.7250996015936255,
        "end": 3896.32,
        "id": 1174,
        "no_speech_prob": 0.000003668842282422702,
        "seek": 387002,
        "start": 3894.12,
        "temperature": 0,
        "text": " I have the skeleton CSS file,",
        "tokens": [
          51569,
          286,
          362,
          264,
          25204,
          24387,
          3991,
          11,
          51679
        ]
      },
      {
        "avg_logprob": -0.24572594185185626,
        "compression_ratio": 1.7250996015936255,
        "end": 3897.64,
        "id": 1175,
        "no_speech_prob": 0.000003668842282422702,
        "seek": 387002,
        "start": 3896.32,
        "temperature": 0,
        "text": " which is on some other server.",
        "tokens": [
          51679,
          597,
          307,
          322,
          512,
          661,
          7154,
          13,
          51745
        ]
      },
      {
        "avg_logprob": -0.24572594185185626,
        "compression_ratio": 1.7250996015936255,
        "end": 3899.64,
        "id": 1176,
        "no_speech_prob": 0.000003668842282422702,
        "seek": 387002,
        "start": 3897.64,
        "temperature": 0,
        "text": " And so your browser will then make the request",
        "tokens": [
          51745,
          400,
          370,
          428,
          11185,
          486,
          550,
          652,
          264,
          5308,
          51845
        ]
      },
      {
        "avg_logprob": -0.2626240470192649,
        "compression_ratio": 1.8359375,
        "end": 3901.7,
        "id": 1177,
        "no_speech_prob": 0.000006144166945887264,
        "seek": 389964,
        "start": 3900.22,
        "temperature": 0,
        "text": " to those servers to then load that content",
        "tokens": [
          50393,
          281,
          729,
          15909,
          281,
          550,
          3677,
          300,
          2701,
          50467
        ]
      },
      {
        "avg_logprob": -0.2626240470192649,
        "compression_ratio": 1.8359375,
        "end": 3903.98,
        "id": 1178,
        "no_speech_prob": 0.000006144166945887264,
        "seek": 389964,
        "start": 3901.7,
        "temperature": 0,
        "text": " and actually load it into the page.",
        "tokens": [
          50467,
          293,
          767,
          3677,
          309,
          666,
          264,
          3028,
          13,
          50581
        ]
      },
      {
        "avg_logprob": -0.2626240470192649,
        "compression_ratio": 1.8359375,
        "end": 3905.42,
        "id": 1179,
        "no_speech_prob": 0.000006144166945887264,
        "seek": 389964,
        "start": 3903.98,
        "temperature": 0,
        "text": " Now the other thing that happens is,",
        "tokens": [
          50581,
          823,
          264,
          661,
          551,
          300,
          2314,
          307,
          11,
          50653
        ]
      },
      {
        "avg_logprob": -0.2626240470192649,
        "compression_ratio": 1.8359375,
        "end": 3906.7,
        "id": 1180,
        "no_speech_prob": 0.000006144166945887264,
        "seek": 389964,
        "start": 3905.42,
        "temperature": 0,
        "text": " well, and even think about scripts.",
        "tokens": [
          50653,
          731,
          11,
          293,
          754,
          519,
          466,
          23294,
          13,
          50717
        ]
      },
      {
        "avg_logprob": -0.2626240470192649,
        "compression_ratio": 1.8359375,
        "end": 3909.2999999999997,
        "id": 1181,
        "no_speech_prob": 0.000006144166945887264,
        "seek": 389964,
        "start": 3906.7,
        "temperature": 0,
        "text": " So the fact that I have script source equals",
        "tokens": [
          50717,
          407,
          264,
          1186,
          300,
          286,
          362,
          5755,
          4009,
          6915,
          50847
        ]
      },
      {
        "avg_logprob": -0.2626240470192649,
        "compression_ratio": 1.8359375,
        "end": 3912.6,
        "id": 1182,
        "no_speech_prob": 0.000006144166945887264,
        "seek": 389964,
        "start": 3911.02,
        "temperature": 0,
        "text": " client.js at the bottom,",
        "tokens": [
          50933,
          6423,
          13,
          25530,
          412,
          264,
          2767,
          11,
          51012
        ]
      },
      {
        "avg_logprob": -0.2626240470192649,
        "compression_ratio": 1.8359375,
        "end": 3913.7599999999998,
        "id": 1183,
        "no_speech_prob": 0.000006144166945887264,
        "seek": 389964,
        "start": 3912.6,
        "temperature": 0,
        "text": " when the browser sees that,",
        "tokens": [
          51012,
          562,
          264,
          11185,
          8194,
          300,
          11,
          51070
        ]
      },
      {
        "avg_logprob": -0.2626240470192649,
        "compression_ratio": 1.8359375,
        "end": 3915.62,
        "id": 1184,
        "no_speech_prob": 0.000006144166945887264,
        "seek": 389964,
        "start": 3913.7599999999998,
        "temperature": 0,
        "text": " it has to actually request that file",
        "tokens": [
          51070,
          309,
          575,
          281,
          767,
          5308,
          300,
          3991,
          51163
        ]
      },
      {
        "avg_logprob": -0.2626240470192649,
        "compression_ratio": 1.8359375,
        "end": 3917.42,
        "id": 1185,
        "no_speech_prob": 0.000006144166945887264,
        "seek": 389964,
        "start": 3915.62,
        "temperature": 0,
        "text": " from the static file server.",
        "tokens": [
          51163,
          490,
          264,
          13437,
          3991,
          7154,
          13,
          51253
        ]
      },
      {
        "avg_logprob": -0.2626240470192649,
        "compression_ratio": 1.8359375,
        "end": 3921.18,
        "id": 1186,
        "no_speech_prob": 0.000006144166945887264,
        "seek": 389964,
        "start": 3917.42,
        "temperature": 0,
        "text": " It loads it in and then runs the code that's inside of it.",
        "tokens": [
          51253,
          467,
          12668,
          309,
          294,
          293,
          550,
          6676,
          264,
          3089,
          300,
          311,
          1854,
          295,
          309,
          13,
          51441
        ]
      },
      {
        "avg_logprob": -0.2626240470192649,
        "compression_ratio": 1.8359375,
        "end": 3922.98,
        "id": 1187,
        "no_speech_prob": 0.000006144166945887264,
        "seek": 389964,
        "start": 3921.18,
        "temperature": 0,
        "text": " And so when it runs that code,",
        "tokens": [
          51441,
          400,
          370,
          562,
          309,
          6676,
          300,
          3089,
          11,
          51531
        ]
      },
      {
        "avg_logprob": -0.2626240470192649,
        "compression_ratio": 1.8359375,
        "end": 3926.2599999999998,
        "id": 1188,
        "no_speech_prob": 0.000006144166945887264,
        "seek": 389964,
        "start": 3922.98,
        "temperature": 0,
        "text": " it actually sees this fetch that says,",
        "tokens": [
          51531,
          309,
          767,
          8194,
          341,
          23673,
          300,
          1619,
          11,
          51695
        ]
      },
      {
        "avg_logprob": -0.2626240470192649,
        "compression_ratio": 1.8359375,
        "end": 3927.2599999999998,
        "id": 1189,
        "no_speech_prob": 0.000006144166945887264,
        "seek": 389964,
        "start": 3926.2599999999998,
        "temperature": 0,
        "text": " get the request from you.",
        "tokens": [
          51695,
          483,
          264,
          5308,
          490,
          291,
          13,
          51745
        ]
      },
      {
        "avg_logprob": -0.3037544852808902,
        "compression_ratio": 1.606060606060606,
        "end": 3931.48,
        "id": 1190,
        "no_speech_prob": 0.0000047850476221356075,
        "seek": 392726,
        "start": 3927.28,
        "temperature": 0,
        "text": " So get, it's a get request to the URL Muse,",
        "tokens": [
          50365,
          407,
          483,
          11,
          309,
          311,
          257,
          483,
          5308,
          281,
          264,
          12905,
          47293,
          11,
          50575
        ]
      },
      {
        "avg_logprob": -0.3037544852808902,
        "compression_ratio": 1.606060606060606,
        "end": 3934.96,
        "id": 1191,
        "no_speech_prob": 0.0000047850476221356075,
        "seek": 392726,
        "start": 3931.48,
        "temperature": 0,
        "text": " and specifically it's going to the server on port 5000.",
        "tokens": [
          50575,
          293,
          4682,
          309,
          311,
          516,
          281,
          264,
          7154,
          322,
          2436,
          23777,
          13,
          50749
        ]
      },
      {
        "avg_logprob": -0.3037544852808902,
        "compression_ratio": 1.606060606060606,
        "end": 3936.48,
        "id": 1192,
        "no_speech_prob": 0.0000047850476221356075,
        "seek": 392726,
        "start": 3934.96,
        "temperature": 0,
        "text": " The server receives that request,",
        "tokens": [
          50749,
          440,
          7154,
          20717,
          300,
          5308,
          11,
          50825
        ]
      },
      {
        "avg_logprob": -0.3037544852808902,
        "compression_ratio": 1.606060606060606,
        "end": 3938.44,
        "id": 1193,
        "no_speech_prob": 0.0000047850476221356075,
        "seek": 392726,
        "start": 3936.48,
        "temperature": 0,
        "text": " and then it actually has to talk to the database.",
        "tokens": [
          50825,
          293,
          550,
          309,
          767,
          575,
          281,
          751,
          281,
          264,
          8149,
          13,
          50923
        ]
      },
      {
        "avg_logprob": -0.3037544852808902,
        "compression_ratio": 1.606060606060606,
        "end": 3942.84,
        "id": 1194,
        "no_speech_prob": 0.0000047850476221356075,
        "seek": 392726,
        "start": 3938.44,
        "temperature": 0,
        "text": " It says, hello database, please find.",
        "tokens": [
          50923,
          467,
          1619,
          11,
          7751,
          8149,
          11,
          1767,
          915,
          13,
          51143
        ]
      },
      {
        "avg_logprob": -0.3037544852808902,
        "compression_ratio": 1.606060606060606,
        "end": 3944.0800000000004,
        "id": 1195,
        "no_speech_prob": 0.0000047850476221356075,
        "seek": 392726,
        "start": 3942.84,
        "temperature": 0,
        "text": " So find.",
        "tokens": [
          51143,
          407,
          915,
          13,
          51205
        ]
      },
      {
        "avg_logprob": -0.3037544852808902,
        "compression_ratio": 1.606060606060606,
        "end": 3949.0800000000004,
        "id": 1196,
        "no_speech_prob": 0.0000047850476221356075,
        "seek": 392726,
        "start": 3948.2400000000002,
        "temperature": 0,
        "text": " We're back.",
        "tokens": [
          51413,
          492,
          434,
          646,
          13,
          51455
        ]
      },
      {
        "avg_logprob": -0.3037544852808902,
        "compression_ratio": 1.606060606060606,
        "end": 3952.0800000000004,
        "id": 1197,
        "no_speech_prob": 0.0000047850476221356075,
        "seek": 392726,
        "start": 3950.0400000000004,
        "temperature": 0,
        "text": " Find all of the things in the database,",
        "tokens": [
          51503,
          11809,
          439,
          295,
          264,
          721,
          294,
          264,
          8149,
          11,
          51605
        ]
      },
      {
        "avg_logprob": -0.3037544852808902,
        "compression_ratio": 1.606060606060606,
        "end": 3954.88,
        "id": 1198,
        "no_speech_prob": 0.0000047850476221356075,
        "seek": 392726,
        "start": 3952.0800000000004,
        "temperature": 0,
        "text": " return them, and then we take those",
        "tokens": [
          51605,
          2736,
          552,
          11,
          293,
          550,
          321,
          747,
          729,
          51745
        ]
      },
      {
        "avg_logprob": -0.2204346443290141,
        "compression_ratio": 1.7294117647058824,
        "end": 3956.2200000000003,
        "id": 1199,
        "no_speech_prob": 0.0000126068352983566,
        "seek": 395488,
        "start": 3954.88,
        "temperature": 0,
        "text": " and we do res.json,",
        "tokens": [
          50364,
          293,
          321,
          360,
          725,
          13,
          73,
          3015,
          11,
          50431
        ]
      },
      {
        "avg_logprob": -0.2204346443290141,
        "compression_ratio": 1.7294117647058824,
        "end": 3959.02,
        "id": 1200,
        "no_speech_prob": 0.0000126068352983566,
        "seek": 395488,
        "start": 3956.2200000000003,
        "temperature": 0,
        "text": " which actually sends them back to the client side.",
        "tokens": [
          50431,
          597,
          767,
          14790,
          552,
          646,
          281,
          264,
          6423,
          1252,
          13,
          50571
        ]
      },
      {
        "avg_logprob": -0.2204346443290141,
        "compression_ratio": 1.7294117647058824,
        "end": 3961.02,
        "id": 1201,
        "no_speech_prob": 0.0000126068352983566,
        "seek": 395488,
        "start": 3959.02,
        "temperature": 0,
        "text": " Then the client will iterate over the array.",
        "tokens": [
          50571,
          1396,
          264,
          6423,
          486,
          44497,
          670,
          264,
          10225,
          13,
          50671
        ]
      },
      {
        "avg_logprob": -0.2204346443290141,
        "compression_ratio": 1.7294117647058824,
        "end": 3962.46,
        "id": 1202,
        "no_speech_prob": 0.0000126068352983566,
        "seek": 395488,
        "start": 3961.02,
        "temperature": 0,
        "text": " It'll add them all to the page.",
        "tokens": [
          50671,
          467,
          603,
          909,
          552,
          439,
          281,
          264,
          3028,
          13,
          50743
        ]
      },
      {
        "avg_logprob": -0.2204346443290141,
        "compression_ratio": 1.7294117647058824,
        "end": 3963.78,
        "id": 1203,
        "no_speech_prob": 0.0000126068352983566,
        "seek": 395488,
        "start": 3962.46,
        "temperature": 0,
        "text": " They're nice and great.",
        "tokens": [
          50743,
          814,
          434,
          1481,
          293,
          869,
          13,
          50809
        ]
      },
      {
        "avg_logprob": -0.2204346443290141,
        "compression_ratio": 1.7294117647058824,
        "end": 3966.06,
        "id": 1204,
        "no_speech_prob": 0.0000126068352983566,
        "seek": 395488,
        "start": 3963.78,
        "temperature": 0,
        "text": " And then lastly, you have that post request.",
        "tokens": [
          50809,
          400,
          550,
          16386,
          11,
          291,
          362,
          300,
          2183,
          5308,
          13,
          50923
        ]
      },
      {
        "avg_logprob": -0.2204346443290141,
        "compression_ratio": 1.7294117647058824,
        "end": 3968.1600000000003,
        "id": 1205,
        "no_speech_prob": 0.0000126068352983566,
        "seek": 395488,
        "start": 3966.06,
        "temperature": 0,
        "text": " So a user will enter into the form here.",
        "tokens": [
          50923,
          407,
          257,
          4195,
          486,
          3242,
          666,
          264,
          1254,
          510,
          13,
          51028
        ]
      },
      {
        "avg_logprob": -0.2204346443290141,
        "compression_ratio": 1.7294117647058824,
        "end": 3969.1800000000003,
        "id": 1206,
        "no_speech_prob": 0.0000126068352983566,
        "seek": 395488,
        "start": 3968.1600000000003,
        "temperature": 0,
        "text": " They click submit.",
        "tokens": [
          51028,
          814,
          2052,
          10315,
          13,
          51079
        ]
      },
      {
        "avg_logprob": -0.2204346443290141,
        "compression_ratio": 1.7294117647058824,
        "end": 3971.62,
        "id": 1207,
        "no_speech_prob": 0.0000126068352983566,
        "seek": 395488,
        "start": 3969.1800000000003,
        "temperature": 0,
        "text": " That makes a request out to our server,",
        "tokens": [
          51079,
          663,
          1669,
          257,
          5308,
          484,
          281,
          527,
          7154,
          11,
          51201
        ]
      },
      {
        "avg_logprob": -0.2204346443290141,
        "compression_ratio": 1.7294117647058824,
        "end": 3974.62,
        "id": 1208,
        "no_speech_prob": 0.0000126068352983566,
        "seek": 395488,
        "start": 3971.62,
        "temperature": 0,
        "text": " which is a post to slash Muse.",
        "tokens": [
          51201,
          597,
          307,
          257,
          2183,
          281,
          17330,
          47293,
          13,
          51351
        ]
      },
      {
        "avg_logprob": -0.2204346443290141,
        "compression_ratio": 1.7294117647058824,
        "end": 3977.62,
        "id": 1209,
        "no_speech_prob": 0.0000126068352983566,
        "seek": 395488,
        "start": 3975.58,
        "temperature": 0,
        "text": " And that will have a body.",
        "tokens": [
          51399,
          400,
          300,
          486,
          362,
          257,
          1772,
          13,
          51501
        ]
      },
      {
        "avg_logprob": -0.2204346443290141,
        "compression_ratio": 1.7294117647058824,
        "end": 3979.38,
        "id": 1210,
        "no_speech_prob": 0.0000126068352983566,
        "seek": 395488,
        "start": 3977.62,
        "temperature": 0,
        "text": " It'll have like, what is your name?",
        "tokens": [
          51501,
          467,
          603,
          362,
          411,
          11,
          437,
          307,
          428,
          1315,
          30,
          51589
        ]
      },
      {
        "avg_logprob": -0.2204346443290141,
        "compression_ratio": 1.7294117647058824,
        "end": 3983.54,
        "id": 1211,
        "no_speech_prob": 0.0000126068352983566,
        "seek": 395488,
        "start": 3980.98,
        "temperature": 0,
        "text": " And it will have the contents.",
        "tokens": [
          51669,
          400,
          309,
          486,
          362,
          264,
          15768,
          13,
          51797
        ]
      },
      {
        "avg_logprob": -0.28897669695425726,
        "compression_ratio": 1.7518796992481203,
        "end": 3988.1800000000003,
        "id": 1212,
        "no_speech_prob": 0.000003500847924442496,
        "seek": 398488,
        "start": 3985.7000000000003,
        "temperature": 0,
        "text": " The server will receive that body.",
        "tokens": [
          50405,
          440,
          7154,
          486,
          4774,
          300,
          1772,
          13,
          50529
        ]
      },
      {
        "avg_logprob": -0.28897669695425726,
        "compression_ratio": 1.7518796992481203,
        "end": 3990.06,
        "id": 1213,
        "no_speech_prob": 0.000003500847924442496,
        "seek": 398488,
        "start": 3988.1800000000003,
        "temperature": 0,
        "text": " It'll parse it, it'll understand it.",
        "tokens": [
          50529,
          467,
          603,
          48377,
          309,
          11,
          309,
          603,
          1223,
          309,
          13,
          50623
        ]
      },
      {
        "avg_logprob": -0.28897669695425726,
        "compression_ratio": 1.7518796992481203,
        "end": 3992.94,
        "id": 1214,
        "no_speech_prob": 0.000003500847924442496,
        "seek": 398488,
        "start": 3990.06,
        "temperature": 0,
        "text": " It will then insert it into the database.",
        "tokens": [
          50623,
          467,
          486,
          550,
          8969,
          309,
          666,
          264,
          8149,
          13,
          50767
        ]
      },
      {
        "avg_logprob": -0.28897669695425726,
        "compression_ratio": 1.7518796992481203,
        "end": 3997.58,
        "id": 1215,
        "no_speech_prob": 0.000003500847924442496,
        "seek": 398488,
        "start": 3993.9,
        "temperature": 0,
        "text": " And then it will respond with the thing that was inserted.",
        "tokens": [
          50815,
          400,
          550,
          309,
          486,
          4196,
          365,
          264,
          551,
          300,
          390,
          27992,
          13,
          50999
        ]
      },
      {
        "avg_logprob": -0.28897669695425726,
        "compression_ratio": 1.7518796992481203,
        "end": 3999.58,
        "id": 1216,
        "no_speech_prob": 0.000003500847924442496,
        "seek": 398488,
        "start": 3997.58,
        "temperature": 0,
        "text": " And then our page, the way we've written the code,",
        "tokens": [
          50999,
          400,
          550,
          527,
          3028,
          11,
          264,
          636,
          321,
          600,
          3720,
          264,
          3089,
          11,
          51099
        ]
      },
      {
        "avg_logprob": -0.28897669695425726,
        "compression_ratio": 1.7518796992481203,
        "end": 4000.7000000000003,
        "id": 1217,
        "no_speech_prob": 0.000003500847924442496,
        "seek": 398488,
        "start": 3999.58,
        "temperature": 0,
        "text": " was that after that's done,",
        "tokens": [
          51099,
          390,
          300,
          934,
          300,
          311,
          1096,
          11,
          51155
        ]
      },
      {
        "avg_logprob": -0.28897669695425726,
        "compression_ratio": 1.7518796992481203,
        "end": 4003.94,
        "id": 1218,
        "no_speech_prob": 0.000003500847924442496,
        "seek": 398488,
        "start": 4000.7000000000003,
        "temperature": 0,
        "text": " it makes another request here to get all the latest ones",
        "tokens": [
          51155,
          309,
          1669,
          1071,
          5308,
          510,
          281,
          483,
          439,
          264,
          6792,
          2306,
          51317
        ]
      },
      {
        "avg_logprob": -0.28897669695425726,
        "compression_ratio": 1.7518796992481203,
        "end": 4005.94,
        "id": 1219,
        "no_speech_prob": 0.000003500847924442496,
        "seek": 398488,
        "start": 4003.94,
        "temperature": 0,
        "text": " and list those out on the page.",
        "tokens": [
          51317,
          293,
          1329,
          729,
          484,
          322,
          264,
          3028,
          13,
          51417
        ]
      },
      {
        "avg_logprob": -0.28897669695425726,
        "compression_ratio": 1.7518796992481203,
        "end": 4006.98,
        "id": 1220,
        "no_speech_prob": 0.000003500847924442496,
        "seek": 398488,
        "start": 4005.94,
        "temperature": 0,
        "text": " Cool, I think we've done it.",
        "tokens": [
          51417,
          8561,
          11,
          286,
          519,
          321,
          600,
          1096,
          309,
          13,
          51469
        ]
      },
      {
        "avg_logprob": -0.28897669695425726,
        "compression_ratio": 1.7518796992481203,
        "end": 4008.34,
        "id": 1221,
        "no_speech_prob": 0.000003500847924442496,
        "seek": 398488,
        "start": 4006.98,
        "temperature": 0,
        "text": " I think that's the app.",
        "tokens": [
          51469,
          286,
          519,
          300,
          311,
          264,
          724,
          13,
          51537
        ]
      },
      {
        "avg_logprob": -0.28897669695425726,
        "compression_ratio": 1.7518796992481203,
        "end": 4011.34,
        "id": 1222,
        "no_speech_prob": 0.000003500847924442496,
        "seek": 398488,
        "start": 4009.34,
        "temperature": 0,
        "text": " People are very, I don't know how,",
        "tokens": [
          51587,
          3432,
          366,
          588,
          11,
          286,
          500,
          380,
          458,
          577,
          11,
          51687
        ]
      },
      {
        "avg_logprob": -0.28897669695425726,
        "compression_ratio": 1.7518796992481203,
        "end": 4013.6600000000003,
        "id": 1223,
        "no_speech_prob": 0.000003500847924442496,
        "seek": 398488,
        "start": 4011.34,
        "temperature": 0,
        "text": " I don't mind staying a little longer.",
        "tokens": [
          51687,
          286,
          500,
          380,
          1575,
          7939,
          257,
          707,
          2854,
          13,
          51803
        ]
      },
      {
        "avg_logprob": -0.2836224003842002,
        "compression_ratio": 1.8005952380952381,
        "end": 4016.2,
        "id": 1224,
        "no_speech_prob": 0.0001022981814458035,
        "seek": 401366,
        "start": 4013.68,
        "temperature": 0,
        "text": " People are very interested at least in some tips",
        "tokens": [
          50365,
          3432,
          366,
          588,
          3102,
          412,
          1935,
          294,
          512,
          6082,
          50491
        ]
      },
      {
        "avg_logprob": -0.2836224003842002,
        "compression_ratio": 1.8005952380952381,
        "end": 4017.6,
        "id": 1225,
        "no_speech_prob": 0.0001022981814458035,
        "seek": 401366,
        "start": 4016.2,
        "temperature": 0,
        "text": " or how you would deploy it.",
        "tokens": [
          50491,
          420,
          577,
          291,
          576,
          7274,
          309,
          13,
          50561
        ]
      },
      {
        "avg_logprob": -0.2836224003842002,
        "compression_ratio": 1.8005952380952381,
        "end": 4020.48,
        "id": 1226,
        "no_speech_prob": 0.0001022981814458035,
        "seek": 401366,
        "start": 4017.6,
        "temperature": 0,
        "text": " Or if it's kind of a thing that we think we could do now,",
        "tokens": [
          50561,
          1610,
          498,
          309,
          311,
          733,
          295,
          257,
          551,
          300,
          321,
          519,
          321,
          727,
          360,
          586,
          11,
          50705
        ]
      },
      {
        "avg_logprob": -0.2836224003842002,
        "compression_ratio": 1.8005952380952381,
        "end": 4021.3199999999997,
        "id": 1227,
        "no_speech_prob": 0.0001022981814458035,
        "seek": 401366,
        "start": 4020.48,
        "temperature": 0,
        "text": " we could do it.",
        "tokens": [
          50705,
          321,
          727,
          360,
          309,
          13,
          50747
        ]
      },
      {
        "avg_logprob": -0.2836224003842002,
        "compression_ratio": 1.8005952380952381,
        "end": 4022.7999999999997,
        "id": 1228,
        "no_speech_prob": 0.0001022981814458035,
        "seek": 401366,
        "start": 4021.3199999999997,
        "temperature": 0,
        "text": " Okay, I mean, do I have 10 minutes?",
        "tokens": [
          50747,
          1033,
          11,
          286,
          914,
          11,
          360,
          286,
          362,
          1266,
          2077,
          30,
          50821
        ]
      },
      {
        "avg_logprob": -0.2836224003842002,
        "compression_ratio": 1.8005952380952381,
        "end": 4023.64,
        "id": 1229,
        "no_speech_prob": 0.0001022981814458035,
        "seek": 401366,
        "start": 4022.7999999999997,
        "temperature": 0,
        "text": " Yeah, let's do 10 minutes.",
        "tokens": [
          50821,
          865,
          11,
          718,
          311,
          360,
          1266,
          2077,
          13,
          50863
        ]
      },
      {
        "avg_logprob": -0.2836224003842002,
        "compression_ratio": 1.8005952380952381,
        "end": 4025.3599999999997,
        "id": 1230,
        "no_speech_prob": 0.0001022981814458035,
        "seek": 401366,
        "start": 4023.64,
        "temperature": 0,
        "text": " 10 minutes, okay, let's deploy, awesome.",
        "tokens": [
          50863,
          1266,
          2077,
          11,
          1392,
          11,
          718,
          311,
          7274,
          11,
          3476,
          13,
          50949
        ]
      },
      {
        "avg_logprob": -0.2836224003842002,
        "compression_ratio": 1.8005952380952381,
        "end": 4027.2,
        "id": 1231,
        "no_speech_prob": 0.0001022981814458035,
        "seek": 401366,
        "start": 4025.3599999999997,
        "temperature": 0,
        "text": " Because it's kind of, that's gives it a big,",
        "tokens": [
          50949,
          1436,
          309,
          311,
          733,
          295,
          11,
          300,
          311,
          2709,
          309,
          257,
          955,
          11,
          51041
        ]
      },
      {
        "avg_logprob": -0.2836224003842002,
        "compression_ratio": 1.8005952380952381,
        "end": 4029.12,
        "id": 1232,
        "no_speech_prob": 0.0001022981814458035,
        "seek": 401366,
        "start": 4027.2,
        "temperature": 0,
        "text": " that's just like the flourish at the end.",
        "tokens": [
          51041,
          300,
          311,
          445,
          411,
          264,
          38311,
          412,
          264,
          917,
          13,
          51137
        ]
      },
      {
        "avg_logprob": -0.2836224003842002,
        "compression_ratio": 1.8005952380952381,
        "end": 4029.96,
        "id": 1233,
        "no_speech_prob": 0.0001022981814458035,
        "seek": 401366,
        "start": 4029.12,
        "temperature": 0,
        "text": " Okay, awesome.",
        "tokens": [
          51137,
          1033,
          11,
          3476,
          13,
          51179
        ]
      },
      {
        "avg_logprob": -0.2836224003842002,
        "compression_ratio": 1.8005952380952381,
        "end": 4031.24,
        "id": 1234,
        "no_speech_prob": 0.0001022981814458035,
        "seek": 401366,
        "start": 4029.96,
        "temperature": 0,
        "text": " So yeah, and so we have this app.",
        "tokens": [
          51179,
          407,
          1338,
          11,
          293,
          370,
          321,
          362,
          341,
          724,
          13,
          51243
        ]
      },
      {
        "avg_logprob": -0.2836224003842002,
        "compression_ratio": 1.8005952380952381,
        "end": 4034.3999999999996,
        "id": 1235,
        "no_speech_prob": 0.0001022981814458035,
        "seek": 401366,
        "start": 4031.24,
        "temperature": 0,
        "text": " And now I will show how we put this out in the world.",
        "tokens": [
          51243,
          400,
          586,
          286,
          486,
          855,
          577,
          321,
          829,
          341,
          484,
          294,
          264,
          1002,
          13,
          51401
        ]
      },
      {
        "avg_logprob": -0.2836224003842002,
        "compression_ratio": 1.8005952380952381,
        "end": 4036.66,
        "id": 1236,
        "no_speech_prob": 0.0001022981814458035,
        "seek": 401366,
        "start": 4034.3999999999996,
        "temperature": 0,
        "text": " And then all of the wonderful people that are watching",
        "tokens": [
          51401,
          400,
          550,
          439,
          295,
          264,
          3715,
          561,
          300,
          366,
          1976,
          51514
        ]
      },
      {
        "avg_logprob": -0.2836224003842002,
        "compression_ratio": 1.8005952380952381,
        "end": 4038.72,
        "id": 1237,
        "no_speech_prob": 0.0001022981814458035,
        "seek": 401366,
        "start": 4036.66,
        "temperature": 0,
        "text": " can submit their Muse and we'll be able to see them.",
        "tokens": [
          51514,
          393,
          10315,
          641,
          47293,
          293,
          321,
          603,
          312,
          1075,
          281,
          536,
          552,
          13,
          51617
        ]
      },
      {
        "avg_logprob": -0.2836224003842002,
        "compression_ratio": 1.8005952380952381,
        "end": 4039.96,
        "id": 1238,
        "no_speech_prob": 0.0001022981814458035,
        "seek": 401366,
        "start": 4038.72,
        "temperature": 0,
        "text": " So I guess before I do that,",
        "tokens": [
          51617,
          407,
          286,
          2041,
          949,
          286,
          360,
          300,
          11,
          51679
        ]
      },
      {
        "avg_logprob": -0.2836224003842002,
        "compression_ratio": 1.8005952380952381,
        "end": 4041.48,
        "id": 1239,
        "no_speech_prob": 0.0001022981814458035,
        "seek": 401366,
        "start": 4039.96,
        "temperature": 0,
        "text": " I do want to add these,",
        "tokens": [
          51679,
          286,
          360,
          528,
          281,
          909,
          613,
          11,
          51755
        ]
      },
      {
        "avg_logprob": -0.29870352008998796,
        "compression_ratio": 1.8041958041958042,
        "end": 4044.58,
        "id": 1240,
        "no_speech_prob": 0.000055620312195969746,
        "seek": 404148,
        "start": 4041.7,
        "temperature": 0,
        "text": " the bad words and filter and the express rate limit.",
        "tokens": [
          50375,
          264,
          1578,
          2283,
          293,
          6608,
          293,
          264,
          5109,
          3314,
          4948,
          13,
          50519
        ]
      },
      {
        "avg_logprob": -0.29870352008998796,
        "compression_ratio": 1.8041958041958042,
        "end": 4049.3,
        "id": 1241,
        "no_speech_prob": 0.000055620312195969746,
        "seek": 404148,
        "start": 4044.58,
        "temperature": 0,
        "text": " So there is a package on npm called bad words.",
        "tokens": [
          50519,
          407,
          456,
          307,
          257,
          7372,
          322,
          297,
          14395,
          1219,
          1578,
          2283,
          13,
          50755
        ]
      },
      {
        "avg_logprob": -0.29870352008998796,
        "compression_ratio": 1.8041958041958042,
        "end": 4051.58,
        "id": 1242,
        "no_speech_prob": 0.000055620312195969746,
        "seek": 404148,
        "start": 4049.3,
        "temperature": 0,
        "text": " So I'm going to install that.",
        "tokens": [
          50755,
          407,
          286,
          478,
          516,
          281,
          3625,
          300,
          13,
          50869
        ]
      },
      {
        "avg_logprob": -0.29870352008998796,
        "compression_ratio": 1.8041958041958042,
        "end": 4052.82,
        "id": 1243,
        "no_speech_prob": 0.000055620312195969746,
        "seek": 404148,
        "start": 4051.58,
        "temperature": 0,
        "text": " There's another one that I use",
        "tokens": [
          50869,
          821,
          311,
          1071,
          472,
          300,
          286,
          764,
          50931
        ]
      },
      {
        "avg_logprob": -0.29870352008998796,
        "compression_ratio": 1.8041958041958042,
        "end": 4054.38,
        "id": 1244,
        "no_speech_prob": 0.000055620312195969746,
        "seek": 404148,
        "start": 4052.82,
        "temperature": 0,
        "text": " that's called like word filter or something.",
        "tokens": [
          50931,
          300,
          311,
          1219,
          411,
          1349,
          6608,
          420,
          746,
          13,
          51009
        ]
      },
      {
        "avg_logprob": -0.29870352008998796,
        "compression_ratio": 1.8041958041958042,
        "end": 4055.86,
        "id": 1245,
        "no_speech_prob": 0.000055620312195969746,
        "seek": 404148,
        "start": 4054.38,
        "temperature": 0,
        "text": " But this, you just go ahead to this one.",
        "tokens": [
          51009,
          583,
          341,
          11,
          291,
          445,
          352,
          2286,
          281,
          341,
          472,
          13,
          51083
        ]
      },
      {
        "avg_logprob": -0.29870352008998796,
        "compression_ratio": 1.8041958041958042,
        "end": 4057.62,
        "id": 1246,
        "no_speech_prob": 0.000055620312195969746,
        "seek": 404148,
        "start": 4055.86,
        "temperature": 0,
        "text": " But it's interesting to note there are a bunch of these.",
        "tokens": [
          51083,
          583,
          309,
          311,
          1880,
          281,
          3637,
          456,
          366,
          257,
          3840,
          295,
          613,
          13,
          51171
        ]
      },
      {
        "avg_logprob": -0.29870352008998796,
        "compression_ratio": 1.8041958041958042,
        "end": 4059.7,
        "id": 1247,
        "no_speech_prob": 0.000055620312195969746,
        "seek": 404148,
        "start": 4057.62,
        "temperature": 0,
        "text": " Yeah, and I just found this the other day",
        "tokens": [
          51171,
          865,
          11,
          293,
          286,
          445,
          1352,
          341,
          264,
          661,
          786,
          51275
        ]
      },
      {
        "avg_logprob": -0.29870352008998796,
        "compression_ratio": 1.8041958041958042,
        "end": 4061.86,
        "id": 1248,
        "no_speech_prob": 0.000055620312195969746,
        "seek": 404148,
        "start": 4059.7,
        "temperature": 0,
        "text": " just by searching like profanity.",
        "tokens": [
          51275,
          445,
          538,
          10808,
          411,
          1740,
          282,
          507,
          13,
          51383
        ]
      },
      {
        "avg_logprob": -0.29870352008998796,
        "compression_ratio": 1.8041958041958042,
        "end": 4065.02,
        "id": 1249,
        "no_speech_prob": 0.000055620312195969746,
        "seek": 404148,
        "start": 4061.86,
        "temperature": 0,
        "text": " And people have a simple list of how to do this.",
        "tokens": [
          51383,
          400,
          561,
          362,
          257,
          2199,
          1329,
          295,
          577,
          281,
          360,
          341,
          13,
          51541
        ]
      },
      {
        "avg_logprob": -0.29870352008998796,
        "compression_ratio": 1.8041958041958042,
        "end": 4066.78,
        "id": 1250,
        "no_speech_prob": 0.000055620312195969746,
        "seek": 404148,
        "start": 4065.02,
        "temperature": 0,
        "text": " Well, not how to, they have a simple list of words",
        "tokens": [
          51541,
          1042,
          11,
          406,
          577,
          281,
          11,
          436,
          362,
          257,
          2199,
          1329,
          295,
          2283,
          51629
        ]
      },
      {
        "avg_logprob": -0.29870352008998796,
        "compression_ratio": 1.8041958041958042,
        "end": 4068.84,
        "id": 1251,
        "no_speech_prob": 0.000055620312195969746,
        "seek": 404148,
        "start": 4066.78,
        "temperature": 0,
        "text": " that you can just add into your app.",
        "tokens": [
          51629,
          300,
          291,
          393,
          445,
          909,
          666,
          428,
          724,
          13,
          51732
        ]
      },
      {
        "avg_logprob": -0.23082940331820784,
        "compression_ratio": 1.8,
        "end": 4070.9,
        "id": 1252,
        "no_speech_prob": 0.000006540420599776553,
        "seek": 406884,
        "start": 4068.86,
        "temperature": 0,
        "text": " So we'll bring it in.",
        "tokens": [
          50365,
          407,
          321,
          603,
          1565,
          309,
          294,
          13,
          50467
        ]
      },
      {
        "avg_logprob": -0.23082940331820784,
        "compression_ratio": 1.8,
        "end": 4073.1400000000003,
        "id": 1253,
        "no_speech_prob": 0.000006540420599776553,
        "seek": 406884,
        "start": 4070.9,
        "temperature": 0,
        "text": " And then anytime we insert something in,",
        "tokens": [
          50467,
          400,
          550,
          13038,
          321,
          8969,
          746,
          294,
          11,
          50579
        ]
      },
      {
        "avg_logprob": -0.23082940331820784,
        "compression_ratio": 1.8,
        "end": 4075.5,
        "id": 1254,
        "no_speech_prob": 0.000006540420599776553,
        "seek": 406884,
        "start": 4073.1400000000003,
        "temperature": 0,
        "text": " we'll just clean it to get rid of any potential bad things.",
        "tokens": [
          50579,
          321,
          603,
          445,
          2541,
          309,
          281,
          483,
          3973,
          295,
          604,
          3995,
          1578,
          721,
          13,
          50697
        ]
      },
      {
        "avg_logprob": -0.23082940331820784,
        "compression_ratio": 1.8,
        "end": 4077.98,
        "id": 1255,
        "no_speech_prob": 0.000006540420599776553,
        "seek": 406884,
        "start": 4075.5,
        "temperature": 0,
        "text": " So this is going to be on the server side.",
        "tokens": [
          50697,
          407,
          341,
          307,
          516,
          281,
          312,
          322,
          264,
          7154,
          1252,
          13,
          50821
        ]
      },
      {
        "avg_logprob": -0.23082940331820784,
        "compression_ratio": 1.8,
        "end": 4080.46,
        "id": 1256,
        "no_speech_prob": 0.000006540420599776553,
        "seek": 406884,
        "start": 4077.98,
        "temperature": 0,
        "text": " Let's bring in filter.",
        "tokens": [
          50821,
          961,
          311,
          1565,
          294,
          6608,
          13,
          50945
        ]
      },
      {
        "avg_logprob": -0.23082940331820784,
        "compression_ratio": 1.8,
        "end": 4084.42,
        "id": 1257,
        "no_speech_prob": 0.000006540420599776553,
        "seek": 406884,
        "start": 4081.5,
        "temperature": 0,
        "text": " And then we will create a filter.",
        "tokens": [
          50997,
          400,
          550,
          321,
          486,
          1884,
          257,
          6608,
          13,
          51143
        ]
      },
      {
        "avg_logprob": -0.23082940331820784,
        "compression_ratio": 1.8,
        "end": 4087.86,
        "id": 1258,
        "no_speech_prob": 0.000006540420599776553,
        "seek": 406884,
        "start": 4085.86,
        "temperature": 0,
        "text": " Let's create a filter right here.",
        "tokens": [
          51215,
          961,
          311,
          1884,
          257,
          6608,
          558,
          510,
          13,
          51315
        ]
      },
      {
        "avg_logprob": -0.23082940331820784,
        "compression_ratio": 1.8,
        "end": 4091.26,
        "id": 1259,
        "no_speech_prob": 0.000006540420599776553,
        "seek": 406884,
        "start": 4088.7400000000002,
        "temperature": 0,
        "text": " And then before we insert it into the database,",
        "tokens": [
          51359,
          400,
          550,
          949,
          321,
          8969,
          309,
          666,
          264,
          8149,
          11,
          51485
        ]
      },
      {
        "avg_logprob": -0.23082940331820784,
        "compression_ratio": 1.8,
        "end": 4093.42,
        "id": 1260,
        "no_speech_prob": 0.000006540420599776553,
        "seek": 406884,
        "start": 4091.26,
        "temperature": 0,
        "text": " which is right here, we're creating the object.",
        "tokens": [
          51485,
          597,
          307,
          558,
          510,
          11,
          321,
          434,
          4084,
          264,
          2657,
          13,
          51593
        ]
      },
      {
        "avg_logprob": -0.23082940331820784,
        "compression_ratio": 1.8,
        "end": 4095.1400000000003,
        "id": 1261,
        "no_speech_prob": 0.000006540420599776553,
        "seek": 406884,
        "start": 4093.42,
        "temperature": 0,
        "text": " I'm just going to do filter.clean.",
        "tokens": [
          51593,
          286,
          478,
          445,
          516,
          281,
          360,
          6608,
          13,
          2160,
          282,
          13,
          51679
        ]
      },
      {
        "avg_logprob": -0.21131933936777042,
        "compression_ratio": 1.7115384615384615,
        "end": 4098.8,
        "id": 1262,
        "no_speech_prob": 0.000004637863185052993,
        "seek": 409514,
        "start": 4095.96,
        "temperature": 0,
        "text": " And I want to do this on the name",
        "tokens": [
          50405,
          400,
          286,
          528,
          281,
          360,
          341,
          322,
          264,
          1315,
          50547
        ]
      },
      {
        "avg_logprob": -0.21131933936777042,
        "compression_ratio": 1.7115384615384615,
        "end": 4100.46,
        "id": 1263,
        "no_speech_prob": 0.000004637863185052993,
        "seek": 409514,
        "start": 4098.8,
        "temperature": 0,
        "text": " and then also on the content.",
        "tokens": [
          50547,
          293,
          550,
          611,
          322,
          264,
          2701,
          13,
          50630
        ]
      },
      {
        "avg_logprob": -0.21131933936777042,
        "compression_ratio": 1.7115384615384615,
        "end": 4106.96,
        "id": 1264,
        "no_speech_prob": 0.000004637863185052993,
        "seek": 409514,
        "start": 4103.2,
        "temperature": 0,
        "text": " Cool, so in theory, this should work.",
        "tokens": [
          50767,
          8561,
          11,
          370,
          294,
          5261,
          11,
          341,
          820,
          589,
          13,
          50955
        ]
      },
      {
        "avg_logprob": -0.21131933936777042,
        "compression_ratio": 1.7115384615384615,
        "end": 4108.28,
        "id": 1265,
        "no_speech_prob": 0.000004637863185052993,
        "seek": 409514,
        "start": 4106.96,
        "temperature": 0,
        "text": " I don't want to type bad words on screen,",
        "tokens": [
          50955,
          286,
          500,
          380,
          528,
          281,
          2010,
          1578,
          2283,
          322,
          2568,
          11,
          51021
        ]
      },
      {
        "avg_logprob": -0.21131933936777042,
        "compression_ratio": 1.7115384615384615,
        "end": 4110.42,
        "id": 1266,
        "no_speech_prob": 0.000004637863185052993,
        "seek": 409514,
        "start": 4108.28,
        "temperature": 0,
        "text": " but it actually will filter it out",
        "tokens": [
          51021,
          457,
          309,
          767,
          486,
          6608,
          309,
          484,
          51128
        ]
      },
      {
        "avg_logprob": -0.21131933936777042,
        "compression_ratio": 1.7115384615384615,
        "end": 4111.44,
        "id": 1267,
        "no_speech_prob": 0.000004637863185052993,
        "seek": 409514,
        "start": 4110.42,
        "temperature": 0,
        "text": " and put like stars in there.",
        "tokens": [
          51128,
          293,
          829,
          411,
          6105,
          294,
          456,
          13,
          51179
        ]
      },
      {
        "avg_logprob": -0.21131933936777042,
        "compression_ratio": 1.7115384615384615,
        "end": 4114.44,
        "id": 1268,
        "no_speech_prob": 0.000004637863185052993,
        "seek": 409514,
        "start": 4111.44,
        "temperature": 0,
        "text": " So as long as the server's still running, yeah, we're good.",
        "tokens": [
          51179,
          407,
          382,
          938,
          382,
          264,
          7154,
          311,
          920,
          2614,
          11,
          1338,
          11,
          321,
          434,
          665,
          13,
          51329
        ]
      },
      {
        "avg_logprob": -0.21131933936777042,
        "compression_ratio": 1.7115384615384615,
        "end": 4115.72,
        "id": 1269,
        "no_speech_prob": 0.000004637863185052993,
        "seek": 409514,
        "start": 4114.44,
        "temperature": 0,
        "text": " The other thing is rate limiting.",
        "tokens": [
          51329,
          440,
          661,
          551,
          307,
          3314,
          22083,
          13,
          51393
        ]
      },
      {
        "avg_logprob": -0.21131933936777042,
        "compression_ratio": 1.7115384615384615,
        "end": 4118.82,
        "id": 1270,
        "no_speech_prob": 0.000004637863185052993,
        "seek": 409514,
        "start": 4115.72,
        "temperature": 0,
        "text": " So I want to make sure that people can't just submit",
        "tokens": [
          51393,
          407,
          286,
          528,
          281,
          652,
          988,
          300,
          561,
          393,
          380,
          445,
          10315,
          51548
        ]
      },
      {
        "avg_logprob": -0.21131933936777042,
        "compression_ratio": 1.7115384615384615,
        "end": 4121,
        "id": 1271,
        "no_speech_prob": 0.000004637863185052993,
        "seek": 409514,
        "start": 4118.82,
        "temperature": 0,
        "text": " thousands and thousands of requests over and over.",
        "tokens": [
          51548,
          5383,
          293,
          5383,
          295,
          12475,
          670,
          293,
          670,
          13,
          51657
        ]
      },
      {
        "avg_logprob": -0.21131933936777042,
        "compression_ratio": 1.7115384615384615,
        "end": 4123.599999999999,
        "id": 1272,
        "no_speech_prob": 0.000004637863185052993,
        "seek": 409514,
        "start": 4121,
        "temperature": 0,
        "text": " So I'm going to use express rate limit.",
        "tokens": [
          51657,
          407,
          286,
          478,
          516,
          281,
          764,
          5109,
          3314,
          4948,
          13,
          51787
        ]
      },
      {
        "avg_logprob": -0.24042481642503005,
        "compression_ratio": 1.6226415094339623,
        "end": 4125.5,
        "id": 1273,
        "no_speech_prob": 0.000016442450942122377,
        "seek": 412360,
        "start": 4123.620000000001,
        "temperature": 0,
        "text": " So let's install this.",
        "tokens": [
          50365,
          407,
          718,
          311,
          3625,
          341,
          13,
          50459
        ]
      },
      {
        "avg_logprob": -0.24042481642503005,
        "compression_ratio": 1.6226415094339623,
        "end": 4134.26,
        "id": 1274,
        "no_speech_prob": 0.000016442450942122377,
        "seek": 412360,
        "start": 4132.38,
        "temperature": 0,
        "text": " And now that we have it, we'll use it.",
        "tokens": [
          50803,
          400,
          586,
          300,
          321,
          362,
          309,
          11,
          321,
          603,
          764,
          309,
          13,
          50897
        ]
      },
      {
        "avg_logprob": -0.24042481642503005,
        "compression_ratio": 1.6226415094339623,
        "end": 4136.620000000001,
        "id": 1275,
        "no_speech_prob": 0.000016442450942122377,
        "seek": 412360,
        "start": 4134.26,
        "temperature": 0,
        "text": " I'll look on npm to see how to use it.",
        "tokens": [
          50897,
          286,
          603,
          574,
          322,
          297,
          14395,
          281,
          536,
          577,
          281,
          764,
          309,
          13,
          51015
        ]
      },
      {
        "avg_logprob": -0.24042481642503005,
        "compression_ratio": 1.6226415094339623,
        "end": 4138.14,
        "id": 1276,
        "no_speech_prob": 0.000016442450942122377,
        "seek": 412360,
        "start": 4136.620000000001,
        "temperature": 0,
        "text": " Express rate limit.",
        "tokens": [
          51015,
          20212,
          3314,
          4948,
          13,
          51091
        ]
      },
      {
        "avg_logprob": -0.24042481642503005,
        "compression_ratio": 1.6226415094339623,
        "end": 4140.72,
        "id": 1277,
        "no_speech_prob": 0.000016442450942122377,
        "seek": 412360,
        "start": 4138.14,
        "temperature": 0,
        "text": " And basically this one is based on IP address.",
        "tokens": [
          51091,
          400,
          1936,
          341,
          472,
          307,
          2361,
          322,
          8671,
          2985,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.24042481642503005,
        "compression_ratio": 1.6226415094339623,
        "end": 4142.1,
        "id": 1278,
        "no_speech_prob": 0.000016442450942122377,
        "seek": 412360,
        "start": 4140.72,
        "temperature": 0,
        "text": " There are other rate limiting packages",
        "tokens": [
          51220,
          821,
          366,
          661,
          3314,
          22083,
          17401,
          51289
        ]
      },
      {
        "avg_logprob": -0.24042481642503005,
        "compression_ratio": 1.6226415094339623,
        "end": 4144.34,
        "id": 1279,
        "no_speech_prob": 0.000016442450942122377,
        "seek": 412360,
        "start": 4142.1,
        "temperature": 0,
        "text": " that will actually use a database to keep track of users",
        "tokens": [
          51289,
          300,
          486,
          767,
          764,
          257,
          8149,
          281,
          1066,
          2837,
          295,
          5022,
          51401
        ]
      },
      {
        "avg_logprob": -0.24042481642503005,
        "compression_ratio": 1.6226415094339623,
        "end": 4146.04,
        "id": 1280,
        "no_speech_prob": 0.000016442450942122377,
        "seek": 412360,
        "start": 4144.34,
        "temperature": 0,
        "text": " that have visited your website.",
        "tokens": [
          51401,
          300,
          362,
          11220,
          428,
          3144,
          13,
          51486
        ]
      },
      {
        "avg_logprob": -0.24042481642503005,
        "compression_ratio": 1.6226415094339623,
        "end": 4147.860000000001,
        "id": 1281,
        "no_speech_prob": 0.000016442450942122377,
        "seek": 412360,
        "start": 4146.04,
        "temperature": 0,
        "text": " So this is how we do it.",
        "tokens": [
          51486,
          407,
          341,
          307,
          577,
          321,
          360,
          309,
          13,
          51577
        ]
      },
      {
        "avg_logprob": -0.24042481642503005,
        "compression_ratio": 1.6226415094339623,
        "end": 4149.22,
        "id": 1282,
        "no_speech_prob": 0.000016442450942122377,
        "seek": 412360,
        "start": 4147.860000000001,
        "temperature": 0,
        "text": " We bring in rate limit.",
        "tokens": [
          51577,
          492,
          1565,
          294,
          3314,
          4948,
          13,
          51645
        ]
      },
      {
        "avg_logprob": -0.4080458361693103,
        "compression_ratio": 1.596244131455399,
        "end": 4152.16,
        "id": 1283,
        "no_speech_prob": 0.000001084514792637492,
        "seek": 414922,
        "start": 4150.22,
        "temperature": 0,
        "text": " And then we need to use it",
        "tokens": [
          50414,
          400,
          550,
          321,
          643,
          281,
          764,
          309,
          50511
        ]
      },
      {
        "avg_logprob": -0.4080458361693103,
        "compression_ratio": 1.596244131455399,
        "end": 4153.76,
        "id": 1284,
        "no_speech_prob": 0.000001084514792637492,
        "seek": 414922,
        "start": 4152.16,
        "temperature": 0,
        "text": " just like we did our other middleware.",
        "tokens": [
          50511,
          445,
          411,
          321,
          630,
          527,
          661,
          2808,
          3039,
          13,
          50591
        ]
      },
      {
        "avg_logprob": -0.4080458361693103,
        "compression_ratio": 1.596244131455399,
        "end": 4157.92,
        "id": 1285,
        "no_speech_prob": 0.000001084514792637492,
        "seek": 414922,
        "start": 4153.76,
        "temperature": 0,
        "text": " So I'll say app.use rate limit dot something.",
        "tokens": [
          50591,
          407,
          286,
          603,
          584,
          724,
          13,
          438,
          3314,
          4948,
          5893,
          746,
          13,
          50799
        ]
      },
      {
        "avg_logprob": -0.4080458361693103,
        "compression_ratio": 1.596244131455399,
        "end": 4159.64,
        "id": 1286,
        "no_speech_prob": 0.000001084514792637492,
        "seek": 414922,
        "start": 4157.92,
        "temperature": 0,
        "text": " So we actually invoke rate limit",
        "tokens": [
          50799,
          407,
          321,
          767,
          41117,
          3314,
          4948,
          50885
        ]
      },
      {
        "avg_logprob": -0.4080458361693103,
        "compression_ratio": 1.596244131455399,
        "end": 4162.76,
        "id": 1287,
        "no_speech_prob": 0.000001084514792637492,
        "seek": 414922,
        "start": 4159.64,
        "temperature": 0,
        "text": " with how often we want to rate limit.",
        "tokens": [
          50885,
          365,
          577,
          2049,
          321,
          528,
          281,
          3314,
          4948,
          13,
          51041
        ]
      },
      {
        "avg_logprob": -0.4080458361693103,
        "compression_ratio": 1.596244131455399,
        "end": 4165.88,
        "id": 1288,
        "no_speech_prob": 0.000001084514792637492,
        "seek": 414922,
        "start": 4162.76,
        "temperature": 0,
        "text": " So in this case, they're limiting it",
        "tokens": [
          51041,
          407,
          294,
          341,
          1389,
          11,
          436,
          434,
          22083,
          309,
          51197
        ]
      },
      {
        "avg_logprob": -0.4080458361693103,
        "compression_ratio": 1.596244131455399,
        "end": 4167.92,
        "id": 1289,
        "no_speech_prob": 0.000001084514792637492,
        "seek": 414922,
        "start": 4165.88,
        "temperature": 0,
        "text": " to 100 requests every 15 minutes.",
        "tokens": [
          51197,
          281,
          2319,
          12475,
          633,
          2119,
          2077,
          13,
          51299
        ]
      },
      {
        "avg_logprob": -0.4080458361693103,
        "compression_ratio": 1.596244131455399,
        "end": 4172.92,
        "id": 1290,
        "no_speech_prob": 0.000001084514792637492,
        "seek": 414922,
        "start": 4167.92,
        "temperature": 0,
        "text": " I'm going to let you do one request every 30 seconds.",
        "tokens": [
          51299,
          286,
          478,
          516,
          281,
          718,
          291,
          360,
          472,
          5308,
          633,
          2217,
          3949,
          13,
          51549
        ]
      },
      {
        "avg_logprob": -0.4080458361693103,
        "compression_ratio": 1.596244131455399,
        "end": 4175.68,
        "id": 1291,
        "no_speech_prob": 0.000001084514792637492,
        "seek": 414922,
        "start": 4173.96,
        "temperature": 0,
        "text": " I think this is in milliseconds.",
        "tokens": [
          51601,
          286,
          519,
          341,
          307,
          294,
          34184,
          13,
          51687
        ]
      },
      {
        "avg_logprob": -0.4796715777853261,
        "compression_ratio": 1.5940170940170941,
        "end": 4179.9800000000005,
        "id": 1292,
        "no_speech_prob": 0.000016964364476734772,
        "seek": 417568,
        "start": 4175.9800000000005,
        "temperature": 0,
        "text": " Yeah, so every 30 seconds, you can only submit one view.",
        "tokens": [
          50379,
          865,
          11,
          370,
          633,
          2217,
          3949,
          11,
          291,
          393,
          787,
          10315,
          472,
          1910,
          13,
          50579
        ]
      },
      {
        "avg_logprob": -0.4796715777853261,
        "compression_ratio": 1.5940170940170941,
        "end": 4180.820000000001,
        "id": 1293,
        "no_speech_prob": 0.000016964364476734772,
        "seek": 417568,
        "start": 4179.9800000000005,
        "temperature": 0,
        "text": " Should I go lower than that?",
        "tokens": [
          50579,
          6454,
          286,
          352,
          3126,
          813,
          300,
          30,
          50621
        ]
      },
      {
        "avg_logprob": -0.4796715777853261,
        "compression_ratio": 1.5940170940170941,
        "end": 4181.66,
        "id": 1294,
        "no_speech_prob": 0.000016964364476734772,
        "seek": 417568,
        "start": 4180.820000000001,
        "temperature": 0,
        "text": " What do you think?",
        "tokens": [
          50621,
          708,
          360,
          291,
          519,
          30,
          50663
        ]
      },
      {
        "avg_logprob": -0.4796715777853261,
        "compression_ratio": 1.5940170940170941,
        "end": 4182.4800000000005,
        "id": 1295,
        "no_speech_prob": 0.000016964364476734772,
        "seek": 417568,
        "start": 4181.66,
        "temperature": 0,
        "text": " Okay, cool.",
        "tokens": [
          50663,
          1033,
          11,
          1627,
          13,
          50704
        ]
      },
      {
        "avg_logprob": -0.4796715777853261,
        "compression_ratio": 1.5940170940170941,
        "end": 4185.900000000001,
        "id": 1296,
        "no_speech_prob": 0.000016964364476734772,
        "seek": 417568,
        "start": 4182.4800000000005,
        "temperature": 0,
        "text": " So every 30 seconds.",
        "tokens": [
          50704,
          407,
          633,
          2217,
          3949,
          13,
          50875
        ]
      },
      {
        "avg_logprob": -0.4796715777853261,
        "compression_ratio": 1.5940170940170941,
        "end": 4187.22,
        "id": 1297,
        "no_speech_prob": 0.000016964364476734772,
        "seek": 417568,
        "start": 4185.900000000001,
        "temperature": 0,
        "text": " Cool, and that should do it as well.",
        "tokens": [
          50875,
          8561,
          11,
          293,
          300,
          820,
          360,
          309,
          382,
          731,
          13,
          50941
        ]
      },
      {
        "avg_logprob": -0.4796715777853261,
        "compression_ratio": 1.5940170940170941,
        "end": 4190.14,
        "id": 1298,
        "no_speech_prob": 0.000016964364476734772,
        "seek": 417568,
        "start": 4187.22,
        "temperature": 0,
        "text": " So one thing that should happen is on the client side now,",
        "tokens": [
          50941,
          407,
          472,
          551,
          300,
          820,
          1051,
          307,
          322,
          264,
          6423,
          1252,
          586,
          11,
          51087
        ]
      },
      {
        "avg_logprob": -0.4796715777853261,
        "compression_ratio": 1.5940170940170941,
        "end": 4191.740000000001,
        "id": 1299,
        "no_speech_prob": 0.000016964364476734772,
        "seek": 417568,
        "start": 4190.14,
        "temperature": 0,
        "text": " if I try to submit something,",
        "tokens": [
          51087,
          498,
          286,
          853,
          281,
          10315,
          746,
          11,
          51167
        ]
      },
      {
        "avg_logprob": -0.4796715777853261,
        "compression_ratio": 1.5940170940170941,
        "end": 4197.62,
        "id": 1300,
        "no_speech_prob": 0.000016964364476734772,
        "seek": 417568,
        "start": 4194.22,
        "temperature": 0,
        "text": " and then send it, too many requests already.",
        "tokens": [
          51291,
          293,
          550,
          2845,
          309,
          11,
          886,
          867,
          12475,
          1217,
          13,
          51461
        ]
      },
      {
        "avg_logprob": -0.4796715777853261,
        "compression_ratio": 1.5940170940170941,
        "end": 4198.860000000001,
        "id": 1301,
        "no_speech_prob": 0.000016964364476734772,
        "seek": 417568,
        "start": 4197.62,
        "temperature": 0,
        "text": " Maybe I didn't specify this right.",
        "tokens": [
          51461,
          2704,
          286,
          994,
          380,
          16500,
          341,
          558,
          13,
          51523
        ]
      },
      {
        "avg_logprob": -0.4796715777853261,
        "compression_ratio": 1.5940170940170941,
        "end": 4202.9400000000005,
        "id": 1302,
        "no_speech_prob": 0.000016964364476734772,
        "seek": 417568,
        "start": 4198.860000000001,
        "temperature": 0,
        "text": " So if we look at one request,",
        "tokens": [
          51523,
          407,
          498,
          321,
          574,
          412,
          472,
          5308,
          11,
          51727
        ]
      },
      {
        "avg_logprob": -0.29092488970075336,
        "compression_ratio": 1.6482412060301508,
        "end": 4206.799999999999,
        "id": 1303,
        "no_speech_prob": 0.0000337372075591702,
        "seek": 420294,
        "start": 4202.96,
        "temperature": 0,
        "text": " so if we look at window milliseconds.",
        "tokens": [
          50365,
          370,
          498,
          321,
          574,
          412,
          4910,
          34184,
          13,
          50557
        ]
      },
      {
        "avg_logprob": -0.29092488970075336,
        "compression_ratio": 1.6482412060301508,
        "end": 4210.759999999999,
        "id": 1304,
        "no_speech_prob": 0.0000337372075591702,
        "seek": 420294,
        "start": 4206.799999999999,
        "temperature": 0,
        "text": " So 30 times 1,000 is 1,000 milliseconds?",
        "tokens": [
          50557,
          407,
          2217,
          1413,
          502,
          11,
          1360,
          307,
          502,
          11,
          1360,
          34184,
          30,
          50755
        ]
      },
      {
        "avg_logprob": -0.29092488970075336,
        "compression_ratio": 1.6482412060301508,
        "end": 4213.879999999999,
        "id": 1305,
        "no_speech_prob": 0.0000337372075591702,
        "seek": 420294,
        "start": 4210.759999999999,
        "temperature": 0,
        "text": " That's 30 seconds, 30,000 milliseconds.",
        "tokens": [
          50755,
          663,
          311,
          2217,
          3949,
          11,
          2217,
          11,
          1360,
          34184,
          13,
          50911
        ]
      },
      {
        "avg_logprob": -0.29092488970075336,
        "compression_ratio": 1.6482412060301508,
        "end": 4217.339999999999,
        "id": 1306,
        "no_speech_prob": 0.0000337372075591702,
        "seek": 420294,
        "start": 4214.879999999999,
        "temperature": 0,
        "text": " Okay, okay.",
        "tokens": [
          50961,
          1033,
          11,
          1392,
          13,
          51084
        ]
      },
      {
        "avg_logprob": -0.29092488970075336,
        "compression_ratio": 1.6482412060301508,
        "end": 4219.759999999999,
        "id": 1307,
        "no_speech_prob": 0.0000337372075591702,
        "seek": 420294,
        "start": 4218.919999999999,
        "temperature": 0,
        "text": " I think that's right.",
        "tokens": [
          51163,
          286,
          519,
          300,
          311,
          558,
          13,
          51205
        ]
      },
      {
        "avg_logprob": -0.29092488970075336,
        "compression_ratio": 1.6482412060301508,
        "end": 4220.599999999999,
        "id": 1308,
        "no_speech_prob": 0.0000337372075591702,
        "seek": 420294,
        "start": 4219.759999999999,
        "temperature": 0,
        "text": " Math is hard.",
        "tokens": [
          51205,
          15776,
          307,
          1152,
          13,
          51247
        ]
      },
      {
        "avg_logprob": -0.29092488970075336,
        "compression_ratio": 1.6482412060301508,
        "end": 4221.759999999999,
        "id": 1309,
        "no_speech_prob": 0.0000337372075591702,
        "seek": 420294,
        "start": 4220.599999999999,
        "temperature": 0,
        "text": " Math is hard.",
        "tokens": [
          51247,
          15776,
          307,
          1152,
          13,
          51305
        ]
      },
      {
        "avg_logprob": -0.29092488970075336,
        "compression_ratio": 1.6482412060301508,
        "end": 4224.16,
        "id": 1310,
        "no_speech_prob": 0.0000337372075591702,
        "seek": 420294,
        "start": 4221.759999999999,
        "temperature": 0,
        "text": " Okay, oh, you know what it is?",
        "tokens": [
          51305,
          1033,
          11,
          1954,
          11,
          291,
          458,
          437,
          309,
          307,
          30,
          51425
        ]
      },
      {
        "avg_logprob": -0.29092488970075336,
        "compression_ratio": 1.6482412060301508,
        "end": 4227.24,
        "id": 1311,
        "no_speech_prob": 0.0000337372075591702,
        "seek": 420294,
        "start": 4224.16,
        "temperature": 0,
        "text": " I think it was because, okay, so the page loaded.",
        "tokens": [
          51425,
          286,
          519,
          309,
          390,
          570,
          11,
          1392,
          11,
          370,
          264,
          3028,
          13210,
          13,
          51579
        ]
      },
      {
        "avg_logprob": -0.29092488970075336,
        "compression_ratio": 1.6482412060301508,
        "end": 4230.46,
        "id": 1312,
        "no_speech_prob": 0.0000337372075591702,
        "seek": 420294,
        "start": 4227.24,
        "temperature": 0,
        "text": " That was one request to get the list.",
        "tokens": [
          51579,
          663,
          390,
          472,
          5308,
          281,
          483,
          264,
          1329,
          13,
          51740
        ]
      },
      {
        "avg_logprob": -0.29092488970075336,
        "compression_ratio": 1.6482412060301508,
        "end": 4232.799999999999,
        "id": 1313,
        "no_speech_prob": 0.0000337372075591702,
        "seek": 420294,
        "start": 4231.5199999999995,
        "temperature": 0,
        "text": " And actually, so this is it.",
        "tokens": [
          51793,
          400,
          767,
          11,
          370,
          341,
          307,
          309,
          13,
          51857
        ]
      },
      {
        "avg_logprob": -0.2813213114835778,
        "compression_ratio": 1.7295373665480427,
        "end": 4236.46,
        "id": 1314,
        "no_speech_prob": 0.00037998330662958324,
        "seek": 423280,
        "start": 4233.62,
        "temperature": 0,
        "text": " I only want a rate limit adding to the server.",
        "tokens": [
          50405,
          286,
          787,
          528,
          257,
          3314,
          4948,
          5127,
          281,
          264,
          7154,
          13,
          50547
        ]
      },
      {
        "avg_logprob": -0.2813213114835778,
        "compression_ratio": 1.7295373665480427,
        "end": 4238.02,
        "id": 1315,
        "no_speech_prob": 0.00037998330662958324,
        "seek": 423280,
        "start": 4236.46,
        "temperature": 0,
        "text": " So you can request all day long.",
        "tokens": [
          50547,
          407,
          291,
          393,
          5308,
          439,
          786,
          938,
          13,
          50625
        ]
      },
      {
        "avg_logprob": -0.2813213114835778,
        "compression_ratio": 1.7295373665480427,
        "end": 4239.860000000001,
        "id": 1316,
        "no_speech_prob": 0.00037998330662958324,
        "seek": 423280,
        "start": 4238.02,
        "temperature": 0,
        "text": " You can make requests over and over and over again.",
        "tokens": [
          50625,
          509,
          393,
          652,
          12475,
          670,
          293,
          670,
          293,
          670,
          797,
          13,
          50717
        ]
      },
      {
        "avg_logprob": -0.2813213114835778,
        "compression_ratio": 1.7295373665480427,
        "end": 4240.7,
        "id": 1317,
        "no_speech_prob": 0.00037998330662958324,
        "seek": 423280,
        "start": 4239.860000000001,
        "temperature": 0,
        "text": " That's fine.",
        "tokens": [
          50717,
          663,
          311,
          2489,
          13,
          50759
        ]
      },
      {
        "avg_logprob": -0.2813213114835778,
        "compression_ratio": 1.7295373665480427,
        "end": 4243.34,
        "id": 1318,
        "no_speech_prob": 0.00037998330662958324,
        "seek": 423280,
        "start": 4240.7,
        "temperature": 0,
        "text": " But actually, submitting one,",
        "tokens": [
          50759,
          583,
          767,
          11,
          31836,
          472,
          11,
          50891
        ]
      },
      {
        "avg_logprob": -0.2813213114835778,
        "compression_ratio": 1.7295373665480427,
        "end": 4244.52,
        "id": 1319,
        "no_speech_prob": 0.00037998330662958324,
        "seek": 423280,
        "start": 4243.34,
        "temperature": 0,
        "text": " that's what I want a rate limit.",
        "tokens": [
          50891,
          300,
          311,
          437,
          286,
          528,
          257,
          3314,
          4948,
          13,
          50950
        ]
      },
      {
        "avg_logprob": -0.2813213114835778,
        "compression_ratio": 1.7295373665480427,
        "end": 4247.12,
        "id": 1320,
        "no_speech_prob": 0.00037998330662958324,
        "seek": 423280,
        "start": 4244.52,
        "temperature": 0,
        "text": " So by simply moving that app.use down,",
        "tokens": [
          50950,
          407,
          538,
          2935,
          2684,
          300,
          724,
          13,
          438,
          760,
          11,
          51080
        ]
      },
      {
        "avg_logprob": -0.2813213114835778,
        "compression_ratio": 1.7295373665480427,
        "end": 4249.54,
        "id": 1321,
        "no_speech_prob": 0.00037998330662958324,
        "seek": 423280,
        "start": 4247.12,
        "temperature": 0,
        "text": " this will now only rate limit creating views.",
        "tokens": [
          51080,
          341,
          486,
          586,
          787,
          3314,
          4948,
          4084,
          6809,
          13,
          51201
        ]
      },
      {
        "avg_logprob": -0.2813213114835778,
        "compression_ratio": 1.7295373665480427,
        "end": 4251.02,
        "id": 1322,
        "no_speech_prob": 0.00037998330662958324,
        "seek": 423280,
        "start": 4249.54,
        "temperature": 0,
        "text": " Okay, let's try it.",
        "tokens": [
          51201,
          1033,
          11,
          718,
          311,
          853,
          309,
          13,
          51275
        ]
      },
      {
        "avg_logprob": -0.2813213114835778,
        "compression_ratio": 1.7295373665480427,
        "end": 4252.3,
        "id": 1323,
        "no_speech_prob": 0.00037998330662958324,
        "seek": 423280,
        "start": 4251.02,
        "temperature": 0,
        "text": " So somehow I missed that.",
        "tokens": [
          51275,
          407,
          6063,
          286,
          6721,
          300,
          13,
          51339
        ]
      },
      {
        "avg_logprob": -0.2813213114835778,
        "compression_ratio": 1.7295373665480427,
        "end": 4255.3,
        "id": 1324,
        "no_speech_prob": 0.00037998330662958324,
        "seek": 423280,
        "start": 4252.3,
        "temperature": 0,
        "text": " By default, it rate limits everything.",
        "tokens": [
          51339,
          3146,
          7576,
          11,
          309,
          3314,
          10406,
          1203,
          13,
          51489
        ]
      },
      {
        "avg_logprob": -0.2813213114835778,
        "compression_ratio": 1.7295373665480427,
        "end": 4256.14,
        "id": 1325,
        "no_speech_prob": 0.00037998330662958324,
        "seek": 423280,
        "start": 4255.3,
        "temperature": 0,
        "text": " Everything, yes.",
        "tokens": [
          51489,
          5471,
          11,
          2086,
          13,
          51531
        ]
      },
      {
        "avg_logprob": -0.2813213114835778,
        "compression_ratio": 1.7295373665480427,
        "end": 4258.74,
        "id": 1326,
        "no_speech_prob": 0.00037998330662958324,
        "seek": 423280,
        "start": 4256.14,
        "temperature": 0,
        "text": " And just where you put it in the code, change that.",
        "tokens": [
          51531,
          400,
          445,
          689,
          291,
          829,
          309,
          294,
          264,
          3089,
          11,
          1319,
          300,
          13,
          51661
        ]
      },
      {
        "avg_logprob": -0.2813213114835778,
        "compression_ratio": 1.7295373665480427,
        "end": 4260.900000000001,
        "id": 1327,
        "no_speech_prob": 0.00037998330662958324,
        "seek": 423280,
        "start": 4258.74,
        "temperature": 0,
        "text": " And so this has to do with middlewares.",
        "tokens": [
          51661,
          400,
          370,
          341,
          575,
          281,
          360,
          365,
          2808,
          4151,
          495,
          13,
          51769
        ]
      },
      {
        "avg_logprob": -0.2378317717533962,
        "compression_ratio": 1.725752508361204,
        "end": 4263.759999999999,
        "id": 1328,
        "no_speech_prob": 0.00031503572245128453,
        "seek": 426090,
        "start": 4260.9,
        "temperature": 0,
        "text": " So in Express, when you do app.use,",
        "tokens": [
          50364,
          407,
          294,
          20212,
          11,
          562,
          291,
          360,
          724,
          13,
          438,
          11,
          50507
        ]
      },
      {
        "avg_logprob": -0.2378317717533962,
        "compression_ratio": 1.725752508361204,
        "end": 4265.04,
        "id": 1329,
        "no_speech_prob": 0.00031503572245128453,
        "seek": 426090,
        "start": 4263.759999999999,
        "temperature": 0,
        "text": " you can think of it as just a waterfall.",
        "tokens": [
          50507,
          291,
          393,
          519,
          295,
          309,
          382,
          445,
          257,
          27848,
          13,
          50571
        ]
      },
      {
        "avg_logprob": -0.2378317717533962,
        "compression_ratio": 1.725752508361204,
        "end": 4265.879999999999,
        "id": 1330,
        "no_speech_prob": 0.00031503572245128453,
        "seek": 426090,
        "start": 4265.04,
        "temperature": 0,
        "text": " It's top-down.",
        "tokens": [
          50571,
          467,
          311,
          1192,
          12,
          5093,
          13,
          50613
        ]
      },
      {
        "avg_logprob": -0.2378317717533962,
        "compression_ratio": 1.725752508361204,
        "end": 4268.759999999999,
        "id": 1331,
        "no_speech_prob": 0.00031503572245128453,
        "seek": 426090,
        "start": 4265.879999999999,
        "temperature": 0,
        "text": " So every request coming into our app hits cores,",
        "tokens": [
          50613,
          407,
          633,
          5308,
          1348,
          666,
          527,
          724,
          8664,
          24826,
          11,
          50757
        ]
      },
      {
        "avg_logprob": -0.2378317717533962,
        "compression_ratio": 1.725752508361204,
        "end": 4270.2,
        "id": 1332,
        "no_speech_prob": 0.00031503572245128453,
        "seek": 426090,
        "start": 4268.759999999999,
        "temperature": 0,
        "text": " then it hits the JSON parser,",
        "tokens": [
          50757,
          550,
          309,
          8664,
          264,
          31828,
          21156,
          260,
          11,
          50829
        ]
      },
      {
        "avg_logprob": -0.2378317717533962,
        "compression_ratio": 1.725752508361204,
        "end": 4271.639999999999,
        "id": 1333,
        "no_speech_prob": 0.00031503572245128453,
        "seek": 426090,
        "start": 4270.2,
        "temperature": 0,
        "text": " then it hits the rate limit.",
        "tokens": [
          50829,
          550,
          309,
          8664,
          264,
          3314,
          4948,
          13,
          50901
        ]
      },
      {
        "avg_logprob": -0.2378317717533962,
        "compression_ratio": 1.725752508361204,
        "end": 4275.639999999999,
        "id": 1334,
        "no_speech_prob": 0.00031503572245128453,
        "seek": 426090,
        "start": 4271.639999999999,
        "temperature": 0,
        "text": " But if we move it, now when a request for Muse comes in,",
        "tokens": [
          50901,
          583,
          498,
          321,
          1286,
          309,
          11,
          586,
          562,
          257,
          5308,
          337,
          47293,
          1487,
          294,
          11,
          51101
        ]
      },
      {
        "avg_logprob": -0.2378317717533962,
        "compression_ratio": 1.725752508361204,
        "end": 4278.7,
        "id": 1335,
        "no_speech_prob": 0.00031503572245128453,
        "seek": 426090,
        "start": 4275.639999999999,
        "temperature": 0,
        "text": " it basically hits this before it ever hits the rate limiter.",
        "tokens": [
          51101,
          309,
          1936,
          8664,
          341,
          949,
          309,
          1562,
          8664,
          264,
          3314,
          2364,
          1681,
          13,
          51254
        ]
      },
      {
        "avg_logprob": -0.2378317717533962,
        "compression_ratio": 1.725752508361204,
        "end": 4279.54,
        "id": 1336,
        "no_speech_prob": 0.00031503572245128453,
        "seek": 426090,
        "start": 4278.7,
        "temperature": 0,
        "text": " Got it.",
        "tokens": [
          51254,
          5803,
          309,
          13,
          51296
        ]
      },
      {
        "avg_logprob": -0.2378317717533962,
        "compression_ratio": 1.725752508361204,
        "end": 4280.36,
        "id": 1337,
        "no_speech_prob": 0.00031503572245128453,
        "seek": 426090,
        "start": 4279.54,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          51296,
          1079,
          13,
          51337
        ]
      },
      {
        "avg_logprob": -0.2378317717533962,
        "compression_ratio": 1.725752508361204,
        "end": 4281.2,
        "id": 1338,
        "no_speech_prob": 0.00031503572245128453,
        "seek": 426090,
        "start": 4280.36,
        "temperature": 0,
        "text": " Ah, that makes sense.",
        "tokens": [
          51337,
          2438,
          11,
          300,
          1669,
          2020,
          13,
          51379
        ]
      },
      {
        "avg_logprob": -0.2378317717533962,
        "compression_ratio": 1.725752508361204,
        "end": 4282.2,
        "id": 1339,
        "no_speech_prob": 0.00031503572245128453,
        "seek": 426090,
        "start": 4281.2,
        "temperature": 0,
        "text": " Well, I did not realize that",
        "tokens": [
          51379,
          1042,
          11,
          286,
          630,
          406,
          4325,
          300,
          51429
        ]
      },
      {
        "avg_logprob": -0.2378317717533962,
        "compression_ratio": 1.725752508361204,
        "end": 4284.16,
        "id": 1340,
        "no_speech_prob": 0.00031503572245128453,
        "seek": 426090,
        "start": 4282.2,
        "temperature": 0,
        "text": " because I think of everything as asynchronous,",
        "tokens": [
          51429,
          570,
          286,
          519,
          295,
          1203,
          382,
          49174,
          11,
          51527
        ]
      },
      {
        "avg_logprob": -0.2378317717533962,
        "compression_ratio": 1.725752508361204,
        "end": 4285.5599999999995,
        "id": 1341,
        "no_speech_prob": 0.00031503572245128453,
        "seek": 426090,
        "start": 4284.16,
        "temperature": 0,
        "text": " so the order doesn't matter.",
        "tokens": [
          51527,
          370,
          264,
          1668,
          1177,
          380,
          1871,
          13,
          51597
        ]
      },
      {
        "avg_logprob": -0.2378317717533962,
        "compression_ratio": 1.725752508361204,
        "end": 4288.879999999999,
        "id": 1342,
        "no_speech_prob": 0.00031503572245128453,
        "seek": 426090,
        "start": 4285.5599999999995,
        "temperature": 0,
        "text": " So the order basically only matters when the app spins up.",
        "tokens": [
          51597,
          407,
          264,
          1668,
          1936,
          787,
          7001,
          562,
          264,
          724,
          31587,
          493,
          13,
          51763
        ]
      },
      {
        "avg_logprob": -0.23825655336733217,
        "compression_ratio": 1.6363636363636365,
        "end": 4291.7,
        "id": 1343,
        "no_speech_prob": 0.000038228987250477076,
        "seek": 428888,
        "start": 4288.88,
        "temperature": 0,
        "text": " And so it creates this ordered list of things to run.",
        "tokens": [
          50364,
          400,
          370,
          309,
          7829,
          341,
          8866,
          1329,
          295,
          721,
          281,
          1190,
          13,
          50505
        ]
      },
      {
        "avg_logprob": -0.23825655336733217,
        "compression_ratio": 1.6363636363636365,
        "end": 4292.74,
        "id": 1344,
        "no_speech_prob": 0.000038228987250477076,
        "seek": 428888,
        "start": 4291.7,
        "temperature": 0,
        "text": " Okay, so that should do it.",
        "tokens": [
          50505,
          1033,
          11,
          370,
          300,
          820,
          360,
          309,
          13,
          50557
        ]
      },
      {
        "avg_logprob": -0.23825655336733217,
        "compression_ratio": 1.6363636363636365,
        "end": 4294.96,
        "id": 1345,
        "no_speech_prob": 0.000038228987250477076,
        "seek": 428888,
        "start": 4292.74,
        "temperature": 0,
        "text": " So now we can request the page all day long.",
        "tokens": [
          50557,
          407,
          586,
          321,
          393,
          5308,
          264,
          3028,
          439,
          786,
          938,
          13,
          50668
        ]
      },
      {
        "avg_logprob": -0.23825655336733217,
        "compression_ratio": 1.6363636363636365,
        "end": 4297.96,
        "id": 1346,
        "no_speech_prob": 0.000038228987250477076,
        "seek": 428888,
        "start": 4294.96,
        "temperature": 0,
        "text": " But if I say my name is CJ and I say hello world, go.",
        "tokens": [
          50668,
          583,
          498,
          286,
          584,
          452,
          1315,
          307,
          42285,
          293,
          286,
          584,
          7751,
          1002,
          11,
          352,
          13,
          50818
        ]
      },
      {
        "avg_logprob": -0.23825655336733217,
        "compression_ratio": 1.6363636363636365,
        "end": 4303.7,
        "id": 1347,
        "no_speech_prob": 0.000038228987250477076,
        "seek": 428888,
        "start": 4300.4400000000005,
        "temperature": 0,
        "text": " So that submitted it, but if I try again within 30 seconds,",
        "tokens": [
          50942,
          407,
          300,
          14405,
          309,
          11,
          457,
          498,
          286,
          853,
          797,
          1951,
          2217,
          3949,
          11,
          51105
        ]
      },
      {
        "avg_logprob": -0.23825655336733217,
        "compression_ratio": 1.6363636363636365,
        "end": 4305.18,
        "id": 1348,
        "no_speech_prob": 0.000038228987250477076,
        "seek": 428888,
        "start": 4303.7,
        "temperature": 0,
        "text": " I get an error, too many requests.",
        "tokens": [
          51105,
          286,
          483,
          364,
          6713,
          11,
          886,
          867,
          12475,
          13,
          51179
        ]
      },
      {
        "avg_logprob": -0.23825655336733217,
        "compression_ratio": 1.6363636363636365,
        "end": 4306.5,
        "id": 1349,
        "no_speech_prob": 0.000038228987250477076,
        "seek": 428888,
        "start": 4305.18,
        "temperature": 0,
        "text": " So this is gonna prevent people",
        "tokens": [
          51179,
          407,
          341,
          307,
          799,
          4871,
          561,
          51245
        ]
      },
      {
        "avg_logprob": -0.23825655336733217,
        "compression_ratio": 1.6363636363636365,
        "end": 4308.86,
        "id": 1350,
        "no_speech_prob": 0.000038228987250477076,
        "seek": 428888,
        "start": 4306.5,
        "temperature": 0,
        "text": " from submitting too many things.",
        "tokens": [
          51245,
          490,
          31836,
          886,
          867,
          721,
          13,
          51363
        ]
      },
      {
        "avg_logprob": -0.23825655336733217,
        "compression_ratio": 1.6363636363636365,
        "end": 4310.14,
        "id": 1351,
        "no_speech_prob": 0.000038228987250477076,
        "seek": 428888,
        "start": 4308.86,
        "temperature": 0,
        "text": " And then one thing I'll do is,",
        "tokens": [
          51363,
          400,
          550,
          472,
          551,
          286,
          603,
          360,
          307,
          11,
          51427
        ]
      },
      {
        "avg_logprob": -0.23825655336733217,
        "compression_ratio": 1.6363636363636365,
        "end": 4312.54,
        "id": 1352,
        "no_speech_prob": 0.000038228987250477076,
        "seek": 428888,
        "start": 4310.14,
        "temperature": 0,
        "text": " instead of showing the form immediately on the client,",
        "tokens": [
          51427,
          2602,
          295,
          4099,
          264,
          1254,
          4258,
          322,
          264,
          6423,
          11,
          51547
        ]
      },
      {
        "avg_logprob": -0.23825655336733217,
        "compression_ratio": 1.6363636363636365,
        "end": 4315.12,
        "id": 1353,
        "no_speech_prob": 0.000038228987250477076,
        "seek": 428888,
        "start": 4312.54,
        "temperature": 0,
        "text": " is just wait 30 seconds before I show it.",
        "tokens": [
          51547,
          307,
          445,
          1699,
          2217,
          3949,
          949,
          286,
          855,
          309,
          13,
          51676
        ]
      },
      {
        "avg_logprob": -0.20250408737747758,
        "compression_ratio": 1.5246636771300448,
        "end": 4319.78,
        "id": 1354,
        "no_speech_prob": 0.000003446576556598302,
        "seek": 431512,
        "start": 4315.12,
        "temperature": 0,
        "text": " So after submitting is successful,",
        "tokens": [
          50364,
          407,
          934,
          31836,
          307,
          4406,
          11,
          50597
        ]
      },
      {
        "avg_logprob": -0.20250408737747758,
        "compression_ratio": 1.5246636771300448,
        "end": 4321.9,
        "id": 1355,
        "no_speech_prob": 0.000003446576556598302,
        "seek": 431512,
        "start": 4319.78,
        "temperature": 0,
        "text": " let's just do a set timeout.",
        "tokens": [
          50597,
          718,
          311,
          445,
          360,
          257,
          992,
          565,
          346,
          13,
          50703
        ]
      },
      {
        "avg_logprob": -0.20250408737747758,
        "compression_ratio": 1.5246636771300448,
        "end": 4326.24,
        "id": 1356,
        "no_speech_prob": 0.000003446576556598302,
        "seek": 431512,
        "start": 4321.9,
        "temperature": 0,
        "text": " And in 30 seconds, we'll unhide the form.",
        "tokens": [
          50703,
          400,
          294,
          2217,
          3949,
          11,
          321,
          603,
          517,
          71,
          482,
          264,
          1254,
          13,
          50920
        ]
      },
      {
        "avg_logprob": -0.20250408737747758,
        "compression_ratio": 1.5246636771300448,
        "end": 4332.34,
        "id": 1357,
        "no_speech_prob": 0.000003446576556598302,
        "seek": 431512,
        "start": 4327.58,
        "temperature": 0,
        "text": " Okay, so CJ, hello world, send.",
        "tokens": [
          50987,
          1033,
          11,
          370,
          42285,
          11,
          7751,
          1002,
          11,
          2845,
          13,
          51225
        ]
      },
      {
        "avg_logprob": -0.20250408737747758,
        "compression_ratio": 1.5246636771300448,
        "end": 4334.7,
        "id": 1358,
        "no_speech_prob": 0.000003446576556598302,
        "seek": 431512,
        "start": 4332.34,
        "temperature": 0,
        "text": " And then now in 30 seconds, that form will pop back up",
        "tokens": [
          51225,
          400,
          550,
          586,
          294,
          2217,
          3949,
          11,
          300,
          1254,
          486,
          1665,
          646,
          493,
          51343
        ]
      },
      {
        "avg_logprob": -0.20250408737747758,
        "compression_ratio": 1.5246636771300448,
        "end": 4336.5,
        "id": 1359,
        "no_speech_prob": 0.000003446576556598302,
        "seek": 431512,
        "start": 4334.7,
        "temperature": 0,
        "text": " and you can submit another one if you want to.",
        "tokens": [
          51343,
          293,
          291,
          393,
          10315,
          1071,
          472,
          498,
          291,
          528,
          281,
          13,
          51433
        ]
      },
      {
        "avg_logprob": -0.20250408737747758,
        "compression_ratio": 1.5246636771300448,
        "end": 4339.26,
        "id": 1360,
        "no_speech_prob": 0.000003446576556598302,
        "seek": 431512,
        "start": 4336.5,
        "temperature": 0,
        "text": " Okay, so I think we've done what we needed to do",
        "tokens": [
          51433,
          1033,
          11,
          370,
          286,
          519,
          321,
          600,
          1096,
          437,
          321,
          2978,
          281,
          360,
          51571
        ]
      },
      {
        "avg_logprob": -0.20250408737747758,
        "compression_ratio": 1.5246636771300448,
        "end": 4341.8,
        "id": 1361,
        "no_speech_prob": 0.000003446576556598302,
        "seek": 431512,
        "start": 4339.26,
        "temperature": 0,
        "text": " to get this thing ready to deploy.",
        "tokens": [
          51571,
          281,
          483,
          341,
          551,
          1919,
          281,
          7274,
          13,
          51698
        ]
      },
      {
        "avg_logprob": -0.20250408737747758,
        "compression_ratio": 1.5246636771300448,
        "end": 4342.7,
        "id": 1362,
        "no_speech_prob": 0.000003446576556598302,
        "seek": 431512,
        "start": 4341.8,
        "temperature": 0,
        "text": " Let's deploy it.",
        "tokens": [
          51698,
          961,
          311,
          7274,
          309,
          13,
          51743
        ]
      },
      {
        "avg_logprob": -0.28018759247055625,
        "compression_ratio": 1.7431906614785992,
        "end": 4347.8,
        "id": 1363,
        "no_speech_prob": 0.0000057719139476830605,
        "seek": 434270,
        "start": 4342.8,
        "temperature": 0,
        "text": " So first thing is set up environment variables.",
        "tokens": [
          50369,
          407,
          700,
          551,
          307,
          992,
          493,
          2823,
          9102,
          13,
          50619
        ]
      },
      {
        "avg_logprob": -0.28018759247055625,
        "compression_ratio": 1.7431906614785992,
        "end": 4350.44,
        "id": 1364,
        "no_speech_prob": 0.0000057719139476830605,
        "seek": 434270,
        "start": 4348.639999999999,
        "temperature": 0,
        "text": " So my server side, right now,",
        "tokens": [
          50661,
          407,
          452,
          7154,
          1252,
          11,
          558,
          586,
          11,
          50751
        ]
      },
      {
        "avg_logprob": -0.28018759247055625,
        "compression_ratio": 1.7431906614785992,
        "end": 4353.48,
        "id": 1365,
        "no_speech_prob": 0.0000057719139476830605,
        "seek": 434270,
        "start": 4350.44,
        "temperature": 0,
        "text": " it's only talking to localhost.yower.",
        "tokens": [
          50751,
          309,
          311,
          787,
          1417,
          281,
          2654,
          6037,
          13,
          88,
          968,
          13,
          50903
        ]
      },
      {
        "avg_logprob": -0.28018759247055625,
        "compression_ratio": 1.7431906614785992,
        "end": 4354.96,
        "id": 1366,
        "no_speech_prob": 0.0000057719139476830605,
        "seek": 434270,
        "start": 4353.48,
        "temperature": 0,
        "text": " I wanna tell it when you're deployed,",
        "tokens": [
          50903,
          286,
          1948,
          980,
          309,
          562,
          291,
          434,
          17826,
          11,
          50977
        ]
      },
      {
        "avg_logprob": -0.28018759247055625,
        "compression_ratio": 1.7431906614785992,
        "end": 4356.36,
        "id": 1367,
        "no_speech_prob": 0.0000057719139476830605,
        "seek": 434270,
        "start": 4354.96,
        "temperature": 0,
        "text": " talk to the deployed database.",
        "tokens": [
          50977,
          751,
          281,
          264,
          17826,
          8149,
          13,
          51047
        ]
      },
      {
        "avg_logprob": -0.28018759247055625,
        "compression_ratio": 1.7431906614785992,
        "end": 4361.36,
        "id": 1368,
        "no_speech_prob": 0.0000057719139476830605,
        "seek": 434270,
        "start": 4356.36,
        "temperature": 0,
        "text": " So I'm gonna do process.env.mongouri.",
        "tokens": [
          51047,
          407,
          286,
          478,
          799,
          360,
          1399,
          13,
          268,
          85,
          13,
          76,
          25729,
          9744,
          13,
          51297
        ]
      },
      {
        "avg_logprob": -0.28018759247055625,
        "compression_ratio": 1.7431906614785992,
        "end": 4363.24,
        "id": 1369,
        "no_speech_prob": 0.0000057719139476830605,
        "seek": 434270,
        "start": 4361.639999999999,
        "temperature": 0,
        "text": " And I can call this whatever I want.",
        "tokens": [
          51311,
          400,
          286,
          393,
          818,
          341,
          2035,
          286,
          528,
          13,
          51391
        ]
      },
      {
        "avg_logprob": -0.28018759247055625,
        "compression_ratio": 1.7431906614785992,
        "end": 4366.36,
        "id": 1370,
        "no_speech_prob": 0.0000057719139476830605,
        "seek": 434270,
        "start": 4363.24,
        "temperature": 0,
        "text": " I'll show, I'm gonna be using a deployment tool called now.",
        "tokens": [
          51391,
          286,
          603,
          855,
          11,
          286,
          478,
          799,
          312,
          1228,
          257,
          19317,
          2290,
          1219,
          586,
          13,
          51547
        ]
      },
      {
        "avg_logprob": -0.28018759247055625,
        "compression_ratio": 1.7431906614785992,
        "end": 4368.8,
        "id": 1371,
        "no_speech_prob": 0.0000057719139476830605,
        "seek": 434270,
        "start": 4366.36,
        "temperature": 0,
        "text": " You can specify what are the environment variables",
        "tokens": [
          51547,
          509,
          393,
          16500,
          437,
          366,
          264,
          2823,
          9102,
          51669
        ]
      },
      {
        "avg_logprob": -0.28018759247055625,
        "compression_ratio": 1.7431906614785992,
        "end": 4369.62,
        "id": 1372,
        "no_speech_prob": 0.0000057719139476830605,
        "seek": 434270,
        "start": 4368.8,
        "temperature": 0,
        "text": " that you deploy with.",
        "tokens": [
          51669,
          300,
          291,
          7274,
          365,
          13,
          51710
        ]
      },
      {
        "avg_logprob": -0.28018759247055625,
        "compression_ratio": 1.7431906614785992,
        "end": 4371.96,
        "id": 1373,
        "no_speech_prob": 0.0000057719139476830605,
        "seek": 434270,
        "start": 4369.62,
        "temperature": 0,
        "text": " And in this case, I'm gonna create one called mongouri.",
        "tokens": [
          51710,
          400,
          294,
          341,
          1389,
          11,
          286,
          478,
          799,
          1884,
          472,
          1219,
          275,
          25729,
          9744,
          13,
          51827
        ]
      },
      {
        "avg_logprob": -0.2482720682443666,
        "compression_ratio": 1.652,
        "end": 4373.9,
        "id": 1374,
        "no_speech_prob": 9.721533160700346e-7,
        "seek": 437196,
        "start": 4371.9800000000005,
        "temperature": 0,
        "text": " So what this says is,",
        "tokens": [
          50365,
          407,
          437,
          341,
          1619,
          307,
          11,
          50461
        ]
      },
      {
        "avg_logprob": -0.2482720682443666,
        "compression_ratio": 1.652,
        "end": 4376.18,
        "id": 1375,
        "no_speech_prob": 9.721533160700346e-7,
        "seek": 437196,
        "start": 4373.9,
        "temperature": 0,
        "text": " if this environment variable is defined,",
        "tokens": [
          50461,
          498,
          341,
          2823,
          7006,
          307,
          7642,
          11,
          50575
        ]
      },
      {
        "avg_logprob": -0.2482720682443666,
        "compression_ratio": 1.652,
        "end": 4377.3,
        "id": 1376,
        "no_speech_prob": 9.721533160700346e-7,
        "seek": 437196,
        "start": 4376.18,
        "temperature": 0,
        "text": " connect to that database,",
        "tokens": [
          50575,
          1745,
          281,
          300,
          8149,
          11,
          50631
        ]
      },
      {
        "avg_logprob": -0.2482720682443666,
        "compression_ratio": 1.652,
        "end": 4379.46,
        "id": 1377,
        "no_speech_prob": 9.721533160700346e-7,
        "seek": 437196,
        "start": 4377.3,
        "temperature": 0,
        "text": " otherwise connect to the localhost one.",
        "tokens": [
          50631,
          5911,
          1745,
          281,
          264,
          2654,
          6037,
          472,
          13,
          50739
        ]
      },
      {
        "avg_logprob": -0.2482720682443666,
        "compression_ratio": 1.652,
        "end": 4381.16,
        "id": 1378,
        "no_speech_prob": 9.721533160700346e-7,
        "seek": 437196,
        "start": 4379.46,
        "temperature": 0,
        "text": " So that's our database connection.",
        "tokens": [
          50739,
          407,
          300,
          311,
          527,
          8149,
          4984,
          13,
          50824
        ]
      },
      {
        "avg_logprob": -0.2482720682443666,
        "compression_ratio": 1.652,
        "end": 4385.6,
        "id": 1379,
        "no_speech_prob": 9.721533160700346e-7,
        "seek": 437196,
        "start": 4382.82,
        "temperature": 0,
        "text": " And we should be able to deploy it.",
        "tokens": [
          50907,
          400,
          321,
          820,
          312,
          1075,
          281,
          7274,
          309,
          13,
          51046
        ]
      },
      {
        "avg_logprob": -0.2482720682443666,
        "compression_ratio": 1.652,
        "end": 4389.74,
        "id": 1380,
        "no_speech_prob": 9.721533160700346e-7,
        "seek": 437196,
        "start": 4385.6,
        "temperature": 0,
        "text": " So for the database, I'm using something called mlab.",
        "tokens": [
          51046,
          407,
          337,
          264,
          8149,
          11,
          286,
          478,
          1228,
          746,
          1219,
          275,
          44990,
          13,
          51253
        ]
      },
      {
        "avg_logprob": -0.2482720682443666,
        "compression_ratio": 1.652,
        "end": 4394.52,
        "id": 1381,
        "no_speech_prob": 9.721533160700346e-7,
        "seek": 437196,
        "start": 4389.74,
        "temperature": 0,
        "text": " And they let you set up a free 500 megabyte Mongo databases.",
        "tokens": [
          51253,
          400,
          436,
          718,
          291,
          992,
          493,
          257,
          1737,
          5923,
          10816,
          34529,
          48380,
          22380,
          13,
          51492
        ]
      },
      {
        "avg_logprob": -0.2482720682443666,
        "compression_ratio": 1.652,
        "end": 4397.22,
        "id": 1382,
        "no_speech_prob": 9.721533160700346e-7,
        "seek": 437196,
        "start": 4394.52,
        "temperature": 0,
        "text": " And you can sign up, log in.",
        "tokens": [
          51492,
          400,
          291,
          393,
          1465,
          493,
          11,
          3565,
          294,
          13,
          51627
        ]
      },
      {
        "avg_logprob": -0.2482720682443666,
        "compression_ratio": 1.652,
        "end": 4399.86,
        "id": 1383,
        "no_speech_prob": 9.721533160700346e-7,
        "seek": 437196,
        "start": 4397.22,
        "temperature": 0,
        "text": " I think to hide my screen, I'll do this.",
        "tokens": [
          51627,
          286,
          519,
          281,
          6479,
          452,
          2568,
          11,
          286,
          603,
          360,
          341,
          13,
          51759
        ]
      },
      {
        "avg_logprob": -0.2482720682443666,
        "compression_ratio": 1.652,
        "end": 4401.26,
        "id": 1384,
        "no_speech_prob": 9.721533160700346e-7,
        "seek": 437196,
        "start": 4399.86,
        "temperature": 0,
        "text": " I'm gonna log in real quick.",
        "tokens": [
          51759,
          286,
          478,
          799,
          3565,
          294,
          957,
          1702,
          13,
          51829
        ]
      },
      {
        "avg_logprob": -0.40414680868892344,
        "compression_ratio": 1.5644444444444445,
        "end": 4406.22,
        "id": 1385,
        "no_speech_prob": 0.00014651943638455123,
        "seek": 440196,
        "start": 4402.78,
        "temperature": 0,
        "text": " And you can also, not that it matters, but.",
        "tokens": [
          50405,
          400,
          291,
          393,
          611,
          11,
          406,
          300,
          309,
          7001,
          11,
          457,
          13,
          50577
        ]
      },
      {
        "avg_logprob": -0.40414680868892344,
        "compression_ratio": 1.5644444444444445,
        "end": 4411.06,
        "id": 1386,
        "no_speech_prob": 0.00014651943638455123,
        "seek": 440196,
        "start": 4410.22,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          50777,
          876,
          13,
          50819
        ]
      },
      {
        "avg_logprob": -0.40414680868892344,
        "compression_ratio": 1.5644444444444445,
        "end": 4412.86,
        "id": 1387,
        "no_speech_prob": 0.00014651943638455123,
        "seek": 440196,
        "start": 4412.02,
        "temperature": 0,
        "text": " That's awesome.",
        "tokens": [
          50867,
          663,
          311,
          3476,
          13,
          50909
        ]
      },
      {
        "avg_logprob": -0.40414680868892344,
        "compression_ratio": 1.5644444444444445,
        "end": 4413.7,
        "id": 1388,
        "no_speech_prob": 0.00014651943638455123,
        "seek": 440196,
        "start": 4412.86,
        "temperature": 0,
        "text": " We can do that.",
        "tokens": [
          50909,
          492,
          393,
          360,
          300,
          13,
          50951
        ]
      },
      {
        "avg_logprob": -0.40414680868892344,
        "compression_ratio": 1.5644444444444445,
        "end": 4417.02,
        "id": 1389,
        "no_speech_prob": 0.00014651943638455123,
        "seek": 440196,
        "start": 4413.7,
        "temperature": 0,
        "text": " We can do that when you deploy it, just to make sure.",
        "tokens": [
          50951,
          492,
          393,
          360,
          300,
          562,
          291,
          7274,
          309,
          11,
          445,
          281,
          652,
          988,
          13,
          51117
        ]
      },
      {
        "avg_logprob": -0.40414680868892344,
        "compression_ratio": 1.5644444444444445,
        "end": 4419.02,
        "id": 1390,
        "no_speech_prob": 0.00014651943638455123,
        "seek": 440196,
        "start": 4417.02,
        "temperature": 0,
        "text": " I don't trust our bad words filtering.",
        "tokens": [
          51117,
          286,
          500,
          380,
          3361,
          527,
          1578,
          2283,
          30822,
          13,
          51217
        ]
      },
      {
        "avg_logprob": -0.40414680868892344,
        "compression_ratio": 1.5644444444444445,
        "end": 4419.86,
        "id": 1391,
        "no_speech_prob": 0.00014651943638455123,
        "seek": 440196,
        "start": 4419.02,
        "temperature": 0,
        "text": " And I don't trust,",
        "tokens": [
          51217,
          400,
          286,
          500,
          380,
          3361,
          11,
          51259
        ]
      },
      {
        "avg_logprob": -0.40414680868892344,
        "compression_ratio": 1.5644444444444445,
        "end": 4423.54,
        "id": 1392,
        "no_speech_prob": 0.00014651943638455123,
        "seek": 440196,
        "start": 4419.86,
        "temperature": 0,
        "text": " there's a wonderful audience of nice, lovely people, but.",
        "tokens": [
          51259,
          456,
          311,
          257,
          3715,
          4034,
          295,
          1481,
          11,
          7496,
          561,
          11,
          457,
          13,
          51443
        ]
      },
      {
        "avg_logprob": -0.40414680868892344,
        "compression_ratio": 1.5644444444444445,
        "end": 4424.38,
        "id": 1393,
        "no_speech_prob": 0.00014651943638455123,
        "seek": 440196,
        "start": 4423.54,
        "temperature": 0,
        "text": " Cool.",
        "tokens": [
          51443,
          8561,
          13,
          51485
        ]
      },
      {
        "avg_logprob": -0.40414680868892344,
        "compression_ratio": 1.5644444444444445,
        "end": 4426.78,
        "id": 1394,
        "no_speech_prob": 0.00014651943638455123,
        "seek": 440196,
        "start": 4424.38,
        "temperature": 0,
        "text": " And so I've actually already created a database.",
        "tokens": [
          51485,
          400,
          370,
          286,
          600,
          767,
          1217,
          2942,
          257,
          8149,
          13,
          51605
        ]
      },
      {
        "avg_logprob": -0.40414680868892344,
        "compression_ratio": 1.5644444444444445,
        "end": 4428.82,
        "id": 1395,
        "no_speech_prob": 0.00014651943638455123,
        "seek": 440196,
        "start": 4426.78,
        "temperature": 0,
        "text": " So this should be, oh, I'm gonna do that.",
        "tokens": [
          51605,
          407,
          341,
          820,
          312,
          11,
          1954,
          11,
          286,
          478,
          799,
          360,
          300,
          13,
          51707
        ]
      },
      {
        "avg_logprob": -0.40414680868892344,
        "compression_ratio": 1.5644444444444445,
        "end": 4431.18,
        "id": 1396,
        "no_speech_prob": 0.00014651943638455123,
        "seek": 440196,
        "start": 4430.34,
        "temperature": 0,
        "text": " Cool.",
        "tokens": [
          51783,
          8561,
          13,
          51825
        ]
      },
      {
        "avg_logprob": -0.21407181876046316,
        "compression_ratio": 1.863799283154122,
        "end": 4433.320000000001,
        "id": 1397,
        "no_speech_prob": 0.0006166171515360475,
        "seek": 443118,
        "start": 4431.200000000001,
        "temperature": 0,
        "text": " So I've created a database, but you can log in,",
        "tokens": [
          50365,
          407,
          286,
          600,
          2942,
          257,
          8149,
          11,
          457,
          291,
          393,
          3565,
          294,
          11,
          50471
        ]
      },
      {
        "avg_logprob": -0.21407181876046316,
        "compression_ratio": 1.863799283154122,
        "end": 4435.76,
        "id": 1398,
        "no_speech_prob": 0.0006166171515360475,
        "seek": 443118,
        "start": 4433.320000000001,
        "temperature": 0,
        "text": " you can sign up, they have a way of creating one for free.",
        "tokens": [
          50471,
          291,
          393,
          1465,
          493,
          11,
          436,
          362,
          257,
          636,
          295,
          4084,
          472,
          337,
          1737,
          13,
          50593
        ]
      },
      {
        "avg_logprob": -0.21407181876046316,
        "compression_ratio": 1.863799283154122,
        "end": 4437.72,
        "id": 1399,
        "no_speech_prob": 0.0006166171515360475,
        "seek": 443118,
        "start": 4435.76,
        "temperature": 0,
        "text": " If you want more than that, you can also pay for it.",
        "tokens": [
          50593,
          759,
          291,
          528,
          544,
          813,
          300,
          11,
          291,
          393,
          611,
          1689,
          337,
          309,
          13,
          50691
        ]
      },
      {
        "avg_logprob": -0.21407181876046316,
        "compression_ratio": 1.863799283154122,
        "end": 4439,
        "id": 1400,
        "no_speech_prob": 0.0006166171515360475,
        "seek": 443118,
        "start": 4437.72,
        "temperature": 0,
        "text": " But I've created the database.",
        "tokens": [
          50691,
          583,
          286,
          600,
          2942,
          264,
          8149,
          13,
          50755
        ]
      },
      {
        "avg_logprob": -0.21407181876046316,
        "compression_ratio": 1.863799283154122,
        "end": 4441.12,
        "id": 1401,
        "no_speech_prob": 0.0006166171515360475,
        "seek": 443118,
        "start": 4439,
        "temperature": 0,
        "text": " You will need to create a user.",
        "tokens": [
          50755,
          509,
          486,
          643,
          281,
          1884,
          257,
          4195,
          13,
          50861
        ]
      },
      {
        "avg_logprob": -0.21407181876046316,
        "compression_ratio": 1.863799283154122,
        "end": 4442.4800000000005,
        "id": 1402,
        "no_speech_prob": 0.0006166171515360475,
        "seek": 443118,
        "start": 4441.12,
        "temperature": 0,
        "text": " And then once you have a user,",
        "tokens": [
          50861,
          400,
          550,
          1564,
          291,
          362,
          257,
          4195,
          11,
          50929
        ]
      },
      {
        "avg_logprob": -0.21407181876046316,
        "compression_ratio": 1.863799283154122,
        "end": 4443.900000000001,
        "id": 1403,
        "no_speech_prob": 0.0006166171515360475,
        "seek": 443118,
        "start": 4442.4800000000005,
        "temperature": 0,
        "text": " you create this connection string.",
        "tokens": [
          50929,
          291,
          1884,
          341,
          4984,
          6798,
          13,
          51000
        ]
      },
      {
        "avg_logprob": -0.21407181876046316,
        "compression_ratio": 1.863799283154122,
        "end": 4445.400000000001,
        "id": 1404,
        "no_speech_prob": 0.0006166171515360475,
        "seek": 443118,
        "start": 4443.900000000001,
        "temperature": 0,
        "text": " And they show you where your username",
        "tokens": [
          51000,
          400,
          436,
          855,
          291,
          689,
          428,
          30351,
          51075
        ]
      },
      {
        "avg_logprob": -0.21407181876046316,
        "compression_ratio": 1.863799283154122,
        "end": 4447.06,
        "id": 1405,
        "no_speech_prob": 0.0006166171515360475,
        "seek": 443118,
        "start": 4445.400000000001,
        "temperature": 0,
        "text": " and your password goes in.",
        "tokens": [
          51075,
          293,
          428,
          11524,
          1709,
          294,
          13,
          51158
        ]
      },
      {
        "avg_logprob": -0.21407181876046316,
        "compression_ratio": 1.863799283154122,
        "end": 4451.64,
        "id": 1406,
        "no_speech_prob": 0.0006166171515360475,
        "seek": 443118,
        "start": 4447.06,
        "temperature": 0,
        "text": " And then you need to add that as a secret on now.",
        "tokens": [
          51158,
          400,
          550,
          291,
          643,
          281,
          909,
          300,
          382,
          257,
          4054,
          322,
          586,
          13,
          51387
        ]
      },
      {
        "avg_logprob": -0.21407181876046316,
        "compression_ratio": 1.863799283154122,
        "end": 4455.68,
        "id": 1407,
        "no_speech_prob": 0.0006166171515360475,
        "seek": 443118,
        "start": 4451.64,
        "temperature": 0,
        "text": " So the way it works is you say now secrets add,",
        "tokens": [
          51387,
          407,
          264,
          636,
          309,
          1985,
          307,
          291,
          584,
          586,
          14093,
          909,
          11,
          51589
        ]
      },
      {
        "avg_logprob": -0.21407181876046316,
        "compression_ratio": 1.863799283154122,
        "end": 4457.6,
        "id": 1408,
        "no_speech_prob": 0.0006166171515360475,
        "seek": 443118,
        "start": 4455.68,
        "temperature": 0,
        "text": " and you can call it anything you want.",
        "tokens": [
          51589,
          293,
          291,
          393,
          818,
          309,
          1340,
          291,
          528,
          13,
          51685
        ]
      },
      {
        "avg_logprob": -0.21407181876046316,
        "compression_ratio": 1.863799283154122,
        "end": 4460.02,
        "id": 1409,
        "no_speech_prob": 0.0006166171515360475,
        "seek": 443118,
        "start": 4458.88,
        "temperature": 0,
        "text": " So I already have one set up,",
        "tokens": [
          51749,
          407,
          286,
          1217,
          362,
          472,
          992,
          493,
          11,
          51806
        ]
      },
      {
        "avg_logprob": -0.22565861071570445,
        "compression_ratio": 1.74,
        "end": 4461.360000000001,
        "id": 1410,
        "no_speech_prob": 0.0000946117434068583,
        "seek": 446002,
        "start": 4460.040000000001,
        "temperature": 0,
        "text": " just because I didn't want to risk doing it.",
        "tokens": [
          50365,
          445,
          570,
          286,
          994,
          380,
          528,
          281,
          3148,
          884,
          309,
          13,
          50431
        ]
      },
      {
        "avg_logprob": -0.22565861071570445,
        "compression_ratio": 1.74,
        "end": 4463.4400000000005,
        "id": 1411,
        "no_speech_prob": 0.0000946117434068583,
        "seek": 446002,
        "start": 4461.360000000001,
        "temperature": 0,
        "text": " But you can give it any name you want,",
        "tokens": [
          50431,
          583,
          291,
          393,
          976,
          309,
          604,
          1315,
          291,
          528,
          11,
          50535
        ]
      },
      {
        "avg_logprob": -0.22565861071570445,
        "compression_ratio": 1.74,
        "end": 4464.4400000000005,
        "id": 1412,
        "no_speech_prob": 0.0000946117434068583,
        "seek": 446002,
        "start": 4463.4400000000005,
        "temperature": 0,
        "text": " and then you give it the value.",
        "tokens": [
          50535,
          293,
          550,
          291,
          976,
          309,
          264,
          2158,
          13,
          50585
        ]
      },
      {
        "avg_logprob": -0.22565861071570445,
        "compression_ratio": 1.74,
        "end": 4467.320000000001,
        "id": 1413,
        "no_speech_prob": 0.0000946117434068583,
        "seek": 446002,
        "start": 4464.4400000000005,
        "temperature": 0,
        "text": " So typically the value would be something like this.",
        "tokens": [
          50585,
          407,
          5850,
          264,
          2158,
          576,
          312,
          746,
          411,
          341,
          13,
          50729
        ]
      },
      {
        "avg_logprob": -0.22565861071570445,
        "compression_ratio": 1.74,
        "end": 4469.360000000001,
        "id": 1414,
        "no_speech_prob": 0.0000946117434068583,
        "seek": 446002,
        "start": 4467.320000000001,
        "temperature": 0,
        "text": " And you would fill in your username and password.",
        "tokens": [
          50729,
          400,
          291,
          576,
          2836,
          294,
          428,
          30351,
          293,
          11524,
          13,
          50831
        ]
      },
      {
        "avg_logprob": -0.22565861071570445,
        "compression_ratio": 1.74,
        "end": 4470.88,
        "id": 1415,
        "no_speech_prob": 0.0000946117434068583,
        "seek": 446002,
        "start": 4469.360000000001,
        "temperature": 0,
        "text": " And now inside of now,",
        "tokens": [
          50831,
          400,
          586,
          1854,
          295,
          586,
          11,
          50907
        ]
      },
      {
        "avg_logprob": -0.22565861071570445,
        "compression_ratio": 1.74,
        "end": 4474.360000000001,
        "id": 1416,
        "no_speech_prob": 0.0000946117434068583,
        "seek": 446002,
        "start": 4470.88,
        "temperature": 0,
        "text": " there is a secret you can use called meowerdb.",
        "tokens": [
          50907,
          456,
          307,
          257,
          4054,
          291,
          393,
          764,
          1219,
          385,
          968,
          67,
          65,
          13,
          51081
        ]
      },
      {
        "avg_logprob": -0.22565861071570445,
        "compression_ratio": 1.74,
        "end": 4476.580000000001,
        "id": 1417,
        "no_speech_prob": 0.0000946117434068583,
        "seek": 446002,
        "start": 4474.360000000001,
        "temperature": 0,
        "text": " And that's what we'll actually use to deploy.",
        "tokens": [
          51081,
          400,
          300,
          311,
          437,
          321,
          603,
          767,
          764,
          281,
          7274,
          13,
          51192
        ]
      },
      {
        "avg_logprob": -0.22565861071570445,
        "compression_ratio": 1.74,
        "end": 4479.200000000001,
        "id": 1418,
        "no_speech_prob": 0.0000946117434068583,
        "seek": 446002,
        "start": 4476.580000000001,
        "temperature": 0,
        "text": " So the site's super easy to use.",
        "tokens": [
          51192,
          407,
          264,
          3621,
          311,
          1687,
          1858,
          281,
          764,
          13,
          51323
        ]
      },
      {
        "avg_logprob": -0.22565861071570445,
        "compression_ratio": 1.74,
        "end": 4480.200000000001,
        "id": 1419,
        "no_speech_prob": 0.0000946117434068583,
        "seek": 446002,
        "start": 4479.200000000001,
        "temperature": 0,
        "text": " I think people have been asking about it.",
        "tokens": [
          51323,
          286,
          519,
          561,
          362,
          668,
          3365,
          466,
          309,
          13,
          51373
        ]
      },
      {
        "avg_logprob": -0.22565861071570445,
        "compression_ratio": 1.74,
        "end": 4482.88,
        "id": 1420,
        "no_speech_prob": 0.0000946117434068583,
        "seek": 446002,
        "start": 4480.200000000001,
        "temperature": 0,
        "text": " We do have a, Coding Garden has a Discord server.",
        "tokens": [
          51373,
          492,
          360,
          362,
          257,
          11,
          383,
          8616,
          19429,
          575,
          257,
          32623,
          7154,
          13,
          51507
        ]
      },
      {
        "avg_logprob": -0.22565861071570445,
        "compression_ratio": 1.74,
        "end": 4484.120000000001,
        "id": 1421,
        "no_speech_prob": 0.0000946117434068583,
        "seek": 446002,
        "start": 4482.88,
        "temperature": 0,
        "text": " So if you're trying to do this stuff",
        "tokens": [
          51507,
          407,
          498,
          291,
          434,
          1382,
          281,
          360,
          341,
          1507,
          51569
        ]
      },
      {
        "avg_logprob": -0.22565861071570445,
        "compression_ratio": 1.74,
        "end": 4485.96,
        "id": 1422,
        "no_speech_prob": 0.0000946117434068583,
        "seek": 446002,
        "start": 4484.120000000001,
        "temperature": 0,
        "text": " and you have questions, feel free to join in there.",
        "tokens": [
          51569,
          293,
          291,
          362,
          1651,
          11,
          841,
          1737,
          281,
          3917,
          294,
          456,
          13,
          51661
        ]
      },
      {
        "avg_logprob": -0.22565861071570445,
        "compression_ratio": 1.74,
        "end": 4487.080000000001,
        "id": 1423,
        "no_speech_prob": 0.0000946117434068583,
        "seek": 446002,
        "start": 4485.96,
        "temperature": 0,
        "text": " We have a help channel.",
        "tokens": [
          51661,
          492,
          362,
          257,
          854,
          2269,
          13,
          51717
        ]
      },
      {
        "avg_logprob": -0.22565861071570445,
        "compression_ratio": 1.74,
        "end": 4488.88,
        "id": 1424,
        "no_speech_prob": 0.0000946117434068583,
        "seek": 446002,
        "start": 4487.080000000001,
        "temperature": 0,
        "text": " You can help people work things out.",
        "tokens": [
          51717,
          509,
          393,
          854,
          561,
          589,
          721,
          484,
          13,
          51807
        ]
      },
      {
        "avg_logprob": -0.2251697602819224,
        "compression_ratio": 1.6575875486381324,
        "end": 4493.54,
        "id": 1425,
        "no_speech_prob": 0.0000035559687603381462,
        "seek": 448888,
        "start": 4489.88,
        "temperature": 0,
        "text": " So this specifically is how we're gonna deploy our database.",
        "tokens": [
          50414,
          407,
          341,
          4682,
          307,
          577,
          321,
          434,
          799,
          7274,
          527,
          8149,
          13,
          50597
        ]
      },
      {
        "avg_logprob": -0.2251697602819224,
        "compression_ratio": 1.6575875486381324,
        "end": 4495.34,
        "id": 1426,
        "no_speech_prob": 0.0000035559687603381462,
        "seek": 448888,
        "start": 4493.54,
        "temperature": 0,
        "text": " And now we deploy our backend",
        "tokens": [
          50597,
          400,
          586,
          321,
          7274,
          527,
          38087,
          50687
        ]
      },
      {
        "avg_logprob": -0.2251697602819224,
        "compression_ratio": 1.6575875486381324,
        "end": 4496.9800000000005,
        "id": 1427,
        "no_speech_prob": 0.0000035559687603381462,
        "seek": 448888,
        "start": 4495.34,
        "temperature": 0,
        "text": " and tell it to talk to that database.",
        "tokens": [
          50687,
          293,
          980,
          309,
          281,
          751,
          281,
          300,
          8149,
          13,
          50769
        ]
      },
      {
        "avg_logprob": -0.2251697602819224,
        "compression_ratio": 1.6575875486381324,
        "end": 4501.1,
        "id": 1428,
        "no_speech_prob": 0.0000035559687603381462,
        "seek": 448888,
        "start": 4496.9800000000005,
        "temperature": 0,
        "text": " So to deploy, I'm using a tool called now.",
        "tokens": [
          50769,
          407,
          281,
          7274,
          11,
          286,
          478,
          1228,
          257,
          2290,
          1219,
          586,
          13,
          50975
        ]
      },
      {
        "avg_logprob": -0.2251697602819224,
        "compression_ratio": 1.6575875486381324,
        "end": 4503.900000000001,
        "id": 1429,
        "no_speech_prob": 0.0000035559687603381462,
        "seek": 448888,
        "start": 4501.1,
        "temperature": 0,
        "text": " You can get it from a website called zeet.co.",
        "tokens": [
          50975,
          509,
          393,
          483,
          309,
          490,
          257,
          3144,
          1219,
          710,
          68,
          302,
          13,
          1291,
          13,
          51115
        ]
      },
      {
        "avg_logprob": -0.2251697602819224,
        "compression_ratio": 1.6575875486381324,
        "end": 4505.38,
        "id": 1430,
        "no_speech_prob": 0.0000035559687603381462,
        "seek": 448888,
        "start": 4503.900000000001,
        "temperature": 0,
        "text": " It's a really, really easy thing to do.",
        "tokens": [
          51115,
          467,
          311,
          257,
          534,
          11,
          534,
          1858,
          551,
          281,
          360,
          13,
          51189
        ]
      },
      {
        "avg_logprob": -0.2251697602819224,
        "compression_ratio": 1.6575875486381324,
        "end": 4508.34,
        "id": 1431,
        "no_speech_prob": 0.0000035559687603381462,
        "seek": 448888,
        "start": 4505.38,
        "temperature": 0,
        "text": " You just type now, and it will automatically deploy",
        "tokens": [
          51189,
          509,
          445,
          2010,
          586,
          11,
          293,
          309,
          486,
          6772,
          7274,
          51337
        ]
      },
      {
        "avg_logprob": -0.2251697602819224,
        "compression_ratio": 1.6575875486381324,
        "end": 4511.02,
        "id": 1432,
        "no_speech_prob": 0.0000035559687603381462,
        "seek": 448888,
        "start": 4508.34,
        "temperature": 0,
        "text": " that either server or client.",
        "tokens": [
          51337,
          300,
          2139,
          7154,
          420,
          6423,
          13,
          51471
        ]
      },
      {
        "avg_logprob": -0.2251697602819224,
        "compression_ratio": 1.6575875486381324,
        "end": 4513.22,
        "id": 1433,
        "no_speech_prob": 0.0000035559687603381462,
        "seek": 448888,
        "start": 4511.02,
        "temperature": 0,
        "text": " But in this case, I want to tell it",
        "tokens": [
          51471,
          583,
          294,
          341,
          1389,
          11,
          286,
          528,
          281,
          980,
          309,
          51581
        ]
      },
      {
        "avg_logprob": -0.2251697602819224,
        "compression_ratio": 1.6575875486381324,
        "end": 4517.18,
        "id": 1434,
        "no_speech_prob": 0.0000035559687603381462,
        "seek": 448888,
        "start": 4513.22,
        "temperature": 0,
        "text": " that my Mongo URI process in environment variable,",
        "tokens": [
          51581,
          300,
          452,
          48380,
          624,
          5577,
          1399,
          294,
          2823,
          7006,
          11,
          51779
        ]
      },
      {
        "avg_logprob": -0.23201995425754124,
        "compression_ratio": 1.57421875,
        "end": 4518.96,
        "id": 1435,
        "no_speech_prob": 0.000007766941962472629,
        "seek": 451718,
        "start": 4517.200000000001,
        "temperature": 0,
        "text": " which I defined right here,",
        "tokens": [
          50365,
          597,
          286,
          7642,
          558,
          510,
          11,
          50453
        ]
      },
      {
        "avg_logprob": -0.23201995425754124,
        "compression_ratio": 1.57421875,
        "end": 4521.34,
        "id": 1436,
        "no_speech_prob": 0.000007766941962472629,
        "seek": 451718,
        "start": 4518.96,
        "temperature": 0,
        "text": " should come from my secret called meowerdb.",
        "tokens": [
          50453,
          820,
          808,
          490,
          452,
          4054,
          1219,
          385,
          968,
          67,
          65,
          13,
          50572
        ]
      },
      {
        "avg_logprob": -0.23201995425754124,
        "compression_ratio": 1.57421875,
        "end": 4522.88,
        "id": 1437,
        "no_speech_prob": 0.000007766941962472629,
        "seek": 451718,
        "start": 4521.34,
        "temperature": 0,
        "text": " So that should now, when it's deployed,",
        "tokens": [
          50572,
          407,
          300,
          820,
          586,
          11,
          562,
          309,
          311,
          17826,
          11,
          50649
        ]
      },
      {
        "avg_logprob": -0.23201995425754124,
        "compression_ratio": 1.57421875,
        "end": 4524.4400000000005,
        "id": 1438,
        "no_speech_prob": 0.000007766941962472629,
        "seek": 451718,
        "start": 4522.88,
        "temperature": 0,
        "text": " connect to the database.",
        "tokens": [
          50649,
          1745,
          281,
          264,
          8149,
          13,
          50727
        ]
      },
      {
        "avg_logprob": -0.23201995425754124,
        "compression_ratio": 1.57421875,
        "end": 4525.280000000001,
        "id": 1439,
        "no_speech_prob": 0.000007766941962472629,
        "seek": 451718,
        "start": 4524.4400000000005,
        "temperature": 0,
        "text": " Let's go.",
        "tokens": [
          50727,
          961,
          311,
          352,
          13,
          50769
        ]
      },
      {
        "avg_logprob": -0.23201995425754124,
        "compression_ratio": 1.57421875,
        "end": 4527.52,
        "id": 1440,
        "no_speech_prob": 0.000007766941962472629,
        "seek": 451718,
        "start": 4526.320000000001,
        "temperature": 0,
        "text": " Apparently I'm using an older version,",
        "tokens": [
          50821,
          16755,
          286,
          478,
          1228,
          364,
          4906,
          3037,
          11,
          50881
        ]
      },
      {
        "avg_logprob": -0.23201995425754124,
        "compression_ratio": 1.57421875,
        "end": 4529.280000000001,
        "id": 1441,
        "no_speech_prob": 0.000007766941962472629,
        "seek": 451718,
        "start": 4527.52,
        "temperature": 0,
        "text": " but this should deploy the backend.",
        "tokens": [
          50881,
          457,
          341,
          820,
          7274,
          264,
          38087,
          13,
          50969
        ]
      },
      {
        "avg_logprob": -0.23201995425754124,
        "compression_ratio": 1.57421875,
        "end": 4536.3,
        "id": 1442,
        "no_speech_prob": 0.000007766941962472629,
        "seek": 451718,
        "start": 4534.96,
        "temperature": 0,
        "text": " Do-do-do-do.",
        "tokens": [
          51253,
          1144,
          12,
          2595,
          12,
          2595,
          12,
          2595,
          13,
          51320
        ]
      },
      {
        "avg_logprob": -0.23201995425754124,
        "compression_ratio": 1.57421875,
        "end": 4537.700000000001,
        "id": 1443,
        "no_speech_prob": 0.000007766941962472629,
        "seek": 451718,
        "start": 4536.3,
        "temperature": 0,
        "text": " And the interesting thing about now",
        "tokens": [
          51320,
          400,
          264,
          1880,
          551,
          466,
          586,
          51390
        ]
      },
      {
        "avg_logprob": -0.23201995425754124,
        "compression_ratio": 1.57421875,
        "end": 4541.08,
        "id": 1444,
        "no_speech_prob": 0.000007766941962472629,
        "seek": 451718,
        "start": 4537.700000000001,
        "temperature": 0,
        "text": " is it gives you a unique URL every time you deploy.",
        "tokens": [
          51390,
          307,
          309,
          2709,
          291,
          257,
          3845,
          12905,
          633,
          565,
          291,
          7274,
          13,
          51559
        ]
      },
      {
        "avg_logprob": -0.23201995425754124,
        "compression_ratio": 1.57421875,
        "end": 4542.400000000001,
        "id": 1445,
        "no_speech_prob": 0.000007766941962472629,
        "seek": 451718,
        "start": 4541.08,
        "temperature": 0,
        "text": " But what we can do is alias it.",
        "tokens": [
          51559,
          583,
          437,
          321,
          393,
          360,
          307,
          419,
          4609,
          309,
          13,
          51625
        ]
      },
      {
        "avg_logprob": -0.23201995425754124,
        "compression_ratio": 1.57421875,
        "end": 4544.8,
        "id": 1446,
        "no_speech_prob": 0.000007766941962472629,
        "seek": 451718,
        "start": 4542.400000000001,
        "temperature": 0,
        "text": " So I'm gonna show you how I'll alias this thing.",
        "tokens": [
          51625,
          407,
          286,
          478,
          799,
          855,
          291,
          577,
          286,
          603,
          419,
          4609,
          341,
          551,
          13,
          51745
        ]
      },
      {
        "avg_logprob": -0.4845581546906502,
        "compression_ratio": 1.7330827067669172,
        "end": 4549.12,
        "id": 1447,
        "no_speech_prob": 0.0000670915687805973,
        "seek": 454718,
        "start": 4547.8,
        "temperature": 0,
        "text": " Okay, and if everything went okay,",
        "tokens": [
          50395,
          1033,
          11,
          293,
          498,
          1203,
          1437,
          1392,
          11,
          50461
        ]
      },
      {
        "avg_logprob": -0.4845581546906502,
        "compression_ratio": 1.7330827067669172,
        "end": 4551.92,
        "id": 1448,
        "no_speech_prob": 0.0000670915687805973,
        "seek": 454718,
        "start": 4549.12,
        "temperature": 0,
        "text": " I can actually throw this in, and I should get back meower.",
        "tokens": [
          50461,
          286,
          393,
          767,
          3507,
          341,
          294,
          11,
          293,
          286,
          820,
          483,
          646,
          385,
          968,
          13,
          50601
        ]
      },
      {
        "avg_logprob": -0.4845581546906502,
        "compression_ratio": 1.7330827067669172,
        "end": 4554.360000000001,
        "id": 1449,
        "no_speech_prob": 0.0000670915687805973,
        "seek": 454718,
        "start": 4551.92,
        "temperature": 0,
        "text": " And if I do a slash mus, I should get back an empty array,",
        "tokens": [
          50601,
          400,
          498,
          286,
          360,
          257,
          17330,
          1038,
          11,
          286,
          820,
          483,
          646,
          364,
          6707,
          10225,
          11,
          50723
        ]
      },
      {
        "avg_logprob": -0.4845581546906502,
        "compression_ratio": 1.7330827067669172,
        "end": 4555.400000000001,
        "id": 1450,
        "no_speech_prob": 0.0000670915687805973,
        "seek": 454718,
        "start": 4554.360000000001,
        "temperature": 0,
        "text": " because there's nothing in the database.",
        "tokens": [
          50723,
          570,
          456,
          311,
          1825,
          294,
          264,
          8149,
          13,
          50775
        ]
      },
      {
        "avg_logprob": -0.4845581546906502,
        "compression_ratio": 1.7330827067669172,
        "end": 4556.8,
        "id": 1451,
        "no_speech_prob": 0.0000670915687805973,
        "seek": 454718,
        "start": 4555.400000000001,
        "temperature": 0,
        "text": " Cool, so we're on the internet.",
        "tokens": [
          50775,
          8561,
          11,
          370,
          321,
          434,
          322,
          264,
          4705,
          13,
          50845
        ]
      },
      {
        "avg_logprob": -0.4845581546906502,
        "compression_ratio": 1.7330827067669172,
        "end": 4559,
        "id": 1452,
        "no_speech_prob": 0.0000670915687805973,
        "seek": 454718,
        "start": 4556.8,
        "temperature": 0,
        "text": " One thing I'll do is I'll set up an alias,",
        "tokens": [
          50845,
          1485,
          551,
          286,
          603,
          360,
          307,
          286,
          603,
          992,
          493,
          364,
          419,
          4609,
          11,
          50955
        ]
      },
      {
        "avg_logprob": -0.4845581546906502,
        "compression_ratio": 1.7330827067669172,
        "end": 4562.240000000001,
        "id": 1453,
        "no_speech_prob": 0.0000670915687805973,
        "seek": 454718,
        "start": 4559,
        "temperature": 0,
        "text": " and I'll say meower-api.",
        "tokens": [
          50955,
          293,
          286,
          603,
          584,
          385,
          968,
          12,
          35891,
          13,
          51117
        ]
      },
      {
        "avg_logprob": -0.4845581546906502,
        "compression_ratio": 1.7330827067669172,
        "end": 4567.240000000001,
        "id": 1454,
        "no_speech_prob": 0.0000670915687805973,
        "seek": 454718,
        "start": 4562.240000000001,
        "temperature": 0,
        "text": " So my backend will be at meower-api.now.sh.",
        "tokens": [
          51117,
          407,
          452,
          38087,
          486,
          312,
          412,
          385,
          968,
          12,
          35891,
          13,
          3785,
          13,
          2716,
          13,
          51367
        ]
      },
      {
        "avg_logprob": -0.4845581546906502,
        "compression_ratio": 1.7330827067669172,
        "end": 4569.6,
        "id": 1455,
        "no_speech_prob": 0.0000670915687805973,
        "seek": 454718,
        "start": 4568.76,
        "temperature": 0,
        "text": " So this alias will just,",
        "tokens": [
          51443,
          407,
          341,
          419,
          4609,
          486,
          445,
          11,
          51485
        ]
      },
      {
        "avg_logprob": -0.4845581546906502,
        "compression_ratio": 1.7330827067669172,
        "end": 4571.56,
        "id": 1456,
        "no_speech_prob": 0.0000670915687805973,
        "seek": 454718,
        "start": 4569.6,
        "temperature": 0,
        "text": " so I don't have to type in that big long thing.",
        "tokens": [
          51485,
          370,
          286,
          500,
          380,
          362,
          281,
          2010,
          294,
          300,
          955,
          938,
          551,
          13,
          51583
        ]
      },
      {
        "avg_logprob": -0.4845581546906502,
        "compression_ratio": 1.7330827067669172,
        "end": 4573.76,
        "id": 1457,
        "no_speech_prob": 0.0000670915687805973,
        "seek": 454718,
        "start": 4571.56,
        "temperature": 0,
        "text": " So now, I'm gonna deploy this.",
        "tokens": [
          51583,
          407,
          586,
          11,
          286,
          478,
          799,
          7274,
          341,
          13,
          51693
        ]
      },
      {
        "avg_logprob": -0.4845581546906502,
        "compression_ratio": 1.7330827067669172,
        "end": 4574.6,
        "id": 1458,
        "no_speech_prob": 0.0000670915687805973,
        "seek": 454718,
        "start": 4573.76,
        "temperature": 0,
        "text": " And I'm gonna say,",
        "tokens": [
          51693,
          400,
          286,
          478,
          799,
          584,
          11,
          51735
        ]
      },
      {
        "avg_logprob": -0.2256018107369442,
        "compression_ratio": 1.7195571955719557,
        "end": 4576.1,
        "id": 1459,
        "no_speech_prob": 0.0005442072870209813,
        "seek": 457460,
        "start": 4574.6,
        "temperature": 0,
        "text": " I don't have to type in that big long thing.",
        "tokens": [
          50364,
          286,
          500,
          380,
          362,
          281,
          2010,
          294,
          300,
          955,
          938,
          551,
          13,
          50439
        ]
      },
      {
        "avg_logprob": -0.2256018107369442,
        "compression_ratio": 1.7195571955719557,
        "end": 4579.14,
        "id": 1460,
        "no_speech_prob": 0.0005442072870209813,
        "seek": 457460,
        "start": 4576.1,
        "temperature": 0,
        "text": " So now, when I go here, it's the exact same server.",
        "tokens": [
          50439,
          407,
          586,
          11,
          562,
          286,
          352,
          510,
          11,
          309,
          311,
          264,
          1900,
          912,
          7154,
          13,
          50591
        ]
      },
      {
        "avg_logprob": -0.2256018107369442,
        "compression_ratio": 1.7195571955719557,
        "end": 4581.860000000001,
        "id": 1461,
        "no_speech_prob": 0.0005442072870209813,
        "seek": 457460,
        "start": 4579.14,
        "temperature": 0,
        "text": " It just has a nice name, and I can do slash mus,",
        "tokens": [
          50591,
          467,
          445,
          575,
          257,
          1481,
          1315,
          11,
          293,
          286,
          393,
          360,
          17330,
          1038,
          11,
          50727
        ]
      },
      {
        "avg_logprob": -0.2256018107369442,
        "compression_ratio": 1.7195571955719557,
        "end": 4582.9800000000005,
        "id": 1462,
        "no_speech_prob": 0.0005442072870209813,
        "seek": 457460,
        "start": 4581.860000000001,
        "temperature": 0,
        "text": " and that gives me back an empty array.",
        "tokens": [
          50727,
          293,
          300,
          2709,
          385,
          646,
          364,
          6707,
          10225,
          13,
          50783
        ]
      },
      {
        "avg_logprob": -0.2256018107369442,
        "compression_ratio": 1.7195571955719557,
        "end": 4583.820000000001,
        "id": 1463,
        "no_speech_prob": 0.0005442072870209813,
        "seek": 457460,
        "start": 4582.9800000000005,
        "temperature": 0,
        "text": " Cool.",
        "tokens": [
          50783,
          8561,
          13,
          50825
        ]
      },
      {
        "avg_logprob": -0.2256018107369442,
        "compression_ratio": 1.7195571955719557,
        "end": 4586.46,
        "id": 1464,
        "no_speech_prob": 0.0005442072870209813,
        "seek": 457460,
        "start": 4584.820000000001,
        "temperature": 0,
        "text": " And now, we wanna deploy our frontend.",
        "tokens": [
          50875,
          400,
          586,
          11,
          321,
          1948,
          7274,
          527,
          1868,
          521,
          13,
          50957
        ]
      },
      {
        "avg_logprob": -0.2256018107369442,
        "compression_ratio": 1.7195571955719557,
        "end": 4589.660000000001,
        "id": 1465,
        "no_speech_prob": 0.0005442072870209813,
        "seek": 457460,
        "start": 4586.46,
        "temperature": 0,
        "text": " So our backend is now at this URL.",
        "tokens": [
          50957,
          407,
          527,
          38087,
          307,
          586,
          412,
          341,
          12905,
          13,
          51117
        ]
      },
      {
        "avg_logprob": -0.2256018107369442,
        "compression_ratio": 1.7195571955719557,
        "end": 4591.9800000000005,
        "id": 1466,
        "no_speech_prob": 0.0005442072870209813,
        "seek": 457460,
        "start": 4589.660000000001,
        "temperature": 0,
        "text": " So our frontend, we need to update the code.",
        "tokens": [
          51117,
          407,
          527,
          1868,
          521,
          11,
          321,
          643,
          281,
          5623,
          264,
          3089,
          13,
          51233
        ]
      },
      {
        "avg_logprob": -0.2256018107369442,
        "compression_ratio": 1.7195571955719557,
        "end": 4593.9400000000005,
        "id": 1467,
        "no_speech_prob": 0.0005442072870209813,
        "seek": 457460,
        "start": 4591.9800000000005,
        "temperature": 0,
        "text": " Right now, it's pointed at localhost.",
        "tokens": [
          51233,
          1779,
          586,
          11,
          309,
          311,
          10932,
          412,
          2654,
          6037,
          13,
          51331
        ]
      },
      {
        "avg_logprob": -0.2256018107369442,
        "compression_ratio": 1.7195571955719557,
        "end": 4597.58,
        "id": 1468,
        "no_speech_prob": 0.0005442072870209813,
        "seek": 457460,
        "start": 4593.9400000000005,
        "temperature": 0,
        "text": " So I need to say, if we're on localhost,",
        "tokens": [
          51331,
          407,
          286,
          643,
          281,
          584,
          11,
          498,
          321,
          434,
          322,
          2654,
          6037,
          11,
          51513
        ]
      },
      {
        "avg_logprob": -0.2256018107369442,
        "compression_ratio": 1.7195571955719557,
        "end": 4599.22,
        "id": 1469,
        "no_speech_prob": 0.0005442072870209813,
        "seek": 457460,
        "start": 4597.58,
        "temperature": 0,
        "text": " send the request to localhost.",
        "tokens": [
          51513,
          2845,
          264,
          5308,
          281,
          2654,
          6037,
          13,
          51595
        ]
      },
      {
        "avg_logprob": -0.2256018107369442,
        "compression_ratio": 1.7195571955719557,
        "end": 4602.84,
        "id": 1470,
        "no_speech_prob": 0.0005442072870209813,
        "seek": 457460,
        "start": 4599.22,
        "temperature": 0,
        "text": " Otherwise, send the request to the now server.",
        "tokens": [
          51595,
          10328,
          11,
          2845,
          264,
          5308,
          281,
          264,
          586,
          7154,
          13,
          51776
        ]
      },
      {
        "avg_logprob": -0.21494545424280087,
        "compression_ratio": 1.55,
        "end": 4606.1,
        "id": 1471,
        "no_speech_prob": 0.000029772945708828047,
        "seek": 460284,
        "start": 4602.860000000001,
        "temperature": 0,
        "text": " So I'll say, if process.env, no, no, sorry.",
        "tokens": [
          50365,
          407,
          286,
          603,
          584,
          11,
          498,
          1399,
          13,
          268,
          85,
          11,
          572,
          11,
          572,
          11,
          2597,
          13,
          50527
        ]
      },
      {
        "avg_logprob": -0.21494545424280087,
        "compression_ratio": 1.55,
        "end": 4607.860000000001,
        "id": 1472,
        "no_speech_prob": 0.000029772945708828047,
        "seek": 460284,
        "start": 4606.1,
        "temperature": 0,
        "text": " We're on the frontend, sorry.",
        "tokens": [
          50527,
          492,
          434,
          322,
          264,
          1868,
          521,
          11,
          2597,
          13,
          50615
        ]
      },
      {
        "avg_logprob": -0.21494545424280087,
        "compression_ratio": 1.55,
        "end": 4612.860000000001,
        "id": 1473,
        "no_speech_prob": 0.000029772945708828047,
        "seek": 460284,
        "start": 4607.860000000001,
        "temperature": 0,
        "text": " If window.location.hostname is equal to localhost,",
        "tokens": [
          50615,
          759,
          4910,
          13,
          5842,
          399,
          13,
          6037,
          16344,
          307,
          2681,
          281,
          2654,
          6037,
          11,
          50865
        ]
      },
      {
        "avg_logprob": -0.21494545424280087,
        "compression_ratio": 1.55,
        "end": 4615.18,
        "id": 1474,
        "no_speech_prob": 0.000029772945708828047,
        "seek": 460284,
        "start": 4614.1,
        "temperature": 0,
        "text": " and I'm gonna use a ternary.",
        "tokens": [
          50927,
          293,
          286,
          478,
          799,
          764,
          257,
          256,
          1248,
          822,
          13,
          50981
        ]
      },
      {
        "avg_logprob": -0.21494545424280087,
        "compression_ratio": 1.55,
        "end": 4617.16,
        "id": 1475,
        "no_speech_prob": 0.000029772945708828047,
        "seek": 460284,
        "start": 4615.18,
        "temperature": 0,
        "text": " I'll say, use that URL.",
        "tokens": [
          50981,
          286,
          603,
          584,
          11,
          764,
          300,
          12905,
          13,
          51080
        ]
      },
      {
        "avg_logprob": -0.21494545424280087,
        "compression_ratio": 1.55,
        "end": 4623.78,
        "id": 1476,
        "no_speech_prob": 0.000029772945708828047,
        "seek": 460284,
        "start": 4618.78,
        "temperature": 0,
        "text": " Otherwise, use this URL, https://mus.",
        "tokens": [
          51161,
          10328,
          11,
          764,
          341,
          12905,
          11,
          276,
          83,
          83,
          1878,
          21492,
          18761,
          13,
          51411
        ]
      },
      {
        "avg_logprob": -0.21494545424280087,
        "compression_ratio": 1.55,
        "end": 4629.06,
        "id": 1477,
        "no_speech_prob": 0.000029772945708828047,
        "seek": 460284,
        "start": 4625.9800000000005,
        "temperature": 0,
        "text": " So now, when we're deployed,",
        "tokens": [
          51521,
          407,
          586,
          11,
          562,
          321,
          434,
          17826,
          11,
          51675
        ]
      },
      {
        "avg_logprob": -0.21494545424280087,
        "compression_ratio": 1.55,
        "end": 4630.9800000000005,
        "id": 1478,
        "no_speech_prob": 0.000029772945708828047,
        "seek": 460284,
        "start": 4629.06,
        "temperature": 0,
        "text": " it'll detect that it's not running on localhost,",
        "tokens": [
          51675,
          309,
          603,
          5531,
          300,
          309,
          311,
          406,
          2614,
          322,
          2654,
          6037,
          11,
          51771
        ]
      },
      {
        "avg_logprob": -0.21494545424280087,
        "compression_ratio": 1.55,
        "end": 4632.78,
        "id": 1479,
        "no_speech_prob": 0.000029772945708828047,
        "seek": 460284,
        "start": 4630.9800000000005,
        "temperature": 0,
        "text": " and it'll make the request against our backend,",
        "tokens": [
          51771,
          293,
          309,
          603,
          652,
          264,
          5308,
          1970,
          527,
          38087,
          11,
          51861
        ]
      },
      {
        "avg_logprob": -0.3298391838596292,
        "compression_ratio": 1.6273062730627306,
        "end": 4634.44,
        "id": 1480,
        "no_speech_prob": 0.00001834287468227558,
        "seek": 463278,
        "start": 4633.599999999999,
        "temperature": 0,
        "text": " instead of the frontend.",
        "tokens": [
          50405,
          2602,
          295,
          264,
          1868,
          521,
          13,
          50447
        ]
      },
      {
        "avg_logprob": -0.3298391838596292,
        "compression_ratio": 1.6273062730627306,
        "end": 4635.259999999999,
        "id": 1481,
        "no_speech_prob": 0.00001834287468227558,
        "seek": 463278,
        "start": 4634.44,
        "temperature": 0,
        "text": " And that should do it.",
        "tokens": [
          50447,
          400,
          300,
          820,
          360,
          309,
          13,
          50488
        ]
      },
      {
        "avg_logprob": -0.3298391838596292,
        "compression_ratio": 1.6273062730627306,
        "end": 4637.639999999999,
        "id": 1482,
        "no_speech_prob": 0.00001834287468227558,
        "seek": 463278,
        "start": 4635.259999999999,
        "temperature": 0,
        "text": " Okay, so I'm gonna cd into the client folder.",
        "tokens": [
          50488,
          1033,
          11,
          370,
          286,
          478,
          799,
          269,
          67,
          666,
          264,
          6423,
          10820,
          13,
          50607
        ]
      },
      {
        "avg_logprob": -0.3298391838596292,
        "compression_ratio": 1.6273062730627306,
        "end": 4638.48,
        "id": 1483,
        "no_speech_prob": 0.00001834287468227558,
        "seek": 463278,
        "start": 4637.639999999999,
        "temperature": 0,
        "text": " We'll deploy it.",
        "tokens": [
          50607,
          492,
          603,
          7274,
          309,
          13,
          50649
        ]
      },
      {
        "avg_logprob": -0.3298391838596292,
        "compression_ratio": 1.6273062730627306,
        "end": 4642.48,
        "id": 1484,
        "no_speech_prob": 0.00001834287468227558,
        "seek": 463278,
        "start": 4640.5199999999995,
        "temperature": 0,
        "text": " That was way too easy for deployment.",
        "tokens": [
          50751,
          663,
          390,
          636,
          886,
          1858,
          337,
          19317,
          13,
          50849
        ]
      },
      {
        "avg_logprob": -0.3298391838596292,
        "compression_ratio": 1.6273062730627306,
        "end": 4643.92,
        "id": 1485,
        "no_speech_prob": 0.00001834287468227558,
        "seek": 463278,
        "start": 4642.48,
        "temperature": 0,
        "text": " Now, I feel like, I can't deploy this,",
        "tokens": [
          50849,
          823,
          11,
          286,
          841,
          411,
          11,
          286,
          393,
          380,
          7274,
          341,
          11,
          50921
        ]
      },
      {
        "avg_logprob": -0.3298391838596292,
        "compression_ratio": 1.6273062730627306,
        "end": 4646.48,
        "id": 1486,
        "no_speech_prob": 0.00001834287468227558,
        "seek": 463278,
        "start": 4643.92,
        "temperature": 0,
        "text": " because it'll be three hours before I have it up.",
        "tokens": [
          50921,
          570,
          309,
          603,
          312,
          1045,
          2496,
          949,
          286,
          362,
          309,
          493,
          13,
          51049
        ]
      },
      {
        "avg_logprob": -0.3298391838596292,
        "compression_ratio": 1.6273062730627306,
        "end": 4647.48,
        "id": 1487,
        "no_speech_prob": 0.00001834287468227558,
        "seek": 463278,
        "start": 4646.48,
        "temperature": 0,
        "text": " Three hours.",
        "tokens": [
          51049,
          6244,
          2496,
          13,
          51099
        ]
      },
      {
        "avg_logprob": -0.3298391838596292,
        "compression_ratio": 1.6273062730627306,
        "end": 4650.599999999999,
        "id": 1488,
        "no_speech_prob": 0.00001834287468227558,
        "seek": 463278,
        "start": 4649.759999999999,
        "temperature": 0,
        "text": " Cool.",
        "tokens": [
          51213,
          8561,
          13,
          51255
        ]
      },
      {
        "avg_logprob": -0.3298391838596292,
        "compression_ratio": 1.6273062730627306,
        "end": 4651.5199999999995,
        "id": 1489,
        "no_speech_prob": 0.00001834287468227558,
        "seek": 463278,
        "start": 4650.599999999999,
        "temperature": 0,
        "text": " It actually did deploy this earlier,",
        "tokens": [
          51255,
          467,
          767,
          630,
          7274,
          341,
          3071,
          11,
          51301
        ]
      },
      {
        "avg_logprob": -0.3298391838596292,
        "compression_ratio": 1.6273062730627306,
        "end": 4652.719999999999,
        "id": 1490,
        "no_speech_prob": 0.00001834287468227558,
        "seek": 463278,
        "start": 4651.5199999999995,
        "temperature": 0,
        "text": " so nobody could take my alias,",
        "tokens": [
          51301,
          370,
          5079,
          727,
          747,
          452,
          419,
          4609,
          11,
          51361
        ]
      },
      {
        "avg_logprob": -0.3298391838596292,
        "compression_ratio": 1.6273062730627306,
        "end": 4654.599999999999,
        "id": 1491,
        "no_speech_prob": 0.00001834287468227558,
        "seek": 463278,
        "start": 4652.719999999999,
        "temperature": 0,
        "text": " because somebody might have tried.",
        "tokens": [
          51361,
          570,
          2618,
          1062,
          362,
          3031,
          13,
          51455
        ]
      },
      {
        "avg_logprob": -0.3298391838596292,
        "compression_ratio": 1.6273062730627306,
        "end": 4657.42,
        "id": 1492,
        "no_speech_prob": 0.00001834287468227558,
        "seek": 463278,
        "start": 4654.599999999999,
        "temperature": 0,
        "text": " But now, ta-da!",
        "tokens": [
          51455,
          583,
          586,
          11,
          1846,
          12,
          2675,
          0,
          51596
        ]
      },
      {
        "avg_logprob": -0.3298391838596292,
        "compression_ratio": 1.6273062730627306,
        "end": 4658.259999999999,
        "id": 1493,
        "no_speech_prob": 0.00001834287468227558,
        "seek": 463278,
        "start": 4657.42,
        "temperature": 0,
        "text": " Okay, so.",
        "tokens": [
          51596,
          1033,
          11,
          370,
          13,
          51638
        ]
      },
      {
        "avg_logprob": -0.3298391838596292,
        "compression_ratio": 1.6273062730627306,
        "end": 4661.4,
        "id": 1494,
        "no_speech_prob": 0.00001834287468227558,
        "seek": 463278,
        "start": 4658.259999999999,
        "temperature": 0,
        "text": " I'm ahead of everybody in real time, so what's the URL?",
        "tokens": [
          51638,
          286,
          478,
          2286,
          295,
          2201,
          294,
          957,
          565,
          11,
          370,
          437,
          311,
          264,
          12905,
          30,
          51795
        ]
      },
      {
        "avg_logprob": -0.4511228840002853,
        "compression_ratio": 1.4012738853503184,
        "end": 4666.98,
        "id": 1495,
        "no_speech_prob": 0.00011774425365729257,
        "seek": 466140,
        "start": 4661.98,
        "temperature": 0,
        "text": " It's a meow, er, so meower.now.sh.",
        "tokens": [
          50393,
          467,
          311,
          257,
          45132,
          11,
          1189,
          11,
          370,
          385,
          968,
          13,
          3785,
          13,
          2716,
          13,
          50643
        ]
      },
      {
        "avg_logprob": -0.4511228840002853,
        "compression_ratio": 1.4012738853503184,
        "end": 4670.219999999999,
        "id": 1496,
        "no_speech_prob": 0.00011774425365729257,
        "seek": 466140,
        "start": 4668.62,
        "temperature": 0,
        "text": " God, I'm gonna be the first one.",
        "tokens": [
          50725,
          1265,
          11,
          286,
          478,
          799,
          312,
          264,
          700,
          472,
          13,
          50805
        ]
      },
      {
        "avg_logprob": -0.4511228840002853,
        "compression_ratio": 1.4012738853503184,
        "end": 4671.04,
        "id": 1497,
        "no_speech_prob": 0.00011774425365729257,
        "seek": 466140,
        "start": 4670.219999999999,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          50805,
          876,
          13,
          50846
        ]
      },
      {
        "avg_logprob": -0.4511228840002853,
        "compression_ratio": 1.4012738853503184,
        "end": 4676.36,
        "id": 1498,
        "no_speech_prob": 0.00011774425365729257,
        "seek": 466140,
        "start": 4674.46,
        "temperature": 0,
        "text": " Oh, I don't know how to do the emoji.",
        "tokens": [
          51017,
          876,
          11,
          286,
          500,
          380,
          458,
          577,
          281,
          360,
          264,
          31595,
          13,
          51112
        ]
      },
      {
        "avg_logprob": -0.4511228840002853,
        "compression_ratio": 1.4012738853503184,
        "end": 4681.58,
        "id": 1499,
        "no_speech_prob": 0.00011774425365729257,
        "seek": 466140,
        "start": 4679.98,
        "temperature": 0,
        "text": " People are gonna be faster than me.",
        "tokens": [
          51293,
          3432,
          366,
          799,
          312,
          4663,
          813,
          385,
          13,
          51373
        ]
      },
      {
        "avg_logprob": -0.4511228840002853,
        "compression_ratio": 1.4012738853503184,
        "end": 4682.42,
        "id": 1500,
        "no_speech_prob": 0.00011774425365729257,
        "seek": 466140,
        "start": 4681.58,
        "temperature": 0,
        "text": " Oh no.",
        "tokens": [
          51373,
          876,
          572,
          13,
          51415
        ]
      },
      {
        "avg_logprob": -0.4511228840002853,
        "compression_ratio": 1.4012738853503184,
        "end": 4686.099999999999,
        "id": 1501,
        "no_speech_prob": 0.00011774425365729257,
        "seek": 466140,
        "start": 4683.46,
        "temperature": 0,
        "text": " 429, oh no, something broke.",
        "tokens": [
          51467,
          1017,
          11871,
          11,
          1954,
          572,
          11,
          746,
          6902,
          13,
          51599
        ]
      },
      {
        "avg_logprob": -0.4511228840002853,
        "compression_ratio": 1.4012738853503184,
        "end": 4687.219999999999,
        "id": 1502,
        "no_speech_prob": 0.00011774425365729257,
        "seek": 466140,
        "start": 4686.099999999999,
        "temperature": 0,
        "text": " I'm gonna debug this really quick.",
        "tokens": [
          51599,
          286,
          478,
          799,
          24083,
          341,
          534,
          1702,
          13,
          51655
        ]
      },
      {
        "avg_logprob": -0.4511228840002853,
        "compression_ratio": 1.4012738853503184,
        "end": 4688.0599999999995,
        "id": 1503,
        "no_speech_prob": 0.00011774425365729257,
        "seek": 466140,
        "start": 4687.219999999999,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          51655,
          876,
          13,
          51697
        ]
      },
      {
        "avg_logprob": -0.2986310240510222,
        "compression_ratio": 1.6722972972972974,
        "end": 4690.400000000001,
        "id": 1504,
        "no_speech_prob": 0.00019716857059393078,
        "seek": 468806,
        "start": 4688.080000000001,
        "temperature": 0,
        "text": " It should've just worked.",
        "tokens": [
          50365,
          467,
          820,
          600,
          445,
          2732,
          13,
          50481
        ]
      },
      {
        "avg_logprob": -0.2986310240510222,
        "compression_ratio": 1.6722972972972974,
        "end": 4691.68,
        "id": 1505,
        "no_speech_prob": 0.00019716857059393078,
        "seek": 468806,
        "start": 4690.400000000001,
        "temperature": 0,
        "text": " Okay, let's see.",
        "tokens": [
          50481,
          1033,
          11,
          718,
          311,
          536,
          13,
          50545
        ]
      },
      {
        "avg_logprob": -0.2986310240510222,
        "compression_ratio": 1.6722972972972974,
        "end": 4692.52,
        "id": 1506,
        "no_speech_prob": 0.00019716857059393078,
        "seek": 468806,
        "start": 4691.68,
        "temperature": 0,
        "text": " So that's working.",
        "tokens": [
          50545,
          407,
          300,
          311,
          1364,
          13,
          50587
        ]
      },
      {
        "avg_logprob": -0.2986310240510222,
        "compression_ratio": 1.6722972972972974,
        "end": 4695.84,
        "id": 1507,
        "no_speech_prob": 0.00019716857059393078,
        "seek": 468806,
        "start": 4692.52,
        "temperature": 0,
        "text": " It's not a proper Coding Train episode if it just works.",
        "tokens": [
          50587,
          467,
          311,
          406,
          257,
          2296,
          383,
          8616,
          28029,
          3500,
          498,
          309,
          445,
          1985,
          13,
          50753
        ]
      },
      {
        "avg_logprob": -0.2986310240510222,
        "compression_ratio": 1.6722972972972974,
        "end": 4696.68,
        "id": 1508,
        "no_speech_prob": 0.00019716857059393078,
        "seek": 468806,
        "start": 4695.84,
        "temperature": 0,
        "text": " I guess it should be.",
        "tokens": [
          50753,
          286,
          2041,
          309,
          820,
          312,
          13,
          50795
        ]
      },
      {
        "avg_logprob": -0.2986310240510222,
        "compression_ratio": 1.6722972972972974,
        "end": 4698.200000000001,
        "id": 1509,
        "no_speech_prob": 0.00019716857059393078,
        "seek": 468806,
        "start": 4696.68,
        "temperature": 0,
        "text": " You can have stuff work on your channel.",
        "tokens": [
          50795,
          509,
          393,
          362,
          1507,
          589,
          322,
          428,
          2269,
          13,
          50871
        ]
      },
      {
        "avg_logprob": -0.2986310240510222,
        "compression_ratio": 1.6722972972972974,
        "end": 4700.200000000001,
        "id": 1510,
        "no_speech_prob": 0.00019716857059393078,
        "seek": 468806,
        "start": 4698.200000000001,
        "temperature": 0,
        "text": " Me, it's all about it being broken.",
        "tokens": [
          50871,
          1923,
          11,
          309,
          311,
          439,
          466,
          309,
          885,
          5463,
          13,
          50971
        ]
      },
      {
        "avg_logprob": -0.2986310240510222,
        "compression_ratio": 1.6722972972972974,
        "end": 4702.92,
        "id": 1511,
        "no_speech_prob": 0.00019716857059393078,
        "seek": 468806,
        "start": 4700.200000000001,
        "temperature": 0,
        "text": " Well, I guess, I prepared a lot for today,",
        "tokens": [
          50971,
          1042,
          11,
          286,
          2041,
          11,
          286,
          4927,
          257,
          688,
          337,
          965,
          11,
          51107
        ]
      },
      {
        "avg_logprob": -0.2986310240510222,
        "compression_ratio": 1.6722972972972974,
        "end": 4704.84,
        "id": 1512,
        "no_speech_prob": 0.00019716857059393078,
        "seek": 468806,
        "start": 4702.92,
        "temperature": 0,
        "text": " but on my channel, I guess I haven't talked about it.",
        "tokens": [
          51107,
          457,
          322,
          452,
          2269,
          11,
          286,
          2041,
          286,
          2378,
          380,
          2825,
          466,
          309,
          13,
          51203
        ]
      },
      {
        "avg_logprob": -0.2986310240510222,
        "compression_ratio": 1.6722972972972974,
        "end": 4708.52,
        "id": 1513,
        "no_speech_prob": 0.00019716857059393078,
        "seek": 468806,
        "start": 4704.84,
        "temperature": 0,
        "text": " Sometimes I just make errors, I read the docs,",
        "tokens": [
          51203,
          4803,
          286,
          445,
          652,
          13603,
          11,
          286,
          1401,
          264,
          45623,
          11,
          51387
        ]
      },
      {
        "avg_logprob": -0.2986310240510222,
        "compression_ratio": 1.6722972972972974,
        "end": 4709.820000000001,
        "id": 1514,
        "no_speech_prob": 0.00019716857059393078,
        "seek": 468806,
        "start": 4708.52,
        "temperature": 0,
        "text": " we figure things out live.",
        "tokens": [
          51387,
          321,
          2573,
          721,
          484,
          1621,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.2986310240510222,
        "compression_ratio": 1.6722972972972974,
        "end": 4713.04,
        "id": 1515,
        "no_speech_prob": 0.00019716857059393078,
        "seek": 468806,
        "start": 4711.080000000001,
        "temperature": 0,
        "text": " So the way I'm gonna debug this is,",
        "tokens": [
          51515,
          407,
          264,
          636,
          286,
          478,
          799,
          24083,
          341,
          307,
          11,
          51613
        ]
      },
      {
        "avg_logprob": -0.2986310240510222,
        "compression_ratio": 1.6722972972972974,
        "end": 4715.160000000001,
        "id": 1516,
        "no_speech_prob": 0.00019716857059393078,
        "seek": 468806,
        "start": 4713.04,
        "temperature": 0,
        "text": " I have the element inspector open,",
        "tokens": [
          51613,
          286,
          362,
          264,
          4478,
          34564,
          1269,
          11,
          51719
        ]
      },
      {
        "avg_logprob": -0.2986310240510222,
        "compression_ratio": 1.6722972972972974,
        "end": 4717.400000000001,
        "id": 1517,
        "no_speech_prob": 0.00019716857059393078,
        "seek": 468806,
        "start": 4715.160000000001,
        "temperature": 0,
        "text": " and I wanna look at the network tab",
        "tokens": [
          51719,
          293,
          286,
          1948,
          574,
          412,
          264,
          3209,
          4421,
          51831
        ]
      },
      {
        "avg_logprob": -0.25024542236328123,
        "compression_ratio": 1.6153846153846154,
        "end": 4720.299999999999,
        "id": 1518,
        "no_speech_prob": 0.00006922138709342107,
        "seek": 471740,
        "start": 4717.42,
        "temperature": 0,
        "text": " to see what I'm actually sending to the server.",
        "tokens": [
          50365,
          281,
          536,
          437,
          286,
          478,
          767,
          7750,
          281,
          264,
          7154,
          13,
          50509
        ]
      },
      {
        "avg_logprob": -0.25024542236328123,
        "compression_ratio": 1.6153846153846154,
        "end": 4725.299999999999,
        "id": 1519,
        "no_speech_prob": 0.00006922138709342107,
        "seek": 471740,
        "start": 4720.299999999999,
        "temperature": 0,
        "text": " So when I click Send, this makes a post request to slash Muse",
        "tokens": [
          50509,
          407,
          562,
          286,
          2052,
          17908,
          11,
          341,
          1669,
          257,
          2183,
          5308,
          281,
          17330,
          47293,
          50759
        ]
      },
      {
        "avg_logprob": -0.25024542236328123,
        "compression_ratio": 1.6153846153846154,
        "end": 4731.5,
        "id": 1520,
        "no_speech_prob": 0.00006922138709342107,
        "seek": 471740,
        "start": 4728.54,
        "temperature": 0,
        "text": " and I can see that I am sending the data,",
        "tokens": [
          50921,
          293,
          286,
          393,
          536,
          300,
          286,
          669,
          7750,
          264,
          1412,
          11,
          51069
        ]
      },
      {
        "avg_logprob": -0.25024542236328123,
        "compression_ratio": 1.6153846153846154,
        "end": 4732.62,
        "id": 1521,
        "no_speech_prob": 0.00006922138709342107,
        "seek": 471740,
        "start": 4731.5,
        "temperature": 0,
        "text": " and if I look at the response,",
        "tokens": [
          51069,
          293,
          498,
          286,
          574,
          412,
          264,
          4134,
          11,
          51125
        ]
      },
      {
        "avg_logprob": -0.25024542236328123,
        "compression_ratio": 1.6153846153846154,
        "end": 4735.78,
        "id": 1522,
        "no_speech_prob": 0.00006922138709342107,
        "seek": 471740,
        "start": 4732.62,
        "temperature": 0,
        "text": " too many requests, please try again later.",
        "tokens": [
          51125,
          886,
          867,
          12475,
          11,
          1767,
          853,
          797,
          1780,
          13,
          51283
        ]
      },
      {
        "avg_logprob": -0.25024542236328123,
        "compression_ratio": 1.6153846153846154,
        "end": 4737.179999999999,
        "id": 1523,
        "no_speech_prob": 0.00006922138709342107,
        "seek": 471740,
        "start": 4735.78,
        "temperature": 0,
        "text": " Did you already add something?",
        "tokens": [
          51283,
          2589,
          291,
          1217,
          909,
          746,
          30,
          51353
        ]
      },
      {
        "avg_logprob": -0.25024542236328123,
        "compression_ratio": 1.6153846153846154,
        "end": 4741.219999999999,
        "id": 1524,
        "no_speech_prob": 0.00006922138709342107,
        "seek": 471740,
        "start": 4737.179999999999,
        "temperature": 0,
        "text": " I did attempt to, and then I just got,",
        "tokens": [
          51353,
          286,
          630,
          5217,
          281,
          11,
          293,
          550,
          286,
          445,
          658,
          11,
          51555
        ]
      },
      {
        "avg_logprob": -0.25024542236328123,
        "compression_ratio": 1.6153846153846154,
        "end": 4742.62,
        "id": 1525,
        "no_speech_prob": 0.00006922138709342107,
        "seek": 471740,
        "start": 4741.219999999999,
        "temperature": 0,
        "text": " I mean, I'm just looking at the console,",
        "tokens": [
          51555,
          286,
          914,
          11,
          286,
          478,
          445,
          1237,
          412,
          264,
          11076,
          11,
          51625
        ]
      },
      {
        "avg_logprob": -0.25024542236328123,
        "compression_ratio": 1.6153846153846154,
        "end": 4745.86,
        "id": 1526,
        "no_speech_prob": 0.00006922138709342107,
        "seek": 471740,
        "start": 4742.62,
        "temperature": 0,
        "text": " I just got uncaught syntax, unexpected token, and JSON.",
        "tokens": [
          51625,
          286,
          445,
          658,
          517,
          496,
          1599,
          28431,
          11,
          13106,
          14862,
          11,
          293,
          31828,
          13,
          51787
        ]
      },
      {
        "avg_logprob": -0.25024542236328123,
        "compression_ratio": 1.6153846153846154,
        "end": 4746.94,
        "id": 1527,
        "no_speech_prob": 0.00006922138709342107,
        "seek": 471740,
        "start": 4745.86,
        "temperature": 0,
        "text": " Okay, I think it's working.",
        "tokens": [
          51787,
          1033,
          11,
          286,
          519,
          309,
          311,
          1364,
          13,
          51841
        ]
      },
      {
        "avg_logprob": -0.3416346058701024,
        "compression_ratio": 1.5682656826568266,
        "end": 4749.44,
        "id": 1528,
        "no_speech_prob": 0.00013982139353174716,
        "seek": 474694,
        "start": 4747.36,
        "temperature": 0,
        "text": " I think we've just rate limited ourselves.",
        "tokens": [
          50385,
          286,
          519,
          321,
          600,
          445,
          3314,
          5567,
          4175,
          13,
          50489
        ]
      },
      {
        "avg_logprob": -0.3416346058701024,
        "compression_ratio": 1.5682656826568266,
        "end": 4751.759999999999,
        "id": 1529,
        "no_speech_prob": 0.00013982139353174716,
        "seek": 474694,
        "start": 4750.719999999999,
        "temperature": 0,
        "text": " Oh yeah.",
        "tokens": [
          50553,
          876,
          1338,
          13,
          50605
        ]
      },
      {
        "avg_logprob": -0.3416346058701024,
        "compression_ratio": 1.5682656826568266,
        "end": 4754.28,
        "id": 1530,
        "no_speech_prob": 0.00013982139353174716,
        "seek": 474694,
        "start": 4751.759999999999,
        "temperature": 0,
        "text": " So yeah, so people are submitting things,",
        "tokens": [
          50605,
          407,
          1338,
          11,
          370,
          561,
          366,
          31836,
          721,
          11,
          50731
        ]
      },
      {
        "avg_logprob": -0.3416346058701024,
        "compression_ratio": 1.5682656826568266,
        "end": 4755.099999999999,
        "id": 1531,
        "no_speech_prob": 0.00013982139353174716,
        "seek": 474694,
        "start": 4754.28,
        "temperature": 0,
        "text": " you just have to make sure",
        "tokens": [
          50731,
          291,
          445,
          362,
          281,
          652,
          988,
          50772
        ]
      },
      {
        "avg_logprob": -0.3416346058701024,
        "compression_ratio": 1.5682656826568266,
        "end": 4757.2,
        "id": 1532,
        "no_speech_prob": 0.00013982139353174716,
        "seek": 474694,
        "start": 4755.099999999999,
        "temperature": 0,
        "text": " that you don't do it every 30 seconds.",
        "tokens": [
          50772,
          300,
          291,
          500,
          380,
          360,
          309,
          633,
          2217,
          3949,
          13,
          50877
        ]
      },
      {
        "avg_logprob": -0.3416346058701024,
        "compression_ratio": 1.5682656826568266,
        "end": 4761.44,
        "id": 1533,
        "no_speech_prob": 0.00013982139353174716,
        "seek": 474694,
        "start": 4758.24,
        "temperature": 0,
        "text": " If I look at the backend, it is...",
        "tokens": [
          50929,
          759,
          286,
          574,
          412,
          264,
          38087,
          11,
          309,
          307,
          485,
          51089
        ]
      },
      {
        "avg_logprob": -0.3416346058701024,
        "compression_ratio": 1.5682656826568266,
        "end": 4762.839999999999,
        "id": 1534,
        "no_speech_prob": 0.00013982139353174716,
        "seek": 474694,
        "start": 4761.44,
        "temperature": 0,
        "text": " Could something be caching?",
        "tokens": [
          51089,
          7497,
          746,
          312,
          269,
          2834,
          30,
          51159
        ]
      },
      {
        "avg_logprob": -0.3416346058701024,
        "compression_ratio": 1.5682656826568266,
        "end": 4766.24,
        "id": 1535,
        "no_speech_prob": 0.00013982139353174716,
        "seek": 474694,
        "start": 4764.28,
        "temperature": 0,
        "text": " No, it's weird, huh?",
        "tokens": [
          51231,
          883,
          11,
          309,
          311,
          3657,
          11,
          7020,
          30,
          51329
        ]
      },
      {
        "avg_logprob": -0.3416346058701024,
        "compression_ratio": 1.5682656826568266,
        "end": 4770.36,
        "id": 1536,
        "no_speech_prob": 0.00013982139353174716,
        "seek": 474694,
        "start": 4768.36,
        "temperature": 0,
        "text": " Is it rate limiting by IP address?",
        "tokens": [
          51435,
          1119,
          309,
          3314,
          22083,
          538,
          8671,
          2985,
          30,
          51535
        ]
      },
      {
        "avg_logprob": -0.3416346058701024,
        "compression_ratio": 1.5682656826568266,
        "end": 4771.96,
        "id": 1537,
        "no_speech_prob": 0.00013982139353174716,
        "seek": 474694,
        "start": 4770.36,
        "temperature": 0,
        "text": " So we would potentially be,",
        "tokens": [
          51535,
          407,
          321,
          576,
          7263,
          312,
          11,
          51615
        ]
      },
      {
        "avg_logprob": -0.3416346058701024,
        "compression_ratio": 1.5682656826568266,
        "end": 4773.599999999999,
        "id": 1538,
        "no_speech_prob": 0.00013982139353174716,
        "seek": 474694,
        "start": 4771.96,
        "temperature": 0,
        "text": " I mean, we're getting a dynamic IP address",
        "tokens": [
          51615,
          286,
          914,
          11,
          321,
          434,
          1242,
          257,
          8546,
          8671,
          2985,
          51697
        ]
      },
      {
        "avg_logprob": -0.3416346058701024,
        "compression_ratio": 1.5682656826568266,
        "end": 4775.839999999999,
        "id": 1539,
        "no_speech_prob": 0.00013982139353174716,
        "seek": 474694,
        "start": 4773.599999999999,
        "temperature": 0,
        "text": " from the Wi-Fi here, but it's ultimately gonna end up",
        "tokens": [
          51697,
          490,
          264,
          14035,
          12,
          13229,
          510,
          11,
          457,
          309,
          311,
          6284,
          799,
          917,
          493,
          51809
        ]
      },
      {
        "avg_logprob": -0.3416346058701024,
        "compression_ratio": 1.5682656826568266,
        "end": 4776.679999999999,
        "id": 1540,
        "no_speech_prob": 0.00013982139353174716,
        "seek": 474694,
        "start": 4775.839999999999,
        "temperature": 0,
        "text": " being the same thing.",
        "tokens": [
          51809,
          885,
          264,
          912,
          551,
          13,
          51851
        ]
      },
      {
        "avg_logprob": -0.26110569047339166,
        "compression_ratio": 1.648829431438127,
        "end": 4778.26,
        "id": 1541,
        "no_speech_prob": 0.002980894176289439,
        "seek": 477668,
        "start": 4777.42,
        "temperature": 0,
        "text": " The same IP, so that could be it.",
        "tokens": [
          50401,
          440,
          912,
          8671,
          11,
          370,
          300,
          727,
          312,
          309,
          13,
          50443
        ]
      },
      {
        "avg_logprob": -0.26110569047339166,
        "compression_ratio": 1.648829431438127,
        "end": 4779.58,
        "id": 1542,
        "no_speech_prob": 0.002980894176289439,
        "seek": 477668,
        "start": 4778.26,
        "temperature": 0,
        "text": " I'll just keep refreshing this.",
        "tokens": [
          50443,
          286,
          603,
          445,
          1066,
          19772,
          341,
          13,
          50509
        ]
      },
      {
        "avg_logprob": -0.26110569047339166,
        "compression_ratio": 1.648829431438127,
        "end": 4781.700000000001,
        "id": 1543,
        "no_speech_prob": 0.002980894176289439,
        "seek": 477668,
        "start": 4779.58,
        "temperature": 0,
        "text": " Okay, there's some people, there's some emails.",
        "tokens": [
          50509,
          1033,
          11,
          456,
          311,
          512,
          561,
          11,
          456,
          311,
          512,
          12524,
          13,
          50615
        ]
      },
      {
        "avg_logprob": -0.26110569047339166,
        "compression_ratio": 1.648829431438127,
        "end": 4783.14,
        "id": 1544,
        "no_speech_prob": 0.002980894176289439,
        "seek": 477668,
        "start": 4781.700000000001,
        "temperature": 0,
        "text": " So it's working for stuff, I just didn't want",
        "tokens": [
          50615,
          407,
          309,
          311,
          1364,
          337,
          1507,
          11,
          286,
          445,
          994,
          380,
          528,
          50687
        ]
      },
      {
        "avg_logprob": -0.26110569047339166,
        "compression_ratio": 1.648829431438127,
        "end": 4785.9800000000005,
        "id": 1545,
        "no_speech_prob": 0.002980894176289439,
        "seek": 477668,
        "start": 4783.14,
        "temperature": 0,
        "text": " to totally open it to the world",
        "tokens": [
          50687,
          281,
          3879,
          1269,
          309,
          281,
          264,
          1002,
          50829
        ]
      },
      {
        "avg_logprob": -0.26110569047339166,
        "compression_ratio": 1.648829431438127,
        "end": 4787.96,
        "id": 1546,
        "no_speech_prob": 0.002980894176289439,
        "seek": 477668,
        "start": 4785.9800000000005,
        "temperature": 0,
        "text": " because this could wreak havoc.",
        "tokens": [
          50829,
          570,
          341,
          727,
          46674,
          514,
          47367,
          13,
          50928
        ]
      },
      {
        "avg_logprob": -0.26110569047339166,
        "compression_ratio": 1.648829431438127,
        "end": 4790.66,
        "id": 1547,
        "no_speech_prob": 0.002980894176289439,
        "seek": 477668,
        "start": 4789.820000000001,
        "temperature": 0,
        "text": " Cool.",
        "tokens": [
          51021,
          8561,
          13,
          51063
        ]
      },
      {
        "avg_logprob": -0.26110569047339166,
        "compression_ratio": 1.648829431438127,
        "end": 4791.780000000001,
        "id": 1548,
        "no_speech_prob": 0.002980894176289439,
        "seek": 477668,
        "start": 4790.66,
        "temperature": 0,
        "text": " Shut it down, shut it down!",
        "tokens": [
          51063,
          13870,
          309,
          760,
          11,
          5309,
          309,
          760,
          0,
          51119
        ]
      },
      {
        "avg_logprob": -0.26110569047339166,
        "compression_ratio": 1.648829431438127,
        "end": 4794.9800000000005,
        "id": 1549,
        "no_speech_prob": 0.002980894176289439,
        "seek": 477668,
        "start": 4793.5,
        "temperature": 0,
        "text": " Cool, I think that's it.",
        "tokens": [
          51205,
          8561,
          11,
          286,
          519,
          300,
          311,
          309,
          13,
          51279
        ]
      },
      {
        "avg_logprob": -0.26110569047339166,
        "compression_ratio": 1.648829431438127,
        "end": 4795.9800000000005,
        "id": 1550,
        "no_speech_prob": 0.002980894176289439,
        "seek": 477668,
        "start": 4794.9800000000005,
        "temperature": 0,
        "text": " Yeah, so if there's other questions,",
        "tokens": [
          51279,
          865,
          11,
          370,
          498,
          456,
          311,
          661,
          1651,
          11,
          51329
        ]
      },
      {
        "avg_logprob": -0.26110569047339166,
        "compression_ratio": 1.648829431438127,
        "end": 4798.22,
        "id": 1551,
        "no_speech_prob": 0.002980894176289439,
        "seek": 477668,
        "start": 4795.9800000000005,
        "temperature": 0,
        "text": " I guess I can talk about my setup,",
        "tokens": [
          51329,
          286,
          2041,
          286,
          393,
          751,
          466,
          452,
          8657,
          11,
          51441
        ]
      },
      {
        "avg_logprob": -0.26110569047339166,
        "compression_ratio": 1.648829431438127,
        "end": 4799.5,
        "id": 1552,
        "no_speech_prob": 0.002980894176289439,
        "seek": 477668,
        "start": 4798.22,
        "temperature": 0,
        "text": " what I do on my channel.",
        "tokens": [
          51441,
          437,
          286,
          360,
          322,
          452,
          2269,
          13,
          51505
        ]
      },
      {
        "avg_logprob": -0.26110569047339166,
        "compression_ratio": 1.648829431438127,
        "end": 4801.46,
        "id": 1553,
        "no_speech_prob": 0.002980894176289439,
        "seek": 477668,
        "start": 4799.5,
        "temperature": 0,
        "text": " Oh yeah, before that, what's next?",
        "tokens": [
          51505,
          876,
          1338,
          11,
          949,
          300,
          11,
          437,
          311,
          958,
          30,
          51603
        ]
      },
      {
        "avg_logprob": -0.26110569047339166,
        "compression_ratio": 1.648829431438127,
        "end": 4803.5,
        "id": 1554,
        "no_speech_prob": 0.002980894176289439,
        "seek": 477668,
        "start": 4801.46,
        "temperature": 0,
        "text": " So this is very, very basic, right?",
        "tokens": [
          51603,
          407,
          341,
          307,
          588,
          11,
          588,
          3875,
          11,
          558,
          30,
          51705
        ]
      },
      {
        "avg_logprob": -0.26110569047339166,
        "compression_ratio": 1.648829431438127,
        "end": 4805.42,
        "id": 1555,
        "no_speech_prob": 0.002980894176289439,
        "seek": 477668,
        "start": 4803.5,
        "temperature": 0,
        "text": " This is, we have a form, you click submit,",
        "tokens": [
          51705,
          639,
          307,
          11,
          321,
          362,
          257,
          1254,
          11,
          291,
          2052,
          10315,
          11,
          51801
        ]
      },
      {
        "avg_logprob": -0.2500197761937192,
        "compression_ratio": 1.7658227848101267,
        "end": 4807.06,
        "id": 1556,
        "no_speech_prob": 0.0007553978939540684,
        "seek": 480542,
        "start": 4805.4400000000005,
        "temperature": 0,
        "text": " it gets listed on the page.",
        "tokens": [
          50365,
          309,
          2170,
          10052,
          322,
          264,
          3028,
          13,
          50446
        ]
      },
      {
        "avg_logprob": -0.2500197761937192,
        "compression_ratio": 1.7658227848101267,
        "end": 4810.96,
        "id": 1557,
        "no_speech_prob": 0.0007553978939540684,
        "seek": 480542,
        "start": 4809.08,
        "temperature": 0,
        "text": " But if you think about Twitter, there's more.",
        "tokens": [
          50547,
          583,
          498,
          291,
          519,
          466,
          5794,
          11,
          456,
          311,
          544,
          13,
          50641
        ]
      },
      {
        "avg_logprob": -0.2500197761937192,
        "compression_ratio": 1.7658227848101267,
        "end": 4813.24,
        "id": 1558,
        "no_speech_prob": 0.0007553978939540684,
        "seek": 480542,
        "start": 4810.96,
        "temperature": 0,
        "text": " There's user profiles, there's searching tweets,",
        "tokens": [
          50641,
          821,
          311,
          4195,
          23693,
          11,
          456,
          311,
          10808,
          25671,
          11,
          50755
        ]
      },
      {
        "avg_logprob": -0.2500197761937192,
        "compression_ratio": 1.7658227848101267,
        "end": 4816.36,
        "id": 1559,
        "no_speech_prob": 0.0007553978939540684,
        "seek": 480542,
        "start": 4813.24,
        "temperature": 0,
        "text": " there's tagging, so we could take this code here,",
        "tokens": [
          50755,
          456,
          311,
          6162,
          3249,
          11,
          370,
          321,
          727,
          747,
          341,
          3089,
          510,
          11,
          50911
        ]
      },
      {
        "avg_logprob": -0.2500197761937192,
        "compression_ratio": 1.7658227848101267,
        "end": 4817.92,
        "id": 1560,
        "no_speech_prob": 0.0007553978939540684,
        "seek": 480542,
        "start": 4816.36,
        "temperature": 0,
        "text": " we could add comments and replies,",
        "tokens": [
          50911,
          321,
          727,
          909,
          3053,
          293,
          42289,
          11,
          50989
        ]
      },
      {
        "avg_logprob": -0.2500197761937192,
        "compression_ratio": 1.7658227848101267,
        "end": 4819.4400000000005,
        "id": 1561,
        "no_speech_prob": 0.0007553978939540684,
        "seek": 480542,
        "start": 4817.92,
        "temperature": 0,
        "text": " so you could reply to a Mew,",
        "tokens": [
          50989,
          370,
          291,
          727,
          16972,
          281,
          257,
          376,
          1023,
          11,
          51065
        ]
      },
      {
        "avg_logprob": -0.2500197761937192,
        "compression_ratio": 1.7658227848101267,
        "end": 4820.8,
        "id": 1562,
        "no_speech_prob": 0.0007553978939540684,
        "seek": 480542,
        "start": 4819.4400000000005,
        "temperature": 0,
        "text": " we could create user accounts",
        "tokens": [
          51065,
          321,
          727,
          1884,
          4195,
          9402,
          51133
        ]
      },
      {
        "avg_logprob": -0.2500197761937192,
        "compression_ratio": 1.7658227848101267,
        "end": 4822.72,
        "id": 1563,
        "no_speech_prob": 0.0007553978939540684,
        "seek": 480542,
        "start": 4820.8,
        "temperature": 0,
        "text": " where you can have specific ones,",
        "tokens": [
          51133,
          689,
          291,
          393,
          362,
          2685,
          2306,
          11,
          51229
        ]
      },
      {
        "avg_logprob": -0.2500197761937192,
        "compression_ratio": 1.7658227848101267,
        "end": 4824.84,
        "id": 1564,
        "no_speech_prob": 0.0007553978939540684,
        "seek": 480542,
        "start": 4822.72,
        "temperature": 0,
        "text": " because right now, if somebody else types in the same name,",
        "tokens": [
          51229,
          570,
          558,
          586,
          11,
          498,
          2618,
          1646,
          3467,
          294,
          264,
          912,
          1315,
          11,
          51335
        ]
      },
      {
        "avg_logprob": -0.2500197761937192,
        "compression_ratio": 1.7658227848101267,
        "end": 4827.88,
        "id": 1565,
        "no_speech_prob": 0.0007553978939540684,
        "seek": 480542,
        "start": 4824.84,
        "temperature": 0,
        "text": " they appear like they're coming from the same person.",
        "tokens": [
          51335,
          436,
          4204,
          411,
          436,
          434,
          1348,
          490,
          264,
          912,
          954,
          13,
          51487
        ]
      },
      {
        "avg_logprob": -0.2500197761937192,
        "compression_ratio": 1.7658227848101267,
        "end": 4829.86,
        "id": 1566,
        "no_speech_prob": 0.0007553978939540684,
        "seek": 480542,
        "start": 4827.88,
        "temperature": 0,
        "text": " Sorry to interrupt, I don't know if this is true,",
        "tokens": [
          51487,
          4919,
          281,
          12729,
          11,
          286,
          500,
          380,
          458,
          498,
          341,
          307,
          2074,
          11,
          51586
        ]
      },
      {
        "avg_logprob": -0.2500197761937192,
        "compression_ratio": 1.7658227848101267,
        "end": 4832,
        "id": 1567,
        "no_speech_prob": 0.0007553978939540684,
        "seek": 480542,
        "start": 4829.86,
        "temperature": 0,
        "text": " but the chat is suggesting that the rate limit",
        "tokens": [
          51586,
          457,
          264,
          5081,
          307,
          18094,
          300,
          264,
          3314,
          4948,
          51693
        ]
      },
      {
        "avg_logprob": -0.2500197761937192,
        "compression_ratio": 1.7658227848101267,
        "end": 4834.42,
        "id": 1568,
        "no_speech_prob": 0.0007553978939540684,
        "seek": 480542,
        "start": 4832,
        "temperature": 0,
        "text": " is actually a single rate limit for everybody.",
        "tokens": [
          51693,
          307,
          767,
          257,
          2167,
          3314,
          4948,
          337,
          2201,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.31867204553940714,
        "compression_ratio": 1.6211180124223603,
        "end": 4837.32,
        "id": 1569,
        "no_speech_prob": 0.000058291036111768335,
        "seek": 483442,
        "start": 4834.4800000000005,
        "temperature": 0,
        "text": " So only anybody, so like once somebody posts,",
        "tokens": [
          50367,
          407,
          787,
          4472,
          11,
          370,
          411,
          1564,
          2618,
          12300,
          11,
          50509
        ]
      },
      {
        "avg_logprob": -0.31867204553940714,
        "compression_ratio": 1.6211180124223603,
        "end": 4838.76,
        "id": 1570,
        "no_speech_prob": 0.000058291036111768335,
        "seek": 483442,
        "start": 4837.32,
        "temperature": 0,
        "text": " nobody can post for 30 more seconds.",
        "tokens": [
          50509,
          5079,
          393,
          2183,
          337,
          2217,
          544,
          3949,
          13,
          50581
        ]
      },
      {
        "avg_logprob": -0.31867204553940714,
        "compression_ratio": 1.6211180124223603,
        "end": 4839.64,
        "id": 1571,
        "no_speech_prob": 0.000058291036111768335,
        "seek": 483442,
        "start": 4838.76,
        "temperature": 0,
        "text": " I don't know if that's true,",
        "tokens": [
          50581,
          286,
          500,
          380,
          458,
          498,
          300,
          311,
          2074,
          11,
          50625
        ]
      },
      {
        "avg_logprob": -0.31867204553940714,
        "compression_ratio": 1.6211180124223603,
        "end": 4841.56,
        "id": 1572,
        "no_speech_prob": 0.000058291036111768335,
        "seek": 483442,
        "start": 4839.64,
        "temperature": 0,
        "text": " that was just being posited by the chat.",
        "tokens": [
          50625,
          300,
          390,
          445,
          885,
          1366,
          1226,
          538,
          264,
          5081,
          13,
          50721
        ]
      },
      {
        "avg_logprob": -0.31867204553940714,
        "compression_ratio": 1.6211180124223603,
        "end": 4843.8,
        "id": 1573,
        "no_speech_prob": 0.000058291036111768335,
        "seek": 483442,
        "start": 4841.56,
        "temperature": 0,
        "text": " This is based on IP address.",
        "tokens": [
          50721,
          639,
          307,
          2361,
          322,
          8671,
          2985,
          13,
          50833
        ]
      },
      {
        "avg_logprob": -0.31867204553940714,
        "compression_ratio": 1.6211180124223603,
        "end": 4845.08,
        "id": 1574,
        "no_speech_prob": 0.000058291036111768335,
        "seek": 483442,
        "start": 4843.8,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50833,
          1033,
          13,
          50897
        ]
      },
      {
        "avg_logprob": -0.31867204553940714,
        "compression_ratio": 1.6211180124223603,
        "end": 4846.06,
        "id": 1575,
        "no_speech_prob": 0.000058291036111768335,
        "seek": 483442,
        "start": 4845.08,
        "temperature": 0,
        "text": " I believe.",
        "tokens": [
          50897,
          286,
          1697,
          13,
          50946
        ]
      },
      {
        "avg_logprob": -0.31867204553940714,
        "compression_ratio": 1.6211180124223603,
        "end": 4848.52,
        "id": 1576,
        "no_speech_prob": 0.000058291036111768335,
        "seek": 483442,
        "start": 4847.32,
        "temperature": 0,
        "text": " Well, we don't have to debug that right now.",
        "tokens": [
          51009,
          1042,
          11,
          321,
          500,
          380,
          362,
          281,
          24083,
          300,
          558,
          586,
          13,
          51069
        ]
      },
      {
        "avg_logprob": -0.31867204553940714,
        "compression_ratio": 1.6211180124223603,
        "end": 4849.52,
        "id": 1577,
        "no_speech_prob": 0.000058291036111768335,
        "seek": 483442,
        "start": 4848.52,
        "temperature": 0,
        "text": " Yeah, don't debug it.",
        "tokens": [
          51069,
          865,
          11,
          500,
          380,
          24083,
          309,
          13,
          51119
        ]
      },
      {
        "avg_logprob": -0.31867204553940714,
        "compression_ratio": 1.6211180124223603,
        "end": 4850.36,
        "id": 1578,
        "no_speech_prob": 0.000058291036111768335,
        "seek": 483442,
        "start": 4849.52,
        "temperature": 0,
        "text": " We won't.",
        "tokens": [
          51119,
          492,
          1582,
          380,
          13,
          51161
        ]
      },
      {
        "avg_logprob": -0.31867204553940714,
        "compression_ratio": 1.6211180124223603,
        "end": 4852.68,
        "id": 1579,
        "no_speech_prob": 0.000058291036111768335,
        "seek": 483442,
        "start": 4851.32,
        "temperature": 0,
        "text": " But again, like all the features of Twitter,",
        "tokens": [
          51209,
          583,
          797,
          11,
          411,
          439,
          264,
          4122,
          295,
          5794,
          11,
          51277
        ]
      },
      {
        "avg_logprob": -0.31867204553940714,
        "compression_ratio": 1.6211180124223603,
        "end": 4854.28,
        "id": 1580,
        "no_speech_prob": 0.000058291036111768335,
        "seek": 483442,
        "start": 4852.68,
        "temperature": 0,
        "text": " we could start to write this.",
        "tokens": [
          51277,
          321,
          727,
          722,
          281,
          2464,
          341,
          13,
          51357
        ]
      },
      {
        "avg_logprob": -0.31867204553940714,
        "compression_ratio": 1.6211180124223603,
        "end": 4856.12,
        "id": 1581,
        "no_speech_prob": 0.000058291036111768335,
        "seek": 483442,
        "start": 4854.28,
        "temperature": 0,
        "text": " And so probably on my channel pretty soon,",
        "tokens": [
          51357,
          400,
          370,
          1391,
          322,
          452,
          2269,
          1238,
          2321,
          11,
          51449
        ]
      },
      {
        "avg_logprob": -0.31867204553940714,
        "compression_ratio": 1.6211180124223603,
        "end": 4857.4,
        "id": 1582,
        "no_speech_prob": 0.000058291036111768335,
        "seek": 483442,
        "start": 4856.12,
        "temperature": 0,
        "text": " I'll start to add features to this",
        "tokens": [
          51449,
          286,
          603,
          722,
          281,
          909,
          4122,
          281,
          341,
          51513
        ]
      },
      {
        "avg_logprob": -0.31867204553940714,
        "compression_ratio": 1.6211180124223603,
        "end": 4859.84,
        "id": 1583,
        "no_speech_prob": 0.000058291036111768335,
        "seek": 483442,
        "start": 4857.4,
        "temperature": 0,
        "text": " and we can work on it as well.",
        "tokens": [
          51513,
          293,
          321,
          393,
          589,
          322,
          309,
          382,
          731,
          13,
          51635
        ]
      },
      {
        "avg_logprob": -0.31867204553940714,
        "compression_ratio": 1.6211180124223603,
        "end": 4860.66,
        "id": 1584,
        "no_speech_prob": 0.000058291036111768335,
        "seek": 483442,
        "start": 4859.84,
        "temperature": 0,
        "text": " That's it.",
        "tokens": [
          51635,
          663,
          311,
          309,
          13,
          51676
        ]
      },
      {
        "avg_logprob": -0.31867204553940714,
        "compression_ratio": 1.6211180124223603,
        "end": 4861.5,
        "id": 1585,
        "no_speech_prob": 0.000058291036111768335,
        "seek": 483442,
        "start": 4860.66,
        "temperature": 0,
        "text": " Awesome.",
        "tokens": [
          51676,
          10391,
          13,
          51718
        ]
      },
      {
        "avg_logprob": -0.31867204553940714,
        "compression_ratio": 1.6211180124223603,
        "end": 4863.46,
        "id": 1586,
        "no_speech_prob": 0.000058291036111768335,
        "seek": 483442,
        "start": 4861.5,
        "temperature": 0,
        "text": " So before, I do wanna say a couple things.",
        "tokens": [
          51718,
          407,
          949,
          11,
          286,
          360,
          1948,
          584,
          257,
          1916,
          721,
          13,
          51816
        ]
      },
      {
        "avg_logprob": -0.3302234864570725,
        "compression_ratio": 1.6366559485530547,
        "end": 4866.04,
        "id": 1587,
        "no_speech_prob": 0.0002453596389386803,
        "seek": 486346,
        "start": 4864.28,
        "temperature": 0,
        "text": " Well, one is people are so interested",
        "tokens": [
          50405,
          1042,
          11,
          472,
          307,
          561,
          366,
          370,
          3102,
          50493
        ]
      },
      {
        "avg_logprob": -0.3302234864570725,
        "compression_ratio": 1.6366559485530547,
        "end": 4869.4,
        "id": 1588,
        "no_speech_prob": 0.0002453596389386803,
        "seek": 486346,
        "start": 4866.04,
        "temperature": 0,
        "text": " in your kind of like theme setup font stuff.",
        "tokens": [
          50493,
          294,
          428,
          733,
          295,
          411,
          6314,
          8657,
          10703,
          1507,
          13,
          50661
        ]
      },
      {
        "avg_logprob": -0.3302234864570725,
        "compression_ratio": 1.6366559485530547,
        "end": 4871.64,
        "id": 1589,
        "no_speech_prob": 0.0002453596389386803,
        "seek": 486346,
        "start": 4869.4,
        "temperature": 0,
        "text": " So do you wanna take a minute to just,",
        "tokens": [
          50661,
          407,
          360,
          291,
          1948,
          747,
          257,
          3456,
          281,
          445,
          11,
          50773
        ]
      },
      {
        "avg_logprob": -0.3302234864570725,
        "compression_ratio": 1.6366559485530547,
        "end": 4875.6,
        "id": 1590,
        "no_speech_prob": 0.0002453596389386803,
        "seek": 486346,
        "start": 4871.64,
        "temperature": 0,
        "text": " so mostly I would suggest subscribe to CJ's channel",
        "tokens": [
          50773,
          370,
          5240,
          286,
          576,
          3402,
          3022,
          281,
          42285,
          311,
          2269,
          50971
        ]
      },
      {
        "avg_logprob": -0.3302234864570725,
        "compression_ratio": 1.6366559485530547,
        "end": 4878.64,
        "id": 1591,
        "no_speech_prob": 0.0002453596389386803,
        "seek": 486346,
        "start": 4875.6,
        "temperature": 0,
        "text": " and then go over all the stuff in like a lot more detail.",
        "tokens": [
          50971,
          293,
          550,
          352,
          670,
          439,
          264,
          1507,
          294,
          411,
          257,
          688,
          544,
          2607,
          13,
          51123
        ]
      },
      {
        "avg_logprob": -0.3302234864570725,
        "compression_ratio": 1.6366559485530547,
        "end": 4880.28,
        "id": 1592,
        "no_speech_prob": 0.0002453596389386803,
        "seek": 486346,
        "start": 4878.64,
        "temperature": 0,
        "text": " But just for the people watching right now,",
        "tokens": [
          51123,
          583,
          445,
          337,
          264,
          561,
          1976,
          558,
          586,
          11,
          51205
        ]
      },
      {
        "avg_logprob": -0.3302234864570725,
        "compression_ratio": 1.6366559485530547,
        "end": 4882.4800000000005,
        "id": 1593,
        "no_speech_prob": 0.0002453596389386803,
        "seek": 486346,
        "start": 4880.28,
        "temperature": 0,
        "text": " are there a quick few things about like",
        "tokens": [
          51205,
          366,
          456,
          257,
          1702,
          1326,
          721,
          466,
          411,
          51315
        ]
      },
      {
        "avg_logprob": -0.3302234864570725,
        "compression_ratio": 1.6366559485530547,
        "end": 4884.56,
        "id": 1594,
        "no_speech_prob": 0.0002453596389386803,
        "seek": 486346,
        "start": 4882.4800000000005,
        "temperature": 0,
        "text": " the what terminal application you're using,",
        "tokens": [
          51315,
          264,
          437,
          14709,
          3861,
          291,
          434,
          1228,
          11,
          51419
        ]
      },
      {
        "avg_logprob": -0.3302234864570725,
        "compression_ratio": 1.6366559485530547,
        "end": 4886.52,
        "id": 1595,
        "no_speech_prob": 0.0002453596389386803,
        "seek": 486346,
        "start": 4884.56,
        "temperature": 0,
        "text": " what theme you're using in Visual Studio Code?",
        "tokens": [
          51419,
          437,
          6314,
          291,
          434,
          1228,
          294,
          23187,
          13500,
          15549,
          30,
          51517
        ]
      },
      {
        "avg_logprob": -0.3302234864570725,
        "compression_ratio": 1.6366559485530547,
        "end": 4888.04,
        "id": 1596,
        "no_speech_prob": 0.0002453596389386803,
        "seek": 486346,
        "start": 4886.52,
        "temperature": 0,
        "text": " I actually did a video on this, so.",
        "tokens": [
          51517,
          286,
          767,
          630,
          257,
          960,
          322,
          341,
          11,
          370,
          13,
          51593
        ]
      },
      {
        "avg_logprob": -0.3302234864570725,
        "compression_ratio": 1.6366559485530547,
        "end": 4889.4,
        "id": 1597,
        "no_speech_prob": 0.0002453596389386803,
        "seek": 486346,
        "start": 4888.04,
        "temperature": 0,
        "text": " Oh, there you go.",
        "tokens": [
          51593,
          876,
          11,
          456,
          291,
          352,
          13,
          51661
        ]
      },
      {
        "avg_logprob": -0.3302234864570725,
        "compression_ratio": 1.6366559485530547,
        "end": 4891.96,
        "id": 1598,
        "no_speech_prob": 0.0002453596389386803,
        "seek": 486346,
        "start": 4889.4,
        "temperature": 0,
        "text": " You know, yeah, but I will like talk through it.",
        "tokens": [
          51661,
          509,
          458,
          11,
          1338,
          11,
          457,
          286,
          486,
          411,
          751,
          807,
          309,
          13,
          51789
        ]
      },
      {
        "avg_logprob": -0.2499307985658999,
        "compression_ratio": 1.7038461538461538,
        "end": 4894.06,
        "id": 1599,
        "no_speech_prob": 0.00006401950668077916,
        "seek": 489196,
        "start": 4892.62,
        "temperature": 0,
        "text": " If you search on my channel,",
        "tokens": [
          50397,
          759,
          291,
          3164,
          322,
          452,
          2269,
          11,
          50469
        ]
      },
      {
        "avg_logprob": -0.2499307985658999,
        "compression_ratio": 1.7038461538461538,
        "end": 4898.74,
        "id": 1600,
        "no_speech_prob": 0.00006401950668077916,
        "seek": 489196,
        "start": 4894.06,
        "temperature": 0,
        "text": " it's Coding Garden Setup Mac, I think.",
        "tokens": [
          50469,
          309,
          311,
          383,
          8616,
          19429,
          8928,
          1010,
          5707,
          11,
          286,
          519,
          13,
          50703
        ]
      },
      {
        "avg_logprob": -0.2499307985658999,
        "compression_ratio": 1.7038461538461538,
        "end": 4901.26,
        "id": 1601,
        "no_speech_prob": 0.00006401950668077916,
        "seek": 489196,
        "start": 4898.74,
        "temperature": 0,
        "text": " Yeah, so setting up a Mac for web development.",
        "tokens": [
          50703,
          865,
          11,
          370,
          3287,
          493,
          257,
          5707,
          337,
          3670,
          3250,
          13,
          50829
        ]
      },
      {
        "avg_logprob": -0.2499307985658999,
        "compression_ratio": 1.7038461538461538,
        "end": 4902.62,
        "id": 1602,
        "no_speech_prob": 0.00006401950668077916,
        "seek": 489196,
        "start": 4901.26,
        "temperature": 0,
        "text": " I talk about.",
        "tokens": [
          50829,
          286,
          751,
          466,
          13,
          50897
        ]
      },
      {
        "avg_logprob": -0.2499307985658999,
        "compression_ratio": 1.7038461538461538,
        "end": 4903.46,
        "id": 1603,
        "no_speech_prob": 0.00006401950668077916,
        "seek": 489196,
        "start": 4902.62,
        "temperature": 0,
        "text": " Sorry.",
        "tokens": [
          50897,
          4919,
          13,
          50939
        ]
      },
      {
        "avg_logprob": -0.2499307985658999,
        "compression_ratio": 1.7038461538461538,
        "end": 4905.22,
        "id": 1604,
        "no_speech_prob": 0.00006401950668077916,
        "seek": 489196,
        "start": 4903.46,
        "temperature": 0,
        "text": " No worries, no worries.",
        "tokens": [
          50939,
          883,
          16340,
          11,
          572,
          16340,
          13,
          51027
        ]
      },
      {
        "avg_logprob": -0.2499307985658999,
        "compression_ratio": 1.7038461538461538,
        "end": 4907.02,
        "id": 1605,
        "no_speech_prob": 0.00006401950668077916,
        "seek": 489196,
        "start": 4905.22,
        "temperature": 0,
        "text": " I talk about the code editor I'm using.",
        "tokens": [
          51027,
          286,
          751,
          466,
          264,
          3089,
          9839,
          286,
          478,
          1228,
          13,
          51117
        ]
      },
      {
        "avg_logprob": -0.2499307985658999,
        "compression_ratio": 1.7038461538461538,
        "end": 4908.94,
        "id": 1606,
        "no_speech_prob": 0.00006401950668077916,
        "seek": 489196,
        "start": 4907.02,
        "temperature": 0,
        "text": " I talk about how I set up my terminal.",
        "tokens": [
          51117,
          286,
          751,
          466,
          577,
          286,
          992,
          493,
          452,
          14709,
          13,
          51213
        ]
      },
      {
        "avg_logprob": -0.2499307985658999,
        "compression_ratio": 1.7038461538461538,
        "end": 4912.54,
        "id": 1607,
        "no_speech_prob": 0.00006401950668077916,
        "seek": 489196,
        "start": 4908.94,
        "temperature": 0,
        "text": " I talk about how I, all the extensions I'm using for VS Code.",
        "tokens": [
          51213,
          286,
          751,
          466,
          577,
          286,
          11,
          439,
          264,
          25129,
          286,
          478,
          1228,
          337,
          25091,
          15549,
          13,
          51393
        ]
      },
      {
        "avg_logprob": -0.2499307985658999,
        "compression_ratio": 1.7038461538461538,
        "end": 4916.02,
        "id": 1608,
        "no_speech_prob": 0.00006401950668077916,
        "seek": 489196,
        "start": 4912.54,
        "temperature": 0,
        "text": " I talk about basically how I have all this set up.",
        "tokens": [
          51393,
          286,
          751,
          466,
          1936,
          577,
          286,
          362,
          439,
          341,
          992,
          493,
          13,
          51567
        ]
      },
      {
        "avg_logprob": -0.2499307985658999,
        "compression_ratio": 1.7038461538461538,
        "end": 4918.02,
        "id": 1609,
        "no_speech_prob": 0.00006401950668077916,
        "seek": 489196,
        "start": 4916.02,
        "temperature": 0,
        "text": " Were there specific questions about?",
        "tokens": [
          51567,
          12448,
          456,
          2685,
          1651,
          466,
          30,
          51667
        ]
      },
      {
        "avg_logprob": -0.2499307985658999,
        "compression_ratio": 1.7038461538461538,
        "end": 4920.78,
        "id": 1610,
        "no_speech_prob": 0.00006401950668077916,
        "seek": 489196,
        "start": 4918.02,
        "temperature": 0,
        "text": " I think people were just like, which font, what color?",
        "tokens": [
          51667,
          286,
          519,
          561,
          645,
          445,
          411,
          11,
          597,
          10703,
          11,
          437,
          2017,
          30,
          51805
        ]
      },
      {
        "avg_logprob": -0.2779780643087038,
        "compression_ratio": 1.6195286195286196,
        "end": 4922.36,
        "id": 1611,
        "no_speech_prob": 0.000016964395399554633,
        "seek": 492078,
        "start": 4920.8,
        "temperature": 0,
        "text": " So that can be the answer.",
        "tokens": [
          50365,
          407,
          300,
          393,
          312,
          264,
          1867,
          13,
          50443
        ]
      },
      {
        "avg_logprob": -0.2779780643087038,
        "compression_ratio": 1.6195286195286196,
        "end": 4924.4,
        "id": 1612,
        "no_speech_prob": 0.000016964395399554633,
        "seek": 492078,
        "start": 4922.36,
        "temperature": 0,
        "text": " Maybe you have this documented in a separate video",
        "tokens": [
          50443,
          2704,
          291,
          362,
          341,
          23007,
          294,
          257,
          4994,
          960,
          50545
        ]
      },
      {
        "avg_logprob": -0.2779780643087038,
        "compression_ratio": 1.6195286195286196,
        "end": 4926.08,
        "id": 1613,
        "no_speech_prob": 0.000016964395399554633,
        "seek": 492078,
        "start": 4924.4,
        "temperature": 0,
        "text": " and people should just go and check that.",
        "tokens": [
          50545,
          293,
          561,
          820,
          445,
          352,
          293,
          1520,
          300,
          13,
          50629
        ]
      },
      {
        "avg_logprob": -0.2779780643087038,
        "compression_ratio": 1.6195286195286196,
        "end": 4928.8,
        "id": 1614,
        "no_speech_prob": 0.000016964395399554633,
        "seek": 492078,
        "start": 4926.08,
        "temperature": 0,
        "text": " It's a good way to plug the channel right now anyway.",
        "tokens": [
          50629,
          467,
          311,
          257,
          665,
          636,
          281,
          5452,
          264,
          2269,
          558,
          586,
          4033,
          13,
          50765
        ]
      },
      {
        "avg_logprob": -0.2779780643087038,
        "compression_ratio": 1.6195286195286196,
        "end": 4931.08,
        "id": 1615,
        "no_speech_prob": 0.000016964395399554633,
        "seek": 492078,
        "start": 4928.8,
        "temperature": 0,
        "text": " Actually, let's see, how many subscribers am I at?",
        "tokens": [
          50765,
          5135,
          11,
          718,
          311,
          536,
          11,
          577,
          867,
          11092,
          669,
          286,
          412,
          30,
          50879
        ]
      },
      {
        "avg_logprob": -0.2779780643087038,
        "compression_ratio": 1.6195286195286196,
        "end": 4933.219999999999,
        "id": 1616,
        "no_speech_prob": 0.000016964395399554633,
        "seek": 492078,
        "start": 4932.04,
        "temperature": 0,
        "text": " Okay, okay, cool.",
        "tokens": [
          50927,
          1033,
          11,
          1392,
          11,
          1627,
          13,
          50986
        ]
      },
      {
        "avg_logprob": -0.2779780643087038,
        "compression_ratio": 1.6195286195286196,
        "end": 4939.08,
        "id": 1617,
        "no_speech_prob": 0.000016964395399554633,
        "seek": 492078,
        "start": 4934.88,
        "temperature": 0,
        "text": " But the font I'm using is Anonymous Pro.",
        "tokens": [
          51069,
          583,
          264,
          10703,
          286,
          478,
          1228,
          307,
          1107,
          18092,
          1705,
          13,
          51279
        ]
      },
      {
        "avg_logprob": -0.2779780643087038,
        "compression_ratio": 1.6195286195286196,
        "end": 4941.96,
        "id": 1618,
        "no_speech_prob": 0.000016964395399554633,
        "seek": 492078,
        "start": 4941,
        "temperature": 0,
        "text": " I really like this font.",
        "tokens": [
          51375,
          286,
          534,
          411,
          341,
          10703,
          13,
          51423
        ]
      },
      {
        "avg_logprob": -0.2779780643087038,
        "compression_ratio": 1.6195286195286196,
        "end": 4942.88,
        "id": 1619,
        "no_speech_prob": 0.000016964395399554633,
        "seek": 492078,
        "start": 4941.96,
        "temperature": 0,
        "text": " There's a lot of other fonts out there,",
        "tokens": [
          51423,
          821,
          311,
          257,
          688,
          295,
          661,
          35316,
          484,
          456,
          11,
          51469
        ]
      },
      {
        "avg_logprob": -0.2779780643087038,
        "compression_ratio": 1.6195286195286196,
        "end": 4946.28,
        "id": 1620,
        "no_speech_prob": 0.000016964395399554633,
        "seek": 492078,
        "start": 4942.88,
        "temperature": 0,
        "text": " but I have this as my terminal font and my editor font.",
        "tokens": [
          51469,
          457,
          286,
          362,
          341,
          382,
          452,
          14709,
          10703,
          293,
          452,
          9839,
          10703,
          13,
          51639
        ]
      },
      {
        "avg_logprob": -0.2779780643087038,
        "compression_ratio": 1.6195286195286196,
        "end": 4947.679999999999,
        "id": 1621,
        "no_speech_prob": 0.000016964395399554633,
        "seek": 492078,
        "start": 4946.28,
        "temperature": 0,
        "text": " But yeah, if you check out that video,",
        "tokens": [
          51639,
          583,
          1338,
          11,
          498,
          291,
          1520,
          484,
          300,
          960,
          11,
          51709
        ]
      },
      {
        "avg_logprob": -0.2779780643087038,
        "compression_ratio": 1.6195286195286196,
        "end": 4950.639999999999,
        "id": 1622,
        "no_speech_prob": 0.000016964395399554633,
        "seek": 492078,
        "start": 4947.679999999999,
        "temperature": 0,
        "text": " I have links to all of my extensions,",
        "tokens": [
          51709,
          286,
          362,
          6123,
          281,
          439,
          295,
          452,
          25129,
          11,
          51857
        ]
      },
      {
        "avg_logprob": -0.2804902429738756,
        "compression_ratio": 1.641025641025641,
        "end": 4952.740000000001,
        "id": 1623,
        "no_speech_prob": 0.00014202269085217267,
        "seek": 495064,
        "start": 4951.42,
        "temperature": 0,
        "text": " my styles, all that stuff that I have set up",
        "tokens": [
          50403,
          452,
          13273,
          11,
          439,
          300,
          1507,
          300,
          286,
          362,
          992,
          493,
          50469
        ]
      },
      {
        "avg_logprob": -0.2804902429738756,
        "compression_ratio": 1.641025641025641,
        "end": 4953.58,
        "id": 1624,
        "no_speech_prob": 0.00014202269085217267,
        "seek": 495064,
        "start": 4952.740000000001,
        "temperature": 0,
        "text": " inside of VS Code.",
        "tokens": [
          50469,
          1854,
          295,
          25091,
          15549,
          13,
          50511
        ]
      },
      {
        "avg_logprob": -0.2804902429738756,
        "compression_ratio": 1.641025641025641,
        "end": 4955.14,
        "id": 1625,
        "no_speech_prob": 0.00014202269085217267,
        "seek": 495064,
        "start": 4953.58,
        "temperature": 0,
        "text": " Great, a few people said they just subscribed.",
        "tokens": [
          50511,
          3769,
          11,
          257,
          1326,
          561,
          848,
          436,
          445,
          16665,
          13,
          50589
        ]
      },
      {
        "avg_logprob": -0.2804902429738756,
        "compression_ratio": 1.641025641025641,
        "end": 4956.22,
        "id": 1626,
        "no_speech_prob": 0.00014202269085217267,
        "seek": 495064,
        "start": 4955.14,
        "temperature": 0,
        "text": " Oh, thank you so much.",
        "tokens": [
          50589,
          876,
          11,
          1309,
          291,
          370,
          709,
          13,
          50643
        ]
      },
      {
        "avg_logprob": -0.2804902429738756,
        "compression_ratio": 1.641025641025641,
        "end": 4957.9400000000005,
        "id": 1627,
        "no_speech_prob": 0.00014202269085217267,
        "seek": 495064,
        "start": 4956.22,
        "temperature": 0,
        "text": " So yeah, so what's amazing about this,",
        "tokens": [
          50643,
          407,
          1338,
          11,
          370,
          437,
          311,
          2243,
          466,
          341,
          11,
          50729
        ]
      },
      {
        "avg_logprob": -0.2804902429738756,
        "compression_ratio": 1.641025641025641,
        "end": 4959.900000000001,
        "id": 1628,
        "no_speech_prob": 0.00014202269085217267,
        "seek": 495064,
        "start": 4957.9400000000005,
        "temperature": 0,
        "text": " first of all, CJ and I were discussing",
        "tokens": [
          50729,
          700,
          295,
          439,
          11,
          42285,
          293,
          286,
          645,
          10850,
          50827
        ]
      },
      {
        "avg_logprob": -0.2804902429738756,
        "compression_ratio": 1.641025641025641,
        "end": 4961.38,
        "id": 1629,
        "no_speech_prob": 0.00014202269085217267,
        "seek": 495064,
        "start": 4959.900000000001,
        "temperature": 0,
        "text": " what he was gonna do and he said,",
        "tokens": [
          50827,
          437,
          415,
          390,
          799,
          360,
          293,
          415,
          848,
          11,
          50901
        ]
      },
      {
        "avg_logprob": -0.2804902429738756,
        "compression_ratio": 1.641025641025641,
        "end": 4962.700000000001,
        "id": 1630,
        "no_speech_prob": 0.00014202269085217267,
        "seek": 495064,
        "start": 4961.38,
        "temperature": 0,
        "text": " oh, I think I'll make a Twitter clone.",
        "tokens": [
          50901,
          1954,
          11,
          286,
          519,
          286,
          603,
          652,
          257,
          5794,
          26506,
          13,
          50967
        ]
      },
      {
        "avg_logprob": -0.2804902429738756,
        "compression_ratio": 1.641025641025641,
        "end": 4964.1,
        "id": 1631,
        "no_speech_prob": 0.00014202269085217267,
        "seek": 495064,
        "start": 4962.700000000001,
        "temperature": 0,
        "text": " It's like, in an hour?",
        "tokens": [
          50967,
          467,
          311,
          411,
          11,
          294,
          364,
          1773,
          30,
          51037
        ]
      },
      {
        "avg_logprob": -0.2804902429738756,
        "compression_ratio": 1.641025641025641,
        "end": 4965.3,
        "id": 1632,
        "no_speech_prob": 0.00014202269085217267,
        "seek": 495064,
        "start": 4964.1,
        "temperature": 0,
        "text": " It's like, that's crazy.",
        "tokens": [
          51037,
          467,
          311,
          411,
          11,
          300,
          311,
          3219,
          13,
          51097
        ]
      },
      {
        "avg_logprob": -0.2804902429738756,
        "compression_ratio": 1.641025641025641,
        "end": 4968.780000000001,
        "id": 1633,
        "no_speech_prob": 0.00014202269085217267,
        "seek": 495064,
        "start": 4965.3,
        "temperature": 0,
        "text": " Well, no user accounts and it's stripped down.",
        "tokens": [
          51097,
          1042,
          11,
          572,
          4195,
          9402,
          293,
          309,
          311,
          33221,
          760,
          13,
          51271
        ]
      },
      {
        "avg_logprob": -0.2804902429738756,
        "compression_ratio": 1.641025641025641,
        "end": 4971.06,
        "id": 1634,
        "no_speech_prob": 0.00014202269085217267,
        "seek": 495064,
        "start": 4968.780000000001,
        "temperature": 0,
        "text": " But still, this was pretty incredible",
        "tokens": [
          51271,
          583,
          920,
          11,
          341,
          390,
          1238,
          4651,
          51385
        ]
      },
      {
        "avg_logprob": -0.2804902429738756,
        "compression_ratio": 1.641025641025641,
        "end": 4974.660000000001,
        "id": 1635,
        "no_speech_prob": 0.00014202269085217267,
        "seek": 495064,
        "start": 4971.06,
        "temperature": 0,
        "text": " to see the full stack, really.",
        "tokens": [
          51385,
          281,
          536,
          264,
          1577,
          8630,
          11,
          534,
          13,
          51565
        ]
      },
      {
        "avg_logprob": -0.2804902429738756,
        "compression_ratio": 1.641025641025641,
        "end": 4975.780000000001,
        "id": 1636,
        "no_speech_prob": 0.00014202269085217267,
        "seek": 495064,
        "start": 4974.660000000001,
        "temperature": 0,
        "text": " I was trying to think of a different word for it,",
        "tokens": [
          51565,
          286,
          390,
          1382,
          281,
          519,
          295,
          257,
          819,
          1349,
          337,
          309,
          11,
          51621
        ]
      },
      {
        "avg_logprob": -0.2804902429738756,
        "compression_ratio": 1.641025641025641,
        "end": 4977.02,
        "id": 1637,
        "no_speech_prob": 0.00014202269085217267,
        "seek": 495064,
        "start": 4975.780000000001,
        "temperature": 0,
        "text": " but that's the word, the full stack.",
        "tokens": [
          51621,
          457,
          300,
          311,
          264,
          1349,
          11,
          264,
          1577,
          8630,
          13,
          51683
        ]
      },
      {
        "avg_logprob": -0.2804902429738756,
        "compression_ratio": 1.641025641025641,
        "end": 4978.42,
        "id": 1638,
        "no_speech_prob": 0.00014202269085217267,
        "seek": 495064,
        "start": 4977.02,
        "temperature": 0,
        "text": " You know, so much of the stuff that I do",
        "tokens": [
          51683,
          509,
          458,
          11,
          370,
          709,
          295,
          264,
          1507,
          300,
          286,
          360,
          51753
        ]
      },
      {
        "avg_logprob": -0.26268250265239196,
        "compression_ratio": 1.7205882352941178,
        "end": 4982.4800000000005,
        "id": 1639,
        "no_speech_prob": 0.00040446786442771554,
        "seek": 497842,
        "start": 4978.4400000000005,
        "temperature": 0,
        "text": " is mostly client side, algorithms, visualization stuff.",
        "tokens": [
          50365,
          307,
          5240,
          6423,
          1252,
          11,
          14642,
          11,
          25801,
          1507,
          13,
          50567
        ]
      },
      {
        "avg_logprob": -0.26268250265239196,
        "compression_ratio": 1.7205882352941178,
        "end": 4985.28,
        "id": 1640,
        "no_speech_prob": 0.00040446786442771554,
        "seek": 497842,
        "start": 4982.4800000000005,
        "temperature": 0,
        "text": " Sometimes I'll pull up a node thing or use a database,",
        "tokens": [
          50567,
          4803,
          286,
          603,
          2235,
          493,
          257,
          9984,
          551,
          420,
          764,
          257,
          8149,
          11,
          50707
        ]
      },
      {
        "avg_logprob": -0.26268250265239196,
        "compression_ratio": 1.7205882352941178,
        "end": 4987,
        "id": 1641,
        "no_speech_prob": 0.00040446786442771554,
        "seek": 497842,
        "start": 4985.28,
        "temperature": 0,
        "text": " but to see that whole picture all together",
        "tokens": [
          50707,
          457,
          281,
          536,
          300,
          1379,
          3036,
          439,
          1214,
          50793
        ]
      },
      {
        "avg_logprob": -0.26268250265239196,
        "compression_ratio": 1.7205882352941178,
        "end": 4988.76,
        "id": 1642,
        "no_speech_prob": 0.00040446786442771554,
        "seek": 497842,
        "start": 4987,
        "temperature": 0,
        "text": " and also just seeing your kind of workflow",
        "tokens": [
          50793,
          293,
          611,
          445,
          2577,
          428,
          733,
          295,
          20993,
          50881
        ]
      },
      {
        "avg_logprob": -0.26268250265239196,
        "compression_ratio": 1.7205882352941178,
        "end": 4991.02,
        "id": 1643,
        "no_speech_prob": 0.00040446786442771554,
        "seek": 497842,
        "start": 4988.76,
        "temperature": 0,
        "text": " is super, super illuminating.",
        "tokens": [
          50881,
          307,
          1687,
          11,
          1687,
          28593,
          990,
          13,
          50994
        ]
      },
      {
        "avg_logprob": -0.26268250265239196,
        "compression_ratio": 1.7205882352941178,
        "end": 4992.8,
        "id": 1644,
        "no_speech_prob": 0.00040446786442771554,
        "seek": 497842,
        "start": 4991.02,
        "temperature": 0,
        "text": " I feel like I learned a ton of stuff.",
        "tokens": [
          50994,
          286,
          841,
          411,
          286,
          3264,
          257,
          2952,
          295,
          1507,
          13,
          51083
        ]
      },
      {
        "avg_logprob": -0.26268250265239196,
        "compression_ratio": 1.7205882352941178,
        "end": 4994.04,
        "id": 1645,
        "no_speech_prob": 0.00040446786442771554,
        "seek": 497842,
        "start": 4992.8,
        "temperature": 0,
        "text": " I was like, made some notes of things",
        "tokens": [
          51083,
          286,
          390,
          411,
          11,
          1027,
          512,
          5570,
          295,
          721,
          51145
        ]
      },
      {
        "avg_logprob": -0.26268250265239196,
        "compression_ratio": 1.7205882352941178,
        "end": 4996.56,
        "id": 1646,
        "no_speech_prob": 0.00040446786442771554,
        "seek": 497842,
        "start": 4994.04,
        "temperature": 0,
        "text": " that I'd never seen before, which was awesome.",
        "tokens": [
          51145,
          300,
          286,
          1116,
          1128,
          1612,
          949,
          11,
          597,
          390,
          3476,
          13,
          51271
        ]
      },
      {
        "avg_logprob": -0.26268250265239196,
        "compression_ratio": 1.7205882352941178,
        "end": 4998.12,
        "id": 1647,
        "no_speech_prob": 0.00040446786442771554,
        "seek": 497842,
        "start": 4996.56,
        "temperature": 0,
        "text": " I guess that's one thing to note.",
        "tokens": [
          51271,
          286,
          2041,
          300,
          311,
          472,
          551,
          281,
          3637,
          13,
          51349
        ]
      },
      {
        "avg_logprob": -0.26268250265239196,
        "compression_ratio": 1.7205882352941178,
        "end": 4999.86,
        "id": 1648,
        "no_speech_prob": 0.00040446786442771554,
        "seek": 497842,
        "start": 4998.12,
        "temperature": 0,
        "text": " So I'm showing the client was the browser,",
        "tokens": [
          51349,
          407,
          286,
          478,
          4099,
          264,
          6423,
          390,
          264,
          11185,
          11,
          51436
        ]
      },
      {
        "avg_logprob": -0.26268250265239196,
        "compression_ratio": 1.7205882352941178,
        "end": 5001.72,
        "id": 1649,
        "no_speech_prob": 0.00040446786442771554,
        "seek": 497842,
        "start": 4999.86,
        "temperature": 0,
        "text": " but the client could be a desktop app.",
        "tokens": [
          51436,
          457,
          264,
          6423,
          727,
          312,
          257,
          14502,
          724,
          13,
          51529
        ]
      },
      {
        "avg_logprob": -0.26268250265239196,
        "compression_ratio": 1.7205882352941178,
        "end": 5004.32,
        "id": 1650,
        "no_speech_prob": 0.00040446786442771554,
        "seek": 497842,
        "start": 5001.72,
        "temperature": 0,
        "text": " It could be a mobile phone native app.",
        "tokens": [
          51529,
          467,
          727,
          312,
          257,
          6013,
          2593,
          8470,
          724,
          13,
          51659
        ]
      },
      {
        "avg_logprob": -0.26268250265239196,
        "compression_ratio": 1.7205882352941178,
        "end": 5005.9400000000005,
        "id": 1651,
        "no_speech_prob": 0.00040446786442771554,
        "seek": 497842,
        "start": 5004.32,
        "temperature": 0,
        "text": " And it could all work in a similar way.",
        "tokens": [
          51659,
          400,
          309,
          727,
          439,
          589,
          294,
          257,
          2531,
          636,
          13,
          51740
        ]
      },
      {
        "avg_logprob": -0.26268250265239196,
        "compression_ratio": 1.7205882352941178,
        "end": 5008.24,
        "id": 1652,
        "no_speech_prob": 0.00040446786442771554,
        "seek": 497842,
        "start": 5005.9400000000005,
        "temperature": 0,
        "text": " And this is actually why I like to build",
        "tokens": [
          51740,
          400,
          341,
          307,
          767,
          983,
          286,
          411,
          281,
          1322,
          51855
        ]
      },
      {
        "avg_logprob": -0.25956638560575596,
        "compression_ratio": 1.6775147928994083,
        "end": 5010.0599999999995,
        "id": 1653,
        "no_speech_prob": 0.001956862397491932,
        "seek": 500824,
        "start": 5009.0199999999995,
        "temperature": 0,
        "text": " architectures this way, because a mobile app",
        "tokens": [
          50403,
          6331,
          1303,
          341,
          636,
          11,
          570,
          257,
          6013,
          724,
          50455
        ]
      },
      {
        "avg_logprob": -0.25956638560575596,
        "compression_ratio": 1.6775147928994083,
        "end": 5012.099999999999,
        "id": 1654,
        "no_speech_prob": 0.001956862397491932,
        "seek": 500824,
        "start": 5010.0599999999995,
        "temperature": 0,
        "text": " could talk to the exact same backend.",
        "tokens": [
          50455,
          727,
          751,
          281,
          264,
          1900,
          912,
          38087,
          13,
          50557
        ]
      },
      {
        "avg_logprob": -0.25956638560575596,
        "compression_ratio": 1.6775147928994083,
        "end": 5013.74,
        "id": 1655,
        "no_speech_prob": 0.001956862397491932,
        "seek": 500824,
        "start": 5012.099999999999,
        "temperature": 0,
        "text": " The only thing that changes is the client.",
        "tokens": [
          50557,
          440,
          787,
          551,
          300,
          2962,
          307,
          264,
          6423,
          13,
          50639
        ]
      },
      {
        "avg_logprob": -0.25956638560575596,
        "compression_ratio": 1.6775147928994083,
        "end": 5016.78,
        "id": 1656,
        "no_speech_prob": 0.001956862397491932,
        "seek": 500824,
        "start": 5013.74,
        "temperature": 0,
        "text": " And are there other, so when is,",
        "tokens": [
          50639,
          400,
          366,
          456,
          661,
          11,
          370,
          562,
          307,
          11,
          50791
        ]
      },
      {
        "avg_logprob": -0.25956638560575596,
        "compression_ratio": 1.6775147928994083,
        "end": 5018.58,
        "id": 1657,
        "no_speech_prob": 0.001956862397491932,
        "seek": 500824,
        "start": 5016.78,
        "temperature": 0,
        "text": " so I know you've been in New York for a while.",
        "tokens": [
          50791,
          370,
          286,
          458,
          291,
          600,
          668,
          294,
          1873,
          3609,
          337,
          257,
          1339,
          13,
          50881
        ]
      },
      {
        "avg_logprob": -0.25956638560575596,
        "compression_ratio": 1.6775147928994083,
        "end": 5019.9,
        "id": 1658,
        "no_speech_prob": 0.001956862397491932,
        "seek": 500824,
        "start": 5018.58,
        "temperature": 0,
        "text": " You're going back, you're based in Denver.",
        "tokens": [
          50881,
          509,
          434,
          516,
          646,
          11,
          291,
          434,
          2361,
          294,
          26270,
          13,
          50947
        ]
      },
      {
        "avg_logprob": -0.25956638560575596,
        "compression_ratio": 1.6775147928994083,
        "end": 5020.74,
        "id": 1659,
        "no_speech_prob": 0.001956862397491932,
        "seek": 500824,
        "start": 5019.9,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          50947,
          1079,
          13,
          50989
        ]
      },
      {
        "avg_logprob": -0.25956638560575596,
        "compression_ratio": 1.6775147928994083,
        "end": 5021.58,
        "id": 1660,
        "no_speech_prob": 0.001956862397491932,
        "seek": 500824,
        "start": 5020.74,
        "temperature": 0,
        "text": " And you're going back there.",
        "tokens": [
          50989,
          400,
          291,
          434,
          516,
          646,
          456,
          13,
          51031
        ]
      },
      {
        "avg_logprob": -0.25956638560575596,
        "compression_ratio": 1.6775147928994083,
        "end": 5024.3,
        "id": 1661,
        "no_speech_prob": 0.001956862397491932,
        "seek": 500824,
        "start": 5021.58,
        "temperature": 0,
        "text": " When is your next live stream?",
        "tokens": [
          51031,
          1133,
          307,
          428,
          958,
          1621,
          4309,
          30,
          51167
        ]
      },
      {
        "avg_logprob": -0.25956638560575596,
        "compression_ratio": 1.6775147928994083,
        "end": 5026.0199999999995,
        "id": 1662,
        "no_speech_prob": 0.001956862397491932,
        "seek": 500824,
        "start": 5024.3,
        "temperature": 0,
        "text": " Are there other things people should check out,",
        "tokens": [
          51167,
          2014,
          456,
          661,
          721,
          561,
          820,
          1520,
          484,
          11,
          51253
        ]
      },
      {
        "avg_logprob": -0.25956638560575596,
        "compression_ratio": 1.6775147928994083,
        "end": 5027.58,
        "id": 1663,
        "no_speech_prob": 0.001956862397491932,
        "seek": 500824,
        "start": 5026.0199999999995,
        "temperature": 0,
        "text": " like, I don't know, Twitter or Instagram",
        "tokens": [
          51253,
          411,
          11,
          286,
          500,
          380,
          458,
          11,
          5794,
          420,
          5281,
          51331
        ]
      },
      {
        "avg_logprob": -0.25956638560575596,
        "compression_ratio": 1.6775147928994083,
        "end": 5028.42,
        "id": 1664,
        "no_speech_prob": 0.001956862397491932,
        "seek": 500824,
        "start": 5027.58,
        "temperature": 0,
        "text": " or stuff like that?",
        "tokens": [
          51331,
          420,
          1507,
          411,
          300,
          30,
          51373
        ]
      },
      {
        "avg_logprob": -0.25956638560575596,
        "compression_ratio": 1.6775147928994083,
        "end": 5029.26,
        "id": 1665,
        "no_speech_prob": 0.001956862397491932,
        "seek": 500824,
        "start": 5028.42,
        "temperature": 0,
        "text": " Definitely, yes.",
        "tokens": [
          51373,
          12151,
          11,
          2086,
          13,
          51415
        ]
      },
      {
        "avg_logprob": -0.25956638560575596,
        "compression_ratio": 1.6775147928994083,
        "end": 5030.62,
        "id": 1666,
        "no_speech_prob": 0.001956862397491932,
        "seek": 500824,
        "start": 5029.26,
        "temperature": 0,
        "text": " Thanks for the fun.",
        "tokens": [
          51415,
          2561,
          337,
          264,
          1019,
          13,
          51483
        ]
      },
      {
        "avg_logprob": -0.25956638560575596,
        "compression_ratio": 1.6775147928994083,
        "end": 5034.66,
        "id": 1667,
        "no_speech_prob": 0.001956862397491932,
        "seek": 500824,
        "start": 5030.62,
        "temperature": 0,
        "text": " So I'm on Twitter, coding underscore garden.",
        "tokens": [
          51483,
          407,
          286,
          478,
          322,
          5794,
          11,
          17720,
          37556,
          7431,
          13,
          51685
        ]
      },
      {
        "avg_logprob": -0.25956638560575596,
        "compression_ratio": 1.6775147928994083,
        "end": 5035.58,
        "id": 1668,
        "no_speech_prob": 0.001956862397491932,
        "seek": 500824,
        "start": 5034.66,
        "temperature": 0,
        "text": " You can follow me there.",
        "tokens": [
          51685,
          509,
          393,
          1524,
          385,
          456,
          13,
          51731
        ]
      },
      {
        "avg_logprob": -0.25956638560575596,
        "compression_ratio": 1.6775147928994083,
        "end": 5037.86,
        "id": 1669,
        "no_speech_prob": 0.001956862397491932,
        "seek": 500824,
        "start": 5035.58,
        "temperature": 0,
        "text": " Every time I go live, it tweets here.",
        "tokens": [
          51731,
          2048,
          565,
          286,
          352,
          1621,
          11,
          309,
          25671,
          510,
          13,
          51845
        ]
      },
      {
        "avg_logprob": -0.22043706959691542,
        "compression_ratio": 1.6464646464646464,
        "end": 5040.48,
        "id": 1670,
        "no_speech_prob": 0.00017673138063400984,
        "seek": 503786,
        "start": 5038.44,
        "temperature": 0,
        "text": " Right now, I do plan to stream, I think, on set.",
        "tokens": [
          50393,
          1779,
          586,
          11,
          286,
          360,
          1393,
          281,
          4309,
          11,
          286,
          519,
          11,
          322,
          992,
          13,
          50495
        ]
      },
      {
        "avg_logprob": -0.22043706959691542,
        "compression_ratio": 1.6464646464646464,
        "end": 5042.5599999999995,
        "id": 1671,
        "no_speech_prob": 0.00017673138063400984,
        "seek": 503786,
        "start": 5040.48,
        "temperature": 0,
        "text": " I have a pretty busy week, because I'm moving",
        "tokens": [
          50495,
          286,
          362,
          257,
          1238,
          5856,
          1243,
          11,
          570,
          286,
          478,
          2684,
          50599
        ]
      },
      {
        "avg_logprob": -0.22043706959691542,
        "compression_ratio": 1.6464646464646464,
        "end": 5043.839999999999,
        "id": 1672,
        "no_speech_prob": 0.00017673138063400984,
        "seek": 503786,
        "start": 5042.5599999999995,
        "temperature": 0,
        "text": " from New York back to Denver.",
        "tokens": [
          50599,
          490,
          1873,
          3609,
          646,
          281,
          26270,
          13,
          50663
        ]
      },
      {
        "avg_logprob": -0.22043706959691542,
        "compression_ratio": 1.6464646464646464,
        "end": 5045.88,
        "id": 1673,
        "no_speech_prob": 0.00017673138063400984,
        "seek": 503786,
        "start": 5043.839999999999,
        "temperature": 0,
        "text": " I've got to pack up, and my students",
        "tokens": [
          50663,
          286,
          600,
          658,
          281,
          2844,
          493,
          11,
          293,
          452,
          1731,
          50765
        ]
      },
      {
        "avg_logprob": -0.22043706959691542,
        "compression_ratio": 1.6464646464646464,
        "end": 5047.16,
        "id": 1674,
        "no_speech_prob": 0.00017673138063400984,
        "seek": 503786,
        "start": 5045.88,
        "temperature": 0,
        "text": " are presenting Capstones tomorrow,",
        "tokens": [
          50765,
          366,
          15578,
          8363,
          38702,
          4153,
          11,
          50829
        ]
      },
      {
        "avg_logprob": -0.22043706959691542,
        "compression_ratio": 1.6464646464646464,
        "end": 5049.32,
        "id": 1675,
        "no_speech_prob": 0.00017673138063400984,
        "seek": 503786,
        "start": 5047.16,
        "temperature": 0,
        "text": " so we're getting all that ready.",
        "tokens": [
          50829,
          370,
          321,
          434,
          1242,
          439,
          300,
          1919,
          13,
          50937
        ]
      },
      {
        "avg_logprob": -0.22043706959691542,
        "compression_ratio": 1.6464646464646464,
        "end": 5051.88,
        "id": 1676,
        "no_speech_prob": 0.00017673138063400984,
        "seek": 503786,
        "start": 5049.32,
        "temperature": 0,
        "text": " But if you look on my channel,",
        "tokens": [
          50937,
          583,
          498,
          291,
          574,
          322,
          452,
          2269,
          11,
          51065
        ]
      },
      {
        "avg_logprob": -0.22043706959691542,
        "compression_ratio": 1.6464646464646464,
        "end": 5055.28,
        "id": 1677,
        "no_speech_prob": 0.00017673138063400984,
        "seek": 503786,
        "start": 5051.88,
        "temperature": 0,
        "text": " I typically try to do upcoming live streams.",
        "tokens": [
          51065,
          286,
          5850,
          853,
          281,
          360,
          11500,
          1621,
          15842,
          13,
          51235
        ]
      },
      {
        "avg_logprob": -0.22043706959691542,
        "compression_ratio": 1.6464646464646464,
        "end": 5058.2,
        "id": 1678,
        "no_speech_prob": 0.00017673138063400984,
        "seek": 503786,
        "start": 5055.28,
        "temperature": 0,
        "text": " And any stream that's upcoming, I'll put it here,",
        "tokens": [
          51235,
          400,
          604,
          4309,
          300,
          311,
          11500,
          11,
          286,
          603,
          829,
          309,
          510,
          11,
          51381
        ]
      },
      {
        "avg_logprob": -0.22043706959691542,
        "compression_ratio": 1.6464646464646464,
        "end": 5060.44,
        "id": 1679,
        "no_speech_prob": 0.00017673138063400984,
        "seek": 503786,
        "start": 5058.2,
        "temperature": 0,
        "text": " so you can click on it to know before it happens.",
        "tokens": [
          51381,
          370,
          291,
          393,
          2052,
          322,
          309,
          281,
          458,
          949,
          309,
          2314,
          13,
          51493
        ]
      },
      {
        "avg_logprob": -0.22043706959691542,
        "compression_ratio": 1.6464646464646464,
        "end": 5062.48,
        "id": 1680,
        "no_speech_prob": 0.00017673138063400984,
        "seek": 503786,
        "start": 5060.44,
        "temperature": 0,
        "text": " The other thing is I do have a Discord,",
        "tokens": [
          51493,
          440,
          661,
          551,
          307,
          286,
          360,
          362,
          257,
          32623,
          11,
          51595
        ]
      },
      {
        "avg_logprob": -0.22043706959691542,
        "compression_ratio": 1.6464646464646464,
        "end": 5064.679999999999,
        "id": 1681,
        "no_speech_prob": 0.00017673138063400984,
        "seek": 503786,
        "start": 5062.48,
        "temperature": 0,
        "text": " and there is a live channel on the Discord.",
        "tokens": [
          51595,
          293,
          456,
          307,
          257,
          1621,
          2269,
          322,
          264,
          32623,
          13,
          51705
        ]
      },
      {
        "avg_logprob": -0.24912142072405133,
        "compression_ratio": 1.623728813559322,
        "end": 5069.740000000001,
        "id": 1682,
        "no_speech_prob": 0.0002652890107128769,
        "seek": 506468,
        "start": 5064.740000000001,
        "temperature": 0,
        "text": " So if you look in one of my more recent videos,",
        "tokens": [
          50367,
          407,
          498,
          291,
          574,
          294,
          472,
          295,
          452,
          544,
          5162,
          2145,
          11,
          50617
        ]
      },
      {
        "avg_logprob": -0.24912142072405133,
        "compression_ratio": 1.623728813559322,
        "end": 5073.900000000001,
        "id": 1683,
        "no_speech_prob": 0.0002652890107128769,
        "seek": 506468,
        "start": 5070.14,
        "temperature": 0,
        "text": " there's a link to fill out a survey to join this Discord,",
        "tokens": [
          50637,
          456,
          311,
          257,
          2113,
          281,
          2836,
          484,
          257,
          8984,
          281,
          3917,
          341,
          32623,
          11,
          50825
        ]
      },
      {
        "avg_logprob": -0.24912142072405133,
        "compression_ratio": 1.623728813559322,
        "end": 5076.700000000001,
        "id": 1684,
        "no_speech_prob": 0.0002652890107128769,
        "seek": 506468,
        "start": 5073.900000000001,
        "temperature": 0,
        "text": " and we have help channels, but typically,",
        "tokens": [
          50825,
          293,
          321,
          362,
          854,
          9235,
          11,
          457,
          5850,
          11,
          50965
        ]
      },
      {
        "avg_logprob": -0.24912142072405133,
        "compression_ratio": 1.623728813559322,
        "end": 5080.14,
        "id": 1685,
        "no_speech_prob": 0.0002652890107128769,
        "seek": 506468,
        "start": 5076.700000000001,
        "temperature": 0,
        "text": " I'll post in the live channel whenever I'm going live.",
        "tokens": [
          50965,
          286,
          603,
          2183,
          294,
          264,
          1621,
          2269,
          5699,
          286,
          478,
          516,
          1621,
          13,
          51137
        ]
      },
      {
        "avg_logprob": -0.24912142072405133,
        "compression_ratio": 1.623728813559322,
        "end": 5080.9800000000005,
        "id": 1686,
        "no_speech_prob": 0.0002652890107128769,
        "seek": 506468,
        "start": 5080.14,
        "temperature": 0,
        "text": " There's Brucer.",
        "tokens": [
          51137,
          821,
          311,
          1603,
          1311,
          260,
          13,
          51179
        ]
      },
      {
        "avg_logprob": -0.24912142072405133,
        "compression_ratio": 1.623728813559322,
        "end": 5083.54,
        "id": 1687,
        "no_speech_prob": 0.0002652890107128769,
        "seek": 506468,
        "start": 5080.9800000000005,
        "temperature": 0,
        "text": " And are there, you were doing some teaching",
        "tokens": [
          51179,
          400,
          366,
          456,
          11,
          291,
          645,
          884,
          512,
          4571,
          51307
        ]
      },
      {
        "avg_logprob": -0.24912142072405133,
        "compression_ratio": 1.623728813559322,
        "end": 5085.62,
        "id": 1688,
        "no_speech_prob": 0.0002652890107128769,
        "seek": 506468,
        "start": 5083.54,
        "temperature": 0,
        "text": " here in New York, are there other things",
        "tokens": [
          51307,
          510,
          294,
          1873,
          3609,
          11,
          366,
          456,
          661,
          721,
          51411
        ]
      },
      {
        "avg_logprob": -0.24912142072405133,
        "compression_ratio": 1.623728813559322,
        "end": 5087.54,
        "id": 1689,
        "no_speech_prob": 0.0002652890107128769,
        "seek": 506468,
        "start": 5085.62,
        "temperature": 0,
        "text": " you've got on the horizon of teaching experiences",
        "tokens": [
          51411,
          291,
          600,
          658,
          322,
          264,
          18046,
          295,
          4571,
          5235,
          51507
        ]
      },
      {
        "avg_logprob": -0.24912142072405133,
        "compression_ratio": 1.623728813559322,
        "end": 5089.22,
        "id": 1690,
        "no_speech_prob": 0.0002652890107128769,
        "seek": 506468,
        "start": 5087.54,
        "temperature": 0,
        "text": " that you're thinking about doing?",
        "tokens": [
          51507,
          300,
          291,
          434,
          1953,
          466,
          884,
          30,
          51591
        ]
      },
      {
        "avg_logprob": -0.24912142072405133,
        "compression_ratio": 1.623728813559322,
        "end": 5091.54,
        "id": 1691,
        "no_speech_prob": 0.0002652890107128769,
        "seek": 506468,
        "start": 5089.22,
        "temperature": 0,
        "text": " Yeah, I mean, not that I know of.",
        "tokens": [
          51591,
          865,
          11,
          286,
          914,
          11,
          406,
          300,
          286,
          458,
          295,
          13,
          51707
        ]
      },
      {
        "avg_logprob": -0.24912142072405133,
        "compression_ratio": 1.623728813559322,
        "end": 5093.46,
        "id": 1692,
        "no_speech_prob": 0.0002652890107128769,
        "seek": 506468,
        "start": 5091.54,
        "temperature": 0,
        "text": " Like, I really am just focusing on.",
        "tokens": [
          51707,
          1743,
          11,
          286,
          534,
          669,
          445,
          8416,
          322,
          13,
          51803
        ]
      },
      {
        "avg_logprob": -0.24912142072405133,
        "compression_ratio": 1.623728813559322,
        "end": 5094.54,
        "id": 1693,
        "no_speech_prob": 0.0002652890107128769,
        "seek": 506468,
        "start": 5093.46,
        "temperature": 0,
        "text": " Yeah, that's awesome.",
        "tokens": [
          51803,
          865,
          11,
          300,
          311,
          3476,
          13,
          51857
        ]
      },
      {
        "avg_logprob": -0.23484140072228774,
        "compression_ratio": 1.6624203821656052,
        "end": 5096.24,
        "id": 1694,
        "no_speech_prob": 0.0008425326086580753,
        "seek": 509454,
        "start": 5095.4,
        "temperature": 0,
        "text": " When I get back to Denver, I will have,",
        "tokens": [
          50407,
          1133,
          286,
          483,
          646,
          281,
          26270,
          11,
          286,
          486,
          362,
          11,
          50449
        ]
      },
      {
        "avg_logprob": -0.23484140072228774,
        "compression_ratio": 1.6624203821656052,
        "end": 5097.32,
        "id": 1695,
        "no_speech_prob": 0.0008425326086580753,
        "seek": 509454,
        "start": 5096.24,
        "temperature": 0,
        "text": " so before I came to New York,",
        "tokens": [
          50449,
          370,
          949,
          286,
          1361,
          281,
          1873,
          3609,
          11,
          50503
        ]
      },
      {
        "avg_logprob": -0.23484140072228774,
        "compression_ratio": 1.6624203821656052,
        "end": 5098.64,
        "id": 1696,
        "no_speech_prob": 0.0008425326086580753,
        "seek": 509454,
        "start": 5097.32,
        "temperature": 0,
        "text": " I was streaming five days a week,",
        "tokens": [
          50503,
          286,
          390,
          11791,
          1732,
          1708,
          257,
          1243,
          11,
          50569
        ]
      },
      {
        "avg_logprob": -0.23484140072228774,
        "compression_ratio": 1.6624203821656052,
        "end": 5100.04,
        "id": 1697,
        "no_speech_prob": 0.0008425326086580753,
        "seek": 509454,
        "start": 5098.64,
        "temperature": 0,
        "text": " and I think that's why you found me,",
        "tokens": [
          50569,
          293,
          286,
          519,
          300,
          311,
          983,
          291,
          1352,
          385,
          11,
          50639
        ]
      },
      {
        "avg_logprob": -0.23484140072228774,
        "compression_ratio": 1.6624203821656052,
        "end": 5103.04,
        "id": 1698,
        "no_speech_prob": 0.0008425326086580753,
        "seek": 509454,
        "start": 5100.04,
        "temperature": 0,
        "text": " because I'm always just there live streaming.",
        "tokens": [
          50639,
          570,
          286,
          478,
          1009,
          445,
          456,
          1621,
          11791,
          13,
          50789
        ]
      },
      {
        "avg_logprob": -0.23484140072228774,
        "compression_ratio": 1.6624203821656052,
        "end": 5105.32,
        "id": 1699,
        "no_speech_prob": 0.0008425326086580753,
        "seek": 509454,
        "start": 5103.04,
        "temperature": 0,
        "text": " But yeah, when I get back, I do plan to do it more often.",
        "tokens": [
          50789,
          583,
          1338,
          11,
          562,
          286,
          483,
          646,
          11,
          286,
          360,
          1393,
          281,
          360,
          309,
          544,
          2049,
          13,
          50903
        ]
      },
      {
        "avg_logprob": -0.23484140072228774,
        "compression_ratio": 1.6624203821656052,
        "end": 5106.88,
        "id": 1700,
        "no_speech_prob": 0.0008425326086580753,
        "seek": 509454,
        "start": 5105.32,
        "temperature": 0,
        "text": " Lately, it's just been, so I'll talk about",
        "tokens": [
          50903,
          441,
          1592,
          11,
          309,
          311,
          445,
          668,
          11,
          370,
          286,
          603,
          751,
          466,
          50981
        ]
      },
      {
        "avg_logprob": -0.23484140072228774,
        "compression_ratio": 1.6624203821656052,
        "end": 5108.74,
        "id": 1701,
        "no_speech_prob": 0.0008425326086580753,
        "seek": 509454,
        "start": 5106.88,
        "temperature": 0,
        "text": " some of the streams I do.",
        "tokens": [
          50981,
          512,
          295,
          264,
          15842,
          286,
          360,
          13,
          51074
        ]
      },
      {
        "avg_logprob": -0.23484140072228774,
        "compression_ratio": 1.6624203821656052,
        "end": 5111.32,
        "id": 1702,
        "no_speech_prob": 0.0008425326086580753,
        "seek": 509454,
        "start": 5108.74,
        "temperature": 0,
        "text": " So every, either Saturday or Sunday,",
        "tokens": [
          51074,
          407,
          633,
          11,
          2139,
          8803,
          420,
          7776,
          11,
          51203
        ]
      },
      {
        "avg_logprob": -0.23484140072228774,
        "compression_ratio": 1.6624203821656052,
        "end": 5114.24,
        "id": 1703,
        "no_speech_prob": 0.0008425326086580753,
        "seek": 509454,
        "start": 5111.32,
        "temperature": 0,
        "text": " I've been streaming with a friend named Tony,",
        "tokens": [
          51203,
          286,
          600,
          668,
          11791,
          365,
          257,
          1277,
          4926,
          10902,
          11,
          51349
        ]
      },
      {
        "avg_logprob": -0.23484140072228774,
        "compression_ratio": 1.6624203821656052,
        "end": 5115.76,
        "id": 1704,
        "no_speech_prob": 0.0008425326086580753,
        "seek": 509454,
        "start": 5114.24,
        "temperature": 0,
        "text": " and we do what's called Noob Quest,",
        "tokens": [
          51349,
          293,
          321,
          360,
          437,
          311,
          1219,
          883,
          996,
          8800,
          11,
          51425
        ]
      },
      {
        "avg_logprob": -0.23484140072228774,
        "compression_ratio": 1.6624203821656052,
        "end": 5118.4,
        "id": 1705,
        "no_speech_prob": 0.0008425326086580753,
        "seek": 509454,
        "start": 5115.76,
        "temperature": 0,
        "text": " where Tony's totally brand new to coding,",
        "tokens": [
          51425,
          689,
          10902,
          311,
          3879,
          3360,
          777,
          281,
          17720,
          11,
          51557
        ]
      },
      {
        "avg_logprob": -0.23484140072228774,
        "compression_ratio": 1.6624203821656052,
        "end": 5120.72,
        "id": 1706,
        "no_speech_prob": 0.0008425326086580753,
        "seek": 509454,
        "start": 5118.4,
        "temperature": 0,
        "text": " and we'll kind of pair and work through things.",
        "tokens": [
          51557,
          293,
          321,
          603,
          733,
          295,
          6119,
          293,
          589,
          807,
          721,
          13,
          51673
        ]
      },
      {
        "avg_logprob": -0.2570940466488109,
        "compression_ratio": 1.744,
        "end": 5126.02,
        "id": 1707,
        "no_speech_prob": 0.00006708972796332091,
        "seek": 512072,
        "start": 5121.7,
        "temperature": 0,
        "text": " And then I also do a, mostly every Wednesday,",
        "tokens": [
          50413,
          400,
          550,
          286,
          611,
          360,
          257,
          11,
          5240,
          633,
          10579,
          11,
          50629
        ]
      },
      {
        "avg_logprob": -0.2570940466488109,
        "compression_ratio": 1.744,
        "end": 5127.26,
        "id": 1708,
        "no_speech_prob": 0.00006708972796332091,
        "seek": 512072,
        "start": 5126.02,
        "temperature": 0,
        "text": " a Code Katas stream.",
        "tokens": [
          50629,
          257,
          15549,
          8365,
          296,
          4309,
          13,
          50691
        ]
      },
      {
        "avg_logprob": -0.2570940466488109,
        "compression_ratio": 1.744,
        "end": 5130.66,
        "id": 1709,
        "no_speech_prob": 0.00006708972796332091,
        "seek": 512072,
        "start": 5127.26,
        "temperature": 0,
        "text": " So if you're familiar with Code Wars, Code Katas,",
        "tokens": [
          50691,
          407,
          498,
          291,
          434,
          4963,
          365,
          15549,
          9818,
          11,
          15549,
          8365,
          296,
          11,
          50861
        ]
      },
      {
        "avg_logprob": -0.2570940466488109,
        "compression_ratio": 1.744,
        "end": 5132.18,
        "id": 1710,
        "no_speech_prob": 0.00006708972796332091,
        "seek": 512072,
        "start": 5130.66,
        "temperature": 0,
        "text": " I'll just sit down for a couple of hours,",
        "tokens": [
          50861,
          286,
          603,
          445,
          1394,
          760,
          337,
          257,
          1916,
          295,
          2496,
          11,
          50937
        ]
      },
      {
        "avg_logprob": -0.2570940466488109,
        "compression_ratio": 1.744,
        "end": 5135.06,
        "id": 1711,
        "no_speech_prob": 0.00006708972796332091,
        "seek": 512072,
        "start": 5132.18,
        "temperature": 0,
        "text": " and I'll pick some out and then just solve them live,",
        "tokens": [
          50937,
          293,
          286,
          603,
          1888,
          512,
          484,
          293,
          550,
          445,
          5039,
          552,
          1621,
          11,
          51081
        ]
      },
      {
        "avg_logprob": -0.2570940466488109,
        "compression_ratio": 1.744,
        "end": 5137.66,
        "id": 1712,
        "no_speech_prob": 0.00006708972796332091,
        "seek": 512072,
        "start": 5135.06,
        "temperature": 0,
        "text": " but I'll also show like 10 different ways",
        "tokens": [
          51081,
          457,
          286,
          603,
          611,
          855,
          411,
          1266,
          819,
          2098,
          51211
        ]
      },
      {
        "avg_logprob": -0.2570940466488109,
        "compression_ratio": 1.744,
        "end": 5138.860000000001,
        "id": 1713,
        "no_speech_prob": 0.00006708972796332091,
        "seek": 512072,
        "start": 5137.66,
        "temperature": 0,
        "text": " to solve the same thing, and like,",
        "tokens": [
          51211,
          281,
          5039,
          264,
          912,
          551,
          11,
          293,
          411,
          11,
          51271
        ]
      },
      {
        "avg_logprob": -0.2570940466488109,
        "compression_ratio": 1.744,
        "end": 5140.02,
        "id": 1714,
        "no_speech_prob": 0.00006708972796332091,
        "seek": 512072,
        "start": 5138.860000000001,
        "temperature": 0,
        "text": " how do we do it with the for loop,",
        "tokens": [
          51271,
          577,
          360,
          321,
          360,
          309,
          365,
          264,
          337,
          6367,
          11,
          51329
        ]
      },
      {
        "avg_logprob": -0.2570940466488109,
        "compression_ratio": 1.744,
        "end": 5141.22,
        "id": 1715,
        "no_speech_prob": 0.00006708972796332091,
        "seek": 512072,
        "start": 5140.02,
        "temperature": 0,
        "text": " how do we do it with reduce,",
        "tokens": [
          51329,
          577,
          360,
          321,
          360,
          309,
          365,
          5407,
          11,
          51389
        ]
      },
      {
        "avg_logprob": -0.2570940466488109,
        "compression_ratio": 1.744,
        "end": 5143.860000000001,
        "id": 1716,
        "no_speech_prob": 0.00006708972796332091,
        "seek": 512072,
        "start": 5141.22,
        "temperature": 0,
        "text": " how do we do it with map and filter.",
        "tokens": [
          51389,
          577,
          360,
          321,
          360,
          309,
          365,
          4471,
          293,
          6608,
          13,
          51521
        ]
      },
      {
        "avg_logprob": -0.2570940466488109,
        "compression_ratio": 1.744,
        "end": 5147.860000000001,
        "id": 1717,
        "no_speech_prob": 0.00006708972796332091,
        "seek": 512072,
        "start": 5143.860000000001,
        "temperature": 0,
        "text": " And I also have, if you check out the GitHub,",
        "tokens": [
          51521,
          400,
          286,
          611,
          362,
          11,
          498,
          291,
          1520,
          484,
          264,
          23331,
          11,
          51721
        ]
      },
      {
        "avg_logprob": -0.289268237632393,
        "compression_ratio": 1.6445993031358885,
        "end": 5151.04,
        "id": 1718,
        "no_speech_prob": 0.00012533352128230035,
        "seek": 514786,
        "start": 5148.679999999999,
        "temperature": 0,
        "text": " tons, like every video I've ever done,",
        "tokens": [
          50405,
          9131,
          11,
          411,
          633,
          960,
          286,
          600,
          1562,
          1096,
          11,
          50523
        ]
      },
      {
        "avg_logprob": -0.289268237632393,
        "compression_ratio": 1.6445993031358885,
        "end": 5153.88,
        "id": 1719,
        "no_speech_prob": 0.00012533352128230035,
        "seek": 514786,
        "start": 5151.04,
        "temperature": 0,
        "text": " the code for it is free and open source here,",
        "tokens": [
          50523,
          264,
          3089,
          337,
          309,
          307,
          1737,
          293,
          1269,
          4009,
          510,
          11,
          50665
        ]
      },
      {
        "avg_logprob": -0.289268237632393,
        "compression_ratio": 1.6445993031358885,
        "end": 5155.88,
        "id": 1720,
        "no_speech_prob": 0.00012533352128230035,
        "seek": 514786,
        "start": 5153.88,
        "temperature": 0,
        "text": " and there's also one for Code Katas,",
        "tokens": [
          50665,
          293,
          456,
          311,
          611,
          472,
          337,
          15549,
          8365,
          296,
          11,
          50765
        ]
      },
      {
        "avg_logprob": -0.289268237632393,
        "compression_ratio": 1.6445993031358885,
        "end": 5157.4,
        "id": 1721,
        "no_speech_prob": 0.00012533352128230035,
        "seek": 514786,
        "start": 5155.88,
        "temperature": 0,
        "text": " so if you have suggestions for that,",
        "tokens": [
          50765,
          370,
          498,
          291,
          362,
          13396,
          337,
          300,
          11,
          50841
        ]
      },
      {
        "avg_logprob": -0.289268237632393,
        "compression_ratio": 1.6445993031358885,
        "end": 5160.5199999999995,
        "id": 1722,
        "no_speech_prob": 0.00012533352128230035,
        "seek": 514786,
        "start": 5157.4,
        "temperature": 0,
        "text": " you can submit them here as an issue as well.",
        "tokens": [
          50841,
          291,
          393,
          10315,
          552,
          510,
          382,
          364,
          2734,
          382,
          731,
          13,
          50997
        ]
      },
      {
        "avg_logprob": -0.289268237632393,
        "compression_ratio": 1.6445993031358885,
        "end": 5162,
        "id": 1723,
        "no_speech_prob": 0.00012533352128230035,
        "seek": 514786,
        "start": 5160.5199999999995,
        "temperature": 0,
        "text": " So nicely organized.",
        "tokens": [
          50997,
          407,
          9594,
          9983,
          13,
          51071
        ]
      },
      {
        "avg_logprob": -0.289268237632393,
        "compression_ratio": 1.6445993031358885,
        "end": 5164.08,
        "id": 1724,
        "no_speech_prob": 0.00012533352128230035,
        "seek": 514786,
        "start": 5162,
        "temperature": 0,
        "text": " Something to aspire to, for me.",
        "tokens": [
          51071,
          6595,
          281,
          41224,
          281,
          11,
          337,
          385,
          13,
          51175
        ]
      },
      {
        "avg_logprob": -0.289268237632393,
        "compression_ratio": 1.6445993031358885,
        "end": 5166.04,
        "id": 1725,
        "no_speech_prob": 0.00012533352128230035,
        "seek": 514786,
        "start": 5164.08,
        "temperature": 0,
        "text": " So disorganized, I feel like.",
        "tokens": [
          51175,
          407,
          717,
          12372,
          1602,
          11,
          286,
          841,
          411,
          13,
          51273
        ]
      },
      {
        "avg_logprob": -0.289268237632393,
        "compression_ratio": 1.6445993031358885,
        "end": 5168.679999999999,
        "id": 1726,
        "no_speech_prob": 0.00012533352128230035,
        "seek": 514786,
        "start": 5166.04,
        "temperature": 0,
        "text": " Awesome, cool, so thank you so much for being here.",
        "tokens": [
          51273,
          10391,
          11,
          1627,
          11,
          370,
          1309,
          291,
          370,
          709,
          337,
          885,
          510,
          13,
          51405
        ]
      },
      {
        "avg_logprob": -0.289268237632393,
        "compression_ratio": 1.6445993031358885,
        "end": 5170.44,
        "id": 1727,
        "no_speech_prob": 0.00012533352128230035,
        "seek": 514786,
        "start": 5168.679999999999,
        "temperature": 0,
        "text": " I'm so glad that this worked out,",
        "tokens": [
          51405,
          286,
          478,
          370,
          5404,
          300,
          341,
          2732,
          484,
          11,
          51493
        ]
      },
      {
        "avg_logprob": -0.289268237632393,
        "compression_ratio": 1.6445993031358885,
        "end": 5172.04,
        "id": 1728,
        "no_speech_prob": 0.00012533352128230035,
        "seek": 514786,
        "start": 5170.44,
        "temperature": 0,
        "text": " because I know it's like, no, wait,",
        "tokens": [
          51493,
          570,
          286,
          458,
          309,
          311,
          411,
          11,
          572,
          11,
          1699,
          11,
          51573
        ]
      },
      {
        "avg_logprob": -0.289268237632393,
        "compression_ratio": 1.6445993031358885,
        "end": 5174.28,
        "id": 1729,
        "no_speech_prob": 0.00012533352128230035,
        "seek": 514786,
        "start": 5172.04,
        "temperature": 0,
        "text": " you're leaving this week, we have to do it now,",
        "tokens": [
          51573,
          291,
          434,
          5012,
          341,
          1243,
          11,
          321,
          362,
          281,
          360,
          309,
          586,
          11,
          51685
        ]
      },
      {
        "avg_logprob": -0.289268237632393,
        "compression_ratio": 1.6445993031358885,
        "end": 5175.92,
        "id": 1730,
        "no_speech_prob": 0.00012533352128230035,
        "seek": 514786,
        "start": 5174.28,
        "temperature": 0,
        "text": " before you go!",
        "tokens": [
          51685,
          949,
          291,
          352,
          0,
          51767
        ]
      },
      {
        "avg_logprob": -0.32637325446762727,
        "compression_ratio": 1.728125,
        "end": 5179.22,
        "id": 1731,
        "no_speech_prob": 0.00020339121692813933,
        "seek": 517592,
        "start": 5175.92,
        "temperature": 0,
        "text": " And so many wonderful, nice comments in the chat,",
        "tokens": [
          50364,
          400,
          370,
          867,
          3715,
          11,
          1481,
          3053,
          294,
          264,
          5081,
          11,
          50529
        ]
      },
      {
        "avg_logprob": -0.32637325446762727,
        "compression_ratio": 1.728125,
        "end": 5182.22,
        "id": 1732,
        "no_speech_prob": 0.00020339121692813933,
        "seek": 517592,
        "start": 5179.22,
        "temperature": 0,
        "text": " I hope people will subscribe to CJ's channel,",
        "tokens": [
          50529,
          286,
          1454,
          561,
          486,
          3022,
          281,
          42285,
          311,
          2269,
          11,
          50679
        ]
      },
      {
        "avg_logprob": -0.32637325446762727,
        "compression_ratio": 1.728125,
        "end": 5184.34,
        "id": 1733,
        "no_speech_prob": 0.00020339121692813933,
        "seek": 517592,
        "start": 5182.22,
        "temperature": 0,
        "text": " when I come to Denver, hopefully I can appear",
        "tokens": [
          50679,
          562,
          286,
          808,
          281,
          26270,
          11,
          4696,
          286,
          393,
          4204,
          50785
        ]
      },
      {
        "avg_logprob": -0.32637325446762727,
        "compression_ratio": 1.728125,
        "end": 5185.18,
        "id": 1734,
        "no_speech_prob": 0.00020339121692813933,
        "seek": 517592,
        "start": 5184.34,
        "temperature": 0,
        "text": " on the Coding Garden.",
        "tokens": [
          50785,
          322,
          264,
          383,
          8616,
          19429,
          13,
          50827
        ]
      },
      {
        "avg_logprob": -0.32637325446762727,
        "compression_ratio": 1.728125,
        "end": 5186.1,
        "id": 1735,
        "no_speech_prob": 0.00020339121692813933,
        "seek": 517592,
        "start": 5185.18,
        "temperature": 0,
        "text": " Absolutely, absolutely.",
        "tokens": [
          50827,
          7021,
          11,
          3122,
          13,
          50873
        ]
      },
      {
        "avg_logprob": -0.32637325446762727,
        "compression_ratio": 1.728125,
        "end": 5187.62,
        "id": 1736,
        "no_speech_prob": 0.00020339121692813933,
        "seek": 517592,
        "start": 5186.1,
        "temperature": 0,
        "text": " No, I just wanna thank you, like,",
        "tokens": [
          50873,
          883,
          11,
          286,
          445,
          1948,
          1309,
          291,
          11,
          411,
          11,
          50949
        ]
      },
      {
        "avg_logprob": -0.32637325446762727,
        "compression_ratio": 1.728125,
        "end": 5189.74,
        "id": 1737,
        "no_speech_prob": 0.00020339121692813933,
        "seek": 517592,
        "start": 5187.62,
        "temperature": 0,
        "text": " this has been amazing, like, to see the space,",
        "tokens": [
          50949,
          341,
          575,
          668,
          2243,
          11,
          411,
          11,
          281,
          536,
          264,
          1901,
          11,
          51055
        ]
      },
      {
        "avg_logprob": -0.32637325446762727,
        "compression_ratio": 1.728125,
        "end": 5191.78,
        "id": 1738,
        "no_speech_prob": 0.00020339121692813933,
        "seek": 517592,
        "start": 5189.74,
        "temperature": 0,
        "text": " also to the coding train community,",
        "tokens": [
          51055,
          611,
          281,
          264,
          17720,
          3847,
          1768,
          11,
          51157
        ]
      },
      {
        "avg_logprob": -0.32637325446762727,
        "compression_ratio": 1.728125,
        "end": 5195.18,
        "id": 1739,
        "no_speech_prob": 0.00020339121692813933,
        "seek": 517592,
        "start": 5191.78,
        "temperature": 0,
        "text": " like all the mods, Kweekmon, and Mayamsumi, and Alka,",
        "tokens": [
          51157,
          411,
          439,
          264,
          30899,
          11,
          591,
          23188,
          3317,
          11,
          293,
          1891,
          4070,
          17800,
          11,
          293,
          967,
          2330,
          11,
          51327
        ]
      },
      {
        "avg_logprob": -0.32637325446762727,
        "compression_ratio": 1.728125,
        "end": 5196.7,
        "id": 1740,
        "no_speech_prob": 0.00020339121692813933,
        "seek": 517592,
        "start": 5195.18,
        "temperature": 0,
        "text": " like, they've been hanging out in my channel,",
        "tokens": [
          51327,
          411,
          11,
          436,
          600,
          668,
          8345,
          484,
          294,
          452,
          2269,
          11,
          51403
        ]
      },
      {
        "avg_logprob": -0.32637325446762727,
        "compression_ratio": 1.728125,
        "end": 5198.9,
        "id": 1741,
        "no_speech_prob": 0.00020339121692813933,
        "seek": 517592,
        "start": 5196.7,
        "temperature": 0,
        "text": " and like, they're all wonderful people, it's awesome.",
        "tokens": [
          51403,
          293,
          411,
          11,
          436,
          434,
          439,
          3715,
          561,
          11,
          309,
          311,
          3476,
          13,
          51513
        ]
      },
      {
        "avg_logprob": -0.32637325446762727,
        "compression_ratio": 1.728125,
        "end": 5200.1,
        "id": 1742,
        "no_speech_prob": 0.00020339121692813933,
        "seek": 517592,
        "start": 5198.9,
        "temperature": 0,
        "text": " Awesome, cool.",
        "tokens": [
          51513,
          10391,
          11,
          1627,
          13,
          51573
        ]
      },
      {
        "avg_logprob": -0.32637325446762727,
        "compression_ratio": 1.728125,
        "end": 5202.18,
        "id": 1743,
        "no_speech_prob": 0.00020339121692813933,
        "seek": 517592,
        "start": 5200.1,
        "temperature": 0,
        "text": " And so, thanks for tuning in, I will,",
        "tokens": [
          51573,
          400,
          370,
          11,
          3231,
          337,
          15164,
          294,
          11,
          286,
          486,
          11,
          51677
        ]
      },
      {
        "avg_logprob": -0.32637325446762727,
        "compression_ratio": 1.728125,
        "end": 5203.58,
        "id": 1744,
        "no_speech_prob": 0.00020339121692813933,
        "seek": 517592,
        "start": 5202.18,
        "temperature": 0,
        "text": " I have this cold, which you might detect,",
        "tokens": [
          51677,
          286,
          362,
          341,
          3554,
          11,
          597,
          291,
          1062,
          5531,
          11,
          51747
        ]
      },
      {
        "avg_logprob": -0.24077075040793117,
        "compression_ratio": 1.7579617834394905,
        "end": 5206,
        "id": 1745,
        "no_speech_prob": 0.028866251930594444,
        "seek": 520358,
        "start": 5203.8,
        "temperature": 0,
        "text": " in theory, assuming I get a little better,",
        "tokens": [
          50375,
          294,
          5261,
          11,
          11926,
          286,
          483,
          257,
          707,
          1101,
          11,
          50485
        ]
      },
      {
        "avg_logprob": -0.24077075040793117,
        "compression_ratio": 1.7579617834394905,
        "end": 5210.88,
        "id": 1746,
        "no_speech_prob": 0.028866251930594444,
        "seek": 520358,
        "start": 5206,
        "temperature": 0,
        "text": " I'll be back on Friday, maybe I'll try the quicksort again,",
        "tokens": [
          50485,
          286,
          603,
          312,
          646,
          322,
          6984,
          11,
          1310,
          286,
          603,
          853,
          264,
          1702,
          82,
          477,
          797,
          11,
          50729
        ]
      },
      {
        "avg_logprob": -0.24077075040793117,
        "compression_ratio": 1.7579617834394905,
        "end": 5211.8,
        "id": 1747,
        "no_speech_prob": 0.028866251930594444,
        "seek": 520358,
        "start": 5210.88,
        "temperature": 0,
        "text": " but I have some other things",
        "tokens": [
          50729,
          457,
          286,
          362,
          512,
          661,
          721,
          50775
        ]
      },
      {
        "avg_logprob": -0.24077075040793117,
        "compression_ratio": 1.7579617834394905,
        "end": 5212.9,
        "id": 1748,
        "no_speech_prob": 0.028866251930594444,
        "seek": 520358,
        "start": 5211.8,
        "temperature": 0,
        "text": " that I'm definitely planning to do,",
        "tokens": [
          50775,
          300,
          286,
          478,
          2138,
          5038,
          281,
          360,
          11,
          50830
        ]
      },
      {
        "avg_logprob": -0.24077075040793117,
        "compression_ratio": 1.7579617834394905,
        "end": 5215.64,
        "id": 1749,
        "no_speech_prob": 0.028866251930594444,
        "seek": 520358,
        "start": 5212.9,
        "temperature": 0,
        "text": " so stay tuned for all that stuff.",
        "tokens": [
          50830,
          370,
          1754,
          10870,
          337,
          439,
          300,
          1507,
          13,
          50967
        ]
      },
      {
        "avg_logprob": -0.24077075040793117,
        "compression_ratio": 1.7579617834394905,
        "end": 5218.7,
        "id": 1750,
        "no_speech_prob": 0.028866251930594444,
        "seek": 520358,
        "start": 5215.64,
        "temperature": 0,
        "text": " This live stream, as soon as I hit stop streaming,",
        "tokens": [
          50967,
          639,
          1621,
          4309,
          11,
          382,
          2321,
          382,
          286,
          2045,
          1590,
          11791,
          11,
          51120
        ]
      },
      {
        "avg_logprob": -0.24077075040793117,
        "compression_ratio": 1.7579617834394905,
        "end": 5220.88,
        "id": 1751,
        "no_speech_prob": 0.028866251930594444,
        "seek": 520358,
        "start": 5218.7,
        "temperature": 0,
        "text": " will be available to watch, I mean,",
        "tokens": [
          51120,
          486,
          312,
          2435,
          281,
          1159,
          11,
          286,
          914,
          11,
          51229
        ]
      },
      {
        "avg_logprob": -0.24077075040793117,
        "compression_ratio": 1.7579617834394905,
        "end": 5222.42,
        "id": 1752,
        "no_speech_prob": 0.028866251930594444,
        "seek": 520358,
        "start": 5220.88,
        "temperature": 0,
        "text": " sometimes it takes like 15 minutes",
        "tokens": [
          51229,
          2171,
          309,
          2516,
          411,
          2119,
          2077,
          51306
        ]
      },
      {
        "avg_logprob": -0.24077075040793117,
        "compression_ratio": 1.7579617834394905,
        "end": 5223.5199999999995,
        "id": 1753,
        "no_speech_prob": 0.028866251930594444,
        "seek": 520358,
        "start": 5222.42,
        "temperature": 0,
        "text": " for like, YouTube to process it,",
        "tokens": [
          51306,
          337,
          411,
          11,
          3088,
          281,
          1399,
          309,
          11,
          51361
        ]
      },
      {
        "avg_logprob": -0.24077075040793117,
        "compression_ratio": 1.7579617834394905,
        "end": 5226.04,
        "id": 1754,
        "no_speech_prob": 0.028866251930594444,
        "seek": 520358,
        "start": 5223.5199999999995,
        "temperature": 0,
        "text": " but then it'll be available to watch as an archive.",
        "tokens": [
          51361,
          457,
          550,
          309,
          603,
          312,
          2435,
          281,
          1159,
          382,
          364,
          23507,
          13,
          51487
        ]
      },
      {
        "avg_logprob": -0.24077075040793117,
        "compression_ratio": 1.7579617834394905,
        "end": 5227.92,
        "id": 1755,
        "no_speech_prob": 0.028866251930594444,
        "seek": 520358,
        "start": 5226.04,
        "temperature": 0,
        "text": " Sometimes I do, you know, as you've watched,",
        "tokens": [
          51487,
          4803,
          286,
          360,
          11,
          291,
          458,
          11,
          382,
          291,
          600,
          6337,
          11,
          51581
        ]
      },
      {
        "avg_logprob": -0.24077075040793117,
        "compression_ratio": 1.7579617834394905,
        "end": 5229.6,
        "id": 1756,
        "no_speech_prob": 0.028866251930594444,
        "seek": 520358,
        "start": 5227.92,
        "temperature": 0,
        "text": " I do like, edited versions of live streams,",
        "tokens": [
          51581,
          286,
          360,
          411,
          11,
          23016,
          9606,
          295,
          1621,
          15842,
          11,
          51665
        ]
      },
      {
        "avg_logprob": -0.24077075040793117,
        "compression_ratio": 1.7579617834394905,
        "end": 5232.5199999999995,
        "id": 1757,
        "no_speech_prob": 0.028866251930594444,
        "seek": 520358,
        "start": 5229.6,
        "temperature": 0,
        "text": " I kinda don't think that this needs an edited version,",
        "tokens": [
          51665,
          286,
          4144,
          500,
          380,
          519,
          300,
          341,
          2203,
          364,
          23016,
          3037,
          11,
          51811
        ]
      },
      {
        "avg_logprob": -0.35091040017721536,
        "compression_ratio": 1.7003610108303249,
        "end": 5234.1,
        "id": 1758,
        "no_speech_prob": 0.0018672127043828368,
        "seek": 523252,
        "start": 5232.540000000001,
        "temperature": 0,
        "text": " because what would we edit out?",
        "tokens": [
          50365,
          570,
          437,
          576,
          321,
          8129,
          484,
          30,
          50443
        ]
      },
      {
        "avg_logprob": -0.35091040017721536,
        "compression_ratio": 1.7003610108303249,
        "end": 5235.740000000001,
        "id": 1759,
        "no_speech_prob": 0.0018672127043828368,
        "seek": 523252,
        "start": 5234.1,
        "temperature": 0,
        "text": " It was like, the whole thing was the thing.",
        "tokens": [
          50443,
          467,
          390,
          411,
          11,
          264,
          1379,
          551,
          390,
          264,
          551,
          13,
          50525
        ]
      },
      {
        "avg_logprob": -0.35091040017721536,
        "compression_ratio": 1.7003610108303249,
        "end": 5237.580000000001,
        "id": 1760,
        "no_speech_prob": 0.0018672127043828368,
        "seek": 523252,
        "start": 5235.740000000001,
        "temperature": 0,
        "text": " So, awesome.",
        "tokens": [
          50525,
          407,
          11,
          3476,
          13,
          50617
        ]
      },
      {
        "avg_logprob": -0.35091040017721536,
        "compression_ratio": 1.7003610108303249,
        "end": 5240.860000000001,
        "id": 1761,
        "no_speech_prob": 0.0018672127043828368,
        "seek": 523252,
        "start": 5237.580000000001,
        "temperature": 0,
        "text": " So thanks, thanks so much CJ, thanks for you watching,",
        "tokens": [
          50617,
          407,
          3231,
          11,
          3231,
          370,
          709,
          42285,
          11,
          3231,
          337,
          291,
          1976,
          11,
          50781
        ]
      },
      {
        "avg_logprob": -0.35091040017721536,
        "compression_ratio": 1.7003610108303249,
        "end": 5245.900000000001,
        "id": 1762,
        "no_speech_prob": 0.0018672127043828368,
        "seek": 523252,
        "start": 5241.9400000000005,
        "temperature": 0,
        "text": " and I'm looking at the chat, I'm gonna wave goodbye,",
        "tokens": [
          50835,
          293,
          286,
          478,
          1237,
          412,
          264,
          5081,
          11,
          286,
          478,
          799,
          5772,
          12084,
          11,
          51033
        ]
      },
      {
        "avg_logprob": -0.35091040017721536,
        "compression_ratio": 1.7003610108303249,
        "end": 5247.780000000001,
        "id": 1763,
        "no_speech_prob": 0.0018672127043828368,
        "seek": 523252,
        "start": 5245.900000000001,
        "temperature": 0,
        "text": " little train whistle for CJ.",
        "tokens": [
          51033,
          707,
          3847,
          23470,
          337,
          42285,
          13,
          51127
        ]
      },
      {
        "avg_logprob": -0.35091040017721536,
        "compression_ratio": 1.7003610108303249,
        "end": 5248.620000000001,
        "id": 1764,
        "no_speech_prob": 0.0018672127043828368,
        "seek": 523252,
        "start": 5247.780000000001,
        "temperature": 0,
        "text": " Ha ha!",
        "tokens": [
          51127,
          220,
          23745,
          324,
          0,
          51169
        ]
      },
      {
        "avg_logprob": -0.35091040017721536,
        "compression_ratio": 1.7003610108303249,
        "end": 5253.26,
        "id": 1765,
        "no_speech_prob": 0.0018672127043828368,
        "seek": 523252,
        "start": 5248.620000000001,
        "temperature": 0,
        "text": " And now I'm gonna hit the, again, someday I'm gonna do,",
        "tokens": [
          51169,
          400,
          586,
          286,
          478,
          799,
          2045,
          264,
          11,
          797,
          11,
          19412,
          286,
          478,
          799,
          360,
          11,
          51401
        ]
      },
      {
        "avg_logprob": -0.35091040017721536,
        "compression_ratio": 1.7003610108303249,
        "end": 5255.820000000001,
        "id": 1766,
        "no_speech_prob": 0.0018672127043828368,
        "seek": 523252,
        "start": 5253.26,
        "temperature": 0,
        "text": " CJ was teaching me some stuff about Open Broadcast Studio,",
        "tokens": [
          51401,
          42285,
          390,
          4571,
          385,
          512,
          1507,
          466,
          7238,
          14074,
          3734,
          13500,
          11,
          51529
        ]
      },
      {
        "avg_logprob": -0.35091040017721536,
        "compression_ratio": 1.7003610108303249,
        "end": 5257.14,
        "id": 1767,
        "no_speech_prob": 0.0018672127043828368,
        "seek": 523252,
        "start": 5255.820000000001,
        "temperature": 0,
        "text": " so maybe I'll get better at it,",
        "tokens": [
          51529,
          370,
          1310,
          286,
          603,
          483,
          1101,
          412,
          309,
          11,
          51595
        ]
      },
      {
        "avg_logprob": -0.35091040017721536,
        "compression_ratio": 1.7003610108303249,
        "end": 5258.660000000001,
        "id": 1768,
        "no_speech_prob": 0.0018672127043828368,
        "seek": 523252,
        "start": 5257.14,
        "temperature": 0,
        "text": " maybe I'll have an outro thing,",
        "tokens": [
          51595,
          1310,
          286,
          603,
          362,
          364,
          13170,
          551,
          11,
          51671
        ]
      },
      {
        "avg_logprob": -0.35091040017721536,
        "compression_ratio": 1.7003610108303249,
        "end": 5260.3,
        "id": 1769,
        "no_speech_prob": 0.0018672127043828368,
        "seek": 523252,
        "start": 5258.660000000001,
        "temperature": 0,
        "text": " but right now I'm just gonna hit the stop streaming button.",
        "tokens": [
          51671,
          457,
          558,
          586,
          286,
          478,
          445,
          799,
          2045,
          264,
          1590,
          11791,
          2960,
          13,
          51753
        ]
      },
      {
        "avg_logprob": -0.5344817421653054,
        "compression_ratio": 0.7948717948717948,
        "end": 5262.6,
        "id": 1770,
        "no_speech_prob": 0.0037649075966328382,
        "seek": 526030,
        "start": 5260.3,
        "temperature": 0,
        "text": " And there we go, bye everybody!",
        "tokens": [
          50401,
          400,
          456,
          321,
          352,
          11,
          6543,
          2201,
          0,
          50479
        ]
      }
    ],
    "transcription": " Yes, I unmuted myself. Okay. I'm getting okay. This is streaming. Hello, welcome to a very special Coding Train episode with a slightly different looking Coding Train logo. Hopefully some plants and flowers and things will start growing from here. I'm kind of vamping here to see if people in the chat start to say hi, that the sound is working and everything. I'm on time today and the reason is because it's not actually me who will be presenting to you. I'm very excited to introduce to you a guest, CJ from the Coding Garden. The Coding Garden is another YouTube channel that you should definitely subscribe to if you like coding tutorials, watching them live streamed on YouTube. We'll put links and all that stuff in the video description. I'm sure you can find it just by typing Coding Garden into the search bar. CJ is an educator, a maker, and a full stack web developer. So somebody who actually knows about proper full stack web development, which is something that I definitely do not know about. So I'm excited to have CJ here for about an hour to do a tutorial. I mean, he'll tell you all about it. I don't need to try to tell you about it. I'm sure I'm going to learn a ton watching it. So this will be a live stream. I am going to tiptoe off to the side and sit with the laptop looking at the chat. So if you have questions, ask them there. I'll kind of compile them. We can interrupt CJ if we need to, but otherwise we'll let him kind of present and then ask some more questions at the end as well. Did I miss anything? I think that's it. Okay. Can you hear CJ? You can hear his voice. So we're going to do the awkward shuffle now. I'm not like a professional talk show kind of like coding host thing where, welcome, and then I'm going to mute my microphone so I don't by accident make too much noise. Welcome CJ. Thanks so much, Dan. First off, just huge, huge thanks to Dan and the Coding Train community. Yes, thank you. And this is going to be a lot of fun. So the plan for today is to build a full stack application. And the idea is I'm going to build a very basic Twitter clone to demonstrate all the parts and pieces of the full stack. So the idea is we're going to be building Meower, which is Twitter for cats. And it will have two features. Cats can send a mew, which is like a tweet, and cats can see all the mews that they have sent. So you can see a simple little animation here of what we're going to be building. Basically, we have a form. You put in your mew. And then when you click send, it gets sent to the server. It gets put in the database. Then the front end requests all of them. It all comes back and you see it all. And we're going to build that today from scratch. So I have all of our objectives here. The first one is to diagram the full stack. So we're going to draw a picture and talk about the different parts and pieces and how all of this interacts together. So let's do that. So the full stack is typically split up into two pieces. More pieces than that in each piece. But you have the front end and the back end. What is this? I think that's your head. It was in the camera. No, it's fine. But front end and back end. So here I'm going to draw the front end. And then we also have the back end. And when we talk about the front end, this is what the user sees. So I'll also be referring to this as the client. But this is what the user sees. So the user uses a web browser. So you can think of it like it's a little box here. And they type in the URL. And they'll have some place to type. And they'll have a button that they can press. But the front end is what the user actually sees. And this gets loaded into a browser. And so you can think of this on a laptop, on a desktop, on a mobile phone. Anything that has a web browser, that is the client. And that is the front end. So there's also the back end. And here we're going to have a couple different back end servers. So the first one will be known as the static file server. And this is where all of the files that we write to run inside of a client will live. And I guess it's important to note that there are a lot of different ways you could build a full stack application. But the way I'm going to build it today kind of splits things up in this way. But let me know. There are a lot of other ways you could do this. And on the back end, you also might have more of a dynamic server. Dynamic server. And today we're going to be using Node.js for that. But there are a lot of other things you could use. And specifically, we are going to be using JavaScript for this dynamic server. But you've probably heard of PHP or C Sharp or Java. Those different things could be running on the server here. At the end of the day, whatever is running on here will return JSON data. So this is we're going to be building a JSON API. So if you've heard of API, if you've heard the word cloud, or I guess, yeah, cloud, that's really when we're talking about the back when you when you say it's in the cloud, it's some back end type of server. Real professional operation. No, it's great. Cool. So we have the client. That's the front end, we have the back end. So we will call this the dynamic server. This is where Node.js will be running. For our static file server, we're going to be using something called live server. I believe Dan set up this the other day on your setup stream. So he shows how you can install that. I'm just going to be using it to serve up our client. And then another part of the back end is the database. And that usually is drawn like this. The database, and there are lots of different things you can use for your database. There's might have heard of SQL, you might have heard of NoSQL. Today, specifically, we're going to be using a NoSQL database called MongoDB. MongoDB. And you might choose a different database depending on the application that you're building. But today, we are going to be using MongoDB. And really, when you build an application, you pick and choose maybe what's the best type of database. But the main idea with a database is that it is persistent storage. Persistent... That might not be how you spell that. Storage. But let's take an example. So when you visit twitter.com, a web page loads, and it's very dynamic. There's a lot of stuff in it. You have your tweets, you have other people's tweets, you have a place where you can search and you have all of this stuff. But what really happens is when you type a URL into your browser and hit enter, that makes a request to, in this case, we'll say a static file server. So the moment you type in a URL, this will make a get request for some file. In this case, it's going to request index.html. And the static file server will then respond with that file, which contains all of the HTML contents. HTML. And this is the code that we write, and it will get loaded into the browser and then the user will see it. So this is kind of the first part of what's happening in the full stack. Let's write some code. Okay, so the first thing we'll do is set up the client side. So in this directory here, oh, and before I forget, I did, all of this is on GitHub right now. It's just a checklist. But as I code, I'll push it up to GitHub. One of the mods can potentially share this link. I put it in the Slack, you can share it in the chat, if people want to click on it. But the first thing is we'll create a client folder. And inside of that client folder, here in VS Code, we'll create a new file and call it index.html. I'll create a basic HTML document. The title will be Twitter for cats. And let's put like a little cat emoji. There we go. For now, I'm going to get rid of this link in the script. Here in the body, we'll add a header. And inside the header, I'll have an h1 that just says, same thing, meower, Twitter for cats. Okay, so I have a basic HTML file. This is what the user will see. So in my terminal, I am currently in the client folder. And here is where I'll run the live server. So this will start up a static file server. And then when the browser loads, it loads that file that I created. So if I change that file, let's add more emojis, cat, another cat, and save it, live server automatically refresh. But the browser will make a get request for this file. So let's just see it happen. I put this URL in, I hit enter, that's a get request to get the HTML, the browser receives it, parses it into the DOM, lots of stuff happens. But ultimately, this is what the user sees. So, so far, we're at that first line in the diagram. Okay, and let's set up like a basic skeleton of a website. So for this skeleton, I'm going to be using this thing called skeleton CSS is a very basic CSS framework. There are a lot of other CSS frameworks out there. Bootstrap is a really popular one or materialize. Basically, it gives us some default styles so that our site looks good by default. It's not like this ugly font. So let's grab this. So I can just grab this CSS file. And then in here, I'll add a link to it, throw that in, save it. And if we go back to the browser, looks a little bit nicer. So this CSS framework automatically adds in fonts and different styles to make it look a little bit better inside of the browser. Let's add our own styles as well. So right below here, I'm going to add a link to styles.css. And then in the folder, I'll create a new file called styles.css. And let's just say the header, let's give it a class. So this h1, we'll give this a class of title. And then in our CSS, we'll say title has text align of center. And that should center the text. And if we go back to the browser, there it is, it's in the center. So just to talk about what's happening so far in the diagram, you'll notice that our HTML file has a link to a CSS file and a link to another CSS file. So what happens is the browser will load the file, and then it will see those links. And then it has to go out and request more files. So let's look at the diagram here. And so basically, it first loaded the request made was made for the HTML file, then it needed more things. Basically, the browser parsed it and said, Oh, you want a CSS file from get skeleton? Oh, you want styles.css. So more requests went out. So there was a request here to get the styles.css. And then the static file server, which is live server responds, the browser takes that and then loads it in and we see some beautiful styles and they're applied to the document. So every single thing that's happening in here is part of a request that's going out to a server. So now that the page is loaded, it the at this point, it's just static, it's just sitting there, we're seeing what we see, it's not communicating to any servers anymore. So what we want to do is we want to make it so that the user can type in their view and then send it off to the server. So let's get that going. Here. So we created a header, we created the form, we brought in our CSS. Oh, haven't created the form, we will create the form. Any lingering questions or anything like that? Okay, cool. Okay, so in here, I'm going to add a main area. And here I'll add the form. Typically forms are what we use to get user input. So if you've ever typed into a text box or something like that, it is a form. So on this form, I want a label, this will be for users name. And then I'll add an input. And this will be a text and we'll give it an ID of name. And we'll give it a name of name. And let's see what we get. So by default, we get a nice little input box on the screen. Let's give it some styles. So built into skeleton is this class named you full width. And you'll notice that the input went all the way across. But I don't want it to take up the whole screen. So let's add some more styles. Let's call this form, let's give it a class of like new form. And in here in the styles, I'll add a new one for new form. Let's say the width is like 50%. And it has margin zero and auto. So it should center there we go. So our form is like nice and center on the screen. And that's for the name. And then we also need a text area for the new. Okay, so the four here will be called this content. We'll say this new, the ID will be content, the name will be new, sorry, content. And instead of an input, we want a text area. And that gives us an area where they can type in their content as well. Okay, last thing we need is a button so that they can submit this form and send the data to the server. So we'll just say send your new input, a nice little cat in there, like that, we get a nice little button. Another thing built into skeleton is this button primary class, and we'll give it a nice blue color. So let's make this button dash primary, then we get a nice little button, we can click cool. So we have this form, the user can type in here, but now we actually want to send this data somewhere. But let's look back at our checklist. So we created a form, we have name, we have content, we've listened, we've set up full width and all the inputs. But now we actually need JavaScript to listen for when this form is submitted. So here's what I'll do. I'll create a new file, let's call this client.js. I'm going to be creating other JavaScript files. So just to make sure we're clear as to where we are when we're working on them, I'm going to call this one client.js. And I'm going to go ahead before I forget, we'll add a script at the bottom here that will bring in our client.js. And just to make sure it's working, let's just log hello world. And back to the browser, open the dev tools, and it is working, we get to the hello world log. Cool. So now we actually want to listen for when the user clicks this button, so that way we can grab all of the data that's in the form. So first thing I'll do is get a reference to the form by using document.query selector. And then with query selector, you can pass in any valid CSS selector to choose some element on the page. So in this case, I want to select this form. So a valid CSS selector for that is just to pass in form. And that will give me the form. So part of our objectives were to differentiate between client-side JavaScript and server-side JavaScript. Anytime you see document, that is client-side JavaScript, because we're actually interacting with the web page, with the thing that the user is interacting with. So we have the form, now we want to listen for when the user clicks submit. So we're going to add an event listener for the submit event. We'll get access to the event. And then for now, let's just log out form was submitted. Cool, let's see what happens. So my name is CJ, my view is hello world, world, world, go. And you'll notice it tried to log but then the page refreshed. And you'll notice the URL changed here. So by default, when a form is submitted, the browser automatically tries to send the data somewhere. But we don't want that we want to stop it from happening so that we can handle it with JavaScript. And for this we can do prevent default. And now that we're preventing the default action, the data won't go anywhere, we're basically telling the browser, well, now we want to do this with JavaScript. So here, let's try to log form submitted. And then hello world, click submit, and it says form submitted. Cool. So we've tapped into when the user clicks this button. Now we actually want to grab the data from the page. So to do that, I'm going to use form data. So form data is built into the web browser. And it works by passing in a reference to the form. So because I already have this form variable, we can pass it in here to form data. And now we can grab some of the user input from the page. So specifically, if I want to grab the name here, because I have the name set up as name, I can say, let's say name is equal to form data.get and pass in name. And if I also want the content, I set up the name here to be content. So I can say, content is form data.get content. And now I have what the user typed into both input boxes. And so let's just create an object called a mu. And inside of it, I'll have the name and the content. And let's just log it out. Cool. So now when the form is submitted, we should see an object. Hello world. Go. Nice. So we have the object. But remember, we're still on the client side, we haven't actually interacted with our dynamic server just yet. So let's go back to our checklist. We are listening for the submit, I guess one thing we'll do is when the form is submitted, we want the user to know that something is happening, like the data is going somewhere. So I'm actually going to show a little loading image. So I have this loading GIF here, let me put it in the client. And in the HTML, I'm going to have a div right below the form. Let's just give this a class of loading. And inside of here, I'll have an image, its source will be loading.gif. And by default, it should like show on the page. There it is. But I want to like center it first. So in my CSS, I'll say loading. Actually, let's just give it the same 50% width as the new form. So that way it should automatically pop up in the middle. Almost good enough for me. So the this is showing automatically when the page loads, but I actually want to hide it the moment the page loads and then only show it whenever we've submitted the form. So let's grab a reference to it. So I'm gonna call this the loading element, this will be document dot query selector. And we need to pass in some selector to get access to this div. In this case, I can tell it to grab the element with the loading class. And when the page loads, I'm just going to hide it. So to do that, I can access its style. So loading element dot style, and set its display to none. Okay, and so now when the page loads, the loading actually hides. But what we want is when we submit the form, we will hide the form and show the loading. So here's what I'll do. I'll set the loading to be displayed, and then I'll set the form to be hidden. Okay, so my name is CJ, my name is Hello World. And then when I click submit, we're logging it to the console, we're showing this loading image. But now we actually need to send the data somewhere. Someone is giving me a tip. Noel is saying center the GIF with text align center on the container. Let's do it. So in here, well, actually, I specifically want to say loading has text align center. Yeah, thanks, Noel. Actually, I just turned my mic back on a couple interesting questions. I noticed you using using query selector. Yes. And somebody asked, well, why don't you use on click or I know there's like document dot get element by etc. So can you talk a bit about why you'd use a query selector? Definitely. So ultimately, what I want to do with this line of code is select some element on the page. So there are a lot of different ways to do it. There's get element by ID, there's get elements by class name, get elements by tag name. There's if you've ever used jQuery, it's just like dollar sign and putting the selector you want in there. I mainly use this because it's convenient. Like I know what specifically what selector to use to select it. But at the end of the day, this is just grabbing an element on the page. So you can use whatever you're comfortable with. Cool. That's a good question. Other ones? There were some more I was trying to keep them like slightly. Let me see. Okay, well, one person asked does use you know, I think they were referring to this is Ahmad in the chat as does using a framework affect performance. And I think that was referring to the CSS framework. So like, is it like a big thing to load? Does it make the page run slower? Are there considerations there? Definitely. So I wouldn't say it makes the page run slow, but there will be a little bit of time before the styles will kick in because the browser does have to download the CSS file. But once it's downloaded the CSS file, and it's up and going, you're good to go there. And a mental note, I don't think we need to do this now. But people are in love with your color themes. I noticed your the console on the browser was like a dark theme. So maybe a little bit at the end, maybe you could show us like, what fonts, theme settings and stuff. Definitely, definitely. And so I totally glossed over this. So on my channel, I talk about Vue.js, I talk about React, I talk about a lot of other front end frameworks. And right now I'm doing all of this with what we call vanilla JavaScript, meaning I haven't added any JavaScript libraries, really to just show how all this stuff is done manually. But typically, I'll use something like Vue.js, which which fits in here on the on the diagram will kind of show where specific technologies fit in. And if you have any questions about like, where does this technology live? Throw that in the chat. And we can put it in the diagram too. Okay, let's look at our checklist. We're hiding the form, we're showing the loading, we got the data form, we've logged it. And now we have completed two objectives, we have gotten user input on the client, and we have hidden and shown elements on the client. So this is typically how we get user input when you're dealing with some sort of form. And when you're dealing with vanilla JavaScript, just manipulating the display property of style is how you hide and show something. So we're doing that. Now, we move on to the back end. So before, in the code that we just wrote, if you click into the chat, you have to click back into the OBS window. Oh, this is this is me over here. So the code, the code that we just wrote is very important note is is running right now it's running inside of the browser. I don't know if you can see that right, let me grab a different color. So we just created that index dot HTML, it's running in here. So what we're about to do is we're going to jump to the back end and write some code that's going to be running on our dynamic server over here. So let's do that. Okay, so first step, let's create the server folder. Now, as I mentioned, there's a lot of different ways to do this, you technically could put the client folder inside of the server folder, but I'm just going to show them completely separate just to really differentiate between like what they are. So here, let's make a server folder. And in the server folder, this is going to be a node project. So I'm going to initialize this with a package JSON. So npm init dash y just gives it all of my defaults, it tells it my name gives it my default license. And then we need a couple of packages. So specifically, we're going to be using Express as our framework to listen for requests that come from the client, and then respond with the appropriate data. We're also going to be using a middleware library called Morgan, which will log all of the incoming requests. So we can kind of debug what's happening on the server. So we're going to install Express and Morgan. Cool. Awesome. So those two things installed. Now we can set up our server. So on the server, new file, let's call this index.js. And inside of here, we're going to create our dynamic server, our backend application. So let's bring in Express. So if you're familiar with Node.js, this is how we bring in a library that we've installed with NPM. So I brought in the Express library. And the first thing we do is create an application. And this is just equal to app equals Express invoked. So now I have an Express application. And now we want it to actually start listening. So if you saw before, right now I'm using this static file server, which is live server. And it's running on port 8080. Every computer has many, many different ports. And so we're going to have two servers running on my computer. One will be on 8080, and the other one will be on 5000. So I want to start up this backend server. And I'm going to tell it to listen on port 5000. And when it's ready to go, I'm going to just log out. Listening on HTTP://localhost 5000. Cool. And so if I run this, we should get a server that starts listening on port 5000. So before I start it, in my package JSON, I'm going to add a start script. So this is basically where you can put the command that should actually start up your server. In this case, it's node index.js. And by doing this, now in the terminal, I can just do NPM start. And that will start up my server on port 5000. So if we take a look at it, right now it's nothing. So we have a blank backend application. It doesn't have any routes. So when I try to request it, it just says, cannot get that. And so basically, we're going to start defining what happens when a client makes requests to this server. So let's look at our checklist. We created the server folder. We initialized it. We installed dependencies. We have our basic setup. Now I'm going to add a listener for when a get request comes in on the slash route. So as I mentioned earlier, when you just put something in your browser and hit Enter, that is a get request. And by default, it's making a get request to the slash route. So what I'm going to do on my server is say, hey, server, when you get a get request on the slash route, run this function. And we have two variables in here. Typically, they're abbreviated rec and res, which I like to do. But they really stand for request and response. And these are two variables that exactly correspond to our diagram. So here, this is the request. It's what the server is asking for. And then this arrow going from the back end to the front end, this is the response. Now in this diagram, that's with our static file server. But the exact same thing is going to happen with our back end server. So our client eventually will be making a get request to our dynamic server. It's going to say, I want to get all news. And the dynamic server will do some processing. It'll talk to the database. And then ultimately, this thing will respond with a big JSON object. Actually, an array. It'll respond with an array of JSON objects. Various things inside of them. But specifically, the request that the client will make here is the request. And the response that the server gives here is the response. I guess I'm using the word in what I'm talking about. Inside of Express, those two variables mean exactly that. Yes, go for it. I have a question. So I'm curious as to why, or if it matters, you're still using the live server for the static files. Is the idea that you would eventually move the static files also? Why not have the dynamic server also host those static files? Yes, so there are a lot of ways to do it. You could do that. But I am actually, at the end, I'll show how we put this on the internet. And the idea with keeping these on a separate server is that we can benefit from things like a CDN, like Content Delivery Network. And so let's say you get thousands of users to your website. They're all going to be requesting the home page from this CDN, which has it cached on thousands of servers all over the world. And so the initial web page will load really well. It's good timing that it turned off now. And so by having it on a separate server, it makes the incoming requests go to different servers. So the request for actual data will be to this server. But when people are loading the page, it'll load there. And I will show how to put it on two different servers. No, it totally makes sense. Let me flip this camera back. It'll be so seamless. No one will even know. Were there other questions? No, I don't think so. OK, let's do it. So as I was mentioning, these two variables represent that incoming request and the outgoing response. So I'm going to rename these to rec and res. And here's what we say. So when the client makes a get request on the slash route, we want to respond with some JSON. In this case, I'm just going to pass in a message. And it says, meow. And we'll throw in an emoji, like a laughing cat. Cool. So we now have our server set up. When it receives a get request on slash, respond with a JSON object. Let's try it. So we go to the browser. We now request the data from our server, which is on port 5000. Nothing happens. So when you're working with Node.js, if you ever modify the files, you have to actually kill the server and then restart it. And then it should work. So we make the request, and we get the data back. But while I'm thinking about it, there's this handy tool called Node Mom, which will automatically refresh every time I change the server. And I'll install that. And basically, I'll run it. And any time I change files on the server, it'll automatically restart. And we should see those changes when we make a request to it. So Node Mom is installed. I'm going to add a new script in my package JSON. So I'm going to create a dev script, Node Mom. And we just do the same thing. So tell Node Mom to run against that file. And now if I do npm run dev, that starts up Node Mom. And any time I make changes, it should restart the server. So this loads. But if I go back to my server code and add a new emoji, like the regular cat, and I, again, make the request. And so you might not be seeing this, but I'm pressing Command-R. So I'm refreshing the page, which is making another get request to the server on slash. And then I see the latest result. Cool. So we have a basic server set up that's responding to incoming requests. Before I move on to this next thing, any other lingering questions? There were some semi-off-topic questions. I mean, they're related to web development, but not exactly what you're coding. So we can save those to the end, I think. Awesome. I've cataloged. Cool. So let's now work on the route for receiving the email. So if we can remind ourselves what's about to happen here. On the client, when we type in CJ and we type in some message like, hello world, and click Send, that has to send it to the server. So we're going to create a route that's waiting for that incoming data. And we'll actually then insert it into our database. So let's create the post route. So here, I'll do an app.post. And we'll make the route slash Muse. So when the server receives a post request on slash Muse, we are going to run this request handler. And for now, I am just going to log the request body, rec.body. Let's log it. And what should happen is when some incoming post request happens to my server, it will log out whatever the client sent to us. Cool. So now, let's get that going on the client side. So we're just logging it. But now, we're going to go back to the front end and actually send the data to the server. So on our front end, we're going to use something called fetch. So right here, instead of just logging out to the console, we're going to actually send that data somewhere. So first thing is I need a variable to hold onto where is the server that I'm making requests to. So we'll call this API URL. And this will be HTTP colon slash slash local host port 5,000. And slash mus. So I'm going to be making a post request against this URL to actually send this object to our dynamic server. So here, we'll use fetch. We'll pass in the URL that we're making the request against. And then we have to specify a few different options. So in this case, we need to tell it that the method is post. We need to say what is the body of the request. In this case, the body of the request or the thing we're sending to the server is the mu itself, this object with name and content. So we're going to set body to be mu. And then also, we need to specify some headers. So we need to tell it what are we sending it. In this case, we'll specify the content type header. And we'll say application JSON. So we're telling the server, hey, server, in the body of my request is JSON. But right now, it's actually not. So right now, it is a JavaScript object. But to turn it into JSON, we have to use JSON.stringify. And this will actually take that object, turn it into something that the server can parse and understand. And then we should be able to see it on the server side. So essentially, what's happening here is when the form is submitted, we grab the stuff from the form. We put it in an object. We show that loading spinner. And then we attempt to send this data off to our back end server. So let's see what happens. And actually, let's set up. OK, I have the back end route. I have the form. Let's see what happens. We're going to watch the server side logs, because we want to make sure that we're actually seeing that incoming thing that the client is sending us. Let's see. OK, so my name is CJ. My mu is hello world. And I throw in a cat. And then we try to send it. Oh, no, the dreaded cores error. You may have seen this before, but right now it's saying response to preflight request doesn't pass access control check. No access control allow origin header is present on the requested resource. So therefore, origin 127.00.0180. So you'll notice the web page is currently on 127.00.0180. That is the current origin. Is therefore not allowed access to the origin, which is on port 5000. So essentially, the browser is trying to protect us. It's doing this on our behalf. It doesn't want JavaScript to be able to talk to just any server in the world unless those servers actually allow it. So what we can do on our back end is say, I will allow incoming requests from any other origin. So to fix this specifically, we're going to install something on the back end. Now, if you get this error, you may not always have your own server. You might get this error because you're trying to talk to some other server. And in that case, there are other ways to get around it or fix it. But in this case, we are going to use a package on the back end which will automatically add this header, this access control allow origin header. So in our server folder here, I'm going to install cores. So this is a npm package, which is an Express middleware. And then in our server side, so first, before we move on, let's clarify where we are. See the cores error revel in this moment. You'll see this error a lot. There are different ways to fix it. But specifically, if you're in control of the server, you can install the cores module. So we saw it. We recognized it. We remembered pretty much how to fix it if we're in control of the server. That was the front end. We were working on code here that's sending data to the server. And now, we're going to transition back to the back end. So we installed cores. And now, let's use it. So the way this works is I can bring in the cores module and then do what's called using it. So I'll say app.use cores. And this actually adds cores as a middleware. So now, any incoming request to my server is going to pass through this middleware, and it's going to automatically add those cores headers to it. So this should get rid of that error. And then we'll see if we're actually logging out what the client is sending us. So we'll go back. We'll try again. My name is CJ. My mu is hello, world. We'll send it. And we see undefined. So another thing that you have to do on the server side is add a middleware that's going to parse incoming data. So right now, in the client, we can see on network that this post request is attempting to happen. So it's making a request here. It's sending this data. So we are sending it from the client, but the server can't process it. So for this, we actually need to add the body parser middleware. And this is built into Express. So I can use express.json. And this is a JSON body parser. So any incoming request that has a content type of application JSON will be parsed by this middleware and then put on the body. So now, we actually should get access to rec.body. Let's try. So name is cj, mu is hello, world. We're going to add a cat here. Oh, not that cat. Cat. Go. And notice, the server is now receiving the data. So the client, the user types in their information. They click the Submit button. It gets sent to the server. And now, the server has to actually do something with it. So let's look at our checklist. We have made sure that we're actually receiving that data. The moment I press this Submit button, the server is receiving it. So I can try again. What? And the server is actually receiving that. So we're taking it from the client and sending it to the server. So we added our middleware. And now, we can process this incoming request. So on the server side, we actually want to do some validation. We want to make sure that the client, what they're sending us has a name, has content. So let's just do, we'll say, if is valid mu. And we'll pass in rec.body. And if it is, then we'll insert into db. So we'll handle that in a bit. But if it's not, we actually want to respond with an error. Right now, my client side, technically, you could click that Submit button without typing anything in. So I want to protect against people just submitting blank data to the server. So here, I'm going to just do a res.status. I'm going to set this to 422. And then here, I'll do a res.json and just give them a message. Hey, name and content are required. Cool. And now, let's write this function isValidMu. So isValidMu, nope, not that, takes in, so this is a function, it takes in a mu. And we want to make sure, so if mu.name is a thing and mu.name.toString.trim, so we're going to take the name that they're sending us, make it a string, trim it to remove all white space, and make sure that that does not equal the empty string. So we're going to make sure that they have actually sent us a name and this exact same thing for the content. So here, we'll make this content. So we're going to make sure that they're sending us a name, they're sending us some content, and then we'll put it into the database. And for now, let's just create an object. Let's call this mu. And it will have a name, which will be rec.body.name.toString. And then we'll also have a content, and this will be rec.body.content.toString. There was actually an interesting question. So I noticed you doing this validation. Do you ever use a library, or this came from Nahuel Jose, is there any library or node module that you know that helps with data validation? Yeah, absolutely. So you don't have to do all that code manually in your code. Definitely. So there is, it's literally called Express Validator. You can search it on NPM. And there's probably a lot of other ones out there. But these are various libraries that just make it a little bit easier to do validation on incoming requests. So this is a pretty popular one. Maybe this is not the one. But yes, there are packages that will do that for you. And then also, on my stream before, I've used something called Joy, which is. It's being discussed in the chat. And I was like, I had no idea what anybody was talking about. Yeah, so Joy is a library that comes out of the Happy team. So Happy is another framework, very similar to Express, but you just do things a little bit differently. But Joy is a really cool library, because you can do object schema validation, and make sure something is a string, and it's alphanumeric, and it has a very nice way of defining it. I actually found one called, I think it's called Yup, which was based on Joy. It's very similar. But yes, there are lots of them. Initially, when you're getting started, I like to just show this to show what's happening. But absolutely, if you have an object that has 10 properties, you probably want to use some library like this. Oh no, did I just close Chrome? I think I did. Wait, did I? Oh well. Localhost 3000, no, 5000. And then localhost 8080. And what about, someone also asked something related to security. Yes. But I don't, well, they're talking about secure those routes, form validations. You talked about form validation. So yeah, and like, I'm. What's missing here in terms of security, I guess. Definitely. So the main thing is, you always want to validate what you're putting into your database. And I'm doing that right here. I'm making sure that the data they're sending us has a name and has some content. And then the other thing I'm doing, which I kind of glossed over, is whatever they're sending us, I'm saying to string. So when you're dealing with a database, you want to prevent what's called injection. So if they tried to send us a nested object instead of just a string, and I didn't say to string, we could potentially put that into our database. So you want to be very careful there. The main thing is, if you're dealing with receiving data from a client, you always want to do validation. You always want to be very careful about what you're putting into your database. They are correct in that I haven't done any validation on the client side. But as long as I'm doing it on the server side, no one's going to be able to put bad stuff into my database. Definitely. OK, so now we're validating it. And it should. So actually, if I, let's look at the dev tools. And I try to send this as an empty form. You'll notice I get back an error. I should probably handle it. We don't have time. But if I do send it good data, then it logged it out. And now we're ready to insert it into a database. So let's look at our checklist. We have validated the name and content. It must be a string. It's not empty. If it's not valid, we're responding with a port 22 error. And we are making sure that it has name and content. Now we want to put this thing into a database. So for the database, I'm going to be using MongoDB. And there are a lot of libraries for talking to MongoDB. Specifically, the library I'm going to be using is called Monk. It's very simple, very easy to interact with. A really popular one people use is called Mongoose. But this is way simpler to get set up. So I'm going to install a package called Monk. And locally, I have MongoDB installed on my computer. So I can type mongo. That drops me into a mongo shell. And I can actually query the database, insert stuff in, and interact with it in this way. But as long as you have it installed and running, the stuff I'm showing now will allow you to connect to your database. So I installed Monk. And let's get it going. So in my server, we're still on the server. Let's create a connection to the database. First thing is we'll bring in Monk. And then we will create a connection to the database using Monk. So I'm going to create a variable called db. This will be Monk. And then you pass in how does it connect to the database. In this case, my database is running on my local machine. So I can do local host. And I tell it what database do I want to talk to. In this case, we'll call it Meower. And right now, this just says connect to the MongoDB on my local machine to a database called Meower. Simple enough. The way Mongo works is with collections. You can have different collections of data. Think of a collection as just basically an array. So ultimately, what we're going to be doing is we'll have an array. And then every time someone submits a mew, we'll put an object in here that has a name. And it has some content. And then Mongo will automatically assign it some unique ID. But basically, every time we put something in the database, this array is just getting bigger and bigger and bigger. But the cool thing about this is it's not just an array. It's a full-fledged database. It keeps track of the information. If the server ever goes down, it's all still there. But that's pretty much what you can think of a Mongo collection as. It's just a database or an array that we're just pushing data into. So I want a collection called mews. So I'm going to create a variable called mews and say db.get. And we'll just pass in mews. So this is now a collection. And the cool thing about Mongo is if the database doesn't exist, this will automatically create it. If the collection doesn't exist, this will automatically create it. So we basically are just connecting directly to the database. And if it doesn't exist, we're creating that collection. Now, mews is a collection inside of our database. And here, after we've done all of our validation, we want to insert it into the database. So let's just do mews.insert. And specifically, if you want to know how to use MonkMore, you can look at their documentation. There's all kinds of methods, like insert and update and find. Specifically, I'm using the insert method. And I'm going to pass in the mew that I want to insert. And then we should get back the created mew. And in this case, I'm just going to respond back to the client with what was just created. So I'm going to do a res.json. We'll pass in the created mew. And let's see what happens. So let's back up a little bit. We are listening for when the client is sending a POST request to this URL. They're sending us data. We're going to validate it before we insert it into our database. We'll create the object. Then, using our existing collection here, we will insert it in. And then once it's inserted, we're going to respond with what was just inserted. So save that. Let's check some boxes. And then we'll check to make sure it works. Cool. Oh, and one thing I forgot is before we insert it, let's also give it a created date so we can actually show whenever these mews were created. So for this, I'm just going to say created is a new date. Cool. We've inserted it. We've responded with it. And as long as I've done everything right, we should be actually inserting it into my database. So now, back to the front end. So if you remember, this was all initiated by this POST request here. The client is sending our server some data. And the server is then inserting it into the database. And then now, we actually need to do something with it. So here, I'm just going to do a.then. We're going to get back the response. And I know that the response is JSON because my server is responding with JSON. So on the client side, I can say res.json. And then I get access to the created mew. And for now, let's just log it. So our client will send the request. The server will receive it. And then we'll log it out. Cool. Let's see what happens. So now, CJ, my mew is hello, world. Throw some emojis. That one, that one, go. Cool. So you'll notice that I'm actually getting back an object. And you'll notice it has an ID. So this thing was actually inserted into the database. And then it responded with that object. So that's great. It's in the database. Now, we actually want to show all of the mews that have been created on the page here. So let's do that. Let's look back here. Cool. So we've logged it out. And now what we'll do is, after the POST request, we want to show the form again and hide the loading spinner. So on the client side, again, we're on the client, we'll say, let's hide the loading elements. We'll say none here. And then let's show the form. So basically, when you're done submitting, re-display the form. So now if I say, CJ, hello again. More cats. Send. You'll notice the page refreshes. Probably one more thing I want to do is reset the form. So I sent it off. It got put in the database. Let's clear out the form here. Easy enough. We can just say form.reset. So a few people, I think one person at least, is not familiar with the fetch function. What's the fetch function doing? Definitely. So I believe in P5, is it called load JSON? Load JSON is equivalent, yeah. Yeah. So if you've ever worked with P5.js, it's a way of requesting data from a server. So there's load JSON. If you've ever worked with jQuery, it's $.get or $.post. Essentially, fetch is now built into the browser. And it's a little bit easier way of making requests to a server. So this is synonymous with AJAX or requesting to a server. Cool. Seems like there's a lot of Coding Garden fans in the chat. I appreciate that. Awesome. OK, so where are we at? We showed the form. We hide the loading spinner. We're in the home stretch. We're very close here. So the last thing we want to be able to do is all of the created mus we need to show them on the page here. So for that, we're going to make a request. We're running low on time, so I don't want to go back to the diagram just yet. But let's get it going. So basically, what should happen is an incoming get request to slash mus should get all of the records from the database and just respond with them in an array. So what we'll do here on the server is say, when the server receives a request on slash mus, we will then query the database. So we'll just say, so if you remember, mus is our variable that represents the collection. And we'll just say mus.find. And if you don't pass in anything, that just means find all of the things in the database. And then we'll get back some mus. And with those mus, we'll just respond. So res.json mus. So now when my server receives a get request on slash mus, go into the database, grab all of them, and then just respond with them as an array. So before I even test this on the client side, I can actually try it in the browser. Because if you remember, when you put in a URL, that is a get request. So if I do slash mus, there we go. Oh, wow, I put a lot of stuff in there. But am I forgetting the created date? Maybe that was before I added created. But now all of the information in the database is being listed here. So now I actually want to make this request with my client side code so that I can show it on the page. So let's do just that. Get, respond. All right. So on the front end, when the page loads, I want to request all of the mus. So I'm going to create a function. Let's call it list all mus. And actually by default, I want the spinning bar to be showing when the page loads, because I'm going to be grabbing all of the mus. So show the loading element and then list all mus. So I have a function, list all mus, and we'll use fetch for this. So we need to make a fetch. And the URL is actually the same. So you'll notice this was the URL I was putting in my browser to request all of the mus. So, but instead of a post request, I want to make a get request to get all of that data. So let's do that. So I want to make the fetch against API URL. And the way fetch works is if you're making a get request, you don't have to specify any options. You can just say, hey, give me that data. Then we get back the response. We'll parse it as JSON because we know that's what it is. And then we get all of the mus. And for now, let's just log those out. So when the page loads, we'll log out all of the mus. And there they are. So now on the client side, we have an array of all of our data. Now we actually want to add it to the page. So one thing I'll do is just iterate over them. So I'm just going to do mus.foreach. We'll get access to each mu. And in order to add it to the page, I need some reference on the page of where I'm going to add it. So in my HTML, I basically need like an X marks the spot. And I'm going to put them right here. Let's give this a class of mus. And so in my JavaScript, I'll select this element and keep a hold of it. And then anytime I want to add a mu, I'm going to put it into this element. We're going to append the child. So in our client, let's create a variable called musElement. And we'll do again, document.querySelector. And because I gave it a class of mus, we can select it like that. And now that I have the mus element, for every element in this array, I want to append it to the page or put it on the page. So first thing is I'll need to create some elements. I'm going to say like a div will be document.createElement. And I'll pass in div. And then we want probably a header to show the person's name. So let's create a header. And this will be document.createElement. We'll pass in like H3 maybe. And then we want to set the contents of that header. So we do header.textContent. And this is going to be mu.name because every mu has a name. And then we also want the actual contents to be in like a paragraph tag. So let's just say contents. That'll be document.createElement p tag. And then I'll say contents.textContent will be mu.contents. Is it contents? Content with a singular. Okay, so we're setting the H3, we're setting the p tag. Now we have to actually put these somewhere. So when you use document.createElement, it doesn't actually put them on the page, it just creates them. So what I'll do is take this H3 and append it to the div. So I'll say div.appendChild header. And then I'll take this p tag and append it to the div as well. So div.appendChild the contents. And now this div has the name in it, it has the content in it. Now I wanna take this div and put it on this muse element. Basically right here, I wanna put that element. So I created that muse element variable and I'm going to append the div to it. And just like that, there they are. But I think I misspelled something. You've got a typo. Okay, and I think I got it. So where? CO, I think you misspelled content somewhere. C-O-N-T-E-T. So it's the chat. Look at that. Okay, cool. It's funny, I'm barely watching the stream, I'm just watching the chat now. It's exploding. And it's working. So we see the name of the muse, sorry, not the tweet, the contents of the tweet, and they're all listed on the page here. So when the page loads, it makes that request, it adds all of them to the page. So that was fixed, awesome. But one thing we wanna do is also hide this loading spinner after all of the muse loads. So let's just say loading element.hide. So after the page loads, we get it all there. I think I wanna add a little bit of styling. Let's say the muse here has a width. So in our styles, let's say muse, let's say it has a width of like 80%. So that should shrink it in a little bit, but we also wanna give it automatic margin so it's centered. There's a good question here. What's the difference between text content and inner text? It might be the same. We can look on the internet. I don't know, that seemed like, I was like, I have no idea, that must be a good question. Is it inner HTML or is there actually an inner text? It might be inner HTML, but I think inner text and text content are probably synonymous. But the main difference is, and the one thing that I'm not using is inner HTML. Got it, so text content is something special. You're specifically using it over inner HTML. Yes, and specifically because this data right here is coming from users, right? So people are entering in their names, they're entering in their muse, and when I add it to the page, I don't wanna potentially add some script tag or something that they put and typed in. So if you use inner HTML, whatever you set as inner HTML will actually get rendered on the page. By using text content, even if they typed in some valid HTML, you'll just see the HTML text. It won't actually render. So this is a security precaution to prevent what's known as cross-site scripting. But then there is, yes, so there's a difference between text content, inner HTML, there's outer HTML. Inner HTML and outer HTML are the same. Whatever you set it to will get rendered. Text content and then inner text probably have the same relationship. I haven't really used inner text before. Cool, but yeah, that was a good question. Oh wait, last thing, I'm not showing the date. So let's also show the date. So let's create a date, and we'll say document.createElementPhoto. Hold on, that's my job. This is like my very important job. You're good, you can force a little break. I'll stay hydrated. Yes, all right. Okay, so the last thing is I'll create a small tag, and then we will append it here. So div. Oh, sorry, we need to set the text content. So I'll say date.textContent is equal to mu.created. And actually, I'll pass this into a new date, so it should give it some decent formatting. And then we'll append the, oh, oh, oh. Alka writes, by the way, one difference is inner text returns the visible text contained in the node, while text content returns the full text. Oh, okay. Cool. And now we're showing some dates. So apparently, when I first started inserting, I wasn't actually adding the date. But on these later ones, I am. But one thing I wanna do is I wanna show these in reverse order, because the more recent ones will appear at the top. So all we have to do for that is before we add them to the page, I'm just going to say mus.reverse. And I guess the other thing is, reverse, reverse is not a function. Cool. And so the latest mus should show up at the top. Name, CJ. Hello. But now, one thing I wanna do is, after I submit the form, just get all of them again, so that after you've immediately submitted, it is added to the top of the page. So getting a little sidetracked here. Okay, we got all the mus. We iterate over the array. We appended them to the page. We reversed them. Now we are showing the form. We're hiding the loading spinner. Last thing is, after you create a mus, I wanna refresh that list, so that it actually pops up in the page. And that should be easy, because we have this function, listAllMus. And so after submitting, so this is the submitting to the server. After submitting, we'll reset the form. We'll show the form. And then we'll list all mus. Like this, okay. So, name is CJ. Hello again again? Again. Like a cat. More cats. Actually, let's do a tiger. Go. And, okay, something weird is happening. So whenever I'm listing all the mus, I'm just appending more and more and more and more to the page. So one thing I actually need to do is clear out the list, so that way I can re-add them. So let's do that. Basically, before listing all mus, this is where I will use innerHTML. I'll just say here, musElement.innerHTML is nothing. So basically, blank out everything that was there before, and then add something new. So, name. That's a legitimate way of removing a whole set of DOM elements? Yes. So you could just visually iterate through them and remove them from the page? You could. I'm not aware, I don't know of the performance implications, but yes. Yes. Somehow that always felt like a thing I'm not supposed to do. I do it all the time. Cool, and so now, we'll notice, did I just type name was name? Oh well. But whatever you are now submitting is getting inserted in here. Hello world. Let's do poop emoji, go. And it shows up at the top of the list. Awesome. So this is our app. I do have on the list here that I was going to deploy, but I don't know if we have enough time for that. One thing I'll talk about in terms of security implications, so putting this out there in the world, I would want to prevent people from inserting bad words or different things like that. So there is this package on npm called bad words, where basically before I insert it into the database, I could filter it, and that way get rid of any nasty words or anything like that. And the other thing is to prevent people from spamming my server with a bunch of different mus. They could, because I've built this API, they technically don't have to use this form. They could write some JavaScript that just makes a post request to my server over and over again. So to prevent that, you might do something called rate limiting. And so there's a package called Express Rate Limiter that just limits the request to, you can set it up to one every 15 seconds or something like that. I guess the last thing is, let's just look at the diagram. Let's review what we built today. And then we can recap, answer questions and stuff. Okay, so the page loads. It initially makes the request to the static file server, which is hosting all of our HTML. And it makes the request for index.html, and that gets loaded into the browser. And then that HTML says, I have a CSS file. I have the skeleton CSS file, which is on some other server. And so your browser will then make the request to those servers to then load that content and actually load it into the page. Now the other thing that happens is, well, and even think about scripts. So the fact that I have script source equals client.js at the bottom, when the browser sees that, it has to actually request that file from the static file server. It loads it in and then runs the code that's inside of it. And so when it runs that code, it actually sees this fetch that says, get the request from you. So get, it's a get request to the URL Muse, and specifically it's going to the server on port 5000. The server receives that request, and then it actually has to talk to the database. It says, hello database, please find. So find. We're back. Find all of the things in the database, return them, and then we take those and we do res.json, which actually sends them back to the client side. Then the client will iterate over the array. It'll add them all to the page. They're nice and great. And then lastly, you have that post request. So a user will enter into the form here. They click submit. That makes a request out to our server, which is a post to slash Muse. And that will have a body. It'll have like, what is your name? And it will have the contents. The server will receive that body. It'll parse it, it'll understand it. It will then insert it into the database. And then it will respond with the thing that was inserted. And then our page, the way we've written the code, was that after that's done, it makes another request here to get all the latest ones and list those out on the page. Cool, I think we've done it. I think that's the app. People are very, I don't know how, I don't mind staying a little longer. People are very interested at least in some tips or how you would deploy it. Or if it's kind of a thing that we think we could do now, we could do it. Okay, I mean, do I have 10 minutes? Yeah, let's do 10 minutes. 10 minutes, okay, let's deploy, awesome. Because it's kind of, that's gives it a big, that's just like the flourish at the end. Okay, awesome. So yeah, and so we have this app. And now I will show how we put this out in the world. And then all of the wonderful people that are watching can submit their Muse and we'll be able to see them. So I guess before I do that, I do want to add these, the bad words and filter and the express rate limit. So there is a package on npm called bad words. So I'm going to install that. There's another one that I use that's called like word filter or something. But this, you just go ahead to this one. But it's interesting to note there are a bunch of these. Yeah, and I just found this the other day just by searching like profanity. And people have a simple list of how to do this. Well, not how to, they have a simple list of words that you can just add into your app. So we'll bring it in. And then anytime we insert something in, we'll just clean it to get rid of any potential bad things. So this is going to be on the server side. Let's bring in filter. And then we will create a filter. Let's create a filter right here. And then before we insert it into the database, which is right here, we're creating the object. I'm just going to do filter.clean. And I want to do this on the name and then also on the content. Cool, so in theory, this should work. I don't want to type bad words on screen, but it actually will filter it out and put like stars in there. So as long as the server's still running, yeah, we're good. The other thing is rate limiting. So I want to make sure that people can't just submit thousands and thousands of requests over and over. So I'm going to use express rate limit. So let's install this. And now that we have it, we'll use it. I'll look on npm to see how to use it. Express rate limit. And basically this one is based on IP address. There are other rate limiting packages that will actually use a database to keep track of users that have visited your website. So this is how we do it. We bring in rate limit. And then we need to use it just like we did our other middleware. So I'll say app.use rate limit dot something. So we actually invoke rate limit with how often we want to rate limit. So in this case, they're limiting it to 100 requests every 15 minutes. I'm going to let you do one request every 30 seconds. I think this is in milliseconds. Yeah, so every 30 seconds, you can only submit one view. Should I go lower than that? What do you think? Okay, cool. So every 30 seconds. Cool, and that should do it as well. So one thing that should happen is on the client side now, if I try to submit something, and then send it, too many requests already. Maybe I didn't specify this right. So if we look at one request, so if we look at window milliseconds. So 30 times 1,000 is 1,000 milliseconds? That's 30 seconds, 30,000 milliseconds. Okay, okay. I think that's right. Math is hard. Math is hard. Okay, oh, you know what it is? I think it was because, okay, so the page loaded. That was one request to get the list. And actually, so this is it. I only want a rate limit adding to the server. So you can request all day long. You can make requests over and over and over again. That's fine. But actually, submitting one, that's what I want a rate limit. So by simply moving that app.use down, this will now only rate limit creating views. Okay, let's try it. So somehow I missed that. By default, it rate limits everything. Everything, yes. And just where you put it in the code, change that. And so this has to do with middlewares. So in Express, when you do app.use, you can think of it as just a waterfall. It's top-down. So every request coming into our app hits cores, then it hits the JSON parser, then it hits the rate limit. But if we move it, now when a request for Muse comes in, it basically hits this before it ever hits the rate limiter. Got it. Yes. Ah, that makes sense. Well, I did not realize that because I think of everything as asynchronous, so the order doesn't matter. So the order basically only matters when the app spins up. And so it creates this ordered list of things to run. Okay, so that should do it. So now we can request the page all day long. But if I say my name is CJ and I say hello world, go. So that submitted it, but if I try again within 30 seconds, I get an error, too many requests. So this is gonna prevent people from submitting too many things. And then one thing I'll do is, instead of showing the form immediately on the client, is just wait 30 seconds before I show it. So after submitting is successful, let's just do a set timeout. And in 30 seconds, we'll unhide the form. Okay, so CJ, hello world, send. And then now in 30 seconds, that form will pop back up and you can submit another one if you want to. Okay, so I think we've done what we needed to do to get this thing ready to deploy. Let's deploy it. So first thing is set up environment variables. So my server side, right now, it's only talking to localhost.yower. I wanna tell it when you're deployed, talk to the deployed database. So I'm gonna do process.env.mongouri. And I can call this whatever I want. I'll show, I'm gonna be using a deployment tool called now. You can specify what are the environment variables that you deploy with. And in this case, I'm gonna create one called mongouri. So what this says is, if this environment variable is defined, connect to that database, otherwise connect to the localhost one. So that's our database connection. And we should be able to deploy it. So for the database, I'm using something called mlab. And they let you set up a free 500 megabyte Mongo databases. And you can sign up, log in. I think to hide my screen, I'll do this. I'm gonna log in real quick. And you can also, not that it matters, but. Oh. That's awesome. We can do that. We can do that when you deploy it, just to make sure. I don't trust our bad words filtering. And I don't trust, there's a wonderful audience of nice, lovely people, but. Cool. And so I've actually already created a database. So this should be, oh, I'm gonna do that. Cool. So I've created a database, but you can log in, you can sign up, they have a way of creating one for free. If you want more than that, you can also pay for it. But I've created the database. You will need to create a user. And then once you have a user, you create this connection string. And they show you where your username and your password goes in. And then you need to add that as a secret on now. So the way it works is you say now secrets add, and you can call it anything you want. So I already have one set up, just because I didn't want to risk doing it. But you can give it any name you want, and then you give it the value. So typically the value would be something like this. And you would fill in your username and password. And now inside of now, there is a secret you can use called meowerdb. And that's what we'll actually use to deploy. So the site's super easy to use. I think people have been asking about it. We do have a, Coding Garden has a Discord server. So if you're trying to do this stuff and you have questions, feel free to join in there. We have a help channel. You can help people work things out. So this specifically is how we're gonna deploy our database. And now we deploy our backend and tell it to talk to that database. So to deploy, I'm using a tool called now. You can get it from a website called zeet.co. It's a really, really easy thing to do. You just type now, and it will automatically deploy that either server or client. But in this case, I want to tell it that my Mongo URI process in environment variable, which I defined right here, should come from my secret called meowerdb. So that should now, when it's deployed, connect to the database. Let's go. Apparently I'm using an older version, but this should deploy the backend. Do-do-do-do. And the interesting thing about now is it gives you a unique URL every time you deploy. But what we can do is alias it. So I'm gonna show you how I'll alias this thing. Okay, and if everything went okay, I can actually throw this in, and I should get back meower. And if I do a slash mus, I should get back an empty array, because there's nothing in the database. Cool, so we're on the internet. One thing I'll do is I'll set up an alias, and I'll say meower-api. So my backend will be at meower-api.now.sh. So this alias will just, so I don't have to type in that big long thing. So now, I'm gonna deploy this. And I'm gonna say, I don't have to type in that big long thing. So now, when I go here, it's the exact same server. It just has a nice name, and I can do slash mus, and that gives me back an empty array. Cool. And now, we wanna deploy our frontend. So our backend is now at this URL. So our frontend, we need to update the code. Right now, it's pointed at localhost. So I need to say, if we're on localhost, send the request to localhost. Otherwise, send the request to the now server. So I'll say, if process.env, no, no, sorry. We're on the frontend, sorry. If window.location.hostname is equal to localhost, and I'm gonna use a ternary. I'll say, use that URL. Otherwise, use this URL, https://mus. So now, when we're deployed, it'll detect that it's not running on localhost, and it'll make the request against our backend, instead of the frontend. And that should do it. Okay, so I'm gonna cd into the client folder. We'll deploy it. That was way too easy for deployment. Now, I feel like, I can't deploy this, because it'll be three hours before I have it up. Three hours. Cool. It actually did deploy this earlier, so nobody could take my alias, because somebody might have tried. But now, ta-da! Okay, so. I'm ahead of everybody in real time, so what's the URL? It's a meow, er, so meower.now.sh. God, I'm gonna be the first one. Oh. Oh, I don't know how to do the emoji. People are gonna be faster than me. Oh no. 429, oh no, something broke. I'm gonna debug this really quick. Oh. It should've just worked. Okay, let's see. So that's working. It's not a proper Coding Train episode if it just works. I guess it should be. You can have stuff work on your channel. Me, it's all about it being broken. Well, I guess, I prepared a lot for today, but on my channel, I guess I haven't talked about it. Sometimes I just make errors, I read the docs, we figure things out live. So the way I'm gonna debug this is, I have the element inspector open, and I wanna look at the network tab to see what I'm actually sending to the server. So when I click Send, this makes a post request to slash Muse and I can see that I am sending the data, and if I look at the response, too many requests, please try again later. Did you already add something? I did attempt to, and then I just got, I mean, I'm just looking at the console, I just got uncaught syntax, unexpected token, and JSON. Okay, I think it's working. I think we've just rate limited ourselves. Oh yeah. So yeah, so people are submitting things, you just have to make sure that you don't do it every 30 seconds. If I look at the backend, it is... Could something be caching? No, it's weird, huh? Is it rate limiting by IP address? So we would potentially be, I mean, we're getting a dynamic IP address from the Wi-Fi here, but it's ultimately gonna end up being the same thing. The same IP, so that could be it. I'll just keep refreshing this. Okay, there's some people, there's some emails. So it's working for stuff, I just didn't want to totally open it to the world because this could wreak havoc. Cool. Shut it down, shut it down! Cool, I think that's it. Yeah, so if there's other questions, I guess I can talk about my setup, what I do on my channel. Oh yeah, before that, what's next? So this is very, very basic, right? This is, we have a form, you click submit, it gets listed on the page. But if you think about Twitter, there's more. There's user profiles, there's searching tweets, there's tagging, so we could take this code here, we could add comments and replies, so you could reply to a Mew, we could create user accounts where you can have specific ones, because right now, if somebody else types in the same name, they appear like they're coming from the same person. Sorry to interrupt, I don't know if this is true, but the chat is suggesting that the rate limit is actually a single rate limit for everybody. So only anybody, so like once somebody posts, nobody can post for 30 more seconds. I don't know if that's true, that was just being posited by the chat. This is based on IP address. Okay. I believe. Well, we don't have to debug that right now. Yeah, don't debug it. We won't. But again, like all the features of Twitter, we could start to write this. And so probably on my channel pretty soon, I'll start to add features to this and we can work on it as well. That's it. Awesome. So before, I do wanna say a couple things. Well, one is people are so interested in your kind of like theme setup font stuff. So do you wanna take a minute to just, so mostly I would suggest subscribe to CJ's channel and then go over all the stuff in like a lot more detail. But just for the people watching right now, are there a quick few things about like the what terminal application you're using, what theme you're using in Visual Studio Code? I actually did a video on this, so. Oh, there you go. You know, yeah, but I will like talk through it. If you search on my channel, it's Coding Garden Setup Mac, I think. Yeah, so setting up a Mac for web development. I talk about. Sorry. No worries, no worries. I talk about the code editor I'm using. I talk about how I set up my terminal. I talk about how I, all the extensions I'm using for VS Code. I talk about basically how I have all this set up. Were there specific questions about? I think people were just like, which font, what color? So that can be the answer. Maybe you have this documented in a separate video and people should just go and check that. It's a good way to plug the channel right now anyway. Actually, let's see, how many subscribers am I at? Okay, okay, cool. But the font I'm using is Anonymous Pro. I really like this font. There's a lot of other fonts out there, but I have this as my terminal font and my editor font. But yeah, if you check out that video, I have links to all of my extensions, my styles, all that stuff that I have set up inside of VS Code. Great, a few people said they just subscribed. Oh, thank you so much. So yeah, so what's amazing about this, first of all, CJ and I were discussing what he was gonna do and he said, oh, I think I'll make a Twitter clone. It's like, in an hour? It's like, that's crazy. Well, no user accounts and it's stripped down. But still, this was pretty incredible to see the full stack, really. I was trying to think of a different word for it, but that's the word, the full stack. You know, so much of the stuff that I do is mostly client side, algorithms, visualization stuff. Sometimes I'll pull up a node thing or use a database, but to see that whole picture all together and also just seeing your kind of workflow is super, super illuminating. I feel like I learned a ton of stuff. I was like, made some notes of things that I'd never seen before, which was awesome. I guess that's one thing to note. So I'm showing the client was the browser, but the client could be a desktop app. It could be a mobile phone native app. And it could all work in a similar way. And this is actually why I like to build architectures this way, because a mobile app could talk to the exact same backend. The only thing that changes is the client. And are there other, so when is, so I know you've been in New York for a while. You're going back, you're based in Denver. Yes. And you're going back there. When is your next live stream? Are there other things people should check out, like, I don't know, Twitter or Instagram or stuff like that? Definitely, yes. Thanks for the fun. So I'm on Twitter, coding underscore garden. You can follow me there. Every time I go live, it tweets here. Right now, I do plan to stream, I think, on set. I have a pretty busy week, because I'm moving from New York back to Denver. I've got to pack up, and my students are presenting Capstones tomorrow, so we're getting all that ready. But if you look on my channel, I typically try to do upcoming live streams. And any stream that's upcoming, I'll put it here, so you can click on it to know before it happens. The other thing is I do have a Discord, and there is a live channel on the Discord. So if you look in one of my more recent videos, there's a link to fill out a survey to join this Discord, and we have help channels, but typically, I'll post in the live channel whenever I'm going live. There's Brucer. And are there, you were doing some teaching here in New York, are there other things you've got on the horizon of teaching experiences that you're thinking about doing? Yeah, I mean, not that I know of. Like, I really am just focusing on. Yeah, that's awesome. When I get back to Denver, I will have, so before I came to New York, I was streaming five days a week, and I think that's why you found me, because I'm always just there live streaming. But yeah, when I get back, I do plan to do it more often. Lately, it's just been, so I'll talk about some of the streams I do. So every, either Saturday or Sunday, I've been streaming with a friend named Tony, and we do what's called Noob Quest, where Tony's totally brand new to coding, and we'll kind of pair and work through things. And then I also do a, mostly every Wednesday, a Code Katas stream. So if you're familiar with Code Wars, Code Katas, I'll just sit down for a couple of hours, and I'll pick some out and then just solve them live, but I'll also show like 10 different ways to solve the same thing, and like, how do we do it with the for loop, how do we do it with reduce, how do we do it with map and filter. And I also have, if you check out the GitHub, tons, like every video I've ever done, the code for it is free and open source here, and there's also one for Code Katas, so if you have suggestions for that, you can submit them here as an issue as well. So nicely organized. Something to aspire to, for me. So disorganized, I feel like. Awesome, cool, so thank you so much for being here. I'm so glad that this worked out, because I know it's like, no, wait, you're leaving this week, we have to do it now, before you go! And so many wonderful, nice comments in the chat, I hope people will subscribe to CJ's channel, when I come to Denver, hopefully I can appear on the Coding Garden. Absolutely, absolutely. No, I just wanna thank you, like, this has been amazing, like, to see the space, also to the coding train community, like all the mods, Kweekmon, and Mayamsumi, and Alka, like, they've been hanging out in my channel, and like, they're all wonderful people, it's awesome. Awesome, cool. And so, thanks for tuning in, I will, I have this cold, which you might detect, in theory, assuming I get a little better, I'll be back on Friday, maybe I'll try the quicksort again, but I have some other things that I'm definitely planning to do, so stay tuned for all that stuff. This live stream, as soon as I hit stop streaming, will be available to watch, I mean, sometimes it takes like 15 minutes for like, YouTube to process it, but then it'll be available to watch as an archive. Sometimes I do, you know, as you've watched, I do like, edited versions of live streams, I kinda don't think that this needs an edited version, because what would we edit out? It was like, the whole thing was the thing. So, awesome. So thanks, thanks so much CJ, thanks for you watching, and I'm looking at the chat, I'm gonna wave goodbye, little train whistle for CJ. Ha ha! And now I'm gonna hit the, again, someday I'm gonna do, CJ was teaching me some stuff about Open Broadcast Studio, so maybe I'll get better at it, maybe I'll have an outro thing, but right now I'm just gonna hit the stop streaming button. And there we go, bye everybody!",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:03:44.906048Z",
  "started_at": "2023-09-26T21:16:35.544601Z",
  "completed_at": "2023-09-26T21:41:32.274663Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=JnEH9tYLxLk",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 1496.730062
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/h4h36wrbpwpd5crtskmvcabjsm/cancel",
    "get": "https://api.replicate.com/v1/predictions/h4h36wrbpwpd5crtskmvcabjsm"
  }
}