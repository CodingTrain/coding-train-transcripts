{
  "id": "sgfk5jzbjohbjjueszhgl47vhi",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/fnoOFQK3tPQ.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/874168 [00:00<?, ?frames/s]\n  0%|          | 2692/874168 [00:01<08:26, 1719.40frames/s]\n  1%|          | 5568/874168 [00:07<22:34, 641.21frames/s] \n  1%|          | 8532/874168 [00:14<28:05, 513.50frames/s]\n  1%|▏         | 11330/874168 [00:23<34:48, 413.07frames/s]\n  2%|▏         | 14134/874168 [00:32<37:40, 380.41frames/s]\n  2%|▏         | 16898/874168 [00:39<37:17, 383.08frames/s]\n  2%|▏         | 19822/874168 [00:43<31:09, 457.02frames/s]\n  3%|▎         | 22770/874168 [00:51<34:03, 416.57frames/s]\n  3%|▎         | 25578/874168 [00:56<31:10, 453.68frames/s]\n  3%|▎         | 28258/874168 [01:03<32:05, 439.30frames/s]\n  4%|▎         | 31258/874168 [01:06<26:34, 528.52frames/s]\n  4%|▍         | 34206/874168 [01:14<29:45, 470.51frames/s]\n  4%|▍         | 37146/874168 [01:20<29:59, 465.19frames/s]\n  5%|▍         | 40062/874168 [01:27<30:12, 460.29frames/s]\n  5%|▍         | 42982/874168 [01:32<29:07, 475.63frames/s]\n  5%|▌         | 45948/874168 [01:39<29:39, 465.47frames/s]\n  6%|▌         | 48668/874168 [01:45<29:33, 465.42frames/s]\n  6%|▌         | 51668/874168 [01:49<26:21, 519.95frames/s]\n  6%|▌         | 53440/874168 [01:51<23:57, 570.83frames/s]\n  6%|▋         | 56336/874168 [01:58<26:06, 522.15frames/s]\n  7%|▋         | 59336/874168 [02:01<23:10, 585.89frames/s]\n  7%|▋         | 62236/874168 [02:11<29:22, 460.63frames/s]\n  7%|▋         | 65236/874168 [02:15<26:42, 504.86frames/s]\n  8%|▊         | 68136/874168 [02:21<26:23, 508.90frames/s]\n  8%|▊         | 70636/874168 [02:25<24:52, 538.24frames/s]\n  8%|▊         | 70636/874168 [02:40<24:52, 538.24frames/s]\n  8%|▊         | 73336/874168 [02:47<49:09, 271.49frames/s]\n  8%|▊         | 73336/874168 [03:00<49:09, 271.49frames/s]\n  9%|▊         | 76136/874168 [03:12<1:10:56, 187.47frames/s]\n  9%|▉         | 78936/874168 [03:17<56:28, 234.66frames/s]  \n  9%|▉         | 81636/874168 [03:25<51:07, 258.33frames/s]\n 10%|▉         | 84536/874168 [03:32<44:24, 296.34frames/s]\n 10%|▉         | 87236/874168 [03:38<40:22, 324.91frames/s]\n 10%|█         | 90036/874168 [03:44<36:26, 358.61frames/s]\n 11%|█         | 92936/874168 [03:53<37:09, 350.44frames/s]\n 11%|█         | 95836/874168 [04:00<35:55, 361.12frames/s]\n 11%|█▏        | 98736/874168 [04:12<40:29, 319.13frames/s]\n 12%|█▏        | 101536/874168 [04:21<40:41, 316.47frames/s]\n 12%|█▏        | 104436/874168 [04:28<37:42, 340.17frames/s]\n 12%|█▏        | 107336/874168 [04:37<37:58, 336.51frames/s]\n 13%|█▎        | 110336/874168 [04:39<28:57, 439.52frames/s]\n 13%|█▎        | 112836/874168 [04:43<26:38, 476.31frames/s]\n 13%|█▎        | 115736/874168 [04:48<25:03, 504.30frames/s]\n 14%|█▎        | 118436/874168 [04:52<23:55, 526.62frames/s]\n 14%|█▍        | 121236/874168 [04:58<23:46, 527.97frames/s]\n 14%|█▍        | 123936/874168 [05:04<25:46, 484.97frames/s]\n 14%|█▍        | 126636/874168 [05:12<28:35, 435.68frames/s]\n 15%|█▍        | 129536/874168 [05:21<31:05, 399.15frames/s]\n 15%|█▌        | 132436/874168 [05:30<34:03, 362.93frames/s]\n 15%|█▌        | 135336/874168 [05:38<34:04, 361.37frames/s]\n 16%|█▌        | 138236/874168 [05:46<33:30, 365.97frames/s]\n 16%|█▌        | 141036/874168 [05:52<31:24, 388.99frames/s]\n 16%|█▋        | 143536/874168 [05:58<30:21, 401.03frames/s]\n 17%|█▋        | 146436/874168 [06:02<25:50, 469.36frames/s]\n 17%|█▋        | 148436/874168 [06:06<25:49, 468.51frames/s]\n 17%|█▋        | 151036/874168 [06:14<28:40, 420.28frames/s]\n 18%|█▊        | 153636/874168 [06:21<29:28, 407.31frames/s]\n 18%|█▊        | 156636/874168 [06:24<24:22, 490.77frames/s]\n 18%|█▊        | 159636/874168 [06:28<21:40, 549.24frames/s]\n 19%|█▊        | 162636/874168 [06:34<21:38, 548.12frames/s]\n 19%|█▉        | 165336/874168 [06:36<18:48, 628.22frames/s]\n 19%|█▉        | 166936/874168 [06:38<17:50, 660.52frames/s]\n 19%|█▉        | 169836/874168 [06:41<15:12, 771.92frames/s]\n 20%|█▉        | 172836/874168 [06:44<13:43, 851.55frames/s]\n 20%|██        | 175536/874168 [06:46<12:50, 906.53frames/s]\n 20%|██        | 178136/874168 [06:49<12:30, 927.92frames/s]\n 21%|██        | 180936/874168 [06:51<11:43, 984.79frames/s]\n 21%|██        | 182736/874168 [06:55<14:30, 793.97frames/s]\n 21%|██        | 185336/874168 [06:58<13:56, 823.50frames/s]\n 21%|██▏       | 187336/874168 [07:00<12:55, 885.31frames/s]\n 22%|██▏       | 189636/874168 [07:02<12:22, 921.42frames/s]\n 22%|██▏       | 192436/874168 [07:05<12:42, 893.85frames/s]\n 22%|██▏       | 195336/874168 [07:10<14:41, 770.29frames/s]\n 23%|██▎       | 198136/874168 [07:15<16:31, 681.50frames/s]\n 23%|██▎       | 201036/874168 [07:23<20:23, 550.31frames/s]\n 23%|██▎       | 203836/874168 [07:28<20:38, 541.11frames/s]\n 24%|██▎       | 206736/874168 [07:36<23:17, 477.61frames/s]\n 24%|██▍       | 209636/874168 [07:43<24:24, 453.92frames/s]\n 24%|██▍       | 212536/874168 [07:52<26:57, 409.05frames/s]\n 25%|██▍       | 215136/874168 [08:01<29:58, 366.47frames/s]\n 25%|██▍       | 218136/874168 [08:03<23:46, 459.97frames/s]\n 25%|██▌       | 220936/874168 [08:09<23:20, 466.38frames/s]\n 25%|██▌       | 222636/874168 [08:14<24:07, 450.19frames/s]\n 26%|██▌       | 225236/874168 [08:19<23:24, 461.89frames/s]\n 26%|██▌       | 228036/874168 [08:25<23:36, 456.23frames/s]\n 26%|██▋       | 230436/874168 [08:32<24:58, 429.62frames/s]\n 27%|██▋       | 233136/874168 [08:38<25:35, 417.48frames/s]\n 27%|██▋       | 235436/874168 [08:42<22:27, 474.00frames/s]\n 27%|██▋       | 237936/874168 [08:47<22:58, 461.44frames/s]\n 28%|██▊       | 240736/874168 [08:54<23:17, 453.15frames/s]\n 28%|██▊       | 243236/874168 [08:59<23:26, 448.50frames/s]\n 28%|██▊       | 245936/874168 [09:02<18:41, 560.13frames/s]\n 28%|██▊       | 248436/874168 [09:04<16:43, 623.51frames/s]\n 29%|██▉       | 251436/874168 [09:07<14:18, 725.51frames/s]\n 29%|██▉       | 254336/874168 [09:12<14:37, 706.08frames/s]\n 29%|██▉       | 257336/874168 [09:14<12:04, 851.26frames/s]\n 30%|██▉       | 259936/874168 [09:22<17:37, 580.89frames/s]\n 30%|███       | 262836/874168 [09:29<20:11, 504.73frames/s]\n 30%|███       | 265436/874168 [09:34<19:55, 509.19frames/s]\n 31%|███       | 268236/874168 [09:42<22:37, 446.43frames/s]\n 31%|███       | 271036/874168 [09:50<24:15, 414.42frames/s]\n 31%|███▏      | 273436/874168 [09:56<24:52, 402.45frames/s]\n 32%|███▏      | 276236/874168 [10:04<25:26, 391.66frames/s]\n 32%|███▏      | 278736/874168 [10:10<25:17, 392.48frames/s]\n 32%|███▏      | 281636/874168 [10:20<27:40, 356.78frames/s]\n 33%|███▎      | 284336/874168 [10:29<29:23, 334.46frames/s]\n 33%|███▎      | 287136/874168 [10:38<29:50, 327.77frames/s]\n 33%|███▎      | 289636/874168 [10:44<27:42, 351.70frames/s]\n 33%|███▎      | 292236/874168 [10:50<25:29, 380.50frames/s]\n 34%|███▎      | 294936/874168 [10:57<25:56, 372.13frames/s]\n 34%|███▍      | 297636/874168 [11:04<25:29, 376.91frames/s]\n 34%|███▍      | 300436/874168 [11:12<25:34, 373.97frames/s]\n 35%|███▍      | 303336/874168 [11:19<25:22, 375.00frames/s]\n 35%|███▌      | 306236/874168 [11:29<27:21, 345.90frames/s]\n 35%|███▌      | 308836/874168 [11:38<28:41, 328.43frames/s]\n 36%|███▌      | 311436/874168 [11:47<29:16, 320.33frames/s]\n 36%|███▌      | 314136/874168 [11:55<28:40, 325.43frames/s]\n 36%|███▌      | 316736/874168 [12:01<27:12, 341.36frames/s]\n 37%|███▋      | 319536/874168 [12:08<25:17, 365.60frames/s]\n 37%|███▋      | 321936/874168 [12:13<23:06, 398.27frames/s]\n 37%|███▋      | 324636/874168 [12:22<25:18, 361.85frames/s]\n 37%|███▋      | 327536/874168 [12:29<24:58, 364.78frames/s]\n 38%|███▊      | 330336/874168 [12:34<21:25, 423.04frames/s]\n 38%|███▊      | 333236/874168 [12:41<21:35, 417.57frames/s]\n 38%|███▊      | 336136/874168 [12:50<23:27, 382.37frames/s]\n 39%|███▊      | 338336/874168 [12:58<26:23, 338.30frames/s]\n 39%|███▉      | 341336/874168 [13:02<20:50, 426.23frames/s]\n 39%|███▉      | 343936/874168 [13:06<18:30, 477.27frames/s]\n 40%|███▉      | 346936/874168 [13:09<15:45, 557.63frames/s]\n 40%|████      | 349936/874168 [13:12<13:51, 630.39frames/s]\n 40%|████      | 352036/874168 [13:15<13:29, 645.38frames/s]\n 41%|████      | 354736/874168 [13:17<11:11, 773.70frames/s]\n 41%|████      | 357336/874168 [13:20<10:44, 801.34frames/s]\n 41%|████      | 359936/874168 [13:25<12:28, 687.24frames/s]\n 41%|████▏     | 362536/874168 [13:32<14:53, 572.50frames/s]\n 42%|████▏     | 365536/874168 [13:34<11:49, 717.27frames/s]\n 42%|████▏     | 368036/874168 [13:37<11:28, 734.70frames/s]\n 42%|████▏     | 370836/874168 [13:40<10:13, 820.27frames/s]\n 43%|████▎     | 373836/874168 [13:41<08:02, 1037.00frames/s]\n 43%|████▎     | 376836/874168 [13:43<07:06, 1165.12frames/s]\n 43%|████▎     | 379136/874168 [13:45<07:45, 1062.89frames/s]\n 44%|████▎     | 381836/874168 [13:52<11:31, 712.16frames/s] \n 44%|████▍     | 384736/874168 [13:55<10:48, 755.17frames/s]\n 44%|████▍     | 387736/874168 [14:02<12:40, 639.21frames/s]\n 45%|████▍     | 390136/874168 [14:06<13:35, 593.90frames/s]\n 45%|████▍     | 392836/874168 [14:13<15:38, 512.74frames/s]\n 45%|████▌     | 395336/874168 [14:19<15:58, 499.68frames/s]\n 46%|████▌     | 398036/874168 [14:24<16:07, 492.28frames/s]\n 46%|████▌     | 400536/874168 [14:30<16:39, 473.66frames/s]\n 46%|████▌     | 403036/874168 [14:37<18:01, 435.83frames/s]\n 46%|████▋     | 405736/874168 [14:44<18:44, 416.75frames/s]\n 47%|████▋     | 408736/874168 [14:53<19:37, 395.31frames/s]\n 47%|████▋     | 411536/874168 [15:01<20:16, 380.33frames/s]\n 47%|████▋     | 414136/874168 [15:07<19:28, 393.61frames/s]\n 48%|████▊     | 416936/874168 [15:12<17:51, 426.69frames/s]\n 48%|████▊     | 419436/874168 [15:18<18:18, 413.78frames/s]\n 48%|████▊     | 421736/874168 [15:25<19:06, 394.71frames/s]\n 49%|████▊     | 424636/874168 [15:32<18:28, 405.70frames/s]\n 49%|████▉     | 427436/874168 [15:40<19:46, 376.45frames/s]\n 49%|████▉     | 430236/874168 [15:49<20:23, 362.79frames/s]\n 50%|████▉     | 433036/874168 [15:54<18:40, 393.58frames/s]\n 50%|████▉     | 435936/874168 [16:04<20:30, 356.02frames/s]\n 50%|█████     | 438436/874168 [16:11<20:18, 357.65frames/s]\n 50%|█████     | 441136/874168 [16:19<20:37, 349.88frames/s]\n 51%|█████     | 443936/874168 [16:27<20:34, 348.47frames/s]\n 51%|█████     | 446736/874168 [16:34<19:20, 368.16frames/s]\n 51%|█████▏    | 449036/874168 [16:42<20:35, 344.16frames/s]\n 52%|█████▏    | 451936/874168 [16:50<20:00, 351.79frames/s]\n 52%|█████▏    | 454636/874168 [16:57<19:36, 356.59frames/s]\n 52%|█████▏    | 457536/874168 [17:06<20:01, 346.65frames/s]\n 53%|█████▎    | 460336/874168 [17:12<18:27, 373.75frames/s]\n 53%|█████▎    | 463236/874168 [17:21<18:54, 362.30frames/s]\n 53%|█████▎    | 466036/874168 [17:29<19:10, 354.85frames/s]\n 54%|█████▎    | 468836/874168 [17:38<19:40, 343.36frames/s]\n 54%|█████▍    | 471736/874168 [17:47<20:03, 334.47frames/s]\n 54%|█████▍    | 474636/874168 [17:54<19:06, 348.61frames/s]\n 55%|█████▍    | 477536/874168 [18:03<18:51, 350.57frames/s]\n 55%|█████▍    | 479836/874168 [18:08<18:10, 361.47frames/s]\n 55%|█████▌    | 482536/874168 [18:14<17:04, 382.19frames/s]\n 55%|█████▌    | 484936/874168 [18:19<15:35, 416.17frames/s]\n 56%|█████▌    | 487636/874168 [18:25<15:12, 423.58frames/s]\n 56%|█████▌    | 490536/874168 [18:32<15:07, 422.75frames/s]\n 56%|█████▋    | 493336/874168 [18:37<13:36, 466.55frames/s]\n 57%|█████▋    | 496336/874168 [18:41<12:17, 512.10frames/s]\n 57%|█████▋    | 499236/874168 [18:49<13:23, 466.86frames/s]\n 57%|█████▋    | 501936/874168 [18:55<13:44, 451.25frames/s]\n 58%|█████▊    | 504736/874168 [19:02<14:18, 430.36frames/s]\n 58%|█████▊    | 507536/874168 [19:08<13:47, 442.86frames/s]\n 58%|█████▊    | 509836/874168 [19:15<14:48, 409.94frames/s]\n 59%|█████▊    | 512736/874168 [19:23<15:03, 399.83frames/s]\n 59%|█████▉    | 515536/874168 [19:29<14:45, 404.84frames/s]\n 59%|█████▉    | 518436/874168 [19:37<15:02, 394.13frames/s]\n 60%|█████▉    | 521136/874168 [19:43<14:34, 403.67frames/s]\n 60%|█████▉    | 523936/874168 [19:48<12:59, 449.02frames/s]\n 60%|██████    | 526736/874168 [19:53<12:05, 478.76frames/s]\n 61%|██████    | 529036/874168 [19:57<11:34, 497.24frames/s]\n 61%|██████    | 531836/874168 [20:01<10:27, 545.64frames/s]\n 61%|██████    | 534336/874168 [20:04<09:02, 626.23frames/s]\n 61%|██████▏   | 537136/874168 [20:06<07:25, 756.38frames/s]\n 62%|██████▏   | 539636/874168 [20:09<07:03, 789.27frames/s]\n 62%|██████▏   | 542536/874168 [20:14<07:54, 699.57frames/s]\n 62%|██████▏   | 545436/874168 [20:17<07:18, 749.23frames/s]\n 63%|██████▎   | 548336/874168 [20:22<08:00, 678.81frames/s]\n 63%|██████▎   | 551136/874168 [20:27<08:08, 661.70frames/s]\n 63%|██████▎   | 553836/874168 [20:30<07:33, 705.98frames/s]\n 64%|██████▎   | 556536/874168 [20:36<08:43, 606.61frames/s]\n 64%|██████▍   | 559136/874168 [20:40<08:36, 609.91frames/s]\n 64%|██████▍   | 561736/874168 [20:44<08:24, 619.04frames/s]\n 65%|██████▍   | 564536/874168 [20:48<08:05, 637.96frames/s]\n 65%|██████▍   | 566836/874168 [20:52<08:07, 630.84frames/s]\n 65%|██████▌   | 569536/874168 [20:56<08:04, 629.29frames/s]\n 65%|██████▌   | 572236/874168 [21:01<08:06, 620.78frames/s]\n 66%|██████▌   | 575136/874168 [21:05<08:01, 621.21frames/s]\n 66%|██████▌   | 577836/874168 [21:10<08:12, 601.73frames/s]\n 66%|██████▋   | 580836/874168 [21:13<07:16, 671.66frames/s]\n 67%|██████▋   | 583836/874168 [21:18<07:05, 682.76frames/s]\n 67%|██████▋   | 586536/874168 [21:19<05:43, 838.17frames/s]\n 67%|██████▋   | 589536/874168 [21:23<05:42, 831.97frames/s]\n 68%|██████▊   | 592236/874168 [21:25<05:20, 878.87frames/s]\n 68%|██████▊   | 595236/874168 [21:27<04:14, 1097.07frames/s]\n 68%|██████▊   | 598236/874168 [21:29<04:01, 1143.54frames/s]\n 69%|██████▉   | 601236/874168 [21:32<04:14, 1073.05frames/s]\n 69%|██████▉   | 604236/874168 [21:34<03:49, 1173.72frames/s]\n 69%|██████▉   | 607036/874168 [21:37<04:07, 1080.63frames/s]\n 70%|██████▉   | 609536/874168 [21:41<04:57, 890.17frames/s] \n 70%|███████   | 612436/874168 [21:46<05:29, 794.35frames/s]\n 70%|███████   | 615236/874168 [21:51<06:14, 692.09frames/s]\n 71%|███████   | 618136/874168 [21:57<06:38, 642.36frames/s]\n 71%|███████   | 621036/874168 [22:02<06:57, 606.84frames/s]\n 71%|███████▏  | 623736/874168 [22:06<06:52, 607.21frames/s]\n 72%|███████▏  | 626636/874168 [22:11<06:53, 598.94frames/s]\n 72%|███████▏  | 629336/874168 [22:16<06:50, 596.33frames/s]\n 72%|███████▏  | 632136/874168 [22:19<06:05, 661.32frames/s]\n 73%|███████▎  | 634936/874168 [22:23<06:05, 654.20frames/s]\n 73%|███████▎  | 637336/874168 [22:28<06:26, 612.69frames/s]\n 73%|███████▎  | 640336/874168 [22:33<06:11, 629.48frames/s]\n 74%|███████▎  | 643336/874168 [22:35<05:05, 754.67frames/s]\n 74%|███████▍  | 646336/874168 [22:38<04:33, 834.05frames/s]\n 74%|███████▍  | 649336/874168 [22:40<03:53, 963.45frames/s]\n 75%|███████▍  | 652336/874168 [22:42<03:42, 996.47frames/s]\n 75%|███████▍  | 655336/874168 [22:45<03:27, 1056.14frames/s]\n 75%|███████▌  | 658336/874168 [22:47<03:05, 1164.22frames/s]\n 76%|███████▌  | 660336/874168 [22:50<03:43, 955.94frames/s] \n 76%|███████▌  | 663136/874168 [22:53<03:43, 943.12frames/s]\n 76%|███████▌  | 665836/874168 [22:55<03:11, 1087.35frames/s]\n 76%|███████▋  | 668736/874168 [23:00<04:01, 849.87frames/s] \n 77%|███████▋  | 671636/874168 [23:04<04:23, 768.52frames/s]\n 77%|███████▋  | 674236/874168 [23:08<04:14, 784.27frames/s]\n 77%|███████▋  | 677036/874168 [23:11<03:59, 823.82frames/s]\n 78%|███████▊  | 680036/874168 [23:15<04:04, 794.82frames/s]\n 78%|███████▊  | 682936/874168 [23:16<03:20, 953.94frames/s]\n 78%|███████▊  | 685436/874168 [23:19<03:12, 980.22frames/s]\n 79%|███████▊  | 688236/874168 [23:22<03:21, 921.18frames/s]\n 79%|███████▉  | 691236/874168 [23:29<04:20, 702.88frames/s]\n 79%|███████▉  | 693736/874168 [23:32<04:14, 709.79frames/s]\n 80%|███████▉  | 696136/874168 [23:34<03:41, 805.52frames/s]\n 80%|███████▉  | 698836/874168 [23:37<03:31, 829.14frames/s]\n 80%|████████  | 701436/874168 [23:40<03:25, 841.63frames/s]\n 81%|████████  | 703936/874168 [23:42<03:04, 924.23frames/s]\n 81%|████████  | 706936/874168 [23:45<02:46, 1001.52frames/s]\n 81%|████████  | 709936/874168 [23:47<02:32, 1078.89frames/s]\n 82%|████████▏ | 712936/874168 [23:49<02:19, 1159.02frames/s]\n 82%|████████▏ | 715636/874168 [23:51<02:17, 1155.26frames/s]\n 82%|████████▏ | 718236/874168 [23:54<02:27, 1055.07frames/s]\n 82%|████████▏ | 721036/874168 [23:57<02:20, 1092.10frames/s]\n 83%|████████▎ | 723836/874168 [24:01<02:38, 948.55frames/s] \n 83%|████████▎ | 725236/874168 [24:03<02:47, 890.51frames/s]\n 83%|████████▎ | 727836/874168 [24:06<03:00, 810.37frames/s]\n 84%|████████▎ | 730536/874168 [24:10<02:57, 809.36frames/s]\n 84%|████████▍ | 733136/874168 [24:11<02:29, 944.48frames/s]\n 84%|████████▍ | 735736/874168 [24:15<02:47, 826.92frames/s]\n 84%|████████▍ | 738536/874168 [24:19<02:46, 813.14frames/s]\n 85%|████████▍ | 740536/874168 [24:20<02:21, 946.44frames/s]\n 85%|████████▌ | 743536/874168 [24:22<02:01, 1074.57frames/s]\n 85%|████████▌ | 746336/874168 [24:26<02:11, 971.57frames/s] \n 86%|████████▌ | 748336/874168 [24:28<02:12, 946.79frames/s]\n 86%|████████▌ | 751136/874168 [24:31<02:07, 966.05frames/s]\n 86%|████████▌ | 753936/874168 [24:33<02:00, 999.91frames/s]\n 87%|████████▋ | 756936/874168 [24:36<01:48, 1076.09frames/s]\n 87%|████████▋ | 758736/874168 [24:38<01:58, 973.51frames/s] \n 87%|████████▋ | 761536/874168 [24:40<01:48, 1040.29frames/s]\n 87%|████████▋ | 764336/874168 [24:43<01:46, 1032.85frames/s]\n 88%|████████▊ | 767136/874168 [24:46<01:42, 1048.08frames/s]\n 88%|████████▊ | 770136/874168 [24:47<01:25, 1215.26frames/s]\n 88%|████████▊ | 772936/874168 [24:54<02:12, 762.97frames/s] \n 89%|████████▉ | 775936/874168 [24:56<01:47, 911.55frames/s]\n 89%|████████▉ | 778936/874168 [24:59<01:42, 927.98frames/s]\n 89%|████████▉ | 781736/874168 [25:03<01:48, 852.43frames/s]\n 90%|████████▉ | 784736/874168 [25:07<01:44, 858.08frames/s]\n 90%|█████████ | 787536/874168 [25:10<01:46, 816.76frames/s]\n 90%|█████████ | 790336/874168 [25:15<01:48, 776.07frames/s]\n 91%|█████████ | 793336/874168 [25:27<02:56, 458.01frames/s]\n 91%|█████████ | 796136/874168 [25:32<02:39, 488.05frames/s]\n 91%|█████████▏| 798936/874168 [25:39<02:48, 446.98frames/s]\n 92%|█████████▏| 801736/874168 [25:44<02:28, 488.40frames/s]\n 92%|█████████▏| 804536/874168 [25:50<02:25, 478.90frames/s]\n 92%|█████████▏| 807336/874168 [26:08<03:47, 293.67frames/s]\n 92%|█████████▏| 807336/874168 [26:20<03:47, 293.67frames/s]\n 93%|█████████▎| 810136/874168 [26:26<04:37, 231.04frames/s]\n 93%|█████████▎| 810136/874168 [26:40<04:37, 231.04frames/s]\n 93%|█████████▎| 812936/874168 [26:53<05:57, 171.17frames/s]\n 93%|█████████▎| 815736/874168 [26:58<04:35, 211.96frames/s]\n 94%|█████████▎| 817736/874168 [27:02<03:44, 251.05frames/s]\n 94%|█████████▍| 820536/874168 [27:08<03:06, 287.18frames/s]\n 94%|█████████▍| 820536/874168 [27:20<03:06, 287.18frames/s]\n 94%|█████████▍| 823536/874168 [27:47<05:34, 151.43frames/s]\n 95%|█████████▍| 826452/874168 [27:56<04:21, 182.58frames/s]\n 95%|█████████▍| 829152/874168 [28:01<03:18, 226.40frames/s]\n 95%|█████████▌| 831088/874168 [28:05<02:46, 258.27frames/s]\n 95%|█████████▌| 833968/874168 [28:11<02:13, 302.11frames/s]\n 96%|█████████▌| 836610/874168 [28:23<02:15, 276.88frames/s]\n 96%|█████████▌| 839438/874168 [28:28<01:47, 324.07frames/s]\n 96%|█████████▋| 842354/874168 [28:34<01:25, 372.70frames/s]\n 97%|█████████▋| 845218/874168 [28:37<01:04, 449.10frames/s]\n 97%|█████████▋| 847706/874168 [28:42<00:56, 466.48frames/s]\n 97%|█████████▋| 850350/874168 [28:45<00:44, 540.24frames/s]\n 98%|█████████▊| 853274/874168 [28:50<00:37, 554.12frames/s]\n 98%|█████████▊| 855932/874168 [28:54<00:32, 561.42frames/s]\n 98%|█████████▊| 858932/874168 [28:58<00:24, 616.24frames/s]\n 99%|█████████▊| 861932/874168 [29:03<00:19, 620.85frames/s]\n 99%|█████████▉| 864932/874168 [29:09<00:15, 592.63frames/s]\n 99%|█████████▉| 867932/874168 [29:13<00:09, 632.87frames/s]\n100%|█████████▉| 870844/874168 [29:18<00:05, 608.73frames/s]\n100%|█████████▉| 873468/874168 [29:24<00:01, 551.04frames/s]\n100%|██████████| 874168/874168 [29:26<00:00, 530.15frames/s]\n100%|██████████| 874168/874168 [29:26<00:00, 494.98frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.5521868655556127,
        "compression_ratio": 0.9333333333333333,
        "end": 21.88,
        "id": 0,
        "no_speech_prob": 0.009244673885405064,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " Good afternoon.",
        "tokens": [
          50364,
          2205,
          6499,
          13,
          51458
        ]
      },
      {
        "avg_logprob": -0.5521868655556127,
        "compression_ratio": 0.9333333333333333,
        "end": 26.92,
        "id": 1,
        "no_speech_prob": 0.009244673885405064,
        "seek": 0,
        "start": 21.88,
        "temperature": 0,
        "text": " It is me again here on the coding train.",
        "tokens": [
          51458,
          467,
          307,
          385,
          797,
          510,
          322,
          264,
          17720,
          3847,
          13,
          51710
        ]
      },
      {
        "avg_logprob": -0.3696794208727385,
        "compression_ratio": 1.5391705069124424,
        "end": 29.240000000000002,
        "id": 2,
        "no_speech_prob": 0.0006563516217283905,
        "seek": 2692,
        "start": 26.92,
        "temperature": 0,
        "text": " My name is Dan.",
        "tokens": [
          50364,
          1222,
          1315,
          307,
          3394,
          13,
          50480
        ]
      },
      {
        "avg_logprob": -0.3696794208727385,
        "compression_ratio": 1.5391705069124424,
        "end": 33.160000000000004,
        "id": 3,
        "no_speech_prob": 0.0006563516217283905,
        "seek": 2692,
        "start": 29.240000000000002,
        "temperature": 0,
        "text": " NASA KOP in the chat asks, does it start now?",
        "tokens": [
          50480,
          12077,
          591,
          12059,
          294,
          264,
          5081,
          8962,
          11,
          775,
          309,
          722,
          586,
          30,
          50676
        ]
      },
      {
        "avg_logprob": -0.3696794208727385,
        "compression_ratio": 1.5391705069124424,
        "end": 35.760000000000005,
        "id": 4,
        "no_speech_prob": 0.0006563516217283905,
        "seek": 2692,
        "start": 33.160000000000004,
        "temperature": 0,
        "text": " In fact, it starts now.",
        "tokens": [
          50676,
          682,
          1186,
          11,
          309,
          3719,
          586,
          13,
          50806
        ]
      },
      {
        "avg_logprob": -0.3696794208727385,
        "compression_ratio": 1.5391705069124424,
        "end": 39.64,
        "id": 5,
        "no_speech_prob": 0.0006563516217283905,
        "seek": 2692,
        "start": 35.760000000000005,
        "temperature": 0,
        "text": " Or maybe officially it starts now.",
        "tokens": [
          50806,
          1610,
          1310,
          12053,
          309,
          3719,
          586,
          13,
          51000
        ]
      },
      {
        "avg_logprob": -0.3696794208727385,
        "compression_ratio": 1.5391705069124424,
        "end": 42.760000000000005,
        "id": 6,
        "no_speech_prob": 0.0006563516217283905,
        "seek": 2692,
        "start": 39.64,
        "temperature": 0,
        "text": " Welcome to the coding train afternoon edition.",
        "tokens": [
          51000,
          4027,
          281,
          264,
          17720,
          3847,
          6499,
          11377,
          13,
          51156
        ]
      },
      {
        "avg_logprob": -0.3696794208727385,
        "compression_ratio": 1.5391705069124424,
        "end": 45.68000000000001,
        "id": 7,
        "no_speech_prob": 0.0006563516217283905,
        "seek": 2692,
        "start": 42.760000000000005,
        "temperature": 0,
        "text": " There was a full 2 and 1 1-hour morning edition",
        "tokens": [
          51156,
          821,
          390,
          257,
          1577,
          568,
          293,
          502,
          502,
          12,
          18048,
          2446,
          11377,
          51302
        ]
      },
      {
        "avg_logprob": -0.3696794208727385,
        "compression_ratio": 1.5391705069124424,
        "end": 49.160000000000004,
        "id": 8,
        "no_speech_prob": 0.0006563516217283905,
        "seek": 2692,
        "start": 45.68000000000001,
        "temperature": 0,
        "text": " of the coding train today where I completed.",
        "tokens": [
          51302,
          295,
          264,
          17720,
          3847,
          965,
          689,
          286,
          7365,
          13,
          51476
        ]
      },
      {
        "avg_logprob": -0.3696794208727385,
        "compression_ratio": 1.5391705069124424,
        "end": 54.52,
        "id": 9,
        "no_speech_prob": 0.0006563516217283905,
        "seek": 2692,
        "start": 52.120000000000005,
        "temperature": 0,
        "text": " Completed is perhaps not the most accurate way",
        "tokens": [
          51624,
          33736,
          10993,
          307,
          4317,
          406,
          264,
          881,
          8559,
          636,
          51744
        ]
      },
      {
        "avg_logprob": -0.3696794208727385,
        "compression_ratio": 1.5391705069124424,
        "end": 55.68000000000001,
        "id": 10,
        "no_speech_prob": 0.0006563516217283905,
        "seek": 2692,
        "start": 54.52,
        "temperature": 0,
        "text": " to describe what happened.",
        "tokens": [
          51744,
          281,
          6786,
          437,
          2011,
          13,
          51802
        ]
      },
      {
        "avg_logprob": -0.24922505131474249,
        "compression_ratio": 1.5782608695652174,
        "end": 61.84,
        "id": 11,
        "no_speech_prob": 0.00005561576472246088,
        "seek": 5568,
        "start": 55.68,
        "temperature": 0,
        "text": " But I did attempt to continue to work on the logo coding",
        "tokens": [
          50364,
          583,
          286,
          630,
          5217,
          281,
          2354,
          281,
          589,
          322,
          264,
          9699,
          17720,
          50672
        ]
      },
      {
        "avg_logprob": -0.24922505131474249,
        "compression_ratio": 1.5782608695652174,
        "end": 62.34,
        "id": 12,
        "no_speech_prob": 0.00005561576472246088,
        "seek": 5568,
        "start": 61.84,
        "temperature": 0,
        "text": " challenge.",
        "tokens": [
          50672,
          3430,
          13,
          50697
        ]
      },
      {
        "avg_logprob": -0.24922505131474249,
        "compression_ratio": 1.5782608695652174,
        "end": 63.16,
        "id": 13,
        "no_speech_prob": 0.00005561576472246088,
        "seek": 5568,
        "start": 62.34,
        "temperature": 0,
        "text": " But that's all.",
        "tokens": [
          50697,
          583,
          300,
          311,
          439,
          13,
          50738
        ]
      },
      {
        "avg_logprob": -0.24922505131474249,
        "compression_ratio": 1.5782608695652174,
        "end": 65.44,
        "id": 14,
        "no_speech_prob": 0.00005561576472246088,
        "seek": 5568,
        "start": 63.16,
        "temperature": 0,
        "text": " I'm done with that.",
        "tokens": [
          50738,
          286,
          478,
          1096,
          365,
          300,
          13,
          50852
        ]
      },
      {
        "avg_logprob": -0.24922505131474249,
        "compression_ratio": 1.5782608695652174,
        "end": 67.16,
        "id": 15,
        "no_speech_prob": 0.00005561576472246088,
        "seek": 5568,
        "start": 65.44,
        "temperature": 0,
        "text": " Won't be returning to that anytime soon.",
        "tokens": [
          50852,
          14710,
          380,
          312,
          12678,
          281,
          300,
          13038,
          2321,
          13,
          50938
        ]
      },
      {
        "avg_logprob": -0.24922505131474249,
        "compression_ratio": 1.5782608695652174,
        "end": 70.24,
        "id": 16,
        "no_speech_prob": 0.00005561576472246088,
        "seek": 5568,
        "start": 67.16,
        "temperature": 0,
        "text": " Just in case you weren't here this morning, I will show you.",
        "tokens": [
          50938,
          1449,
          294,
          1389,
          291,
          4999,
          380,
          510,
          341,
          2446,
          11,
          286,
          486,
          855,
          291,
          13,
          51092
        ]
      },
      {
        "avg_logprob": -0.24922505131474249,
        "compression_ratio": 1.5782608695652174,
        "end": 73.68,
        "id": 17,
        "no_speech_prob": 0.00005561576472246088,
        "seek": 5568,
        "start": 70.24,
        "temperature": 0,
        "text": " I will pull this up very briefly.",
        "tokens": [
          51092,
          286,
          486,
          2235,
          341,
          493,
          588,
          10515,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.24922505131474249,
        "compression_ratio": 1.5782608695652174,
        "end": 78.32,
        "id": 18,
        "no_speech_prob": 0.00005561576472246088,
        "seek": 5568,
        "start": 73.68,
        "temperature": 0,
        "text": " If I go to a logo, coding train slash logo,",
        "tokens": [
          51264,
          759,
          286,
          352,
          281,
          257,
          9699,
          11,
          17720,
          3847,
          17330,
          9699,
          11,
          51496
        ]
      },
      {
        "avg_logprob": -0.24922505131474249,
        "compression_ratio": 1.5782608695652174,
        "end": 81.52,
        "id": 19,
        "no_speech_prob": 0.00005561576472246088,
        "seek": 5568,
        "start": 78.32,
        "temperature": 0,
        "text": " this is the GitHub repo.",
        "tokens": [
          51496,
          341,
          307,
          264,
          23331,
          49040,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.24922505131474249,
        "compression_ratio": 1.5782608695652174,
        "end": 85.32,
        "id": 20,
        "no_speech_prob": 0.00005561576472246088,
        "seek": 5568,
        "start": 81.52,
        "temperature": 0,
        "text": " There are some issues here that I would love help with",
        "tokens": [
          51656,
          821,
          366,
          512,
          2663,
          510,
          300,
          286,
          576,
          959,
          854,
          365,
          51846
        ]
      },
      {
        "avg_logprob": -0.29961483514131004,
        "compression_ratio": 1.6911764705882353,
        "end": 86.75999999999999,
        "id": 21,
        "no_speech_prob": 0.00014200365694705397,
        "seek": 8532,
        "start": 85.32,
        "temperature": 0,
        "text": " and thoughts on.",
        "tokens": [
          50364,
          293,
          4598,
          322,
          13,
          50436
        ]
      },
      {
        "avg_logprob": -0.29961483514131004,
        "compression_ratio": 1.6911764705882353,
        "end": 89.39999999999999,
        "id": 22,
        "no_speech_prob": 0.00014200365694705397,
        "seek": 8532,
        "start": 86.75999999999999,
        "temperature": 0,
        "text": " There are a couple of design pull requests.",
        "tokens": [
          50436,
          821,
          366,
          257,
          1916,
          295,
          1715,
          2235,
          12475,
          13,
          50568
        ]
      },
      {
        "avg_logprob": -0.29961483514131004,
        "compression_ratio": 1.6911764705882353,
        "end": 91.75999999999999,
        "id": 23,
        "no_speech_prob": 0.00014200365694705397,
        "seek": 8532,
        "start": 89.39999999999999,
        "temperature": 0,
        "text": " But I merged a couple of things without checking them.",
        "tokens": [
          50568,
          583,
          286,
          36427,
          257,
          1916,
          295,
          721,
          1553,
          8568,
          552,
          13,
          50686
        ]
      },
      {
        "avg_logprob": -0.29961483514131004,
        "compression_ratio": 1.6911764705882353,
        "end": 93.27999999999999,
        "id": 24,
        "no_speech_prob": 0.00014200365694705397,
        "seek": 8532,
        "start": 91.75999999999999,
        "temperature": 0,
        "text": " So let's actually see.",
        "tokens": [
          50686,
          407,
          718,
          311,
          767,
          536,
          13,
          50762
        ]
      },
      {
        "avg_logprob": -0.29961483514131004,
        "compression_ratio": 1.6911764705882353,
        "end": 96.44,
        "id": 25,
        "no_speech_prob": 0.00014200365694705397,
        "seek": 8532,
        "start": 93.27999999999999,
        "temperature": 0,
        "text": " Coding train dot GitHub slash.",
        "tokens": [
          50762,
          383,
          8616,
          3847,
          5893,
          23331,
          17330,
          13,
          50920
        ]
      },
      {
        "avg_logprob": -0.29961483514131004,
        "compression_ratio": 1.6911764705882353,
        "end": 98.67999999999999,
        "id": 26,
        "no_speech_prob": 0.00014200365694705397,
        "seek": 8532,
        "start": 96.44,
        "temperature": 0,
        "text": " This should be the demo.",
        "tokens": [
          50920,
          639,
          820,
          312,
          264,
          10723,
          13,
          51032
        ]
      },
      {
        "avg_logprob": -0.29961483514131004,
        "compression_ratio": 1.6911764705882353,
        "end": 100.52,
        "id": 27,
        "no_speech_prob": 0.00014200365694705397,
        "seek": 8532,
        "start": 98.67999999999999,
        "temperature": 0,
        "text": " And it still works.",
        "tokens": [
          51032,
          400,
          309,
          920,
          1985,
          13,
          51124
        ]
      },
      {
        "avg_logprob": -0.29961483514131004,
        "compression_ratio": 1.6911764705882353,
        "end": 101.17999999999999,
        "id": 28,
        "no_speech_prob": 0.00014200365694705397,
        "seek": 8532,
        "start": 100.52,
        "temperature": 0,
        "text": " So there you go.",
        "tokens": [
          51124,
          407,
          456,
          291,
          352,
          13,
          51157
        ]
      },
      {
        "avg_logprob": -0.29961483514131004,
        "compression_ratio": 1.6911764705882353,
        "end": 102.28,
        "id": 29,
        "no_speech_prob": 0.00014200365694705397,
        "seek": 8532,
        "start": 101.17999999999999,
        "temperature": 0,
        "text": " So this is what it does.",
        "tokens": [
          51157,
          407,
          341,
          307,
          437,
          309,
          775,
          13,
          51212
        ]
      },
      {
        "avg_logprob": -0.29961483514131004,
        "compression_ratio": 1.6911764705882353,
        "end": 105.67999999999999,
        "id": 30,
        "no_speech_prob": 0.00014200365694705397,
        "seek": 8532,
        "start": 102.28,
        "temperature": 0,
        "text": " It is a logo interpreter where you can type logo commands.",
        "tokens": [
          51212,
          467,
          307,
          257,
          9699,
          34132,
          689,
          291,
          393,
          2010,
          9699,
          16901,
          13,
          51382
        ]
      },
      {
        "avg_logprob": -0.29961483514131004,
        "compression_ratio": 1.6911764705882353,
        "end": 106.88,
        "id": 31,
        "no_speech_prob": 0.00014200365694705397,
        "seek": 8532,
        "start": 105.67999999999999,
        "temperature": 0,
        "text": " And it will draw them for you.",
        "tokens": [
          51382,
          400,
          309,
          486,
          2642,
          552,
          337,
          291,
          13,
          51442
        ]
      },
      {
        "avg_logprob": -0.29961483514131004,
        "compression_ratio": 1.6911764705882353,
        "end": 110.6,
        "id": 32,
        "no_speech_prob": 0.00014200365694705397,
        "seek": 8532,
        "start": 106.88,
        "temperature": 0,
        "text": " And apparently now, it supports some new commands",
        "tokens": [
          51442,
          400,
          7970,
          586,
          11,
          309,
          9346,
          512,
          777,
          16901,
          51628
        ]
      },
      {
        "avg_logprob": -0.29961483514131004,
        "compression_ratio": 1.6911764705882353,
        "end": 112.8,
        "id": 33,
        "no_speech_prob": 0.00014200365694705397,
        "seek": 8532,
        "start": 110.6,
        "temperature": 0,
        "text": " that it didn't as of this morning based on a few pull",
        "tokens": [
          51628,
          300,
          309,
          994,
          380,
          382,
          295,
          341,
          2446,
          2361,
          322,
          257,
          1326,
          2235,
          51738
        ]
      },
      {
        "avg_logprob": -0.29961483514131004,
        "compression_ratio": 1.6911764705882353,
        "end": 113.3,
        "id": 34,
        "no_speech_prob": 0.00014200365694705397,
        "seek": 8532,
        "start": 112.8,
        "temperature": 0,
        "text": " requests.",
        "tokens": [
          51738,
          12475,
          13,
          51763
        ]
      },
      {
        "avg_logprob": -0.25633065795898435,
        "compression_ratio": 1.6747967479674797,
        "end": 114.86,
        "id": 35,
        "no_speech_prob": 0.0035380059853196144,
        "seek": 11330,
        "start": 113.3,
        "temperature": 0,
        "text": " I don't want to rehash that too much.",
        "tokens": [
          50364,
          286,
          500,
          380,
          528,
          281,
          22355,
          1299,
          300,
          886,
          709,
          13,
          50442
        ]
      },
      {
        "avg_logprob": -0.25633065795898435,
        "compression_ratio": 1.6747967479674797,
        "end": 120.53999999999999,
        "id": 36,
        "no_speech_prob": 0.0035380059853196144,
        "seek": 11330,
        "start": 117.34,
        "temperature": 0,
        "text": " What I want to do, I'm going to do something.",
        "tokens": [
          50566,
          708,
          286,
          528,
          281,
          360,
          11,
          286,
          478,
          516,
          281,
          360,
          746,
          13,
          50726
        ]
      },
      {
        "avg_logprob": -0.25633065795898435,
        "compression_ratio": 1.6747967479674797,
        "end": 122.5,
        "id": 37,
        "no_speech_prob": 0.0035380059853196144,
        "seek": 11330,
        "start": 120.53999999999999,
        "temperature": 0,
        "text": " Oh, this is going to be good.",
        "tokens": [
          50726,
          876,
          11,
          341,
          307,
          516,
          281,
          312,
          665,
          13,
          50824
        ]
      },
      {
        "avg_logprob": -0.25633065795898435,
        "compression_ratio": 1.6747967479674797,
        "end": 125.82,
        "id": 38,
        "no_speech_prob": 0.0035380059853196144,
        "seek": 11330,
        "start": 122.5,
        "temperature": 0,
        "text": " I'm just going to get right into things, right into things.",
        "tokens": [
          50824,
          286,
          478,
          445,
          516,
          281,
          483,
          558,
          666,
          721,
          11,
          558,
          666,
          721,
          13,
          50990
        ]
      },
      {
        "avg_logprob": -0.25633065795898435,
        "compression_ratio": 1.6747967479674797,
        "end": 129.7,
        "id": 39,
        "no_speech_prob": 0.0035380059853196144,
        "seek": 11330,
        "start": 125.82,
        "temperature": 0,
        "text": " I am going to continue today, The Beginner's Guide",
        "tokens": [
          50990,
          286,
          669,
          516,
          281,
          2354,
          965,
          11,
          440,
          20660,
          1193,
          311,
          18727,
          51184
        ]
      },
      {
        "avg_logprob": -0.25633065795898435,
        "compression_ratio": 1.6747967479674797,
        "end": 132.26,
        "id": 40,
        "no_speech_prob": 0.0035380059853196144,
        "seek": 11330,
        "start": 129.7,
        "temperature": 0,
        "text": " to Machine Learning with ML5.js.",
        "tokens": [
          51184,
          281,
          22155,
          15205,
          365,
          21601,
          20,
          13,
          25530,
          13,
          51312
        ]
      },
      {
        "avg_logprob": -0.25633065795898435,
        "compression_ratio": 1.6747967479674797,
        "end": 134.18,
        "id": 41,
        "no_speech_prob": 0.0035380059853196144,
        "seek": 11330,
        "start": 132.26,
        "temperature": 0,
        "text": " In particular, I am going to make",
        "tokens": [
          51312,
          682,
          1729,
          11,
          286,
          669,
          516,
          281,
          652,
          51408
        ]
      },
      {
        "avg_logprob": -0.25633065795898435,
        "compression_ratio": 1.6747967479674797,
        "end": 136.85999999999999,
        "id": 42,
        "no_speech_prob": 0.0035380059853196144,
        "seek": 11330,
        "start": 134.18,
        "temperature": 0,
        "text": " a new video, which will appear as number seven",
        "tokens": [
          51408,
          257,
          777,
          960,
          11,
          597,
          486,
          4204,
          382,
          1230,
          3407,
          51542
        ]
      },
      {
        "avg_logprob": -0.25633065795898435,
        "compression_ratio": 1.6747967479674797,
        "end": 138.06,
        "id": 43,
        "no_speech_prob": 0.0035380059853196144,
        "seek": 11330,
        "start": 136.85999999999999,
        "temperature": 0,
        "text": " in this playlist.",
        "tokens": [
          51542,
          294,
          341,
          16788,
          13,
          51602
        ]
      },
      {
        "avg_logprob": -0.25633065795898435,
        "compression_ratio": 1.6747967479674797,
        "end": 141.34,
        "id": 44,
        "no_speech_prob": 0.0035380059853196144,
        "seek": 11330,
        "start": 138.06,
        "temperature": 0,
        "text": " In a moment, I'm probably going to repeat myself again.",
        "tokens": [
          51602,
          682,
          257,
          1623,
          11,
          286,
          478,
          1391,
          516,
          281,
          7149,
          2059,
          797,
          13,
          51766
        ]
      },
      {
        "avg_logprob": -0.19798044888478405,
        "compression_ratio": 1.65625,
        "end": 143.5,
        "id": 45,
        "no_speech_prob": 0.0000037266104300215375,
        "seek": 14134,
        "start": 141.34,
        "temperature": 0,
        "text": " And what I'm going to do is I'm going",
        "tokens": [
          50364,
          400,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          50472
        ]
      },
      {
        "avg_logprob": -0.19798044888478405,
        "compression_ratio": 1.65625,
        "end": 147.54,
        "id": 46,
        "no_speech_prob": 0.0000037266104300215375,
        "seek": 14134,
        "start": 143.5,
        "temperature": 0,
        "text": " to take this previous example that I made.",
        "tokens": [
          50472,
          281,
          747,
          341,
          3894,
          1365,
          300,
          286,
          1027,
          13,
          50674
        ]
      },
      {
        "avg_logprob": -0.19798044888478405,
        "compression_ratio": 1.65625,
        "end": 152.22,
        "id": 47,
        "no_speech_prob": 0.0000037266104300215375,
        "seek": 14134,
        "start": 147.54,
        "temperature": 0,
        "text": " And I am going to save, which trains a model.",
        "tokens": [
          50674,
          400,
          286,
          669,
          516,
          281,
          3155,
          11,
          597,
          16329,
          257,
          2316,
          13,
          50908
        ]
      },
      {
        "avg_logprob": -0.19798044888478405,
        "compression_ratio": 1.65625,
        "end": 156.38,
        "id": 48,
        "no_speech_prob": 0.0000037266104300215375,
        "seek": 14134,
        "start": 152.22,
        "temperature": 0,
        "text": " I'm going to save that model and then reload it back",
        "tokens": [
          50908,
          286,
          478,
          516,
          281,
          3155,
          300,
          2316,
          293,
          550,
          25628,
          309,
          646,
          51116
        ]
      },
      {
        "avg_logprob": -0.19798044888478405,
        "compression_ratio": 1.65625,
        "end": 159.98000000000002,
        "id": 49,
        "no_speech_prob": 0.0000037266104300215375,
        "seek": 14134,
        "start": 156.38,
        "temperature": 0,
        "text": " into the sketch so that I don't have to constantly retrain",
        "tokens": [
          51116,
          666,
          264,
          12325,
          370,
          300,
          286,
          500,
          380,
          362,
          281,
          6460,
          1533,
          7146,
          51296
        ]
      },
      {
        "avg_logprob": -0.19798044888478405,
        "compression_ratio": 1.65625,
        "end": 162.26,
        "id": 50,
        "no_speech_prob": 0.0000037266104300215375,
        "seek": 14134,
        "start": 159.98000000000002,
        "temperature": 0,
        "text": " every time I refresh the page, et cetera.",
        "tokens": [
          51296,
          633,
          565,
          286,
          15134,
          264,
          3028,
          11,
          1030,
          11458,
          13,
          51410
        ]
      },
      {
        "avg_logprob": -0.19798044888478405,
        "compression_ratio": 1.65625,
        "end": 165.62,
        "id": 51,
        "no_speech_prob": 0.0000037266104300215375,
        "seek": 14134,
        "start": 162.26,
        "temperature": 0,
        "text": " So this has been a long overdue feature,",
        "tokens": [
          51410,
          407,
          341,
          575,
          668,
          257,
          938,
          19853,
          622,
          4111,
          11,
          51578
        ]
      },
      {
        "avg_logprob": -0.19798044888478405,
        "compression_ratio": 1.65625,
        "end": 168.98000000000002,
        "id": 52,
        "no_speech_prob": 0.0000037266104300215375,
        "seek": 14134,
        "start": 165.62,
        "temperature": 0,
        "text": " or a widely requested feature in the ML5 library.",
        "tokens": [
          51578,
          420,
          257,
          13371,
          16436,
          4111,
          294,
          264,
          21601,
          20,
          6405,
          13,
          51746
        ]
      },
      {
        "avg_logprob": -0.3254291346815766,
        "compression_ratio": 1.3471074380165289,
        "end": 171.85999999999999,
        "id": 53,
        "no_speech_prob": 0.0009849787456914783,
        "seek": 16898,
        "start": 168.98,
        "temperature": 0,
        "text": " Let's go to GitHub.",
        "tokens": [
          50364,
          961,
          311,
          352,
          281,
          23331,
          13,
          50508
        ]
      },
      {
        "avg_logprob": -0.3254291346815766,
        "compression_ratio": 1.3471074380165289,
        "end": 173.01999999999998,
        "id": 54,
        "no_speech_prob": 0.0009849787456914783,
        "seek": 16898,
        "start": 171.85999999999999,
        "temperature": 0,
        "text": " Let's go to Issues.",
        "tokens": [
          50508,
          961,
          311,
          352,
          281,
          38195,
          1247,
          13,
          50566
        ]
      },
      {
        "avg_logprob": -0.3254291346815766,
        "compression_ratio": 1.3471074380165289,
        "end": 173.94,
        "id": 55,
        "no_speech_prob": 0.0009849787456914783,
        "seek": 16898,
        "start": 173.01999999999998,
        "temperature": 0,
        "text": " It might be closed.",
        "tokens": [
          50566,
          467,
          1062,
          312,
          5395,
          13,
          50612
        ]
      },
      {
        "avg_logprob": -0.3254291346815766,
        "compression_ratio": 1.3471074380165289,
        "end": 186.66,
        "id": 56,
        "no_speech_prob": 0.0009849787456914783,
        "seek": 16898,
        "start": 181.66,
        "temperature": 0,
        "text": " Let's look at, where did this get added?",
        "tokens": [
          50998,
          961,
          311,
          574,
          412,
          11,
          689,
          630,
          341,
          483,
          3869,
          30,
          51248
        ]
      },
      {
        "avg_logprob": -0.3254291346815766,
        "compression_ratio": 1.3471074380165289,
        "end": 187.26,
        "id": 57,
        "no_speech_prob": 0.0009849787456914783,
        "seek": 16898,
        "start": 186.66,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51248,
          821,
          321,
          352,
          13,
          51278
        ]
      },
      {
        "avg_logprob": -0.3254291346815766,
        "compression_ratio": 1.3471074380165289,
        "end": 197.14,
        "id": 58,
        "no_speech_prob": 0.0009849787456914783,
        "seek": 16898,
        "start": 189.94,
        "temperature": 0,
        "text": " So this is the support.",
        "tokens": [
          51412,
          407,
          341,
          307,
          264,
          1406,
          13,
          51772
        ]
      },
      {
        "avg_logprob": -0.3254291346815766,
        "compression_ratio": 1.3471074380165289,
        "end": 198.22,
        "id": 59,
        "no_speech_prob": 0.0009849787456914783,
        "seek": 16898,
        "start": 197.14,
        "temperature": 0,
        "text": " This is the pull request.",
        "tokens": [
          51772,
          639,
          307,
          264,
          2235,
          5308,
          13,
          51826
        ]
      },
      {
        "avg_logprob": -0.32317161560058594,
        "compression_ratio": 1.5806451612903225,
        "end": 200.74,
        "id": 60,
        "no_speech_prob": 0.00004400067336973734,
        "seek": 19822,
        "start": 199.22,
        "temperature": 0,
        "text": " So I'm going to leave this open.",
        "tokens": [
          50414,
          407,
          286,
          478,
          516,
          281,
          1856,
          341,
          1269,
          13,
          50490
        ]
      },
      {
        "avg_logprob": -0.32317161560058594,
        "compression_ratio": 1.5806451612903225,
        "end": 207.26,
        "id": 61,
        "no_speech_prob": 0.00004400067336973734,
        "seek": 19822,
        "start": 205.86,
        "temperature": 0,
        "text": " Yes, K. Wichman.",
        "tokens": [
          50746,
          1079,
          11,
          591,
          13,
          343,
          480,
          1601,
          13,
          50816
        ]
      },
      {
        "avg_logprob": -0.32317161560058594,
        "compression_ratio": 1.5806451612903225,
        "end": 208.38,
        "id": 62,
        "no_speech_prob": 0.00004400067336973734,
        "seek": 19822,
        "start": 207.26,
        "temperature": 0,
        "text": " Here we are again.",
        "tokens": [
          50816,
          1692,
          321,
          366,
          797,
          13,
          50872
        ]
      },
      {
        "avg_logprob": -0.32317161560058594,
        "compression_ratio": 1.5806451612903225,
        "end": 211.14,
        "id": 63,
        "no_speech_prob": 0.00004400067336973734,
        "seek": 19822,
        "start": 208.38,
        "temperature": 0,
        "text": " I am streaming extra, a little bit extra.",
        "tokens": [
          50872,
          286,
          669,
          11791,
          2857,
          11,
          257,
          707,
          857,
          2857,
          13,
          51010
        ]
      },
      {
        "avg_logprob": -0.32317161560058594,
        "compression_ratio": 1.5806451612903225,
        "end": 213.82,
        "id": 64,
        "no_speech_prob": 0.00004400067336973734,
        "seek": 19822,
        "start": 211.14,
        "temperature": 0,
        "text": " I've decided to come try to do two streams today,",
        "tokens": [
          51010,
          286,
          600,
          3047,
          281,
          808,
          853,
          281,
          360,
          732,
          15842,
          965,
          11,
          51144
        ]
      },
      {
        "avg_logprob": -0.32317161560058594,
        "compression_ratio": 1.5806451612903225,
        "end": 217.34,
        "id": 65,
        "no_speech_prob": 0.00004400067336973734,
        "seek": 19822,
        "start": 213.82,
        "temperature": 0,
        "text": " because A, I didn't get to last week because I was teaching.",
        "tokens": [
          51144,
          570,
          316,
          11,
          286,
          994,
          380,
          483,
          281,
          1036,
          1243,
          570,
          286,
          390,
          4571,
          13,
          51320
        ]
      },
      {
        "avg_logprob": -0.32317161560058594,
        "compression_ratio": 1.5806451612903225,
        "end": 219.46,
        "id": 66,
        "no_speech_prob": 0.00004400067336973734,
        "seek": 19822,
        "start": 217.34,
        "temperature": 0,
        "text": " And then also, I will just mention again",
        "tokens": [
          51320,
          400,
          550,
          611,
          11,
          286,
          486,
          445,
          2152,
          797,
          51426
        ]
      },
      {
        "avg_logprob": -0.32317161560058594,
        "compression_ratio": 1.5806451612903225,
        "end": 221.94,
        "id": 67,
        "no_speech_prob": 0.00004400067336973734,
        "seek": 19822,
        "start": 219.46,
        "temperature": 0,
        "text": " that I will be next week, next Saturday,",
        "tokens": [
          51426,
          300,
          286,
          486,
          312,
          958,
          1243,
          11,
          958,
          8803,
          11,
          51550
        ]
      },
      {
        "avg_logprob": -0.32317161560058594,
        "compression_ratio": 1.5806451612903225,
        "end": 224.14,
        "id": 68,
        "no_speech_prob": 0.00004400067336973734,
        "seek": 19822,
        "start": 221.94,
        "temperature": 0,
        "text": " at ThinkerCon in Hoodstool, Alabama,",
        "tokens": [
          51550,
          412,
          6557,
          260,
          9838,
          294,
          3631,
          378,
          372,
          1092,
          11,
          20898,
          11,
          51660
        ]
      },
      {
        "avg_logprob": -0.32317161560058594,
        "compression_ratio": 1.5806451612903225,
        "end": 227.7,
        "id": 69,
        "no_speech_prob": 0.00004400067336973734,
        "seek": 19822,
        "start": 224.14,
        "temperature": 0,
        "text": " a place I've never been to, the home of the rocket.",
        "tokens": [
          51660,
          257,
          1081,
          286,
          600,
          1128,
          668,
          281,
          11,
          264,
          1280,
          295,
          264,
          13012,
          13,
          51838
        ]
      },
      {
        "avg_logprob": -0.3297748565673828,
        "compression_ratio": 1.463855421686747,
        "end": 230.17999999999998,
        "id": 70,
        "no_speech_prob": 0.000013845894500263967,
        "seek": 22770,
        "start": 227.73999999999998,
        "temperature": 0,
        "text": " And if any of you are going to be there, please say hello.",
        "tokens": [
          50366,
          400,
          498,
          604,
          295,
          291,
          366,
          516,
          281,
          312,
          456,
          11,
          1767,
          584,
          7751,
          13,
          50488
        ]
      },
      {
        "avg_logprob": -0.3297748565673828,
        "compression_ratio": 1.463855421686747,
        "end": 241.01999999999998,
        "id": 71,
        "no_speech_prob": 0.000013845894500263967,
        "seek": 22770,
        "start": 238.66,
        "temperature": 0,
        "text": " All right, let's just get started here.",
        "tokens": [
          50912,
          1057,
          558,
          11,
          718,
          311,
          445,
          483,
          1409,
          510,
          13,
          51030
        ]
      },
      {
        "avg_logprob": -0.3297748565673828,
        "compression_ratio": 1.463855421686747,
        "end": 246.57999999999998,
        "id": 72,
        "no_speech_prob": 0.000013845894500263967,
        "seek": 22770,
        "start": 244.78,
        "temperature": 0,
        "text": " Let's just get started.",
        "tokens": [
          51218,
          961,
          311,
          445,
          483,
          1409,
          13,
          51308
        ]
      },
      {
        "avg_logprob": -0.3297748565673828,
        "compression_ratio": 1.463855421686747,
        "end": 247.73999999999998,
        "id": 73,
        "no_speech_prob": 0.000013845894500263967,
        "seek": 22770,
        "start": 246.57999999999998,
        "temperature": 0,
        "text": " So what else am I?",
        "tokens": [
          51308,
          407,
          437,
          1646,
          669,
          286,
          30,
          51366
        ]
      },
      {
        "avg_logprob": -0.3297748565673828,
        "compression_ratio": 1.463855421686747,
        "end": 252.5,
        "id": 74,
        "no_speech_prob": 0.000013845894500263967,
        "seek": 22770,
        "start": 247.73999999999998,
        "temperature": 0,
        "text": " I've got an hour or so or two, some amount of time.",
        "tokens": [
          51366,
          286,
          600,
          658,
          364,
          1773,
          420,
          370,
          420,
          732,
          11,
          512,
          2372,
          295,
          565,
          13,
          51604
        ]
      },
      {
        "avg_logprob": -0.3297748565673828,
        "compression_ratio": 1.463855421686747,
        "end": 255.78,
        "id": 75,
        "no_speech_prob": 0.000013845894500263967,
        "seek": 22770,
        "start": 252.5,
        "temperature": 0,
        "text": " I'm going to start with this ML5 save load model.",
        "tokens": [
          51604,
          286,
          478,
          516,
          281,
          722,
          365,
          341,
          21601,
          20,
          3155,
          3677,
          2316,
          13,
          51768
        ]
      },
      {
        "avg_logprob": -0.27463326760388296,
        "compression_ratio": 1.5512820512820513,
        "end": 258.14,
        "id": 76,
        "no_speech_prob": 0.0004442039062269032,
        "seek": 25578,
        "start": 255.78,
        "temperature": 0,
        "text": " I am going to also look at an example",
        "tokens": [
          50364,
          286,
          669,
          516,
          281,
          611,
          574,
          412,
          364,
          1365,
          50482
        ]
      },
      {
        "avg_logprob": -0.27463326760388296,
        "compression_ratio": 1.5512820512820513,
        "end": 260.86,
        "id": 77,
        "no_speech_prob": 0.0004442039062269032,
        "seek": 25578,
        "start": 258.14,
        "temperature": 0,
        "text": " with working with the Google Quick Draw data set,",
        "tokens": [
          50482,
          365,
          1364,
          365,
          264,
          3329,
          12101,
          20386,
          1412,
          992,
          11,
          50618
        ]
      },
      {
        "avg_logprob": -0.27463326760388296,
        "compression_ratio": 1.5512820512820513,
        "end": 267.9,
        "id": 78,
        "no_speech_prob": 0.0004442039062269032,
        "seek": 25578,
        "start": 260.86,
        "temperature": 0,
        "text": " because that is leading up to looking at the Sketch RNN",
        "tokens": [
          50618,
          570,
          300,
          307,
          5775,
          493,
          281,
          1237,
          412,
          264,
          49245,
          45702,
          45,
          50970
        ]
      },
      {
        "avg_logprob": -0.27463326760388296,
        "compression_ratio": 1.5512820512820513,
        "end": 269.22,
        "id": 79,
        "no_speech_prob": 0.0004442039062269032,
        "seek": 25578,
        "start": 267.9,
        "temperature": 0,
        "text": " model in ML5.",
        "tokens": [
          50970,
          2316,
          294,
          21601,
          20,
          13,
          51036
        ]
      },
      {
        "avg_logprob": -0.27463326760388296,
        "compression_ratio": 1.5512820512820513,
        "end": 269.86,
        "id": 80,
        "no_speech_prob": 0.0004442039062269032,
        "seek": 25578,
        "start": 269.22,
        "temperature": 0,
        "text": " So many things.",
        "tokens": [
          51036,
          407,
          867,
          721,
          13,
          51068
        ]
      },
      {
        "avg_logprob": -0.27463326760388296,
        "compression_ratio": 1.5512820512820513,
        "end": 272.58,
        "id": 81,
        "no_speech_prob": 0.0004442039062269032,
        "seek": 25578,
        "start": 269.86,
        "temperature": 0,
        "text": " I've got a long ML5 list of things to cover.",
        "tokens": [
          51068,
          286,
          600,
          658,
          257,
          938,
          21601,
          20,
          1329,
          295,
          721,
          281,
          2060,
          13,
          51204
        ]
      },
      {
        "avg_logprob": -0.27463326760388296,
        "compression_ratio": 1.5512820512820513,
        "end": 274.34,
        "id": 82,
        "no_speech_prob": 0.0004442039062269032,
        "seek": 25578,
        "start": 272.58,
        "temperature": 0,
        "text": " I want to look at some new stuff that's",
        "tokens": [
          51204,
          286,
          528,
          281,
          574,
          412,
          512,
          777,
          1507,
          300,
          311,
          51292
        ]
      },
      {
        "avg_logprob": -0.27463326760388296,
        "compression_ratio": 1.5512820512820513,
        "end": 278.46,
        "id": 83,
        "no_speech_prob": 0.0004442039062269032,
        "seek": 25578,
        "start": 274.34,
        "temperature": 0,
        "text": " been added for recurrent neural networks with text, Sketch RNN,",
        "tokens": [
          51292,
          668,
          3869,
          337,
          18680,
          1753,
          18161,
          9590,
          365,
          2487,
          11,
          49245,
          45702,
          45,
          11,
          51498
        ]
      },
      {
        "avg_logprob": -0.27463326760388296,
        "compression_ratio": 1.5512820512820513,
        "end": 282.58,
        "id": 84,
        "no_speech_prob": 0.0004442039062269032,
        "seek": 25578,
        "start": 278.46,
        "temperature": 0,
        "text": " PoseNet, KNN classifier, so many things.",
        "tokens": [
          51498,
          40174,
          31890,
          11,
          26967,
          45,
          1508,
          9902,
          11,
          370,
          867,
          721,
          13,
          51704
        ]
      },
      {
        "avg_logprob": -0.43032163943884505,
        "compression_ratio": 1.3053435114503817,
        "end": 284.26,
        "id": 85,
        "no_speech_prob": 0.00006814748485339805,
        "seek": 28258,
        "start": 283.26,
        "temperature": 0,
        "text": " So let us begin.",
        "tokens": [
          50398,
          407,
          718,
          505,
          1841,
          13,
          50448
        ]
      },
      {
        "avg_logprob": -0.43032163943884505,
        "compression_ratio": 1.3053435114503817,
        "end": 292.34,
        "id": 86,
        "no_speech_prob": 0.00006814748485339805,
        "seek": 28258,
        "start": 291.41999999999996,
        "temperature": 0,
        "text": " Hello.",
        "tokens": [
          50806,
          2425,
          13,
          50852
        ]
      },
      {
        "avg_logprob": -0.43032163943884505,
        "compression_ratio": 1.3053435114503817,
        "end": 295.58,
        "id": 87,
        "no_speech_prob": 0.00006814748485339805,
        "seek": 28258,
        "start": 292.34,
        "temperature": 0,
        "text": " I am here to make video number seven, which does not yet",
        "tokens": [
          50852,
          286,
          669,
          510,
          281,
          652,
          960,
          1230,
          3407,
          11,
          597,
          775,
          406,
          1939,
          51014
        ]
      },
      {
        "avg_logprob": -0.43032163943884505,
        "compression_ratio": 1.3053435114503817,
        "end": 296.08,
        "id": 88,
        "no_speech_prob": 0.00006814748485339805,
        "seek": 28258,
        "start": 295.58,
        "temperature": 0,
        "text": " exist.",
        "tokens": [
          51014,
          2514,
          13,
          51039
        ]
      },
      {
        "avg_logprob": -0.43032163943884505,
        "compression_ratio": 1.3053435114503817,
        "end": 298.18,
        "id": 89,
        "no_speech_prob": 0.00006814748485339805,
        "seek": 28258,
        "start": 296.08,
        "temperature": 0,
        "text": " If you have been watching this playlist,",
        "tokens": [
          51039,
          759,
          291,
          362,
          668,
          1976,
          341,
          16788,
          11,
          51144
        ]
      },
      {
        "avg_logprob": -0.43032163943884505,
        "compression_ratio": 1.3053435114503817,
        "end": 302.7,
        "id": 90,
        "no_speech_prob": 0.00006814748485339805,
        "seek": 28258,
        "start": 298.18,
        "temperature": 0,
        "text": " the place where I left off was training a.",
        "tokens": [
          51144,
          264,
          1081,
          689,
          286,
          1411,
          766,
          390,
          3097,
          257,
          13,
          51370
        ]
      },
      {
        "avg_logprob": -0.2681690700470455,
        "compression_ratio": 1.5942028985507246,
        "end": 313.38,
        "id": 91,
        "no_speech_prob": 0.00045119464630261064,
        "seek": 31258,
        "start": 312.82,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          50376,
          6962,
          322,
          13,
          50404
        ]
      },
      {
        "avg_logprob": -0.2681690700470455,
        "compression_ratio": 1.5942028985507246,
        "end": 316.06,
        "id": 92,
        "no_speech_prob": 0.00045119464630261064,
        "seek": 31258,
        "start": 313.38,
        "temperature": 0,
        "text": " I forgot to turn on this part of my brain.",
        "tokens": [
          50404,
          286,
          5298,
          281,
          1261,
          322,
          341,
          644,
          295,
          452,
          3567,
          13,
          50538
        ]
      },
      {
        "avg_logprob": -0.2681690700470455,
        "compression_ratio": 1.5942028985507246,
        "end": 323.46,
        "id": 93,
        "no_speech_prob": 0.00045119464630261064,
        "seek": 31258,
        "start": 320.14,
        "temperature": 0,
        "text": " Hello, welcome to a new ML5 beginner's guide",
        "tokens": [
          50742,
          2425,
          11,
          2928,
          281,
          257,
          777,
          21601,
          20,
          22080,
          311,
          5934,
          50908
        ]
      },
      {
        "avg_logprob": -0.2681690700470455,
        "compression_ratio": 1.5942028985507246,
        "end": 324.94,
        "id": 94,
        "no_speech_prob": 0.00045119464630261064,
        "seek": 31258,
        "start": 323.46,
        "temperature": 0,
        "text": " to machine learning video.",
        "tokens": [
          50908,
          281,
          3479,
          2539,
          960,
          13,
          50982
        ]
      },
      {
        "avg_logprob": -0.2681690700470455,
        "compression_ratio": 1.5942028985507246,
        "end": 327.3,
        "id": 95,
        "no_speech_prob": 0.00045119464630261064,
        "seek": 31258,
        "start": 324.94,
        "temperature": 0,
        "text": " I am about to make video number seven.",
        "tokens": [
          50982,
          286,
          669,
          466,
          281,
          652,
          960,
          1230,
          3407,
          13,
          51100
        ]
      },
      {
        "avg_logprob": -0.2681690700470455,
        "compression_ratio": 1.5942028985507246,
        "end": 329.14,
        "id": 96,
        "no_speech_prob": 0.00045119464630261064,
        "seek": 31258,
        "start": 327.3,
        "temperature": 0,
        "text": " Right now, that's what you're watching.",
        "tokens": [
          51100,
          1779,
          586,
          11,
          300,
          311,
          437,
          291,
          434,
          1976,
          13,
          51192
        ]
      },
      {
        "avg_logprob": -0.2681690700470455,
        "compression_ratio": 1.5942028985507246,
        "end": 331.02,
        "id": 97,
        "no_speech_prob": 0.00045119464630261064,
        "seek": 31258,
        "start": 329.14,
        "temperature": 0,
        "text": " Where I left off, I looked at how",
        "tokens": [
          51192,
          2305,
          286,
          1411,
          766,
          11,
          286,
          2956,
          412,
          577,
          51286
        ]
      },
      {
        "avg_logprob": -0.2681690700470455,
        "compression_ratio": 1.5942028985507246,
        "end": 334.28,
        "id": 98,
        "no_speech_prob": 0.00045119464630261064,
        "seek": 31258,
        "start": 331.02,
        "temperature": 0,
        "text": " you could train your own image classifier with images coming",
        "tokens": [
          51286,
          291,
          727,
          3847,
          428,
          1065,
          3256,
          1508,
          9902,
          365,
          5267,
          1348,
          51449
        ]
      },
      {
        "avg_logprob": -0.2681690700470455,
        "compression_ratio": 1.5942028985507246,
        "end": 336.41999999999996,
        "id": 99,
        "no_speech_prob": 0.00045119464630261064,
        "seek": 31258,
        "start": 334.28,
        "temperature": 0,
        "text": " in from the webcam with a technique known",
        "tokens": [
          51449,
          294,
          490,
          264,
          39490,
          365,
          257,
          6532,
          2570,
          51556
        ]
      },
      {
        "avg_logprob": -0.2681690700470455,
        "compression_ratio": 1.5942028985507246,
        "end": 337.34,
        "id": 100,
        "no_speech_prob": 0.00045119464630261064,
        "seek": 31258,
        "start": 336.41999999999996,
        "temperature": 0,
        "text": " as transfer learning.",
        "tokens": [
          51556,
          382,
          5003,
          2539,
          13,
          51602
        ]
      },
      {
        "avg_logprob": -0.2681690700470455,
        "compression_ratio": 1.5942028985507246,
        "end": 338.38,
        "id": 101,
        "no_speech_prob": 0.00045119464630261064,
        "seek": 31258,
        "start": 337.34,
        "temperature": 0,
        "text": " This is the example.",
        "tokens": [
          51602,
          639,
          307,
          264,
          1365,
          13,
          51654
        ]
      },
      {
        "avg_logprob": -0.2681690700470455,
        "compression_ratio": 1.5942028985507246,
        "end": 342.06,
        "id": 102,
        "no_speech_prob": 0.00045119464630261064,
        "seek": 31258,
        "start": 338.38,
        "temperature": 0,
        "text": " So this example needs to be trained, but I could do this.",
        "tokens": [
          51654,
          407,
          341,
          1365,
          2203,
          281,
          312,
          8895,
          11,
          457,
          286,
          727,
          360,
          341,
          13,
          51838
        ]
      },
      {
        "avg_logprob": -0.3804149812865026,
        "compression_ratio": 1.6666666666666667,
        "end": 346.02,
        "id": 103,
        "no_speech_prob": 0.0004954776377417147,
        "seek": 34206,
        "start": 342.06,
        "temperature": 0,
        "text": " I could get a lot of examples of me being happy,",
        "tokens": [
          50364,
          286,
          727,
          483,
          257,
          688,
          295,
          5110,
          295,
          385,
          885,
          2055,
          11,
          50562
        ]
      },
      {
        "avg_logprob": -0.3804149812865026,
        "compression_ratio": 1.6666666666666667,
        "end": 348.38,
        "id": 104,
        "no_speech_prob": 0.0004954776377417147,
        "seek": 34206,
        "start": 346.02,
        "temperature": 0,
        "text": " a lot of examples of me being sad.",
        "tokens": [
          50562,
          257,
          688,
          295,
          5110,
          295,
          385,
          885,
          4227,
          13,
          50680
        ]
      },
      {
        "avg_logprob": -0.3804149812865026,
        "compression_ratio": 1.6666666666666667,
        "end": 350.02,
        "id": 105,
        "no_speech_prob": 0.0004954776377417147,
        "seek": 34206,
        "start": 348.38,
        "temperature": 0,
        "text": " Then I could hit the Train button,",
        "tokens": [
          50680,
          1396,
          286,
          727,
          2045,
          264,
          28029,
          2960,
          11,
          50762
        ]
      },
      {
        "avg_logprob": -0.3804149812865026,
        "compression_ratio": 1.6666666666666667,
        "end": 353.86,
        "id": 106,
        "no_speech_prob": 0.0004954776377417147,
        "seek": 34206,
        "start": 350.02,
        "temperature": 0,
        "text": " and once it finishes training, it is then going to be done.",
        "tokens": [
          50762,
          293,
          1564,
          309,
          23615,
          3097,
          11,
          309,
          307,
          550,
          516,
          281,
          312,
          1096,
          13,
          50954
        ]
      },
      {
        "avg_logprob": -0.3804149812865026,
        "compression_ratio": 1.6666666666666667,
        "end": 354.58,
        "id": 107,
        "no_speech_prob": 0.0004954776377417147,
        "seek": 34206,
        "start": 353.86,
        "temperature": 0,
        "text": " And now I, hi.",
        "tokens": [
          50954,
          400,
          586,
          286,
          11,
          4879,
          13,
          50990
        ]
      },
      {
        "avg_logprob": -0.3804149812865026,
        "compression_ratio": 1.6666666666666667,
        "end": 361.54,
        "id": 108,
        "no_speech_prob": 0.0004954776377417147,
        "seek": 34206,
        "start": 360.62,
        "temperature": 0,
        "text": " This failed.",
        "tokens": [
          51292,
          639,
          7612,
          13,
          51338
        ]
      },
      {
        "avg_logprob": -0.3804149812865026,
        "compression_ratio": 1.6666666666666667,
        "end": 364.22,
        "id": 109,
        "no_speech_prob": 0.0004954776377417147,
        "seek": 34206,
        "start": 361.54,
        "temperature": 0,
        "text": " I shouldn't have been so, I didn't give it enough.",
        "tokens": [
          51338,
          286,
          4659,
          380,
          362,
          668,
          370,
          11,
          286,
          994,
          380,
          976,
          309,
          1547,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -0.3804149812865026,
        "compression_ratio": 1.6666666666666667,
        "end": 364.9,
        "id": 110,
        "no_speech_prob": 0.0004954776377417147,
        "seek": 34206,
        "start": 364.22,
        "temperature": 0,
        "text": " One more try.",
        "tokens": [
          51472,
          1485,
          544,
          853,
          13,
          51506
        ]
      },
      {
        "avg_logprob": -0.3804149812865026,
        "compression_ratio": 1.6666666666666667,
        "end": 369.02,
        "id": 111,
        "no_speech_prob": 0.0004954776377417147,
        "seek": 34206,
        "start": 367.54,
        "temperature": 0,
        "text": " One more try.",
        "tokens": [
          51638,
          1485,
          544,
          853,
          13,
          51712
        ]
      },
      {
        "avg_logprob": -0.3804149812865026,
        "compression_ratio": 1.6666666666666667,
        "end": 371.46,
        "id": 112,
        "no_speech_prob": 0.0004954776377417147,
        "seek": 34206,
        "start": 369.02,
        "temperature": 0,
        "text": " This time with feeling, everybody.",
        "tokens": [
          51712,
          639,
          565,
          365,
          2633,
          11,
          2201,
          13,
          51834
        ]
      },
      {
        "avg_logprob": -0.2447843208587427,
        "compression_ratio": 1.6426229508196721,
        "end": 374.06,
        "id": 113,
        "no_speech_prob": 0.00020342340576462448,
        "seek": 37146,
        "start": 371.46,
        "temperature": 0,
        "text": " Don't you just love watching the live streams where I just",
        "tokens": [
          50364,
          1468,
          380,
          291,
          445,
          959,
          1976,
          264,
          1621,
          15842,
          689,
          286,
          445,
          50494
        ]
      },
      {
        "avg_logprob": -0.2447843208587427,
        "compression_ratio": 1.6426229508196721,
        "end": 377.97999999999996,
        "id": 114,
        "no_speech_prob": 0.00020342340576462448,
        "seek": 37146,
        "start": 374.06,
        "temperature": 0,
        "text": " do the same thing over and over again?",
        "tokens": [
          50494,
          360,
          264,
          912,
          551,
          670,
          293,
          670,
          797,
          30,
          50690
        ]
      },
      {
        "avg_logprob": -0.2447843208587427,
        "compression_ratio": 1.6426229508196721,
        "end": 381.06,
        "id": 115,
        "no_speech_prob": 0.00020342340576462448,
        "seek": 37146,
        "start": 377.97999999999996,
        "temperature": 0,
        "text": " Hello, and welcome to another beginner's guide",
        "tokens": [
          50690,
          2425,
          11,
          293,
          2928,
          281,
          1071,
          22080,
          311,
          5934,
          50844
        ]
      },
      {
        "avg_logprob": -0.2447843208587427,
        "compression_ratio": 1.6426229508196721,
        "end": 383.26,
        "id": 116,
        "no_speech_prob": 0.00020342340576462448,
        "seek": 37146,
        "start": 381.06,
        "temperature": 0,
        "text": " to machine learning with ML5.js video.",
        "tokens": [
          50844,
          281,
          3479,
          2539,
          365,
          21601,
          20,
          13,
          25530,
          960,
          13,
          50954
        ]
      },
      {
        "avg_logprob": -0.2447843208587427,
        "compression_ratio": 1.6426229508196721,
        "end": 385.02,
        "id": 117,
        "no_speech_prob": 0.00020342340576462448,
        "seek": 37146,
        "start": 383.26,
        "temperature": 0,
        "text": " This is video number seven in this playlist.",
        "tokens": [
          50954,
          639,
          307,
          960,
          1230,
          3407,
          294,
          341,
          16788,
          13,
          51042
        ]
      },
      {
        "avg_logprob": -0.2447843208587427,
        "compression_ratio": 1.6426229508196721,
        "end": 386.94,
        "id": 118,
        "no_speech_prob": 0.00020342340576462448,
        "seek": 37146,
        "start": 385.02,
        "temperature": 0,
        "text": " At least that's where I intend it to be.",
        "tokens": [
          51042,
          1711,
          1935,
          300,
          311,
          689,
          286,
          19759,
          309,
          281,
          312,
          13,
          51138
        ]
      },
      {
        "avg_logprob": -0.2447843208587427,
        "compression_ratio": 1.6426229508196721,
        "end": 389.29999999999995,
        "id": 119,
        "no_speech_prob": 0.00020342340576462448,
        "seek": 37146,
        "start": 386.94,
        "temperature": 0,
        "text": " And in this video, I'm going to take a step forward.",
        "tokens": [
          51138,
          400,
          294,
          341,
          960,
          11,
          286,
          478,
          516,
          281,
          747,
          257,
          1823,
          2128,
          13,
          51256
        ]
      },
      {
        "avg_logprob": -0.2447843208587427,
        "compression_ratio": 1.6426229508196721,
        "end": 393.02,
        "id": 120,
        "no_speech_prob": 0.00020342340576462448,
        "seek": 37146,
        "start": 389.29999999999995,
        "temperature": 0,
        "text": " I am going to do something that has been so widely requested.",
        "tokens": [
          51256,
          286,
          669,
          516,
          281,
          360,
          746,
          300,
          575,
          668,
          370,
          13371,
          16436,
          13,
          51442
        ]
      },
      {
        "avg_logprob": -0.2447843208587427,
        "compression_ratio": 1.6426229508196721,
        "end": 395.26,
        "id": 121,
        "no_speech_prob": 0.00020342340576462448,
        "seek": 37146,
        "start": 393.02,
        "temperature": 0,
        "text": " A new feature that was recently added to ML5",
        "tokens": [
          51442,
          316,
          777,
          4111,
          300,
          390,
          3938,
          3869,
          281,
          21601,
          20,
          51554
        ]
      },
      {
        "avg_logprob": -0.2447843208587427,
        "compression_ratio": 1.6426229508196721,
        "end": 398.82,
        "id": 122,
        "no_speech_prob": 0.00020342340576462448,
        "seek": 37146,
        "start": 395.26,
        "temperature": 0,
        "text": " to save and reload a model.",
        "tokens": [
          51554,
          281,
          3155,
          293,
          25628,
          257,
          2316,
          13,
          51732
        ]
      },
      {
        "avg_logprob": -0.2447843208587427,
        "compression_ratio": 1.6426229508196721,
        "end": 400.62,
        "id": 123,
        "no_speech_prob": 0.00020342340576462448,
        "seek": 37146,
        "start": 398.82,
        "temperature": 0,
        "text": " Now, what kind of model am I talking about?",
        "tokens": [
          51732,
          823,
          11,
          437,
          733,
          295,
          2316,
          669,
          286,
          1417,
          466,
          30,
          51822
        ]
      },
      {
        "avg_logprob": -0.34067118962605797,
        "compression_ratio": 1.6651982378854626,
        "end": 402.5,
        "id": 124,
        "no_speech_prob": 0.000009972865882446058,
        "seek": 40062,
        "start": 400.66,
        "temperature": 0,
        "text": " So the last example I left off with",
        "tokens": [
          50366,
          407,
          264,
          1036,
          1365,
          286,
          1411,
          766,
          365,
          50458
        ]
      },
      {
        "avg_logprob": -0.34067118962605797,
        "compression_ratio": 1.6651982378854626,
        "end": 405.58,
        "id": 125,
        "no_speech_prob": 0.000009972865882446058,
        "seek": 40062,
        "start": 402.5,
        "temperature": 0,
        "text": " was this transfer learning example,",
        "tokens": [
          50458,
          390,
          341,
          5003,
          2539,
          1365,
          11,
          50612
        ]
      },
      {
        "avg_logprob": -0.34067118962605797,
        "compression_ratio": 1.6651982378854626,
        "end": 409.74,
        "id": 126,
        "no_speech_prob": 0.000009972865882446058,
        "seek": 40062,
        "start": 405.58,
        "temperature": 0,
        "text": " where I can train my own image classifier with images",
        "tokens": [
          50612,
          689,
          286,
          393,
          3847,
          452,
          1065,
          3256,
          1508,
          9902,
          365,
          5267,
          50820
        ]
      },
      {
        "avg_logprob": -0.34067118962605797,
        "compression_ratio": 1.6651982378854626,
        "end": 410.9,
        "id": 127,
        "no_speech_prob": 0.000009972865882446058,
        "seek": 40062,
        "start": 409.74,
        "temperature": 0,
        "text": " coming in from the webcam.",
        "tokens": [
          50820,
          1348,
          294,
          490,
          264,
          39490,
          13,
          50878
        ]
      },
      {
        "avg_logprob": -0.34067118962605797,
        "compression_ratio": 1.6651982378854626,
        "end": 412.12,
        "id": 128,
        "no_speech_prob": 0.000009972865882446058,
        "seek": 40062,
        "start": 410.9,
        "temperature": 0,
        "text": " So for example, I could say, here's",
        "tokens": [
          50878,
          407,
          337,
          1365,
          11,
          286,
          727,
          584,
          11,
          510,
          311,
          50939
        ]
      },
      {
        "avg_logprob": -0.34067118962605797,
        "compression_ratio": 1.6651982378854626,
        "end": 413.54,
        "id": 129,
        "no_speech_prob": 0.000009972865882446058,
        "seek": 40062,
        "start": 412.12,
        "temperature": 0,
        "text": " a lot of images of me being happy.",
        "tokens": [
          50939,
          257,
          688,
          295,
          5267,
          295,
          385,
          885,
          2055,
          13,
          51010
        ]
      },
      {
        "avg_logprob": -0.34067118962605797,
        "compression_ratio": 1.6651982378854626,
        "end": 419.06,
        "id": 130,
        "no_speech_prob": 0.000009972865882446058,
        "seek": 40062,
        "start": 417.5,
        "temperature": 0,
        "text": " Is this interesting yet?",
        "tokens": [
          51208,
          1119,
          341,
          1880,
          1939,
          30,
          51286
        ]
      },
      {
        "avg_logprob": -0.34067118962605797,
        "compression_ratio": 1.6651982378854626,
        "end": 420.22,
        "id": 131,
        "no_speech_prob": 0.000009972865882446058,
        "seek": 40062,
        "start": 419.06,
        "temperature": 0,
        "text": " What's going on?",
        "tokens": [
          51286,
          708,
          311,
          516,
          322,
          30,
          51344
        ]
      },
      {
        "avg_logprob": -0.34067118962605797,
        "compression_ratio": 1.6651982378854626,
        "end": 421.22,
        "id": 132,
        "no_speech_prob": 0.000009972865882446058,
        "seek": 40062,
        "start": 420.22,
        "temperature": 0,
        "text": " Here's all the images.",
        "tokens": [
          51344,
          1692,
          311,
          439,
          264,
          5267,
          13,
          51394
        ]
      },
      {
        "avg_logprob": -0.34067118962605797,
        "compression_ratio": 1.6651982378854626,
        "end": 422.02,
        "id": 133,
        "no_speech_prob": 0.000009972865882446058,
        "seek": 40062,
        "start": 421.22,
        "temperature": 0,
        "text": " What are you doing?",
        "tokens": [
          51394,
          708,
          366,
          291,
          884,
          30,
          51434
        ]
      },
      {
        "avg_logprob": -0.34067118962605797,
        "compression_ratio": 1.6651982378854626,
        "end": 422.52,
        "id": 134,
        "no_speech_prob": 0.000009972865882446058,
        "seek": 40062,
        "start": 422.02,
        "temperature": 0,
        "text": " I'm sad.",
        "tokens": [
          51434,
          286,
          478,
          4227,
          13,
          51459
        ]
      },
      {
        "avg_logprob": -0.34067118962605797,
        "compression_ratio": 1.6651982378854626,
        "end": 428.46,
        "id": 135,
        "no_speech_prob": 0.000009972865882446058,
        "seek": 40062,
        "start": 426.18,
        "temperature": 0,
        "text": " Then I'm going to train it.",
        "tokens": [
          51642,
          1396,
          286,
          478,
          516,
          281,
          3847,
          309,
          13,
          51756
        ]
      },
      {
        "avg_logprob": -0.34067118962605797,
        "compression_ratio": 1.6651982378854626,
        "end": 429.82,
        "id": 136,
        "no_speech_prob": 0.000009972865882446058,
        "seek": 40062,
        "start": 428.46,
        "temperature": 0,
        "text": " And then I'm going to come back.",
        "tokens": [
          51756,
          400,
          550,
          286,
          478,
          516,
          281,
          808,
          646,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.23691591303399268,
        "compression_ratio": 1.7108433734939759,
        "end": 430.74,
        "id": 137,
        "no_speech_prob": 0.00001670130222919397,
        "seek": 42982,
        "start": 429.82,
        "temperature": 0,
        "text": " It's going to be done.",
        "tokens": [
          50364,
          467,
          311,
          516,
          281,
          312,
          1096,
          13,
          50410
        ]
      },
      {
        "avg_logprob": -0.23691591303399268,
        "compression_ratio": 1.7108433734939759,
        "end": 435.7,
        "id": 138,
        "no_speech_prob": 0.00001670130222919397,
        "seek": 42982,
        "start": 435.06,
        "temperature": 0,
        "text": " So that works.",
        "tokens": [
          50626,
          407,
          300,
          1985,
          13,
          50658
        ]
      },
      {
        "avg_logprob": -0.23691591303399268,
        "compression_ratio": 1.7108433734939759,
        "end": 440.02,
        "id": 139,
        "no_speech_prob": 0.00001670130222919397,
        "seek": 42982,
        "start": 435.7,
        "temperature": 0,
        "text": " But what happens now if I refresh the page?",
        "tokens": [
          50658,
          583,
          437,
          2314,
          586,
          498,
          286,
          15134,
          264,
          3028,
          30,
          50874
        ]
      },
      {
        "avg_logprob": -0.23691591303399268,
        "compression_ratio": 1.7108433734939759,
        "end": 441.74,
        "id": 140,
        "no_speech_prob": 0.00001670130222919397,
        "seek": 42982,
        "start": 440.02,
        "temperature": 0,
        "text": " Need to be trained again.",
        "tokens": [
          50874,
          16984,
          281,
          312,
          8895,
          797,
          13,
          50960
        ]
      },
      {
        "avg_logprob": -0.23691591303399268,
        "compression_ratio": 1.7108433734939759,
        "end": 444.14,
        "id": 141,
        "no_speech_prob": 0.00001670130222919397,
        "seek": 42982,
        "start": 441.74,
        "temperature": 0,
        "text": " That model is lost.",
        "tokens": [
          50960,
          663,
          2316,
          307,
          2731,
          13,
          51080
        ]
      },
      {
        "avg_logprob": -0.23691591303399268,
        "compression_ratio": 1.7108433734939759,
        "end": 447.9,
        "id": 142,
        "no_speech_prob": 0.00001670130222919397,
        "seek": 42982,
        "start": 444.14,
        "temperature": 0,
        "text": " So there is a new feature in ML5, a load function",
        "tokens": [
          51080,
          407,
          456,
          307,
          257,
          777,
          4111,
          294,
          21601,
          20,
          11,
          257,
          3677,
          2445,
          51268
        ]
      },
      {
        "avg_logprob": -0.23691591303399268,
        "compression_ratio": 1.7108433734939759,
        "end": 449.18,
        "id": 143,
        "no_speech_prob": 0.00001670130222919397,
        "seek": 42982,
        "start": 447.9,
        "temperature": 0,
        "text": " and a save function.",
        "tokens": [
          51268,
          293,
          257,
          3155,
          2445,
          13,
          51332
        ]
      },
      {
        "avg_logprob": -0.23691591303399268,
        "compression_ratio": 1.7108433734939759,
        "end": 450.58,
        "id": 144,
        "no_speech_prob": 0.00001670130222919397,
        "seek": 42982,
        "start": 449.18,
        "temperature": 0,
        "text": " A save function and a load function.",
        "tokens": [
          51332,
          316,
          3155,
          2445,
          293,
          257,
          3677,
          2445,
          13,
          51402
        ]
      },
      {
        "avg_logprob": -0.23691591303399268,
        "compression_ratio": 1.7108433734939759,
        "end": 451.65999999999997,
        "id": 145,
        "no_speech_prob": 0.00001670130222919397,
        "seek": 42982,
        "start": 450.58,
        "temperature": 0,
        "text": " This is what I'm going to show you in this video.",
        "tokens": [
          51402,
          639,
          307,
          437,
          286,
          478,
          516,
          281,
          855,
          291,
          294,
          341,
          960,
          13,
          51456
        ]
      },
      {
        "avg_logprob": -0.23691591303399268,
        "compression_ratio": 1.7108433734939759,
        "end": 452.78,
        "id": 146,
        "no_speech_prob": 0.00001670130222919397,
        "seek": 42982,
        "start": 451.65999999999997,
        "temperature": 0,
        "text": " Let's see if we can get it to work.",
        "tokens": [
          51456,
          961,
          311,
          536,
          498,
          321,
          393,
          483,
          309,
          281,
          589,
          13,
          51512
        ]
      },
      {
        "avg_logprob": -0.23691591303399268,
        "compression_ratio": 1.7108433734939759,
        "end": 453.28,
        "id": 147,
        "no_speech_prob": 0.00001670130222919397,
        "seek": 42982,
        "start": 452.78,
        "temperature": 0,
        "text": " That's it.",
        "tokens": [
          51512,
          663,
          311,
          309,
          13,
          51537
        ]
      },
      {
        "avg_logprob": -0.23691591303399268,
        "compression_ratio": 1.7108433734939759,
        "end": 455.06,
        "id": 148,
        "no_speech_prob": 0.00001670130222919397,
        "seek": 42982,
        "start": 453.28,
        "temperature": 0,
        "text": " It's all I'm going to add.",
        "tokens": [
          51537,
          467,
          311,
          439,
          286,
          478,
          516,
          281,
          909,
          13,
          51626
        ]
      },
      {
        "avg_logprob": -0.23691591303399268,
        "compression_ratio": 1.7108433734939759,
        "end": 457.21999999999997,
        "id": 149,
        "no_speech_prob": 0.00001670130222919397,
        "seek": 42982,
        "start": 455.06,
        "temperature": 0,
        "text": " So I've got the code from the previous example",
        "tokens": [
          51626,
          407,
          286,
          600,
          658,
          264,
          3089,
          490,
          264,
          3894,
          1365,
          51734
        ]
      },
      {
        "avg_logprob": -0.23691591303399268,
        "compression_ratio": 1.7108433734939759,
        "end": 459.48,
        "id": 150,
        "no_speech_prob": 0.00001670130222919397,
        "seek": 42982,
        "start": 457.21999999999997,
        "temperature": 0,
        "text": " here to pull it up.",
        "tokens": [
          51734,
          510,
          281,
          2235,
          309,
          493,
          13,
          51847
        ]
      },
      {
        "avg_logprob": -0.3151137942359561,
        "compression_ratio": 1.8622222222222222,
        "end": 461.88,
        "id": 151,
        "no_speech_prob": 0.000058290686865802854,
        "seek": 45948,
        "start": 459.48,
        "temperature": 0,
        "text": " And what I'm going to do, let's add another button.",
        "tokens": [
          50364,
          400,
          437,
          286,
          478,
          516,
          281,
          360,
          11,
          718,
          311,
          909,
          1071,
          2960,
          13,
          50484
        ]
      },
      {
        "avg_logprob": -0.3151137942359561,
        "compression_ratio": 1.8622222222222222,
        "end": 462.84000000000003,
        "id": 152,
        "no_speech_prob": 0.000058290686865802854,
        "seek": 45948,
        "start": 461.88,
        "temperature": 0,
        "text": " Where are the buttons?",
        "tokens": [
          50484,
          2305,
          366,
          264,
          9905,
          30,
          50532
        ]
      },
      {
        "avg_logprob": -0.3151137942359561,
        "compression_ratio": 1.8622222222222222,
        "end": 463.56,
        "id": 153,
        "no_speech_prob": 0.000058290686865802854,
        "seek": 45948,
        "start": 462.84000000000003,
        "temperature": 0,
        "text": " Did I use create?",
        "tokens": [
          50532,
          2589,
          286,
          764,
          1884,
          30,
          50568
        ]
      },
      {
        "avg_logprob": -0.3151137942359561,
        "compression_ratio": 1.8622222222222222,
        "end": 465.40000000000003,
        "id": 154,
        "no_speech_prob": 0.000058290686865802854,
        "seek": 45948,
        "start": 463.56,
        "temperature": 0,
        "text": " Yeah, I used create button, I guess.",
        "tokens": [
          50568,
          865,
          11,
          286,
          1143,
          1884,
          2960,
          11,
          286,
          2041,
          13,
          50660
        ]
      },
      {
        "avg_logprob": -0.3151137942359561,
        "compression_ratio": 1.8622222222222222,
        "end": 467.8,
        "id": 155,
        "no_speech_prob": 0.000058290686865802854,
        "seek": 45948,
        "start": 465.40000000000003,
        "temperature": 0,
        "text": " So I'm going to go into setup.",
        "tokens": [
          50660,
          407,
          286,
          478,
          516,
          281,
          352,
          666,
          8657,
          13,
          50780
        ]
      },
      {
        "avg_logprob": -0.3151137942359561,
        "compression_ratio": 1.8622222222222222,
        "end": 469.6,
        "id": 156,
        "no_speech_prob": 0.000058290686865802854,
        "seek": 45948,
        "start": 467.8,
        "temperature": 0,
        "text": " And I'm going to, I forgot if these are called",
        "tokens": [
          50780,
          400,
          286,
          478,
          516,
          281,
          11,
          286,
          5298,
          498,
          613,
          366,
          1219,
          50870
        ]
      },
      {
        "avg_logprob": -0.3151137942359561,
        "compression_ratio": 1.8622222222222222,
        "end": 474.12,
        "id": 157,
        "no_speech_prob": 0.000058290686865802854,
        "seek": 45948,
        "start": 469.6,
        "temperature": 0,
        "text": " yuke buttons and whistle buttons, because why not?",
        "tokens": [
          50870,
          288,
          2034,
          68,
          9905,
          293,
          23470,
          9905,
          11,
          570,
          983,
          406,
          30,
          51096
        ]
      },
      {
        "avg_logprob": -0.3151137942359561,
        "compression_ratio": 1.8622222222222222,
        "end": 479.72,
        "id": 158,
        "no_speech_prob": 0.000058290686865802854,
        "seek": 45948,
        "start": 474.12,
        "temperature": 0,
        "text": " I'm going to make a save button equals create button, save.",
        "tokens": [
          51096,
          286,
          478,
          516,
          281,
          652,
          257,
          3155,
          2960,
          6915,
          1884,
          2960,
          11,
          3155,
          13,
          51376
        ]
      },
      {
        "avg_logprob": -0.3151137942359561,
        "compression_ratio": 1.8622222222222222,
        "end": 484.32,
        "id": 159,
        "no_speech_prob": 0.000058290686865802854,
        "seek": 45948,
        "start": 479.72,
        "temperature": 0,
        "text": " Then I'm going to say save button dot mouse pressed.",
        "tokens": [
          51376,
          1396,
          286,
          478,
          516,
          281,
          584,
          3155,
          2960,
          5893,
          9719,
          17355,
          13,
          51606
        ]
      },
      {
        "avg_logprob": -0.3151137942359561,
        "compression_ratio": 1.8622222222222222,
        "end": 486.68,
        "id": 160,
        "no_speech_prob": 0.000058290686865802854,
        "seek": 45948,
        "start": 484.32,
        "temperature": 0,
        "text": " I'm going to put an anonymous function in here.",
        "tokens": [
          51606,
          286,
          478,
          516,
          281,
          829,
          364,
          24932,
          2445,
          294,
          510,
          13,
          51724
        ]
      },
      {
        "avg_logprob": -0.21772830550735062,
        "compression_ratio": 1.4242424242424243,
        "end": 491.68,
        "id": 161,
        "no_speech_prob": 0.00004133499169256538,
        "seek": 48668,
        "start": 486.68,
        "temperature": 0,
        "text": " And I am going to now say classifier dot save.",
        "tokens": [
          50364,
          400,
          286,
          669,
          516,
          281,
          586,
          584,
          1508,
          9902,
          5893,
          3155,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.21772830550735062,
        "compression_ratio": 1.4242424242424243,
        "end": 493.24,
        "id": 162,
        "no_speech_prob": 0.00004133499169256538,
        "seek": 48668,
        "start": 491.68,
        "temperature": 0,
        "text": " That's it.",
        "tokens": [
          50614,
          663,
          311,
          309,
          13,
          50692
        ]
      },
      {
        "avg_logprob": -0.21772830550735062,
        "compression_ratio": 1.4242424242424243,
        "end": 496.2,
        "id": 163,
        "no_speech_prob": 0.00004133499169256538,
        "seek": 48668,
        "start": 493.24,
        "temperature": 0,
        "text": " The classifier object, if you remember,",
        "tokens": [
          50692,
          440,
          1508,
          9902,
          2657,
          11,
          498,
          291,
          1604,
          11,
          50840
        ]
      },
      {
        "avg_logprob": -0.21772830550735062,
        "compression_ratio": 1.4242424242424243,
        "end": 503.96000000000004,
        "id": 164,
        "no_speech_prob": 0.00004133499169256538,
        "seek": 48668,
        "start": 496.2,
        "temperature": 0,
        "text": " is a classification object made from a feature extractor",
        "tokens": [
          50840,
          307,
          257,
          21538,
          2657,
          1027,
          490,
          257,
          4111,
          8947,
          284,
          51228
        ]
      },
      {
        "avg_logprob": -0.21772830550735062,
        "compression_ratio": 1.4242424242424243,
        "end": 506.2,
        "id": 165,
        "no_speech_prob": 0.00004133499169256538,
        "seek": 48668,
        "start": 503.96000000000004,
        "temperature": 0,
        "text": " from the MobileNet library.",
        "tokens": [
          51228,
          490,
          264,
          22625,
          31890,
          6405,
          13,
          51340
        ]
      },
      {
        "avg_logprob": -0.21772830550735062,
        "compression_ratio": 1.4242424242424243,
        "end": 508.76,
        "id": 166,
        "no_speech_prob": 0.00004133499169256538,
        "seek": 48668,
        "start": 506.2,
        "temperature": 0,
        "text": " Rattling mic.",
        "tokens": [
          51340,
          497,
          1591,
          1688,
          3123,
          13,
          51468
        ]
      },
      {
        "avg_logprob": -0.21772830550735062,
        "compression_ratio": 1.4242424242424243,
        "end": 509.56,
        "id": 167,
        "no_speech_prob": 0.00004133499169256538,
        "seek": 48668,
        "start": 508.76,
        "temperature": 0,
        "text": " Sorry, time out.",
        "tokens": [
          51468,
          4919,
          11,
          565,
          484,
          13,
          51508
        ]
      },
      {
        "avg_logprob": -0.21772830550735062,
        "compression_ratio": 1.4242424242424243,
        "end": 510.8,
        "id": 168,
        "no_speech_prob": 0.00004133499169256538,
        "seek": 48668,
        "start": 509.56,
        "temperature": 0,
        "text": " Is the mic a problem?",
        "tokens": [
          51508,
          1119,
          264,
          3123,
          257,
          1154,
          30,
          51570
        ]
      },
      {
        "avg_logprob": -0.521333578861121,
        "compression_ratio": 1.0759493670886076,
        "end": 530.04,
        "id": 169,
        "no_speech_prob": 0.00008218484435928985,
        "seek": 51668,
        "start": 516.68,
        "temperature": 0,
        "text": " Is this better now?",
        "tokens": [
          50364,
          1119,
          341,
          1101,
          586,
          30,
          51032
        ]
      },
      {
        "avg_logprob": -0.521333578861121,
        "compression_ratio": 1.0759493670886076,
        "end": 530.88,
        "id": 170,
        "no_speech_prob": 0.00008218484435928985,
        "seek": 51668,
        "start": 530.04,
        "temperature": 0,
        "text": " OK?",
        "tokens": [
          51032,
          2264,
          30,
          51074
        ]
      },
      {
        "avg_logprob": -0.521333578861121,
        "compression_ratio": 1.0759493670886076,
        "end": 532.4799999999999,
        "id": 171,
        "no_speech_prob": 0.00008218484435928985,
        "seek": 51668,
        "start": 530.88,
        "temperature": 0,
        "text": " Is the mic OK?",
        "tokens": [
          51074,
          1119,
          264,
          3123,
          2264,
          30,
          51154
        ]
      },
      {
        "avg_logprob": -0.521333578861121,
        "compression_ratio": 1.0759493670886076,
        "end": 534.4,
        "id": 172,
        "no_speech_prob": 0.00008218484435928985,
        "seek": 51668,
        "start": 532.4799999999999,
        "temperature": 0,
        "text": " I kind of want to start this video over again.",
        "tokens": [
          51154,
          286,
          733,
          295,
          528,
          281,
          722,
          341,
          960,
          670,
          797,
          13,
          51250
        ]
      },
      {
        "avg_logprob": -0.6497393467629603,
        "compression_ratio": 1.876923076923077,
        "end": 538.12,
        "id": 173,
        "no_speech_prob": 0.0001106079071178101,
        "seek": 53440,
        "start": 535.4,
        "temperature": 0,
        "text": " I just, I'm waiting before I keep going to see",
        "tokens": [
          50414,
          286,
          445,
          11,
          286,
          478,
          3806,
          949,
          286,
          1066,
          516,
          281,
          536,
          50550
        ]
      },
      {
        "avg_logprob": -0.6497393467629603,
        "compression_ratio": 1.876923076923077,
        "end": 539.12,
        "id": 174,
        "no_speech_prob": 0.0001106079071178101,
        "seek": 53440,
        "start": 538.12,
        "temperature": 0,
        "text": " that the sound is OK.",
        "tokens": [
          50550,
          300,
          264,
          1626,
          307,
          2264,
          13,
          50600
        ]
      },
      {
        "avg_logprob": -0.6497393467629603,
        "compression_ratio": 1.876923076923077,
        "end": 543.84,
        "id": 175,
        "no_speech_prob": 0.0001106079071178101,
        "seek": 53440,
        "start": 542.12,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          50750,
          1079,
          13,
          50836
        ]
      },
      {
        "avg_logprob": -0.6497393467629603,
        "compression_ratio": 1.876923076923077,
        "end": 546.36,
        "id": 176,
        "no_speech_prob": 0.0001106079071178101,
        "seek": 53440,
        "start": 543.84,
        "temperature": 0,
        "text": " 1, 2, 1, 2, my mic is clattering a lot.",
        "tokens": [
          50836,
          502,
          11,
          568,
          11,
          502,
          11,
          568,
          11,
          452,
          3123,
          307,
          596,
          14849,
          257,
          688,
          13,
          50962
        ]
      },
      {
        "avg_logprob": -0.6497393467629603,
        "compression_ratio": 1.876923076923077,
        "end": 547.68,
        "id": 177,
        "no_speech_prob": 0.0001106079071178101,
        "seek": 53440,
        "start": 546.36,
        "temperature": 0,
        "text": " Is it still clattering?",
        "tokens": [
          50962,
          1119,
          309,
          920,
          596,
          14849,
          30,
          51028
        ]
      },
      {
        "avg_logprob": -0.6497393467629603,
        "compression_ratio": 1.876923076923077,
        "end": 550.04,
        "id": 178,
        "no_speech_prob": 0.0001106079071178101,
        "seek": 53440,
        "start": 547.68,
        "temperature": 0,
        "text": " Maybe I better go back and redo this whole video.",
        "tokens": [
          51028,
          2704,
          286,
          1101,
          352,
          646,
          293,
          29956,
          341,
          1379,
          960,
          13,
          51146
        ]
      },
      {
        "avg_logprob": -0.6497393467629603,
        "compression_ratio": 1.876923076923077,
        "end": 553.1999999999999,
        "id": 179,
        "no_speech_prob": 0.0001106079071178101,
        "seek": 53440,
        "start": 550.04,
        "temperature": 0,
        "text": " Nothing would make me happier.",
        "tokens": [
          51146,
          6693,
          576,
          652,
          385,
          20423,
          13,
          51304
        ]
      },
      {
        "avg_logprob": -0.6497393467629603,
        "compression_ratio": 1.876923076923077,
        "end": 554.56,
        "id": 180,
        "no_speech_prob": 0.0001106079071178101,
        "seek": 53440,
        "start": 553.1999999999999,
        "temperature": 0,
        "text": " Let's actually see if this works.",
        "tokens": [
          51304,
          961,
          311,
          767,
          536,
          498,
          341,
          1985,
          13,
          51372
        ]
      },
      {
        "avg_logprob": -0.6497393467629603,
        "compression_ratio": 1.876923076923077,
        "end": 559.04,
        "id": 181,
        "no_speech_prob": 0.0001106079071178101,
        "seek": 53440,
        "start": 558.56,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51572,
          2264,
          13,
          51596
        ]
      },
      {
        "avg_logprob": -0.6497393467629603,
        "compression_ratio": 1.876923076923077,
        "end": 559.92,
        "id": 182,
        "no_speech_prob": 0.0001106079071178101,
        "seek": 53440,
        "start": 559.04,
        "temperature": 0,
        "text": " I think it's working.",
        "tokens": [
          51596,
          286,
          519,
          309,
          311,
          1364,
          13,
          51640
        ]
      },
      {
        "avg_logprob": -0.6497393467629603,
        "compression_ratio": 1.876923076923077,
        "end": 560.8,
        "id": 183,
        "no_speech_prob": 0.0001106079071178101,
        "seek": 53440,
        "start": 559.92,
        "temperature": 0,
        "text": " I think it's working.",
        "tokens": [
          51640,
          286,
          519,
          309,
          311,
          1364,
          13,
          51684
        ]
      },
      {
        "avg_logprob": -0.6497393467629603,
        "compression_ratio": 1.876923076923077,
        "end": 561.68,
        "id": 184,
        "no_speech_prob": 0.0001106079071178101,
        "seek": 53440,
        "start": 560.8,
        "temperature": 0,
        "text": " I think it's working.",
        "tokens": [
          51684,
          286,
          519,
          309,
          311,
          1364,
          13,
          51728
        ]
      },
      {
        "avg_logprob": -0.6497393467629603,
        "compression_ratio": 1.876923076923077,
        "end": 562.52,
        "id": 185,
        "no_speech_prob": 0.0001106079071178101,
        "seek": 53440,
        "start": 561.68,
        "temperature": 0,
        "text": " I think it's working.",
        "tokens": [
          51728,
          286,
          519,
          309,
          311,
          1364,
          13,
          51770
        ]
      },
      {
        "avg_logprob": -0.6497393467629603,
        "compression_ratio": 1.876923076923077,
        "end": 563.36,
        "id": 186,
        "no_speech_prob": 0.0001106079071178101,
        "seek": 53440,
        "start": 562.52,
        "temperature": 0,
        "text": " I think it's working.",
        "tokens": [
          51770,
          286,
          519,
          309,
          311,
          1364,
          13,
          51812
        ]
      },
      {
        "avg_logprob": -0.49513131481106,
        "compression_ratio": 1.312,
        "end": 565.84,
        "id": 187,
        "no_speech_prob": 0.00024533062241971493,
        "seek": 56336,
        "start": 564.36,
        "temperature": 0,
        "text": " While I'm here, I'm going to redo it.",
        "tokens": [
          50414,
          3987,
          286,
          478,
          510,
          11,
          286,
          478,
          516,
          281,
          29956,
          309,
          13,
          50488
        ]
      },
      {
        "avg_logprob": -0.49513131481106,
        "compression_ratio": 1.312,
        "end": 573.76,
        "id": 188,
        "no_speech_prob": 0.00024533062241971493,
        "seek": 56336,
        "start": 572.8000000000001,
        "temperature": 0,
        "text": " Classifier dot save.",
        "tokens": [
          50836,
          9471,
          9902,
          5893,
          3155,
          13,
          50884
        ]
      },
      {
        "avg_logprob": -0.49513131481106,
        "compression_ratio": 1.312,
        "end": 576.16,
        "id": 189,
        "no_speech_prob": 0.00024533062241971493,
        "seek": 56336,
        "start": 573.76,
        "temperature": 0,
        "text": " Oh, I forgot.",
        "tokens": [
          50884,
          876,
          11,
          286,
          5298,
          13,
          51004
        ]
      },
      {
        "avg_logprob": -0.49513131481106,
        "compression_ratio": 1.312,
        "end": 576.6800000000001,
        "id": 190,
        "no_speech_prob": 0.00024533062241971493,
        "seek": 56336,
        "start": 576.16,
        "temperature": 0,
        "text": " Great.",
        "tokens": [
          51004,
          3769,
          13,
          51030
        ]
      },
      {
        "avg_logprob": -0.49513131481106,
        "compression_ratio": 1.312,
        "end": 579,
        "id": 191,
        "no_speech_prob": 0.00024533062241971493,
        "seek": 56336,
        "start": 576.6800000000001,
        "temperature": 0,
        "text": " So this, I'm going to have this happen,",
        "tokens": [
          51030,
          407,
          341,
          11,
          286,
          478,
          516,
          281,
          362,
          341,
          1051,
          11,
          51146
        ]
      },
      {
        "avg_logprob": -0.49513131481106,
        "compression_ratio": 1.312,
        "end": 580.92,
        "id": 192,
        "no_speech_prob": 0.00024533062241971493,
        "seek": 56336,
        "start": 579,
        "temperature": 0,
        "text": " because I have to upgrade my version of ml5.",
        "tokens": [
          51146,
          570,
          286,
          362,
          281,
          11484,
          452,
          3037,
          295,
          23271,
          20,
          13,
          51242
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 596.36,
        "id": 193,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 593.36,
        "temperature": 0,
        "text": " Yep.",
        "tokens": [
          50364,
          7010,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 597.36,
        "id": 194,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 596.36,
        "temperature": 0,
        "text": " Great.",
        "tokens": [
          50514,
          3769,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 598.36,
        "id": 195,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 597.36,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50564,
          2264,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 599.36,
        "id": 196,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 598.36,
        "temperature": 0,
        "text": " So that worked.",
        "tokens": [
          50614,
          407,
          300,
          2732,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 600.36,
        "id": 197,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 599.36,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50664,
          2264,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 602.36,
        "id": 198,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 600.36,
        "temperature": 0,
        "text": " How do I tell it not to show the warnings?",
        "tokens": [
          50714,
          1012,
          360,
          286,
          980,
          309,
          406,
          281,
          855,
          264,
          30009,
          30,
          50814
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 603.36,
        "id": 199,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 602.36,
        "temperature": 0,
        "text": " Show.",
        "tokens": [
          50814,
          6895,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 605.36,
        "id": 200,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 603.36,
        "temperature": 0,
        "text": " Where's the preference for showing warnings?",
        "tokens": [
          50864,
          2305,
          311,
          264,
          17502,
          337,
          4099,
          30009,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 606.36,
        "id": 201,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 605.36,
        "temperature": 0,
        "text": " Oh, I see.",
        "tokens": [
          50964,
          876,
          11,
          286,
          536,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 607.36,
        "id": 202,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 606.36,
        "temperature": 0,
        "text": " I see.",
        "tokens": [
          51014,
          286,
          536,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 608.36,
        "id": 203,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 607.36,
        "temperature": 0,
        "text": " I see.",
        "tokens": [
          51064,
          286,
          536,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 609.36,
        "id": 204,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 608.36,
        "temperature": 0,
        "text": " I see.",
        "tokens": [
          51114,
          286,
          536,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 610.36,
        "id": 205,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 609.36,
        "temperature": 0,
        "text": " I see.",
        "tokens": [
          51164,
          286,
          536,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 611.36,
        "id": 206,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 610.36,
        "temperature": 0,
        "text": " I see.",
        "tokens": [
          51214,
          286,
          536,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 612.36,
        "id": 207,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 611.36,
        "temperature": 0,
        "text": " I see.",
        "tokens": [
          51264,
          286,
          536,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 613.36,
        "id": 208,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 612.36,
        "temperature": 0,
        "text": " I see.",
        "tokens": [
          51314,
          286,
          536,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 614.36,
        "id": 209,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 613.36,
        "temperature": 0,
        "text": " I see.",
        "tokens": [
          51364,
          286,
          536,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 615.36,
        "id": 210,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 614.36,
        "temperature": 0,
        "text": " I see.",
        "tokens": [
          51414,
          286,
          536,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 616.36,
        "id": 211,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 615.36,
        "temperature": 0,
        "text": " I see.",
        "tokens": [
          51464,
          286,
          536,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 617.36,
        "id": 212,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 616.36,
        "temperature": 0,
        "text": " I see.",
        "tokens": [
          51514,
          286,
          536,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 618.36,
        "id": 213,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 617.36,
        "temperature": 0,
        "text": " I see.",
        "tokens": [
          51564,
          286,
          536,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 619.36,
        "id": 214,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 618.36,
        "temperature": 0,
        "text": " I see.",
        "tokens": [
          51614,
          286,
          536,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 620.36,
        "id": 215,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 619.36,
        "temperature": 0,
        "text": " I see.",
        "tokens": [
          51664,
          286,
          536,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 621.36,
        "id": 216,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 620.36,
        "temperature": 0,
        "text": " I see.",
        "tokens": [
          51714,
          286,
          536,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 622.36,
        "id": 217,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 621.36,
        "temperature": 0,
        "text": " I see.",
        "tokens": [
          51764,
          286,
          536,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.37166153757195725,
        "compression_ratio": 1.5139664804469273,
        "end": 624.36,
        "id": 218,
        "no_speech_prob": 0.1847383826971054,
        "seek": 62236,
        "start": 622.36,
        "temperature": 0,
        "text": " Show warnings.",
        "tokens": [
          50364,
          6895,
          30009,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.37166153757195725,
        "compression_ratio": 1.5139664804469273,
        "end": 627.36,
        "id": 219,
        "no_speech_prob": 0.1847383826971054,
        "seek": 62236,
        "start": 624.36,
        "temperature": 0,
        "text": " Because I kind of would prefer not to see them, frankly.",
        "tokens": [
          50464,
          1436,
          286,
          733,
          295,
          576,
          4382,
          406,
          281,
          536,
          552,
          11,
          11939,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.37166153757195725,
        "compression_ratio": 1.5139664804469273,
        "end": 637.36,
        "id": 220,
        "no_speech_prob": 0.1847383826971054,
        "seek": 62236,
        "start": 630.36,
        "temperature": 0,
        "text": " High network, evaluation, preserve log, show warnings.",
        "tokens": [
          50764,
          5229,
          3209,
          11,
          308,
          46504,
          11,
          15665,
          3565,
          11,
          855,
          30009,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.37166153757195725,
        "compression_ratio": 1.5139664804469273,
        "end": 638.36,
        "id": 221,
        "no_speech_prob": 0.1847383826971054,
        "seek": 62236,
        "start": 637.36,
        "temperature": 0,
        "text": " Somebody will show me.",
        "tokens": [
          51114,
          13463,
          486,
          855,
          385,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.37166153757195725,
        "compression_ratio": 1.5139664804469273,
        "end": 644.36,
        "id": 222,
        "no_speech_prob": 0.1847383826971054,
        "seek": 62236,
        "start": 641.36,
        "temperature": 0,
        "text": " If anyone in the Slack channel could tell me how the mic is",
        "tokens": [
          51314,
          759,
          2878,
          294,
          264,
          37211,
          2269,
          727,
          980,
          385,
          577,
          264,
          3123,
          307,
          51464
        ]
      },
      {
        "avg_logprob": -0.37166153757195725,
        "compression_ratio": 1.5139664804469273,
        "end": 646.36,
        "id": 223,
        "no_speech_prob": 0.1847383826971054,
        "seek": 62236,
        "start": 644.36,
        "temperature": 0,
        "text": " going, I would really appreciate that.",
        "tokens": [
          51464,
          516,
          11,
          286,
          576,
          534,
          4449,
          300,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.37166153757195725,
        "compression_ratio": 1.5139664804469273,
        "end": 647.36,
        "id": 224,
        "no_speech_prob": 0.1847383826971054,
        "seek": 62236,
        "start": 646.36,
        "temperature": 0,
        "text": " Show warnings.",
        "tokens": [
          51564,
          6895,
          30009,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.37166153757195725,
        "compression_ratio": 1.5139664804469273,
        "end": 648.36,
        "id": 225,
        "no_speech_prob": 0.1847383826971054,
        "seek": 62236,
        "start": 647.36,
        "temperature": 0,
        "text": " Chrome.",
        "tokens": [
          51614,
          15327,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19616810306087956,
        "compression_ratio": 1.4275862068965517,
        "end": 655.36,
        "id": 226,
        "no_speech_prob": 0.010316010564565659,
        "seek": 65236,
        "start": 653.36,
        "temperature": 0,
        "text": " Hide warnings in the console window.",
        "tokens": [
          50414,
          35118,
          30009,
          294,
          264,
          11076,
          4910,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.19616810306087956,
        "compression_ratio": 1.4275862068965517,
        "end": 657.36,
        "id": 227,
        "no_speech_prob": 0.010316010564565659,
        "seek": 65236,
        "start": 655.36,
        "temperature": 0,
        "text": " Is there.",
        "tokens": [
          50514,
          1119,
          456,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19616810306087956,
        "compression_ratio": 1.4275862068965517,
        "end": 660.36,
        "id": 228,
        "no_speech_prob": 0.010316010564565659,
        "seek": 65236,
        "start": 657.36,
        "temperature": 0,
        "text": " Top filter, errors, level, warning.",
        "tokens": [
          50614,
          8840,
          6608,
          11,
          13603,
          11,
          1496,
          11,
          9164,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19616810306087956,
        "compression_ratio": 1.4275862068965517,
        "end": 661.36,
        "id": 229,
        "no_speech_prob": 0.010316010564565659,
        "seek": 65236,
        "start": 660.36,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50764,
          2264,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19616810306087956,
        "compression_ratio": 1.4275862068965517,
        "end": 662.36,
        "id": 230,
        "no_speech_prob": 0.010316010564565659,
        "seek": 65236,
        "start": 661.36,
        "temperature": 0,
        "text": " So it must be.",
        "tokens": [
          50814,
          407,
          309,
          1633,
          312,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19616810306087956,
        "compression_ratio": 1.4275862068965517,
        "end": 665.36,
        "id": 231,
        "no_speech_prob": 0.010316010564565659,
        "seek": 65236,
        "start": 662.36,
        "temperature": 0,
        "text": " Oh, I just don't see it here.",
        "tokens": [
          50864,
          876,
          11,
          286,
          445,
          500,
          380,
          536,
          309,
          510,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19616810306087956,
        "compression_ratio": 1.4275862068965517,
        "end": 668.36,
        "id": 232,
        "no_speech_prob": 0.010316010564565659,
        "seek": 65236,
        "start": 665.36,
        "temperature": 0,
        "text": " Because.",
        "tokens": [
          51014,
          1436,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19616810306087956,
        "compression_ratio": 1.4275862068965517,
        "end": 670.36,
        "id": 233,
        "no_speech_prob": 0.010316010564565659,
        "seek": 65236,
        "start": 668.36,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51164,
          821,
          321,
          352,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19616810306087956,
        "compression_ratio": 1.4275862068965517,
        "end": 671.36,
        "id": 234,
        "no_speech_prob": 0.010316010564565659,
        "seek": 65236,
        "start": 670.36,
        "temperature": 0,
        "text": " So let's.",
        "tokens": [
          51264,
          407,
          718,
          311,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19616810306087956,
        "compression_ratio": 1.4275862068965517,
        "end": 672.36,
        "id": 235,
        "no_speech_prob": 0.010316010564565659,
        "seek": 65236,
        "start": 671.36,
        "temperature": 0,
        "text": " Ah.",
        "tokens": [
          51314,
          2438,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19616810306087956,
        "compression_ratio": 1.4275862068965517,
        "end": 673.36,
        "id": 236,
        "no_speech_prob": 0.010316010564565659,
        "seek": 65236,
        "start": 672.36,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51364,
          821,
          321,
          352,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19616810306087956,
        "compression_ratio": 1.4275862068965517,
        "end": 674.36,
        "id": 237,
        "no_speech_prob": 0.010316010564565659,
        "seek": 65236,
        "start": 673.36,
        "temperature": 0,
        "text": " There it is.",
        "tokens": [
          51414,
          821,
          309,
          307,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19616810306087956,
        "compression_ratio": 1.4275862068965517,
        "end": 675.36,
        "id": 238,
        "no_speech_prob": 0.010316010564565659,
        "seek": 65236,
        "start": 674.36,
        "temperature": 0,
        "text": " Got that.",
        "tokens": [
          51464,
          5803,
          300,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19616810306087956,
        "compression_ratio": 1.4275862068965517,
        "end": 681.36,
        "id": 239,
        "no_speech_prob": 0.010316010564565659,
        "seek": 65236,
        "start": 680.36,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51764,
          2264,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.20562521616617838,
        "compression_ratio": 1.3624161073825503,
        "end": 683.36,
        "id": 240,
        "no_speech_prob": 0.004133427515625954,
        "seek": 68136,
        "start": 681.36,
        "temperature": 0,
        "text": " The mic quality is perfect now.",
        "tokens": [
          50364,
          440,
          3123,
          3125,
          307,
          2176,
          586,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.20562521616617838,
        "compression_ratio": 1.3624161073825503,
        "end": 684.36,
        "id": 241,
        "no_speech_prob": 0.004133427515625954,
        "seek": 68136,
        "start": 683.36,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50464,
          2264,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.20562521616617838,
        "compression_ratio": 1.3624161073825503,
        "end": 686.36,
        "id": 242,
        "no_speech_prob": 0.004133427515625954,
        "seek": 68136,
        "start": 684.36,
        "temperature": 0,
        "text": " Apologies to everyone, but just because there were some mic",
        "tokens": [
          50514,
          8723,
          6204,
          281,
          1518,
          11,
          457,
          445,
          570,
          456,
          645,
          512,
          3123,
          50614
        ]
      },
      {
        "avg_logprob": -0.20562521616617838,
        "compression_ratio": 1.3624161073825503,
        "end": 689.36,
        "id": 243,
        "no_speech_prob": 0.004133427515625954,
        "seek": 68136,
        "start": 686.36,
        "temperature": 0,
        "text": " issues, I'm going to start over.",
        "tokens": [
          50614,
          2663,
          11,
          286,
          478,
          516,
          281,
          722,
          670,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20562521616617838,
        "compression_ratio": 1.3624161073825503,
        "end": 692.36,
        "id": 244,
        "no_speech_prob": 0.004133427515625954,
        "seek": 68136,
        "start": 691.36,
        "temperature": 0,
        "text": " And.",
        "tokens": [
          50864,
          400,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20562521616617838,
        "compression_ratio": 1.3624161073825503,
        "end": 702.36,
        "id": 245,
        "no_speech_prob": 0.004133427515625954,
        "seek": 68136,
        "start": 699.36,
        "temperature": 0,
        "text": " So I'm actually going to do this.",
        "tokens": [
          51264,
          407,
          286,
          478,
          767,
          516,
          281,
          360,
          341,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20562521616617838,
        "compression_ratio": 1.3624161073825503,
        "end": 705.36,
        "id": 246,
        "no_speech_prob": 0.004133427515625954,
        "seek": 68136,
        "start": 702.36,
        "temperature": 0,
        "text": " And go back to here.",
        "tokens": [
          51414,
          400,
          352,
          646,
          281,
          510,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20562521616617838,
        "compression_ratio": 1.3624161073825503,
        "end": 706.36,
        "id": 247,
        "no_speech_prob": 0.004133427515625954,
        "seek": 68136,
        "start": 705.36,
        "temperature": 0,
        "text": " Take this out.",
        "tokens": [
          51564,
          3664,
          341,
          484,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.4759126334354795,
        "compression_ratio": 2.25,
        "end": 707.36,
        "id": 248,
        "no_speech_prob": 0.000245349743636325,
        "seek": 70636,
        "start": 706.36,
        "temperature": 0.2,
        "text": " And refresh.",
        "tokens": [
          50364,
          400,
          15134,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.4759126334354795,
        "compression_ratio": 2.25,
        "end": 708.36,
        "id": 249,
        "no_speech_prob": 0.000245349743636325,
        "seek": 70636,
        "start": 707.36,
        "temperature": 0.2,
        "text": " OK.",
        "tokens": [
          50414,
          2264,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.4759126334354795,
        "compression_ratio": 2.25,
        "end": 709.36,
        "id": 250,
        "no_speech_prob": 0.000245349743636325,
        "seek": 70636,
        "start": 708.36,
        "temperature": 0.2,
        "text": " All right.",
        "tokens": [
          50464,
          1057,
          558,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.4759126334354795,
        "compression_ratio": 2.25,
        "end": 710.36,
        "id": 251,
        "no_speech_prob": 0.000245349743636325,
        "seek": 70636,
        "start": 709.36,
        "temperature": 0.2,
        "text": " Here we go, everybody.",
        "tokens": [
          50514,
          1692,
          321,
          352,
          11,
          2201,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.4759126334354795,
        "compression_ratio": 2.25,
        "end": 713.36,
        "id": 252,
        "no_speech_prob": 0.000245349743636325,
        "seek": 70636,
        "start": 710.36,
        "temperature": 0.2,
        "text": " So I realize that some of you watching might not have actually",
        "tokens": [
          50564,
          407,
          286,
          4325,
          300,
          512,
          295,
          291,
          1976,
          1062,
          406,
          362,
          767,
          50714
        ]
      },
      {
        "avg_logprob": -0.4759126334354795,
        "compression_ratio": 2.25,
        "end": 715.36,
        "id": 253,
        "no_speech_prob": 0.000245349743636325,
        "seek": 70636,
        "start": 713.36,
        "temperature": 0.2,
        "text": " gone through this video tutorial.",
        "tokens": [
          50714,
          2780,
          807,
          341,
          960,
          7073,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.4759126334354795,
        "compression_ratio": 2.25,
        "end": 718.36,
        "id": 254,
        "no_speech_prob": 0.000245349743636325,
        "seek": 70636,
        "start": 715.36,
        "temperature": 0.2,
        "text": " The idea of ML5 might be totally new to you.",
        "tokens": [
          50814,
          440,
          1558,
          295,
          21601,
          20,
          1062,
          312,
          3879,
          777,
          281,
          291,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.4759126334354795,
        "compression_ratio": 2.25,
        "end": 721.36,
        "id": 255,
        "no_speech_prob": 0.000245349743636325,
        "seek": 70636,
        "start": 718.36,
        "temperature": 0.2,
        "text": " Just very briefly, ML5 is a beginner JavaScript, a beginner",
        "tokens": [
          50964,
          1449,
          588,
          10515,
          11,
          21601,
          20,
          307,
          257,
          22080,
          15778,
          11,
          257,
          22080,
          51114
        ]
      },
      {
        "avg_logprob": -0.4759126334354795,
        "compression_ratio": 2.25,
        "end": 722.36,
        "id": 256,
        "no_speech_prob": 0.000245349743636325,
        "seek": 70636,
        "start": 721.36,
        "temperature": 0.2,
        "text": " JavaScript library.",
        "tokens": [
          51114,
          15778,
          6405,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.4759126334354795,
        "compression_ratio": 2.25,
        "end": 725.36,
        "id": 257,
        "no_speech_prob": 0.000245349743636325,
        "seek": 70636,
        "start": 722.36,
        "temperature": 0.2,
        "text": " It's a library that's built for the web.",
        "tokens": [
          51164,
          467,
          311,
          257,
          6405,
          300,
          311,
          3094,
          337,
          264,
          3670,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.4759126334354795,
        "compression_ratio": 2.25,
        "end": 727.36,
        "id": 258,
        "no_speech_prob": 0.000245349743636325,
        "seek": 70636,
        "start": 725.36,
        "temperature": 0.2,
        "text": " It's a library that's built for the web.",
        "tokens": [
          51314,
          467,
          311,
          257,
          6405,
          300,
          311,
          3094,
          337,
          264,
          3670,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.4759126334354795,
        "compression_ratio": 2.25,
        "end": 729.36,
        "id": 259,
        "no_speech_prob": 0.000245349743636325,
        "seek": 70636,
        "start": 727.36,
        "temperature": 0.2,
        "text": " It's a library that's built for the web.",
        "tokens": [
          51414,
          467,
          311,
          257,
          6405,
          300,
          311,
          3094,
          337,
          264,
          3670,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.4759126334354795,
        "compression_ratio": 2.25,
        "end": 731.36,
        "id": 260,
        "no_speech_prob": 0.000245349743636325,
        "seek": 70636,
        "start": 729.36,
        "temperature": 0.2,
        "text": " It's a library that's built for the web.",
        "tokens": [
          51514,
          467,
          311,
          257,
          6405,
          300,
          311,
          3094,
          337,
          264,
          3670,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.4759126334354795,
        "compression_ratio": 2.25,
        "end": 733.36,
        "id": 261,
        "no_speech_prob": 0.000245349743636325,
        "seek": 70636,
        "start": 731.36,
        "temperature": 0.2,
        "text": " It's a library that's built for the web.",
        "tokens": [
          51614,
          467,
          311,
          257,
          6405,
          300,
          311,
          3094,
          337,
          264,
          3670,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.23039616040947022,
        "compression_ratio": 1.7065217391304348,
        "end": 736.36,
        "id": 262,
        "no_speech_prob": 0.06753785163164139,
        "seek": 73336,
        "start": 733.36,
        "temperature": 0.4,
        "text": " And ML5 is a beginner JavaScript, a beginner-friendly JavaScript",
        "tokens": [
          50364,
          400,
          21601,
          20,
          307,
          257,
          22080,
          15778,
          11,
          257,
          22080,
          12,
          22864,
          15778,
          50514
        ]
      },
      {
        "avg_logprob": -0.23039616040947022,
        "compression_ratio": 1.7065217391304348,
        "end": 738.36,
        "id": 263,
        "no_speech_prob": 0.06753785163164139,
        "seek": 73336,
        "start": 736.36,
        "temperature": 0.4,
        "text": " library for machine learning.",
        "tokens": [
          50514,
          6405,
          337,
          3479,
          2539,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.23039616040947022,
        "compression_ratio": 1.7065217391304348,
        "end": 741.36,
        "id": 264,
        "no_speech_prob": 0.06753785163164139,
        "seek": 73336,
        "start": 738.36,
        "temperature": 0.4,
        "text": " It's built on top of TensorFlow.js, which is an open source",
        "tokens": [
          50614,
          467,
          311,
          3094,
          322,
          1192,
          295,
          37624,
          13,
          25530,
          11,
          597,
          307,
          364,
          1269,
          4009,
          50764
        ]
      },
      {
        "avg_logprob": -0.23039616040947022,
        "compression_ratio": 1.7065217391304348,
        "end": 744.36,
        "id": 265,
        "no_speech_prob": 0.06753785163164139,
        "seek": 73336,
        "start": 741.36,
        "temperature": 0.4,
        "text": " machine learning library made by Google.",
        "tokens": [
          50764,
          3479,
          2539,
          6405,
          1027,
          538,
          3329,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.23039616040947022,
        "compression_ratio": 1.7065217391304348,
        "end": 748.36,
        "id": 266,
        "no_speech_prob": 0.06753785163164139,
        "seek": 73336,
        "start": 744.36,
        "temperature": 0.4,
        "text": " TensorFlow.js is a JavaScript port of TensorFlow, which is C++",
        "tokens": [
          50914,
          37624,
          13,
          25530,
          307,
          257,
          15778,
          2436,
          295,
          37624,
          11,
          597,
          307,
          383,
          25472,
          51114
        ]
      },
      {
        "avg_logprob": -0.23039616040947022,
        "compression_ratio": 1.7065217391304348,
        "end": 752.36,
        "id": 267,
        "no_speech_prob": 0.06753785163164139,
        "seek": 73336,
        "start": 748.36,
        "temperature": 0.4,
        "text": " and Python and, you know, that's about as far as I'm willing to",
        "tokens": [
          51114,
          293,
          15329,
          293,
          11,
          291,
          458,
          11,
          300,
          311,
          466,
          382,
          1400,
          382,
          286,
          478,
          4950,
          281,
          51314
        ]
      },
      {
        "avg_logprob": -0.23039616040947022,
        "compression_ratio": 1.7065217391304348,
        "end": 754.36,
        "id": 268,
        "no_speech_prob": 0.06753785163164139,
        "seek": 73336,
        "start": 752.36,
        "temperature": 0.4,
        "text": " go with that right now.",
        "tokens": [
          51314,
          352,
          365,
          300,
          558,
          586,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.23039616040947022,
        "compression_ratio": 1.7065217391304348,
        "end": 758.36,
        "id": 269,
        "no_speech_prob": 0.06753785163164139,
        "seek": 73336,
        "start": 754.36,
        "temperature": 0.4,
        "text": " And this series explains how image classification works with",
        "tokens": [
          51414,
          400,
          341,
          2638,
          13948,
          577,
          3256,
          21538,
          1985,
          365,
          51614
        ]
      },
      {
        "avg_logprob": -0.23039616040947022,
        "compression_ratio": 1.7065217391304348,
        "end": 761.36,
        "id": 270,
        "no_speech_prob": 0.06753785163164139,
        "seek": 73336,
        "start": 758.36,
        "temperature": 0.4,
        "text": " the pre-trained model and then how you can train your own model",
        "tokens": [
          51614,
          264,
          659,
          12,
          17227,
          2001,
          2316,
          293,
          550,
          577,
          291,
          393,
          3847,
          428,
          1065,
          2316,
          51764
        ]
      },
      {
        "avg_logprob": -0.21456251473262392,
        "compression_ratio": 1.5,
        "end": 763.36,
        "id": 271,
        "no_speech_prob": 0.0026729567907750607,
        "seek": 76136,
        "start": 761.36,
        "temperature": 0,
        "text": " on top of that.",
        "tokens": [
          50364,
          322,
          1192,
          295,
          300,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.21456251473262392,
        "compression_ratio": 1.5,
        "end": 765.36,
        "id": 272,
        "no_speech_prob": 0.0026729567907750607,
        "seek": 76136,
        "start": 763.36,
        "temperature": 0,
        "text": " So that's where I left off, but you could never save it.",
        "tokens": [
          50464,
          407,
          300,
          311,
          689,
          286,
          1411,
          766,
          11,
          457,
          291,
          727,
          1128,
          3155,
          309,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.21456251473262392,
        "compression_ratio": 1.5,
        "end": 768.36,
        "id": 273,
        "no_speech_prob": 0.0026729567907750607,
        "seek": 76136,
        "start": 765.36,
        "temperature": 0,
        "text": " So now, here we are.",
        "tokens": [
          50564,
          407,
          586,
          11,
          510,
          321,
          366,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.21456251473262392,
        "compression_ratio": 1.5,
        "end": 780.36,
        "id": 274,
        "no_speech_prob": 0.0026729567907750607,
        "seek": 76136,
        "start": 776.36,
        "temperature": 0,
        "text": " Hello and welcome to another beginner's guide to machine",
        "tokens": [
          51114,
          2425,
          293,
          2928,
          281,
          1071,
          22080,
          311,
          5934,
          281,
          3479,
          51314
        ]
      },
      {
        "avg_logprob": -0.21456251473262392,
        "compression_ratio": 1.5,
        "end": 782.36,
        "id": 275,
        "no_speech_prob": 0.0026729567907750607,
        "seek": 76136,
        "start": 780.36,
        "temperature": 0,
        "text": " learning with ML5.js video.",
        "tokens": [
          51314,
          2539,
          365,
          21601,
          20,
          13,
          25530,
          960,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.21456251473262392,
        "compression_ratio": 1.5,
        "end": 786.36,
        "id": 276,
        "no_speech_prob": 0.0026729567907750607,
        "seek": 76136,
        "start": 782.36,
        "temperature": 0,
        "text": " Now, in this video, something very exciting is going to happen.",
        "tokens": [
          51414,
          823,
          11,
          294,
          341,
          960,
          11,
          746,
          588,
          4670,
          307,
          516,
          281,
          1051,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.21456251473262392,
        "compression_ratio": 1.5,
        "end": 789.36,
        "id": 277,
        "no_speech_prob": 0.0026729567907750607,
        "seek": 76136,
        "start": 786.36,
        "temperature": 0,
        "text": " If you happened to watch all the previous videos a while ago",
        "tokens": [
          51614,
          759,
          291,
          2011,
          281,
          1159,
          439,
          264,
          3894,
          2145,
          257,
          1339,
          2057,
          51764
        ]
      },
      {
        "avg_logprob": -0.18518229228694263,
        "compression_ratio": 1.6643109540636043,
        "end": 792.36,
        "id": 278,
        "no_speech_prob": 0.007937764748930931,
        "seek": 78936,
        "start": 789.36,
        "temperature": 0,
        "text": " and you discovered this one new, a new feature has been added",
        "tokens": [
          50364,
          293,
          291,
          6941,
          341,
          472,
          777,
          11,
          257,
          777,
          4111,
          575,
          668,
          3869,
          50514
        ]
      },
      {
        "avg_logprob": -0.18518229228694263,
        "compression_ratio": 1.6643109540636043,
        "end": 797.36,
        "id": 279,
        "no_speech_prob": 0.007937764748930931,
        "seek": 78936,
        "start": 792.36,
        "temperature": 0,
        "text": " to ML5, the save load feature extractor with ML5 specs.",
        "tokens": [
          50514,
          281,
          21601,
          20,
          11,
          264,
          3155,
          3677,
          4111,
          8947,
          284,
          365,
          21601,
          20,
          27911,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.18518229228694263,
        "compression_ratio": 1.6643109540636043,
        "end": 799.36,
        "id": 280,
        "no_speech_prob": 0.007937764748930931,
        "seek": 78936,
        "start": 797.36,
        "temperature": 0,
        "text": " So you can find the pull request here if you want to see more",
        "tokens": [
          50764,
          407,
          291,
          393,
          915,
          264,
          2235,
          5308,
          510,
          498,
          291,
          528,
          281,
          536,
          544,
          50864
        ]
      },
      {
        "avg_logprob": -0.18518229228694263,
        "compression_ratio": 1.6643109540636043,
        "end": 801.36,
        "id": 281,
        "no_speech_prob": 0.007937764748930931,
        "seek": 78936,
        "start": 799.36,
        "temperature": 0,
        "text": " about how that was implemented.",
        "tokens": [
          50864,
          466,
          577,
          300,
          390,
          12270,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18518229228694263,
        "compression_ratio": 1.6643109540636043,
        "end": 804.36,
        "id": 282,
        "no_speech_prob": 0.007937764748930931,
        "seek": 78936,
        "start": 801.36,
        "temperature": 0,
        "text": " But the point of that is the following.",
        "tokens": [
          50964,
          583,
          264,
          935,
          295,
          300,
          307,
          264,
          3480,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18518229228694263,
        "compression_ratio": 1.6643109540636043,
        "end": 806.36,
        "id": 283,
        "no_speech_prob": 0.007937764748930931,
        "seek": 78936,
        "start": 804.36,
        "temperature": 0,
        "text": " Where I left off was this example.",
        "tokens": [
          51114,
          2305,
          286,
          1411,
          766,
          390,
          341,
          1365,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.18518229228694263,
        "compression_ratio": 1.6643109540636043,
        "end": 809.36,
        "id": 284,
        "no_speech_prob": 0.007937764748930931,
        "seek": 78936,
        "start": 806.36,
        "temperature": 0,
        "text": " This is an example that loads a pre-trained image classifier",
        "tokens": [
          51214,
          639,
          307,
          364,
          1365,
          300,
          12668,
          257,
          659,
          12,
          17227,
          2001,
          3256,
          1508,
          9902,
          51364
        ]
      },
      {
        "avg_logprob": -0.18518229228694263,
        "compression_ratio": 1.6643109540636043,
        "end": 812.36,
        "id": 285,
        "no_speech_prob": 0.007937764748930931,
        "seek": 78936,
        "start": 809.36,
        "temperature": 0,
        "text": " called MobileNet, something that was trained by somebody else,",
        "tokens": [
          51364,
          1219,
          22625,
          31890,
          11,
          746,
          300,
          390,
          8895,
          538,
          2618,
          1646,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.18518229228694263,
        "compression_ratio": 1.6643109540636043,
        "end": 816.36,
        "id": 286,
        "no_speech_prob": 0.007937764748930931,
        "seek": 78936,
        "start": 812.36,
        "temperature": 0,
        "text": " explained in my previous videos, and allows the user, allows",
        "tokens": [
          51514,
          8825,
          294,
          452,
          3894,
          2145,
          11,
          293,
          4045,
          264,
          4195,
          11,
          4045,
          51714
        ]
      },
      {
        "avg_logprob": -0.2404776367486692,
        "compression_ratio": 1.6391304347826088,
        "end": 821.36,
        "id": 287,
        "no_speech_prob": 0.005554649513214827,
        "seek": 81636,
        "start": 816.36,
        "temperature": 0,
        "text": " the coder to use a process known as transfer learning to extract",
        "tokens": [
          50364,
          264,
          17656,
          260,
          281,
          764,
          257,
          1399,
          2570,
          382,
          5003,
          2539,
          281,
          8947,
          50614
        ]
      },
      {
        "avg_logprob": -0.2404776367486692,
        "compression_ratio": 1.6391304347826088,
        "end": 826.36,
        "id": 288,
        "no_speech_prob": 0.005554649513214827,
        "seek": 81636,
        "start": 821.36,
        "temperature": 0,
        "text": " the features that the model detects in an image and reassign",
        "tokens": [
          50614,
          264,
          4122,
          300,
          264,
          2316,
          5531,
          82,
          294,
          364,
          3256,
          293,
          19486,
          788,
          50864
        ]
      },
      {
        "avg_logprob": -0.2404776367486692,
        "compression_ratio": 1.6391304347826088,
        "end": 827.36,
        "id": 289,
        "no_speech_prob": 0.005554649513214827,
        "seek": 81636,
        "start": 826.36,
        "temperature": 0,
        "text": " them to new labels.",
        "tokens": [
          50864,
          552,
          281,
          777,
          16949,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2404776367486692,
        "compression_ratio": 1.6391304347826088,
        "end": 832.36,
        "id": 290,
        "no_speech_prob": 0.005554649513214827,
        "seek": 81636,
        "start": 827.36,
        "temperature": 0,
        "text": " So, for example, I can make a very happy face and click on happy",
        "tokens": [
          50914,
          407,
          11,
          337,
          1365,
          11,
          286,
          393,
          652,
          257,
          588,
          2055,
          1851,
          293,
          2052,
          322,
          2055,
          51164
        ]
      },
      {
        "avg_logprob": -0.2404776367486692,
        "compression_ratio": 1.6391304347826088,
        "end": 838.36,
        "id": 291,
        "no_speech_prob": 0.005554649513214827,
        "seek": 81636,
        "start": 832.36,
        "temperature": 0,
        "text": " a bunch of times and wonder why my Mac is showing that weird window.",
        "tokens": [
          51164,
          257,
          3840,
          295,
          1413,
          293,
          2441,
          983,
          452,
          5707,
          307,
          4099,
          300,
          3657,
          4910,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2404776367486692,
        "compression_ratio": 1.6391304347826088,
        "end": 843.36,
        "id": 292,
        "no_speech_prob": 0.005554649513214827,
        "seek": 81636,
        "start": 838.36,
        "temperature": 0,
        "text": " And then I could add a bunch of times and then click train.",
        "tokens": [
          51464,
          400,
          550,
          286,
          727,
          909,
          257,
          3840,
          295,
          1413,
          293,
          550,
          2052,
          3847,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2404776367486692,
        "compression_ratio": 1.6391304347826088,
        "end": 845.36,
        "id": 293,
        "no_speech_prob": 0.005554649513214827,
        "seek": 81636,
        "start": 843.36,
        "temperature": 0,
        "text": " And now we have to wait for a minute.",
        "tokens": [
          51714,
          400,
          586,
          321,
          362,
          281,
          1699,
          337,
          257,
          3456,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19619976744359854,
        "compression_ratio": 1.6307692307692307,
        "end": 848.36,
        "id": 294,
        "no_speech_prob": 0.00011591867951210588,
        "seek": 84536,
        "start": 845.36,
        "temperature": 0,
        "text": " We always blow the train whistle for train.",
        "tokens": [
          50364,
          492,
          1009,
          6327,
          264,
          3847,
          23470,
          337,
          3847,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.19619976744359854,
        "compression_ratio": 1.6307692307692307,
        "end": 850.36,
        "id": 295,
        "no_speech_prob": 0.00011591867951210588,
        "seek": 84536,
        "start": 848.36,
        "temperature": 0,
        "text": " And now the training is complete.",
        "tokens": [
          50514,
          400,
          586,
          264,
          3097,
          307,
          3566,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19619976744359854,
        "compression_ratio": 1.6307692307692307,
        "end": 855.36,
        "id": 296,
        "no_speech_prob": 0.00011591867951210588,
        "seek": 84536,
        "start": 850.36,
        "temperature": 0,
        "text": " And I go, hi.",
        "tokens": [
          50614,
          400,
          286,
          352,
          11,
          4879,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19619976744359854,
        "compression_ratio": 1.6307692307692307,
        "end": 856.36,
        "id": 297,
        "no_speech_prob": 0.00011591867951210588,
        "seek": 84536,
        "start": 855.36,
        "temperature": 0,
        "text": " Let me go back and do this again.",
        "tokens": [
          50864,
          961,
          385,
          352,
          646,
          293,
          360,
          341,
          797,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19619976744359854,
        "compression_ratio": 1.6307692307692307,
        "end": 860.36,
        "id": 298,
        "no_speech_prob": 0.00011591867951210588,
        "seek": 84536,
        "start": 856.36,
        "temperature": 0,
        "text": " It's really bothering me that this clicking on this is like,",
        "tokens": [
          50914,
          467,
          311,
          534,
          31432,
          385,
          300,
          341,
          9697,
          322,
          341,
          307,
          411,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.19619976744359854,
        "compression_ratio": 1.6307692307692307,
        "end": 861.36,
        "id": 299,
        "no_speech_prob": 0.00011591867951210588,
        "seek": 84536,
        "start": 860.36,
        "temperature": 0,
        "text": " was pulling that thing up.",
        "tokens": [
          51114,
          390,
          8407,
          300,
          551,
          493,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19619976744359854,
        "compression_ratio": 1.6307692307692307,
        "end": 866.36,
        "id": 300,
        "no_speech_prob": 0.00011591867951210588,
        "seek": 84536,
        "start": 861.36,
        "temperature": 0,
        "text": " It's because I'm selecting the text.",
        "tokens": [
          51164,
          467,
          311,
          570,
          286,
          478,
          18182,
          264,
          2487,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19619976744359854,
        "compression_ratio": 1.6307692307692307,
        "end": 870.36,
        "id": 301,
        "no_speech_prob": 0.00011591867951210588,
        "seek": 84536,
        "start": 866.36,
        "temperature": 0,
        "text": " I'm going to get this.",
        "tokens": [
          51414,
          286,
          478,
          516,
          281,
          483,
          341,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19619976744359854,
        "compression_ratio": 1.6307692307692307,
        "end": 872.36,
        "id": 302,
        "no_speech_prob": 0.00011591867951210588,
        "seek": 84536,
        "start": 870.36,
        "temperature": 0,
        "text": " And I'm kind of standing in front of it too.",
        "tokens": [
          51614,
          400,
          286,
          478,
          733,
          295,
          4877,
          294,
          1868,
          295,
          309,
          886,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.24742116530736288,
        "compression_ratio": 1.638095238095238,
        "end": 876.36,
        "id": 303,
        "no_speech_prob": 0.0015978305600583553,
        "seek": 87236,
        "start": 872.36,
        "temperature": 0,
        "text": " So with this example, I can make a happy face and click happy.",
        "tokens": [
          50364,
          407,
          365,
          341,
          1365,
          11,
          286,
          393,
          652,
          257,
          2055,
          1851,
          293,
          2052,
          2055,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.24742116530736288,
        "compression_ratio": 1.638095238095238,
        "end": 880.36,
        "id": 304,
        "no_speech_prob": 0.0015978305600583553,
        "seek": 87236,
        "start": 876.36,
        "temperature": 0,
        "text": " This is me giving it a bunch of examples of me being happy.",
        "tokens": [
          50564,
          639,
          307,
          385,
          2902,
          309,
          257,
          3840,
          295,
          5110,
          295,
          385,
          885,
          2055,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.24742116530736288,
        "compression_ratio": 1.638095238095238,
        "end": 886.36,
        "id": 305,
        "no_speech_prob": 0.0015978305600583553,
        "seek": 87236,
        "start": 880.36,
        "temperature": 0,
        "text": " And then we bring it down.",
        "tokens": [
          50764,
          400,
          550,
          321,
          1565,
          309,
          760,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.24742116530736288,
        "compression_ratio": 1.638095238095238,
        "end": 888.36,
        "id": 306,
        "no_speech_prob": 0.0015978305600583553,
        "seek": 87236,
        "start": 886.36,
        "temperature": 0,
        "text": " Now I can press the train button.",
        "tokens": [
          51064,
          823,
          286,
          393,
          1886,
          264,
          3847,
          2960,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.24742116530736288,
        "compression_ratio": 1.638095238095238,
        "end": 890.36,
        "id": 307,
        "no_speech_prob": 0.0015978305600583553,
        "seek": 87236,
        "start": 888.36,
        "temperature": 0,
        "text": " It is training.",
        "tokens": [
          51164,
          467,
          307,
          3097,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.24742116530736288,
        "compression_ratio": 1.638095238095238,
        "end": 894.36,
        "id": 308,
        "no_speech_prob": 0.0015978305600583553,
        "seek": 87236,
        "start": 890.36,
        "temperature": 0,
        "text": " And now that it has finished training, it will recognize,",
        "tokens": [
          51264,
          400,
          586,
          300,
          309,
          575,
          4335,
          3097,
          11,
          309,
          486,
          5521,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.24742116530736288,
        "compression_ratio": 1.638095238095238,
        "end": 899.36,
        "id": 309,
        "no_speech_prob": 0.0015978305600583553,
        "seek": 87236,
        "start": 894.36,
        "temperature": 0,
        "text": " it will determine if the webcam is showing an image that looks more",
        "tokens": [
          51464,
          309,
          486,
          6997,
          498,
          264,
          39490,
          307,
          4099,
          364,
          3256,
          300,
          1542,
          544,
          51714
        ]
      },
      {
        "avg_logprob": -0.24742116530736288,
        "compression_ratio": 1.638095238095238,
        "end": 900.36,
        "id": 310,
        "no_speech_prob": 0.0015978305600583553,
        "seek": 87236,
        "start": 899.36,
        "temperature": 0,
        "text": " like happy or sad.",
        "tokens": [
          51714,
          411,
          2055,
          420,
          4227,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1855572762249185,
        "compression_ratio": 1.718146718146718,
        "end": 904.36,
        "id": 311,
        "no_speech_prob": 0.0003982106572948396,
        "seek": 90036,
        "start": 901.36,
        "temperature": 0,
        "text": " Happy, sad.",
        "tokens": [
          50414,
          8277,
          11,
          4227,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1855572762249185,
        "compression_ratio": 1.718146718146718,
        "end": 907.36,
        "id": 312,
        "no_speech_prob": 0.0003982106572948396,
        "seek": 90036,
        "start": 904.36,
        "temperature": 0,
        "text": " Happy, sad.",
        "tokens": [
          50564,
          8277,
          11,
          4227,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1855572762249185,
        "compression_ratio": 1.718146718146718,
        "end": 908.36,
        "id": 313,
        "no_speech_prob": 0.0003982106572948396,
        "seek": 90036,
        "start": 907.36,
        "temperature": 0,
        "text": " Happy.",
        "tokens": [
          50714,
          8277,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1855572762249185,
        "compression_ratio": 1.718146718146718,
        "end": 910.36,
        "id": 314,
        "no_speech_prob": 0.0003982106572948396,
        "seek": 90036,
        "start": 908.36,
        "temperature": 0,
        "text": " Okay, so that's what the example did before.",
        "tokens": [
          50764,
          1033,
          11,
          370,
          300,
          311,
          437,
          264,
          1365,
          630,
          949,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1855572762249185,
        "compression_ratio": 1.718146718146718,
        "end": 914.36,
        "id": 315,
        "no_speech_prob": 0.0003982106572948396,
        "seek": 90036,
        "start": 910.36,
        "temperature": 0,
        "text": " If you're still watching, what the problem with this example is,",
        "tokens": [
          50864,
          759,
          291,
          434,
          920,
          1976,
          11,
          437,
          264,
          1154,
          365,
          341,
          1365,
          307,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.1855572762249185,
        "compression_ratio": 1.718146718146718,
        "end": 917.36,
        "id": 316,
        "no_speech_prob": 0.0003982106572948396,
        "seek": 90036,
        "start": 914.36,
        "temperature": 0,
        "text": " if I hit refresh, it's gone.",
        "tokens": [
          51064,
          498,
          286,
          2045,
          15134,
          11,
          309,
          311,
          2780,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1855572762249185,
        "compression_ratio": 1.718146718146718,
        "end": 919.36,
        "id": 317,
        "no_speech_prob": 0.0003982106572948396,
        "seek": 90036,
        "start": 917.36,
        "temperature": 0,
        "text": " It needs to be trained again.",
        "tokens": [
          51214,
          467,
          2203,
          281,
          312,
          8895,
          797,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1855572762249185,
        "compression_ratio": 1.718146718146718,
        "end": 921.36,
        "id": 318,
        "no_speech_prob": 0.0003982106572948396,
        "seek": 90036,
        "start": 919.36,
        "temperature": 0,
        "text": " So what I want to show in this video, and boy, it's taking me a long time",
        "tokens": [
          51314,
          407,
          437,
          286,
          528,
          281,
          855,
          294,
          341,
          960,
          11,
          293,
          3237,
          11,
          309,
          311,
          1940,
          385,
          257,
          938,
          565,
          51414
        ]
      },
      {
        "avg_logprob": -0.1855572762249185,
        "compression_ratio": 1.718146718146718,
        "end": 923.36,
        "id": 319,
        "no_speech_prob": 0.0003982106572948396,
        "seek": 90036,
        "start": 921.36,
        "temperature": 0,
        "text": " to get to it, is how to save.",
        "tokens": [
          51414,
          281,
          483,
          281,
          309,
          11,
          307,
          577,
          281,
          3155,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1855572762249185,
        "compression_ratio": 1.718146718146718,
        "end": 925.36,
        "id": 320,
        "no_speech_prob": 0.0003982106572948396,
        "seek": 90036,
        "start": 923.36,
        "temperature": 0,
        "text": " And really, there's just two functions we're going to add here,",
        "tokens": [
          51514,
          400,
          534,
          11,
          456,
          311,
          445,
          732,
          6828,
          321,
          434,
          516,
          281,
          909,
          510,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.1855572762249185,
        "compression_ratio": 1.718146718146718,
        "end": 927.36,
        "id": 321,
        "no_speech_prob": 0.0003982106572948396,
        "seek": 90036,
        "start": 925.36,
        "temperature": 0,
        "text": " save function and a load function.",
        "tokens": [
          51614,
          3155,
          2445,
          293,
          257,
          3677,
          2445,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1855572762249185,
        "compression_ratio": 1.718146718146718,
        "end": 929.36,
        "id": 322,
        "no_speech_prob": 0.0003982106572948396,
        "seek": 90036,
        "start": 927.36,
        "temperature": 0,
        "text": " So I'm starting with the code from before.",
        "tokens": [
          51714,
          407,
          286,
          478,
          2891,
          365,
          264,
          3089,
          490,
          949,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.18058897930642834,
        "compression_ratio": 1.7261904761904763,
        "end": 931.36,
        "id": 323,
        "no_speech_prob": 0.0008558881818316877,
        "seek": 92936,
        "start": 929.36,
        "temperature": 0,
        "text": " And I'm going to go into setup.",
        "tokens": [
          50364,
          400,
          286,
          478,
          516,
          281,
          352,
          666,
          8657,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.18058897930642834,
        "compression_ratio": 1.7261904761904763,
        "end": 935.36,
        "id": 324,
        "no_speech_prob": 0.0008558881818316877,
        "seek": 92936,
        "start": 931.36,
        "temperature": 0,
        "text": " And this is where I made the buttons for sad and happy and train.",
        "tokens": [
          50464,
          400,
          341,
          307,
          689,
          286,
          1027,
          264,
          9905,
          337,
          4227,
          293,
          2055,
          293,
          3847,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.18058897930642834,
        "compression_ratio": 1.7261904761904763,
        "end": 938.36,
        "id": 325,
        "no_speech_prob": 0.0008558881818316877,
        "seek": 92936,
        "start": 935.36,
        "temperature": 0,
        "text": " I gave them weird variable names which don't have any meaning anymore.",
        "tokens": [
          50664,
          286,
          2729,
          552,
          3657,
          7006,
          5288,
          597,
          500,
          380,
          362,
          604,
          3620,
          3602,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.18058897930642834,
        "compression_ratio": 1.7261904761904763,
        "end": 942.36,
        "id": 326,
        "no_speech_prob": 0.0008558881818316877,
        "seek": 92936,
        "start": 938.36,
        "temperature": 0,
        "text": " But I'm going to make a new button called save button equals create button.",
        "tokens": [
          50814,
          583,
          286,
          478,
          516,
          281,
          652,
          257,
          777,
          2960,
          1219,
          3155,
          2960,
          6915,
          1884,
          2960,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18058897930642834,
        "compression_ratio": 1.7261904761904763,
        "end": 944.36,
        "id": 327,
        "no_speech_prob": 0.0008558881818316877,
        "seek": 92936,
        "start": 942.36,
        "temperature": 0,
        "text": " Save.",
        "tokens": [
          51014,
          15541,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18058897930642834,
        "compression_ratio": 1.7261904761904763,
        "end": 948.36,
        "id": 328,
        "no_speech_prob": 0.0008558881818316877,
        "seek": 92936,
        "start": 944.36,
        "temperature": 0,
        "text": " I guess I should make this a global variable just to be consistent.",
        "tokens": [
          51114,
          286,
          2041,
          286,
          820,
          652,
          341,
          257,
          4338,
          7006,
          445,
          281,
          312,
          8398,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18058897930642834,
        "compression_ratio": 1.7261904761904763,
        "end": 950.36,
        "id": 329,
        "no_speech_prob": 0.0008558881818316877,
        "seek": 92936,
        "start": 948.36,
        "temperature": 0,
        "text": " That might be unnecessary.",
        "tokens": [
          51314,
          663,
          1062,
          312,
          19350,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18058897930642834,
        "compression_ratio": 1.7261904761904763,
        "end": 956.36,
        "id": 330,
        "no_speech_prob": 0.0008558881818316877,
        "seek": 92936,
        "start": 950.36,
        "temperature": 0,
        "text": " And then I'm going to add a function to handle the event",
        "tokens": [
          51414,
          400,
          550,
          286,
          478,
          516,
          281,
          909,
          257,
          2445,
          281,
          4813,
          264,
          2280,
          51714
        ]
      },
      {
        "avg_logprob": -0.18058897930642834,
        "compression_ratio": 1.7261904761904763,
        "end": 958.36,
        "id": 331,
        "no_speech_prob": 0.0008558881818316877,
        "seek": 92936,
        "start": 956.36,
        "temperature": 0,
        "text": " when the save button is pressed.",
        "tokens": [
          51714,
          562,
          264,
          3155,
          2960,
          307,
          17355,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1405218603776738,
        "compression_ratio": 1.9528985507246377,
        "end": 960.36,
        "id": 332,
        "no_speech_prob": 0.0033243780490010977,
        "seek": 95836,
        "start": 958.36,
        "temperature": 0,
        "text": " So what do I need to do when the save button is pressed?",
        "tokens": [
          50364,
          407,
          437,
          360,
          286,
          643,
          281,
          360,
          562,
          264,
          3155,
          2960,
          307,
          17355,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.1405218603776738,
        "compression_ratio": 1.9528985507246377,
        "end": 961.36,
        "id": 333,
        "no_speech_prob": 0.0033243780490010977,
        "seek": 95836,
        "start": 960.36,
        "temperature": 0,
        "text": " Guess what?",
        "tokens": [
          50464,
          17795,
          437,
          30,
          50514
        ]
      },
      {
        "avg_logprob": -0.1405218603776738,
        "compression_ratio": 1.9528985507246377,
        "end": 962.36,
        "id": 334,
        "no_speech_prob": 0.0033243780490010977,
        "seek": 95836,
        "start": 961.36,
        "temperature": 0,
        "text": " This is super simple.",
        "tokens": [
          50514,
          639,
          307,
          1687,
          2199,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1405218603776738,
        "compression_ratio": 1.9528985507246377,
        "end": 965.36,
        "id": 335,
        "no_speech_prob": 0.0033243780490010977,
        "seek": 95836,
        "start": 962.36,
        "temperature": 0,
        "text": " All I need to do is say classifier.save.",
        "tokens": [
          50564,
          1057,
          286,
          643,
          281,
          360,
          307,
          584,
          1508,
          9902,
          13,
          82,
          946,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1405218603776738,
        "compression_ratio": 1.9528985507246377,
        "end": 967.36,
        "id": 336,
        "no_speech_prob": 0.0033243780490010977,
        "seek": 95836,
        "start": 965.36,
        "temperature": 0,
        "text": " I'm just saying classifier.save.",
        "tokens": [
          50714,
          286,
          478,
          445,
          1566,
          1508,
          9902,
          13,
          82,
          946,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1405218603776738,
        "compression_ratio": 1.9528985507246377,
        "end": 968.36,
        "id": 337,
        "no_speech_prob": 0.0033243780490010977,
        "seek": 95836,
        "start": 967.36,
        "temperature": 0,
        "text": " Now what's going to happen there?",
        "tokens": [
          50814,
          823,
          437,
          311,
          516,
          281,
          1051,
          456,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.1405218603776738,
        "compression_ratio": 1.9528985507246377,
        "end": 969.36,
        "id": 338,
        "no_speech_prob": 0.0033243780490010977,
        "seek": 95836,
        "start": 968.36,
        "temperature": 0,
        "text": " Let's wait and see.",
        "tokens": [
          50864,
          961,
          311,
          1699,
          293,
          536,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1405218603776738,
        "compression_ratio": 1.9528985507246377,
        "end": 971.36,
        "id": 339,
        "no_speech_prob": 0.0033243780490010977,
        "seek": 95836,
        "start": 969.36,
        "temperature": 0,
        "text": " So I'm going to go here.",
        "tokens": [
          50914,
          407,
          286,
          478,
          516,
          281,
          352,
          510,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1405218603776738,
        "compression_ratio": 1.9528985507246377,
        "end": 973.36,
        "id": 340,
        "no_speech_prob": 0.0033243780490010977,
        "seek": 95836,
        "start": 971.36,
        "temperature": 0,
        "text": " I'm going to, oh, look, the save button is there.",
        "tokens": [
          51014,
          286,
          478,
          516,
          281,
          11,
          1954,
          11,
          574,
          11,
          264,
          3155,
          2960,
          307,
          456,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1405218603776738,
        "compression_ratio": 1.9528985507246377,
        "end": 975.36,
        "id": 341,
        "no_speech_prob": 0.0033243780490010977,
        "seek": 95836,
        "start": 973.36,
        "temperature": 0,
        "text": " I'm going to be happy.",
        "tokens": [
          51114,
          286,
          478,
          516,
          281,
          312,
          2055,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1405218603776738,
        "compression_ratio": 1.9528985507246377,
        "end": 976.36,
        "id": 342,
        "no_speech_prob": 0.0033243780490010977,
        "seek": 95836,
        "start": 975.36,
        "temperature": 0,
        "text": " I'm going to be sad.",
        "tokens": [
          51214,
          286,
          478,
          516,
          281,
          312,
          4227,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1405218603776738,
        "compression_ratio": 1.9528985507246377,
        "end": 978.36,
        "id": 343,
        "no_speech_prob": 0.0033243780490010977,
        "seek": 95836,
        "start": 976.36,
        "temperature": 0,
        "text": " I'm going to train.",
        "tokens": [
          51264,
          286,
          478,
          516,
          281,
          3847,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1405218603776738,
        "compression_ratio": 1.9528985507246377,
        "end": 980.36,
        "id": 344,
        "no_speech_prob": 0.0033243780490010977,
        "seek": 95836,
        "start": 978.36,
        "temperature": 0,
        "text": " Then I have to wait for it to finish training.",
        "tokens": [
          51364,
          1396,
          286,
          362,
          281,
          1699,
          337,
          309,
          281,
          2413,
          3097,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1405218603776738,
        "compression_ratio": 1.9528985507246377,
        "end": 982.36,
        "id": 345,
        "no_speech_prob": 0.0033243780490010977,
        "seek": 95836,
        "start": 980.36,
        "temperature": 0,
        "text": " Once it's done, I'm going to hit save.",
        "tokens": [
          51464,
          3443,
          309,
          311,
          1096,
          11,
          286,
          478,
          516,
          281,
          2045,
          3155,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1405218603776738,
        "compression_ratio": 1.9528985507246377,
        "end": 983.36,
        "id": 346,
        "no_speech_prob": 0.0033243780490010977,
        "seek": 95836,
        "start": 982.36,
        "temperature": 0,
        "text": " And guess what?",
        "tokens": [
          51564,
          400,
          2041,
          437,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.1405218603776738,
        "compression_ratio": 1.9528985507246377,
        "end": 984.36,
        "id": 347,
        "no_speech_prob": 0.0033243780490010977,
        "seek": 95836,
        "start": 983.36,
        "temperature": 0,
        "text": " I got an error.",
        "tokens": [
          51614,
          286,
          658,
          364,
          6713,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1405218603776738,
        "compression_ratio": 1.9528985507246377,
        "end": 985.36,
        "id": 348,
        "no_speech_prob": 0.0033243780490010977,
        "seek": 95836,
        "start": 984.36,
        "temperature": 0,
        "text": " Save is not a function.",
        "tokens": [
          51664,
          15541,
          307,
          406,
          257,
          2445,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1405218603776738,
        "compression_ratio": 1.9528985507246377,
        "end": 987.36,
        "id": 349,
        "no_speech_prob": 0.0033243780490010977,
        "seek": 95836,
        "start": 985.36,
        "temperature": 0,
        "text": " So I left this error happen on purpose.",
        "tokens": [
          51714,
          407,
          286,
          1411,
          341,
          6713,
          1051,
          322,
          4334,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1348087101766508,
        "compression_ratio": 1.59765625,
        "end": 989.36,
        "id": 350,
        "no_speech_prob": 0.008187683299183846,
        "seek": 98736,
        "start": 987.36,
        "temperature": 0,
        "text": " This is a new feature of the ml5 library.",
        "tokens": [
          50364,
          639,
          307,
          257,
          777,
          4111,
          295,
          264,
          23271,
          20,
          6405,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1348087101766508,
        "compression_ratio": 1.59765625,
        "end": 992.36,
        "id": 351,
        "no_speech_prob": 0.008187683299183846,
        "seek": 98736,
        "start": 989.36,
        "temperature": 0,
        "text": " And if I go and look into my HTML,",
        "tokens": [
          50464,
          400,
          498,
          286,
          352,
          293,
          574,
          666,
          452,
          17995,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.1348087101766508,
        "compression_ratio": 1.59765625,
        "end": 996.36,
        "id": 352,
        "no_speech_prob": 0.008187683299183846,
        "seek": 98736,
        "start": 992.36,
        "temperature": 0,
        "text": " I can see I'm using the ml5 library 0.1.1.",
        "tokens": [
          50614,
          286,
          393,
          536,
          286,
          478,
          1228,
          264,
          23271,
          20,
          6405,
          1958,
          13,
          16,
          13,
          16,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1348087101766508,
        "compression_ratio": 1.59765625,
        "end": 997.36,
        "id": 353,
        "no_speech_prob": 0.008187683299183846,
        "seek": 98736,
        "start": 996.36,
        "temperature": 0,
        "text": " Maybe you're watching this.",
        "tokens": [
          50814,
          2704,
          291,
          434,
          1976,
          341,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1348087101766508,
        "compression_ratio": 1.59765625,
        "end": 1001.36,
        "id": 354,
        "no_speech_prob": 0.008187683299183846,
        "seek": 98736,
        "start": 997.36,
        "temperature": 0,
        "text": " Maybe it's like right now it's like 9.4.3",
        "tokens": [
          50864,
          2704,
          309,
          311,
          411,
          558,
          586,
          309,
          311,
          411,
          1722,
          13,
          19,
          13,
          18,
          51064
        ]
      },
      {
        "avg_logprob": -0.1348087101766508,
        "compression_ratio": 1.59765625,
        "end": 1004.36,
        "id": 355,
        "no_speech_prob": 0.008187683299183846,
        "seek": 98736,
        "start": 1001.36,
        "temperature": 0,
        "text": " and you're in this future world of ml5.",
        "tokens": [
          51064,
          293,
          291,
          434,
          294,
          341,
          2027,
          1002,
          295,
          23271,
          20,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1348087101766508,
        "compression_ratio": 1.59765625,
        "end": 1008.36,
        "id": 356,
        "no_speech_prob": 0.008187683299183846,
        "seek": 98736,
        "start": 1004.36,
        "temperature": 0,
        "text": " But the current version is 0.1.3.",
        "tokens": [
          51214,
          583,
          264,
          2190,
          3037,
          307,
          1958,
          13,
          16,
          13,
          18,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1348087101766508,
        "compression_ratio": 1.59765625,
        "end": 1010.36,
        "id": 357,
        "no_speech_prob": 0.008187683299183846,
        "seek": 98736,
        "start": 1008.36,
        "temperature": 0,
        "text": " So if I add that, I'm going to hit refresh.",
        "tokens": [
          51414,
          407,
          498,
          286,
          909,
          300,
          11,
          286,
          478,
          516,
          281,
          2045,
          15134,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1348087101766508,
        "compression_ratio": 1.59765625,
        "end": 1013.36,
        "id": 358,
        "no_speech_prob": 0.008187683299183846,
        "seek": 98736,
        "start": 1010.36,
        "temperature": 0,
        "text": " Now I'm going to really try to train a good model here.",
        "tokens": [
          51514,
          823,
          286,
          478,
          516,
          281,
          534,
          853,
          281,
          3847,
          257,
          665,
          2316,
          510,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1348087101766508,
        "compression_ratio": 1.59765625,
        "end": 1014.36,
        "id": 359,
        "no_speech_prob": 0.008187683299183846,
        "seek": 98736,
        "start": 1013.36,
        "temperature": 0,
        "text": " So let's train.",
        "tokens": [
          51664,
          407,
          718,
          311,
          3847,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1348087101766508,
        "compression_ratio": 1.59765625,
        "end": 1015.36,
        "id": 360,
        "no_speech_prob": 0.008187683299183846,
        "seek": 98736,
        "start": 1014.36,
        "temperature": 0,
        "text": " Oh, I don't have the ukulele.",
        "tokens": [
          51714,
          876,
          11,
          286,
          500,
          380,
          362,
          264,
          26769,
          2271,
          306,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1834125518798828,
        "compression_ratio": 1.8032786885245902,
        "end": 1018.36,
        "id": 361,
        "no_speech_prob": 0.04271950200200081,
        "seek": 101536,
        "start": 1015.36,
        "temperature": 0,
        "text": " I'm going to do the train whistle.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          360,
          264,
          3847,
          23470,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1834125518798828,
        "compression_ratio": 1.8032786885245902,
        "end": 1019.36,
        "id": 362,
        "no_speech_prob": 0.04271950200200081,
        "seek": 101536,
        "start": 1018.36,
        "temperature": 0,
        "text": " So I'll just do happy and sad.",
        "tokens": [
          50514,
          407,
          286,
          603,
          445,
          360,
          2055,
          293,
          4227,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1834125518798828,
        "compression_ratio": 1.8032786885245902,
        "end": 1021.36,
        "id": 363,
        "no_speech_prob": 0.04271950200200081,
        "seek": 101536,
        "start": 1019.36,
        "temperature": 0,
        "text": " I'm happy with the train whistle.",
        "tokens": [
          50564,
          286,
          478,
          2055,
          365,
          264,
          3847,
          23470,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1834125518798828,
        "compression_ratio": 1.8032786885245902,
        "end": 1030.3600000000001,
        "id": 364,
        "no_speech_prob": 0.04271950200200081,
        "seek": 101536,
        "start": 1026.3600000000001,
        "temperature": 0,
        "text": " And I'm very sad with no train whistle.",
        "tokens": [
          50914,
          400,
          286,
          478,
          588,
          4227,
          365,
          572,
          3847,
          23470,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1834125518798828,
        "compression_ratio": 1.8032786885245902,
        "end": 1032.3600000000001,
        "id": 365,
        "no_speech_prob": 0.04271950200200081,
        "seek": 101536,
        "start": 1030.3600000000001,
        "temperature": 0,
        "text": " I don't have a train whistle.",
        "tokens": [
          51114,
          286,
          500,
          380,
          362,
          257,
          3847,
          23470,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1834125518798828,
        "compression_ratio": 1.8032786885245902,
        "end": 1033.3600000000001,
        "id": 366,
        "no_speech_prob": 0.04271950200200081,
        "seek": 101536,
        "start": 1032.3600000000001,
        "temperature": 0,
        "text": " I'm so sad.",
        "tokens": [
          51214,
          286,
          478,
          370,
          4227,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1834125518798828,
        "compression_ratio": 1.8032786885245902,
        "end": 1034.3600000000001,
        "id": 367,
        "no_speech_prob": 0.04271950200200081,
        "seek": 101536,
        "start": 1033.3600000000001,
        "temperature": 0,
        "text": " No train whistle.",
        "tokens": [
          51264,
          883,
          3847,
          23470,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1834125518798828,
        "compression_ratio": 1.8032786885245902,
        "end": 1035.3600000000001,
        "id": 368,
        "no_speech_prob": 0.04271950200200081,
        "seek": 101536,
        "start": 1034.3600000000001,
        "temperature": 0,
        "text": " Now I'm going to train.",
        "tokens": [
          51314,
          823,
          286,
          478,
          516,
          281,
          3847,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1834125518798828,
        "compression_ratio": 1.8032786885245902,
        "end": 1037.3600000000001,
        "id": 369,
        "no_speech_prob": 0.04271950200200081,
        "seek": 101536,
        "start": 1035.3600000000001,
        "temperature": 0,
        "text": " So I gave it a whole bunch of examples.",
        "tokens": [
          51364,
          407,
          286,
          2729,
          309,
          257,
          1379,
          3840,
          295,
          5110,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1834125518798828,
        "compression_ratio": 1.8032786885245902,
        "end": 1040.3600000000001,
        "id": 370,
        "no_speech_prob": 0.04271950200200081,
        "seek": 101536,
        "start": 1037.3600000000001,
        "temperature": 0,
        "text": " And something weird is going on here.",
        "tokens": [
          51464,
          400,
          746,
          3657,
          307,
          516,
          322,
          510,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1834125518798828,
        "compression_ratio": 1.8032786885245902,
        "end": 1044.3600000000001,
        "id": 371,
        "no_speech_prob": 0.04271950200200081,
        "seek": 101536,
        "start": 1040.3600000000001,
        "temperature": 0,
        "text": " OK, let's see if this works.",
        "tokens": [
          51614,
          2264,
          11,
          718,
          311,
          536,
          498,
          341,
          1985,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.15685574849446615,
        "compression_ratio": 1.841409691629956,
        "end": 1045.36,
        "id": 372,
        "no_speech_prob": 0.025956183671951294,
        "seek": 104436,
        "start": 1044.36,
        "temperature": 0,
        "text": " I'm happy.",
        "tokens": [
          50364,
          286,
          478,
          2055,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.15685574849446615,
        "compression_ratio": 1.841409691629956,
        "end": 1046.36,
        "id": 373,
        "no_speech_prob": 0.025956183671951294,
        "seek": 104436,
        "start": 1045.36,
        "temperature": 0,
        "text": " I'm happy with the train whistle.",
        "tokens": [
          50414,
          286,
          478,
          2055,
          365,
          264,
          3847,
          23470,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.15685574849446615,
        "compression_ratio": 1.841409691629956,
        "end": 1047.36,
        "id": 374,
        "no_speech_prob": 0.025956183671951294,
        "seek": 104436,
        "start": 1046.36,
        "temperature": 0,
        "text": " I'm sad.",
        "tokens": [
          50464,
          286,
          478,
          4227,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.15685574849446615,
        "compression_ratio": 1.841409691629956,
        "end": 1048.36,
        "id": 375,
        "no_speech_prob": 0.025956183671951294,
        "seek": 104436,
        "start": 1047.36,
        "temperature": 0,
        "text": " No train whistle.",
        "tokens": [
          50514,
          883,
          3847,
          23470,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.15685574849446615,
        "compression_ratio": 1.841409691629956,
        "end": 1049.36,
        "id": 376,
        "no_speech_prob": 0.025956183671951294,
        "seek": 104436,
        "start": 1048.36,
        "temperature": 0,
        "text": " I'm happy with the train whistle.",
        "tokens": [
          50564,
          286,
          478,
          2055,
          365,
          264,
          3847,
          23470,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.15685574849446615,
        "compression_ratio": 1.841409691629956,
        "end": 1050.36,
        "id": 377,
        "no_speech_prob": 0.025956183671951294,
        "seek": 104436,
        "start": 1049.36,
        "temperature": 0,
        "text": " I'm sad.",
        "tokens": [
          50614,
          286,
          478,
          4227,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.15685574849446615,
        "compression_ratio": 1.841409691629956,
        "end": 1051.36,
        "id": 378,
        "no_speech_prob": 0.025956183671951294,
        "seek": 104436,
        "start": 1050.36,
        "temperature": 0,
        "text": " No train whistle.",
        "tokens": [
          50664,
          883,
          3847,
          23470,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.15685574849446615,
        "compression_ratio": 1.841409691629956,
        "end": 1052.36,
        "id": 379,
        "no_speech_prob": 0.025956183671951294,
        "seek": 104436,
        "start": 1051.36,
        "temperature": 0,
        "text": " And I want to keep this model.",
        "tokens": [
          50714,
          400,
          286,
          528,
          281,
          1066,
          341,
          2316,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.15685574849446615,
        "compression_ratio": 1.841409691629956,
        "end": 1055.36,
        "id": 380,
        "no_speech_prob": 0.025956183671951294,
        "seek": 104436,
        "start": 1052.36,
        "temperature": 0,
        "text": " So I'm now going to click Save.",
        "tokens": [
          50764,
          407,
          286,
          478,
          586,
          516,
          281,
          2052,
          15541,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.15685574849446615,
        "compression_ratio": 1.841409691629956,
        "end": 1056.36,
        "id": 381,
        "no_speech_prob": 0.025956183671951294,
        "seek": 104436,
        "start": 1055.36,
        "temperature": 0,
        "text": " And look at this.",
        "tokens": [
          50914,
          400,
          574,
          412,
          341,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.15685574849446615,
        "compression_ratio": 1.841409691629956,
        "end": 1060.36,
        "id": 382,
        "no_speech_prob": 0.025956183671951294,
        "seek": 104436,
        "start": 1056.36,
        "temperature": 0,
        "text": " Look what has downloaded to the download directory.",
        "tokens": [
          50964,
          2053,
          437,
          575,
          21748,
          281,
          264,
          5484,
          21120,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.15685574849446615,
        "compression_ratio": 1.841409691629956,
        "end": 1063.36,
        "id": 383,
        "no_speech_prob": 0.025956183671951294,
        "seek": 104436,
        "start": 1060.36,
        "temperature": 0,
        "text": " I'm going to go show in Finder and see.",
        "tokens": [
          51164,
          286,
          478,
          516,
          281,
          352,
          855,
          294,
          479,
          5669,
          293,
          536,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.15685574849446615,
        "compression_ratio": 1.841409691629956,
        "end": 1064.36,
        "id": 384,
        "no_speech_prob": 0.025956183671951294,
        "seek": 104436,
        "start": 1063.36,
        "temperature": 0,
        "text": " Look at this, two files.",
        "tokens": [
          51314,
          2053,
          412,
          341,
          11,
          732,
          7098,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.15685574849446615,
        "compression_ratio": 1.841409691629956,
        "end": 1066.36,
        "id": 385,
        "no_speech_prob": 0.025956183671951294,
        "seek": 104436,
        "start": 1064.36,
        "temperature": 0,
        "text": " Today is 2.17 PM.",
        "tokens": [
          51364,
          2692,
          307,
          568,
          13,
          7773,
          12499,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.15685574849446615,
        "compression_ratio": 1.841409691629956,
        "end": 1070.36,
        "id": 386,
        "no_speech_prob": 0.025956183671951294,
        "seek": 104436,
        "start": 1066.36,
        "temperature": 0,
        "text": " Model.json, model.weights.bin.",
        "tokens": [
          51464,
          17105,
          13,
          73,
          3015,
          11,
          2316,
          13,
          826,
          5761,
          13,
          13496,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.15685574849446615,
        "compression_ratio": 1.841409691629956,
        "end": 1073.36,
        "id": 387,
        "no_speech_prob": 0.025956183671951294,
        "seek": 104436,
        "start": 1070.36,
        "temperature": 0,
        "text": " OK, so let's take a moment to explain.",
        "tokens": [
          51664,
          2264,
          11,
          370,
          718,
          311,
          747,
          257,
          1623,
          281,
          2903,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.3416576618101539,
        "compression_ratio": 1.0561797752808988,
        "end": 1073.86,
        "id": 388,
        "no_speech_prob": 0.0378853939473629,
        "seek": 107336,
        "start": 1073.36,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          50364,
          876,
          13,
          50389
        ]
      },
      {
        "avg_logprob": -0.3416576618101539,
        "compression_ratio": 1.0561797752808988,
        "end": 1089.36,
        "id": 389,
        "no_speech_prob": 0.0378853939473629,
        "seek": 107336,
        "start": 1088.36,
        "temperature": 0,
        "text": " Let's see.",
        "tokens": [
          51114,
          961,
          311,
          536,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.3416576618101539,
        "compression_ratio": 1.0561797752808988,
        "end": 1091.36,
        "id": 390,
        "no_speech_prob": 0.0378853939473629,
        "seek": 107336,
        "start": 1089.36,
        "temperature": 0,
        "text": " Why is the whiteboard not working?",
        "tokens": [
          51164,
          1545,
          307,
          264,
          2418,
          3787,
          406,
          1364,
          30,
          51264
        ]
      },
      {
        "avg_logprob": -0.3416576618101539,
        "compression_ratio": 1.0561797752808988,
        "end": 1096.36,
        "id": 391,
        "no_speech_prob": 0.0378853939473629,
        "seek": 107336,
        "start": 1094.36,
        "temperature": 0,
        "text": " Loose cable?",
        "tokens": [
          51414,
          6130,
          541,
          8220,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.3416576618101539,
        "compression_ratio": 1.0561797752808988,
        "end": 1098.36,
        "id": 392,
        "no_speech_prob": 0.0378853939473629,
        "seek": 107336,
        "start": 1096.36,
        "temperature": 0,
        "text": " Maybe.",
        "tokens": [
          51514,
          2704,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.3416576618101539,
        "compression_ratio": 1.0561797752808988,
        "end": 1099.36,
        "id": 393,
        "no_speech_prob": 0.0378853939473629,
        "seek": 107336,
        "start": 1098.36,
        "temperature": 0,
        "text": " Check, check, no, check.",
        "tokens": [
          51614,
          6881,
          11,
          1520,
          11,
          572,
          11,
          1520,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.15649786660837572,
        "compression_ratio": 1.5121951219512195,
        "end": 1104.36,
        "id": 394,
        "no_speech_prob": 0.00003269903390901163,
        "seek": 110336,
        "start": 1103.36,
        "temperature": 0,
        "text": " Oh, there we go.",
        "tokens": [
          50364,
          876,
          11,
          456,
          321,
          352,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.15649786660837572,
        "compression_ratio": 1.5121951219512195,
        "end": 1106.36,
        "id": 395,
        "no_speech_prob": 0.00003269903390901163,
        "seek": 110336,
        "start": 1104.36,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50414,
          2264,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.15649786660837572,
        "compression_ratio": 1.5121951219512195,
        "end": 1109.36,
        "id": 396,
        "no_speech_prob": 0.00003269903390901163,
        "seek": 110336,
        "start": 1106.36,
        "temperature": 0,
        "text": " Let's take a moment to talk about what's in these files.",
        "tokens": [
          50514,
          961,
          311,
          747,
          257,
          1623,
          281,
          751,
          466,
          437,
          311,
          294,
          613,
          7098,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.15649786660837572,
        "compression_ratio": 1.5121951219512195,
        "end": 1114.36,
        "id": 397,
        "no_speech_prob": 0.00003269903390901163,
        "seek": 110336,
        "start": 1109.36,
        "temperature": 0,
        "text": " So why is there a file called model.json and a file called,",
        "tokens": [
          50664,
          407,
          983,
          307,
          456,
          257,
          3991,
          1219,
          2316,
          13,
          73,
          3015,
          293,
          257,
          3991,
          1219,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.15649786660837572,
        "compression_ratio": 1.5121951219512195,
        "end": 1118.36,
        "id": 398,
        "no_speech_prob": 0.00003269903390901163,
        "seek": 110336,
        "start": 1114.36,
        "temperature": 0,
        "text": " I already forgot, model.weights.bin?",
        "tokens": [
          50914,
          286,
          1217,
          5298,
          11,
          2316,
          13,
          826,
          5761,
          13,
          13496,
          30,
          51114
        ]
      },
      {
        "avg_logprob": -0.15649786660837572,
        "compression_ratio": 1.5121951219512195,
        "end": 1123.36,
        "id": 399,
        "no_speech_prob": 0.00003269903390901163,
        "seek": 110336,
        "start": 1118.36,
        "temperature": 0,
        "text": " Model.weights.bin.",
        "tokens": [
          51114,
          17105,
          13,
          826,
          5761,
          13,
          13496,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.15649786660837572,
        "compression_ratio": 1.5121951219512195,
        "end": 1128.36,
        "id": 400,
        "no_speech_prob": 0.00003269903390901163,
        "seek": 110336,
        "start": 1123.36,
        "temperature": 0,
        "text": " OK, so we haven't really, as part of this video series",
        "tokens": [
          51364,
          2264,
          11,
          370,
          321,
          2378,
          380,
          534,
          11,
          382,
          644,
          295,
          341,
          960,
          2638,
          51614
        ]
      },
      {
        "avg_logprob": -0.1333165075264725,
        "compression_ratio": 1.8366336633663367,
        "end": 1131.36,
        "id": 401,
        "no_speech_prob": 0.0076955948024988174,
        "seek": 112836,
        "start": 1128.36,
        "temperature": 0,
        "text": " at least, talked about the details of what",
        "tokens": [
          50364,
          412,
          1935,
          11,
          2825,
          466,
          264,
          4365,
          295,
          437,
          50514
        ]
      },
      {
        "avg_logprob": -0.1333165075264725,
        "compression_ratio": 1.8366336633663367,
        "end": 1133.36,
        "id": 402,
        "no_speech_prob": 0.0076955948024988174,
        "seek": 112836,
        "start": 1131.36,
        "temperature": 0,
        "text": " a neural network is.",
        "tokens": [
          50514,
          257,
          18161,
          3209,
          307,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1333165075264725,
        "compression_ratio": 1.8366336633663367,
        "end": 1137.36,
        "id": 403,
        "no_speech_prob": 0.0076955948024988174,
        "seek": 112836,
        "start": 1133.36,
        "temperature": 0,
        "text": " But this particular machine learning model",
        "tokens": [
          50614,
          583,
          341,
          1729,
          3479,
          2539,
          2316,
          50814
        ]
      },
      {
        "avg_logprob": -0.1333165075264725,
        "compression_ratio": 1.8366336633663367,
        "end": 1139.36,
        "id": 404,
        "no_speech_prob": 0.0076955948024988174,
        "seek": 112836,
        "start": 1137.36,
        "temperature": 0,
        "text": " is a neural network.",
        "tokens": [
          50814,
          307,
          257,
          18161,
          3209,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1333165075264725,
        "compression_ratio": 1.8366336633663367,
        "end": 1142.36,
        "id": 405,
        "no_speech_prob": 0.0076955948024988174,
        "seek": 112836,
        "start": 1139.36,
        "temperature": 0,
        "text": " And a neural network has some kind of architecture to it.",
        "tokens": [
          50914,
          400,
          257,
          18161,
          3209,
          575,
          512,
          733,
          295,
          9482,
          281,
          309,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1333165075264725,
        "compression_ratio": 1.8366336633663367,
        "end": 1146.36,
        "id": 406,
        "no_speech_prob": 0.0076955948024988174,
        "seek": 112836,
        "start": 1142.36,
        "temperature": 0,
        "text": " It has a whole bunch of inputs.",
        "tokens": [
          51064,
          467,
          575,
          257,
          1379,
          3840,
          295,
          15743,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1333165075264725,
        "compression_ratio": 1.8366336633663367,
        "end": 1148.36,
        "id": 407,
        "no_speech_prob": 0.0076955948024988174,
        "seek": 112836,
        "start": 1146.36,
        "temperature": 0,
        "text": " And it has a bunch of outputs.",
        "tokens": [
          51264,
          400,
          309,
          575,
          257,
          3840,
          295,
          23930,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1333165075264725,
        "compression_ratio": 1.8366336633663367,
        "end": 1152.36,
        "id": 408,
        "no_speech_prob": 0.0076955948024988174,
        "seek": 112836,
        "start": 1148.36,
        "temperature": 0,
        "text": " And in this case, it actually just has two outputs,",
        "tokens": [
          51364,
          400,
          294,
          341,
          1389,
          11,
          309,
          767,
          445,
          575,
          732,
          23930,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.1333165075264725,
        "compression_ratio": 1.8366336633663367,
        "end": 1154.36,
        "id": 409,
        "no_speech_prob": 0.0076955948024988174,
        "seek": 112836,
        "start": 1152.36,
        "temperature": 0,
        "text": " a happy or a sad.",
        "tokens": [
          51564,
          257,
          2055,
          420,
          257,
          4227,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1333165075264725,
        "compression_ratio": 1.8366336633663367,
        "end": 1157.36,
        "id": 410,
        "no_speech_prob": 0.0076955948024988174,
        "seek": 112836,
        "start": 1154.36,
        "temperature": 0,
        "text": " And the actual thing the neural network is producing",
        "tokens": [
          51664,
          400,
          264,
          3539,
          551,
          264,
          18161,
          3209,
          307,
          10501,
          51814
        ]
      },
      {
        "avg_logprob": -0.1727321743965149,
        "compression_ratio": 1.6887755102040816,
        "end": 1162.36,
        "id": 411,
        "no_speech_prob": 0.0001634642540011555,
        "seek": 115736,
        "start": 1157.36,
        "temperature": 0,
        "text": " is a probability of one or the other.",
        "tokens": [
          50364,
          307,
          257,
          8482,
          295,
          472,
          420,
          264,
          661,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1727321743965149,
        "compression_ratio": 1.6887755102040816,
        "end": 1166.36,
        "id": 412,
        "no_speech_prob": 0.0001634642540011555,
        "seek": 115736,
        "start": 1162.36,
        "temperature": 0,
        "text": " Now, in between, oh, and the inputs, sorry,",
        "tokens": [
          50614,
          823,
          11,
          294,
          1296,
          11,
          1954,
          11,
          293,
          264,
          15743,
          11,
          2597,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.1727321743965149,
        "compression_ratio": 1.6887755102040816,
        "end": 1169.36,
        "id": 413,
        "no_speech_prob": 0.0001634642540011555,
        "seek": 115736,
        "start": 1166.36,
        "temperature": 0,
        "text": " the inputs is an image.",
        "tokens": [
          50814,
          264,
          15743,
          307,
          364,
          3256,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1727321743965149,
        "compression_ratio": 1.6887755102040816,
        "end": 1171.36,
        "id": 414,
        "no_speech_prob": 0.0001634642540011555,
        "seek": 115736,
        "start": 1169.36,
        "temperature": 0,
        "text": " So maybe every single pixel of the image",
        "tokens": [
          50964,
          407,
          1310,
          633,
          2167,
          19261,
          295,
          264,
          3256,
          51064
        ]
      },
      {
        "avg_logprob": -0.1727321743965149,
        "compression_ratio": 1.6887755102040816,
        "end": 1174.36,
        "id": 415,
        "no_speech_prob": 0.0001634642540011555,
        "seek": 115736,
        "start": 1171.36,
        "temperature": 0,
        "text": " is wired to one of these inputs.",
        "tokens": [
          51064,
          307,
          27415,
          281,
          472,
          295,
          613,
          15743,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1727321743965149,
        "compression_ratio": 1.6887755102040816,
        "end": 1176.36,
        "id": 416,
        "no_speech_prob": 0.0001634642540011555,
        "seek": 115736,
        "start": 1174.36,
        "temperature": 0,
        "text": " Then there are these layers.",
        "tokens": [
          51214,
          1396,
          456,
          366,
          613,
          7914,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1727321743965149,
        "compression_ratio": 1.6887755102040816,
        "end": 1178.36,
        "id": 417,
        "no_speech_prob": 0.0001634642540011555,
        "seek": 115736,
        "start": 1176.36,
        "temperature": 0,
        "text": " The data is going to be processed forward.",
        "tokens": [
          51314,
          440,
          1412,
          307,
          516,
          281,
          312,
          18846,
          2128,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1727321743965149,
        "compression_ratio": 1.6887755102040816,
        "end": 1180.36,
        "id": 418,
        "no_speech_prob": 0.0001634642540011555,
        "seek": 115736,
        "start": 1178.36,
        "temperature": 0,
        "text": " The math and various things are going",
        "tokens": [
          51414,
          440,
          5221,
          293,
          3683,
          721,
          366,
          516,
          51514
        ]
      },
      {
        "avg_logprob": -0.1727321743965149,
        "compression_ratio": 1.6887755102040816,
        "end": 1184.36,
        "id": 419,
        "no_speech_prob": 0.0001634642540011555,
        "seek": 115736,
        "start": 1180.36,
        "temperature": 0,
        "text": " to happen to the data as it goes forward.",
        "tokens": [
          51514,
          281,
          1051,
          281,
          264,
          1412,
          382,
          309,
          1709,
          2128,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17507476466042654,
        "compression_ratio": 1.6422764227642277,
        "end": 1188.36,
        "id": 420,
        "no_speech_prob": 0.004468331579118967,
        "seek": 118436,
        "start": 1184.36,
        "temperature": 0,
        "text": " And it needs to have some amount of hidden layers",
        "tokens": [
          50364,
          400,
          309,
          2203,
          281,
          362,
          512,
          2372,
          295,
          7633,
          7914,
          50564
        ]
      },
      {
        "avg_logprob": -0.17507476466042654,
        "compression_ratio": 1.6422764227642277,
        "end": 1189.36,
        "id": 421,
        "no_speech_prob": 0.004468331579118967,
        "seek": 118436,
        "start": 1188.36,
        "temperature": 0,
        "text": " and other types of nodes.",
        "tokens": [
          50564,
          293,
          661,
          3467,
          295,
          13891,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.17507476466042654,
        "compression_ratio": 1.6422764227642277,
        "end": 1190.36,
        "id": 422,
        "no_speech_prob": 0.004468331579118967,
        "seek": 118436,
        "start": 1189.36,
        "temperature": 0,
        "text": " And everything is connected.",
        "tokens": [
          50614,
          400,
          1203,
          307,
          4582,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17507476466042654,
        "compression_ratio": 1.6422764227642277,
        "end": 1193.36,
        "id": 423,
        "no_speech_prob": 0.004468331579118967,
        "seek": 118436,
        "start": 1190.36,
        "temperature": 0,
        "text": " And this is stuff that I have described in other videos.",
        "tokens": [
          50664,
          400,
          341,
          307,
          1507,
          300,
          286,
          362,
          7619,
          294,
          661,
          2145,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.17507476466042654,
        "compression_ratio": 1.6422764227642277,
        "end": 1196.36,
        "id": 424,
        "no_speech_prob": 0.004468331579118967,
        "seek": 118436,
        "start": 1193.36,
        "temperature": 0,
        "text": " And I'll also refer you to the 3Blue1Brown",
        "tokens": [
          50814,
          400,
          286,
          603,
          611,
          2864,
          291,
          281,
          264,
          805,
          45231,
          16,
          22170,
          648,
          50964
        ]
      },
      {
        "avg_logprob": -0.17507476466042654,
        "compression_ratio": 1.6422764227642277,
        "end": 1199.36,
        "id": 425,
        "no_speech_prob": 0.004468331579118967,
        "seek": 118436,
        "start": 1196.36,
        "temperature": 0,
        "text": " What is a Neural Network video, which is terrific to see more.",
        "tokens": [
          50964,
          708,
          307,
          257,
          1734,
          1807,
          12640,
          960,
          11,
          597,
          307,
          20899,
          281,
          536,
          544,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17507476466042654,
        "compression_ratio": 1.6422764227642277,
        "end": 1202.36,
        "id": 426,
        "no_speech_prob": 0.004468331579118967,
        "seek": 118436,
        "start": 1199.36,
        "temperature": 0,
        "text": " But the reason why I'm mentioning this",
        "tokens": [
          51114,
          583,
          264,
          1778,
          983,
          286,
          478,
          18315,
          341,
          51264
        ]
      },
      {
        "avg_logprob": -0.17507476466042654,
        "compression_ratio": 1.6422764227642277,
        "end": 1206.36,
        "id": 427,
        "no_speech_prob": 0.004468331579118967,
        "seek": 118436,
        "start": 1202.36,
        "temperature": 0,
        "text": " is this model.json is a file that",
        "tokens": [
          51264,
          307,
          341,
          2316,
          13,
          73,
          3015,
          307,
          257,
          3991,
          300,
          51464
        ]
      },
      {
        "avg_logprob": -0.17507476466042654,
        "compression_ratio": 1.6422764227642277,
        "end": 1208.36,
        "id": 428,
        "no_speech_prob": 0.004468331579118967,
        "seek": 118436,
        "start": 1206.36,
        "temperature": 0,
        "text": " describes the architecture, maybe",
        "tokens": [
          51464,
          15626,
          264,
          9482,
          11,
          1310,
          51564
        ]
      },
      {
        "avg_logprob": -0.17507476466042654,
        "compression_ratio": 1.6422764227642277,
        "end": 1212.36,
        "id": 429,
        "no_speech_prob": 0.004468331579118967,
        "seek": 118436,
        "start": 1208.36,
        "temperature": 0,
        "text": " is architecture of the model.",
        "tokens": [
          51564,
          307,
          9482,
          295,
          264,
          2316,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18888042353782333,
        "compression_ratio": 1.6666666666666667,
        "end": 1215.36,
        "id": 430,
        "no_speech_prob": 0.00018522539176046848,
        "seek": 121236,
        "start": 1212.36,
        "temperature": 0,
        "text": " And this model.weights.bin is a file",
        "tokens": [
          50364,
          400,
          341,
          2316,
          13,
          826,
          5761,
          13,
          13496,
          307,
          257,
          3991,
          50514
        ]
      },
      {
        "avg_logprob": -0.18888042353782333,
        "compression_ratio": 1.6666666666666667,
        "end": 1217.36,
        "id": 431,
        "no_speech_prob": 0.00018522539176046848,
        "seek": 121236,
        "start": 1215.36,
        "temperature": 0,
        "text": " that describes all the weights.",
        "tokens": [
          50514,
          300,
          15626,
          439,
          264,
          17443,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18888042353782333,
        "compression_ratio": 1.6666666666666667,
        "end": 1221.36,
        "id": 432,
        "no_speech_prob": 0.00018522539176046848,
        "seek": 121236,
        "start": 1217.36,
        "temperature": 0,
        "text": " So what I mean by architecture is how many inputs,",
        "tokens": [
          50614,
          407,
          437,
          286,
          914,
          538,
          9482,
          307,
          577,
          867,
          15743,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.18888042353782333,
        "compression_ratio": 1.6666666666666667,
        "end": 1224.36,
        "id": 433,
        "no_speech_prob": 0.00018522539176046848,
        "seek": 121236,
        "start": 1221.36,
        "temperature": 0,
        "text": " how many outputs, how many hidden layers,",
        "tokens": [
          50814,
          577,
          867,
          23930,
          11,
          577,
          867,
          7633,
          7914,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.18888042353782333,
        "compression_ratio": 1.6666666666666667,
        "end": 1226.36,
        "id": 434,
        "no_speech_prob": 0.00018522539176046848,
        "seek": 121236,
        "start": 1224.36,
        "temperature": 0,
        "text": " and all sorts of configuration details",
        "tokens": [
          50964,
          293,
          439,
          7527,
          295,
          11694,
          4365,
          51064
        ]
      },
      {
        "avg_logprob": -0.18888042353782333,
        "compression_ratio": 1.6666666666666667,
        "end": 1228.36,
        "id": 435,
        "no_speech_prob": 0.00018522539176046848,
        "seek": 121236,
        "start": 1226.36,
        "temperature": 0,
        "text": " about the architecture of this neural network",
        "tokens": [
          51064,
          466,
          264,
          9482,
          295,
          341,
          18161,
          3209,
          51164
        ]
      },
      {
        "avg_logprob": -0.18888042353782333,
        "compression_ratio": 1.6666666666666667,
        "end": 1232.36,
        "id": 436,
        "no_speech_prob": 0.00018522539176046848,
        "seek": 121236,
        "start": 1228.36,
        "temperature": 0,
        "text": " that I've half-drawn here in a pretty crude way.",
        "tokens": [
          51164,
          300,
          286,
          600,
          1922,
          12,
          67,
          29603,
          510,
          294,
          257,
          1238,
          30796,
          636,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18888042353782333,
        "compression_ratio": 1.6666666666666667,
        "end": 1234.36,
        "id": 437,
        "no_speech_prob": 0.00018522539176046848,
        "seek": 121236,
        "start": 1232.36,
        "temperature": 0,
        "text": " The thing that I'm kind of not mentioning,",
        "tokens": [
          51364,
          440,
          551,
          300,
          286,
          478,
          733,
          295,
          406,
          18315,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.18888042353782333,
        "compression_ratio": 1.6666666666666667,
        "end": 1237.36,
        "id": 438,
        "no_speech_prob": 0.00018522539176046848,
        "seek": 121236,
        "start": 1234.36,
        "temperature": 0,
        "text": " because I don't want to be here for the next 17 hours",
        "tokens": [
          51464,
          570,
          286,
          500,
          380,
          528,
          281,
          312,
          510,
          337,
          264,
          958,
          3282,
          2496,
          51614
        ]
      },
      {
        "avg_logprob": -0.18888042353782333,
        "compression_ratio": 1.6666666666666667,
        "end": 1239.36,
        "id": 439,
        "no_speech_prob": 0.00018522539176046848,
        "seek": 121236,
        "start": 1237.36,
        "temperature": 0,
        "text": " going to every sound, every different road of detail",
        "tokens": [
          51614,
          516,
          281,
          633,
          1626,
          11,
          633,
          819,
          3060,
          295,
          2607,
          51714
        ]
      },
      {
        "avg_logprob": -0.17125606536865234,
        "compression_ratio": 1.8645418326693226,
        "end": 1242.36,
        "id": 440,
        "no_speech_prob": 0.0006361885461956263,
        "seek": 123936,
        "start": 1239.36,
        "temperature": 0,
        "text": " here, is that the data as it's passing",
        "tokens": [
          50364,
          510,
          11,
          307,
          300,
          264,
          1412,
          382,
          309,
          311,
          8437,
          50514
        ]
      },
      {
        "avg_logprob": -0.17125606536865234,
        "compression_ratio": 1.8645418326693226,
        "end": 1245.36,
        "id": 441,
        "no_speech_prob": 0.0006361885461956263,
        "seek": 123936,
        "start": 1242.36,
        "temperature": 0,
        "text": " through the neural network, all of these different nodes",
        "tokens": [
          50514,
          807,
          264,
          18161,
          3209,
          11,
          439,
          295,
          613,
          819,
          13891,
          50664
        ]
      },
      {
        "avg_logprob": -0.17125606536865234,
        "compression_ratio": 1.8645418326693226,
        "end": 1248.36,
        "id": 442,
        "no_speech_prob": 0.0006361885461956263,
        "seek": 123936,
        "start": 1245.36,
        "temperature": 0,
        "text": " between the inputs and the outputs and the hidden layers,",
        "tokens": [
          50664,
          1296,
          264,
          15743,
          293,
          264,
          23930,
          293,
          264,
          7633,
          7914,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.17125606536865234,
        "compression_ratio": 1.8645418326693226,
        "end": 1251.36,
        "id": 443,
        "no_speech_prob": 0.0006361885461956263,
        "seek": 123936,
        "start": 1248.36,
        "temperature": 0,
        "text": " all of these nodes are connected.",
        "tokens": [
          50814,
          439,
          295,
          613,
          13891,
          366,
          4582,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.17125606536865234,
        "compression_ratio": 1.8645418326693226,
        "end": 1253.36,
        "id": 444,
        "no_speech_prob": 0.0006361885461956263,
        "seek": 123936,
        "start": 1251.36,
        "temperature": 0,
        "text": " And each one of those connections has a weight.",
        "tokens": [
          50964,
          400,
          1184,
          472,
          295,
          729,
          9271,
          575,
          257,
          3364,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17125606536865234,
        "compression_ratio": 1.8645418326693226,
        "end": 1255.36,
        "id": 445,
        "no_speech_prob": 0.0006361885461956263,
        "seek": 123936,
        "start": 1253.36,
        "temperature": 0,
        "text": " You can think of the neural network",
        "tokens": [
          51064,
          509,
          393,
          519,
          295,
          264,
          18161,
          3209,
          51164
        ]
      },
      {
        "avg_logprob": -0.17125606536865234,
        "compression_ratio": 1.8645418326693226,
        "end": 1257.36,
        "id": 446,
        "no_speech_prob": 0.0006361885461956263,
        "seek": 123936,
        "start": 1255.36,
        "temperature": 0,
        "text": " as a thing that has just lots and lots of dials in it.",
        "tokens": [
          51164,
          382,
          257,
          551,
          300,
          575,
          445,
          3195,
          293,
          3195,
          295,
          5502,
          82,
          294,
          309,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.17125606536865234,
        "compression_ratio": 1.8645418326693226,
        "end": 1260.36,
        "id": 447,
        "no_speech_prob": 0.0006361885461956263,
        "seek": 123936,
        "start": 1257.36,
        "temperature": 0,
        "text": " And it's trying to learn what the right setting for all",
        "tokens": [
          51264,
          400,
          309,
          311,
          1382,
          281,
          1466,
          437,
          264,
          558,
          3287,
          337,
          439,
          51414
        ]
      },
      {
        "avg_logprob": -0.17125606536865234,
        "compression_ratio": 1.8645418326693226,
        "end": 1264.36,
        "id": 448,
        "no_speech_prob": 0.0006361885461956263,
        "seek": 123936,
        "start": 1260.36,
        "temperature": 0,
        "text": " the dials is to produce the appropriate happy or sad result",
        "tokens": [
          51414,
          264,
          5502,
          82,
          307,
          281,
          5258,
          264,
          6854,
          2055,
          420,
          4227,
          1874,
          51614
        ]
      },
      {
        "avg_logprob": -0.17125606536865234,
        "compression_ratio": 1.8645418326693226,
        "end": 1266.36,
        "id": 449,
        "no_speech_prob": 0.0006361885461956263,
        "seek": 123936,
        "start": 1264.36,
        "temperature": 0,
        "text": " based on the input image.",
        "tokens": [
          51614,
          2361,
          322,
          264,
          4846,
          3256,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1596644559352518,
        "compression_ratio": 1.7256317689530687,
        "end": 1269.36,
        "id": 450,
        "no_speech_prob": 0.000007527984507760266,
        "seek": 126636,
        "start": 1266.36,
        "temperature": 0,
        "text": " So all of the numbers that store the values",
        "tokens": [
          50364,
          407,
          439,
          295,
          264,
          3547,
          300,
          3531,
          264,
          4190,
          50514
        ]
      },
      {
        "avg_logprob": -0.1596644559352518,
        "compression_ratio": 1.7256317689530687,
        "end": 1272.36,
        "id": 451,
        "no_speech_prob": 0.000007527984507760266,
        "seek": 126636,
        "start": 1269.36,
        "temperature": 0,
        "text": " of all of these weights are all in this file.",
        "tokens": [
          50514,
          295,
          439,
          295,
          613,
          17443,
          366,
          439,
          294,
          341,
          3991,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1596644559352518,
        "compression_ratio": 1.7256317689530687,
        "end": 1274.36,
        "id": 452,
        "no_speech_prob": 0.000007527984507760266,
        "seek": 126636,
        "start": 1272.36,
        "temperature": 0,
        "text": " So this is actually a file that we could very easily",
        "tokens": [
          50664,
          407,
          341,
          307,
          767,
          257,
          3991,
          300,
          321,
          727,
          588,
          3612,
          50764
        ]
      },
      {
        "avg_logprob": -0.1596644559352518,
        "compression_ratio": 1.7256317689530687,
        "end": 1275.36,
        "id": 453,
        "no_speech_prob": 0.000007527984507760266,
        "seek": 126636,
        "start": 1274.36,
        "temperature": 0,
        "text": " go and look inside.",
        "tokens": [
          50764,
          352,
          293,
          574,
          1854,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1596644559352518,
        "compression_ratio": 1.7256317689530687,
        "end": 1277.36,
        "id": 454,
        "no_speech_prob": 0.000007527984507760266,
        "seek": 126636,
        "start": 1275.36,
        "temperature": 0,
        "text": " It's JavaScript object notation.",
        "tokens": [
          50814,
          467,
          311,
          15778,
          2657,
          24657,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1596644559352518,
        "compression_ratio": 1.7256317689530687,
        "end": 1278.36,
        "id": 455,
        "no_speech_prob": 0.000007527984507760266,
        "seek": 126636,
        "start": 1277.36,
        "temperature": 0,
        "text": " It's a JSON file.",
        "tokens": [
          50914,
          467,
          311,
          257,
          31828,
          3991,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1596644559352518,
        "compression_ratio": 1.7256317689530687,
        "end": 1279.36,
        "id": 456,
        "no_speech_prob": 0.000007527984507760266,
        "seek": 126636,
        "start": 1278.36,
        "temperature": 0,
        "text": " We will look at that.",
        "tokens": [
          50964,
          492,
          486,
          574,
          412,
          300,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1596644559352518,
        "compression_ratio": 1.7256317689530687,
        "end": 1281.36,
        "id": 457,
        "no_speech_prob": 0.000007527984507760266,
        "seek": 126636,
        "start": 1279.36,
        "temperature": 0,
        "text": " But the weights is really the big thing.",
        "tokens": [
          51014,
          583,
          264,
          17443,
          307,
          534,
          264,
          955,
          551,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1596644559352518,
        "compression_ratio": 1.7256317689530687,
        "end": 1283.36,
        "id": 458,
        "no_speech_prob": 0.000007527984507760266,
        "seek": 126636,
        "start": 1281.36,
        "temperature": 0,
        "text": " It's where there's a ton of stuff.",
        "tokens": [
          51114,
          467,
          311,
          689,
          456,
          311,
          257,
          2952,
          295,
          1507,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1596644559352518,
        "compression_ratio": 1.7256317689530687,
        "end": 1285.36,
        "id": 459,
        "no_speech_prob": 0.000007527984507760266,
        "seek": 126636,
        "start": 1283.36,
        "temperature": 0,
        "text": " There's tons of these connections.",
        "tokens": [
          51214,
          821,
          311,
          9131,
          295,
          613,
          9271,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1596644559352518,
        "compression_ratio": 1.7256317689530687,
        "end": 1286.36,
        "id": 460,
        "no_speech_prob": 0.000007527984507760266,
        "seek": 126636,
        "start": 1285.36,
        "temperature": 0,
        "text": " It's many, many numbers.",
        "tokens": [
          51314,
          467,
          311,
          867,
          11,
          867,
          3547,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1596644559352518,
        "compression_ratio": 1.7256317689530687,
        "end": 1289.36,
        "id": 461,
        "no_speech_prob": 0.000007527984507760266,
        "seek": 126636,
        "start": 1286.36,
        "temperature": 0,
        "text": " So it's typically stored in binary format,",
        "tokens": [
          51364,
          407,
          309,
          311,
          5850,
          12187,
          294,
          17434,
          7877,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.1596644559352518,
        "compression_ratio": 1.7256317689530687,
        "end": 1295.36,
        "id": 462,
        "no_speech_prob": 0.000007527984507760266,
        "seek": 126636,
        "start": 1289.36,
        "temperature": 0,
        "text": " raw digital data, so that to have it be the smallest file size.",
        "tokens": [
          51514,
          8936,
          4562,
          1412,
          11,
          370,
          300,
          281,
          362,
          309,
          312,
          264,
          16998,
          3991,
          2744,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.15133255989320815,
        "compression_ratio": 1.6339869281045751,
        "end": 1297.36,
        "id": 463,
        "no_speech_prob": 0.0003301505639683455,
        "seek": 129536,
        "start": 1295.36,
        "temperature": 0,
        "text": " So these are the two files that we need.",
        "tokens": [
          50364,
          407,
          613,
          366,
          264,
          732,
          7098,
          300,
          321,
          643,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.15133255989320815,
        "compression_ratio": 1.6339869281045751,
        "end": 1299.36,
        "id": 464,
        "no_speech_prob": 0.0003301505639683455,
        "seek": 129536,
        "start": 1297.36,
        "temperature": 0,
        "text": " Let's go take a look at those.",
        "tokens": [
          50464,
          961,
          311,
          352,
          747,
          257,
          574,
          412,
          729,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.15133255989320815,
        "compression_ratio": 1.6339869281045751,
        "end": 1304.36,
        "id": 465,
        "no_speech_prob": 0.0003301505639683455,
        "seek": 129536,
        "start": 1299.36,
        "temperature": 0,
        "text": " So the next step for us is to take these two files.",
        "tokens": [
          50564,
          407,
          264,
          958,
          1823,
          337,
          505,
          307,
          281,
          747,
          613,
          732,
          7098,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.15133255989320815,
        "compression_ratio": 1.6339869281045751,
        "end": 1306.36,
        "id": 466,
        "no_speech_prob": 0.0003301505639683455,
        "seek": 129536,
        "start": 1304.36,
        "temperature": 0,
        "text": " I'm going to copy them.",
        "tokens": [
          50814,
          286,
          478,
          516,
          281,
          5055,
          552,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.15133255989320815,
        "compression_ratio": 1.6339869281045751,
        "end": 1309.36,
        "id": 467,
        "no_speech_prob": 0.0003301505639683455,
        "seek": 129536,
        "start": 1306.36,
        "temperature": 0,
        "text": " And actually, I think I could probably just drag them",
        "tokens": [
          50914,
          400,
          767,
          11,
          286,
          519,
          286,
          727,
          1391,
          445,
          5286,
          552,
          51064
        ]
      },
      {
        "avg_logprob": -0.15133255989320815,
        "compression_ratio": 1.6339869281045751,
        "end": 1311.36,
        "id": 468,
        "no_speech_prob": 0.0003301505639683455,
        "seek": 129536,
        "start": 1309.36,
        "temperature": 0,
        "text": " into Visual Studio Code because I want",
        "tokens": [
          51064,
          666,
          23187,
          13500,
          15549,
          570,
          286,
          528,
          51164
        ]
      },
      {
        "avg_logprob": -0.15133255989320815,
        "compression_ratio": 1.6339869281045751,
        "end": 1312.36,
        "id": 469,
        "no_speech_prob": 0.0003301505639683455,
        "seek": 129536,
        "start": 1311.36,
        "temperature": 0,
        "text": " them to be part of this example.",
        "tokens": [
          51164,
          552,
          281,
          312,
          644,
          295,
          341,
          1365,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.15133255989320815,
        "compression_ratio": 1.6339869281045751,
        "end": 1313.36,
        "id": 470,
        "no_speech_prob": 0.0003301505639683455,
        "seek": 129536,
        "start": 1312.36,
        "temperature": 0,
        "text": " Right.",
        "tokens": [
          51214,
          1779,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.15133255989320815,
        "compression_ratio": 1.6339869281045751,
        "end": 1314.36,
        "id": 471,
        "no_speech_prob": 0.0003301505639683455,
        "seek": 129536,
        "start": 1313.36,
        "temperature": 0,
        "text": " So we can see that they're here now.",
        "tokens": [
          51264,
          407,
          321,
          393,
          536,
          300,
          436,
          434,
          510,
          586,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.15133255989320815,
        "compression_ratio": 1.6339869281045751,
        "end": 1318.36,
        "id": 472,
        "no_speech_prob": 0.0003301505639683455,
        "seek": 129536,
        "start": 1314.36,
        "temperature": 0,
        "text": " Now that I have model.json and model.weights.bin",
        "tokens": [
          51314,
          823,
          300,
          286,
          362,
          2316,
          13,
          73,
          3015,
          293,
          2316,
          13,
          826,
          5761,
          13,
          13496,
          51514
        ]
      },
      {
        "avg_logprob": -0.15133255989320815,
        "compression_ratio": 1.6339869281045751,
        "end": 1321.36,
        "id": 473,
        "no_speech_prob": 0.0003301505639683455,
        "seek": 129536,
        "start": 1318.36,
        "temperature": 0,
        "text": " as a part of my project, if I were using the P5 web editor,",
        "tokens": [
          51514,
          382,
          257,
          644,
          295,
          452,
          1716,
          11,
          498,
          286,
          645,
          1228,
          264,
          430,
          20,
          3670,
          9839,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.15133255989320815,
        "compression_ratio": 1.6339869281045751,
        "end": 1323.36,
        "id": 474,
        "no_speech_prob": 0.0003301505639683455,
        "seek": 129536,
        "start": 1321.36,
        "temperature": 0,
        "text": " I'd need to upload these files.",
        "tokens": [
          51664,
          286,
          1116,
          643,
          281,
          6580,
          613,
          7098,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.15133255989320815,
        "compression_ratio": 1.6339869281045751,
        "end": 1324.36,
        "id": 475,
        "no_speech_prob": 0.0003301505639683455,
        "seek": 129536,
        "start": 1323.36,
        "temperature": 0,
        "text": " I'm not sure if that's actually possible.",
        "tokens": [
          51764,
          286,
          478,
          406,
          988,
          498,
          300,
          311,
          767,
          1944,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1496036017118995,
        "compression_ratio": 1.6859504132231404,
        "end": 1326.36,
        "id": 476,
        "no_speech_prob": 0.0009547087829560041,
        "seek": 132436,
        "start": 1324.36,
        "temperature": 0,
        "text": " I'll have to look into that.",
        "tokens": [
          50364,
          286,
          603,
          362,
          281,
          574,
          666,
          300,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1496036017118995,
        "compression_ratio": 1.6859504132231404,
        "end": 1328.36,
        "id": 477,
        "no_speech_prob": 0.0009547087829560041,
        "seek": 132436,
        "start": 1326.36,
        "temperature": 0,
        "text": " And then if we look at model.json, for example,",
        "tokens": [
          50464,
          400,
          550,
          498,
          321,
          574,
          412,
          2316,
          13,
          73,
          3015,
          11,
          337,
          1365,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.1496036017118995,
        "compression_ratio": 1.6859504132231404,
        "end": 1330.36,
        "id": 478,
        "no_speech_prob": 0.0009547087829560041,
        "seek": 132436,
        "start": 1328.36,
        "temperature": 0,
        "text": " you can see, and I'm going to hit Save,",
        "tokens": [
          50564,
          291,
          393,
          536,
          11,
          293,
          286,
          478,
          516,
          281,
          2045,
          15541,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.1496036017118995,
        "compression_ratio": 1.6859504132231404,
        "end": 1333.36,
        "id": 479,
        "no_speech_prob": 0.0009547087829560041,
        "seek": 132436,
        "start": 1330.36,
        "temperature": 0,
        "text": " we can see this is the model topology.",
        "tokens": [
          50664,
          321,
          393,
          536,
          341,
          307,
          264,
          2316,
          1192,
          1793,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1496036017118995,
        "compression_ratio": 1.6859504132231404,
        "end": 1335.36,
        "id": 480,
        "no_speech_prob": 0.0009547087829560041,
        "seek": 132436,
        "start": 1333.36,
        "temperature": 0,
        "text": " It's a sequential model.",
        "tokens": [
          50814,
          467,
          311,
          257,
          42881,
          2316,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1496036017118995,
        "compression_ratio": 1.6859504132231404,
        "end": 1337.36,
        "id": 481,
        "no_speech_prob": 0.0009547087829560041,
        "seek": 132436,
        "start": 1335.36,
        "temperature": 0,
        "text": " And these are the inputs.",
        "tokens": [
          50914,
          400,
          613,
          366,
          264,
          15743,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1496036017118995,
        "compression_ratio": 1.6859504132231404,
        "end": 1340.36,
        "id": 482,
        "no_speech_prob": 0.0009547087829560041,
        "seek": 132436,
        "start": 1337.36,
        "temperature": 0,
        "text": " The inputs are 7 by 7 by 256.",
        "tokens": [
          51014,
          440,
          15743,
          366,
          1614,
          538,
          1614,
          538,
          38882,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1496036017118995,
        "compression_ratio": 1.6859504132231404,
        "end": 1345.36,
        "id": 483,
        "no_speech_prob": 0.0009547087829560041,
        "seek": 132436,
        "start": 1340.36,
        "temperature": 0,
        "text": " And somewhere, ah, yes, ml5 specs.",
        "tokens": [
          51164,
          400,
          4079,
          11,
          3716,
          11,
          2086,
          11,
          23271,
          20,
          27911,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1496036017118995,
        "compression_ratio": 1.6859504132231404,
        "end": 1348.36,
        "id": 484,
        "no_speech_prob": 0.0009547087829560041,
        "seek": 132436,
        "start": 1345.36,
        "temperature": 0,
        "text": " These are the labels, happy and sad.",
        "tokens": [
          51414,
          1981,
          366,
          264,
          16949,
          11,
          2055,
          293,
          4227,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1496036017118995,
        "compression_ratio": 1.6859504132231404,
        "end": 1350.36,
        "id": 485,
        "no_speech_prob": 0.0009547087829560041,
        "seek": 132436,
        "start": 1348.36,
        "temperature": 0,
        "text": " There's all sorts of other stuff.",
        "tokens": [
          51564,
          821,
          311,
          439,
          7527,
          295,
          661,
          1507,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1496036017118995,
        "compression_ratio": 1.6859504132231404,
        "end": 1351.36,
        "id": 486,
        "no_speech_prob": 0.0009547087829560041,
        "seek": 132436,
        "start": 1350.36,
        "temperature": 0,
        "text": " There's some dense layers.",
        "tokens": [
          51664,
          821,
          311,
          512,
          18011,
          7914,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1496036017118995,
        "compression_ratio": 1.6859504132231404,
        "end": 1353.36,
        "id": 487,
        "no_speech_prob": 0.0009547087829560041,
        "seek": 132436,
        "start": 1351.36,
        "temperature": 0,
        "text": " And there's where it gets the weights.",
        "tokens": [
          51714,
          400,
          456,
          311,
          689,
          309,
          2170,
          264,
          17443,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.17432131729726716,
        "compression_ratio": 1.6452830188679246,
        "end": 1356.36,
        "id": 488,
        "no_speech_prob": 0.000007183260549936676,
        "seek": 135336,
        "start": 1353.36,
        "temperature": 0,
        "text": " And it's using TensorFlow layers and TensorFlow.js.",
        "tokens": [
          50364,
          400,
          309,
          311,
          1228,
          37624,
          7914,
          293,
          37624,
          13,
          25530,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.17432131729726716,
        "compression_ratio": 1.6452830188679246,
        "end": 1359.36,
        "id": 489,
        "no_speech_prob": 0.000007183260549936676,
        "seek": 135336,
        "start": 1356.36,
        "temperature": 0,
        "text": " So all this information is in here.",
        "tokens": [
          50514,
          407,
          439,
          341,
          1589,
          307,
          294,
          510,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17432131729726716,
        "compression_ratio": 1.6452830188679246,
        "end": 1362.36,
        "id": 490,
        "no_speech_prob": 0.000007183260549936676,
        "seek": 135336,
        "start": 1359.36,
        "temperature": 0,
        "text": " The bin file is not something we can really look at",
        "tokens": [
          50664,
          440,
          5171,
          3991,
          307,
          406,
          746,
          321,
          393,
          534,
          574,
          412,
          50814
        ]
      },
      {
        "avg_logprob": -0.17432131729726716,
        "compression_ratio": 1.6452830188679246,
        "end": 1364.36,
        "id": 491,
        "no_speech_prob": 0.000007183260549936676,
        "seek": 135336,
        "start": 1362.36,
        "temperature": 0,
        "text": " because it's in binary format.",
        "tokens": [
          50814,
          570,
          309,
          311,
          294,
          17434,
          7877,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17432131729726716,
        "compression_ratio": 1.6452830188679246,
        "end": 1366.36,
        "id": 492,
        "no_speech_prob": 0.000007183260549936676,
        "seek": 135336,
        "start": 1364.36,
        "temperature": 0,
        "text": " But we can know that all of the numbers,",
        "tokens": [
          50914,
          583,
          321,
          393,
          458,
          300,
          439,
          295,
          264,
          3547,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.17432131729726716,
        "compression_ratio": 1.6452830188679246,
        "end": 1367.36,
        "id": 493,
        "no_speech_prob": 0.000007183260549936676,
        "seek": 135336,
        "start": 1366.36,
        "temperature": 0,
        "text": " those weights are there.",
        "tokens": [
          51014,
          729,
          17443,
          366,
          456,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17432131729726716,
        "compression_ratio": 1.6452830188679246,
        "end": 1369.36,
        "id": 494,
        "no_speech_prob": 0.000007183260549936676,
        "seek": 135336,
        "start": 1367.36,
        "temperature": 0,
        "text": " So now, guess what?",
        "tokens": [
          51064,
          407,
          586,
          11,
          2041,
          437,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.17432131729726716,
        "compression_ratio": 1.6452830188679246,
        "end": 1371.36,
        "id": 495,
        "no_speech_prob": 0.000007183260549936676,
        "seek": 135336,
        "start": 1369.36,
        "temperature": 0,
        "text": " We're going to go back to our code.",
        "tokens": [
          51164,
          492,
          434,
          516,
          281,
          352,
          646,
          281,
          527,
          3089,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.17432131729726716,
        "compression_ratio": 1.6452830188679246,
        "end": 1375.36,
        "id": 496,
        "no_speech_prob": 0.000007183260549936676,
        "seek": 135336,
        "start": 1371.36,
        "temperature": 0,
        "text": " And I'm going to look at the steps here in setup again.",
        "tokens": [
          51264,
          400,
          286,
          478,
          516,
          281,
          574,
          412,
          264,
          4439,
          510,
          294,
          8657,
          797,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.17432131729726716,
        "compression_ratio": 1.6452830188679246,
        "end": 1380.36,
        "id": 497,
        "no_speech_prob": 0.000007183260549936676,
        "seek": 135336,
        "start": 1375.36,
        "temperature": 0,
        "text": " So in setup, the first thing that I do is I create",
        "tokens": [
          51464,
          407,
          294,
          8657,
          11,
          264,
          700,
          551,
          300,
          286,
          360,
          307,
          286,
          1884,
          51714
        ]
      },
      {
        "avg_logprob": -0.17432131729726716,
        "compression_ratio": 1.6452830188679246,
        "end": 1382.36,
        "id": 498,
        "no_speech_prob": 0.000007183260549936676,
        "seek": 135336,
        "start": 1380.36,
        "temperature": 0,
        "text": " a feature extractor with mobile net.",
        "tokens": [
          51714,
          257,
          4111,
          8947,
          284,
          365,
          6013,
          2533,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.16351395657188014,
        "compression_ratio": 1.645631067961165,
        "end": 1389.36,
        "id": 499,
        "no_speech_prob": 0.00002710858461796306,
        "seek": 138236,
        "start": 1382.36,
        "temperature": 0,
        "text": " When that model is ready, hold on, I'm thinking for a second.",
        "tokens": [
          50364,
          1133,
          300,
          2316,
          307,
          1919,
          11,
          1797,
          322,
          11,
          286,
          478,
          1953,
          337,
          257,
          1150,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.16351395657188014,
        "compression_ratio": 1.645631067961165,
        "end": 1396.36,
        "id": 500,
        "no_speech_prob": 0.00002710858461796306,
        "seek": 138236,
        "start": 1394.36,
        "temperature": 0,
        "text": " Just time out for a second.",
        "tokens": [
          50964,
          1449,
          565,
          484,
          337,
          257,
          1150,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.16351395657188014,
        "compression_ratio": 1.645631067961165,
        "end": 1398.36,
        "id": 501,
        "no_speech_prob": 0.00002710858461796306,
        "seek": 138236,
        "start": 1396.36,
        "temperature": 0,
        "text": " I just want to look.",
        "tokens": [
          51064,
          286,
          445,
          528,
          281,
          574,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.16351395657188014,
        "compression_ratio": 1.645631067961165,
        "end": 1401.36,
        "id": 502,
        "no_speech_prob": 0.00002710858461796306,
        "seek": 138236,
        "start": 1398.36,
        "temperature": 0,
        "text": " Unfortunately, the documentation isn't up on the website for this.",
        "tokens": [
          51164,
          8590,
          11,
          264,
          14333,
          1943,
          380,
          493,
          322,
          264,
          3144,
          337,
          341,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.16351395657188014,
        "compression_ratio": 1.645631067961165,
        "end": 1404.36,
        "id": 503,
        "no_speech_prob": 0.00002710858461796306,
        "seek": 138236,
        "start": 1401.36,
        "temperature": 0,
        "text": " So I just want to check something to make sure I'm doing it correctly.",
        "tokens": [
          51314,
          407,
          286,
          445,
          528,
          281,
          1520,
          746,
          281,
          652,
          988,
          286,
          478,
          884,
          309,
          8944,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.16351395657188014,
        "compression_ratio": 1.645631067961165,
        "end": 1406.36,
        "id": 504,
        "no_speech_prob": 0.00002710858461796306,
        "seek": 138236,
        "start": 1404.36,
        "temperature": 0,
        "text": " I'm going to look at it over here real briefly.",
        "tokens": [
          51464,
          286,
          478,
          516,
          281,
          574,
          412,
          309,
          670,
          510,
          957,
          10515,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.16351395657188014,
        "compression_ratio": 1.645631067961165,
        "end": 1410.36,
        "id": 505,
        "no_speech_prob": 0.00002710858461796306,
        "seek": 138236,
        "start": 1406.36,
        "temperature": 0,
        "text": " I'm just looking in the existing examples.",
        "tokens": [
          51564,
          286,
          478,
          445,
          1237,
          294,
          264,
          6741,
          5110,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20105970575568383,
        "compression_ratio": 1.4867724867724867,
        "end": 1412.36,
        "id": 506,
        "no_speech_prob": 0.00020026932179462165,
        "seek": 141036,
        "start": 1410.36,
        "temperature": 0,
        "text": " There actually is an existing example for this.",
        "tokens": [
          50364,
          821,
          767,
          307,
          364,
          6741,
          1365,
          337,
          341,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.20105970575568383,
        "compression_ratio": 1.4867724867724867,
        "end": 1414.36,
        "id": 507,
        "no_speech_prob": 0.00020026932179462165,
        "seek": 141036,
        "start": 1412.36,
        "temperature": 0,
        "text": " I don't know why I'm not pulling it up here.",
        "tokens": [
          50464,
          286,
          500,
          380,
          458,
          983,
          286,
          478,
          406,
          8407,
          309,
          493,
          510,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.20105970575568383,
        "compression_ratio": 1.4867724867724867,
        "end": 1416.36,
        "id": 508,
        "no_speech_prob": 0.00020026932179462165,
        "seek": 141036,
        "start": 1414.36,
        "temperature": 0,
        "text": " I probably should.",
        "tokens": [
          50564,
          286,
          1391,
          820,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20105970575568383,
        "compression_ratio": 1.4867724867724867,
        "end": 1422.36,
        "id": 509,
        "no_speech_prob": 0.00020026932179462165,
        "seek": 141036,
        "start": 1420.36,
        "temperature": 0,
        "text": " I think it's here.",
        "tokens": [
          50864,
          286,
          519,
          309,
          311,
          510,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20105970575568383,
        "compression_ratio": 1.4867724867724867,
        "end": 1425.36,
        "id": 510,
        "no_speech_prob": 0.00020026932179462165,
        "seek": 141036,
        "start": 1422.36,
        "temperature": 0,
        "text": " I just need to understand the order of this.",
        "tokens": [
          50964,
          286,
          445,
          643,
          281,
          1223,
          264,
          1668,
          295,
          341,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20105970575568383,
        "compression_ratio": 1.4867724867724867,
        "end": 1429.36,
        "id": 511,
        "no_speech_prob": 0.00020026932179462165,
        "seek": 141036,
        "start": 1425.36,
        "temperature": 0,
        "text": " Classifier. Oh, yeah. Okay.",
        "tokens": [
          51114,
          9471,
          9902,
          13,
          876,
          11,
          1338,
          13,
          1033,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20105970575568383,
        "compression_ratio": 1.4867724867724867,
        "end": 1432.36,
        "id": 512,
        "no_speech_prob": 0.00020026932179462165,
        "seek": 141036,
        "start": 1429.36,
        "temperature": 0,
        "text": " That's interesting.",
        "tokens": [
          51314,
          663,
          311,
          1880,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20105970575568383,
        "compression_ratio": 1.4867724867724867,
        "end": 1433.36,
        "id": 513,
        "no_speech_prob": 0.00020026932179462165,
        "seek": 141036,
        "start": 1432.36,
        "temperature": 0,
        "text": " I guess that works.",
        "tokens": [
          51464,
          286,
          2041,
          300,
          1985,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20105970575568383,
        "compression_ratio": 1.4867724867724867,
        "end": 1435.36,
        "id": 514,
        "no_speech_prob": 0.00020026932179462165,
        "seek": 141036,
        "start": 1433.36,
        "temperature": 0,
        "text": " The order of all this stuff is weird.",
        "tokens": [
          51514,
          440,
          1668,
          295,
          439,
          341,
          1507,
          307,
          3657,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.24379677608095365,
        "compression_ratio": 1.3088235294117647,
        "end": 1438.36,
        "id": 515,
        "no_speech_prob": 0.0017007100395858288,
        "seek": 143536,
        "start": 1435.36,
        "temperature": 0,
        "text": " And I feel like this is a thing we have to work on with the library.",
        "tokens": [
          50364,
          400,
          286,
          841,
          411,
          341,
          307,
          257,
          551,
          321,
          362,
          281,
          589,
          322,
          365,
          264,
          6405,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.24379677608095365,
        "compression_ratio": 1.3088235294117647,
        "end": 1448.36,
        "id": 516,
        "no_speech_prob": 0.0017007100395858288,
        "seek": 143536,
        "start": 1446.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50914,
          1057,
          558,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.24379677608095365,
        "compression_ratio": 1.3088235294117647,
        "end": 1452.36,
        "id": 517,
        "no_speech_prob": 0.0017007100395858288,
        "seek": 143536,
        "start": 1448.36,
        "temperature": 0,
        "text": " I'm going to not worry about this too much.",
        "tokens": [
          51014,
          286,
          478,
          516,
          281,
          406,
          3292,
          466,
          341,
          886,
          709,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.24379677608095365,
        "compression_ratio": 1.3088235294117647,
        "end": 1454.36,
        "id": 518,
        "no_speech_prob": 0.0017007100395858288,
        "seek": 143536,
        "start": 1452.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51214,
          1033,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.24379677608095365,
        "compression_ratio": 1.3088235294117647,
        "end": 1464.36,
        "id": 519,
        "no_speech_prob": 0.0017007100395858288,
        "seek": 143536,
        "start": 1458.36,
        "temperature": 0,
        "text": " So once the model is ready, then I can go ahead.",
        "tokens": [
          51514,
          407,
          1564,
          264,
          2316,
          307,
          1919,
          11,
          550,
          286,
          393,
          352,
          2286,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.21480385462443033,
        "compression_ratio": 1.4532374100719425,
        "end": 1469.36,
        "id": 520,
        "no_speech_prob": 0.00015843591245356947,
        "seek": 146436,
        "start": 1465.36,
        "temperature": 0,
        "text": " This is the function for when the model is ready.",
        "tokens": [
          50414,
          639,
          307,
          264,
          2445,
          337,
          562,
          264,
          2316,
          307,
          1919,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.21480385462443033,
        "compression_ratio": 1.4532374100719425,
        "end": 1472.36,
        "id": 521,
        "no_speech_prob": 0.00015843591245356947,
        "seek": 146436,
        "start": 1469.36,
        "temperature": 0,
        "text": " I can now go and say classifier.load.",
        "tokens": [
          50614,
          286,
          393,
          586,
          352,
          293,
          584,
          1508,
          9902,
          13,
          2907,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21480385462443033,
        "compression_ratio": 1.4532374100719425,
        "end": 1474.36,
        "id": 522,
        "no_speech_prob": 0.00015843591245356947,
        "seek": 146436,
        "start": 1472.36,
        "temperature": 0,
        "text": " And guess what I want to tell it to load?",
        "tokens": [
          50764,
          400,
          2041,
          437,
          286,
          528,
          281,
          980,
          309,
          281,
          3677,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.21480385462443033,
        "compression_ratio": 1.4532374100719425,
        "end": 1476.36,
        "id": 523,
        "no_speech_prob": 0.00015843591245356947,
        "seek": 146436,
        "start": 1474.36,
        "temperature": 0,
        "text": " Model.json.",
        "tokens": [
          50864,
          17105,
          13,
          73,
          3015,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.21480385462443033,
        "compression_ratio": 1.4532374100719425,
        "end": 1480.36,
        "id": 524,
        "no_speech_prob": 0.00015843591245356947,
        "seek": 146436,
        "start": 1476.36,
        "temperature": 0,
        "text": " And I'm going to say custom model ready.",
        "tokens": [
          50964,
          400,
          286,
          478,
          516,
          281,
          584,
          2375,
          2316,
          1919,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.21480385462443033,
        "compression_ratio": 1.4532374100719425,
        "end": 1484.36,
        "id": 525,
        "no_speech_prob": 0.00015843591245356947,
        "seek": 146436,
        "start": 1480.36,
        "temperature": 0,
        "text": " Custom model ready.",
        "tokens": [
          51164,
          16649,
          2316,
          1919,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.3241001475941051,
        "compression_ratio": 1.7004830917874396,
        "end": 1488.36,
        "id": 526,
        "no_speech_prob": 0.015663348138332367,
        "seek": 148436,
        "start": 1484.36,
        "temperature": 0,
        "text": " Custom model is ready.",
        "tokens": [
          50364,
          16649,
          2316,
          307,
          1919,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.3241001475941051,
        "compression_ratio": 1.7004830917874396,
        "end": 1491.36,
        "id": 527,
        "no_speech_prob": 0.015663348138332367,
        "seek": 148436,
        "start": 1488.36,
        "temperature": 0,
        "text": " So first, mobile net has to be loaded.",
        "tokens": [
          50564,
          407,
          700,
          11,
          6013,
          2533,
          575,
          281,
          312,
          13210,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.3241001475941051,
        "compression_ratio": 1.7004830917874396,
        "end": 1495.36,
        "id": 528,
        "no_speech_prob": 0.015663348138332367,
        "seek": 148436,
        "start": 1491.36,
        "temperature": 0,
        "text": " Once that's done, then the custom model can be loaded.",
        "tokens": [
          50714,
          3443,
          300,
          311,
          1096,
          11,
          550,
          264,
          2375,
          2316,
          393,
          312,
          13210,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.3241001475941051,
        "compression_ratio": 1.7004830917874396,
        "end": 1497.36,
        "id": 529,
        "no_speech_prob": 0.015663348138332367,
        "seek": 148436,
        "start": 1495.36,
        "temperature": 0,
        "text": " Now, look at this.",
        "tokens": [
          50914,
          823,
          11,
          574,
          412,
          341,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.3241001475941051,
        "compression_ratio": 1.7004830917874396,
        "end": 1499.36,
        "id": 530,
        "no_speech_prob": 0.015663348138332367,
        "seek": 148436,
        "start": 1497.36,
        "temperature": 0,
        "text": " Classifier.load.model.json.",
        "tokens": [
          51014,
          9471,
          9902,
          13,
          2907,
          13,
          8014,
          338,
          13,
          73,
          3015,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.3241001475941051,
        "compression_ratio": 1.7004830917874396,
        "end": 1501.36,
        "id": 531,
        "no_speech_prob": 0.015663348138332367,
        "seek": 148436,
        "start": 1499.36,
        "temperature": 0,
        "text": " Remember, there are two files.",
        "tokens": [
          51114,
          5459,
          11,
          456,
          366,
          732,
          7098,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.3241001475941051,
        "compression_ratio": 1.7004830917874396,
        "end": 1503.36,
        "id": 532,
        "no_speech_prob": 0.015663348138332367,
        "seek": 148436,
        "start": 1501.36,
        "temperature": 0,
        "text": " Model.weights.bin and model.json.",
        "tokens": [
          51214,
          17105,
          13,
          826,
          5761,
          13,
          13496,
          293,
          2316,
          13,
          73,
          3015,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.3241001475941051,
        "compression_ratio": 1.7004830917874396,
        "end": 1507.36,
        "id": 533,
        "no_speech_prob": 0.015663348138332367,
        "seek": 148436,
        "start": 1503.36,
        "temperature": 0,
        "text": " ml5 is set up to work that if you just tell it where the json file is,",
        "tokens": [
          51314,
          23271,
          20,
          307,
          992,
          493,
          281,
          589,
          300,
          498,
          291,
          445,
          980,
          309,
          689,
          264,
          361,
          3015,
          3991,
          307,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.3241001475941051,
        "compression_ratio": 1.7004830917874396,
        "end": 1510.36,
        "id": 534,
        "no_speech_prob": 0.015663348138332367,
        "seek": 148436,
        "start": 1507.36,
        "temperature": 0,
        "text": " model.weights.bin, then it will load the model.json.",
        "tokens": [
          51514,
          2316,
          13,
          826,
          5761,
          13,
          13496,
          11,
          550,
          309,
          486,
          3677,
          264,
          2316,
          13,
          73,
          3015,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.24035243813050997,
        "compression_ratio": 1.5708154506437768,
        "end": 1514.36,
        "id": 535,
        "no_speech_prob": 0.09137439727783203,
        "seek": 151036,
        "start": 1510.36,
        "temperature": 0,
        "text": " And set up to work that if you just tell it where the json file is,",
        "tokens": [
          50364,
          400,
          992,
          493,
          281,
          589,
          300,
          498,
          291,
          445,
          980,
          309,
          689,
          264,
          361,
          3015,
          3991,
          307,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.24035243813050997,
        "compression_ratio": 1.5708154506437768,
        "end": 1518.36,
        "id": 536,
        "no_speech_prob": 0.09137439727783203,
        "seek": 151036,
        "start": 1514.36,
        "temperature": 0,
        "text": " model.json, it will look for the corresponding model.weights.bin file",
        "tokens": [
          50564,
          2316,
          13,
          73,
          3015,
          11,
          309,
          486,
          574,
          337,
          264,
          11760,
          2316,
          13,
          826,
          5761,
          13,
          13496,
          3991,
          50764
        ]
      },
      {
        "avg_logprob": -0.24035243813050997,
        "compression_ratio": 1.5708154506437768,
        "end": 1520.36,
        "id": 537,
        "no_speech_prob": 0.09137439727783203,
        "seek": 151036,
        "start": 1518.36,
        "temperature": 0,
        "text": " in the same directory.",
        "tokens": [
          50764,
          294,
          264,
          912,
          21120,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.24035243813050997,
        "compression_ratio": 1.5708154506437768,
        "end": 1522.36,
        "id": 538,
        "no_speech_prob": 0.09137439727783203,
        "seek": 151036,
        "start": 1520.36,
        "temperature": 0,
        "text": " There are ways that you can customize what those file names are",
        "tokens": [
          50864,
          821,
          366,
          2098,
          300,
          291,
          393,
          19734,
          437,
          729,
          3991,
          5288,
          366,
          50964
        ]
      },
      {
        "avg_logprob": -0.24035243813050997,
        "compression_ratio": 1.5708154506437768,
        "end": 1525.36,
        "id": 539,
        "no_speech_prob": 0.09137439727783203,
        "seek": 151036,
        "start": 1522.36,
        "temperature": 0,
        "text": " and have them in different paths, but this is the simplest way of doing it.",
        "tokens": [
          50964,
          293,
          362,
          552,
          294,
          819,
          14518,
          11,
          457,
          341,
          307,
          264,
          22811,
          636,
          295,
          884,
          309,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.24035243813050997,
        "compression_ratio": 1.5708154506437768,
        "end": 1528.36,
        "id": 540,
        "no_speech_prob": 0.09137439727783203,
        "seek": 151036,
        "start": 1525.36,
        "temperature": 0,
        "text": " So let's see if this works now.",
        "tokens": [
          51114,
          407,
          718,
          311,
          536,
          498,
          341,
          1985,
          586,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.24035243813050997,
        "compression_ratio": 1.5708154506437768,
        "end": 1532.36,
        "id": 541,
        "no_speech_prob": 0.09137439727783203,
        "seek": 151036,
        "start": 1531.36,
        "temperature": 0,
        "text": " Model is ready.",
        "tokens": [
          51414,
          17105,
          307,
          1919,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.24035243813050997,
        "compression_ratio": 1.5708154506437768,
        "end": 1534.36,
        "id": 542,
        "no_speech_prob": 0.09137439727783203,
        "seek": 151036,
        "start": 1532.36,
        "temperature": 0,
        "text": " Ah!",
        "tokens": [
          51464,
          2438,
          0,
          51564
        ]
      },
      {
        "avg_logprob": -0.24035243813050997,
        "compression_ratio": 1.5708154506437768,
        "end": 1536.36,
        "id": 543,
        "no_speech_prob": 0.09137439727783203,
        "seek": 151036,
        "start": 1534.36,
        "temperature": 0,
        "text": " Got an error.",
        "tokens": [
          51564,
          5803,
          364,
          6713,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.3148613335951319,
        "compression_ratio": 1.2195121951219512,
        "end": 1540.36,
        "id": 544,
        "no_speech_prob": 0.002714709611609578,
        "seek": 153636,
        "start": 1537.36,
        "temperature": 0,
        "text": " What is this error?",
        "tokens": [
          50414,
          708,
          307,
          341,
          6713,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.3148613335951319,
        "compression_ratio": 1.2195121951219512,
        "end": 1544.36,
        "id": 545,
        "no_speech_prob": 0.002714709611609578,
        "seek": 153636,
        "start": 1542.36,
        "temperature": 0,
        "text": " That was sad.",
        "tokens": [
          50664,
          663,
          390,
          4227,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.3148613335951319,
        "compression_ratio": 1.2195121951219512,
        "end": 1555.36,
        "id": 546,
        "no_speech_prob": 0.002714709611609578,
        "seek": 153636,
        "start": 1552.36,
        "temperature": 0,
        "text": " Maybe it has zero.",
        "tokens": [
          51164,
          2704,
          309,
          575,
          4018,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.3148613335951319,
        "compression_ratio": 1.2195121951219512,
        "end": 1558.36,
        "id": 547,
        "no_speech_prob": 0.002714709611609578,
        "seek": 153636,
        "start": 1556.36,
        "temperature": 0,
        "text": " Let's look at...",
        "tokens": [
          51364,
          961,
          311,
          574,
          412,
          485,
          51464
        ]
      },
      {
        "avg_logprob": -0.3148613335951319,
        "compression_ratio": 1.2195121951219512,
        "end": 1560.36,
        "id": 548,
        "no_speech_prob": 0.002714709611609578,
        "seek": 153636,
        "start": 1558.36,
        "temperature": 0,
        "text": " 5 megabytes, that makes sense.",
        "tokens": [
          51464,
          1025,
          10816,
          24538,
          11,
          300,
          1669,
          2020,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.3148613335951319,
        "compression_ratio": 1.2195121951219512,
        "end": 1562.36,
        "id": 549,
        "no_speech_prob": 0.002714709611609578,
        "seek": 153636,
        "start": 1560.36,
        "temperature": 0,
        "text": " That's right.",
        "tokens": [
          51564,
          663,
          311,
          558,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.3148613335951319,
        "compression_ratio": 1.2195121951219512,
        "end": 1564.36,
        "id": 550,
        "no_speech_prob": 0.002714709611609578,
        "seek": 153636,
        "start": 1562.36,
        "temperature": 0,
        "text": " It's definitely like weights there.",
        "tokens": [
          51664,
          467,
          311,
          2138,
          411,
          17443,
          456,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.21682062456684728,
        "compression_ratio": 1.2327586206896552,
        "end": 1568.36,
        "id": 551,
        "no_speech_prob": 0.0005527600296773016,
        "seek": 156636,
        "start": 1566.36,
        "temperature": 0,
        "text": " Oh, it didn't find it.",
        "tokens": [
          50364,
          876,
          11,
          309,
          994,
          380,
          915,
          309,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.21682062456684728,
        "compression_ratio": 1.2327586206896552,
        "end": 1569.36,
        "id": 552,
        "no_speech_prob": 0.0005527600296773016,
        "seek": 156636,
        "start": 1568.36,
        "temperature": 0,
        "text": " Oh, weird.",
        "tokens": [
          50464,
          876,
          11,
          3657,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.21682062456684728,
        "compression_ratio": 1.2327586206896552,
        "end": 1571.36,
        "id": 553,
        "no_speech_prob": 0.0005527600296773016,
        "seek": 156636,
        "start": 1569.36,
        "temperature": 0,
        "text": " Oh!",
        "tokens": [
          50514,
          876,
          0,
          50614
        ]
      },
      {
        "avg_logprob": -0.21682062456684728,
        "compression_ratio": 1.2327586206896552,
        "end": 1577.36,
        "id": 554,
        "no_speech_prob": 0.0005527600296773016,
        "seek": 156636,
        "start": 1574.36,
        "temperature": 0,
        "text": " I know what the problem is.",
        "tokens": [
          50764,
          286,
          458,
          437,
          264,
          1154,
          307,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.21682062456684728,
        "compression_ratio": 1.2327586206896552,
        "end": 1582.36,
        "id": 555,
        "no_speech_prob": 0.0005527600296773016,
        "seek": 156636,
        "start": 1579.36,
        "temperature": 0,
        "text": " Ugh, I don't like this.",
        "tokens": [
          51014,
          16506,
          11,
          286,
          500,
          380,
          411,
          341,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.21682062456684728,
        "compression_ratio": 1.2327586206896552,
        "end": 1585.36,
        "id": 556,
        "no_speech_prob": 0.0005527600296773016,
        "seek": 156636,
        "start": 1582.36,
        "temperature": 0,
        "text": " I think it's going to work now.",
        "tokens": [
          51164,
          286,
          519,
          309,
          311,
          516,
          281,
          589,
          586,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.21682062456684728,
        "compression_ratio": 1.2327586206896552,
        "end": 1587.36,
        "id": 557,
        "no_speech_prob": 0.0005527600296773016,
        "seek": 156636,
        "start": 1585.36,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51314,
          865,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.21682062456684728,
        "compression_ratio": 1.2327586206896552,
        "end": 1594.36,
        "id": 558,
        "no_speech_prob": 0.0005527600296773016,
        "seek": 156636,
        "start": 1591.36,
        "temperature": 0,
        "text": " So it did load.",
        "tokens": [
          51614,
          407,
          309,
          630,
          3677,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20389718787614688,
        "compression_ratio": 1.5103092783505154,
        "end": 1598.36,
        "id": 559,
        "no_speech_prob": 0.0005033235065639019,
        "seek": 159636,
        "start": 1596.36,
        "temperature": 0,
        "text": " So the issue is the following.",
        "tokens": [
          50364,
          407,
          264,
          2734,
          307,
          264,
          3480,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.20389718787614688,
        "compression_ratio": 1.5103092783505154,
        "end": 1601.36,
        "id": 560,
        "no_speech_prob": 0.0005033235065639019,
        "seek": 159636,
        "start": 1598.36,
        "temperature": 0,
        "text": " This is actually kind of like a bug",
        "tokens": [
          50464,
          639,
          307,
          767,
          733,
          295,
          411,
          257,
          7426,
          50614
        ]
      },
      {
        "avg_logprob": -0.20389718787614688,
        "compression_ratio": 1.5103092783505154,
        "end": 1606.36,
        "id": 561,
        "no_speech_prob": 0.0005033235065639019,
        "seek": 159636,
        "start": 1601.36,
        "temperature": 0,
        "text": " because it's not looking in the local directory",
        "tokens": [
          50614,
          570,
          309,
          311,
          406,
          1237,
          294,
          264,
          2654,
          21120,
          50864
        ]
      },
      {
        "avg_logprob": -0.20389718787614688,
        "compression_ratio": 1.5103092783505154,
        "end": 1609.36,
        "id": 562,
        "no_speech_prob": 0.0005033235065639019,
        "seek": 159636,
        "start": 1606.36,
        "temperature": 0,
        "text": " unless you specifically do the./.",
        "tokens": [
          50864,
          5969,
          291,
          4682,
          360,
          264,
          2411,
          48550,
          51014
        ]
      },
      {
        "avg_logprob": -0.20389718787614688,
        "compression_ratio": 1.5103092783505154,
        "end": 1613.36,
        "id": 563,
        "no_speech_prob": 0.0005033235065639019,
        "seek": 159636,
        "start": 1609.36,
        "temperature": 0,
        "text": " But I think it would be simpler to let the user just do this.",
        "tokens": [
          51014,
          583,
          286,
          519,
          309,
          576,
          312,
          18587,
          281,
          718,
          264,
          4195,
          445,
          360,
          341,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20389718787614688,
        "compression_ratio": 1.5103092783505154,
        "end": 1618.36,
        "id": 564,
        "no_speech_prob": 0.0005033235065639019,
        "seek": 159636,
        "start": 1613.36,
        "temperature": 0,
        "text": " So that is a bug to file.",
        "tokens": [
          51214,
          407,
          300,
          307,
          257,
          7426,
          281,
          3991,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20389718787614688,
        "compression_ratio": 1.5103092783505154,
        "end": 1621.36,
        "id": 565,
        "no_speech_prob": 0.0005033235065639019,
        "seek": 159636,
        "start": 1618.36,
        "temperature": 0,
        "text": " Let me do that real quick.",
        "tokens": [
          51464,
          961,
          385,
          360,
          300,
          957,
          1702,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20389718787614688,
        "compression_ratio": 1.5103092783505154,
        "end": 1625.36,
        "id": 566,
        "no_speech_prob": 0.0005033235065639019,
        "seek": 159636,
        "start": 1622.36,
        "temperature": 0,
        "text": " But I won't worry about that.",
        "tokens": [
          51664,
          583,
          286,
          1582,
          380,
          3292,
          466,
          300,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.32630436237041766,
        "compression_ratio": 1.0851063829787233,
        "end": 1629.36,
        "id": 567,
        "no_speech_prob": 0.0015245015965774655,
        "seek": 162636,
        "start": 1626.36,
        "temperature": 0,
        "text": " Right now.",
        "tokens": [
          50364,
          1779,
          586,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.32630436237041766,
        "compression_ratio": 1.0851063829787233,
        "end": 1636.36,
        "id": 568,
        "no_speech_prob": 0.0015245015965774655,
        "seek": 162636,
        "start": 1634.36,
        "temperature": 0,
        "text": " What is this?",
        "tokens": [
          50764,
          708,
          307,
          341,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.32630436237041766,
        "compression_ratio": 1.0851063829787233,
        "end": 1644.36,
        "id": 569,
        "no_speech_prob": 0.0015245015965774655,
        "seek": 162636,
        "start": 1636.36,
        "temperature": 0,
        "text": " Feature, extractor, model loading, relative path.",
        "tokens": [
          50864,
          3697,
          1503,
          11,
          8947,
          284,
          11,
          2316,
          15114,
          11,
          4972,
          3100,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.32630436237041766,
        "compression_ratio": 1.0851063829787233,
        "end": 1651.36,
        "id": 570,
        "no_speech_prob": 0.0015245015965774655,
        "seek": 162636,
        "start": 1649.36,
        "temperature": 0,
        "text": " So is this...",
        "tokens": [
          51514,
          407,
          307,
          341,
          485,
          51614
        ]
      },
      {
        "avg_logprob": -0.32630436237041766,
        "compression_ratio": 1.0851063829787233,
        "end": 1653.36,
        "id": 571,
        "no_speech_prob": 0.0015245015965774655,
        "seek": 162636,
        "start": 1651.36,
        "temperature": 0,
        "text": " Look at this.",
        "tokens": [
          51614,
          2053,
          412,
          341,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.28549309877248913,
        "compression_ratio": 1.2,
        "end": 1658.36,
        "id": 572,
        "no_speech_prob": 0.005058242008090019,
        "seek": 165336,
        "start": 1654.36,
        "temperature": 0,
        "text": " The following works.",
        "tokens": [
          50414,
          440,
          3480,
          1985,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.28549309877248913,
        "compression_ratio": 1.2,
        "end": 1665.36,
        "id": 573,
        "no_speech_prob": 0.005058242008090019,
        "seek": 165336,
        "start": 1658.36,
        "temperature": 0,
        "text": " Making a live example live on YouTube right now.",
        "tokens": [
          50614,
          14595,
          257,
          1621,
          1365,
          1621,
          322,
          3088,
          558,
          586,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.28549309877248913,
        "compression_ratio": 1.2,
        "end": 1669.36,
        "id": 574,
        "no_speech_prob": 0.005058242008090019,
        "seek": 165336,
        "start": 1665.36,
        "temperature": 0,
        "text": " The following works.",
        "tokens": [
          50964,
          440,
          3480,
          1985,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.24214225345187718,
        "compression_ratio": 1.2285714285714286,
        "end": 1683.36,
        "id": 575,
        "no_speech_prob": 0.07580260187387466,
        "seek": 166936,
        "start": 1670.36,
        "temperature": 0,
        "text": " However, just referencing the file name",
        "tokens": [
          50414,
          2908,
          11,
          445,
          40582,
          264,
          3991,
          1315,
          51064
        ]
      },
      {
        "avg_logprob": -0.24214225345187718,
        "compression_ratio": 1.2285714285714286,
        "end": 1687.36,
        "id": 576,
        "no_speech_prob": 0.07580260187387466,
        "seek": 166936,
        "start": 1683.36,
        "temperature": 0,
        "text": " and expecting it to be the local path",
        "tokens": [
          51064,
          293,
          9650,
          309,
          281,
          312,
          264,
          2654,
          3100,
          51264
        ]
      },
      {
        "avg_logprob": -0.24214225345187718,
        "compression_ratio": 1.2285714285714286,
        "end": 1698.36,
        "id": 577,
        "no_speech_prob": 0.07580260187387466,
        "seek": 166936,
        "start": 1687.36,
        "temperature": 0,
        "text": " doesn't work because it looks for model.weights.bin",
        "tokens": [
          51264,
          1177,
          380,
          589,
          570,
          309,
          1542,
          337,
          2316,
          13,
          826,
          5761,
          13,
          13496,
          51814
        ]
      },
      {
        "avg_logprob": -0.1886999316331817,
        "compression_ratio": 1.2142857142857142,
        "end": 1702.36,
        "id": 578,
        "no_speech_prob": 0.005137545522302389,
        "seek": 169836,
        "start": 1699.36,
        "temperature": 0,
        "text": " somewhere else.",
        "tokens": [
          50414,
          4079,
          1646,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1886999316331817,
        "compression_ratio": 1.2142857142857142,
        "end": 1707.36,
        "id": 579,
        "no_speech_prob": 0.005137545522302389,
        "seek": 169836,
        "start": 1703.36,
        "temperature": 0,
        "text": " This is a minor detail because we can definitely get it to work.",
        "tokens": [
          50614,
          639,
          307,
          257,
          6696,
          2607,
          570,
          321,
          393,
          2138,
          483,
          309,
          281,
          589,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1886999316331817,
        "compression_ratio": 1.2142857142857142,
        "end": 1717.36,
        "id": 580,
        "no_speech_prob": 0.005137545522302389,
        "seek": 169836,
        "start": 1713.36,
        "temperature": 0,
        "text": " Let's get this error.",
        "tokens": [
          51114,
          961,
          311,
          483,
          341,
          6713,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1886999316331817,
        "compression_ratio": 1.2142857142857142,
        "end": 1726.36,
        "id": 581,
        "no_speech_prob": 0.005137545522302389,
        "seek": 169836,
        "start": 1722.36,
        "temperature": 0,
        "text": " And let's go back to GitHub here.",
        "tokens": [
          51564,
          400,
          718,
          311,
          352,
          646,
          281,
          23331,
          510,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.38650332556830513,
        "compression_ratio": 1.0119047619047619,
        "end": 1731.36,
        "id": 582,
        "no_speech_prob": 0.0026727442163974047,
        "seek": 172836,
        "start": 1729.36,
        "temperature": 0,
        "text": " Let's see.",
        "tokens": [
          50414,
          961,
          311,
          536,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.38650332556830513,
        "compression_ratio": 1.0119047619047619,
        "end": 1743.36,
        "id": 583,
        "no_speech_prob": 0.0026727442163974047,
        "seek": 172836,
        "start": 1741.36,
        "temperature": 0,
        "text": " Oh, weird.",
        "tokens": [
          51014,
          876,
          11,
          3657,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.38650332556830513,
        "compression_ratio": 1.0119047619047619,
        "end": 1747.36,
        "id": 584,
        "no_speech_prob": 0.0026727442163974047,
        "seek": 172836,
        "start": 1743.36,
        "temperature": 0,
        "text": " But it actually did look in the right place.",
        "tokens": [
          51114,
          583,
          309,
          767,
          630,
          574,
          294,
          264,
          558,
          1081,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.38650332556830513,
        "compression_ratio": 1.0119047619047619,
        "end": 1749.36,
        "id": 585,
        "no_speech_prob": 0.0026727442163974047,
        "seek": 172836,
        "start": 1747.36,
        "temperature": 0,
        "text": " Huh.",
        "tokens": [
          51314,
          8063,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.38650332556830513,
        "compression_ratio": 1.0119047619047619,
        "end": 1755.36,
        "id": 586,
        "no_speech_prob": 0.0026727442163974047,
        "seek": 172836,
        "start": 1754.36,
        "temperature": 0,
        "text": " That's weird.",
        "tokens": [
          51664,
          663,
          311,
          3657,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.230288789078996,
        "compression_ratio": 1.0476190476190477,
        "end": 1757.36,
        "id": 587,
        "no_speech_prob": 0.004198399372398853,
        "seek": 175536,
        "start": 1755.36,
        "temperature": 0,
        "text": " This is a thing.",
        "tokens": [
          50364,
          639,
          307,
          257,
          551,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.230288789078996,
        "compression_ratio": 1.0476190476190477,
        "end": 1761.36,
        "id": 588,
        "no_speech_prob": 0.004198399372398853,
        "seek": 175536,
        "start": 1759.36,
        "temperature": 0,
        "text": " I'm so confused.",
        "tokens": [
          50564,
          286,
          478,
          370,
          9019,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.230288789078996,
        "compression_ratio": 1.0476190476190477,
        "end": 1771.36,
        "id": 589,
        "no_speech_prob": 0.004198399372398853,
        "seek": 175536,
        "start": 1769.36,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          51064,
          45263,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.230288789078996,
        "compression_ratio": 1.0476190476190477,
        "end": 1777.36,
        "id": 590,
        "no_speech_prob": 0.004198399372398853,
        "seek": 175536,
        "start": 1775.36,
        "temperature": 0,
        "text": " Oh!",
        "tokens": [
          51364,
          876,
          0,
          51464
        ]
      },
      {
        "avg_logprob": -0.230288789078996,
        "compression_ratio": 1.0476190476190477,
        "end": 1779.36,
        "id": 591,
        "no_speech_prob": 0.004198399372398853,
        "seek": 175536,
        "start": 1777.36,
        "temperature": 0,
        "text": " It would have worked.",
        "tokens": [
          51464,
          467,
          576,
          362,
          2732,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.230288789078996,
        "compression_ratio": 1.0476190476190477,
        "end": 1781.36,
        "id": 592,
        "no_speech_prob": 0.004198399372398853,
        "seek": 175536,
        "start": 1779.36,
        "temperature": 0,
        "text": " This is interesting.",
        "tokens": [
          51564,
          639,
          307,
          1880,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2813091033544296,
        "compression_ratio": 1.2555555555555555,
        "end": 1786.36,
        "id": 593,
        "no_speech_prob": 0.00043732678750529885,
        "seek": 178136,
        "start": 1782.36,
        "temperature": 0,
        "text": " It would have worked.",
        "tokens": [
          50414,
          467,
          576,
          362,
          2732,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2813091033544296,
        "compression_ratio": 1.2555555555555555,
        "end": 1790.36,
        "id": 594,
        "no_speech_prob": 0.00043732678750529885,
        "seek": 178136,
        "start": 1786.36,
        "temperature": 0,
        "text": " I'm not being careful enough.",
        "tokens": [
          50614,
          286,
          478,
          406,
          885,
          5026,
          1547,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2813091033544296,
        "compression_ratio": 1.2555555555555555,
        "end": 1795.36,
        "id": 595,
        "no_speech_prob": 0.00043732678750529885,
        "seek": 178136,
        "start": 1790.36,
        "temperature": 0,
        "text": " If I were running the server from here...",
        "tokens": [
          50814,
          759,
          286,
          645,
          2614,
          264,
          7154,
          490,
          510,
          485,
          51064
        ]
      },
      {
        "avg_logprob": -0.2813091033544296,
        "compression_ratio": 1.2555555555555555,
        "end": 1806.36,
        "id": 596,
        "no_speech_prob": 0.00043732678750529885,
        "seek": 178136,
        "start": 1804.36,
        "temperature": 0,
        "text": " It works.",
        "tokens": [
          51514,
          467,
          1985,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2813091033544296,
        "compression_ratio": 1.2555555555555555,
        "end": 1809.36,
        "id": 597,
        "no_speech_prob": 0.00043732678750529885,
        "seek": 178136,
        "start": 1806.36,
        "temperature": 0,
        "text": " It works.",
        "tokens": [
          51614,
          467,
          1985,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.226391591523823,
        "compression_ratio": 1.2741935483870968,
        "end": 1813.36,
        "id": 598,
        "no_speech_prob": 0.0010004861978814006,
        "seek": 180936,
        "start": 1809.36,
        "temperature": 0,
        "text": " It works because it's a subfolder.",
        "tokens": [
          50364,
          467,
          1985,
          570,
          309,
          311,
          257,
          1422,
          18353,
          260,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.226391591523823,
        "compression_ratio": 1.2741935483870968,
        "end": 1818.36,
        "id": 599,
        "no_speech_prob": 0.0010004861978814006,
        "seek": 180936,
        "start": 1813.36,
        "temperature": 0,
        "text": " But I feel like it should figure out that it's in a subfolder.",
        "tokens": [
          50564,
          583,
          286,
          841,
          411,
          309,
          820,
          2573,
          484,
          300,
          309,
          311,
          294,
          257,
          1422,
          18353,
          260,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.226391591523823,
        "compression_ratio": 1.2741935483870968,
        "end": 1820.36,
        "id": 600,
        "no_speech_prob": 0.0010004861978814006,
        "seek": 180936,
        "start": 1818.36,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          50814,
          1779,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.226391591523823,
        "compression_ratio": 1.2741935483870968,
        "end": 1822.36,
        "id": 601,
        "no_speech_prob": 0.0010004861978814006,
        "seek": 180936,
        "start": 1820.36,
        "temperature": 0,
        "text": " So...",
        "tokens": [
          50914,
          407,
          485,
          51014
        ]
      },
      {
        "avg_logprob": -0.226391591523823,
        "compression_ratio": 1.2741935483870968,
        "end": 1824.36,
        "id": 602,
        "no_speech_prob": 0.0010004861978814006,
        "seek": 180936,
        "start": 1822.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51014,
          1033,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.226391591523823,
        "compression_ratio": 1.2741935483870968,
        "end": 1827.36,
        "id": 603,
        "no_speech_prob": 0.0010004861978814006,
        "seek": 180936,
        "start": 1824.36,
        "temperature": 0,
        "text": " I've got to change my error message here.",
        "tokens": [
          51114,
          286,
          600,
          658,
          281,
          1319,
          452,
          6713,
          3636,
          510,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.4905350311942723,
        "compression_ratio": 1.5208333333333333,
        "end": 1834.36,
        "id": 604,
        "no_speech_prob": 0.14024503529071808,
        "seek": 182736,
        "start": 1828.36,
        "temperature": 0,
        "text": " If the sketch is not at the root path,",
        "tokens": [
          50414,
          759,
          264,
          12325,
          307,
          406,
          412,
          264,
          5593,
          3100,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.4905350311942723,
        "compression_ratio": 1.5208333333333333,
        "end": 1840.36,
        "id": 605,
        "no_speech_prob": 0.14024503529071808,
        "seek": 182736,
        "start": 1834.36,
        "temperature": 0,
        "text": " I can load the model via a relative path as follows.",
        "tokens": [
          50714,
          286,
          393,
          3677,
          264,
          2316,
          5766,
          257,
          4972,
          3100,
          382,
          10002,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.4905350311942723,
        "compression_ratio": 1.5208333333333333,
        "end": 1845.36,
        "id": 606,
        "no_speech_prob": 0.14024503529071808,
        "seek": 182736,
        "start": 1843.36,
        "temperature": 0,
        "text": " But...",
        "tokens": [
          51164,
          583,
          485,
          51264
        ]
      },
      {
        "avg_logprob": -0.4905350311942723,
        "compression_ratio": 1.5208333333333333,
        "end": 1853.36,
        "id": 607,
        "no_speech_prob": 0.14024503529071808,
        "seek": 182736,
        "start": 1847.36,
        "temperature": 0,
        "text": " However, if the sketch is not at the root path,",
        "tokens": [
          51364,
          2908,
          11,
          498,
          264,
          12325,
          307,
          406,
          412,
          264,
          5593,
          3100,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.3261133943285261,
        "compression_ratio": 1.0384615384615385,
        "end": 1855.36,
        "id": 608,
        "no_speech_prob": 0.020011436194181442,
        "seek": 185336,
        "start": 1853.36,
        "temperature": 0,
        "text": " but...",
        "tokens": [
          50364,
          457,
          485,
          50464
        ]
      },
      {
        "avg_logprob": -0.3261133943285261,
        "compression_ratio": 1.0384615384615385,
        "end": 1865.36,
        "id": 609,
        "no_speech_prob": 0.020011436194181442,
        "seek": 185336,
        "start": 1856.36,
        "temperature": 0,
        "text": " However, if I look for model.json",
        "tokens": [
          50514,
          2908,
          11,
          498,
          286,
          574,
          337,
          2316,
          13,
          73,
          3015,
          50964
        ]
      },
      {
        "avg_logprob": -0.3261133943285261,
        "compression_ratio": 1.0384615384615385,
        "end": 1873.36,
        "id": 610,
        "no_speech_prob": 0.020011436194181442,
        "seek": 185336,
        "start": 1868.36,
        "temperature": 0,
        "text": " with a relative path like the following,",
        "tokens": [
          51114,
          365,
          257,
          4972,
          3100,
          411,
          264,
          3480,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.2702052651382074,
        "compression_ratio": 1.2522522522522523,
        "end": 1887.36,
        "id": 611,
        "no_speech_prob": 0.020623043179512024,
        "seek": 187336,
        "start": 1874.36,
        "temperature": 0,
        "text": " it then looks in the root directory for model.weights.bin.",
        "tokens": [
          50414,
          309,
          550,
          1542,
          294,
          264,
          5593,
          21120,
          337,
          2316,
          13,
          826,
          5761,
          13,
          13496,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2702052651382074,
        "compression_ratio": 1.2522522522522523,
        "end": 1891.36,
        "id": 612,
        "no_speech_prob": 0.020623043179512024,
        "seek": 187336,
        "start": 1887.36,
        "temperature": 0,
        "text": " This is minor for my example,",
        "tokens": [
          51064,
          639,
          307,
          6696,
          337,
          452,
          1365,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.2702052651382074,
        "compression_ratio": 1.2522522522522523,
        "end": 1896.36,
        "id": 613,
        "no_speech_prob": 0.020623043179512024,
        "seek": 187336,
        "start": 1891.36,
        "temperature": 0,
        "text": " but noting as it's an error people will encounter,",
        "tokens": [
          51264,
          457,
          26801,
          382,
          309,
          311,
          364,
          6713,
          561,
          486,
          8593,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.2564524634409759,
        "compression_ratio": 1.4428571428571428,
        "end": 1906.36,
        "id": 614,
        "no_speech_prob": 0.04739188402891159,
        "seek": 189636,
        "start": 1897.36,
        "temperature": 0,
        "text": " is it trivial to support looking always in...",
        "tokens": [
          50414,
          307,
          309,
          26703,
          281,
          1406,
          1237,
          1009,
          294,
          485,
          50864
        ]
      },
      {
        "avg_logprob": -0.2564524634409759,
        "compression_ratio": 1.4428571428571428,
        "end": 1909.36,
        "id": 615,
        "no_speech_prob": 0.04739188402891159,
        "seek": 189636,
        "start": 1908.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50964,
          1033,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2564524634409759,
        "compression_ratio": 1.4428571428571428,
        "end": 1911.36,
        "id": 616,
        "no_speech_prob": 0.04739188402891159,
        "seek": 189636,
        "start": 1909.36,
        "temperature": 0,
        "text": " So I think this is...",
        "tokens": [
          51014,
          407,
          286,
          519,
          341,
          307,
          485,
          51114
        ]
      },
      {
        "avg_logprob": -0.2564524634409759,
        "compression_ratio": 1.4428571428571428,
        "end": 1913.36,
        "id": 617,
        "no_speech_prob": 0.04739188402891159,
        "seek": 189636,
        "start": 1911.36,
        "temperature": 0,
        "text": " If the sketch is not at the root path,",
        "tokens": [
          51114,
          759,
          264,
          12325,
          307,
          406,
          412,
          264,
          5593,
          3100,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.2564524634409759,
        "compression_ratio": 1.4428571428571428,
        "end": 1919.36,
        "id": 618,
        "no_speech_prob": 0.04739188402891159,
        "seek": 189636,
        "start": 1913.36,
        "temperature": 0,
        "text": " I can load the model via the current directory.",
        "tokens": [
          51214,
          286,
          393,
          3677,
          264,
          2316,
          5766,
          264,
          2190,
          21120,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2564524634409759,
        "compression_ratio": 1.4428571428571428,
        "end": 1924.36,
        "id": 619,
        "no_speech_prob": 0.04739188402891159,
        "seek": 189636,
        "start": 1919.36,
        "temperature": 0,
        "text": " At the current path directory as follows.",
        "tokens": [
          51514,
          1711,
          264,
          2190,
          3100,
          21120,
          382,
          10002,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.23369359970092773,
        "compression_ratio": 1.4326241134751774,
        "end": 1933.36,
        "id": 620,
        "no_speech_prob": 0.007010572124272585,
        "seek": 192436,
        "start": 1924.36,
        "temperature": 0,
        "text": " However, if I ask for model.json as follow,",
        "tokens": [
          50364,
          2908,
          11,
          498,
          286,
          1029,
          337,
          2316,
          13,
          73,
          3015,
          382,
          1524,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.23369359970092773,
        "compression_ratio": 1.4326241134751774,
        "end": 1936.36,
        "id": 621,
        "no_speech_prob": 0.007010572124272585,
        "seek": 192436,
        "start": 1933.36,
        "temperature": 0,
        "text": " this way,",
        "tokens": [
          50814,
          341,
          636,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.23369359970092773,
        "compression_ratio": 1.4326241134751774,
        "end": 1942.36,
        "id": 622,
        "no_speech_prob": 0.007010572124272585,
        "seek": 192436,
        "start": 1936.36,
        "temperature": 0,
        "text": " it then looks in the root directory for model.weights.bin.",
        "tokens": [
          50964,
          309,
          550,
          1542,
          294,
          264,
          5593,
          21120,
          337,
          2316,
          13,
          826,
          5761,
          13,
          13496,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.23369359970092773,
        "compression_ratio": 1.4326241134751774,
        "end": 1946.36,
        "id": 623,
        "no_speech_prob": 0.007010572124272585,
        "seek": 192436,
        "start": 1945.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51414,
          1057,
          558,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.23369359970092773,
        "compression_ratio": 1.4326241134751774,
        "end": 1949.36,
        "id": 624,
        "no_speech_prob": 0.007010572124272585,
        "seek": 192436,
        "start": 1946.36,
        "temperature": 0,
        "text": " So let me submit this.",
        "tokens": [
          51464,
          407,
          718,
          385,
          10315,
          341,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.23369359970092773,
        "compression_ratio": 1.4326241134751774,
        "end": 1950.36,
        "id": 625,
        "no_speech_prob": 0.007010572124272585,
        "seek": 192436,
        "start": 1949.36,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51614,
          865,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.23369359970092773,
        "compression_ratio": 1.4326241134751774,
        "end": 1951.36,
        "id": 626,
        "no_speech_prob": 0.007010572124272585,
        "seek": 192436,
        "start": 1950.36,
        "temperature": 0,
        "text": " Let me submit this.",
        "tokens": [
          51664,
          961,
          385,
          10315,
          341,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.23369359970092773,
        "compression_ratio": 1.4326241134751774,
        "end": 1953.36,
        "id": 627,
        "no_speech_prob": 0.007010572124272585,
        "seek": 192436,
        "start": 1951.36,
        "temperature": 0,
        "text": " I think this makes sense now.",
        "tokens": [
          51714,
          286,
          519,
          341,
          1669,
          2020,
          586,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2276543208530971,
        "compression_ratio": 1.5179856115107915,
        "end": 1957.36,
        "id": 628,
        "no_speech_prob": 0.0008693064446561038,
        "seek": 195336,
        "start": 1953.36,
        "temperature": 0,
        "text": " Apologies if this issue is weird,",
        "tokens": [
          50364,
          8723,
          6204,
          498,
          341,
          2734,
          307,
          3657,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.2276543208530971,
        "compression_ratio": 1.5179856115107915,
        "end": 1959.36,
        "id": 629,
        "no_speech_prob": 0.0008693064446561038,
        "seek": 195336,
        "start": 1957.36,
        "temperature": 0,
        "text": " because I'm doing this in a live stream.",
        "tokens": [
          50564,
          570,
          286,
          478,
          884,
          341,
          294,
          257,
          1621,
          4309,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2276543208530971,
        "compression_ratio": 1.5179856115107915,
        "end": 1960.36,
        "id": 630,
        "no_speech_prob": 0.0008693064446561038,
        "seek": 195336,
        "start": 1959.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50664,
          1033,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2276543208530971,
        "compression_ratio": 1.5179856115107915,
        "end": 1964.36,
        "id": 631,
        "no_speech_prob": 0.0008693064446561038,
        "seek": 195336,
        "start": 1962.36,
        "temperature": 0,
        "text": " So I'm actually...",
        "tokens": [
          50814,
          407,
          286,
          478,
          767,
          485,
          50914
        ]
      },
      {
        "avg_logprob": -0.2276543208530971,
        "compression_ratio": 1.5179856115107915,
        "end": 1967.36,
        "id": 632,
        "no_speech_prob": 0.0008693064446561038,
        "seek": 195336,
        "start": 1964.36,
        "temperature": 0,
        "text": " We're going to fake this here.",
        "tokens": [
          50914,
          492,
          434,
          516,
          281,
          7592,
          341,
          510,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2276543208530971,
        "compression_ratio": 1.5179856115107915,
        "end": 1969.36,
        "id": 633,
        "no_speech_prob": 0.0008693064446561038,
        "seek": 195336,
        "start": 1967.36,
        "temperature": 0,
        "text": " No one will notice.",
        "tokens": [
          51064,
          883,
          472,
          486,
          3449,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2276543208530971,
        "compression_ratio": 1.5179856115107915,
        "end": 1978.36,
        "id": 634,
        "no_speech_prob": 0.0008693064446561038,
        "seek": 195336,
        "start": 1977.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51564,
          1033,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2276543208530971,
        "compression_ratio": 1.5179856115107915,
        "end": 1979.36,
        "id": 635,
        "no_speech_prob": 0.0008693064446561038,
        "seek": 195336,
        "start": 1978.36,
        "temperature": 0,
        "text": " We're going to fake this.",
        "tokens": [
          51614,
          492,
          434,
          516,
          281,
          7592,
          341,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2276543208530971,
        "compression_ratio": 1.5179856115107915,
        "end": 1981.36,
        "id": 636,
        "no_speech_prob": 0.0008693064446561038,
        "seek": 195336,
        "start": 1979.36,
        "temperature": 0,
        "text": " So, Mathieu, I'm going to...",
        "tokens": [
          51664,
          407,
          11,
          15776,
          19347,
          11,
          286,
          478,
          516,
          281,
          485,
          51764
        ]
      },
      {
        "avg_logprob": -0.15789435673685906,
        "compression_ratio": 1.5132275132275133,
        "end": 1983.36,
        "id": 637,
        "no_speech_prob": 0.000010451524758536834,
        "seek": 198136,
        "start": 1981.36,
        "temperature": 0,
        "text": " I'm not going to show that error, actually,",
        "tokens": [
          50364,
          286,
          478,
          406,
          516,
          281,
          855,
          300,
          6713,
          11,
          767,
          11,
          50464
        ]
      },
      {
        "avg_logprob": -0.15789435673685906,
        "compression_ratio": 1.5132275132275133,
        "end": 1988.36,
        "id": 638,
        "no_speech_prob": 0.000010451524758536834,
        "seek": 198136,
        "start": 1983.36,
        "temperature": 0,
        "text": " because that error is irrelevant to what I'm doing here.",
        "tokens": [
          50464,
          570,
          300,
          6713,
          307,
          28682,
          281,
          437,
          286,
          478,
          884,
          510,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.15789435673685906,
        "compression_ratio": 1.5132275132275133,
        "end": 1997.36,
        "id": 639,
        "no_speech_prob": 0.000010451524758536834,
        "seek": 198136,
        "start": 1992.36,
        "temperature": 0,
        "text": " So let's see if I can get it to work just like this.",
        "tokens": [
          50914,
          407,
          718,
          311,
          536,
          498,
          286,
          393,
          483,
          309,
          281,
          589,
          445,
          411,
          341,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.15789435673685906,
        "compression_ratio": 1.5132275132275133,
        "end": 1998.36,
        "id": 640,
        "no_speech_prob": 0.000010451524758536834,
        "seek": 198136,
        "start": 1997.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51164,
          1033,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.15789435673685906,
        "compression_ratio": 1.5132275132275133,
        "end": 2000.36,
        "id": 641,
        "no_speech_prob": 0.000010451524758536834,
        "seek": 198136,
        "start": 1998.36,
        "temperature": 0,
        "text": " Because I think that'll get fixed later.",
        "tokens": [
          51214,
          1436,
          286,
          519,
          300,
          603,
          483,
          6806,
          1780,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.15789435673685906,
        "compression_ratio": 1.5132275132275133,
        "end": 2001.36,
        "id": 642,
        "no_speech_prob": 0.000010451524758536834,
        "seek": 198136,
        "start": 2000.36,
        "temperature": 0,
        "text": " I hope.",
        "tokens": [
          51314,
          286,
          1454,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.15789435673685906,
        "compression_ratio": 1.5132275132275133,
        "end": 2002.36,
        "id": 643,
        "no_speech_prob": 0.000010451524758536834,
        "seek": 198136,
        "start": 2001.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51364,
          1033,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.15789435673685906,
        "compression_ratio": 1.5132275132275133,
        "end": 2003.36,
        "id": 644,
        "no_speech_prob": 0.000010451524758536834,
        "seek": 198136,
        "start": 2002.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51414,
          1033,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.15789435673685906,
        "compression_ratio": 1.5132275132275133,
        "end": 2005.36,
        "id": 645,
        "no_speech_prob": 0.000010451524758536834,
        "seek": 198136,
        "start": 2003.36,
        "temperature": 0,
        "text": " Let's go back.",
        "tokens": [
          51464,
          961,
          311,
          352,
          646,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.15789435673685906,
        "compression_ratio": 1.5132275132275133,
        "end": 2006.36,
        "id": 646,
        "no_speech_prob": 0.000010451524758536834,
        "seek": 198136,
        "start": 2005.36,
        "temperature": 0,
        "text": " Oh, it's already...",
        "tokens": [
          51564,
          876,
          11,
          309,
          311,
          1217,
          485,
          51614
        ]
      },
      {
        "avg_logprob": -0.15789435673685906,
        "compression_ratio": 1.5132275132275133,
        "end": 2008.36,
        "id": 647,
        "no_speech_prob": 0.000010451524758536834,
        "seek": 198136,
        "start": 2006.36,
        "temperature": 0,
        "text": " That's no good.",
        "tokens": [
          51614,
          663,
          311,
          572,
          665,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.15789435673685906,
        "compression_ratio": 1.5132275132275133,
        "end": 2010.36,
        "id": 648,
        "no_speech_prob": 0.000010451524758536834,
        "seek": 198136,
        "start": 2008.36,
        "temperature": 0,
        "text": " So how do I...",
        "tokens": [
          51714,
          407,
          577,
          360,
          286,
          485,
          51814
        ]
      },
      {
        "avg_logprob": -0.19174203119779887,
        "compression_ratio": 1.4154929577464788,
        "end": 2011.36,
        "id": 649,
        "no_speech_prob": 0.00011591832299018279,
        "seek": 201036,
        "start": 2010.36,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          50364,
          6962,
          322,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.19174203119779887,
        "compression_ratio": 1.4154929577464788,
        "end": 2018.36,
        "id": 650,
        "no_speech_prob": 0.00011591832299018279,
        "seek": 201036,
        "start": 2017.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50714,
          1033,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19174203119779887,
        "compression_ratio": 1.4154929577464788,
        "end": 2022.36,
        "id": 651,
        "no_speech_prob": 0.00011591832299018279,
        "seek": 201036,
        "start": 2021.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50914,
          1057,
          558,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19174203119779887,
        "compression_ratio": 1.4154929577464788,
        "end": 2025.36,
        "id": 652,
        "no_speech_prob": 0.00011591832299018279,
        "seek": 201036,
        "start": 2022.36,
        "temperature": 0,
        "text": " Let's try now loading that model.",
        "tokens": [
          50964,
          961,
          311,
          853,
          586,
          15114,
          300,
          2316,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19174203119779887,
        "compression_ratio": 1.4154929577464788,
        "end": 2028.36,
        "id": 653,
        "no_speech_prob": 0.00011591832299018279,
        "seek": 201036,
        "start": 2025.36,
        "temperature": 0,
        "text": " I'm going to hit refresh.",
        "tokens": [
          51114,
          286,
          478,
          516,
          281,
          2045,
          15134,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19174203119779887,
        "compression_ratio": 1.4154929577464788,
        "end": 2029.36,
        "id": 654,
        "no_speech_prob": 0.00011591832299018279,
        "seek": 201036,
        "start": 2028.36,
        "temperature": 0,
        "text": " Model's ready.",
        "tokens": [
          51264,
          17105,
          311,
          1919,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19174203119779887,
        "compression_ratio": 1.4154929577464788,
        "end": 2030.36,
        "id": 655,
        "no_speech_prob": 0.00011591832299018279,
        "seek": 201036,
        "start": 2029.36,
        "temperature": 0,
        "text": " Video's ready.",
        "tokens": [
          51314,
          9777,
          311,
          1919,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19174203119779887,
        "compression_ratio": 1.4154929577464788,
        "end": 2031.36,
        "id": 656,
        "no_speech_prob": 0.00011591832299018279,
        "seek": 201036,
        "start": 2030.36,
        "temperature": 0,
        "text": " Custom model is ready.",
        "tokens": [
          51364,
          16649,
          2316,
          307,
          1919,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19174203119779887,
        "compression_ratio": 1.4154929577464788,
        "end": 2035.36,
        "id": 657,
        "no_speech_prob": 0.00011591832299018279,
        "seek": 201036,
        "start": 2031.36,
        "temperature": 0,
        "text": " So it's been loaded, but I'm not...",
        "tokens": [
          51414,
          407,
          309,
          311,
          668,
          13210,
          11,
          457,
          286,
          478,
          406,
          485,
          51614
        ]
      },
      {
        "avg_logprob": -0.19174203119779887,
        "compression_ratio": 1.4154929577464788,
        "end": 2038.36,
        "id": 658,
        "no_speech_prob": 0.00011591832299018279,
        "seek": 201036,
        "start": 2035.36,
        "temperature": 0,
        "text": " I'm not seeing the labels.",
        "tokens": [
          51614,
          286,
          478,
          406,
          2577,
          264,
          16949,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2194025901056105,
        "compression_ratio": 1.7132075471698114,
        "end": 2039.36,
        "id": 659,
        "no_speech_prob": 0.007460474036633968,
        "seek": 203836,
        "start": 2038.36,
        "temperature": 0,
        "text": " So it doesn't...",
        "tokens": [
          50364,
          407,
          309,
          1177,
          380,
          485,
          50414
        ]
      },
      {
        "avg_logprob": -0.2194025901056105,
        "compression_ratio": 1.7132075471698114,
        "end": 2042.36,
        "id": 660,
        "no_speech_prob": 0.007460474036633968,
        "seek": 203836,
        "start": 2039.36,
        "temperature": 0,
        "text": " Even though that model was loaded, I now have to figure out...",
        "tokens": [
          50414,
          2754,
          1673,
          300,
          2316,
          390,
          13210,
          11,
          286,
          586,
          362,
          281,
          2573,
          484,
          485,
          50564
        ]
      },
      {
        "avg_logprob": -0.2194025901056105,
        "compression_ratio": 1.7132075471698114,
        "end": 2047.36,
        "id": 661,
        "no_speech_prob": 0.007460474036633968,
        "seek": 203836,
        "start": 2042.36,
        "temperature": 0,
        "text": " I now have to tell the code no longer really needs to be trained in this case.",
        "tokens": [
          50564,
          286,
          586,
          362,
          281,
          980,
          264,
          3089,
          572,
          2854,
          534,
          2203,
          281,
          312,
          8895,
          294,
          341,
          1389,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2194025901056105,
        "compression_ratio": 1.7132075471698114,
        "end": 2049.3599999999997,
        "id": 662,
        "no_speech_prob": 0.007460474036633968,
        "seek": 203836,
        "start": 2047.36,
        "temperature": 0,
        "text": " I might want to retrain and do fancy.",
        "tokens": [
          50814,
          286,
          1062,
          528,
          281,
          1533,
          7146,
          293,
          360,
          10247,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2194025901056105,
        "compression_ratio": 1.7132075471698114,
        "end": 2051.3599999999997,
        "id": 663,
        "no_speech_prob": 0.007460474036633968,
        "seek": 203836,
        "start": 2049.3599999999997,
        "temperature": 0,
        "text": " I'm going to take out the training button,",
        "tokens": [
          50914,
          286,
          478,
          516,
          281,
          747,
          484,
          264,
          3097,
          2960,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.2194025901056105,
        "compression_ratio": 1.7132075471698114,
        "end": 2055.3599999999997,
        "id": 664,
        "no_speech_prob": 0.007460474036633968,
        "seek": 203836,
        "start": 2051.3599999999997,
        "temperature": 0,
        "text": " and then somewhere there's like an event where it finished training",
        "tokens": [
          51014,
          293,
          550,
          4079,
          456,
          311,
          411,
          364,
          2280,
          689,
          309,
          4335,
          3097,
          51214
        ]
      },
      {
        "avg_logprob": -0.2194025901056105,
        "compression_ratio": 1.7132075471698114,
        "end": 2060.3599999999997,
        "id": 665,
        "no_speech_prob": 0.007460474036633968,
        "seek": 203836,
        "start": 2055.3599999999997,
        "temperature": 0,
        "text": " where I said classifier, classifier got results.",
        "tokens": [
          51214,
          689,
          286,
          848,
          1508,
          9902,
          11,
          1508,
          9902,
          658,
          3542,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2194025901056105,
        "compression_ratio": 1.7132075471698114,
        "end": 2064.3599999999997,
        "id": 666,
        "no_speech_prob": 0.007460474036633968,
        "seek": 203836,
        "start": 2060.3599999999997,
        "temperature": 0,
        "text": " And so that's what I want to do now when the custom model is ready.",
        "tokens": [
          51464,
          400,
          370,
          300,
          311,
          437,
          286,
          528,
          281,
          360,
          586,
          562,
          264,
          2375,
          2316,
          307,
          1919,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2194025901056105,
        "compression_ratio": 1.7132075471698114,
        "end": 2067.3599999999997,
        "id": 667,
        "no_speech_prob": 0.007460474036633968,
        "seek": 203836,
        "start": 2064.3599999999997,
        "temperature": 0,
        "text": " So the events are as follows.",
        "tokens": [
          51664,
          407,
          264,
          3931,
          366,
          382,
          10002,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1907839022184673,
        "compression_ratio": 1.6584158415841583,
        "end": 2070.36,
        "id": 668,
        "no_speech_prob": 0.00006108844536356628,
        "seek": 206736,
        "start": 2067.36,
        "temperature": 0,
        "text": " Let's bring this down here.",
        "tokens": [
          50364,
          961,
          311,
          1565,
          341,
          760,
          510,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1907839022184673,
        "compression_ratio": 1.6584158415841583,
        "end": 2074.36,
        "id": 669,
        "no_speech_prob": 0.00006108844536356628,
        "seek": 206736,
        "start": 2070.36,
        "temperature": 0,
        "text": " First, load the MobileNet model.",
        "tokens": [
          50514,
          2386,
          11,
          3677,
          264,
          22625,
          31890,
          2316,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1907839022184673,
        "compression_ratio": 1.6584158415841583,
        "end": 2079.36,
        "id": 670,
        "no_speech_prob": 0.00006108844536356628,
        "seek": 206736,
        "start": 2074.36,
        "temperature": 0,
        "text": " When the MobileNet model is ready, then load the custom model.",
        "tokens": [
          50714,
          1133,
          264,
          22625,
          31890,
          2316,
          307,
          1919,
          11,
          550,
          3677,
          264,
          2375,
          2316,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1907839022184673,
        "compression_ratio": 1.6584158415841583,
        "end": 2082.36,
        "id": 671,
        "no_speech_prob": 0.00006108844536356628,
        "seek": 206736,
        "start": 2079.36,
        "temperature": 0,
        "text": " When the custom model's ready, start classifying the image.",
        "tokens": [
          50964,
          1133,
          264,
          2375,
          2316,
          311,
          1919,
          11,
          722,
          1508,
          5489,
          264,
          3256,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1907839022184673,
        "compression_ratio": 1.6584158415841583,
        "end": 2083.36,
        "id": 672,
        "no_speech_prob": 0.00006108844536356628,
        "seek": 206736,
        "start": 2082.36,
        "temperature": 0,
        "text": " All right?",
        "tokens": [
          51114,
          1057,
          558,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.1907839022184673,
        "compression_ratio": 1.6584158415841583,
        "end": 2084.36,
        "id": 673,
        "no_speech_prob": 0.00006108844536356628,
        "seek": 206736,
        "start": 2083.36,
        "temperature": 0,
        "text": " So here we go.",
        "tokens": [
          51164,
          407,
          510,
          321,
          352,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1907839022184673,
        "compression_ratio": 1.6584158415841583,
        "end": 2085.36,
        "id": 674,
        "no_speech_prob": 0.00006108844536356628,
        "seek": 206736,
        "start": 2084.36,
        "temperature": 0,
        "text": " Let's...",
        "tokens": [
          51214,
          961,
          311,
          485,
          51264
        ]
      },
      {
        "avg_logprob": -0.1907839022184673,
        "compression_ratio": 1.6584158415841583,
        "end": 2090.36,
        "id": 675,
        "no_speech_prob": 0.00006108844536356628,
        "seek": 206736,
        "start": 2088.36,
        "temperature": 0,
        "text": " Ah, yay!",
        "tokens": [
          51414,
          2438,
          11,
          23986,
          0,
          51514
        ]
      },
      {
        "avg_logprob": -0.1907839022184673,
        "compression_ratio": 1.6584158415841583,
        "end": 2092.36,
        "id": 676,
        "no_speech_prob": 0.00006108844536356628,
        "seek": 206736,
        "start": 2091.36,
        "temperature": 0,
        "text": " What did I have with this hand?",
        "tokens": [
          51564,
          708,
          630,
          286,
          362,
          365,
          341,
          1011,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.1907839022184673,
        "compression_ratio": 1.6584158415841583,
        "end": 2093.36,
        "id": 677,
        "no_speech_prob": 0.00006108844536356628,
        "seek": 206736,
        "start": 2092.36,
        "temperature": 0,
        "text": " I can't even remember.",
        "tokens": [
          51614,
          286,
          393,
          380,
          754,
          1604,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1907839022184673,
        "compression_ratio": 1.6584158415841583,
        "end": 2094.36,
        "id": 678,
        "no_speech_prob": 0.00006108844536356628,
        "seek": 206736,
        "start": 2093.36,
        "temperature": 0,
        "text": " No, it was this hand.",
        "tokens": [
          51664,
          883,
          11,
          309,
          390,
          341,
          1011,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1907839022184673,
        "compression_ratio": 1.6584158415841583,
        "end": 2095.36,
        "id": 679,
        "no_speech_prob": 0.00006108844536356628,
        "seek": 206736,
        "start": 2094.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51714,
          1057,
          558,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1907839022184673,
        "compression_ratio": 1.6584158415841583,
        "end": 2096.36,
        "id": 680,
        "no_speech_prob": 0.00006108844536356628,
        "seek": 206736,
        "start": 2095.36,
        "temperature": 0,
        "text": " So this is working.",
        "tokens": [
          51764,
          407,
          341,
          307,
          1364,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1711046810807853,
        "compression_ratio": 1.6887417218543046,
        "end": 2098.36,
        "id": 681,
        "no_speech_prob": 0.005384799093008041,
        "seek": 209636,
        "start": 2096.36,
        "temperature": 0,
        "text": " The buttons are now no longer relevant,",
        "tokens": [
          50364,
          440,
          9905,
          366,
          586,
          572,
          2854,
          7340,
          11,
          50464
        ]
      },
      {
        "avg_logprob": -0.1711046810807853,
        "compression_ratio": 1.6887417218543046,
        "end": 2100.36,
        "id": 682,
        "no_speech_prob": 0.005384799093008041,
        "seek": 209636,
        "start": 2098.36,
        "temperature": 0,
        "text": " so I could actually take all the buttons out.",
        "tokens": [
          50464,
          370,
          286,
          727,
          767,
          747,
          439,
          264,
          9905,
          484,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1711046810807853,
        "compression_ratio": 1.6887417218543046,
        "end": 2101.36,
        "id": 683,
        "no_speech_prob": 0.005384799093008041,
        "seek": 209636,
        "start": 2100.36,
        "temperature": 0,
        "text": " And this is now...",
        "tokens": [
          50564,
          400,
          341,
          307,
          586,
          485,
          50614
        ]
      },
      {
        "avg_logprob": -0.1711046810807853,
        "compression_ratio": 1.6887417218543046,
        "end": 2105.36,
        "id": 684,
        "no_speech_prob": 0.005384799093008041,
        "seek": 209636,
        "start": 2101.36,
        "temperature": 0,
        "text": " Again, whether you want to have one sketch where you train and save and load",
        "tokens": [
          50614,
          3764,
          11,
          1968,
          291,
          528,
          281,
          362,
          472,
          12325,
          689,
          291,
          3847,
          293,
          3155,
          293,
          3677,
          50814
        ]
      },
      {
        "avg_logprob": -0.1711046810807853,
        "compression_ratio": 1.6887417218543046,
        "end": 2108.36,
        "id": 685,
        "no_speech_prob": 0.005384799093008041,
        "seek": 209636,
        "start": 2105.36,
        "temperature": 0,
        "text": " or two different ones, but I'll just show you right now.",
        "tokens": [
          50814,
          420,
          732,
          819,
          2306,
          11,
          457,
          286,
          603,
          445,
          855,
          291,
          558,
          586,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1711046810807853,
        "compression_ratio": 1.6887417218543046,
        "end": 2111.36,
        "id": 686,
        "no_speech_prob": 0.005384799093008041,
        "seek": 209636,
        "start": 2108.36,
        "temperature": 0,
        "text": " The idea here is I did my training, I'm done,",
        "tokens": [
          50964,
          440,
          1558,
          510,
          307,
          286,
          630,
          452,
          3097,
          11,
          286,
          478,
          1096,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.1711046810807853,
        "compression_ratio": 1.6887417218543046,
        "end": 2114.36,
        "id": 687,
        "no_speech_prob": 0.005384799093008041,
        "seek": 209636,
        "start": 2111.36,
        "temperature": 0,
        "text": " and now I have something that automatically loads the model.",
        "tokens": [
          51114,
          293,
          586,
          286,
          362,
          746,
          300,
          6772,
          12668,
          264,
          2316,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1711046810807853,
        "compression_ratio": 1.6887417218543046,
        "end": 2115.36,
        "id": 688,
        "no_speech_prob": 0.005384799093008041,
        "seek": 209636,
        "start": 2114.36,
        "temperature": 0,
        "text": " Yay!",
        "tokens": [
          51264,
          13268,
          0,
          51314
        ]
      },
      {
        "avg_logprob": -0.1711046810807853,
        "compression_ratio": 1.6887417218543046,
        "end": 2116.36,
        "id": 689,
        "no_speech_prob": 0.005384799093008041,
        "seek": 209636,
        "start": 2115.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51314,
          1057,
          558,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1711046810807853,
        "compression_ratio": 1.6887417218543046,
        "end": 2117.36,
        "id": 690,
        "no_speech_prob": 0.005384799093008041,
        "seek": 209636,
        "start": 2116.36,
        "temperature": 0,
        "text": " So I hope this was helpful.",
        "tokens": [
          51364,
          407,
          286,
          1454,
          341,
          390,
          4961,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1711046810807853,
        "compression_ratio": 1.6887417218543046,
        "end": 2119.36,
        "id": 691,
        "no_speech_prob": 0.005384799093008041,
        "seek": 209636,
        "start": 2117.36,
        "temperature": 0,
        "text": " You can now see that process, right?",
        "tokens": [
          51414,
          509,
          393,
          586,
          536,
          300,
          1399,
          11,
          558,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.1711046810807853,
        "compression_ratio": 1.6887417218543046,
        "end": 2120.36,
        "id": 692,
        "no_speech_prob": 0.005384799093008041,
        "seek": 209636,
        "start": 2119.36,
        "temperature": 0,
        "text": " What is the process?",
        "tokens": [
          51514,
          708,
          307,
          264,
          1399,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.1711046810807853,
        "compression_ratio": 1.6887417218543046,
        "end": 2125.36,
        "id": 693,
        "no_speech_prob": 0.005384799093008041,
        "seek": 209636,
        "start": 2120.36,
        "temperature": 0,
        "text": " Train the model, call the save function to download model.json",
        "tokens": [
          51564,
          28029,
          264,
          2316,
          11,
          818,
          264,
          3155,
          2445,
          281,
          5484,
          2316,
          13,
          73,
          3015,
          51814
        ]
      },
      {
        "avg_logprob": -0.17995607036433808,
        "compression_ratio": 1.7208480565371025,
        "end": 2129.36,
        "id": 694,
        "no_speech_prob": 0.0031725962180644274,
        "seek": 212536,
        "start": 2125.36,
        "temperature": 0,
        "text": " and model.weights.bin, then take those files into your sketch,",
        "tokens": [
          50364,
          293,
          2316,
          13,
          826,
          5761,
          13,
          13496,
          11,
          550,
          747,
          729,
          7098,
          666,
          428,
          12325,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.17995607036433808,
        "compression_ratio": 1.7208480565371025,
        "end": 2133.36,
        "id": 695,
        "no_speech_prob": 0.0031725962180644274,
        "seek": 212536,
        "start": 2129.36,
        "temperature": 0,
        "text": " use the load function to load them both, and then start classifying.",
        "tokens": [
          50564,
          764,
          264,
          3677,
          2445,
          281,
          3677,
          552,
          1293,
          11,
          293,
          550,
          722,
          1508,
          5489,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.17995607036433808,
        "compression_ratio": 1.7208480565371025,
        "end": 2134.36,
        "id": 696,
        "no_speech_prob": 0.0031725962180644274,
        "seek": 212536,
        "start": 2133.36,
        "temperature": 0,
        "text": " All right?",
        "tokens": [
          50764,
          1057,
          558,
          30,
          50814
        ]
      },
      {
        "avg_logprob": -0.17995607036433808,
        "compression_ratio": 1.7208480565371025,
        "end": 2135.36,
        "id": 697,
        "no_speech_prob": 0.0031725962180644274,
        "seek": 212536,
        "start": 2134.36,
        "temperature": 0,
        "text": " So give this a try.",
        "tokens": [
          50814,
          407,
          976,
          341,
          257,
          853,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.17995607036433808,
        "compression_ratio": 1.7208480565371025,
        "end": 2139.36,
        "id": 698,
        "no_speech_prob": 0.0031725962180644274,
        "seek": 212536,
        "start": 2135.36,
        "temperature": 0,
        "text": " See what you can do now that you can spend a lot of time training your model",
        "tokens": [
          50864,
          3008,
          437,
          291,
          393,
          360,
          586,
          300,
          291,
          393,
          3496,
          257,
          688,
          295,
          565,
          3097,
          428,
          2316,
          51064
        ]
      },
      {
        "avg_logprob": -0.17995607036433808,
        "compression_ratio": 1.7208480565371025,
        "end": 2142.36,
        "id": 699,
        "no_speech_prob": 0.0031725962180644274,
        "seek": 212536,
        "start": 2139.36,
        "temperature": 0,
        "text": " because you can save it and see what you make with it.",
        "tokens": [
          51064,
          570,
          291,
          393,
          3155,
          309,
          293,
          536,
          437,
          291,
          652,
          365,
          309,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17995607036433808,
        "compression_ratio": 1.7208480565371025,
        "end": 2143.36,
        "id": 700,
        "no_speech_prob": 0.0031725962180644274,
        "seek": 212536,
        "start": 2142.36,
        "temperature": 0,
        "text": " All right?",
        "tokens": [
          51214,
          1057,
          558,
          30,
          51264
        ]
      },
      {
        "avg_logprob": -0.17995607036433808,
        "compression_ratio": 1.7208480565371025,
        "end": 2145.36,
        "id": 701,
        "no_speech_prob": 0.0031725962180644274,
        "seek": 212536,
        "start": 2143.36,
        "temperature": 0,
        "text": " Thanks for watching, and I will see you in another ML...",
        "tokens": [
          51264,
          2561,
          337,
          1976,
          11,
          293,
          286,
          486,
          536,
          291,
          294,
          1071,
          21601,
          485,
          51364
        ]
      },
      {
        "avg_logprob": -0.17995607036433808,
        "compression_ratio": 1.7208480565371025,
        "end": 2147.36,
        "id": 702,
        "no_speech_prob": 0.0031725962180644274,
        "seek": 212536,
        "start": 2145.36,
        "temperature": 0,
        "text": " There will be more ML5 videos.",
        "tokens": [
          51364,
          821,
          486,
          312,
          544,
          21601,
          20,
          2145,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.17995607036433808,
        "compression_ratio": 1.7208480565371025,
        "end": 2149.36,
        "id": 703,
        "no_speech_prob": 0.0031725962180644274,
        "seek": 212536,
        "start": 2147.36,
        "temperature": 0,
        "text": " I don't even know what's next, but if there's a video that's next,",
        "tokens": [
          51464,
          286,
          500,
          380,
          754,
          458,
          437,
          311,
          958,
          11,
          457,
          498,
          456,
          311,
          257,
          960,
          300,
          311,
          958,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.17995607036433808,
        "compression_ratio": 1.7208480565371025,
        "end": 2150.36,
        "id": 704,
        "no_speech_prob": 0.0031725962180644274,
        "seek": 212536,
        "start": 2149.36,
        "temperature": 0,
        "text": " you can watch it.",
        "tokens": [
          51564,
          291,
          393,
          1159,
          309,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.17995607036433808,
        "compression_ratio": 1.7208480565371025,
        "end": 2151.36,
        "id": 705,
        "no_speech_prob": 0.0031725962180644274,
        "seek": 212536,
        "start": 2150.36,
        "temperature": 0,
        "text": " Goodbye.",
        "tokens": [
          51614,
          15528,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.24201452164422899,
        "compression_ratio": 1.3333333333333333,
        "end": 2154.36,
        "id": 706,
        "no_speech_prob": 0.032099705189466476,
        "seek": 215136,
        "start": 2152.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50414,
          1057,
          558,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.24201452164422899,
        "compression_ratio": 1.3333333333333333,
        "end": 2158.36,
        "id": 707,
        "no_speech_prob": 0.032099705189466476,
        "seek": 215136,
        "start": 2154.36,
        "temperature": 0,
        "text": " Hopefully that can be made into something understandable.",
        "tokens": [
          50514,
          10429,
          300,
          393,
          312,
          1027,
          666,
          746,
          25648,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.24201452164422899,
        "compression_ratio": 1.3333333333333333,
        "end": 2170.36,
        "id": 708,
        "no_speech_prob": 0.032099705189466476,
        "seek": 215136,
        "start": 2168.36,
        "temperature": 0,
        "text": " I wonder what would happen if...",
        "tokens": [
          51214,
          286,
          2441,
          437,
          576,
          1051,
          498,
          485,
          51314
        ]
      },
      {
        "avg_logprob": -0.24201452164422899,
        "compression_ratio": 1.3333333333333333,
        "end": 2172.36,
        "id": 709,
        "no_speech_prob": 0.032099705189466476,
        "seek": 215136,
        "start": 2170.36,
        "temperature": 0,
        "text": " I'm just curious, what would happen if I retrained it?",
        "tokens": [
          51314,
          286,
          478,
          445,
          6369,
          11,
          437,
          576,
          1051,
          498,
          286,
          1533,
          31774,
          309,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.24286498626073202,
        "compression_ratio": 1.5721649484536082,
        "end": 2184.36,
        "id": 710,
        "no_speech_prob": 0.00011061112309107557,
        "seek": 218136,
        "start": 2182.36,
        "temperature": 0,
        "text": " Yeah, I guess it retrains.",
        "tokens": [
          50414,
          865,
          11,
          286,
          2041,
          309,
          1533,
          424,
          1292,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.24286498626073202,
        "compression_ratio": 1.5721649484536082,
        "end": 2190.36,
        "id": 711,
        "no_speech_prob": 0.00011061112309107557,
        "seek": 218136,
        "start": 2188.36,
        "temperature": 0,
        "text": " Yeah, but then if I refresh, it's loading that previous model.",
        "tokens": [
          50714,
          865,
          11,
          457,
          550,
          498,
          286,
          15134,
          11,
          309,
          311,
          15114,
          300,
          3894,
          2316,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.24286498626073202,
        "compression_ratio": 1.5721649484536082,
        "end": 2191.36,
        "id": 712,
        "no_speech_prob": 0.00011061112309107557,
        "seek": 218136,
        "start": 2190.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50814,
          1033,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.24286498626073202,
        "compression_ratio": 1.5721649484536082,
        "end": 2194.36,
        "id": 713,
        "no_speech_prob": 0.00011061112309107557,
        "seek": 218136,
        "start": 2191.36,
        "temperature": 0,
        "text": " Any questions about this?",
        "tokens": [
          50864,
          2639,
          1651,
          466,
          341,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.24286498626073202,
        "compression_ratio": 1.5721649484536082,
        "end": 2198.36,
        "id": 714,
        "no_speech_prob": 0.00011061112309107557,
        "seek": 218136,
        "start": 2196.36,
        "temperature": 0,
        "text": " Will JS always load the setup function?",
        "tokens": [
          51114,
          3099,
          33063,
          1009,
          3677,
          264,
          8657,
          2445,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.24286498626073202,
        "compression_ratio": 1.5721649484536082,
        "end": 2200.36,
        "id": 715,
        "no_speech_prob": 0.00011061112309107557,
        "seek": 218136,
        "start": 2198.36,
        "temperature": 0,
        "text": " Automatic asks Tobias.",
        "tokens": [
          51214,
          6049,
          13143,
          8962,
          26350,
          4609,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.24286498626073202,
        "compression_ratio": 1.5721649484536082,
        "end": 2203.36,
        "id": 716,
        "no_speech_prob": 0.00011061112309107557,
        "seek": 218136,
        "start": 2200.36,
        "temperature": 0,
        "text": " So this is a feature of the p5 library.",
        "tokens": [
          51314,
          407,
          341,
          307,
          257,
          4111,
          295,
          264,
          280,
          20,
          6405,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.24286498626073202,
        "compression_ratio": 1.5721649484536082,
        "end": 2209.36,
        "id": 717,
        "no_speech_prob": 0.00011061112309107557,
        "seek": 218136,
        "start": 2203.36,
        "temperature": 0,
        "text": " So I'm using the p5 library, and the p5 library always calls the setup function.",
        "tokens": [
          51464,
          407,
          286,
          478,
          1228,
          264,
          280,
          20,
          6405,
          11,
          293,
          264,
          280,
          20,
          6405,
          1009,
          5498,
          264,
          992,
          84,
          79,
          2445,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2445828574044364,
        "compression_ratio": 1.4186046511627908,
        "end": 2212.36,
        "id": 718,
        "no_speech_prob": 0.028433112427592278,
        "seek": 220936,
        "start": 2209.36,
        "temperature": 0,
        "text": " And the p5 library always calls the setup function first.",
        "tokens": [
          50364,
          400,
          264,
          280,
          20,
          6405,
          1009,
          5498,
          264,
          8657,
          2445,
          700,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2445828574044364,
        "compression_ratio": 1.4186046511627908,
        "end": 2213.36,
        "id": 719,
        "no_speech_prob": 0.028433112427592278,
        "seek": 220936,
        "start": 2212.36,
        "temperature": 0,
        "text": " That's the way it's configured.",
        "tokens": [
          50514,
          663,
          311,
          264,
          636,
          309,
          311,
          30538,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2445828574044364,
        "compression_ratio": 1.4186046511627908,
        "end": 2216.36,
        "id": 720,
        "no_speech_prob": 0.028433112427592278,
        "seek": 220936,
        "start": 2213.36,
        "temperature": 0,
        "text": " But this is not something that will just happen in any JavaScript environment.",
        "tokens": [
          50564,
          583,
          341,
          307,
          406,
          746,
          300,
          486,
          445,
          1051,
          294,
          604,
          15778,
          2823,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2445828574044364,
        "compression_ratio": 1.4186046511627908,
        "end": 2217.36,
        "id": 721,
        "no_speech_prob": 0.028433112427592278,
        "seek": 220936,
        "start": 2216.36,
        "temperature": 0,
        "text": " It's here...",
        "tokens": [
          50714,
          467,
          311,
          510,
          485,
          50764
        ]
      },
      {
        "avg_logprob": -0.2445828574044364,
        "compression_ratio": 1.4186046511627908,
        "end": 2220.36,
        "id": 722,
        "no_speech_prob": 0.028433112427592278,
        "seek": 220936,
        "start": 2217.36,
        "temperature": 0,
        "text": " It's specifically part of the...",
        "tokens": [
          50764,
          467,
          311,
          4682,
          644,
          295,
          264,
          485,
          50914
        ]
      },
      {
        "avg_logprob": -0.2445828574044364,
        "compression_ratio": 1.4186046511627908,
        "end": 2225.36,
        "id": 723,
        "no_speech_prob": 0.028433112427592278,
        "seek": 220936,
        "start": 2221.36,
        "temperature": 0,
        "text": " Part of the p5 library.",
        "tokens": [
          50964,
          4100,
          295,
          264,
          280,
          20,
          6405,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2445828574044364,
        "compression_ratio": 1.4186046511627908,
        "end": 2226.36,
        "id": 724,
        "no_speech_prob": 0.028433112427592278,
        "seek": 220936,
        "start": 2225.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51164,
          1033,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2195391125149197,
        "compression_ratio": 1.5125628140703518,
        "end": 2227.36,
        "id": 725,
        "no_speech_prob": 0.014502664096653461,
        "seek": 222636,
        "start": 2226.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.2195391125149197,
        "compression_ratio": 1.5125628140703518,
        "end": 2239.36,
        "id": 726,
        "no_speech_prob": 0.014502664096653461,
        "seek": 222636,
        "start": 2235.36,
        "temperature": 0,
        "text": " Copper asks, so save not save all the model like in Keras?",
        "tokens": [
          50814,
          47243,
          8962,
          11,
          370,
          3155,
          406,
          3155,
          439,
          264,
          2316,
          411,
          294,
          591,
          6985,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.2195391125149197,
        "compression_ratio": 1.5125628140703518,
        "end": 2243.36,
        "id": 727,
        "no_speech_prob": 0.014502664096653461,
        "seek": 222636,
        "start": 2239.36,
        "temperature": 0,
        "text": " I'm not sure I completely understand that question, but I'm going to try to rephrase it.",
        "tokens": [
          51014,
          286,
          478,
          406,
          988,
          286,
          2584,
          1223,
          300,
          1168,
          11,
          457,
          286,
          478,
          516,
          281,
          853,
          281,
          319,
          44598,
          651,
          309,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2195391125149197,
        "compression_ratio": 1.5125628140703518,
        "end": 2248.36,
        "id": 728,
        "no_speech_prob": 0.014502664096653461,
        "seek": 222636,
        "start": 2243.36,
        "temperature": 0,
        "text": " I think what Copper is asking is, is this like saving a model in Keras?",
        "tokens": [
          51214,
          286,
          519,
          437,
          47243,
          307,
          3365,
          307,
          11,
          307,
          341,
          411,
          6816,
          257,
          2316,
          294,
          591,
          6985,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.2195391125149197,
        "compression_ratio": 1.5125628140703518,
        "end": 2250.36,
        "id": 729,
        "no_speech_prob": 0.014502664096653461,
        "seek": 222636,
        "start": 2248.36,
        "temperature": 0,
        "text": " And the answer is yes.",
        "tokens": [
          51464,
          400,
          264,
          1867,
          307,
          2086,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2195391125149197,
        "compression_ratio": 1.5125628140703518,
        "end": 2252.36,
        "id": 730,
        "no_speech_prob": 0.014502664096653461,
        "seek": 222636,
        "start": 2250.36,
        "temperature": 0,
        "text": " There's a lot of nuance to this, because number one,",
        "tokens": [
          51564,
          821,
          311,
          257,
          688,
          295,
          42625,
          281,
          341,
          11,
          570,
          1230,
          472,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.18213034964896538,
        "compression_ratio": 1.6980392156862745,
        "end": 2257.36,
        "id": 731,
        "no_speech_prob": 0.024052172899246216,
        "seek": 225236,
        "start": 2252.36,
        "temperature": 0,
        "text": " it's saving the model in a particular format that is compatible with TensorFlow.js.",
        "tokens": [
          50364,
          309,
          311,
          6816,
          264,
          2316,
          294,
          257,
          1729,
          7877,
          300,
          307,
          18218,
          365,
          37624,
          13,
          25530,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18213034964896538,
        "compression_ratio": 1.6980392156862745,
        "end": 2262.36,
        "id": 732,
        "no_speech_prob": 0.024052172899246216,
        "seek": 225236,
        "start": 2257.36,
        "temperature": 0,
        "text": " So this model that we saved won't necessarily work with a Python Keras example",
        "tokens": [
          50614,
          407,
          341,
          2316,
          300,
          321,
          6624,
          1582,
          380,
          4725,
          589,
          365,
          257,
          15329,
          591,
          6985,
          1365,
          50864
        ]
      },
      {
        "avg_logprob": -0.18213034964896538,
        "compression_ratio": 1.6980392156862745,
        "end": 2265.36,
        "id": 733,
        "no_speech_prob": 0.024052172899246216,
        "seek": 225236,
        "start": 2262.36,
        "temperature": 0,
        "text": " without being sort of converted to what it needs there.",
        "tokens": [
          50864,
          1553,
          885,
          1333,
          295,
          16424,
          281,
          437,
          309,
          2203,
          456,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18213034964896538,
        "compression_ratio": 1.6980392156862745,
        "end": 2271.36,
        "id": 734,
        "no_speech_prob": 0.024052172899246216,
        "seek": 225236,
        "start": 2265.36,
        "temperature": 0,
        "text": " And there's also this sort of strange feature of it,",
        "tokens": [
          51014,
          400,
          456,
          311,
          611,
          341,
          1333,
          295,
          5861,
          4111,
          295,
          309,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.18213034964896538,
        "compression_ratio": 1.6980392156862745,
        "end": 2273.36,
        "id": 735,
        "no_speech_prob": 0.024052172899246216,
        "seek": 225236,
        "start": 2271.36,
        "temperature": 0,
        "text": " which is that it's already like...",
        "tokens": [
          51314,
          597,
          307,
          300,
          309,
          311,
          1217,
          411,
          485,
          51414
        ]
      },
      {
        "avg_logprob": -0.18213034964896538,
        "compression_ratio": 1.6980392156862745,
        "end": 2277.36,
        "id": 736,
        "no_speech_prob": 0.024052172899246216,
        "seek": 225236,
        "start": 2273.36,
        "temperature": 0,
        "text": " We're just saving the sort of part that's on top of the MobileNet model.",
        "tokens": [
          51414,
          492,
          434,
          445,
          6816,
          264,
          1333,
          295,
          644,
          300,
          311,
          322,
          1192,
          295,
          264,
          22625,
          31890,
          2316,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18213034964896538,
        "compression_ratio": 1.6980392156862745,
        "end": 2280.36,
        "id": 737,
        "no_speech_prob": 0.024052172899246216,
        "seek": 225236,
        "start": 2277.36,
        "temperature": 0,
        "text": " So I haven't like resaved the entire MobileNet model.",
        "tokens": [
          51614,
          407,
          286,
          2378,
          380,
          411,
          725,
          12865,
          264,
          2302,
          22625,
          31890,
          2316,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.22362785713345396,
        "compression_ratio": 1.6390243902439023,
        "end": 2286.36,
        "id": 738,
        "no_speech_prob": 0.005060240160673857,
        "seek": 228036,
        "start": 2280.36,
        "temperature": 0,
        "text": " I'm just saving the transfer learning piece of it that is plugged into the MobileNet model.",
        "tokens": [
          50364,
          286,
          478,
          445,
          6816,
          264,
          5003,
          2539,
          2522,
          295,
          309,
          300,
          307,
          25679,
          666,
          264,
          22625,
          31890,
          2316,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.22362785713345396,
        "compression_ratio": 1.6390243902439023,
        "end": 2289.36,
        "id": 739,
        "no_speech_prob": 0.005060240160673857,
        "seek": 228036,
        "start": 2286.36,
        "temperature": 0,
        "text": " Because it's still always loading the MobileNet model.",
        "tokens": [
          50664,
          1436,
          309,
          311,
          920,
          1009,
          15114,
          264,
          22625,
          31890,
          2316,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.22362785713345396,
        "compression_ratio": 1.6390243902439023,
        "end": 2296.36,
        "id": 740,
        "no_speech_prob": 0.005060240160673857,
        "seek": 228036,
        "start": 2290.36,
        "temperature": 0,
        "text": " And yes, KWikOne says, as far as I know, you can even import a Keras model into tf.js.",
        "tokens": [
          50864,
          400,
          2086,
          11,
          591,
          54,
          1035,
          15426,
          1619,
          11,
          382,
          1400,
          382,
          286,
          458,
          11,
          291,
          393,
          754,
          974,
          257,
          591,
          6985,
          2316,
          666,
          256,
          69,
          13,
          25530,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.22362785713345396,
        "compression_ratio": 1.6390243902439023,
        "end": 2300.36,
        "id": 741,
        "no_speech_prob": 0.005060240160673857,
        "seek": 228036,
        "start": 2296.36,
        "temperature": 0,
        "text": " So yes, if you want to import a Keras model into tf.js,",
        "tokens": [
          51164,
          407,
          2086,
          11,
          498,
          291,
          528,
          281,
          974,
          257,
          591,
          6985,
          2316,
          666,
          256,
          69,
          13,
          25530,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.22362785713345396,
        "compression_ratio": 1.6390243902439023,
        "end": 2304.36,
        "id": 742,
        "no_speech_prob": 0.005060240160673857,
        "seek": 228036,
        "start": 2300.36,
        "temperature": 0,
        "text": " you just need to look for the tf.js converter.",
        "tokens": [
          51364,
          291,
          445,
          643,
          281,
          574,
          337,
          264,
          256,
          69,
          13,
          25530,
          33905,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18257080348192062,
        "compression_ratio": 1.6311787072243347,
        "end": 2310.36,
        "id": 743,
        "no_speech_prob": 0.039046432822942734,
        "seek": 230436,
        "start": 2304.36,
        "temperature": 0,
        "text": " This is a script that will take any TensorFlow or Keras saved model and convert it into TensorFlow.js.",
        "tokens": [
          50364,
          639,
          307,
          257,
          5755,
          300,
          486,
          747,
          604,
          37624,
          420,
          591,
          6985,
          6624,
          2316,
          293,
          7620,
          309,
          666,
          37624,
          13,
          25530,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.18257080348192062,
        "compression_ratio": 1.6311787072243347,
        "end": 2313.36,
        "id": 744,
        "no_speech_prob": 0.039046432822942734,
        "seek": 230436,
        "start": 2310.36,
        "temperature": 0,
        "text": " This is from the TensorFlow project itself.",
        "tokens": [
          50664,
          639,
          307,
          490,
          264,
          37624,
          1716,
          2564,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.18257080348192062,
        "compression_ratio": 1.6311787072243347,
        "end": 2316.36,
        "id": 745,
        "no_speech_prob": 0.039046432822942734,
        "seek": 230436,
        "start": 2313.36,
        "temperature": 0,
        "text": " Does that mean it will work automatically with ml5?",
        "tokens": [
          50814,
          4402,
          300,
          914,
          309,
          486,
          589,
          6772,
          365,
          23271,
          20,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.18257080348192062,
        "compression_ratio": 1.6311787072243347,
        "end": 2320.36,
        "id": 746,
        "no_speech_prob": 0.039046432822942734,
        "seek": 230436,
        "start": 2316.36,
        "temperature": 0,
        "text": " In theory, yes, but ml5 is kind of a subset of TensorFlow.js",
        "tokens": [
          50964,
          682,
          5261,
          11,
          2086,
          11,
          457,
          23271,
          20,
          307,
          733,
          295,
          257,
          25993,
          295,
          37624,
          13,
          25530,
          51164
        ]
      },
      {
        "avg_logprob": -0.18257080348192062,
        "compression_ratio": 1.6311787072243347,
        "end": 2323.36,
        "id": 747,
        "no_speech_prob": 0.039046432822942734,
        "seek": 230436,
        "start": 2320.36,
        "temperature": 0,
        "text": " with a bunch of things wrapped to be a little simpler to work with.",
        "tokens": [
          51164,
          365,
          257,
          3840,
          295,
          721,
          14226,
          281,
          312,
          257,
          707,
          18587,
          281,
          589,
          365,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18257080348192062,
        "compression_ratio": 1.6311787072243347,
        "end": 2331.36,
        "id": 748,
        "no_speech_prob": 0.039046432822942734,
        "seek": 230436,
        "start": 2325.36,
        "temperature": 0,
        "text": " I kind of want to do that video again, because I feel like I don't know if I hit all the right notes.",
        "tokens": [
          51414,
          286,
          733,
          295,
          528,
          281,
          360,
          300,
          960,
          797,
          11,
          570,
          286,
          841,
          411,
          286,
          500,
          380,
          458,
          498,
          286,
          2045,
          439,
          264,
          558,
          5570,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.3193274580914041,
        "compression_ratio": 1.2540983606557377,
        "end": 2335.36,
        "id": 749,
        "no_speech_prob": 0.000010952910997730214,
        "seek": 233136,
        "start": 2332.36,
        "temperature": 0,
        "text": " I'm going to do it again.",
        "tokens": [
          50414,
          286,
          478,
          516,
          281,
          360,
          309,
          797,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.3193274580914041,
        "compression_ratio": 1.2540983606557377,
        "end": 2342.36,
        "id": 750,
        "no_speech_prob": 0.000010952910997730214,
        "seek": 233136,
        "start": 2337.36,
        "temperature": 0,
        "text": " And then Mathieu can pull, because I feel like this is a really sort of important one.",
        "tokens": [
          50664,
          400,
          550,
          15776,
          19347,
          393,
          2235,
          11,
          570,
          286,
          841,
          411,
          341,
          307,
          257,
          534,
          1333,
          295,
          1021,
          472,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.3193274580914041,
        "compression_ratio": 1.2540983606557377,
        "end": 2354.36,
        "id": 751,
        "no_speech_prob": 0.000010952910997730214,
        "seek": 233136,
        "start": 2351.36,
        "temperature": 0,
        "text": " And then I will do the quick draw stuff.",
        "tokens": [
          51364,
          400,
          550,
          286,
          486,
          360,
          264,
          1702,
          2642,
          1507,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2120096787162449,
        "compression_ratio": 1.4043715846994536,
        "end": 2360.36,
        "id": 752,
        "no_speech_prob": 0.002434096299111843,
        "seek": 235436,
        "start": 2355.36,
        "temperature": 0,
        "text": " ASDFGHJKL space ASDFGHJKL asks,",
        "tokens": [
          50414,
          7469,
          35,
          37,
          4269,
          41,
          42,
          43,
          1901,
          7469,
          35,
          37,
          4269,
          41,
          42,
          43,
          8962,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.2120096787162449,
        "compression_ratio": 1.4043715846994536,
        "end": 2366.36,
        "id": 753,
        "no_speech_prob": 0.002434096299111843,
        "seek": 235436,
        "start": 2362.36,
        "temperature": 0,
        "text": " why do you choose p5.js over other JavaScript libraries?",
        "tokens": [
          50764,
          983,
          360,
          291,
          2826,
          280,
          20,
          13,
          25530,
          670,
          661,
          15778,
          15148,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.2120096787162449,
        "compression_ratio": 1.4043715846994536,
        "end": 2368.36,
        "id": 754,
        "no_speech_prob": 0.002434096299111843,
        "seek": 235436,
        "start": 2366.36,
        "temperature": 0,
        "text": " I love p5.js.",
        "tokens": [
          50964,
          286,
          959,
          280,
          20,
          13,
          25530,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2120096787162449,
        "compression_ratio": 1.4043715846994536,
        "end": 2375.36,
        "id": 755,
        "no_speech_prob": 0.002434096299111843,
        "seek": 235436,
        "start": 2368.36,
        "temperature": 0,
        "text": " I mean, it's a great question, and I don't think there, I certainly am not here to say,",
        "tokens": [
          51064,
          286,
          914,
          11,
          309,
          311,
          257,
          869,
          1168,
          11,
          293,
          286,
          500,
          380,
          519,
          456,
          11,
          286,
          3297,
          669,
          406,
          510,
          281,
          584,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.2120096787162449,
        "compression_ratio": 1.4043715846994536,
        "end": 2379.36,
        "id": 756,
        "no_speech_prob": 0.002434096299111843,
        "seek": 235436,
        "start": 2375.36,
        "temperature": 0,
        "text": " please, I think you, the viewer of this channel, should use p5.js.",
        "tokens": [
          51414,
          1767,
          11,
          286,
          519,
          291,
          11,
          264,
          16767,
          295,
          341,
          2269,
          11,
          820,
          764,
          280,
          20,
          13,
          25530,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1696357421875,
        "compression_ratio": 1.7035714285714285,
        "end": 2385.36,
        "id": 757,
        "no_speech_prob": 0.0020827152766287327,
        "seek": 237936,
        "start": 2379.36,
        "temperature": 0,
        "text": " The reason why I use it is because it's a project that's connected to a project.",
        "tokens": [
          50364,
          440,
          1778,
          983,
          286,
          764,
          309,
          307,
          570,
          309,
          311,
          257,
          1716,
          300,
          311,
          4582,
          281,
          257,
          1716,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1696357421875,
        "compression_ratio": 1.7035714285714285,
        "end": 2386.36,
        "id": 758,
        "no_speech_prob": 0.0020827152766287327,
        "seek": 237936,
        "start": 2385.36,
        "temperature": 0,
        "text": " It is a project.",
        "tokens": [
          50664,
          467,
          307,
          257,
          1716,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1696357421875,
        "compression_ratio": 1.7035714285714285,
        "end": 2390.36,
        "id": 759,
        "no_speech_prob": 0.0020827152766287327,
        "seek": 237936,
        "start": 2386.36,
        "temperature": 0,
        "text": " It's part of a project called the Processing Foundation, an entity that I've worked on for many years",
        "tokens": [
          50714,
          467,
          311,
          644,
          295,
          257,
          1716,
          1219,
          264,
          31093,
          278,
          10335,
          11,
          364,
          13977,
          300,
          286,
          600,
          2732,
          322,
          337,
          867,
          924,
          50914
        ]
      },
      {
        "avg_logprob": -0.1696357421875,
        "compression_ratio": 1.7035714285714285,
        "end": 2392.36,
        "id": 760,
        "no_speech_prob": 0.0020827152766287327,
        "seek": 237936,
        "start": 2390.36,
        "temperature": 0,
        "text": " that I have a lot of personal investment in,",
        "tokens": [
          50914,
          300,
          286,
          362,
          257,
          688,
          295,
          2973,
          6078,
          294,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.1696357421875,
        "compression_ratio": 1.7035714285714285,
        "end": 2398.36,
        "id": 761,
        "no_speech_prob": 0.0020827152766287327,
        "seek": 237936,
        "start": 2392.36,
        "temperature": 0,
        "text": " and the goals of that project in terms of being beginner-friendly, being inclusive,",
        "tokens": [
          51014,
          293,
          264,
          5493,
          295,
          300,
          1716,
          294,
          2115,
          295,
          885,
          22080,
          12,
          22864,
          11,
          885,
          13429,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.1696357421875,
        "compression_ratio": 1.7035714285714285,
        "end": 2402.36,
        "id": 762,
        "no_speech_prob": 0.0020827152766287327,
        "seek": 237936,
        "start": 2398.36,
        "temperature": 0,
        "text": " are values and principles that are close to my heart",
        "tokens": [
          51314,
          366,
          4190,
          293,
          9156,
          300,
          366,
          1998,
          281,
          452,
          1917,
          51514
        ]
      },
      {
        "avg_logprob": -0.1696357421875,
        "compression_ratio": 1.7035714285714285,
        "end": 2405.36,
        "id": 763,
        "no_speech_prob": 0.0020827152766287327,
        "seek": 237936,
        "start": 2402.36,
        "temperature": 0,
        "text": " and that work well with the kind of stuff that I want to do in this channel.",
        "tokens": [
          51514,
          293,
          300,
          589,
          731,
          365,
          264,
          733,
          295,
          1507,
          300,
          286,
          528,
          281,
          360,
          294,
          341,
          2269,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1696357421875,
        "compression_ratio": 1.7035714285714285,
        "end": 2407.36,
        "id": 764,
        "no_speech_prob": 0.0020827152766287327,
        "seek": 237936,
        "start": 2405.36,
        "temperature": 0,
        "text": " Is it perfect? No.",
        "tokens": [
          51664,
          1119,
          309,
          2176,
          30,
          883,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20633965272169846,
        "compression_ratio": 1.5485232067510548,
        "end": 2410.36,
        "id": 765,
        "no_speech_prob": 0.000030718041671207175,
        "seek": 240736,
        "start": 2407.36,
        "temperature": 0,
        "text": " Are there other things that you might want to use instead?",
        "tokens": [
          50364,
          2014,
          456,
          661,
          721,
          300,
          291,
          1062,
          528,
          281,
          764,
          2602,
          30,
          50514
        ]
      },
      {
        "avg_logprob": -0.20633965272169846,
        "compression_ratio": 1.5485232067510548,
        "end": 2415.36,
        "id": 766,
        "no_speech_prob": 0.000030718041671207175,
        "seek": 240736,
        "start": 2410.36,
        "temperature": 0,
        "text": " Definitely, but it's a good foundation library for me to build a lot of stuff with.",
        "tokens": [
          50514,
          12151,
          11,
          457,
          309,
          311,
          257,
          665,
          7030,
          6405,
          337,
          385,
          281,
          1322,
          257,
          688,
          295,
          1507,
          365,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20633965272169846,
        "compression_ratio": 1.5485232067510548,
        "end": 2416.36,
        "id": 767,
        "no_speech_prob": 0.000030718041671207175,
        "seek": 240736,
        "start": 2415.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50764,
          1057,
          558,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20633965272169846,
        "compression_ratio": 1.5485232067510548,
        "end": 2419.36,
        "id": 768,
        "no_speech_prob": 0.000030718041671207175,
        "seek": 240736,
        "start": 2416.36,
        "temperature": 0,
        "text": " I know I've been torturing you all, but I'm going to do this again",
        "tokens": [
          50814,
          286,
          458,
          286,
          600,
          668,
          10806,
          1345,
          291,
          439,
          11,
          457,
          286,
          478,
          516,
          281,
          360,
          341,
          797,
          50964
        ]
      },
      {
        "avg_logprob": -0.20633965272169846,
        "compression_ratio": 1.5485232067510548,
        "end": 2422.36,
        "id": 769,
        "no_speech_prob": 0.000030718041671207175,
        "seek": 240736,
        "start": 2419.36,
        "temperature": 0,
        "text": " just to give Matthew more material to work with",
        "tokens": [
          50964,
          445,
          281,
          976,
          6789,
          3322,
          86,
          544,
          2527,
          281,
          589,
          365,
          51114
        ]
      },
      {
        "avg_logprob": -0.20633965272169846,
        "compression_ratio": 1.5485232067510548,
        "end": 2428.36,
        "id": 770,
        "no_speech_prob": 0.000030718041671207175,
        "seek": 240736,
        "start": 2422.36,
        "temperature": 0,
        "text": " now that I have a sense of what the issues are.",
        "tokens": [
          51114,
          586,
          300,
          286,
          362,
          257,
          2020,
          295,
          437,
          264,
          2663,
          366,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20633965272169846,
        "compression_ratio": 1.5485232067510548,
        "end": 2432.36,
        "id": 771,
        "no_speech_prob": 0.000030718041671207175,
        "seek": 240736,
        "start": 2428.36,
        "temperature": 0,
        "text": " So I'm going to go back to what it was originally,",
        "tokens": [
          51414,
          407,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          437,
          309,
          390,
          7993,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.29486903166159606,
        "compression_ratio": 1.1979166666666667,
        "end": 2437.36,
        "id": 772,
        "no_speech_prob": 0.1560734510421753,
        "seek": 243236,
        "start": 2433.36,
        "temperature": 0,
        "text": " and I'm going to redo a couple things to make it less awkward.",
        "tokens": [
          50414,
          293,
          286,
          478,
          516,
          281,
          29956,
          257,
          1916,
          721,
          281,
          652,
          309,
          1570,
          11411,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.29486903166159606,
        "compression_ratio": 1.1979166666666667,
        "end": 2446.36,
        "id": 773,
        "no_speech_prob": 0.1560734510421753,
        "seek": 243236,
        "start": 2443.36,
        "temperature": 0,
        "text": " I am going to—let's just see here.",
        "tokens": [
          50914,
          286,
          669,
          516,
          281,
          2958,
          2631,
          311,
          445,
          536,
          510,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.29486903166159606,
        "compression_ratio": 1.1979166666666667,
        "end": 2459.36,
        "id": 774,
        "no_speech_prob": 0.1560734510421753,
        "seek": 243236,
        "start": 2458.36,
        "temperature": 0,
        "text": " Let's see here.",
        "tokens": [
          51664,
          961,
          311,
          536,
          510,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18124210834503174,
        "compression_ratio": 1.3359375,
        "end": 2460.36,
        "id": 775,
        "no_speech_prob": 0.000020145622329437174,
        "seek": 245936,
        "start": 2459.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.18124210834503174,
        "compression_ratio": 1.3359375,
        "end": 2468.36,
        "id": 776,
        "no_speech_prob": 0.000020145622329437174,
        "seek": 245936,
        "start": 2460.36,
        "temperature": 0,
        "text": " So I'm going to move some things around, I think, to make things less awkward.",
        "tokens": [
          50414,
          407,
          286,
          478,
          516,
          281,
          1286,
          512,
          721,
          926,
          11,
          286,
          519,
          11,
          281,
          652,
          721,
          1570,
          11411,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.18124210834503174,
        "compression_ratio": 1.3359375,
        "end": 2477.36,
        "id": 777,
        "no_speech_prob": 0.000020145622329437174,
        "seek": 245936,
        "start": 2474.36,
        "temperature": 0,
        "text": " Is that legible, this font size?",
        "tokens": [
          51114,
          1119,
          300,
          1676,
          964,
          11,
          341,
          10703,
          2744,
          30,
          51264
        ]
      },
      {
        "avg_logprob": -0.18124210834503174,
        "compression_ratio": 1.3359375,
        "end": 2481.36,
        "id": 778,
        "no_speech_prob": 0.000020145622329437174,
        "seek": 245936,
        "start": 2480.36,
        "temperature": 0,
        "text": " Is this legible?",
        "tokens": [
          51414,
          1119,
          341,
          1676,
          964,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.18124210834503174,
        "compression_ratio": 1.3359375,
        "end": 2484.36,
        "id": 779,
        "no_speech_prob": 0.000020145622329437174,
        "seek": 245936,
        "start": 2481.36,
        "temperature": 0,
        "text": " It's smaller than I usually have it,",
        "tokens": [
          51464,
          467,
          311,
          4356,
          813,
          286,
          2673,
          362,
          309,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.18986403942108154,
        "compression_ratio": 1.2477064220183487,
        "end": 2492.36,
        "id": 780,
        "no_speech_prob": 0.0003150323173031211,
        "seek": 248436,
        "start": 2484.36,
        "temperature": 0,
        "text": " but this might be helpful to have a little bit more room to look at the code.",
        "tokens": [
          50364,
          457,
          341,
          1062,
          312,
          4961,
          281,
          362,
          257,
          707,
          857,
          544,
          1808,
          281,
          574,
          412,
          264,
          3089,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.18986403942108154,
        "compression_ratio": 1.2477064220183487,
        "end": 2512.36,
        "id": 781,
        "no_speech_prob": 0.0003150323173031211,
        "seek": 248436,
        "start": 2509.36,
        "temperature": 0,
        "text": " Yeah, let me rename the uke and whistle button.",
        "tokens": [
          51614,
          865,
          11,
          718,
          385,
          36741,
          264,
          344,
          330,
          293,
          23470,
          2960,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18986403942108154,
        "compression_ratio": 1.2477064220183487,
        "end": 2513.36,
        "id": 782,
        "no_speech_prob": 0.0003150323173031211,
        "seek": 248436,
        "start": 2512.36,
        "temperature": 0,
        "text": " Thank you.",
        "tokens": [
          51764,
          1044,
          291,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1934615337487423,
        "compression_ratio": 1.2307692307692308,
        "end": 2515.36,
        "id": 783,
        "no_speech_prob": 0.00003321352050988935,
        "seek": 251436,
        "start": 2514.36,
        "temperature": 0,
        "text": " Let me rename those.",
        "tokens": [
          50364,
          961,
          385,
          36741,
          729,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.1934615337487423,
        "compression_ratio": 1.2307692307692308,
        "end": 2516.36,
        "id": 784,
        "no_speech_prob": 0.00003321352050988935,
        "seek": 251436,
        "start": 2515.36,
        "temperature": 0,
        "text": " Thank you.",
        "tokens": [
          50414,
          1044,
          291,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1934615337487423,
        "compression_ratio": 1.2307692307692308,
        "end": 2518.36,
        "id": 785,
        "no_speech_prob": 0.00003321352050988935,
        "seek": 251436,
        "start": 2516.36,
        "temperature": 0,
        "text": " That is—I don't know why I'm—",
        "tokens": [
          50464,
          663,
          307,
          2958,
          40,
          500,
          380,
          458,
          983,
          286,
          478,
          2958,
          50564
        ]
      },
      {
        "avg_logprob": -0.1934615337487423,
        "compression_ratio": 1.2307692307692308,
        "end": 2527.36,
        "id": 786,
        "no_speech_prob": 0.00003321352050988935,
        "seek": 251436,
        "start": 2518.36,
        "temperature": 0,
        "text": " a happy button, sad button, a train button.",
        "tokens": [
          50564,
          257,
          2055,
          2960,
          11,
          4227,
          2960,
          11,
          257,
          3847,
          2960,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1934615337487423,
        "compression_ratio": 1.2307692307692308,
        "end": 2529.36,
        "id": 787,
        "no_speech_prob": 0.00003321352050988935,
        "seek": 251436,
        "start": 2527.36,
        "temperature": 0,
        "text": " Okay, so that's good.",
        "tokens": [
          51014,
          1033,
          11,
          370,
          300,
          311,
          665,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1934615337487423,
        "compression_ratio": 1.2307692307692308,
        "end": 2531.36,
        "id": 788,
        "no_speech_prob": 0.00003321352050988935,
        "seek": 251436,
        "start": 2529.36,
        "temperature": 0,
        "text": " Any other suggestions?",
        "tokens": [
          51114,
          2639,
          661,
          13396,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.1934615337487423,
        "compression_ratio": 1.2307692307692308,
        "end": 2539.36,
        "id": 789,
        "no_speech_prob": 0.00003321352050988935,
        "seek": 251436,
        "start": 2537.36,
        "temperature": 0,
        "text": " It's fine.",
        "tokens": [
          51514,
          467,
          311,
          2489,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1934615337487423,
        "compression_ratio": 1.2307692307692308,
        "end": 2543.36,
        "id": 790,
        "no_speech_prob": 0.00003321352050988935,
        "seek": 251436,
        "start": 2542.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51764,
          1057,
          558,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.17476214302910698,
        "compression_ratio": 1.0129870129870129,
        "end": 2546.36,
        "id": 791,
        "no_speech_prob": 0.00007367782382061705,
        "seek": 254336,
        "start": 2543.36,
        "temperature": 0,
        "text": " Let me try it with the code a little bit smaller.",
        "tokens": [
          50364,
          961,
          385,
          853,
          309,
          365,
          264,
          3089,
          257,
          707,
          857,
          4356,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.17476214302910698,
        "compression_ratio": 1.0129870129870129,
        "end": 2560.36,
        "id": 792,
        "no_speech_prob": 0.00007367782382061705,
        "seek": 254336,
        "start": 2559.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51164,
          1033,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17476214302910698,
        "compression_ratio": 1.0129870129870129,
        "end": 2563.36,
        "id": 793,
        "no_speech_prob": 0.00007367782382061705,
        "seek": 254336,
        "start": 2561.36,
        "temperature": 0,
        "text": " Here we go, everybody.",
        "tokens": [
          51264,
          1692,
          321,
          352,
          11,
          2201,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1829935184195022,
        "compression_ratio": 1.6511627906976745,
        "end": 2576.36,
        "id": 794,
        "no_speech_prob": 0.020328350365161896,
        "seek": 257336,
        "start": 2574.36,
        "temperature": 0,
        "text": " Oh, right.",
        "tokens": [
          50414,
          876,
          11,
          558,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1829935184195022,
        "compression_ratio": 1.6511627906976745,
        "end": 2578.36,
        "id": 795,
        "no_speech_prob": 0.020328350365161896,
        "seek": 257336,
        "start": 2576.36,
        "temperature": 0,
        "text": " I have to do this ridiculous thing again.",
        "tokens": [
          50514,
          286,
          362,
          281,
          360,
          341,
          11083,
          551,
          797,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1829935184195022,
        "compression_ratio": 1.6511627906976745,
        "end": 2581.36,
        "id": 796,
        "no_speech_prob": 0.020328350365161896,
        "seek": 257336,
        "start": 2578.36,
        "temperature": 0,
        "text": " I mean, Mathieu, whenever you watch this,",
        "tokens": [
          50614,
          286,
          914,
          11,
          15776,
          19347,
          11,
          5699,
          291,
          1159,
          341,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.1829935184195022,
        "compression_ratio": 1.6511627906976745,
        "end": 2584.36,
        "id": 797,
        "no_speech_prob": 0.020328350365161896,
        "seek": 257336,
        "start": 2581.36,
        "temperature": 0,
        "text": " you can take stuff from the first try and mix it if you want,",
        "tokens": [
          50764,
          291,
          393,
          747,
          1507,
          490,
          264,
          700,
          853,
          293,
          2890,
          309,
          498,
          291,
          528,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.1829935184195022,
        "compression_ratio": 1.6511627906976745,
        "end": 2588.36,
        "id": 798,
        "no_speech_prob": 0.020328350365161896,
        "seek": 257336,
        "start": 2584.36,
        "temperature": 0,
        "text": " but it's my hope that this will just be a cleaner version of that video.",
        "tokens": [
          50914,
          457,
          309,
          311,
          452,
          1454,
          300,
          341,
          486,
          445,
          312,
          257,
          16532,
          3037,
          295,
          300,
          960,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1829935184195022,
        "compression_ratio": 1.6511627906976745,
        "end": 2592.36,
        "id": 799,
        "no_speech_prob": 0.020328350365161896,
        "seek": 257336,
        "start": 2588.36,
        "temperature": 0,
        "text": " And apologies to all of you watching live when I make the same jokes again.",
        "tokens": [
          51114,
          400,
          34929,
          281,
          439,
          295,
          291,
          1976,
          1621,
          562,
          286,
          652,
          264,
          912,
          14439,
          797,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1829935184195022,
        "compression_ratio": 1.6511627906976745,
        "end": 2595.36,
        "id": 800,
        "no_speech_prob": 0.020328350365161896,
        "seek": 257336,
        "start": 2592.36,
        "temperature": 0,
        "text": " Not that I made any jokes, not that any of them were funny,",
        "tokens": [
          51314,
          1726,
          300,
          286,
          1027,
          604,
          14439,
          11,
          406,
          300,
          604,
          295,
          552,
          645,
          4074,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.1829935184195022,
        "compression_ratio": 1.6511627906976745,
        "end": 2599.36,
        "id": 801,
        "no_speech_prob": 0.020328350365161896,
        "seek": 257336,
        "start": 2595.36,
        "temperature": 0,
        "text": " but if I did, I'll probably make them again, more awkwardly.",
        "tokens": [
          51464,
          457,
          498,
          286,
          630,
          11,
          286,
          603,
          1391,
          652,
          552,
          797,
          11,
          544,
          11411,
          356,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.24030811475670855,
        "compression_ratio": 1.4980392156862745,
        "end": 2603.36,
        "id": 802,
        "no_speech_prob": 0.0008166500483639538,
        "seek": 259936,
        "start": 2600.36,
        "temperature": 0,
        "text": " Can you continue working on the local project, asks David.",
        "tokens": [
          50414,
          1664,
          291,
          2354,
          1364,
          322,
          264,
          2654,
          1716,
          11,
          8962,
          4389,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.24030811475670855,
        "compression_ratio": 1.4980392156862745,
        "end": 2604.36,
        "id": 803,
        "no_speech_prob": 0.0008166500483639538,
        "seek": 259936,
        "start": 2603.36,
        "temperature": 0,
        "text": " I don't think so.",
        "tokens": [
          50564,
          286,
          500,
          380,
          519,
          370,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.24030811475670855,
        "compression_ratio": 1.4980392156862745,
        "end": 2605.36,
        "id": 804,
        "no_speech_prob": 0.0008166500483639538,
        "seek": 259936,
        "start": 2604.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50614,
          1033,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.24030811475670855,
        "compression_ratio": 1.4980392156862745,
        "end": 2611.36,
        "id": 805,
        "no_speech_prob": 0.0008166500483639538,
        "seek": 259936,
        "start": 2607.36,
        "temperature": 0,
        "text": " Hello, and welcome to another ML5 beginner's guide to machine learning",
        "tokens": [
          50764,
          2425,
          11,
          293,
          2928,
          281,
          1071,
          21601,
          20,
          22080,
          311,
          5934,
          281,
          3479,
          2539,
          50964
        ]
      },
      {
        "avg_logprob": -0.24030811475670855,
        "compression_ratio": 1.4980392156862745,
        "end": 2613.36,
        "id": 806,
        "no_speech_prob": 0.0008166500483639538,
        "seek": 259936,
        "start": 2611.36,
        "temperature": 0,
        "text": " with ML5.js video.",
        "tokens": [
          50964,
          365,
          21601,
          20,
          13,
          25530,
          960,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.24030811475670855,
        "compression_ratio": 1.4980392156862745,
        "end": 2616.36,
        "id": 807,
        "no_speech_prob": 0.0008166500483639538,
        "seek": 259936,
        "start": 2613.36,
        "temperature": 0,
        "text": " All right, so this one's a good one, I hope.",
        "tokens": [
          51064,
          1057,
          558,
          11,
          370,
          341,
          472,
          311,
          257,
          665,
          472,
          11,
          286,
          1454,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.24030811475670855,
        "compression_ratio": 1.4980392156862745,
        "end": 2619.36,
        "id": 808,
        "no_speech_prob": 0.0008166500483639538,
        "seek": 259936,
        "start": 2616.36,
        "temperature": 0,
        "text": " I'm about to make video number seven in this playlist.",
        "tokens": [
          51214,
          286,
          478,
          466,
          281,
          652,
          960,
          1230,
          3407,
          294,
          341,
          16788,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.24030811475670855,
        "compression_ratio": 1.4980392156862745,
        "end": 2621.36,
        "id": 809,
        "no_speech_prob": 0.0008166500483639538,
        "seek": 259936,
        "start": 2619.36,
        "temperature": 0,
        "text": " And this—the element in the—",
        "tokens": [
          51364,
          400,
          341,
          2958,
          3322,
          4478,
          294,
          264,
          2958,
          51464
        ]
      },
      {
        "avg_logprob": -0.24030811475670855,
        "compression_ratio": 1.4980392156862745,
        "end": 2624.36,
        "id": 810,
        "no_speech_prob": 0.0008166500483639538,
        "seek": 259936,
        "start": 2621.36,
        "temperature": 0,
        "text": " Oh, I forgot something.",
        "tokens": [
          51464,
          876,
          11,
          286,
          5298,
          746,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.24030811475670855,
        "compression_ratio": 1.4980392156862745,
        "end": 2628.36,
        "id": 811,
        "no_speech_prob": 0.0008166500483639538,
        "seek": 259936,
        "start": 2624.36,
        "temperature": 0,
        "text": " I forgot that I have all of this stuff here already.",
        "tokens": [
          51614,
          286,
          5298,
          300,
          286,
          362,
          439,
          295,
          341,
          1507,
          510,
          1217,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1990973154703776,
        "compression_ratio": 1.7833333333333334,
        "end": 2631.36,
        "id": 812,
        "no_speech_prob": 0.003074751468375325,
        "seek": 262836,
        "start": 2628.36,
        "temperature": 0,
        "text": " And I don't want it to be.",
        "tokens": [
          50364,
          400,
          286,
          500,
          380,
          528,
          309,
          281,
          312,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1990973154703776,
        "compression_ratio": 1.7833333333333334,
        "end": 2634.36,
        "id": 813,
        "no_speech_prob": 0.003074751468375325,
        "seek": 262836,
        "start": 2631.36,
        "temperature": 0,
        "text": " Delete, delete, I'm so in love with you.",
        "tokens": [
          50514,
          49452,
          11,
          12097,
          11,
          286,
          478,
          370,
          294,
          959,
          365,
          291,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1990973154703776,
        "compression_ratio": 1.7833333333333334,
        "end": 2638.36,
        "id": 814,
        "no_speech_prob": 0.003074751468375325,
        "seek": 262836,
        "start": 2634.36,
        "temperature": 0,
        "text": " Delete, delete, oh, with my eyes so blue.",
        "tokens": [
          50664,
          49452,
          11,
          12097,
          11,
          1954,
          11,
          365,
          452,
          2575,
          370,
          3344,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1990973154703776,
        "compression_ratio": 1.7833333333333334,
        "end": 2644.36,
        "id": 815,
        "no_speech_prob": 0.003074751468375325,
        "seek": 262836,
        "start": 2638.36,
        "temperature": 0,
        "text": " Delete, delete, delete, delete, delete, delete, delete.",
        "tokens": [
          50864,
          49452,
          11,
          12097,
          11,
          12097,
          11,
          12097,
          11,
          12097,
          11,
          12097,
          11,
          12097,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1990973154703776,
        "compression_ratio": 1.7833333333333334,
        "end": 2651.36,
        "id": 816,
        "no_speech_prob": 0.003074751468375325,
        "seek": 262836,
        "start": 2649.36,
        "temperature": 0,
        "text": " It's getting hot in here.",
        "tokens": [
          51414,
          467,
          311,
          1242,
          2368,
          294,
          510,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1990973154703776,
        "compression_ratio": 1.7833333333333334,
        "end": 2654.36,
        "id": 817,
        "no_speech_prob": 0.003074751468375325,
        "seek": 262836,
        "start": 2652.36,
        "temperature": 0,
        "text": " All right, here we go.",
        "tokens": [
          51564,
          1057,
          558,
          11,
          510,
          321,
          352,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.15526770066845325,
        "compression_ratio": 1.6666666666666667,
        "end": 2661.36,
        "id": 818,
        "no_speech_prob": 0.0002694762370083481,
        "seek": 265436,
        "start": 2655.36,
        "temperature": 0,
        "text": " Hello, and welcome to another beginner's guide to machine learning with ML5.js video.",
        "tokens": [
          50414,
          2425,
          11,
          293,
          2928,
          281,
          1071,
          22080,
          311,
          5934,
          281,
          3479,
          2539,
          365,
          21601,
          20,
          13,
          25530,
          960,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.15526770066845325,
        "compression_ratio": 1.6666666666666667,
        "end": 2665.36,
        "id": 819,
        "no_speech_prob": 0.0002694762370083481,
        "seek": 265436,
        "start": 2661.36,
        "temperature": 0,
        "text": " Now, in this video, I am going to unlock something for you.",
        "tokens": [
          50714,
          823,
          11,
          294,
          341,
          960,
          11,
          286,
          669,
          516,
          281,
          11634,
          746,
          337,
          291,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.15526770066845325,
        "compression_ratio": 1.6666666666666667,
        "end": 2667.36,
        "id": 820,
        "no_speech_prob": 0.0002694762370083481,
        "seek": 265436,
        "start": 2665.36,
        "temperature": 0,
        "text": " It's already unlocked for you, but I'm going to show it to you.",
        "tokens": [
          50914,
          467,
          311,
          1217,
          30180,
          337,
          291,
          11,
          457,
          286,
          478,
          516,
          281,
          855,
          309,
          281,
          291,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.15526770066845325,
        "compression_ratio": 1.6666666666666667,
        "end": 2670.36,
        "id": 821,
        "no_speech_prob": 0.0002694762370083481,
        "seek": 265436,
        "start": 2667.36,
        "temperature": 0,
        "text": " That is incredibly powerful for what you can do now with ML5",
        "tokens": [
          51014,
          663,
          307,
          6252,
          4005,
          337,
          437,
          291,
          393,
          360,
          586,
          365,
          21601,
          20,
          51164
        ]
      },
      {
        "avg_logprob": -0.15526770066845325,
        "compression_ratio": 1.6666666666666667,
        "end": 2673.36,
        "id": 822,
        "no_speech_prob": 0.0002694762370083481,
        "seek": 265436,
        "start": 2670.36,
        "temperature": 0,
        "text": " that you couldn't do before, but many of you asked about in the comments.",
        "tokens": [
          51164,
          300,
          291,
          2809,
          380,
          360,
          949,
          11,
          457,
          867,
          295,
          291,
          2351,
          466,
          294,
          264,
          3053,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.15526770066845325,
        "compression_ratio": 1.6666666666666667,
        "end": 2674.36,
        "id": 823,
        "no_speech_prob": 0.0002694762370083481,
        "seek": 265436,
        "start": 2673.36,
        "temperature": 0,
        "text": " And what is that?",
        "tokens": [
          51314,
          400,
          437,
          307,
          300,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.15526770066845325,
        "compression_ratio": 1.6666666666666667,
        "end": 2677.36,
        "id": 824,
        "no_speech_prob": 0.0002694762370083481,
        "seek": 265436,
        "start": 2674.36,
        "temperature": 0,
        "text": " It is the save load feature extractor.",
        "tokens": [
          51364,
          467,
          307,
          264,
          3155,
          3677,
          4111,
          8947,
          284,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.15526770066845325,
        "compression_ratio": 1.6666666666666667,
        "end": 2682.36,
        "id": 825,
        "no_speech_prob": 0.0002694762370083481,
        "seek": 265436,
        "start": 2677.36,
        "temperature": 0,
        "text": " This is a new feature that was added to ML5 just five days ago.",
        "tokens": [
          51514,
          639,
          307,
          257,
          777,
          4111,
          300,
          390,
          3869,
          281,
          21601,
          20,
          445,
          1732,
          1708,
          2057,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.15899481538866386,
        "compression_ratio": 1.6290909090909091,
        "end": 2687.36,
        "id": 826,
        "no_speech_prob": 0.0004655234806705266,
        "seek": 268236,
        "start": 2682.36,
        "temperature": 0,
        "text": " You need to make sure that you are using ML5 0.1.3",
        "tokens": [
          50364,
          509,
          643,
          281,
          652,
          988,
          300,
          291,
          366,
          1228,
          21601,
          20,
          1958,
          13,
          16,
          13,
          18,
          50614
        ]
      },
      {
        "avg_logprob": -0.15899481538866386,
        "compression_ratio": 1.6290909090909091,
        "end": 2691.36,
        "id": 827,
        "no_speech_prob": 0.0004655234806705266,
        "seek": 268236,
        "start": 2687.36,
        "temperature": 0,
        "text": " or whatever number in the future past that.",
        "tokens": [
          50614,
          420,
          2035,
          1230,
          294,
          264,
          2027,
          1791,
          300,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.15899481538866386,
        "compression_ratio": 1.6290909090909091,
        "end": 2694.36,
        "id": 828,
        "no_speech_prob": 0.0004655234806705266,
        "seek": 268236,
        "start": 2691.36,
        "temperature": 0,
        "text": " But certainly, this is the version of the library that I'm using in this video.",
        "tokens": [
          50814,
          583,
          3297,
          11,
          341,
          307,
          264,
          3037,
          295,
          264,
          6405,
          300,
          286,
          478,
          1228,
          294,
          341,
          960,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.15899481538866386,
        "compression_ratio": 1.6290909090909091,
        "end": 2696.36,
        "id": 829,
        "no_speech_prob": 0.0004655234806705266,
        "seek": 268236,
        "start": 2694.36,
        "temperature": 0,
        "text": " Now, what does it do?",
        "tokens": [
          50964,
          823,
          11,
          437,
          775,
          309,
          360,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.15899481538866386,
        "compression_ratio": 1.6290909090909091,
        "end": 2700.36,
        "id": 830,
        "no_speech_prob": 0.0004655234806705266,
        "seek": 268236,
        "start": 2696.36,
        "temperature": 0,
        "text": " So, the last example, if you've been watching these video series in order,",
        "tokens": [
          51064,
          407,
          11,
          264,
          1036,
          1365,
          11,
          498,
          291,
          600,
          668,
          1976,
          613,
          960,
          2638,
          294,
          1668,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.15899481538866386,
        "compression_ratio": 1.6290909090909091,
        "end": 2702.36,
        "id": 831,
        "no_speech_prob": 0.0004655234806705266,
        "seek": 268236,
        "start": 2700.36,
        "temperature": 0,
        "text": " was this example.",
        "tokens": [
          51264,
          390,
          341,
          1365,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.15899481538866386,
        "compression_ratio": 1.6290909090909091,
        "end": 2706.36,
        "id": 832,
        "no_speech_prob": 0.0004655234806705266,
        "seek": 268236,
        "start": 2702.36,
        "temperature": 0,
        "text": " What this example does is it loads a pre-trained image classification model",
        "tokens": [
          51364,
          708,
          341,
          1365,
          775,
          307,
          309,
          12668,
          257,
          659,
          12,
          17227,
          2001,
          3256,
          21538,
          2316,
          51564
        ]
      },
      {
        "avg_logprob": -0.15899481538866386,
        "compression_ratio": 1.6290909090909091,
        "end": 2708.36,
        "id": 833,
        "no_speech_prob": 0.0004655234806705266,
        "seek": 268236,
        "start": 2706.36,
        "temperature": 0,
        "text": " called MobileNet.",
        "tokens": [
          51564,
          1219,
          22625,
          31890,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.15899481538866386,
        "compression_ratio": 1.6290909090909091,
        "end": 2710.36,
        "id": 834,
        "no_speech_prob": 0.0004655234806705266,
        "seek": 268236,
        "start": 2708.36,
        "temperature": 0,
        "text": " And MobileNet is trained on a thousand different kinds of things",
        "tokens": [
          51664,
          400,
          22625,
          31890,
          307,
          8895,
          322,
          257,
          4714,
          819,
          3685,
          295,
          721,
          51764
        ]
      },
      {
        "avg_logprob": -0.17093084426153274,
        "compression_ratio": 1.6515151515151516,
        "end": 2714.36,
        "id": 835,
        "no_speech_prob": 0.004468285478651524,
        "seek": 271036,
        "start": 2710.36,
        "temperature": 0,
        "text": " and recognizes puppies and dogs and birds and different kinds of objects.",
        "tokens": [
          50364,
          293,
          26564,
          33734,
          293,
          7197,
          293,
          9009,
          293,
          819,
          3685,
          295,
          6565,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.17093084426153274,
        "compression_ratio": 1.6515151515151516,
        "end": 2719.36,
        "id": 836,
        "no_speech_prob": 0.004468285478651524,
        "seek": 271036,
        "start": 2714.36,
        "temperature": 0,
        "text": " Transfer learning is the process by which we take that pre-trained MobileNet model",
        "tokens": [
          50564,
          35025,
          2539,
          307,
          264,
          1399,
          538,
          597,
          321,
          747,
          300,
          659,
          12,
          17227,
          2001,
          22625,
          31890,
          2316,
          50814
        ]
      },
      {
        "avg_logprob": -0.17093084426153274,
        "compression_ratio": 1.6515151515151516,
        "end": 2724.36,
        "id": 837,
        "no_speech_prob": 0.004468285478651524,
        "seek": 271036,
        "start": 2719.36,
        "temperature": 0,
        "text": " and basically disconnect it from all those labels and reconnect it to our own labels.",
        "tokens": [
          50814,
          293,
          1936,
          14299,
          309,
          490,
          439,
          729,
          16949,
          293,
          30095,
          309,
          281,
          527,
          1065,
          16949,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17093084426153274,
        "compression_ratio": 1.6515151515151516,
        "end": 2727.36,
        "id": 838,
        "no_speech_prob": 0.004468285478651524,
        "seek": 271036,
        "start": 2724.36,
        "temperature": 0,
        "text": " For example, I'm going to make up a label called happy and a label called sad.",
        "tokens": [
          51064,
          1171,
          1365,
          11,
          286,
          478,
          516,
          281,
          652,
          493,
          257,
          7645,
          1219,
          2055,
          293,
          257,
          7645,
          1219,
          4227,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17093084426153274,
        "compression_ratio": 1.6515151515151516,
        "end": 2729.36,
        "id": 839,
        "no_speech_prob": 0.004468285478651524,
        "seek": 271036,
        "start": 2727.36,
        "temperature": 0,
        "text": " I can certainly have more than just two.",
        "tokens": [
          51214,
          286,
          393,
          3297,
          362,
          544,
          813,
          445,
          732,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17093084426153274,
        "compression_ratio": 1.6515151515151516,
        "end": 2734.36,
        "id": 840,
        "no_speech_prob": 0.004468285478651524,
        "seek": 271036,
        "start": 2729.36,
        "temperature": 0,
        "text": " And I'm going to show it things like the train whistle is me being happy.",
        "tokens": [
          51314,
          400,
          286,
          478,
          516,
          281,
          855,
          309,
          721,
          411,
          264,
          3847,
          23470,
          307,
          385,
          885,
          2055,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.266486250121018,
        "compression_ratio": 1.7951219512195122,
        "end": 2742.36,
        "id": 841,
        "no_speech_prob": 0.03020716831088066,
        "seek": 273436,
        "start": 2734.36,
        "temperature": 0,
        "text": " I'm going to show it that train whistle a bunch of times.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          855,
          309,
          300,
          3847,
          23470,
          257,
          3840,
          295,
          1413,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.266486250121018,
        "compression_ratio": 1.7951219512195122,
        "end": 2744.36,
        "id": 842,
        "no_speech_prob": 0.03020716831088066,
        "seek": 273436,
        "start": 2742.36,
        "temperature": 0,
        "text": " Say happy, happy, happy, happy, happy.",
        "tokens": [
          50764,
          6463,
          2055,
          11,
          2055,
          11,
          2055,
          11,
          2055,
          11,
          2055,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.266486250121018,
        "compression_ratio": 1.7951219512195122,
        "end": 2747.36,
        "id": 843,
        "no_speech_prob": 0.03020716831088066,
        "seek": 273436,
        "start": 2744.36,
        "temperature": 0,
        "text": " Now, no train whistle is very sad.",
        "tokens": [
          50864,
          823,
          11,
          572,
          3847,
          23470,
          307,
          588,
          4227,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.266486250121018,
        "compression_ratio": 1.7951219512195122,
        "end": 2749.36,
        "id": 844,
        "no_speech_prob": 0.03020716831088066,
        "seek": 273436,
        "start": 2747.36,
        "temperature": 0,
        "text": " I'm sad. No train whistle is sad.",
        "tokens": [
          51014,
          286,
          478,
          4227,
          13,
          883,
          3847,
          23470,
          307,
          4227,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.266486250121018,
        "compression_ratio": 1.7951219512195122,
        "end": 2753.36,
        "id": 845,
        "no_speech_prob": 0.03020716831088066,
        "seek": 273436,
        "start": 2749.36,
        "temperature": 0,
        "text": " Oh, I'm spending way too much time on this because I haven't implemented the thing that I want to implement.",
        "tokens": [
          51114,
          876,
          11,
          286,
          478,
          6434,
          636,
          886,
          709,
          565,
          322,
          341,
          570,
          286,
          2378,
          380,
          12270,
          264,
          551,
          300,
          286,
          528,
          281,
          4445,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.266486250121018,
        "compression_ratio": 1.7951219512195122,
        "end": 2755.36,
        "id": 846,
        "no_speech_prob": 0.03020716831088066,
        "seek": 273436,
        "start": 2753.36,
        "temperature": 0,
        "text": " Now, I'm going to say train and it's going to train.",
        "tokens": [
          51314,
          823,
          11,
          286,
          478,
          516,
          281,
          584,
          3847,
          293,
          309,
          311,
          516,
          281,
          3847,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.266486250121018,
        "compression_ratio": 1.7951219512195122,
        "end": 2758.36,
        "id": 847,
        "no_speech_prob": 0.03020716831088066,
        "seek": 273436,
        "start": 2755.36,
        "temperature": 0,
        "text": " And then once it's done, ah!",
        "tokens": [
          51414,
          400,
          550,
          1564,
          309,
          311,
          1096,
          11,
          3716,
          0,
          51564
        ]
      },
      {
        "avg_logprob": -0.266486250121018,
        "compression_ratio": 1.7951219512195122,
        "end": 2760.36,
        "id": 848,
        "no_speech_prob": 0.03020716831088066,
        "seek": 273436,
        "start": 2758.36,
        "temperature": 0,
        "text": " Happy.",
        "tokens": [
          51564,
          8277,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.266486250121018,
        "compression_ratio": 1.7951219512195122,
        "end": 2762.36,
        "id": 849,
        "no_speech_prob": 0.03020716831088066,
        "seek": 273436,
        "start": 2760.36,
        "temperature": 0,
        "text": " Sad.",
        "tokens": [
          51664,
          12269,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.21699470520019531,
        "compression_ratio": 1.5246636771300448,
        "end": 2764.36,
        "id": 850,
        "no_speech_prob": 0.012820951640605927,
        "seek": 276236,
        "start": 2762.36,
        "temperature": 0,
        "text": " Happy.",
        "tokens": [
          50364,
          8277,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.21699470520019531,
        "compression_ratio": 1.5246636771300448,
        "end": 2766.36,
        "id": 851,
        "no_speech_prob": 0.012820951640605927,
        "seek": 276236,
        "start": 2764.36,
        "temperature": 0,
        "text": " Sad.",
        "tokens": [
          50464,
          12269,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.21699470520019531,
        "compression_ratio": 1.5246636771300448,
        "end": 2767.36,
        "id": 852,
        "no_speech_prob": 0.012820951640605927,
        "seek": 276236,
        "start": 2766.36,
        "temperature": 0,
        "text": " Okay, so it works.",
        "tokens": [
          50564,
          1033,
          11,
          370,
          309,
          1985,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.21699470520019531,
        "compression_ratio": 1.5246636771300448,
        "end": 2771.36,
        "id": 853,
        "no_speech_prob": 0.012820951640605927,
        "seek": 276236,
        "start": 2767.36,
        "temperature": 0,
        "text": " It is now learning to classify images in real time according to those two categories.",
        "tokens": [
          50614,
          467,
          307,
          586,
          2539,
          281,
          33872,
          5267,
          294,
          957,
          565,
          4650,
          281,
          729,
          732,
          10479,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21699470520019531,
        "compression_ratio": 1.5246636771300448,
        "end": 2776.36,
        "id": 854,
        "no_speech_prob": 0.012820951640605927,
        "seek": 276236,
        "start": 2771.36,
        "temperature": 0,
        "text": " But I'm a big spaz and I'm going to just be over here doing refresh.",
        "tokens": [
          50814,
          583,
          286,
          478,
          257,
          955,
          637,
          921,
          293,
          286,
          478,
          516,
          281,
          445,
          312,
          670,
          510,
          884,
          15134,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.21699470520019531,
        "compression_ratio": 1.5246636771300448,
        "end": 2778.36,
        "id": 855,
        "no_speech_prob": 0.012820951640605927,
        "seek": 276236,
        "start": 2776.36,
        "temperature": 0,
        "text": " And I have now lost that forever.",
        "tokens": [
          51064,
          400,
          286,
          362,
          586,
          2731,
          300,
          5680,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.21699470520019531,
        "compression_ratio": 1.5246636771300448,
        "end": 2780.36,
        "id": 856,
        "no_speech_prob": 0.012820951640605927,
        "seek": 276236,
        "start": 2778.36,
        "temperature": 0,
        "text": " I no longer have that model.",
        "tokens": [
          51164,
          286,
          572,
          2854,
          362,
          300,
          2316,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.21699470520019531,
        "compression_ratio": 1.5246636771300448,
        "end": 2781.36,
        "id": 857,
        "no_speech_prob": 0.012820951640605927,
        "seek": 276236,
        "start": 2780.36,
        "temperature": 0,
        "text": " It's gone.",
        "tokens": [
          51264,
          467,
          311,
          2780,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.21699470520019531,
        "compression_ratio": 1.5246636771300448,
        "end": 2787.36,
        "id": 858,
        "no_speech_prob": 0.012820951640605927,
        "seek": 276236,
        "start": 2781.36,
        "temperature": 0,
        "text": " The new feature is ability to save that custom trained model and then reload it.",
        "tokens": [
          51314,
          440,
          777,
          4111,
          307,
          3485,
          281,
          3155,
          300,
          2375,
          8895,
          2316,
          293,
          550,
          25628,
          309,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18427074787228606,
        "compression_ratio": 1.9559322033898305,
        "end": 2793.36,
        "id": 859,
        "no_speech_prob": 0.22267775237560272,
        "seek": 278736,
        "start": 2787.36,
        "temperature": 0,
        "text": " So if you're using this for an installation and you're going to take down the computer and set it up every day,",
        "tokens": [
          50364,
          407,
          498,
          291,
          434,
          1228,
          341,
          337,
          364,
          13260,
          293,
          291,
          434,
          516,
          281,
          747,
          760,
          264,
          3820,
          293,
          992,
          309,
          493,
          633,
          786,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.18427074787228606,
        "compression_ratio": 1.9559322033898305,
        "end": 2794.36,
        "id": 860,
        "no_speech_prob": 0.22267775237560272,
        "seek": 278736,
        "start": 2793.36,
        "temperature": 0,
        "text": " you can save that model.",
        "tokens": [
          50664,
          291,
          393,
          3155,
          300,
          2316,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18427074787228606,
        "compression_ratio": 1.9559322033898305,
        "end": 2795.36,
        "id": 861,
        "no_speech_prob": 0.22267775237560272,
        "seek": 278736,
        "start": 2794.36,
        "temperature": 0,
        "text": " You can imagine.",
        "tokens": [
          50714,
          509,
          393,
          3811,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.18427074787228606,
        "compression_ratio": 1.9559322033898305,
        "end": 2796.36,
        "id": 862,
        "no_speech_prob": 0.22267775237560272,
        "seek": 278736,
        "start": 2795.36,
        "temperature": 0,
        "text": " There's lots of possibilities here.",
        "tokens": [
          50764,
          821,
          311,
          3195,
          295,
          12178,
          510,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.18427074787228606,
        "compression_ratio": 1.9559322033898305,
        "end": 2799.36,
        "id": 863,
        "no_speech_prob": 0.22267775237560272,
        "seek": 278736,
        "start": 2796.36,
        "temperature": 0,
        "text": " So there's only two things that I really need to add to the code.",
        "tokens": [
          50814,
          407,
          456,
          311,
          787,
          732,
          721,
          300,
          286,
          534,
          643,
          281,
          909,
          281,
          264,
          3089,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18427074787228606,
        "compression_ratio": 1.9559322033898305,
        "end": 2801.36,
        "id": 864,
        "no_speech_prob": 0.22267775237560272,
        "seek": 278736,
        "start": 2799.36,
        "temperature": 0,
        "text": " There's a save function and a load function.",
        "tokens": [
          50964,
          821,
          311,
          257,
          3155,
          2445,
          293,
          257,
          3677,
          2445,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.18427074787228606,
        "compression_ratio": 1.9559322033898305,
        "end": 2803.36,
        "id": 865,
        "no_speech_prob": 0.22267775237560272,
        "seek": 278736,
        "start": 2801.36,
        "temperature": 0,
        "text": " There's a bunch of pieces there, but that's what I'm going to do right now.",
        "tokens": [
          51064,
          821,
          311,
          257,
          3840,
          295,
          3755,
          456,
          11,
          457,
          300,
          311,
          437,
          286,
          478,
          516,
          281,
          360,
          558,
          586,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.18427074787228606,
        "compression_ratio": 1.9559322033898305,
        "end": 2808.36,
        "id": 866,
        "no_speech_prob": 0.22267775237560272,
        "seek": 278736,
        "start": 2803.36,
        "temperature": 0,
        "text": " So I'm going to go here into the code and I'm going to just add another button.",
        "tokens": [
          51164,
          407,
          286,
          478,
          516,
          281,
          352,
          510,
          666,
          264,
          3089,
          293,
          286,
          478,
          516,
          281,
          445,
          909,
          1071,
          2960,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18427074787228606,
        "compression_ratio": 1.9559322033898305,
        "end": 2811.36,
        "id": 867,
        "no_speech_prob": 0.22267775237560272,
        "seek": 278736,
        "start": 2808.36,
        "temperature": 0,
        "text": " Like I have a happy button, a sad button, and a train button.",
        "tokens": [
          51414,
          1743,
          286,
          362,
          257,
          2055,
          2960,
          11,
          257,
          4227,
          2960,
          11,
          293,
          257,
          3847,
          2960,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18427074787228606,
        "compression_ratio": 1.9559322033898305,
        "end": 2813.36,
        "id": 868,
        "no_speech_prob": 0.22267775237560272,
        "seek": 278736,
        "start": 2811.36,
        "temperature": 0,
        "text": " Choo-choo.",
        "tokens": [
          51564,
          761,
          1986,
          12,
          339,
          1986,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18427074787228606,
        "compression_ratio": 1.9559322033898305,
        "end": 2815.36,
        "id": 869,
        "no_speech_prob": 0.22267775237560272,
        "seek": 278736,
        "start": 2813.36,
        "temperature": 0,
        "text": " I'm going to add a sad button.",
        "tokens": [
          51664,
          286,
          478,
          516,
          281,
          909,
          257,
          4227,
          2960,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18427074787228606,
        "compression_ratio": 1.9559322033898305,
        "end": 2816.36,
        "id": 870,
        "no_speech_prob": 0.22267775237560272,
        "seek": 278736,
        "start": 2815.36,
        "temperature": 0,
        "text": " No, no, not sad.",
        "tokens": [
          51764,
          883,
          11,
          572,
          11,
          406,
          4227,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2058208957795174,
        "compression_ratio": 1.9057377049180328,
        "end": 2818.36,
        "id": 871,
        "no_speech_prob": 0.0028448929078876972,
        "seek": 281636,
        "start": 2816.36,
        "temperature": 0,
        "text": " Save button.",
        "tokens": [
          50364,
          15541,
          2960,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2058208957795174,
        "compression_ratio": 1.9057377049180328,
        "end": 2820.36,
        "id": 872,
        "no_speech_prob": 0.0028448929078876972,
        "seek": 281636,
        "start": 2818.36,
        "temperature": 0,
        "text": " I'm going to call it save.",
        "tokens": [
          50464,
          286,
          478,
          516,
          281,
          818,
          309,
          3155,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2058208957795174,
        "compression_ratio": 1.9057377049180328,
        "end": 2824.36,
        "id": 873,
        "no_speech_prob": 0.0028448929078876972,
        "seek": 281636,
        "start": 2820.36,
        "temperature": 0,
        "text": " And save button, when the mouse is pressed, I'm just going to say classifier.save.",
        "tokens": [
          50564,
          400,
          3155,
          2960,
          11,
          562,
          264,
          9719,
          307,
          17355,
          11,
          286,
          478,
          445,
          516,
          281,
          584,
          1508,
          9902,
          13,
          82,
          946,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2058208957795174,
        "compression_ratio": 1.9057377049180328,
        "end": 2825.36,
        "id": 874,
        "no_speech_prob": 0.0028448929078876972,
        "seek": 281636,
        "start": 2824.36,
        "temperature": 0,
        "text": " That's it.",
        "tokens": [
          50764,
          663,
          311,
          309,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2058208957795174,
        "compression_ratio": 1.9057377049180328,
        "end": 2827.36,
        "id": 875,
        "no_speech_prob": 0.0028448929078876972,
        "seek": 281636,
        "start": 2825.36,
        "temperature": 0,
        "text": " All I have to do is say classifier.save.",
        "tokens": [
          50814,
          1057,
          286,
          362,
          281,
          360,
          307,
          584,
          1508,
          9902,
          13,
          82,
          946,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2058208957795174,
        "compression_ratio": 1.9057377049180328,
        "end": 2830.36,
        "id": 876,
        "no_speech_prob": 0.0028448929078876972,
        "seek": 281636,
        "start": 2827.36,
        "temperature": 0,
        "text": " Let's see what happens.",
        "tokens": [
          50914,
          961,
          311,
          536,
          437,
          2314,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2058208957795174,
        "compression_ratio": 1.9057377049180328,
        "end": 2833.36,
        "id": 877,
        "no_speech_prob": 0.0028448929078876972,
        "seek": 281636,
        "start": 2830.36,
        "temperature": 0,
        "text": " So I'm not going to train it very...",
        "tokens": [
          51064,
          407,
          286,
          478,
          406,
          516,
          281,
          3847,
          309,
          588,
          485,
          51214
        ]
      },
      {
        "avg_logprob": -0.2058208957795174,
        "compression_ratio": 1.9057377049180328,
        "end": 2835.36,
        "id": 878,
        "no_speech_prob": 0.0028448929078876972,
        "seek": 281636,
        "start": 2833.36,
        "temperature": 0,
        "text": " Actually, no, I am going to train.",
        "tokens": [
          51214,
          5135,
          11,
          572,
          11,
          286,
          669,
          516,
          281,
          3847,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2058208957795174,
        "compression_ratio": 1.9057377049180328,
        "end": 2838.36,
        "id": 879,
        "no_speech_prob": 0.0028448929078876972,
        "seek": 281636,
        "start": 2835.36,
        "temperature": 0,
        "text": " I'm going to let's do a really good, solid training this time because this is the one we're going to save.",
        "tokens": [
          51314,
          286,
          478,
          516,
          281,
          718,
          311,
          360,
          257,
          534,
          665,
          11,
          5100,
          3097,
          341,
          565,
          570,
          341,
          307,
          264,
          472,
          321,
          434,
          516,
          281,
          3155,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2058208957795174,
        "compression_ratio": 1.9057377049180328,
        "end": 2839.36,
        "id": 880,
        "no_speech_prob": 0.0028448929078876972,
        "seek": 281636,
        "start": 2838.36,
        "temperature": 0,
        "text": " As long as it works.",
        "tokens": [
          51464,
          1018,
          938,
          382,
          309,
          1985,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2058208957795174,
        "compression_ratio": 1.9057377049180328,
        "end": 2840.36,
        "id": 881,
        "no_speech_prob": 0.0028448929078876972,
        "seek": 281636,
        "start": 2839.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51514,
          1057,
          558,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2058208957795174,
        "compression_ratio": 1.9057377049180328,
        "end": 2841.36,
        "id": 882,
        "no_speech_prob": 0.0028448929078876972,
        "seek": 281636,
        "start": 2840.36,
        "temperature": 0,
        "text": " So let's do the same thing.",
        "tokens": [
          51564,
          407,
          718,
          311,
          360,
          264,
          912,
          551,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2058208957795174,
        "compression_ratio": 1.9057377049180328,
        "end": 2843.36,
        "id": 883,
        "no_speech_prob": 0.0028448929078876972,
        "seek": 281636,
        "start": 2841.36,
        "temperature": 0,
        "text": " Happy, happy, happy, happy.",
        "tokens": [
          51614,
          8277,
          11,
          2055,
          11,
          2055,
          11,
          2055,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.16709189347817865,
        "compression_ratio": 1.800865800865801,
        "end": 2846.36,
        "id": 884,
        "no_speech_prob": 0.007815605029463768,
        "seek": 284336,
        "start": 2844.36,
        "temperature": 0,
        "text": " Train whistle is a happy thing.",
        "tokens": [
          50414,
          28029,
          23470,
          307,
          257,
          2055,
          551,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.16709189347817865,
        "compression_ratio": 1.800865800865801,
        "end": 2848.36,
        "id": 885,
        "no_speech_prob": 0.007815605029463768,
        "seek": 284336,
        "start": 2846.36,
        "temperature": 0,
        "text": " A happy, happy, happy thing.",
        "tokens": [
          50514,
          316,
          2055,
          11,
          2055,
          11,
          2055,
          551,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.16709189347817865,
        "compression_ratio": 1.800865800865801,
        "end": 2850.36,
        "id": 886,
        "no_speech_prob": 0.007815605029463768,
        "seek": 284336,
        "start": 2848.36,
        "temperature": 0,
        "text": " Just me is very sad.",
        "tokens": [
          50614,
          1449,
          385,
          307,
          588,
          4227,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.16709189347817865,
        "compression_ratio": 1.800865800865801,
        "end": 2851.36,
        "id": 887,
        "no_speech_prob": 0.007815605029463768,
        "seek": 284336,
        "start": 2850.36,
        "temperature": 0,
        "text": " There's no train whistle.",
        "tokens": [
          50714,
          821,
          311,
          572,
          3847,
          23470,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.16709189347817865,
        "compression_ratio": 1.800865800865801,
        "end": 2852.36,
        "id": 888,
        "no_speech_prob": 0.007815605029463768,
        "seek": 284336,
        "start": 2851.36,
        "temperature": 0,
        "text": " I'm so sad.",
        "tokens": [
          50764,
          286,
          478,
          370,
          4227,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.16709189347817865,
        "compression_ratio": 1.800865800865801,
        "end": 2853.36,
        "id": 889,
        "no_speech_prob": 0.007815605029463768,
        "seek": 284336,
        "start": 2852.36,
        "temperature": 0,
        "text": " I'm very sad.",
        "tokens": [
          50814,
          286,
          478,
          588,
          4227,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.16709189347817865,
        "compression_ratio": 1.800865800865801,
        "end": 2854.36,
        "id": 890,
        "no_speech_prob": 0.007815605029463768,
        "seek": 284336,
        "start": 2853.36,
        "temperature": 0,
        "text": " I'm very sad.",
        "tokens": [
          50864,
          286,
          478,
          588,
          4227,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.16709189347817865,
        "compression_ratio": 1.800865800865801,
        "end": 2856.36,
        "id": 891,
        "no_speech_prob": 0.007815605029463768,
        "seek": 284336,
        "start": 2854.36,
        "temperature": 0,
        "text": " And now I'm going to train this.",
        "tokens": [
          50914,
          400,
          586,
          286,
          478,
          516,
          281,
          3847,
          341,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.16709189347817865,
        "compression_ratio": 1.800865800865801,
        "end": 2858.36,
        "id": 892,
        "no_speech_prob": 0.007815605029463768,
        "seek": 284336,
        "start": 2856.36,
        "temperature": 0,
        "text": " Weird how the loss is zero.",
        "tokens": [
          51014,
          32033,
          577,
          264,
          4470,
          307,
          4018,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.16709189347817865,
        "compression_ratio": 1.800865800865801,
        "end": 2860.36,
        "id": 893,
        "no_speech_prob": 0.007815605029463768,
        "seek": 284336,
        "start": 2858.36,
        "temperature": 0,
        "text": " I'm just going to not worry about that too much.",
        "tokens": [
          51114,
          286,
          478,
          445,
          516,
          281,
          406,
          3292,
          466,
          300,
          886,
          709,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.16709189347817865,
        "compression_ratio": 1.800865800865801,
        "end": 2863.36,
        "id": 894,
        "no_speech_prob": 0.007815605029463768,
        "seek": 284336,
        "start": 2860.36,
        "temperature": 0,
        "text": " I'm going to hit save.",
        "tokens": [
          51214,
          286,
          478,
          516,
          281,
          2045,
          3155,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.16709189347817865,
        "compression_ratio": 1.800865800865801,
        "end": 2867.36,
        "id": 895,
        "no_speech_prob": 0.007815605029463768,
        "seek": 284336,
        "start": 2863.36,
        "temperature": 0,
        "text": " And now, you can see that down here, by the way, that I did this a couple times practicing.",
        "tokens": [
          51364,
          400,
          586,
          11,
          291,
          393,
          536,
          300,
          760,
          510,
          11,
          538,
          264,
          636,
          11,
          300,
          286,
          630,
          341,
          257,
          1916,
          1413,
          11350,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.16709189347817865,
        "compression_ratio": 1.800865800865801,
        "end": 2870.36,
        "id": 896,
        "no_speech_prob": 0.007815605029463768,
        "seek": 284336,
        "start": 2867.36,
        "temperature": 0,
        "text": " Now, what it did is it downloaded.",
        "tokens": [
          51564,
          823,
          11,
          437,
          309,
          630,
          307,
          309,
          21748,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.16709189347817865,
        "compression_ratio": 1.800865800865801,
        "end": 2871.36,
        "id": 897,
        "no_speech_prob": 0.007815605029463768,
        "seek": 284336,
        "start": 2870.36,
        "temperature": 0,
        "text": " Come on.",
        "tokens": [
          51714,
          2492,
          322,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2083344911274157,
        "compression_ratio": 1.6787564766839378,
        "end": 2874.36,
        "id": 898,
        "no_speech_prob": 0.0058198473416268826,
        "seek": 287136,
        "start": 2871.36,
        "temperature": 0,
        "text": " To my download directory, two files.",
        "tokens": [
          50364,
          1407,
          452,
          5484,
          21120,
          11,
          732,
          7098,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2083344911274157,
        "compression_ratio": 1.6787564766839378,
        "end": 2878.36,
        "id": 899,
        "no_speech_prob": 0.0058198473416268826,
        "seek": 287136,
        "start": 2874.36,
        "temperature": 0,
        "text": " Model.json and model.weights.bin.",
        "tokens": [
          50514,
          17105,
          13,
          73,
          3015,
          293,
          2316,
          13,
          826,
          5761,
          13,
          13496,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2083344911274157,
        "compression_ratio": 1.6787564766839378,
        "end": 2883.36,
        "id": 900,
        "no_speech_prob": 0.0058198473416268826,
        "seek": 287136,
        "start": 2878.36,
        "temperature": 0,
        "text": " So those files will end up wherever the default downloads directory of your browser is.",
        "tokens": [
          50714,
          407,
          729,
          7098,
          486,
          917,
          493,
          8660,
          264,
          7576,
          36553,
          21120,
          295,
          428,
          11185,
          307,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2083344911274157,
        "compression_ratio": 1.6787564766839378,
        "end": 2886.36,
        "id": 901,
        "no_speech_prob": 0.0058198473416268826,
        "seek": 287136,
        "start": 2883.36,
        "temperature": 0,
        "text": " And the next step is just to load those files in.",
        "tokens": [
          50964,
          400,
          264,
          958,
          1823,
          307,
          445,
          281,
          3677,
          729,
          7098,
          294,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2083344911274157,
        "compression_ratio": 1.6787564766839378,
        "end": 2889.36,
        "id": 902,
        "no_speech_prob": 0.0058198473416268826,
        "seek": 287136,
        "start": 2886.36,
        "temperature": 0,
        "text": " But before we load them, let's talk about what's in those files.",
        "tokens": [
          51114,
          583,
          949,
          321,
          3677,
          552,
          11,
          718,
          311,
          751,
          466,
          437,
          311,
          294,
          729,
          7098,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2083344911274157,
        "compression_ratio": 1.6787564766839378,
        "end": 2890.36,
        "id": 903,
        "no_speech_prob": 0.0058198473416268826,
        "seek": 287136,
        "start": 2889.36,
        "temperature": 0,
        "text": " So there's two files.",
        "tokens": [
          51264,
          407,
          456,
          311,
          732,
          7098,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2083344911274157,
        "compression_ratio": 1.6787564766839378,
        "end": 2896.36,
        "id": 904,
        "no_speech_prob": 0.0058198473416268826,
        "seek": 287136,
        "start": 2890.36,
        "temperature": 0,
        "text": " I said model.json and model.",
        "tokens": [
          51314,
          286,
          848,
          2316,
          13,
          73,
          3015,
          293,
          2316,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.16598408642937154,
        "compression_ratio": 1.5628415300546448,
        "end": 2906.36,
        "id": 905,
        "no_speech_prob": 0.00011959845141973346,
        "seek": 289636,
        "start": 2896.36,
        "temperature": 0,
        "text": " Model.weights.bin.",
        "tokens": [
          50364,
          17105,
          13,
          826,
          5761,
          13,
          13496,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.16598408642937154,
        "compression_ratio": 1.5628415300546448,
        "end": 2908.36,
        "id": 906,
        "no_speech_prob": 0.00011959845141973346,
        "seek": 289636,
        "start": 2906.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50864,
          1033,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.16598408642937154,
        "compression_ratio": 1.5628415300546448,
        "end": 2911.36,
        "id": 907,
        "no_speech_prob": 0.00011959845141973346,
        "seek": 289636,
        "start": 2908.36,
        "temperature": 0,
        "text": " So what is a neural network?",
        "tokens": [
          50964,
          407,
          437,
          307,
          257,
          18161,
          3209,
          30,
          51114
        ]
      },
      {
        "avg_logprob": -0.16598408642937154,
        "compression_ratio": 1.5628415300546448,
        "end": 2913.36,
        "id": 908,
        "no_speech_prob": 0.00011959845141973346,
        "seek": 289636,
        "start": 2911.36,
        "temperature": 0,
        "text": " What is a machine learning model?",
        "tokens": [
          51114,
          708,
          307,
          257,
          3479,
          2539,
          2316,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.16598408642937154,
        "compression_ratio": 1.5628415300546448,
        "end": 2914.36,
        "id": 909,
        "no_speech_prob": 0.00011959845141973346,
        "seek": 289636,
        "start": 2913.36,
        "temperature": 0,
        "text": " What is the thing that we're saving?",
        "tokens": [
          51214,
          708,
          307,
          264,
          551,
          300,
          321,
          434,
          6816,
          30,
          51264
        ]
      },
      {
        "avg_logprob": -0.16598408642937154,
        "compression_ratio": 1.5628415300546448,
        "end": 2918.36,
        "id": 910,
        "no_speech_prob": 0.00011959845141973346,
        "seek": 289636,
        "start": 2914.36,
        "temperature": 0,
        "text": " Well, in this case, it's actually saving the configuration of a neural network.",
        "tokens": [
          51264,
          1042,
          11,
          294,
          341,
          1389,
          11,
          309,
          311,
          767,
          6816,
          264,
          11694,
          295,
          257,
          18161,
          3209,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.16598408642937154,
        "compression_ratio": 1.5628415300546448,
        "end": 2922.36,
        "id": 911,
        "no_speech_prob": 0.00011959845141973346,
        "seek": 289636,
        "start": 2918.36,
        "temperature": 0,
        "text": " Now, if you want to know what a neural network is, I have some videos about that.",
        "tokens": [
          51464,
          823,
          11,
          498,
          291,
          528,
          281,
          458,
          437,
          257,
          18161,
          3209,
          307,
          11,
          286,
          362,
          512,
          2145,
          466,
          300,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17516641616821288,
        "compression_ratio": 1.6136363636363635,
        "end": 2927.36,
        "id": 912,
        "no_speech_prob": 0.14222349226474762,
        "seek": 292236,
        "start": 2922.36,
        "temperature": 0,
        "text": " But I would refer you to the 3Blue1Brown video, What is a Neural Network?",
        "tokens": [
          50364,
          583,
          286,
          576,
          2864,
          291,
          281,
          264,
          805,
          45231,
          16,
          22170,
          648,
          960,
          11,
          708,
          307,
          257,
          1734,
          1807,
          12640,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.17516641616821288,
        "compression_ratio": 1.6136363636363635,
        "end": 2929.36,
        "id": 913,
        "no_speech_prob": 0.14222349226474762,
        "seek": 292236,
        "start": 2927.36,
        "temperature": 0,
        "text": " I will link to that in this video's description.",
        "tokens": [
          50614,
          286,
          486,
          2113,
          281,
          300,
          294,
          341,
          960,
          311,
          3855,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.17516641616821288,
        "compression_ratio": 1.6136363636363635,
        "end": 2933.36,
        "id": 914,
        "no_speech_prob": 0.14222349226474762,
        "seek": 292236,
        "start": 2929.36,
        "temperature": 0,
        "text": " That will give you a much bigger deep dive into those details.",
        "tokens": [
          50714,
          663,
          486,
          976,
          291,
          257,
          709,
          3801,
          2452,
          9192,
          666,
          729,
          4365,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17516641616821288,
        "compression_ratio": 1.6136363636363635,
        "end": 2937.36,
        "id": 915,
        "no_speech_prob": 0.14222349226474762,
        "seek": 292236,
        "start": 2933.36,
        "temperature": 0,
        "text": " But if you look at that video, what you'll see is there's basically like a big diagram.",
        "tokens": [
          50914,
          583,
          498,
          291,
          574,
          412,
          300,
          960,
          11,
          437,
          291,
          603,
          536,
          307,
          456,
          311,
          1936,
          411,
          257,
          955,
          10686,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17516641616821288,
        "compression_ratio": 1.6136363636363635,
        "end": 2940.36,
        "id": 916,
        "no_speech_prob": 0.14222349226474762,
        "seek": 292236,
        "start": 2937.36,
        "temperature": 0,
        "text": " And the diagram has a bunch of inputs.",
        "tokens": [
          51114,
          400,
          264,
          10686,
          575,
          257,
          3840,
          295,
          15743,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.17516641616821288,
        "compression_ratio": 1.6136363636363635,
        "end": 2942.36,
        "id": 917,
        "no_speech_prob": 0.14222349226474762,
        "seek": 292236,
        "start": 2940.36,
        "temperature": 0,
        "text": " It has some outputs.",
        "tokens": [
          51264,
          467,
          575,
          512,
          23930,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.17516641616821288,
        "compression_ratio": 1.6136363636363635,
        "end": 2949.36,
        "id": 918,
        "no_speech_prob": 0.14222349226474762,
        "seek": 292236,
        "start": 2942.36,
        "temperature": 0,
        "text": " By the way, in this case, we could actually say the outputs are just two, a happy and a sad.",
        "tokens": [
          51364,
          3146,
          264,
          636,
          11,
          294,
          341,
          1389,
          11,
          321,
          727,
          767,
          584,
          264,
          23930,
          366,
          445,
          732,
          11,
          257,
          2055,
          293,
          257,
          4227,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18922996520996094,
        "compression_ratio": 1.7740585774058577,
        "end": 2953.36,
        "id": 919,
        "no_speech_prob": 0.01518874429166317,
        "seek": 294936,
        "start": 2949.36,
        "temperature": 0,
        "text": " And what the neural network, what the machine learning model outputs is a probability,",
        "tokens": [
          50364,
          400,
          437,
          264,
          18161,
          3209,
          11,
          437,
          264,
          3479,
          2539,
          2316,
          23930,
          307,
          257,
          8482,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.18922996520996094,
        "compression_ratio": 1.7740585774058577,
        "end": 2962.36,
        "id": 920,
        "no_speech_prob": 0.01518874429166317,
        "seek": 294936,
        "start": 2953.36,
        "temperature": 0,
        "text": " maybe like 80% of it being happy, of that image being happy, and 20% that image is sad.",
        "tokens": [
          50564,
          1310,
          411,
          4688,
          4,
          295,
          309,
          885,
          2055,
          11,
          295,
          300,
          3256,
          885,
          2055,
          11,
          293,
          945,
          4,
          300,
          3256,
          307,
          4227,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18922996520996094,
        "compression_ratio": 1.7740585774058577,
        "end": 2965.36,
        "id": 921,
        "no_speech_prob": 0.01518874429166317,
        "seek": 294936,
        "start": 2962.36,
        "temperature": 0,
        "text": " So the whole point of this is to feed in an image.",
        "tokens": [
          51014,
          407,
          264,
          1379,
          935,
          295,
          341,
          307,
          281,
          3154,
          294,
          364,
          3256,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.18922996520996094,
        "compression_ratio": 1.7740585774058577,
        "end": 2971.36,
        "id": 922,
        "no_speech_prob": 0.01518874429166317,
        "seek": 294936,
        "start": 2965.36,
        "temperature": 0,
        "text": " It's the image and maybe all the pixels of the image that are actually these inputs.",
        "tokens": [
          51164,
          467,
          311,
          264,
          3256,
          293,
          1310,
          439,
          264,
          18668,
          295,
          264,
          3256,
          300,
          366,
          767,
          613,
          15743,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18922996520996094,
        "compression_ratio": 1.7740585774058577,
        "end": 2974.36,
        "id": 923,
        "no_speech_prob": 0.01518874429166317,
        "seek": 294936,
        "start": 2971.36,
        "temperature": 0,
        "text": " It goes through this magic neural network thing, which isn't really magic.",
        "tokens": [
          51464,
          467,
          1709,
          807,
          341,
          5585,
          18161,
          3209,
          551,
          11,
          597,
          1943,
          380,
          534,
          5585,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18922996520996094,
        "compression_ratio": 1.7740585774058577,
        "end": 2976.36,
        "id": 924,
        "no_speech_prob": 0.01518874429166317,
        "seek": 294936,
        "start": 2974.36,
        "temperature": 0,
        "text": " It's a thing that you can learn about.",
        "tokens": [
          51614,
          467,
          311,
          257,
          551,
          300,
          291,
          393,
          1466,
          466,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20142867916920146,
        "compression_ratio": 1.7304964539007093,
        "end": 2980.36,
        "id": 925,
        "no_speech_prob": 0.0009110474493354559,
        "seek": 297636,
        "start": 2976.36,
        "temperature": 0,
        "text": " And then out the other end comes a guess as to whether it's happy or sad.",
        "tokens": [
          50364,
          400,
          550,
          484,
          264,
          661,
          917,
          1487,
          257,
          2041,
          382,
          281,
          1968,
          309,
          311,
          2055,
          420,
          4227,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.20142867916920146,
        "compression_ratio": 1.7304964539007093,
        "end": 2982.36,
        "id": 926,
        "no_speech_prob": 0.0009110474493354559,
        "seek": 297636,
        "start": 2980.36,
        "temperature": 0,
        "text": " Now what is all this stuff in the middle?",
        "tokens": [
          50564,
          823,
          437,
          307,
          439,
          341,
          1507,
          294,
          264,
          2808,
          30,
          50664
        ]
      },
      {
        "avg_logprob": -0.20142867916920146,
        "compression_ratio": 1.7304964539007093,
        "end": 2988.36,
        "id": 927,
        "no_speech_prob": 0.0009110474493354559,
        "seek": 297636,
        "start": 2982.36,
        "temperature": 0,
        "text": " The stuff in the middle is typically referred to, and there are many different styles and flavors and kinds of neural network,",
        "tokens": [
          50664,
          440,
          1507,
          294,
          264,
          2808,
          307,
          5850,
          10839,
          281,
          11,
          293,
          456,
          366,
          867,
          819,
          13273,
          293,
          16303,
          293,
          3685,
          295,
          18161,
          3209,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.20142867916920146,
        "compression_ratio": 1.7304964539007093,
        "end": 2994.36,
        "id": 928,
        "no_speech_prob": 0.0009110474493354559,
        "seek": 297636,
        "start": 2988.36,
        "temperature": 0,
        "text": " but in the sort of zoomed out view, in general terms, is what's known as a hidden layer or hidden layers.",
        "tokens": [
          50964,
          457,
          294,
          264,
          1333,
          295,
          8863,
          292,
          484,
          1910,
          11,
          294,
          2674,
          2115,
          11,
          307,
          437,
          311,
          2570,
          382,
          257,
          7633,
          4583,
          420,
          7633,
          7914,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20142867916920146,
        "compression_ratio": 1.7304964539007093,
        "end": 2999.36,
        "id": 929,
        "no_speech_prob": 0.0009110474493354559,
        "seek": 297636,
        "start": 2994.36,
        "temperature": 0,
        "text": " So every input is connected to the output, but not directly.",
        "tokens": [
          51264,
          407,
          633,
          4846,
          307,
          4582,
          281,
          264,
          5598,
          11,
          457,
          406,
          3838,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20142867916920146,
        "compression_ratio": 1.7304964539007093,
        "end": 3004.36,
        "id": 930,
        "no_speech_prob": 0.0009110474493354559,
        "seek": 297636,
        "start": 2999.36,
        "temperature": 0,
        "text": " There are some amount of nodes, maybe two hidden layers, each with four nodes.",
        "tokens": [
          51514,
          821,
          366,
          512,
          2372,
          295,
          13891,
          11,
          1310,
          732,
          7633,
          7914,
          11,
          1184,
          365,
          1451,
          13891,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1745881877961706,
        "compression_ratio": 2.0252100840336134,
        "end": 3010.36,
        "id": 931,
        "no_speech_prob": 0.0018386607989668846,
        "seek": 300436,
        "start": 3004.36,
        "temperature": 0,
        "text": " And every input is connected to every node, and then every node is connected to every node,",
        "tokens": [
          50364,
          400,
          633,
          4846,
          307,
          4582,
          281,
          633,
          9984,
          11,
          293,
          550,
          633,
          9984,
          307,
          4582,
          281,
          633,
          9984,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.1745881877961706,
        "compression_ratio": 2.0252100840336134,
        "end": 3013.36,
        "id": 932,
        "no_speech_prob": 0.0018386607989668846,
        "seek": 300436,
        "start": 3010.36,
        "temperature": 0,
        "text": " and then every node is connected to every output, and so on and so forth.",
        "tokens": [
          50664,
          293,
          550,
          633,
          9984,
          307,
          4582,
          281,
          633,
          5598,
          11,
          293,
          370,
          322,
          293,
          370,
          5220,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1745881877961706,
        "compression_ratio": 2.0252100840336134,
        "end": 3017.36,
        "id": 933,
        "no_speech_prob": 0.0018386607989668846,
        "seek": 300436,
        "start": 3013.36,
        "temperature": 0,
        "text": " So I could be here all day trying to do this diagram and draw every connection between everything.",
        "tokens": [
          50814,
          407,
          286,
          727,
          312,
          510,
          439,
          786,
          1382,
          281,
          360,
          341,
          10686,
          293,
          2642,
          633,
          4984,
          1296,
          1203,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1745881877961706,
        "compression_ratio": 2.0252100840336134,
        "end": 3019.36,
        "id": 934,
        "no_speech_prob": 0.0018386607989668846,
        "seek": 300436,
        "start": 3017.36,
        "temperature": 0,
        "text": " I'm not going to do that.",
        "tokens": [
          51014,
          286,
          478,
          406,
          516,
          281,
          360,
          300,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1745881877961706,
        "compression_ratio": 2.0252100840336134,
        "end": 3024.36,
        "id": 935,
        "no_speech_prob": 0.0018386607989668846,
        "seek": 300436,
        "start": 3019.36,
        "temperature": 0,
        "text": " But all of the information about here is what is saved in these two files.",
        "tokens": [
          51114,
          583,
          439,
          295,
          264,
          1589,
          466,
          510,
          307,
          437,
          307,
          6624,
          294,
          613,
          732,
          7098,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1745881877961706,
        "compression_ratio": 2.0252100840336134,
        "end": 3033.36,
        "id": 936,
        "no_speech_prob": 0.0018386607989668846,
        "seek": 300436,
        "start": 3024.36,
        "temperature": 0,
        "text": " Model.json is a file that just explains all of these pieces, the layers, the outputs, the inputs, all of that stuff.",
        "tokens": [
          51364,
          17105,
          13,
          73,
          3015,
          307,
          257,
          3991,
          300,
          445,
          13948,
          439,
          295,
          613,
          3755,
          11,
          264,
          7914,
          11,
          264,
          23930,
          11,
          264,
          15743,
          11,
          439,
          295,
          300,
          1507,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.17663822174072266,
        "compression_ratio": 1.7798165137614679,
        "end": 3036.36,
        "id": 937,
        "no_speech_prob": 0.0010004960931837559,
        "seek": 303336,
        "start": 3033.36,
        "temperature": 0,
        "text": " That is what is in model.json.",
        "tokens": [
          50364,
          663,
          307,
          437,
          307,
          294,
          2316,
          13,
          73,
          3015,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.17663822174072266,
        "compression_ratio": 1.7798165137614679,
        "end": 3038.36,
        "id": 938,
        "no_speech_prob": 0.0010004960931837559,
        "seek": 303336,
        "start": 3036.36,
        "temperature": 0,
        "text": " In a moment I'll just open up that file and look at it.",
        "tokens": [
          50514,
          682,
          257,
          1623,
          286,
          603,
          445,
          1269,
          493,
          300,
          3991,
          293,
          574,
          412,
          309,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.17663822174072266,
        "compression_ratio": 1.7798165137614679,
        "end": 3040.36,
        "id": 939,
        "no_speech_prob": 0.0010004960931837559,
        "seek": 303336,
        "start": 3038.36,
        "temperature": 0,
        "text": " Model.weights is an interesting thing.",
        "tokens": [
          50614,
          17105,
          13,
          826,
          5761,
          307,
          364,
          1880,
          551,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.17663822174072266,
        "compression_ratio": 1.7798165137614679,
        "end": 3044.36,
        "id": 940,
        "no_speech_prob": 0.0010004960931837559,
        "seek": 303336,
        "start": 3040.36,
        "temperature": 0,
        "text": " So the magic of a neural network, what makes a neural network work,",
        "tokens": [
          50714,
          407,
          264,
          5585,
          295,
          257,
          18161,
          3209,
          11,
          437,
          1669,
          257,
          18161,
          3209,
          589,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.17663822174072266,
        "compression_ratio": 1.7798165137614679,
        "end": 3048.36,
        "id": 941,
        "no_speech_prob": 0.0010004960931837559,
        "seek": 303336,
        "start": 3044.36,
        "temperature": 0,
        "text": " is a number that's associated with every single one of these connections known as a weight.",
        "tokens": [
          50914,
          307,
          257,
          1230,
          300,
          311,
          6615,
          365,
          633,
          2167,
          472,
          295,
          613,
          9271,
          2570,
          382,
          257,
          3364,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17663822174072266,
        "compression_ratio": 1.7798165137614679,
        "end": 3051.36,
        "id": 942,
        "no_speech_prob": 0.0010004960931837559,
        "seek": 303336,
        "start": 3048.36,
        "temperature": 0,
        "text": " You can think of it as a whole bunch of dials.",
        "tokens": [
          51114,
          509,
          393,
          519,
          295,
          309,
          382,
          257,
          1379,
          3840,
          295,
          5502,
          82,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.17663822174072266,
        "compression_ratio": 1.7798165137614679,
        "end": 3052.36,
        "id": 943,
        "no_speech_prob": 0.0010004960931837559,
        "seek": 303336,
        "start": 3051.36,
        "temperature": 0,
        "text": " So I'm tuning the dials, right?",
        "tokens": [
          51264,
          407,
          286,
          478,
          15164,
          264,
          5502,
          82,
          11,
          558,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.17663822174072266,
        "compression_ratio": 1.7798165137614679,
        "end": 3057.36,
        "id": 944,
        "no_speech_prob": 0.0010004960931837559,
        "seek": 303336,
        "start": 3052.36,
        "temperature": 0,
        "text": " I'm trying to get the dials in the right position so that it really makes good guesses about happy versus sad.",
        "tokens": [
          51314,
          286,
          478,
          1382,
          281,
          483,
          264,
          5502,
          82,
          294,
          264,
          558,
          2535,
          370,
          300,
          309,
          534,
          1669,
          665,
          42703,
          466,
          2055,
          5717,
          4227,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.17663822174072266,
        "compression_ratio": 1.7798165137614679,
        "end": 3058.36,
        "id": 945,
        "no_speech_prob": 0.0010004960931837559,
        "seek": 303336,
        "start": 3057.36,
        "temperature": 0,
        "text": " That's the training process.",
        "tokens": [
          51564,
          663,
          311,
          264,
          3097,
          1399,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.17663822174072266,
        "compression_ratio": 1.7798165137614679,
        "end": 3062.36,
        "id": 946,
        "no_speech_prob": 0.0010004960931837559,
        "seek": 303336,
        "start": 3058.36,
        "temperature": 0,
        "text": " Once that training process is done, I want to save where all those dials are.",
        "tokens": [
          51614,
          3443,
          300,
          3097,
          1399,
          307,
          1096,
          11,
          286,
          528,
          281,
          3155,
          689,
          439,
          729,
          5502,
          82,
          366,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.20862171925655026,
        "compression_ratio": 1.7777777777777777,
        "end": 3064.36,
        "id": 947,
        "no_speech_prob": 0.00007967292185639963,
        "seek": 306236,
        "start": 3062.36,
        "temperature": 0,
        "text": " All of those numbers are in this file.",
        "tokens": [
          50364,
          1057,
          295,
          729,
          3547,
          366,
          294,
          341,
          3991,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.20862171925655026,
        "compression_ratio": 1.7777777777777777,
        "end": 3067.36,
        "id": 948,
        "no_speech_prob": 0.00007967292185639963,
        "seek": 306236,
        "start": 3064.36,
        "temperature": 0,
        "text": " This is a binary format file because there's a lot of numbers.",
        "tokens": [
          50464,
          639,
          307,
          257,
          17434,
          7877,
          3991,
          570,
          456,
          311,
          257,
          688,
          295,
          3547,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20862171925655026,
        "compression_ratio": 1.7777777777777777,
        "end": 3072.36,
        "id": 949,
        "no_speech_prob": 0.00007967292185639963,
        "seek": 306236,
        "start": 3067.36,
        "temperature": 0,
        "text": " Millions upon millions of connections potentially between a lot of pixels and a lot of labels and a lot of hidden layers.",
        "tokens": [
          50614,
          7190,
          626,
          3564,
          6803,
          295,
          9271,
          7263,
          1296,
          257,
          688,
          295,
          18668,
          293,
          257,
          688,
          295,
          16949,
          293,
          257,
          688,
          295,
          7633,
          7914,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20862171925655026,
        "compression_ratio": 1.7777777777777777,
        "end": 3077.36,
        "id": 950,
        "no_speech_prob": 0.00007967292185639963,
        "seek": 306236,
        "start": 3072.36,
        "temperature": 0,
        "text": " So this, you'll notice, the file that we saved is 5 megabytes because it's tons and tons of numbers.",
        "tokens": [
          50864,
          407,
          341,
          11,
          291,
          603,
          3449,
          11,
          264,
          3991,
          300,
          321,
          6624,
          307,
          1025,
          10816,
          24538,
          570,
          309,
          311,
          9131,
          293,
          9131,
          295,
          3547,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20862171925655026,
        "compression_ratio": 1.7777777777777777,
        "end": 3083.36,
        "id": 951,
        "no_speech_prob": 0.00007967292185639963,
        "seek": 306236,
        "start": 3077.36,
        "temperature": 0,
        "text": " So it ends up, but this is just a very small file with a little bit of text information about how this is configured.",
        "tokens": [
          51114,
          407,
          309,
          5314,
          493,
          11,
          457,
          341,
          307,
          445,
          257,
          588,
          1359,
          3991,
          365,
          257,
          707,
          857,
          295,
          2487,
          1589,
          466,
          577,
          341,
          307,
          30538,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20862171925655026,
        "compression_ratio": 1.7777777777777777,
        "end": 3084.36,
        "id": 952,
        "no_speech_prob": 0.00007967292185639963,
        "seek": 306236,
        "start": 3083.36,
        "temperature": 0,
        "text": " Okay, I spent a lot of time on that.",
        "tokens": [
          51414,
          1033,
          11,
          286,
          4418,
          257,
          688,
          295,
          565,
          322,
          300,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20862171925655026,
        "compression_ratio": 1.7777777777777777,
        "end": 3086.36,
        "id": 953,
        "no_speech_prob": 0.00007967292185639963,
        "seek": 306236,
        "start": 3084.36,
        "temperature": 0,
        "text": " Hopefully that's some helpful background to you.",
        "tokens": [
          51464,
          10429,
          300,
          311,
          512,
          4961,
          3678,
          281,
          291,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20862171925655026,
        "compression_ratio": 1.7777777777777777,
        "end": 3088.36,
        "id": 954,
        "no_speech_prob": 0.00007967292185639963,
        "seek": 306236,
        "start": 3086.36,
        "temperature": 0,
        "text": " Let's go back and actually look at those files.",
        "tokens": [
          51564,
          961,
          311,
          352,
          646,
          293,
          767,
          574,
          412,
          729,
          7098,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.16084329060145786,
        "compression_ratio": 1.660649819494585,
        "end": 3091.36,
        "id": 955,
        "no_speech_prob": 0.01518786046653986,
        "seek": 308836,
        "start": 3089.36,
        "temperature": 0,
        "text": " So now I've got those files.",
        "tokens": [
          50414,
          407,
          586,
          286,
          600,
          658,
          729,
          7098,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.16084329060145786,
        "compression_ratio": 1.660649819494585,
        "end": 3097.36,
        "id": 956,
        "no_speech_prob": 0.01518786046653986,
        "seek": 308836,
        "start": 3091.36,
        "temperature": 0,
        "text": " What I'm going to do is I'm just going to drag them into Visual Studio Code, which is what I'm using to code this right now.",
        "tokens": [
          50514,
          708,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          445,
          516,
          281,
          5286,
          552,
          666,
          23187,
          13500,
          15549,
          11,
          597,
          307,
          437,
          286,
          478,
          1228,
          281,
          3089,
          341,
          558,
          586,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.16084329060145786,
        "compression_ratio": 1.660649819494585,
        "end": 3099.36,
        "id": 957,
        "no_speech_prob": 0.01518786046653986,
        "seek": 308836,
        "start": 3097.36,
        "temperature": 0,
        "text": " But you could be using any environment.",
        "tokens": [
          50814,
          583,
          291,
          727,
          312,
          1228,
          604,
          2823,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.16084329060145786,
        "compression_ratio": 1.660649819494585,
        "end": 3101.36,
        "id": 958,
        "no_speech_prob": 0.01518786046653986,
        "seek": 308836,
        "start": 3099.36,
        "temperature": 0,
        "text": " Oops, they didn't make it into the right place.",
        "tokens": [
          50914,
          21726,
          11,
          436,
          994,
          380,
          652,
          309,
          666,
          264,
          558,
          1081,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.16084329060145786,
        "compression_ratio": 1.660649819494585,
        "end": 3103.36,
        "id": 959,
        "no_speech_prob": 0.01518786046653986,
        "seek": 308836,
        "start": 3101.36,
        "temperature": 0,
        "text": " Let me try that again.",
        "tokens": [
          51014,
          961,
          385,
          853,
          300,
          797,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.16084329060145786,
        "compression_ratio": 1.660649819494585,
        "end": 3105.36,
        "id": 960,
        "no_speech_prob": 0.01518786046653986,
        "seek": 308836,
        "start": 3103.36,
        "temperature": 0,
        "text": " I'll clean this up later, but I want them in this directory.",
        "tokens": [
          51114,
          286,
          603,
          2541,
          341,
          493,
          1780,
          11,
          457,
          286,
          528,
          552,
          294,
          341,
          21120,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.16084329060145786,
        "compression_ratio": 1.660649819494585,
        "end": 3106.36,
        "id": 961,
        "no_speech_prob": 0.01518786046653986,
        "seek": 308836,
        "start": 3105.36,
        "temperature": 0,
        "text": " Great.",
        "tokens": [
          51214,
          3769,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.16084329060145786,
        "compression_ratio": 1.660649819494585,
        "end": 3109.36,
        "id": 962,
        "no_speech_prob": 0.01518786046653986,
        "seek": 308836,
        "start": 3106.36,
        "temperature": 0,
        "text": " So you can see that they're there, model.json, model.weights.bin.",
        "tokens": [
          51264,
          407,
          291,
          393,
          536,
          300,
          436,
          434,
          456,
          11,
          2316,
          13,
          73,
          3015,
          11,
          2316,
          13,
          826,
          5761,
          13,
          13496,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.16084329060145786,
        "compression_ratio": 1.660649819494585,
        "end": 3114.36,
        "id": 963,
        "no_speech_prob": 0.01518786046653986,
        "seek": 308836,
        "start": 3109.36,
        "temperature": 0,
        "text": " If I click on this, you can start to see all the stuff in it.",
        "tokens": [
          51414,
          759,
          286,
          2052,
          322,
          341,
          11,
          291,
          393,
          722,
          281,
          536,
          439,
          264,
          1507,
          294,
          309,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2394444098839393,
        "compression_ratio": 1.706451612903226,
        "end": 3124.36,
        "id": 964,
        "no_speech_prob": 0.06953917443752289,
        "seek": 311436,
        "start": 3114.36,
        "temperature": 0,
        "text": " There's information about the input shape, and is it a sequential model, and what kind of algorithm are you using, and is it dense, and it uses something called softmat, all this stuff.",
        "tokens": [
          50364,
          821,
          311,
          1589,
          466,
          264,
          4846,
          3909,
          11,
          293,
          307,
          309,
          257,
          42881,
          2316,
          11,
          293,
          437,
          733,
          295,
          9284,
          366,
          291,
          1228,
          11,
          293,
          307,
          309,
          18011,
          11,
          293,
          309,
          4960,
          746,
          1219,
          2787,
          15677,
          11,
          439,
          341,
          1507,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2394444098839393,
        "compression_ratio": 1.706451612903226,
        "end": 3130.36,
        "id": 965,
        "no_speech_prob": 0.06953917443752289,
        "seek": 311436,
        "start": 3124.36,
        "temperature": 0,
        "text": " So this is way beyond the scope of what I'm doing in these videos, but if you're interested in more about these details,",
        "tokens": [
          50864,
          407,
          341,
          307,
          636,
          4399,
          264,
          11923,
          295,
          437,
          286,
          478,
          884,
          294,
          613,
          2145,
          11,
          457,
          498,
          291,
          434,
          3102,
          294,
          544,
          466,
          613,
          4365,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.2394444098839393,
        "compression_ratio": 1.706451612903226,
        "end": 3135.36,
        "id": 966,
        "no_speech_prob": 0.06953917443752289,
        "seek": 311436,
        "start": 3130.36,
        "temperature": 0,
        "text": " you could look at some of my videos that use TensorFlow.js natively to understand more pieces here.",
        "tokens": [
          51164,
          291,
          727,
          574,
          412,
          512,
          295,
          452,
          2145,
          300,
          764,
          37624,
          13,
          25530,
          8470,
          356,
          281,
          1223,
          544,
          3755,
          510,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2394444098839393,
        "compression_ratio": 1.706451612903226,
        "end": 3140.36,
        "id": 967,
        "no_speech_prob": 0.06953917443752289,
        "seek": 311436,
        "start": 3135.36,
        "temperature": 0,
        "text": " But you can see here, this is where it's looking for the weights file, et cetera, et cetera.",
        "tokens": [
          51414,
          583,
          291,
          393,
          536,
          510,
          11,
          341,
          307,
          689,
          309,
          311,
          1237,
          337,
          264,
          17443,
          3991,
          11,
          1030,
          11458,
          11,
          1030,
          11458,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2394444098839393,
        "compression_ratio": 1.706451612903226,
        "end": 3141.36,
        "id": 968,
        "no_speech_prob": 0.06953917443752289,
        "seek": 311436,
        "start": 3140.36,
        "temperature": 0,
        "text": " And this is really important.",
        "tokens": [
          51664,
          400,
          341,
          307,
          534,
          1021,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2100093194416591,
        "compression_ratio": 1.6382113821138211,
        "end": 3151.36,
        "id": 969,
        "no_speech_prob": 0.004755127709358931,
        "seek": 314136,
        "start": 3141.36,
        "temperature": 0,
        "text": " This is really just what TensorFlow.js would do natively, but ml5 is helping with a little bit on top of it by adding these happy and sad labels.",
        "tokens": [
          50364,
          639,
          307,
          534,
          445,
          437,
          37624,
          13,
          25530,
          576,
          360,
          8470,
          356,
          11,
          457,
          23271,
          20,
          307,
          4315,
          365,
          257,
          707,
          857,
          322,
          1192,
          295,
          309,
          538,
          5127,
          613,
          2055,
          293,
          4227,
          16949,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2100093194416591,
        "compression_ratio": 1.6382113821138211,
        "end": 3152.36,
        "id": 970,
        "no_speech_prob": 0.004755127709358931,
        "seek": 314136,
        "start": 3151.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50864,
          1033,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2100093194416591,
        "compression_ratio": 1.6382113821138211,
        "end": 3155.36,
        "id": 971,
        "no_speech_prob": 0.004755127709358931,
        "seek": 314136,
        "start": 3152.36,
        "temperature": 0,
        "text": " So now, all we have to do is load the model now.",
        "tokens": [
          50914,
          407,
          586,
          11,
          439,
          321,
          362,
          281,
          360,
          307,
          3677,
          264,
          2316,
          586,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2100093194416591,
        "compression_ratio": 1.6382113821138211,
        "end": 3163.36,
        "id": 972,
        "no_speech_prob": 0.004755127709358931,
        "seek": 314136,
        "start": 3155.36,
        "temperature": 0,
        "text": " Okay, so we're going to go, we saved that model, and so the steps are, the first thing we have to do is load the MobileNet model.",
        "tokens": [
          51064,
          1033,
          11,
          370,
          321,
          434,
          516,
          281,
          352,
          11,
          321,
          6624,
          300,
          2316,
          11,
          293,
          370,
          264,
          4439,
          366,
          11,
          264,
          700,
          551,
          321,
          362,
          281,
          360,
          307,
          3677,
          264,
          22625,
          31890,
          2316,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2100093194416591,
        "compression_ratio": 1.6382113821138211,
        "end": 3167.36,
        "id": 973,
        "no_speech_prob": 0.004755127709358931,
        "seek": 314136,
        "start": 3163.36,
        "temperature": 0,
        "text": " So we're not actually saving that original pre-trained image classifier.",
        "tokens": [
          51464,
          407,
          321,
          434,
          406,
          767,
          6816,
          300,
          3380,
          659,
          12,
          17227,
          2001,
          3256,
          1508,
          9902,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.176906173293655,
        "compression_ratio": 1.691304347826087,
        "end": 3171.36,
        "id": 974,
        "no_speech_prob": 0.03021412156522274,
        "seek": 316736,
        "start": 3167.36,
        "temperature": 0,
        "text": " We're just saving the bits and pieces that are hooked into it.",
        "tokens": [
          50364,
          492,
          434,
          445,
          6816,
          264,
          9239,
          293,
          3755,
          300,
          366,
          20410,
          666,
          309,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.176906173293655,
        "compression_ratio": 1.691304347826087,
        "end": 3174.36,
        "id": 975,
        "no_speech_prob": 0.03021412156522274,
        "seek": 316736,
        "start": 3171.36,
        "temperature": 0,
        "text": " So we can't hook into it until MobileNet is ready.",
        "tokens": [
          50564,
          407,
          321,
          393,
          380,
          6328,
          666,
          309,
          1826,
          22625,
          31890,
          307,
          1919,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.176906173293655,
        "compression_ratio": 1.691304347826087,
        "end": 3184.36,
        "id": 976,
        "no_speech_prob": 0.03021412156522274,
        "seek": 316736,
        "start": 3174.36,
        "temperature": 0,
        "text": " So once we've hooked into it, once MobileNet is ready, we can then say classifier.load model.json.",
        "tokens": [
          50714,
          407,
          1564,
          321,
          600,
          20410,
          666,
          309,
          11,
          1564,
          22625,
          31890,
          307,
          1919,
          11,
          321,
          393,
          550,
          584,
          1508,
          9902,
          13,
          2907,
          2316,
          13,
          73,
          3015,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.176906173293655,
        "compression_ratio": 1.691304347826087,
        "end": 3195.36,
        "id": 977,
        "no_speech_prob": 0.03021412156522274,
        "seek": 316736,
        "start": 3184.36,
        "temperature": 0,
        "text": " Now, there are two files, model.json and model.weights.bin, but ml5 has set up that if you just give it one file, it'll look automatically for the other file in the same place.",
        "tokens": [
          51214,
          823,
          11,
          456,
          366,
          732,
          7098,
          11,
          2316,
          13,
          73,
          3015,
          293,
          2316,
          13,
          826,
          5761,
          13,
          13496,
          11,
          457,
          23271,
          20,
          575,
          992,
          493,
          300,
          498,
          291,
          445,
          976,
          309,
          472,
          3991,
          11,
          309,
          603,
          574,
          6772,
          337,
          264,
          661,
          3991,
          294,
          264,
          912,
          1081,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20391149723783453,
        "compression_ratio": 1.775609756097561,
        "end": 3201.36,
        "id": 978,
        "no_speech_prob": 0.00600346690043807,
        "seek": 319536,
        "start": 3195.36,
        "temperature": 0,
        "text": " There are ways of customizing the file names and their paths and all that, but that you can sort of look into in the documentation.",
        "tokens": [
          50364,
          821,
          366,
          2098,
          295,
          2375,
          3319,
          264,
          3991,
          5288,
          293,
          641,
          14518,
          293,
          439,
          300,
          11,
          457,
          300,
          291,
          393,
          1333,
          295,
          574,
          666,
          294,
          264,
          14333,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20391149723783453,
        "compression_ratio": 1.775609756097561,
        "end": 3206.36,
        "id": 979,
        "no_speech_prob": 0.00600346690043807,
        "seek": 319536,
        "start": 3201.36,
        "temperature": 0,
        "text": " But the easiest thing for just to do this, and then I'm going to say custom model ready.",
        "tokens": [
          50664,
          583,
          264,
          12889,
          551,
          337,
          445,
          281,
          360,
          341,
          11,
          293,
          550,
          286,
          478,
          516,
          281,
          584,
          2375,
          2316,
          1919,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20391149723783453,
        "compression_ratio": 1.775609756097561,
        "end": 3217.36,
        "id": 980,
        "no_speech_prob": 0.00600346690043807,
        "seek": 319536,
        "start": 3206.36,
        "temperature": 0,
        "text": " So I'm going to write another event function, custom model ready, and there I'm going to say custom model is ready.",
        "tokens": [
          50914,
          407,
          286,
          478,
          516,
          281,
          2464,
          1071,
          2280,
          2445,
          11,
          2375,
          2316,
          1919,
          11,
          293,
          456,
          286,
          478,
          516,
          281,
          584,
          2375,
          2316,
          307,
          1919,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20391149723783453,
        "compression_ratio": 1.775609756097561,
        "end": 3219.36,
        "id": 981,
        "no_speech_prob": 0.00600346690043807,
        "seek": 319536,
        "start": 3217.36,
        "temperature": 0,
        "text": " So it's a two-step process.",
        "tokens": [
          51464,
          407,
          309,
          311,
          257,
          732,
          12,
          16792,
          1399,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.24218859199349208,
        "compression_ratio": 1.6946564885496183,
        "end": 3222.36,
        "id": 982,
        "no_speech_prob": 0.5428047776222229,
        "seek": 321936,
        "start": 3219.36,
        "temperature": 0,
        "text": " So I'm going to say if the load MobileNet, MobileNet is ready.",
        "tokens": [
          50364,
          407,
          286,
          478,
          516,
          281,
          584,
          498,
          264,
          3677,
          22625,
          31890,
          11,
          22625,
          31890,
          307,
          1919,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.24218859199349208,
        "compression_ratio": 1.6946564885496183,
        "end": 3226.36,
        "id": 983,
        "no_speech_prob": 0.5428047776222229,
        "seek": 321936,
        "start": 3222.36,
        "temperature": 0,
        "text": " Then load model.json with the weights, custom model is ready.",
        "tokens": [
          50514,
          1396,
          3677,
          2316,
          13,
          73,
          3015,
          365,
          264,
          17443,
          11,
          2375,
          2316,
          307,
          1919,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.24218859199349208,
        "compression_ratio": 1.6946564885496183,
        "end": 3229.36,
        "id": 984,
        "no_speech_prob": 0.5428047776222229,
        "seek": 321936,
        "start": 3226.36,
        "temperature": 0,
        "text": " All right, let's just run this.",
        "tokens": [
          50714,
          1057,
          558,
          11,
          718,
          311,
          445,
          1190,
          341,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.24218859199349208,
        "compression_ratio": 1.6946564885496183,
        "end": 3233.36,
        "id": 985,
        "no_speech_prob": 0.5428047776222229,
        "seek": 321936,
        "start": 3229.36,
        "temperature": 0,
        "text": " Zoom back out, and there we go.",
        "tokens": [
          50864,
          13453,
          646,
          484,
          11,
          293,
          456,
          321,
          352,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.24218859199349208,
        "compression_ratio": 1.6946564885496183,
        "end": 3236.36,
        "id": 986,
        "no_speech_prob": 0.5428047776222229,
        "seek": 321936,
        "start": 3233.36,
        "temperature": 0,
        "text": " Everything's loaded, but I don't see any results.",
        "tokens": [
          51064,
          5471,
          311,
          13210,
          11,
          457,
          286,
          500,
          380,
          536,
          604,
          3542,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.24218859199349208,
        "compression_ratio": 1.6946564885496183,
        "end": 3237.36,
        "id": 987,
        "no_speech_prob": 0.5428047776222229,
        "seek": 321936,
        "start": 3236.36,
        "temperature": 0,
        "text": " Hmm, I don't see any results.",
        "tokens": [
          51214,
          8239,
          11,
          286,
          500,
          380,
          536,
          604,
          3542,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.24218859199349208,
        "compression_ratio": 1.6946564885496183,
        "end": 3238.36,
        "id": 988,
        "no_speech_prob": 0.5428047776222229,
        "seek": 321936,
        "start": 3237.36,
        "temperature": 0,
        "text": " Why?",
        "tokens": [
          51264,
          1545,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.24218859199349208,
        "compression_ratio": 1.6946564885496183,
        "end": 3243.36,
        "id": 989,
        "no_speech_prob": 0.5428047776222229,
        "seek": 321936,
        "start": 3238.36,
        "temperature": 0,
        "text": " Well, this sketch was written originally with code to train.",
        "tokens": [
          51314,
          1042,
          11,
          341,
          12325,
          390,
          3720,
          7993,
          365,
          3089,
          281,
          3847,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.24218859199349208,
        "compression_ratio": 1.6946564885496183,
        "end": 3246.36,
        "id": 990,
        "no_speech_prob": 0.5428047776222229,
        "seek": 321936,
        "start": 3243.36,
        "temperature": 0,
        "text": " So I'm supposed to press the buttons and hit train, but now I don't need to train because I loaded the model.",
        "tokens": [
          51564,
          407,
          286,
          478,
          3442,
          281,
          1886,
          264,
          9905,
          293,
          2045,
          3847,
          11,
          457,
          586,
          286,
          500,
          380,
          643,
          281,
          3847,
          570,
          286,
          13210,
          264,
          2316,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17900823125776077,
        "compression_ratio": 1.838095238095238,
        "end": 3250.36,
        "id": 991,
        "no_speech_prob": 0.021614935249090195,
        "seek": 324636,
        "start": 3246.36,
        "temperature": 0,
        "text": " So this is where I kind of like, I don't know what you should do next.",
        "tokens": [
          50364,
          407,
          341,
          307,
          689,
          286,
          733,
          295,
          411,
          11,
          286,
          500,
          380,
          458,
          437,
          291,
          820,
          360,
          958,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.17900823125776077,
        "compression_ratio": 1.838095238095238,
        "end": 3255.36,
        "id": 992,
        "no_speech_prob": 0.021614935249090195,
        "seek": 324636,
        "start": 3250.36,
        "temperature": 0,
        "text": " Maybe you want to keep two separate web pages, two separate sketches, one for training and one for loading.",
        "tokens": [
          50564,
          2704,
          291,
          528,
          281,
          1066,
          732,
          4994,
          3670,
          7183,
          11,
          732,
          4994,
          34547,
          11,
          472,
          337,
          3097,
          293,
          472,
          337,
          15114,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.17900823125776077,
        "compression_ratio": 1.838095238095238,
        "end": 3257.36,
        "id": 993,
        "no_speech_prob": 0.021614935249090195,
        "seek": 324636,
        "start": 3255.36,
        "temperature": 0,
        "text": " Maybe you do it all in one.",
        "tokens": [
          50814,
          2704,
          291,
          360,
          309,
          439,
          294,
          472,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17900823125776077,
        "compression_ratio": 1.838095238095238,
        "end": 3263.36,
        "id": 994,
        "no_speech_prob": 0.021614935249090195,
        "seek": 324636,
        "start": 3257.36,
        "temperature": 0,
        "text": " You'll actually see if you go to the ml5 examples, there's one that has like a button that you can like drag and drop.",
        "tokens": [
          50914,
          509,
          603,
          767,
          536,
          498,
          291,
          352,
          281,
          264,
          23271,
          20,
          5110,
          11,
          456,
          311,
          472,
          300,
          575,
          411,
          257,
          2960,
          300,
          291,
          393,
          411,
          5286,
          293,
          3270,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17900823125776077,
        "compression_ratio": 1.838095238095238,
        "end": 3266.36,
        "id": 995,
        "no_speech_prob": 0.021614935249090195,
        "seek": 324636,
        "start": 3263.36,
        "temperature": 0,
        "text": " You can actually like select files and load them and save them all in the same sketch.",
        "tokens": [
          51214,
          509,
          393,
          767,
          411,
          3048,
          7098,
          293,
          3677,
          552,
          293,
          3155,
          552,
          439,
          294,
          264,
          912,
          12325,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.17900823125776077,
        "compression_ratio": 1.838095238095238,
        "end": 3272.36,
        "id": 996,
        "no_speech_prob": 0.021614935249090195,
        "seek": 324636,
        "start": 3266.36,
        "temperature": 0,
        "text": " But what I want to do now is basically a workflow for I'm done with the training, so I'm not going to ever train again.",
        "tokens": [
          51364,
          583,
          437,
          286,
          528,
          281,
          360,
          586,
          307,
          1936,
          257,
          20993,
          337,
          286,
          478,
          1096,
          365,
          264,
          3097,
          11,
          370,
          286,
          478,
          406,
          516,
          281,
          1562,
          3847,
          797,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17900823125776077,
        "compression_ratio": 1.838095238095238,
        "end": 3275.36,
        "id": 997,
        "no_speech_prob": 0.021614935249090195,
        "seek": 324636,
        "start": 3272.36,
        "temperature": 0,
        "text": " So I can actually remove all of these buttons.",
        "tokens": [
          51664,
          407,
          286,
          393,
          767,
          4159,
          439,
          295,
          613,
          9905,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19534568353132767,
        "compression_ratio": 1.7431693989071038,
        "end": 3277.36,
        "id": 998,
        "no_speech_prob": 0.0019877685699611902,
        "seek": 327536,
        "start": 3275.36,
        "temperature": 0,
        "text": " They're no longer relevant to me.",
        "tokens": [
          50364,
          814,
          434,
          572,
          2854,
          7340,
          281,
          385,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.19534568353132767,
        "compression_ratio": 1.7431693989071038,
        "end": 3283.36,
        "id": 999,
        "no_speech_prob": 0.0019877685699611902,
        "seek": 327536,
        "start": 3277.36,
        "temperature": 0,
        "text": " The text that should show up at the beginning is just loading model.",
        "tokens": [
          50464,
          440,
          2487,
          300,
          820,
          855,
          493,
          412,
          264,
          2863,
          307,
          445,
          15114,
          2316,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19534568353132767,
        "compression_ratio": 1.7431693989071038,
        "end": 3295.36,
        "id": 1000,
        "no_speech_prob": 0.0019877685699611902,
        "seek": 327536,
        "start": 3283.36,
        "temperature": 0,
        "text": " And then when the model is ready, I would say label equals model ready.",
        "tokens": [
          50764,
          400,
          550,
          562,
          264,
          2316,
          307,
          1919,
          11,
          286,
          576,
          584,
          7645,
          6915,
          2316,
          1919,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19534568353132767,
        "compression_ratio": 1.7431693989071038,
        "end": 3297.36,
        "id": 1001,
        "no_speech_prob": 0.0019877685699611902,
        "seek": 327536,
        "start": 3295.36,
        "temperature": 0,
        "text": " So let's run this now.",
        "tokens": [
          51364,
          407,
          718,
          311,
          1190,
          341,
          586,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19534568353132767,
        "compression_ratio": 1.7431693989071038,
        "end": 3300.36,
        "id": 1002,
        "no_speech_prob": 0.0019877685699611902,
        "seek": 327536,
        "start": 3297.36,
        "temperature": 0,
        "text": " So now loading model, loading model, model ready.",
        "tokens": [
          51464,
          407,
          586,
          15114,
          2316,
          11,
          15114,
          2316,
          11,
          2316,
          1919,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19534568353132767,
        "compression_ratio": 1.7431693989071038,
        "end": 3303.36,
        "id": 1003,
        "no_speech_prob": 0.0019877685699611902,
        "seek": 327536,
        "start": 3300.36,
        "temperature": 0,
        "text": " And now once the model is ready, all I need to do is start classifying.",
        "tokens": [
          51614,
          400,
          586,
          1564,
          264,
          2316,
          307,
          1919,
          11,
          439,
          286,
          643,
          281,
          360,
          307,
          722,
          1508,
          5489,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2089923082199772,
        "compression_ratio": 1.8099547511312217,
        "end": 3308.36,
        "id": 1004,
        "no_speech_prob": 0.02595660276710987,
        "seek": 330336,
        "start": 3303.36,
        "temperature": 0,
        "text": " And before I didn't classify until the training was finished.",
        "tokens": [
          50364,
          400,
          949,
          286,
          994,
          380,
          33872,
          1826,
          264,
          3097,
          390,
          4335,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2089923082199772,
        "compression_ratio": 1.8099547511312217,
        "end": 3310.36,
        "id": 1005,
        "no_speech_prob": 0.02595660276710987,
        "seek": 330336,
        "start": 3308.36,
        "temperature": 0,
        "text": " The training is now irrelevant.",
        "tokens": [
          50614,
          440,
          3097,
          307,
          586,
          28682,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2089923082199772,
        "compression_ratio": 1.8099547511312217,
        "end": 3313.36,
        "id": 1006,
        "no_speech_prob": 0.02595660276710987,
        "seek": 330336,
        "start": 3310.36,
        "temperature": 0,
        "text": " I could actually completely comment this out as well.",
        "tokens": [
          50714,
          286,
          727,
          767,
          2584,
          2871,
          341,
          484,
          382,
          731,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2089923082199772,
        "compression_ratio": 1.8099547511312217,
        "end": 3317.36,
        "id": 1007,
        "no_speech_prob": 0.02595660276710987,
        "seek": 330336,
        "start": 3313.36,
        "temperature": 0,
        "text": " And basically I want to start training when the model is ready.",
        "tokens": [
          50864,
          400,
          1936,
          286,
          528,
          281,
          722,
          3097,
          562,
          264,
          2316,
          307,
          1919,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2089923082199772,
        "compression_ratio": 1.8099547511312217,
        "end": 3318.36,
        "id": 1008,
        "no_speech_prob": 0.02595660276710987,
        "seek": 330336,
        "start": 3317.36,
        "temperature": 0,
        "text": " Not training, sorry.",
        "tokens": [
          51064,
          1726,
          3097,
          11,
          2597,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2089923082199772,
        "compression_ratio": 1.8099547511312217,
        "end": 3323.36,
        "id": 1009,
        "no_speech_prob": 0.02595660276710987,
        "seek": 330336,
        "start": 3318.36,
        "temperature": 0,
        "text": " I want to start guessing when the model is ready by saying classifier, classify, got results.",
        "tokens": [
          51114,
          286,
          528,
          281,
          722,
          17939,
          562,
          264,
          2316,
          307,
          1919,
          538,
          1566,
          1508,
          9902,
          11,
          33872,
          11,
          658,
          3542,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2089923082199772,
        "compression_ratio": 1.8099547511312217,
        "end": 3325.36,
        "id": 1010,
        "no_speech_prob": 0.02595660276710987,
        "seek": 330336,
        "start": 3323.36,
        "temperature": 0,
        "text": " And now here we go.",
        "tokens": [
          51364,
          400,
          586,
          510,
          321,
          352,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2089923082199772,
        "compression_ratio": 1.8099547511312217,
        "end": 3327.36,
        "id": 1011,
        "no_speech_prob": 0.02595660276710987,
        "seek": 330336,
        "start": 3325.36,
        "temperature": 0,
        "text": " Loading the model.",
        "tokens": [
          51464,
          6130,
          8166,
          264,
          2316,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2089923082199772,
        "compression_ratio": 1.8099547511312217,
        "end": 3328.36,
        "id": 1012,
        "no_speech_prob": 0.02595660276710987,
        "seek": 330336,
        "start": 3327.36,
        "temperature": 0,
        "text": " Model is ready.",
        "tokens": [
          51564,
          17105,
          307,
          1919,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2089923082199772,
        "compression_ratio": 1.8099547511312217,
        "end": 3330.36,
        "id": 1013,
        "no_speech_prob": 0.02595660276710987,
        "seek": 330336,
        "start": 3328.36,
        "temperature": 0,
        "text": " Happy.",
        "tokens": [
          51614,
          8277,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2089923082199772,
        "compression_ratio": 1.8099547511312217,
        "end": 3331.36,
        "id": 1014,
        "no_speech_prob": 0.02595660276710987,
        "seek": 330336,
        "start": 3330.36,
        "temperature": 0,
        "text": " Sad.",
        "tokens": [
          51714,
          12269,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2089923082199772,
        "compression_ratio": 1.8099547511312217,
        "end": 3332.36,
        "id": 1015,
        "no_speech_prob": 0.02595660276710987,
        "seek": 330336,
        "start": 3331.36,
        "temperature": 0,
        "text": " Happy.",
        "tokens": [
          51764,
          8277,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19503703338420944,
        "compression_ratio": 1.7666666666666666,
        "end": 3333.36,
        "id": 1016,
        "no_speech_prob": 0.004468267317861319,
        "seek": 333236,
        "start": 3332.36,
        "temperature": 0,
        "text": " Sad.",
        "tokens": [
          50364,
          12269,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.19503703338420944,
        "compression_ratio": 1.7666666666666666,
        "end": 3336.36,
        "id": 1017,
        "no_speech_prob": 0.004468267317861319,
        "seek": 333236,
        "start": 3333.36,
        "temperature": 0,
        "text": " And I can refresh the page again.",
        "tokens": [
          50414,
          400,
          286,
          393,
          15134,
          264,
          3028,
          797,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19503703338420944,
        "compression_ratio": 1.7666666666666666,
        "end": 3340.36,
        "id": 1018,
        "no_speech_prob": 0.004468267317861319,
        "seek": 333236,
        "start": 3336.36,
        "temperature": 0,
        "text": " And happy.",
        "tokens": [
          50564,
          400,
          2055,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19503703338420944,
        "compression_ratio": 1.7666666666666666,
        "end": 3341.36,
        "id": 1019,
        "no_speech_prob": 0.004468267317861319,
        "seek": 333236,
        "start": 3340.36,
        "temperature": 0,
        "text": " Sad.",
        "tokens": [
          50764,
          12269,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19503703338420944,
        "compression_ratio": 1.7666666666666666,
        "end": 3342.36,
        "id": 1020,
        "no_speech_prob": 0.004468267317861319,
        "seek": 333236,
        "start": 3341.36,
        "temperature": 0,
        "text": " Happy.",
        "tokens": [
          50814,
          8277,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19503703338420944,
        "compression_ratio": 1.7666666666666666,
        "end": 3343.36,
        "id": 1021,
        "no_speech_prob": 0.004468267317861319,
        "seek": 333236,
        "start": 3342.36,
        "temperature": 0,
        "text": " Sad.",
        "tokens": [
          50864,
          12269,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19503703338420944,
        "compression_ratio": 1.7666666666666666,
        "end": 3344.36,
        "id": 1022,
        "no_speech_prob": 0.004468267317861319,
        "seek": 333236,
        "start": 3343.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50914,
          1057,
          558,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19503703338420944,
        "compression_ratio": 1.7666666666666666,
        "end": 3345.36,
        "id": 1023,
        "no_speech_prob": 0.004468267317861319,
        "seek": 333236,
        "start": 3344.36,
        "temperature": 0,
        "text": " So it works.",
        "tokens": [
          50964,
          407,
          309,
          1985,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19503703338420944,
        "compression_ratio": 1.7666666666666666,
        "end": 3346.36,
        "id": 1024,
        "no_speech_prob": 0.004468267317861319,
        "seek": 333236,
        "start": 3345.36,
        "temperature": 0,
        "text": " We're done.",
        "tokens": [
          51014,
          492,
          434,
          1096,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19503703338420944,
        "compression_ratio": 1.7666666666666666,
        "end": 3347.36,
        "id": 1025,
        "no_speech_prob": 0.004468267317861319,
        "seek": 333236,
        "start": 3346.36,
        "temperature": 0,
        "text": " Yay.",
        "tokens": [
          51064,
          13268,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19503703338420944,
        "compression_ratio": 1.7666666666666666,
        "end": 3348.36,
        "id": 1026,
        "no_speech_prob": 0.004468267317861319,
        "seek": 333236,
        "start": 3347.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51114,
          1033,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19503703338420944,
        "compression_ratio": 1.7666666666666666,
        "end": 3349.36,
        "id": 1027,
        "no_speech_prob": 0.004468267317861319,
        "seek": 333236,
        "start": 3348.36,
        "temperature": 0,
        "text": " So this is a thing you can do now.",
        "tokens": [
          51164,
          407,
          341,
          307,
          257,
          551,
          291,
          393,
          360,
          586,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19503703338420944,
        "compression_ratio": 1.7666666666666666,
        "end": 3350.36,
        "id": 1028,
        "no_speech_prob": 0.004468267317861319,
        "seek": 333236,
        "start": 3349.36,
        "temperature": 0,
        "text": " You can train your own transfer learning model.",
        "tokens": [
          51214,
          509,
          393,
          3847,
          428,
          1065,
          5003,
          2539,
          2316,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19503703338420944,
        "compression_ratio": 1.7666666666666666,
        "end": 3353.36,
        "id": 1029,
        "no_speech_prob": 0.004468267317861319,
        "seek": 333236,
        "start": 3350.36,
        "temperature": 0,
        "text": " You can do this with the regression example too if you watched that video.",
        "tokens": [
          51264,
          509,
          393,
          360,
          341,
          365,
          264,
          24590,
          1365,
          886,
          498,
          291,
          6337,
          300,
          960,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19503703338420944,
        "compression_ratio": 1.7666666666666666,
        "end": 3354.36,
        "id": 1030,
        "no_speech_prob": 0.004468267317861319,
        "seek": 333236,
        "start": 3353.36,
        "temperature": 0,
        "text": " You can save it.",
        "tokens": [
          51414,
          509,
          393,
          3155,
          309,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19503703338420944,
        "compression_ratio": 1.7666666666666666,
        "end": 3355.36,
        "id": 1031,
        "no_speech_prob": 0.004468267317861319,
        "seek": 333236,
        "start": 3354.36,
        "temperature": 0,
        "text": " So I don't know.",
        "tokens": [
          51464,
          407,
          286,
          500,
          380,
          458,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19503703338420944,
        "compression_ratio": 1.7666666666666666,
        "end": 3356.36,
        "id": 1032,
        "no_speech_prob": 0.004468267317861319,
        "seek": 333236,
        "start": 3355.36,
        "temperature": 0,
        "text": " Share.",
        "tokens": [
          51514,
          14945,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19503703338420944,
        "compression_ratio": 1.7666666666666666,
        "end": 3357.36,
        "id": 1033,
        "no_speech_prob": 0.004468267317861319,
        "seek": 333236,
        "start": 3356.36,
        "temperature": 0,
        "text": " You can share models.",
        "tokens": [
          51564,
          509,
          393,
          2073,
          5245,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19503703338420944,
        "compression_ratio": 1.7666666666666666,
        "end": 3358.36,
        "id": 1034,
        "no_speech_prob": 0.004468267317861319,
        "seek": 333236,
        "start": 3357.36,
        "temperature": 0,
        "text": " Let's all share models with each other.",
        "tokens": [
          51614,
          961,
          311,
          439,
          2073,
          5245,
          365,
          1184,
          661,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19503703338420944,
        "compression_ratio": 1.7666666666666666,
        "end": 3360.36,
        "id": 1035,
        "no_speech_prob": 0.004468267317861319,
        "seek": 333236,
        "start": 3358.36,
        "temperature": 0,
        "text": " Share your model with me.",
        "tokens": [
          51664,
          14945,
          428,
          2316,
          365,
          385,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19503703338420944,
        "compression_ratio": 1.7666666666666666,
        "end": 3361.36,
        "id": 1036,
        "no_speech_prob": 0.004468267317861319,
        "seek": 333236,
        "start": 3360.36,
        "temperature": 0,
        "text": " Let's see what happens.",
        "tokens": [
          51764,
          961,
          311,
          536,
          437,
          2314,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.20638965879167828,
        "compression_ratio": 1.652027027027027,
        "end": 3362.36,
        "id": 1037,
        "no_speech_prob": 0.019121648743748665,
        "seek": 336136,
        "start": 3361.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50364,
          1057,
          558,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.20638965879167828,
        "compression_ratio": 1.652027027027027,
        "end": 3364.36,
        "id": 1038,
        "no_speech_prob": 0.019121648743748665,
        "seek": 336136,
        "start": 3362.36,
        "temperature": 0,
        "text": " I'm curious to see what kind of creative stuff you come up with.",
        "tokens": [
          50414,
          286,
          478,
          6369,
          281,
          536,
          437,
          733,
          295,
          5880,
          1507,
          291,
          808,
          493,
          365,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.20638965879167828,
        "compression_ratio": 1.652027027027027,
        "end": 3367.36,
        "id": 1039,
        "no_speech_prob": 0.019121648743748665,
        "seek": 336136,
        "start": 3364.36,
        "temperature": 0,
        "text": " What kind of the interaction that I've done here is like super awkward.",
        "tokens": [
          50514,
          708,
          733,
          295,
          220,
          3322,
          9285,
          300,
          286,
          600,
          1096,
          510,
          307,
          411,
          1687,
          11411,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20638965879167828,
        "compression_ratio": 1.652027027027027,
        "end": 3369.36,
        "id": 1040,
        "no_speech_prob": 0.019121648743748665,
        "seek": 336136,
        "start": 3367.36,
        "temperature": 0,
        "text": " Like I'm going to press the button all the time.",
        "tokens": [
          50664,
          1743,
          286,
          478,
          516,
          281,
          1886,
          264,
          2960,
          439,
          264,
          565,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20638965879167828,
        "compression_ratio": 1.652027027027027,
        "end": 3371.36,
        "id": 1041,
        "no_speech_prob": 0.019121648743748665,
        "seek": 336136,
        "start": 3369.36,
        "temperature": 0,
        "text": " And maybe you don't actually have to train with just video.",
        "tokens": [
          50764,
          400,
          1310,
          291,
          500,
          380,
          767,
          362,
          281,
          3847,
          365,
          445,
          960,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20638965879167828,
        "compression_ratio": 1.652027027027027,
        "end": 3372.36,
        "id": 1042,
        "no_speech_prob": 0.019121648743748665,
        "seek": 336136,
        "start": 3371.36,
        "temperature": 0,
        "text": " You could load a bunch of images.",
        "tokens": [
          50864,
          509,
          727,
          3677,
          257,
          3840,
          295,
          5267,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20638965879167828,
        "compression_ratio": 1.652027027027027,
        "end": 3374.36,
        "id": 1043,
        "no_speech_prob": 0.019121648743748665,
        "seek": 336136,
        "start": 3372.36,
        "temperature": 0,
        "text": " So there's so many possibilities here.",
        "tokens": [
          50914,
          407,
          456,
          311,
          370,
          867,
          12178,
          510,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20638965879167828,
        "compression_ratio": 1.652027027027027,
        "end": 3376.36,
        "id": 1044,
        "no_speech_prob": 0.019121648743748665,
        "seek": 336136,
        "start": 3374.36,
        "temperature": 0,
        "text": " And I look forward to seeing what you make.",
        "tokens": [
          51014,
          400,
          286,
          574,
          2128,
          281,
          2577,
          437,
          291,
          652,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20638965879167828,
        "compression_ratio": 1.652027027027027,
        "end": 3379.36,
        "id": 1045,
        "no_speech_prob": 0.019121648743748665,
        "seek": 336136,
        "start": 3376.36,
        "temperature": 0,
        "text": " And stay tuned for more ml5 videos.",
        "tokens": [
          51114,
          400,
          1754,
          10870,
          337,
          544,
          23271,
          20,
          2145,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20638965879167828,
        "compression_ratio": 1.652027027027027,
        "end": 3380.36,
        "id": 1046,
        "no_speech_prob": 0.019121648743748665,
        "seek": 336136,
        "start": 3379.36,
        "temperature": 0,
        "text": " More stuff is coming.",
        "tokens": [
          51264,
          5048,
          1507,
          307,
          1348,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20638965879167828,
        "compression_ratio": 1.652027027027027,
        "end": 3382.36,
        "id": 1047,
        "no_speech_prob": 0.019121648743748665,
        "seek": 336136,
        "start": 3380.36,
        "temperature": 0,
        "text": " I don't know yet what, but more stuff is coming.",
        "tokens": [
          51314,
          286,
          500,
          380,
          458,
          1939,
          437,
          11,
          457,
          544,
          1507,
          307,
          1348,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20638965879167828,
        "compression_ratio": 1.652027027027027,
        "end": 3383.36,
        "id": 1048,
        "no_speech_prob": 0.019121648743748665,
        "seek": 336136,
        "start": 3382.36,
        "temperature": 0,
        "text": " Goodbye.",
        "tokens": [
          51414,
          15528,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2251708361567283,
        "compression_ratio": 1.2903225806451613,
        "end": 3386.36,
        "id": 1049,
        "no_speech_prob": 0.0715843215584755,
        "seek": 338336,
        "start": 3384.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2251708361567283,
        "compression_ratio": 1.2903225806451613,
        "end": 3392.36,
        "id": 1050,
        "no_speech_prob": 0.0715843215584755,
        "seek": 338336,
        "start": 3390.36,
        "temperature": 0,
        "text": " All right, everyone.",
        "tokens": [
          50714,
          1057,
          558,
          11,
          1518,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2251708361567283,
        "compression_ratio": 1.2903225806451613,
        "end": 3394.36,
        "id": 1051,
        "no_speech_prob": 0.0715843215584755,
        "seek": 338336,
        "start": 3392.36,
        "temperature": 0,
        "text": " I'm glad that I did that a second time.",
        "tokens": [
          50814,
          286,
          478,
          5404,
          300,
          286,
          630,
          300,
          257,
          1150,
          565,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2251708361567283,
        "compression_ratio": 1.2903225806451613,
        "end": 3401.36,
        "id": 1052,
        "no_speech_prob": 0.0715843215584755,
        "seek": 338336,
        "start": 3398.36,
        "temperature": 0,
        "text": " This computer went to sleep for no reason.",
        "tokens": [
          51114,
          639,
          3820,
          1437,
          281,
          2817,
          337,
          572,
          1778,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2251708361567283,
        "compression_ratio": 1.2903225806451613,
        "end": 3408.36,
        "id": 1053,
        "no_speech_prob": 0.0715843215584755,
        "seek": 338336,
        "start": 3404.36,
        "temperature": 0,
        "text": " And there's very little going on in this computer.",
        "tokens": [
          51414,
          400,
          456,
          311,
          588,
          707,
          516,
          322,
          294,
          341,
          3820,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2629119512197134,
        "compression_ratio": 1.4391891891891893,
        "end": 3416.36,
        "id": 1054,
        "no_speech_prob": 0.0000064389719227619935,
        "seek": 341336,
        "start": 3414.36,
        "temperature": 0,
        "text": " Oh, okay.",
        "tokens": [
          50414,
          876,
          11,
          1392,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2629119512197134,
        "compression_ratio": 1.4391891891891893,
        "end": 3418.36,
        "id": 1055,
        "no_speech_prob": 0.0000064389719227619935,
        "seek": 341336,
        "start": 3416.36,
        "temperature": 0,
        "text": " So maybe that's fine.",
        "tokens": [
          50514,
          407,
          1310,
          300,
          311,
          2489,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2629119512197134,
        "compression_ratio": 1.4391891891891893,
        "end": 3422.36,
        "id": 1056,
        "no_speech_prob": 0.0000064389719227619935,
        "seek": 341336,
        "start": 3418.36,
        "temperature": 0,
        "text": " Somebody wrote a comment on my issue.",
        "tokens": [
          50614,
          13463,
          4114,
          257,
          2871,
          322,
          452,
          2734,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2629119512197134,
        "compression_ratio": 1.4391891891891893,
        "end": 3424.36,
        "id": 1057,
        "no_speech_prob": 0.0000064389719227619935,
        "seek": 341336,
        "start": 3422.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50814,
          1033,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2629119512197134,
        "compression_ratio": 1.4391891891891893,
        "end": 3430.36,
        "id": 1058,
        "no_speech_prob": 0.0000064389719227619935,
        "seek": 341336,
        "start": 3428.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51114,
          1057,
          558,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2629119512197134,
        "compression_ratio": 1.4391891891891893,
        "end": 3432.36,
        "id": 1059,
        "no_speech_prob": 0.0000064389719227619935,
        "seek": 341336,
        "start": 3430.36,
        "temperature": 0,
        "text": " So I'm done there.",
        "tokens": [
          51214,
          407,
          286,
          478,
          1096,
          456,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2629119512197134,
        "compression_ratio": 1.4391891891891893,
        "end": 3433.36,
        "id": 1060,
        "no_speech_prob": 0.0000064389719227619935,
        "seek": 341336,
        "start": 3432.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51314,
          1033,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2629119512197134,
        "compression_ratio": 1.4391891891891893,
        "end": 3435.36,
        "id": 1061,
        "no_speech_prob": 0.0000064389719227619935,
        "seek": 341336,
        "start": 3433.36,
        "temperature": 0,
        "text": " That's going to be a good one to release.",
        "tokens": [
          51364,
          663,
          311,
          516,
          281,
          312,
          257,
          665,
          472,
          281,
          4374,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2629119512197134,
        "compression_ratio": 1.4391891891891893,
        "end": 3439.36,
        "id": 1062,
        "no_speech_prob": 0.0000064389719227619935,
        "seek": 341336,
        "start": 3435.36,
        "temperature": 0,
        "text": " Now we are going to move on to something totally different.",
        "tokens": [
          51464,
          823,
          321,
          366,
          516,
          281,
          1286,
          322,
          281,
          746,
          3879,
          819,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20082275569438934,
        "compression_ratio": 1.375,
        "end": 3443.36,
        "id": 1063,
        "no_speech_prob": 0.0004173113266006112,
        "seek": 343936,
        "start": 3440.36,
        "temperature": 0,
        "text": " We are going to move on to something totally different.",
        "tokens": [
          50414,
          492,
          366,
          516,
          281,
          1286,
          322,
          281,
          746,
          3879,
          819,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.20082275569438934,
        "compression_ratio": 1.375,
        "end": 3446.36,
        "id": 1064,
        "no_speech_prob": 0.0004173113266006112,
        "seek": 343936,
        "start": 3445.36,
        "temperature": 0,
        "text": " What time is it?",
        "tokens": [
          50664,
          708,
          565,
          307,
          309,
          30,
          50714
        ]
      },
      {
        "avg_logprob": -0.20082275569438934,
        "compression_ratio": 1.375,
        "end": 3448.36,
        "id": 1065,
        "no_speech_prob": 0.0004173113266006112,
        "seek": 343936,
        "start": 3446.36,
        "temperature": 0,
        "text": " 3 o'clock.",
        "tokens": [
          50714,
          805,
          277,
          6,
          9023,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20082275569438934,
        "compression_ratio": 1.375,
        "end": 3450.36,
        "id": 1066,
        "no_speech_prob": 0.0004173113266006112,
        "seek": 343936,
        "start": 3448.36,
        "temperature": 0,
        "text": " It's getting warm in here.",
        "tokens": [
          50814,
          467,
          311,
          1242,
          4561,
          294,
          510,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20082275569438934,
        "compression_ratio": 1.375,
        "end": 3460.36,
        "id": 1067,
        "no_speech_prob": 0.0004173113266006112,
        "seek": 343936,
        "start": 3456.36,
        "temperature": 0,
        "text": " Actually, so now I need to release this example.",
        "tokens": [
          51214,
          5135,
          11,
          370,
          586,
          286,
          643,
          281,
          4374,
          341,
          1365,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20082275569438934,
        "compression_ratio": 1.375,
        "end": 3465.36,
        "id": 1068,
        "no_speech_prob": 0.0004173113266006112,
        "seek": 343936,
        "start": 3460.36,
        "temperature": 0,
        "text": " So I'm going to delete the model and the weights.",
        "tokens": [
          51414,
          407,
          286,
          478,
          516,
          281,
          12097,
          264,
          2316,
          293,
          264,
          17443,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.24612273867168125,
        "compression_ratio": 1.536231884057971,
        "end": 3475.36,
        "id": 1069,
        "no_speech_prob": 0.001064923475496471,
        "seek": 346936,
        "start": 3469.36,
        "temperature": 0,
        "text": " I'm going to delete the model and the weights.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          12097,
          264,
          2316,
          293,
          264,
          17443,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.24612273867168125,
        "compression_ratio": 1.536231884057971,
        "end": 3480.36,
        "id": 1070,
        "no_speech_prob": 0.001064923475496471,
        "seek": 346936,
        "start": 3477.36,
        "temperature": 0,
        "text": " I'm going to, I just want to leave this.",
        "tokens": [
          50764,
          286,
          478,
          516,
          281,
          11,
          286,
          445,
          528,
          281,
          1856,
          341,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.24612273867168125,
        "compression_ratio": 1.536231884057971,
        "end": 3486.36,
        "id": 1071,
        "no_speech_prob": 0.001064923475496471,
        "seek": 346936,
        "start": 3480.36,
        "temperature": 0,
        "text": " I think what I'm going to do is leave this example with this stuff here.",
        "tokens": [
          50914,
          286,
          519,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          1856,
          341,
          1365,
          365,
          341,
          1507,
          510,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.24612273867168125,
        "compression_ratio": 1.536231884057971,
        "end": 3490.36,
        "id": 1072,
        "no_speech_prob": 0.001064923475496471,
        "seek": 346936,
        "start": 3486.36,
        "temperature": 0,
        "text": " And then, this is tricky.",
        "tokens": [
          51214,
          400,
          550,
          11,
          341,
          307,
          12414,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.24612273867168125,
        "compression_ratio": 1.536231884057971,
        "end": 3495.36,
        "id": 1073,
        "no_speech_prob": 0.001064923475496471,
        "seek": 346936,
        "start": 3493.36,
        "temperature": 0,
        "text": " Comment out loading this.",
        "tokens": [
          51564,
          16328,
          484,
          15114,
          341,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.23726279518821022,
        "compression_ratio": 1.4516129032258065,
        "end": 3501.36,
        "id": 1074,
        "no_speech_prob": 0.00008480663382215425,
        "seek": 349936,
        "start": 3499.36,
        "temperature": 0,
        "text": " Comment this out.",
        "tokens": [
          50364,
          16328,
          341,
          484,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.23726279518821022,
        "compression_ratio": 1.4516129032258065,
        "end": 3505.36,
        "id": 1075,
        "no_speech_prob": 0.00008480663382215425,
        "seek": 349936,
        "start": 3501.36,
        "temperature": 0,
        "text": " So this example is now left in the training state.",
        "tokens": [
          50464,
          407,
          341,
          1365,
          307,
          586,
          1411,
          294,
          264,
          3097,
          1785,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.23726279518821022,
        "compression_ratio": 1.4516129032258065,
        "end": 3511.36,
        "id": 1076,
        "no_speech_prob": 0.00008480663382215425,
        "seek": 349936,
        "start": 3505.36,
        "temperature": 0,
        "text": " But it has the loading code in it, but commented out.",
        "tokens": [
          50664,
          583,
          309,
          575,
          264,
          15114,
          3089,
          294,
          309,
          11,
          457,
          26940,
          484,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.23726279518821022,
        "compression_ratio": 1.4516129032258065,
        "end": 3514.36,
        "id": 1077,
        "no_speech_prob": 0.00008480663382215425,
        "seek": 349936,
        "start": 3511.36,
        "temperature": 0,
        "text": " And so now let me just put this.",
        "tokens": [
          50964,
          400,
          370,
          586,
          718,
          385,
          445,
          829,
          341,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.23726279518821022,
        "compression_ratio": 1.4516129032258065,
        "end": 3520.36,
        "id": 1078,
        "no_speech_prob": 0.00008480663382215425,
        "seek": 349936,
        "start": 3517.36,
        "temperature": 0,
        "text": " We just put this online.",
        "tokens": [
          51264,
          492,
          445,
          829,
          341,
          2950,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.3686145544052124,
        "compression_ratio": 1.108433734939759,
        "end": 3533.36,
        "id": 1079,
        "no_speech_prob": 0.04399382695555687,
        "seek": 352036,
        "start": 3520.36,
        "temperature": 0,
        "text": " Code from save load live stream.",
        "tokens": [
          50364,
          15549,
          490,
          3155,
          3677,
          1621,
          4309,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.3686145544052124,
        "compression_ratio": 1.108433734939759,
        "end": 3541.36,
        "id": 1080,
        "no_speech_prob": 0.04399382695555687,
        "seek": 352036,
        "start": 3538.36,
        "temperature": 0,
        "text": " Save load ml5.",
        "tokens": [
          51264,
          15541,
          3677,
          23271,
          20,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.3686145544052124,
        "compression_ratio": 1.108433734939759,
        "end": 3547.36,
        "id": 1081,
        "no_speech_prob": 0.04399382695555687,
        "seek": 352036,
        "start": 3543.36,
        "temperature": 0,
        "text": " So this is now, it should be in the website.",
        "tokens": [
          51514,
          407,
          341,
          307,
          586,
          11,
          309,
          820,
          312,
          294,
          264,
          3144,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18381708008902414,
        "compression_ratio": 1.2937062937062938,
        "end": 3551.36,
        "id": 1082,
        "no_speech_prob": 0.0035372672136873007,
        "seek": 354736,
        "start": 3548.36,
        "temperature": 0,
        "text": " I'm going to create a pull request here.",
        "tokens": [
          50414,
          286,
          478,
          516,
          281,
          1884,
          257,
          2235,
          5308,
          510,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18381708008902414,
        "compression_ratio": 1.2937062937062938,
        "end": 3561.36,
        "id": 1083,
        "no_speech_prob": 0.0035372672136873007,
        "seek": 354736,
        "start": 3554.36,
        "temperature": 0,
        "text": " This is the code from 11.9 live stream.",
        "tokens": [
          50714,
          639,
          307,
          264,
          3089,
          490,
          2975,
          13,
          24,
          1621,
          4309,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.18381708008902414,
        "compression_ratio": 1.2937062937062938,
        "end": 3566.36,
        "id": 1084,
        "no_speech_prob": 0.0035372672136873007,
        "seek": 354736,
        "start": 3561.36,
        "temperature": 0,
        "text": " I'm not sure if I should make this two examples or just one.",
        "tokens": [
          51064,
          286,
          478,
          406,
          988,
          498,
          286,
          820,
          652,
          341,
          732,
          5110,
          420,
          445,
          472,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18381708008902414,
        "compression_ratio": 1.2937062937062938,
        "end": 3573.36,
        "id": 1085,
        "no_speech_prob": 0.0035372672136873007,
        "seek": 354736,
        "start": 3566.36,
        "temperature": 0,
        "text": " For now, the loading code is commented out.",
        "tokens": [
          51314,
          1171,
          586,
          11,
          264,
          15114,
          3089,
          307,
          26940,
          484,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.22626297562210648,
        "compression_ratio": 1.4719101123595506,
        "end": 3575.36,
        "id": 1086,
        "no_speech_prob": 0.0018385117873549461,
        "seek": 357336,
        "start": 3574.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.22626297562210648,
        "compression_ratio": 1.4719101123595506,
        "end": 3578.36,
        "id": 1087,
        "no_speech_prob": 0.0018385117873549461,
        "seek": 357336,
        "start": 3575.36,
        "temperature": 0,
        "text": " So I'm going to create this pull request.",
        "tokens": [
          50464,
          407,
          286,
          478,
          516,
          281,
          1884,
          341,
          2235,
          5308,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.22626297562210648,
        "compression_ratio": 1.4719101123595506,
        "end": 3582.36,
        "id": 1088,
        "no_speech_prob": 0.0018385117873549461,
        "seek": 357336,
        "start": 3578.36,
        "temperature": 0,
        "text": " And it should be just these files.",
        "tokens": [
          50614,
          400,
          309,
          820,
          312,
          445,
          613,
          7098,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.22626297562210648,
        "compression_ratio": 1.4719101123595506,
        "end": 3584.36,
        "id": 1089,
        "no_speech_prob": 0.0018385117873549461,
        "seek": 357336,
        "start": 3582.36,
        "temperature": 0,
        "text": " Okay, good. Great.",
        "tokens": [
          50814,
          1033,
          11,
          665,
          13,
          3769,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.22626297562210648,
        "compression_ratio": 1.4719101123595506,
        "end": 3588.36,
        "id": 1090,
        "no_speech_prob": 0.0018385117873549461,
        "seek": 357336,
        "start": 3584.36,
        "temperature": 0,
        "text": " So that code will be on the coding train website.",
        "tokens": [
          50914,
          407,
          300,
          3089,
          486,
          312,
          322,
          264,
          17720,
          3847,
          3144,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.22626297562210648,
        "compression_ratio": 1.4719101123595506,
        "end": 3596.36,
        "id": 1091,
        "no_speech_prob": 0.0018385117873549461,
        "seek": 357336,
        "start": 3588.36,
        "temperature": 0,
        "text": " Just for people who are looking, there is also this example.",
        "tokens": [
          51114,
          1449,
          337,
          561,
          567,
          366,
          1237,
          11,
          456,
          307,
          611,
          341,
          1365,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.22626297562210648,
        "compression_ratio": 1.4719101123595506,
        "end": 3597.36,
        "id": 1092,
        "no_speech_prob": 0.0018385117873549461,
        "seek": 357336,
        "start": 3596.36,
        "temperature": 0,
        "text": " I had it open.",
        "tokens": [
          51514,
          286,
          632,
          309,
          1269,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.22626297562210648,
        "compression_ratio": 1.4719101123595506,
        "end": 3599.36,
        "id": 1093,
        "no_speech_prob": 0.0018385117873549461,
        "seek": 357336,
        "start": 3597.36,
        "temperature": 0,
        "text": " So this is the same exact example.",
        "tokens": [
          51564,
          407,
          341,
          307,
          264,
          912,
          1900,
          1365,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2124584109284157,
        "compression_ratio": 1.6120218579234973,
        "end": 3605.36,
        "id": 1094,
        "no_speech_prob": 0.007815469987690449,
        "seek": 359936,
        "start": 3599.36,
        "temperature": 0,
        "text": " I'll note, though, that this example uses a button that you can select and then select files and load them.",
        "tokens": [
          50364,
          286,
          603,
          3637,
          11,
          1673,
          11,
          300,
          341,
          1365,
          4960,
          257,
          2960,
          300,
          291,
          393,
          3048,
          293,
          550,
          3048,
          7098,
          293,
          3677,
          552,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2124584109284157,
        "compression_ratio": 1.6120218579234973,
        "end": 3607.36,
        "id": 1095,
        "no_speech_prob": 0.007815469987690449,
        "seek": 359936,
        "start": 3605.36,
        "temperature": 0,
        "text": " So there's a lot of other ways of approaching this.",
        "tokens": [
          50664,
          407,
          456,
          311,
          257,
          688,
          295,
          661,
          2098,
          295,
          14908,
          341,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2124584109284157,
        "compression_ratio": 1.6120218579234973,
        "end": 3611.36,
        "id": 1096,
        "no_speech_prob": 0.007815469987690449,
        "seek": 359936,
        "start": 3607.36,
        "temperature": 0,
        "text": " So here's yet another example with sort of more features that you can look at.",
        "tokens": [
          50764,
          407,
          510,
          311,
          1939,
          1071,
          1365,
          365,
          1333,
          295,
          544,
          4122,
          300,
          291,
          393,
          574,
          412,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2124584109284157,
        "compression_ratio": 1.6120218579234973,
        "end": 3612.36,
        "id": 1097,
        "no_speech_prob": 0.007815469987690449,
        "seek": 359936,
        "start": 3611.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50964,
          1033,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2124584109284157,
        "compression_ratio": 1.6120218579234973,
        "end": 3617.36,
        "id": 1098,
        "no_speech_prob": 0.007815469987690449,
        "seek": 359936,
        "start": 3616.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51214,
          1057,
          558,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2124584109284157,
        "compression_ratio": 1.6120218579234973,
        "end": 3620.36,
        "id": 1099,
        "no_speech_prob": 0.007815469987690449,
        "seek": 359936,
        "start": 3617.36,
        "temperature": 0,
        "text": " So now what do I want to do?",
        "tokens": [
          51264,
          407,
          586,
          437,
          360,
          286,
          528,
          281,
          360,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.2124584109284157,
        "compression_ratio": 1.6120218579234973,
        "end": 3625.36,
        "id": 1100,
        "no_speech_prob": 0.007815469987690449,
        "seek": 359936,
        "start": 3624.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51614,
          1057,
          558,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2522867012023926,
        "compression_ratio": 1.0338983050847457,
        "end": 3627.36,
        "id": 1101,
        "no_speech_prob": 0.015901822596788406,
        "seek": 362536,
        "start": 3625.36,
        "temperature": 0,
        "text": " I am going to go to the desktop.",
        "tokens": [
          50364,
          286,
          669,
          516,
          281,
          352,
          281,
          264,
          14502,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2522867012023926,
        "compression_ratio": 1.0338983050847457,
        "end": 3633.36,
        "id": 1102,
        "no_speech_prob": 0.015901822596788406,
        "seek": 362536,
        "start": 3632.36,
        "temperature": 0,
        "text": " And.",
        "tokens": [
          50714,
          400,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2522867012023926,
        "compression_ratio": 1.0338983050847457,
        "end": 3649.36,
        "id": 1103,
        "no_speech_prob": 0.015901822596788406,
        "seek": 362536,
        "start": 3647.36,
        "temperature": 0,
        "text": " And I just want to get.",
        "tokens": [
          51464,
          400,
          286,
          445,
          528,
          281,
          483,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2667365301223028,
        "compression_ratio": 1.2685185185185186,
        "end": 3663.36,
        "id": 1104,
        "no_speech_prob": 0.021929917857050896,
        "seek": 365536,
        "start": 3656.36,
        "temperature": 0,
        "text": " I just want to have like a P5 sketch in that directory that I can kind of start using.",
        "tokens": [
          50414,
          286,
          445,
          528,
          281,
          362,
          411,
          257,
          430,
          20,
          12325,
          294,
          300,
          21120,
          300,
          286,
          393,
          733,
          295,
          722,
          1228,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2667365301223028,
        "compression_ratio": 1.2685185185185186,
        "end": 3673.36,
        "id": 1105,
        "no_speech_prob": 0.021929917857050896,
        "seek": 365536,
        "start": 3668.36,
        "temperature": 0,
        "text": " And so let's get rid of everything here.",
        "tokens": [
          51014,
          400,
          370,
          718,
          311,
          483,
          3973,
          295,
          1203,
          510,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2667365301223028,
        "compression_ratio": 1.2685185185185186,
        "end": 3680.36,
        "id": 1106,
        "no_speech_prob": 0.021929917857050896,
        "seek": 365536,
        "start": 3678.36,
        "temperature": 0,
        "text": " And here.",
        "tokens": [
          51514,
          400,
          510,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.3877827227115631,
        "compression_ratio": 1.015625,
        "end": 3684.36,
        "id": 1107,
        "no_speech_prob": 0.02331640012562275,
        "seek": 368036,
        "start": 3681.36,
        "temperature": 0,
        "text": " And index.",
        "tokens": [
          50414,
          400,
          8186,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.3877827227115631,
        "compression_ratio": 1.015625,
        "end": 3686.36,
        "id": 1108,
        "no_speech_prob": 0.02331640012562275,
        "seek": 368036,
        "start": 3684.36,
        "temperature": 0,
        "text": " Quick draw.",
        "tokens": [
          50564,
          12101,
          2642,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.3877827227115631,
        "compression_ratio": 1.015625,
        "end": 3688.36,
        "id": 1109,
        "no_speech_prob": 0.02331640012562275,
        "seek": 368036,
        "start": 3687.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50714,
          1033,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.3877827227115631,
        "compression_ratio": 1.015625,
        "end": 3704.36,
        "id": 1110,
        "no_speech_prob": 0.02331640012562275,
        "seek": 368036,
        "start": 3703.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51514,
          1033,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.3877827227115631,
        "compression_ratio": 1.015625,
        "end": 3705.36,
        "id": 1111,
        "no_speech_prob": 0.02331640012562275,
        "seek": 368036,
        "start": 3704.36,
        "temperature": 0,
        "text": " Now.",
        "tokens": [
          51564,
          823,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.3877827227115631,
        "compression_ratio": 1.015625,
        "end": 3708.36,
        "id": 1112,
        "no_speech_prob": 0.02331640012562275,
        "seek": 368036,
        "start": 3706.36,
        "temperature": 0,
        "text": " What did I minimize that?",
        "tokens": [
          51664,
          708,
          630,
          286,
          17522,
          300,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.2881588018857516,
        "compression_ratio": 0.7714285714285715,
        "end": 3710.36,
        "id": 1113,
        "no_speech_prob": 0.02514987625181675,
        "seek": 370836,
        "start": 3708.36,
        "temperature": 0,
        "text": " So I need the browser.",
        "tokens": [
          50364,
          407,
          286,
          643,
          264,
          11185,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2881588018857516,
        "compression_ratio": 0.7714285714285715,
        "end": 3712.36,
        "id": 1114,
        "no_speech_prob": 0.02514987625181675,
        "seek": 370836,
        "start": 3711.36,
        "temperature": 0,
        "text": " And.",
        "tokens": [
          50514,
          400,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.37504226684570313,
        "compression_ratio": 0.8823529411764706,
        "end": 3739.36,
        "id": 1115,
        "no_speech_prob": 0.02401699125766754,
        "seek": 373836,
        "start": 3738.36,
        "temperature": 0,
        "text": " And.",
        "tokens": [
          50364,
          400,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.37504226684570313,
        "compression_ratio": 0.8823529411764706,
        "end": 3748.36,
        "id": 1116,
        "no_speech_prob": 0.02401699125766754,
        "seek": 373836,
        "start": 3745.36,
        "temperature": 0,
        "text": " Quick draw data.",
        "tokens": [
          50714,
          12101,
          2642,
          1412,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.37504226684570313,
        "compression_ratio": 0.8823529411764706,
        "end": 3754.36,
        "id": 1117,
        "no_speech_prob": 0.02401699125766754,
        "seek": 373836,
        "start": 3753.36,
        "temperature": 0,
        "text": " And.",
        "tokens": [
          51114,
          400,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.37504226684570313,
        "compression_ratio": 0.8823529411764706,
        "end": 3756.36,
        "id": 1118,
        "no_speech_prob": 0.02401699125766754,
        "seek": 373836,
        "start": 3755.36,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51214,
          821,
          321,
          352,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.37504226684570313,
        "compression_ratio": 0.8823529411764706,
        "end": 3759.36,
        "id": 1119,
        "no_speech_prob": 0.02401699125766754,
        "seek": 373836,
        "start": 3758.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51364,
          1033,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.27332102624993576,
        "compression_ratio": 1.0357142857142858,
        "end": 3769.36,
        "id": 1120,
        "no_speech_prob": 0.04145070165395737,
        "seek": 376836,
        "start": 3768.36,
        "temperature": 0,
        "text": " And.",
        "tokens": [
          50364,
          400,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.27332102624993576,
        "compression_ratio": 1.0357142857142858,
        "end": 3777.36,
        "id": 1121,
        "no_speech_prob": 0.04145070165395737,
        "seek": 376836,
        "start": 3774.36,
        "temperature": 0,
        "text": " And then this is part of.",
        "tokens": [
          50664,
          400,
          550,
          341,
          307,
          644,
          295,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.27332102624993576,
        "compression_ratio": 1.0357142857142858,
        "end": 3781.36,
        "id": 1122,
        "no_speech_prob": 0.04145070165395737,
        "seek": 376836,
        "start": 3778.36,
        "temperature": 0,
        "text": " Build your own API with node.",
        "tokens": [
          50864,
          11875,
          428,
          1065,
          9362,
          365,
          9984,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.27332102624993576,
        "compression_ratio": 1.0357142857142858,
        "end": 3783.36,
        "id": 1123,
        "no_speech_prob": 0.04145070165395737,
        "seek": 376836,
        "start": 3782.36,
        "temperature": 0,
        "text": " Where is that?",
        "tokens": [
          51064,
          2305,
          307,
          300,
          30,
          51114
        ]
      },
      {
        "avg_logprob": -0.27332102624993576,
        "compression_ratio": 1.0357142857142858,
        "end": 3789.36,
        "id": 1124,
        "no_speech_prob": 0.04145070165395737,
        "seek": 376836,
        "start": 3788.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51364,
          1033,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.27332102624993576,
        "compression_ratio": 1.0357142857142858,
        "end": 3791.36,
        "id": 1125,
        "no_speech_prob": 0.04145070165395737,
        "seek": 376836,
        "start": 3790.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51464,
          1033,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.27160227180707575,
        "compression_ratio": 1.5851528384279476,
        "end": 3792.36,
        "id": 1126,
        "no_speech_prob": 0.004399248864501715,
        "seek": 379136,
        "start": 3791.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.27160227180707575,
        "compression_ratio": 1.5851528384279476,
        "end": 3804.36,
        "id": 1127,
        "no_speech_prob": 0.004399248864501715,
        "seek": 379136,
        "start": 3796.36,
        "temperature": 0,
        "text": " Yeah, that looks like there's a discussion in the chat about why I'm using the separate terminal instead of the built-in terminal VS code.",
        "tokens": [
          50614,
          865,
          11,
          300,
          1542,
          411,
          456,
          311,
          257,
          5017,
          294,
          264,
          5081,
          466,
          983,
          286,
          478,
          1228,
          264,
          4994,
          14709,
          2602,
          295,
          264,
          3094,
          12,
          259,
          14709,
          25091,
          3089,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.27160227180707575,
        "compression_ratio": 1.5851528384279476,
        "end": 3807.36,
        "id": 1128,
        "no_speech_prob": 0.004399248864501715,
        "seek": 379136,
        "start": 3804.36,
        "temperature": 0,
        "text": " And why not just use the VS code live server?",
        "tokens": [
          51014,
          400,
          983,
          406,
          445,
          764,
          264,
          25091,
          3089,
          1621,
          7154,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.27160227180707575,
        "compression_ratio": 1.5851528384279476,
        "end": 3809.36,
        "id": 1129,
        "no_speech_prob": 0.004399248864501715,
        "seek": 379136,
        "start": 3807.36,
        "temperature": 0,
        "text": " Those are all very good questions.",
        "tokens": [
          51164,
          3950,
          366,
          439,
          588,
          665,
          1651,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.27160227180707575,
        "compression_ratio": 1.5851528384279476,
        "end": 3813.36,
        "id": 1130,
        "no_speech_prob": 0.004399248864501715,
        "seek": 379136,
        "start": 3809.36,
        "temperature": 0,
        "text": " I you know sometimes I don't like to feel like I'm just only using one thing.",
        "tokens": [
          51264,
          286,
          291,
          458,
          2171,
          286,
          500,
          380,
          411,
          281,
          841,
          411,
          286,
          478,
          445,
          787,
          1228,
          472,
          551,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.27160227180707575,
        "compression_ratio": 1.5851528384279476,
        "end": 3815.36,
        "id": 1131,
        "no_speech_prob": 0.004399248864501715,
        "seek": 379136,
        "start": 3813.36,
        "temperature": 0,
        "text": " And then what if that one thing goes away?",
        "tokens": [
          51464,
          400,
          550,
          437,
          498,
          300,
          472,
          551,
          1709,
          1314,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.27160227180707575,
        "compression_ratio": 1.5851528384279476,
        "end": 3818.36,
        "id": 1132,
        "no_speech_prob": 0.004399248864501715,
        "seek": 379136,
        "start": 3816.36,
        "temperature": 0,
        "text": " So I don't know.",
        "tokens": [
          51614,
          407,
          286,
          500,
          380,
          458,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.3134810265074385,
        "compression_ratio": 1.2376237623762376,
        "end": 3823.36,
        "id": 1133,
        "no_speech_prob": 0.01590348221361637,
        "seek": 381836,
        "start": 3818.36,
        "temperature": 0,
        "text": " Why does this keep this camera keep going out?",
        "tokens": [
          50364,
          1545,
          775,
          341,
          1066,
          341,
          2799,
          1066,
          516,
          484,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.3134810265074385,
        "compression_ratio": 1.2376237623762376,
        "end": 3825.36,
        "id": 1134,
        "no_speech_prob": 0.01590348221361637,
        "seek": 381836,
        "start": 3823.36,
        "temperature": 0,
        "text": " Is it a very loose cable or something?",
        "tokens": [
          50614,
          1119,
          309,
          257,
          588,
          9612,
          8220,
          420,
          746,
          30,
          50714
        ]
      },
      {
        "avg_logprob": -0.3134810265074385,
        "compression_ratio": 1.2376237623762376,
        "end": 3826.36,
        "id": 1135,
        "no_speech_prob": 0.01590348221361637,
        "seek": 381836,
        "start": 3825.36,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50714,
          821,
          321,
          352,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.3134810265074385,
        "compression_ratio": 1.2376237623762376,
        "end": 3832.36,
        "id": 1136,
        "no_speech_prob": 0.01590348221361637,
        "seek": 381836,
        "start": 3831.36,
        "temperature": 0,
        "text": " Alright.",
        "tokens": [
          51014,
          2798,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.3134810265074385,
        "compression_ratio": 1.2376237623762376,
        "end": 3843.36,
        "id": 1137,
        "no_speech_prob": 0.01590348221361637,
        "seek": 381836,
        "start": 3842.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51564,
          1033,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.3134810265074385,
        "compression_ratio": 1.2376237623762376,
        "end": 3846.36,
        "id": 1138,
        "no_speech_prob": 0.01590348221361637,
        "seek": 381836,
        "start": 3845.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51714,
          1033,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.3134810265074385,
        "compression_ratio": 1.2376237623762376,
        "end": 3847.36,
        "id": 1139,
        "no_speech_prob": 0.01590348221361637,
        "seek": 381836,
        "start": 3846.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51764,
          1033,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.21076354201959105,
        "compression_ratio": 1.5586854460093897,
        "end": 3848.36,
        "id": 1140,
        "no_speech_prob": 0.0002098788390867412,
        "seek": 384736,
        "start": 3847.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.21076354201959105,
        "compression_ratio": 1.5586854460093897,
        "end": 3849.36,
        "id": 1141,
        "no_speech_prob": 0.0002098788390867412,
        "seek": 384736,
        "start": 3848.36,
        "temperature": 0,
        "text": " Okay everybody.",
        "tokens": [
          50414,
          1033,
          2201,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.21076354201959105,
        "compression_ratio": 1.5586854460093897,
        "end": 3851.36,
        "id": 1142,
        "no_speech_prob": 0.0002098788390867412,
        "seek": 384736,
        "start": 3849.36,
        "temperature": 0,
        "text": " Everybody settle down.",
        "tokens": [
          50464,
          7646,
          11852,
          760,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.21076354201959105,
        "compression_ratio": 1.5586854460093897,
        "end": 3855.36,
        "id": 1143,
        "no_speech_prob": 0.0002098788390867412,
        "seek": 384736,
        "start": 3853.36,
        "temperature": 0,
        "text": " We're going to do something really fun.",
        "tokens": [
          50664,
          492,
          434,
          516,
          281,
          360,
          746,
          534,
          1019,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21076354201959105,
        "compression_ratio": 1.5586854460093897,
        "end": 3857.36,
        "id": 1144,
        "no_speech_prob": 0.0002098788390867412,
        "seek": 384736,
        "start": 3855.36,
        "temperature": 0,
        "text": " Oh this is empty.",
        "tokens": [
          50764,
          876,
          341,
          307,
          6707,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.21076354201959105,
        "compression_ratio": 1.5586854460093897,
        "end": 3862.36,
        "id": 1145,
        "no_speech_prob": 0.0002098788390867412,
        "seek": 384736,
        "start": 3859.36,
        "temperature": 0,
        "text": " This is the last thing I'm going to do before the weekend.",
        "tokens": [
          50964,
          639,
          307,
          264,
          1036,
          551,
          286,
          478,
          516,
          281,
          360,
          949,
          264,
          6711,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21076354201959105,
        "compression_ratio": 1.5586854460093897,
        "end": 3865.36,
        "id": 1146,
        "no_speech_prob": 0.0002098788390867412,
        "seek": 384736,
        "start": 3862.36,
        "temperature": 0,
        "text": " And there will not be any live streams next week.",
        "tokens": [
          51114,
          400,
          456,
          486,
          406,
          312,
          604,
          1621,
          15842,
          958,
          1243,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.21076354201959105,
        "compression_ratio": 1.5586854460093897,
        "end": 3869.36,
        "id": 1147,
        "no_speech_prob": 0.0002098788390867412,
        "seek": 384736,
        "start": 3865.36,
        "temperature": 0,
        "text": " Unless somehow I figure out some magic way to live stream from thinkercon.",
        "tokens": [
          51264,
          16581,
          6063,
          286,
          2573,
          484,
          512,
          5585,
          636,
          281,
          1621,
          4309,
          490,
          519,
          260,
          1671,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.21076354201959105,
        "compression_ratio": 1.5586854460093897,
        "end": 3871.36,
        "id": 1148,
        "no_speech_prob": 0.0002098788390867412,
        "seek": 384736,
        "start": 3869.36,
        "temperature": 0,
        "text": " But we'll see if that's possible or not.",
        "tokens": [
          51464,
          583,
          321,
          603,
          536,
          498,
          300,
          311,
          1944,
          420,
          406,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21076354201959105,
        "compression_ratio": 1.5586854460093897,
        "end": 3873.36,
        "id": 1149,
        "no_speech_prob": 0.0002098788390867412,
        "seek": 384736,
        "start": 3872.36,
        "temperature": 0,
        "text": " And.",
        "tokens": [
          51614,
          400,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.26339408874511716,
        "compression_ratio": 1.391025641025641,
        "end": 3879.36,
        "id": 1150,
        "no_speech_prob": 0.00039819092489778996,
        "seek": 387736,
        "start": 3878.36,
        "temperature": 0,
        "text": " Alright.",
        "tokens": [
          50414,
          2798,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.26339408874511716,
        "compression_ratio": 1.391025641025641,
        "end": 3880.36,
        "id": 1151,
        "no_speech_prob": 0.00039819092489778996,
        "seek": 387736,
        "start": 3879.36,
        "temperature": 0,
        "text": " Now.",
        "tokens": [
          50464,
          823,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.26339408874511716,
        "compression_ratio": 1.391025641025641,
        "end": 3884.36,
        "id": 1152,
        "no_speech_prob": 0.00039819092489778996,
        "seek": 387736,
        "start": 3881.36,
        "temperature": 0,
        "text": " I think I am ready.",
        "tokens": [
          50564,
          286,
          519,
          286,
          669,
          1919,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.26339408874511716,
        "compression_ratio": 1.391025641025641,
        "end": 3889.36,
        "id": 1153,
        "no_speech_prob": 0.00039819092489778996,
        "seek": 387736,
        "start": 3888.36,
        "temperature": 0,
        "text": " I think I am ready.",
        "tokens": [
          50914,
          286,
          519,
          286,
          669,
          1919,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.26339408874511716,
        "compression_ratio": 1.391025641025641,
        "end": 3891.36,
        "id": 1154,
        "no_speech_prob": 0.00039819092489778996,
        "seek": 387736,
        "start": 3889.36,
        "temperature": 0,
        "text": " I have all the pieces that I want.",
        "tokens": [
          50964,
          286,
          362,
          439,
          264,
          3755,
          300,
          286,
          528,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.26339408874511716,
        "compression_ratio": 1.391025641025641,
        "end": 3895.36,
        "id": 1155,
        "no_speech_prob": 0.00039819092489778996,
        "seek": 387736,
        "start": 3892.36,
        "temperature": 0,
        "text": " This is actually, I'm going to make this a coding challenge.",
        "tokens": [
          51114,
          639,
          307,
          767,
          11,
          286,
          478,
          516,
          281,
          652,
          341,
          257,
          17720,
          3430,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.26339408874511716,
        "compression_ratio": 1.391025641025641,
        "end": 3899.36,
        "id": 1156,
        "no_speech_prob": 0.00039819092489778996,
        "seek": 387736,
        "start": 3895.36,
        "temperature": 0,
        "text": " Maybe the sketch RNN stuff will be tutorial-ish with ml5 but.",
        "tokens": [
          51264,
          2704,
          264,
          12325,
          45702,
          45,
          1507,
          486,
          312,
          7073,
          12,
          742,
          365,
          23271,
          20,
          457,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.26339408874511716,
        "compression_ratio": 1.391025641025641,
        "end": 3901.36,
        "id": 1157,
        "no_speech_prob": 0.00039819092489778996,
        "seek": 387736,
        "start": 3900.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51514,
          1033,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.29265643033114347,
        "compression_ratio": 1.6511627906976745,
        "end": 3904.36,
        "id": 1158,
        "no_speech_prob": 0.007815119810402393,
        "seek": 390136,
        "start": 3902.36,
        "temperature": 0,
        "text": " Well I don't know what to do.",
        "tokens": [
          50414,
          1042,
          286,
          500,
          380,
          458,
          437,
          281,
          360,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.29265643033114347,
        "compression_ratio": 1.6511627906976745,
        "end": 3906.36,
        "id": 1159,
        "no_speech_prob": 0.007815119810402393,
        "seek": 390136,
        "start": 3904.36,
        "temperature": 0,
        "text": " I'm going to make this a coding challenge.",
        "tokens": [
          50514,
          286,
          478,
          516,
          281,
          652,
          341,
          257,
          17720,
          3430,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.29265643033114347,
        "compression_ratio": 1.6511627906976745,
        "end": 3910.36,
        "id": 1160,
        "no_speech_prob": 0.007815119810402393,
        "seek": 390136,
        "start": 3906.36,
        "temperature": 0,
        "text": " People watch the coding challenges more than if they're in the tutorial videos.",
        "tokens": [
          50614,
          3432,
          1159,
          264,
          17720,
          4759,
          544,
          813,
          498,
          436,
          434,
          294,
          264,
          7073,
          2145,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.29265643033114347,
        "compression_ratio": 1.6511627906976745,
        "end": 3911.36,
        "id": 1161,
        "no_speech_prob": 0.007815119810402393,
        "seek": 390136,
        "start": 3910.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50814,
          1033,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.29265643033114347,
        "compression_ratio": 1.6511627906976745,
        "end": 3915.36,
        "id": 1162,
        "no_speech_prob": 0.007815119810402393,
        "seek": 390136,
        "start": 3911.36,
        "temperature": 0,
        "text": " I'm just trying to do like my stretching because my back issues.",
        "tokens": [
          50864,
          286,
          478,
          445,
          1382,
          281,
          360,
          411,
          452,
          19632,
          570,
          452,
          646,
          2663,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.29265643033114347,
        "compression_ratio": 1.6511627906976745,
        "end": 3916.36,
        "id": 1163,
        "no_speech_prob": 0.007815119810402393,
        "seek": 390136,
        "start": 3915.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51064,
          1033,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.29265643033114347,
        "compression_ratio": 1.6511627906976745,
        "end": 3921.36,
        "id": 1164,
        "no_speech_prob": 0.007815119810402393,
        "seek": 390136,
        "start": 3920.36,
        "temperature": 0,
        "text": " You know.",
        "tokens": [
          51314,
          509,
          458,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.29265643033114347,
        "compression_ratio": 1.6511627906976745,
        "end": 3922.36,
        "id": 1165,
        "no_speech_prob": 0.007815119810402393,
        "seek": 390136,
        "start": 3921.36,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          51364,
          6962,
          322,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.29265643033114347,
        "compression_ratio": 1.6511627906976745,
        "end": 3923.36,
        "id": 1166,
        "no_speech_prob": 0.007815119810402393,
        "seek": 390136,
        "start": 3922.36,
        "temperature": 0,
        "text": " Mathew.",
        "tokens": [
          51414,
          6789,
          17418,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.29265643033114347,
        "compression_ratio": 1.6511627906976745,
        "end": 3924.36,
        "id": 1167,
        "no_speech_prob": 0.007815119810402393,
        "seek": 390136,
        "start": 3923.36,
        "temperature": 0,
        "text": " I'll make a thumbnail.",
        "tokens": [
          51464,
          286,
          603,
          652,
          257,
          26746,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.29265643033114347,
        "compression_ratio": 1.6511627906976745,
        "end": 3926.36,
        "id": 1168,
        "no_speech_prob": 0.007815119810402393,
        "seek": 390136,
        "start": 3924.36,
        "temperature": 0,
        "text": " I better make a good thumbnail for this.",
        "tokens": [
          51514,
          286,
          1101,
          652,
          257,
          665,
          26746,
          337,
          341,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.29265643033114347,
        "compression_ratio": 1.6511627906976745,
        "end": 3928.36,
        "id": 1169,
        "no_speech_prob": 0.007815119810402393,
        "seek": 390136,
        "start": 3926.36,
        "temperature": 0,
        "text": " Remind me to make some thumbnails.",
        "tokens": [
          51614,
          4080,
          471,
          385,
          281,
          652,
          512,
          46987,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.24288529085825725,
        "compression_ratio": 1.4966442953020134,
        "end": 3930.36,
        "id": 1170,
        "no_speech_prob": 0.01691385544836521,
        "seek": 392836,
        "start": 3928.36,
        "temperature": 0,
        "text": " I mean just like pose with the results.",
        "tokens": [
          50364,
          286,
          914,
          445,
          411,
          10774,
          365,
          264,
          3542,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.24288529085825725,
        "compression_ratio": 1.4966442953020134,
        "end": 3931.36,
        "id": 1171,
        "no_speech_prob": 0.01691385544836521,
        "seek": 392836,
        "start": 3930.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50464,
          1033,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.24288529085825725,
        "compression_ratio": 1.4966442953020134,
        "end": 3938.36,
        "id": 1172,
        "no_speech_prob": 0.01691385544836521,
        "seek": 392836,
        "start": 3937.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50814,
          1033,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.24288529085825725,
        "compression_ratio": 1.4966442953020134,
        "end": 3944.36,
        "id": 1173,
        "no_speech_prob": 0.01691385544836521,
        "seek": 392836,
        "start": 3942.36,
        "temperature": 0,
        "text": " Hello and welcome to a coding challenge.",
        "tokens": [
          51064,
          2425,
          293,
          2928,
          281,
          257,
          17720,
          3430,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.24288529085825725,
        "compression_ratio": 1.4966442953020134,
        "end": 3945.36,
        "id": 1174,
        "no_speech_prob": 0.01691385544836521,
        "seek": 392836,
        "start": 3944.36,
        "temperature": 0,
        "text": " Actually you know what?",
        "tokens": [
          51164,
          5135,
          291,
          458,
          437,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.24288529085825725,
        "compression_ratio": 1.4966442953020134,
        "end": 3946.36,
        "id": 1175,
        "no_speech_prob": 0.01691385544836521,
        "seek": 392836,
        "start": 3945.36,
        "temperature": 0,
        "text": " No, no, no, no, no, no.",
        "tokens": [
          51214,
          883,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.24288529085825725,
        "compression_ratio": 1.4966442953020134,
        "end": 3948.36,
        "id": 1176,
        "no_speech_prob": 0.01691385544836521,
        "seek": 392836,
        "start": 3946.36,
        "temperature": 0,
        "text": " This is what it's going to be.",
        "tokens": [
          51264,
          639,
          307,
          437,
          309,
          311,
          516,
          281,
          312,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.24288529085825725,
        "compression_ratio": 1.4966442953020134,
        "end": 3950.36,
        "id": 1177,
        "no_speech_prob": 0.01691385544836521,
        "seek": 392836,
        "start": 3949.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51414,
          1033,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.24288529085825725,
        "compression_ratio": 1.4966442953020134,
        "end": 3952.36,
        "id": 1178,
        "no_speech_prob": 0.01691385544836521,
        "seek": 392836,
        "start": 3950.36,
        "temperature": 0,
        "text": " I'm going to start with this behind me.",
        "tokens": [
          51464,
          286,
          478,
          516,
          281,
          722,
          365,
          341,
          2261,
          385,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.24288529085825725,
        "compression_ratio": 1.4966442953020134,
        "end": 3953.36,
        "id": 1179,
        "no_speech_prob": 0.01691385544836521,
        "seek": 392836,
        "start": 3952.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51564,
          1033,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1861553606779679,
        "compression_ratio": 1.5576923076923077,
        "end": 3954.36,
        "id": 1180,
        "no_speech_prob": 0.0013044613879173994,
        "seek": 395336,
        "start": 3953.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.1861553606779679,
        "compression_ratio": 1.5576923076923077,
        "end": 3960.36,
        "id": 1181,
        "no_speech_prob": 0.0013044613879173994,
        "seek": 395336,
        "start": 3958.36,
        "temperature": 0,
        "text": " Can I do a grand entrance?",
        "tokens": [
          50614,
          1664,
          286,
          360,
          257,
          2697,
          12014,
          30,
          50714
        ]
      },
      {
        "avg_logprob": -0.1861553606779679,
        "compression_ratio": 1.5576923076923077,
        "end": 3964.36,
        "id": 1182,
        "no_speech_prob": 0.0013044613879173994,
        "seek": 395336,
        "start": 3963.36,
        "temperature": 0,
        "text": " Hello.",
        "tokens": [
          50864,
          2425,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1861553606779679,
        "compression_ratio": 1.5576923076923077,
        "end": 3969.36,
        "id": 1183,
        "no_speech_prob": 0.0013044613879173994,
        "seek": 395336,
        "start": 3965.36,
        "temperature": 0,
        "text": " Hello and welcome to a coding challenge quick draw edition.",
        "tokens": [
          50964,
          2425,
          293,
          2928,
          281,
          257,
          17720,
          3430,
          1702,
          2642,
          11377,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1861553606779679,
        "compression_ratio": 1.5576923076923077,
        "end": 3972.36,
        "id": 1184,
        "no_speech_prob": 0.0013044613879173994,
        "seek": 395336,
        "start": 3969.36,
        "temperature": 0,
        "text": " Now I have been talking about doing this for a very long time.",
        "tokens": [
          51164,
          823,
          286,
          362,
          668,
          1417,
          466,
          884,
          341,
          337,
          257,
          588,
          938,
          565,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1861553606779679,
        "compression_ratio": 1.5576923076923077,
        "end": 3974.36,
        "id": 1185,
        "no_speech_prob": 0.0013044613879173994,
        "seek": 395336,
        "start": 3972.36,
        "temperature": 0,
        "text": " And I'm excited to finally try this on my channel.",
        "tokens": [
          51314,
          400,
          286,
          478,
          2919,
          281,
          2721,
          853,
          341,
          322,
          452,
          2269,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1861553606779679,
        "compression_ratio": 1.5576923076923077,
        "end": 3978.36,
        "id": 1186,
        "no_speech_prob": 0.0013044613879173994,
        "seek": 395336,
        "start": 3974.36,
        "temperature": 0,
        "text": " One of my favorite data sets that is out there in the world is the quick draw data set.",
        "tokens": [
          51414,
          1485,
          295,
          452,
          2954,
          1412,
          6352,
          300,
          307,
          484,
          456,
          294,
          264,
          1002,
          307,
          264,
          1702,
          2642,
          1412,
          992,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1861553606779679,
        "compression_ratio": 1.5576923076923077,
        "end": 3980.36,
        "id": 1187,
        "no_speech_prob": 0.0013044613879173994,
        "seek": 395336,
        "start": 3978.36,
        "temperature": 0,
        "text": " Now here's the reason.",
        "tokens": [
          51614,
          823,
          510,
          311,
          264,
          1778,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2022015089841233,
        "compression_ratio": 1.6224066390041494,
        "end": 3985.36,
        "id": 1188,
        "no_speech_prob": 0.0037071651313453913,
        "seek": 398036,
        "start": 3980.36,
        "temperature": 0,
        "text": " One of the reasons why I'm interested in this is not just this data set of 50 million drawings",
        "tokens": [
          50364,
          1485,
          295,
          264,
          4112,
          983,
          286,
          478,
          3102,
          294,
          341,
          307,
          406,
          445,
          341,
          1412,
          992,
          295,
          2625,
          2459,
          18618,
          50614
        ]
      },
      {
        "avg_logprob": -0.2022015089841233,
        "compression_ratio": 1.6224066390041494,
        "end": 3988.36,
        "id": 1189,
        "no_speech_prob": 0.0037071651313453913,
        "seek": 398036,
        "start": 3985.36,
        "temperature": 0,
        "text": " which is interesting and fun to play with on its own.",
        "tokens": [
          50614,
          597,
          307,
          1880,
          293,
          1019,
          281,
          862,
          365,
          322,
          1080,
          1065,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2022015089841233,
        "compression_ratio": 1.6224066390041494,
        "end": 3995.36,
        "id": 1190,
        "no_speech_prob": 0.0037071651313453913,
        "seek": 398036,
        "start": 3988.36,
        "temperature": 0,
        "text": " But there is something called Sketch RNN which was developed by a set of researchers at Google.",
        "tokens": [
          50764,
          583,
          456,
          307,
          746,
          1219,
          49245,
          45702,
          45,
          597,
          390,
          4743,
          538,
          257,
          992,
          295,
          10309,
          412,
          3329,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2022015089841233,
        "compression_ratio": 1.6224066390041494,
        "end": 3996.36,
        "id": 1191,
        "no_speech_prob": 0.0037071651313453913,
        "seek": 398036,
        "start": 3995.36,
        "temperature": 0,
        "text": " Google Brain.",
        "tokens": [
          51114,
          3329,
          29783,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2022015089841233,
        "compression_ratio": 1.6224066390041494,
        "end": 3998.36,
        "id": 1192,
        "no_speech_prob": 0.0037071651313453913,
        "seek": 398036,
        "start": 3996.36,
        "temperature": 0,
        "text": " And you can see some of them here who wrote this paper.",
        "tokens": [
          51164,
          400,
          291,
          393,
          536,
          512,
          295,
          552,
          510,
          567,
          4114,
          341,
          3035,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2022015089841233,
        "compression_ratio": 1.6224066390041494,
        "end": 4005.36,
        "id": 1193,
        "no_speech_prob": 0.0037071651313453913,
        "seek": 398036,
        "start": 3999.36,
        "temperature": 0,
        "text": " And explained how Sketch RNN is a neural network, a recurrent neural network",
        "tokens": [
          51314,
          400,
          8825,
          577,
          49245,
          45702,
          45,
          307,
          257,
          18161,
          3209,
          11,
          257,
          18680,
          1753,
          18161,
          3209,
          51614
        ]
      },
      {
        "avg_logprob": -0.17620346002411424,
        "compression_ratio": 1.685483870967742,
        "end": 4010.36,
        "id": 1194,
        "no_speech_prob": 0.0367666557431221,
        "seek": 400536,
        "start": 4005.36,
        "temperature": 0,
        "text": " that learned about how to draw various things from the quick draw data set",
        "tokens": [
          50364,
          300,
          3264,
          466,
          577,
          281,
          2642,
          3683,
          721,
          490,
          264,
          1702,
          2642,
          1412,
          992,
          50614
        ]
      },
      {
        "avg_logprob": -0.17620346002411424,
        "compression_ratio": 1.685483870967742,
        "end": 4015.36,
        "id": 1195,
        "no_speech_prob": 0.0367666557431221,
        "seek": 400536,
        "start": 4010.36,
        "temperature": 0,
        "text": " and then can try and imagine and create new drawings based on how it learned",
        "tokens": [
          50614,
          293,
          550,
          393,
          853,
          293,
          3811,
          293,
          1884,
          777,
          18618,
          2361,
          322,
          577,
          309,
          3264,
          50864
        ]
      },
      {
        "avg_logprob": -0.17620346002411424,
        "compression_ratio": 1.685483870967742,
        "end": 4017.36,
        "id": 1196,
        "no_speech_prob": 0.0367666557431221,
        "seek": 400536,
        "start": 4015.36,
        "temperature": 0,
        "text": " and can even interact and draw with you.",
        "tokens": [
          50864,
          293,
          393,
          754,
          4648,
          293,
          2642,
          365,
          291,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.17620346002411424,
        "compression_ratio": 1.685483870967742,
        "end": 4018.36,
        "id": 1197,
        "no_speech_prob": 0.0367666557431221,
        "seek": 400536,
        "start": 4017.36,
        "temperature": 0,
        "text": " So many possibilities.",
        "tokens": [
          50964,
          407,
          867,
          12178,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17620346002411424,
        "compression_ratio": 1.685483870967742,
        "end": 4019.36,
        "id": 1198,
        "no_speech_prob": 0.0367666557431221,
        "seek": 400536,
        "start": 4018.36,
        "temperature": 0,
        "text": " So this is where I'm going with this.",
        "tokens": [
          51014,
          407,
          341,
          307,
          689,
          286,
          478,
          516,
          365,
          341,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17620346002411424,
        "compression_ratio": 1.685483870967742,
        "end": 4023.36,
        "id": 1199,
        "no_speech_prob": 0.0367666557431221,
        "seek": 400536,
        "start": 4019.36,
        "temperature": 0,
        "text": " I am going to make it, Sketch RNN has recently been added to the ml5 library.",
        "tokens": [
          51064,
          286,
          669,
          516,
          281,
          652,
          309,
          11,
          49245,
          45702,
          45,
          575,
          3938,
          668,
          3869,
          281,
          264,
          23271,
          20,
          6405,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.17620346002411424,
        "compression_ratio": 1.685483870967742,
        "end": 4028.36,
        "id": 1200,
        "no_speech_prob": 0.0367666557431221,
        "seek": 400536,
        "start": 4024.36,
        "temperature": 0,
        "text": " And I'm going to show you an example.",
        "tokens": [
          51314,
          400,
          286,
          478,
          516,
          281,
          855,
          291,
          364,
          1365,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.17620346002411424,
        "compression_ratio": 1.685483870967742,
        "end": 4030.36,
        "id": 1201,
        "no_speech_prob": 0.0367666557431221,
        "seek": 400536,
        "start": 4028.36,
        "temperature": 0,
        "text": " And I'm going to build that with Sketch RNN ml5.",
        "tokens": [
          51514,
          400,
          286,
          478,
          516,
          281,
          1322,
          300,
          365,
          49245,
          45702,
          45,
          23271,
          20,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18731840033280223,
        "compression_ratio": 1.592057761732852,
        "end": 4037.36,
        "id": 1202,
        "no_speech_prob": 0.01590491645038128,
        "seek": 403036,
        "start": 4030.36,
        "temperature": 0,
        "text": " But I feel like before we start making the artificially intelligent system that generates the drawings,",
        "tokens": [
          50364,
          583,
          286,
          841,
          411,
          949,
          321,
          722,
          1455,
          264,
          39905,
          2270,
          13232,
          1185,
          300,
          23815,
          264,
          18618,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.18731840033280223,
        "compression_ratio": 1.592057761732852,
        "end": 4041.36,
        "id": 1203,
        "no_speech_prob": 0.01590491645038128,
        "seek": 403036,
        "start": 4037.36,
        "temperature": 0,
        "text": " let's look at the actual data itself that it was trained on.",
        "tokens": [
          50714,
          718,
          311,
          574,
          412,
          264,
          3539,
          1412,
          2564,
          300,
          309,
          390,
          8895,
          322,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.18731840033280223,
        "compression_ratio": 1.592057761732852,
        "end": 4043.36,
        "id": 1204,
        "no_speech_prob": 0.01590491645038128,
        "seek": 403036,
        "start": 4041.36,
        "temperature": 0,
        "text": " So first, where did that data come from?",
        "tokens": [
          50914,
          407,
          700,
          11,
          689,
          630,
          300,
          1412,
          808,
          490,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.18731840033280223,
        "compression_ratio": 1.592057761732852,
        "end": 4046.36,
        "id": 1205,
        "no_speech_prob": 0.01590491645038128,
        "seek": 403036,
        "start": 4043.36,
        "temperature": 0,
        "text": " So, and apologies if I get anything wrong.",
        "tokens": [
          51014,
          407,
          11,
          293,
          34929,
          498,
          286,
          483,
          1340,
          2085,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.18731840033280223,
        "compression_ratio": 1.592057761732852,
        "end": 4047.36,
        "id": 1206,
        "no_speech_prob": 0.01590491645038128,
        "seek": 403036,
        "start": 4046.36,
        "temperature": 0,
        "text": " Please let me know in the comments.",
        "tokens": [
          51164,
          2555,
          718,
          385,
          458,
          294,
          264,
          3053,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.18731840033280223,
        "compression_ratio": 1.592057761732852,
        "end": 4049.36,
        "id": 1207,
        "no_speech_prob": 0.01590491645038128,
        "seek": 403036,
        "start": 4047.36,
        "temperature": 0,
        "text": " Because this is not my project.",
        "tokens": [
          51214,
          1436,
          341,
          307,
          406,
          452,
          1716,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18731840033280223,
        "compression_ratio": 1.592057761732852,
        "end": 4051.36,
        "id": 1208,
        "no_speech_prob": 0.01590491645038128,
        "seek": 403036,
        "start": 4049.36,
        "temperature": 0,
        "text": " I am just inspired and enthused by it.",
        "tokens": [
          51314,
          286,
          669,
          445,
          7547,
          293,
          948,
          71,
          4717,
          538,
          309,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18731840033280223,
        "compression_ratio": 1.592057761732852,
        "end": 4057.36,
        "id": 1209,
        "no_speech_prob": 0.01590491645038128,
        "seek": 403036,
        "start": 4051.36,
        "temperature": 0,
        "text": " So the quick draw project is a project, an AI experiment made by friends from Google.",
        "tokens": [
          51414,
          407,
          264,
          1702,
          2642,
          1716,
          307,
          257,
          1716,
          11,
          364,
          7318,
          5120,
          1027,
          538,
          1855,
          490,
          3329,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2319126413829291,
        "compression_ratio": 1.5755102040816327,
        "end": 4062.36,
        "id": 1210,
        "no_speech_prob": 0.013635428622364998,
        "seek": 405736,
        "start": 4057.36,
        "temperature": 0,
        "text": " And it is a game that you could play where you say draw a pencil in under 20 seconds.",
        "tokens": [
          50364,
          400,
          309,
          307,
          257,
          1216,
          300,
          291,
          727,
          862,
          689,
          291,
          584,
          2642,
          257,
          10985,
          294,
          833,
          945,
          3949,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2319126413829291,
        "compression_ratio": 1.5755102040816327,
        "end": 4063.36,
        "id": 1211,
        "no_speech_prob": 0.013635428622364998,
        "seek": 405736,
        "start": 4062.36,
        "temperature": 0,
        "text": " Okay, here we go.",
        "tokens": [
          50614,
          1033,
          11,
          510,
          321,
          352,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2319126413829291,
        "compression_ratio": 1.5755102040816327,
        "end": 4066.36,
        "id": 1212,
        "no_speech_prob": 0.013635428622364998,
        "seek": 405736,
        "start": 4063.36,
        "temperature": 0,
        "text": " I see marker or lipstick.",
        "tokens": [
          50664,
          286,
          536,
          15247,
          420,
          22543,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2319126413829291,
        "compression_ratio": 1.5755102040816327,
        "end": 4067.36,
        "id": 1213,
        "no_speech_prob": 0.013635428622364998,
        "seek": 405736,
        "start": 4066.36,
        "temperature": 0,
        "text": " No, no, no.",
        "tokens": [
          50814,
          883,
          11,
          572,
          11,
          572,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2319126413829291,
        "compression_ratio": 1.5755102040816327,
        "end": 4069.36,
        "id": 1214,
        "no_speech_prob": 0.013635428622364998,
        "seek": 405736,
        "start": 4067.36,
        "temperature": 0,
        "text": " That's not really like a pencil.",
        "tokens": [
          50864,
          663,
          311,
          406,
          534,
          411,
          257,
          10985,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2319126413829291,
        "compression_ratio": 1.5755102040816327,
        "end": 4070.36,
        "id": 1215,
        "no_speech_prob": 0.013635428622364998,
        "seek": 405736,
        "start": 4069.36,
        "temperature": 0,
        "text": " If I put an eraser here.",
        "tokens": [
          50964,
          759,
          286,
          829,
          364,
          46018,
          510,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2319126413829291,
        "compression_ratio": 1.5755102040816327,
        "end": 4071.36,
        "id": 1216,
        "no_speech_prob": 0.013635428622364998,
        "seek": 405736,
        "start": 4070.36,
        "temperature": 0,
        "text": " I see rocket.",
        "tokens": [
          51014,
          286,
          536,
          13012,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2319126413829291,
        "compression_ratio": 1.5755102040816327,
        "end": 4072.36,
        "id": 1217,
        "no_speech_prob": 0.013635428622364998,
        "seek": 405736,
        "start": 4071.36,
        "temperature": 0,
        "text": " No, rocket.",
        "tokens": [
          51064,
          883,
          11,
          13012,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2319126413829291,
        "compression_ratio": 1.5755102040816327,
        "end": 4073.36,
        "id": 1218,
        "no_speech_prob": 0.013635428622364998,
        "seek": 405736,
        "start": 4072.36,
        "temperature": 0,
        "text": " I'm the worst.",
        "tokens": [
          51114,
          286,
          478,
          264,
          5855,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2319126413829291,
        "compression_ratio": 1.5755102040816327,
        "end": 4076.36,
        "id": 1219,
        "no_speech_prob": 0.013635428622364998,
        "seek": 405736,
        "start": 4073.36,
        "temperature": 0,
        "text": " I'm not sure what that is.",
        "tokens": [
          51164,
          286,
          478,
          406,
          988,
          437,
          300,
          307,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2319126413829291,
        "compression_ratio": 1.5755102040816327,
        "end": 4078.36,
        "id": 1220,
        "no_speech_prob": 0.013635428622364998,
        "seek": 405736,
        "start": 4076.36,
        "temperature": 0,
        "text": " Yeah, I don't know what that is either.",
        "tokens": [
          51314,
          865,
          11,
          286,
          500,
          380,
          458,
          437,
          300,
          307,
          2139,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2319126413829291,
        "compression_ratio": 1.5755102040816327,
        "end": 4080.36,
        "id": 1221,
        "no_speech_prob": 0.013635428622364998,
        "seek": 405736,
        "start": 4078.36,
        "temperature": 0,
        "text": " Time is running out.",
        "tokens": [
          51414,
          6161,
          307,
          2614,
          484,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2319126413829291,
        "compression_ratio": 1.5755102040816327,
        "end": 4083.36,
        "id": 1222,
        "no_speech_prob": 0.013635428622364998,
        "seek": 405736,
        "start": 4082.36,
        "temperature": 0,
        "text": " Sorry, I couldn't guess.",
        "tokens": [
          51614,
          4919,
          11,
          286,
          2809,
          380,
          2041,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2319126413829291,
        "compression_ratio": 1.5755102040816327,
        "end": 4085.36,
        "id": 1223,
        "no_speech_prob": 0.013635428622364998,
        "seek": 405736,
        "start": 4083.36,
        "temperature": 0,
        "text": " All right, let's try basketball.",
        "tokens": [
          51664,
          1057,
          558,
          11,
          718,
          311,
          853,
          11767,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2042679637670517,
        "compression_ratio": 1.6055363321799307,
        "end": 4091.36,
        "id": 1224,
        "no_speech_prob": 0.0001313508691964671,
        "seek": 408736,
        "start": 4087.36,
        "temperature": 0,
        "text": " I see nose or moon or blueberry or baseball or bracelet.",
        "tokens": [
          50364,
          286,
          536,
          6690,
          420,
          7135,
          420,
          48243,
          420,
          14323,
          420,
          23021,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2042679637670517,
        "compression_ratio": 1.6055363321799307,
        "end": 4092.36,
        "id": 1225,
        "no_speech_prob": 0.0001313508691964671,
        "seek": 408736,
        "start": 4091.36,
        "temperature": 0,
        "text": " Oh, I know.",
        "tokens": [
          50564,
          876,
          11,
          286,
          458,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2042679637670517,
        "compression_ratio": 1.6055363321799307,
        "end": 4093.36,
        "id": 1226,
        "no_speech_prob": 0.0001313508691964671,
        "seek": 408736,
        "start": 4092.36,
        "temperature": 0,
        "text": " It's basketball.",
        "tokens": [
          50614,
          467,
          311,
          11767,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2042679637670517,
        "compression_ratio": 1.6055363321799307,
        "end": 4095.36,
        "id": 1227,
        "no_speech_prob": 0.0001313508691964671,
        "seek": 408736,
        "start": 4093.36,
        "temperature": 0,
        "text": " All right, I win.",
        "tokens": [
          50664,
          1057,
          558,
          11,
          286,
          1942,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2042679637670517,
        "compression_ratio": 1.6055363321799307,
        "end": 4096.360000000001,
        "id": 1228,
        "no_speech_prob": 0.0001313508691964671,
        "seek": 408736,
        "start": 4095.36,
        "temperature": 0,
        "text": " Okay, so you get the idea.",
        "tokens": [
          50764,
          1033,
          11,
          370,
          291,
          483,
          264,
          1558,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2042679637670517,
        "compression_ratio": 1.6055363321799307,
        "end": 4098.360000000001,
        "id": 1229,
        "no_speech_prob": 0.0001313508691964671,
        "seek": 408736,
        "start": 4096.360000000001,
        "temperature": 0,
        "text": " I could be stuck here for quite a while.",
        "tokens": [
          50814,
          286,
          727,
          312,
          5541,
          510,
          337,
          1596,
          257,
          1339,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2042679637670517,
        "compression_ratio": 1.6055363321799307,
        "end": 4105.360000000001,
        "id": 1230,
        "no_speech_prob": 0.0001313508691964671,
        "seek": 408736,
        "start": 4098.360000000001,
        "temperature": 0,
        "text": " Now, what you might not, when you are playing this game, your doodles are being collected.",
        "tokens": [
          50914,
          823,
          11,
          437,
          291,
          1062,
          406,
          11,
          562,
          291,
          366,
          2433,
          341,
          1216,
          11,
          428,
          360,
          35192,
          366,
          885,
          11087,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2042679637670517,
        "compression_ratio": 1.6055363321799307,
        "end": 4110.360000000001,
        "id": 1231,
        "no_speech_prob": 0.0001313508691964671,
        "seek": 408736,
        "start": 4105.360000000001,
        "temperature": 0,
        "text": " And over 15 million players have contributed millions of drawings playing quick draw.",
        "tokens": [
          51264,
          400,
          670,
          2119,
          2459,
          4150,
          362,
          18434,
          6803,
          295,
          18618,
          2433,
          1702,
          2642,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2042679637670517,
        "compression_ratio": 1.6055363321799307,
        "end": 4111.360000000001,
        "id": 1232,
        "no_speech_prob": 0.0001313508691964671,
        "seek": 408736,
        "start": 4110.360000000001,
        "temperature": 0,
        "text": " Oh, and I've used this before, right?",
        "tokens": [
          51514,
          876,
          11,
          293,
          286,
          600,
          1143,
          341,
          949,
          11,
          558,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.2042679637670517,
        "compression_ratio": 1.6055363321799307,
        "end": 4115.360000000001,
        "id": 1233,
        "no_speech_prob": 0.0001313508691964671,
        "seek": 408736,
        "start": 4111.360000000001,
        "temperature": 0,
        "text": " I made an example with a neural network that tried to recognize your drawing.",
        "tokens": [
          51564,
          286,
          1027,
          364,
          1365,
          365,
          257,
          18161,
          3209,
          300,
          3031,
          281,
          5521,
          428,
          6316,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.23889470323223935,
        "compression_ratio": 1.8140495867768596,
        "end": 4118.36,
        "id": 1234,
        "no_speech_prob": 0.0023231415543705225,
        "seek": 411536,
        "start": 4115.36,
        "temperature": 0,
        "text": " So, this has been done on my channel before.",
        "tokens": [
          50364,
          407,
          11,
          341,
          575,
          668,
          1096,
          322,
          452,
          2269,
          949,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.23889470323223935,
        "compression_ratio": 1.8140495867768596,
        "end": 4122.36,
        "id": 1235,
        "no_speech_prob": 0.0023231415543705225,
        "seek": 411536,
        "start": 4118.36,
        "temperature": 0,
        "text": " But what I haven't actually looked at, what I looked at before was I looked at all the drawings as pixels.",
        "tokens": [
          50514,
          583,
          437,
          286,
          2378,
          380,
          767,
          2956,
          412,
          11,
          437,
          286,
          2956,
          412,
          949,
          390,
          286,
          2956,
          412,
          439,
          264,
          18618,
          382,
          18668,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.23889470323223935,
        "compression_ratio": 1.8140495867768596,
        "end": 4131.36,
        "id": 1236,
        "no_speech_prob": 0.0023231415543705225,
        "seek": 411536,
        "start": 4122.36,
        "temperature": 0,
        "text": " What's actually, what's interesting about the data is that the data, which you can find here, information about it on GitHub, is not pixels.",
        "tokens": [
          50714,
          708,
          311,
          767,
          11,
          437,
          311,
          1880,
          466,
          264,
          1412,
          307,
          300,
          264,
          1412,
          11,
          597,
          291,
          393,
          915,
          510,
          11,
          1589,
          466,
          309,
          322,
          23331,
          11,
          307,
          406,
          18668,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.23889470323223935,
        "compression_ratio": 1.8140495867768596,
        "end": 4137.36,
        "id": 1237,
        "no_speech_prob": 0.0023231415543705225,
        "seek": 411536,
        "start": 4131.36,
        "temperature": 0,
        "text": " It's actually the pixel paths of the people making the drawings with timing information.",
        "tokens": [
          51164,
          467,
          311,
          767,
          264,
          19261,
          14518,
          295,
          264,
          561,
          1455,
          264,
          18618,
          365,
          10822,
          1589,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.23889470323223935,
        "compression_ratio": 1.8140495867768596,
        "end": 4141.36,
        "id": 1238,
        "no_speech_prob": 0.0023231415543705225,
        "seek": 411536,
        "start": 4137.36,
        "temperature": 0,
        "text": " So, you could load that data and replay any drawing back.",
        "tokens": [
          51464,
          407,
          11,
          291,
          727,
          3677,
          300,
          1412,
          293,
          23836,
          604,
          6316,
          646,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21496888940984551,
        "compression_ratio": 1.7219917012448134,
        "end": 4156.36,
        "id": 1239,
        "no_speech_prob": 0.20176853239536285,
        "seek": 414136,
        "start": 4142.36,
        "temperature": 0,
        "text": " And each drawing has the word that was associated with it, the country where the person is from who drew it, at least the IP address presumably, and then whether it was recognized, and then the actual drawing itself.",
        "tokens": [
          50414,
          400,
          1184,
          6316,
          575,
          264,
          1349,
          300,
          390,
          6615,
          365,
          309,
          11,
          264,
          1941,
          689,
          264,
          954,
          307,
          490,
          567,
          12804,
          309,
          11,
          412,
          1935,
          264,
          8671,
          2985,
          26742,
          11,
          293,
          550,
          1968,
          309,
          390,
          9823,
          11,
          293,
          550,
          264,
          3539,
          6316,
          2564,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21496888940984551,
        "compression_ratio": 1.7219917012448134,
        "end": 4163.36,
        "id": 1240,
        "no_speech_prob": 0.20176853239536285,
        "seek": 414136,
        "start": 4156.36,
        "temperature": 0,
        "text": " So, what I want to do, and you can see here that the format of the data is a whole lot of xy positions.",
        "tokens": [
          51114,
          407,
          11,
          437,
          286,
          528,
          281,
          360,
          11,
          293,
          291,
          393,
          536,
          510,
          300,
          264,
          7877,
          295,
          264,
          1412,
          307,
          257,
          1379,
          688,
          295,
          2031,
          88,
          8432,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.21496888940984551,
        "compression_ratio": 1.7219917012448134,
        "end": 4166.36,
        "id": 1241,
        "no_speech_prob": 0.20176853239536285,
        "seek": 414136,
        "start": 4163.36,
        "temperature": 0,
        "text": " xy, xy, xy with timing.",
        "tokens": [
          51464,
          2031,
          88,
          11,
          2031,
          88,
          11,
          2031,
          88,
          365,
          10822,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.21496888940984551,
        "compression_ratio": 1.7219917012448134,
        "end": 4169.36,
        "id": 1242,
        "no_speech_prob": 0.20176853239536285,
        "seek": 414136,
        "start": 4166.36,
        "temperature": 0,
        "text": " What time was I at the first point, the second point, the third point?",
        "tokens": [
          51614,
          708,
          565,
          390,
          286,
          412,
          264,
          700,
          935,
          11,
          264,
          1150,
          935,
          11,
          264,
          2636,
          935,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.1603017182185732,
        "compression_ratio": 1.6640316205533596,
        "end": 4173.36,
        "id": 1243,
        "no_speech_prob": 0.0966992974281311,
        "seek": 416936,
        "start": 4169.36,
        "temperature": 0,
        "text": " Then, I might have lifted up my pen, moved, and started doing another one.",
        "tokens": [
          50364,
          1396,
          11,
          286,
          1062,
          362,
          17854,
          493,
          452,
          3435,
          11,
          4259,
          11,
          293,
          1409,
          884,
          1071,
          472,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1603017182185732,
        "compression_ratio": 1.6640316205533596,
        "end": 4174.36,
        "id": 1244,
        "no_speech_prob": 0.0966992974281311,
        "seek": 416936,
        "start": 4173.36,
        "temperature": 0,
        "text": " So, it's a bunch of strokes.",
        "tokens": [
          50564,
          407,
          11,
          309,
          311,
          257,
          3840,
          295,
          24493,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1603017182185732,
        "compression_ratio": 1.6640316205533596,
        "end": 4182.36,
        "id": 1245,
        "no_speech_prob": 0.0966992974281311,
        "seek": 416936,
        "start": 4174.36,
        "temperature": 0,
        "text": " So, this is, it's a little tricky because I can't use the word stroke as a variable name in p5 because stroke is a function that actually sets the pen color.",
        "tokens": [
          50614,
          407,
          11,
          341,
          307,
          11,
          309,
          311,
          257,
          707,
          12414,
          570,
          286,
          393,
          380,
          764,
          264,
          1349,
          12403,
          382,
          257,
          7006,
          1315,
          294,
          280,
          20,
          570,
          12403,
          307,
          257,
          2445,
          300,
          767,
          6352,
          264,
          3435,
          2017,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1603017182185732,
        "compression_ratio": 1.6640316205533596,
        "end": 4190.36,
        "id": 1246,
        "no_speech_prob": 0.0966992974281311,
        "seek": 416936,
        "start": 4182.36,
        "temperature": 0,
        "text": " But the idea is that if I do this, it's sampling a bunch of my points as I drew along that path.",
        "tokens": [
          51014,
          583,
          264,
          1558,
          307,
          300,
          498,
          286,
          360,
          341,
          11,
          309,
          311,
          21179,
          257,
          3840,
          295,
          452,
          2793,
          382,
          286,
          12804,
          2051,
          300,
          3100,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1603017182185732,
        "compression_ratio": 1.6640316205533596,
        "end": 4194.36,
        "id": 1247,
        "no_speech_prob": 0.0966992974281311,
        "seek": 416936,
        "start": 4190.36,
        "temperature": 0,
        "text": " Each one of these is an xy point associated with a given time.",
        "tokens": [
          51414,
          6947,
          472,
          295,
          613,
          307,
          364,
          2031,
          88,
          935,
          6615,
          365,
          257,
          2212,
          565,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19763983998979842,
        "compression_ratio": 1.8481012658227849,
        "end": 4201.36,
        "id": 1248,
        "no_speech_prob": 0.05920691788196564,
        "seek": 419436,
        "start": 4194.36,
        "temperature": 0,
        "text": " And then, there is an array with all of the x's, all of the corresponding y's, and the corresponding times.",
        "tokens": [
          50364,
          400,
          550,
          11,
          456,
          307,
          364,
          10225,
          365,
          439,
          295,
          264,
          2031,
          311,
          11,
          439,
          295,
          264,
          11760,
          288,
          311,
          11,
          293,
          264,
          11760,
          1413,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19763983998979842,
        "compression_ratio": 1.8481012658227849,
        "end": 4210.36,
        "id": 1249,
        "no_speech_prob": 0.05920691788196564,
        "seek": 419436,
        "start": 4201.36,
        "temperature": 0,
        "text": " Now, what I'm actually going to use in this video is if, there are a bunch of different versions of the data, I'm going to use a simplified version of it because these are huge data files.",
        "tokens": [
          50714,
          823,
          11,
          437,
          286,
          478,
          767,
          516,
          281,
          764,
          294,
          341,
          960,
          307,
          498,
          11,
          456,
          366,
          257,
          3840,
          295,
          819,
          9606,
          295,
          264,
          1412,
          11,
          286,
          478,
          516,
          281,
          764,
          257,
          26335,
          3037,
          295,
          309,
          570,
          613,
          366,
          2603,
          1412,
          7098,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19763983998979842,
        "compression_ratio": 1.8481012658227849,
        "end": 4217.36,
        "id": 1250,
        "no_speech_prob": 0.05920691788196564,
        "seek": 419436,
        "start": 4210.36,
        "temperature": 0,
        "text": " But I encourage you as an exercise to try to do what I'm going to do but with the non-simplified version, maybe with the timing aspect of it.",
        "tokens": [
          51164,
          583,
          286,
          5373,
          291,
          382,
          364,
          5380,
          281,
          853,
          281,
          360,
          437,
          286,
          478,
          516,
          281,
          360,
          457,
          365,
          264,
          2107,
          12,
          30937,
          564,
          2587,
          3037,
          11,
          1310,
          365,
          264,
          10822,
          4171,
          295,
          309,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.22418877737862722,
        "compression_ratio": 1.6926229508196722,
        "end": 4229.36,
        "id": 1251,
        "no_speech_prob": 0.02758469060063362,
        "seek": 421736,
        "start": 4217.36,
        "temperature": 0,
        "text": " But the simplified drawing files are the same exact thing, the same exact thing, but no timing information.",
        "tokens": [
          50364,
          583,
          264,
          26335,
          6316,
          7098,
          366,
          264,
          912,
          1900,
          551,
          11,
          264,
          912,
          1900,
          551,
          11,
          457,
          572,
          10822,
          1589,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.22418877737862722,
        "compression_ratio": 1.6926229508196722,
        "end": 4239.36,
        "id": 1252,
        "no_speech_prob": 0.02758469060063362,
        "seek": 421736,
        "start": 4229.36,
        "temperature": 0,
        "text": " And also, they have been sub-sampled, meaning, you know, in theory, as the person is drawing, as the user is drawing, a lot of points are being captured.",
        "tokens": [
          50964,
          400,
          611,
          11,
          436,
          362,
          668,
          1422,
          12,
          19988,
          15551,
          11,
          3620,
          11,
          291,
          458,
          11,
          294,
          5261,
          11,
          382,
          264,
          954,
          307,
          6316,
          11,
          382,
          264,
          4195,
          307,
          6316,
          11,
          257,
          688,
          295,
          2793,
          366,
          885,
          11828,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.22418877737862722,
        "compression_ratio": 1.6926229508196722,
        "end": 4241.36,
        "id": 1253,
        "no_speech_prob": 0.02758469060063362,
        "seek": 421736,
        "start": 4239.36,
        "temperature": 0,
        "text": " But maybe you don't need that level of detail.",
        "tokens": [
          51464,
          583,
          1310,
          291,
          500,
          380,
          643,
          300,
          1496,
          295,
          2607,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.22418877737862722,
        "compression_ratio": 1.6926229508196722,
        "end": 4246.36,
        "id": 1254,
        "no_speech_prob": 0.02758469060063362,
        "seek": 421736,
        "start": 4241.36,
        "temperature": 0,
        "text": " And that's often referred to as like pixel factor or scale factor, I believe, or epsilon value, I guess.",
        "tokens": [
          51564,
          400,
          300,
          311,
          2049,
          10839,
          281,
          382,
          411,
          19261,
          5952,
          420,
          4373,
          5952,
          11,
          286,
          1697,
          11,
          420,
          17889,
          2158,
          11,
          286,
          2041,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2204199264298624,
        "compression_ratio": 1.6135593220338984,
        "end": 4255.36,
        "id": 1255,
        "no_speech_prob": 0.04084247350692749,
        "seek": 424636,
        "start": 4246.36,
        "temperature": 0,
        "text": " So, you can say simplify all strokes using the Rammer-Douglas-Puker algorithm, I don't know if I pronounced that correctly, with an epsilon value of 2.",
        "tokens": [
          50364,
          407,
          11,
          291,
          393,
          584,
          20460,
          439,
          24493,
          1228,
          264,
          497,
          5136,
          260,
          12,
          35,
          513,
          7743,
          12,
          47,
          2034,
          260,
          9284,
          11,
          286,
          500,
          380,
          458,
          498,
          286,
          23155,
          300,
          8944,
          11,
          365,
          364,
          17889,
          2158,
          295,
          568,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2204199264298624,
        "compression_ratio": 1.6135593220338984,
        "end": 4258.36,
        "id": 1256,
        "no_speech_prob": 0.04084247350692749,
        "seek": 424636,
        "start": 4255.36,
        "temperature": 0,
        "text": " So, these are available as something called NDJSON.",
        "tokens": [
          50814,
          407,
          11,
          613,
          366,
          2435,
          382,
          746,
          1219,
          40709,
          41,
          10388,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2204199264298624,
        "compression_ratio": 1.6135593220338984,
        "end": 4264.36,
        "id": 1257,
        "no_speech_prob": 0.04084247350692749,
        "seek": 424636,
        "start": 4258.36,
        "temperature": 0,
        "text": " Now, if you've watched my videos before, you're probably familiar with JSON, JavaScript Object Notation.",
        "tokens": [
          50964,
          823,
          11,
          498,
          291,
          600,
          6337,
          452,
          2145,
          949,
          11,
          291,
          434,
          1391,
          4963,
          365,
          31828,
          11,
          15778,
          24753,
          1726,
          399,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2204199264298624,
        "compression_ratio": 1.6135593220338984,
        "end": 4267.36,
        "id": 1258,
        "no_speech_prob": 0.04084247350692749,
        "seek": 424636,
        "start": 4264.36,
        "temperature": 0,
        "text": " That is a format where you can store data.",
        "tokens": [
          51264,
          663,
          307,
          257,
          7877,
          689,
          291,
          393,
          3531,
          1412,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2204199264298624,
        "compression_ratio": 1.6135593220338984,
        "end": 4269.36,
        "id": 1259,
        "no_speech_prob": 0.04084247350692749,
        "seek": 424636,
        "start": 4267.36,
        "temperature": 0,
        "text": " That's in JavaScript Object Notation.",
        "tokens": [
          51414,
          663,
          311,
          294,
          15778,
          24753,
          1726,
          399,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2204199264298624,
        "compression_ratio": 1.6135593220338984,
        "end": 4271.36,
        "id": 1260,
        "no_speech_prob": 0.04084247350692749,
        "seek": 424636,
        "start": 4269.36,
        "temperature": 0,
        "text": " I have some videos about what is JSON.",
        "tokens": [
          51514,
          286,
          362,
          512,
          2145,
          466,
          437,
          307,
          31828,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2204199264298624,
        "compression_ratio": 1.6135593220338984,
        "end": 4272.36,
        "id": 1261,
        "no_speech_prob": 0.04084247350692749,
        "seek": 424636,
        "start": 4271.36,
        "temperature": 0,
        "text": " NDJSON is a funny thing.",
        "tokens": [
          51614,
          40709,
          41,
          10388,
          307,
          257,
          4074,
          551,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2204199264298624,
        "compression_ratio": 1.6135593220338984,
        "end": 4274.36,
        "id": 1262,
        "no_speech_prob": 0.04084247350692749,
        "seek": 424636,
        "start": 4272.36,
        "temperature": 0,
        "text": " Ha ha, it's hilarious.",
        "tokens": [
          51664,
          4064,
          324,
          11,
          309,
          311,
          19796,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19970493168793907,
        "compression_ratio": 1.7110266159695817,
        "end": 4277.36,
        "id": 1263,
        "no_speech_prob": 0.0005703109782189131,
        "seek": 427436,
        "start": 4274.36,
        "temperature": 0,
        "text": " It's like the funniest version of JSON.",
        "tokens": [
          50364,
          467,
          311,
          411,
          264,
          42681,
          3037,
          295,
          31828,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.19970493168793907,
        "compression_ratio": 1.7110266159695817,
        "end": 4285.36,
        "id": 1264,
        "no_speech_prob": 0.0005703109782189131,
        "seek": 427436,
        "start": 4277.36,
        "temperature": 0,
        "text": " And it actually is a set of multiple JSON elements, each on a different line in a file.",
        "tokens": [
          50514,
          400,
          309,
          767,
          307,
          257,
          992,
          295,
          3866,
          31828,
          4959,
          11,
          1184,
          322,
          257,
          819,
          1622,
          294,
          257,
          3991,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19970493168793907,
        "compression_ratio": 1.7110266159695817,
        "end": 4287.36,
        "id": 1265,
        "no_speech_prob": 0.0005703109782189131,
        "seek": 427436,
        "start": 4285.36,
        "temperature": 0,
        "text": " So, it makes sense to do that.",
        "tokens": [
          50914,
          407,
          11,
          309,
          1669,
          2020,
          281,
          360,
          300,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19970493168793907,
        "compression_ratio": 1.7110266159695817,
        "end": 4291.36,
        "id": 1266,
        "no_speech_prob": 0.0005703109782189131,
        "seek": 427436,
        "start": 4287.36,
        "temperature": 0,
        "text": " Each drawing is its own sort of like JSON object on a different line in the file.",
        "tokens": [
          51014,
          6947,
          6316,
          307,
          1080,
          1065,
          1333,
          295,
          411,
          31828,
          2657,
          322,
          257,
          819,
          1622,
          294,
          264,
          3991,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19970493168793907,
        "compression_ratio": 1.7110266159695817,
        "end": 4293.36,
        "id": 1267,
        "no_speech_prob": 0.0005703109782189131,
        "seek": 427436,
        "start": 4291.36,
        "temperature": 0,
        "text": " So, let's go grab one of these files.",
        "tokens": [
          51214,
          407,
          11,
          718,
          311,
          352,
          4444,
          472,
          295,
          613,
          7098,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19970493168793907,
        "compression_ratio": 1.7110266159695817,
        "end": 4297.36,
        "id": 1268,
        "no_speech_prob": 0.0005703109782189131,
        "seek": 427436,
        "start": 4293.36,
        "temperature": 0,
        "text": " So, getting the data, we can actually go to the public datasets.",
        "tokens": [
          51314,
          407,
          11,
          1242,
          264,
          1412,
          11,
          321,
          393,
          767,
          352,
          281,
          264,
          1908,
          42856,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19970493168793907,
        "compression_ratio": 1.7110266159695817,
        "end": 4299.36,
        "id": 1269,
        "no_speech_prob": 0.0005703109782189131,
        "seek": 427436,
        "start": 4297.36,
        "temperature": 0,
        "text": " Oops, no, I'm sorry.",
        "tokens": [
          51514,
          21726,
          11,
          572,
          11,
          286,
          478,
          2597,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19970493168793907,
        "compression_ratio": 1.7110266159695817,
        "end": 4302.36,
        "id": 1270,
        "no_speech_prob": 0.0005703109782189131,
        "seek": 427436,
        "start": 4299.36,
        "temperature": 0,
        "text": " I just want to go to the list of the files in the cloud console, which is right here.",
        "tokens": [
          51614,
          286,
          445,
          528,
          281,
          352,
          281,
          264,
          1329,
          295,
          264,
          7098,
          294,
          264,
          4588,
          11076,
          11,
          597,
          307,
          558,
          510,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.22086857640466026,
        "compression_ratio": 1.4385964912280702,
        "end": 4307.36,
        "id": 1271,
        "no_speech_prob": 0.0012842973228543997,
        "seek": 430236,
        "start": 4303.36,
        "temperature": 0,
        "text": " I'm going to say I agree and I don't want any email updates, but I accept.",
        "tokens": [
          50414,
          286,
          478,
          516,
          281,
          584,
          286,
          3986,
          293,
          286,
          500,
          380,
          528,
          604,
          3796,
          9205,
          11,
          457,
          286,
          3241,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.22086857640466026,
        "compression_ratio": 1.4385964912280702,
        "end": 4308.36,
        "id": 1272,
        "no_speech_prob": 0.0012842973228543997,
        "seek": 430236,
        "start": 4307.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50614,
          1033,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.22086857640466026,
        "compression_ratio": 1.4385964912280702,
        "end": 4310.36,
        "id": 1273,
        "no_speech_prob": 0.0012842973228543997,
        "seek": 430236,
        "start": 4308.36,
        "temperature": 0,
        "text": " Accept.",
        "tokens": [
          50664,
          39957,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.22086857640466026,
        "compression_ratio": 1.4385964912280702,
        "end": 4312.36,
        "id": 1274,
        "no_speech_prob": 0.0012842973228543997,
        "seek": 430236,
        "start": 4310.36,
        "temperature": 0,
        "text": " So, I'm going to go to full.",
        "tokens": [
          50764,
          407,
          11,
          286,
          478,
          516,
          281,
          352,
          281,
          1577,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.22086857640466026,
        "compression_ratio": 1.4385964912280702,
        "end": 4314.36,
        "id": 1275,
        "no_speech_prob": 0.0012842973228543997,
        "seek": 430236,
        "start": 4312.36,
        "temperature": 0,
        "text": " And, oops.",
        "tokens": [
          50864,
          400,
          11,
          34166,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.22086857640466026,
        "compression_ratio": 1.4385964912280702,
        "end": 4326.36,
        "id": 1276,
        "no_speech_prob": 0.0012842973228543997,
        "seek": 430236,
        "start": 4323.36,
        "temperature": 0,
        "text": " I realize you can't see anything here, so let's try to make this bigger.",
        "tokens": [
          51414,
          286,
          4325,
          291,
          393,
          380,
          536,
          1340,
          510,
          11,
          370,
          718,
          311,
          853,
          281,
          652,
          341,
          3801,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.22086857640466026,
        "compression_ratio": 1.4385964912280702,
        "end": 4328.36,
        "id": 1277,
        "no_speech_prob": 0.0012842973228543997,
        "seek": 430236,
        "start": 4326.36,
        "temperature": 0,
        "text": " Let me dismiss this right now.",
        "tokens": [
          51564,
          961,
          385,
          16974,
          341,
          558,
          586,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.22086857640466026,
        "compression_ratio": 1.4385964912280702,
        "end": 4330.36,
        "id": 1278,
        "no_speech_prob": 0.0012842973228543997,
        "seek": 430236,
        "start": 4328.36,
        "temperature": 0,
        "text": " And, come on.",
        "tokens": [
          51664,
          400,
          11,
          808,
          322,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17039329383023985,
        "compression_ratio": 1.6774193548387097,
        "end": 4333.36,
        "id": 1279,
        "no_speech_prob": 0.000055622000218136236,
        "seek": 433036,
        "start": 4331.36,
        "temperature": 0,
        "text": " I guess I'll make this smaller and I'll just zoom in.",
        "tokens": [
          50414,
          286,
          2041,
          286,
          603,
          652,
          341,
          4356,
          293,
          286,
          603,
          445,
          8863,
          294,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.17039329383023985,
        "compression_ratio": 1.6774193548387097,
        "end": 4335.36,
        "id": 1280,
        "no_speech_prob": 0.000055622000218136236,
        "seek": 433036,
        "start": 4333.36,
        "temperature": 0,
        "text": " So, these are the different formats.",
        "tokens": [
          50514,
          407,
          11,
          613,
          366,
          264,
          819,
          25879,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.17039329383023985,
        "compression_ratio": 1.6774193548387097,
        "end": 4337.36,
        "id": 1281,
        "no_speech_prob": 0.000055622000218136236,
        "seek": 433036,
        "start": 4335.36,
        "temperature": 0,
        "text": " They're actually all the data in just like binary.",
        "tokens": [
          50614,
          814,
          434,
          767,
          439,
          264,
          1412,
          294,
          445,
          411,
          17434,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.17039329383023985,
        "compression_ratio": 1.6774193548387097,
        "end": 4342.36,
        "id": 1282,
        "no_speech_prob": 0.000055622000218136236,
        "seek": 433036,
        "start": 4337.36,
        "temperature": 0,
        "text": " There's this NumPy bitmap, which is useful for other kinds of machine learning, different things you might want to try.",
        "tokens": [
          50714,
          821,
          311,
          341,
          22592,
          47,
          88,
          857,
          24223,
          11,
          597,
          307,
          4420,
          337,
          661,
          3685,
          295,
          3479,
          2539,
          11,
          819,
          721,
          291,
          1062,
          528,
          281,
          853,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.17039329383023985,
        "compression_ratio": 1.6774193548387097,
        "end": 4345.36,
        "id": 1283,
        "no_speech_prob": 0.000055622000218136236,
        "seek": 433036,
        "start": 4342.36,
        "temperature": 0,
        "text": " The raw data, but let's look at the simplified data.",
        "tokens": [
          50964,
          440,
          8936,
          1412,
          11,
          457,
          718,
          311,
          574,
          412,
          264,
          26335,
          1412,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17039329383023985,
        "compression_ratio": 1.6774193548387097,
        "end": 4347.36,
        "id": 1284,
        "no_speech_prob": 0.000055622000218136236,
        "seek": 433036,
        "start": 4345.36,
        "temperature": 0,
        "text": " And, let's pick, oh, I don't know.",
        "tokens": [
          51114,
          400,
          11,
          718,
          311,
          1888,
          11,
          1954,
          11,
          286,
          500,
          380,
          458,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17039329383023985,
        "compression_ratio": 1.6774193548387097,
        "end": 4349.36,
        "id": 1285,
        "no_speech_prob": 0.000055622000218136236,
        "seek": 433036,
        "start": 4347.36,
        "temperature": 0,
        "text": " Which model should I pick?",
        "tokens": [
          51214,
          3013,
          2316,
          820,
          286,
          1888,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.17039329383023985,
        "compression_ratio": 1.6774193548387097,
        "end": 4350.36,
        "id": 1286,
        "no_speech_prob": 0.000055622000218136236,
        "seek": 433036,
        "start": 4349.36,
        "temperature": 0,
        "text": " There's so many.",
        "tokens": [
          51314,
          821,
          311,
          370,
          867,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.17039329383023985,
        "compression_ratio": 1.6774193548387097,
        "end": 4354.36,
        "id": 1287,
        "no_speech_prob": 0.000055622000218136236,
        "seek": 433036,
        "start": 4350.36,
        "temperature": 0,
        "text": " Banana, bandage, baseball, basketball, bat, beach, bear, beard.",
        "tokens": [
          51364,
          39588,
          11,
          4116,
          609,
          11,
          14323,
          11,
          11767,
          11,
          7362,
          11,
          7534,
          11,
          6155,
          11,
          17455,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.17039329383023985,
        "compression_ratio": 1.6774193548387097,
        "end": 4356.36,
        "id": 1288,
        "no_speech_prob": 0.000055622000218136236,
        "seek": 433036,
        "start": 4354.36,
        "temperature": 0,
        "text": " I guess I should do beard.",
        "tokens": [
          51564,
          286,
          2041,
          286,
          820,
          360,
          17455,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17039329383023985,
        "compression_ratio": 1.6774193548387097,
        "end": 4357.36,
        "id": 1289,
        "no_speech_prob": 0.000055622000218136236,
        "seek": 433036,
        "start": 4356.36,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          51664,
          1779,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.17039329383023985,
        "compression_ratio": 1.6774193548387097,
        "end": 4359.36,
        "id": 1290,
        "no_speech_prob": 0.000055622000218136236,
        "seek": 433036,
        "start": 4357.36,
        "temperature": 0,
        "text": " That's kind of lame, though.",
        "tokens": [
          51714,
          663,
          311,
          733,
          295,
          27635,
          11,
          1673,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19110988515668212,
        "compression_ratio": 1.5862068965517242,
        "end": 4360.36,
        "id": 1291,
        "no_speech_prob": 0.0002913695643655956,
        "seek": 435936,
        "start": 4359.36,
        "temperature": 0,
        "text": " Birthday cake.",
        "tokens": [
          50364,
          29236,
          5908,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.19110988515668212,
        "compression_ratio": 1.5862068965517242,
        "end": 4361.36,
        "id": 1292,
        "no_speech_prob": 0.0002913695643655956,
        "seek": 435936,
        "start": 4360.36,
        "temperature": 0,
        "text": " Is there like a unicorn?",
        "tokens": [
          50414,
          1119,
          456,
          411,
          257,
          28122,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.19110988515668212,
        "compression_ratio": 1.5862068965517242,
        "end": 4363.36,
        "id": 1293,
        "no_speech_prob": 0.0002913695643655956,
        "seek": 435936,
        "start": 4361.36,
        "temperature": 0,
        "text": " Maybe there's a unicorn.",
        "tokens": [
          50464,
          2704,
          456,
          311,
          257,
          28122,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19110988515668212,
        "compression_ratio": 1.5862068965517242,
        "end": 4364.36,
        "id": 1294,
        "no_speech_prob": 0.0002913695643655956,
        "seek": 435936,
        "start": 4363.36,
        "temperature": 0,
        "text": " No.",
        "tokens": [
          50564,
          883,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19110988515668212,
        "compression_ratio": 1.5862068965517242,
        "end": 4366.36,
        "id": 1295,
        "no_speech_prob": 0.0002913695643655956,
        "seek": 435936,
        "start": 4364.36,
        "temperature": 0,
        "text": " Was there a rainbow?",
        "tokens": [
          50614,
          3027,
          456,
          257,
          18526,
          30,
          50714
        ]
      },
      {
        "avg_logprob": -0.19110988515668212,
        "compression_ratio": 1.5862068965517242,
        "end": 4369.36,
        "id": 1296,
        "no_speech_prob": 0.0002913695643655956,
        "seek": 435936,
        "start": 4368.36,
        "temperature": 0,
        "text": " Yes!",
        "tokens": [
          50814,
          1079,
          0,
          50864
        ]
      },
      {
        "avg_logprob": -0.19110988515668212,
        "compression_ratio": 1.5862068965517242,
        "end": 4370.36,
        "id": 1297,
        "no_speech_prob": 0.0002913695643655956,
        "seek": 435936,
        "start": 4369.36,
        "temperature": 0,
        "text": " There's a rainbow!",
        "tokens": [
          50864,
          821,
          311,
          257,
          18526,
          0,
          50914
        ]
      },
      {
        "avg_logprob": -0.19110988515668212,
        "compression_ratio": 1.5862068965517242,
        "end": 4372.36,
        "id": 1298,
        "no_speech_prob": 0.0002913695643655956,
        "seek": 435936,
        "start": 4370.36,
        "temperature": 0,
        "text": " Alright, so we'll use the rainbow.",
        "tokens": [
          50914,
          2798,
          11,
          370,
          321,
          603,
          764,
          264,
          18526,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19110988515668212,
        "compression_ratio": 1.5862068965517242,
        "end": 4375.36,
        "id": 1299,
        "no_speech_prob": 0.0002913695643655956,
        "seek": 435936,
        "start": 4372.36,
        "temperature": 0,
        "text": " So, I am going to, oops, download this file.",
        "tokens": [
          51014,
          407,
          11,
          286,
          669,
          516,
          281,
          11,
          34166,
          11,
          5484,
          341,
          3991,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19110988515668212,
        "compression_ratio": 1.5862068965517242,
        "end": 4377.36,
        "id": 1300,
        "no_speech_prob": 0.0002913695643655956,
        "seek": 435936,
        "start": 4375.36,
        "temperature": 0,
        "text": " So, here's the thing.",
        "tokens": [
          51164,
          407,
          11,
          510,
          311,
          264,
          551,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19110988515668212,
        "compression_ratio": 1.5862068965517242,
        "end": 4380.36,
        "id": 1301,
        "no_speech_prob": 0.0002913695643655956,
        "seek": 435936,
        "start": 4377.36,
        "temperature": 0,
        "text": " This is a very large file.",
        "tokens": [
          51264,
          639,
          307,
          257,
          588,
          2416,
          3991,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19110988515668212,
        "compression_ratio": 1.5862068965517242,
        "end": 4382.36,
        "id": 1302,
        "no_speech_prob": 0.0002913695643655956,
        "seek": 435936,
        "start": 4380.36,
        "temperature": 0,
        "text": " I had a reason why I was doing this challenge also.",
        "tokens": [
          51414,
          286,
          632,
          257,
          1778,
          983,
          286,
          390,
          884,
          341,
          3430,
          611,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19110988515668212,
        "compression_ratio": 1.5862068965517242,
        "end": 4384.36,
        "id": 1303,
        "no_speech_prob": 0.0002913695643655956,
        "seek": 435936,
        "start": 4382.36,
        "temperature": 0,
        "text": " This is a 43 megabyte file.",
        "tokens": [
          51514,
          639,
          307,
          257,
          17914,
          10816,
          34529,
          3991,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.21198996084707755,
        "compression_ratio": 1.5873015873015872,
        "end": 4391.36,
        "id": 1304,
        "no_speech_prob": 0.10520114004611969,
        "seek": 438436,
        "start": 4384.36,
        "temperature": 0,
        "text": " Now, I could just use some code in my client-side JavaScript to load that file and put it on the web.",
        "tokens": [
          50364,
          823,
          11,
          286,
          727,
          445,
          764,
          512,
          3089,
          294,
          452,
          6423,
          12,
          1812,
          15778,
          281,
          3677,
          300,
          3991,
          293,
          829,
          309,
          322,
          264,
          3670,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.21198996084707755,
        "compression_ratio": 1.5873015873015872,
        "end": 4394.36,
        "id": 1305,
        "no_speech_prob": 0.10520114004611969,
        "seek": 438436,
        "start": 4391.36,
        "temperature": 0,
        "text": " And, at some point, I might show you some techniques for doing that.",
        "tokens": [
          50714,
          400,
          11,
          412,
          512,
          935,
          11,
          286,
          1062,
          855,
          291,
          512,
          7512,
          337,
          884,
          300,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.21198996084707755,
        "compression_ratio": 1.5873015873015872,
        "end": 4396.36,
        "id": 1306,
        "no_speech_prob": 0.10520114004611969,
        "seek": 438436,
        "start": 4394.36,
        "temperature": 0,
        "text": " Stay tuned in the future.",
        "tokens": [
          50864,
          8691,
          10870,
          294,
          264,
          2027,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.21198996084707755,
        "compression_ratio": 1.5873015873015872,
        "end": 4406.36,
        "id": 1307,
        "no_speech_prob": 0.10520114004611969,
        "seek": 438436,
        "start": 4396.36,
        "temperature": 0,
        "text": " But, I think this is a good case where my video series, the sort of module for my programming from A to Z class, or the program with text class, building an API with Node and Express.",
        "tokens": [
          50964,
          583,
          11,
          286,
          519,
          341,
          307,
          257,
          665,
          1389,
          689,
          452,
          960,
          2638,
          11,
          264,
          1333,
          295,
          10088,
          337,
          452,
          9410,
          490,
          316,
          281,
          1176,
          1508,
          11,
          420,
          264,
          1461,
          365,
          2487,
          1508,
          11,
          2390,
          364,
          9362,
          365,
          38640,
          293,
          20212,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.21198996084707755,
        "compression_ratio": 1.5873015873015872,
        "end": 4408.36,
        "id": 1308,
        "no_speech_prob": 0.10520114004611969,
        "seek": 438436,
        "start": 4406.36,
        "temperature": 0,
        "text": " This is a case where I've got this.",
        "tokens": [
          51464,
          639,
          307,
          257,
          1389,
          689,
          286,
          600,
          658,
          341,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21198996084707755,
        "compression_ratio": 1.5873015873015872,
        "end": 4409.36,
        "id": 1309,
        "no_speech_prob": 0.10520114004611969,
        "seek": 438436,
        "start": 4408.36,
        "temperature": 0,
        "text": " What if I wanted to have every drawing?",
        "tokens": [
          51564,
          708,
          498,
          286,
          1415,
          281,
          362,
          633,
          6316,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.21198996084707755,
        "compression_ratio": 1.5873015873015872,
        "end": 4411.36,
        "id": 1310,
        "no_speech_prob": 0.10520114004611969,
        "seek": 438436,
        "start": 4409.36,
        "temperature": 0,
        "text": " Some of the, there's just millions of them.",
        "tokens": [
          51614,
          2188,
          295,
          264,
          11,
          456,
          311,
          445,
          6803,
          295,
          552,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.15919281618438497,
        "compression_ratio": 1.6823899371069182,
        "end": 4416.36,
        "id": 1311,
        "no_speech_prob": 0.16024655103683472,
        "seek": 441136,
        "start": 4411.36,
        "temperature": 0,
        "text": " I don't want to load hundreds of megabytes and gigabytes of files in my client-side JavaScript.",
        "tokens": [
          50364,
          286,
          500,
          380,
          528,
          281,
          3677,
          6779,
          295,
          10816,
          24538,
          293,
          42741,
          295,
          7098,
          294,
          452,
          6423,
          12,
          1812,
          15778,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.15919281618438497,
        "compression_ratio": 1.6823899371069182,
        "end": 4421.36,
        "id": 1312,
        "no_speech_prob": 0.16024655103683472,
        "seek": 441136,
        "start": 4416.36,
        "temperature": 0,
        "text": " I could write a little Node program whose sole purpose is to hold on to all that data.",
        "tokens": [
          50614,
          286,
          727,
          2464,
          257,
          707,
          38640,
          1461,
          6104,
          12321,
          4334,
          307,
          281,
          1797,
          322,
          281,
          439,
          300,
          1412,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.15919281618438497,
        "compression_ratio": 1.6823899371069182,
        "end": 4424.36,
        "id": 1313,
        "no_speech_prob": 0.16024655103683472,
        "seek": 441136,
        "start": 4421.36,
        "temperature": 0,
        "text": " And, my client-side JavaScript could just request it.",
        "tokens": [
          50864,
          400,
          11,
          452,
          6423,
          12,
          1812,
          15778,
          727,
          445,
          5308,
          309,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.15919281618438497,
        "compression_ratio": 1.6823899371069182,
        "end": 4430.36,
        "id": 1314,
        "no_speech_prob": 0.16024655103683472,
        "seek": 441136,
        "start": 4424.36,
        "temperature": 0,
        "text": " So, this could be because what I want to do is create an API out in the world for people to get drawing information.",
        "tokens": [
          51014,
          407,
          11,
          341,
          727,
          312,
          570,
          437,
          286,
          528,
          281,
          360,
          307,
          1884,
          364,
          9362,
          484,
          294,
          264,
          1002,
          337,
          561,
          281,
          483,
          6316,
          1589,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.15919281618438497,
        "compression_ratio": 1.6823899371069182,
        "end": 4433.36,
        "id": 1315,
        "no_speech_prob": 0.16024655103683472,
        "seek": 441136,
        "start": 4430.36,
        "temperature": 0,
        "text": " But, this isn't data that I own in a way that I would necessarily do that.",
        "tokens": [
          51314,
          583,
          11,
          341,
          1943,
          380,
          1412,
          300,
          286,
          1065,
          294,
          257,
          636,
          300,
          286,
          576,
          4725,
          360,
          300,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.15919281618438497,
        "compression_ratio": 1.6823899371069182,
        "end": 4437.36,
        "id": 1316,
        "no_speech_prob": 0.16024655103683472,
        "seek": 441136,
        "start": 4433.36,
        "temperature": 0,
        "text": " We'd have to look at the licensing to see if that's even something reasonable to do.",
        "tokens": [
          51464,
          492,
          1116,
          362,
          281,
          574,
          412,
          264,
          29759,
          281,
          536,
          498,
          300,
          311,
          754,
          746,
          10585,
          281,
          360,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.15919281618438497,
        "compression_ratio": 1.6823899371069182,
        "end": 4439.36,
        "id": 1317,
        "no_speech_prob": 0.16024655103683472,
        "seek": 441136,
        "start": 4437.36,
        "temperature": 0,
        "text": " Where is that eraser?",
        "tokens": [
          51664,
          2305,
          307,
          300,
          46018,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.20143666474715524,
        "compression_ratio": 1.7808219178082192,
        "end": 4449.36,
        "id": 1318,
        "no_speech_prob": 0.0005527653847821057,
        "seek": 443936,
        "start": 4439.36,
        "temperature": 0,
        "text": " But, what I can do is on my computer here, the idea here is like, oh, I'm going to make a server.",
        "tokens": [
          50364,
          583,
          11,
          437,
          286,
          393,
          360,
          307,
          322,
          452,
          3820,
          510,
          11,
          264,
          1558,
          510,
          307,
          411,
          11,
          1954,
          11,
          286,
          478,
          516,
          281,
          652,
          257,
          7154,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20143666474715524,
        "compression_ratio": 1.7808219178082192,
        "end": 4453.36,
        "id": 1319,
        "no_speech_prob": 0.0005527653847821057,
        "seek": 443936,
        "start": 4449.36,
        "temperature": 0,
        "text": " And, the server is going to hold all of the drawings.",
        "tokens": [
          50864,
          400,
          11,
          264,
          7154,
          307,
          516,
          281,
          1797,
          439,
          295,
          264,
          18618,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.20143666474715524,
        "compression_ratio": 1.7808219178082192,
        "end": 4459.36,
        "id": 1320,
        "no_speech_prob": 0.0005527653847821057,
        "seek": 443936,
        "start": 4453.36,
        "temperature": 0,
        "text": " And, then my P5 sketch can just say, hey, can make a request, like a get request.",
        "tokens": [
          51064,
          400,
          11,
          550,
          452,
          430,
          20,
          12325,
          393,
          445,
          584,
          11,
          4177,
          11,
          393,
          652,
          257,
          5308,
          11,
          411,
          257,
          483,
          5308,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20143666474715524,
        "compression_ratio": 1.7808219178082192,
        "end": 4461.36,
        "id": 1321,
        "no_speech_prob": 0.0005527653847821057,
        "seek": 443936,
        "start": 4459.36,
        "temperature": 0,
        "text": " Please, could I have a rainbow?",
        "tokens": [
          51364,
          2555,
          11,
          727,
          286,
          362,
          257,
          18526,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.20143666474715524,
        "compression_ratio": 1.7808219178082192,
        "end": 4465.36,
        "id": 1322,
        "no_speech_prob": 0.0005527653847821057,
        "seek": 443936,
        "start": 4461.36,
        "temperature": 0,
        "text": " And, then the server is going to send back just a single drawing.",
        "tokens": [
          51464,
          400,
          11,
          550,
          264,
          7154,
          307,
          516,
          281,
          2845,
          646,
          445,
          257,
          2167,
          6316,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20143666474715524,
        "compression_ratio": 1.7808219178082192,
        "end": 4467.36,
        "id": 1323,
        "no_speech_prob": 0.0005527653847821057,
        "seek": 443936,
        "start": 4465.36,
        "temperature": 0,
        "text": " It's not going to send back hundreds of megabytes of data.",
        "tokens": [
          51664,
          467,
          311,
          406,
          516,
          281,
          2845,
          646,
          6779,
          295,
          10816,
          24538,
          295,
          1412,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1947061997051387,
        "compression_ratio": 1.7097902097902098,
        "end": 4470.36,
        "id": 1324,
        "no_speech_prob": 0.009708312340080738,
        "seek": 446736,
        "start": 4467.36,
        "temperature": 0,
        "text": " It's storing all that data, but it's going to send back just one piece.",
        "tokens": [
          50364,
          467,
          311,
          26085,
          439,
          300,
          1412,
          11,
          457,
          309,
          311,
          516,
          281,
          2845,
          646,
          445,
          472,
          2522,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1947061997051387,
        "compression_ratio": 1.7097902097902098,
        "end": 4474.36,
        "id": 1325,
        "no_speech_prob": 0.009708312340080738,
        "seek": 446736,
        "start": 4470.36,
        "temperature": 0,
        "text": " The interesting thing is this server can easily just also run on the laptop.",
        "tokens": [
          50514,
          440,
          1880,
          551,
          307,
          341,
          7154,
          393,
          3612,
          445,
          611,
          1190,
          322,
          264,
          10732,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1947061997051387,
        "compression_ratio": 1.7097902097902098,
        "end": 4476.36,
        "id": 1326,
        "no_speech_prob": 0.009708312340080738,
        "seek": 446736,
        "start": 4474.36,
        "temperature": 0,
        "text": " So, and I could connect to it.",
        "tokens": [
          50714,
          407,
          11,
          293,
          286,
          727,
          1745,
          281,
          309,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1947061997051387,
        "compression_ratio": 1.7097902097902098,
        "end": 4480.36,
        "id": 1327,
        "no_speech_prob": 0.009708312340080738,
        "seek": 446736,
        "start": 4476.36,
        "temperature": 0,
        "text": " So, there's a variety of ways you could deploy this and use this, but I'm going to do it all from this laptop.",
        "tokens": [
          50814,
          407,
          11,
          456,
          311,
          257,
          5673,
          295,
          2098,
          291,
          727,
          7274,
          341,
          293,
          764,
          341,
          11,
          457,
          286,
          478,
          516,
          281,
          360,
          309,
          439,
          490,
          341,
          10732,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1947061997051387,
        "compression_ratio": 1.7097902097902098,
        "end": 4486.36,
        "id": 1328,
        "no_speech_prob": 0.009708312340080738,
        "seek": 446736,
        "start": 4480.36,
        "temperature": 0,
        "text": " Alright, so to run a server with Node and Express, you can go back and watch some of these videos where I step through this in more detail.",
        "tokens": [
          51014,
          2798,
          11,
          370,
          281,
          1190,
          257,
          7154,
          365,
          38640,
          293,
          20212,
          11,
          291,
          393,
          352,
          646,
          293,
          1159,
          512,
          295,
          613,
          2145,
          689,
          286,
          1823,
          807,
          341,
          294,
          544,
          2607,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1947061997051387,
        "compression_ratio": 1.7097902097902098,
        "end": 4490.36,
        "id": 1329,
        "no_speech_prob": 0.009708312340080738,
        "seek": 446736,
        "start": 4486.36,
        "temperature": 0,
        "text": " I'm just going to start it in the directory in my console.",
        "tokens": [
          51314,
          286,
          478,
          445,
          516,
          281,
          722,
          309,
          294,
          264,
          21120,
          294,
          452,
          11076,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19547880554199218,
        "compression_ratio": 1.6791666666666667,
        "end": 4498.36,
        "id": 1330,
        "no_speech_prob": 0.3039971590042114,
        "seek": 449036,
        "start": 4490.36,
        "temperature": 0,
        "text": " And, I'm going to say npm init, and I'm going to call this a coding train quick draw example.",
        "tokens": [
          50364,
          400,
          11,
          286,
          478,
          516,
          281,
          584,
          297,
          14395,
          3157,
          11,
          293,
          286,
          478,
          516,
          281,
          818,
          341,
          257,
          17720,
          3847,
          1702,
          2642,
          1365,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19547880554199218,
        "compression_ratio": 1.6791666666666667,
        "end": 4501.36,
        "id": 1331,
        "no_speech_prob": 0.3039971590042114,
        "seek": 449036,
        "start": 4498.36,
        "temperature": 0,
        "text": " And, it's version 0.0.1.",
        "tokens": [
          50764,
          400,
          11,
          309,
          311,
          3037,
          1958,
          13,
          15,
          13,
          16,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19547880554199218,
        "compression_ratio": 1.6791666666666667,
        "end": 4506.36,
        "id": 1332,
        "no_speech_prob": 0.3039971590042114,
        "seek": 449036,
        "start": 4501.36,
        "temperature": 0,
        "text": " It is an example that I am making on the coding train.",
        "tokens": [
          50914,
          467,
          307,
          364,
          1365,
          300,
          286,
          669,
          1455,
          322,
          264,
          17720,
          3847,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19547880554199218,
        "compression_ratio": 1.6791666666666667,
        "end": 4508.36,
        "id": 1333,
        "no_speech_prob": 0.3039971590042114,
        "seek": 449036,
        "start": 4506.36,
        "temperature": 0,
        "text": " And, you know, whatever. I'm going to skip through a lot of this stuff.",
        "tokens": [
          51164,
          400,
          11,
          291,
          458,
          11,
          2035,
          13,
          286,
          478,
          516,
          281,
          10023,
          807,
          257,
          688,
          295,
          341,
          1507,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19547880554199218,
        "compression_ratio": 1.6791666666666667,
        "end": 4509.36,
        "id": 1334,
        "no_speech_prob": 0.3039971590042114,
        "seek": 449036,
        "start": 4508.36,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          51264,
          1079,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19547880554199218,
        "compression_ratio": 1.6791666666666667,
        "end": 4515.36,
        "id": 1335,
        "no_speech_prob": 0.3039971590042114,
        "seek": 449036,
        "start": 4509.36,
        "temperature": 0,
        "text": " Okay, so now if I go to my code, you can actually see I have this package.json file.",
        "tokens": [
          51314,
          1033,
          11,
          370,
          586,
          498,
          286,
          352,
          281,
          452,
          3089,
          11,
          291,
          393,
          767,
          536,
          286,
          362,
          341,
          7372,
          13,
          73,
          3015,
          3991,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19547880554199218,
        "compression_ratio": 1.6791666666666667,
        "end": 4519.36,
        "id": 1336,
        "no_speech_prob": 0.3039971590042114,
        "seek": 449036,
        "start": 4515.36,
        "temperature": 0,
        "text": " The package.json file has all that information that I just entered.",
        "tokens": [
          51614,
          440,
          7372,
          13,
          73,
          3015,
          3991,
          575,
          439,
          300,
          1589,
          300,
          286,
          445,
          9065,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1950937368101993,
        "compression_ratio": 1.7161572052401746,
        "end": 4522.36,
        "id": 1337,
        "no_speech_prob": 0.003884422592818737,
        "seek": 451936,
        "start": 4519.36,
        "temperature": 0,
        "text": " This is the configuration file for my project.",
        "tokens": [
          50364,
          639,
          307,
          264,
          11694,
          3991,
          337,
          452,
          1716,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1950937368101993,
        "compression_ratio": 1.7161572052401746,
        "end": 4525.36,
        "id": 1338,
        "no_speech_prob": 0.003884422592818737,
        "seek": 451936,
        "start": 4522.36,
        "temperature": 0,
        "text": " Node is the sort of central manager of this project now.",
        "tokens": [
          50514,
          38640,
          307,
          264,
          1333,
          295,
          5777,
          6598,
          295,
          341,
          1716,
          586,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1950937368101993,
        "compression_ratio": 1.7161572052401746,
        "end": 4529.36,
        "id": 1339,
        "no_speech_prob": 0.003884422592818737,
        "seek": 451936,
        "start": 4525.36,
        "temperature": 0,
        "text": " So, I need a couple Node packages to be able to make this work.",
        "tokens": [
          50664,
          407,
          11,
          286,
          643,
          257,
          1916,
          38640,
          17401,
          281,
          312,
          1075,
          281,
          652,
          341,
          589,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1950937368101993,
        "compression_ratio": 1.7161572052401746,
        "end": 4531.36,
        "id": 1340,
        "no_speech_prob": 0.003884422592818737,
        "seek": 451936,
        "start": 4529.36,
        "temperature": 0,
        "text": " I need to use Express.",
        "tokens": [
          50864,
          286,
          643,
          281,
          764,
          20212,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1950937368101993,
        "compression_ratio": 1.7161572052401746,
        "end": 4537.36,
        "id": 1341,
        "no_speech_prob": 0.003884422592818737,
        "seek": 451936,
        "start": 4531.36,
        "temperature": 0,
        "text": " Express is what I'm going to use to handle that get request, this HTTP get request.",
        "tokens": [
          50964,
          20212,
          307,
          437,
          286,
          478,
          516,
          281,
          764,
          281,
          4813,
          300,
          483,
          5308,
          11,
          341,
          33283,
          483,
          5308,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1950937368101993,
        "compression_ratio": 1.7161572052401746,
        "end": 4540.36,
        "id": 1342,
        "no_speech_prob": 0.003884422592818737,
        "seek": 451936,
        "start": 4537.36,
        "temperature": 0,
        "text": " So, I'm going to say npm install express.",
        "tokens": [
          51264,
          407,
          11,
          286,
          478,
          516,
          281,
          584,
          297,
          14395,
          3625,
          5109,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1950937368101993,
        "compression_ratio": 1.7161572052401746,
        "end": 4544.36,
        "id": 1343,
        "no_speech_prob": 0.003884422592818737,
        "seek": 451936,
        "start": 4540.36,
        "temperature": 0,
        "text": " And, then I also need something to load that nd.json file.",
        "tokens": [
          51414,
          400,
          11,
          550,
          286,
          611,
          643,
          746,
          281,
          3677,
          300,
          220,
          273,
          13,
          73,
          3015,
          3991,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1950937368101993,
        "compression_ratio": 1.7161572052401746,
        "end": 4546.36,
        "id": 1344,
        "no_speech_prob": 0.003884422592818737,
        "seek": 451936,
        "start": 4544.36,
        "temperature": 0,
        "text": " So, nd.json Node.",
        "tokens": [
          51614,
          407,
          11,
          220,
          273,
          13,
          73,
          3015,
          38640,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.15966040651563188,
        "compression_ratio": 1.683982683982684,
        "end": 4549.36,
        "id": 1345,
        "no_speech_prob": 0.005301796365529299,
        "seek": 454636,
        "start": 4547.36,
        "temperature": 0,
        "text": " I've actually used this before.",
        "tokens": [
          50414,
          286,
          600,
          767,
          1143,
          341,
          949,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.15966040651563188,
        "compression_ratio": 1.683982683982684,
        "end": 4550.36,
        "id": 1346,
        "no_speech_prob": 0.005301796365529299,
        "seek": 454636,
        "start": 4549.36,
        "temperature": 0,
        "text": " But, let's look.",
        "tokens": [
          50514,
          583,
          11,
          718,
          311,
          574,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.15966040651563188,
        "compression_ratio": 1.683982683982684,
        "end": 4554.36,
        "id": 1347,
        "no_speech_prob": 0.005301796365529299,
        "seek": 454636,
        "start": 4550.36,
        "temperature": 0,
        "text": " So, this is a Node package for loading an nd.json file.",
        "tokens": [
          50564,
          407,
          11,
          341,
          307,
          257,
          38640,
          7372,
          337,
          15114,
          364,
          220,
          273,
          13,
          73,
          3015,
          3991,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.15966040651563188,
        "compression_ratio": 1.683982683982684,
        "end": 4558.36,
        "id": 1348,
        "no_speech_prob": 0.005301796365529299,
        "seek": 454636,
        "start": 4554.36,
        "temperature": 0,
        "text": " So, I'm going to say npm install nd.json.",
        "tokens": [
          50764,
          407,
          11,
          286,
          478,
          516,
          281,
          584,
          297,
          14395,
          3625,
          220,
          273,
          13,
          73,
          3015,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.15966040651563188,
        "compression_ratio": 1.683982683982684,
        "end": 4560.36,
        "id": 1349,
        "no_speech_prob": 0.005301796365529299,
        "seek": 454636,
        "start": 4558.36,
        "temperature": 0,
        "text": " Great. There we go.",
        "tokens": [
          50964,
          3769,
          13,
          821,
          321,
          352,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.15966040651563188,
        "compression_ratio": 1.683982683982684,
        "end": 4563.36,
        "id": 1350,
        "no_speech_prob": 0.005301796365529299,
        "seek": 454636,
        "start": 4560.36,
        "temperature": 0,
        "text": " And, now I meant to show you what is that nd.json.",
        "tokens": [
          51064,
          400,
          11,
          586,
          286,
          4140,
          281,
          855,
          291,
          437,
          307,
          300,
          220,
          273,
          13,
          73,
          3015,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.15966040651563188,
        "compression_ratio": 1.683982683982684,
        "end": 4566.36,
        "id": 1351,
        "no_speech_prob": 0.005301796365529299,
        "seek": 454636,
        "start": 4563.36,
        "temperature": 0,
        "text": " Oh, I got to grab that file now.",
        "tokens": [
          51214,
          876,
          11,
          286,
          658,
          281,
          4444,
          300,
          3991,
          586,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.15966040651563188,
        "compression_ratio": 1.683982683982684,
        "end": 4570.36,
        "id": 1352,
        "no_speech_prob": 0.005301796365529299,
        "seek": 454636,
        "start": 4566.36,
        "temperature": 0,
        "text": " So, I also need, I'm just going to rename this to rainbow.nd.json.",
        "tokens": [
          51364,
          407,
          11,
          286,
          611,
          643,
          11,
          286,
          478,
          445,
          516,
          281,
          36741,
          341,
          281,
          18526,
          13,
          273,
          13,
          73,
          3015,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.15966040651563188,
        "compression_ratio": 1.683982683982684,
        "end": 4573.36,
        "id": 1353,
        "no_speech_prob": 0.005301796365529299,
        "seek": 454636,
        "start": 4570.36,
        "temperature": 0,
        "text": " I'm going to drag it here into my project.",
        "tokens": [
          51564,
          286,
          478,
          516,
          281,
          5286,
          309,
          510,
          666,
          452,
          1716,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.15966040651563188,
        "compression_ratio": 1.683982683982684,
        "end": 4575.36,
        "id": 1354,
        "no_speech_prob": 0.005301796365529299,
        "seek": 454636,
        "start": 4573.36,
        "temperature": 0,
        "text": " So, now this is a huge file.",
        "tokens": [
          51714,
          407,
          11,
          586,
          341,
          307,
          257,
          2603,
          3991,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2003463777173467,
        "compression_ratio": 1.6875,
        "end": 4578.36,
        "id": 1355,
        "no_speech_prob": 0.0008040809188969433,
        "seek": 457536,
        "start": 4575.36,
        "temperature": 0,
        "text": " And, so you can see that Visual Studio Code is like freaking out.",
        "tokens": [
          50364,
          400,
          11,
          370,
          291,
          393,
          536,
          300,
          23187,
          13500,
          15549,
          307,
          411,
          14612,
          484,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2003463777173467,
        "compression_ratio": 1.6875,
        "end": 4583.36,
        "id": 1356,
        "no_speech_prob": 0.0008040809188969433,
        "seek": 457536,
        "start": 4578.36,
        "temperature": 0,
        "text": " It's like I don't want to deal with this file because it's too big.",
        "tokens": [
          50514,
          467,
          311,
          411,
          286,
          500,
          380,
          528,
          281,
          2028,
          365,
          341,
          3991,
          570,
          309,
          311,
          886,
          955,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2003463777173467,
        "compression_ratio": 1.6875,
        "end": 4590.36,
        "id": 1357,
        "no_speech_prob": 0.0008040809188969433,
        "seek": 457536,
        "start": 4583.36,
        "temperature": 0,
        "text": " But, you can see that what this is, is every single drawing on one line.",
        "tokens": [
          50764,
          583,
          11,
          291,
          393,
          536,
          300,
          437,
          341,
          307,
          11,
          307,
          633,
          2167,
          6316,
          322,
          472,
          1622,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2003463777173467,
        "compression_ratio": 1.6875,
        "end": 4592.36,
        "id": 1358,
        "no_speech_prob": 0.0008040809188969433,
        "seek": 457536,
        "start": 4590.36,
        "temperature": 0,
        "text": " So, it's like this is my database, essentially.",
        "tokens": [
          51114,
          407,
          11,
          309,
          311,
          411,
          341,
          307,
          452,
          8149,
          11,
          4476,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2003463777173467,
        "compression_ratio": 1.6875,
        "end": 4594.36,
        "id": 1359,
        "no_speech_prob": 0.0008040809188969433,
        "seek": 457536,
        "start": 4592.36,
        "temperature": 0,
        "text": " Database of rainbow drawings.",
        "tokens": [
          51214,
          40461,
          651,
          295,
          18526,
          18618,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2003463777173467,
        "compression_ratio": 1.6875,
        "end": 4596.36,
        "id": 1360,
        "no_speech_prob": 0.0008040809188969433,
        "seek": 457536,
        "start": 4594.36,
        "temperature": 0,
        "text": " I have a database of rainbow drawings.",
        "tokens": [
          51314,
          286,
          362,
          257,
          8149,
          295,
          18526,
          18618,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2003463777173467,
        "compression_ratio": 1.6875,
        "end": 4598.36,
        "id": 1361,
        "no_speech_prob": 0.0008040809188969433,
        "seek": 457536,
        "start": 4596.36,
        "temperature": 0,
        "text": " What could be better?",
        "tokens": [
          51414,
          708,
          727,
          312,
          1101,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.2003463777173467,
        "compression_ratio": 1.6875,
        "end": 4600.36,
        "id": 1362,
        "no_speech_prob": 0.0008040809188969433,
        "seek": 457536,
        "start": 4598.36,
        "temperature": 0,
        "text": " Okay. So, what was I doing?",
        "tokens": [
          51514,
          1033,
          13,
          407,
          11,
          437,
          390,
          286,
          884,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.2003463777173467,
        "compression_ratio": 1.6875,
        "end": 4603.36,
        "id": 1363,
        "no_speech_prob": 0.0008040809188969433,
        "seek": 457536,
        "start": 4600.36,
        "temperature": 0,
        "text": " Back to the code in the server.",
        "tokens": [
          51614,
          5833,
          281,
          264,
          3089,
          294,
          264,
          7154,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.15869099459202168,
        "compression_ratio": 1.8149779735682818,
        "end": 4606.36,
        "id": 1364,
        "no_speech_prob": 0.003945371601730585,
        "seek": 460336,
        "start": 4604.36,
        "temperature": 0,
        "text": " Oh, I don't have a server yet.",
        "tokens": [
          50414,
          876,
          11,
          286,
          500,
          380,
          362,
          257,
          7154,
          1939,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.15869099459202168,
        "compression_ratio": 1.8149779735682818,
        "end": 4607.36,
        "id": 1365,
        "no_speech_prob": 0.003945371601730585,
        "seek": 460336,
        "start": 4606.36,
        "temperature": 0,
        "text": " I'm going to add one.",
        "tokens": [
          50514,
          286,
          478,
          516,
          281,
          909,
          472,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.15869099459202168,
        "compression_ratio": 1.8149779735682818,
        "end": 4609.36,
        "id": 1366,
        "no_speech_prob": 0.003945371601730585,
        "seek": 460336,
        "start": 4607.36,
        "temperature": 0,
        "text": " I'm going to call it server.js.",
        "tokens": [
          50564,
          286,
          478,
          516,
          281,
          818,
          309,
          7154,
          13,
          25530,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.15869099459202168,
        "compression_ratio": 1.8149779735682818,
        "end": 4612.36,
        "id": 1367,
        "no_speech_prob": 0.003945371601730585,
        "seek": 460336,
        "start": 4609.36,
        "temperature": 0,
        "text": " I could call it app.js or index.js.",
        "tokens": [
          50664,
          286,
          727,
          818,
          309,
          724,
          13,
          25530,
          420,
          8186,
          13,
          25530,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.15869099459202168,
        "compression_ratio": 1.8149779735682818,
        "end": 4615.36,
        "id": 1368,
        "no_speech_prob": 0.003945371601730585,
        "seek": 460336,
        "start": 4612.36,
        "temperature": 0,
        "text": " And, here I'm going to go back to this.",
        "tokens": [
          50814,
          400,
          11,
          510,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          341,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.15869099459202168,
        "compression_ratio": 1.8149779735682818,
        "end": 4617.36,
        "id": 1369,
        "no_speech_prob": 0.003945371601730585,
        "seek": 460336,
        "start": 4615.36,
        "temperature": 0,
        "text": " And, basically, I just want to do exactly this.",
        "tokens": [
          50964,
          400,
          11,
          1936,
          11,
          286,
          445,
          528,
          281,
          360,
          2293,
          341,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.15869099459202168,
        "compression_ratio": 1.8149779735682818,
        "end": 4621.36,
        "id": 1370,
        "no_speech_prob": 0.003945371601730585,
        "seek": 460336,
        "start": 4617.36,
        "temperature": 0,
        "text": " So, the first thing, I want to use this.",
        "tokens": [
          51064,
          407,
          11,
          264,
          700,
          551,
          11,
          286,
          528,
          281,
          764,
          341,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.15869099459202168,
        "compression_ratio": 1.8149779735682818,
        "end": 4624.36,
        "id": 1371,
        "no_speech_prob": 0.003945371601730585,
        "seek": 460336,
        "start": 4621.36,
        "temperature": 0,
        "text": " I need the file system module.",
        "tokens": [
          51264,
          286,
          643,
          264,
          3991,
          1185,
          10088,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.15869099459202168,
        "compression_ratio": 1.8149779735682818,
        "end": 4627.36,
        "id": 1372,
        "no_speech_prob": 0.003945371601730585,
        "seek": 460336,
        "start": 4624.36,
        "temperature": 0,
        "text": " So, I'm going to say const fs equals require file system.",
        "tokens": [
          51414,
          407,
          11,
          286,
          478,
          516,
          281,
          584,
          1817,
          283,
          82,
          6915,
          3651,
          3991,
          1185,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.15869099459202168,
        "compression_ratio": 1.8149779735682818,
        "end": 4630.36,
        "id": 1373,
        "no_speech_prob": 0.003945371601730585,
        "seek": 460336,
        "start": 4627.36,
        "temperature": 0,
        "text": " File system is a module that comes with Node.",
        "tokens": [
          51564,
          26196,
          1185,
          307,
          257,
          10088,
          300,
          1487,
          365,
          38640,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.15869099459202168,
        "compression_ratio": 1.8149779735682818,
        "end": 4632.36,
        "id": 1374,
        "no_speech_prob": 0.003945371601730585,
        "seek": 460336,
        "start": 4630.36,
        "temperature": 0,
        "text": " I don't have to install it.",
        "tokens": [
          51714,
          286,
          500,
          380,
          362,
          281,
          3625,
          309,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.22528390742059964,
        "compression_ratio": 1.6106194690265487,
        "end": 4637.36,
        "id": 1375,
        "no_speech_prob": 0.0000231874619203154,
        "seek": 463236,
        "start": 4632.36,
        "temperature": 0,
        "text": " But, I also want the nd.json module.",
        "tokens": [
          50364,
          583,
          11,
          286,
          611,
          528,
          264,
          220,
          273,
          13,
          73,
          3015,
          10088,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.22528390742059964,
        "compression_ratio": 1.6106194690265487,
        "end": 4641.36,
        "id": 1376,
        "no_speech_prob": 0.0000231874619203154,
        "seek": 463236,
        "start": 4637.36,
        "temperature": 0,
        "text": " Which, it doesn't come with Node, but I added it.",
        "tokens": [
          50614,
          3013,
          11,
          309,
          1177,
          380,
          808,
          365,
          38640,
          11,
          457,
          286,
          3869,
          309,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.22528390742059964,
        "compression_ratio": 1.6106194690265487,
        "end": 4644.36,
        "id": 1377,
        "no_speech_prob": 0.0000231874619203154,
        "seek": 463236,
        "start": 4641.36,
        "temperature": 0,
        "text": " And, here we go.",
        "tokens": [
          50814,
          400,
          11,
          510,
          321,
          352,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.22528390742059964,
        "compression_ratio": 1.6106194690265487,
        "end": 4647.36,
        "id": 1378,
        "no_speech_prob": 0.0000231874619203154,
        "seek": 463236,
        "start": 4644.36,
        "temperature": 0,
        "text": " And, we can see, by the way, that when I installed those,",
        "tokens": [
          50964,
          400,
          11,
          321,
          393,
          536,
          11,
          538,
          264,
          636,
          11,
          300,
          562,
          286,
          8899,
          729,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.22528390742059964,
        "compression_ratio": 1.6106194690265487,
        "end": 4650.36,
        "id": 1379,
        "no_speech_prob": 0.0000231874619203154,
        "seek": 463236,
        "start": 4647.36,
        "temperature": 0,
        "text": " they are now dependencies in the package.json file.",
        "tokens": [
          51114,
          436,
          366,
          586,
          36606,
          294,
          264,
          7372,
          13,
          73,
          3015,
          3991,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.22528390742059964,
        "compression_ratio": 1.6106194690265487,
        "end": 4653.36,
        "id": 1380,
        "no_speech_prob": 0.0000231874619203154,
        "seek": 463236,
        "start": 4650.36,
        "temperature": 0,
        "text": " And, now, do, do, do, do, do.",
        "tokens": [
          51264,
          400,
          11,
          586,
          11,
          360,
          11,
          360,
          11,
          360,
          11,
          360,
          11,
          360,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.22528390742059964,
        "compression_ratio": 1.6106194690265487,
        "end": 4654.36,
        "id": 1381,
        "no_speech_prob": 0.0000231874619203154,
        "seek": 463236,
        "start": 4653.36,
        "temperature": 0,
        "text": " Ah, there we go.",
        "tokens": [
          51414,
          2438,
          11,
          456,
          321,
          352,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.22528390742059964,
        "compression_ratio": 1.6106194690265487,
        "end": 4656.36,
        "id": 1382,
        "no_speech_prob": 0.0000231874619203154,
        "seek": 463236,
        "start": 4654.36,
        "temperature": 0,
        "text": " Now, this is, so what is this doing?",
        "tokens": [
          51464,
          823,
          11,
          341,
          307,
          11,
          370,
          437,
          307,
          341,
          884,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.22528390742059964,
        "compression_ratio": 1.6106194690265487,
        "end": 4657.36,
        "id": 1383,
        "no_speech_prob": 0.0000231874619203154,
        "seek": 463236,
        "start": 4656.36,
        "temperature": 0,
        "text": " This is streaming it.",
        "tokens": [
          51564,
          639,
          307,
          11791,
          309,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.22528390742059964,
        "compression_ratio": 1.6106194690265487,
        "end": 4659.36,
        "id": 1384,
        "no_speech_prob": 0.0000231874619203154,
        "seek": 463236,
        "start": 4657.36,
        "temperature": 0,
        "text": " So, this is really useful.",
        "tokens": [
          51614,
          407,
          11,
          341,
          307,
          534,
          4420,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.22528390742059964,
        "compression_ratio": 1.6106194690265487,
        "end": 4660.36,
        "id": 1385,
        "no_speech_prob": 0.0000231874619203154,
        "seek": 463236,
        "start": 4659.36,
        "temperature": 0,
        "text": " It's a huge file.",
        "tokens": [
          51714,
          467,
          311,
          257,
          2603,
          3991,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1852391242980957,
        "compression_ratio": 1.757936507936508,
        "end": 4663.36,
        "id": 1386,
        "no_speech_prob": 0.049586087465286255,
        "seek": 466036,
        "start": 4660.36,
        "temperature": 0,
        "text": " Rainbow.nd.json.",
        "tokens": [
          50364,
          29477,
          13,
          273,
          13,
          73,
          3015,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1852391242980957,
        "compression_ratio": 1.757936507936508,
        "end": 4667.36,
        "id": 1387,
        "no_speech_prob": 0.049586087465286255,
        "seek": 466036,
        "start": 4663.36,
        "temperature": 0,
        "text": " I certainly could load it, just using, loading the file into a big string,",
        "tokens": [
          50514,
          286,
          3297,
          727,
          3677,
          309,
          11,
          445,
          1228,
          11,
          15114,
          264,
          3991,
          666,
          257,
          955,
          6798,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.1852391242980957,
        "compression_ratio": 1.757936507936508,
        "end": 4669.36,
        "id": 1388,
        "no_speech_prob": 0.049586087465286255,
        "seek": 466036,
        "start": 4667.36,
        "temperature": 0,
        "text": " chopping it up and parsing it.",
        "tokens": [
          50714,
          35205,
          309,
          493,
          293,
          21156,
          278,
          309,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1852391242980957,
        "compression_ratio": 1.757936507936508,
        "end": 4671.36,
        "id": 1389,
        "no_speech_prob": 0.049586087465286255,
        "seek": 466036,
        "start": 4669.36,
        "temperature": 0,
        "text": " But, when you have a big file, like an nd.json file,",
        "tokens": [
          50814,
          583,
          11,
          562,
          291,
          362,
          257,
          955,
          3991,
          11,
          411,
          364,
          220,
          273,
          13,
          73,
          3015,
          3991,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.1852391242980957,
        "compression_ratio": 1.757936507936508,
        "end": 4674.36,
        "id": 1390,
        "no_speech_prob": 0.049586087465286255,
        "seek": 466036,
        "start": 4671.36,
        "temperature": 0,
        "text": " you want to read it as a stream, essentially one line at a time.",
        "tokens": [
          50914,
          291,
          528,
          281,
          1401,
          309,
          382,
          257,
          4309,
          11,
          4476,
          472,
          1622,
          412,
          257,
          565,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1852391242980957,
        "compression_ratio": 1.757936507936508,
        "end": 4676.36,
        "id": 1391,
        "no_speech_prob": 0.049586087465286255,
        "seek": 466036,
        "start": 4674.36,
        "temperature": 0,
        "text": " Because, it could be like a gigabyte file.",
        "tokens": [
          51064,
          1436,
          11,
          309,
          727,
          312,
          411,
          257,
          8741,
          34529,
          3991,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1852391242980957,
        "compression_ratio": 1.757936507936508,
        "end": 4678.36,
        "id": 1392,
        "no_speech_prob": 0.049586087465286255,
        "seek": 466036,
        "start": 4676.36,
        "temperature": 0,
        "text": " I'm not going to, in this case, I'm just going to say,",
        "tokens": [
          51164,
          286,
          478,
          406,
          516,
          281,
          11,
          294,
          341,
          1389,
          11,
          286,
          478,
          445,
          516,
          281,
          584,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.1852391242980957,
        "compression_ratio": 1.757936507936508,
        "end": 4681.36,
        "id": 1393,
        "no_speech_prob": 0.049586087465286255,
        "seek": 466036,
        "start": 4678.36,
        "temperature": 0,
        "text": " like I'm going to make an empty array.",
        "tokens": [
          51264,
          411,
          286,
          478,
          516,
          281,
          652,
          364,
          6707,
          10225,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1852391242980957,
        "compression_ratio": 1.757936507936508,
        "end": 4688.36,
        "id": 1394,
        "no_speech_prob": 0.049586087465286255,
        "seek": 466036,
        "start": 4681.36,
        "temperature": 0,
        "text": " And, every single object, I'm just going to push into that array.",
        "tokens": [
          51414,
          400,
          11,
          633,
          2167,
          2657,
          11,
          286,
          478,
          445,
          516,
          281,
          2944,
          666,
          300,
          10225,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.16518192542226692,
        "compression_ratio": 1.8436213991769548,
        "end": 4692.36,
        "id": 1395,
        "no_speech_prob": 0.001810200628824532,
        "seek": 468836,
        "start": 4688.36,
        "temperature": 0,
        "text": " But, let's console.log them, just to see that this is working.",
        "tokens": [
          50364,
          583,
          11,
          718,
          311,
          11076,
          13,
          4987,
          552,
          11,
          445,
          281,
          536,
          300,
          341,
          307,
          1364,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.16518192542226692,
        "compression_ratio": 1.8436213991769548,
        "end": 4694.36,
        "id": 1396,
        "no_speech_prob": 0.001810200628824532,
        "seek": 468836,
        "start": 4692.36,
        "temperature": 0,
        "text": " So, this is the stream.",
        "tokens": [
          50564,
          407,
          11,
          341,
          307,
          264,
          4309,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.16518192542226692,
        "compression_ratio": 1.8436213991769548,
        "end": 4698.36,
        "id": 1397,
        "no_speech_prob": 0.001810200628824532,
        "seek": 468836,
        "start": 4694.36,
        "temperature": 0,
        "text": " As it reads line by line by line, the nd.json file,",
        "tokens": [
          50664,
          1018,
          309,
          15700,
          1622,
          538,
          1622,
          538,
          1622,
          11,
          264,
          220,
          273,
          13,
          73,
          3015,
          3991,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.16518192542226692,
        "compression_ratio": 1.8436213991769548,
        "end": 4701.36,
        "id": 1398,
        "no_speech_prob": 0.001810200628824532,
        "seek": 468836,
        "start": 4698.36,
        "temperature": 0,
        "text": " it's going to console.log that object.",
        "tokens": [
          50864,
          309,
          311,
          516,
          281,
          11076,
          13,
          4987,
          300,
          2657,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.16518192542226692,
        "compression_ratio": 1.8436213991769548,
        "end": 4702.36,
        "id": 1399,
        "no_speech_prob": 0.001810200628824532,
        "seek": 468836,
        "start": 4701.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51014,
          1033,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.16518192542226692,
        "compression_ratio": 1.8436213991769548,
        "end": 4704.36,
        "id": 1400,
        "no_speech_prob": 0.001810200628824532,
        "seek": 468836,
        "start": 4702.36,
        "temperature": 0,
        "text": " So, let's go here.",
        "tokens": [
          51064,
          407,
          11,
          718,
          311,
          352,
          510,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.16518192542226692,
        "compression_ratio": 1.8436213991769548,
        "end": 4708.36,
        "id": 1401,
        "no_speech_prob": 0.001810200628824532,
        "seek": 468836,
        "start": 4704.36,
        "temperature": 0,
        "text": " And, I'm going to say, node server.js.",
        "tokens": [
          51164,
          400,
          11,
          286,
          478,
          516,
          281,
          584,
          11,
          9984,
          7154,
          13,
          25530,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.16518192542226692,
        "compression_ratio": 1.8436213991769548,
        "end": 4709.36,
        "id": 1402,
        "no_speech_prob": 0.001810200628824532,
        "seek": 468836,
        "start": 4708.36,
        "temperature": 0,
        "text": " And, there you go.",
        "tokens": [
          51364,
          400,
          11,
          456,
          291,
          352,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.16518192542226692,
        "compression_ratio": 1.8436213991769548,
        "end": 4710.36,
        "id": 1403,
        "no_speech_prob": 0.001810200628824532,
        "seek": 468836,
        "start": 4709.36,
        "temperature": 0,
        "text": " You can see, this is it.",
        "tokens": [
          51414,
          509,
          393,
          536,
          11,
          341,
          307,
          309,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.16518192542226692,
        "compression_ratio": 1.8436213991769548,
        "end": 4711.36,
        "id": 1404,
        "no_speech_prob": 0.001810200628824532,
        "seek": 468836,
        "start": 4710.36,
        "temperature": 0,
        "text": " This is every single drawing.",
        "tokens": [
          51464,
          639,
          307,
          633,
          2167,
          6316,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.16518192542226692,
        "compression_ratio": 1.8436213991769548,
        "end": 4713.36,
        "id": 1405,
        "no_speech_prob": 0.001810200628824532,
        "seek": 468836,
        "start": 4711.36,
        "temperature": 0,
        "text": " It's going to take quite a while,",
        "tokens": [
          51514,
          467,
          311,
          516,
          281,
          747,
          1596,
          257,
          1339,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.16518192542226692,
        "compression_ratio": 1.8436213991769548,
        "end": 4715.36,
        "id": 1406,
        "no_speech_prob": 0.001810200628824532,
        "seek": 468836,
        "start": 4713.36,
        "temperature": 0,
        "text": " because there's thousands and thousands and thousands of them.",
        "tokens": [
          51614,
          570,
          456,
          311,
          5383,
          293,
          5383,
          293,
          5383,
          295,
          552,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.16518192542226692,
        "compression_ratio": 1.8436213991769548,
        "end": 4717.36,
        "id": 1407,
        "no_speech_prob": 0.001810200628824532,
        "seek": 468836,
        "start": 4715.36,
        "temperature": 0,
        "text": " But, you can see, this is the word.",
        "tokens": [
          51714,
          583,
          11,
          291,
          393,
          536,
          11,
          341,
          307,
          264,
          1349,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1530312982224326,
        "compression_ratio": 1.6733067729083666,
        "end": 4718.36,
        "id": 1408,
        "no_speech_prob": 0.00035696974373422563,
        "seek": 471736,
        "start": 4717.36,
        "temperature": 0,
        "text": " This was the country code.",
        "tokens": [
          50364,
          639,
          390,
          264,
          1941,
          3089,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.1530312982224326,
        "compression_ratio": 1.6733067729083666,
        "end": 4719.36,
        "id": 1409,
        "no_speech_prob": 0.00035696974373422563,
        "seek": 471736,
        "start": 4718.36,
        "temperature": 0,
        "text": " This is whether it was recognized.",
        "tokens": [
          50414,
          639,
          307,
          1968,
          309,
          390,
          9823,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1530312982224326,
        "compression_ratio": 1.6733067729083666,
        "end": 4720.36,
        "id": 1410,
        "no_speech_prob": 0.00035696974373422563,
        "seek": 471736,
        "start": 4719.36,
        "temperature": 0,
        "text": " It has an ID.",
        "tokens": [
          50464,
          467,
          575,
          364,
          7348,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1530312982224326,
        "compression_ratio": 1.6733067729083666,
        "end": 4723.36,
        "id": 1411,
        "no_speech_prob": 0.00035696974373422563,
        "seek": 471736,
        "start": 4720.36,
        "temperature": 0,
        "text": " And, then the drawing is in these arrays, which aren't console logging,",
        "tokens": [
          50514,
          400,
          11,
          550,
          264,
          6316,
          307,
          294,
          613,
          41011,
          11,
          597,
          3212,
          380,
          11076,
          27991,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.1530312982224326,
        "compression_ratio": 1.6733067729083666,
        "end": 4724.36,
        "id": 1412,
        "no_speech_prob": 0.00035696974373422563,
        "seek": 471736,
        "start": 4723.36,
        "temperature": 0,
        "text": " but I can get access to them.",
        "tokens": [
          50664,
          457,
          286,
          393,
          483,
          2105,
          281,
          552,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1530312982224326,
        "compression_ratio": 1.6733067729083666,
        "end": 4725.36,
        "id": 1413,
        "no_speech_prob": 0.00035696974373422563,
        "seek": 471736,
        "start": 4724.36,
        "temperature": 0,
        "text": " Wonderful.",
        "tokens": [
          50714,
          22768,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1530312982224326,
        "compression_ratio": 1.6733067729083666,
        "end": 4733.36,
        "id": 1414,
        "no_speech_prob": 0.00035696974373422563,
        "seek": 471736,
        "start": 4725.36,
        "temperature": 0,
        "text": " So, I now have an array that has every single drawing in it.",
        "tokens": [
          50764,
          407,
          11,
          286,
          586,
          362,
          364,
          10225,
          300,
          575,
          633,
          2167,
          6316,
          294,
          309,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1530312982224326,
        "compression_ratio": 1.6733067729083666,
        "end": 4736.36,
        "id": 1415,
        "no_speech_prob": 0.00035696974373422563,
        "seek": 471736,
        "start": 4733.36,
        "temperature": 0,
        "text": " Now, how do I get access to that?",
        "tokens": [
          51164,
          823,
          11,
          577,
          360,
          286,
          483,
          2105,
          281,
          300,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.1530312982224326,
        "compression_ratio": 1.6733067729083666,
        "end": 4740.36,
        "id": 1416,
        "no_speech_prob": 0.00035696974373422563,
        "seek": 471736,
        "start": 4736.36,
        "temperature": 0,
        "text": " I need to be able to make a get request to the server.",
        "tokens": [
          51314,
          286,
          643,
          281,
          312,
          1075,
          281,
          652,
          257,
          483,
          5308,
          281,
          264,
          7154,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1530312982224326,
        "compression_ratio": 1.6733067729083666,
        "end": 4742.36,
        "id": 1417,
        "no_speech_prob": 0.00035696974373422563,
        "seek": 471736,
        "start": 4740.36,
        "temperature": 0,
        "text": " So, let's see how we would do that.",
        "tokens": [
          51514,
          407,
          11,
          718,
          311,
          536,
          577,
          321,
          576,
          360,
          300,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1530312982224326,
        "compression_ratio": 1.6733067729083666,
        "end": 4746.36,
        "id": 1418,
        "no_speech_prob": 0.00035696974373422563,
        "seek": 471736,
        "start": 4742.36,
        "temperature": 0,
        "text": " So, I need to make an express server-y thing.",
        "tokens": [
          51614,
          407,
          11,
          286,
          643,
          281,
          652,
          364,
          5109,
          7154,
          12,
          88,
          551,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.18272106231205046,
        "compression_ratio": 1.7250996015936255,
        "end": 4754.36,
        "id": 1419,
        "no_speech_prob": 0.0001088967765099369,
        "seek": 474636,
        "start": 4746.36,
        "temperature": 0,
        "text": " Let's just look up express node and go to the kind of like quick getting started, hello world.",
        "tokens": [
          50364,
          961,
          311,
          445,
          574,
          493,
          5109,
          9984,
          293,
          352,
          281,
          264,
          733,
          295,
          411,
          1702,
          1242,
          1409,
          11,
          7751,
          1002,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.18272106231205046,
        "compression_ratio": 1.7250996015936255,
        "end": 4757.36,
        "id": 1420,
        "no_speech_prob": 0.0001088967765099369,
        "seek": 474636,
        "start": 4754.36,
        "temperature": 0,
        "text": " Like the hello world express example is all we need, basically.",
        "tokens": [
          50764,
          1743,
          264,
          7751,
          1002,
          5109,
          1365,
          307,
          439,
          321,
          643,
          11,
          1936,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.18272106231205046,
        "compression_ratio": 1.7250996015936255,
        "end": 4763.36,
        "id": 1421,
        "no_speech_prob": 0.0001088967765099369,
        "seek": 474636,
        "start": 4757.36,
        "temperature": 0,
        "text": " I'm going to grab all of this, and I'm going to put it into my code.",
        "tokens": [
          50914,
          286,
          478,
          516,
          281,
          4444,
          439,
          295,
          341,
          11,
          293,
          286,
          478,
          516,
          281,
          829,
          309,
          666,
          452,
          3089,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.18272106231205046,
        "compression_ratio": 1.7250996015936255,
        "end": 4764.36,
        "id": 1422,
        "no_speech_prob": 0.0001088967765099369,
        "seek": 474636,
        "start": 4763.36,
        "temperature": 0,
        "text": " So, what's going on?",
        "tokens": [
          51214,
          407,
          11,
          437,
          311,
          516,
          322,
          30,
          51264
        ]
      },
      {
        "avg_logprob": -0.18272106231205046,
        "compression_ratio": 1.7250996015936255,
        "end": 4767.36,
        "id": 1423,
        "no_speech_prob": 0.0001088967765099369,
        "seek": 474636,
        "start": 4764.36,
        "temperature": 0,
        "text": " Number one is I need to require the express library.",
        "tokens": [
          51264,
          5118,
          472,
          307,
          286,
          643,
          281,
          3651,
          264,
          5109,
          6405,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18272106231205046,
        "compression_ratio": 1.7250996015936255,
        "end": 4770.36,
        "id": 1424,
        "no_speech_prob": 0.0001088967765099369,
        "seek": 474636,
        "start": 4767.36,
        "temperature": 0,
        "text": " I need to create an app, which is calling the express function.",
        "tokens": [
          51414,
          286,
          643,
          281,
          1884,
          364,
          724,
          11,
          597,
          307,
          5141,
          264,
          5109,
          2445,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18272106231205046,
        "compression_ratio": 1.7250996015936255,
        "end": 4771.36,
        "id": 1425,
        "no_speech_prob": 0.0001088967765099369,
        "seek": 474636,
        "start": 4770.36,
        "temperature": 0,
        "text": " I'm adding the semicolons.",
        "tokens": [
          51564,
          286,
          478,
          5127,
          264,
          27515,
          401,
          892,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18272106231205046,
        "compression_ratio": 1.7250996015936255,
        "end": 4773.36,
        "id": 1426,
        "no_speech_prob": 0.0001088967765099369,
        "seek": 474636,
        "start": 4771.36,
        "temperature": 0,
        "text": " Gosh darn it.",
        "tokens": [
          51614,
          19185,
          29063,
          309,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18272106231205046,
        "compression_ratio": 1.7250996015936255,
        "end": 4775.36,
        "id": 1427,
        "no_speech_prob": 0.0001088967765099369,
        "seek": 474636,
        "start": 4773.36,
        "temperature": 0,
        "text": " I need semicolons to live.",
        "tokens": [
          51714,
          286,
          643,
          27515,
          401,
          892,
          281,
          1621,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.20135358969370523,
        "compression_ratio": 1.470873786407767,
        "end": 4776.36,
        "id": 1428,
        "no_speech_prob": 0.004609535913914442,
        "seek": 477536,
        "start": 4775.36,
        "temperature": 0,
        "text": " I can't do it without.",
        "tokens": [
          50364,
          286,
          393,
          380,
          360,
          309,
          1553,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.20135358969370523,
        "compression_ratio": 1.470873786407767,
        "end": 4777.36,
        "id": 1429,
        "no_speech_prob": 0.004609535913914442,
        "seek": 477536,
        "start": 4776.36,
        "temperature": 0,
        "text": " I need to pick a port.",
        "tokens": [
          50414,
          286,
          643,
          281,
          1888,
          257,
          2436,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.20135358969370523,
        "compression_ratio": 1.470873786407767,
        "end": 4781.36,
        "id": 1430,
        "no_speech_prob": 0.004609535913914442,
        "seek": 477536,
        "start": 4777.36,
        "temperature": 0,
        "text": " So, port, this is somewhat arbitrary, but I'm going to use the port 3000.",
        "tokens": [
          50464,
          407,
          11,
          2436,
          11,
          341,
          307,
          8344,
          23211,
          11,
          457,
          286,
          478,
          516,
          281,
          764,
          264,
          2436,
          20984,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20135358969370523,
        "compression_ratio": 1.470873786407767,
        "end": 4784.36,
        "id": 1431,
        "no_speech_prob": 0.004609535913914442,
        "seek": 477536,
        "start": 4781.36,
        "temperature": 0,
        "text": " And then, I'm going to set up a route.",
        "tokens": [
          50664,
          400,
          550,
          11,
          286,
          478,
          516,
          281,
          992,
          493,
          257,
          7955,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20135358969370523,
        "compression_ratio": 1.470873786407767,
        "end": 4788.36,
        "id": 1432,
        "no_speech_prob": 0.004609535913914442,
        "seek": 477536,
        "start": 4784.36,
        "temperature": 0,
        "text": " So, the idea, and I prefer to be a little more long-winded about this.",
        "tokens": [
          50814,
          407,
          11,
          264,
          1558,
          11,
          293,
          286,
          4382,
          281,
          312,
          257,
          707,
          544,
          938,
          12,
          12199,
          292,
          466,
          341,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20135358969370523,
        "compression_ratio": 1.470873786407767,
        "end": 4798.36,
        "id": 1433,
        "no_speech_prob": 0.004609535913914442,
        "seek": 477536,
        "start": 4788.36,
        "temperature": 0,
        "text": " This is using the arrow syntax, which is a kind of ES6 JavaScript syntax.",
        "tokens": [
          51014,
          639,
          307,
          1228,
          264,
          11610,
          28431,
          11,
          597,
          307,
          257,
          733,
          295,
          12564,
          21,
          15778,
          28431,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19224349851530742,
        "compression_ratio": 1.7261410788381744,
        "end": 4805.36,
        "id": 1434,
        "no_speech_prob": 0.20431819558143616,
        "seek": 479836,
        "start": 4798.36,
        "temperature": 0,
        "text": " And I'm just going to, I just have to do things the way that I do them.",
        "tokens": [
          50364,
          400,
          286,
          478,
          445,
          516,
          281,
          11,
          286,
          445,
          362,
          281,
          360,
          721,
          264,
          636,
          300,
          286,
          360,
          552,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19224349851530742,
        "compression_ratio": 1.7261410788381744,
        "end": 4809.36,
        "id": 1435,
        "no_speech_prob": 0.20431819558143616,
        "seek": 479836,
        "start": 4805.36,
        "temperature": 0,
        "text": " So, there's two functions that I care about with my app.",
        "tokens": [
          50714,
          407,
          11,
          456,
          311,
          732,
          6828,
          300,
          286,
          1127,
          466,
          365,
          452,
          724,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19224349851530742,
        "compression_ratio": 1.7261410788381744,
        "end": 4811.36,
        "id": 1436,
        "no_speech_prob": 0.20431819558143616,
        "seek": 479836,
        "start": 4809.36,
        "temperature": 0,
        "text": " One is that I need it to listen on the port.",
        "tokens": [
          50914,
          1485,
          307,
          300,
          286,
          643,
          309,
          281,
          2140,
          322,
          264,
          2436,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19224349851530742,
        "compression_ratio": 1.7261410788381744,
        "end": 4815.36,
        "id": 1437,
        "no_speech_prob": 0.20431819558143616,
        "seek": 479836,
        "start": 4811.36,
        "temperature": 0,
        "text": " So, this, I'm setting up the server, creating a server, and that server is listening.",
        "tokens": [
          51014,
          407,
          11,
          341,
          11,
          286,
          478,
          3287,
          493,
          264,
          7154,
          11,
          4084,
          257,
          7154,
          11,
          293,
          300,
          7154,
          307,
          4764,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19224349851530742,
        "compression_ratio": 1.7261410788381744,
        "end": 4818.36,
        "id": 1438,
        "no_speech_prob": 0.20431819558143616,
        "seek": 479836,
        "start": 4815.36,
        "temperature": 0,
        "text": " Because ultimately, I've got to get to that p5 sketch that's going to make the drawing.",
        "tokens": [
          51214,
          1436,
          6284,
          11,
          286,
          600,
          658,
          281,
          483,
          281,
          300,
          280,
          20,
          12325,
          300,
          311,
          516,
          281,
          652,
          264,
          6316,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19224349851530742,
        "compression_ratio": 1.7261410788381744,
        "end": 4820.36,
        "id": 1439,
        "no_speech_prob": 0.20431819558143616,
        "seek": 479836,
        "start": 4818.36,
        "temperature": 0,
        "text": " I haven't even gotten there yet.",
        "tokens": [
          51364,
          286,
          2378,
          380,
          754,
          5768,
          456,
          1939,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19224349851530742,
        "compression_ratio": 1.7261410788381744,
        "end": 4825.36,
        "id": 1440,
        "no_speech_prob": 0.20431819558143616,
        "seek": 479836,
        "start": 4820.36,
        "temperature": 0,
        "text": " Now, I then want to set up a route.",
        "tokens": [
          51464,
          823,
          11,
          286,
          550,
          528,
          281,
          992,
          493,
          257,
          7955,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17562571132884305,
        "compression_ratio": 1.530612244897959,
        "end": 4829.36,
        "id": 1441,
        "no_speech_prob": 0.0012644113739952445,
        "seek": 482536,
        "start": 4825.36,
        "temperature": 0,
        "text": " And then, when the user makes a request to that route, send something back.",
        "tokens": [
          50364,
          400,
          550,
          11,
          562,
          264,
          4195,
          1669,
          257,
          5308,
          281,
          300,
          7955,
          11,
          2845,
          746,
          646,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.17562571132884305,
        "compression_ratio": 1.530612244897959,
        "end": 4840.36,
        "id": 1442,
        "no_speech_prob": 0.0012644113739952445,
        "seek": 482536,
        "start": 4829.36,
        "temperature": 0,
        "text": " So, in this hello world example, if I run the server and go to localhost 3000, it says hello world.",
        "tokens": [
          50564,
          407,
          11,
          294,
          341,
          7751,
          1002,
          1365,
          11,
          498,
          286,
          1190,
          264,
          7154,
          293,
          352,
          281,
          2654,
          6037,
          20984,
          11,
          309,
          1619,
          7751,
          1002,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17562571132884305,
        "compression_ratio": 1.530612244897959,
        "end": 4842.36,
        "id": 1443,
        "no_speech_prob": 0.0012644113739952445,
        "seek": 482536,
        "start": 4840.36,
        "temperature": 0,
        "text": " But that's not what I want.",
        "tokens": [
          51114,
          583,
          300,
          311,
          406,
          437,
          286,
          528,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17562571132884305,
        "compression_ratio": 1.530612244897959,
        "end": 4845.36,
        "id": 1444,
        "no_speech_prob": 0.0012644113739952445,
        "seek": 482536,
        "start": 4842.36,
        "temperature": 0,
        "text": " I don't care about sending hello world.",
        "tokens": [
          51214,
          286,
          500,
          380,
          1127,
          466,
          7750,
          7751,
          1002,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.17562571132884305,
        "compression_ratio": 1.530612244897959,
        "end": 4849.36,
        "id": 1445,
        "no_speech_prob": 0.0012644113739952445,
        "seek": 482536,
        "start": 4845.36,
        "temperature": 0,
        "text": " What I want to do is let me make a route called rainbow.",
        "tokens": [
          51364,
          708,
          286,
          528,
          281,
          360,
          307,
          718,
          385,
          652,
          257,
          7955,
          1219,
          18526,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19953754712950508,
        "compression_ratio": 1.755868544600939,
        "end": 4862.36,
        "id": 1446,
        "no_speech_prob": 0.05032915249466896,
        "seek": 484936,
        "start": 4850.36,
        "temperature": 0,
        "text": " Then, what I'm going to do is I'm going to say let a random number equals math.floor, math.random, times drawings.length.",
        "tokens": [
          50414,
          1396,
          11,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          584,
          718,
          257,
          4974,
          1230,
          6915,
          5221,
          13,
          43645,
          284,
          11,
          5221,
          13,
          3699,
          298,
          11,
          1413,
          18618,
          13,
          45390,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19953754712950508,
        "compression_ratio": 1.755868544600939,
        "end": 4866.36,
        "id": 1447,
        "no_speech_prob": 0.05032915249466896,
        "seek": 484936,
        "start": 4862.36,
        "temperature": 0,
        "text": " So, however many drawings have been loaded when somebody goes to this route, pick a random one.",
        "tokens": [
          51014,
          407,
          11,
          4461,
          867,
          18618,
          362,
          668,
          13210,
          562,
          2618,
          1709,
          281,
          341,
          7955,
          11,
          1888,
          257,
          4974,
          472,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19953754712950508,
        "compression_ratio": 1.755868544600939,
        "end": 4870.36,
        "id": 1448,
        "no_speech_prob": 0.05032915249466896,
        "seek": 484936,
        "start": 4866.36,
        "temperature": 0,
        "text": " And then, I'm going to say, and this could be a const, I guess.",
        "tokens": [
          51214,
          400,
          550,
          11,
          286,
          478,
          516,
          281,
          584,
          11,
          293,
          341,
          727,
          312,
          257,
          1817,
          11,
          286,
          2041,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19953754712950508,
        "compression_ratio": 1.755868544600939,
        "end": 4874.36,
        "id": 1449,
        "no_speech_prob": 0.05032915249466896,
        "seek": 484936,
        "start": 4870.36,
        "temperature": 0,
        "text": " And I'm going to say response send drawings index r.",
        "tokens": [
          51414,
          400,
          286,
          478,
          516,
          281,
          584,
          4134,
          2845,
          18618,
          8186,
          367,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19953754712950508,
        "compression_ratio": 1.755868544600939,
        "end": 4876.36,
        "id": 1450,
        "no_speech_prob": 0.05032915249466896,
        "seek": 484936,
        "start": 4874.36,
        "temperature": 0,
        "text": " And I suppose I should call this index.",
        "tokens": [
          51614,
          400,
          286,
          7297,
          286,
          820,
          818,
          341,
          8186,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18529394956735465,
        "compression_ratio": 1.5833333333333333,
        "end": 4881.36,
        "id": 1451,
        "no_speech_prob": 0.005139567889273167,
        "seek": 487636,
        "start": 4877.36,
        "temperature": 0,
        "text": " So, now, oops, index.",
        "tokens": [
          50414,
          407,
          11,
          586,
          11,
          34166,
          11,
          8186,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18529394956735465,
        "compression_ratio": 1.5833333333333333,
        "end": 4883.36,
        "id": 1452,
        "no_speech_prob": 0.005139567889273167,
        "seek": 487636,
        "start": 4881.36,
        "temperature": 0,
        "text": " Let's rerun the server.",
        "tokens": [
          50614,
          961,
          311,
          43819,
          409,
          264,
          7154,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18529394956735465,
        "compression_ratio": 1.5833333333333333,
        "end": 4886.36,
        "id": 1453,
        "no_speech_prob": 0.005139567889273167,
        "seek": 487636,
        "start": 4883.36,
        "temperature": 0,
        "text": " And there is a tool called nodemon which will restart the server for you.",
        "tokens": [
          50714,
          400,
          456,
          307,
          257,
          2290,
          1219,
          9984,
          3317,
          597,
          486,
          21022,
          264,
          7154,
          337,
          291,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.18529394956735465,
        "compression_ratio": 1.5833333333333333,
        "end": 4888.36,
        "id": 1454,
        "no_speech_prob": 0.005139567889273167,
        "seek": 487636,
        "start": 4886.36,
        "temperature": 0,
        "text": " I'm going to do this manually.",
        "tokens": [
          50864,
          286,
          478,
          516,
          281,
          360,
          341,
          16945,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18529394956735465,
        "compression_ratio": 1.5833333333333333,
        "end": 4890.36,
        "id": 1455,
        "no_speech_prob": 0.005139567889273167,
        "seek": 487636,
        "start": 4888.36,
        "temperature": 0,
        "text": " And then, I'm going to go here.",
        "tokens": [
          50964,
          400,
          550,
          11,
          286,
          478,
          516,
          281,
          352,
          510,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.18529394956735465,
        "compression_ratio": 1.5833333333333333,
        "end": 4895.36,
        "id": 1456,
        "no_speech_prob": 0.005139567889273167,
        "seek": 487636,
        "start": 4890.36,
        "temperature": 0,
        "text": " Cannot get slash because there is no route anymore at slash.",
        "tokens": [
          51064,
          29866,
          310,
          483,
          17330,
          570,
          456,
          307,
          572,
          7955,
          3602,
          412,
          17330,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18529394956735465,
        "compression_ratio": 1.5833333333333333,
        "end": 4900.36,
        "id": 1457,
        "no_speech_prob": 0.005139567889273167,
        "seek": 487636,
        "start": 4895.36,
        "temperature": 0,
        "text": " But if I go to slash rainbow, there we go.",
        "tokens": [
          51314,
          583,
          498,
          286,
          352,
          281,
          17330,
          18526,
          11,
          456,
          321,
          352,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18529394956735465,
        "compression_ratio": 1.5833333333333333,
        "end": 4903.36,
        "id": 1458,
        "no_speech_prob": 0.005139567889273167,
        "seek": 487636,
        "start": 4900.36,
        "temperature": 0,
        "text": " There is the drawing.",
        "tokens": [
          51564,
          821,
          307,
          264,
          6316,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18529394956735465,
        "compression_ratio": 1.5833333333333333,
        "end": 4905.36,
        "id": 1459,
        "no_speech_prob": 0.005139567889273167,
        "seek": 487636,
        "start": 4903.36,
        "temperature": 0,
        "text": " Hold on a sec.",
        "tokens": [
          51714,
          6962,
          322,
          257,
          907,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2593471840636371,
        "compression_ratio": 1.5294117647058822,
        "end": 4907.36,
        "id": 1460,
        "no_speech_prob": 0.04813394695520401,
        "seek": 490536,
        "start": 4905.36,
        "temperature": 0,
        "text": " Time out for a second.",
        "tokens": [
          50364,
          6161,
          484,
          337,
          257,
          1150,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2593471840636371,
        "compression_ratio": 1.5294117647058822,
        "end": 4919.36,
        "id": 1461,
        "no_speech_prob": 0.04813394695520401,
        "seek": 490536,
        "start": 4912.36,
        "temperature": 0,
        "text": " I could have sworn I have this extension that will format the JSON, but I guess I didn't.",
        "tokens": [
          50714,
          286,
          727,
          362,
          40068,
          286,
          362,
          341,
          10320,
          300,
          486,
          7877,
          264,
          31828,
          11,
          457,
          286,
          2041,
          286,
          994,
          380,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2593471840636371,
        "compression_ratio": 1.5294117647058822,
        "end": 4929.36,
        "id": 1462,
        "no_speech_prob": 0.04813394695520401,
        "seek": 490536,
        "start": 4925.36,
        "temperature": 0,
        "text": " All right. I just installed a Chrome extension to format the JSON so I could see it.",
        "tokens": [
          51364,
          1057,
          558,
          13,
          286,
          445,
          8899,
          257,
          15327,
          10320,
          281,
          7877,
          264,
          31828,
          370,
          286,
          727,
          536,
          309,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2593471840636371,
        "compression_ratio": 1.5294117647058822,
        "end": 4931.36,
        "id": 1463,
        "no_speech_prob": 0.04813394695520401,
        "seek": 490536,
        "start": 4929.36,
        "temperature": 0,
        "text": " So, here is a random drawing.",
        "tokens": [
          51564,
          407,
          11,
          510,
          307,
          257,
          4974,
          6316,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2593471840636371,
        "compression_ratio": 1.5294117647058822,
        "end": 4933.36,
        "id": 1464,
        "no_speech_prob": 0.04813394695520401,
        "seek": 490536,
        "start": 4931.36,
        "temperature": 0,
        "text": " And this is all the information.",
        "tokens": [
          51664,
          400,
          341,
          307,
          439,
          264,
          1589,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.26084675200997964,
        "compression_ratio": 1.3625730994152048,
        "end": 4941.36,
        "id": 1465,
        "no_speech_prob": 0.0007436919840984046,
        "seek": 493336,
        "start": 4933.36,
        "temperature": 0,
        "text": " All I need to do is have p5 request JSON from this route and then render the drawing.",
        "tokens": [
          50364,
          1057,
          286,
          643,
          281,
          360,
          307,
          362,
          280,
          20,
          5308,
          31828,
          490,
          341,
          7955,
          293,
          550,
          15529,
          264,
          6316,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.26084675200997964,
        "compression_ratio": 1.3625730994152048,
        "end": 4943.36,
        "id": 1466,
        "no_speech_prob": 0.0007436919840984046,
        "seek": 493336,
        "start": 4941.36,
        "temperature": 0,
        "text": " Pause for a second.",
        "tokens": [
          50764,
          31973,
          337,
          257,
          1150,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.26084675200997964,
        "compression_ratio": 1.3625730994152048,
        "end": 4948.36,
        "id": 1467,
        "no_speech_prob": 0.0007436919840984046,
        "seek": 493336,
        "start": 4943.36,
        "temperature": 0,
        "text": " I think I'm not doing multi-part videos this day.",
        "tokens": [
          50864,
          286,
          519,
          286,
          478,
          406,
          884,
          4825,
          12,
          6971,
          2145,
          341,
          786,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.26084675200997964,
        "compression_ratio": 1.3625730994152048,
        "end": 4952.36,
        "id": 1468,
        "no_speech_prob": 0.0007436919840984046,
        "seek": 493336,
        "start": 4948.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51114,
          1057,
          558,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.26084675200997964,
        "compression_ratio": 1.3625730994152048,
        "end": 4954.36,
        "id": 1469,
        "no_speech_prob": 0.0007436919840984046,
        "seek": 493336,
        "start": 4952.36,
        "temperature": 0,
        "text": " Oh, there's been some new members.",
        "tokens": [
          51314,
          876,
          11,
          456,
          311,
          668,
          512,
          777,
          2679,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.26084675200997964,
        "compression_ratio": 1.3625730994152048,
        "end": 4956.36,
        "id": 1470,
        "no_speech_prob": 0.0007436919840984046,
        "seek": 493336,
        "start": 4954.36,
        "temperature": 0,
        "text": " Thank you very much.",
        "tokens": [
          51414,
          1044,
          291,
          588,
          709,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.26084675200997964,
        "compression_ratio": 1.3625730994152048,
        "end": 4958.36,
        "id": 1471,
        "no_speech_prob": 0.0007436919840984046,
        "seek": 493336,
        "start": 4956.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51514,
          1057,
          558,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.17769189740790695,
        "compression_ratio": 1.6329588014981273,
        "end": 4969.36,
        "id": 1472,
        "no_speech_prob": 0.002550847129896283,
        "seek": 496336,
        "start": 4964.36,
        "temperature": 0,
        "text": " So, now the question is where do I run my p5 sketch?",
        "tokens": [
          50414,
          407,
          11,
          586,
          264,
          1168,
          307,
          689,
          360,
          286,
          1190,
          452,
          280,
          20,
          12325,
          30,
          50664
        ]
      },
      {
        "avg_logprob": -0.17769189740790695,
        "compression_ratio": 1.6329588014981273,
        "end": 4971.36,
        "id": 1473,
        "no_speech_prob": 0.002550847129896283,
        "seek": 496336,
        "start": 4969.36,
        "temperature": 0,
        "text": " And there are a variety of ways.",
        "tokens": [
          50664,
          400,
          456,
          366,
          257,
          5673,
          295,
          2098,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.17769189740790695,
        "compression_ratio": 1.6329588014981273,
        "end": 4974.36,
        "id": 1474,
        "no_speech_prob": 0.002550847129896283,
        "seek": 496336,
        "start": 4971.36,
        "temperature": 0,
        "text": " In theory, this is an API that anyone could make a request to.",
        "tokens": [
          50764,
          682,
          5261,
          11,
          341,
          307,
          364,
          9362,
          300,
          2878,
          727,
          652,
          257,
          5308,
          281,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17769189740790695,
        "compression_ratio": 1.6329588014981273,
        "end": 4980.36,
        "id": 1475,
        "no_speech_prob": 0.002550847129896283,
        "seek": 496336,
        "start": 4974.36,
        "temperature": 0,
        "text": " Whether or not I'm opening it up for other people to request to it or not is a complicated question.",
        "tokens": [
          50914,
          8503,
          420,
          406,
          286,
          478,
          5193,
          309,
          493,
          337,
          661,
          561,
          281,
          5308,
          281,
          309,
          420,
          406,
          307,
          257,
          6179,
          1168,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17769189740790695,
        "compression_ratio": 1.6329588014981273,
        "end": 4986.36,
        "id": 1476,
        "no_speech_prob": 0.002550847129896283,
        "seek": 496336,
        "start": 4980.36,
        "temperature": 0,
        "text": " But one way that I could use it is just have this particular server host a p5 sketch in the first place.",
        "tokens": [
          51214,
          583,
          472,
          636,
          300,
          286,
          727,
          764,
          309,
          307,
          445,
          362,
          341,
          1729,
          7154,
          3975,
          257,
          280,
          20,
          12325,
          294,
          264,
          700,
          1081,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.17769189740790695,
        "compression_ratio": 1.6329588014981273,
        "end": 4992.36,
        "id": 1477,
        "no_speech_prob": 0.002550847129896283,
        "seek": 496336,
        "start": 4986.36,
        "temperature": 0,
        "text": " So, the way to do that, if I go back to my files and I go to desktop, quick draw.",
        "tokens": [
          51514,
          407,
          11,
          264,
          636,
          281,
          360,
          300,
          11,
          498,
          286,
          352,
          646,
          281,
          452,
          7098,
          293,
          286,
          352,
          281,
          14502,
          11,
          1702,
          2642,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2202124502144608,
        "compression_ratio": 1.5374449339207048,
        "end": 4994.36,
        "id": 1478,
        "no_speech_prob": 0.0006461988086812198,
        "seek": 499236,
        "start": 4992.36,
        "temperature": 0,
        "text": " This is where all the files are.",
        "tokens": [
          50364,
          639,
          307,
          689,
          439,
          264,
          7098,
          366,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2202124502144608,
        "compression_ratio": 1.5374449339207048,
        "end": 4999.36,
        "id": 1479,
        "no_speech_prob": 0.0006461988086812198,
        "seek": 499236,
        "start": 4994.36,
        "temperature": 0,
        "text": " I'm actually going, I have a p5 HTML file and a sketch.js file in here.",
        "tokens": [
          50464,
          286,
          478,
          767,
          516,
          11,
          286,
          362,
          257,
          280,
          20,
          17995,
          3991,
          293,
          257,
          12325,
          13,
          25530,
          3991,
          294,
          510,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2202124502144608,
        "compression_ratio": 1.5374449339207048,
        "end": 5001.36,
        "id": 1480,
        "no_speech_prob": 0.0006461988086812198,
        "seek": 499236,
        "start": 4999.36,
        "temperature": 0,
        "text": " But I'm going to make another directory called public.",
        "tokens": [
          50714,
          583,
          286,
          478,
          516,
          281,
          652,
          1071,
          21120,
          1219,
          1908,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2202124502144608,
        "compression_ratio": 1.5374449339207048,
        "end": 5008.36,
        "id": 1481,
        "no_speech_prob": 0.0006461988086812198,
        "seek": 499236,
        "start": 5001.36,
        "temperature": 0,
        "text": " So, these would be where I want files that are hosted by the server to live, public.",
        "tokens": [
          50814,
          407,
          11,
          613,
          576,
          312,
          689,
          286,
          528,
          7098,
          300,
          366,
          19204,
          538,
          264,
          7154,
          281,
          1621,
          11,
          1908,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2202124502144608,
        "compression_ratio": 1.5374449339207048,
        "end": 5013.36,
        "id": 1482,
        "no_speech_prob": 0.0006461988086812198,
        "seek": 499236,
        "start": 5008.36,
        "temperature": 0,
        "text": " And then I'm going to say something like in my code, app.",
        "tokens": [
          51164,
          400,
          550,
          286,
          478,
          516,
          281,
          584,
          746,
          411,
          294,
          452,
          3089,
          11,
          724,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2202124502144608,
        "compression_ratio": 1.5374449339207048,
        "end": 5015.36,
        "id": 1483,
        "no_speech_prob": 0.0006461988086812198,
        "seek": 499236,
        "start": 5013.36,
        "temperature": 0,
        "text": " I don't remember.",
        "tokens": [
          51414,
          286,
          500,
          380,
          1604,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2202124502144608,
        "compression_ratio": 1.5374449339207048,
        "end": 5019.36,
        "id": 1484,
        "no_speech_prob": 0.0006461988086812198,
        "seek": 499236,
        "start": 5015.36,
        "temperature": 0,
        "text": " Static file hosting express.",
        "tokens": [
          51514,
          745,
          2399,
          3991,
          16058,
          5109,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1701818239890923,
        "compression_ratio": 1.6622222222222223,
        "end": 5021.36,
        "id": 1485,
        "no_speech_prob": 0.0769570916891098,
        "seek": 501936,
        "start": 5019.36,
        "temperature": 0,
        "text": " Serving static files in express is just this.",
        "tokens": [
          50364,
          4210,
          798,
          13437,
          7098,
          294,
          5109,
          307,
          445,
          341,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1701818239890923,
        "compression_ratio": 1.6622222222222223,
        "end": 5028.36,
        "id": 1486,
        "no_speech_prob": 0.0769570916891098,
        "seek": 501936,
        "start": 5021.36,
        "temperature": 0,
        "text": " So, basically what I want to do is serve up the HTML and the JavaScript files as well.",
        "tokens": [
          50464,
          407,
          11,
          1936,
          437,
          286,
          528,
          281,
          360,
          307,
          4596,
          493,
          264,
          17995,
          293,
          264,
          15778,
          7098,
          382,
          731,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1701818239890923,
        "compression_ratio": 1.6622222222222223,
        "end": 5030.36,
        "id": 1487,
        "no_speech_prob": 0.0769570916891098,
        "seek": 501936,
        "start": 5028.36,
        "temperature": 0,
        "text": " So, I'm going to do that here.",
        "tokens": [
          50814,
          407,
          11,
          286,
          478,
          516,
          281,
          360,
          300,
          510,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1701818239890923,
        "compression_ratio": 1.6622222222222223,
        "end": 5032.36,
        "id": 1488,
        "no_speech_prob": 0.0769570916891098,
        "seek": 501936,
        "start": 5030.36,
        "temperature": 0,
        "text": " I'm going to add this.",
        "tokens": [
          50914,
          286,
          478,
          516,
          281,
          909,
          341,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1701818239890923,
        "compression_ratio": 1.6622222222222223,
        "end": 5034.36,
        "id": 1489,
        "no_speech_prob": 0.0769570916891098,
        "seek": 501936,
        "start": 5032.36,
        "temperature": 0,
        "text": " So, now look at this.",
        "tokens": [
          51014,
          407,
          11,
          586,
          574,
          412,
          341,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1701818239890923,
        "compression_ratio": 1.6622222222222223,
        "end": 5040.36,
        "id": 1490,
        "no_speech_prob": 0.0769570916891098,
        "seek": 501936,
        "start": 5034.36,
        "temperature": 0,
        "text": " Now, and let's go to the p5 code and let's say background 0.",
        "tokens": [
          51114,
          823,
          11,
          293,
          718,
          311,
          352,
          281,
          264,
          280,
          20,
          3089,
          293,
          718,
          311,
          584,
          3678,
          1958,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1701818239890923,
        "compression_ratio": 1.6622222222222223,
        "end": 5046.36,
        "id": 1491,
        "no_speech_prob": 0.0769570916891098,
        "seek": 501936,
        "start": 5040.36,
        "temperature": 0,
        "text": " So, all that this p5 code does is create a 100 by 100 canvas with a background of 0.",
        "tokens": [
          51414,
          407,
          11,
          439,
          300,
          341,
          280,
          20,
          3089,
          775,
          307,
          1884,
          257,
          2319,
          538,
          2319,
          16267,
          365,
          257,
          3678,
          295,
          1958,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1701818239890923,
        "compression_ratio": 1.6622222222222223,
        "end": 5047.36,
        "id": 1492,
        "no_speech_prob": 0.0769570916891098,
        "seek": 501936,
        "start": 5046.36,
        "temperature": 0,
        "text": " So, now guess what?",
        "tokens": [
          51714,
          407,
          11,
          586,
          2041,
          437,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.2013658708141696,
        "compression_ratio": 1.6649484536082475,
        "end": 5058.36,
        "id": 1493,
        "no_speech_prob": 0.0007437008316628635,
        "seek": 504736,
        "start": 5047.36,
        "temperature": 0,
        "text": " If I go to localhost 3000 slash rainbow, I get a drawing because I'm handling that rainbow route with a, by sending back a drawing.",
        "tokens": [
          50364,
          759,
          286,
          352,
          281,
          2654,
          6037,
          20984,
          17330,
          18526,
          11,
          286,
          483,
          257,
          6316,
          570,
          286,
          478,
          13175,
          300,
          18526,
          7955,
          365,
          257,
          11,
          538,
          7750,
          646,
          257,
          6316,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2013658708141696,
        "compression_ratio": 1.6649484536082475,
        "end": 5063.36,
        "id": 1494,
        "no_speech_prob": 0.0007437008316628635,
        "seek": 504736,
        "start": 5058.36,
        "temperature": 0,
        "text": " But if I go to just slash, oh, I didn't restart the server, did I?",
        "tokens": [
          50914,
          583,
          498,
          286,
          352,
          281,
          445,
          17330,
          11,
          1954,
          11,
          286,
          994,
          380,
          21022,
          264,
          7154,
          11,
          630,
          286,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.2013658708141696,
        "compression_ratio": 1.6649484536082475,
        "end": 5067.36,
        "id": 1495,
        "no_speech_prob": 0.0007437008316628635,
        "seek": 504736,
        "start": 5063.36,
        "temperature": 0,
        "text": " Restart the server, go to slash, there's the p5 sketch.",
        "tokens": [
          51164,
          13094,
          446,
          264,
          7154,
          11,
          352,
          281,
          17330,
          11,
          456,
          311,
          264,
          280,
          20,
          12325,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2013658708141696,
        "compression_ratio": 1.6649484536082475,
        "end": 5075.36,
        "id": 1496,
        "no_speech_prob": 0.0007437008316628635,
        "seek": 504736,
        "start": 5067.36,
        "temperature": 0,
        "text": " So, now my p5 sketch can finally ask for the server for the drawing.",
        "tokens": [
          51364,
          407,
          11,
          586,
          452,
          280,
          20,
          12325,
          393,
          2721,
          1029,
          337,
          264,
          7154,
          337,
          264,
          6316,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.22874357082225658,
        "compression_ratio": 1.790909090909091,
        "end": 5076.36,
        "id": 1497,
        "no_speech_prob": 0.0012255567125976086,
        "seek": 507536,
        "start": 5075.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.22874357082225658,
        "compression_ratio": 1.790909090909091,
        "end": 5089.36,
        "id": 1498,
        "no_speech_prob": 0.0012255567125976086,
        "seek": 507536,
        "start": 5076.36,
        "temperature": 0,
        "text": " I'm going to go over here and I'm going to say, first of all, one thing is by the way that simplified data set, all of the simplified version of the quick draw data set, all of the drawings were simplified or scaled to 255 by 255 pixels.",
        "tokens": [
          50414,
          286,
          478,
          516,
          281,
          352,
          670,
          510,
          293,
          286,
          478,
          516,
          281,
          584,
          11,
          700,
          295,
          439,
          11,
          472,
          551,
          307,
          538,
          264,
          636,
          300,
          26335,
          1412,
          992,
          11,
          439,
          295,
          264,
          26335,
          3037,
          295,
          264,
          1702,
          2642,
          1412,
          992,
          11,
          439,
          295,
          264,
          18618,
          645,
          26335,
          420,
          36039,
          281,
          3552,
          20,
          538,
          3552,
          20,
          18668,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.22874357082225658,
        "compression_ratio": 1.790909090909091,
        "end": 5091.36,
        "id": 1499,
        "no_speech_prob": 0.0012255567125976086,
        "seek": 507536,
        "start": 5089.36,
        "temperature": 0,
        "text": " So, that makes things easier to work with.",
        "tokens": [
          51064,
          407,
          11,
          300,
          1669,
          721,
          3571,
          281,
          589,
          365,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.22874357082225658,
        "compression_ratio": 1.790909090909091,
        "end": 5094.36,
        "id": 1500,
        "no_speech_prob": 0.0012255567125976086,
        "seek": 507536,
        "start": 5091.36,
        "temperature": 0,
        "text": " I'm going to call the function loadJSON and guess what?",
        "tokens": [
          51164,
          286,
          478,
          516,
          281,
          818,
          264,
          2445,
          3677,
          41,
          10388,
          293,
          2041,
          437,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.22874357082225658,
        "compression_ratio": 1.790909090909091,
        "end": 5098.36,
        "id": 1501,
        "no_speech_prob": 0.0012255567125976086,
        "seek": 507536,
        "start": 5094.36,
        "temperature": 0,
        "text": " I'm just going to say loadJSON rainbow got rainbow.",
        "tokens": [
          51314,
          286,
          478,
          445,
          516,
          281,
          584,
          3677,
          41,
          10388,
          18526,
          658,
          18526,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1953424816289224,
        "compression_ratio": 1.6953405017921146,
        "end": 5107.36,
        "id": 1502,
        "no_speech_prob": 0.42248666286468506,
        "seek": 509836,
        "start": 5099.36,
        "temperature": 0,
        "text": " And then I'm going to write a function got rainbow that gets some data and I'm going to say console log data.",
        "tokens": [
          50414,
          400,
          550,
          286,
          478,
          516,
          281,
          2464,
          257,
          2445,
          658,
          18526,
          300,
          2170,
          512,
          1412,
          293,
          286,
          478,
          516,
          281,
          584,
          11076,
          3565,
          1412,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1953424816289224,
        "compression_ratio": 1.6953405017921146,
        "end": 5108.36,
        "id": 1503,
        "no_speech_prob": 0.42248666286468506,
        "seek": 509836,
        "start": 5107.36,
        "temperature": 0,
        "text": " So, this is the idea.",
        "tokens": [
          50814,
          407,
          11,
          341,
          307,
          264,
          1558,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1953424816289224,
        "compression_ratio": 1.6953405017921146,
        "end": 5118.36,
        "id": 1504,
        "no_speech_prob": 0.42248666286468506,
        "seek": 509836,
        "start": 5108.36,
        "temperature": 0,
        "text": " Now, if you've seen loadJSON before, maybe before I've used it for like load this actual JSON file or maybe I've said loadJSON from an API like Wordnik.",
        "tokens": [
          50864,
          823,
          11,
          498,
          291,
          600,
          1612,
          3677,
          41,
          10388,
          949,
          11,
          1310,
          949,
          286,
          600,
          1143,
          309,
          337,
          411,
          3677,
          341,
          3539,
          31828,
          3991,
          420,
          1310,
          286,
          600,
          848,
          3677,
          41,
          10388,
          490,
          364,
          9362,
          411,
          8725,
          13123,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1953424816289224,
        "compression_ratio": 1.6953405017921146,
        "end": 5123.36,
        "id": 1505,
        "no_speech_prob": 0.42248666286468506,
        "seek": 509836,
        "start": 5118.36,
        "temperature": 0,
        "text": " Now, I'm going to the slash rainbow route which is local to this particular server and guess what?",
        "tokens": [
          51364,
          823,
          11,
          286,
          478,
          516,
          281,
          264,
          17330,
          18526,
          7955,
          597,
          307,
          2654,
          281,
          341,
          1729,
          7154,
          293,
          2041,
          437,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.1953424816289224,
        "compression_ratio": 1.6953405017921146,
        "end": 5127.36,
        "id": 1506,
        "no_speech_prob": 0.42248666286468506,
        "seek": 509836,
        "start": 5123.36,
        "temperature": 0,
        "text": " I don't actually even need to restart the server because this will be loaded dynamically.",
        "tokens": [
          51614,
          286,
          500,
          380,
          767,
          754,
          643,
          281,
          21022,
          264,
          7154,
          570,
          341,
          486,
          312,
          13210,
          43492,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.17300869594110507,
        "compression_ratio": 1.6527777777777777,
        "end": 5130.36,
        "id": 1507,
        "no_speech_prob": 0.00293492223136127,
        "seek": 512736,
        "start": 5127.36,
        "temperature": 0,
        "text": " So, let's go here and we can see there it is.",
        "tokens": [
          50364,
          407,
          11,
          718,
          311,
          352,
          510,
          293,
          321,
          393,
          536,
          456,
          309,
          307,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.17300869594110507,
        "compression_ratio": 1.6527777777777777,
        "end": 5133.36,
        "id": 1508,
        "no_speech_prob": 0.00293492223136127,
        "seek": 512736,
        "start": 5130.36,
        "temperature": 0,
        "text": " This is the rainbow drawing right here.",
        "tokens": [
          50514,
          639,
          307,
          264,
          18526,
          6316,
          558,
          510,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17300869594110507,
        "compression_ratio": 1.6527777777777777,
        "end": 5135.36,
        "id": 1509,
        "no_speech_prob": 0.00293492223136127,
        "seek": 512736,
        "start": 5133.36,
        "temperature": 0,
        "text": " Let me give myself some more room and here's the drawing itself.",
        "tokens": [
          50664,
          961,
          385,
          976,
          2059,
          512,
          544,
          1808,
          293,
          510,
          311,
          264,
          6316,
          2564,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.17300869594110507,
        "compression_ratio": 1.6527777777777777,
        "end": 5141.36,
        "id": 1510,
        "no_speech_prob": 0.00293492223136127,
        "seek": 512736,
        "start": 5135.36,
        "temperature": 0,
        "text": " So, all I need to do now is write an algorithm to go through and draw this drawing.",
        "tokens": [
          50764,
          407,
          11,
          439,
          286,
          643,
          281,
          360,
          586,
          307,
          2464,
          364,
          9284,
          281,
          352,
          807,
          293,
          2642,
          341,
          6316,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17300869594110507,
        "compression_ratio": 1.6527777777777777,
        "end": 5142.36,
        "id": 1511,
        "no_speech_prob": 0.00293492223136127,
        "seek": 512736,
        "start": 5141.36,
        "temperature": 0,
        "text": " All right, we're ready.",
        "tokens": [
          51064,
          1057,
          558,
          11,
          321,
          434,
          1919,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17300869594110507,
        "compression_ratio": 1.6527777777777777,
        "end": 5146.36,
        "id": 1512,
        "no_speech_prob": 0.00293492223136127,
        "seek": 512736,
        "start": 5142.36,
        "temperature": 0,
        "text": " So, let me make the background like 200.",
        "tokens": [
          51114,
          407,
          11,
          718,
          385,
          652,
          264,
          3678,
          411,
          2331,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17300869594110507,
        "compression_ratio": 1.6527777777777777,
        "end": 5153.36,
        "id": 1513,
        "no_speech_prob": 0.00293492223136127,
        "seek": 512736,
        "start": 5146.36,
        "temperature": 0,
        "text": " Let me say the drawing is in data.drawing.",
        "tokens": [
          51314,
          961,
          385,
          584,
          264,
          6316,
          307,
          294,
          1412,
          13,
          48848,
          278,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17300869594110507,
        "compression_ratio": 1.6527777777777777,
        "end": 5155.36,
        "id": 1514,
        "no_speech_prob": 0.00293492223136127,
        "seek": 512736,
        "start": 5153.36,
        "temperature": 0,
        "text": " Is that right?",
        "tokens": [
          51664,
          1119,
          300,
          558,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.22034659151171074,
        "compression_ratio": 1.6172248803827751,
        "end": 5157.36,
        "id": 1515,
        "no_speech_prob": 0.013636676594614983,
        "seek": 515536,
        "start": 5155.36,
        "temperature": 0,
        "text": " Console log drawing.",
        "tokens": [
          50364,
          44152,
          3565,
          6316,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.22034659151171074,
        "compression_ratio": 1.6172248803827751,
        "end": 5158.36,
        "id": 1516,
        "no_speech_prob": 0.013636676594614983,
        "seek": 515536,
        "start": 5157.36,
        "temperature": 0,
        "text": " Let's look at that.",
        "tokens": [
          50464,
          961,
          311,
          574,
          412,
          300,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.22034659151171074,
        "compression_ratio": 1.6172248803827751,
        "end": 5160.36,
        "id": 1517,
        "no_speech_prob": 0.013636676594614983,
        "seek": 515536,
        "start": 5158.36,
        "temperature": 0,
        "text": " Yeah, so this is the actual drawing.",
        "tokens": [
          50514,
          865,
          11,
          370,
          341,
          307,
          264,
          3539,
          6316,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.22034659151171074,
        "compression_ratio": 1.6172248803827751,
        "end": 5163.36,
        "id": 1518,
        "no_speech_prob": 0.013636676594614983,
        "seek": 515536,
        "start": 5160.36,
        "temperature": 0,
        "text": " It's just two arrays because it was just two strokes.",
        "tokens": [
          50614,
          467,
          311,
          445,
          732,
          41011,
          570,
          309,
          390,
          445,
          732,
          24493,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.22034659151171074,
        "compression_ratio": 1.6172248803827751,
        "end": 5173.36,
        "id": 1519,
        "no_speech_prob": 0.013636676594614983,
        "seek": 515536,
        "start": 5163.36,
        "temperature": 0,
        "text": " Now, I am going to say for let i equals 0, i is less than drawing dot.",
        "tokens": [
          50764,
          823,
          11,
          286,
          669,
          516,
          281,
          584,
          337,
          718,
          741,
          6915,
          1958,
          11,
          741,
          307,
          1570,
          813,
          6316,
          5893,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.22034659151171074,
        "compression_ratio": 1.6172248803827751,
        "end": 5176.36,
        "id": 1520,
        "no_speech_prob": 0.013636676594614983,
        "seek": 515536,
        "start": 5173.36,
        "temperature": 0,
        "text": " Oh, let me figure this out.",
        "tokens": [
          51264,
          876,
          11,
          718,
          385,
          2573,
          341,
          484,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.22034659151171074,
        "compression_ratio": 1.6172248803827751,
        "end": 5177.36,
        "id": 1521,
        "no_speech_prob": 0.013636676594614983,
        "seek": 515536,
        "start": 5176.36,
        "temperature": 0,
        "text": " This is an array.",
        "tokens": [
          51414,
          639,
          307,
          364,
          10225,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.22034659151171074,
        "compression_ratio": 1.6172248803827751,
        "end": 5178.36,
        "id": 1522,
        "no_speech_prob": 0.013636676594614983,
        "seek": 515536,
        "start": 5177.36,
        "temperature": 0,
        "text": " Oh, right.",
        "tokens": [
          51464,
          876,
          11,
          558,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.22034659151171074,
        "compression_ratio": 1.6172248803827751,
        "end": 5179.36,
        "id": 1523,
        "no_speech_prob": 0.013636676594614983,
        "seek": 515536,
        "start": 5178.36,
        "temperature": 0,
        "text": " Oh, weird.",
        "tokens": [
          51514,
          876,
          11,
          3657,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.22034659151171074,
        "compression_ratio": 1.6172248803827751,
        "end": 5180.36,
        "id": 1524,
        "no_speech_prob": 0.013636676594614983,
        "seek": 515536,
        "start": 5179.36,
        "temperature": 0,
        "text": " I'm sorry.",
        "tokens": [
          51564,
          286,
          478,
          2597,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.22034659151171074,
        "compression_ratio": 1.6172248803827751,
        "end": 5181.36,
        "id": 1525,
        "no_speech_prob": 0.013636676594614983,
        "seek": 515536,
        "start": 5180.36,
        "temperature": 0,
        "text": " I'm going, oh, right.",
        "tokens": [
          51614,
          286,
          478,
          516,
          11,
          1954,
          11,
          558,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.22034659151171074,
        "compression_ratio": 1.6172248803827751,
        "end": 5182.36,
        "id": 1526,
        "no_speech_prob": 0.013636676594614983,
        "seek": 515536,
        "start": 5181.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51664,
          1033,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.22034659151171074,
        "compression_ratio": 1.6172248803827751,
        "end": 5184.36,
        "id": 1527,
        "no_speech_prob": 0.013636676594614983,
        "seek": 515536,
        "start": 5182.36,
        "temperature": 0,
        "text": " So, this is only one stroke.",
        "tokens": [
          51714,
          407,
          11,
          341,
          307,
          787,
          472,
          12403,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.15973357877869537,
        "compression_ratio": 1.7743362831858407,
        "end": 5185.36,
        "id": 1528,
        "no_speech_prob": 0.004133932758122683,
        "seek": 518436,
        "start": 5184.36,
        "temperature": 0,
        "text": " Oh, this was confusing here.",
        "tokens": [
          50364,
          876,
          11,
          341,
          390,
          13181,
          510,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.15973357877869537,
        "compression_ratio": 1.7743362831858407,
        "end": 5187.36,
        "id": 1529,
        "no_speech_prob": 0.004133932758122683,
        "seek": 518436,
        "start": 5185.36,
        "temperature": 0,
        "text": " Some of these rainbows, there we go.",
        "tokens": [
          50414,
          2188,
          295,
          613,
          4830,
          21118,
          11,
          456,
          321,
          352,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.15973357877869537,
        "compression_ratio": 1.7743362831858407,
        "end": 5188.36,
        "id": 1530,
        "no_speech_prob": 0.004133932758122683,
        "seek": 518436,
        "start": 5187.36,
        "temperature": 0,
        "text": " This is what I want to look at.",
        "tokens": [
          50514,
          639,
          307,
          437,
          286,
          528,
          281,
          574,
          412,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.15973357877869537,
        "compression_ratio": 1.7743362831858407,
        "end": 5191.36,
        "id": 1531,
        "no_speech_prob": 0.004133932758122683,
        "seek": 518436,
        "start": 5188.36,
        "temperature": 0,
        "text": " I have three different strokes.",
        "tokens": [
          50564,
          286,
          362,
          1045,
          819,
          24493,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.15973357877869537,
        "compression_ratio": 1.7743362831858407,
        "end": 5193.36,
        "id": 1532,
        "no_speech_prob": 0.004133932758122683,
        "seek": 518436,
        "start": 5191.36,
        "temperature": 0,
        "text": " So, first I need to look at all the strokes.",
        "tokens": [
          50714,
          407,
          11,
          700,
          286,
          643,
          281,
          574,
          412,
          439,
          264,
          24493,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.15973357877869537,
        "compression_ratio": 1.7743362831858407,
        "end": 5194.36,
        "id": 1533,
        "no_speech_prob": 0.004133932758122683,
        "seek": 518436,
        "start": 5193.36,
        "temperature": 0,
        "text": " Sorry.",
        "tokens": [
          50814,
          4919,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.15973357877869537,
        "compression_ratio": 1.7743362831858407,
        "end": 5197.36,
        "id": 1534,
        "no_speech_prob": 0.004133932758122683,
        "seek": 518436,
        "start": 5194.36,
        "temperature": 0,
        "text": " So, I want to say let and I'm going to call it a path.",
        "tokens": [
          50864,
          407,
          11,
          286,
          528,
          281,
          584,
          718,
          293,
          286,
          478,
          516,
          281,
          818,
          309,
          257,
          3100,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.15973357877869537,
        "compression_ratio": 1.7743362831858407,
        "end": 5200.36,
        "id": 1535,
        "no_speech_prob": 0.004133932758122683,
        "seek": 518436,
        "start": 5197.36,
        "temperature": 0,
        "text": " So, for let path of drawing.",
        "tokens": [
          51014,
          407,
          11,
          337,
          718,
          3100,
          295,
          6316,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.15973357877869537,
        "compression_ratio": 1.7743362831858407,
        "end": 5202.36,
        "id": 1536,
        "no_speech_prob": 0.004133932758122683,
        "seek": 518436,
        "start": 5200.36,
        "temperature": 0,
        "text": " This is each and every path.",
        "tokens": [
          51164,
          639,
          307,
          1184,
          293,
          633,
          3100,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.15973357877869537,
        "compression_ratio": 1.7743362831858407,
        "end": 5204.36,
        "id": 1537,
        "no_speech_prob": 0.004133932758122683,
        "seek": 518436,
        "start": 5202.36,
        "temperature": 0,
        "text": " Path 0, path 1, path 2.",
        "tokens": [
          51264,
          21914,
          1958,
          11,
          3100,
          502,
          11,
          3100,
          568,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.15973357877869537,
        "compression_ratio": 1.7743362831858407,
        "end": 5206.36,
        "id": 1538,
        "no_speech_prob": 0.004133932758122683,
        "seek": 518436,
        "start": 5204.36,
        "temperature": 0,
        "text": " Then, each path has a bunch of points.",
        "tokens": [
          51364,
          1396,
          11,
          1184,
          3100,
          575,
          257,
          3840,
          295,
          2793,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.15973357877869537,
        "compression_ratio": 1.7743362831858407,
        "end": 5211.36,
        "id": 1539,
        "no_speech_prob": 0.004133932758122683,
        "seek": 518436,
        "start": 5206.36,
        "temperature": 0,
        "text": " Path 0 has 15, path 1 has 10, path 2 has 6.",
        "tokens": [
          51464,
          21914,
          1958,
          575,
          2119,
          11,
          3100,
          502,
          575,
          1266,
          11,
          3100,
          568,
          575,
          1386,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1902053451538086,
        "compression_ratio": 1.528735632183908,
        "end": 5219.36,
        "id": 1540,
        "no_speech_prob": 0.003824470331892371,
        "seek": 521136,
        "start": 5211.36,
        "temperature": 0,
        "text": " I'm going to say for let i equals 0, i is less than path index 0 dot length.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          584,
          337,
          718,
          741,
          6915,
          1958,
          11,
          741,
          307,
          1570,
          813,
          3100,
          8186,
          1958,
          5893,
          4641,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1902053451538086,
        "compression_ratio": 1.528735632183908,
        "end": 5227.36,
        "id": 1541,
        "no_speech_prob": 0.003824470331892371,
        "seek": 521136,
        "start": 5219.36,
        "temperature": 0,
        "text": " And then, the x is path index 0 index 1.",
        "tokens": [
          50764,
          400,
          550,
          11,
          264,
          2031,
          307,
          3100,
          8186,
          1958,
          8186,
          502,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1902053451538086,
        "compression_ratio": 1.528735632183908,
        "end": 5229.36,
        "id": 1542,
        "no_speech_prob": 0.003824470331892371,
        "seek": 521136,
        "start": 5227.36,
        "temperature": 0,
        "text": " Wait, no, index i.",
        "tokens": [
          51164,
          3802,
          11,
          572,
          11,
          8186,
          741,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1902053451538086,
        "compression_ratio": 1.528735632183908,
        "end": 5230.36,
        "id": 1543,
        "no_speech_prob": 0.003824470331892371,
        "seek": 521136,
        "start": 5229.36,
        "temperature": 0,
        "text": " Oh, sorry.",
        "tokens": [
          51264,
          876,
          11,
          2597,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1902053451538086,
        "compression_ratio": 1.528735632183908,
        "end": 5231.36,
        "id": 1544,
        "no_speech_prob": 0.003824470331892371,
        "seek": 521136,
        "start": 5230.36,
        "temperature": 0,
        "text": " This is confusing.",
        "tokens": [
          51314,
          639,
          307,
          13181,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1902053451538086,
        "compression_ratio": 1.528735632183908,
        "end": 5234.36,
        "id": 1545,
        "no_speech_prob": 0.003824470331892371,
        "seek": 521136,
        "start": 5231.36,
        "temperature": 0,
        "text": " And the y is path index 1 index i.",
        "tokens": [
          51364,
          400,
          264,
          288,
          307,
          3100,
          8186,
          502,
          8186,
          741,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1902053451538086,
        "compression_ratio": 1.528735632183908,
        "end": 5235.36,
        "id": 1546,
        "no_speech_prob": 0.003824470331892371,
        "seek": 521136,
        "start": 5234.36,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          51514,
          1779,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.1902053451538086,
        "compression_ratio": 1.528735632183908,
        "end": 5236.36,
        "id": 1547,
        "no_speech_prob": 0.003824470331892371,
        "seek": 521136,
        "start": 5235.36,
        "temperature": 0,
        "text": " So, this is what I'm doing.",
        "tokens": [
          51564,
          407,
          11,
          341,
          307,
          437,
          286,
          478,
          884,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1902053451538086,
        "compression_ratio": 1.528735632183908,
        "end": 5239.36,
        "id": 1548,
        "no_speech_prob": 0.003824470331892371,
        "seek": 521136,
        "start": 5236.36,
        "temperature": 0,
        "text": " I am looping through 0, 1, 2.",
        "tokens": [
          51614,
          286,
          669,
          6367,
          278,
          807,
          1958,
          11,
          502,
          11,
          568,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1644955895163796,
        "compression_ratio": 1.658682634730539,
        "end": 5240.36,
        "id": 1549,
        "no_speech_prob": 0.01048901118338108,
        "seek": 523936,
        "start": 5239.36,
        "temperature": 0,
        "text": " 0, 1, 2.",
        "tokens": [
          50364,
          1958,
          11,
          502,
          11,
          568,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.1644955895163796,
        "compression_ratio": 1.658682634730539,
        "end": 5242.36,
        "id": 1550,
        "no_speech_prob": 0.01048901118338108,
        "seek": 523936,
        "start": 5240.36,
        "temperature": 0,
        "text": " That's the outer loop.",
        "tokens": [
          50414,
          663,
          311,
          264,
          10847,
          6367,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1644955895163796,
        "compression_ratio": 1.658682634730539,
        "end": 5243.36,
        "id": 1551,
        "no_speech_prob": 0.01048901118338108,
        "seek": 523936,
        "start": 5242.36,
        "temperature": 0,
        "text": " Each path.",
        "tokens": [
          50514,
          6947,
          3100,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1644955895163796,
        "compression_ratio": 1.658682634730539,
        "end": 5246.36,
        "id": 1552,
        "no_speech_prob": 0.01048901118338108,
        "seek": 523936,
        "start": 5243.36,
        "temperature": 0,
        "text": " Each path is two arrays.",
        "tokens": [
          50564,
          6947,
          3100,
          307,
          732,
          41011,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1644955895163796,
        "compression_ratio": 1.658682634730539,
        "end": 5248.36,
        "id": 1553,
        "no_speech_prob": 0.01048901118338108,
        "seek": 523936,
        "start": 5246.36,
        "temperature": 0,
        "text": " Path 0 is all the x's.",
        "tokens": [
          50714,
          21914,
          1958,
          307,
          439,
          264,
          2031,
          311,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1644955895163796,
        "compression_ratio": 1.658682634730539,
        "end": 5249.36,
        "id": 1554,
        "no_speech_prob": 0.01048901118338108,
        "seek": 523936,
        "start": 5248.36,
        "temperature": 0,
        "text": " Path 1 is all the y's.",
        "tokens": [
          50814,
          21914,
          502,
          307,
          439,
          264,
          288,
          311,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1644955895163796,
        "compression_ratio": 1.658682634730539,
        "end": 5254.36,
        "id": 1555,
        "no_speech_prob": 0.01048901118338108,
        "seek": 523936,
        "start": 5249.36,
        "temperature": 0,
        "text": " I need to look at all the x's and all the y's and then set a vertex x comma y.",
        "tokens": [
          50864,
          286,
          643,
          281,
          574,
          412,
          439,
          264,
          2031,
          311,
          293,
          439,
          264,
          288,
          311,
          293,
          550,
          992,
          257,
          28162,
          2031,
          22117,
          288,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1644955895163796,
        "compression_ratio": 1.658682634730539,
        "end": 5260.36,
        "id": 1556,
        "no_speech_prob": 0.01048901118338108,
        "seek": 523936,
        "start": 5254.36,
        "temperature": 0,
        "text": " So, I can say begin shape, end shape.",
        "tokens": [
          51114,
          407,
          11,
          286,
          393,
          584,
          1841,
          3909,
          11,
          917,
          3909,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1644955895163796,
        "compression_ratio": 1.658682634730539,
        "end": 5265.36,
        "id": 1557,
        "no_speech_prob": 0.01048901118338108,
        "seek": 523936,
        "start": 5260.36,
        "temperature": 0,
        "text": " I can say no fill, stroke 0.",
        "tokens": [
          51414,
          286,
          393,
          584,
          572,
          2836,
          11,
          12403,
          1958,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1644955895163796,
        "compression_ratio": 1.658682634730539,
        "end": 5266.36,
        "id": 1558,
        "no_speech_prob": 0.01048901118338108,
        "seek": 523936,
        "start": 5265.36,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          51664,
          45263,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1644955895163796,
        "compression_ratio": 1.658682634730539,
        "end": 5267.36,
        "id": 1559,
        "no_speech_prob": 0.01048901118338108,
        "seek": 523936,
        "start": 5266.36,
        "temperature": 0,
        "text": " Stroke 0.",
        "tokens": [
          51714,
          42196,
          330,
          1958,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17376892218429052,
        "compression_ratio": 1.4653465346534653,
        "end": 5273.36,
        "id": 1560,
        "no_speech_prob": 0.0022872190456837416,
        "seek": 526736,
        "start": 5267.36,
        "temperature": 0,
        "text": " And maybe I'll say stroke weight 3 just to make the lines a little bit thicker.",
        "tokens": [
          50364,
          400,
          1310,
          286,
          603,
          584,
          12403,
          3364,
          805,
          445,
          281,
          652,
          264,
          3876,
          257,
          707,
          857,
          18142,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17376892218429052,
        "compression_ratio": 1.4653465346534653,
        "end": 5275.36,
        "id": 1561,
        "no_speech_prob": 0.0022872190456837416,
        "seek": 526736,
        "start": 5273.36,
        "temperature": 0,
        "text": " And let's see what I see.",
        "tokens": [
          50664,
          400,
          718,
          311,
          536,
          437,
          286,
          536,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.17376892218429052,
        "compression_ratio": 1.4653465346534653,
        "end": 5277.36,
        "id": 1562,
        "no_speech_prob": 0.0022872190456837416,
        "seek": 526736,
        "start": 5275.36,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50764,
          821,
          321,
          352,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.17376892218429052,
        "compression_ratio": 1.4653465346534653,
        "end": 5278.36,
        "id": 1563,
        "no_speech_prob": 0.0022872190456837416,
        "seek": 526736,
        "start": 5277.36,
        "temperature": 0,
        "text": " Rainbows.",
        "tokens": [
          50864,
          14487,
          21118,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17376892218429052,
        "compression_ratio": 1.4653465346534653,
        "end": 5280.36,
        "id": 1564,
        "no_speech_prob": 0.0022872190456837416,
        "seek": 526736,
        "start": 5278.36,
        "temperature": 0,
        "text": " Rainbows galore.",
        "tokens": [
          50914,
          14487,
          21118,
          7660,
          418,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17376892218429052,
        "compression_ratio": 1.4653465346534653,
        "end": 5283.36,
        "id": 1565,
        "no_speech_prob": 0.0022872190456837416,
        "seek": 526736,
        "start": 5280.36,
        "temperature": 0,
        "text": " These are everybody's rainbows each time I hit refresh.",
        "tokens": [
          51014,
          1981,
          366,
          2201,
          311,
          4830,
          21118,
          1184,
          565,
          286,
          2045,
          15134,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.17376892218429052,
        "compression_ratio": 1.4653465346534653,
        "end": 5290.36,
        "id": 1566,
        "no_speech_prob": 0.0022872190456837416,
        "seek": 526736,
        "start": 5283.36,
        "temperature": 0,
        "text": " You know, one thing I could do now is when it finishes, I could just say like load JSON again.",
        "tokens": [
          51164,
          509,
          458,
          11,
          472,
          551,
          286,
          727,
          360,
          586,
          307,
          562,
          309,
          23615,
          11,
          286,
          727,
          445,
          584,
          411,
          3677,
          31828,
          797,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2172854777132527,
        "compression_ratio": 1.5450236966824644,
        "end": 5293.36,
        "id": 1567,
        "no_speech_prob": 0.01826336234807968,
        "seek": 529036,
        "start": 5291.36,
        "temperature": 0,
        "text": " Ooh.",
        "tokens": [
          50414,
          7951,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2172854777132527,
        "compression_ratio": 1.5450236966824644,
        "end": 5299.36,
        "id": 1568,
        "no_speech_prob": 0.01826336234807968,
        "seek": 529036,
        "start": 5293.36,
        "temperature": 0,
        "text": " Maybe I would want to redraw the background every time.",
        "tokens": [
          50514,
          2704,
          286,
          576,
          528,
          281,
          2182,
          5131,
          264,
          3678,
          633,
          565,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2172854777132527,
        "compression_ratio": 1.5450236966824644,
        "end": 5301.36,
        "id": 1569,
        "no_speech_prob": 0.01826336234807968,
        "seek": 529036,
        "start": 5299.36,
        "temperature": 0,
        "text": " That might make sense.",
        "tokens": [
          50814,
          663,
          1062,
          652,
          2020,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2172854777132527,
        "compression_ratio": 1.5450236966824644,
        "end": 5303.36,
        "id": 1570,
        "no_speech_prob": 0.01826336234807968,
        "seek": 529036,
        "start": 5301.36,
        "temperature": 0,
        "text": " And here we go.",
        "tokens": [
          50914,
          400,
          510,
          321,
          352,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2172854777132527,
        "compression_ratio": 1.5450236966824644,
        "end": 5306.36,
        "id": 1571,
        "no_speech_prob": 0.01826336234807968,
        "seek": 529036,
        "start": 5303.36,
        "temperature": 0,
        "text": " This is a random drawing over and over and over again.",
        "tokens": [
          51014,
          639,
          307,
          257,
          4974,
          6316,
          670,
          293,
          670,
          293,
          670,
          797,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2172854777132527,
        "compression_ratio": 1.5450236966824644,
        "end": 5310.36,
        "id": 1572,
        "no_speech_prob": 0.01826336234807968,
        "seek": 529036,
        "start": 5306.36,
        "temperature": 0,
        "text": " So, I could start to do things like request a specific drawing from a certain country.",
        "tokens": [
          51164,
          407,
          11,
          286,
          727,
          722,
          281,
          360,
          721,
          411,
          5308,
          257,
          2685,
          6316,
          490,
          257,
          1629,
          1941,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2172854777132527,
        "compression_ratio": 1.5450236966824644,
        "end": 5315.36,
        "id": 1573,
        "no_speech_prob": 0.01826336234807968,
        "seek": 529036,
        "start": 5310.36,
        "temperature": 0,
        "text": " I could download different models.",
        "tokens": [
          51364,
          286,
          727,
          5484,
          819,
          5245,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2172854777132527,
        "compression_ratio": 1.5450236966824644,
        "end": 5318.36,
        "id": 1574,
        "no_speech_prob": 0.01826336234807968,
        "seek": 529036,
        "start": 5315.36,
        "temperature": 0,
        "text": " Let me pause for a second and grab another model.",
        "tokens": [
          51614,
          961,
          385,
          10465,
          337,
          257,
          1150,
          293,
          4444,
          1071,
          2316,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.27130033455643,
        "compression_ratio": 1.1559633027522935,
        "end": 5325.36,
        "id": 1575,
        "no_speech_prob": 0.004007278475910425,
        "seek": 531836,
        "start": 5318.36,
        "temperature": 0,
        "text": " So, let's get...",
        "tokens": [
          50364,
          407,
          11,
          718,
          311,
          483,
          485,
          50714
        ]
      },
      {
        "avg_logprob": -0.27130033455643,
        "compression_ratio": 1.1559633027522935,
        "end": 5328.36,
        "id": 1576,
        "no_speech_prob": 0.004007278475910425,
        "seek": 531836,
        "start": 5325.36,
        "temperature": 0,
        "text": " What's a good one?",
        "tokens": [
          50714,
          708,
          311,
          257,
          665,
          472,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.27130033455643,
        "compression_ratio": 1.1559633027522935,
        "end": 5338.36,
        "id": 1577,
        "no_speech_prob": 0.004007278475910425,
        "seek": 531836,
        "start": 5328.36,
        "temperature": 0,
        "text": " Apple, asparagus, axe.",
        "tokens": [
          50864,
          6373,
          11,
          382,
          49537,
          11,
          30195,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.27130033455643,
        "compression_ratio": 1.1559633027522935,
        "end": 5341.36,
        "id": 1578,
        "no_speech_prob": 0.004007278475910425,
        "seek": 531836,
        "start": 5338.36,
        "temperature": 0,
        "text": " I mean, cat is sort of like the typical one.",
        "tokens": [
          51364,
          286,
          914,
          11,
          3857,
          307,
          1333,
          295,
          411,
          264,
          7476,
          472,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.27130033455643,
        "compression_ratio": 1.1559633027522935,
        "end": 5343.36,
        "id": 1579,
        "no_speech_prob": 0.004007278475910425,
        "seek": 531836,
        "start": 5341.36,
        "temperature": 0,
        "text": " So, let's just do cat.",
        "tokens": [
          51514,
          407,
          11,
          718,
          311,
          445,
          360,
          3857,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2887677431106567,
        "compression_ratio": 1.1157894736842104,
        "end": 5348.36,
        "id": 1580,
        "no_speech_prob": 0.028435181826353073,
        "seek": 534336,
        "start": 5344.36,
        "temperature": 0,
        "text": " So many.",
        "tokens": [
          50414,
          407,
          867,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2887677431106567,
        "compression_ratio": 1.1157894736842104,
        "end": 5365.36,
        "id": 1581,
        "no_speech_prob": 0.028435181826353073,
        "seek": 534336,
        "start": 5364.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51414,
          1057,
          558,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2887677431106567,
        "compression_ratio": 1.1157894736842104,
        "end": 5368.36,
        "id": 1582,
        "no_speech_prob": 0.028435181826353073,
        "seek": 534336,
        "start": 5365.36,
        "temperature": 0,
        "text": " I downloaded the cat file now.",
        "tokens": [
          51464,
          286,
          21748,
          264,
          3857,
          3991,
          586,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2887677431106567,
        "compression_ratio": 1.1157894736842104,
        "end": 5370.36,
        "id": 1583,
        "no_speech_prob": 0.028435181826353073,
        "seek": 534336,
        "start": 5368.36,
        "temperature": 0,
        "text": " And I'm just going to put that in here as well.",
        "tokens": [
          51614,
          400,
          286,
          478,
          445,
          516,
          281,
          829,
          300,
          294,
          510,
          382,
          731,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2887677431106567,
        "compression_ratio": 1.1157894736842104,
        "end": 5371.36,
        "id": 1584,
        "no_speech_prob": 0.028435181826353073,
        "seek": 534336,
        "start": 5370.36,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          51714,
          45263,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2853096600236564,
        "compression_ratio": 1.2037037037037037,
        "end": 5373.36,
        "id": 1585,
        "no_speech_prob": 0.014062038622796535,
        "seek": 537136,
        "start": 5371.36,
        "temperature": 0,
        "text": " Did I put that somewhere weird?",
        "tokens": [
          50364,
          2589,
          286,
          829,
          300,
          4079,
          3657,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.2853096600236564,
        "compression_ratio": 1.2037037037037037,
        "end": 5374.36,
        "id": 1586,
        "no_speech_prob": 0.014062038622796535,
        "seek": 537136,
        "start": 5373.36,
        "temperature": 0,
        "text": " No, I...",
        "tokens": [
          50464,
          883,
          11,
          286,
          485,
          50514
        ]
      },
      {
        "avg_logprob": -0.2853096600236564,
        "compression_ratio": 1.2037037037037037,
        "end": 5375.36,
        "id": 1587,
        "no_speech_prob": 0.014062038622796535,
        "seek": 537136,
        "start": 5374.36,
        "temperature": 0,
        "text": " Ah, sorry.",
        "tokens": [
          50514,
          2438,
          11,
          2597,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2853096600236564,
        "compression_ratio": 1.2037037037037037,
        "end": 5379.36,
        "id": 1588,
        "no_speech_prob": 0.014062038622796535,
        "seek": 537136,
        "start": 5375.36,
        "temperature": 0,
        "text": " Sorry, let me do that again.",
        "tokens": [
          50564,
          4919,
          11,
          718,
          385,
          360,
          300,
          797,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2853096600236564,
        "compression_ratio": 1.2037037037037037,
        "end": 5382.36,
        "id": 1589,
        "no_speech_prob": 0.014062038622796535,
        "seek": 537136,
        "start": 5379.36,
        "temperature": 0,
        "text": " Delete.",
        "tokens": [
          50764,
          49452,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2853096600236564,
        "compression_ratio": 1.2037037037037037,
        "end": 5384.36,
        "id": 1590,
        "no_speech_prob": 0.014062038622796535,
        "seek": 537136,
        "start": 5382.36,
        "temperature": 0,
        "text": " Ah, shoot.",
        "tokens": [
          50914,
          2438,
          11,
          3076,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2853096600236564,
        "compression_ratio": 1.2037037037037037,
        "end": 5394.36,
        "id": 1591,
        "no_speech_prob": 0.014062038622796535,
        "seek": 537136,
        "start": 5384.36,
        "temperature": 0,
        "text": " Ah.",
        "tokens": [
          51014,
          2438,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2853096600236564,
        "compression_ratio": 1.2037037037037037,
        "end": 5395.36,
        "id": 1592,
        "no_speech_prob": 0.014062038622796535,
        "seek": 537136,
        "start": 5394.36,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          51514,
          6962,
          322,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2853096600236564,
        "compression_ratio": 1.2037037037037037,
        "end": 5396.36,
        "id": 1593,
        "no_speech_prob": 0.014062038622796535,
        "seek": 537136,
        "start": 5395.36,
        "temperature": 0,
        "text": " Sorry, everybody.",
        "tokens": [
          51564,
          4919,
          11,
          2201,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1890287901225843,
        "compression_ratio": 1.6482412060301508,
        "end": 5403.36,
        "id": 1594,
        "no_speech_prob": 0.05419198051095009,
        "seek": 539636,
        "start": 5396.36,
        "temperature": 0,
        "text": " Ah, here we go.",
        "tokens": [
          50364,
          2438,
          11,
          510,
          321,
          352,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1890287901225843,
        "compression_ratio": 1.6482412060301508,
        "end": 5407.36,
        "id": 1595,
        "no_speech_prob": 0.05419198051095009,
        "seek": 539636,
        "start": 5403.36,
        "temperature": 0,
        "text": " Okay, so I downloaded one more set of drawings, the cat files.",
        "tokens": [
          50714,
          1033,
          11,
          370,
          286,
          21748,
          472,
          544,
          992,
          295,
          18618,
          11,
          264,
          3857,
          7098,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1890287901225843,
        "compression_ratio": 1.6482412060301508,
        "end": 5408.36,
        "id": 1596,
        "no_speech_prob": 0.05419198051095009,
        "seek": 539636,
        "start": 5407.36,
        "temperature": 0,
        "text": " So, I'm going to...",
        "tokens": [
          50914,
          407,
          11,
          286,
          478,
          516,
          281,
          485,
          50964
        ]
      },
      {
        "avg_logprob": -0.1890287901225843,
        "compression_ratio": 1.6482412060301508,
        "end": 5411.36,
        "id": 1597,
        "no_speech_prob": 0.05419198051095009,
        "seek": 539636,
        "start": 5408.36,
        "temperature": 0,
        "text": " The cat drawings, I'm going to copy that into here.",
        "tokens": [
          50964,
          440,
          3857,
          18618,
          11,
          286,
          478,
          516,
          281,
          5055,
          300,
          666,
          510,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1890287901225843,
        "compression_ratio": 1.6482412060301508,
        "end": 5414.36,
        "id": 1598,
        "no_speech_prob": 0.05419198051095009,
        "seek": 539636,
        "start": 5411.36,
        "temperature": 0,
        "text": " And we can see now I have cat.nd.json.",
        "tokens": [
          51114,
          400,
          321,
          393,
          536,
          586,
          286,
          362,
          3857,
          13,
          273,
          13,
          73,
          3015,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1890287901225843,
        "compression_ratio": 1.6482412060301508,
        "end": 5417.36,
        "id": 1599,
        "no_speech_prob": 0.05419198051095009,
        "seek": 539636,
        "start": 5414.36,
        "temperature": 0,
        "text": " If I go back to my server, I could do...",
        "tokens": [
          51264,
          759,
          286,
          352,
          646,
          281,
          452,
          7154,
          11,
          286,
          727,
          360,
          485,
          51414
        ]
      },
      {
        "avg_logprob": -0.1890287901225843,
        "compression_ratio": 1.6482412060301508,
        "end": 5418.36,
        "id": 1600,
        "no_speech_prob": 0.05419198051095009,
        "seek": 539636,
        "start": 5417.36,
        "temperature": 0,
        "text": " I'm going to say...",
        "tokens": [
          51414,
          286,
          478,
          516,
          281,
          584,
          485,
          51464
        ]
      },
      {
        "avg_logprob": -0.1890287901225843,
        "compression_ratio": 1.6482412060301508,
        "end": 5421.36,
        "id": 1601,
        "no_speech_prob": 0.05419198051095009,
        "seek": 539636,
        "start": 5418.36,
        "temperature": 0,
        "text": " I'm going to call this rainbows.",
        "tokens": [
          51464,
          286,
          478,
          516,
          281,
          818,
          341,
          4830,
          21118,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1890287901225843,
        "compression_ratio": 1.6482412060301508,
        "end": 5425.36,
        "id": 1602,
        "no_speech_prob": 0.05419198051095009,
        "seek": 539636,
        "start": 5421.36,
        "temperature": 0,
        "text": " And I'm going to do a different one for cat.",
        "tokens": [
          51614,
          400,
          286,
          478,
          516,
          281,
          360,
          257,
          819,
          472,
          337,
          3857,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.20014428401338882,
        "compression_ratio": 1.4545454545454546,
        "end": 5429.36,
        "id": 1603,
        "no_speech_prob": 0.000984991085715592,
        "seek": 542536,
        "start": 5425.36,
        "temperature": 0,
        "text": " And I'm also going to do cats.",
        "tokens": [
          50364,
          400,
          286,
          478,
          611,
          516,
          281,
          360,
          11111,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.20014428401338882,
        "compression_ratio": 1.4545454545454546,
        "end": 5431.36,
        "id": 1604,
        "no_speech_prob": 0.000984991085715592,
        "seek": 542536,
        "start": 5429.36,
        "temperature": 0,
        "text": " Cats push object.",
        "tokens": [
          50564,
          40902,
          2944,
          2657,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20014428401338882,
        "compression_ratio": 1.4545454545454546,
        "end": 5441.36,
        "id": 1605,
        "no_speech_prob": 0.000984991085715592,
        "seek": 542536,
        "start": 5431.36,
        "temperature": 0,
        "text": " And then I'm going to make another route for cats.",
        "tokens": [
          50664,
          400,
          550,
          286,
          478,
          516,
          281,
          652,
          1071,
          7955,
          337,
          11111,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.20014428401338882,
        "compression_ratio": 1.4545454545454546,
        "end": 5447.36,
        "id": 1606,
        "no_speech_prob": 0.000984991085715592,
        "seek": 542536,
        "start": 5441.36,
        "temperature": 0,
        "text": " So, now, if I rerun the server...",
        "tokens": [
          51164,
          407,
          11,
          586,
          11,
          498,
          286,
          43819,
          409,
          264,
          7154,
          485,
          51464
        ]
      },
      {
        "avg_logprob": -0.20014428401338882,
        "compression_ratio": 1.4545454545454546,
        "end": 5450.36,
        "id": 1607,
        "no_speech_prob": 0.000984991085715592,
        "seek": 542536,
        "start": 5447.36,
        "temperature": 0,
        "text": " And I go back to my actual sketch.",
        "tokens": [
          51464,
          400,
          286,
          352,
          646,
          281,
          452,
          3539,
          12325,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20014428401338882,
        "compression_ratio": 1.4545454545454546,
        "end": 5454.36,
        "id": 1608,
        "no_speech_prob": 0.000984991085715592,
        "seek": 542536,
        "start": 5450.36,
        "temperature": 0,
        "text": " And I switch to going to the cat route.",
        "tokens": [
          51614,
          400,
          286,
          3679,
          281,
          516,
          281,
          264,
          3857,
          7955,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1282992446631716,
        "compression_ratio": 1.570754716981132,
        "end": 5456.36,
        "id": 1609,
        "no_speech_prob": 0.0028895174618810415,
        "seek": 545436,
        "start": 5454.36,
        "temperature": 0,
        "text": " Now, where was that?",
        "tokens": [
          50364,
          823,
          11,
          689,
          390,
          300,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.1282992446631716,
        "compression_ratio": 1.570754716981132,
        "end": 5457.36,
        "id": 1610,
        "no_speech_prob": 0.0028895174618810415,
        "seek": 545436,
        "start": 5456.36,
        "temperature": 0,
        "text": " Here I am.",
        "tokens": [
          50464,
          1692,
          286,
          669,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1282992446631716,
        "compression_ratio": 1.570754716981132,
        "end": 5459.36,
        "id": 1611,
        "no_speech_prob": 0.0028895174618810415,
        "seek": 545436,
        "start": 5457.36,
        "temperature": 0,
        "text": " I'm going to hit enter.",
        "tokens": [
          50514,
          286,
          478,
          516,
          281,
          2045,
          3242,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1282992446631716,
        "compression_ratio": 1.570754716981132,
        "end": 5461.36,
        "id": 1612,
        "no_speech_prob": 0.0028895174618810415,
        "seek": 545436,
        "start": 5459.36,
        "temperature": 0,
        "text": " Ooh, I got some issue.",
        "tokens": [
          50614,
          7951,
          11,
          286,
          658,
          512,
          2734,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1282992446631716,
        "compression_ratio": 1.570754716981132,
        "end": 5463.36,
        "id": 1613,
        "no_speech_prob": 0.0028895174618810415,
        "seek": 545436,
        "start": 5461.36,
        "temperature": 0,
        "text": " Cat internal server error.",
        "tokens": [
          50714,
          9565,
          6920,
          7154,
          6713,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1282992446631716,
        "compression_ratio": 1.570754716981132,
        "end": 5466.36,
        "id": 1614,
        "no_speech_prob": 0.0028895174618810415,
        "seek": 545436,
        "start": 5463.36,
        "temperature": 0,
        "text": " So, what's going on here?",
        "tokens": [
          50814,
          407,
          11,
          437,
          311,
          516,
          322,
          510,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.1282992446631716,
        "compression_ratio": 1.570754716981132,
        "end": 5468.36,
        "id": 1615,
        "no_speech_prob": 0.0028895174618810415,
        "seek": 545436,
        "start": 5466.36,
        "temperature": 0,
        "text": " Drawings is not defined.",
        "tokens": [
          50964,
          20386,
          1109,
          307,
          406,
          7642,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1282992446631716,
        "compression_ratio": 1.570754716981132,
        "end": 5471.36,
        "id": 1616,
        "no_speech_prob": 0.0028895174618810415,
        "seek": 545436,
        "start": 5468.36,
        "temperature": 0,
        "text": " So, I made a mistake in my server.",
        "tokens": [
          51064,
          407,
          11,
          286,
          1027,
          257,
          6146,
          294,
          452,
          7154,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1282992446631716,
        "compression_ratio": 1.570754716981132,
        "end": 5473.36,
        "id": 1617,
        "no_speech_prob": 0.0028895174618810415,
        "seek": 545436,
        "start": 5471.36,
        "temperature": 0,
        "text": " Oh, this is...",
        "tokens": [
          51214,
          876,
          11,
          341,
          307,
          485,
          51314
        ]
      },
      {
        "avg_logprob": -0.1282992446631716,
        "compression_ratio": 1.570754716981132,
        "end": 5476.36,
        "id": 1618,
        "no_speech_prob": 0.0028895174618810415,
        "seek": 545436,
        "start": 5473.36,
        "temperature": 0,
        "text": " Over here is rainbows.length.",
        "tokens": [
          51314,
          4886,
          510,
          307,
          4830,
          21118,
          13,
          45390,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1282992446631716,
        "compression_ratio": 1.570754716981132,
        "end": 5479.36,
        "id": 1619,
        "no_speech_prob": 0.0028895174618810415,
        "seek": 545436,
        "start": 5476.36,
        "temperature": 0,
        "text": " And this is cats.length.",
        "tokens": [
          51464,
          400,
          341,
          307,
          11111,
          13,
          45390,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1282992446631716,
        "compression_ratio": 1.570754716981132,
        "end": 5483.36,
        "id": 1620,
        "no_speech_prob": 0.0028895174618810415,
        "seek": 545436,
        "start": 5479.36,
        "temperature": 0,
        "text": " And I would have seen that error here if I was paying closer attention.",
        "tokens": [
          51614,
          400,
          286,
          576,
          362,
          1612,
          300,
          6713,
          510,
          498,
          286,
          390,
          6229,
          4966,
          3202,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19000922527509867,
        "compression_ratio": 1.4486486486486487,
        "end": 5485.36,
        "id": 1621,
        "no_speech_prob": 0.00955886673182249,
        "seek": 548336,
        "start": 5483.36,
        "temperature": 0,
        "text": " There, now I've got cats.",
        "tokens": [
          50364,
          821,
          11,
          586,
          286,
          600,
          658,
          11111,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.19000922527509867,
        "compression_ratio": 1.4486486486486487,
        "end": 5489.36,
        "id": 1622,
        "no_speech_prob": 0.00955886673182249,
        "seek": 548336,
        "start": 5485.36,
        "temperature": 0,
        "text": " And now, let's look at a lot of cats.",
        "tokens": [
          50464,
          400,
          586,
          11,
          718,
          311,
          574,
          412,
          257,
          688,
          295,
          11111,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19000922527509867,
        "compression_ratio": 1.4486486486486487,
        "end": 5493.36,
        "id": 1623,
        "no_speech_prob": 0.00955886673182249,
        "seek": 548336,
        "start": 5489.36,
        "temperature": 0,
        "text": " Ooh, it's still giving me rainbows.",
        "tokens": [
          50664,
          7951,
          11,
          309,
          311,
          920,
          2902,
          385,
          4830,
          21118,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19000922527509867,
        "compression_ratio": 1.4486486486486487,
        "end": 5496.36,
        "id": 1624,
        "no_speech_prob": 0.00955886673182249,
        "seek": 548336,
        "start": 5493.36,
        "temperature": 0,
        "text": " Did I not hit save?",
        "tokens": [
          50864,
          2589,
          286,
          406,
          2045,
          3155,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.19000922527509867,
        "compression_ratio": 1.4486486486486487,
        "end": 5499.36,
        "id": 1625,
        "no_speech_prob": 0.00955886673182249,
        "seek": 548336,
        "start": 5496.36,
        "temperature": 0,
        "text": " Load JSON cat.",
        "tokens": [
          51014,
          48408,
          31828,
          3857,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19000922527509867,
        "compression_ratio": 1.4486486486486487,
        "end": 5501.36,
        "id": 1626,
        "no_speech_prob": 0.00955886673182249,
        "seek": 548336,
        "start": 5499.36,
        "temperature": 0,
        "text": " Oh, load JSON cat.",
        "tokens": [
          51164,
          876,
          11,
          3677,
          31828,
          3857,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19000922527509867,
        "compression_ratio": 1.4486486486486487,
        "end": 5504.36,
        "id": 1627,
        "no_speech_prob": 0.00955886673182249,
        "seek": 548336,
        "start": 5501.36,
        "temperature": 0,
        "text": " Whatever, I'm not being too thoughtful about this.",
        "tokens": [
          51264,
          8541,
          11,
          286,
          478,
          406,
          885,
          886,
          21566,
          466,
          341,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19000922527509867,
        "compression_ratio": 1.4486486486486487,
        "end": 5505.36,
        "id": 1628,
        "no_speech_prob": 0.00955886673182249,
        "seek": 548336,
        "start": 5504.36,
        "temperature": 0,
        "text": " Give me the cats!",
        "tokens": [
          51414,
          5303,
          385,
          264,
          11111,
          0,
          51464
        ]
      },
      {
        "avg_logprob": -0.19000922527509867,
        "compression_ratio": 1.4486486486486487,
        "end": 5508.36,
        "id": 1629,
        "no_speech_prob": 0.00955886673182249,
        "seek": 548336,
        "start": 5505.36,
        "temperature": 0,
        "text": " I want to see the meow meow!",
        "tokens": [
          51464,
          286,
          528,
          281,
          536,
          264,
          45132,
          45132,
          0,
          51614
        ]
      },
      {
        "avg_logprob": -0.19000922527509867,
        "compression_ratio": 1.4486486486486487,
        "end": 5511.36,
        "id": 1630,
        "no_speech_prob": 0.00955886673182249,
        "seek": 548336,
        "start": 5508.36,
        "temperature": 0,
        "text": " What's going on?",
        "tokens": [
          51614,
          708,
          311,
          516,
          322,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.2227596225160541,
        "compression_ratio": 1.295774647887324,
        "end": 5514.36,
        "id": 1631,
        "no_speech_prob": 0.010169440880417824,
        "seek": 551136,
        "start": 5511.36,
        "temperature": 0,
        "text": " Run the server again.",
        "tokens": [
          50364,
          8950,
          264,
          7154,
          797,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2227596225160541,
        "compression_ratio": 1.295774647887324,
        "end": 5521.36,
        "id": 1632,
        "no_speech_prob": 0.010169440880417824,
        "seek": 551136,
        "start": 5518.36,
        "temperature": 0,
        "text": " Let me refresh this page.",
        "tokens": [
          50714,
          961,
          385,
          15134,
          341,
          3028,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2227596225160541,
        "compression_ratio": 1.295774647887324,
        "end": 5523.36,
        "id": 1633,
        "no_speech_prob": 0.010169440880417824,
        "seek": 551136,
        "start": 5521.36,
        "temperature": 0,
        "text": " It's still rainbows.",
        "tokens": [
          50864,
          467,
          311,
          920,
          4830,
          21118,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2227596225160541,
        "compression_ratio": 1.295774647887324,
        "end": 5527.36,
        "id": 1634,
        "no_speech_prob": 0.010169440880417824,
        "seek": 551136,
        "start": 5523.36,
        "temperature": 0,
        "text": " Cat, cat, got rainbow.",
        "tokens": [
          50964,
          9565,
          11,
          3857,
          11,
          658,
          18526,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2227596225160541,
        "compression_ratio": 1.295774647887324,
        "end": 5529.36,
        "id": 1635,
        "no_speech_prob": 0.010169440880417824,
        "seek": 551136,
        "start": 5527.36,
        "temperature": 0,
        "text": " Somewhere I messed this up.",
        "tokens": [
          51164,
          34500,
          286,
          16507,
          341,
          493,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2227596225160541,
        "compression_ratio": 1.295774647887324,
        "end": 5532.36,
        "id": 1636,
        "no_speech_prob": 0.010169440880417824,
        "seek": 551136,
        "start": 5529.36,
        "temperature": 0,
        "text": " Cat, cats.",
        "tokens": [
          51264,
          9565,
          11,
          11111,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2227596225160541,
        "compression_ratio": 1.295774647887324,
        "end": 5535.36,
        "id": 1637,
        "no_speech_prob": 0.010169440880417824,
        "seek": 551136,
        "start": 5532.36,
        "temperature": 0,
        "text": " Ah!",
        "tokens": [
          51414,
          2438,
          0,
          51564
        ]
      },
      {
        "avg_logprob": -0.2227596225160541,
        "compression_ratio": 1.295774647887324,
        "end": 5538.36,
        "id": 1638,
        "no_speech_prob": 0.010169440880417824,
        "seek": 551136,
        "start": 5535.36,
        "temperature": 0,
        "text": " This is what I get for trying to code so quickly.",
        "tokens": [
          51564,
          639,
          307,
          437,
          286,
          483,
          337,
          1382,
          281,
          3089,
          370,
          2661,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20444875688695197,
        "compression_ratio": 1.6178861788617886,
        "end": 5541.36,
        "id": 1639,
        "no_speech_prob": 0.014727727510035038,
        "seek": 553836,
        "start": 5538.36,
        "temperature": 0,
        "text": " This is supposed to say cat.json.",
        "tokens": [
          50364,
          639,
          307,
          3442,
          281,
          584,
          3857,
          13,
          73,
          3015,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.20444875688695197,
        "compression_ratio": 1.6178861788617886,
        "end": 5543.36,
        "id": 1640,
        "no_speech_prob": 0.014727727510035038,
        "seek": 553836,
        "start": 5541.36,
        "temperature": 0,
        "text": " Cat.ndjson.",
        "tokens": [
          50514,
          9565,
          13,
          273,
          73,
          3015,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20444875688695197,
        "compression_ratio": 1.6178861788617886,
        "end": 5545.36,
        "id": 1641,
        "no_speech_prob": 0.014727727510035038,
        "seek": 553836,
        "start": 5543.36,
        "temperature": 0,
        "text": " Now, here we go.",
        "tokens": [
          50614,
          823,
          11,
          510,
          321,
          352,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20444875688695197,
        "compression_ratio": 1.6178861788617886,
        "end": 5548.36,
        "id": 1642,
        "no_speech_prob": 0.014727727510035038,
        "seek": 553836,
        "start": 5545.36,
        "temperature": 0,
        "text": " Oh, I have to restart the server.",
        "tokens": [
          50714,
          876,
          11,
          286,
          362,
          281,
          21022,
          264,
          7154,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20444875688695197,
        "compression_ratio": 1.6178861788617886,
        "end": 5550.36,
        "id": 1643,
        "no_speech_prob": 0.014727727510035038,
        "seek": 553836,
        "start": 5548.36,
        "temperature": 0,
        "text": " And here we go.",
        "tokens": [
          50864,
          400,
          510,
          321,
          352,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20444875688695197,
        "compression_ratio": 1.6178861788617886,
        "end": 5552.36,
        "id": 1644,
        "no_speech_prob": 0.014727727510035038,
        "seek": 553836,
        "start": 5550.36,
        "temperature": 0,
        "text": " Finally, cats!",
        "tokens": [
          50964,
          6288,
          11,
          11111,
          0,
          51064
        ]
      },
      {
        "avg_logprob": -0.20444875688695197,
        "compression_ratio": 1.6178861788617886,
        "end": 5554.36,
        "id": 1645,
        "no_speech_prob": 0.014727727510035038,
        "seek": 553836,
        "start": 5552.36,
        "temperature": 0,
        "text": " There's a lot of different cat drawings.",
        "tokens": [
          51064,
          821,
          311,
          257,
          688,
          295,
          819,
          3857,
          18618,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.20444875688695197,
        "compression_ratio": 1.6178861788617886,
        "end": 5556.36,
        "id": 1646,
        "no_speech_prob": 0.014727727510035038,
        "seek": 553836,
        "start": 5554.36,
        "temperature": 0,
        "text": " I really should slow this down.",
        "tokens": [
          51164,
          286,
          534,
          820,
          2964,
          341,
          760,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20444875688695197,
        "compression_ratio": 1.6178861788617886,
        "end": 5558.36,
        "id": 1647,
        "no_speech_prob": 0.014727727510035038,
        "seek": 553836,
        "start": 5556.36,
        "temperature": 0,
        "text": " Let me just slow this down a little bit.",
        "tokens": [
          51264,
          961,
          385,
          445,
          2964,
          341,
          760,
          257,
          707,
          857,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20444875688695197,
        "compression_ratio": 1.6178861788617886,
        "end": 5559.36,
        "id": 1648,
        "no_speech_prob": 0.014727727510035038,
        "seek": 553836,
        "start": 5558.36,
        "temperature": 0,
        "text": " Oh, here's what I want to do, actually.",
        "tokens": [
          51364,
          876,
          11,
          510,
          311,
          437,
          286,
          528,
          281,
          360,
          11,
          767,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20444875688695197,
        "compression_ratio": 1.6178861788617886,
        "end": 5561.36,
        "id": 1649,
        "no_speech_prob": 0.014727727510035038,
        "seek": 553836,
        "start": 5559.36,
        "temperature": 0,
        "text": " Oh, this video should really be over.",
        "tokens": [
          51414,
          876,
          11,
          341,
          960,
          820,
          534,
          312,
          670,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20444875688695197,
        "compression_ratio": 1.6178861788617886,
        "end": 5563.36,
        "id": 1650,
        "no_speech_prob": 0.014727727510035038,
        "seek": 553836,
        "start": 5561.36,
        "temperature": 0,
        "text": " But, you've already watched this much.",
        "tokens": [
          51514,
          583,
          11,
          291,
          600,
          1217,
          6337,
          341,
          709,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20444875688695197,
        "compression_ratio": 1.6178861788617886,
        "end": 5565.36,
        "id": 1651,
        "no_speech_prob": 0.014727727510035038,
        "seek": 553836,
        "start": 5563.36,
        "temperature": 0,
        "text": " You can watch a little bit more, right?",
        "tokens": [
          51614,
          509,
          393,
          1159,
          257,
          707,
          857,
          544,
          11,
          558,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.20458164843884144,
        "compression_ratio": 1.544041450777202,
        "end": 5570.36,
        "id": 1652,
        "no_speech_prob": 0.001548746251501143,
        "seek": 556536,
        "start": 5566.36,
        "temperature": 0,
        "text": " I really want to draw the drawing in sequence.",
        "tokens": [
          50414,
          286,
          534,
          528,
          281,
          2642,
          264,
          6316,
          294,
          8310,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20458164843884144,
        "compression_ratio": 1.544041450777202,
        "end": 5574.36,
        "id": 1653,
        "no_speech_prob": 0.001548746251501143,
        "seek": 556536,
        "start": 5570.36,
        "temperature": 0,
        "text": " Now, I don't have the timing information.",
        "tokens": [
          50614,
          823,
          11,
          286,
          500,
          380,
          362,
          264,
          10822,
          1589,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20458164843884144,
        "compression_ratio": 1.544041450777202,
        "end": 5576.36,
        "id": 1654,
        "no_speech_prob": 0.001548746251501143,
        "seek": 556536,
        "start": 5574.36,
        "temperature": 0,
        "text": " And that would be useful to have.",
        "tokens": [
          50814,
          400,
          300,
          576,
          312,
          4420,
          281,
          362,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20458164843884144,
        "compression_ratio": 1.544041450777202,
        "end": 5578.36,
        "id": 1655,
        "no_speech_prob": 0.001548746251501143,
        "seek": 556536,
        "start": 5576.36,
        "temperature": 0,
        "text": " But let's make it actually animate.",
        "tokens": [
          50914,
          583,
          718,
          311,
          652,
          309,
          767,
          36439,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20458164843884144,
        "compression_ratio": 1.544041450777202,
        "end": 5581.36,
        "id": 1656,
        "no_speech_prob": 0.001548746251501143,
        "seek": 556536,
        "start": 5578.36,
        "temperature": 0,
        "text": " So, I'm going to add a draw function.",
        "tokens": [
          51014,
          407,
          11,
          286,
          478,
          516,
          281,
          909,
          257,
          2642,
          2445,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.20458164843884144,
        "compression_ratio": 1.544041450777202,
        "end": 5587.36,
        "id": 1657,
        "no_speech_prob": 0.001548746251501143,
        "seek": 556536,
        "start": 5584.36,
        "temperature": 0,
        "text": " I'm not going to add a page transition event.",
        "tokens": [
          51314,
          286,
          478,
          406,
          516,
          281,
          909,
          257,
          3028,
          6034,
          2280,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20458164843884144,
        "compression_ratio": 1.544041450777202,
        "end": 5591.36,
        "id": 1658,
        "no_speech_prob": 0.001548746251501143,
        "seek": 556536,
        "start": 5587.36,
        "temperature": 0,
        "text": " And so, when I've got a cat, and I'll just change this.",
        "tokens": [
          51464,
          400,
          370,
          11,
          562,
          286,
          600,
          658,
          257,
          3857,
          11,
          293,
          286,
          603,
          445,
          1319,
          341,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2418523328057651,
        "compression_ratio": 1.756578947368421,
        "end": 5598.36,
        "id": 1659,
        "no_speech_prob": 0.000057387136621400714,
        "seek": 559136,
        "start": 5591.36,
        "temperature": 0,
        "text": " What I'm actually going to do is just set current...",
        "tokens": [
          50364,
          708,
          286,
          478,
          767,
          516,
          281,
          360,
          307,
          445,
          992,
          2190,
          485,
          50714
        ]
      },
      {
        "avg_logprob": -0.2418523328057651,
        "compression_ratio": 1.756578947368421,
        "end": 5602.36,
        "id": 1660,
        "no_speech_prob": 0.000057387136621400714,
        "seek": 559136,
        "start": 5599.36,
        "temperature": 0,
        "text": " I'm going to just say set cat equal to data.",
        "tokens": [
          50764,
          286,
          478,
          516,
          281,
          445,
          584,
          992,
          3857,
          2681,
          281,
          1412,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2418523328057651,
        "compression_ratio": 1.756578947368421,
        "end": 5604.36,
        "id": 1661,
        "no_speech_prob": 0.000057387136621400714,
        "seek": 559136,
        "start": 5602.36,
        "temperature": 0,
        "text": " So, I'm going to take out all of this.",
        "tokens": [
          50914,
          407,
          11,
          286,
          478,
          516,
          281,
          747,
          484,
          439,
          295,
          341,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2418523328057651,
        "compression_ratio": 1.756578947368421,
        "end": 5606.36,
        "id": 1662,
        "no_speech_prob": 0.000057387136621400714,
        "seek": 559136,
        "start": 5604.36,
        "temperature": 0,
        "text": " cat equal to data dot drawing.",
        "tokens": [
          51014,
          3857,
          2681,
          281,
          1412,
          5893,
          6316,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2418523328057651,
        "compression_ratio": 1.756578947368421,
        "end": 5609.36,
        "id": 1663,
        "no_speech_prob": 0.000057387136621400714,
        "seek": 559136,
        "start": 5606.36,
        "temperature": 0,
        "text": " So, I'm going to comment this out.",
        "tokens": [
          51114,
          407,
          11,
          286,
          478,
          516,
          281,
          2871,
          341,
          484,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2418523328057651,
        "compression_ratio": 1.756578947368421,
        "end": 5612.36,
        "id": 1664,
        "no_speech_prob": 0.000057387136621400714,
        "seek": 559136,
        "start": 5610.36,
        "temperature": 0,
        "text": " Let's think about this.",
        "tokens": [
          51314,
          961,
          311,
          519,
          466,
          341,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2418523328057651,
        "compression_ratio": 1.756578947368421,
        "end": 5617.36,
        "id": 1665,
        "no_speech_prob": 0.000057387136621400714,
        "seek": 559136,
        "start": 5612.36,
        "temperature": 0,
        "text": " And then I'm going to say let x comma y.",
        "tokens": [
          51414,
          400,
          550,
          286,
          478,
          516,
          281,
          584,
          718,
          2031,
          22117,
          288,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19266016729946794,
        "compression_ratio": 1.650887573964497,
        "end": 5619.36,
        "id": 1666,
        "no_speech_prob": 0.00020027316350024194,
        "seek": 561736,
        "start": 5617.36,
        "temperature": 0,
        "text": " And I'm going to have...",
        "tokens": [
          50364,
          400,
          286,
          478,
          516,
          281,
          362,
          485,
          50464
        ]
      },
      {
        "avg_logprob": -0.19266016729946794,
        "compression_ratio": 1.650887573964497,
        "end": 5625.36,
        "id": 1667,
        "no_speech_prob": 0.00020027316350024194,
        "seek": 561736,
        "start": 5619.36,
        "temperature": 0,
        "text": " I'm going to say if cat, then I now need to keep track of where I am.",
        "tokens": [
          50464,
          286,
          478,
          516,
          281,
          584,
          498,
          3857,
          11,
          550,
          286,
          586,
          643,
          281,
          1066,
          2837,
          295,
          689,
          286,
          669,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19266016729946794,
        "compression_ratio": 1.650887573964497,
        "end": 5631.36,
        "id": 1668,
        "no_speech_prob": 0.00020027316350024194,
        "seek": 561736,
        "start": 5625.36,
        "temperature": 0,
        "text": " Let stroke index equal zero.",
        "tokens": [
          50764,
          961,
          12403,
          8186,
          2681,
          4018,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19266016729946794,
        "compression_ratio": 1.650887573964497,
        "end": 5636.36,
        "id": 1669,
        "no_speech_prob": 0.00020027316350024194,
        "seek": 561736,
        "start": 5631.36,
        "temperature": 0,
        "text": " Let pen index equal zero.",
        "tokens": [
          51064,
          961,
          3435,
          8186,
          2681,
          4018,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19266016729946794,
        "compression_ratio": 1.650887573964497,
        "end": 5638.36,
        "id": 1670,
        "no_speech_prob": 0.00020027316350024194,
        "seek": 561736,
        "start": 5636.36,
        "temperature": 0,
        "text": " So, I need to keep track of two indices, right?",
        "tokens": [
          51314,
          407,
          11,
          286,
          643,
          281,
          1066,
          2837,
          295,
          732,
          43840,
          11,
          558,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.19266016729946794,
        "compression_ratio": 1.650887573964497,
        "end": 5641.36,
        "id": 1671,
        "no_speech_prob": 0.00020027316350024194,
        "seek": 561736,
        "start": 5638.36,
        "temperature": 0,
        "text": " Because I'm going to walk through one at a time.",
        "tokens": [
          51414,
          1436,
          286,
          478,
          516,
          281,
          1792,
          807,
          472,
          412,
          257,
          565,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19266016729946794,
        "compression_ratio": 1.650887573964497,
        "end": 5645.36,
        "id": 1672,
        "no_speech_prob": 0.00020027316350024194,
        "seek": 561736,
        "start": 5641.36,
        "temperature": 0,
        "text": " Each vector of the first stroke.",
        "tokens": [
          51564,
          6947,
          8062,
          295,
          264,
          700,
          12403,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2625542879104614,
        "compression_ratio": 1.4567901234567902,
        "end": 5648.36,
        "id": 1673,
        "no_speech_prob": 0.00009761547698872164,
        "seek": 564536,
        "start": 5645.36,
        "temperature": 0,
        "text": " And then stroke is going to go from zero to one.",
        "tokens": [
          50364,
          400,
          550,
          12403,
          307,
          516,
          281,
          352,
          490,
          4018,
          281,
          472,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2625542879104614,
        "compression_ratio": 1.4567901234567902,
        "end": 5650.36,
        "id": 1674,
        "no_speech_prob": 0.00009761547698872164,
        "seek": 564536,
        "start": 5648.36,
        "temperature": 0,
        "text": " And go through each of the other ones.",
        "tokens": [
          50514,
          400,
          352,
          807,
          1184,
          295,
          264,
          661,
          2306,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2625542879104614,
        "compression_ratio": 1.4567901234567902,
        "end": 5655.36,
        "id": 1675,
        "no_speech_prob": 0.00009761547698872164,
        "seek": 564536,
        "start": 5650.36,
        "temperature": 0,
        "text": " So, if there's a cat, the first thing I need to do is say...",
        "tokens": [
          50614,
          407,
          11,
          498,
          456,
          311,
          257,
          3857,
          11,
          264,
          700,
          551,
          286,
          643,
          281,
          360,
          307,
          584,
          485,
          50864
        ]
      },
      {
        "avg_logprob": -0.2625542879104614,
        "compression_ratio": 1.4567901234567902,
        "end": 5661.36,
        "id": 1676,
        "no_speech_prob": 0.00009761547698872164,
        "seek": 564536,
        "start": 5657.36,
        "temperature": 0,
        "text": " So, if I'm going to say x equals...",
        "tokens": [
          50964,
          407,
          11,
          498,
          286,
          478,
          516,
          281,
          584,
          2031,
          6915,
          485,
          51164
        ]
      },
      {
        "avg_logprob": -0.2625542879104614,
        "compression_ratio": 1.4567901234567902,
        "end": 5663.36,
        "id": 1677,
        "no_speech_prob": 0.00009761547698872164,
        "seek": 564536,
        "start": 5661.36,
        "temperature": 0,
        "text": " And what was this stuff?",
        "tokens": [
          51164,
          400,
          437,
          390,
          341,
          1507,
          30,
          51264
        ]
      },
      {
        "avg_logprob": -0.2625542879104614,
        "compression_ratio": 1.4567901234567902,
        "end": 5665.36,
        "id": 1678,
        "no_speech_prob": 0.00009761547698872164,
        "seek": 564536,
        "start": 5663.36,
        "temperature": 0,
        "text": " It is path...",
        "tokens": [
          51264,
          467,
          307,
          3100,
          485,
          51364
        ]
      },
      {
        "avg_logprob": -0.2625542879104614,
        "compression_ratio": 1.4567901234567902,
        "end": 5668.36,
        "id": 1679,
        "no_speech_prob": 0.00009761547698872164,
        "seek": 564536,
        "start": 5667.36,
        "temperature": 0,
        "text": " Oh, drawing.",
        "tokens": [
          51464,
          876,
          11,
          6316,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.23058372415522094,
        "compression_ratio": 1.5252525252525253,
        "end": 5675.36,
        "id": 1680,
        "no_speech_prob": 0.050328463315963745,
        "seek": 566836,
        "start": 5668.36,
        "temperature": 0,
        "text": " So, cat index stroke index.",
        "tokens": [
          50364,
          407,
          11,
          3857,
          8186,
          12403,
          8186,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.23058372415522094,
        "compression_ratio": 1.5252525252525253,
        "end": 5681.36,
        "id": 1681,
        "no_speech_prob": 0.050328463315963745,
        "seek": 566836,
        "start": 5677.36,
        "temperature": 0,
        "text": " Index pen index.",
        "tokens": [
          50814,
          33552,
          3435,
          8186,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.23058372415522094,
        "compression_ratio": 1.5252525252525253,
        "end": 5683.36,
        "id": 1682,
        "no_speech_prob": 0.050328463315963745,
        "seek": 566836,
        "start": 5681.36,
        "temperature": 0,
        "text": " Index zero.",
        "tokens": [
          51014,
          33552,
          4018,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.23058372415522094,
        "compression_ratio": 1.5252525252525253,
        "end": 5687.36,
        "id": 1683,
        "no_speech_prob": 0.050328463315963745,
        "seek": 566836,
        "start": 5683.36,
        "temperature": 0,
        "text": " Boy, this is really awkward about how it's using just arrays for everything.",
        "tokens": [
          51114,
          9486,
          11,
          341,
          307,
          534,
          11411,
          466,
          577,
          309,
          311,
          1228,
          445,
          41011,
          337,
          1203,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.23058372415522094,
        "compression_ratio": 1.5252525252525253,
        "end": 5689.36,
        "id": 1684,
        "no_speech_prob": 0.050328463315963745,
        "seek": 566836,
        "start": 5687.36,
        "temperature": 0,
        "text": " But I'm in the first stroke.",
        "tokens": [
          51314,
          583,
          286,
          478,
          294,
          264,
          700,
          12403,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.23058372415522094,
        "compression_ratio": 1.5252525252525253,
        "end": 5691.36,
        "id": 1685,
        "no_speech_prob": 0.050328463315963745,
        "seek": 566836,
        "start": 5689.36,
        "temperature": 0,
        "text": " In the first... Pen is not the right term.",
        "tokens": [
          51414,
          682,
          264,
          700,
          485,
          10571,
          307,
          406,
          264,
          558,
          1433,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.23058372415522094,
        "compression_ratio": 1.5252525252525253,
        "end": 5692.36,
        "id": 1686,
        "no_speech_prob": 0.050328463315963745,
        "seek": 566836,
        "start": 5691.36,
        "temperature": 0,
        "text": " I don't know what to call it. Vertex?",
        "tokens": [
          51514,
          286,
          500,
          380,
          458,
          437,
          281,
          818,
          309,
          13,
          21044,
          3121,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.23058372415522094,
        "compression_ratio": 1.5252525252525253,
        "end": 5693.36,
        "id": 1687,
        "no_speech_prob": 0.050328463315963745,
        "seek": 566836,
        "start": 5692.36,
        "temperature": 0,
        "text": " But whatever.",
        "tokens": [
          51564,
          583,
          2035,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.23058372415522094,
        "compression_ratio": 1.5252525252525253,
        "end": 5695.36,
        "id": 1688,
        "no_speech_prob": 0.050328463315963745,
        "seek": 566836,
        "start": 5693.36,
        "temperature": 0,
        "text": " I could actually just call this index maybe.",
        "tokens": [
          51614,
          286,
          727,
          767,
          445,
          818,
          341,
          8186,
          1310,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2179018924110814,
        "compression_ratio": 1.654320987654321,
        "end": 5697.36,
        "id": 1689,
        "no_speech_prob": 0.0003859650460071862,
        "seek": 569536,
        "start": 5696.36,
        "temperature": 0,
        "text": " The stroke index and the index.",
        "tokens": [
          50414,
          440,
          12403,
          8186,
          293,
          264,
          8186,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2179018924110814,
        "compression_ratio": 1.654320987654321,
        "end": 5699.36,
        "id": 1690,
        "no_speech_prob": 0.0003859650460071862,
        "seek": 569536,
        "start": 5697.36,
        "temperature": 0,
        "text": " And zero is for x.",
        "tokens": [
          50464,
          400,
          4018,
          307,
          337,
          2031,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2179018924110814,
        "compression_ratio": 1.654320987654321,
        "end": 5703.36,
        "id": 1691,
        "no_speech_prob": 0.0003859650460071862,
        "seek": 569536,
        "start": 5700.36,
        "temperature": 0,
        "text": " And then one is for y.",
        "tokens": [
          50614,
          400,
          550,
          472,
          307,
          337,
          288,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2179018924110814,
        "compression_ratio": 1.654320987654321,
        "end": 5705.36,
        "id": 1692,
        "no_speech_prob": 0.0003859650460071862,
        "seek": 569536,
        "start": 5703.36,
        "temperature": 0,
        "text": " And let me just... Just to see that this works.",
        "tokens": [
          50764,
          400,
          718,
          385,
          445,
          485,
          1449,
          281,
          536,
          300,
          341,
          1985,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2179018924110814,
        "compression_ratio": 1.654320987654321,
        "end": 5707.36,
        "id": 1693,
        "no_speech_prob": 0.0003859650460071862,
        "seek": 569536,
        "start": 5705.36,
        "temperature": 0,
        "text": " Let me say point...",
        "tokens": [
          50864,
          961,
          385,
          584,
          935,
          485,
          50964
        ]
      },
      {
        "avg_logprob": -0.2179018924110814,
        "compression_ratio": 1.654320987654321,
        "end": 5714.36,
        "id": 1694,
        "no_speech_prob": 0.0003859650460071862,
        "seek": 569536,
        "start": 5711.36,
        "temperature": 0,
        "text": " Let me say point x, y.",
        "tokens": [
          51164,
          961,
          385,
          584,
          935,
          2031,
          11,
          288,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2179018924110814,
        "compression_ratio": 1.654320987654321,
        "end": 5716.36,
        "id": 1695,
        "no_speech_prob": 0.0003859650460071862,
        "seek": 569536,
        "start": 5714.36,
        "temperature": 0,
        "text": " And these don't need to be global.",
        "tokens": [
          51314,
          400,
          613,
          500,
          380,
          643,
          281,
          312,
          4338,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2179018924110814,
        "compression_ratio": 1.654320987654321,
        "end": 5720.36,
        "id": 1696,
        "no_speech_prob": 0.0003859650460071862,
        "seek": 569536,
        "start": 5718.36,
        "temperature": 0,
        "text": " So, let's see what this does.",
        "tokens": [
          51514,
          407,
          11,
          718,
          311,
          536,
          437,
          341,
          775,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2179018924110814,
        "compression_ratio": 1.654320987654321,
        "end": 5722.36,
        "id": 1697,
        "no_speech_prob": 0.0003859650460071862,
        "seek": 569536,
        "start": 5720.36,
        "temperature": 0,
        "text": " So, first of all, let's just run this.",
        "tokens": [
          51614,
          407,
          11,
          700,
          295,
          439,
          11,
          718,
          311,
          445,
          1190,
          341,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20426222421590565,
        "compression_ratio": 1.4223300970873787,
        "end": 5725.36,
        "id": 1698,
        "no_speech_prob": 0.00006014136306475848,
        "seek": 572236,
        "start": 5723.36,
        "temperature": 0,
        "text": " Oh, boy. I freaked it out.",
        "tokens": [
          50414,
          876,
          11,
          3237,
          13,
          286,
          37853,
          309,
          484,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.20426222421590565,
        "compression_ratio": 1.4223300970873787,
        "end": 5727.36,
        "id": 1699,
        "no_speech_prob": 0.00006014136306475848,
        "seek": 572236,
        "start": 5725.36,
        "temperature": 0,
        "text": " It won't ever stop.",
        "tokens": [
          50514,
          467,
          1582,
          380,
          1562,
          1590,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20426222421590565,
        "compression_ratio": 1.4223300970873787,
        "end": 5732.36,
        "id": 1700,
        "no_speech_prob": 0.00006014136306475848,
        "seek": 572236,
        "start": 5730.36,
        "temperature": 0,
        "text": " Well, I think, by the way, I killed this.",
        "tokens": [
          50764,
          1042,
          11,
          286,
          519,
          11,
          538,
          264,
          636,
          11,
          286,
          4652,
          341,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20426222421590565,
        "compression_ratio": 1.4223300970873787,
        "end": 5735.36,
        "id": 1701,
        "no_speech_prob": 0.00006014136306475848,
        "seek": 572236,
        "start": 5732.36,
        "temperature": 0,
        "text": " I need to build in a little more of a delay with these API calls.",
        "tokens": [
          50864,
          286,
          643,
          281,
          1322,
          294,
          257,
          707,
          544,
          295,
          257,
          8577,
          365,
          613,
          9362,
          5498,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20426222421590565,
        "compression_ratio": 1.4223300970873787,
        "end": 5737.36,
        "id": 1702,
        "no_speech_prob": 0.00006014136306475848,
        "seek": 572236,
        "start": 5735.36,
        "temperature": 0,
        "text": " So, cat is not defined.",
        "tokens": [
          51014,
          407,
          11,
          3857,
          307,
          406,
          7642,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20426222421590565,
        "compression_ratio": 1.4223300970873787,
        "end": 5739.36,
        "id": 1703,
        "no_speech_prob": 0.00006014136306475848,
        "seek": 572236,
        "start": 5737.36,
        "temperature": 0,
        "text": " Sketch.js line 12.",
        "tokens": [
          51114,
          49245,
          13,
          25530,
          1622,
          2272,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20426222421590565,
        "compression_ratio": 1.4223300970873787,
        "end": 5742.36,
        "id": 1704,
        "no_speech_prob": 0.00006014136306475848,
        "seek": 572236,
        "start": 5739.36,
        "temperature": 0,
        "text": " If cat... That needs to be a global variable.",
        "tokens": [
          51214,
          759,
          3857,
          485,
          663,
          2203,
          281,
          312,
          257,
          4338,
          7006,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20426222421590565,
        "compression_ratio": 1.4223300970873787,
        "end": 5748.36,
        "id": 1705,
        "no_speech_prob": 0.00006014136306475848,
        "seek": 572236,
        "start": 5745.36,
        "temperature": 0,
        "text": " So, and let me just say here...",
        "tokens": [
          51514,
          407,
          11,
          293,
          718,
          385,
          445,
          584,
          510,
          485,
          51664
        ]
      },
      {
        "avg_logprob": -0.20426222421590565,
        "compression_ratio": 1.4223300970873787,
        "end": 5751.36,
        "id": 1706,
        "no_speech_prob": 0.00006014136306475848,
        "seek": 572236,
        "start": 5748.36,
        "temperature": 0,
        "text": " Console log x, y.",
        "tokens": [
          51664,
          44152,
          3565,
          2031,
          11,
          288,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19482398701605397,
        "compression_ratio": 1.5181347150259068,
        "end": 5753.36,
        "id": 1707,
        "no_speech_prob": 0.0007793587283231318,
        "seek": 575136,
        "start": 5751.36,
        "temperature": 0,
        "text": " Did I get an x, y? Yes.",
        "tokens": [
          50364,
          2589,
          286,
          483,
          364,
          2031,
          11,
          288,
          30,
          1079,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.19482398701605397,
        "compression_ratio": 1.5181347150259068,
        "end": 5755.36,
        "id": 1708,
        "no_speech_prob": 0.0007793587283231318,
        "seek": 575136,
        "start": 5753.36,
        "temperature": 0,
        "text": " So, I've got that first point over and over again.",
        "tokens": [
          50464,
          407,
          11,
          286,
          600,
          658,
          300,
          700,
          935,
          670,
          293,
          670,
          797,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19482398701605397,
        "compression_ratio": 1.5181347150259068,
        "end": 5758.36,
        "id": 1709,
        "no_speech_prob": 0.0007793587283231318,
        "seek": 575136,
        "start": 5755.36,
        "temperature": 0,
        "text": " And presumably, 52, 48.",
        "tokens": [
          50564,
          400,
          26742,
          11,
          18079,
          11,
          11174,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19482398701605397,
        "compression_ratio": 1.5181347150259068,
        "end": 5759.36,
        "id": 1710,
        "no_speech_prob": 0.0007793587283231318,
        "seek": 575136,
        "start": 5758.36,
        "temperature": 0,
        "text": " I don't know why I don't see...",
        "tokens": [
          50714,
          286,
          500,
          380,
          458,
          983,
          286,
          500,
          380,
          536,
          485,
          50764
        ]
      },
      {
        "avg_logprob": -0.19482398701605397,
        "compression_ratio": 1.5181347150259068,
        "end": 5762.36,
        "id": 1711,
        "no_speech_prob": 0.0007793587283231318,
        "seek": 575136,
        "start": 5759.36,
        "temperature": 0,
        "text": " I guess I need to say stroke zero.",
        "tokens": [
          50764,
          286,
          2041,
          286,
          643,
          281,
          584,
          12403,
          4018,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19482398701605397,
        "compression_ratio": 1.5181347150259068,
        "end": 5767.36,
        "id": 1712,
        "no_speech_prob": 0.0007793587283231318,
        "seek": 575136,
        "start": 5763.36,
        "temperature": 0,
        "text": " Stroke weight three.",
        "tokens": [
          50964,
          42196,
          330,
          3364,
          1045,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19482398701605397,
        "compression_ratio": 1.5181347150259068,
        "end": 5770.36,
        "id": 1713,
        "no_speech_prob": 0.0007793587283231318,
        "seek": 575136,
        "start": 5769.36,
        "temperature": 0,
        "text": " There we go. So, there it is.",
        "tokens": [
          51264,
          821,
          321,
          352,
          13,
          407,
          11,
          456,
          309,
          307,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19482398701605397,
        "compression_ratio": 1.5181347150259068,
        "end": 5772.36,
        "id": 1714,
        "no_speech_prob": 0.0007793587283231318,
        "seek": 575136,
        "start": 5770.36,
        "temperature": 0,
        "text": " That's the first point.",
        "tokens": [
          51314,
          663,
          311,
          264,
          700,
          935,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19482398701605397,
        "compression_ratio": 1.5181347150259068,
        "end": 5774.36,
        "id": 1715,
        "no_speech_prob": 0.0007793587283231318,
        "seek": 575136,
        "start": 5772.36,
        "temperature": 0,
        "text": " So, now what I need to do is say...",
        "tokens": [
          51414,
          407,
          11,
          586,
          437,
          286,
          643,
          281,
          360,
          307,
          584,
          485,
          51514
        ]
      },
      {
        "avg_logprob": -0.19482398701605397,
        "compression_ratio": 1.5181347150259068,
        "end": 5778.36,
        "id": 1716,
        "no_speech_prob": 0.0007793587283231318,
        "seek": 575136,
        "start": 5776.36,
        "temperature": 0,
        "text": " Index plus plus.",
        "tokens": [
          51614,
          33552,
          1804,
          1804,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2268093270315251,
        "compression_ratio": 1.537037037037037,
        "end": 5788.36,
        "id": 1717,
        "no_speech_prob": 0.00012533673725556582,
        "seek": 577836,
        "start": 5778.36,
        "temperature": 0,
        "text": " If index is greater than or equal to cat stroke index dot length,",
        "tokens": [
          50364,
          759,
          8186,
          307,
          5044,
          813,
          420,
          2681,
          281,
          3857,
          12403,
          8186,
          5893,
          4641,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.2268093270315251,
        "compression_ratio": 1.537037037037037,
        "end": 5796.36,
        "id": 1718,
        "no_speech_prob": 0.00012533673725556582,
        "seek": 577836,
        "start": 5788.36,
        "temperature": 0,
        "text": " then stroke index plus plus and index equals zero.",
        "tokens": [
          50864,
          550,
          12403,
          8186,
          1804,
          1804,
          293,
          8186,
          6915,
          4018,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2268093270315251,
        "compression_ratio": 1.537037037037037,
        "end": 5799.36,
        "id": 1719,
        "no_speech_prob": 0.00012533673725556582,
        "seek": 577836,
        "start": 5796.36,
        "temperature": 0,
        "text": " So, this is me marching through them one at a time.",
        "tokens": [
          51264,
          407,
          11,
          341,
          307,
          385,
          30523,
          807,
          552,
          472,
          412,
          257,
          565,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2268093270315251,
        "compression_ratio": 1.537037037037037,
        "end": 5804.36,
        "id": 1720,
        "no_speech_prob": 0.00012533673725556582,
        "seek": 577836,
        "start": 5801.36,
        "temperature": 0,
        "text": " So, ooh, and I don't have the y.",
        "tokens": [
          51514,
          407,
          11,
          17024,
          11,
          293,
          286,
          500,
          380,
          362,
          264,
          288,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2268093270315251,
        "compression_ratio": 1.537037037037037,
        "end": 5807.36,
        "id": 1721,
        "no_speech_prob": 0.00012533673725556582,
        "seek": 577836,
        "start": 5805.36,
        "temperature": 0,
        "text": " Right? You can see that something's wrong here.",
        "tokens": [
          51714,
          1779,
          30,
          509,
          393,
          536,
          300,
          746,
          311,
          2085,
          510,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.20835449384606403,
        "compression_ratio": 1.530054644808743,
        "end": 5811.36,
        "id": 1722,
        "no_speech_prob": 0.00003647833727882244,
        "seek": 580836,
        "start": 5809.36,
        "temperature": 0,
        "text": " I mean, this... Let's see.",
        "tokens": [
          50414,
          286,
          914,
          11,
          341,
          485,
          961,
          311,
          536,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.20835449384606403,
        "compression_ratio": 1.530054644808743,
        "end": 5814.36,
        "id": 1723,
        "no_speech_prob": 0.00003647833727882244,
        "seek": 580836,
        "start": 5812.36,
        "temperature": 0,
        "text": " Stroke index plus plus.",
        "tokens": [
          50564,
          42196,
          330,
          8186,
          1804,
          1804,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20835449384606403,
        "compression_ratio": 1.530054644808743,
        "end": 5817.36,
        "id": 1724,
        "no_speech_prob": 0.00003647833727882244,
        "seek": 580836,
        "start": 5816.36,
        "temperature": 0,
        "text": " I think this is right.",
        "tokens": [
          50764,
          286,
          519,
          341,
          307,
          558,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20835449384606403,
        "compression_ratio": 1.530054644808743,
        "end": 5824.36,
        "id": 1725,
        "no_speech_prob": 0.00003647833727882244,
        "seek": 580836,
        "start": 5821.36,
        "temperature": 0,
        "text": " Well, the point of this is what I actually want to do...",
        "tokens": [
          51014,
          1042,
          11,
          264,
          935,
          295,
          341,
          307,
          437,
          286,
          767,
          528,
          281,
          360,
          485,
          51164
        ]
      },
      {
        "avg_logprob": -0.20835449384606403,
        "compression_ratio": 1.530054644808743,
        "end": 5825.36,
        "id": 1726,
        "no_speech_prob": 0.00003647833727882244,
        "seek": 580836,
        "start": 5824.36,
        "temperature": 0,
        "text": " Hmm.",
        "tokens": [
          51164,
          8239,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20835449384606403,
        "compression_ratio": 1.530054644808743,
        "end": 5827.36,
        "id": 1727,
        "no_speech_prob": 0.00003647833727882244,
        "seek": 580836,
        "start": 5825.36,
        "temperature": 0,
        "text": " So, time out for a second.",
        "tokens": [
          51214,
          407,
          11,
          565,
          484,
          337,
          257,
          1150,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20835449384606403,
        "compression_ratio": 1.530054644808743,
        "end": 5828.36,
        "id": 1728,
        "no_speech_prob": 0.00003647833727882244,
        "seek": 580836,
        "start": 5827.36,
        "temperature": 0,
        "text": " I forgot the variable.",
        "tokens": [
          51314,
          286,
          5298,
          264,
          7006,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20835449384606403,
        "compression_ratio": 1.530054644808743,
        "end": 5830.36,
        "id": 1729,
        "no_speech_prob": 0.00003647833727882244,
        "seek": 580836,
        "start": 5828.36,
        "temperature": 0,
        "text": " Well, that's probably an old comment from before.",
        "tokens": [
          51364,
          1042,
          11,
          300,
          311,
          1391,
          364,
          1331,
          2871,
          490,
          949,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20835449384606403,
        "compression_ratio": 1.530054644808743,
        "end": 5833.36,
        "id": 1730,
        "no_speech_prob": 0.00003647833727882244,
        "seek": 580836,
        "start": 5830.36,
        "temperature": 0,
        "text": " Hold on. I need a little break for a second.",
        "tokens": [
          51464,
          6962,
          322,
          13,
          286,
          643,
          257,
          707,
          1821,
          337,
          257,
          1150,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.4323893388112386,
        "compression_ratio": 0.9696969696969697,
        "end": 5841.36,
        "id": 1731,
        "no_speech_prob": 0.0016484428197145462,
        "seek": 583836,
        "start": 5839.36,
        "temperature": 0,
        "text": " Why did this not work?",
        "tokens": [
          50414,
          1545,
          630,
          341,
          406,
          589,
          30,
          50514
        ]
      },
      {
        "avg_logprob": -0.4323893388112386,
        "compression_ratio": 0.9696969696969697,
        "end": 5844.36,
        "id": 1732,
        "no_speech_prob": 0.0016484428197145462,
        "seek": 583836,
        "start": 5842.36,
        "temperature": 0,
        "text": " Something is off about this.",
        "tokens": [
          50564,
          6595,
          307,
          766,
          466,
          341,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.4323893388112386,
        "compression_ratio": 0.9696969696969697,
        "end": 5865.36,
        "id": 1733,
        "no_speech_prob": 0.0016484428197145462,
        "seek": 583836,
        "start": 5864.36,
        "temperature": 0,
        "text": " Do I have...",
        "tokens": [
          51664,
          1144,
          286,
          362,
          485,
          51714
        ]
      },
      {
        "avg_logprob": -0.19291112361810145,
        "compression_ratio": 1.61864406779661,
        "end": 5869.36,
        "id": 1734,
        "no_speech_prob": 0.000008939674444263801,
        "seek": 586536,
        "start": 5866.36,
        "temperature": 0,
        "text": " Do I have these in the wrong order?",
        "tokens": [
          50414,
          1144,
          286,
          362,
          613,
          294,
          264,
          2085,
          1668,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.19291112361810145,
        "compression_ratio": 1.61864406779661,
        "end": 5875.36,
        "id": 1735,
        "no_speech_prob": 0.000008939674444263801,
        "seek": 586536,
        "start": 5874.36,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          50814,
          6962,
          322,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19291112361810145,
        "compression_ratio": 1.61864406779661,
        "end": 5882.36,
        "id": 1736,
        "no_speech_prob": 0.000008939674444263801,
        "seek": 586536,
        "start": 5879.36,
        "temperature": 0,
        "text": " Right? It's going zero, zero, zero, one, one, zero.",
        "tokens": [
          51064,
          1779,
          30,
          467,
          311,
          516,
          4018,
          11,
          4018,
          11,
          4018,
          11,
          472,
          11,
          472,
          11,
          4018,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19291112361810145,
        "compression_ratio": 1.61864406779661,
        "end": 5884.36,
        "id": 1737,
        "no_speech_prob": 0.000008939674444263801,
        "seek": 586536,
        "start": 5883.36,
        "temperature": 0,
        "text": " Ooh.",
        "tokens": [
          51264,
          7951,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19291112361810145,
        "compression_ratio": 1.61864406779661,
        "end": 5887.36,
        "id": 1738,
        "no_speech_prob": 0.000008939674444263801,
        "seek": 586536,
        "start": 5885.36,
        "temperature": 0,
        "text": " There were 17.",
        "tokens": [
          51364,
          821,
          645,
          3282,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19291112361810145,
        "compression_ratio": 1.61864406779661,
        "end": 5889.36,
        "id": 1739,
        "no_speech_prob": 0.000008939674444263801,
        "seek": 586536,
        "start": 5887.36,
        "temperature": 0,
        "text": " Oh, no, no, no, no, no, no.",
        "tokens": [
          51464,
          876,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19291112361810145,
        "compression_ratio": 1.61864406779661,
        "end": 5891.36,
        "id": 1740,
        "no_speech_prob": 0.000008939674444263801,
        "seek": 586536,
        "start": 5889.36,
        "temperature": 0,
        "text": " I have these in the wrong order.",
        "tokens": [
          51564,
          286,
          362,
          613,
          294,
          264,
          2085,
          1668,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19291112361810145,
        "compression_ratio": 1.61864406779661,
        "end": 5892.36,
        "id": 1741,
        "no_speech_prob": 0.000008939674444263801,
        "seek": 586536,
        "start": 5891.36,
        "temperature": 0,
        "text": " That's weird.",
        "tokens": [
          51664,
          663,
          311,
          3657,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.6358714633517795,
        "compression_ratio": 1.3027522935779816,
        "end": 5897.36,
        "id": 1742,
        "no_speech_prob": 0.00024923027376644313,
        "seek": 589536,
        "start": 5895.36,
        "temperature": 0,
        "text": " Oh, I have these in the wrong order.",
        "tokens": [
          50364,
          876,
          11,
          286,
          362,
          613,
          294,
          264,
          2085,
          1668,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.6358714633517795,
        "compression_ratio": 1.3027522935779816,
        "end": 5913.36,
        "id": 1743,
        "no_speech_prob": 0.00024923027376644313,
        "seek": 589536,
        "start": 5910.36,
        "temperature": 0,
        "text": " Like, I think it should be zero index...",
        "tokens": [
          51114,
          1743,
          11,
          286,
          519,
          309,
          820,
          312,
          4018,
          8186,
          485,
          51264
        ]
      },
      {
        "avg_logprob": -0.6358714633517795,
        "compression_ratio": 1.3027522935779816,
        "end": 5917.36,
        "id": 1744,
        "no_speech_prob": 0.00024923027376644313,
        "seek": 589536,
        "start": 5915.36,
        "temperature": 0,
        "text": " It actually works this way?",
        "tokens": [
          51364,
          467,
          767,
          1985,
          341,
          636,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.6358714633517795,
        "compression_ratio": 1.3027522935779816,
        "end": 5920.36,
        "id": 1745,
        "no_speech_prob": 0.00024923027376644313,
        "seek": 589536,
        "start": 5919.36,
        "temperature": 0,
        "text": " Oh, I'm sorry.",
        "tokens": [
          51564,
          876,
          11,
          286,
          478,
          2597,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.6358714633517795,
        "compression_ratio": 1.3027522935779816,
        "end": 5921.36,
        "id": 1746,
        "no_speech_prob": 0.00024923027376644313,
        "seek": 589536,
        "start": 5920.36,
        "temperature": 0,
        "text": " I'm sorry.",
        "tokens": [
          51614,
          286,
          478,
          2597,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.6358714633517795,
        "compression_ratio": 1.3027522935779816,
        "end": 5922.36,
        "id": 1747,
        "no_speech_prob": 0.00024923027376644313,
        "seek": 589536,
        "start": 5921.36,
        "temperature": 0,
        "text": " I'm sorry.",
        "tokens": [
          51664,
          286,
          478,
          2597,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1712800979614258,
        "compression_ratio": 0.9117647058823529,
        "end": 5924.36,
        "id": 1748,
        "no_speech_prob": 0.0011693655978888273,
        "seek": 592236,
        "start": 5922.36,
        "temperature": 0,
        "text": " It actually works this way?",
        "tokens": [
          50364,
          467,
          767,
          1985,
          341,
          636,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.1712800979614258,
        "compression_ratio": 0.9117647058823529,
        "end": 5947.36,
        "id": 1749,
        "no_speech_prob": 0.0011693655978888273,
        "seek": 592236,
        "start": 5945.36,
        "temperature": 0,
        "text": " It doesn't seem more like the cat.",
        "tokens": [
          51514,
          467,
          1177,
          380,
          1643,
          544,
          411,
          264,
          3857,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.28633156228572765,
        "compression_ratio": 1.12,
        "end": 5954.36,
        "id": 1750,
        "no_speech_prob": 0.0010004385840147734,
        "seek": 595236,
        "start": 5953.36,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          50414,
          876,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.28633156228572765,
        "compression_ratio": 1.12,
        "end": 5956.36,
        "id": 1751,
        "no_speech_prob": 0.0010004385840147734,
        "seek": 595236,
        "start": 5955.36,
        "temperature": 0,
        "text": " It's this.",
        "tokens": [
          50514,
          467,
          311,
          341,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.28633156228572765,
        "compression_ratio": 1.12,
        "end": 5962.36,
        "id": 1752,
        "no_speech_prob": 0.0010004385840147734,
        "seek": 595236,
        "start": 5960.36,
        "temperature": 0,
        "text": " This is what it is.",
        "tokens": [
          50764,
          639,
          307,
          437,
          309,
          307,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.28633156228572765,
        "compression_ratio": 1.12,
        "end": 5963.36,
        "id": 1753,
        "no_speech_prob": 0.0010004385840147734,
        "seek": 595236,
        "start": 5962.36,
        "temperature": 0,
        "text": " Of course.",
        "tokens": [
          50864,
          2720,
          1164,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.28633156228572765,
        "compression_ratio": 1.12,
        "end": 5974.36,
        "id": 1754,
        "no_speech_prob": 0.0010004385840147734,
        "seek": 595236,
        "start": 5973.36,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          51414,
          1779,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.28633156228572765,
        "compression_ratio": 1.12,
        "end": 5980.36,
        "id": 1755,
        "no_speech_prob": 0.0010004385840147734,
        "seek": 595236,
        "start": 5974.36,
        "temperature": 0,
        "text": " Because stroke index, then zero is the x's, one is the y's.",
        "tokens": [
          51464,
          1436,
          12403,
          8186,
          11,
          550,
          4018,
          307,
          264,
          2031,
          311,
          11,
          472,
          307,
          264,
          288,
          311,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.16468772603504694,
        "compression_ratio": 1.255813953488372,
        "end": 5985.36,
        "id": 1756,
        "no_speech_prob": 0.00014883426774758846,
        "seek": 598236,
        "start": 5983.36,
        "temperature": 0,
        "text": " Index is going up.",
        "tokens": [
          50414,
          33552,
          307,
          516,
          493,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.16468772603504694,
        "compression_ratio": 1.255813953488372,
        "end": 5988.36,
        "id": 1757,
        "no_speech_prob": 0.00014883426774758846,
        "seek": 598236,
        "start": 5986.36,
        "temperature": 0,
        "text": " And then this.",
        "tokens": [
          50564,
          400,
          550,
          341,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.16468772603504694,
        "compression_ratio": 1.255813953488372,
        "end": 5989.36,
        "id": 1758,
        "no_speech_prob": 0.00014883426774758846,
        "seek": 598236,
        "start": 5988.36,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50664,
          821,
          321,
          352,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.16468772603504694,
        "compression_ratio": 1.255813953488372,
        "end": 5992.36,
        "id": 1759,
        "no_speech_prob": 0.00014883426774758846,
        "seek": 598236,
        "start": 5991.36,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          50814,
          865,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.16468772603504694,
        "compression_ratio": 1.255813953488372,
        "end": 5996.36,
        "id": 1760,
        "no_speech_prob": 0.00014883426774758846,
        "seek": 598236,
        "start": 5995.36,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51014,
          865,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.16468772603504694,
        "compression_ratio": 1.255813953488372,
        "end": 5997.36,
        "id": 1761,
        "no_speech_prob": 0.00014883426774758846,
        "seek": 598236,
        "start": 5996.36,
        "temperature": 0,
        "text": " It's hard to see, but these are the cats.",
        "tokens": [
          51064,
          467,
          311,
          1152,
          281,
          536,
          11,
          457,
          613,
          366,
          264,
          11111,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.16468772603504694,
        "compression_ratio": 1.255813953488372,
        "end": 5998.36,
        "id": 1762,
        "no_speech_prob": 0.00014883426774758846,
        "seek": 598236,
        "start": 5997.36,
        "temperature": 0,
        "text": " Okay, I got it now.",
        "tokens": [
          51114,
          1033,
          11,
          286,
          658,
          309,
          586,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.16468772603504694,
        "compression_ratio": 1.255813953488372,
        "end": 6000.36,
        "id": 1763,
        "no_speech_prob": 0.00014883426774758846,
        "seek": 598236,
        "start": 5999.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51214,
          1057,
          558,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.16468772603504694,
        "compression_ratio": 1.255813953488372,
        "end": 6005.36,
        "id": 1764,
        "no_speech_prob": 0.00014883426774758846,
        "seek": 598236,
        "start": 6003.36,
        "temperature": 0,
        "text": " Let me go back to where I was.",
        "tokens": [
          51414,
          961,
          385,
          352,
          646,
          281,
          689,
          286,
          390,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.3340870883013751,
        "compression_ratio": 1.1063829787234043,
        "end": 6014.36,
        "id": 1765,
        "no_speech_prob": 0.0036498464178293943,
        "seek": 601236,
        "start": 6013.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50414,
          1057,
          558,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.3340870883013751,
        "compression_ratio": 1.1063829787234043,
        "end": 6016.36,
        "id": 1766,
        "no_speech_prob": 0.0036498464178293943,
        "seek": 601236,
        "start": 6014.36,
        "temperature": 0,
        "text": " I wasn't paying attention.",
        "tokens": [
          50464,
          286,
          2067,
          380,
          6229,
          3202,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.3340870883013751,
        "compression_ratio": 1.1063829787234043,
        "end": 6020.36,
        "id": 1767,
        "no_speech_prob": 0.0036498464178293943,
        "seek": 601236,
        "start": 6016.36,
        "temperature": 0,
        "text": " If I look at how those arrays are organized, the...",
        "tokens": [
          50564,
          759,
          286,
          574,
          412,
          577,
          729,
          41011,
          366,
          9983,
          11,
          264,
          485,
          50764
        ]
      },
      {
        "avg_logprob": -0.3340870883013751,
        "compression_ratio": 1.1063829787234043,
        "end": 6022.36,
        "id": 1768,
        "no_speech_prob": 0.0036498464178293943,
        "seek": 601236,
        "start": 6021.36,
        "temperature": 0,
        "text": " It's...",
        "tokens": [
          50814,
          467,
          311,
          485,
          50864
        ]
      },
      {
        "avg_logprob": -0.3340870883013751,
        "compression_ratio": 1.1063829787234043,
        "end": 6023.36,
        "id": 1769,
        "no_speech_prob": 0.0036498464178293943,
        "seek": 601236,
        "start": 6022.36,
        "temperature": 0,
        "text": " Sorry.",
        "tokens": [
          50864,
          4919,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2606017772967999,
        "compression_ratio": 1.411764705882353,
        "end": 6044.36,
        "id": 1770,
        "no_speech_prob": 0.010013063438236713,
        "seek": 604236,
        "start": 6043.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2606017772967999,
        "compression_ratio": 1.411764705882353,
        "end": 6054.36,
        "id": 1771,
        "no_speech_prob": 0.010013063438236713,
        "seek": 604236,
        "start": 6052.36,
        "temperature": 0,
        "text": " Okay, something is terribly wrong here.",
        "tokens": [
          50864,
          1033,
          11,
          746,
          307,
          22903,
          2085,
          510,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2606017772967999,
        "compression_ratio": 1.411764705882353,
        "end": 6058.36,
        "id": 1772,
        "no_speech_prob": 0.010013063438236713,
        "seek": 604236,
        "start": 6054.36,
        "temperature": 0,
        "text": " And actually, I have not been carefully looking at how those arrays are organized.",
        "tokens": [
          50964,
          400,
          767,
          11,
          286,
          362,
          406,
          668,
          7500,
          1237,
          412,
          577,
          729,
          41011,
          366,
          9983,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2606017772967999,
        "compression_ratio": 1.411764705882353,
        "end": 6061.36,
        "id": 1773,
        "no_speech_prob": 0.010013063438236713,
        "seek": 604236,
        "start": 6058.36,
        "temperature": 0,
        "text": " It's very confusing to store all these data in arrays.",
        "tokens": [
          51164,
          467,
          311,
          588,
          13181,
          281,
          3531,
          439,
          613,
          1412,
          294,
          41011,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2606017772967999,
        "compression_ratio": 1.411764705882353,
        "end": 6066.36,
        "id": 1774,
        "no_speech_prob": 0.010013063438236713,
        "seek": 604236,
        "start": 6061.36,
        "temperature": 0,
        "text": " But there are 11 strokes.",
        "tokens": [
          51314,
          583,
          456,
          366,
          2975,
          24493,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2606017772967999,
        "compression_ratio": 1.411764705882353,
        "end": 6070.36,
        "id": 1775,
        "no_speech_prob": 0.010013063438236713,
        "seek": 604236,
        "start": 6066.36,
        "temperature": 0,
        "text": " And this stroke has 23 points.",
        "tokens": [
          51564,
          400,
          341,
          12403,
          575,
          6673,
          2793,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17793638627607744,
        "compression_ratio": 1.7790697674418605,
        "end": 6072.36,
        "id": 1776,
        "no_speech_prob": 0.0006986735970713198,
        "seek": 607036,
        "start": 6070.36,
        "temperature": 0,
        "text": " This stroke has 9 points.",
        "tokens": [
          50364,
          639,
          12403,
          575,
          1722,
          2793,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.17793638627607744,
        "compression_ratio": 1.7790697674418605,
        "end": 6074.36,
        "id": 1777,
        "no_speech_prob": 0.0006986735970713198,
        "seek": 607036,
        "start": 6072.36,
        "temperature": 0,
        "text": " But notice that the...",
        "tokens": [
          50464,
          583,
          3449,
          300,
          264,
          485,
          50564
        ]
      },
      {
        "avg_logprob": -0.17793638627607744,
        "compression_ratio": 1.7790697674418605,
        "end": 6076.36,
        "id": 1778,
        "no_speech_prob": 0.0006986735970713198,
        "seek": 607036,
        "start": 6074.36,
        "temperature": 0,
        "text": " I have the order wrong.",
        "tokens": [
          50564,
          286,
          362,
          264,
          1668,
          2085,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17793638627607744,
        "compression_ratio": 1.7790697674418605,
        "end": 6077.36,
        "id": 1779,
        "no_speech_prob": 0.0006986735970713198,
        "seek": 607036,
        "start": 6076.36,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          50664,
          1779,
          30,
          50714
        ]
      },
      {
        "avg_logprob": -0.17793638627607744,
        "compression_ratio": 1.7790697674418605,
        "end": 6079.36,
        "id": 1780,
        "no_speech_prob": 0.0006986735970713198,
        "seek": 607036,
        "start": 6077.36,
        "temperature": 0,
        "text": " This is an array of an array of arrays.",
        "tokens": [
          50714,
          639,
          307,
          364,
          10225,
          295,
          364,
          10225,
          295,
          41011,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.17793638627607744,
        "compression_ratio": 1.7790697674418605,
        "end": 6083.36,
        "id": 1781,
        "no_speech_prob": 0.0006986735970713198,
        "seek": 607036,
        "start": 6079.36,
        "temperature": 0,
        "text": " And so, basically, the stroke...",
        "tokens": [
          50814,
          400,
          370,
          11,
          1936,
          11,
          264,
          12403,
          485,
          51014
        ]
      },
      {
        "avg_logprob": -0.17793638627607744,
        "compression_ratio": 1.7790697674418605,
        "end": 6088.36,
        "id": 1782,
        "no_speech_prob": 0.0006986735970713198,
        "seek": 607036,
        "start": 6083.36,
        "temperature": 0,
        "text": " The zero element of the stroke is all the different x values.",
        "tokens": [
          51014,
          440,
          4018,
          4478,
          295,
          264,
          12403,
          307,
          439,
          264,
          819,
          2031,
          4190,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.17793638627607744,
        "compression_ratio": 1.7790697674418605,
        "end": 6093.36,
        "id": 1783,
        "no_speech_prob": 0.0006986735970713198,
        "seek": 607036,
        "start": 6088.36,
        "temperature": 0,
        "text": " And this one element of the stroke is all the different y values.",
        "tokens": [
          51264,
          400,
          341,
          472,
          4478,
          295,
          264,
          12403,
          307,
          439,
          264,
          819,
          288,
          4190,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.17793638627607744,
        "compression_ratio": 1.7790697674418605,
        "end": 6095.36,
        "id": 1784,
        "no_speech_prob": 0.0006986735970713198,
        "seek": 607036,
        "start": 6093.36,
        "temperature": 0,
        "text": " I had those out of order.",
        "tokens": [
          51514,
          286,
          632,
          729,
          484,
          295,
          1668,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19358459784060109,
        "compression_ratio": 1.7307692307692308,
        "end": 6102.36,
        "id": 1785,
        "no_speech_prob": 0.005641771014779806,
        "seek": 609536,
        "start": 6095.36,
        "temperature": 0,
        "text": " And then here, the number of points is not the number of strokes, but rather the number of x's.",
        "tokens": [
          50364,
          400,
          550,
          510,
          11,
          264,
          1230,
          295,
          2793,
          307,
          406,
          264,
          1230,
          295,
          24493,
          11,
          457,
          2831,
          264,
          1230,
          295,
          2031,
          311,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19358459784060109,
        "compression_ratio": 1.7307692307692308,
        "end": 6106.36,
        "id": 1786,
        "no_speech_prob": 0.005641771014779806,
        "seek": 609536,
        "start": 6102.36,
        "temperature": 0,
        "text": " So now, if I redo this, I should see...",
        "tokens": [
          50714,
          407,
          586,
          11,
          498,
          286,
          29956,
          341,
          11,
          286,
          820,
          536,
          485,
          50914
        ]
      },
      {
        "avg_logprob": -0.19358459784060109,
        "compression_ratio": 1.7307692307692308,
        "end": 6108.36,
        "id": 1787,
        "no_speech_prob": 0.005641771014779806,
        "seek": 609536,
        "start": 6106.36,
        "temperature": 0,
        "text": " I can sort of see it drawing.",
        "tokens": [
          50914,
          286,
          393,
          1333,
          295,
          536,
          309,
          6316,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19358459784060109,
        "compression_ratio": 1.7307692307692308,
        "end": 6118.36,
        "id": 1788,
        "no_speech_prob": 0.005641771014779806,
        "seek": 609536,
        "start": 6116.36,
        "temperature": 0,
        "text": " You can see the outline of a cat there.",
        "tokens": [
          51414,
          509,
          393,
          536,
          264,
          16387,
          295,
          257,
          3857,
          456,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19358459784060109,
        "compression_ratio": 1.7307692307692308,
        "end": 6122.36,
        "id": 1789,
        "no_speech_prob": 0.005641771014779806,
        "seek": 609536,
        "start": 6118.36,
        "temperature": 0,
        "text": " You can start to see the outline of a cat here.",
        "tokens": [
          51514,
          509,
          393,
          722,
          281,
          536,
          264,
          16387,
          295,
          257,
          3857,
          510,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19358459784060109,
        "compression_ratio": 1.7307692307692308,
        "end": 6123.36,
        "id": 1790,
        "no_speech_prob": 0.005641771014779806,
        "seek": 609536,
        "start": 6122.36,
        "temperature": 0,
        "text": " Of course, it gets stuck at the end.",
        "tokens": [
          51714,
          2720,
          1164,
          11,
          309,
          2170,
          5541,
          412,
          264,
          917,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19358459784060109,
        "compression_ratio": 1.7307692307692308,
        "end": 6124.36,
        "id": 1791,
        "no_speech_prob": 0.005641771014779806,
        "seek": 609536,
        "start": 6123.36,
        "temperature": 0,
        "text": " It's giving me an error.",
        "tokens": [
          51764,
          467,
          311,
          2902,
          385,
          364,
          6713,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1929452481477157,
        "compression_ratio": 1.7821782178217822,
        "end": 6126.36,
        "id": 1792,
        "no_speech_prob": 0.0017006865236908197,
        "seek": 612436,
        "start": 6124.36,
        "temperature": 0,
        "text": " So first, let me fix that error.",
        "tokens": [
          50364,
          407,
          700,
          11,
          718,
          385,
          3191,
          300,
          6713,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1929452481477157,
        "compression_ratio": 1.7821782178217822,
        "end": 6128.36,
        "id": 1793,
        "no_speech_prob": 0.0017006865236908197,
        "seek": 612436,
        "start": 6126.36,
        "temperature": 0,
        "text": " So the error that I need to check is...",
        "tokens": [
          50464,
          407,
          264,
          6713,
          300,
          286,
          643,
          281,
          1520,
          307,
          485,
          50564
        ]
      },
      {
        "avg_logprob": -0.1929452481477157,
        "compression_ratio": 1.7821782178217822,
        "end": 6136.36,
        "id": 1794,
        "no_speech_prob": 0.0017006865236908197,
        "seek": 612436,
        "start": 6128.36,
        "temperature": 0,
        "text": " If strokeIndex equals cat.length...",
        "tokens": [
          50564,
          759,
          12403,
          21790,
          3121,
          6915,
          3857,
          13,
          45390,
          485,
          50964
        ]
      },
      {
        "avg_logprob": -0.1929452481477157,
        "compression_ratio": 1.7821782178217822,
        "end": 6138.36,
        "id": 1795,
        "no_speech_prob": 0.0017006865236908197,
        "seek": 612436,
        "start": 6136.36,
        "temperature": 0,
        "text": " Then I'm done.",
        "tokens": [
          50964,
          1396,
          286,
          478,
          1096,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1929452481477157,
        "compression_ratio": 1.7821782178217822,
        "end": 6140.36,
        "id": 1796,
        "no_speech_prob": 0.0017006865236908197,
        "seek": 612436,
        "start": 6138.36,
        "temperature": 0,
        "text": " Then I'm going to say cat equals null.",
        "tokens": [
          51064,
          1396,
          286,
          478,
          516,
          281,
          584,
          3857,
          6915,
          18184,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1929452481477157,
        "compression_ratio": 1.7821782178217822,
        "end": 6143.36,
        "id": 1797,
        "no_speech_prob": 0.0017006865236908197,
        "seek": 612436,
        "start": 6140.36,
        "temperature": 0,
        "text": " I am going to say no more to the cat.",
        "tokens": [
          51164,
          286,
          669,
          516,
          281,
          584,
          572,
          544,
          281,
          264,
          3857,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1929452481477157,
        "compression_ratio": 1.7821782178217822,
        "end": 6145.36,
        "id": 1798,
        "no_speech_prob": 0.0017006865236908197,
        "seek": 612436,
        "start": 6143.36,
        "temperature": 0,
        "text": " And there we go.",
        "tokens": [
          51314,
          400,
          456,
          321,
          352,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1929452481477157,
        "compression_ratio": 1.7821782178217822,
        "end": 6146.36,
        "id": 1799,
        "no_speech_prob": 0.0017006865236908197,
        "seek": 612436,
        "start": 6145.36,
        "temperature": 0,
        "text": " So this is the drawing of the cat.",
        "tokens": [
          51414,
          407,
          341,
          307,
          264,
          6316,
          295,
          264,
          3857,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1929452481477157,
        "compression_ratio": 1.7821782178217822,
        "end": 6148.36,
        "id": 1800,
        "no_speech_prob": 0.0017006865236908197,
        "seek": 612436,
        "start": 6146.36,
        "temperature": 0,
        "text": " Now, of course, I'm just drawing all the points.",
        "tokens": [
          51464,
          823,
          11,
          295,
          1164,
          11,
          286,
          478,
          445,
          6316,
          439,
          264,
          2793,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1929452481477157,
        "compression_ratio": 1.7821782178217822,
        "end": 6152.36,
        "id": 1801,
        "no_speech_prob": 0.0017006865236908197,
        "seek": 612436,
        "start": 6148.36,
        "temperature": 0,
        "text": " I need to connect the previous points to the other points.",
        "tokens": [
          51564,
          286,
          643,
          281,
          1745,
          264,
          3894,
          2793,
          281,
          264,
          661,
          2793,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.21977202645663557,
        "compression_ratio": 1.776536312849162,
        "end": 6156.36,
        "id": 1802,
        "no_speech_prob": 0.0010484595550224185,
        "seek": 615236,
        "start": 6152.36,
        "temperature": 0,
        "text": " So I'm going to add a previousX, previousY.",
        "tokens": [
          50364,
          407,
          286,
          478,
          516,
          281,
          909,
          257,
          3894,
          55,
          11,
          3894,
          56,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.21977202645663557,
        "compression_ratio": 1.776536312849162,
        "end": 6158.36,
        "id": 1803,
        "no_speech_prob": 0.0010484595550224185,
        "seek": 615236,
        "start": 6156.36,
        "temperature": 0,
        "text": " And then I'm going to say...",
        "tokens": [
          50564,
          400,
          550,
          286,
          478,
          516,
          281,
          584,
          485,
          50664
        ]
      },
      {
        "avg_logprob": -0.21977202645663557,
        "compression_ratio": 1.776536312849162,
        "end": 6160.36,
        "id": 1804,
        "no_speech_prob": 0.0010484595550224185,
        "seek": 615236,
        "start": 6158.36,
        "temperature": 0,
        "text": " Here, down here.",
        "tokens": [
          50664,
          1692,
          11,
          760,
          510,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21977202645663557,
        "compression_ratio": 1.776536312849162,
        "end": 6162.36,
        "id": 1805,
        "no_speech_prob": 0.0010484595550224185,
        "seek": 615236,
        "start": 6160.36,
        "temperature": 0,
        "text": " PreviousX equals X.",
        "tokens": [
          50764,
          6001,
          1502,
          55,
          6915,
          1783,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.21977202645663557,
        "compression_ratio": 1.776536312849162,
        "end": 6165.36,
        "id": 1806,
        "no_speech_prob": 0.0010484595550224185,
        "seek": 615236,
        "start": 6162.36,
        "temperature": 0,
        "text": " PreviousY equals Y.",
        "tokens": [
          50864,
          6001,
          1502,
          56,
          6915,
          398,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.21977202645663557,
        "compression_ratio": 1.776536312849162,
        "end": 6172.36,
        "id": 1807,
        "no_speech_prob": 0.0010484595550224185,
        "seek": 615236,
        "start": 6165.36,
        "temperature": 0,
        "text": " And then here, I'm going to say a line between previousX, previousY, and X and Y.",
        "tokens": [
          51014,
          400,
          550,
          510,
          11,
          286,
          478,
          516,
          281,
          584,
          257,
          1622,
          1296,
          3894,
          55,
          11,
          3894,
          56,
          11,
          293,
          1783,
          293,
          398,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.21977202645663557,
        "compression_ratio": 1.776536312849162,
        "end": 6175.36,
        "id": 1808,
        "no_speech_prob": 0.0010484595550224185,
        "seek": 615236,
        "start": 6172.36,
        "temperature": 0,
        "text": " Now, it should do nothing when those values are null.",
        "tokens": [
          51364,
          823,
          11,
          309,
          820,
          360,
          1825,
          562,
          729,
          4190,
          366,
          18184,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.21977202645663557,
        "compression_ratio": 1.776536312849162,
        "end": 6177.36,
        "id": 1809,
        "no_speech_prob": 0.0010484595550224185,
        "seek": 615236,
        "start": 6175.36,
        "temperature": 0,
        "text": " So now we see...",
        "tokens": [
          51514,
          407,
          586,
          321,
          536,
          485,
          51614
        ]
      },
      {
        "avg_logprob": -0.21977202645663557,
        "compression_ratio": 1.776536312849162,
        "end": 6179.36,
        "id": 1810,
        "no_speech_prob": 0.0010484595550224185,
        "seek": 615236,
        "start": 6177.36,
        "temperature": 0,
        "text": " Oh, wait a sec.",
        "tokens": [
          51614,
          876,
          11,
          1699,
          257,
          907,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.21977202645663557,
        "compression_ratio": 1.776536312849162,
        "end": 6181.36,
        "id": 1811,
        "no_speech_prob": 0.0010484595550224185,
        "seek": 615236,
        "start": 6179.36,
        "temperature": 0,
        "text": " No, no, no, no, no.",
        "tokens": [
          51714,
          883,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.20159504994624802,
        "compression_ratio": 1.6592920353982301,
        "end": 6188.36,
        "id": 1812,
        "no_speech_prob": 0.000013845991816197056,
        "seek": 618136,
        "start": 6181.36,
        "temperature": 0,
        "text": " Ah! When I get to the next stroke, then I need to say previousX equals undefined again.",
        "tokens": [
          50364,
          2438,
          0,
          1133,
          286,
          483,
          281,
          264,
          958,
          12403,
          11,
          550,
          286,
          643,
          281,
          584,
          3894,
          55,
          6915,
          674,
          5666,
          2001,
          797,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20159504994624802,
        "compression_ratio": 1.6592920353982301,
        "end": 6190.36,
        "id": 1813,
        "no_speech_prob": 0.000013845991816197056,
        "seek": 618136,
        "start": 6188.36,
        "temperature": 0,
        "text": " And previousY equals...",
        "tokens": [
          50714,
          400,
          3894,
          56,
          6915,
          485,
          50814
        ]
      },
      {
        "avg_logprob": -0.20159504994624802,
        "compression_ratio": 1.6592920353982301,
        "end": 6192.36,
        "id": 1814,
        "no_speech_prob": 0.000013845991816197056,
        "seek": 618136,
        "start": 6190.36,
        "temperature": 0,
        "text": " Because I don't want to connect the strokes.",
        "tokens": [
          50814,
          1436,
          286,
          500,
          380,
          528,
          281,
          1745,
          264,
          24493,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20159504994624802,
        "compression_ratio": 1.6592920353982301,
        "end": 6194.36,
        "id": 1815,
        "no_speech_prob": 0.000013845991816197056,
        "seek": 618136,
        "start": 6192.36,
        "temperature": 0,
        "text": " So that's a little bit of an awkward way of doing it.",
        "tokens": [
          50914,
          407,
          300,
          311,
          257,
          707,
          857,
          295,
          364,
          11411,
          636,
          295,
          884,
          309,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20159504994624802,
        "compression_ratio": 1.6592920353982301,
        "end": 6196.36,
        "id": 1816,
        "no_speech_prob": 0.000013845991816197056,
        "seek": 618136,
        "start": 6194.36,
        "temperature": 0,
        "text": " It's still doing that, isn't it?",
        "tokens": [
          51014,
          467,
          311,
          920,
          884,
          300,
          11,
          1943,
          380,
          309,
          30,
          51114
        ]
      },
      {
        "avg_logprob": -0.20159504994624802,
        "compression_ratio": 1.6592920353982301,
        "end": 6201.36,
        "id": 1817,
        "no_speech_prob": 0.000013845991816197056,
        "seek": 618136,
        "start": 6196.36,
        "temperature": 0,
        "text": " And then I want to say if previousX...",
        "tokens": [
          51114,
          400,
          550,
          286,
          528,
          281,
          584,
          498,
          3894,
          55,
          485,
          51364
        ]
      },
      {
        "avg_logprob": -0.20159504994624802,
        "compression_ratio": 1.6592920353982301,
        "end": 6203.36,
        "id": 1818,
        "no_speech_prob": 0.000013845991816197056,
        "seek": 618136,
        "start": 6201.36,
        "temperature": 0,
        "text": " Maybe if I do this...",
        "tokens": [
          51364,
          2704,
          498,
          286,
          360,
          341,
          485,
          51464
        ]
      },
      {
        "avg_logprob": -0.20159504994624802,
        "compression_ratio": 1.6592920353982301,
        "end": 6206.36,
        "id": 1819,
        "no_speech_prob": 0.000013845991816197056,
        "seek": 618136,
        "start": 6203.36,
        "temperature": 0,
        "text": " Does not equal undefined.",
        "tokens": [
          51464,
          4402,
          406,
          2681,
          674,
          5666,
          2001,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20159504994624802,
        "compression_ratio": 1.6592920353982301,
        "end": 6208.36,
        "id": 1820,
        "no_speech_prob": 0.000013845991816197056,
        "seek": 618136,
        "start": 6206.36,
        "temperature": 0,
        "text": " Then draw the line.",
        "tokens": [
          51614,
          1396,
          2642,
          264,
          1622,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20159504994624802,
        "compression_ratio": 1.6592920353982301,
        "end": 6210.36,
        "id": 1821,
        "no_speech_prob": 0.000013845991816197056,
        "seek": 618136,
        "start": 6208.36,
        "temperature": 0,
        "text": " Let's see if this works.",
        "tokens": [
          51714,
          961,
          311,
          536,
          498,
          341,
          1985,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.21136415765640584,
        "compression_ratio": 1.4381443298969072,
        "end": 6212.36,
        "id": 1822,
        "no_speech_prob": 0.00008220172458095476,
        "seek": 621036,
        "start": 6210.36,
        "temperature": 0,
        "text": " Whoops. Sketch line 19.",
        "tokens": [
          50364,
          45263,
          13,
          49245,
          1622,
          1294,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.21136415765640584,
        "compression_ratio": 1.4381443298969072,
        "end": 6214.36,
        "id": 1823,
        "no_speech_prob": 0.00008220172458095476,
        "seek": 621036,
        "start": 6212.36,
        "temperature": 0,
        "text": " I always have this extra equals there.",
        "tokens": [
          50464,
          286,
          1009,
          362,
          341,
          2857,
          6915,
          456,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.21136415765640584,
        "compression_ratio": 1.4381443298969072,
        "end": 6216.36,
        "id": 1824,
        "no_speech_prob": 0.00008220172458095476,
        "seek": 621036,
        "start": 6214.36,
        "temperature": 0,
        "text": " Oh, weird.",
        "tokens": [
          50564,
          876,
          11,
          3657,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.21136415765640584,
        "compression_ratio": 1.4381443298969072,
        "end": 6220.36,
        "id": 1825,
        "no_speech_prob": 0.00008220172458095476,
        "seek": 621036,
        "start": 6218.36,
        "temperature": 0,
        "text": " It's still connecting everything.",
        "tokens": [
          50764,
          467,
          311,
          920,
          11015,
          1203,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.21136415765640584,
        "compression_ratio": 1.4381443298969072,
        "end": 6222.36,
        "id": 1826,
        "no_speech_prob": 0.00008220172458095476,
        "seek": 621036,
        "start": 6220.36,
        "temperature": 0,
        "text": " A lovely little cat there.",
        "tokens": [
          50864,
          316,
          7496,
          707,
          3857,
          456,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.21136415765640584,
        "compression_ratio": 1.4381443298969072,
        "end": 6224.36,
        "id": 1827,
        "no_speech_prob": 0.00008220172458095476,
        "seek": 621036,
        "start": 6222.36,
        "temperature": 0,
        "text": " What am I missing?",
        "tokens": [
          50964,
          708,
          669,
          286,
          5361,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.21136415765640584,
        "compression_ratio": 1.4381443298969072,
        "end": 6227.36,
        "id": 1828,
        "no_speech_prob": 0.00008220172458095476,
        "seek": 621036,
        "start": 6224.36,
        "temperature": 0,
        "text": " I don't want to draw the line.",
        "tokens": [
          51064,
          286,
          500,
          380,
          528,
          281,
          2642,
          264,
          1622,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.21136415765640584,
        "compression_ratio": 1.4381443298969072,
        "end": 6230.36,
        "id": 1829,
        "no_speech_prob": 0.00008220172458095476,
        "seek": 621036,
        "start": 6227.36,
        "temperature": 0,
        "text": " These are undefined at the beginning.",
        "tokens": [
          51214,
          1981,
          366,
          674,
          5666,
          2001,
          412,
          264,
          2863,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.21136415765640584,
        "compression_ratio": 1.4381443298969072,
        "end": 6233.36,
        "id": 1830,
        "no_speech_prob": 0.00008220172458095476,
        "seek": 621036,
        "start": 6230.36,
        "temperature": 0,
        "text": " Oh, it gets set to here.",
        "tokens": [
          51364,
          876,
          11,
          309,
          2170,
          992,
          281,
          510,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.21136415765640584,
        "compression_ratio": 1.4381443298969072,
        "end": 6235.36,
        "id": 1831,
        "no_speech_prob": 0.00008220172458095476,
        "seek": 621036,
        "start": 6233.36,
        "temperature": 0,
        "text": " So I need an else here.",
        "tokens": [
          51514,
          407,
          286,
          643,
          364,
          1646,
          510,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.21136415765640584,
        "compression_ratio": 1.4381443298969072,
        "end": 6237.36,
        "id": 1832,
        "no_speech_prob": 0.00008220172458095476,
        "seek": 621036,
        "start": 6235.36,
        "temperature": 0,
        "text": " Else...",
        "tokens": [
          51614,
          45472,
          485,
          51714
        ]
      },
      {
        "avg_logprob": -0.18948910453102805,
        "compression_ratio": 1.5118483412322274,
        "end": 6240.36,
        "id": 1833,
        "no_speech_prob": 0.0012842790456488729,
        "seek": 623736,
        "start": 6237.36,
        "temperature": 0,
        "text": " Don't set it if it's at the end.",
        "tokens": [
          50364,
          1468,
          380,
          992,
          309,
          498,
          309,
          311,
          412,
          264,
          917,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.18948910453102805,
        "compression_ratio": 1.5118483412322274,
        "end": 6242.36,
        "id": 1834,
        "no_speech_prob": 0.0012842790456488729,
        "seek": 623736,
        "start": 6240.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50514,
          1033,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18948910453102805,
        "compression_ratio": 1.5118483412322274,
        "end": 6244.36,
        "id": 1835,
        "no_speech_prob": 0.0012842790456488729,
        "seek": 623736,
        "start": 6242.36,
        "temperature": 0,
        "text": " There we go! Finally!",
        "tokens": [
          50614,
          821,
          321,
          352,
          0,
          6288,
          0,
          50714
        ]
      },
      {
        "avg_logprob": -0.18948910453102805,
        "compression_ratio": 1.5118483412322274,
        "end": 6246.36,
        "id": 1836,
        "no_speech_prob": 0.0012842790456488729,
        "seek": 623736,
        "start": 6244.36,
        "temperature": 0,
        "text": " We are drawing cats.",
        "tokens": [
          50714,
          492,
          366,
          6316,
          11111,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.18948910453102805,
        "compression_ratio": 1.5118483412322274,
        "end": 6252.36,
        "id": 1837,
        "no_speech_prob": 0.0012842790456488729,
        "seek": 623736,
        "start": 6246.36,
        "temperature": 0,
        "text": " Now, all I have to do is then, when I reset there, I can just ask for a new one.",
        "tokens": [
          50814,
          823,
          11,
          439,
          286,
          362,
          281,
          360,
          307,
          550,
          11,
          562,
          286,
          14322,
          456,
          11,
          286,
          393,
          445,
          1029,
          337,
          257,
          777,
          472,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18948910453102805,
        "compression_ratio": 1.5118483412322274,
        "end": 6255.36,
        "id": 1838,
        "no_speech_prob": 0.0012842790456488729,
        "seek": 623736,
        "start": 6252.36,
        "temperature": 0,
        "text": " So let's ask for a new cat.",
        "tokens": [
          51114,
          407,
          718,
          311,
          1029,
          337,
          257,
          777,
          3857,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18948910453102805,
        "compression_ratio": 1.5118483412322274,
        "end": 6261.36,
        "id": 1839,
        "no_speech_prob": 0.0012842790456488729,
        "seek": 623736,
        "start": 6255.36,
        "temperature": 0,
        "text": " And whenever I've got a cat, let's draw a white background.",
        "tokens": [
          51264,
          400,
          5699,
          286,
          600,
          658,
          257,
          3857,
          11,
          718,
          311,
          2642,
          257,
          2418,
          3678,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18948910453102805,
        "compression_ratio": 1.5118483412322274,
        "end": 6264.36,
        "id": 1840,
        "no_speech_prob": 0.0012842790456488729,
        "seek": 623736,
        "start": 6261.36,
        "temperature": 0,
        "text": " Let's make it a little bit gray.",
        "tokens": [
          51564,
          961,
          311,
          652,
          309,
          257,
          707,
          857,
          10855,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18948910453102805,
        "compression_ratio": 1.5118483412322274,
        "end": 6266.36,
        "id": 1841,
        "no_speech_prob": 0.0012842790456488729,
        "seek": 623736,
        "start": 6264.36,
        "temperature": 0,
        "text": " We'll set it gray at the beginning.",
        "tokens": [
          51714,
          492,
          603,
          992,
          309,
          10855,
          412,
          264,
          2863,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2894374192363084,
        "compression_ratio": 1.4526315789473685,
        "end": 6268.36,
        "id": 1842,
        "no_speech_prob": 0.0022515824530273676,
        "seek": 626636,
        "start": 6266.36,
        "temperature": 0,
        "text": " There we go. Now, here we go!",
        "tokens": [
          50364,
          821,
          321,
          352,
          13,
          823,
          11,
          510,
          321,
          352,
          0,
          50464
        ]
      },
      {
        "avg_logprob": -0.2894374192363084,
        "compression_ratio": 1.4526315789473685,
        "end": 6271.36,
        "id": 1843,
        "no_speech_prob": 0.0022515824530273676,
        "seek": 626636,
        "start": 6268.36,
        "temperature": 0,
        "text": " We are now going to draw lots of cats.",
        "tokens": [
          50464,
          492,
          366,
          586,
          516,
          281,
          2642,
          3195,
          295,
          11111,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2894374192363084,
        "compression_ratio": 1.4526315789473685,
        "end": 6273.36,
        "id": 1844,
        "no_speech_prob": 0.0022515824530273676,
        "seek": 626636,
        "start": 6271.36,
        "temperature": 0,
        "text": " It should finish one.",
        "tokens": [
          50614,
          467,
          820,
          2413,
          472,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2894374192363084,
        "compression_ratio": 1.4526315789473685,
        "end": 6275.36,
        "id": 1845,
        "no_speech_prob": 0.0022515824530273676,
        "seek": 626636,
        "start": 6273.36,
        "temperature": 0,
        "text": " Oh! Didn't get another one.",
        "tokens": [
          50714,
          876,
          0,
          11151,
          380,
          483,
          1071,
          472,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2894374192363084,
        "compression_ratio": 1.4526315789473685,
        "end": 6277.36,
        "id": 1846,
        "no_speech_prob": 0.0022515824530273676,
        "seek": 626636,
        "start": 6275.36,
        "temperature": 0,
        "text": " Sketch line 13.",
        "tokens": [
          50814,
          49245,
          1622,
          3705,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2894374192363084,
        "compression_ratio": 1.4526315789473685,
        "end": 6279.36,
        "id": 1847,
        "no_speech_prob": 0.0022515824530273676,
        "seek": 626636,
        "start": 6277.36,
        "temperature": 0,
        "text": " Uh...",
        "tokens": [
          50914,
          4019,
          485,
          51014
        ]
      },
      {
        "avg_logprob": -0.2894374192363084,
        "compression_ratio": 1.4526315789473685,
        "end": 6283.36,
        "id": 1848,
        "no_speech_prob": 0.0022515824530273676,
        "seek": 626636,
        "start": 6279.36,
        "temperature": 0,
        "text": " Cat is undefined.",
        "tokens": [
          51014,
          9565,
          307,
          674,
          5666,
          2001,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2894374192363084,
        "compression_ratio": 1.4526315789473685,
        "end": 6288.36,
        "id": 1849,
        "no_speech_prob": 0.0022515824530273676,
        "seek": 626636,
        "start": 6283.36,
        "temperature": 0,
        "text": " And then, there should be no more cat until I've got a cat.",
        "tokens": [
          51214,
          400,
          550,
          11,
          456,
          820,
          312,
          572,
          544,
          3857,
          1826,
          286,
          600,
          658,
          257,
          3857,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2894374192363084,
        "compression_ratio": 1.4526315789473685,
        "end": 6290.36,
        "id": 1850,
        "no_speech_prob": 0.0022515824530273676,
        "seek": 626636,
        "start": 6288.36,
        "temperature": 0,
        "text": " Try that again.",
        "tokens": [
          51464,
          6526,
          300,
          797,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2894374192363084,
        "compression_ratio": 1.4526315789473685,
        "end": 6293.36,
        "id": 1851,
        "no_speech_prob": 0.0022515824530273676,
        "seek": 626636,
        "start": 6290.36,
        "temperature": 0,
        "text": " There we go! I don't know what did wrong.",
        "tokens": [
          51564,
          821,
          321,
          352,
          0,
          286,
          500,
          380,
          458,
          437,
          630,
          2085,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.33040440271771143,
        "compression_ratio": 1.34375,
        "end": 6295.36,
        "id": 1852,
        "no_speech_prob": 0.13115157186985016,
        "seek": 629336,
        "start": 6293.36,
        "temperature": 0,
        "text": " Oh!",
        "tokens": [
          50364,
          876,
          0,
          50464
        ]
      },
      {
        "avg_logprob": -0.33040440271771143,
        "compression_ratio": 1.34375,
        "end": 6298.36,
        "id": 1853,
        "no_speech_prob": 0.13115157186985016,
        "seek": 629336,
        "start": 6295.36,
        "temperature": 0,
        "text": " It drew a bunch of them and then didn't get one.",
        "tokens": [
          50464,
          467,
          12804,
          257,
          3840,
          295,
          552,
          293,
          550,
          994,
          380,
          483,
          472,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.33040440271771143,
        "compression_ratio": 1.34375,
        "end": 6300.36,
        "id": 1854,
        "no_speech_prob": 0.13115157186985016,
        "seek": 629336,
        "start": 6298.36,
        "temperature": 0,
        "text": " Where is it breaking?",
        "tokens": [
          50614,
          2305,
          307,
          309,
          7697,
          30,
          50714
        ]
      },
      {
        "avg_logprob": -0.33040440271771143,
        "compression_ratio": 1.34375,
        "end": 6305.36,
        "id": 1855,
        "no_speech_prob": 0.13115157186985016,
        "seek": 629336,
        "start": 6300.36,
        "temperature": 0,
        "text": " Am I... Is it like a sequencing thing?",
        "tokens": [
          50714,
          2012,
          286,
          485,
          1119,
          309,
          411,
          257,
          32693,
          551,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.33040440271771143,
        "compression_ratio": 1.34375,
        "end": 6312.36,
        "id": 1856,
        "no_speech_prob": 0.13115157186985016,
        "seek": 629336,
        "start": 6309.36,
        "temperature": 0,
        "text": " Like it's drew the cat...",
        "tokens": [
          51164,
          1743,
          309,
          311,
          12804,
          264,
          3857,
          485,
          51314
        ]
      },
      {
        "avg_logprob": -0.33040440271771143,
        "compression_ratio": 1.34375,
        "end": 6318.36,
        "id": 1857,
        "no_speech_prob": 0.13115157186985016,
        "seek": 629336,
        "start": 6316.36,
        "temperature": 0,
        "text": " Is it...",
        "tokens": [
          51514,
          1119,
          309,
          485,
          51614
        ]
      },
      {
        "avg_logprob": -0.33040440271771143,
        "compression_ratio": 1.34375,
        "end": 6321.36,
        "id": 1858,
        "no_speech_prob": 0.13115157186985016,
        "seek": 629336,
        "start": 6318.36,
        "temperature": 0,
        "text": " Asking for a new cat...",
        "tokens": [
          51614,
          1018,
          5092,
          337,
          257,
          777,
          3857,
          485,
          51764
        ]
      },
      {
        "avg_logprob": -0.3645302621941817,
        "compression_ratio": 1.421875,
        "end": 6324.36,
        "id": 1859,
        "no_speech_prob": 0.0038842768408358097,
        "seek": 632136,
        "start": 6321.36,
        "temperature": 0,
        "text": " Should I say no loop?",
        "tokens": [
          50364,
          6454,
          286,
          584,
          572,
          6367,
          30,
          50514
        ]
      },
      {
        "avg_logprob": -0.3645302621941817,
        "compression_ratio": 1.421875,
        "end": 6329.36,
        "id": 1860,
        "no_speech_prob": 0.0038842768408358097,
        "seek": 632136,
        "start": 6324.36,
        "temperature": 0,
        "text": " And then, when it gets a cat, say loop.",
        "tokens": [
          50514,
          400,
          550,
          11,
          562,
          309,
          2170,
          257,
          3857,
          11,
          584,
          6367,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.3645302621941817,
        "compression_ratio": 1.421875,
        "end": 6332.36,
        "id": 1861,
        "no_speech_prob": 0.0038842768408358097,
        "seek": 632136,
        "start": 6329.36,
        "temperature": 0,
        "text": " Oh! Stroke index needs to be set to zero.",
        "tokens": [
          50764,
          876,
          0,
          42196,
          330,
          8186,
          2203,
          281,
          312,
          992,
          281,
          4018,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.3645302621941817,
        "compression_ratio": 1.421875,
        "end": 6335.36,
        "id": 1862,
        "no_speech_prob": 0.0038842768408358097,
        "seek": 632136,
        "start": 6332.36,
        "temperature": 0,
        "text": " Ah! Okay! Thank you to the chat.",
        "tokens": [
          50914,
          2438,
          0,
          1033,
          0,
          1044,
          291,
          281,
          264,
          5081,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.3645302621941817,
        "compression_ratio": 1.421875,
        "end": 6337.36,
        "id": 1863,
        "no_speech_prob": 0.0038842768408358097,
        "seek": 632136,
        "start": 6335.36,
        "temperature": 0,
        "text": " Wait, hold on.",
        "tokens": [
          51064,
          3802,
          11,
          1797,
          322,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.3645302621941817,
        "compression_ratio": 1.421875,
        "end": 6342.36,
        "id": 1864,
        "no_speech_prob": 0.0038842768408358097,
        "seek": 632136,
        "start": 6337.36,
        "temperature": 0,
        "text": " Mattheo, you can edit out me trying to think about this for a minute.",
        "tokens": [
          51164,
          6789,
          3322,
          78,
          11,
          291,
          393,
          8129,
          484,
          385,
          1382,
          281,
          519,
          466,
          341,
          337,
          257,
          3456,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.3645302621941817,
        "compression_ratio": 1.421875,
        "end": 6349.36,
        "id": 1865,
        "no_speech_prob": 0.0038842768408358097,
        "seek": 632136,
        "start": 6345.36,
        "temperature": 0,
        "text": " Thank you to BIMSOMEE and Louise, both in the chat,",
        "tokens": [
          51564,
          1044,
          291,
          281,
          363,
          6324,
          50,
          5251,
          7258,
          293,
          35962,
          11,
          1293,
          294,
          264,
          5081,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.21238128662109376,
        "compression_ratio": 1.7684729064039408,
        "end": 6354.36,
        "id": 1866,
        "no_speech_prob": 0.0025105292443186045,
        "seek": 634936,
        "start": 6349.36,
        "temperature": 0,
        "text": " who just pointed out that my technique here is correct,",
        "tokens": [
          50364,
          567,
          445,
          10932,
          484,
          300,
          452,
          6532,
          510,
          307,
          3006,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.21238128662109376,
        "compression_ratio": 1.7684729064039408,
        "end": 6358.36,
        "id": 1867,
        "no_speech_prob": 0.0025105292443186045,
        "seek": 634936,
        "start": 6354.36,
        "temperature": 0,
        "text": " but the issue is that I need to reset everything back to zero.",
        "tokens": [
          50614,
          457,
          264,
          2734,
          307,
          300,
          286,
          643,
          281,
          14322,
          1203,
          646,
          281,
          4018,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21238128662109376,
        "compression_ratio": 1.7684729064039408,
        "end": 6362.36,
        "id": 1868,
        "no_speech_prob": 0.0025105292443186045,
        "seek": 634936,
        "start": 6358.36,
        "temperature": 0,
        "text": " So here, I need to set stroke index back to zero.",
        "tokens": [
          50814,
          407,
          510,
          11,
          286,
          643,
          281,
          992,
          12403,
          8186,
          646,
          281,
          4018,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.21238128662109376,
        "compression_ratio": 1.7684729064039408,
        "end": 6364.36,
        "id": 1869,
        "no_speech_prob": 0.0025105292443186045,
        "seek": 634936,
        "start": 6362.36,
        "temperature": 0,
        "text": " And I think index will already be zero.",
        "tokens": [
          51014,
          400,
          286,
          519,
          8186,
          486,
          1217,
          312,
          4018,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21238128662109376,
        "compression_ratio": 1.7684729064039408,
        "end": 6365.36,
        "id": 1870,
        "no_speech_prob": 0.0025105292443186045,
        "seek": 634936,
        "start": 6364.36,
        "temperature": 0,
        "text": " Yeah, index is already zero.",
        "tokens": [
          51114,
          865,
          11,
          8186,
          307,
          1217,
          4018,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.21238128662109376,
        "compression_ratio": 1.7684729064039408,
        "end": 6367.36,
        "id": 1871,
        "no_speech_prob": 0.0025105292443186045,
        "seek": 634936,
        "start": 6365.36,
        "temperature": 0,
        "text": " So yes, that stroke index needs to go back to the beginning.",
        "tokens": [
          51164,
          407,
          2086,
          11,
          300,
          12403,
          8186,
          2203,
          281,
          352,
          646,
          281,
          264,
          2863,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.21238128662109376,
        "compression_ratio": 1.7684729064039408,
        "end": 6373.36,
        "id": 1872,
        "no_speech_prob": 0.0025105292443186045,
        "seek": 634936,
        "start": 6367.36,
        "temperature": 0,
        "text": " And now, I think we're ready to enjoy a whole bunch of cats.",
        "tokens": [
          51264,
          400,
          586,
          11,
          286,
          519,
          321,
          434,
          1919,
          281,
          2103,
          257,
          1379,
          3840,
          295,
          11111,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.44917356353445154,
        "compression_ratio": 1.5852534562211982,
        "end": 6375.36,
        "id": 1873,
        "no_speech_prob": 0.06848935782909393,
        "seek": 637336,
        "start": 6373.36,
        "temperature": 0,
        "text": " Cat drawings!",
        "tokens": [
          50364,
          9565,
          18618,
          0,
          50464
        ]
      },
      {
        "avg_logprob": -0.44917356353445154,
        "compression_ratio": 1.5852534562211982,
        "end": 6379.36,
        "id": 1874,
        "no_speech_prob": 0.06848935782909393,
        "seek": 637336,
        "start": 6375.36,
        "temperature": 0,
        "text": " Alright, thanks for watching this coding challenge",
        "tokens": [
          50464,
          2798,
          11,
          3231,
          337,
          1976,
          341,
          17720,
          3430,
          50664
        ]
      },
      {
        "avg_logprob": -0.44917356353445154,
        "compression_ratio": 1.5852534562211982,
        "end": 6381.36,
        "id": 1875,
        "no_speech_prob": 0.06848935782909393,
        "seek": 637336,
        "start": 6379.36,
        "temperature": 0,
        "text": " with the Google Quick Draw dataset.",
        "tokens": [
          50664,
          365,
          264,
          3329,
          12101,
          20386,
          28872,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.44917356353445154,
        "compression_ratio": 1.5852534562211982,
        "end": 6387.36,
        "id": 1876,
        "no_speech_prob": 0.06848935782909393,
        "seek": 637336,
        "start": 6381.36,
        "temperature": 0,
        "text": " Stay tuned for a future video where I show how to...",
        "tokens": [
          50764,
          8691,
          10870,
          337,
          257,
          2027,
          960,
          689,
          286,
          855,
          577,
          281,
          485,
          51064
        ]
      },
      {
        "avg_logprob": -0.44917356353445154,
        "compression_ratio": 1.5852534562211982,
        "end": 6390.36,
        "id": 1877,
        "no_speech_prob": 0.06848935782909393,
        "seek": 637336,
        "start": 6389.36,
        "temperature": 0,
        "text": " What do I do?",
        "tokens": [
          51164,
          708,
          360,
          286,
          360,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.44917356353445154,
        "compression_ratio": 1.5852534562211982,
        "end": 6393.36,
        "id": 1878,
        "no_speech_prob": 0.06848935782909393,
        "seek": 637336,
        "start": 6390.36,
        "temperature": 0,
        "text": " This is where I show how to create new drawings",
        "tokens": [
          51214,
          639,
          307,
          689,
          286,
          855,
          577,
          281,
          1884,
          777,
          18618,
          51364
        ]
      },
      {
        "avg_logprob": -0.44917356353445154,
        "compression_ratio": 1.5852534562211982,
        "end": 6395.36,
        "id": 1879,
        "no_speech_prob": 0.06848935782909393,
        "seek": 637336,
        "start": 6393.36,
        "temperature": 0,
        "text": " with the Sketch RNN model, the machine learning model",
        "tokens": [
          51364,
          365,
          264,
          49245,
          45702,
          45,
          2316,
          11,
          264,
          3479,
          2539,
          2316,
          51464
        ]
      },
      {
        "avg_logprob": -0.44917356353445154,
        "compression_ratio": 1.5852534562211982,
        "end": 6398.36,
        "id": 1880,
        "no_speech_prob": 0.06848935782909393,
        "seek": 637336,
        "start": 6395.36,
        "temperature": 0,
        "text": " that was trained on the Sketch RNN model.",
        "tokens": [
          51464,
          300,
          390,
          8895,
          322,
          264,
          49245,
          45702,
          45,
          2316,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.44917356353445154,
        "compression_ratio": 1.5852534562211982,
        "end": 6399.36,
        "id": 1881,
        "no_speech_prob": 0.06848935782909393,
        "seek": 637336,
        "start": 6398.36,
        "temperature": 0,
        "text": " And I'll see you next time.",
        "tokens": [
          51614,
          400,
          286,
          603,
          536,
          291,
          958,
          565,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.44917356353445154,
        "compression_ratio": 1.5852534562211982,
        "end": 6400.36,
        "id": 1882,
        "no_speech_prob": 0.06848935782909393,
        "seek": 637336,
        "start": 6399.36,
        "temperature": 0,
        "text": " Bye!",
        "tokens": [
          51664,
          4621,
          0,
          51714
        ]
      },
      {
        "avg_logprob": -0.24018795593925144,
        "compression_ratio": 1.2868852459016393,
        "end": 6404.36,
        "id": 1883,
        "no_speech_prob": 0.8090403079986572,
        "seek": 640336,
        "start": 6403.36,
        "temperature": 0,
        "text": " I love these drawings.",
        "tokens": [
          50364,
          286,
          959,
          613,
          18618,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.24018795593925144,
        "compression_ratio": 1.2868852459016393,
        "end": 6406.36,
        "id": 1884,
        "no_speech_prob": 0.8090403079986572,
        "seek": 640336,
        "start": 6404.36,
        "temperature": 0,
        "text": " And if this was one of your drawings,",
        "tokens": [
          50414,
          400,
          498,
          341,
          390,
          472,
          295,
          428,
          18618,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.24018795593925144,
        "compression_ratio": 1.2868852459016393,
        "end": 6408.36,
        "id": 1885,
        "no_speech_prob": 0.8090403079986572,
        "seek": 640336,
        "start": 6406.36,
        "temperature": 0,
        "text": " thank you for making this beautiful cat,",
        "tokens": [
          50514,
          1309,
          291,
          337,
          1455,
          341,
          2238,
          3857,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.24018795593925144,
        "compression_ratio": 1.2868852459016393,
        "end": 6409.36,
        "id": 1886,
        "no_speech_prob": 0.8090403079986572,
        "seek": 640336,
        "start": 6408.36,
        "temperature": 0,
        "text": " and I'll see you in a future coding challenge.",
        "tokens": [
          50614,
          293,
          286,
          603,
          536,
          291,
          294,
          257,
          2027,
          17720,
          3430,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.24018795593925144,
        "compression_ratio": 1.2868852459016393,
        "end": 6410.36,
        "id": 1887,
        "no_speech_prob": 0.8090403079986572,
        "seek": 640336,
        "start": 6409.36,
        "temperature": 0,
        "text": " Goodbye!",
        "tokens": [
          50664,
          15528,
          0,
          50714
        ]
      },
      {
        "avg_logprob": -0.2534565340008652,
        "compression_ratio": 1.338235294117647,
        "end": 6437.36,
        "id": 1888,
        "no_speech_prob": 0.7306209206581116,
        "seek": 643336,
        "start": 6434.36,
        "temperature": 0,
        "text": " This is like, immensely satisfying.",
        "tokens": [
          50414,
          639,
          307,
          411,
          11,
          38674,
          18348,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2534565340008652,
        "compression_ratio": 1.338235294117647,
        "end": 6446.36,
        "id": 1889,
        "no_speech_prob": 0.7306209206581116,
        "seek": 643336,
        "start": 6443.36,
        "temperature": 0,
        "text": " Like, I could just watch this all day.",
        "tokens": [
          50864,
          1743,
          11,
          286,
          727,
          445,
          1159,
          341,
          439,
          786,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2534565340008652,
        "compression_ratio": 1.338235294117647,
        "end": 6451.36,
        "id": 1890,
        "no_speech_prob": 0.7306209206581116,
        "seek": 643336,
        "start": 6449.36,
        "temperature": 0,
        "text": " Is it not finishing the drawings?",
        "tokens": [
          51164,
          1119,
          309,
          406,
          12693,
          264,
          18618,
          30,
          51264
        ]
      },
      {
        "avg_logprob": -0.2534565340008652,
        "compression_ratio": 1.338235294117647,
        "end": 6458.36,
        "id": 1891,
        "no_speech_prob": 0.7306209206581116,
        "seek": 643336,
        "start": 6455.36,
        "temperature": 0,
        "text": " Well, I should give it a little, like, delay.",
        "tokens": [
          51464,
          1042,
          11,
          286,
          820,
          976,
          309,
          257,
          707,
          11,
          411,
          11,
          8577,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2534565340008652,
        "compression_ratio": 1.338235294117647,
        "end": 6462.36,
        "id": 1892,
        "no_speech_prob": 0.7306209206581116,
        "seek": 643336,
        "start": 6459.36,
        "temperature": 0,
        "text": " Like, if I did set timeout.",
        "tokens": [
          51664,
          1743,
          11,
          498,
          286,
          630,
          992,
          565,
          346,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.500978029691256,
        "compression_ratio": 1.169811320754717,
        "end": 6465.36,
        "id": 1893,
        "no_speech_prob": 0.001500896643847227,
        "seek": 646336,
        "start": 6463.36,
        "temperature": 0,
        "text": " I should probably do that.",
        "tokens": [
          50364,
          286,
          820,
          1391,
          360,
          300,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.500978029691256,
        "compression_ratio": 1.169811320754717,
        "end": 6476.36,
        "id": 1894,
        "no_speech_prob": 0.001500896643847227,
        "seek": 646336,
        "start": 6473.36,
        "temperature": 0,
        "text": " Let me just make a function called new cat.",
        "tokens": [
          50864,
          961,
          385,
          445,
          652,
          257,
          2445,
          1219,
          777,
          3857,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.500978029691256,
        "compression_ratio": 1.169811320754717,
        "end": 6486.36,
        "id": 1895,
        "no_speech_prob": 0.001500896643847227,
        "seek": 646336,
        "start": 6484.36,
        "temperature": 0,
        "text": " I don't know what music I just played.",
        "tokens": [
          51414,
          286,
          500,
          380,
          458,
          437,
          1318,
          286,
          445,
          3737,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.500978029691256,
        "compression_ratio": 1.169811320754717,
        "end": 6488.36,
        "id": 1896,
        "no_speech_prob": 0.001500896643847227,
        "seek": 646336,
        "start": 6486.36,
        "temperature": 0,
        "text": " This is weird.",
        "tokens": [
          51514,
          639,
          307,
          3657,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.25434736619915876,
        "compression_ratio": 1.3423423423423424,
        "end": 6496.36,
        "id": 1897,
        "no_speech_prob": 0.0003458924766164273,
        "seek": 649336,
        "start": 6494.36,
        "temperature": 0,
        "text": " So now, let's take a look.",
        "tokens": [
          50414,
          407,
          586,
          11,
          718,
          311,
          747,
          257,
          574,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.25434736619915876,
        "compression_ratio": 1.3423423423423424,
        "end": 6499.36,
        "id": 1898,
        "no_speech_prob": 0.0003458924766164273,
        "seek": 649336,
        "start": 6496.36,
        "temperature": 0,
        "text": " Now I just give it a little delay.",
        "tokens": [
          50514,
          823,
          286,
          445,
          976,
          309,
          257,
          707,
          8577,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.25434736619915876,
        "compression_ratio": 1.3423423423423424,
        "end": 6507.36,
        "id": 1899,
        "no_speech_prob": 0.0003458924766164273,
        "seek": 649336,
        "start": 6504.36,
        "temperature": 0,
        "text": " What? What? What?",
        "tokens": [
          50914,
          708,
          30,
          708,
          30,
          708,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.25434736619915876,
        "compression_ratio": 1.3423423423423424,
        "end": 6509.36,
        "id": 1900,
        "no_speech_prob": 0.0003458924766164273,
        "seek": 649336,
        "start": 6507.36,
        "temperature": 0,
        "text": " 38.",
        "tokens": [
          51064,
          12843,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.25434736619915876,
        "compression_ratio": 1.3423423423423424,
        "end": 6511.36,
        "id": 1901,
        "no_speech_prob": 0.0003458924766164273,
        "seek": 649336,
        "start": 6509.36,
        "temperature": 0,
        "text": " I messed something up.",
        "tokens": [
          51164,
          286,
          16507,
          746,
          493,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.25434736619915876,
        "compression_ratio": 1.3423423423423424,
        "end": 6515.36,
        "id": 1902,
        "no_speech_prob": 0.0003458924766164273,
        "seek": 649336,
        "start": 6513.36,
        "temperature": 0,
        "text": " I messed something up with my...",
        "tokens": [
          51364,
          286,
          16507,
          746,
          493,
          365,
          452,
          485,
          51464
        ]
      },
      {
        "avg_logprob": -0.25434736619915876,
        "compression_ratio": 1.3423423423423424,
        "end": 6518.36,
        "id": 1903,
        "no_speech_prob": 0.0003458924766164273,
        "seek": 649336,
        "start": 6516.36,
        "temperature": 0,
        "text": " Oh, yeah.",
        "tokens": [
          51514,
          876,
          11,
          1338,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.23475518518564653,
        "compression_ratio": 1.4038461538461537,
        "end": 6526.36,
        "id": 1904,
        "no_speech_prob": 0.00043721863767132163,
        "seek": 652336,
        "start": 6524.36,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          50414,
          865,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.23475518518564653,
        "compression_ratio": 1.4038461538461537,
        "end": 6528.36,
        "id": 1905,
        "no_speech_prob": 0.00043721863767132163,
        "seek": 652336,
        "start": 6526.36,
        "temperature": 0,
        "text": " I think that's right.",
        "tokens": [
          50514,
          286,
          519,
          300,
          311,
          558,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.23475518518564653,
        "compression_ratio": 1.4038461538461537,
        "end": 6537.36,
        "id": 1906,
        "no_speech_prob": 0.00043721863767132163,
        "seek": 652336,
        "start": 6535.36,
        "temperature": 0,
        "text": " Is it finishing it?",
        "tokens": [
          50964,
          1119,
          309,
          12693,
          309,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.23475518518564653,
        "compression_ratio": 1.4038461538461537,
        "end": 6543.36,
        "id": 1907,
        "no_speech_prob": 0.00043721863767132163,
        "seek": 652336,
        "start": 6541.36,
        "temperature": 0,
        "text": " I think it's finishing the cat.",
        "tokens": [
          51264,
          286,
          519,
          309,
          311,
          12693,
          264,
          3857,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.23475518518564653,
        "compression_ratio": 1.4038461538461537,
        "end": 6550.36,
        "id": 1908,
        "no_speech_prob": 0.00043721863767132163,
        "seek": 652336,
        "start": 6547.36,
        "temperature": 0,
        "text": " It does sort of seem like it's not doing the very last one, right?",
        "tokens": [
          51564,
          467,
          775,
          1333,
          295,
          1643,
          411,
          309,
          311,
          406,
          884,
          264,
          588,
          1036,
          472,
          11,
          558,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.2724048511402027,
        "compression_ratio": 1.065934065934066,
        "end": 6556.36,
        "id": 1909,
        "no_speech_prob": 0.00013544778630603105,
        "seek": 655336,
        "start": 6554.36,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          50414,
          865,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2724048511402027,
        "compression_ratio": 1.065934065934066,
        "end": 6566.36,
        "id": 1910,
        "no_speech_prob": 0.00013544778630603105,
        "seek": 655336,
        "start": 6564.36,
        "temperature": 0,
        "text": " Yeah, I don't know.",
        "tokens": [
          50914,
          865,
          11,
          286,
          500,
          380,
          458,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2724048511402027,
        "compression_ratio": 1.065934065934066,
        "end": 6570.36,
        "id": 1911,
        "no_speech_prob": 0.00013544778630603105,
        "seek": 655336,
        "start": 6568.36,
        "temperature": 0,
        "text": " That's way too long to wait.",
        "tokens": [
          51114,
          663,
          311,
          636,
          886,
          938,
          281,
          1699,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2724048511402027,
        "compression_ratio": 1.065934065934066,
        "end": 6579.36,
        "id": 1912,
        "no_speech_prob": 0.00013544778630603105,
        "seek": 655336,
        "start": 6577.36,
        "temperature": 0,
        "text": " People who draw it didn't finish it, yeah.",
        "tokens": [
          51564,
          3432,
          567,
          2642,
          309,
          994,
          380,
          2413,
          309,
          11,
          1338,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.24731560827980578,
        "compression_ratio": 1.2955974842767295,
        "end": 6586.36,
        "id": 1913,
        "no_speech_prob": 0.0004044613742735237,
        "seek": 658336,
        "start": 6584.36,
        "temperature": 0,
        "text": " All right, everybody.",
        "tokens": [
          50414,
          1057,
          558,
          11,
          2201,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.24731560827980578,
        "compression_ratio": 1.2955974842767295,
        "end": 6588.36,
        "id": 1914,
        "no_speech_prob": 0.0004044613742735237,
        "seek": 658336,
        "start": 6586.36,
        "temperature": 0,
        "text": " Now, is it...",
        "tokens": [
          50514,
          823,
          11,
          307,
          309,
          485,
          50614
        ]
      },
      {
        "avg_logprob": -0.24731560827980578,
        "compression_ratio": 1.2955974842767295,
        "end": 6590.36,
        "id": 1915,
        "no_speech_prob": 0.0004044613742735237,
        "seek": 658336,
        "start": 6588.36,
        "temperature": 0,
        "text": " It's not even 4 o'clock yet.",
        "tokens": [
          50614,
          467,
          311,
          406,
          754,
          1017,
          277,
          6,
          9023,
          1939,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.24731560827980578,
        "compression_ratio": 1.2955974842767295,
        "end": 6592.36,
        "id": 1916,
        "no_speech_prob": 0.0004044613742735237,
        "seek": 658336,
        "start": 6590.36,
        "temperature": 0,
        "text": " Do I dare...",
        "tokens": [
          50714,
          1144,
          286,
          8955,
          485,
          50814
        ]
      },
      {
        "avg_logprob": -0.24731560827980578,
        "compression_ratio": 1.2955974842767295,
        "end": 6594.36,
        "id": 1917,
        "no_speech_prob": 0.0004044613742735237,
        "seek": 658336,
        "start": 6592.36,
        "temperature": 0,
        "text": " Dare...",
        "tokens": [
          50814,
          42320,
          485,
          50914
        ]
      },
      {
        "avg_logprob": -0.24731560827980578,
        "compression_ratio": 1.2955974842767295,
        "end": 6596.36,
        "id": 1918,
        "no_speech_prob": 0.0004044613742735237,
        "seek": 658336,
        "start": 6594.36,
        "temperature": 0,
        "text": " To sketch RNN?",
        "tokens": [
          50914,
          1407,
          12325,
          45702,
          45,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.24731560827980578,
        "compression_ratio": 1.2955974842767295,
        "end": 6601.36,
        "id": 1919,
        "no_speech_prob": 0.0004044613742735237,
        "seek": 658336,
        "start": 6597.36,
        "temperature": 0,
        "text": " Oh, right, because the Google Quick Draw guessed it before the person finished.",
        "tokens": [
          51064,
          876,
          11,
          558,
          11,
          570,
          264,
          3329,
          12101,
          20386,
          21852,
          309,
          949,
          264,
          954,
          4335,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.24731560827980578,
        "compression_ratio": 1.2955974842767295,
        "end": 6603.36,
        "id": 1920,
        "no_speech_prob": 0.0004044613742735237,
        "seek": 658336,
        "start": 6601.36,
        "temperature": 0,
        "text": " That's interesting, yeah.",
        "tokens": [
          51264,
          663,
          311,
          1880,
          11,
          1338,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.36862869868202813,
        "compression_ratio": 1.5858585858585859,
        "end": 6607.36,
        "id": 1921,
        "no_speech_prob": 0.010008509270846844,
        "seek": 660336,
        "start": 6604.36,
        "temperature": 0,
        "text": " I think I might be done for today.",
        "tokens": [
          50414,
          286,
          519,
          286,
          1062,
          312,
          1096,
          337,
          965,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.36862869868202813,
        "compression_ratio": 1.5858585858585859,
        "end": 6611.36,
        "id": 1922,
        "no_speech_prob": 0.010008509270846844,
        "seek": 660336,
        "start": 6609.36,
        "temperature": 0,
        "text": " Did I do what I said I was going to do?",
        "tokens": [
          50664,
          2589,
          286,
          360,
          437,
          286,
          848,
          286,
          390,
          516,
          281,
          360,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.36862869868202813,
        "compression_ratio": 1.5858585858585859,
        "end": 6615.36,
        "id": 1923,
        "no_speech_prob": 0.010008509270846844,
        "seek": 660336,
        "start": 6613.36,
        "temperature": 0,
        "text": " Let me just look here.",
        "tokens": [
          50864,
          961,
          385,
          445,
          574,
          510,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.36862869868202813,
        "compression_ratio": 1.5858585858585859,
        "end": 6625.36,
        "id": 1924,
        "no_speech_prob": 0.010008509270846844,
        "seek": 660336,
        "start": 6623.36,
        "temperature": 0,
        "text": " I think I did.",
        "tokens": [
          51364,
          286,
          519,
          286,
          630,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.36862869868202813,
        "compression_ratio": 1.5858585858585859,
        "end": 6627.36,
        "id": 1925,
        "no_speech_prob": 0.010008509270846844,
        "seek": 660336,
        "start": 6625.36,
        "temperature": 0,
        "text": " I think I did.",
        "tokens": [
          51464,
          286,
          519,
          286,
          630,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.36862869868202813,
        "compression_ratio": 1.5858585858585859,
        "end": 6629.36,
        "id": 1926,
        "no_speech_prob": 0.010008509270846844,
        "seek": 660336,
        "start": 6627.36,
        "temperature": 0,
        "text": " I think I did.",
        "tokens": [
          51564,
          286,
          519,
          286,
          630,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.36862869868202813,
        "compression_ratio": 1.5858585858585859,
        "end": 6631.36,
        "id": 1927,
        "no_speech_prob": 0.010008509270846844,
        "seek": 660336,
        "start": 6629.36,
        "temperature": 0,
        "text": " I think I did.",
        "tokens": [
          51664,
          286,
          519,
          286,
          630,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.23860900155429182,
        "compression_ratio": 1,
        "end": 6634.36,
        "id": 1928,
        "no_speech_prob": 0.04801204800605774,
        "seek": 663136,
        "start": 6632.36,
        "temperature": 0,
        "text": " Hmm.",
        "tokens": [
          50414,
          8239,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.23860900155429182,
        "compression_ratio": 1,
        "end": 6638.36,
        "id": 1929,
        "no_speech_prob": 0.04801204800605774,
        "seek": 663136,
        "start": 6636.36,
        "temperature": 0,
        "text": " Hmm.",
        "tokens": [
          50614,
          8239,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.23860900155429182,
        "compression_ratio": 1,
        "end": 6655.36,
        "id": 1930,
        "no_speech_prob": 0.04801204800605774,
        "seek": 663136,
        "start": 6653.36,
        "temperature": 0,
        "text": " Hmm.",
        "tokens": [
          51464,
          8239,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.23860900155429182,
        "compression_ratio": 1,
        "end": 6658.36,
        "id": 1931,
        "no_speech_prob": 0.04801204800605774,
        "seek": 663136,
        "start": 6655.36,
        "temperature": 0,
        "text": " Sorry, I'm looking here to think about Sketch RNN.",
        "tokens": [
          51564,
          4919,
          11,
          286,
          478,
          1237,
          510,
          281,
          519,
          466,
          49245,
          45702,
          45,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2724986856633967,
        "compression_ratio": 1.7055555555555555,
        "end": 6661.36,
        "id": 1932,
        "no_speech_prob": 0.00003373435538378544,
        "seek": 665836,
        "start": 6659.36,
        "temperature": 0,
        "text": " So people are...",
        "tokens": [
          50414,
          407,
          561,
          366,
          485,
          50514
        ]
      },
      {
        "avg_logprob": -0.2724986856633967,
        "compression_ratio": 1.7055555555555555,
        "end": 6663.36,
        "id": 1933,
        "no_speech_prob": 0.00003373435538378544,
        "seek": 665836,
        "start": 6661.36,
        "temperature": 0,
        "text": " This, by the way, is not...",
        "tokens": [
          50514,
          639,
          11,
          538,
          264,
          636,
          11,
          307,
          406,
          485,
          50614
        ]
      },
      {
        "avg_logprob": -0.2724986856633967,
        "compression_ratio": 1.7055555555555555,
        "end": 6665.36,
        "id": 1934,
        "no_speech_prob": 0.00003373435538378544,
        "seek": 665836,
        "start": 6663.36,
        "temperature": 0,
        "text": " This, by the way, is not Sketch RNN.",
        "tokens": [
          50614,
          639,
          11,
          538,
          264,
          636,
          11,
          307,
          406,
          49245,
          45702,
          45,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2724986856633967,
        "compression_ratio": 1.7055555555555555,
        "end": 6667.36,
        "id": 1935,
        "no_speech_prob": 0.00003373435538378544,
        "seek": 665836,
        "start": 6665.36,
        "temperature": 0,
        "text": " Just to be clear, this is the...",
        "tokens": [
          50714,
          1449,
          281,
          312,
          1850,
          11,
          341,
          307,
          264,
          485,
          50814
        ]
      },
      {
        "avg_logprob": -0.2724986856633967,
        "compression_ratio": 1.7055555555555555,
        "end": 6670.36,
        "id": 1936,
        "no_speech_prob": 0.00003373435538378544,
        "seek": 665836,
        "start": 6667.36,
        "temperature": 0,
        "text": " These are the actual drawings, not the imagined drawings.",
        "tokens": [
          50814,
          1981,
          366,
          264,
          3539,
          18618,
          11,
          406,
          264,
          16590,
          18618,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2724986856633967,
        "compression_ratio": 1.7055555555555555,
        "end": 6672.36,
        "id": 1937,
        "no_speech_prob": 0.00003373435538378544,
        "seek": 665836,
        "start": 6670.36,
        "temperature": 0,
        "text": " I feel like I...",
        "tokens": [
          50964,
          286,
          841,
          411,
          286,
          485,
          51064
        ]
      },
      {
        "avg_logprob": -0.2724986856633967,
        "compression_ratio": 1.7055555555555555,
        "end": 6674.36,
        "id": 1938,
        "no_speech_prob": 0.00003373435538378544,
        "seek": 665836,
        "start": 6672.36,
        "temperature": 0,
        "text": " I think I'm done for today.",
        "tokens": [
          51064,
          286,
          519,
          286,
          478,
          1096,
          337,
          965,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2724986856633967,
        "compression_ratio": 1.7055555555555555,
        "end": 6676.36,
        "id": 1939,
        "no_speech_prob": 0.00003373435538378544,
        "seek": 665836,
        "start": 6674.36,
        "temperature": 0,
        "text": " What did I make today?",
        "tokens": [
          51164,
          708,
          630,
          286,
          652,
          965,
          30,
          51264
        ]
      },
      {
        "avg_logprob": -0.2724986856633967,
        "compression_ratio": 1.7055555555555555,
        "end": 6678.36,
        "id": 1940,
        "no_speech_prob": 0.00003373435538378544,
        "seek": 665836,
        "start": 6676.36,
        "temperature": 0,
        "text": " I got the logo part 2 done.",
        "tokens": [
          51264,
          286,
          658,
          264,
          9699,
          644,
          568,
          1096,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2724986856633967,
        "compression_ratio": 1.7055555555555555,
        "end": 6680.36,
        "id": 1941,
        "no_speech_prob": 0.00003373435538378544,
        "seek": 665836,
        "start": 6678.36,
        "temperature": 0,
        "text": " I got the...",
        "tokens": [
          51364,
          286,
          658,
          264,
          485,
          51464
        ]
      },
      {
        "avg_logprob": -0.2724986856633967,
        "compression_ratio": 1.7055555555555555,
        "end": 6685.36,
        "id": 1942,
        "no_speech_prob": 0.00003373435538378544,
        "seek": 665836,
        "start": 6683.36,
        "temperature": 0,
        "text": " I got the...",
        "tokens": [
          51614,
          286,
          658,
          264,
          485,
          51714
        ]
      },
      {
        "avg_logprob": -0.2724986856633967,
        "compression_ratio": 1.7055555555555555,
        "end": 6687.36,
        "id": 1943,
        "no_speech_prob": 0.00003373435538378544,
        "seek": 665836,
        "start": 6685.36,
        "temperature": 0,
        "text": " I got the...",
        "tokens": [
          51714,
          286,
          658,
          264,
          485,
          51814
        ]
      },
      {
        "avg_logprob": -0.22871932204888792,
        "compression_ratio": 1.5243243243243243,
        "end": 6690.36,
        "id": 1944,
        "no_speech_prob": 0.00043046390055678785,
        "seek": 668736,
        "start": 6688.36,
        "temperature": 0,
        "text": " I got the...",
        "tokens": [
          50414,
          286,
          658,
          264,
          485,
          50514
        ]
      },
      {
        "avg_logprob": -0.22871932204888792,
        "compression_ratio": 1.5243243243243243,
        "end": 6692.36,
        "id": 1945,
        "no_speech_prob": 0.00043046390055678785,
        "seek": 668736,
        "start": 6690.36,
        "temperature": 0,
        "text": " I got the...",
        "tokens": [
          50514,
          286,
          658,
          264,
          485,
          50614
        ]
      },
      {
        "avg_logprob": -0.22871932204888792,
        "compression_ratio": 1.5243243243243243,
        "end": 6694.36,
        "id": 1946,
        "no_speech_prob": 0.00043046390055678785,
        "seek": 668736,
        "start": 6692.36,
        "temperature": 0,
        "text": " I got the...",
        "tokens": [
          50614,
          286,
          658,
          264,
          485,
          50714
        ]
      },
      {
        "avg_logprob": -0.22871932204888792,
        "compression_ratio": 1.5243243243243243,
        "end": 6698.36,
        "id": 1947,
        "no_speech_prob": 0.00043046390055678785,
        "seek": 668736,
        "start": 6694.36,
        "temperature": 0,
        "text": " Sorry, logo part 2, the ML5 saved model, and the Quick Draw stuff.",
        "tokens": [
          50714,
          4919,
          11,
          9699,
          644,
          568,
          11,
          264,
          21601,
          20,
          6624,
          2316,
          11,
          293,
          264,
          12101,
          20386,
          1507,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.22871932204888792,
        "compression_ratio": 1.5243243243243243,
        "end": 6704.36,
        "id": 1948,
        "no_speech_prob": 0.00043046390055678785,
        "seek": 668736,
        "start": 6698.36,
        "temperature": 0,
        "text": " I think I want to wait until Sketch RNN is in the documentation of ML5.",
        "tokens": [
          50914,
          286,
          519,
          286,
          528,
          281,
          1699,
          1826,
          49245,
          45702,
          45,
          307,
          294,
          264,
          14333,
          295,
          21601,
          20,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.22871932204888792,
        "compression_ratio": 1.5243243243243243,
        "end": 6706.36,
        "id": 1949,
        "no_speech_prob": 0.00043046390055678785,
        "seek": 668736,
        "start": 6704.36,
        "temperature": 0,
        "text": " So I will come back and do that another time.",
        "tokens": [
          51214,
          407,
          286,
          486,
          808,
          646,
          293,
          360,
          300,
          1071,
          565,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.22871932204888792,
        "compression_ratio": 1.5243243243243243,
        "end": 6708.36,
        "id": 1950,
        "no_speech_prob": 0.00043046390055678785,
        "seek": 668736,
        "start": 6706.36,
        "temperature": 0,
        "text": " Plus, I feel like...",
        "tokens": [
          51314,
          7721,
          11,
          286,
          841,
          411,
          485,
          51414
        ]
      },
      {
        "avg_logprob": -0.22871932204888792,
        "compression_ratio": 1.5243243243243243,
        "end": 6710.36,
        "id": 1951,
        "no_speech_prob": 0.00043046390055678785,
        "seek": 668736,
        "start": 6708.36,
        "temperature": 0,
        "text": " Plus, I feel like...",
        "tokens": [
          51414,
          7721,
          11,
          286,
          841,
          411,
          485,
          51514
        ]
      },
      {
        "avg_logprob": -0.22871932204888792,
        "compression_ratio": 1.5243243243243243,
        "end": 6712.36,
        "id": 1952,
        "no_speech_prob": 0.00043046390055678785,
        "seek": 668736,
        "start": 6710.36,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51514,
          865,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.22871932204888792,
        "compression_ratio": 1.5243243243243243,
        "end": 6716.36,
        "id": 1953,
        "no_speech_prob": 0.00043046390055678785,
        "seek": 668736,
        "start": 6714.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51714,
          1057,
          558,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19459561568040115,
        "compression_ratio": 1.3537414965986394,
        "end": 6718.36,
        "id": 1954,
        "no_speech_prob": 0.11913000047206879,
        "seek": 671636,
        "start": 6716.36,
        "temperature": 0,
        "text": " I could watch this all day.",
        "tokens": [
          50364,
          286,
          727,
          1159,
          341,
          439,
          786,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.19459561568040115,
        "compression_ratio": 1.3537414965986394,
        "end": 6723.36,
        "id": 1955,
        "no_speech_prob": 0.11913000047206879,
        "seek": 671636,
        "start": 6720.36,
        "temperature": 0,
        "text": " Let me make sure it's actually doing the last bit.",
        "tokens": [
          50564,
          961,
          385,
          652,
          988,
          309,
          311,
          767,
          884,
          264,
          1036,
          857,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19459561568040115,
        "compression_ratio": 1.3537414965986394,
        "end": 6725.36,
        "id": 1956,
        "no_speech_prob": 0.11913000047206879,
        "seek": 671636,
        "start": 6723.36,
        "temperature": 0,
        "text": " Let's think about this.",
        "tokens": [
          50714,
          961,
          311,
          519,
          466,
          341,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19459561568040115,
        "compression_ratio": 1.3537414965986394,
        "end": 6735.36,
        "id": 1957,
        "no_speech_prob": 0.11913000047206879,
        "seek": 671636,
        "start": 6730.36,
        "temperature": 0,
        "text": " If strokeIndex equals cat.length...",
        "tokens": [
          51064,
          759,
          12403,
          21790,
          3121,
          6915,
          3857,
          13,
          45390,
          485,
          51314
        ]
      },
      {
        "avg_logprob": -0.19459561568040115,
        "compression_ratio": 1.3537414965986394,
        "end": 6740.36,
        "id": 1958,
        "no_speech_prob": 0.11913000047206879,
        "seek": 671636,
        "start": 6736.36,
        "temperature": 0,
        "text": " Yeah, this has to have done the last one, right?",
        "tokens": [
          51364,
          865,
          11,
          341,
          575,
          281,
          362,
          1096,
          264,
          1036,
          472,
          11,
          558,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.19459561568040115,
        "compression_ratio": 1.3537414965986394,
        "end": 6742.36,
        "id": 1959,
        "no_speech_prob": 0.11913000047206879,
        "seek": 671636,
        "start": 6740.36,
        "temperature": 0,
        "text": " So let's...",
        "tokens": [
          51564,
          407,
          718,
          311,
          485,
          51664
        ]
      },
      {
        "avg_logprob": -0.1854831172573951,
        "compression_ratio": 1.375,
        "end": 6747.36,
        "id": 1960,
        "no_speech_prob": 0.000020145285816397518,
        "seek": 674236,
        "start": 6743.36,
        "temperature": 0,
        "text": " Let's not do this for a second.",
        "tokens": [
          50414,
          961,
          311,
          406,
          360,
          341,
          337,
          257,
          1150,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1854831172573951,
        "compression_ratio": 1.375,
        "end": 6750.36,
        "id": 1961,
        "no_speech_prob": 0.000020145285816397518,
        "seek": 674236,
        "start": 6747.36,
        "temperature": 0,
        "text": " And let's console.log...",
        "tokens": [
          50614,
          400,
          718,
          311,
          11076,
          13,
          4987,
          485,
          50764
        ]
      },
      {
        "avg_logprob": -0.1854831172573951,
        "compression_ratio": 1.375,
        "end": 6764.36,
        "id": 1962,
        "no_speech_prob": 0.000020145285816397518,
        "seek": 674236,
        "start": 6760.36,
        "temperature": 0,
        "text": " Yeah, it's greater than...",
        "tokens": [
          51264,
          865,
          11,
          309,
          311,
          5044,
          813,
          485,
          51464
        ]
      },
      {
        "avg_logprob": -0.1854831172573951,
        "compression_ratio": 1.375,
        "end": 6766.36,
        "id": 1963,
        "no_speech_prob": 0.000020145285816397518,
        "seek": 674236,
        "start": 6764.36,
        "temperature": 0,
        "text": " Yeah, I think it's doing all of them.",
        "tokens": [
          51464,
          865,
          11,
          286,
          519,
          309,
          311,
          884,
          439,
          295,
          552,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1854831172573951,
        "compression_ratio": 1.375,
        "end": 6768.36,
        "id": 1964,
        "no_speech_prob": 0.000020145285816397518,
        "seek": 674236,
        "start": 6766.36,
        "temperature": 0,
        "text": " I'm looking at this code.",
        "tokens": [
          51564,
          286,
          478,
          1237,
          412,
          341,
          3089,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1854831172573951,
        "compression_ratio": 1.375,
        "end": 6770.36,
        "id": 1965,
        "no_speech_prob": 0.000020145285816397518,
        "seek": 674236,
        "start": 6768.36,
        "temperature": 0,
        "text": " It wouldn't be skipping one.",
        "tokens": [
          51664,
          467,
          2759,
          380,
          312,
          31533,
          472,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.21261164785801678,
        "compression_ratio": 1.4722222222222223,
        "end": 6774.36,
        "id": 1966,
        "no_speech_prob": 0.000005093696927360725,
        "seek": 677036,
        "start": 6770.36,
        "temperature": 0,
        "text": " Because index is invalid here, and then it goes up.",
        "tokens": [
          50364,
          1436,
          8186,
          307,
          34702,
          510,
          11,
          293,
          550,
          309,
          1709,
          493,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.21261164785801678,
        "compression_ratio": 1.4722222222222223,
        "end": 6778.36,
        "id": 1967,
        "no_speech_prob": 0.000005093696927360725,
        "seek": 677036,
        "start": 6775.36,
        "temperature": 0,
        "text": " It resets index to 0.",
        "tokens": [
          50614,
          467,
          725,
          1385,
          8186,
          281,
          1958,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21261164785801678,
        "compression_ratio": 1.4722222222222223,
        "end": 6781.36,
        "id": 1968,
        "no_speech_prob": 0.000005093696927360725,
        "seek": 677036,
        "start": 6778.36,
        "temperature": 0,
        "text": " It loops back around and starts over.",
        "tokens": [
          50764,
          467,
          16121,
          646,
          926,
          293,
          3719,
          670,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.21261164785801678,
        "compression_ratio": 1.4722222222222223,
        "end": 6784.36,
        "id": 1969,
        "no_speech_prob": 0.000005093696927360725,
        "seek": 677036,
        "start": 6781.36,
        "temperature": 0,
        "text": " Yeah, it's got to have gotten the last one.",
        "tokens": [
          50914,
          865,
          11,
          309,
          311,
          658,
          281,
          362,
          5768,
          264,
          1036,
          472,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.21261164785801678,
        "compression_ratio": 1.4722222222222223,
        "end": 6786.36,
        "id": 1970,
        "no_speech_prob": 0.000005093696927360725,
        "seek": 677036,
        "start": 6784.36,
        "temperature": 0,
        "text": " Just try going one further.",
        "tokens": [
          51064,
          1449,
          853,
          516,
          472,
          3052,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.21261164785801678,
        "compression_ratio": 1.4722222222222223,
        "end": 6788.36,
        "id": 1971,
        "no_speech_prob": 0.000005093696927360725,
        "seek": 677036,
        "start": 6786.36,
        "temperature": 0,
        "text": " It'll break and you'll be right.",
        "tokens": [
          51164,
          467,
          603,
          1821,
          293,
          291,
          603,
          312,
          558,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.21261164785801678,
        "compression_ratio": 1.4722222222222223,
        "end": 6790.36,
        "id": 1972,
        "no_speech_prob": 0.000005093696927360725,
        "seek": 677036,
        "start": 6788.36,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51264,
          865,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.21261164785801678,
        "compression_ratio": 1.4722222222222223,
        "end": 6795.36,
        "id": 1973,
        "no_speech_prob": 0.000005093696927360725,
        "seek": 677036,
        "start": 6793.36,
        "temperature": 0,
        "text": " Yeah, I mean, I could say...",
        "tokens": [
          51514,
          865,
          11,
          286,
          914,
          11,
          286,
          727,
          584,
          485,
          51614
        ]
      },
      {
        "avg_logprob": -0.21261164785801678,
        "compression_ratio": 1.4722222222222223,
        "end": 6799.36,
        "id": 1974,
        "no_speech_prob": 0.000005093696927360725,
        "seek": 677036,
        "start": 6797.36,
        "temperature": 0,
        "text": " Or something.",
        "tokens": [
          51714,
          1610,
          746,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2123905340830485,
        "compression_ratio": 1.0161290322580645,
        "end": 6803.36,
        "id": 1975,
        "no_speech_prob": 0.0002611628151498735,
        "seek": 680036,
        "start": 6801.36,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          50414,
          865,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2123905340830485,
        "compression_ratio": 1.0161290322580645,
        "end": 6808.36,
        "id": 1976,
        "no_speech_prob": 0.0002611628151498735,
        "seek": 680036,
        "start": 6806.36,
        "temperature": 0,
        "text": " Yeah, it broke.",
        "tokens": [
          50664,
          865,
          11,
          309,
          6902,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2123905340830485,
        "compression_ratio": 1.0161290322580645,
        "end": 6811.36,
        "id": 1977,
        "no_speech_prob": 0.0002611628151498735,
        "seek": 680036,
        "start": 6808.36,
        "temperature": 0,
        "text": " Sketch.js line 18.",
        "tokens": [
          50764,
          49245,
          13,
          25530,
          1622,
          2443,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2123905340830485,
        "compression_ratio": 1.0161290322580645,
        "end": 6821.36,
        "id": 1978,
        "no_speech_prob": 0.0002611628151498735,
        "seek": 680036,
        "start": 6819.36,
        "temperature": 0,
        "text": " It broke.",
        "tokens": [
          51314,
          467,
          6902,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2123905340830485,
        "compression_ratio": 1.0161290322580645,
        "end": 6829.36,
        "id": 1979,
        "no_speech_prob": 0.0002611628151498735,
        "seek": 680036,
        "start": 6827.36,
        "temperature": 0,
        "text": " Interesting.",
        "tokens": [
          51714,
          14711,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.24439334869384766,
        "compression_ratio": 1.1785714285714286,
        "end": 6832.36,
        "id": 1980,
        "no_speech_prob": 0.00019409882952459157,
        "seek": 682936,
        "start": 6829.36,
        "temperature": 0,
        "text": " So I think maybe it wasn't...",
        "tokens": [
          50364,
          407,
          286,
          519,
          1310,
          309,
          2067,
          380,
          485,
          50514
        ]
      },
      {
        "avg_logprob": -0.24439334869384766,
        "compression_ratio": 1.1785714285714286,
        "end": 6839.36,
        "id": 1981,
        "no_speech_prob": 0.00019409882952459157,
        "seek": 682936,
        "start": 6832.36,
        "temperature": 0,
        "text": " Maybe it was not getting the very last one of each stroke.",
        "tokens": [
          50514,
          2704,
          309,
          390,
          406,
          1242,
          264,
          588,
          1036,
          472,
          295,
          1184,
          12403,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.24439334869384766,
        "compression_ratio": 1.1785714285714286,
        "end": 6841.36,
        "id": 1982,
        "no_speech_prob": 0.00019409882952459157,
        "seek": 682936,
        "start": 6839.36,
        "temperature": 0,
        "text": " Why is that?",
        "tokens": [
          50864,
          1545,
          307,
          300,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.24439334869384766,
        "compression_ratio": 1.1785714285714286,
        "end": 6843.36,
        "id": 1983,
        "no_speech_prob": 0.00019409882952459157,
        "seek": 682936,
        "start": 6841.36,
        "temperature": 0,
        "text": " It's crazy cat.",
        "tokens": [
          50964,
          467,
          311,
          3219,
          3857,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.24439334869384766,
        "compression_ratio": 1.1785714285714286,
        "end": 6854.36,
        "id": 1984,
        "no_speech_prob": 0.00019409882952459157,
        "seek": 682936,
        "start": 6852.36,
        "temperature": 0,
        "text": " Length plus 1.",
        "tokens": [
          51514,
          441,
          4206,
          1804,
          502,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.21205382151146457,
        "compression_ratio": 1.4266666666666667,
        "end": 6858.36,
        "id": 1985,
        "no_speech_prob": 0.0002066218148684129,
        "seek": 685436,
        "start": 6855.36,
        "temperature": 0,
        "text": " Index goes up.",
        "tokens": [
          50414,
          33552,
          1709,
          493,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.21205382151146457,
        "compression_ratio": 1.4266666666666667,
        "end": 6863.36,
        "id": 1986,
        "no_speech_prob": 0.0002066218148684129,
        "seek": 685436,
        "start": 6860.36,
        "temperature": 0,
        "text": " Oh, because I'm pulling it here.",
        "tokens": [
          50664,
          876,
          11,
          570,
          286,
          478,
          8407,
          309,
          510,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21205382151146457,
        "compression_ratio": 1.4266666666666667,
        "end": 6868.36,
        "id": 1987,
        "no_speech_prob": 0.0002066218148684129,
        "seek": 685436,
        "start": 6865.36,
        "temperature": 0,
        "text": " And then index goes up by 1.",
        "tokens": [
          50914,
          400,
          550,
          8186,
          1709,
          493,
          538,
          502,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.21205382151146457,
        "compression_ratio": 1.4266666666666667,
        "end": 6871.36,
        "id": 1988,
        "no_speech_prob": 0.0002066218148684129,
        "seek": 685436,
        "start": 6868.36,
        "temperature": 0,
        "text": " That doesn't make sense.",
        "tokens": [
          51064,
          663,
          1177,
          380,
          652,
          2020,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.21205382151146457,
        "compression_ratio": 1.4266666666666667,
        "end": 6875.36,
        "id": 1989,
        "no_speech_prob": 0.0002066218148684129,
        "seek": 685436,
        "start": 6873.36,
        "temperature": 0,
        "text": " I'm so confused.",
        "tokens": [
          51314,
          286,
          478,
          370,
          9019,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.21205382151146457,
        "compression_ratio": 1.4266666666666667,
        "end": 6877.36,
        "id": 1990,
        "no_speech_prob": 0.0002066218148684129,
        "seek": 685436,
        "start": 6875.36,
        "temperature": 0,
        "text": " My brain is confused.",
        "tokens": [
          51414,
          1222,
          3567,
          307,
          9019,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.21205382151146457,
        "compression_ratio": 1.4266666666666667,
        "end": 6880.36,
        "id": 1991,
        "no_speech_prob": 0.0002066218148684129,
        "seek": 685436,
        "start": 6878.36,
        "temperature": 0,
        "text": " May I am so me is typing.",
        "tokens": [
          51564,
          1891,
          286,
          669,
          370,
          385,
          307,
          18444,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21205382151146457,
        "compression_ratio": 1.4266666666666667,
        "end": 6882.36,
        "id": 1992,
        "no_speech_prob": 0.0002066218148684129,
        "seek": 685436,
        "start": 6880.36,
        "temperature": 0,
        "text": " This means the answer is about to come through.",
        "tokens": [
          51664,
          639,
          1355,
          264,
          1867,
          307,
          466,
          281,
          808,
          807,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19935773652175376,
        "compression_ratio": 1.6752136752136753,
        "end": 6884.36,
        "id": 1993,
        "no_speech_prob": 0.0003740928659681231,
        "seek": 688236,
        "start": 6882.36,
        "temperature": 0,
        "text": " The last index won't error.",
        "tokens": [
          50364,
          440,
          1036,
          8186,
          1582,
          380,
          6713,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.19935773652175376,
        "compression_ratio": 1.6752136752136753,
        "end": 6886.36,
        "id": 1994,
        "no_speech_prob": 0.0003740928659681231,
        "seek": 688236,
        "start": 6884.36,
        "temperature": 0,
        "text": " It won't error.",
        "tokens": [
          50464,
          467,
          1582,
          380,
          6713,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19935773652175376,
        "compression_ratio": 1.6752136752136753,
        "end": 6888.36,
        "id": 1995,
        "no_speech_prob": 0.0003740928659681231,
        "seek": 688236,
        "start": 6886.36,
        "temperature": 0,
        "text": " It's just going to be undefined.",
        "tokens": [
          50564,
          467,
          311,
          445,
          516,
          281,
          312,
          674,
          5666,
          2001,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19935773652175376,
        "compression_ratio": 1.6752136752136753,
        "end": 6889.36,
        "id": 1996,
        "no_speech_prob": 0.0003740928659681231,
        "seek": 688236,
        "start": 6888.36,
        "temperature": 0,
        "text": " So I'm good.",
        "tokens": [
          50664,
          407,
          286,
          478,
          665,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19935773652175376,
        "compression_ratio": 1.6752136752136753,
        "end": 6890.36,
        "id": 1997,
        "no_speech_prob": 0.0003740928659681231,
        "seek": 688236,
        "start": 6889.36,
        "temperature": 0,
        "text": " It's the same.",
        "tokens": [
          50714,
          467,
          311,
          264,
          912,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19935773652175376,
        "compression_ratio": 1.6752136752136753,
        "end": 6891.36,
        "id": 1998,
        "no_speech_prob": 0.0003740928659681231,
        "seek": 688236,
        "start": 6890.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50764,
          1033,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19935773652175376,
        "compression_ratio": 1.6752136752136753,
        "end": 6892.36,
        "id": 1999,
        "no_speech_prob": 0.0003740928659681231,
        "seek": 688236,
        "start": 6891.36,
        "temperature": 0,
        "text": " It'll just be undefined.",
        "tokens": [
          50814,
          467,
          603,
          445,
          312,
          674,
          5666,
          2001,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19935773652175376,
        "compression_ratio": 1.6752136752136753,
        "end": 6893.36,
        "id": 2000,
        "no_speech_prob": 0.0003740928659681231,
        "seek": 688236,
        "start": 6892.36,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          50864,
          865,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19935773652175376,
        "compression_ratio": 1.6752136752136753,
        "end": 6894.36,
        "id": 2001,
        "no_speech_prob": 0.0003740928659681231,
        "seek": 688236,
        "start": 6893.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50914,
          1057,
          558,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19935773652175376,
        "compression_ratio": 1.6752136752136753,
        "end": 6895.36,
        "id": 2002,
        "no_speech_prob": 0.0003740928659681231,
        "seek": 688236,
        "start": 6894.36,
        "temperature": 0,
        "text": " We're good.",
        "tokens": [
          50964,
          492,
          434,
          665,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19935773652175376,
        "compression_ratio": 1.6752136752136753,
        "end": 6896.36,
        "id": 2003,
        "no_speech_prob": 0.0003740928659681231,
        "seek": 688236,
        "start": 6895.36,
        "temperature": 0,
        "text": " We're good, everybody.",
        "tokens": [
          51014,
          492,
          434,
          665,
          11,
          2201,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19935773652175376,
        "compression_ratio": 1.6752136752136753,
        "end": 6898.36,
        "id": 2004,
        "no_speech_prob": 0.0003740928659681231,
        "seek": 688236,
        "start": 6896.36,
        "temperature": 0,
        "text": " My mental math is still correct.",
        "tokens": [
          51064,
          1222,
          4973,
          5221,
          307,
          920,
          3006,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19935773652175376,
        "compression_ratio": 1.6752136752136753,
        "end": 6899.36,
        "id": 2005,
        "no_speech_prob": 0.0003740928659681231,
        "seek": 688236,
        "start": 6898.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51164,
          1057,
          558,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19935773652175376,
        "compression_ratio": 1.6752136752136753,
        "end": 6900.36,
        "id": 2006,
        "no_speech_prob": 0.0003740928659681231,
        "seek": 688236,
        "start": 6899.36,
        "temperature": 0,
        "text": " Thank you, everybody.",
        "tokens": [
          51214,
          1044,
          291,
          11,
          2201,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19935773652175376,
        "compression_ratio": 1.6752136752136753,
        "end": 6901.36,
        "id": 2007,
        "no_speech_prob": 0.0003740928659681231,
        "seek": 688236,
        "start": 6900.36,
        "temperature": 0,
        "text": " It is 4 o'clock.",
        "tokens": [
          51264,
          467,
          307,
          1017,
          277,
          6,
          9023,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19935773652175376,
        "compression_ratio": 1.6752136752136753,
        "end": 6903.36,
        "id": 2008,
        "no_speech_prob": 0.0003740928659681231,
        "seek": 688236,
        "start": 6901.36,
        "temperature": 0,
        "text": " I think I am finished.",
        "tokens": [
          51314,
          286,
          519,
          286,
          669,
          4335,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19935773652175376,
        "compression_ratio": 1.6752136752136753,
        "end": 6904.36,
        "id": 2009,
        "no_speech_prob": 0.0003740928659681231,
        "seek": 688236,
        "start": 6903.36,
        "temperature": 0,
        "text": " I just want to...",
        "tokens": [
          51414,
          286,
          445,
          528,
          281,
          485,
          51464
        ]
      },
      {
        "avg_logprob": -0.19935773652175376,
        "compression_ratio": 1.6752136752136753,
        "end": 6909.36,
        "id": 2010,
        "no_speech_prob": 0.0003740928659681231,
        "seek": 688236,
        "start": 6904.36,
        "temperature": 0,
        "text": " Is there any last little bits of stuff that I want to cover or talk about today?",
        "tokens": [
          51464,
          1119,
          456,
          604,
          1036,
          707,
          9239,
          295,
          1507,
          300,
          286,
          528,
          281,
          2060,
          420,
          751,
          466,
          965,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.196880190713065,
        "compression_ratio": 1.3142857142857143,
        "end": 6916.36,
        "id": 2011,
        "no_speech_prob": 0.00014202094462234527,
        "seek": 691236,
        "start": 6913.36,
        "temperature": 0,
        "text": " Pac-Man.",
        "tokens": [
          50414,
          10702,
          12,
          6652,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.196880190713065,
        "compression_ratio": 1.3142857142857143,
        "end": 6918.36,
        "id": 2012,
        "no_speech_prob": 0.00014202094462234527,
        "seek": 691236,
        "start": 6916.36,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          50564,
          865,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.196880190713065,
        "compression_ratio": 1.3142857142857143,
        "end": 6920.36,
        "id": 2013,
        "no_speech_prob": 0.00014202094462234527,
        "seek": 691236,
        "start": 6918.36,
        "temperature": 0,
        "text": " Thank you, everybody.",
        "tokens": [
          50664,
          1044,
          291,
          11,
          2201,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.196880190713065,
        "compression_ratio": 1.3142857142857143,
        "end": 6921.36,
        "id": 2014,
        "no_speech_prob": 0.00014202094462234527,
        "seek": 691236,
        "start": 6920.36,
        "temperature": 0,
        "text": " So let's see.",
        "tokens": [
          50764,
          407,
          718,
          311,
          536,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.196880190713065,
        "compression_ratio": 1.3142857142857143,
        "end": 6924.36,
        "id": 2015,
        "no_speech_prob": 0.00014202094462234527,
        "seek": 691236,
        "start": 6921.36,
        "temperature": 0,
        "text": " I should put this code somewhere.",
        "tokens": [
          50814,
          286,
          820,
          829,
          341,
          3089,
          4079,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.196880190713065,
        "compression_ratio": 1.3142857142857143,
        "end": 6927.36,
        "id": 2016,
        "no_speech_prob": 0.00014202094462234527,
        "seek": 691236,
        "start": 6925.36,
        "temperature": 0,
        "text": " This will be...",
        "tokens": [
          51014,
          639,
          486,
          312,
          485,
          51114
        ]
      },
      {
        "avg_logprob": -0.196880190713065,
        "compression_ratio": 1.3142857142857143,
        "end": 6932.36,
        "id": 2017,
        "no_speech_prob": 0.00014202094462234527,
        "seek": 691236,
        "start": 6930.36,
        "temperature": 0,
        "text": " So let me do a little quick...",
        "tokens": [
          51264,
          407,
          718,
          385,
          360,
          257,
          707,
          1702,
          485,
          51364
        ]
      },
      {
        "avg_logprob": -0.196880190713065,
        "compression_ratio": 1.3142857142857143,
        "end": 6935.36,
        "id": 2018,
        "no_speech_prob": 0.00014202094462234527,
        "seek": 691236,
        "start": 6932.36,
        "temperature": 0,
        "text": " Just so the code is ready.",
        "tokens": [
          51364,
          1449,
          370,
          264,
          3089,
          307,
          1919,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.196880190713065,
        "compression_ratio": 1.3142857142857143,
        "end": 6937.36,
        "id": 2019,
        "no_speech_prob": 0.00014202094462234527,
        "seek": 691236,
        "start": 6935.36,
        "temperature": 0,
        "text": " I'm going to do this now.",
        "tokens": [
          51514,
          286,
          478,
          516,
          281,
          360,
          341,
          586,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.30817508697509766,
        "compression_ratio": 1.1585365853658536,
        "end": 6948.36,
        "id": 2020,
        "no_speech_prob": 0.022283678874373436,
        "seek": 693736,
        "start": 6937.36,
        "temperature": 0,
        "text": " So I'm going to grab these three files.",
        "tokens": [
          50364,
          407,
          286,
          478,
          516,
          281,
          4444,
          613,
          1045,
          7098,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.30817508697509766,
        "compression_ratio": 1.1585365853658536,
        "end": 6952.36,
        "id": 2021,
        "no_speech_prob": 0.022283678874373436,
        "seek": 693736,
        "start": 6948.36,
        "temperature": 0,
        "text": " I'm going to put them in...",
        "tokens": [
          50914,
          286,
          478,
          516,
          281,
          829,
          552,
          294,
          485,
          51114
        ]
      },
      {
        "avg_logprob": -0.30817508697509766,
        "compression_ratio": 1.1585365853658536,
        "end": 6958.36,
        "id": 2022,
        "no_speech_prob": 0.022283678874373436,
        "seek": 693736,
        "start": 6956.36,
        "temperature": 0,
        "text": " Website.",
        "tokens": [
          51314,
          45347,
          642,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.30817508697509766,
        "compression_ratio": 1.1585365853658536,
        "end": 6961.36,
        "id": 2023,
        "no_speech_prob": 0.022283678874373436,
        "seek": 693736,
        "start": 6958.36,
        "temperature": 0,
        "text": " Coding challenges.",
        "tokens": [
          51414,
          383,
          8616,
          4759,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2632558228539639,
        "compression_ratio": 1.2769230769230768,
        "end": 6965.36,
        "id": 2024,
        "no_speech_prob": 0.0025507973041385412,
        "seek": 696136,
        "start": 6962.36,
        "temperature": 0,
        "text": " So I need to make...",
        "tokens": [
          50414,
          407,
          286,
          643,
          281,
          652,
          485,
          50564
        ]
      },
      {
        "avg_logprob": -0.2632558228539639,
        "compression_ratio": 1.2769230769230768,
        "end": 6970.36,
        "id": 2025,
        "no_speech_prob": 0.0025507973041385412,
        "seek": 696136,
        "start": 6967.36,
        "temperature": 0,
        "text": " The question is...",
        "tokens": [
          50664,
          440,
          1168,
          307,
          485,
          50814
        ]
      },
      {
        "avg_logprob": -0.2632558228539639,
        "compression_ratio": 1.2769230769230768,
        "end": 6974.36,
        "id": 2026,
        "no_speech_prob": 0.0025507973041385412,
        "seek": 696136,
        "start": 6970.36,
        "temperature": 0,
        "text": " Was this morning like part two of Logo?",
        "tokens": [
          50814,
          3027,
          341,
          2446,
          411,
          644,
          732,
          295,
          10824,
          78,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.2632558228539639,
        "compression_ratio": 1.2769230769230768,
        "end": 6976.36,
        "id": 2027,
        "no_speech_prob": 0.0025507973041385412,
        "seek": 696136,
        "start": 6974.36,
        "temperature": 0,
        "text": " I think it kind of was.",
        "tokens": [
          51014,
          286,
          519,
          309,
          733,
          295,
          390,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2632558228539639,
        "compression_ratio": 1.2769230769230768,
        "end": 6979.36,
        "id": 2028,
        "no_speech_prob": 0.0025507973041385412,
        "seek": 696136,
        "start": 6976.36,
        "temperature": 0,
        "text": " So this will be 1.22.",
        "tokens": [
          51114,
          407,
          341,
          486,
          312,
          502,
          13,
          7490,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2632558228539639,
        "compression_ratio": 1.2769230769230768,
        "end": 6981.36,
        "id": 2029,
        "no_speech_prob": 0.0025507973041385412,
        "seek": 696136,
        "start": 6979.36,
        "temperature": 0,
        "text": " Quick draw.",
        "tokens": [
          51264,
          12101,
          2642,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2632558228539639,
        "compression_ratio": 1.2769230769230768,
        "end": 6988.36,
        "id": 2030,
        "no_speech_prob": 0.0025507973041385412,
        "seek": 696136,
        "start": 6985.36,
        "temperature": 0,
        "text": " So that stuff goes in there.",
        "tokens": [
          51564,
          407,
          300,
          1507,
          1709,
          294,
          456,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2165185559180475,
        "compression_ratio": 1.328358208955224,
        "end": 6991.36,
        "id": 2031,
        "no_speech_prob": 0.0009397318935953081,
        "seek": 698836,
        "start": 6989.36,
        "temperature": 0,
        "text": " And...",
        "tokens": [
          50414,
          400,
          485,
          50514
        ]
      },
      {
        "avg_logprob": -0.2165185559180475,
        "compression_ratio": 1.328358208955224,
        "end": 6996.36,
        "id": 2032,
        "no_speech_prob": 0.0009397318935953081,
        "seek": 698836,
        "start": 6991.36,
        "temperature": 0,
        "text": " Let's change this to 1.",
        "tokens": [
          50514,
          961,
          311,
          1319,
          341,
          281,
          502,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2165185559180475,
        "compression_ratio": 1.328358208955224,
        "end": 7001.36,
        "id": 2033,
        "no_speech_prob": 0.0009397318935953081,
        "seek": 698836,
        "start": 6998.36,
        "temperature": 0,
        "text": " And then also make a version 2.",
        "tokens": [
          50864,
          400,
          550,
          611,
          652,
          257,
          3037,
          568,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2165185559180475,
        "compression_ratio": 1.328358208955224,
        "end": 7003.36,
        "id": 2034,
        "no_speech_prob": 0.0009397318935953081,
        "seek": 698836,
        "start": 7001.36,
        "temperature": 0,
        "text": " Sorry if you can't see this.",
        "tokens": [
          51014,
          4919,
          498,
          291,
          393,
          380,
          536,
          341,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2165185559180475,
        "compression_ratio": 1.328358208955224,
        "end": 7008.36,
        "id": 2035,
        "no_speech_prob": 0.0009397318935953081,
        "seek": 698836,
        "start": 7005.36,
        "temperature": 0,
        "text": " And then I'm going to go to desktop.",
        "tokens": [
          51214,
          400,
          550,
          286,
          478,
          516,
          281,
          352,
          281,
          14502,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2165185559180475,
        "compression_ratio": 1.328358208955224,
        "end": 7010.36,
        "id": 2036,
        "no_speech_prob": 0.0009397318935953081,
        "seek": 698836,
        "start": 7008.36,
        "temperature": 0,
        "text": " Logo.",
        "tokens": [
          51364,
          10824,
          78,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2165185559180475,
        "compression_ratio": 1.328358208955224,
        "end": 7014.36,
        "id": 2037,
        "no_speech_prob": 0.0009397318935953081,
        "seek": 698836,
        "start": 7010.36,
        "temperature": 0,
        "text": " This should be everything for this version.",
        "tokens": [
          51464,
          639,
          820,
          312,
          1203,
          337,
          341,
          3037,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2270352534758739,
        "compression_ratio": 1.125,
        "end": 7020.36,
        "id": 2038,
        "no_speech_prob": 0.0007552982424385846,
        "seek": 701436,
        "start": 7015.36,
        "temperature": 0,
        "text": " So now if I go to...",
        "tokens": [
          50414,
          407,
          586,
          498,
          286,
          352,
          281,
          485,
          50664
        ]
      },
      {
        "avg_logprob": -0.2270352534758739,
        "compression_ratio": 1.125,
        "end": 7028.36,
        "id": 2039,
        "no_speech_prob": 0.0007552982424385846,
        "seek": 701436,
        "start": 7024.36,
        "temperature": 0,
        "text": " I really messed up here.",
        "tokens": [
          50864,
          286,
          534,
          16507,
          493,
          510,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2270352534758739,
        "compression_ratio": 1.125,
        "end": 7033.36,
        "id": 2040,
        "no_speech_prob": 0.0007552982424385846,
        "seek": 701436,
        "start": 7030.36,
        "temperature": 0,
        "text": " Because I didn't...",
        "tokens": [
          51164,
          1436,
          286,
          994,
          380,
          485,
          51314
        ]
      },
      {
        "avg_logprob": -0.2270352534758739,
        "compression_ratio": 1.125,
        "end": 7036.36,
        "id": 2041,
        "no_speech_prob": 0.0007552982424385846,
        "seek": 701436,
        "start": 7033.36,
        "temperature": 0,
        "text": " Let me just...",
        "tokens": [
          51314,
          961,
          385,
          445,
          485,
          51464
        ]
      },
      {
        "avg_logprob": -0.2270352534758739,
        "compression_ratio": 1.125,
        "end": 7039.36,
        "id": 2042,
        "no_speech_prob": 0.0007552982424385846,
        "seek": 701436,
        "start": 7036.36,
        "temperature": 0,
        "text": " Let me merge this.",
        "tokens": [
          51464,
          961,
          385,
          22183,
          341,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.34996398614377394,
        "compression_ratio": 1.2072072072072073,
        "end": 7044.36,
        "id": 2043,
        "no_speech_prob": 0.003648962825536728,
        "seek": 703936,
        "start": 7040.36,
        "temperature": 0,
        "text": " This was the code from save load live stream.",
        "tokens": [
          50414,
          639,
          390,
          264,
          3089,
          490,
          3155,
          3677,
          1621,
          4309,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.34996398614377394,
        "compression_ratio": 1.2072072072072073,
        "end": 7047.36,
        "id": 2044,
        "no_speech_prob": 0.003648962825536728,
        "seek": 703936,
        "start": 7044.36,
        "temperature": 0,
        "text": " I'm going to merge this.",
        "tokens": [
          50614,
          286,
          478,
          516,
          281,
          22183,
          341,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.34996398614377394,
        "compression_ratio": 1.2072072072072073,
        "end": 7052.36,
        "id": 2045,
        "no_speech_prob": 0.003648962825536728,
        "seek": 703936,
        "start": 7049.36,
        "temperature": 0,
        "text": " And then...",
        "tokens": [
          50864,
          400,
          550,
          485,
          51014
        ]
      },
      {
        "avg_logprob": -0.34996398614377394,
        "compression_ratio": 1.2072072072072073,
        "end": 7056.36,
        "id": 2046,
        "no_speech_prob": 0.003648962825536728,
        "seek": 703936,
        "start": 7054.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51114,
          1033,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.34996398614377394,
        "compression_ratio": 1.2072072072072073,
        "end": 7061.36,
        "id": 2047,
        "no_speech_prob": 0.003648962825536728,
        "seek": 703936,
        "start": 7058.36,
        "temperature": 0,
        "text": " And I'm going to...",
        "tokens": [
          51314,
          400,
          286,
          478,
          516,
          281,
          485,
          51464
        ]
      },
      {
        "avg_logprob": -0.34996398614377394,
        "compression_ratio": 1.2072072072072073,
        "end": 7065.36,
        "id": 2048,
        "no_speech_prob": 0.003648962825536728,
        "seek": 703936,
        "start": 7062.36,
        "temperature": 0,
        "text": " Get branch...",
        "tokens": [
          51514,
          3240,
          9819,
          485,
          51664
        ]
      },
      {
        "avg_logprob": -0.34996398614377394,
        "compression_ratio": 1.2072072072072073,
        "end": 7068.36,
        "id": 2049,
        "no_speech_prob": 0.003648962825536728,
        "seek": 703936,
        "start": 7065.36,
        "temperature": 0,
        "text": " Quick draw.",
        "tokens": [
          51664,
          12101,
          2642,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2818352516661299,
        "compression_ratio": 1.3626373626373627,
        "end": 7072.36,
        "id": 2050,
        "no_speech_prob": 0.0032203870359808207,
        "seek": 706936,
        "start": 7070.36,
        "temperature": 0,
        "text": " Check out.",
        "tokens": [
          50414,
          6881,
          484,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2818352516661299,
        "compression_ratio": 1.3626373626373627,
        "end": 7075.36,
        "id": 2051,
        "no_speech_prob": 0.0032203870359808207,
        "seek": 706936,
        "start": 7072.36,
        "temperature": 0,
        "text": " Quick draw.",
        "tokens": [
          50514,
          12101,
          2642,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2818352516661299,
        "compression_ratio": 1.3626373626373627,
        "end": 7084.36,
        "id": 2052,
        "no_speech_prob": 0.0032203870359808207,
        "seek": 706936,
        "start": 7079.36,
        "temperature": 0,
        "text": " Get add coding challenges.",
        "tokens": [
          50864,
          3240,
          909,
          17720,
          4759,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2818352516661299,
        "compression_ratio": 1.3626373626373627,
        "end": 7086.36,
        "id": 2053,
        "no_speech_prob": 0.0032203870359808207,
        "seek": 706936,
        "start": 7084.36,
        "temperature": 0,
        "text": " 1.22.",
        "tokens": [
          51114,
          502,
          13,
          7490,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2818352516661299,
        "compression_ratio": 1.3626373626373627,
        "end": 7088.36,
        "id": 2054,
        "no_speech_prob": 0.0032203870359808207,
        "seek": 706936,
        "start": 7086.36,
        "temperature": 0,
        "text": " Quick draw.",
        "tokens": [
          51214,
          12101,
          2642,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2818352516661299,
        "compression_ratio": 1.3626373626373627,
        "end": 7091.36,
        "id": 2055,
        "no_speech_prob": 0.0032203870359808207,
        "seek": 706936,
        "start": 7088.36,
        "temperature": 0,
        "text": " Code from quick draw.",
        "tokens": [
          51314,
          15549,
          490,
          1702,
          2642,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2818352516661299,
        "compression_ratio": 1.3626373626373627,
        "end": 7094.36,
        "id": 2056,
        "no_speech_prob": 0.0032203870359808207,
        "seek": 706936,
        "start": 7091.36,
        "temperature": 0,
        "text": " Challenge.",
        "tokens": [
          51464,
          17517,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2818352516661299,
        "compression_ratio": 1.3626373626373627,
        "end": 7098.36,
        "id": 2057,
        "no_speech_prob": 0.0032203870359808207,
        "seek": 706936,
        "start": 7094.36,
        "temperature": 0,
        "text": " Push origin quick draw.",
        "tokens": [
          51614,
          18229,
          4957,
          1702,
          2642,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.274511315101801,
        "compression_ratio": 1.1063829787234043,
        "end": 7102.36,
        "id": 2058,
        "no_speech_prob": 0.011682628653943539,
        "seek": 709936,
        "start": 7100.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.274511315101801,
        "compression_ratio": 1.1063829787234043,
        "end": 7104.36,
        "id": 2059,
        "no_speech_prob": 0.011682628653943539,
        "seek": 709936,
        "start": 7102.36,
        "temperature": 0,
        "text": " Check out.",
        "tokens": [
          50514,
          6881,
          484,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.274511315101801,
        "compression_ratio": 1.1063829787234043,
        "end": 7106.36,
        "id": 2060,
        "no_speech_prob": 0.011682628653943539,
        "seek": 709936,
        "start": 7104.36,
        "temperature": 0,
        "text": " Master.",
        "tokens": [
          50614,
          6140,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.274511315101801,
        "compression_ratio": 1.1063829787234043,
        "end": 7112.36,
        "id": 2061,
        "no_speech_prob": 0.011682628653943539,
        "seek": 709936,
        "start": 7108.36,
        "temperature": 0,
        "text": " And what I want to do is...",
        "tokens": [
          50814,
          400,
          437,
          286,
          528,
          281,
          360,
          307,
          485,
          51014
        ]
      },
      {
        "avg_logprob": -0.274511315101801,
        "compression_ratio": 1.1063829787234043,
        "end": 7114.36,
        "id": 2062,
        "no_speech_prob": 0.011682628653943539,
        "seek": 709936,
        "start": 7112.36,
        "temperature": 0,
        "text": " Shoot.",
        "tokens": [
          51014,
          19760,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.274511315101801,
        "compression_ratio": 1.1063829787234043,
        "end": 7120.36,
        "id": 2063,
        "no_speech_prob": 0.011682628653943539,
        "seek": 709936,
        "start": 7117.36,
        "temperature": 0,
        "text": " I have an idea here.",
        "tokens": [
          51264,
          286,
          362,
          364,
          1558,
          510,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.274511315101801,
        "compression_ratio": 1.1063829787234043,
        "end": 7128.36,
        "id": 2064,
        "no_speech_prob": 0.011682628653943539,
        "seek": 709936,
        "start": 7124.36,
        "temperature": 0,
        "text": " Where is this nonsense?",
        "tokens": [
          51614,
          2305,
          307,
          341,
          14925,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.32748368445863113,
        "compression_ratio": 1.1886792452830188,
        "end": 7133.36,
        "id": 2065,
        "no_speech_prob": 0.008705592714250088,
        "seek": 712936,
        "start": 7129.36,
        "temperature": 0,
        "text": " There is some extra thing here that I'm going to get rid of.",
        "tokens": [
          50364,
          821,
          307,
          512,
          2857,
          551,
          510,
          300,
          286,
          478,
          516,
          281,
          483,
          3973,
          295,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.32748368445863113,
        "compression_ratio": 1.1886792452830188,
        "end": 7142.36,
        "id": 2066,
        "no_speech_prob": 0.008705592714250088,
        "seek": 712936,
        "start": 7138.36,
        "temperature": 0,
        "text": " Get branch logo.",
        "tokens": [
          50814,
          3240,
          9819,
          9699,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.32748368445863113,
        "compression_ratio": 1.1886792452830188,
        "end": 7145.36,
        "id": 2067,
        "no_speech_prob": 0.008705592714250088,
        "seek": 712936,
        "start": 7142.36,
        "temperature": 0,
        "text": " Get check out logo.",
        "tokens": [
          51014,
          3240,
          1520,
          484,
          9699,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.32748368445863113,
        "compression_ratio": 1.1886792452830188,
        "end": 7153.36,
        "id": 2068,
        "no_speech_prob": 0.008705592714250088,
        "seek": 712936,
        "start": 7151.36,
        "temperature": 0,
        "text": " And hold on.",
        "tokens": [
          51464,
          400,
          1797,
          322,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.32748368445863113,
        "compression_ratio": 1.1886792452830188,
        "end": 7156.36,
        "id": 2069,
        "no_speech_prob": 0.008705592714250088,
        "seek": 712936,
        "start": 7153.36,
        "temperature": 0,
        "text": " Logo 1, logo 2.",
        "tokens": [
          51564,
          10824,
          78,
          502,
          11,
          9699,
          568,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.3991878751724485,
        "compression_ratio": 1.4726027397260273,
        "end": 7159.36,
        "id": 2070,
        "no_speech_prob": 0.027571413666009903,
        "seek": 715636,
        "start": 7156.36,
        "temperature": 0,
        "text": " Get add.",
        "tokens": [
          50364,
          3240,
          909,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.3991878751724485,
        "compression_ratio": 1.4726027397260273,
        "end": 7163.36,
        "id": 2071,
        "no_speech_prob": 0.027571413666009903,
        "seek": 715636,
        "start": 7159.36,
        "temperature": 0,
        "text": " Moving logo code around.",
        "tokens": [
          50514,
          14242,
          9699,
          3089,
          926,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.3991878751724485,
        "compression_ratio": 1.4726027397260273,
        "end": 7166.36,
        "id": 2072,
        "no_speech_prob": 0.027571413666009903,
        "seek": 715636,
        "start": 7163.36,
        "temperature": 0,
        "text": " And adding second part.",
        "tokens": [
          50714,
          400,
          5127,
          1150,
          644,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.3991878751724485,
        "compression_ratio": 1.4726027397260273,
        "end": 7170.36,
        "id": 2073,
        "no_speech_prob": 0.027571413666009903,
        "seek": 715636,
        "start": 7166.36,
        "temperature": 0,
        "text": " And now get push origin logo.",
        "tokens": [
          50864,
          400,
          586,
          483,
          2944,
          4957,
          9699,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.3991878751724485,
        "compression_ratio": 1.4726027397260273,
        "end": 7174.36,
        "id": 2074,
        "no_speech_prob": 0.027571413666009903,
        "seek": 715636,
        "start": 7170.36,
        "temperature": 0,
        "text": " So I should have two separate pull requests now.",
        "tokens": [
          51064,
          407,
          286,
          820,
          362,
          732,
          4994,
          2235,
          12475,
          586,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.3991878751724485,
        "compression_ratio": 1.4726027397260273,
        "end": 7178.36,
        "id": 2075,
        "no_speech_prob": 0.027571413666009903,
        "seek": 715636,
        "start": 7174.36,
        "temperature": 0,
        "text": " Welcome to weird things with GitHub.",
        "tokens": [
          51264,
          4027,
          281,
          3657,
          721,
          365,
          23331,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.3991878751724485,
        "compression_ratio": 1.4726027397260273,
        "end": 7182.36,
        "id": 2076,
        "no_speech_prob": 0.027571413666009903,
        "seek": 715636,
        "start": 7178.36,
        "temperature": 0,
        "text": " So I should be able to pull request this.",
        "tokens": [
          51464,
          407,
          286,
          820,
          312,
          1075,
          281,
          2235,
          5308,
          341,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.3676542441050212,
        "compression_ratio": 1.1734693877551021,
        "end": 7186.36,
        "id": 2077,
        "no_speech_prob": 0.00043048651423305273,
        "seek": 718236,
        "start": 7182.36,
        "temperature": 0,
        "text": " This is the quick draw code.",
        "tokens": [
          50364,
          639,
          307,
          264,
          1702,
          2642,
          3089,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.3676542441050212,
        "compression_ratio": 1.1734693877551021,
        "end": 7190.36,
        "id": 2078,
        "no_speech_prob": 0.00043048651423305273,
        "seek": 718236,
        "start": 7186.36,
        "temperature": 0,
        "text": " For challenge 1.22.",
        "tokens": [
          50564,
          1171,
          3430,
          502,
          13,
          7490,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.3676542441050212,
        "compression_ratio": 1.1734693877551021,
        "end": 7197.36,
        "id": 2079,
        "no_speech_prob": 0.00043048651423305273,
        "seek": 718236,
        "start": 7194.36,
        "temperature": 0,
        "text": " Well...",
        "tokens": [
          50964,
          1042,
          485,
          51114
        ]
      },
      {
        "avg_logprob": -0.3676542441050212,
        "compression_ratio": 1.1734693877551021,
        "end": 7202.36,
        "id": 2080,
        "no_speech_prob": 0.00043048651423305273,
        "seek": 718236,
        "start": 7200.36,
        "temperature": 0,
        "text": " Wait.",
        "tokens": [
          51264,
          3802,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.3676542441050212,
        "compression_ratio": 1.1734693877551021,
        "end": 7204.36,
        "id": 2081,
        "no_speech_prob": 0.00043048651423305273,
        "seek": 718236,
        "start": 7202.36,
        "temperature": 0,
        "text": " Why is my...",
        "tokens": [
          51364,
          1545,
          307,
          452,
          485,
          51464
        ]
      },
      {
        "avg_logprob": -0.3676542441050212,
        "compression_ratio": 1.1734693877551021,
        "end": 7208.36,
        "id": 2082,
        "no_speech_prob": 0.00043048651423305273,
        "seek": 718236,
        "start": 7204.36,
        "temperature": 0,
        "text": " What sort of set of tabs is this?",
        "tokens": [
          51464,
          708,
          1333,
          295,
          992,
          295,
          20743,
          307,
          341,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.3676542441050212,
        "compression_ratio": 1.1734693877551021,
        "end": 7210.36,
        "id": 2083,
        "no_speech_prob": 0.00043048651423305273,
        "seek": 718236,
        "start": 7208.36,
        "temperature": 0,
        "text": " What?",
        "tokens": [
          51664,
          708,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.34432206670921967,
        "compression_ratio": 1.5135135135135136,
        "end": 7213.36,
        "id": 2084,
        "no_speech_prob": 0.0029347743839025497,
        "seek": 721036,
        "start": 7211.36,
        "temperature": 0,
        "text": " What?",
        "tokens": [
          50414,
          708,
          30,
          50514
        ]
      },
      {
        "avg_logprob": -0.34432206670921967,
        "compression_ratio": 1.5135135135135136,
        "end": 7216.36,
        "id": 2085,
        "no_speech_prob": 0.0029347743839025497,
        "seek": 721036,
        "start": 7213.36,
        "temperature": 0,
        "text": " Have I been using four space tabs all this time?",
        "tokens": [
          50514,
          3560,
          286,
          668,
          1228,
          1451,
          1901,
          20743,
          439,
          341,
          565,
          30,
          50664
        ]
      },
      {
        "avg_logprob": -0.34432206670921967,
        "compression_ratio": 1.5135135135135136,
        "end": 7218.36,
        "id": 2086,
        "no_speech_prob": 0.0029347743839025497,
        "seek": 721036,
        "start": 7216.36,
        "temperature": 0,
        "text": " And not noticing...",
        "tokens": [
          50664,
          400,
          406,
          21814,
          485,
          50764
        ]
      },
      {
        "avg_logprob": -0.34432206670921967,
        "compression_ratio": 1.5135135135135136,
        "end": 7220.36,
        "id": 2087,
        "no_speech_prob": 0.0029347743839025497,
        "seek": 721036,
        "start": 7218.36,
        "temperature": 0,
        "text": " This is like 18 space tabs.",
        "tokens": [
          50764,
          639,
          307,
          411,
          2443,
          1901,
          20743,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.34432206670921967,
        "compression_ratio": 1.5135135135135136,
        "end": 7222.36,
        "id": 2088,
        "no_speech_prob": 0.0029347743839025497,
        "seek": 721036,
        "start": 7220.36,
        "temperature": 0,
        "text": " This is insane.",
        "tokens": [
          50864,
          639,
          307,
          10838,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.34432206670921967,
        "compression_ratio": 1.5135135135135136,
        "end": 7224.36,
        "id": 2089,
        "no_speech_prob": 0.0029347743839025497,
        "seek": 721036,
        "start": 7222.36,
        "temperature": 0,
        "text": " What is going on?",
        "tokens": [
          50964,
          708,
          307,
          516,
          322,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.34432206670921967,
        "compression_ratio": 1.5135135135135136,
        "end": 7228.36,
        "id": 2090,
        "no_speech_prob": 0.0029347743839025497,
        "seek": 721036,
        "start": 7224.36,
        "temperature": 0,
        "text": " This looks like two spaces.",
        "tokens": [
          51064,
          639,
          1542,
          411,
          732,
          7673,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.34432206670921967,
        "compression_ratio": 1.5135135135135136,
        "end": 7230.36,
        "id": 2091,
        "no_speech_prob": 0.0029347743839025497,
        "seek": 721036,
        "start": 7228.36,
        "temperature": 0,
        "text": " What is going on?",
        "tokens": [
          51264,
          708,
          307,
          516,
          322,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.34432206670921967,
        "compression_ratio": 1.5135135135135136,
        "end": 7232.36,
        "id": 2092,
        "no_speech_prob": 0.0029347743839025497,
        "seek": 721036,
        "start": 7230.36,
        "temperature": 0,
        "text": " Tab size 2.",
        "tokens": [
          51364,
          14106,
          2744,
          568,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.34432206670921967,
        "compression_ratio": 1.5135135135135136,
        "end": 7234.36,
        "id": 2093,
        "no_speech_prob": 0.0029347743839025497,
        "seek": 721036,
        "start": 7232.36,
        "temperature": 0,
        "text": " Render white space.",
        "tokens": [
          51464,
          497,
          3216,
          2418,
          1901,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.34432206670921967,
        "compression_ratio": 1.5135135135135136,
        "end": 7236.36,
        "id": 2094,
        "no_speech_prob": 0.0029347743839025497,
        "seek": 721036,
        "start": 7234.36,
        "temperature": 0,
        "text": " All.",
        "tokens": [
          51564,
          1057,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.34432206670921967,
        "compression_ratio": 1.5135135135135136,
        "end": 7238.36,
        "id": 2095,
        "no_speech_prob": 0.0029347743839025497,
        "seek": 721036,
        "start": 7236.36,
        "temperature": 0,
        "text": " Hmm.",
        "tokens": [
          51664,
          8239,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.32469698098989636,
        "compression_ratio": 1.1935483870967742,
        "end": 7240.36,
        "id": 2096,
        "no_speech_prob": 0.007936827838420868,
        "seek": 723836,
        "start": 7238.36,
        "temperature": 0,
        "text": " Those are tabs.",
        "tokens": [
          50364,
          3950,
          366,
          20743,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.32469698098989636,
        "compression_ratio": 1.1935483870967742,
        "end": 7243.36,
        "id": 2097,
        "no_speech_prob": 0.007936827838420868,
        "seek": 723836,
        "start": 7242.36,
        "temperature": 0,
        "text": " Why is it...",
        "tokens": [
          50564,
          1545,
          307,
          309,
          485,
          50614
        ]
      },
      {
        "avg_logprob": -0.32469698098989636,
        "compression_ratio": 1.1935483870967742,
        "end": 7246.36,
        "id": 2098,
        "no_speech_prob": 0.007936827838420868,
        "seek": 723836,
        "start": 7243.36,
        "temperature": 0,
        "text": " What setting in VS code is changing those to tabs?",
        "tokens": [
          50614,
          708,
          3287,
          294,
          25091,
          3089,
          307,
          4473,
          729,
          281,
          20743,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.32469698098989636,
        "compression_ratio": 1.1935483870967742,
        "end": 7249.36,
        "id": 2099,
        "no_speech_prob": 0.007936827838420868,
        "seek": 723836,
        "start": 7246.36,
        "temperature": 0,
        "text": " Oh my goodness.",
        "tokens": [
          50764,
          876,
          452,
          8387,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.32469698098989636,
        "compression_ratio": 1.1935483870967742,
        "end": 7252.36,
        "id": 2100,
        "no_speech_prob": 0.007936827838420868,
        "seek": 723836,
        "start": 7249.36,
        "temperature": 0,
        "text": " This cannot be.",
        "tokens": [
          50914,
          639,
          2644,
          312,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.48304757727197856,
        "compression_ratio": 1.5177304964539007,
        "end": 7255.36,
        "id": 2101,
        "no_speech_prob": 0.054977789521217346,
        "seek": 725236,
        "start": 7253.36,
        "temperature": 0,
        "text": " What am I...",
        "tokens": [
          50414,
          708,
          669,
          286,
          485,
          50514
        ]
      },
      {
        "avg_logprob": -0.48304757727197856,
        "compression_ratio": 1.5177304964539007,
        "end": 7258.36,
        "id": 2102,
        "no_speech_prob": 0.054977789521217346,
        "seek": 725236,
        "start": 7255.36,
        "temperature": 0,
        "text": " I forgot if I'm using prettier.",
        "tokens": [
          50514,
          286,
          5298,
          498,
          286,
          478,
          1228,
          36825,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.48304757727197856,
        "compression_ratio": 1.5177304964539007,
        "end": 7261.36,
        "id": 2103,
        "no_speech_prob": 0.054977789521217346,
        "seek": 725236,
        "start": 7258.36,
        "temperature": 0,
        "text": " I switched everything in my workflow.",
        "tokens": [
          50664,
          286,
          16858,
          1203,
          294,
          452,
          20993,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.48304757727197856,
        "compression_ratio": 1.5177304964539007,
        "end": 7264.36,
        "id": 2104,
        "no_speech_prob": 0.054977789521217346,
        "seek": 725236,
        "start": 7261.36,
        "temperature": 0,
        "text": " But I never did it on this.",
        "tokens": [
          50814,
          583,
          286,
          1128,
          630,
          309,
          322,
          341,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.48304757727197856,
        "compression_ratio": 1.5177304964539007,
        "end": 7266.36,
        "id": 2105,
        "no_speech_prob": 0.054977789521217346,
        "seek": 725236,
        "start": 7264.36,
        "temperature": 0,
        "text": " Am I...",
        "tokens": [
          50964,
          2012,
          286,
          485,
          51064
        ]
      },
      {
        "avg_logprob": -0.48304757727197856,
        "compression_ratio": 1.5177304964539007,
        "end": 7268.36,
        "id": 2106,
        "no_speech_prob": 0.054977789521217346,
        "seek": 725236,
        "start": 7266.36,
        "temperature": 0,
        "text": " Do not I have...",
        "tokens": [
          51064,
          1144,
          406,
          286,
          362,
          485,
          51164
        ]
      },
      {
        "avg_logprob": -0.48304757727197856,
        "compression_ratio": 1.5177304964539007,
        "end": 7270.36,
        "id": 2107,
        "no_speech_prob": 0.054977789521217346,
        "seek": 725236,
        "start": 7268.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51164,
          1057,
          558,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.48304757727197856,
        "compression_ratio": 1.5177304964539007,
        "end": 7272.36,
        "id": 2108,
        "no_speech_prob": 0.054977789521217346,
        "seek": 725236,
        "start": 7270.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51264,
          1057,
          558,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.48304757727197856,
        "compression_ratio": 1.5177304964539007,
        "end": 7274.36,
        "id": 2109,
        "no_speech_prob": 0.054977789521217346,
        "seek": 725236,
        "start": 7272.36,
        "temperature": 0,
        "text": " Let's see.",
        "tokens": [
          51364,
          961,
          311,
          536,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.48304757727197856,
        "compression_ratio": 1.5177304964539007,
        "end": 7276.36,
        "id": 2110,
        "no_speech_prob": 0.054977789521217346,
        "seek": 725236,
        "start": 7274.36,
        "temperature": 0,
        "text": " I'm going to try this.",
        "tokens": [
          51464,
          286,
          478,
          516,
          281,
          853,
          341,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.48304757727197856,
        "compression_ratio": 1.5177304964539007,
        "end": 7278.36,
        "id": 2111,
        "no_speech_prob": 0.054977789521217346,
        "seek": 725236,
        "start": 7276.36,
        "temperature": 0,
        "text": " I'm going to try this.",
        "tokens": [
          51564,
          286,
          478,
          516,
          281,
          853,
          341,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.3216944984767748,
        "compression_ratio": 1.22,
        "end": 7281.36,
        "id": 2112,
        "no_speech_prob": 0.015903297811746597,
        "seek": 727836,
        "start": 7279.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50414,
          1057,
          558,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.3216944984767748,
        "compression_ratio": 1.22,
        "end": 7283.36,
        "id": 2113,
        "no_speech_prob": 0.015903297811746597,
        "seek": 727836,
        "start": 7281.36,
        "temperature": 0,
        "text": " Let's see.",
        "tokens": [
          50514,
          961,
          311,
          536,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.3216944984767748,
        "compression_ratio": 1.22,
        "end": 7285.36,
        "id": 2114,
        "no_speech_prob": 0.015903297811746597,
        "seek": 727836,
        "start": 7283.36,
        "temperature": 0,
        "text": " Oh, this...",
        "tokens": [
          50614,
          876,
          11,
          341,
          485,
          50714
        ]
      },
      {
        "avg_logprob": -0.3216944984767748,
        "compression_ratio": 1.22,
        "end": 7287.36,
        "id": 2115,
        "no_speech_prob": 0.015903297811746597,
        "seek": 727836,
        "start": 7285.36,
        "temperature": 0,
        "text": " I have this crazy thing.",
        "tokens": [
          50714,
          286,
          362,
          341,
          3219,
          551,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.3216944984767748,
        "compression_ratio": 1.22,
        "end": 7289.36,
        "id": 2116,
        "no_speech_prob": 0.015903297811746597,
        "seek": 727836,
        "start": 7287.36,
        "temperature": 0,
        "text": " Indent with tabs.",
        "tokens": [
          50814,
          2333,
          317,
          365,
          20743,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.3216944984767748,
        "compression_ratio": 1.22,
        "end": 7291.36,
        "id": 2117,
        "no_speech_prob": 0.015903297811746597,
        "seek": 727836,
        "start": 7289.36,
        "temperature": 0,
        "text": " Size 4.",
        "tokens": [
          50914,
          35818,
          1017,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.3216944984767748,
        "compression_ratio": 1.22,
        "end": 7293.36,
        "id": 2118,
        "no_speech_prob": 0.015903297811746597,
        "seek": 727836,
        "start": 7291.36,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          51014,
          876,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.3216944984767748,
        "compression_ratio": 1.22,
        "end": 7295.36,
        "id": 2119,
        "no_speech_prob": 0.015903297811746597,
        "seek": 727836,
        "start": 7293.36,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          51114,
          876,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.3216944984767748,
        "compression_ratio": 1.22,
        "end": 7297.36,
        "id": 2120,
        "no_speech_prob": 0.015903297811746597,
        "seek": 727836,
        "start": 7295.36,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          51214,
          876,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.3216944984767748,
        "compression_ratio": 1.22,
        "end": 7299.36,
        "id": 2121,
        "no_speech_prob": 0.015903297811746597,
        "seek": 727836,
        "start": 7297.36,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          51314,
          876,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.3216944984767748,
        "compression_ratio": 1.22,
        "end": 7301.36,
        "id": 2122,
        "no_speech_prob": 0.015903297811746597,
        "seek": 727836,
        "start": 7299.36,
        "temperature": 0,
        "text": " What is this?",
        "tokens": [
          51414,
          708,
          307,
          341,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.3216944984767748,
        "compression_ratio": 1.22,
        "end": 7303.36,
        "id": 2123,
        "no_speech_prob": 0.015903297811746597,
        "seek": 727836,
        "start": 7301.36,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          51514,
          876,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.3216944984767748,
        "compression_ratio": 1.22,
        "end": 7305.36,
        "id": 2124,
        "no_speech_prob": 0.015903297811746597,
        "seek": 727836,
        "start": 7303.36,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          51614,
          876,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2830940677273658,
        "compression_ratio": 1.0657894736842106,
        "end": 7309.36,
        "id": 2125,
        "no_speech_prob": 0.02193620055913925,
        "seek": 730536,
        "start": 7306.36,
        "temperature": 0,
        "text": " Let's disable this for a second.",
        "tokens": [
          50414,
          961,
          311,
          28362,
          341,
          337,
          257,
          1150,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2830940677273658,
        "compression_ratio": 1.0657894736842106,
        "end": 7320.36,
        "id": 2126,
        "no_speech_prob": 0.02193620055913925,
        "seek": 730536,
        "start": 7317.36,
        "temperature": 0,
        "text": " Let's install this prettier thing.",
        "tokens": [
          50964,
          961,
          311,
          3625,
          341,
          36825,
          551,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2830940677273658,
        "compression_ratio": 1.0657894736842106,
        "end": 7329.36,
        "id": 2127,
        "no_speech_prob": 0.02193620055913925,
        "seek": 730536,
        "start": 7327.36,
        "temperature": 0,
        "text": " Reload.",
        "tokens": [
          51464,
          8738,
          78,
          345,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2830940677273658,
        "compression_ratio": 1.0657894736842106,
        "end": 7331.36,
        "id": 2128,
        "no_speech_prob": 0.02193620055913925,
        "seek": 730536,
        "start": 7329.36,
        "temperature": 0,
        "text": " Yeah!",
        "tokens": [
          51564,
          865,
          0,
          51664
        ]
      },
      {
        "avg_logprob": -0.21361971449577946,
        "compression_ratio": 1.3402777777777777,
        "end": 7333.36,
        "id": 2129,
        "no_speech_prob": 0.010166464373469353,
        "seek": 733136,
        "start": 7331.36,
        "temperature": 0,
        "text": " Yeah!",
        "tokens": [
          50364,
          865,
          0,
          50464
        ]
      },
      {
        "avg_logprob": -0.21361971449577946,
        "compression_ratio": 1.3402777777777777,
        "end": 7335.36,
        "id": 2130,
        "no_speech_prob": 0.010166464373469353,
        "seek": 733136,
        "start": 7333.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50464,
          1033,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.21361971449577946,
        "compression_ratio": 1.3402777777777777,
        "end": 7337.36,
        "id": 2131,
        "no_speech_prob": 0.010166464373469353,
        "seek": 733136,
        "start": 7335.36,
        "temperature": 0,
        "text": " Oh, what a mess.",
        "tokens": [
          50564,
          876,
          11,
          437,
          257,
          2082,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.21361971449577946,
        "compression_ratio": 1.3402777777777777,
        "end": 7339.36,
        "id": 2132,
        "no_speech_prob": 0.010166464373469353,
        "seek": 733136,
        "start": 7337.36,
        "temperature": 0,
        "text": " Where am I?",
        "tokens": [
          50664,
          2305,
          669,
          286,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.21361971449577946,
        "compression_ratio": 1.3402777777777777,
        "end": 7341.36,
        "id": 2133,
        "no_speech_prob": 0.010166464373469353,
        "seek": 733136,
        "start": 7339.36,
        "temperature": 0,
        "text": " Uh-oh.",
        "tokens": [
          50764,
          4019,
          12,
          1445,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.21361971449577946,
        "compression_ratio": 1.3402777777777777,
        "end": 7343.36,
        "id": 2134,
        "no_speech_prob": 0.010166464373469353,
        "seek": 733136,
        "start": 7341.36,
        "temperature": 0,
        "text": " Uh-oh.",
        "tokens": [
          50864,
          4019,
          12,
          1445,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.21361971449577946,
        "compression_ratio": 1.3402777777777777,
        "end": 7345.36,
        "id": 2135,
        "no_speech_prob": 0.010166464373469353,
        "seek": 733136,
        "start": 7343.36,
        "temperature": 0,
        "text": " Who knows where I am?",
        "tokens": [
          50964,
          2102,
          3255,
          689,
          286,
          669,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.21361971449577946,
        "compression_ratio": 1.3402777777777777,
        "end": 7347.36,
        "id": 2136,
        "no_speech_prob": 0.010166464373469353,
        "seek": 733136,
        "start": 7345.36,
        "temperature": 0,
        "text": " I'm lost.",
        "tokens": [
          51064,
          286,
          478,
          2731,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.21361971449577946,
        "compression_ratio": 1.3402777777777777,
        "end": 7349.36,
        "id": 2137,
        "no_speech_prob": 0.010166464373469353,
        "seek": 733136,
        "start": 7347.36,
        "temperature": 0,
        "text": " I've ruined everything.",
        "tokens": [
          51164,
          286,
          600,
          17013,
          1203,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.21361971449577946,
        "compression_ratio": 1.3402777777777777,
        "end": 7351.36,
        "id": 2138,
        "no_speech_prob": 0.010166464373469353,
        "seek": 733136,
        "start": 7349.36,
        "temperature": 0,
        "text": " I'm in the quick draw thing.",
        "tokens": [
          51264,
          286,
          478,
          294,
          264,
          1702,
          2642,
          551,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.21361971449577946,
        "compression_ratio": 1.3402777777777777,
        "end": 7353.36,
        "id": 2139,
        "no_speech_prob": 0.010166464373469353,
        "seek": 733136,
        "start": 7351.36,
        "temperature": 0,
        "text": " I want to be in the website thing.",
        "tokens": [
          51364,
          286,
          528,
          281,
          312,
          294,
          264,
          3144,
          551,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.21361971449577946,
        "compression_ratio": 1.3402777777777777,
        "end": 7355.36,
        "id": 2140,
        "no_speech_prob": 0.010166464373469353,
        "seek": 733136,
        "start": 7353.36,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          51464,
          45263,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21361971449577946,
        "compression_ratio": 1.3402777777777777,
        "end": 7357.36,
        "id": 2141,
        "no_speech_prob": 0.010166464373469353,
        "seek": 733136,
        "start": 7355.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51564,
          1057,
          558,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20703884124755859,
        "compression_ratio": 1.253968253968254,
        "end": 7359.36,
        "id": 2142,
        "no_speech_prob": 0.006903011351823807,
        "seek": 735736,
        "start": 7357.36,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          50364,
          45263,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.20703884124755859,
        "compression_ratio": 1.253968253968254,
        "end": 7361.36,
        "id": 2143,
        "no_speech_prob": 0.006903011351823807,
        "seek": 735736,
        "start": 7359.36,
        "temperature": 0,
        "text": " Oh, what a mess I've made of everything.",
        "tokens": [
          50464,
          876,
          11,
          437,
          257,
          2082,
          286,
          600,
          1027,
          295,
          1203,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.20703884124755859,
        "compression_ratio": 1.253968253968254,
        "end": 7363.36,
        "id": 2144,
        "no_speech_prob": 0.006903011351823807,
        "seek": 735736,
        "start": 7361.36,
        "temperature": 0,
        "text": " Logo.",
        "tokens": [
          50564,
          10824,
          78,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20703884124755859,
        "compression_ratio": 1.253968253968254,
        "end": 7365.36,
        "id": 2145,
        "no_speech_prob": 0.006903011351823807,
        "seek": 735736,
        "start": 7363.36,
        "temperature": 0,
        "text": " One.",
        "tokens": [
          50664,
          1485,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20703884124755859,
        "compression_ratio": 1.253968253968254,
        "end": 7367.36,
        "id": 2146,
        "no_speech_prob": 0.006903011351823807,
        "seek": 735736,
        "start": 7365.36,
        "temperature": 0,
        "text": " Two.",
        "tokens": [
          50764,
          4453,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20703884124755859,
        "compression_ratio": 1.253968253968254,
        "end": 7369.36,
        "id": 2147,
        "no_speech_prob": 0.006903011351823807,
        "seek": 735736,
        "start": 7367.36,
        "temperature": 0,
        "text": " These are fine.",
        "tokens": [
          50864,
          1981,
          366,
          2489,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20703884124755859,
        "compression_ratio": 1.253968253968254,
        "end": 7371.36,
        "id": 2148,
        "no_speech_prob": 0.006903011351823807,
        "seek": 735736,
        "start": 7369.36,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50964,
          821,
          321,
          352,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.20703884124755859,
        "compression_ratio": 1.253968253968254,
        "end": 7373.36,
        "id": 2149,
        "no_speech_prob": 0.006903011351823807,
        "seek": 735736,
        "start": 7371.36,
        "temperature": 0,
        "text": " Ah!",
        "tokens": [
          51064,
          2438,
          0,
          51164
        ]
      },
      {
        "avg_logprob": -0.20703884124755859,
        "compression_ratio": 1.253968253968254,
        "end": 7375.36,
        "id": 2150,
        "no_speech_prob": 0.006903011351823807,
        "seek": 735736,
        "start": 7373.36,
        "temperature": 0,
        "text": " Oh, no.",
        "tokens": [
          51164,
          876,
          11,
          572,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20703884124755859,
        "compression_ratio": 1.253968253968254,
        "end": 7377.36,
        "id": 2151,
        "no_speech_prob": 0.006903011351823807,
        "seek": 735736,
        "start": 7375.36,
        "temperature": 0,
        "text": " It's inheriting.",
        "tokens": [
          51264,
          467,
          311,
          9484,
          1748,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20703884124755859,
        "compression_ratio": 1.253968253968254,
        "end": 7383.36,
        "id": 2152,
        "no_speech_prob": 0.006903011351823807,
        "seek": 735736,
        "start": 7381.36,
        "temperature": 0,
        "text": " Do I need to reload this thing?",
        "tokens": [
          51564,
          1144,
          286,
          643,
          281,
          25628,
          341,
          551,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.20703884124755859,
        "compression_ratio": 1.253968253968254,
        "end": 7385.36,
        "id": 2153,
        "no_speech_prob": 0.006903011351823807,
        "seek": 735736,
        "start": 7383.36,
        "temperature": 0,
        "text": " No.",
        "tokens": [
          51664,
          883,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.41985785166422523,
        "compression_ratio": 0.7391304347826086,
        "end": 7387.36,
        "id": 2154,
        "no_speech_prob": 0.028420675545930862,
        "seek": 738536,
        "start": 7385.36,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          50364,
          876,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.41985785166422523,
        "compression_ratio": 0.7391304347826086,
        "end": 7389.36,
        "id": 2155,
        "no_speech_prob": 0.028420675545930862,
        "seek": 738536,
        "start": 7387.36,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          50464,
          876,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.41985785166422523,
        "compression_ratio": 0.7391304347826086,
        "end": 7405.36,
        "id": 2156,
        "no_speech_prob": 0.028420675545930862,
        "seek": 738536,
        "start": 7403.36,
        "temperature": 0,
        "text": " Prettier.",
        "tokens": [
          51264,
          9739,
          25402,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19608240861159104,
        "compression_ratio": 1.037037037037037,
        "end": 7407.36,
        "id": 2157,
        "no_speech_prob": 0.017707569524645805,
        "seek": 740536,
        "start": 7405.36,
        "temperature": 0,
        "text": " Prettier.",
        "tokens": [
          50364,
          9739,
          25402,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.19608240861159104,
        "compression_ratio": 1.037037037037037,
        "end": 7417.36,
        "id": 2158,
        "no_speech_prob": 0.017707569524645805,
        "seek": 740536,
        "start": 7415.36,
        "temperature": 0,
        "text": " Default two.",
        "tokens": [
          50864,
          9548,
          5107,
          732,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19608240861159104,
        "compression_ratio": 1.037037037037037,
        "end": 7419.36,
        "id": 2159,
        "no_speech_prob": 0.017707569524645805,
        "seek": 740536,
        "start": 7417.36,
        "temperature": 0,
        "text": " Tabs.",
        "tokens": [
          50964,
          14106,
          82,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19608240861159104,
        "compression_ratio": 1.037037037037037,
        "end": 7421.36,
        "id": 2160,
        "no_speech_prob": 0.017707569524645805,
        "seek": 740536,
        "start": 7419.36,
        "temperature": 0,
        "text": " False.",
        "tokens": [
          51064,
          50040,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19608240861159104,
        "compression_ratio": 1.037037037037037,
        "end": 7427.36,
        "id": 2161,
        "no_speech_prob": 0.017707569524645805,
        "seek": 740536,
        "start": 7425.36,
        "temperature": 0,
        "text": " Semicolons true.",
        "tokens": [
          51364,
          318,
          3438,
          401,
          892,
          2074,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19608240861159104,
        "compression_ratio": 1.037037037037037,
        "end": 7431.36,
        "id": 2162,
        "no_speech_prob": 0.017707569524645805,
        "seek": 740536,
        "start": 7429.36,
        "temperature": 0,
        "text": " So, these are all the settings.",
        "tokens": [
          51564,
          407,
          11,
          613,
          366,
          439,
          264,
          6257,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.24959615758947423,
        "compression_ratio": 1.2885906040268456,
        "end": 7437.36,
        "id": 2163,
        "no_speech_prob": 0.006097239442169666,
        "seek": 743536,
        "start": 7435.36,
        "temperature": 0,
        "text": " Oh, I've gone off the deep end here.",
        "tokens": [
          50364,
          876,
          11,
          286,
          600,
          2780,
          766,
          264,
          2452,
          917,
          510,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.24959615758947423,
        "compression_ratio": 1.2885906040268456,
        "end": 7439.36,
        "id": 2164,
        "no_speech_prob": 0.006097239442169666,
        "seek": 743536,
        "start": 7437.36,
        "temperature": 0,
        "text": " Are people really watching me do this right now?",
        "tokens": [
          50464,
          2014,
          561,
          534,
          1976,
          385,
          360,
          341,
          558,
          586,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.24959615758947423,
        "compression_ratio": 1.2885906040268456,
        "end": 7441.36,
        "id": 2165,
        "no_speech_prob": 0.006097239442169666,
        "seek": 743536,
        "start": 7439.36,
        "temperature": 0,
        "text": " Right.",
        "tokens": [
          50564,
          1779,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.24959615758947423,
        "compression_ratio": 1.2885906040268456,
        "end": 7443.36,
        "id": 2166,
        "no_speech_prob": 0.006097239442169666,
        "seek": 743536,
        "start": 7441.36,
        "temperature": 0,
        "text": " Where is...",
        "tokens": [
          50664,
          2305,
          307,
          485,
          50764
        ]
      },
      {
        "avg_logprob": -0.24959615758947423,
        "compression_ratio": 1.2885906040268456,
        "end": 7449.36,
        "id": 2167,
        "no_speech_prob": 0.006097239442169666,
        "seek": 743536,
        "start": 7447.36,
        "temperature": 0,
        "text": " Look at the chat.",
        "tokens": [
          50964,
          2053,
          412,
          264,
          5081,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.24959615758947423,
        "compression_ratio": 1.2885906040268456,
        "end": 7451.36,
        "id": 2168,
        "no_speech_prob": 0.006097239442169666,
        "seek": 743536,
        "start": 7449.36,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          51064,
          6962,
          322,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.24959615758947423,
        "compression_ratio": 1.2885906040268456,
        "end": 7453.36,
        "id": 2169,
        "no_speech_prob": 0.006097239442169666,
        "seek": 743536,
        "start": 7451.36,
        "temperature": 0,
        "text": " Tab.",
        "tokens": [
          51164,
          14106,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.24959615758947423,
        "compression_ratio": 1.2885906040268456,
        "end": 7459.36,
        "id": 2170,
        "no_speech_prob": 0.006097239442169666,
        "seek": 743536,
        "start": 7457.36,
        "temperature": 0,
        "text": " Oh, GitHub is rendering a six-space tab.",
        "tokens": [
          51464,
          876,
          11,
          23331,
          307,
          22407,
          257,
          2309,
          12,
          24824,
          4421,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.24959615758947423,
        "compression_ratio": 1.2885906040268456,
        "end": 7461.36,
        "id": 2171,
        "no_speech_prob": 0.006097239442169666,
        "seek": 743536,
        "start": 7459.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51564,
          1033,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.24959615758947423,
        "compression_ratio": 1.2885906040268456,
        "end": 7463.36,
        "id": 2172,
        "no_speech_prob": 0.006097239442169666,
        "seek": 743536,
        "start": 7461.36,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          51664,
          6962,
          322,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2318240483601888,
        "compression_ratio": 1.2,
        "end": 7465.36,
        "id": 2173,
        "no_speech_prob": 0.032580528408288956,
        "seek": 746336,
        "start": 7463.36,
        "temperature": 0,
        "text": " Default two.",
        "tokens": [
          50364,
          9548,
          5107,
          732,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2318240483601888,
        "compression_ratio": 1.2,
        "end": 7467.36,
        "id": 2174,
        "no_speech_prob": 0.032580528408288956,
        "seek": 746336,
        "start": 7465.36,
        "temperature": 0,
        "text": " VS code prettier settings.",
        "tokens": [
          50464,
          25091,
          3089,
          36825,
          6257,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2318240483601888,
        "compression_ratio": 1.2,
        "end": 7473.36,
        "id": 2175,
        "no_speech_prob": 0.032580528408288956,
        "seek": 746336,
        "start": 7471.36,
        "temperature": 0,
        "text": " Let's see.",
        "tokens": [
          50764,
          961,
          311,
          536,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2318240483601888,
        "compression_ratio": 1.2,
        "end": 7475.36,
        "id": 2176,
        "no_speech_prob": 0.032580528408288956,
        "seek": 746336,
        "start": 7473.36,
        "temperature": 0,
        "text": " This.",
        "tokens": [
          50864,
          639,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2318240483601888,
        "compression_ratio": 1.2,
        "end": 7477.36,
        "id": 2177,
        "no_speech_prob": 0.032580528408288956,
        "seek": 746336,
        "start": 7475.36,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          50964,
          1079,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2318240483601888,
        "compression_ratio": 1.2,
        "end": 7479.36,
        "id": 2178,
        "no_speech_prob": 0.032580528408288956,
        "seek": 746336,
        "start": 7477.36,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          51064,
          1079,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2318240483601888,
        "compression_ratio": 1.2,
        "end": 7481.36,
        "id": 2179,
        "no_speech_prob": 0.032580528408288956,
        "seek": 746336,
        "start": 7479.36,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          51164,
          1692,
          321,
          352,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2318240483601888,
        "compression_ratio": 1.2,
        "end": 7483.36,
        "id": 2180,
        "no_speech_prob": 0.032580528408288956,
        "seek": 746336,
        "start": 7481.36,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          51264,
          1692,
          321,
          352,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.28059122855203195,
        "compression_ratio": 1.2164948453608246,
        "end": 7485.36,
        "id": 2181,
        "no_speech_prob": 0.015185104683041573,
        "seek": 748336,
        "start": 7483.36,
        "temperature": 0,
        "text": " This.",
        "tokens": [
          50364,
          639,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.28059122855203195,
        "compression_ratio": 1.2164948453608246,
        "end": 7487.36,
        "id": 2182,
        "no_speech_prob": 0.015185104683041573,
        "seek": 748336,
        "start": 7485.36,
        "temperature": 0,
        "text": " This.",
        "tokens": [
          50464,
          639,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.28059122855203195,
        "compression_ratio": 1.2164948453608246,
        "end": 7493.36,
        "id": 2183,
        "no_speech_prob": 0.015185104683041573,
        "seek": 748336,
        "start": 7491.36,
        "temperature": 0,
        "text": " Prettier.",
        "tokens": [
          50764,
          9739,
          25402,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.28059122855203195,
        "compression_ratio": 1.2164948453608246,
        "end": 7495.36,
        "id": 2184,
        "no_speech_prob": 0.015185104683041573,
        "seek": 748336,
        "start": 7493.36,
        "temperature": 0,
        "text": " Oh, there's all these things here.",
        "tokens": [
          50864,
          876,
          11,
          456,
          311,
          439,
          613,
          721,
          510,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.28059122855203195,
        "compression_ratio": 1.2164948453608246,
        "end": 7497.36,
        "id": 2185,
        "no_speech_prob": 0.015185104683041573,
        "seek": 748336,
        "start": 7495.36,
        "temperature": 0,
        "text": " Great.",
        "tokens": [
          50964,
          3769,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.28059122855203195,
        "compression_ratio": 1.2164948453608246,
        "end": 7499.36,
        "id": 2186,
        "no_speech_prob": 0.015185104683041573,
        "seek": 748336,
        "start": 7497.36,
        "temperature": 0,
        "text": " Prettier tab width.",
        "tokens": [
          51064,
          9739,
          25402,
          4421,
          11402,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.28059122855203195,
        "compression_ratio": 1.2164948453608246,
        "end": 7501.36,
        "id": 2187,
        "no_speech_prob": 0.015185104683041573,
        "seek": 748336,
        "start": 7499.36,
        "temperature": 0,
        "text": " Two.",
        "tokens": [
          51164,
          4453,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.28059122855203195,
        "compression_ratio": 1.2164948453608246,
        "end": 7503.36,
        "id": 2188,
        "no_speech_prob": 0.015185104683041573,
        "seek": 748336,
        "start": 7501.36,
        "temperature": 0,
        "text": " Let's see.",
        "tokens": [
          51264,
          961,
          311,
          536,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.28059122855203195,
        "compression_ratio": 1.2164948453608246,
        "end": 7509.36,
        "id": 2189,
        "no_speech_prob": 0.015185104683041573,
        "seek": 748336,
        "start": 7507.36,
        "temperature": 0,
        "text": " That's nice.",
        "tokens": [
          51564,
          663,
          311,
          1481,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.28059122855203195,
        "compression_ratio": 1.2164948453608246,
        "end": 7511.36,
        "id": 2190,
        "no_speech_prob": 0.015185104683041573,
        "seek": 748336,
        "start": 7509.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51664,
          1033,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2429675875969653,
        "compression_ratio": 1.165137614678899,
        "end": 7513.36,
        "id": 2191,
        "no_speech_prob": 0.002550277393311262,
        "seek": 751136,
        "start": 7511.36,
        "temperature": 0,
        "text": " And then, what was the other thing that I want now?",
        "tokens": [
          50364,
          400,
          550,
          11,
          437,
          390,
          264,
          661,
          551,
          300,
          286,
          528,
          586,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.2429675875969653,
        "compression_ratio": 1.165137614678899,
        "end": 7515.36,
        "id": 2192,
        "no_speech_prob": 0.002550277393311262,
        "seek": 751136,
        "start": 7513.36,
        "temperature": 0,
        "text": " Is...",
        "tokens": [
          50464,
          1119,
          485,
          50564
        ]
      },
      {
        "avg_logprob": -0.2429675875969653,
        "compression_ratio": 1.165137614678899,
        "end": 7517.36,
        "id": 2193,
        "no_speech_prob": 0.002550277393311262,
        "seek": 751136,
        "start": 7515.36,
        "temperature": 0,
        "text": " Oh, hold on.",
        "tokens": [
          50564,
          876,
          11,
          1797,
          322,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2429675875969653,
        "compression_ratio": 1.165137614678899,
        "end": 7519.36,
        "id": 2194,
        "no_speech_prob": 0.002550277393311262,
        "seek": 751136,
        "start": 7517.36,
        "temperature": 0,
        "text": " Prettier spaces.",
        "tokens": [
          50664,
          9739,
          25402,
          7673,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2429675875969653,
        "compression_ratio": 1.165137614678899,
        "end": 7531.36,
        "id": 2195,
        "no_speech_prob": 0.002550277393311262,
        "seek": 751136,
        "start": 7529.36,
        "temperature": 0,
        "text": " Use tabs.",
        "tokens": [
          51264,
          8278,
          20743,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2429675875969653,
        "compression_ratio": 1.165137614678899,
        "end": 7533.36,
        "id": 2196,
        "no_speech_prob": 0.002550277393311262,
        "seek": 751136,
        "start": 7531.36,
        "temperature": 0,
        "text": " That must be...",
        "tokens": [
          51364,
          663,
          1633,
          312,
          485,
          51464
        ]
      },
      {
        "avg_logprob": -0.2429675875969653,
        "compression_ratio": 1.165137614678899,
        "end": 7535.36,
        "id": 2197,
        "no_speech_prob": 0.002550277393311262,
        "seek": 751136,
        "start": 7533.36,
        "temperature": 0,
        "text": " Right.",
        "tokens": [
          51464,
          1779,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2429675875969653,
        "compression_ratio": 1.165137614678899,
        "end": 7539.36,
        "id": 2198,
        "no_speech_prob": 0.002550277393311262,
        "seek": 751136,
        "start": 7537.36,
        "temperature": 0,
        "text": " False.",
        "tokens": [
          51664,
          50040,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19119228200709565,
        "compression_ratio": 1.1203703703703705,
        "end": 7541.36,
        "id": 2199,
        "no_speech_prob": 0.004467377904802561,
        "seek": 753936,
        "start": 7539.36,
        "temperature": 0,
        "text": " That's the default value.",
        "tokens": [
          50364,
          663,
          311,
          264,
          7576,
          2158,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.19119228200709565,
        "compression_ratio": 1.1203703703703705,
        "end": 7549.36,
        "id": 2200,
        "no_speech_prob": 0.004467377904802561,
        "seek": 753936,
        "start": 7547.36,
        "temperature": 0,
        "text": " This is very important, what I'm doing right now.",
        "tokens": [
          50764,
          639,
          307,
          588,
          1021,
          11,
          437,
          286,
          478,
          884,
          558,
          586,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19119228200709565,
        "compression_ratio": 1.1203703703703705,
        "end": 7551.36,
        "id": 2201,
        "no_speech_prob": 0.004467377904802561,
        "seek": 753936,
        "start": 7549.36,
        "temperature": 0,
        "text": " No!",
        "tokens": [
          50864,
          883,
          0,
          50964
        ]
      },
      {
        "avg_logprob": -0.19119228200709565,
        "compression_ratio": 1.1203703703703705,
        "end": 7553.36,
        "id": 2202,
        "no_speech_prob": 0.004467377904802561,
        "seek": 753936,
        "start": 7551.36,
        "temperature": 0,
        "text": " Wait.",
        "tokens": [
          50964,
          3802,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19119228200709565,
        "compression_ratio": 1.1203703703703705,
        "end": 7561.36,
        "id": 2203,
        "no_speech_prob": 0.004467377904802561,
        "seek": 753936,
        "start": 7559.36,
        "temperature": 0,
        "text": " Why?",
        "tokens": [
          51364,
          1545,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.19119228200709565,
        "compression_ratio": 1.1203703703703705,
        "end": 7563.36,
        "id": 2204,
        "no_speech_prob": 0.004467377904802561,
        "seek": 753936,
        "start": 7561.36,
        "temperature": 0,
        "text": " Why is this one...",
        "tokens": [
          51464,
          1545,
          307,
          341,
          472,
          485,
          51564
        ]
      },
      {
        "avg_logprob": -0.19119228200709565,
        "compression_ratio": 1.1203703703703705,
        "end": 7565.36,
        "id": 2205,
        "no_speech_prob": 0.004467377904802561,
        "seek": 753936,
        "start": 7563.36,
        "temperature": 0,
        "text": " Still tabs?",
        "tokens": [
          51564,
          8291,
          20743,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.2609647244823222,
        "compression_ratio": 1.2924528301886793,
        "end": 7571.36,
        "id": 2206,
        "no_speech_prob": 0.0041982028633356094,
        "seek": 756936,
        "start": 7569.36,
        "temperature": 0,
        "text": " Why is this one tabs?",
        "tokens": [
          50364,
          1545,
          307,
          341,
          472,
          20743,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.2609647244823222,
        "compression_ratio": 1.2924528301886793,
        "end": 7573.36,
        "id": 2207,
        "no_speech_prob": 0.0041982028633356094,
        "seek": 756936,
        "start": 7571.36,
        "temperature": 0,
        "text": " What have I done?",
        "tokens": [
          50464,
          708,
          362,
          286,
          1096,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.2609647244823222,
        "compression_ratio": 1.2924528301886793,
        "end": 7575.36,
        "id": 2208,
        "no_speech_prob": 0.0041982028633356094,
        "seek": 756936,
        "start": 7573.36,
        "temperature": 0,
        "text": " What have I done to deserve this?",
        "tokens": [
          50564,
          708,
          362,
          286,
          1096,
          281,
          9948,
          341,
          30,
          50664
        ]
      },
      {
        "avg_logprob": -0.2609647244823222,
        "compression_ratio": 1.2924528301886793,
        "end": 7577.36,
        "id": 2209,
        "no_speech_prob": 0.0041982028633356094,
        "seek": 756936,
        "start": 7575.36,
        "temperature": 0,
        "text": " Insert spaces when pressing tab.",
        "tokens": [
          50664,
          36487,
          7673,
          562,
          12417,
          4421,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2609647244823222,
        "compression_ratio": 1.2924528301886793,
        "end": 7583.36,
        "id": 2210,
        "no_speech_prob": 0.0041982028633356094,
        "seek": 756936,
        "start": 7581.36,
        "temperature": 0,
        "text": " Text editor.",
        "tokens": [
          50964,
          18643,
          9839,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2609647244823222,
        "compression_ratio": 1.2924528301886793,
        "end": 7585.36,
        "id": 2211,
        "no_speech_prob": 0.0041982028633356094,
        "seek": 756936,
        "start": 7583.36,
        "temperature": 0,
        "text": " Auto indent.",
        "tokens": [
          51064,
          13738,
          44494,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2609647244823222,
        "compression_ratio": 1.2924528301886793,
        "end": 7587.36,
        "id": 2212,
        "no_speech_prob": 0.0041982028633356094,
        "seek": 756936,
        "start": 7585.36,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          51164,
          1079,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1719211599101191,
        "compression_ratio": 1.1222222222222222,
        "end": 7589.36,
        "id": 2213,
        "no_speech_prob": 0.011684241704642773,
        "seek": 758736,
        "start": 7587.36,
        "temperature": 0,
        "text": " Auto indent.",
        "tokens": [
          50364,
          13738,
          44494,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1719211599101191,
        "compression_ratio": 1.1222222222222222,
        "end": 7591.36,
        "id": 2214,
        "no_speech_prob": 0.011684241704642773,
        "seek": 758736,
        "start": 7589.36,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          50464,
          1079,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1719211599101191,
        "compression_ratio": 1.1222222222222222,
        "end": 7603.36,
        "id": 2215,
        "no_speech_prob": 0.011684241704642773,
        "seek": 758736,
        "start": 7601.36,
        "temperature": 0,
        "text": " Ah.",
        "tokens": [
          51064,
          2438,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1719211599101191,
        "compression_ratio": 1.1222222222222222,
        "end": 7605.36,
        "id": 2216,
        "no_speech_prob": 0.011684241704642773,
        "seek": 758736,
        "start": 7603.36,
        "temperature": 0,
        "text": " I don't ever want to use tabs.",
        "tokens": [
          51164,
          286,
          500,
          380,
          1562,
          528,
          281,
          764,
          20743,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1719211599101191,
        "compression_ratio": 1.1222222222222222,
        "end": 7607.36,
        "id": 2217,
        "no_speech_prob": 0.011684241704642773,
        "seek": 758736,
        "start": 7605.36,
        "temperature": 0,
        "text": " Let's try that.",
        "tokens": [
          51264,
          961,
          311,
          853,
          300,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1719211599101191,
        "compression_ratio": 1.1222222222222222,
        "end": 7613.36,
        "id": 2218,
        "no_speech_prob": 0.011684241704642773,
        "seek": 758736,
        "start": 7611.36,
        "temperature": 0,
        "text": " No.",
        "tokens": [
          51564,
          883,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1719211599101191,
        "compression_ratio": 1.1222222222222222,
        "end": 7615.36,
        "id": 2219,
        "no_speech_prob": 0.011684241704642773,
        "seek": 758736,
        "start": 7613.36,
        "temperature": 0,
        "text": " It's not even formatting it.",
        "tokens": [
          51664,
          467,
          311,
          406,
          754,
          39366,
          309,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20558307788990163,
        "compression_ratio": 1.183673469387755,
        "end": 7617.36,
        "id": 2220,
        "no_speech_prob": 0.003429401433095336,
        "seek": 761536,
        "start": 7615.36,
        "temperature": 0,
        "text": " Huh.",
        "tokens": [
          50364,
          8063,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.20558307788990163,
        "compression_ratio": 1.183673469387755,
        "end": 7619.36,
        "id": 2221,
        "no_speech_prob": 0.003429401433095336,
        "seek": 761536,
        "start": 7617.36,
        "temperature": 0,
        "text": " Uh.",
        "tokens": [
          50464,
          4019,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.20558307788990163,
        "compression_ratio": 1.183673469387755,
        "end": 7621.36,
        "id": 2222,
        "no_speech_prob": 0.003429401433095336,
        "seek": 761536,
        "start": 7619.36,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          50564,
          6962,
          322,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20558307788990163,
        "compression_ratio": 1.183673469387755,
        "end": 7625.36,
        "id": 2223,
        "no_speech_prob": 0.003429401433095336,
        "seek": 761536,
        "start": 7623.36,
        "temperature": 0,
        "text": " Why is this...",
        "tokens": [
          50764,
          1545,
          307,
          341,
          485,
          50864
        ]
      },
      {
        "avg_logprob": -0.20558307788990163,
        "compression_ratio": 1.183673469387755,
        "end": 7627.36,
        "id": 2224,
        "no_speech_prob": 0.003429401433095336,
        "seek": 761536,
        "start": 7625.36,
        "temperature": 0,
        "text": " Why have I lost my format on save?",
        "tokens": [
          50864,
          1545,
          362,
          286,
          2731,
          452,
          7877,
          322,
          3155,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.20558307788990163,
        "compression_ratio": 1.183673469387755,
        "end": 7637.36,
        "id": 2225,
        "no_speech_prob": 0.003429401433095336,
        "seek": 761536,
        "start": 7635.36,
        "temperature": 0,
        "text": " Format on save.",
        "tokens": [
          51364,
          10126,
          267,
          322,
          3155,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20558307788990163,
        "compression_ratio": 1.183673469387755,
        "end": 7639.36,
        "id": 2226,
        "no_speech_prob": 0.003429401433095336,
        "seek": 761536,
        "start": 7637.36,
        "temperature": 0,
        "text": " True.",
        "tokens": [
          51464,
          13587,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20558307788990163,
        "compression_ratio": 1.183673469387755,
        "end": 7641.36,
        "id": 2227,
        "no_speech_prob": 0.003429401433095336,
        "seek": 761536,
        "start": 7639.36,
        "temperature": 0,
        "text": " Detect indentation.",
        "tokens": [
          51564,
          4237,
          557,
          44494,
          399,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20558307788990163,
        "compression_ratio": 1.183673469387755,
        "end": 7643.36,
        "id": 2228,
        "no_speech_prob": 0.003429401433095336,
        "seek": 761536,
        "start": 7641.36,
        "temperature": 0,
        "text": " False.",
        "tokens": [
          51664,
          50040,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.16936605116900275,
        "compression_ratio": 1.2058823529411764,
        "end": 7645.36,
        "id": 2229,
        "no_speech_prob": 0.002630985574796796,
        "seek": 764336,
        "start": 7643.36,
        "temperature": 0,
        "text": " Um.",
        "tokens": [
          50364,
          3301,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.16936605116900275,
        "compression_ratio": 1.2058823529411764,
        "end": 7647.36,
        "id": 2230,
        "no_speech_prob": 0.002630985574796796,
        "seek": 764336,
        "start": 7645.36,
        "temperature": 0,
        "text": " Huh.",
        "tokens": [
          50464,
          8063,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.16936605116900275,
        "compression_ratio": 1.2058823529411764,
        "end": 7653.36,
        "id": 2231,
        "no_speech_prob": 0.002630985574796796,
        "seek": 764336,
        "start": 7651.36,
        "temperature": 0,
        "text": " Restart prettier.",
        "tokens": [
          50764,
          13094,
          446,
          36825,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.16936605116900275,
        "compression_ratio": 1.2058823529411764,
        "end": 7655.36,
        "id": 2232,
        "no_speech_prob": 0.002630985574796796,
        "seek": 764336,
        "start": 7653.36,
        "temperature": 0,
        "text": " That's a good idea.",
        "tokens": [
          50864,
          663,
          311,
          257,
          665,
          1558,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.16936605116900275,
        "compression_ratio": 1.2058823529411764,
        "end": 7657.36,
        "id": 2233,
        "no_speech_prob": 0.002630985574796796,
        "seek": 764336,
        "start": 7655.36,
        "temperature": 0,
        "text": " Let's just restart the whole thing.",
        "tokens": [
          50964,
          961,
          311,
          445,
          21022,
          264,
          1379,
          551,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.16936605116900275,
        "compression_ratio": 1.2058823529411764,
        "end": 7667.36,
        "id": 2234,
        "no_speech_prob": 0.002630985574796796,
        "seek": 764336,
        "start": 7665.36,
        "temperature": 0,
        "text": " Weird.",
        "tokens": [
          51464,
          32033,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.16936605116900275,
        "compression_ratio": 1.2058823529411764,
        "end": 7669.36,
        "id": 2235,
        "no_speech_prob": 0.002630985574796796,
        "seek": 764336,
        "start": 7667.36,
        "temperature": 0,
        "text": " Let's go to extensions.",
        "tokens": [
          51564,
          961,
          311,
          352,
          281,
          25129,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.16936605116900275,
        "compression_ratio": 1.2058823529411764,
        "end": 7671.36,
        "id": 2236,
        "no_speech_prob": 0.002630985574796796,
        "seek": 764336,
        "start": 7669.36,
        "temperature": 0,
        "text": " Prettier.",
        "tokens": [
          51664,
          9739,
          25402,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.40223795572916665,
        "compression_ratio": 0.9833333333333333,
        "end": 7673.36,
        "id": 2237,
        "no_speech_prob": 0.016764124855399132,
        "seek": 767136,
        "start": 7671.36,
        "temperature": 0,
        "text": " No.",
        "tokens": [
          50364,
          883,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.40223795572916665,
        "compression_ratio": 0.9833333333333333,
        "end": 7675.36,
        "id": 2238,
        "no_speech_prob": 0.016764124855399132,
        "seek": 767136,
        "start": 7673.36,
        "temperature": 0,
        "text": " Uh.",
        "tokens": [
          50464,
          4019,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.40223795572916665,
        "compression_ratio": 0.9833333333333333,
        "end": 7677.36,
        "id": 2239,
        "no_speech_prob": 0.016764124855399132,
        "seek": 767136,
        "start": 7675.36,
        "temperature": 0,
        "text": " I'm going to try to re-format that.",
        "tokens": [
          50564,
          286,
          478,
          516,
          281,
          853,
          281,
          319,
          12,
          837,
          267,
          300,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.40223795572916665,
        "compression_ratio": 0.9833333333333333,
        "end": 7679.36,
        "id": 2240,
        "no_speech_prob": 0.016764124855399132,
        "seek": 767136,
        "start": 7677.36,
        "temperature": 0,
        "text": " Let's try this.",
        "tokens": [
          50664,
          961,
          311,
          853,
          341,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.3692055293491909,
        "compression_ratio": 0.961038961038961,
        "end": 7703.36,
        "id": 2241,
        "no_speech_prob": 0.08147426694631577,
        "seek": 770136,
        "start": 7701.36,
        "temperature": 0.2,
        "text": " Oh.",
        "tokens": [
          50364,
          876,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.3692055293491909,
        "compression_ratio": 0.961038961038961,
        "end": 7705.36,
        "id": 2242,
        "no_speech_prob": 0.08147426694631577,
        "seek": 770136,
        "start": 7703.36,
        "temperature": 0.2,
        "text": " It's not formatting on save.",
        "tokens": [
          50464,
          467,
          311,
          406,
          39366,
          322,
          3155,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.3692055293491909,
        "compression_ratio": 0.961038961038961,
        "end": 7715.36,
        "id": 2243,
        "no_speech_prob": 0.08147426694631577,
        "seek": 770136,
        "start": 7713.36,
        "temperature": 0.2,
        "text": " Now it is.",
        "tokens": [
          50964,
          823,
          309,
          307,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.3692055293491909,
        "compression_ratio": 0.961038961038961,
        "end": 7717.36,
        "id": 2244,
        "no_speech_prob": 0.08147426694631577,
        "seek": 770136,
        "start": 7715.36,
        "temperature": 0.2,
        "text": " I don't need this, though.",
        "tokens": [
          51064,
          286,
          500,
          380,
          643,
          341,
          11,
          1673,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.3692055293491909,
        "compression_ratio": 0.961038961038961,
        "end": 7729.36,
        "id": 2245,
        "no_speech_prob": 0.08147426694631577,
        "seek": 770136,
        "start": 7727.36,
        "temperature": 0.2,
        "text": " Uh.",
        "tokens": [
          51664,
          4019,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.22572744914463588,
        "compression_ratio": 1.0410958904109588,
        "end": 7731.36,
        "id": 2246,
        "no_speech_prob": 0.007118393667042255,
        "seek": 772936,
        "start": 7729.36,
        "temperature": 0,
        "text": " Uh.",
        "tokens": [
          50364,
          4019,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.22572744914463588,
        "compression_ratio": 1.0410958904109588,
        "end": 7741.36,
        "id": 2247,
        "no_speech_prob": 0.007118393667042255,
        "seek": 772936,
        "start": 7739.36,
        "temperature": 0,
        "text": " I saved it as a new file,",
        "tokens": [
          50864,
          286,
          6624,
          309,
          382,
          257,
          777,
          3991,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.22572744914463588,
        "compression_ratio": 1.0410958904109588,
        "end": 7743.36,
        "id": 2248,
        "no_speech_prob": 0.007118393667042255,
        "seek": 772936,
        "start": 7741.36,
        "temperature": 0,
        "text": " and it reformatted it.",
        "tokens": [
          50964,
          293,
          309,
          8290,
          32509,
          309,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.22572744914463588,
        "compression_ratio": 1.0410958904109588,
        "end": 7749.36,
        "id": 2249,
        "no_speech_prob": 0.007118393667042255,
        "seek": 772936,
        "start": 7747.36,
        "temperature": 0,
        "text": " Weird.",
        "tokens": [
          51264,
          32033,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.22572744914463588,
        "compression_ratio": 1.0410958904109588,
        "end": 7757.36,
        "id": 2250,
        "no_speech_prob": 0.007118393667042255,
        "seek": 772936,
        "start": 7755.36,
        "temperature": 0,
        "text": " There. Fixed it.",
        "tokens": [
          51664,
          821,
          13,
          25538,
          292,
          309,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1720179896200857,
        "compression_ratio": 1.5353535353535352,
        "end": 7761.36,
        "id": 2251,
        "no_speech_prob": 0.0335475355386734,
        "seek": 775936,
        "start": 7759.36,
        "temperature": 0,
        "text": " This is fine.",
        "tokens": [
          50364,
          639,
          307,
          2489,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1720179896200857,
        "compression_ratio": 1.5353535353535352,
        "end": 7763.36,
        "id": 2252,
        "no_speech_prob": 0.0335475355386734,
        "seek": 775936,
        "start": 7761.36,
        "temperature": 0,
        "text": " This is fine.",
        "tokens": [
          50464,
          639,
          307,
          2489,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1720179896200857,
        "compression_ratio": 1.5353535353535352,
        "end": 7765.36,
        "id": 2253,
        "no_speech_prob": 0.0335475355386734,
        "seek": 775936,
        "start": 7763.36,
        "temperature": 0,
        "text": " And this is fine.",
        "tokens": [
          50564,
          400,
          341,
          307,
          2489,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1720179896200857,
        "compression_ratio": 1.5353535353535352,
        "end": 7767.36,
        "id": 2254,
        "no_speech_prob": 0.0335475355386734,
        "seek": 775936,
        "start": 7765.36,
        "temperature": 0,
        "text": " I don't know what was wrong with that one file.",
        "tokens": [
          50664,
          286,
          500,
          380,
          458,
          437,
          390,
          2085,
          365,
          300,
          472,
          3991,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1720179896200857,
        "compression_ratio": 1.5353535353535352,
        "end": 7769.36,
        "id": 2255,
        "no_speech_prob": 0.0335475355386734,
        "seek": 775936,
        "start": 7767.36,
        "temperature": 0,
        "text": " This is spaces.",
        "tokens": [
          50764,
          639,
          307,
          7673,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1720179896200857,
        "compression_ratio": 1.5353535353535352,
        "end": 7771.36,
        "id": 2256,
        "no_speech_prob": 0.0335475355386734,
        "seek": 775936,
        "start": 7769.36,
        "temperature": 0,
        "text": " This is spaces.",
        "tokens": [
          50864,
          639,
          307,
          7673,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1720179896200857,
        "compression_ratio": 1.5353535353535352,
        "end": 7773.36,
        "id": 2257,
        "no_speech_prob": 0.0335475355386734,
        "seek": 775936,
        "start": 7771.36,
        "temperature": 0,
        "text": " Um.",
        "tokens": [
          50964,
          3301,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1720179896200857,
        "compression_ratio": 1.5353535353535352,
        "end": 7775.36,
        "id": 2258,
        "no_speech_prob": 0.0335475355386734,
        "seek": 775936,
        "start": 7773.36,
        "temperature": 0,
        "text": " And.",
        "tokens": [
          51064,
          400,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1720179896200857,
        "compression_ratio": 1.5353535353535352,
        "end": 7785.36,
        "id": 2259,
        "no_speech_prob": 0.0335475355386734,
        "seek": 775936,
        "start": 7783.36,
        "temperature": 0,
        "text": " Spaces, not tabs.",
        "tokens": [
          51564,
          1738,
          2116,
          11,
          406,
          20743,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.28682892743278954,
        "compression_ratio": 1.368421052631579,
        "end": 7791.36,
        "id": 2260,
        "no_speech_prob": 0.054180603474378586,
        "seek": 778936,
        "start": 7789.36,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          50364,
          876,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.28682892743278954,
        "compression_ratio": 1.368421052631579,
        "end": 7793.36,
        "id": 2261,
        "no_speech_prob": 0.054180603474378586,
        "seek": 778936,
        "start": 7791.36,
        "temperature": 0,
        "text": " That was scary.",
        "tokens": [
          50464,
          663,
          390,
          6958,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.28682892743278954,
        "compression_ratio": 1.368421052631579,
        "end": 7795.36,
        "id": 2262,
        "no_speech_prob": 0.054180603474378586,
        "seek": 778936,
        "start": 7793.36,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          50564,
          876,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.28682892743278954,
        "compression_ratio": 1.368421052631579,
        "end": 7797.36,
        "id": 2263,
        "no_speech_prob": 0.054180603474378586,
        "seek": 778936,
        "start": 7795.36,
        "temperature": 0,
        "text": " But my quick draw stuff.",
        "tokens": [
          50664,
          583,
          452,
          1702,
          2642,
          1507,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.28682892743278954,
        "compression_ratio": 1.368421052631579,
        "end": 7799.36,
        "id": 2264,
        "no_speech_prob": 0.054180603474378586,
        "seek": 778936,
        "start": 7797.36,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          50764,
          876,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.28682892743278954,
        "compression_ratio": 1.368421052631579,
        "end": 7801.36,
        "id": 2265,
        "no_speech_prob": 0.054180603474378586,
        "seek": 778936,
        "start": 7799.36,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          50864,
          6962,
          322,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.28682892743278954,
        "compression_ratio": 1.368421052631579,
        "end": 7803.36,
        "id": 2266,
        "no_speech_prob": 0.054180603474378586,
        "seek": 778936,
        "start": 7801.36,
        "temperature": 0,
        "text": " Pull requests.",
        "tokens": [
          50964,
          15074,
          12475,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.28682892743278954,
        "compression_ratio": 1.368421052631579,
        "end": 7805.36,
        "id": 2267,
        "no_speech_prob": 0.054180603474378586,
        "seek": 778936,
        "start": 7803.36,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          51064,
          876,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.28682892743278954,
        "compression_ratio": 1.368421052631579,
        "end": 7807.36,
        "id": 2268,
        "no_speech_prob": 0.054180603474378586,
        "seek": 778936,
        "start": 7805.36,
        "temperature": 0,
        "text": " I didn't actually make the pull request.",
        "tokens": [
          51164,
          286,
          994,
          380,
          767,
          652,
          264,
          2235,
          5308,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.28682892743278954,
        "compression_ratio": 1.368421052631579,
        "end": 7809.36,
        "id": 2269,
        "no_speech_prob": 0.054180603474378586,
        "seek": 778936,
        "start": 7807.36,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          51264,
          6962,
          322,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.28682892743278954,
        "compression_ratio": 1.368421052631579,
        "end": 7811.36,
        "id": 2270,
        "no_speech_prob": 0.054180603474378586,
        "seek": 778936,
        "start": 7809.36,
        "temperature": 0,
        "text": " Now.",
        "tokens": [
          51364,
          823,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.28682892743278954,
        "compression_ratio": 1.368421052631579,
        "end": 7813.36,
        "id": 2271,
        "no_speech_prob": 0.054180603474378586,
        "seek": 778936,
        "start": 7811.36,
        "temperature": 0,
        "text": " Everybody just relax.",
        "tokens": [
          51464,
          7646,
          445,
          5789,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.28682892743278954,
        "compression_ratio": 1.368421052631579,
        "end": 7815.36,
        "id": 2272,
        "no_speech_prob": 0.054180603474378586,
        "seek": 778936,
        "start": 7813.36,
        "temperature": 0,
        "text": " I can't believe how much time.",
        "tokens": [
          51564,
          286,
          393,
          380,
          1697,
          577,
          709,
          565,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.28682892743278954,
        "compression_ratio": 1.368421052631579,
        "end": 7817.36,
        "id": 2273,
        "no_speech_prob": 0.054180603474378586,
        "seek": 778936,
        "start": 7815.36,
        "temperature": 0,
        "text": " What was it called?",
        "tokens": [
          51664,
          708,
          390,
          309,
          1219,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.2592125203874376,
        "compression_ratio": 1.3014705882352942,
        "end": 7819.36,
        "id": 2274,
        "no_speech_prob": 0.011157631874084473,
        "seek": 781736,
        "start": 7817.36,
        "temperature": 0,
        "text": " Wait.",
        "tokens": [
          50364,
          3802,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2592125203874376,
        "compression_ratio": 1.3014705882352942,
        "end": 7821.36,
        "id": 2275,
        "no_speech_prob": 0.011157631874084473,
        "seek": 781736,
        "start": 7819.36,
        "temperature": 0,
        "text": " Where is my quick draw?",
        "tokens": [
          50464,
          2305,
          307,
          452,
          1702,
          2642,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.2592125203874376,
        "compression_ratio": 1.3014705882352942,
        "end": 7825.36,
        "id": 2276,
        "no_speech_prob": 0.011157631874084473,
        "seek": 781736,
        "start": 7823.36,
        "temperature": 0,
        "text": " We go to this branch.",
        "tokens": [
          50664,
          492,
          352,
          281,
          341,
          9819,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2592125203874376,
        "compression_ratio": 1.3014705882352942,
        "end": 7827.36,
        "id": 2277,
        "no_speech_prob": 0.011157631874084473,
        "seek": 781736,
        "start": 7825.36,
        "temperature": 0,
        "text": " And then here.",
        "tokens": [
          50764,
          400,
          550,
          510,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2592125203874376,
        "compression_ratio": 1.3014705882352942,
        "end": 7829.36,
        "id": 2278,
        "no_speech_prob": 0.011157631874084473,
        "seek": 781736,
        "start": 7827.36,
        "temperature": 0,
        "text": " That's spaces.",
        "tokens": [
          50864,
          663,
          311,
          7673,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2592125203874376,
        "compression_ratio": 1.3014705882352942,
        "end": 7831.36,
        "id": 2279,
        "no_speech_prob": 0.011157631874084473,
        "seek": 781736,
        "start": 7829.36,
        "temperature": 0,
        "text": " Tabs.",
        "tokens": [
          50964,
          14106,
          82,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2592125203874376,
        "compression_ratio": 1.3014705882352942,
        "end": 7833.36,
        "id": 2280,
        "no_speech_prob": 0.011157631874084473,
        "seek": 781736,
        "start": 7831.36,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          51064,
          876,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2592125203874376,
        "compression_ratio": 1.3014705882352942,
        "end": 7835.36,
        "id": 2281,
        "no_speech_prob": 0.011157631874084473,
        "seek": 781736,
        "start": 7833.36,
        "temperature": 0,
        "text": " This file, too.",
        "tokens": [
          51164,
          639,
          3991,
          11,
          886,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2592125203874376,
        "compression_ratio": 1.3014705882352942,
        "end": 7837.36,
        "id": 2282,
        "no_speech_prob": 0.011157631874084473,
        "seek": 781736,
        "start": 7835.36,
        "temperature": 0,
        "text": " What is it with the files?",
        "tokens": [
          51264,
          708,
          307,
          309,
          365,
          264,
          7098,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.2592125203874376,
        "compression_ratio": 1.3014705882352942,
        "end": 7839.36,
        "id": 2283,
        "no_speech_prob": 0.011157631874084473,
        "seek": 781736,
        "start": 7837.36,
        "temperature": 0,
        "text": " What if I manually.",
        "tokens": [
          51364,
          708,
          498,
          286,
          16945,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2592125203874376,
        "compression_ratio": 1.3014705882352942,
        "end": 7841.36,
        "id": 2284,
        "no_speech_prob": 0.011157631874084473,
        "seek": 781736,
        "start": 7839.36,
        "temperature": 0,
        "text": " Why are certain files.",
        "tokens": [
          51464,
          1545,
          366,
          1629,
          7098,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.17724474464974752,
        "compression_ratio": 1.4803149606299213,
        "end": 7849.36,
        "id": 2285,
        "no_speech_prob": 0.020644450560212135,
        "seek": 784736,
        "start": 7847.36,
        "temperature": 0,
        "text": " Not formatting.",
        "tokens": [
          50364,
          1726,
          39366,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.17724474464974752,
        "compression_ratio": 1.4803149606299213,
        "end": 7851.36,
        "id": 2286,
        "no_speech_prob": 0.020644450560212135,
        "seek": 784736,
        "start": 7849.36,
        "temperature": 0,
        "text": " That's so weird.",
        "tokens": [
          50464,
          663,
          311,
          370,
          3657,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.17724474464974752,
        "compression_ratio": 1.4803149606299213,
        "end": 7853.36,
        "id": 2287,
        "no_speech_prob": 0.020644450560212135,
        "seek": 784736,
        "start": 7851.36,
        "temperature": 0,
        "text": " I've never seen this.",
        "tokens": [
          50564,
          286,
          600,
          1128,
          1612,
          341,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17724474464974752,
        "compression_ratio": 1.4803149606299213,
        "end": 7855.36,
        "id": 2288,
        "no_speech_prob": 0.020644450560212135,
        "seek": 784736,
        "start": 7853.36,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          50664,
          45263,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.17724474464974752,
        "compression_ratio": 1.4803149606299213,
        "end": 7857.36,
        "id": 2289,
        "no_speech_prob": 0.020644450560212135,
        "seek": 784736,
        "start": 7855.36,
        "temperature": 0,
        "text": " Format.",
        "tokens": [
          50764,
          10126,
          267,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.17724474464974752,
        "compression_ratio": 1.4803149606299213,
        "end": 7859.36,
        "id": 2290,
        "no_speech_prob": 0.020644450560212135,
        "seek": 784736,
        "start": 7857.36,
        "temperature": 0,
        "text": " Document.",
        "tokens": [
          50864,
          37684,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.17724474464974752,
        "compression_ratio": 1.4803149606299213,
        "end": 7861.36,
        "id": 2291,
        "no_speech_prob": 0.020644450560212135,
        "seek": 784736,
        "start": 7859.36,
        "temperature": 0,
        "text": " Format.",
        "tokens": [
          50964,
          10126,
          267,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17724474464974752,
        "compression_ratio": 1.4803149606299213,
        "end": 7863.36,
        "id": 2292,
        "no_speech_prob": 0.020644450560212135,
        "seek": 784736,
        "start": 7861.36,
        "temperature": 0,
        "text": " Format selection.",
        "tokens": [
          51064,
          10126,
          267,
          9450,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.17724474464974752,
        "compression_ratio": 1.4803149606299213,
        "end": 7865.36,
        "id": 2293,
        "no_speech_prob": 0.020644450560212135,
        "seek": 784736,
        "start": 7863.36,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          51164,
          45263,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.17724474464974752,
        "compression_ratio": 1.4803149606299213,
        "end": 7867.36,
        "id": 2294,
        "no_speech_prob": 0.020644450560212135,
        "seek": 784736,
        "start": 7865.36,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          51264,
          876,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.17724474464974752,
        "compression_ratio": 1.4803149606299213,
        "end": 7869.36,
        "id": 2295,
        "no_speech_prob": 0.020644450560212135,
        "seek": 784736,
        "start": 7867.36,
        "temperature": 0,
        "text": " That did it.",
        "tokens": [
          51364,
          663,
          630,
          309,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.17724474464974752,
        "compression_ratio": 1.4803149606299213,
        "end": 7871.36,
        "id": 2296,
        "no_speech_prob": 0.020644450560212135,
        "seek": 784736,
        "start": 7869.36,
        "temperature": 0,
        "text": " Format selection did it.",
        "tokens": [
          51464,
          10126,
          267,
          9450,
          630,
          309,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.17724474464974752,
        "compression_ratio": 1.4803149606299213,
        "end": 7873.36,
        "id": 2297,
        "no_speech_prob": 0.020644450560212135,
        "seek": 784736,
        "start": 7871.36,
        "temperature": 0,
        "text": " I can't explain it.",
        "tokens": [
          51564,
          286,
          393,
          380,
          2903,
          309,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17724474464974752,
        "compression_ratio": 1.4803149606299213,
        "end": 7875.36,
        "id": 2298,
        "no_speech_prob": 0.020644450560212135,
        "seek": 784736,
        "start": 7873.36,
        "temperature": 0,
        "text": " Where am I?",
        "tokens": [
          51664,
          2305,
          669,
          286,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.18738329687783883,
        "compression_ratio": 1.3866666666666667,
        "end": 7877.36,
        "id": 2299,
        "no_speech_prob": 0.06007789447903633,
        "seek": 787536,
        "start": 7875.36,
        "temperature": 0,
        "text": " Format selection did it.",
        "tokens": [
          50364,
          10126,
          267,
          9450,
          630,
          309,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.18738329687783883,
        "compression_ratio": 1.3866666666666667,
        "end": 7879.36,
        "id": 2300,
        "no_speech_prob": 0.06007789447903633,
        "seek": 787536,
        "start": 7877.36,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          50464,
          1779,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.18738329687783883,
        "compression_ratio": 1.3866666666666667,
        "end": 7881.36,
        "id": 2301,
        "no_speech_prob": 0.06007789447903633,
        "seek": 787536,
        "start": 7879.36,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          50564,
          865,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.18738329687783883,
        "compression_ratio": 1.3866666666666667,
        "end": 7883.36,
        "id": 2302,
        "no_speech_prob": 0.06007789447903633,
        "seek": 787536,
        "start": 7881.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50664,
          1033,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.18738329687783883,
        "compression_ratio": 1.3866666666666667,
        "end": 7885.36,
        "id": 2303,
        "no_speech_prob": 0.06007789447903633,
        "seek": 787536,
        "start": 7883.36,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          50764,
          876,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.18738329687783883,
        "compression_ratio": 1.3866666666666667,
        "end": 7887.36,
        "id": 2304,
        "no_speech_prob": 0.06007789447903633,
        "seek": 787536,
        "start": 7885.36,
        "temperature": 0,
        "text": " It's because of this file.",
        "tokens": [
          50864,
          467,
          311,
          570,
          295,
          341,
          3991,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18738329687783883,
        "compression_ratio": 1.3866666666666667,
        "end": 7889.36,
        "id": 2305,
        "no_speech_prob": 0.06007789447903633,
        "seek": 787536,
        "start": 7887.36,
        "temperature": 0,
        "text": " Maybe.",
        "tokens": [
          50964,
          2704,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.18738329687783883,
        "compression_ratio": 1.3866666666666667,
        "end": 7891.36,
        "id": 2306,
        "no_speech_prob": 0.06007789447903633,
        "seek": 787536,
        "start": 7889.36,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51064,
          865,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.18738329687783883,
        "compression_ratio": 1.3866666666666667,
        "end": 7893.36,
        "id": 2307,
        "no_speech_prob": 0.06007789447903633,
        "seek": 787536,
        "start": 7891.36,
        "temperature": 0,
        "text": " Because I'm in this repo.",
        "tokens": [
          51164,
          1436,
          286,
          478,
          294,
          341,
          49040,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18738329687783883,
        "compression_ratio": 1.3866666666666667,
        "end": 7895.36,
        "id": 2308,
        "no_speech_prob": 0.06007789447903633,
        "seek": 787536,
        "start": 7893.36,
        "temperature": 0,
        "text": " That's probably why.",
        "tokens": [
          51264,
          663,
          311,
          1391,
          983,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18738329687783883,
        "compression_ratio": 1.3866666666666667,
        "end": 7897.36,
        "id": 2309,
        "no_speech_prob": 0.06007789447903633,
        "seek": 787536,
        "start": 7895.36,
        "temperature": 0,
        "text": " It must be like picking up.",
        "tokens": [
          51364,
          467,
          1633,
          312,
          411,
          8867,
          493,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18738329687783883,
        "compression_ratio": 1.3866666666666667,
        "end": 7899.36,
        "id": 2310,
        "no_speech_prob": 0.06007789447903633,
        "seek": 787536,
        "start": 7897.36,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          51464,
          876,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18738329687783883,
        "compression_ratio": 1.3866666666666667,
        "end": 7901.36,
        "id": 2311,
        "no_speech_prob": 0.06007789447903633,
        "seek": 787536,
        "start": 7899.36,
        "temperature": 0,
        "text": " It's picking up settings from here.",
        "tokens": [
          51564,
          467,
          311,
          8867,
          493,
          6257,
          490,
          510,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18738329687783883,
        "compression_ratio": 1.3866666666666667,
        "end": 7903.36,
        "id": 2312,
        "no_speech_prob": 0.06007789447903633,
        "seek": 787536,
        "start": 7901.36,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51664,
          865,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2688592274983724,
        "compression_ratio": 1.28125,
        "end": 7905.36,
        "id": 2313,
        "no_speech_prob": 0.08384312689304352,
        "seek": 790336,
        "start": 7903.36,
        "temperature": 0.4,
        "text": " All right.",
        "tokens": [
          50364,
          1057,
          558,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2688592274983724,
        "compression_ratio": 1.28125,
        "end": 7907.36,
        "id": 2314,
        "no_speech_prob": 0.08384312689304352,
        "seek": 790336,
        "start": 7905.36,
        "temperature": 0.4,
        "text": " That's got to be it.",
        "tokens": [
          50464,
          663,
          311,
          658,
          281,
          312,
          309,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2688592274983724,
        "compression_ratio": 1.28125,
        "end": 7909.36,
        "id": 2315,
        "no_speech_prob": 0.08384312689304352,
        "seek": 790336,
        "start": 7907.36,
        "temperature": 0.4,
        "text": " All right.",
        "tokens": [
          50564,
          1057,
          558,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2688592274983724,
        "compression_ratio": 1.28125,
        "end": 7913.36,
        "id": 2316,
        "no_speech_prob": 0.08384312689304352,
        "seek": 790336,
        "start": 7909.36,
        "temperature": 0.4,
        "text": " I know the camera went off.",
        "tokens": [
          50664,
          286,
          458,
          264,
          2799,
          1437,
          766,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2688592274983724,
        "compression_ratio": 1.28125,
        "end": 7929.36,
        "id": 2317,
        "no_speech_prob": 0.08384312689304352,
        "seek": 790336,
        "start": 7927.36,
        "temperature": 0.4,
        "text": " All right.",
        "tokens": [
          51564,
          1057,
          558,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2688592274983724,
        "compression_ratio": 1.28125,
        "end": 7931.36,
        "id": 2318,
        "no_speech_prob": 0.08384312689304352,
        "seek": 790336,
        "start": 7929.36,
        "temperature": 0.4,
        "text": " Let's finish these pull requests, people.",
        "tokens": [
          51664,
          961,
          311,
          2413,
          613,
          2235,
          12475,
          11,
          561,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.34999734787713915,
        "compression_ratio": 1.6687898089171975,
        "end": 7935.36,
        "id": 2319,
        "no_speech_prob": 0.044008512049913406,
        "seek": 793336,
        "start": 7933.36,
        "temperature": 0,
        "text": " Oh, wait.",
        "tokens": [
          50364,
          876,
          11,
          1699,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.34999734787713915,
        "compression_ratio": 1.6687898089171975,
        "end": 7937.36,
        "id": 2320,
        "no_speech_prob": 0.044008512049913406,
        "seek": 793336,
        "start": 7935.36,
        "temperature": 0,
        "text": " No.",
        "tokens": [
          50464,
          883,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.34999734787713915,
        "compression_ratio": 1.6687898089171975,
        "end": 7939.36,
        "id": 2321,
        "no_speech_prob": 0.044008512049913406,
        "seek": 793336,
        "start": 7937.36,
        "temperature": 0,
        "text": " Let's do the quick draw one first.",
        "tokens": [
          50564,
          961,
          311,
          360,
          264,
          1702,
          2642,
          472,
          700,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.34999734787713915,
        "compression_ratio": 1.6687898089171975,
        "end": 7941.36,
        "id": 2322,
        "no_speech_prob": 0.044008512049913406,
        "seek": 793336,
        "start": 7939.36,
        "temperature": 0,
        "text": " This is the quick draw code for challenge 122.",
        "tokens": [
          50664,
          639,
          307,
          264,
          1702,
          2642,
          3089,
          337,
          3430,
          2272,
          17,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.34999734787713915,
        "compression_ratio": 1.6687898089171975,
        "end": 7943.36,
        "id": 2323,
        "no_speech_prob": 0.044008512049913406,
        "seek": 793336,
        "start": 7941.36,
        "temperature": 0,
        "text": " If we look at this.",
        "tokens": [
          50764,
          759,
          321,
          574,
          412,
          341,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.34999734787713915,
        "compression_ratio": 1.6687898089171975,
        "end": 7945.36,
        "id": 2324,
        "no_speech_prob": 0.044008512049913406,
        "seek": 793336,
        "start": 7943.36,
        "temperature": 0,
        "text": " There.",
        "tokens": [
          50864,
          821,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.34999734787713915,
        "compression_ratio": 1.6687898089171975,
        "end": 7947.36,
        "id": 2325,
        "no_speech_prob": 0.044008512049913406,
        "seek": 793336,
        "start": 7945.36,
        "temperature": 0,
        "text": " Look at this.",
        "tokens": [
          50964,
          2053,
          412,
          341,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.34999734787713915,
        "compression_ratio": 1.6687898089171975,
        "end": 7949.36,
        "id": 2326,
        "no_speech_prob": 0.044008512049913406,
        "seek": 793336,
        "start": 7947.36,
        "temperature": 0,
        "text": " Look at this nice, normally indented code.",
        "tokens": [
          51064,
          2053,
          412,
          341,
          1481,
          11,
          5646,
          1016,
          6003,
          3089,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.34999734787713915,
        "compression_ratio": 1.6687898089171975,
        "end": 7951.36,
        "id": 2327,
        "no_speech_prob": 0.044008512049913406,
        "seek": 793336,
        "start": 7949.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51164,
          1033,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.34999734787713915,
        "compression_ratio": 1.6687898089171975,
        "end": 7953.36,
        "id": 2328,
        "no_speech_prob": 0.044008512049913406,
        "seek": 793336,
        "start": 7951.36,
        "temperature": 0,
        "text": " Now, let me do this.",
        "tokens": [
          51264,
          823,
          11,
          718,
          385,
          360,
          341,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.34999734787713915,
        "compression_ratio": 1.6687898089171975,
        "end": 7955.36,
        "id": 2329,
        "no_speech_prob": 0.044008512049913406,
        "seek": 793336,
        "start": 7953.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51364,
          1057,
          558,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.34999734787713915,
        "compression_ratio": 1.6687898089171975,
        "end": 7957.36,
        "id": 2330,
        "no_speech_prob": 0.044008512049913406,
        "seek": 793336,
        "start": 7955.36,
        "temperature": 0,
        "text": " Let's do this.",
        "tokens": [
          51464,
          961,
          311,
          360,
          341,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.34999734787713915,
        "compression_ratio": 1.6687898089171975,
        "end": 7959.36,
        "id": 2331,
        "no_speech_prob": 0.044008512049913406,
        "seek": 793336,
        "start": 7957.36,
        "temperature": 0,
        "text": " Let's do this.",
        "tokens": [
          51564,
          961,
          311,
          360,
          341,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.34999734787713915,
        "compression_ratio": 1.6687898089171975,
        "end": 7961.36,
        "id": 2332,
        "no_speech_prob": 0.044008512049913406,
        "seek": 793336,
        "start": 7959.36,
        "temperature": 0,
        "text": " Let's do this.",
        "tokens": [
          51664,
          961,
          311,
          360,
          341,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.30920139435798893,
        "compression_ratio": 1.5161290322580645,
        "end": 7963.36,
        "id": 2333,
        "no_speech_prob": 0.05919022858142853,
        "seek": 796136,
        "start": 7961.36,
        "temperature": 0.2,
        "text": " All right.",
        "tokens": [
          50364,
          1057,
          558,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.30920139435798893,
        "compression_ratio": 1.5161290322580645,
        "end": 7965.36,
        "id": 2334,
        "no_speech_prob": 0.05919022858142853,
        "seek": 796136,
        "start": 7963.36,
        "temperature": 0.2,
        "text": " Let's do this.",
        "tokens": [
          50464,
          961,
          311,
          360,
          341,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.30920139435798893,
        "compression_ratio": 1.5161290322580645,
        "end": 7977.36,
        "id": 2335,
        "no_speech_prob": 0.05919022858142853,
        "seek": 796136,
        "start": 7965.36,
        "temperature": 0.2,
        "text": " This moves challenge 121 into 121 underscore one and adds 121 underscore two for the second part of the logo challenge.",
        "tokens": [
          50564,
          639,
          6067,
          3430,
          2272,
          16,
          666,
          2272,
          16,
          37556,
          472,
          293,
          10860,
          2272,
          16,
          37556,
          732,
          337,
          264,
          1150,
          644,
          295,
          264,
          9699,
          3430,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.30920139435798893,
        "compression_ratio": 1.5161290322580645,
        "end": 7989.36,
        "id": 2336,
        "no_speech_prob": 0.05919022858142853,
        "seek": 796136,
        "start": 7977.36,
        "temperature": 0.2,
        "text": " It shouldn't be merged without fixing the markdown file for challenge 121 part one first.",
        "tokens": [
          51164,
          467,
          4659,
          380,
          312,
          36427,
          1553,
          19442,
          264,
          1491,
          5093,
          3991,
          337,
          3430,
          2272,
          16,
          644,
          472,
          700,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.23726802402072483,
        "compression_ratio": 1.9435483870967742,
        "end": 7991.36,
        "id": 2337,
        "no_speech_prob": 0.03845774009823799,
        "seek": 798936,
        "start": 7989.36,
        "temperature": 0,
        "text": " So, let me do that.",
        "tokens": [
          50364,
          407,
          11,
          718,
          385,
          360,
          300,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.23726802402072483,
        "compression_ratio": 1.9435483870967742,
        "end": 7993.36,
        "id": 2338,
        "no_speech_prob": 0.03845774009823799,
        "seek": 798936,
        "start": 7991.36,
        "temperature": 0,
        "text": " And what is this?",
        "tokens": [
          50464,
          400,
          437,
          307,
          341,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.23726802402072483,
        "compression_ratio": 1.9435483870967742,
        "end": 7995.36,
        "id": 2339,
        "no_speech_prob": 0.03845774009823799,
        "seek": 798936,
        "start": 7993.36,
        "temperature": 0,
        "text": " Get repeat.",
        "tokens": [
          50564,
          3240,
          7149,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.23726802402072483,
        "compression_ratio": 1.9435483870967742,
        "end": 7997.36,
        "id": 2340,
        "no_speech_prob": 0.03845774009823799,
        "seek": 798936,
        "start": 7995.36,
        "temperature": 0,
        "text": " Oh, yeah, yeah.",
        "tokens": [
          50664,
          876,
          11,
          1338,
          11,
          1338,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.23726802402072483,
        "compression_ratio": 1.9435483870967742,
        "end": 7999.36,
        "id": 2341,
        "no_speech_prob": 0.03845774009823799,
        "seek": 798936,
        "start": 7997.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50764,
          1033,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.23726802402072483,
        "compression_ratio": 1.9435483870967742,
        "end": 8001.36,
        "id": 2342,
        "no_speech_prob": 0.03845774009823799,
        "seek": 798936,
        "start": 7999.36,
        "temperature": 0,
        "text": " What kind of crazy code did I write earlier today?",
        "tokens": [
          50864,
          708,
          733,
          295,
          3219,
          3089,
          630,
          286,
          2464,
          3071,
          965,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.23726802402072483,
        "compression_ratio": 1.9435483870967742,
        "end": 8003.36,
        "id": 2343,
        "no_speech_prob": 0.03845774009823799,
        "seek": 798936,
        "start": 8001.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50964,
          1033,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.23726802402072483,
        "compression_ratio": 1.9435483870967742,
        "end": 8005.36,
        "id": 2344,
        "no_speech_prob": 0.03845774009823799,
        "seek": 798936,
        "start": 8003.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51064,
          1057,
          558,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.23726802402072483,
        "compression_ratio": 1.9435483870967742,
        "end": 8007.36,
        "id": 2345,
        "no_speech_prob": 0.03845774009823799,
        "seek": 798936,
        "start": 8005.36,
        "temperature": 0,
        "text": " Oh, my goodness.",
        "tokens": [
          51164,
          876,
          11,
          452,
          8387,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.23726802402072483,
        "compression_ratio": 1.9435483870967742,
        "end": 8009.36,
        "id": 2346,
        "no_speech_prob": 0.03845774009823799,
        "seek": 798936,
        "start": 8007.36,
        "temperature": 0,
        "text": " Oh, my goodness.",
        "tokens": [
          51264,
          876,
          11,
          452,
          8387,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.23726802402072483,
        "compression_ratio": 1.9435483870967742,
        "end": 8011.36,
        "id": 2347,
        "no_speech_prob": 0.03845774009823799,
        "seek": 798936,
        "start": 8009.36,
        "temperature": 0,
        "text": " Oh, my goodness.",
        "tokens": [
          51364,
          876,
          11,
          452,
          8387,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.23726802402072483,
        "compression_ratio": 1.9435483870967742,
        "end": 8013.36,
        "id": 2348,
        "no_speech_prob": 0.03845774009823799,
        "seek": 798936,
        "start": 8011.36,
        "temperature": 0,
        "text": " Oh, my goodness.",
        "tokens": [
          51464,
          876,
          11,
          452,
          8387,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.23726802402072483,
        "compression_ratio": 1.9435483870967742,
        "end": 8015.36,
        "id": 2349,
        "no_speech_prob": 0.03845774009823799,
        "seek": 798936,
        "start": 8013.36,
        "temperature": 0,
        "text": " Oh, my goodness.",
        "tokens": [
          51564,
          876,
          11,
          452,
          8387,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.23726802402072483,
        "compression_ratio": 1.9435483870967742,
        "end": 8017.36,
        "id": 2350,
        "no_speech_prob": 0.03845774009823799,
        "seek": 798936,
        "start": 8015.36,
        "temperature": 0,
        "text": " Oh, my goodness.",
        "tokens": [
          51664,
          876,
          11,
          452,
          8387,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.26007991050606344,
        "compression_ratio": 1.875,
        "end": 8019.36,
        "id": 2351,
        "no_speech_prob": 0.13290126621723175,
        "seek": 801736,
        "start": 8017.36,
        "temperature": 0,
        "text": " Oh, my goodness.",
        "tokens": [
          50364,
          876,
          11,
          452,
          8387,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.26007991050606344,
        "compression_ratio": 1.875,
        "end": 8021.36,
        "id": 2352,
        "no_speech_prob": 0.13290126621723175,
        "seek": 801736,
        "start": 8019.36,
        "temperature": 0,
        "text": " Oh, my goodness.",
        "tokens": [
          50464,
          876,
          11,
          452,
          8387,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.26007991050606344,
        "compression_ratio": 1.875,
        "end": 8023.36,
        "id": 2353,
        "no_speech_prob": 0.13290126621723175,
        "seek": 801736,
        "start": 8021.36,
        "temperature": 0,
        "text": " Oh, my goodness.",
        "tokens": [
          50564,
          876,
          11,
          452,
          8387,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.26007991050606344,
        "compression_ratio": 1.875,
        "end": 8025.36,
        "id": 2354,
        "no_speech_prob": 0.13290126621723175,
        "seek": 801736,
        "start": 8023.36,
        "temperature": 0,
        "text": " Oh, my goodness.",
        "tokens": [
          50664,
          876,
          11,
          452,
          8387,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.26007991050606344,
        "compression_ratio": 1.875,
        "end": 8027.36,
        "id": 2355,
        "no_speech_prob": 0.13290126621723175,
        "seek": 801736,
        "start": 8025.36,
        "temperature": 0,
        "text": " All right, everyone.",
        "tokens": [
          50764,
          1057,
          558,
          11,
          1518,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.26007991050606344,
        "compression_ratio": 1.875,
        "end": 8029.36,
        "id": 2356,
        "no_speech_prob": 0.13290126621723175,
        "seek": 801736,
        "start": 8027.36,
        "temperature": 0,
        "text": " I'm definitely done.",
        "tokens": [
          50864,
          286,
          478,
          2138,
          1096,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.26007991050606344,
        "compression_ratio": 1.875,
        "end": 8031.36,
        "id": 2357,
        "no_speech_prob": 0.13290126621723175,
        "seek": 801736,
        "start": 8029.36,
        "temperature": 0,
        "text": " I really want to do more, but sometimes you just have to know when to quit.",
        "tokens": [
          50964,
          286,
          534,
          528,
          281,
          360,
          544,
          11,
          457,
          2171,
          291,
          445,
          362,
          281,
          458,
          562,
          281,
          10366,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.26007991050606344,
        "compression_ratio": 1.875,
        "end": 8033.36,
        "id": 2358,
        "no_speech_prob": 0.13290126621723175,
        "seek": 801736,
        "start": 8031.36,
        "temperature": 0,
        "text": " I don't usually know when to quit.",
        "tokens": [
          51064,
          286,
          500,
          380,
          2673,
          458,
          562,
          281,
          10366,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.26007991050606344,
        "compression_ratio": 1.875,
        "end": 8035.36,
        "id": 2359,
        "no_speech_prob": 0.13290126621723175,
        "seek": 801736,
        "start": 8033.36,
        "temperature": 0,
        "text": " I would be glad to take any questions.",
        "tokens": [
          51164,
          286,
          576,
          312,
          5404,
          281,
          747,
          604,
          1651,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.26007991050606344,
        "compression_ratio": 1.875,
        "end": 8037.36,
        "id": 2360,
        "no_speech_prob": 0.13290126621723175,
        "seek": 801736,
        "start": 8035.36,
        "temperature": 0,
        "text": " A few questions.",
        "tokens": [
          51264,
          316,
          1326,
          1651,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.26007991050606344,
        "compression_ratio": 1.875,
        "end": 8039.36,
        "id": 2361,
        "no_speech_prob": 0.13290126621723175,
        "seek": 801736,
        "start": 8037.36,
        "temperature": 0,
        "text": " Thank you to new members who joined.",
        "tokens": [
          51364,
          1044,
          291,
          281,
          777,
          2679,
          567,
          6869,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.26007991050606344,
        "compression_ratio": 1.875,
        "end": 8041.36,
        "id": 2362,
        "no_speech_prob": 0.13290126621723175,
        "seek": 801736,
        "start": 8039.36,
        "temperature": 0,
        "text": " Actually, okay.",
        "tokens": [
          51464,
          5135,
          11,
          1392,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.26007991050606344,
        "compression_ratio": 1.875,
        "end": 8043.36,
        "id": 2363,
        "no_speech_prob": 0.13290126621723175,
        "seek": 801736,
        "start": 8041.36,
        "temperature": 0,
        "text": " So, let me do a little housekeeping.",
        "tokens": [
          51564,
          407,
          11,
          718,
          385,
          360,
          257,
          707,
          1782,
          16055,
          278,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.26007991050606344,
        "compression_ratio": 1.875,
        "end": 8045.36,
        "id": 2364,
        "no_speech_prob": 0.13290126621723175,
        "seek": 801736,
        "start": 8043.36,
        "temperature": 0,
        "text": " I'm going to do a little housekeeping.",
        "tokens": [
          51664,
          286,
          478,
          516,
          281,
          360,
          257,
          707,
          1782,
          16055,
          278,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.32140330576526066,
        "compression_ratio": 2.3859060402684564,
        "end": 8047.36,
        "id": 2365,
        "no_speech_prob": 0.05747537687420845,
        "seek": 804536,
        "start": 8045.36,
        "temperature": 0.2,
        "text": " I can't imagine that anybody is still watching.",
        "tokens": [
          50364,
          286,
          393,
          380,
          3811,
          300,
          4472,
          307,
          920,
          1976,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.32140330576526066,
        "compression_ratio": 2.3859060402684564,
        "end": 8049.36,
        "id": 2366,
        "no_speech_prob": 0.05747537687420845,
        "seek": 804536,
        "start": 8047.36,
        "temperature": 0.2,
        "text": " But if you are, I will mention that I am way behind on sending out stickers and books to patron and YouTube members.",
        "tokens": [
          50464,
          583,
          498,
          291,
          366,
          11,
          286,
          486,
          2152,
          300,
          286,
          669,
          636,
          2261,
          322,
          7750,
          484,
          21019,
          293,
          3642,
          281,
          21843,
          293,
          3088,
          2679,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.32140330576526066,
        "compression_ratio": 2.3859060402684564,
        "end": 8051.36,
        "id": 2367,
        "no_speech_prob": 0.05747537687420845,
        "seek": 804536,
        "start": 8049.36,
        "temperature": 0.2,
        "text": " I am really...",
        "tokens": [
          50564,
          286,
          669,
          534,
          485,
          50664
        ]
      },
      {
        "avg_logprob": -0.32140330576526066,
        "compression_ratio": 2.3859060402684564,
        "end": 8053.36,
        "id": 2368,
        "no_speech_prob": 0.05747537687420845,
        "seek": 804536,
        "start": 8051.36,
        "temperature": 0.2,
        "text": " This is my goal.",
        "tokens": [
          50664,
          639,
          307,
          452,
          3387,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.32140330576526066,
        "compression_ratio": 2.3859060402684564,
        "end": 8055.36,
        "id": 2369,
        "no_speech_prob": 0.05747537687420845,
        "seek": 804536,
        "start": 8053.36,
        "temperature": 0.2,
        "text": " Everyone who joined November 1st or earlier, sorry if you joined in the last week.",
        "tokens": [
          50764,
          5198,
          567,
          6869,
          7674,
          502,
          372,
          420,
          3071,
          11,
          2597,
          498,
          291,
          6869,
          294,
          264,
          1036,
          1243,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.32140330576526066,
        "compression_ratio": 2.3859060402684564,
        "end": 8057.36,
        "id": 2370,
        "no_speech_prob": 0.05747537687420845,
        "seek": 804536,
        "start": 8055.36,
        "temperature": 0.2,
        "text": " I'm compiling everything.",
        "tokens": [
          50864,
          286,
          478,
          715,
          4883,
          1203,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.32140330576526066,
        "compression_ratio": 2.3859060402684564,
        "end": 8059.36,
        "id": 2371,
        "no_speech_prob": 0.05747537687420845,
        "seek": 804536,
        "start": 8057.36,
        "temperature": 0.2,
        "text": " I've got to get everybody everything by the holidays.",
        "tokens": [
          50964,
          286,
          600,
          658,
          281,
          483,
          2201,
          1203,
          538,
          264,
          15734,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.32140330576526066,
        "compression_ratio": 2.3859060402684564,
        "end": 8061.36,
        "id": 2372,
        "no_speech_prob": 0.05747537687420845,
        "seek": 804536,
        "start": 8059.36,
        "temperature": 0.2,
        "text": " If you do not have something and are wondering about the status of it, please do.",
        "tokens": [
          51064,
          759,
          291,
          360,
          406,
          362,
          746,
          293,
          366,
          6359,
          466,
          264,
          6558,
          295,
          309,
          11,
          1767,
          360,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.32140330576526066,
        "compression_ratio": 2.3859060402684564,
        "end": 8063.36,
        "id": 2373,
        "no_speech_prob": 0.05747537687420845,
        "seek": 804536,
        "start": 8061.36,
        "temperature": 0.2,
        "text": " I'm going to be doing a lot of housekeeping.",
        "tokens": [
          51164,
          286,
          478,
          516,
          281,
          312,
          884,
          257,
          688,
          295,
          48033,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.32140330576526066,
        "compression_ratio": 2.3859060402684564,
        "end": 8065.36,
        "id": 2374,
        "no_speech_prob": 0.05747537687420845,
        "seek": 804536,
        "start": 8063.36,
        "temperature": 0.2,
        "text": " I'm going to be doing a lot of housekeeping.",
        "tokens": [
          51264,
          286,
          478,
          516,
          281,
          312,
          884,
          257,
          688,
          295,
          48033,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.32140330576526066,
        "compression_ratio": 2.3859060402684564,
        "end": 8067.36,
        "id": 2375,
        "no_speech_prob": 0.05747537687420845,
        "seek": 804536,
        "start": 8065.36,
        "temperature": 0.2,
        "text": " I'm going to be doing a lot of housekeeping.",
        "tokens": [
          51364,
          286,
          478,
          516,
          281,
          312,
          884,
          257,
          688,
          295,
          48033,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.32140330576526066,
        "compression_ratio": 2.3859060402684564,
        "end": 8069.36,
        "id": 2376,
        "no_speech_prob": 0.05747537687420845,
        "seek": 804536,
        "start": 8067.36,
        "temperature": 0.2,
        "text": " I'm going to be doing a lot of housekeeping.",
        "tokens": [
          51464,
          286,
          478,
          516,
          281,
          312,
          884,
          257,
          688,
          295,
          48033,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.32140330576526066,
        "compression_ratio": 2.3859060402684564,
        "end": 8071.36,
        "id": 2377,
        "no_speech_prob": 0.05747537687420845,
        "seek": 804536,
        "start": 8069.36,
        "temperature": 0.2,
        "text": " I'm going to be doing a lot of housekeeping.",
        "tokens": [
          51564,
          286,
          478,
          516,
          281,
          312,
          884,
          257,
          688,
          295,
          48033,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.32140330576526066,
        "compression_ratio": 2.3859060402684564,
        "end": 8073.36,
        "id": 2378,
        "no_speech_prob": 0.05747537687420845,
        "seek": 804536,
        "start": 8071.36,
        "temperature": 0.2,
        "text": " I'm going to be doing a lot of housekeeping.",
        "tokens": [
          51664,
          286,
          478,
          516,
          281,
          312,
          884,
          257,
          688,
          295,
          48033,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2914091335829868,
        "compression_ratio": 2.174496644295302,
        "end": 8075.36,
        "id": 2379,
        "no_speech_prob": 0.2017376869916916,
        "seek": 807336,
        "start": 8073.36,
        "temperature": 0.2,
        "text": " If you are a YouTube member and are wondering about the status of it, please send me a message on Slack.",
        "tokens": [
          50364,
          759,
          291,
          366,
          257,
          3088,
          4006,
          293,
          366,
          6359,
          466,
          264,
          6558,
          295,
          309,
          11,
          3362,
          651,
          2845,
          385,
          257,
          3636,
          322,
          37211,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2914091335829868,
        "compression_ratio": 2.174496644295302,
        "end": 8077.36,
        "id": 2380,
        "no_speech_prob": 0.2017376869916916,
        "seek": 807336,
        "start": 8075.36,
        "temperature": 0.2,
        "text": " If you are a YouTube member and you don't have a Slack invite,",
        "tokens": [
          50464,
          759,
          291,
          366,
          257,
          3088,
          4006,
          293,
          291,
          500,
          380,
          362,
          257,
          37211,
          7980,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.2914091335829868,
        "compression_ratio": 2.174496644295302,
        "end": 8079.36,
        "id": 2381,
        "no_speech_prob": 0.2017376869916916,
        "seek": 807336,
        "start": 8077.36,
        "temperature": 0.2,
        "text": " then make sure you find the community post which has the form to get a Slack invite.",
        "tokens": [
          50564,
          550,
          652,
          988,
          291,
          915,
          264,
          1768,
          2183,
          597,
          575,
          264,
          1254,
          281,
          483,
          257,
          37211,
          7980,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2914091335829868,
        "compression_ratio": 2.174496644295302,
        "end": 8081.36,
        "id": 2382,
        "no_speech_prob": 0.2017376869916916,
        "seek": 807336,
        "start": 8079.36,
        "temperature": 0.2,
        "text": " And also, you can message at math blank on Slack who is doing the stuff.",
        "tokens": [
          50664,
          400,
          611,
          11,
          291,
          393,
          3636,
          412,
          5221,
          8247,
          322,
          37211,
          567,
          307,
          884,
          264,
          1507,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2914091335829868,
        "compression_ratio": 2.174496644295302,
        "end": 8083.36,
        "id": 2383,
        "no_speech_prob": 0.2017376869916916,
        "seek": 807336,
        "start": 8081.36,
        "temperature": 0.2,
        "text": " If you are interested in Coding Train merchandise,",
        "tokens": [
          50764,
          759,
          291,
          366,
          3102,
          294,
          383,
          8616,
          28029,
          34485,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.2914091335829868,
        "compression_ratio": 2.174496644295302,
        "end": 8085.36,
        "id": 2384,
        "no_speech_prob": 0.2017376869916916,
        "seek": 807336,
        "start": 8083.36,
        "temperature": 0.2,
        "text": " I might as well plug this just for a second because it's new.",
        "tokens": [
          50864,
          286,
          1062,
          382,
          731,
          5452,
          341,
          445,
          337,
          257,
          1150,
          570,
          309,
          311,
          777,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2914091335829868,
        "compression_ratio": 2.174496644295302,
        "end": 8087.36,
        "id": 2385,
        "no_speech_prob": 0.2017376869916916,
        "seek": 807336,
        "start": 8085.36,
        "temperature": 0.2,
        "text": " Actually, I am wearing right now, this is one of these shirts.",
        "tokens": [
          50964,
          5135,
          11,
          286,
          669,
          4769,
          558,
          586,
          11,
          341,
          307,
          472,
          295,
          613,
          20832,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2914091335829868,
        "compression_ratio": 2.174496644295302,
        "end": 8089.36,
        "id": 2386,
        "no_speech_prob": 0.2017376869916916,
        "seek": 807336,
        "start": 8087.36,
        "temperature": 0.2,
        "text": " I'm wearing a shirt.",
        "tokens": [
          51064,
          286,
          478,
          4769,
          257,
          8336,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2914091335829868,
        "compression_ratio": 2.174496644295302,
        "end": 8091.36,
        "id": 2387,
        "no_speech_prob": 0.2017376869916916,
        "seek": 807336,
        "start": 8089.36,
        "temperature": 0.2,
        "text": " I'm wearing a shirt.",
        "tokens": [
          51164,
          286,
          478,
          4769,
          257,
          8336,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2914091335829868,
        "compression_ratio": 2.174496644295302,
        "end": 8093.36,
        "id": 2388,
        "no_speech_prob": 0.2017376869916916,
        "seek": 807336,
        "start": 8091.36,
        "temperature": 0.2,
        "text": " I'm wearing a shirt.",
        "tokens": [
          51264,
          286,
          478,
          4769,
          257,
          8336,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2914091335829868,
        "compression_ratio": 2.174496644295302,
        "end": 8095.36,
        "id": 2389,
        "no_speech_prob": 0.2017376869916916,
        "seek": 807336,
        "start": 8093.36,
        "temperature": 0.2,
        "text": " I'm wearing a shirt.",
        "tokens": [
          51364,
          286,
          478,
          4769,
          257,
          8336,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2914091335829868,
        "compression_ratio": 2.174496644295302,
        "end": 8097.36,
        "id": 2390,
        "no_speech_prob": 0.2017376869916916,
        "seek": 807336,
        "start": 8095.36,
        "temperature": 0.2,
        "text": " I'm wearing a shirt.",
        "tokens": [
          51464,
          286,
          478,
          4769,
          257,
          8336,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2914091335829868,
        "compression_ratio": 2.174496644295302,
        "end": 8099.36,
        "id": 2391,
        "no_speech_prob": 0.2017376869916916,
        "seek": 807336,
        "start": 8097.36,
        "temperature": 0.2,
        "text": " I'm wearing a shirt.",
        "tokens": [
          51564,
          286,
          478,
          4769,
          257,
          8336,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2914091335829868,
        "compression_ratio": 2.174496644295302,
        "end": 8101.36,
        "id": 2392,
        "no_speech_prob": 0.2017376869916916,
        "seek": 807336,
        "start": 8099.36,
        "temperature": 0.2,
        "text": " I'm wearing a shirt.",
        "tokens": [
          51664,
          286,
          478,
          4769,
          257,
          8336,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.5463351814114318,
        "compression_ratio": 1.6768060836501901,
        "end": 8103.36,
        "id": 2393,
        "no_speech_prob": 0.1328674852848053,
        "seek": 810136,
        "start": 8101.36,
        "temperature": 0.8,
        "text": " I'm wearing a shirt right now.",
        "tokens": [
          50364,
          286,
          478,
          4769,
          257,
          8336,
          558,
          586,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.5463351814114318,
        "compression_ratio": 1.6768060836501901,
        "end": 8105.36,
        "id": 2394,
        "no_speech_prob": 0.1328674852848053,
        "seek": 810136,
        "start": 8103.36,
        "temperature": 0.8,
        "text": " I am actually wearing 2 shirts.",
        "tokens": [
          50464,
          286,
          220,
          335,
          767,
          4769,
          568,
          20832,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.5463351814114318,
        "compression_ratio": 1.6768060836501901,
        "end": 8107.36,
        "id": 2395,
        "no_speech_prob": 0.1328674852848053,
        "seek": 810136,
        "start": 8105.36,
        "temperature": 0.8,
        "text": " It looks like I am disrobing.",
        "tokens": [
          50564,
          467,
          1542,
          411,
          286,
          669,
          717,
          340,
          4324,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.5463351814114318,
        "compression_ratio": 1.6768060836501901,
        "end": 8109.36,
        "id": 2396,
        "no_speech_prob": 0.1328674852848053,
        "seek": 810136,
        "start": 8107.36,
        "temperature": 0.8,
        "text": " Don't worry, I am not.",
        "tokens": [
          50664,
          1468,
          380,
          3292,
          11,
          286,
          669,
          406,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.5463351814114318,
        "compression_ratio": 1.6768060836501901,
        "end": 8111.36,
        "id": 2397,
        "no_speech_prob": 0.1328674852848053,
        "seek": 810136,
        "start": 8109.36,
        "temperature": 0.8,
        "text": " I'm just showing you my Never Forget.",
        "tokens": [
          50764,
          286,
          478,
          445,
          4099,
          291,
          452,
          7344,
          18675,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.5463351814114318,
        "compression_ratio": 1.6768060836501901,
        "end": 8113.36,
        "id": 2398,
        "no_speech_prob": 0.1328674852848053,
        "seek": 810136,
        "start": 8111.36,
        "temperature": 0.8,
        "text": " It was kind of translucent.",
        "tokens": [
          50864,
          467,
          390,
          733,
          295,
          504,
          282,
          10418,
          1311,
          317,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.5463351814114318,
        "compression_ratio": 1.6768060836501901,
        "end": 8115.36,
        "id": 2399,
        "no_speech_prob": 0.1328674852848053,
        "seek": 810136,
        "start": 8113.36,
        "temperature": 0.8,
        "text": " Never Forget, the This Dot shirt.",
        "tokens": [
          50964,
          7344,
          18675,
          11,
          264,
          639,
          38753,
          8336,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.5463351814114318,
        "compression_ratio": 1.6768060836501901,
        "end": 8117.36,
        "id": 2400,
        "no_speech_prob": 0.1328674852848053,
        "seek": 810136,
        "start": 8115.36,
        "temperature": 0.8,
        "text": " You can get your own Never Forget",
        "tokens": [
          51064,
          509,
          393,
          483,
          428,
          1065,
          7344,
          18675,
          51164
        ]
      },
      {
        "avg_logprob": -0.5463351814114318,
        "compression_ratio": 1.6768060836501901,
        "end": 8119.36,
        "id": 2401,
        "no_speech_prob": 0.1328674852848053,
        "seek": 810136,
        "start": 8117.36,
        "temperature": 0.8,
        "text": " the This Dot shirt designed by humans",
        "tokens": [
          51164,
          264,
          314,
          18300,
          38753,
          8336,
          730,
          328,
          9232,
          538,
          6255,
          51264
        ]
      },
      {
        "avg_logprob": -0.5463351814114318,
        "compression_ratio": 1.6768060836501901,
        "end": 8121.36,
        "id": 2402,
        "no_speech_prob": 0.1328674852848053,
        "seek": 810136,
        "start": 8119.36,
        "temperature": 0.8,
        "text": " slash shop slash Coding Train,",
        "tokens": [
          51264,
          17330,
          3945,
          17330,
          383,
          8616,
          28029,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.5463351814114318,
        "compression_ratio": 1.6768060836501901,
        "end": 8123.36,
        "id": 2403,
        "no_speech_prob": 0.1328674852848053,
        "seek": 810136,
        "start": 8121.36,
        "temperature": 0.8,
        "text": " I believe.",
        "tokens": [
          51364,
          286,
          1697,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.5463351814114318,
        "compression_ratio": 1.6768060836501901,
        "end": 8125.36,
        "id": 2404,
        "no_speech_prob": 0.1328674852848053,
        "seek": 810136,
        "start": 8123.36,
        "temperature": 0.8,
        "text": " So, you can see these are the various",
        "tokens": [
          51464,
          407,
          11,
          291,
          393,
          536,
          613,
          366,
          220,
          3322,
          3683,
          51564
        ]
      },
      {
        "avg_logprob": -0.5463351814114318,
        "compression_ratio": 1.6768060836501901,
        "end": 8127.36,
        "id": 2405,
        "no_speech_prob": 0.1328674852848053,
        "seek": 810136,
        "start": 8125.36,
        "temperature": 0.8,
        "text": " shirts and things.",
        "tokens": [
          51564,
          20832,
          293,
          721,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.5463351814114318,
        "compression_ratio": 1.6768060836501901,
        "end": 8129.36,
        "id": 2406,
        "no_speech_prob": 0.1328674852848053,
        "seek": 810136,
        "start": 8127.36,
        "temperature": 0.8,
        "text": " I wanted to mention, people, it's hard to notice this,",
        "tokens": [
          51664,
          286,
          1415,
          281,
          2152,
          11,
          561,
          11,
          309,
          311,
          1152,
          281,
          572,
          83,
          573,
          341,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.22150444799615432,
        "compression_ratio": 1.578397212543554,
        "end": 8131.36,
        "id": 2407,
        "no_speech_prob": 0.00011959485709667206,
        "seek": 812936,
        "start": 8129.36,
        "temperature": 0,
        "text": " this phone case here",
        "tokens": [
          50364,
          341,
          2593,
          1389,
          510,
          50464
        ]
      },
      {
        "avg_logprob": -0.22150444799615432,
        "compression_ratio": 1.578397212543554,
        "end": 8133.36,
        "id": 2408,
        "no_speech_prob": 0.00011959485709667206,
        "seek": 812936,
        "start": 8131.36,
        "temperature": 0,
        "text": " is $35. That's crazy.",
        "tokens": [
          50464,
          307,
          1848,
          8794,
          13,
          663,
          311,
          3219,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.22150444799615432,
        "compression_ratio": 1.578397212543554,
        "end": 8135.36,
        "id": 2409,
        "no_speech_prob": 0.00011959485709667206,
        "seek": 812936,
        "start": 8133.36,
        "temperature": 0,
        "text": " But this is actually",
        "tokens": [
          50564,
          583,
          341,
          307,
          767,
          50664
        ]
      },
      {
        "avg_logprob": -0.22150444799615432,
        "compression_ratio": 1.578397212543554,
        "end": 8137.36,
        "id": 2410,
        "no_speech_prob": 0.00011959485709667206,
        "seek": 812936,
        "start": 8135.36,
        "temperature": 0,
        "text": " designed to probably make this a default",
        "tokens": [
          50664,
          4761,
          281,
          1391,
          652,
          341,
          257,
          7576,
          50764
        ]
      },
      {
        "avg_logprob": -0.22150444799615432,
        "compression_ratio": 1.578397212543554,
        "end": 8139.36,
        "id": 2411,
        "no_speech_prob": 0.00011959485709667206,
        "seek": 812936,
        "start": 8137.36,
        "temperature": 0,
        "text": " for a zip hoodie where the Never Forget",
        "tokens": [
          50764,
          337,
          257,
          20730,
          41191,
          689,
          264,
          7344,
          18675,
          50864
        ]
      },
      {
        "avg_logprob": -0.22150444799615432,
        "compression_ratio": 1.578397212543554,
        "end": 8141.36,
        "id": 2412,
        "no_speech_prob": 0.00011959485709667206,
        "seek": 812936,
        "start": 8139.36,
        "temperature": 0,
        "text": " the This Dot is on this side.",
        "tokens": [
          50864,
          264,
          639,
          38753,
          307,
          322,
          341,
          1252,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.22150444799615432,
        "compression_ratio": 1.578397212543554,
        "end": 8143.36,
        "id": 2413,
        "no_speech_prob": 0.00011959485709667206,
        "seek": 812936,
        "start": 8141.36,
        "temperature": 0,
        "text": " I just wanted to mention that.",
        "tokens": [
          50964,
          286,
          445,
          1415,
          281,
          2152,
          300,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.22150444799615432,
        "compression_ratio": 1.578397212543554,
        "end": 8145.36,
        "id": 2414,
        "no_speech_prob": 0.00011959485709667206,
        "seek": 812936,
        "start": 8143.36,
        "temperature": 0,
        "text": " Other housekeeping things. Let's see what other questions",
        "tokens": [
          51064,
          5358,
          48033,
          721,
          13,
          961,
          311,
          536,
          437,
          661,
          1651,
          51164
        ]
      },
      {
        "avg_logprob": -0.22150444799615432,
        "compression_ratio": 1.578397212543554,
        "end": 8147.36,
        "id": 2415,
        "no_speech_prob": 0.00011959485709667206,
        "seek": 812936,
        "start": 8145.36,
        "temperature": 0,
        "text": " there are. What do you think about",
        "tokens": [
          51164,
          456,
          366,
          13,
          708,
          360,
          291,
          519,
          466,
          51264
        ]
      },
      {
        "avg_logprob": -0.22150444799615432,
        "compression_ratio": 1.578397212543554,
        "end": 8149.36,
        "id": 2416,
        "no_speech_prob": 0.00011959485709667206,
        "seek": 812936,
        "start": 8147.36,
        "temperature": 0,
        "text": " GANs or Generative Adversarial Networks?",
        "tokens": [
          51264,
          460,
          1770,
          82,
          420,
          15409,
          1166,
          1999,
          840,
          44745,
          12640,
          82,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.22150444799615432,
        "compression_ratio": 1.578397212543554,
        "end": 8151.36,
        "id": 2417,
        "no_speech_prob": 0.00011959485709667206,
        "seek": 812936,
        "start": 8149.36,
        "temperature": 0,
        "text": " They are very interesting",
        "tokens": [
          51364,
          814,
          366,
          588,
          1880,
          51464
        ]
      },
      {
        "avg_logprob": -0.22150444799615432,
        "compression_ratio": 1.578397212543554,
        "end": 8153.36,
        "id": 2418,
        "no_speech_prob": 0.00011959485709667206,
        "seek": 812936,
        "start": 8151.36,
        "temperature": 0,
        "text": " to me and I would love to",
        "tokens": [
          51464,
          281,
          385,
          293,
          286,
          576,
          959,
          281,
          51564
        ]
      },
      {
        "avg_logprob": -0.22150444799615432,
        "compression_ratio": 1.578397212543554,
        "end": 8155.36,
        "id": 2419,
        "no_speech_prob": 0.00011959485709667206,
        "seek": 812936,
        "start": 8153.36,
        "temperature": 0,
        "text": " learn more about them and",
        "tokens": [
          51564,
          1466,
          544,
          466,
          552,
          293,
          51664
        ]
      },
      {
        "avg_logprob": -0.22150444799615432,
        "compression_ratio": 1.578397212543554,
        "end": 8157.36,
        "id": 2420,
        "no_speech_prob": 0.00011959485709667206,
        "seek": 812936,
        "start": 8155.36,
        "temperature": 0,
        "text": " maybe do some tutorials about them.",
        "tokens": [
          51664,
          1310,
          360,
          512,
          17616,
          466,
          552,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2148707274234656,
        "compression_ratio": 1.3263888888888888,
        "end": 8159.36,
        "id": 2421,
        "no_speech_prob": 0.03620734065771103,
        "seek": 815736,
        "start": 8157.36,
        "temperature": 0,
        "text": " A wonderful artist who does",
        "tokens": [
          50364,
          316,
          3715,
          5748,
          567,
          775,
          50464
        ]
      },
      {
        "avg_logprob": -0.2148707274234656,
        "compression_ratio": 1.3263888888888888,
        "end": 8161.36,
        "id": 2422,
        "no_speech_prob": 0.03620734065771103,
        "seek": 815736,
        "start": 8159.36,
        "temperature": 0,
        "text": " wonderful things with GAN is",
        "tokens": [
          50464,
          3715,
          721,
          365,
          460,
          1770,
          307,
          50564
        ]
      },
      {
        "avg_logprob": -0.2148707274234656,
        "compression_ratio": 1.3263888888888888,
        "end": 8163.36,
        "id": 2423,
        "no_speech_prob": 0.03620734065771103,
        "seek": 815736,
        "start": 8161.36,
        "temperature": 0,
        "text": " Helena...",
        "tokens": [
          50564,
          49294,
          485,
          50664
        ]
      },
      {
        "avg_logprob": -0.2148707274234656,
        "compression_ratio": 1.3263888888888888,
        "end": 8165.36,
        "id": 2424,
        "no_speech_prob": 0.03620734065771103,
        "seek": 815736,
        "start": 8163.36,
        "temperature": 0,
        "text": " Is this her name?",
        "tokens": [
          50664,
          1119,
          341,
          720,
          1315,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.2148707274234656,
        "compression_ratio": 1.3263888888888888,
        "end": 8167.36,
        "id": 2425,
        "no_speech_prob": 0.03620734065771103,
        "seek": 815736,
        "start": 8165.36,
        "temperature": 0,
        "text": " Yes. You should check out",
        "tokens": [
          50764,
          1079,
          13,
          509,
          820,
          1520,
          484,
          50864
        ]
      },
      {
        "avg_logprob": -0.2148707274234656,
        "compression_ratio": 1.3263888888888888,
        "end": 8169.36,
        "id": 2426,
        "no_speech_prob": 0.03620734065771103,
        "seek": 815736,
        "start": 8167.36,
        "temperature": 0,
        "text": " Glagolista on",
        "tokens": [
          50864,
          460,
          27298,
          401,
          5236,
          322,
          50964
        ]
      },
      {
        "avg_logprob": -0.2148707274234656,
        "compression_ratio": 1.3263888888888888,
        "end": 8171.36,
        "id": 2427,
        "no_speech_prob": 0.03620734065771103,
        "seek": 815736,
        "start": 8169.36,
        "temperature": 0,
        "text": " Twitter who makes all sorts",
        "tokens": [
          50964,
          5794,
          567,
          1669,
          439,
          7527,
          51064
        ]
      },
      {
        "avg_logprob": -0.2148707274234656,
        "compression_ratio": 1.3263888888888888,
        "end": 8173.36,
        "id": 2428,
        "no_speech_prob": 0.03620734065771103,
        "seek": 815736,
        "start": 8171.36,
        "temperature": 0,
        "text": " of amazing GAN-related",
        "tokens": [
          51064,
          295,
          2243,
          460,
          1770,
          12,
          12004,
          51164
        ]
      },
      {
        "avg_logprob": -0.2148707274234656,
        "compression_ratio": 1.3263888888888888,
        "end": 8175.36,
        "id": 2429,
        "no_speech_prob": 0.03620734065771103,
        "seek": 815736,
        "start": 8173.36,
        "temperature": 0,
        "text": " projects.",
        "tokens": [
          51164,
          4455,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2148707274234656,
        "compression_ratio": 1.3263888888888888,
        "end": 8177.36,
        "id": 2430,
        "no_speech_prob": 0.03620734065771103,
        "seek": 815736,
        "start": 8175.36,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51264,
          865,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.47610628215316075,
        "compression_ratio": 2.331730769230769,
        "end": 8179.36,
        "id": 2431,
        "no_speech_prob": 0.313674658536911,
        "seek": 817736,
        "start": 8177.36,
        "temperature": 0,
        "text": " I'm not going yet.",
        "tokens": [
          50364,
          286,
          478,
          406,
          516,
          1939,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.47610628215316075,
        "compression_ratio": 2.331730769230769,
        "end": 8181.36,
        "id": 2432,
        "no_speech_prob": 0.313674658536911,
        "seek": 817736,
        "start": 8179.36,
        "temperature": 0,
        "text": " Waiting to see if there's any more questions.",
        "tokens": [
          50464,
          37291,
          281,
          536,
          498,
          456,
          311,
          604,
          544,
          1651,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.47610628215316075,
        "compression_ratio": 2.331730769230769,
        "end": 8183.36,
        "id": 2433,
        "no_speech_prob": 0.313674658536911,
        "seek": 817736,
        "start": 8181.36,
        "temperature": 0,
        "text": " My mic is very quiet.",
        "tokens": [
          50564,
          1222,
          3123,
          307,
          588,
          5677,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.47610628215316075,
        "compression_ratio": 2.331730769230769,
        "end": 8185.36,
        "id": 2434,
        "no_speech_prob": 0.313674658536911,
        "seek": 817736,
        "start": 8183.36,
        "temperature": 0,
        "text": " That doesn't surprise me because",
        "tokens": [
          50664,
          663,
          1177,
          380,
          6365,
          385,
          570,
          50764
        ]
      },
      {
        "avg_logprob": -0.47610628215316075,
        "compression_ratio": 2.331730769230769,
        "end": 8187.36,
        "id": 2435,
        "no_speech_prob": 0.313674658536911,
        "seek": 817736,
        "start": 8185.36,
        "temperature": 0,
        "text": " it got moved around, but hopefully it's fine now.",
        "tokens": [
          50764,
          309,
          658,
          4259,
          926,
          11,
          457,
          4696,
          309,
          311,
          2489,
          586,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.47610628215316075,
        "compression_ratio": 2.331730769230769,
        "end": 8189.36,
        "id": 2436,
        "no_speech_prob": 0.313674658536911,
        "seek": 817736,
        "start": 8187.36,
        "temperature": 0,
        "text": " Thank you,",
        "tokens": [
          50864,
          1044,
          291,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.47610628215316075,
        "compression_ratio": 2.331730769230769,
        "end": 8191.36,
        "id": 2437,
        "no_speech_prob": 0.313674658536911,
        "seek": 817736,
        "start": 8189.36,
        "temperature": 0,
        "text": " Awefek, for letting me know.",
        "tokens": [
          50964,
          316,
          826,
          69,
          916,
          11,
          337,
          8295,
          385,
          458,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.47610628215316075,
        "compression_ratio": 2.331730769230769,
        "end": 8193.36,
        "id": 2438,
        "no_speech_prob": 0.313674658536911,
        "seek": 817736,
        "start": 8191.36,
        "temperature": 0,
        "text": " This is the end of today's live stream.",
        "tokens": [
          51064,
          639,
          307,
          264,
          917,
          295,
          965,
          311,
          1621,
          4309,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.47610628215316075,
        "compression_ratio": 2.331730769230769,
        "end": 8195.36,
        "id": 2439,
        "no_speech_prob": 0.313674658536911,
        "seek": 817736,
        "start": 8193.36,
        "temperature": 0,
        "text": " Today I'm going to be talking about",
        "tokens": [
          51164,
          2692,
          286,
          478,
          516,
          281,
          312,
          1417,
          466,
          51264
        ]
      },
      {
        "avg_logprob": -0.47610628215316075,
        "compression_ratio": 2.331730769230769,
        "end": 8197.36,
        "id": 2440,
        "no_speech_prob": 0.313674658536911,
        "seek": 817736,
        "start": 8195.36,
        "temperature": 0,
        "text": " the news. I'm going to be talking about",
        "tokens": [
          51264,
          264,
          220,
          7686,
          82,
          13,
          286,
          478,
          516,
          281,
          312,
          1417,
          466,
          51364
        ]
      },
      {
        "avg_logprob": -0.47610628215316075,
        "compression_ratio": 2.331730769230769,
        "end": 8199.36,
        "id": 2441,
        "no_speech_prob": 0.313674658536911,
        "seek": 817736,
        "start": 8197.36,
        "temperature": 0,
        "text": " the news. I'm going to be talking about",
        "tokens": [
          51364,
          264,
          2583,
          13,
          286,
          478,
          516,
          281,
          312,
          1417,
          466,
          51464
        ]
      },
      {
        "avg_logprob": -0.47610628215316075,
        "compression_ratio": 2.331730769230769,
        "end": 8201.36,
        "id": 2442,
        "no_speech_prob": 0.313674658536911,
        "seek": 817736,
        "start": 8199.36,
        "temperature": 0,
        "text": " the news. I'm going to be talking about",
        "tokens": [
          51464,
          264,
          2583,
          13,
          286,
          478,
          516,
          281,
          312,
          1417,
          466,
          51564
        ]
      },
      {
        "avg_logprob": -0.47610628215316075,
        "compression_ratio": 2.331730769230769,
        "end": 8203.36,
        "id": 2443,
        "no_speech_prob": 0.313674658536911,
        "seek": 817736,
        "start": 8201.36,
        "temperature": 0,
        "text": " the news. I'm going to be talking about",
        "tokens": [
          51564,
          264,
          2583,
          13,
          286,
          478,
          516,
          281,
          312,
          1417,
          466,
          51664
        ]
      },
      {
        "avg_logprob": -0.47610628215316075,
        "compression_ratio": 2.331730769230769,
        "end": 8205.36,
        "id": 2444,
        "no_speech_prob": 0.313674658536911,
        "seek": 817736,
        "start": 8203.36,
        "temperature": 0,
        "text": " the news. I'm going to be talking about",
        "tokens": [
          51664,
          264,
          2583,
          13,
          286,
          478,
          516,
          281,
          312,
          1417,
          466,
          51764
        ]
      },
      {
        "avg_logprob": -3.764300584793091,
        "compression_ratio": 0.38461538461538464,
        "end": 8233.460000000001,
        "id": 2445,
        "no_speech_prob": 0.5727648735046387,
        "seek": 820536,
        "start": 8205.36,
        "temperature": 1,
        "text": " calm,",
        "tokens": [
          50364,
          220,
          496,
          75,
          76,
          11,
          51769
        ]
      },
      {
        "avg_logprob": -3.141343733843635,
        "compression_ratio": 1.7106382978723405,
        "end": 8237.460000000001,
        "id": 2446,
        "no_speech_prob": 0.49189937114715576,
        "seek": 823536,
        "start": 8235.44,
        "temperature": 1,
        "text": " nutty level favorites.",
        "tokens": [
          50368,
          5393,
          874,
          1496,
          16907,
          13,
          50469
        ]
      },
      {
        "avg_logprob": -3.141343733843635,
        "compression_ratio": 1.7106382978723405,
        "end": 8239.2,
        "id": 2447,
        "no_speech_prob": 0.49189937114715576,
        "seek": 823536,
        "start": 8237.460000000001,
        "temperature": 1,
        "text": " I love all of these.",
        "tokens": [
          50469,
          286,
          959,
          439,
          220,
          2670,
          613,
          13,
          50556
        ]
      },
      {
        "avg_logprob": -3.141343733843635,
        "compression_ratio": 1.7106382978723405,
        "end": 8240.800000000001,
        "id": 2448,
        "no_speech_prob": 0.49189937114715576,
        "seek": 823536,
        "start": 8239.2,
        "temperature": 1,
        "text": " And the regulator was like...",
        "tokens": [
          50556,
          400,
          264,
          36250,
          390,
          411,
          485,
          50636
        ]
      },
      {
        "avg_logprob": -3.141343733843635,
        "compression_ratio": 1.7106382978723405,
        "end": 8244.52,
        "id": 2449,
        "no_speech_prob": 0.49189937114715576,
        "seek": 823536,
        "start": 8240.800000000001,
        "temperature": 1,
        "text": " I would love to do a serial business,",
        "tokens": [
          50636,
          286,
          576,
          959,
          220,
          1353,
          360,
          257,
          17436,
          1606,
          11,
          50822
        ]
      },
      {
        "avg_logprob": -3.141343733843635,
        "compression_ratio": 1.7106382978723405,
        "end": 8247.400000000001,
        "id": 2450,
        "no_speech_prob": 0.49189937114715576,
        "seek": 823536,
        "start": 8244.52,
        "temperature": 1,
        "text": " if that's what you want and I would love to print",
        "tokens": [
          50822,
          498,
          300,
          311,
          437,
          291,
          46930,
          83,
          293,
          286,
          576,
          959,
          281,
          4482,
          50966
        ]
      },
      {
        "avg_logprob": -3.141343733843635,
        "compression_ratio": 1.7106382978723405,
        "end": 8251.16,
        "id": 2451,
        "no_speech_prob": 0.49189937114715576,
        "seek": 823536,
        "start": 8247.400000000001,
        "temperature": 1,
        "text": " out your book, and, and do some bargaining.",
        "tokens": [
          50966,
          484,
          428,
          1446,
          11,
          293,
          11,
          293,
          360,
          512,
          42108,
          13,
          51154
        ]
      },
      {
        "avg_logprob": -3.141343733843635,
        "compression_ratio": 1.7106382978723405,
        "end": 8253.560000000001,
        "id": 2452,
        "no_speech_prob": 0.49189937114715576,
        "seek": 823536,
        "start": 8251.16,
        "temperature": 1,
        "text": " And so that's, that's the first one.",
        "tokens": [
          51154,
          400,
          370,
          300,
          311,
          11,
          300,
          311,
          256,
          675,
          700,
          472,
          13,
          51274
        ]
      },
      {
        "avg_logprob": -3.141343733843635,
        "compression_ratio": 1.7106382978723405,
        "end": 8256.220000000001,
        "id": 2453,
        "no_speech_prob": 0.49189937114715576,
        "seek": 823536,
        "start": 8253.560000000001,
        "temperature": 1,
        "text": " But then the second one is what I do at home.",
        "tokens": [
          51274,
          583,
          550,
          264,
          1150,
          472,
          307,
          437,
          286,
          220,
          2595,
          412,
          1280,
          13,
          51407
        ]
      },
      {
        "avg_logprob": -3.141343733843635,
        "compression_ratio": 1.7106382978723405,
        "end": 8260.04,
        "id": 2454,
        "no_speech_prob": 0.49189937114715576,
        "seek": 823536,
        "start": 8256.220000000001,
        "temperature": 1,
        "text": " I spend a two hour, an hour on the computer,",
        "tokens": [
          51407,
          286,
          3496,
          257,
          732,
          1773,
          11,
          364,
          36621,
          81,
          322,
          256,
          675,
          3820,
          11,
          51598
        ]
      },
      {
        "avg_logprob": -3.141343733843635,
        "compression_ratio": 1.7106382978723405,
        "end": 8261.800000000001,
        "id": 2455,
        "no_speech_prob": 0.49189937114715576,
        "seek": 823536,
        "start": 8260.04,
        "temperature": 1,
        "text": " sound game sound and I'm  weighs it,",
        "tokens": [
          51598,
          1626,
          8019,
          68,
          1626,
          293,
          286,
          478,
          220,
          24911,
          741,
          83,
          11,
          51686
        ]
      },
      {
        "avg_logprob": -3.141343733843635,
        "compression_ratio": 1.7106382978723405,
        "end": 8264.52,
        "id": 2456,
        "no_speech_prob": 0.49189937114715576,
        "seek": 823536,
        "start": 8261.800000000001,
        "temperature": 1,
        "text": " and then I start dialing it up.",
        "tokens": [
          51686,
          293,
          550,
          286,
          722,
          6801,
          1688,
          309,
          493,
          13,
          51822
        ]
      },
      {
        "avg_logprob": -0.3863708842884411,
        "compression_ratio": 1.5725806451612903,
        "end": 8266.08,
        "id": 2457,
        "no_speech_prob": 0.00118786480743438,
        "seek": 826452,
        "start": 8264.52,
        "temperature": 0,
        "text": " And it's really helpful for me to develop,",
        "tokens": [
          50364,
          400,
          309,
          311,
          534,
          4961,
          337,
          385,
          281,
          1499,
          11,
          50442
        ]
      },
      {
        "avg_logprob": -0.3863708842884411,
        "compression_ratio": 1.5725806451612903,
        "end": 8268.76,
        "id": 2458,
        "no_speech_prob": 0.00118786480743438,
        "seek": 826452,
        "start": 8266.08,
        "temperature": 0,
        "text": " continue to develop better strategies",
        "tokens": [
          50442,
          2354,
          281,
          1499,
          1101,
          9029,
          50576
        ]
      },
      {
        "avg_logprob": -0.3863708842884411,
        "compression_ratio": 1.5725806451612903,
        "end": 8270.4,
        "id": 2459,
        "no_speech_prob": 0.00118786480743438,
        "seek": 826452,
        "start": 8268.76,
        "temperature": 0,
        "text": " for debugging to demonstrate.",
        "tokens": [
          50576,
          337,
          45592,
          281,
          11698,
          13,
          50658
        ]
      },
      {
        "avg_logprob": -0.3863708842884411,
        "compression_ratio": 1.5725806451612903,
        "end": 8272.960000000001,
        "id": 2460,
        "no_speech_prob": 0.00118786480743438,
        "seek": 826452,
        "start": 8270.4,
        "temperature": 0,
        "text": " You mean you don't like my technique of having a bug",
        "tokens": [
          50658,
          509,
          914,
          291,
          500,
          380,
          411,
          452,
          6532,
          295,
          1419,
          257,
          7426,
          50786
        ]
      },
      {
        "avg_logprob": -0.3863708842884411,
        "compression_ratio": 1.5725806451612903,
        "end": 8274.720000000001,
        "id": 2461,
        "no_speech_prob": 0.00118786480743438,
        "seek": 826452,
        "start": 8272.960000000001,
        "temperature": 0,
        "text": " and just sitting there going like this?",
        "tokens": [
          50786,
          293,
          445,
          3798,
          456,
          516,
          411,
          341,
          30,
          50874
        ]
      },
      {
        "avg_logprob": -0.3863708842884411,
        "compression_ratio": 1.5725806451612903,
        "end": 8276.44,
        "id": 2462,
        "no_speech_prob": 0.00118786480743438,
        "seek": 826452,
        "start": 8274.720000000001,
        "temperature": 0,
        "text": " You're like, maybe the chat will tell me",
        "tokens": [
          50874,
          509,
          434,
          411,
          11,
          1310,
          264,
          5081,
          486,
          980,
          385,
          50960
        ]
      },
      {
        "avg_logprob": -0.3863708842884411,
        "compression_ratio": 1.5725806451612903,
        "end": 8277.960000000001,
        "id": 2463,
        "no_speech_prob": 0.00118786480743438,
        "seek": 826452,
        "start": 8276.44,
        "temperature": 0,
        "text": " what's wrong in just a minute.",
        "tokens": [
          50960,
          437,
          311,
          2085,
          294,
          445,
          257,
          3456,
          13,
          51036
        ]
      },
      {
        "avg_logprob": -0.3863708842884411,
        "compression_ratio": 1.5725806451612903,
        "end": 8285.220000000001,
        "id": 2464,
        "no_speech_prob": 0.00118786480743438,
        "seek": 826452,
        "start": 8282.04,
        "temperature": 0,
        "text": " Do you code, Tim asks, do you code any other languages",
        "tokens": [
          51240,
          1144,
          291,
          3089,
          11,
          7172,
          8962,
          11,
          360,
          291,
          3089,
          604,
          661,
          8650,
          51399
        ]
      },
      {
        "avg_logprob": -0.3863708842884411,
        "compression_ratio": 1.5725806451612903,
        "end": 8287.24,
        "id": 2465,
        "no_speech_prob": 0.00118786480743438,
        "seek": 826452,
        "start": 8285.220000000001,
        "temperature": 0,
        "text": " than JavaScript?",
        "tokens": [
          51399,
          813,
          15778,
          30,
          51500
        ]
      },
      {
        "avg_logprob": -0.3863708842884411,
        "compression_ratio": 1.5725806451612903,
        "end": 8288.44,
        "id": 2466,
        "no_speech_prob": 0.00118786480743438,
        "seek": 826452,
        "start": 8287.24,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          51500,
          1079,
          13,
          51560
        ]
      },
      {
        "avg_logprob": -0.3863708842884411,
        "compression_ratio": 1.5725806451612903,
        "end": 8291.52,
        "id": 2467,
        "no_speech_prob": 0.00118786480743438,
        "seek": 826452,
        "start": 8288.44,
        "temperature": 0,
        "text": " So I do a lot of programming in Java,",
        "tokens": [
          51560,
          407,
          286,
          360,
          257,
          688,
          295,
          9410,
          294,
          10745,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.3514427535835354,
        "compression_ratio": 1.5658536585365854,
        "end": 8293.880000000001,
        "id": 2468,
        "no_speech_prob": 0.000042633910197764635,
        "seek": 829152,
        "start": 8291.52,
        "temperature": 0,
        "text": " specifically using Processing,",
        "tokens": [
          50364,
          4682,
          1228,
          31093,
          278,
          11,
          50482
        ]
      },
      {
        "avg_logprob": -0.3514427535835354,
        "compression_ratio": 1.5658536585365854,
        "end": 8298.32,
        "id": 2469,
        "no_speech_prob": 0.000042633910197764635,
        "seek": 829152,
        "start": 8293.880000000001,
        "temperature": 0,
        "text": " which is a Java based platform, you can download here.",
        "tokens": [
          50482,
          597,
          307,
          257,
          10745,
          2361,
          3663,
          11,
          291,
          393,
          5484,
          510,
          13,
          50704
        ]
      },
      {
        "avg_logprob": -0.3514427535835354,
        "compression_ratio": 1.5658536585365854,
        "end": 8300.720000000001,
        "id": 2470,
        "no_speech_prob": 0.000042633910197764635,
        "seek": 829152,
        "start": 8298.32,
        "temperature": 0,
        "text": " I actually was thinking of doing the quick draw stuff",
        "tokens": [
          50704,
          286,
          767,
          390,
          1953,
          295,
          884,
          264,
          1702,
          2642,
          1507,
          50824
        ]
      },
      {
        "avg_logprob": -0.3514427535835354,
        "compression_ratio": 1.5658536585365854,
        "end": 8304.08,
        "id": 2471,
        "no_speech_prob": 0.000042633910197764635,
        "seek": 829152,
        "start": 8300.720000000001,
        "temperature": 0,
        "text": " in Processing, because of loading the big files,",
        "tokens": [
          50824,
          294,
          31093,
          278,
          11,
          570,
          295,
          15114,
          264,
          955,
          7098,
          11,
          50992
        ]
      },
      {
        "avg_logprob": -0.3514427535835354,
        "compression_ratio": 1.5658536585365854,
        "end": 8305.52,
        "id": 2472,
        "no_speech_prob": 0.000042633910197764635,
        "seek": 829152,
        "start": 8304.08,
        "temperature": 0,
        "text": " I didn't want to deal with setting up a server,",
        "tokens": [
          50992,
          286,
          994,
          380,
          528,
          281,
          2028,
          365,
          3287,
          493,
          257,
          7154,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.3514427535835354,
        "compression_ratio": 1.5658536585365854,
        "end": 8307.36,
        "id": 2473,
        "no_speech_prob": 0.000042633910197764635,
        "seek": 829152,
        "start": 8305.52,
        "temperature": 0,
        "text": " but then I went ahead and did the node things,",
        "tokens": [
          51064,
          457,
          550,
          286,
          1437,
          2286,
          293,
          630,
          264,
          9984,
          721,
          11,
          51156
        ]
      },
      {
        "avg_logprob": -0.3514427535835354,
        "compression_ratio": 1.5658536585365854,
        "end": 8308.960000000001,
        "id": 2474,
        "no_speech_prob": 0.000042633910197764635,
        "seek": 829152,
        "start": 8307.36,
        "temperature": 0,
        "text": " I thought that was interesting.",
        "tokens": [
          51156,
          286,
          1194,
          300,
          390,
          1880,
          13,
          51236
        ]
      },
      {
        "avg_logprob": -0.3514427535835354,
        "compression_ratio": 1.5658536585365854,
        "end": 8310.880000000001,
        "id": 2475,
        "no_speech_prob": 0.000042633910197764635,
        "seek": 829152,
        "start": 8310.04,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51290,
          1033,
          13,
          51332
        ]
      },
      {
        "avg_logprob": -3.790250543962445,
        "compression_ratio": 1.4634146341463414,
        "end": 8313.859999999999,
        "id": 2476,
        "no_speech_prob": 0.4708526134490967,
        "seek": 831088,
        "start": 8311.839999999998,
        "temperature": 1,
        "text": " So I will not just upload text,",
        "tokens": [
          50412,
          407,
          286,
          486,
          406,
          445,
          6580,
          2487,
          11,
          50513
        ]
      },
      {
        "avg_logprob": -3.790250543962445,
        "compression_ratio": 1.4634146341463414,
        "end": 8317.599999999999,
        "id": 2477,
        "no_speech_prob": 0.4708526134490967,
        "seek": 831088,
        "start": 8315.72,
        "temperature": 1,
        "text": " double double click,",
        "tokens": [
          50606,
          3834,
          3834,
          2052,
          11,
          50700
        ]
      },
      {
        "avg_logprob": -3.790250543962445,
        "compression_ratio": 1.4634146341463414,
        "end": 8319.599999999999,
        "id": 2478,
        "no_speech_prob": 0.4708526134490967,
        "seek": 831088,
        "start": 8317.599999999999,
        "temperature": 1,
        "text": " and then actually just run the program",
        "tokens": [
          50700,
          293,
          550,
          767,
          445,
          1190,
          264,
          1461,
          50800
        ]
      },
      {
        "avg_logprob": -3.790250543962445,
        "compression_ratio": 1.4634146341463414,
        "end": 8322.179999999998,
        "id": 2479,
        "no_speech_prob": 0.4708526134490967,
        "seek": 831088,
        "start": 8319.599999999999,
        "temperature": 1,
        "text": " and not follow all the steps and get all the equipment",
        "tokens": [
          50800,
          293,
          406,
          1524,
          439,
          264,
          4439,
          220,
          282,
          67,
          483,
          439,
          264,
          1267,
          647,
          518,
          50929
        ]
      },
      {
        "avg_logprob": -3.790250543962445,
        "compression_ratio": 1.4634146341463414,
        "end": 8335.88,
        "id": 2480,
        "no_speech_prob": 0.4708526134490967,
        "seek": 831088,
        "start": 8322.179999999998,
        "temperature": 1,
        "text": " fast forward",
        "tokens": [
          50929,
          283,
          64,
          372,
          2128,
          51614
        ]
      },
      {
        "avg_logprob": -3.790250543962445,
        "compression_ratio": 1.4634146341463414,
        "end": 8339.679999999998,
        "id": 2481,
        "no_speech_prob": 0.4708526134490967,
        "seek": 831088,
        "start": 8338.38,
        "temperature": 1,
        "text": " and then receive it,",
        "tokens": [
          51739,
          293,
          550,
          4774,
          309,
          11,
          51804
        ]
      },
      {
        "avg_logprob": -0.4423358676669834,
        "compression_ratio": 1.546938775510204,
        "end": 8340.76,
        "id": 2482,
        "no_speech_prob": 0.039610907435417175,
        "seek": 833968,
        "start": 8339.68,
        "temperature": 0.2,
        "text": " and then start in the JS file",
        "tokens": [
          50364,
          293,
          550,
          722,
          294,
          264,
          33063,
          3991,
          50418
        ]
      },
      {
        "avg_logprob": -0.4423358676669834,
        "compression_ratio": 1.546938775510204,
        "end": 8343.52,
        "id": 2483,
        "no_speech_prob": 0.039610907435417175,
        "seek": 833968,
        "start": 8340.76,
        "temperature": 0.2,
        "text": " and Chrome will stop at that break point for you.",
        "tokens": [
          50418,
          293,
          15327,
          486,
          1590,
          412,
          300,
          1821,
          935,
          337,
          291,
          13,
          50556
        ]
      },
      {
        "avg_logprob": -0.4423358676669834,
        "compression_ratio": 1.546938775510204,
        "end": 8345.2,
        "id": 2484,
        "no_speech_prob": 0.039610907435417175,
        "seek": 833968,
        "start": 8343.52,
        "temperature": 0.2,
        "text": " I should probably try that at some point.",
        "tokens": [
          50556,
          286,
          820,
          1391,
          853,
          300,
          412,
          512,
          935,
          13,
          50640
        ]
      },
      {
        "avg_logprob": -0.4423358676669834,
        "compression_ratio": 1.546938775510204,
        "end": 8347.2,
        "id": 2485,
        "no_speech_prob": 0.039610907435417175,
        "seek": 833968,
        "start": 8345.2,
        "temperature": 0.2,
        "text": " That's a very good suggestion, thank you.",
        "tokens": [
          50640,
          663,
          311,
          257,
          588,
          665,
          16541,
          11,
          1309,
          291,
          13,
          50740
        ]
      },
      {
        "avg_logprob": -0.4423358676669834,
        "compression_ratio": 1.546938775510204,
        "end": 8350.64,
        "id": 2486,
        "no_speech_prob": 0.039610907435417175,
        "seek": 833968,
        "start": 8348.720000000001,
        "temperature": 0.2,
        "text": " Thank you, Joop, for your kind comment.",
        "tokens": [
          50816,
          1044,
          291,
          11,
          3139,
          404,
          11,
          337,
          428,
          733,
          2871,
          13,
          50912
        ]
      },
      {
        "avg_logprob": -0.4423358676669834,
        "compression_ratio": 1.546938775510204,
        "end": 8353.720000000001,
        "id": 2487,
        "no_speech_prob": 0.039610907435417175,
        "seek": 833968,
        "start": 8350.64,
        "temperature": 0.2,
        "text": " What classes do you teach and what are they about code?",
        "tokens": [
          50912,
          708,
          5359,
          360,
          291,
          2924,
          293,
          437,
          366,
          436,
          466,
          3089,
          30,
          51066
        ]
      },
      {
        "avg_logprob": -0.4423358676669834,
        "compression_ratio": 1.546938775510204,
        "end": 8361,
        "id": 2488,
        "no_speech_prob": 0.039610907435417175,
        "seek": 833968,
        "start": 8356,
        "temperature": 0.2,
        "text": " All right, so very quickly I will answer Aki MC's question.",
        "tokens": [
          51180,
          1057,
          558,
          11,
          370,
          588,
          2661,
          286,
          486,
          1867,
          316,
          2984,
          8797,
          311,
          1168,
          13,
          51430
        ]
      },
      {
        "avg_logprob": -0.4423358676669834,
        "compression_ratio": 1.546938775510204,
        "end": 8363.84,
        "id": 2489,
        "no_speech_prob": 0.039610907435417175,
        "seek": 833968,
        "start": 8361.48,
        "temperature": 0.2,
        "text": " Thank you to I, Luis Mise,",
        "tokens": [
          51454,
          1044,
          291,
          281,
          286,
          11,
          25133,
          376,
          908,
          11,
          51572
        ]
      },
      {
        "avg_logprob": -0.4423358676669834,
        "compression_ratio": 1.546938775510204,
        "end": 8366.1,
        "id": 2490,
        "no_speech_prob": 0.039610907435417175,
        "seek": 833968,
        "start": 8363.84,
        "temperature": 0.2,
        "text": " who has added two pull requests.",
        "tokens": [
          51572,
          567,
          575,
          3869,
          732,
          2235,
          12475,
          13,
          51685
        ]
      },
      {
        "avg_logprob": -0.27942939696273184,
        "compression_ratio": 1.6458333333333333,
        "end": 8369.98,
        "id": 2491,
        "no_speech_prob": 0.008444528095424175,
        "seek": 836610,
        "start": 8366.7,
        "temperature": 0,
        "text": " So I teach classes at New York University,",
        "tokens": [
          50394,
          407,
          286,
          2924,
          5359,
          412,
          1873,
          3609,
          3535,
          11,
          50558
        ]
      },
      {
        "avg_logprob": -0.27942939696273184,
        "compression_ratio": 1.6458333333333333,
        "end": 8371.220000000001,
        "id": 2492,
        "no_speech_prob": 0.008444528095424175,
        "seek": 836610,
        "start": 8369.98,
        "temperature": 0,
        "text": " a part of Tisch School of the Arts.",
        "tokens": [
          50558,
          257,
          644,
          295,
          48192,
          5070,
          295,
          264,
          12407,
          13,
          50620
        ]
      },
      {
        "avg_logprob": -0.27942939696273184,
        "compression_ratio": 1.6458333333333333,
        "end": 8372.9,
        "id": 2493,
        "no_speech_prob": 0.008444528095424175,
        "seek": 836610,
        "start": 8371.220000000001,
        "temperature": 0,
        "text": " There's a grad program called ITP",
        "tokens": [
          50620,
          821,
          311,
          257,
          2771,
          1461,
          1219,
          6783,
          47,
          50704
        ]
      },
      {
        "avg_logprob": -0.27942939696273184,
        "compression_ratio": 1.6458333333333333,
        "end": 8375.34,
        "id": 2494,
        "no_speech_prob": 0.008444528095424175,
        "seek": 836610,
        "start": 8372.9,
        "temperature": 0,
        "text": " and an undergrad program called IMA.",
        "tokens": [
          50704,
          293,
          364,
          14295,
          1461,
          1219,
          286,
          9998,
          13,
          50826
        ]
      },
      {
        "avg_logprob": -0.27942939696273184,
        "compression_ratio": 1.6458333333333333,
        "end": 8379.140000000001,
        "id": 2495,
        "no_speech_prob": 0.008444528095424175,
        "seek": 836610,
        "start": 8375.34,
        "temperature": 0,
        "text": " And then online I make videos for this YouTube channel",
        "tokens": [
          50826,
          400,
          550,
          2950,
          286,
          652,
          2145,
          337,
          341,
          3088,
          2269,
          51016
        ]
      },
      {
        "avg_logprob": -0.27942939696273184,
        "compression_ratio": 1.6458333333333333,
        "end": 8381.58,
        "id": 2496,
        "no_speech_prob": 0.008444528095424175,
        "seek": 836610,
        "start": 8379.140000000001,
        "temperature": 0,
        "text": " and some of them are loosely grouped into things",
        "tokens": [
          51016,
          293,
          512,
          295,
          552,
          366,
          37966,
          41877,
          666,
          721,
          51138
        ]
      },
      {
        "avg_logprob": -0.27942939696273184,
        "compression_ratio": 1.6458333333333333,
        "end": 8384.1,
        "id": 2497,
        "no_speech_prob": 0.008444528095424175,
        "seek": 836610,
        "start": 8381.58,
        "temperature": 0,
        "text": " that could possibly somewhat be classes,",
        "tokens": [
          51138,
          300,
          727,
          6264,
          8344,
          312,
          5359,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.27942939696273184,
        "compression_ratio": 1.6458333333333333,
        "end": 8386.380000000001,
        "id": 2498,
        "no_speech_prob": 0.008444528095424175,
        "seek": 836610,
        "start": 8384.1,
        "temperature": 0,
        "text": " but I haven't really cracked that nut yet",
        "tokens": [
          51264,
          457,
          286,
          2378,
          380,
          534,
          25140,
          300,
          5393,
          1939,
          51378
        ]
      },
      {
        "avg_logprob": -0.27942939696273184,
        "compression_ratio": 1.6458333333333333,
        "end": 8389.56,
        "id": 2499,
        "no_speech_prob": 0.008444528095424175,
        "seek": 836610,
        "start": 8386.380000000001,
        "temperature": 0,
        "text": " of like this thing on YouTube is a course",
        "tokens": [
          51378,
          295,
          411,
          341,
          551,
          322,
          3088,
          307,
          257,
          1164,
          51537
        ]
      },
      {
        "avg_logprob": -0.27942939696273184,
        "compression_ratio": 1.6458333333333333,
        "end": 8390.56,
        "id": 2500,
        "no_speech_prob": 0.008444528095424175,
        "seek": 836610,
        "start": 8389.56,
        "temperature": 0,
        "text": " that you could take.",
        "tokens": [
          51537,
          300,
          291,
          727,
          747,
          13,
          51587
        ]
      },
      {
        "avg_logprob": -0.27942939696273184,
        "compression_ratio": 1.6458333333333333,
        "end": 8392.06,
        "id": 2501,
        "no_speech_prob": 0.008444528095424175,
        "seek": 836610,
        "start": 8390.56,
        "temperature": 0,
        "text": " It's really just a lot of content",
        "tokens": [
          51587,
          467,
          311,
          534,
          445,
          257,
          688,
          295,
          2701,
          51662
        ]
      },
      {
        "avg_logprob": -0.27942939696273184,
        "compression_ratio": 1.6458333333333333,
        "end": 8394.380000000001,
        "id": 2502,
        "no_speech_prob": 0.008444528095424175,
        "seek": 836610,
        "start": 8392.06,
        "temperature": 0,
        "text": " and hopefully inspirational and helpful,",
        "tokens": [
          51662,
          293,
          4696,
          33554,
          293,
          4961,
          11,
          51778
        ]
      },
      {
        "avg_logprob": -0.28513959801715355,
        "compression_ratio": 1.6558704453441295,
        "end": 8396.9,
        "id": 2503,
        "no_speech_prob": 0.000004289326625439571,
        "seek": 839438,
        "start": 8394.38,
        "temperature": 0,
        "text": " but in terms of the actual things being a course,",
        "tokens": [
          50364,
          457,
          294,
          2115,
          295,
          264,
          3539,
          721,
          885,
          257,
          1164,
          11,
          50490
        ]
      },
      {
        "avg_logprob": -0.28513959801715355,
        "compression_ratio": 1.6558704453441295,
        "end": 8398.58,
        "id": 2504,
        "no_speech_prob": 0.000004289326625439571,
        "seek": 839438,
        "start": 8396.9,
        "temperature": 0,
        "text": " the place where you can look,",
        "tokens": [
          50490,
          264,
          1081,
          689,
          291,
          393,
          574,
          11,
          50574
        ]
      },
      {
        "avg_logprob": -0.28513959801715355,
        "compression_ratio": 1.6558704453441295,
        "end": 8402.539999999999,
        "id": 2505,
        "no_speech_prob": 0.000004289326625439571,
        "seek": 839438,
        "start": 8399.74,
        "temperature": 0,
        "text": " one thing is I'm really trying to do is in theory",
        "tokens": [
          50632,
          472,
          551,
          307,
          286,
          478,
          534,
          1382,
          281,
          360,
          307,
          294,
          5261,
          50772
        ]
      },
      {
        "avg_logprob": -0.28513959801715355,
        "compression_ratio": 1.6558704453441295,
        "end": 8404.339999999998,
        "id": 2506,
        "no_speech_prob": 0.000004289326625439571,
        "seek": 839438,
        "start": 8402.539999999999,
        "temperature": 0,
        "text": " I would like to continue to work on",
        "tokens": [
          50772,
          286,
          576,
          411,
          281,
          2354,
          281,
          589,
          322,
          50862
        ]
      },
      {
        "avg_logprob": -0.28513959801715355,
        "compression_ratio": 1.6558704453441295,
        "end": 8406.9,
        "id": 2507,
        "no_speech_prob": 0.000004289326625439571,
        "seek": 839438,
        "start": 8404.339999999998,
        "temperature": 0,
        "text": " and improve the navigation here.",
        "tokens": [
          50862,
          293,
          3470,
          264,
          17346,
          510,
          13,
          50990
        ]
      },
      {
        "avg_logprob": -0.28513959801715355,
        "compression_ratio": 1.6558704453441295,
        "end": 8409.32,
        "id": 2508,
        "no_speech_prob": 0.000004289326625439571,
        "seek": 839438,
        "start": 8406.9,
        "temperature": 0,
        "text": " So there are some,",
        "tokens": [
          50990,
          407,
          456,
          366,
          512,
          11,
          51111
        ]
      },
      {
        "avg_logprob": -0.28513959801715355,
        "compression_ratio": 1.6558704453441295,
        "end": 8414.06,
        "id": 2509,
        "no_speech_prob": 0.000004289326625439571,
        "seek": 839438,
        "start": 8410.82,
        "temperature": 0,
        "text": " so in theory I would like this website to be a place",
        "tokens": [
          51186,
          370,
          294,
          5261,
          286,
          576,
          411,
          341,
          3144,
          281,
          312,
          257,
          1081,
          51348
        ]
      },
      {
        "avg_logprob": -0.28513959801715355,
        "compression_ratio": 1.6558704453441295,
        "end": 8418.14,
        "id": 2510,
        "no_speech_prob": 0.000004289326625439571,
        "seek": 839438,
        "start": 8414.06,
        "temperature": 0,
        "text": " where it's easier to find the packaged courses.",
        "tokens": [
          51348,
          689,
          309,
          311,
          3571,
          281,
          915,
          264,
          38162,
          7712,
          13,
          51552
        ]
      },
      {
        "avg_logprob": -0.28513959801715355,
        "compression_ratio": 1.6558704453441295,
        "end": 8419.8,
        "id": 2511,
        "no_speech_prob": 0.000004289326625439571,
        "seek": 839438,
        "start": 8418.14,
        "temperature": 0,
        "text": " Right now if you're looking for that,",
        "tokens": [
          51552,
          1779,
          586,
          498,
          291,
          434,
          1237,
          337,
          300,
          11,
          51635
        ]
      },
      {
        "avg_logprob": -0.28513959801715355,
        "compression_ratio": 1.6558704453441295,
        "end": 8423.539999999999,
        "id": 2512,
        "no_speech_prob": 0.000004289326625439571,
        "seek": 839438,
        "start": 8419.8,
        "temperature": 0,
        "text": " I think if you go to YouTube Coding Train Playlists,",
        "tokens": [
          51635,
          286,
          519,
          498,
          291,
          352,
          281,
          3088,
          383,
          8616,
          28029,
          5506,
          36693,
          11,
          51822
        ]
      },
      {
        "avg_logprob": -0.3185855656454008,
        "compression_ratio": 1.4430379746835442,
        "end": 8424.54,
        "id": 2513,
        "no_speech_prob": 0.0000027264566142548574,
        "seek": 842354,
        "start": 8423.54,
        "temperature": 0,
        "text": " Playlists,",
        "tokens": [
          50364,
          5506,
          36693,
          11,
          50414
        ]
      },
      {
        "avg_logprob": -0.3185855656454008,
        "compression_ratio": 1.4430379746835442,
        "end": 8429.740000000002,
        "id": 2514,
        "no_speech_prob": 0.0000027264566142548574,
        "seek": 842354,
        "start": 8427.34,
        "temperature": 0,
        "text": " and if I do All Playlists,",
        "tokens": [
          50554,
          293,
          498,
          286,
          360,
          1057,
          5506,
          36693,
          11,
          50674
        ]
      },
      {
        "avg_logprob": -0.3185855656454008,
        "compression_ratio": 1.4430379746835442,
        "end": 8435.94,
        "id": 2515,
        "no_speech_prob": 0.0000027264566142548574,
        "seek": 842354,
        "start": 8433.26,
        "temperature": 0,
        "text": " whoops, you can see,",
        "tokens": [
          50850,
          567,
          3370,
          11,
          291,
          393,
          536,
          11,
          50984
        ]
      },
      {
        "avg_logprob": -0.3185855656454008,
        "compression_ratio": 1.4430379746835442,
        "end": 8438.36,
        "id": 2516,
        "no_speech_prob": 0.0000027264566142548574,
        "seek": 842354,
        "start": 8435.94,
        "temperature": 0,
        "text": " but this is a big mess of things.",
        "tokens": [
          50984,
          457,
          341,
          307,
          257,
          955,
          2082,
          295,
          721,
          13,
          51105
        ]
      },
      {
        "avg_logprob": -0.3185855656454008,
        "compression_ratio": 1.4430379746835442,
        "end": 8441.060000000001,
        "id": 2517,
        "no_speech_prob": 0.0000027264566142548574,
        "seek": 842354,
        "start": 8438.36,
        "temperature": 0,
        "text": " So I'm trying to figure this out.",
        "tokens": [
          51105,
          407,
          286,
          478,
          1382,
          281,
          2573,
          341,
          484,
          13,
          51240
        ]
      },
      {
        "avg_logprob": -0.3185855656454008,
        "compression_ratio": 1.4430379746835442,
        "end": 8443.580000000002,
        "id": 2518,
        "no_speech_prob": 0.0000027264566142548574,
        "seek": 842354,
        "start": 8441.060000000001,
        "temperature": 0,
        "text": " Some things are organized, for example,",
        "tokens": [
          51240,
          2188,
          721,
          366,
          9983,
          11,
          337,
          1365,
          11,
          51366
        ]
      },
      {
        "avg_logprob": -0.3185855656454008,
        "compression_ratio": 1.4430379746835442,
        "end": 8449.54,
        "id": 2519,
        "no_speech_prob": 0.0000027264566142548574,
        "seek": 842354,
        "start": 8447.94,
        "temperature": 0,
        "text": " you can see here these are",
        "tokens": [
          51584,
          291,
          393,
          536,
          510,
          613,
          366,
          51664
        ]
      },
      {
        "avg_logprob": -0.3185855656454008,
        "compression_ratio": 1.4430379746835442,
        "end": 8452.18,
        "id": 2520,
        "no_speech_prob": 0.0000027264566142548574,
        "seek": 842354,
        "start": 8449.54,
        "temperature": 0,
        "text": " the beginner JavaScript tutorials,",
        "tokens": [
          51664,
          264,
          22080,
          15778,
          17616,
          11,
          51796
        ]
      },
      {
        "avg_logprob": -0.29063094664956923,
        "compression_ratio": 1.595330739299611,
        "end": 8453.460000000001,
        "id": 2521,
        "no_speech_prob": 0.00005649766171700321,
        "seek": 845218,
        "start": 8452.18,
        "temperature": 0,
        "text": " Playlists one through seven,",
        "tokens": [
          50364,
          5506,
          36693,
          472,
          807,
          3407,
          11,
          50428
        ]
      },
      {
        "avg_logprob": -0.29063094664956923,
        "compression_ratio": 1.595330739299611,
        "end": 8456.1,
        "id": 2522,
        "no_speech_prob": 0.00005649766171700321,
        "seek": 845218,
        "start": 8453.460000000001,
        "temperature": 0,
        "text": " Playlist eight, et cetera.",
        "tokens": [
          50428,
          5506,
          8264,
          3180,
          11,
          1030,
          11458,
          13,
          50560
        ]
      },
      {
        "avg_logprob": -0.29063094664956923,
        "compression_ratio": 1.595330739299611,
        "end": 8457.74,
        "id": 2523,
        "no_speech_prob": 0.00005649766171700321,
        "seek": 845218,
        "start": 8456.1,
        "temperature": 0,
        "text": " These are some playlists associated",
        "tokens": [
          50560,
          1981,
          366,
          512,
          862,
          36693,
          6615,
          50642
        ]
      },
      {
        "avg_logprob": -0.29063094664956923,
        "compression_ratio": 1.595330739299611,
        "end": 8460.1,
        "id": 2524,
        "no_speech_prob": 0.00005649766171700321,
        "seek": 845218,
        "start": 8457.74,
        "temperature": 0,
        "text": " with neural networks and machine learning.",
        "tokens": [
          50642,
          365,
          18161,
          9590,
          293,
          3479,
          2539,
          13,
          50760
        ]
      },
      {
        "avg_logprob": -0.29063094664956923,
        "compression_ratio": 1.595330739299611,
        "end": 8462.34,
        "id": 2525,
        "no_speech_prob": 0.00005649766171700321,
        "seek": 845218,
        "start": 8460.1,
        "temperature": 0,
        "text": " This is an old antiquated Twitter bot tutorial",
        "tokens": [
          50760,
          639,
          307,
          364,
          1331,
          41036,
          770,
          5794,
          10592,
          7073,
          50872
        ]
      },
      {
        "avg_logprob": -0.29063094664956923,
        "compression_ratio": 1.595330739299611,
        "end": 8463.460000000001,
        "id": 2526,
        "no_speech_prob": 0.00005649766171700321,
        "seek": 845218,
        "start": 8462.34,
        "temperature": 0,
        "text": " that probably doesn't work anymore.",
        "tokens": [
          50872,
          300,
          1391,
          1177,
          380,
          589,
          3602,
          13,
          50928
        ]
      },
      {
        "avg_logprob": -0.29063094664956923,
        "compression_ratio": 1.595330739299611,
        "end": 8465.66,
        "id": 2527,
        "no_speech_prob": 0.00005649766171700321,
        "seek": 845218,
        "start": 8463.460000000001,
        "temperature": 0,
        "text": " These are some old nature of code videos.",
        "tokens": [
          50928,
          1981,
          366,
          512,
          1331,
          3687,
          295,
          3089,
          2145,
          13,
          51038
        ]
      },
      {
        "avg_logprob": -0.29063094664956923,
        "compression_ratio": 1.595330739299611,
        "end": 8468.380000000001,
        "id": 2528,
        "no_speech_prob": 0.00005649766171700321,
        "seek": 845218,
        "start": 8465.66,
        "temperature": 0,
        "text": " Here's the beginner processing videos, Git and GitHub.",
        "tokens": [
          51038,
          1692,
          311,
          264,
          22080,
          9007,
          2145,
          11,
          16939,
          293,
          23331,
          13,
          51174
        ]
      },
      {
        "avg_logprob": -0.29063094664956923,
        "compression_ratio": 1.595330739299611,
        "end": 8473.26,
        "id": 2529,
        "no_speech_prob": 0.00005649766171700321,
        "seek": 845218,
        "start": 8468.380000000001,
        "temperature": 0,
        "text": " But again, please somebody save me",
        "tokens": [
          51174,
          583,
          797,
          11,
          1767,
          2618,
          3155,
          385,
          51418
        ]
      },
      {
        "avg_logprob": -0.29063094664956923,
        "compression_ratio": 1.595330739299611,
        "end": 8476.220000000001,
        "id": 2530,
        "no_speech_prob": 0.00005649766171700321,
        "seek": 845218,
        "start": 8473.26,
        "temperature": 0,
        "text": " and help me figure out how to organize all this stuff.",
        "tokens": [
          51418,
          293,
          854,
          385,
          2573,
          484,
          577,
          281,
          13859,
          439,
          341,
          1507,
          13,
          51566
        ]
      },
      {
        "avg_logprob": -0.29063094664956923,
        "compression_ratio": 1.595330739299611,
        "end": 8477.06,
        "id": 2531,
        "no_speech_prob": 0.00005649766171700321,
        "seek": 845218,
        "start": 8476.220000000001,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51566,
          1033,
          13,
          51608
        ]
      },
      {
        "avg_logprob": -0.35635551573738217,
        "compression_ratio": 1.4705882352941178,
        "end": 8481.3,
        "id": 2532,
        "no_speech_prob": 0.000024300175937241875,
        "seek": 847706,
        "start": 8477.56,
        "temperature": 0,
        "text": " Why not create a storyboard for the website?",
        "tokens": [
          50389,
          220,
          8429,
          406,
          1884,
          257,
          1657,
          3787,
          337,
          264,
          3144,
          30,
          50576
        ]
      },
      {
        "avg_logprob": -0.35635551573738217,
        "compression_ratio": 1.4705882352941178,
        "end": 8488.859999999999,
        "id": 2533,
        "no_speech_prob": 0.000024300175937241875,
        "seek": 847706,
        "start": 8486.539999999999,
        "temperature": 0,
        "text": " Yes, actually, so Matthew,",
        "tokens": [
          50838,
          1079,
          11,
          767,
          11,
          370,
          12434,
          11,
          50954
        ]
      },
      {
        "avg_logprob": -0.35635551573738217,
        "compression_ratio": 1.4705882352941178,
        "end": 8492.8,
        "id": 2534,
        "no_speech_prob": 0.000024300175937241875,
        "seek": 847706,
        "start": 8488.859999999999,
        "temperature": 0,
        "text": " if you go to the GitHub repository for the website,",
        "tokens": [
          50954,
          498,
          291,
          352,
          281,
          264,
          23331,
          25841,
          337,
          264,
          3144,
          11,
          51151
        ]
      },
      {
        "avg_logprob": -0.35635551573738217,
        "compression_ratio": 1.4705882352941178,
        "end": 8495.9,
        "id": 2535,
        "no_speech_prob": 0.000024300175937241875,
        "seek": 847706,
        "start": 8494.26,
        "temperature": 0,
        "text": " if you go under Issues,",
        "tokens": [
          51224,
          498,
          291,
          352,
          833,
          38195,
          1247,
          11,
          51306
        ]
      },
      {
        "avg_logprob": -0.35635551573738217,
        "compression_ratio": 1.4705882352941178,
        "end": 8498.6,
        "id": 2536,
        "no_speech_prob": 0.000024300175937241875,
        "seek": 847706,
        "start": 8495.9,
        "temperature": 0,
        "text": " there are a few different issues",
        "tokens": [
          51306,
          456,
          366,
          257,
          1326,
          819,
          2663,
          51441
        ]
      },
      {
        "avg_logprob": -0.35635551573738217,
        "compression_ratio": 1.4705882352941178,
        "end": 8503.5,
        "id": 2537,
        "no_speech_prob": 0.000024300175937241875,
        "seek": 847706,
        "start": 8498.6,
        "temperature": 0,
        "text": " that are currently tracking this discussion.",
        "tokens": [
          51441,
          300,
          366,
          4362,
          11603,
          341,
          5017,
          13,
          51686
        ]
      },
      {
        "avg_logprob": -0.27119223854758523,
        "compression_ratio": 1.7,
        "end": 8508.44,
        "id": 2538,
        "no_speech_prob": 0.0000035007979022338986,
        "seek": 850350,
        "start": 8503.5,
        "temperature": 0,
        "text": " So this is one proposal to have the website organized",
        "tokens": [
          50364,
          407,
          341,
          307,
          472,
          11494,
          281,
          362,
          264,
          3144,
          9983,
          50611
        ]
      },
      {
        "avg_logprob": -0.27119223854758523,
        "compression_ratio": 1.7,
        "end": 8511.98,
        "id": 2539,
        "no_speech_prob": 0.0000035007979022338986,
        "seek": 850350,
        "start": 8508.44,
        "temperature": 0,
        "text": " as coding challenges, beginner playlists,",
        "tokens": [
          50611,
          382,
          17720,
          4759,
          11,
          22080,
          862,
          36693,
          11,
          50788
        ]
      },
      {
        "avg_logprob": -0.27119223854758523,
        "compression_ratio": 1.7,
        "end": 8516.88,
        "id": 2540,
        "no_speech_prob": 0.0000035007979022338986,
        "seek": 850350,
        "start": 8511.98,
        "temperature": 0,
        "text": " and then other courses that are not for beginners.",
        "tokens": [
          50788,
          293,
          550,
          661,
          7712,
          300,
          366,
          406,
          337,
          26992,
          13,
          51033
        ]
      },
      {
        "avg_logprob": -0.27119223854758523,
        "compression_ratio": 1.7,
        "end": 8518.26,
        "id": 2541,
        "no_speech_prob": 0.0000035007979022338986,
        "seek": 850350,
        "start": 8516.88,
        "temperature": 0,
        "text": " So that's one thing that,",
        "tokens": [
          51033,
          407,
          300,
          311,
          472,
          551,
          300,
          11,
          51102
        ]
      },
      {
        "avg_logprob": -0.27119223854758523,
        "compression_ratio": 1.7,
        "end": 8519.88,
        "id": 2542,
        "no_speech_prob": 0.0000035007979022338986,
        "seek": 850350,
        "start": 8518.26,
        "temperature": 0,
        "text": " and then all the live stream archives.",
        "tokens": [
          51102,
          293,
          550,
          439,
          264,
          1621,
          4309,
          25607,
          13,
          51183
        ]
      },
      {
        "avg_logprob": -0.27119223854758523,
        "compression_ratio": 1.7,
        "end": 8521.46,
        "id": 2543,
        "no_speech_prob": 0.0000035007979022338986,
        "seek": 850350,
        "start": 8519.88,
        "temperature": 0,
        "text": " So again, this is like,",
        "tokens": [
          51183,
          407,
          797,
          11,
          341,
          307,
          411,
          11,
          51262
        ]
      },
      {
        "avg_logprob": -0.27119223854758523,
        "compression_ratio": 1.7,
        "end": 8524.66,
        "id": 2544,
        "no_speech_prob": 0.0000035007979022338986,
        "seek": 850350,
        "start": 8521.46,
        "temperature": 0,
        "text": " Niels Webb has done, and many other contributors,",
        "tokens": [
          51262,
          426,
          44189,
          49649,
          575,
          1096,
          11,
          293,
          867,
          661,
          45627,
          11,
          51422
        ]
      },
      {
        "avg_logprob": -0.27119223854758523,
        "compression_ratio": 1.7,
        "end": 8525.98,
        "id": 2545,
        "no_speech_prob": 0.0000035007979022338986,
        "seek": 850350,
        "start": 8524.66,
        "temperature": 0,
        "text": " but Niels Webb in particular",
        "tokens": [
          51422,
          457,
          426,
          44189,
          49649,
          294,
          1729,
          51488
        ]
      },
      {
        "avg_logprob": -0.27119223854758523,
        "compression_ratio": 1.7,
        "end": 8528.3,
        "id": 2546,
        "no_speech_prob": 0.0000035007979022338986,
        "seek": 850350,
        "start": 8525.98,
        "temperature": 0,
        "text": " has done a tremendous amount of work.",
        "tokens": [
          51488,
          575,
          1096,
          257,
          10048,
          2372,
          295,
          589,
          13,
          51604
        ]
      },
      {
        "avg_logprob": -0.27119223854758523,
        "compression_ratio": 1.7,
        "end": 8532.74,
        "id": 2547,
        "no_speech_prob": 0.0000035007979022338986,
        "seek": 850350,
        "start": 8528.3,
        "temperature": 0,
        "text": " Niels Webber is a student and web developer in Germany.",
        "tokens": [
          51604,
          426,
          44189,
          9573,
          607,
          307,
          257,
          3107,
          293,
          3670,
          10754,
          294,
          7244,
          13,
          51826
        ]
      },
      {
        "avg_logprob": -0.34049334968488243,
        "compression_ratio": 1.480349344978166,
        "end": 8537.74,
        "id": 2548,
        "no_speech_prob": 0.000010616045983624645,
        "seek": 853274,
        "start": 8533.06,
        "temperature": 0,
        "text": " And so, thank you so much to Niels Webb,",
        "tokens": [
          50380,
          400,
          370,
          11,
          1309,
          291,
          370,
          709,
          281,
          426,
          44189,
          49649,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.34049334968488243,
        "compression_ratio": 1.480349344978166,
        "end": 8541.539999999999,
        "id": 2549,
        "no_speech_prob": 0.000010616045983624645,
        "seek": 853274,
        "start": 8537.74,
        "temperature": 0,
        "text": " and I am certainly happy for people to contribute",
        "tokens": [
          50614,
          293,
          286,
          669,
          3297,
          2055,
          337,
          561,
          281,
          10586,
          50804
        ]
      },
      {
        "avg_logprob": -0.34049334968488243,
        "compression_ratio": 1.480349344978166,
        "end": 8543.38,
        "id": 2550,
        "no_speech_prob": 0.000010616045983624645,
        "seek": 853274,
        "start": 8541.539999999999,
        "temperature": 0,
        "text": " and participate in the development of a website.",
        "tokens": [
          50804,
          293,
          8197,
          294,
          264,
          3250,
          295,
          257,
          3144,
          13,
          50896
        ]
      },
      {
        "avg_logprob": -0.34049334968488243,
        "compression_ratio": 1.480349344978166,
        "end": 8545.86,
        "id": 2551,
        "no_speech_prob": 0.000010616045983624645,
        "seek": 853274,
        "start": 8543.38,
        "temperature": 0,
        "text": " I haven't figured out really like a structure to do that,",
        "tokens": [
          50896,
          286,
          2378,
          380,
          8932,
          484,
          534,
          411,
          257,
          3877,
          281,
          360,
          300,
          11,
          51020
        ]
      },
      {
        "avg_logprob": -0.34049334968488243,
        "compression_ratio": 1.480349344978166,
        "end": 8548.82,
        "id": 2552,
        "no_speech_prob": 0.000010616045983624645,
        "seek": 853274,
        "start": 8545.86,
        "temperature": 0,
        "text": " but it's happening in a sort of ad hoc basis.",
        "tokens": [
          51020,
          457,
          309,
          311,
          2737,
          294,
          257,
          1333,
          295,
          614,
          16708,
          5143,
          13,
          51168
        ]
      },
      {
        "avg_logprob": -0.34049334968488243,
        "compression_ratio": 1.480349344978166,
        "end": 8553.82,
        "id": 2553,
        "no_speech_prob": 0.000010616045983624645,
        "seek": 853274,
        "start": 8548.82,
        "temperature": 0,
        "text": " To Shar Mitra asked, last question, do you game?",
        "tokens": [
          51168,
          220,
          13342,
          22030,
          10821,
          424,
          2351,
          11,
          1036,
          1168,
          11,
          360,
          291,
          1216,
          30,
          51418
        ]
      },
      {
        "avg_logprob": -0.34049334968488243,
        "compression_ratio": 1.480349344978166,
        "end": 8559.32,
        "id": 2554,
        "no_speech_prob": 0.000010616045983624645,
        "seek": 853274,
        "start": 8556.66,
        "temperature": 0,
        "text": " All right, you're going to be sorry you asked.",
        "tokens": [
          51560,
          1057,
          558,
          11,
          291,
          434,
          516,
          281,
          312,
          2597,
          291,
          2351,
          13,
          51693
        ]
      },
      {
        "avg_logprob": -0.33757235680097414,
        "compression_ratio": 1.3768844221105527,
        "end": 8562.48,
        "id": 2555,
        "no_speech_prob": 0.00006502600444946438,
        "seek": 855932,
        "start": 8560.32,
        "temperature": 0,
        "text": " If you go to youtube.com,",
        "tokens": [
          50414,
          759,
          291,
          352,
          281,
          12487,
          13,
          1112,
          11,
          50522
        ]
      },
      {
        "avg_logprob": -0.33757235680097414,
        "compression_ratio": 1.3768844221105527,
        "end": 8568.1,
        "id": 2556,
        "no_speech_prob": 0.00006502600444946438,
        "seek": 855932,
        "start": 8564.92,
        "temperature": 0,
        "text": " and you search for EOD Gaming,",
        "tokens": [
          50644,
          293,
          291,
          3164,
          337,
          462,
          14632,
          30288,
          11,
          50803
        ]
      },
      {
        "avg_logprob": -0.33757235680097414,
        "compression_ratio": 1.3768844221105527,
        "end": 8574.36,
        "id": 2557,
        "no_speech_prob": 0.00006502600444946438,
        "seek": 855932,
        "start": 8569.36,
        "temperature": 0,
        "text": " this here with 166 subscribers",
        "tokens": [
          50866,
          341,
          510,
          365,
          3165,
          21,
          11092,
          51116
        ]
      },
      {
        "avg_logprob": -0.33757235680097414,
        "compression_ratio": 1.3768844221105527,
        "end": 8578.619999999999,
        "id": 2558,
        "no_speech_prob": 0.00006502600444946438,
        "seek": 855932,
        "start": 8575.4,
        "temperature": 0,
        "text": " is my gaming channel with my kids,",
        "tokens": [
          51168,
          307,
          452,
          9703,
          2269,
          365,
          452,
          2301,
          11,
          51329
        ]
      },
      {
        "avg_logprob": -0.33757235680097414,
        "compression_ratio": 1.3768844221105527,
        "end": 8579.779999999999,
        "id": 2559,
        "no_speech_prob": 0.00006502600444946438,
        "seek": 855932,
        "start": 8578.619999999999,
        "temperature": 0,
        "text": " who I'm very conflicted about.",
        "tokens": [
          51329,
          567,
          286,
          478,
          588,
          6596,
          292,
          466,
          13,
          51387
        ]
      },
      {
        "avg_logprob": -0.33757235680097414,
        "compression_ratio": 1.3768844221105527,
        "end": 8583.86,
        "id": 2560,
        "no_speech_prob": 0.00006502600444946438,
        "seek": 855932,
        "start": 8579.779999999999,
        "temperature": 0,
        "text": " But this video is really what I would recommend.",
        "tokens": [
          51387,
          583,
          341,
          960,
          307,
          534,
          437,
          286,
          576,
          2748,
          13,
          51591
        ]
      },
      {
        "avg_logprob": -0.33757235680097414,
        "compression_ratio": 1.3768844221105527,
        "end": 8587.08,
        "id": 2561,
        "no_speech_prob": 0.00006502600444946438,
        "seek": 855932,
        "start": 8583.86,
        "temperature": 0,
        "text": " My daughter and I played like snipper clips",
        "tokens": [
          51591,
          1222,
          4653,
          293,
          286,
          3737,
          411,
          2406,
          15124,
          13117,
          51752
        ]
      },
      {
        "avg_logprob": -0.33757235680097414,
        "compression_ratio": 1.3768844221105527,
        "end": 8588.779999999999,
        "id": 2562,
        "no_speech_prob": 0.00006502600444946438,
        "seek": 855932,
        "start": 8587.08,
        "temperature": 0,
        "text": " for an hour and 40 minutes.",
        "tokens": [
          51752,
          337,
          364,
          1773,
          293,
          3356,
          2077,
          13,
          51837
        ]
      },
      {
        "avg_logprob": -0.31236231209027887,
        "compression_ratio": 1.4863636363636363,
        "end": 8594.199999999999,
        "id": 2563,
        "no_speech_prob": 0.00009459981811232865,
        "seek": 858932,
        "start": 8590.32,
        "temperature": 0,
        "text": " And it's a wonderful game,",
        "tokens": [
          50414,
          400,
          309,
          311,
          257,
          3715,
          1216,
          11,
          50608
        ]
      },
      {
        "avg_logprob": -0.31236231209027887,
        "compression_ratio": 1.4863636363636363,
        "end": 8596.56,
        "id": 2564,
        "no_speech_prob": 0.00009459981811232865,
        "seek": 858932,
        "start": 8594.199999999999,
        "temperature": 0,
        "text": " and hopefully we'll do this again this weekend sometimes,",
        "tokens": [
          50608,
          293,
          4696,
          321,
          603,
          360,
          341,
          797,
          341,
          6711,
          2171,
          11,
          50726
        ]
      },
      {
        "avg_logprob": -0.31236231209027887,
        "compression_ratio": 1.4863636363636363,
        "end": 8599.8,
        "id": 2565,
        "no_speech_prob": 0.00009459981811232865,
        "seek": 858932,
        "start": 8596.56,
        "temperature": 0,
        "text": " but we do live streams trying to play.",
        "tokens": [
          50726,
          457,
          321,
          360,
          1621,
          15842,
          1382,
          281,
          862,
          13,
          50888
        ]
      },
      {
        "avg_logprob": -0.31236231209027887,
        "compression_ratio": 1.4863636363636363,
        "end": 8602.22,
        "id": 2566,
        "no_speech_prob": 0.00009459981811232865,
        "seek": 858932,
        "start": 8599.8,
        "temperature": 0,
        "text": " I love this game so much, it's so much fun.",
        "tokens": [
          50888,
          286,
          959,
          341,
          1216,
          370,
          709,
          11,
          309,
          311,
          370,
          709,
          1019,
          13,
          51009
        ]
      },
      {
        "avg_logprob": -0.31236231209027887,
        "compression_ratio": 1.4863636363636363,
        "end": 8606.98,
        "id": 2567,
        "no_speech_prob": 0.00009459981811232865,
        "seek": 858932,
        "start": 8605.32,
        "temperature": 0,
        "text": " Of course I got a copyright notice",
        "tokens": [
          51164,
          2720,
          1164,
          286,
          658,
          257,
          17996,
          3449,
          51247
        ]
      },
      {
        "avg_logprob": -0.31236231209027887,
        "compression_ratio": 1.4863636363636363,
        "end": 8608.76,
        "id": 2568,
        "no_speech_prob": 0.00009459981811232865,
        "seek": 858932,
        "start": 8606.98,
        "temperature": 0,
        "text": " because I used the snipper clips.",
        "tokens": [
          51247,
          570,
          286,
          1143,
          264,
          2406,
          15124,
          13117,
          13,
          51336
        ]
      },
      {
        "avg_logprob": -0.31236231209027887,
        "compression_ratio": 1.4863636363636363,
        "end": 8614.6,
        "id": 2569,
        "no_speech_prob": 0.00009459981811232865,
        "seek": 858932,
        "start": 8611.199999999999,
        "temperature": 0,
        "text": " Oh, look at this, and like, am I on YouTube Gaming?",
        "tokens": [
          51458,
          876,
          11,
          574,
          412,
          341,
          11,
          293,
          411,
          11,
          669,
          286,
          322,
          3088,
          30288,
          30,
          51628
        ]
      },
      {
        "avg_logprob": -0.31236231209027887,
        "compression_ratio": 1.4863636363636363,
        "end": 8617.699999999999,
        "id": 2570,
        "no_speech_prob": 0.00009459981811232865,
        "seek": 858932,
        "start": 8614.6,
        "temperature": 0,
        "text": " So if I go to like gaming.youtube.com,",
        "tokens": [
          51628,
          407,
          498,
          286,
          352,
          281,
          411,
          9703,
          13,
          88,
          346,
          1977,
          13,
          1112,
          11,
          51783
        ]
      },
      {
        "avg_logprob": -0.29453600606610697,
        "compression_ratio": 1.5761316872427984,
        "end": 8620.4,
        "id": 2571,
        "no_speech_prob": 0.00003426800321904011,
        "seek": 861932,
        "start": 8619.32,
        "temperature": 0,
        "text": " whoa, look at this.",
        "tokens": [
          50364,
          13310,
          11,
          574,
          412,
          341,
          13,
          50418
        ]
      },
      {
        "avg_logprob": -0.29453600606610697,
        "compression_ratio": 1.5761316872427984,
        "end": 8626.64,
        "id": 2572,
        "no_speech_prob": 0.00003426800321904011,
        "seek": 861932,
        "start": 8622.44,
        "temperature": 0,
        "text": " Yeah, so someday this is going to be even bigger",
        "tokens": [
          50520,
          865,
          11,
          370,
          19412,
          341,
          307,
          516,
          281,
          312,
          754,
          3801,
          50730
        ]
      },
      {
        "avg_logprob": -0.29453600606610697,
        "compression_ratio": 1.5761316872427984,
        "end": 8630.199999999999,
        "id": 2573,
        "no_speech_prob": 0.00003426800321904011,
        "seek": 861932,
        "start": 8628.08,
        "temperature": 0,
        "text": " than the coding train, oh, I don't think so.",
        "tokens": [
          50802,
          813,
          264,
          17720,
          3847,
          11,
          1954,
          11,
          286,
          500,
          380,
          519,
          370,
          13,
          50908
        ]
      },
      {
        "avg_logprob": -0.29453600606610697,
        "compression_ratio": 1.5761316872427984,
        "end": 8632.039999999999,
        "id": 2574,
        "no_speech_prob": 0.00003426800321904011,
        "seek": 861932,
        "start": 8630.199999999999,
        "temperature": 0,
        "text": " All right everybody, goodbye,",
        "tokens": [
          50908,
          1057,
          558,
          2201,
          11,
          12084,
          11,
          51000
        ]
      },
      {
        "avg_logprob": -0.29453600606610697,
        "compression_ratio": 1.5761316872427984,
        "end": 8633.68,
        "id": 2575,
        "no_speech_prob": 0.00003426800321904011,
        "seek": 861932,
        "start": 8632.039999999999,
        "temperature": 0,
        "text": " thank you so much for tuning in.",
        "tokens": [
          51000,
          1309,
          291,
          370,
          709,
          337,
          15164,
          294,
          13,
          51082
        ]
      },
      {
        "avg_logprob": -0.29453600606610697,
        "compression_ratio": 1.5761316872427984,
        "end": 8635.72,
        "id": 2576,
        "no_speech_prob": 0.00003426800321904011,
        "seek": 861932,
        "start": 8633.68,
        "temperature": 0,
        "text": " I am going to now stop this live stream",
        "tokens": [
          51082,
          286,
          669,
          516,
          281,
          586,
          1590,
          341,
          1621,
          4309,
          51184
        ]
      },
      {
        "avg_logprob": -0.29453600606610697,
        "compression_ratio": 1.5761316872427984,
        "end": 8639.279999999999,
        "id": 2577,
        "no_speech_prob": 0.00003426800321904011,
        "seek": 861932,
        "start": 8635.72,
        "temperature": 0,
        "text": " and go on with my life.",
        "tokens": [
          51184,
          293,
          352,
          322,
          365,
          452,
          993,
          13,
          51362
        ]
      },
      {
        "avg_logprob": -0.29453600606610697,
        "compression_ratio": 1.5761316872427984,
        "end": 8643.08,
        "id": 2578,
        "no_speech_prob": 0.00003426800321904011,
        "seek": 861932,
        "start": 8640.64,
        "temperature": 0,
        "text": " And I hope to hear from you, see you,",
        "tokens": [
          51430,
          400,
          286,
          1454,
          281,
          1568,
          490,
          291,
          11,
          536,
          291,
          11,
          51552
        ]
      },
      {
        "avg_logprob": -0.29453600606610697,
        "compression_ratio": 1.5761316872427984,
        "end": 8645.84,
        "id": 2579,
        "no_speech_prob": 0.00003426800321904011,
        "seek": 861932,
        "start": 8643.08,
        "temperature": 0,
        "text": " ah, if you're coming to ThinkerCon, let me know.",
        "tokens": [
          51552,
          3716,
          11,
          498,
          291,
          434,
          1348,
          281,
          6557,
          260,
          9838,
          11,
          718,
          385,
          458,
          13,
          51690
        ]
      },
      {
        "avg_logprob": -0.29453600606610697,
        "compression_ratio": 1.5761316872427984,
        "end": 8647.199999999999,
        "id": 2580,
        "no_speech_prob": 0.00003426800321904011,
        "seek": 861932,
        "start": 8645.84,
        "temperature": 0,
        "text": " I would love to see you there.",
        "tokens": [
          51690,
          286,
          576,
          959,
          281,
          536,
          291,
          456,
          13,
          51758
        ]
      },
      {
        "avg_logprob": -0.29453600606610697,
        "compression_ratio": 1.5761316872427984,
        "end": 8648.56,
        "id": 2581,
        "no_speech_prob": 0.00003426800321904011,
        "seek": 861932,
        "start": 8647.199999999999,
        "temperature": 0,
        "text": " I'm so excited about it.",
        "tokens": [
          51758,
          286,
          478,
          370,
          2919,
          466,
          309,
          13,
          51826
        ]
      },
      {
        "avg_logprob": -0.42683720308191636,
        "compression_ratio": 1.4076433121019107,
        "end": 8650.64,
        "id": 2582,
        "no_speech_prob": 0.00035143509740009904,
        "seek": 864932,
        "start": 8649.8,
        "temperature": 0,
        "text": " Okay, and.",
        "tokens": [
          50388,
          1033,
          11,
          293,
          13,
          50430
        ]
      },
      {
        "avg_logprob": -0.42683720308191636,
        "compression_ratio": 1.4076433121019107,
        "end": 8662.4,
        "id": 2583,
        "no_speech_prob": 0.00035143509740009904,
        "seek": 864932,
        "start": 8660.199999999999,
        "temperature": 0,
        "text": " Is this playing at, what's fun is to put this",
        "tokens": [
          50908,
          1119,
          341,
          2433,
          412,
          11,
          437,
          311,
          1019,
          307,
          281,
          829,
          341,
          51018
        ]
      },
      {
        "avg_logprob": -0.42683720308191636,
        "compression_ratio": 1.4076433121019107,
        "end": 8663.24,
        "id": 2584,
        "no_speech_prob": 0.00035143509740009904,
        "seek": 864932,
        "start": 8662.4,
        "temperature": 0,
        "text": " on double speed.",
        "tokens": [
          51018,
          322,
          3834,
          3073,
          13,
          51060
        ]
      },
      {
        "avg_logprob": -0.42683720308191636,
        "compression_ratio": 1.4076433121019107,
        "end": 8666.56,
        "id": 2585,
        "no_speech_prob": 0.00035143509740009904,
        "seek": 864932,
        "start": 8664.8,
        "temperature": 0,
        "text": " Come on, we can get it in that basket.",
        "tokens": [
          51138,
          2492,
          322,
          11,
          321,
          393,
          483,
          309,
          294,
          300,
          8390,
          13,
          51226
        ]
      },
      {
        "avg_logprob": -0.42683720308191636,
        "compression_ratio": 1.4076433121019107,
        "end": 8667.52,
        "id": 2586,
        "no_speech_prob": 0.00035143509740009904,
        "seek": 864932,
        "start": 8666.56,
        "temperature": 0,
        "text": " Hold on, I have to.",
        "tokens": [
          51226,
          6962,
          322,
          11,
          286,
          362,
          281,
          13,
          51274
        ]
      },
      {
        "avg_logprob": -0.42683720308191636,
        "compression_ratio": 1.4076433121019107,
        "end": 8672.6,
        "id": 2587,
        "no_speech_prob": 0.00035143509740009904,
        "seek": 864932,
        "start": 8670.8,
        "temperature": 0,
        "text": " I'm sorry, I just have to wait.",
        "tokens": [
          51438,
          286,
          478,
          2597,
          11,
          286,
          445,
          362,
          281,
          1699,
          13,
          51528
        ]
      },
      {
        "avg_logprob": -0.42683720308191636,
        "compression_ratio": 1.4076433121019107,
        "end": 8673.88,
        "id": 2588,
        "no_speech_prob": 0.00035143509740009904,
        "seek": 864932,
        "start": 8672.6,
        "temperature": 0,
        "text": " This took us so long.",
        "tokens": [
          51528,
          639,
          1890,
          505,
          370,
          938,
          13,
          51592
        ]
      },
      {
        "avg_logprob": -0.42683720308191636,
        "compression_ratio": 1.4076433121019107,
        "end": 8677.38,
        "id": 2589,
        "no_speech_prob": 0.00035143509740009904,
        "seek": 864932,
        "start": 8675.92,
        "temperature": 0,
        "text": " Okay, come on.",
        "tokens": [
          51694,
          1033,
          11,
          808,
          322,
          13,
          51767
        ]
      },
      {
        "avg_logprob": -0.42683720308191636,
        "compression_ratio": 1.4076433121019107,
        "end": 8678.38,
        "id": 2590,
        "no_speech_prob": 0.00035143509740009904,
        "seek": 864932,
        "start": 8677.38,
        "temperature": 0,
        "text": " Oh, am I gonna get?",
        "tokens": [
          51767,
          876,
          11,
          669,
          286,
          799,
          483,
          30,
          51817
        ]
      },
      {
        "avg_logprob": -0.46534380996436403,
        "compression_ratio": 1.6850828729281768,
        "end": 8684.56,
        "id": 2591,
        "no_speech_prob": 0.00007722023292444646,
        "seek": 867932,
        "start": 8680.199999999999,
        "temperature": 0,
        "text": " I'm probably gonna get deep copyright notice",
        "tokens": [
          50408,
          286,
          478,
          1391,
          799,
          483,
          2452,
          17996,
          3449,
          50626
        ]
      },
      {
        "avg_logprob": -0.46534380996436403,
        "compression_ratio": 1.6850828729281768,
        "end": 8685.4,
        "id": 2592,
        "no_speech_prob": 0.00007722023292444646,
        "seek": 867932,
        "start": 8684.56,
        "temperature": 0,
        "text": " now in this video.",
        "tokens": [
          50626,
          586,
          294,
          341,
          960,
          13,
          50668
        ]
      },
      {
        "avg_logprob": -0.46534380996436403,
        "compression_ratio": 1.6850828729281768,
        "end": 8686.22,
        "id": 2593,
        "no_speech_prob": 0.00007722023292444646,
        "seek": 867932,
        "start": 8685.4,
        "temperature": 0,
        "text": " Although you won't be able to,",
        "tokens": [
          50668,
          5780,
          291,
          1582,
          380,
          312,
          1075,
          281,
          11,
          50709
        ]
      },
      {
        "avg_logprob": -0.46534380996436403,
        "compression_ratio": 1.6850828729281768,
        "end": 8687.72,
        "id": 2594,
        "no_speech_prob": 0.00007722023292444646,
        "seek": 867932,
        "start": 8686.22,
        "temperature": 0,
        "text": " you probably can't really hear this.",
        "tokens": [
          50709,
          291,
          1391,
          393,
          380,
          534,
          1568,
          341,
          13,
          50784
        ]
      },
      {
        "avg_logprob": -0.46534380996436403,
        "compression_ratio": 1.6850828729281768,
        "end": 8690.68,
        "id": 2595,
        "no_speech_prob": 0.00007722023292444646,
        "seek": 867932,
        "start": 8689.56,
        "temperature": 0,
        "text": " I can turn music off.",
        "tokens": [
          50876,
          286,
          393,
          1261,
          1318,
          766,
          13,
          50932
        ]
      },
      {
        "avg_logprob": -0.46534380996436403,
        "compression_ratio": 1.6850828729281768,
        "end": 8693.4,
        "id": 2596,
        "no_speech_prob": 0.00007722023292444646,
        "seek": 867932,
        "start": 8691.64,
        "temperature": 0,
        "text": " Oh, so close.",
        "tokens": [
          50980,
          876,
          11,
          370,
          1998,
          13,
          51068
        ]
      },
      {
        "avg_logprob": -0.46534380996436403,
        "compression_ratio": 1.6850828729281768,
        "end": 8700.56,
        "id": 2597,
        "no_speech_prob": 0.00007722023292444646,
        "seek": 867932,
        "start": 8697.4,
        "temperature": 0,
        "text": " Come on, come on, come on, come on, come on.",
        "tokens": [
          51268,
          2492,
          322,
          11,
          808,
          322,
          11,
          808,
          322,
          11,
          808,
          322,
          11,
          808,
          322,
          13,
          51426
        ]
      },
      {
        "avg_logprob": -0.46534380996436403,
        "compression_ratio": 1.6850828729281768,
        "end": 8703.08,
        "id": 2598,
        "no_speech_prob": 0.00007722023292444646,
        "seek": 867932,
        "start": 8700.56,
        "temperature": 0,
        "text": " Oh, oh, up, up, go on.",
        "tokens": [
          51426,
          876,
          11,
          1954,
          11,
          493,
          11,
          493,
          11,
          352,
          322,
          13,
          51552
        ]
      },
      {
        "avg_logprob": -0.46534380996436403,
        "compression_ratio": 1.6850828729281768,
        "end": 8704.119999999999,
        "id": 2599,
        "no_speech_prob": 0.00007722023292444646,
        "seek": 867932,
        "start": 8703.08,
        "temperature": 0,
        "text": " Ah, there you go, no.",
        "tokens": [
          51552,
          2438,
          11,
          456,
          291,
          352,
          11,
          572,
          13,
          51604
        ]
      },
      {
        "avg_logprob": -0.46534380996436403,
        "compression_ratio": 1.6850828729281768,
        "end": 8706.96,
        "id": 2600,
        "no_speech_prob": 0.00007722023292444646,
        "seek": 867932,
        "start": 8704.119999999999,
        "temperature": 0,
        "text": " Oh, oh boy, oh come on.",
        "tokens": [
          51604,
          876,
          11,
          1954,
          3237,
          11,
          1954,
          808,
          322,
          13,
          51746
        ]
      },
      {
        "avg_logprob": -0.46534380996436403,
        "compression_ratio": 1.6850828729281768,
        "end": 8708.44,
        "id": 2601,
        "no_speech_prob": 0.00007722023292444646,
        "seek": 867932,
        "start": 8706.96,
        "temperature": 0,
        "text": " I'm like reliving this.",
        "tokens": [
          51746,
          286,
          478,
          411,
          1039,
          2123,
          341,
          13,
          51820
        ]
      },
      {
        "avg_logprob": -0.27248429518479567,
        "compression_ratio": 1.6390041493775933,
        "end": 8709.640000000001,
        "id": 2602,
        "no_speech_prob": 0.000021782034309580922,
        "seek": 870844,
        "start": 8708.480000000001,
        "temperature": 0,
        "text": " It's so painful.",
        "tokens": [
          50366,
          467,
          311,
          370,
          11697,
          13,
          50424
        ]
      },
      {
        "avg_logprob": -0.27248429518479567,
        "compression_ratio": 1.6390041493775933,
        "end": 8712.380000000001,
        "id": 2603,
        "no_speech_prob": 0.000021782034309580922,
        "seek": 870844,
        "start": 8711.44,
        "temperature": 0,
        "text": " I really have to go.",
        "tokens": [
          50514,
          286,
          534,
          362,
          281,
          352,
          13,
          50561
        ]
      },
      {
        "avg_logprob": -0.27248429518479567,
        "compression_ratio": 1.6390041493775933,
        "end": 8713.44,
        "id": 2604,
        "no_speech_prob": 0.000021782034309580922,
        "seek": 870844,
        "start": 8712.380000000001,
        "temperature": 0,
        "text": " Okay, goodbye everybody.",
        "tokens": [
          50561,
          1033,
          11,
          12084,
          2201,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.27248429518479567,
        "compression_ratio": 1.6390041493775933,
        "end": 8715.84,
        "id": 2605,
        "no_speech_prob": 0.000021782034309580922,
        "seek": 870844,
        "start": 8713.44,
        "temperature": 0,
        "text": " You can go and watch this video on your own.",
        "tokens": [
          50614,
          509,
          393,
          352,
          293,
          1159,
          341,
          960,
          322,
          428,
          1065,
          13,
          50734
        ]
      },
      {
        "avg_logprob": -0.27248429518479567,
        "compression_ratio": 1.6390041493775933,
        "end": 8718.42,
        "id": 2606,
        "no_speech_prob": 0.000021782034309580922,
        "seek": 870844,
        "start": 8715.84,
        "temperature": 0,
        "text": " If you link to, I will link to it in the chat.",
        "tokens": [
          50734,
          759,
          291,
          2113,
          281,
          11,
          286,
          486,
          2113,
          281,
          309,
          294,
          264,
          5081,
          13,
          50863
        ]
      },
      {
        "avg_logprob": -0.27248429518479567,
        "compression_ratio": 1.6390041493775933,
        "end": 8720.1,
        "id": 2607,
        "no_speech_prob": 0.000021782034309580922,
        "seek": 870844,
        "start": 8718.42,
        "temperature": 0,
        "text": " Or somebody can link to it in the chat for me.",
        "tokens": [
          50863,
          1610,
          2618,
          393,
          2113,
          281,
          309,
          294,
          264,
          5081,
          337,
          385,
          13,
          50947
        ]
      },
      {
        "avg_logprob": -0.27248429518479567,
        "compression_ratio": 1.6390041493775933,
        "end": 8721.460000000001,
        "id": 2608,
        "no_speech_prob": 0.000021782034309580922,
        "seek": 870844,
        "start": 8720.1,
        "temperature": 0,
        "text": " It is this.",
        "tokens": [
          50947,
          467,
          307,
          341,
          13,
          51015
        ]
      },
      {
        "avg_logprob": -0.27248429518479567,
        "compression_ratio": 1.6390041493775933,
        "end": 8723.84,
        "id": 2609,
        "no_speech_prob": 0.000021782034309580922,
        "seek": 870844,
        "start": 8722.36,
        "temperature": 0,
        "text": " We had so much fun.",
        "tokens": [
          51060,
          492,
          632,
          370,
          709,
          1019,
          13,
          51134
        ]
      },
      {
        "avg_logprob": -0.27248429518479567,
        "compression_ratio": 1.6390041493775933,
        "end": 8725.36,
        "id": 2610,
        "no_speech_prob": 0.000021782034309580922,
        "seek": 870844,
        "start": 8723.84,
        "temperature": 0,
        "text": " All right, goodbye everybody.",
        "tokens": [
          51134,
          1057,
          558,
          11,
          12084,
          2201,
          13,
          51210
        ]
      },
      {
        "avg_logprob": -0.27248429518479567,
        "compression_ratio": 1.6390041493775933,
        "end": 8727.68,
        "id": 2611,
        "no_speech_prob": 0.000021782034309580922,
        "seek": 870844,
        "start": 8726.24,
        "temperature": 0,
        "text": " I'm gonna stop streaming now.",
        "tokens": [
          51254,
          286,
          478,
          799,
          1590,
          11791,
          586,
          13,
          51326
        ]
      },
      {
        "avg_logprob": -0.27248429518479567,
        "compression_ratio": 1.6390041493775933,
        "end": 8729.960000000001,
        "id": 2612,
        "no_speech_prob": 0.000021782034309580922,
        "seek": 870844,
        "start": 8729.12,
        "temperature": 0,
        "text": " See you next time.",
        "tokens": [
          51398,
          3008,
          291,
          958,
          565,
          13,
          51440
        ]
      },
      {
        "avg_logprob": -0.27248429518479567,
        "compression_ratio": 1.6390041493775933,
        "end": 8732.44,
        "id": 2613,
        "no_speech_prob": 0.000021782034309580922,
        "seek": 870844,
        "start": 8729.960000000001,
        "temperature": 0,
        "text": " Won't be for a few weeks, so stay tuned.",
        "tokens": [
          51440,
          14710,
          380,
          312,
          337,
          257,
          1326,
          3259,
          11,
          370,
          1754,
          10870,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.27248429518479567,
        "compression_ratio": 1.6390041493775933,
        "end": 8734.68,
        "id": 2614,
        "no_speech_prob": 0.000021782034309580922,
        "seek": 870844,
        "start": 8732.44,
        "temperature": 0,
        "text": " If you wanna get an alert when I schedule",
        "tokens": [
          51564,
          759,
          291,
          1948,
          483,
          364,
          9615,
          562,
          286,
          7567,
          51676
        ]
      },
      {
        "avg_logprob": -0.3819725092719583,
        "compression_ratio": 1.1470588235294117,
        "end": 8738.68,
        "id": 2615,
        "no_speech_prob": 0.03209351748228073,
        "seek": 873468,
        "start": 8734.68,
        "temperature": 0,
        "text": " the next live stream, subscribe and then click",
        "tokens": [
          50364,
          264,
          958,
          1621,
          4309,
          11,
          3022,
          293,
          550,
          2052,
          50564
        ]
      },
      {
        "avg_logprob": -0.3819725092719583,
        "compression_ratio": 1.1470588235294117,
        "end": 8740.800000000001,
        "id": 2616,
        "no_speech_prob": 0.03209351748228073,
        "seek": 873468,
        "start": 8738.68,
        "temperature": 0,
        "text": " that alarm bell is the thing you're supposed to do.",
        "tokens": [
          50564,
          300,
          14183,
          4549,
          307,
          264,
          551,
          291,
          434,
          3442,
          281,
          360,
          13,
          50670
        ]
      },
      {
        "avg_logprob": -0.3819725092719583,
        "compression_ratio": 1.1470588235294117,
        "end": 8741.76,
        "id": 2617,
        "no_speech_prob": 0.03209351748228073,
        "seek": 873468,
        "start": 8740.800000000001,
        "temperature": 0,
        "text": " If you want, okay.",
        "tokens": [
          50670,
          759,
          291,
          528,
          11,
          1392,
          13,
          50718
        ]
      }
    ],
    "transcription": " Good afternoon. It is me again here on the coding train. My name is Dan. NASA KOP in the chat asks, does it start now? In fact, it starts now. Or maybe officially it starts now. Welcome to the coding train afternoon edition. There was a full 2 and 1 1-hour morning edition of the coding train today where I completed. Completed is perhaps not the most accurate way to describe what happened. But I did attempt to continue to work on the logo coding challenge. But that's all. I'm done with that. Won't be returning to that anytime soon. Just in case you weren't here this morning, I will show you. I will pull this up very briefly. If I go to a logo, coding train slash logo, this is the GitHub repo. There are some issues here that I would love help with and thoughts on. There are a couple of design pull requests. But I merged a couple of things without checking them. So let's actually see. Coding train dot GitHub slash. This should be the demo. And it still works. So there you go. So this is what it does. It is a logo interpreter where you can type logo commands. And it will draw them for you. And apparently now, it supports some new commands that it didn't as of this morning based on a few pull requests. I don't want to rehash that too much. What I want to do, I'm going to do something. Oh, this is going to be good. I'm just going to get right into things, right into things. I am going to continue today, The Beginner's Guide to Machine Learning with ML5.js. In particular, I am going to make a new video, which will appear as number seven in this playlist. In a moment, I'm probably going to repeat myself again. And what I'm going to do is I'm going to take this previous example that I made. And I am going to save, which trains a model. I'm going to save that model and then reload it back into the sketch so that I don't have to constantly retrain every time I refresh the page, et cetera. So this has been a long overdue feature, or a widely requested feature in the ML5 library. Let's go to GitHub. Let's go to Issues. It might be closed. Let's look at, where did this get added? There we go. So this is the support. This is the pull request. So I'm going to leave this open. Yes, K. Wichman. Here we are again. I am streaming extra, a little bit extra. I've decided to come try to do two streams today, because A, I didn't get to last week because I was teaching. And then also, I will just mention again that I will be next week, next Saturday, at ThinkerCon in Hoodstool, Alabama, a place I've never been to, the home of the rocket. And if any of you are going to be there, please say hello. All right, let's just get started here. Let's just get started. So what else am I? I've got an hour or so or two, some amount of time. I'm going to start with this ML5 save load model. I am going to also look at an example with working with the Google Quick Draw data set, because that is leading up to looking at the Sketch RNN model in ML5. So many things. I've got a long ML5 list of things to cover. I want to look at some new stuff that's been added for recurrent neural networks with text, Sketch RNN, PoseNet, KNN classifier, so many things. So let us begin. Hello. I am here to make video number seven, which does not yet exist. If you have been watching this playlist, the place where I left off was training a. Hold on. I forgot to turn on this part of my brain. Hello, welcome to a new ML5 beginner's guide to machine learning video. I am about to make video number seven. Right now, that's what you're watching. Where I left off, I looked at how you could train your own image classifier with images coming in from the webcam with a technique known as transfer learning. This is the example. So this example needs to be trained, but I could do this. I could get a lot of examples of me being happy, a lot of examples of me being sad. Then I could hit the Train button, and once it finishes training, it is then going to be done. And now I, hi. This failed. I shouldn't have been so, I didn't give it enough. One more try. One more try. This time with feeling, everybody. Don't you just love watching the live streams where I just do the same thing over and over again? Hello, and welcome to another beginner's guide to machine learning with ML5.js video. This is video number seven in this playlist. At least that's where I intend it to be. And in this video, I'm going to take a step forward. I am going to do something that has been so widely requested. A new feature that was recently added to ML5 to save and reload a model. Now, what kind of model am I talking about? So the last example I left off with was this transfer learning example, where I can train my own image classifier with images coming in from the webcam. So for example, I could say, here's a lot of images of me being happy. Is this interesting yet? What's going on? Here's all the images. What are you doing? I'm sad. Then I'm going to train it. And then I'm going to come back. It's going to be done. So that works. But what happens now if I refresh the page? Need to be trained again. That model is lost. So there is a new feature in ML5, a load function and a save function. A save function and a load function. This is what I'm going to show you in this video. Let's see if we can get it to work. That's it. It's all I'm going to add. So I've got the code from the previous example here to pull it up. And what I'm going to do, let's add another button. Where are the buttons? Did I use create? Yeah, I used create button, I guess. So I'm going to go into setup. And I'm going to, I forgot if these are called yuke buttons and whistle buttons, because why not? I'm going to make a save button equals create button, save. Then I'm going to say save button dot mouse pressed. I'm going to put an anonymous function in here. And I am going to now say classifier dot save. That's it. The classifier object, if you remember, is a classification object made from a feature extractor from the MobileNet library. Rattling mic. Sorry, time out. Is the mic a problem? Is this better now? OK? Is the mic OK? I kind of want to start this video over again. I just, I'm waiting before I keep going to see that the sound is OK. Yes. 1, 2, 1, 2, my mic is clattering a lot. Is it still clattering? Maybe I better go back and redo this whole video. Nothing would make me happier. Let's actually see if this works. OK. I think it's working. I think it's working. I think it's working. I think it's working. I think it's working. While I'm here, I'm going to redo it. Classifier dot save. Oh, I forgot. Great. So this, I'm going to have this happen, because I have to upgrade my version of ml5. Yep. Great. OK. So that worked. OK. How do I tell it not to show the warnings? Show. Where's the preference for showing warnings? Oh, I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. Show warnings. Because I kind of would prefer not to see them, frankly. High network, evaluation, preserve log, show warnings. Somebody will show me. If anyone in the Slack channel could tell me how the mic is going, I would really appreciate that. Show warnings. Chrome. Hide warnings in the console window. Is there. Top filter, errors, level, warning. OK. So it must be. Oh, I just don't see it here. Because. There we go. So let's. Ah. There we go. There it is. Got that. OK. The mic quality is perfect now. OK. Apologies to everyone, but just because there were some mic issues, I'm going to start over. And. So I'm actually going to do this. And go back to here. Take this out. And refresh. OK. All right. Here we go, everybody. So I realize that some of you watching might not have actually gone through this video tutorial. The idea of ML5 might be totally new to you. Just very briefly, ML5 is a beginner JavaScript, a beginner JavaScript library. It's a library that's built for the web. It's a library that's built for the web. It's a library that's built for the web. It's a library that's built for the web. It's a library that's built for the web. And ML5 is a beginner JavaScript, a beginner-friendly JavaScript library for machine learning. It's built on top of TensorFlow.js, which is an open source machine learning library made by Google. TensorFlow.js is a JavaScript port of TensorFlow, which is C++ and Python and, you know, that's about as far as I'm willing to go with that right now. And this series explains how image classification works with the pre-trained model and then how you can train your own model on top of that. So that's where I left off, but you could never save it. So now, here we are. Hello and welcome to another beginner's guide to machine learning with ML5.js video. Now, in this video, something very exciting is going to happen. If you happened to watch all the previous videos a while ago and you discovered this one new, a new feature has been added to ML5, the save load feature extractor with ML5 specs. So you can find the pull request here if you want to see more about how that was implemented. But the point of that is the following. Where I left off was this example. This is an example that loads a pre-trained image classifier called MobileNet, something that was trained by somebody else, explained in my previous videos, and allows the user, allows the coder to use a process known as transfer learning to extract the features that the model detects in an image and reassign them to new labels. So, for example, I can make a very happy face and click on happy a bunch of times and wonder why my Mac is showing that weird window. And then I could add a bunch of times and then click train. And now we have to wait for a minute. We always blow the train whistle for train. And now the training is complete. And I go, hi. Let me go back and do this again. It's really bothering me that this clicking on this is like, was pulling that thing up. It's because I'm selecting the text. I'm going to get this. And I'm kind of standing in front of it too. So with this example, I can make a happy face and click happy. This is me giving it a bunch of examples of me being happy. And then we bring it down. Now I can press the train button. It is training. And now that it has finished training, it will recognize, it will determine if the webcam is showing an image that looks more like happy or sad. Happy, sad. Happy, sad. Happy. Okay, so that's what the example did before. If you're still watching, what the problem with this example is, if I hit refresh, it's gone. It needs to be trained again. So what I want to show in this video, and boy, it's taking me a long time to get to it, is how to save. And really, there's just two functions we're going to add here, save function and a load function. So I'm starting with the code from before. And I'm going to go into setup. And this is where I made the buttons for sad and happy and train. I gave them weird variable names which don't have any meaning anymore. But I'm going to make a new button called save button equals create button. Save. I guess I should make this a global variable just to be consistent. That might be unnecessary. And then I'm going to add a function to handle the event when the save button is pressed. So what do I need to do when the save button is pressed? Guess what? This is super simple. All I need to do is say classifier.save. I'm just saying classifier.save. Now what's going to happen there? Let's wait and see. So I'm going to go here. I'm going to, oh, look, the save button is there. I'm going to be happy. I'm going to be sad. I'm going to train. Then I have to wait for it to finish training. Once it's done, I'm going to hit save. And guess what? I got an error. Save is not a function. So I left this error happen on purpose. This is a new feature of the ml5 library. And if I go and look into my HTML, I can see I'm using the ml5 library 0.1.1. Maybe you're watching this. Maybe it's like right now it's like 9.4.3 and you're in this future world of ml5. But the current version is 0.1.3. So if I add that, I'm going to hit refresh. Now I'm going to really try to train a good model here. So let's train. Oh, I don't have the ukulele. I'm going to do the train whistle. So I'll just do happy and sad. I'm happy with the train whistle. And I'm very sad with no train whistle. I don't have a train whistle. I'm so sad. No train whistle. Now I'm going to train. So I gave it a whole bunch of examples. And something weird is going on here. OK, let's see if this works. I'm happy. I'm happy with the train whistle. I'm sad. No train whistle. I'm happy with the train whistle. I'm sad. No train whistle. And I want to keep this model. So I'm now going to click Save. And look at this. Look what has downloaded to the download directory. I'm going to go show in Finder and see. Look at this, two files. Today is 2.17 PM. Model.json, model.weights.bin. OK, so let's take a moment to explain. Oh. Let's see. Why is the whiteboard not working? Loose cable? Maybe. Check, check, no, check. Oh, there we go. OK. Let's take a moment to talk about what's in these files. So why is there a file called model.json and a file called, I already forgot, model.weights.bin? Model.weights.bin. OK, so we haven't really, as part of this video series at least, talked about the details of what a neural network is. But this particular machine learning model is a neural network. And a neural network has some kind of architecture to it. It has a whole bunch of inputs. And it has a bunch of outputs. And in this case, it actually just has two outputs, a happy or a sad. And the actual thing the neural network is producing is a probability of one or the other. Now, in between, oh, and the inputs, sorry, the inputs is an image. So maybe every single pixel of the image is wired to one of these inputs. Then there are these layers. The data is going to be processed forward. The math and various things are going to happen to the data as it goes forward. And it needs to have some amount of hidden layers and other types of nodes. And everything is connected. And this is stuff that I have described in other videos. And I'll also refer you to the 3Blue1Brown What is a Neural Network video, which is terrific to see more. But the reason why I'm mentioning this is this model.json is a file that describes the architecture, maybe is architecture of the model. And this model.weights.bin is a file that describes all the weights. So what I mean by architecture is how many inputs, how many outputs, how many hidden layers, and all sorts of configuration details about the architecture of this neural network that I've half-drawn here in a pretty crude way. The thing that I'm kind of not mentioning, because I don't want to be here for the next 17 hours going to every sound, every different road of detail here, is that the data as it's passing through the neural network, all of these different nodes between the inputs and the outputs and the hidden layers, all of these nodes are connected. And each one of those connections has a weight. You can think of the neural network as a thing that has just lots and lots of dials in it. And it's trying to learn what the right setting for all the dials is to produce the appropriate happy or sad result based on the input image. So all of the numbers that store the values of all of these weights are all in this file. So this is actually a file that we could very easily go and look inside. It's JavaScript object notation. It's a JSON file. We will look at that. But the weights is really the big thing. It's where there's a ton of stuff. There's tons of these connections. It's many, many numbers. So it's typically stored in binary format, raw digital data, so that to have it be the smallest file size. So these are the two files that we need. Let's go take a look at those. So the next step for us is to take these two files. I'm going to copy them. And actually, I think I could probably just drag them into Visual Studio Code because I want them to be part of this example. Right. So we can see that they're here now. Now that I have model.json and model.weights.bin as a part of my project, if I were using the P5 web editor, I'd need to upload these files. I'm not sure if that's actually possible. I'll have to look into that. And then if we look at model.json, for example, you can see, and I'm going to hit Save, we can see this is the model topology. It's a sequential model. And these are the inputs. The inputs are 7 by 7 by 256. And somewhere, ah, yes, ml5 specs. These are the labels, happy and sad. There's all sorts of other stuff. There's some dense layers. And there's where it gets the weights. And it's using TensorFlow layers and TensorFlow.js. So all this information is in here. The bin file is not something we can really look at because it's in binary format. But we can know that all of the numbers, those weights are there. So now, guess what? We're going to go back to our code. And I'm going to look at the steps here in setup again. So in setup, the first thing that I do is I create a feature extractor with mobile net. When that model is ready, hold on, I'm thinking for a second. Just time out for a second. I just want to look. Unfortunately, the documentation isn't up on the website for this. So I just want to check something to make sure I'm doing it correctly. I'm going to look at it over here real briefly. I'm just looking in the existing examples. There actually is an existing example for this. I don't know why I'm not pulling it up here. I probably should. I think it's here. I just need to understand the order of this. Classifier. Oh, yeah. Okay. That's interesting. I guess that works. The order of all this stuff is weird. And I feel like this is a thing we have to work on with the library. All right. I'm going to not worry about this too much. Okay. So once the model is ready, then I can go ahead. This is the function for when the model is ready. I can now go and say classifier.load. And guess what I want to tell it to load? Model.json. And I'm going to say custom model ready. Custom model ready. Custom model is ready. So first, mobile net has to be loaded. Once that's done, then the custom model can be loaded. Now, look at this. Classifier.load.model.json. Remember, there are two files. Model.weights.bin and model.json. ml5 is set up to work that if you just tell it where the json file is, model.weights.bin, then it will load the model.json. And set up to work that if you just tell it where the json file is, model.json, it will look for the corresponding model.weights.bin file in the same directory. There are ways that you can customize what those file names are and have them in different paths, but this is the simplest way of doing it. So let's see if this works now. Model is ready. Ah! Got an error. What is this error? That was sad. Maybe it has zero. Let's look at... 5 megabytes, that makes sense. That's right. It's definitely like weights there. Oh, it didn't find it. Oh, weird. Oh! I know what the problem is. Ugh, I don't like this. I think it's going to work now. Yeah. So it did load. So the issue is the following. This is actually kind of like a bug because it's not looking in the local directory unless you specifically do the./. But I think it would be simpler to let the user just do this. So that is a bug to file. Let me do that real quick. But I won't worry about that. Right now. What is this? Feature, extractor, model loading, relative path. So is this... Look at this. The following works. Making a live example live on YouTube right now. The following works. However, just referencing the file name and expecting it to be the local path doesn't work because it looks for model.weights.bin somewhere else. This is a minor detail because we can definitely get it to work. Let's get this error. And let's go back to GitHub here. Let's see. Oh, weird. But it actually did look in the right place. Huh. That's weird. This is a thing. I'm so confused. Whoops. Oh! It would have worked. This is interesting. It would have worked. I'm not being careful enough. If I were running the server from here... It works. It works. It works because it's a subfolder. But I feel like it should figure out that it's in a subfolder. Right? So... Okay. I've got to change my error message here. If the sketch is not at the root path, I can load the model via a relative path as follows. But... However, if the sketch is not at the root path, but... However, if I look for model.json with a relative path like the following, it then looks in the root directory for model.weights.bin. This is minor for my example, but noting as it's an error people will encounter, is it trivial to support looking always in... Okay. So I think this is... If the sketch is not at the root path, I can load the model via the current directory. At the current path directory as follows. However, if I ask for model.json as follow, this way, it then looks in the root directory for model.weights.bin. All right. So let me submit this. Yeah. Let me submit this. I think this makes sense now. Apologies if this issue is weird, because I'm doing this in a live stream. Okay. So I'm actually... We're going to fake this here. No one will notice. Okay. We're going to fake this. So, Mathieu, I'm going to... I'm not going to show that error, actually, because that error is irrelevant to what I'm doing here. So let's see if I can get it to work just like this. Okay. Because I think that'll get fixed later. I hope. Okay. Okay. Let's go back. Oh, it's already... That's no good. So how do I... Hold on. Okay. All right. Let's try now loading that model. I'm going to hit refresh. Model's ready. Video's ready. Custom model is ready. So it's been loaded, but I'm not... I'm not seeing the labels. So it doesn't... Even though that model was loaded, I now have to figure out... I now have to tell the code no longer really needs to be trained in this case. I might want to retrain and do fancy. I'm going to take out the training button, and then somewhere there's like an event where it finished training where I said classifier, classifier got results. And so that's what I want to do now when the custom model is ready. So the events are as follows. Let's bring this down here. First, load the MobileNet model. When the MobileNet model is ready, then load the custom model. When the custom model's ready, start classifying the image. All right? So here we go. Let's... Ah, yay! What did I have with this hand? I can't even remember. No, it was this hand. All right. So this is working. The buttons are now no longer relevant, so I could actually take all the buttons out. And this is now... Again, whether you want to have one sketch where you train and save and load or two different ones, but I'll just show you right now. The idea here is I did my training, I'm done, and now I have something that automatically loads the model. Yay! All right. So I hope this was helpful. You can now see that process, right? What is the process? Train the model, call the save function to download model.json and model.weights.bin, then take those files into your sketch, use the load function to load them both, and then start classifying. All right? So give this a try. See what you can do now that you can spend a lot of time training your model because you can save it and see what you make with it. All right? Thanks for watching, and I will see you in another ML... There will be more ML5 videos. I don't even know what's next, but if there's a video that's next, you can watch it. Goodbye. All right. Hopefully that can be made into something understandable. I wonder what would happen if... I'm just curious, what would happen if I retrained it? Yeah, I guess it retrains. Yeah, but then if I refresh, it's loading that previous model. Okay. Any questions about this? Will JS always load the setup function? Automatic asks Tobias. So this is a feature of the p5 library. So I'm using the p5 library, and the p5 library always calls the setup function. And the p5 library always calls the setup function first. That's the way it's configured. But this is not something that will just happen in any JavaScript environment. It's here... It's specifically part of the... Part of the p5 library. Okay. Okay. Copper asks, so save not save all the model like in Keras? I'm not sure I completely understand that question, but I'm going to try to rephrase it. I think what Copper is asking is, is this like saving a model in Keras? And the answer is yes. There's a lot of nuance to this, because number one, it's saving the model in a particular format that is compatible with TensorFlow.js. So this model that we saved won't necessarily work with a Python Keras example without being sort of converted to what it needs there. And there's also this sort of strange feature of it, which is that it's already like... We're just saving the sort of part that's on top of the MobileNet model. So I haven't like resaved the entire MobileNet model. I'm just saving the transfer learning piece of it that is plugged into the MobileNet model. Because it's still always loading the MobileNet model. And yes, KWikOne says, as far as I know, you can even import a Keras model into tf.js. So yes, if you want to import a Keras model into tf.js, you just need to look for the tf.js converter. This is a script that will take any TensorFlow or Keras saved model and convert it into TensorFlow.js. This is from the TensorFlow project itself. Does that mean it will work automatically with ml5? In theory, yes, but ml5 is kind of a subset of TensorFlow.js with a bunch of things wrapped to be a little simpler to work with. I kind of want to do that video again, because I feel like I don't know if I hit all the right notes. I'm going to do it again. And then Mathieu can pull, because I feel like this is a really sort of important one. And then I will do the quick draw stuff. ASDFGHJKL space ASDFGHJKL asks, why do you choose p5.js over other JavaScript libraries? I love p5.js. I mean, it's a great question, and I don't think there, I certainly am not here to say, please, I think you, the viewer of this channel, should use p5.js. The reason why I use it is because it's a project that's connected to a project. It is a project. It's part of a project called the Processing Foundation, an entity that I've worked on for many years that I have a lot of personal investment in, and the goals of that project in terms of being beginner-friendly, being inclusive, are values and principles that are close to my heart and that work well with the kind of stuff that I want to do in this channel. Is it perfect? No. Are there other things that you might want to use instead? Definitely, but it's a good foundation library for me to build a lot of stuff with. All right. I know I've been torturing you all, but I'm going to do this again just to give Matthew more material to work with now that I have a sense of what the issues are. So I'm going to go back to what it was originally, and I'm going to redo a couple things to make it less awkward. I am going to—let's just see here. Let's see here. Okay. So I'm going to move some things around, I think, to make things less awkward. Is that legible, this font size? Is this legible? It's smaller than I usually have it, but this might be helpful to have a little bit more room to look at the code. Yeah, let me rename the uke and whistle button. Thank you. Let me rename those. Thank you. That is—I don't know why I'm— a happy button, sad button, a train button. Okay, so that's good. Any other suggestions? It's fine. All right. Let me try it with the code a little bit smaller. Okay. Here we go, everybody. Oh, right. I have to do this ridiculous thing again. I mean, Mathieu, whenever you watch this, you can take stuff from the first try and mix it if you want, but it's my hope that this will just be a cleaner version of that video. And apologies to all of you watching live when I make the same jokes again. Not that I made any jokes, not that any of them were funny, but if I did, I'll probably make them again, more awkwardly. Can you continue working on the local project, asks David. I don't think so. Okay. Hello, and welcome to another ML5 beginner's guide to machine learning with ML5.js video. All right, so this one's a good one, I hope. I'm about to make video number seven in this playlist. And this—the element in the— Oh, I forgot something. I forgot that I have all of this stuff here already. And I don't want it to be. Delete, delete, I'm so in love with you. Delete, delete, oh, with my eyes so blue. Delete, delete, delete, delete, delete, delete, delete. It's getting hot in here. All right, here we go. Hello, and welcome to another beginner's guide to machine learning with ML5.js video. Now, in this video, I am going to unlock something for you. It's already unlocked for you, but I'm going to show it to you. That is incredibly powerful for what you can do now with ML5 that you couldn't do before, but many of you asked about in the comments. And what is that? It is the save load feature extractor. This is a new feature that was added to ML5 just five days ago. You need to make sure that you are using ML5 0.1.3 or whatever number in the future past that. But certainly, this is the version of the library that I'm using in this video. Now, what does it do? So, the last example, if you've been watching these video series in order, was this example. What this example does is it loads a pre-trained image classification model called MobileNet. And MobileNet is trained on a thousand different kinds of things and recognizes puppies and dogs and birds and different kinds of objects. Transfer learning is the process by which we take that pre-trained MobileNet model and basically disconnect it from all those labels and reconnect it to our own labels. For example, I'm going to make up a label called happy and a label called sad. I can certainly have more than just two. And I'm going to show it things like the train whistle is me being happy. I'm going to show it that train whistle a bunch of times. Say happy, happy, happy, happy, happy. Now, no train whistle is very sad. I'm sad. No train whistle is sad. Oh, I'm spending way too much time on this because I haven't implemented the thing that I want to implement. Now, I'm going to say train and it's going to train. And then once it's done, ah! Happy. Sad. Happy. Sad. Okay, so it works. It is now learning to classify images in real time according to those two categories. But I'm a big spaz and I'm going to just be over here doing refresh. And I have now lost that forever. I no longer have that model. It's gone. The new feature is ability to save that custom trained model and then reload it. So if you're using this for an installation and you're going to take down the computer and set it up every day, you can save that model. You can imagine. There's lots of possibilities here. So there's only two things that I really need to add to the code. There's a save function and a load function. There's a bunch of pieces there, but that's what I'm going to do right now. So I'm going to go here into the code and I'm going to just add another button. Like I have a happy button, a sad button, and a train button. Choo-choo. I'm going to add a sad button. No, no, not sad. Save button. I'm going to call it save. And save button, when the mouse is pressed, I'm just going to say classifier.save. That's it. All I have to do is say classifier.save. Let's see what happens. So I'm not going to train it very... Actually, no, I am going to train. I'm going to let's do a really good, solid training this time because this is the one we're going to save. As long as it works. All right. So let's do the same thing. Happy, happy, happy, happy. Train whistle is a happy thing. A happy, happy, happy thing. Just me is very sad. There's no train whistle. I'm so sad. I'm very sad. I'm very sad. And now I'm going to train this. Weird how the loss is zero. I'm just going to not worry about that too much. I'm going to hit save. And now, you can see that down here, by the way, that I did this a couple times practicing. Now, what it did is it downloaded. Come on. To my download directory, two files. Model.json and model.weights.bin. So those files will end up wherever the default downloads directory of your browser is. And the next step is just to load those files in. But before we load them, let's talk about what's in those files. So there's two files. I said model.json and model. Model.weights.bin. Okay. So what is a neural network? What is a machine learning model? What is the thing that we're saving? Well, in this case, it's actually saving the configuration of a neural network. Now, if you want to know what a neural network is, I have some videos about that. But I would refer you to the 3Blue1Brown video, What is a Neural Network? I will link to that in this video's description. That will give you a much bigger deep dive into those details. But if you look at that video, what you'll see is there's basically like a big diagram. And the diagram has a bunch of inputs. It has some outputs. By the way, in this case, we could actually say the outputs are just two, a happy and a sad. And what the neural network, what the machine learning model outputs is a probability, maybe like 80% of it being happy, of that image being happy, and 20% that image is sad. So the whole point of this is to feed in an image. It's the image and maybe all the pixels of the image that are actually these inputs. It goes through this magic neural network thing, which isn't really magic. It's a thing that you can learn about. And then out the other end comes a guess as to whether it's happy or sad. Now what is all this stuff in the middle? The stuff in the middle is typically referred to, and there are many different styles and flavors and kinds of neural network, but in the sort of zoomed out view, in general terms, is what's known as a hidden layer or hidden layers. So every input is connected to the output, but not directly. There are some amount of nodes, maybe two hidden layers, each with four nodes. And every input is connected to every node, and then every node is connected to every node, and then every node is connected to every output, and so on and so forth. So I could be here all day trying to do this diagram and draw every connection between everything. I'm not going to do that. But all of the information about here is what is saved in these two files. Model.json is a file that just explains all of these pieces, the layers, the outputs, the inputs, all of that stuff. That is what is in model.json. In a moment I'll just open up that file and look at it. Model.weights is an interesting thing. So the magic of a neural network, what makes a neural network work, is a number that's associated with every single one of these connections known as a weight. You can think of it as a whole bunch of dials. So I'm tuning the dials, right? I'm trying to get the dials in the right position so that it really makes good guesses about happy versus sad. That's the training process. Once that training process is done, I want to save where all those dials are. All of those numbers are in this file. This is a binary format file because there's a lot of numbers. Millions upon millions of connections potentially between a lot of pixels and a lot of labels and a lot of hidden layers. So this, you'll notice, the file that we saved is 5 megabytes because it's tons and tons of numbers. So it ends up, but this is just a very small file with a little bit of text information about how this is configured. Okay, I spent a lot of time on that. Hopefully that's some helpful background to you. Let's go back and actually look at those files. So now I've got those files. What I'm going to do is I'm just going to drag them into Visual Studio Code, which is what I'm using to code this right now. But you could be using any environment. Oops, they didn't make it into the right place. Let me try that again. I'll clean this up later, but I want them in this directory. Great. So you can see that they're there, model.json, model.weights.bin. If I click on this, you can start to see all the stuff in it. There's information about the input shape, and is it a sequential model, and what kind of algorithm are you using, and is it dense, and it uses something called softmat, all this stuff. So this is way beyond the scope of what I'm doing in these videos, but if you're interested in more about these details, you could look at some of my videos that use TensorFlow.js natively to understand more pieces here. But you can see here, this is where it's looking for the weights file, et cetera, et cetera. And this is really important. This is really just what TensorFlow.js would do natively, but ml5 is helping with a little bit on top of it by adding these happy and sad labels. Okay. So now, all we have to do is load the model now. Okay, so we're going to go, we saved that model, and so the steps are, the first thing we have to do is load the MobileNet model. So we're not actually saving that original pre-trained image classifier. We're just saving the bits and pieces that are hooked into it. So we can't hook into it until MobileNet is ready. So once we've hooked into it, once MobileNet is ready, we can then say classifier.load model.json. Now, there are two files, model.json and model.weights.bin, but ml5 has set up that if you just give it one file, it'll look automatically for the other file in the same place. There are ways of customizing the file names and their paths and all that, but that you can sort of look into in the documentation. But the easiest thing for just to do this, and then I'm going to say custom model ready. So I'm going to write another event function, custom model ready, and there I'm going to say custom model is ready. So it's a two-step process. So I'm going to say if the load MobileNet, MobileNet is ready. Then load model.json with the weights, custom model is ready. All right, let's just run this. Zoom back out, and there we go. Everything's loaded, but I don't see any results. Hmm, I don't see any results. Why? Well, this sketch was written originally with code to train. So I'm supposed to press the buttons and hit train, but now I don't need to train because I loaded the model. So this is where I kind of like, I don't know what you should do next. Maybe you want to keep two separate web pages, two separate sketches, one for training and one for loading. Maybe you do it all in one. You'll actually see if you go to the ml5 examples, there's one that has like a button that you can like drag and drop. You can actually like select files and load them and save them all in the same sketch. But what I want to do now is basically a workflow for I'm done with the training, so I'm not going to ever train again. So I can actually remove all of these buttons. They're no longer relevant to me. The text that should show up at the beginning is just loading model. And then when the model is ready, I would say label equals model ready. So let's run this now. So now loading model, loading model, model ready. And now once the model is ready, all I need to do is start classifying. And before I didn't classify until the training was finished. The training is now irrelevant. I could actually completely comment this out as well. And basically I want to start training when the model is ready. Not training, sorry. I want to start guessing when the model is ready by saying classifier, classify, got results. And now here we go. Loading the model. Model is ready. Happy. Sad. Happy. Sad. And I can refresh the page again. And happy. Sad. Happy. Sad. All right. So it works. We're done. Yay. Okay. So this is a thing you can do now. You can train your own transfer learning model. You can do this with the regression example too if you watched that video. You can save it. So I don't know. Share. You can share models. Let's all share models with each other. Share your model with me. Let's see what happens. All right. I'm curious to see what kind of creative stuff you come up with. What kind of the interaction that I've done here is like super awkward. Like I'm going to press the button all the time. And maybe you don't actually have to train with just video. You could load a bunch of images. So there's so many possibilities here. And I look forward to seeing what you make. And stay tuned for more ml5 videos. More stuff is coming. I don't know yet what, but more stuff is coming. Goodbye. Okay. All right, everyone. I'm glad that I did that a second time. This computer went to sleep for no reason. And there's very little going on in this computer. Oh, okay. So maybe that's fine. Somebody wrote a comment on my issue. Okay. All right. So I'm done there. Okay. That's going to be a good one to release. Now we are going to move on to something totally different. We are going to move on to something totally different. What time is it? 3 o'clock. It's getting warm in here. Actually, so now I need to release this example. So I'm going to delete the model and the weights. I'm going to delete the model and the weights. I'm going to, I just want to leave this. I think what I'm going to do is leave this example with this stuff here. And then, this is tricky. Comment out loading this. Comment this out. So this example is now left in the training state. But it has the loading code in it, but commented out. And so now let me just put this. We just put this online. Code from save load live stream. Save load ml5. So this is now, it should be in the website. I'm going to create a pull request here. This is the code from 11.9 live stream. I'm not sure if I should make this two examples or just one. For now, the loading code is commented out. Okay. So I'm going to create this pull request. And it should be just these files. Okay, good. Great. So that code will be on the coding train website. Just for people who are looking, there is also this example. I had it open. So this is the same exact example. I'll note, though, that this example uses a button that you can select and then select files and load them. So there's a lot of other ways of approaching this. So here's yet another example with sort of more features that you can look at. Okay. All right. So now what do I want to do? All right. I am going to go to the desktop. And. And I just want to get. I just want to have like a P5 sketch in that directory that I can kind of start using. And so let's get rid of everything here. And here. And index. Quick draw. Okay. Okay. Now. What did I minimize that? So I need the browser. And. And. Quick draw data. And. There we go. Okay. And. And then this is part of. Build your own API with node. Where is that? Okay. Okay. Okay. Yeah, that looks like there's a discussion in the chat about why I'm using the separate terminal instead of the built-in terminal VS code. And why not just use the VS code live server? Those are all very good questions. I you know sometimes I don't like to feel like I'm just only using one thing. And then what if that one thing goes away? So I don't know. Why does this keep this camera keep going out? Is it a very loose cable or something? There we go. Alright. Okay. Okay. Okay. Okay. Okay everybody. Everybody settle down. We're going to do something really fun. Oh this is empty. This is the last thing I'm going to do before the weekend. And there will not be any live streams next week. Unless somehow I figure out some magic way to live stream from thinkercon. But we'll see if that's possible or not. And. Alright. Now. I think I am ready. I think I am ready. I have all the pieces that I want. This is actually, I'm going to make this a coding challenge. Maybe the sketch RNN stuff will be tutorial-ish with ml5 but. Okay. Well I don't know what to do. I'm going to make this a coding challenge. People watch the coding challenges more than if they're in the tutorial videos. Okay. I'm just trying to do like my stretching because my back issues. Okay. You know. Hold on. Mathew. I'll make a thumbnail. I better make a good thumbnail for this. Remind me to make some thumbnails. I mean just like pose with the results. Okay. Okay. Hello and welcome to a coding challenge. Actually you know what? No, no, no, no, no, no. This is what it's going to be. Okay. I'm going to start with this behind me. Okay. Okay. Can I do a grand entrance? Hello. Hello and welcome to a coding challenge quick draw edition. Now I have been talking about doing this for a very long time. And I'm excited to finally try this on my channel. One of my favorite data sets that is out there in the world is the quick draw data set. Now here's the reason. One of the reasons why I'm interested in this is not just this data set of 50 million drawings which is interesting and fun to play with on its own. But there is something called Sketch RNN which was developed by a set of researchers at Google. Google Brain. And you can see some of them here who wrote this paper. And explained how Sketch RNN is a neural network, a recurrent neural network that learned about how to draw various things from the quick draw data set and then can try and imagine and create new drawings based on how it learned and can even interact and draw with you. So many possibilities. So this is where I'm going with this. I am going to make it, Sketch RNN has recently been added to the ml5 library. And I'm going to show you an example. And I'm going to build that with Sketch RNN ml5. But I feel like before we start making the artificially intelligent system that generates the drawings, let's look at the actual data itself that it was trained on. So first, where did that data come from? So, and apologies if I get anything wrong. Please let me know in the comments. Because this is not my project. I am just inspired and enthused by it. So the quick draw project is a project, an AI experiment made by friends from Google. And it is a game that you could play where you say draw a pencil in under 20 seconds. Okay, here we go. I see marker or lipstick. No, no, no. That's not really like a pencil. If I put an eraser here. I see rocket. No, rocket. I'm the worst. I'm not sure what that is. Yeah, I don't know what that is either. Time is running out. Sorry, I couldn't guess. All right, let's try basketball. I see nose or moon or blueberry or baseball or bracelet. Oh, I know. It's basketball. All right, I win. Okay, so you get the idea. I could be stuck here for quite a while. Now, what you might not, when you are playing this game, your doodles are being collected. And over 15 million players have contributed millions of drawings playing quick draw. Oh, and I've used this before, right? I made an example with a neural network that tried to recognize your drawing. So, this has been done on my channel before. But what I haven't actually looked at, what I looked at before was I looked at all the drawings as pixels. What's actually, what's interesting about the data is that the data, which you can find here, information about it on GitHub, is not pixels. It's actually the pixel paths of the people making the drawings with timing information. So, you could load that data and replay any drawing back. And each drawing has the word that was associated with it, the country where the person is from who drew it, at least the IP address presumably, and then whether it was recognized, and then the actual drawing itself. So, what I want to do, and you can see here that the format of the data is a whole lot of xy positions. xy, xy, xy with timing. What time was I at the first point, the second point, the third point? Then, I might have lifted up my pen, moved, and started doing another one. So, it's a bunch of strokes. So, this is, it's a little tricky because I can't use the word stroke as a variable name in p5 because stroke is a function that actually sets the pen color. But the idea is that if I do this, it's sampling a bunch of my points as I drew along that path. Each one of these is an xy point associated with a given time. And then, there is an array with all of the x's, all of the corresponding y's, and the corresponding times. Now, what I'm actually going to use in this video is if, there are a bunch of different versions of the data, I'm going to use a simplified version of it because these are huge data files. But I encourage you as an exercise to try to do what I'm going to do but with the non-simplified version, maybe with the timing aspect of it. But the simplified drawing files are the same exact thing, the same exact thing, but no timing information. And also, they have been sub-sampled, meaning, you know, in theory, as the person is drawing, as the user is drawing, a lot of points are being captured. But maybe you don't need that level of detail. And that's often referred to as like pixel factor or scale factor, I believe, or epsilon value, I guess. So, you can say simplify all strokes using the Rammer-Douglas-Puker algorithm, I don't know if I pronounced that correctly, with an epsilon value of 2. So, these are available as something called NDJSON. Now, if you've watched my videos before, you're probably familiar with JSON, JavaScript Object Notation. That is a format where you can store data. That's in JavaScript Object Notation. I have some videos about what is JSON. NDJSON is a funny thing. Ha ha, it's hilarious. It's like the funniest version of JSON. And it actually is a set of multiple JSON elements, each on a different line in a file. So, it makes sense to do that. Each drawing is its own sort of like JSON object on a different line in the file. So, let's go grab one of these files. So, getting the data, we can actually go to the public datasets. Oops, no, I'm sorry. I just want to go to the list of the files in the cloud console, which is right here. I'm going to say I agree and I don't want any email updates, but I accept. Okay. Accept. So, I'm going to go to full. And, oops. I realize you can't see anything here, so let's try to make this bigger. Let me dismiss this right now. And, come on. I guess I'll make this smaller and I'll just zoom in. So, these are the different formats. They're actually all the data in just like binary. There's this NumPy bitmap, which is useful for other kinds of machine learning, different things you might want to try. The raw data, but let's look at the simplified data. And, let's pick, oh, I don't know. Which model should I pick? There's so many. Banana, bandage, baseball, basketball, bat, beach, bear, beard. I guess I should do beard. Right? That's kind of lame, though. Birthday cake. Is there like a unicorn? Maybe there's a unicorn. No. Was there a rainbow? Yes! There's a rainbow! Alright, so we'll use the rainbow. So, I am going to, oops, download this file. So, here's the thing. This is a very large file. I had a reason why I was doing this challenge also. This is a 43 megabyte file. Now, I could just use some code in my client-side JavaScript to load that file and put it on the web. And, at some point, I might show you some techniques for doing that. Stay tuned in the future. But, I think this is a good case where my video series, the sort of module for my programming from A to Z class, or the program with text class, building an API with Node and Express. This is a case where I've got this. What if I wanted to have every drawing? Some of the, there's just millions of them. I don't want to load hundreds of megabytes and gigabytes of files in my client-side JavaScript. I could write a little Node program whose sole purpose is to hold on to all that data. And, my client-side JavaScript could just request it. So, this could be because what I want to do is create an API out in the world for people to get drawing information. But, this isn't data that I own in a way that I would necessarily do that. We'd have to look at the licensing to see if that's even something reasonable to do. Where is that eraser? But, what I can do is on my computer here, the idea here is like, oh, I'm going to make a server. And, the server is going to hold all of the drawings. And, then my P5 sketch can just say, hey, can make a request, like a get request. Please, could I have a rainbow? And, then the server is going to send back just a single drawing. It's not going to send back hundreds of megabytes of data. It's storing all that data, but it's going to send back just one piece. The interesting thing is this server can easily just also run on the laptop. So, and I could connect to it. So, there's a variety of ways you could deploy this and use this, but I'm going to do it all from this laptop. Alright, so to run a server with Node and Express, you can go back and watch some of these videos where I step through this in more detail. I'm just going to start it in the directory in my console. And, I'm going to say npm init, and I'm going to call this a coding train quick draw example. And, it's version 0.0.1. It is an example that I am making on the coding train. And, you know, whatever. I'm going to skip through a lot of this stuff. Yes. Okay, so now if I go to my code, you can actually see I have this package.json file. The package.json file has all that information that I just entered. This is the configuration file for my project. Node is the sort of central manager of this project now. So, I need a couple Node packages to be able to make this work. I need to use Express. Express is what I'm going to use to handle that get request, this HTTP get request. So, I'm going to say npm install express. And, then I also need something to load that nd.json file. So, nd.json Node. I've actually used this before. But, let's look. So, this is a Node package for loading an nd.json file. So, I'm going to say npm install nd.json. Great. There we go. And, now I meant to show you what is that nd.json. Oh, I got to grab that file now. So, I also need, I'm just going to rename this to rainbow.nd.json. I'm going to drag it here into my project. So, now this is a huge file. And, so you can see that Visual Studio Code is like freaking out. It's like I don't want to deal with this file because it's too big. But, you can see that what this is, is every single drawing on one line. So, it's like this is my database, essentially. Database of rainbow drawings. I have a database of rainbow drawings. What could be better? Okay. So, what was I doing? Back to the code in the server. Oh, I don't have a server yet. I'm going to add one. I'm going to call it server.js. I could call it app.js or index.js. And, here I'm going to go back to this. And, basically, I just want to do exactly this. So, the first thing, I want to use this. I need the file system module. So, I'm going to say const fs equals require file system. File system is a module that comes with Node. I don't have to install it. But, I also want the nd.json module. Which, it doesn't come with Node, but I added it. And, here we go. And, we can see, by the way, that when I installed those, they are now dependencies in the package.json file. And, now, do, do, do, do, do. Ah, there we go. Now, this is, so what is this doing? This is streaming it. So, this is really useful. It's a huge file. Rainbow.nd.json. I certainly could load it, just using, loading the file into a big string, chopping it up and parsing it. But, when you have a big file, like an nd.json file, you want to read it as a stream, essentially one line at a time. Because, it could be like a gigabyte file. I'm not going to, in this case, I'm just going to say, like I'm going to make an empty array. And, every single object, I'm just going to push into that array. But, let's console.log them, just to see that this is working. So, this is the stream. As it reads line by line by line, the nd.json file, it's going to console.log that object. Okay. So, let's go here. And, I'm going to say, node server.js. And, there you go. You can see, this is it. This is every single drawing. It's going to take quite a while, because there's thousands and thousands and thousands of them. But, you can see, this is the word. This was the country code. This is whether it was recognized. It has an ID. And, then the drawing is in these arrays, which aren't console logging, but I can get access to them. Wonderful. So, I now have an array that has every single drawing in it. Now, how do I get access to that? I need to be able to make a get request to the server. So, let's see how we would do that. So, I need to make an express server-y thing. Let's just look up express node and go to the kind of like quick getting started, hello world. Like the hello world express example is all we need, basically. I'm going to grab all of this, and I'm going to put it into my code. So, what's going on? Number one is I need to require the express library. I need to create an app, which is calling the express function. I'm adding the semicolons. Gosh darn it. I need semicolons to live. I can't do it without. I need to pick a port. So, port, this is somewhat arbitrary, but I'm going to use the port 3000. And then, I'm going to set up a route. So, the idea, and I prefer to be a little more long-winded about this. This is using the arrow syntax, which is a kind of ES6 JavaScript syntax. And I'm just going to, I just have to do things the way that I do them. So, there's two functions that I care about with my app. One is that I need it to listen on the port. So, this, I'm setting up the server, creating a server, and that server is listening. Because ultimately, I've got to get to that p5 sketch that's going to make the drawing. I haven't even gotten there yet. Now, I then want to set up a route. And then, when the user makes a request to that route, send something back. So, in this hello world example, if I run the server and go to localhost 3000, it says hello world. But that's not what I want. I don't care about sending hello world. What I want to do is let me make a route called rainbow. Then, what I'm going to do is I'm going to say let a random number equals math.floor, math.random, times drawings.length. So, however many drawings have been loaded when somebody goes to this route, pick a random one. And then, I'm going to say, and this could be a const, I guess. And I'm going to say response send drawings index r. And I suppose I should call this index. So, now, oops, index. Let's rerun the server. And there is a tool called nodemon which will restart the server for you. I'm going to do this manually. And then, I'm going to go here. Cannot get slash because there is no route anymore at slash. But if I go to slash rainbow, there we go. There is the drawing. Hold on a sec. Time out for a second. I could have sworn I have this extension that will format the JSON, but I guess I didn't. All right. I just installed a Chrome extension to format the JSON so I could see it. So, here is a random drawing. And this is all the information. All I need to do is have p5 request JSON from this route and then render the drawing. Pause for a second. I think I'm not doing multi-part videos this day. All right. Oh, there's been some new members. Thank you very much. All right. So, now the question is where do I run my p5 sketch? And there are a variety of ways. In theory, this is an API that anyone could make a request to. Whether or not I'm opening it up for other people to request to it or not is a complicated question. But one way that I could use it is just have this particular server host a p5 sketch in the first place. So, the way to do that, if I go back to my files and I go to desktop, quick draw. This is where all the files are. I'm actually going, I have a p5 HTML file and a sketch.js file in here. But I'm going to make another directory called public. So, these would be where I want files that are hosted by the server to live, public. And then I'm going to say something like in my code, app. I don't remember. Static file hosting express. Serving static files in express is just this. So, basically what I want to do is serve up the HTML and the JavaScript files as well. So, I'm going to do that here. I'm going to add this. So, now look at this. Now, and let's go to the p5 code and let's say background 0. So, all that this p5 code does is create a 100 by 100 canvas with a background of 0. So, now guess what? If I go to localhost 3000 slash rainbow, I get a drawing because I'm handling that rainbow route with a, by sending back a drawing. But if I go to just slash, oh, I didn't restart the server, did I? Restart the server, go to slash, there's the p5 sketch. So, now my p5 sketch can finally ask for the server for the drawing. Okay. I'm going to go over here and I'm going to say, first of all, one thing is by the way that simplified data set, all of the simplified version of the quick draw data set, all of the drawings were simplified or scaled to 255 by 255 pixels. So, that makes things easier to work with. I'm going to call the function loadJSON and guess what? I'm just going to say loadJSON rainbow got rainbow. And then I'm going to write a function got rainbow that gets some data and I'm going to say console log data. So, this is the idea. Now, if you've seen loadJSON before, maybe before I've used it for like load this actual JSON file or maybe I've said loadJSON from an API like Wordnik. Now, I'm going to the slash rainbow route which is local to this particular server and guess what? I don't actually even need to restart the server because this will be loaded dynamically. So, let's go here and we can see there it is. This is the rainbow drawing right here. Let me give myself some more room and here's the drawing itself. So, all I need to do now is write an algorithm to go through and draw this drawing. All right, we're ready. So, let me make the background like 200. Let me say the drawing is in data.drawing. Is that right? Console log drawing. Let's look at that. Yeah, so this is the actual drawing. It's just two arrays because it was just two strokes. Now, I am going to say for let i equals 0, i is less than drawing dot. Oh, let me figure this out. This is an array. Oh, right. Oh, weird. I'm sorry. I'm going, oh, right. Okay. So, this is only one stroke. Oh, this was confusing here. Some of these rainbows, there we go. This is what I want to look at. I have three different strokes. So, first I need to look at all the strokes. Sorry. So, I want to say let and I'm going to call it a path. So, for let path of drawing. This is each and every path. Path 0, path 1, path 2. Then, each path has a bunch of points. Path 0 has 15, path 1 has 10, path 2 has 6. I'm going to say for let i equals 0, i is less than path index 0 dot length. And then, the x is path index 0 index 1. Wait, no, index i. Oh, sorry. This is confusing. And the y is path index 1 index i. Right? So, this is what I'm doing. I am looping through 0, 1, 2. 0, 1, 2. That's the outer loop. Each path. Each path is two arrays. Path 0 is all the x's. Path 1 is all the y's. I need to look at all the x's and all the y's and then set a vertex x comma y. So, I can say begin shape, end shape. I can say no fill, stroke 0. Whoops. Stroke 0. And maybe I'll say stroke weight 3 just to make the lines a little bit thicker. And let's see what I see. There we go. Rainbows. Rainbows galore. These are everybody's rainbows each time I hit refresh. You know, one thing I could do now is when it finishes, I could just say like load JSON again. Ooh. Maybe I would want to redraw the background every time. That might make sense. And here we go. This is a random drawing over and over and over again. So, I could start to do things like request a specific drawing from a certain country. I could download different models. Let me pause for a second and grab another model. So, let's get... What's a good one? Apple, asparagus, axe. I mean, cat is sort of like the typical one. So, let's just do cat. So many. All right. I downloaded the cat file now. And I'm just going to put that in here as well. Whoops. Did I put that somewhere weird? No, I... Ah, sorry. Sorry, let me do that again. Delete. Ah, shoot. Ah. Hold on. Sorry, everybody. Ah, here we go. Okay, so I downloaded one more set of drawings, the cat files. So, I'm going to... The cat drawings, I'm going to copy that into here. And we can see now I have cat.nd.json. If I go back to my server, I could do... I'm going to say... I'm going to call this rainbows. And I'm going to do a different one for cat. And I'm also going to do cats. Cats push object. And then I'm going to make another route for cats. So, now, if I rerun the server... And I go back to my actual sketch. And I switch to going to the cat route. Now, where was that? Here I am. I'm going to hit enter. Ooh, I got some issue. Cat internal server error. So, what's going on here? Drawings is not defined. So, I made a mistake in my server. Oh, this is... Over here is rainbows.length. And this is cats.length. And I would have seen that error here if I was paying closer attention. There, now I've got cats. And now, let's look at a lot of cats. Ooh, it's still giving me rainbows. Did I not hit save? Load JSON cat. Oh, load JSON cat. Whatever, I'm not being too thoughtful about this. Give me the cats! I want to see the meow meow! What's going on? Run the server again. Let me refresh this page. It's still rainbows. Cat, cat, got rainbow. Somewhere I messed this up. Cat, cats. Ah! This is what I get for trying to code so quickly. This is supposed to say cat.json. Cat.ndjson. Now, here we go. Oh, I have to restart the server. And here we go. Finally, cats! There's a lot of different cat drawings. I really should slow this down. Let me just slow this down a little bit. Oh, here's what I want to do, actually. Oh, this video should really be over. But, you've already watched this much. You can watch a little bit more, right? I really want to draw the drawing in sequence. Now, I don't have the timing information. And that would be useful to have. But let's make it actually animate. So, I'm going to add a draw function. I'm not going to add a page transition event. And so, when I've got a cat, and I'll just change this. What I'm actually going to do is just set current... I'm going to just say set cat equal to data. So, I'm going to take out all of this. cat equal to data dot drawing. So, I'm going to comment this out. Let's think about this. And then I'm going to say let x comma y. And I'm going to have... I'm going to say if cat, then I now need to keep track of where I am. Let stroke index equal zero. Let pen index equal zero. So, I need to keep track of two indices, right? Because I'm going to walk through one at a time. Each vector of the first stroke. And then stroke is going to go from zero to one. And go through each of the other ones. So, if there's a cat, the first thing I need to do is say... So, if I'm going to say x equals... And what was this stuff? It is path... Oh, drawing. So, cat index stroke index. Index pen index. Index zero. Boy, this is really awkward about how it's using just arrays for everything. But I'm in the first stroke. In the first... Pen is not the right term. I don't know what to call it. Vertex? But whatever. I could actually just call this index maybe. The stroke index and the index. And zero is for x. And then one is for y. And let me just... Just to see that this works. Let me say point... Let me say point x, y. And these don't need to be global. So, let's see what this does. So, first of all, let's just run this. Oh, boy. I freaked it out. It won't ever stop. Well, I think, by the way, I killed this. I need to build in a little more of a delay with these API calls. So, cat is not defined. Sketch.js line 12. If cat... That needs to be a global variable. So, and let me just say here... Console log x, y. Did I get an x, y? Yes. So, I've got that first point over and over again. And presumably, 52, 48. I don't know why I don't see... I guess I need to say stroke zero. Stroke weight three. There we go. So, there it is. That's the first point. So, now what I need to do is say... Index plus plus. If index is greater than or equal to cat stroke index dot length, then stroke index plus plus and index equals zero. So, this is me marching through them one at a time. So, ooh, and I don't have the y. Right? You can see that something's wrong here. I mean, this... Let's see. Stroke index plus plus. I think this is right. Well, the point of this is what I actually want to do... Hmm. So, time out for a second. I forgot the variable. Well, that's probably an old comment from before. Hold on. I need a little break for a second. Why did this not work? Something is off about this. Do I have... Do I have these in the wrong order? Hold on. Right? It's going zero, zero, zero, one, one, zero. Ooh. There were 17. Oh, no, no, no, no, no, no. I have these in the wrong order. That's weird. Oh, I have these in the wrong order. Like, I think it should be zero index... It actually works this way? Oh, I'm sorry. I'm sorry. I'm sorry. It actually works this way? It doesn't seem more like the cat. Oh. It's this. This is what it is. Of course. Right? Because stroke index, then zero is the x's, one is the y's. Index is going up. And then this. There we go. Yeah. Yeah. It's hard to see, but these are the cats. Okay, I got it now. All right. Let me go back to where I was. All right. I wasn't paying attention. If I look at how those arrays are organized, the... It's... Sorry. Okay. Okay, something is terribly wrong here. And actually, I have not been carefully looking at how those arrays are organized. It's very confusing to store all these data in arrays. But there are 11 strokes. And this stroke has 23 points. This stroke has 9 points. But notice that the... I have the order wrong. Right? This is an array of an array of arrays. And so, basically, the stroke... The zero element of the stroke is all the different x values. And this one element of the stroke is all the different y values. I had those out of order. And then here, the number of points is not the number of strokes, but rather the number of x's. So now, if I redo this, I should see... I can sort of see it drawing. You can see the outline of a cat there. You can start to see the outline of a cat here. Of course, it gets stuck at the end. It's giving me an error. So first, let me fix that error. So the error that I need to check is... If strokeIndex equals cat.length... Then I'm done. Then I'm going to say cat equals null. I am going to say no more to the cat. And there we go. So this is the drawing of the cat. Now, of course, I'm just drawing all the points. I need to connect the previous points to the other points. So I'm going to add a previousX, previousY. And then I'm going to say... Here, down here. PreviousX equals X. PreviousY equals Y. And then here, I'm going to say a line between previousX, previousY, and X and Y. Now, it should do nothing when those values are null. So now we see... Oh, wait a sec. No, no, no, no, no. Ah! When I get to the next stroke, then I need to say previousX equals undefined again. And previousY equals... Because I don't want to connect the strokes. So that's a little bit of an awkward way of doing it. It's still doing that, isn't it? And then I want to say if previousX... Maybe if I do this... Does not equal undefined. Then draw the line. Let's see if this works. Whoops. Sketch line 19. I always have this extra equals there. Oh, weird. It's still connecting everything. A lovely little cat there. What am I missing? I don't want to draw the line. These are undefined at the beginning. Oh, it gets set to here. So I need an else here. Else... Don't set it if it's at the end. Okay. There we go! Finally! We are drawing cats. Now, all I have to do is then, when I reset there, I can just ask for a new one. So let's ask for a new cat. And whenever I've got a cat, let's draw a white background. Let's make it a little bit gray. We'll set it gray at the beginning. There we go. Now, here we go! We are now going to draw lots of cats. It should finish one. Oh! Didn't get another one. Sketch line 13. Uh... Cat is undefined. And then, there should be no more cat until I've got a cat. Try that again. There we go! I don't know what did wrong. Oh! It drew a bunch of them and then didn't get one. Where is it breaking? Am I... Is it like a sequencing thing? Like it's drew the cat... Is it... Asking for a new cat... Should I say no loop? And then, when it gets a cat, say loop. Oh! Stroke index needs to be set to zero. Ah! Okay! Thank you to the chat. Wait, hold on. Mattheo, you can edit out me trying to think about this for a minute. Thank you to BIMSOMEE and Louise, both in the chat, who just pointed out that my technique here is correct, but the issue is that I need to reset everything back to zero. So here, I need to set stroke index back to zero. And I think index will already be zero. Yeah, index is already zero. So yes, that stroke index needs to go back to the beginning. And now, I think we're ready to enjoy a whole bunch of cats. Cat drawings! Alright, thanks for watching this coding challenge with the Google Quick Draw dataset. Stay tuned for a future video where I show how to... What do I do? This is where I show how to create new drawings with the Sketch RNN model, the machine learning model that was trained on the Sketch RNN model. And I'll see you next time. Bye! I love these drawings. And if this was one of your drawings, thank you for making this beautiful cat, and I'll see you in a future coding challenge. Goodbye! This is like, immensely satisfying. Like, I could just watch this all day. Is it not finishing the drawings? Well, I should give it a little, like, delay. Like, if I did set timeout. I should probably do that. Let me just make a function called new cat. I don't know what music I just played. This is weird. So now, let's take a look. Now I just give it a little delay. What? What? What? 38. I messed something up. I messed something up with my... Oh, yeah. Yeah. I think that's right. Is it finishing it? I think it's finishing the cat. It does sort of seem like it's not doing the very last one, right? Yeah. Yeah, I don't know. That's way too long to wait. People who draw it didn't finish it, yeah. All right, everybody. Now, is it... It's not even 4 o'clock yet. Do I dare... Dare... To sketch RNN? Oh, right, because the Google Quick Draw guessed it before the person finished. That's interesting, yeah. I think I might be done for today. Did I do what I said I was going to do? Let me just look here. I think I did. I think I did. I think I did. I think I did. Hmm. Hmm. Hmm. Sorry, I'm looking here to think about Sketch RNN. So people are... This, by the way, is not... This, by the way, is not Sketch RNN. Just to be clear, this is the... These are the actual drawings, not the imagined drawings. I feel like I... I think I'm done for today. What did I make today? I got the logo part 2 done. I got the... I got the... I got the... I got the... I got the... I got the... Sorry, logo part 2, the ML5 saved model, and the Quick Draw stuff. I think I want to wait until Sketch RNN is in the documentation of ML5. So I will come back and do that another time. Plus, I feel like... Plus, I feel like... Yeah. All right. I could watch this all day. Let me make sure it's actually doing the last bit. Let's think about this. If strokeIndex equals cat.length... Yeah, this has to have done the last one, right? So let's... Let's not do this for a second. And let's console.log... Yeah, it's greater than... Yeah, I think it's doing all of them. I'm looking at this code. It wouldn't be skipping one. Because index is invalid here, and then it goes up. It resets index to 0. It loops back around and starts over. Yeah, it's got to have gotten the last one. Just try going one further. It'll break and you'll be right. Yeah. Yeah, I mean, I could say... Or something. Yeah. Yeah, it broke. Sketch.js line 18. It broke. Interesting. So I think maybe it wasn't... Maybe it was not getting the very last one of each stroke. Why is that? It's crazy cat. Length plus 1. Index goes up. Oh, because I'm pulling it here. And then index goes up by 1. That doesn't make sense. I'm so confused. My brain is confused. May I am so me is typing. This means the answer is about to come through. The last index won't error. It won't error. It's just going to be undefined. So I'm good. It's the same. Okay. It'll just be undefined. Yeah. All right. We're good. We're good, everybody. My mental math is still correct. All right. Thank you, everybody. It is 4 o'clock. I think I am finished. I just want to... Is there any last little bits of stuff that I want to cover or talk about today? Pac-Man. Yeah. Thank you, everybody. So let's see. I should put this code somewhere. This will be... So let me do a little quick... Just so the code is ready. I'm going to do this now. So I'm going to grab these three files. I'm going to put them in... Website. Coding challenges. So I need to make... The question is... Was this morning like part two of Logo? I think it kind of was. So this will be 1.22. Quick draw. So that stuff goes in there. And... Let's change this to 1. And then also make a version 2. Sorry if you can't see this. And then I'm going to go to desktop. Logo. This should be everything for this version. So now if I go to... I really messed up here. Because I didn't... Let me just... Let me merge this. This was the code from save load live stream. I'm going to merge this. And then... Okay. And I'm going to... Get branch... Quick draw. Check out. Quick draw. Get add coding challenges. 1.22. Quick draw. Code from quick draw. Challenge. Push origin quick draw. Okay. Check out. Master. And what I want to do is... Shoot. I have an idea here. Where is this nonsense? There is some extra thing here that I'm going to get rid of. Get branch logo. Get check out logo. And hold on. Logo 1, logo 2. Get add. Moving logo code around. And adding second part. And now get push origin logo. So I should have two separate pull requests now. Welcome to weird things with GitHub. So I should be able to pull request this. This is the quick draw code. For challenge 1.22. Well... Wait. Why is my... What sort of set of tabs is this? What? What? Have I been using four space tabs all this time? And not noticing... This is like 18 space tabs. This is insane. What is going on? This looks like two spaces. What is going on? Tab size 2. Render white space. All. Hmm. Those are tabs. Why is it... What setting in VS code is changing those to tabs? Oh my goodness. This cannot be. What am I... I forgot if I'm using prettier. I switched everything in my workflow. But I never did it on this. Am I... Do not I have... All right. All right. Let's see. I'm going to try this. I'm going to try this. All right. Let's see. Oh, this... I have this crazy thing. Indent with tabs. Size 4. Oh. Oh. Oh. Oh. What is this? Oh. Oh. Let's disable this for a second. Let's install this prettier thing. Reload. Yeah! Yeah! Okay. Oh, what a mess. Where am I? Uh-oh. Uh-oh. Who knows where I am? I'm lost. I've ruined everything. I'm in the quick draw thing. I want to be in the website thing. Whoops. All right. Whoops. Oh, what a mess I've made of everything. Logo. One. Two. These are fine. There we go. Ah! Oh, no. It's inheriting. Do I need to reload this thing? No. Oh. Oh. Prettier. Prettier. Default two. Tabs. False. Semicolons true. So, these are all the settings. Oh, I've gone off the deep end here. Are people really watching me do this right now? Right. Where is... Look at the chat. Hold on. Tab. Oh, GitHub is rendering a six-space tab. Okay. Hold on. Default two. VS code prettier settings. Let's see. This. Yes. Yes. Here we go. Here we go. This. This. Prettier. Oh, there's all these things here. Great. Prettier tab width. Two. Let's see. That's nice. Okay. And then, what was the other thing that I want now? Is... Oh, hold on. Prettier spaces. Use tabs. That must be... Right. False. That's the default value. This is very important, what I'm doing right now. No! Wait. Why? Why is this one... Still tabs? Why is this one tabs? What have I done? What have I done to deserve this? Insert spaces when pressing tab. Text editor. Auto indent. Yes. Auto indent. Yes. Ah. I don't ever want to use tabs. Let's try that. No. It's not even formatting it. Huh. Uh. Hold on. Why is this... Why have I lost my format on save? Format on save. True. Detect indentation. False. Um. Huh. Restart prettier. That's a good idea. Let's just restart the whole thing. Weird. Let's go to extensions. Prettier. No. Uh. I'm going to try to re-format that. Let's try this. Oh. It's not formatting on save. Now it is. I don't need this, though. Uh. Uh. I saved it as a new file, and it reformatted it. Weird. There. Fixed it. This is fine. This is fine. And this is fine. I don't know what was wrong with that one file. This is spaces. This is spaces. Um. And. Spaces, not tabs. Oh. That was scary. Oh. But my quick draw stuff. Oh. Hold on. Pull requests. Oh. I didn't actually make the pull request. Hold on. Now. Everybody just relax. I can't believe how much time. What was it called? Wait. Where is my quick draw? We go to this branch. And then here. That's spaces. Tabs. Oh. This file, too. What is it with the files? What if I manually. Why are certain files. Not formatting. That's so weird. I've never seen this. Whoops. Format. Document. Format. Format selection. Whoops. Oh. That did it. Format selection did it. I can't explain it. Where am I? Format selection did it. Right? Yeah. Okay. Oh. It's because of this file. Maybe. Yeah. Because I'm in this repo. That's probably why. It must be like picking up. Oh. It's picking up settings from here. Yeah. All right. That's got to be it. All right. I know the camera went off. All right. Let's finish these pull requests, people. Oh, wait. No. Let's do the quick draw one first. This is the quick draw code for challenge 122. If we look at this. There. Look at this. Look at this nice, normally indented code. Okay. Now, let me do this. All right. Let's do this. Let's do this. Let's do this. All right. Let's do this. This moves challenge 121 into 121 underscore one and adds 121 underscore two for the second part of the logo challenge. It shouldn't be merged without fixing the markdown file for challenge 121 part one first. So, let me do that. And what is this? Get repeat. Oh, yeah, yeah. Okay. What kind of crazy code did I write earlier today? Okay. All right. Oh, my goodness. Oh, my goodness. Oh, my goodness. Oh, my goodness. Oh, my goodness. Oh, my goodness. Oh, my goodness. Oh, my goodness. Oh, my goodness. Oh, my goodness. All right, everyone. I'm definitely done. I really want to do more, but sometimes you just have to know when to quit. I don't usually know when to quit. I would be glad to take any questions. A few questions. Thank you to new members who joined. Actually, okay. So, let me do a little housekeeping. I'm going to do a little housekeeping. I can't imagine that anybody is still watching. But if you are, I will mention that I am way behind on sending out stickers and books to patron and YouTube members. I am really... This is my goal. Everyone who joined November 1st or earlier, sorry if you joined in the last week. I'm compiling everything. I've got to get everybody everything by the holidays. If you do not have something and are wondering about the status of it, please do. I'm going to be doing a lot of housekeeping. I'm going to be doing a lot of housekeeping. I'm going to be doing a lot of housekeeping. I'm going to be doing a lot of housekeeping. I'm going to be doing a lot of housekeeping. I'm going to be doing a lot of housekeeping. If you are a YouTube member and are wondering about the status of it, please send me a message on Slack. If you are a YouTube member and you don't have a Slack invite, then make sure you find the community post which has the form to get a Slack invite. And also, you can message at math blank on Slack who is doing the stuff. If you are interested in Coding Train merchandise, I might as well plug this just for a second because it's new. Actually, I am wearing right now, this is one of these shirts. I'm wearing a shirt. I'm wearing a shirt. I'm wearing a shirt. I'm wearing a shirt. I'm wearing a shirt. I'm wearing a shirt. I'm wearing a shirt. I'm wearing a shirt right now. I am actually wearing 2 shirts. It looks like I am disrobing. Don't worry, I am not. I'm just showing you my Never Forget. It was kind of translucent. Never Forget, the This Dot shirt. You can get your own Never Forget the This Dot shirt designed by humans slash shop slash Coding Train, I believe. So, you can see these are the various shirts and things. I wanted to mention, people, it's hard to notice this, this phone case here is $35. That's crazy. But this is actually designed to probably make this a default for a zip hoodie where the Never Forget the This Dot is on this side. I just wanted to mention that. Other housekeeping things. Let's see what other questions there are. What do you think about GANs or Generative Adversarial Networks? They are very interesting to me and I would love to learn more about them and maybe do some tutorials about them. A wonderful artist who does wonderful things with GAN is Helena... Is this her name? Yes. You should check out Glagolista on Twitter who makes all sorts of amazing GAN-related projects. Yeah. I'm not going yet. Waiting to see if there's any more questions. My mic is very quiet. That doesn't surprise me because it got moved around, but hopefully it's fine now. Thank you, Awefek, for letting me know. This is the end of today's live stream. Today I'm going to be talking about the news. I'm going to be talking about the news. I'm going to be talking about the news. I'm going to be talking about the news. I'm going to be talking about the news. I'm going to be talking about calm, nutty level favorites. I love all of these. And the regulator was like... I would love to do a serial business, if that's what you want and I would love to print out your book, and, and do some bargaining. And so that's, that's the first one. But then the second one is what I do at home. I spend a two hour, an hour on the computer, sound game sound and I'm  weighs it, and then I start dialing it up. And it's really helpful for me to develop, continue to develop better strategies for debugging to demonstrate. You mean you don't like my technique of having a bug and just sitting there going like this? You're like, maybe the chat will tell me what's wrong in just a minute. Do you code, Tim asks, do you code any other languages than JavaScript? Yes. So I do a lot of programming in Java, specifically using Processing, which is a Java based platform, you can download here. I actually was thinking of doing the quick draw stuff in Processing, because of loading the big files, I didn't want to deal with setting up a server, but then I went ahead and did the node things, I thought that was interesting. Okay. So I will not just upload text, double double click, and then actually just run the program and not follow all the steps and get all the equipment fast forward and then receive it, and then start in the JS file and Chrome will stop at that break point for you. I should probably try that at some point. That's a very good suggestion, thank you. Thank you, Joop, for your kind comment. What classes do you teach and what are they about code? All right, so very quickly I will answer Aki MC's question. Thank you to I, Luis Mise, who has added two pull requests. So I teach classes at New York University, a part of Tisch School of the Arts. There's a grad program called ITP and an undergrad program called IMA. And then online I make videos for this YouTube channel and some of them are loosely grouped into things that could possibly somewhat be classes, but I haven't really cracked that nut yet of like this thing on YouTube is a course that you could take. It's really just a lot of content and hopefully inspirational and helpful, but in terms of the actual things being a course, the place where you can look, one thing is I'm really trying to do is in theory I would like to continue to work on and improve the navigation here. So there are some, so in theory I would like this website to be a place where it's easier to find the packaged courses. Right now if you're looking for that, I think if you go to YouTube Coding Train Playlists, Playlists, and if I do All Playlists, whoops, you can see, but this is a big mess of things. So I'm trying to figure this out. Some things are organized, for example, you can see here these are the beginner JavaScript tutorials, Playlists one through seven, Playlist eight, et cetera. These are some playlists associated with neural networks and machine learning. This is an old antiquated Twitter bot tutorial that probably doesn't work anymore. These are some old nature of code videos. Here's the beginner processing videos, Git and GitHub. But again, please somebody save me and help me figure out how to organize all this stuff. Okay. Why not create a storyboard for the website? Yes, actually, so Matthew, if you go to the GitHub repository for the website, if you go under Issues, there are a few different issues that are currently tracking this discussion. So this is one proposal to have the website organized as coding challenges, beginner playlists, and then other courses that are not for beginners. So that's one thing that, and then all the live stream archives. So again, this is like, Niels Webb has done, and many other contributors, but Niels Webb in particular has done a tremendous amount of work. Niels Webber is a student and web developer in Germany. And so, thank you so much to Niels Webb, and I am certainly happy for people to contribute and participate in the development of a website. I haven't figured out really like a structure to do that, but it's happening in a sort of ad hoc basis. To Shar Mitra asked, last question, do you game? All right, you're going to be sorry you asked. If you go to youtube.com, and you search for EOD Gaming, this here with 166 subscribers is my gaming channel with my kids, who I'm very conflicted about. But this video is really what I would recommend. My daughter and I played like snipper clips for an hour and 40 minutes. And it's a wonderful game, and hopefully we'll do this again this weekend sometimes, but we do live streams trying to play. I love this game so much, it's so much fun. Of course I got a copyright notice because I used the snipper clips. Oh, look at this, and like, am I on YouTube Gaming? So if I go to like gaming.youtube.com, whoa, look at this. Yeah, so someday this is going to be even bigger than the coding train, oh, I don't think so. All right everybody, goodbye, thank you so much for tuning in. I am going to now stop this live stream and go on with my life. And I hope to hear from you, see you, ah, if you're coming to ThinkerCon, let me know. I would love to see you there. I'm so excited about it. Okay, and. Is this playing at, what's fun is to put this on double speed. Come on, we can get it in that basket. Hold on, I have to. I'm sorry, I just have to wait. This took us so long. Okay, come on. Oh, am I gonna get? I'm probably gonna get deep copyright notice now in this video. Although you won't be able to, you probably can't really hear this. I can turn music off. Oh, so close. Come on, come on, come on, come on, come on. Oh, oh, up, up, go on. Ah, there you go, no. Oh, oh boy, oh come on. I'm like reliving this. It's so painful. I really have to go. Okay, goodbye everybody. You can go and watch this video on your own. If you link to, I will link to it in the chat. Or somebody can link to it in the chat for me. It is this. We had so much fun. All right, goodbye everybody. I'm gonna stop streaming now. See you next time. Won't be for a few weeks, so stay tuned. If you wanna get an alert when I schedule the next live stream, subscribe and then click that alarm bell is the thing you're supposed to do. If you want, okay.",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:04:01.822904Z",
  "started_at": "2023-09-26T21:32:17.128441Z",
  "completed_at": "2023-09-26T22:02:13.18085Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=fnoOFQK3tPQ",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 1796.052409
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/sgfk5jzbjohbjjueszhgl47vhi/cancel",
    "get": "https://api.replicate.com/v1/predictions/sgfk5jzbjohbjjueszhgl47vhi"
  }
}