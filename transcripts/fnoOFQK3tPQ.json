{
  "id": "eaumccbbl5gmrgeao3t7dnvduq",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/fnoOFQK3tPQ.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/874168 [00:00<?, ?frames/s]\n  0%|          | 2692/874168 [00:01<06:07, 2370.31frames/s]\n  1%|          | 5568/874168 [00:05<15:17, 946.28frames/s] \n  1%|          | 8532/874168 [00:10<19:18, 747.11frames/s]\n  1%|▏         | 11330/874168 [00:16<23:34, 609.96frames/s]\n  2%|▏         | 14134/874168 [00:21<25:33, 560.95frames/s]\n  2%|▏         | 16898/874168 [00:26<25:21, 563.36frames/s]\n  2%|▏         | 19822/874168 [00:29<21:30, 661.94frames/s]\n  3%|▎         | 22770/874168 [00:35<23:25, 605.68frames/s]\n  3%|▎         | 25578/874168 [00:39<22:03, 641.11frames/s]\n  3%|▎         | 28258/874168 [00:44<23:23, 602.76frames/s]\n  4%|▎         | 31258/874168 [00:46<19:52, 707.09frames/s]\n  4%|▍         | 34206/874168 [00:52<22:16, 628.48frames/s]\n  4%|▍         | 37146/874168 [00:57<22:28, 620.70frames/s]\n  5%|▍         | 40062/874168 [01:03<24:31, 566.79frames/s]\n  5%|▍         | 42982/874168 [01:09<24:50, 557.70frames/s]\n  5%|▌         | 45948/874168 [01:15<26:20, 524.15frames/s]\n  6%|▌         | 48668/874168 [01:21<27:04, 508.05frames/s]\n  6%|▌         | 51668/874168 [01:24<23:32, 582.23frames/s]\n  6%|▌         | 53440/874168 [01:26<21:30, 635.91frames/s]\n  6%|▋         | 56336/874168 [01:32<23:22, 582.93frames/s]\n  7%|▋         | 59336/874168 [01:35<20:05, 675.79frames/s]\n  7%|▋         | 62236/874168 [01:42<23:12, 583.21frames/s]\n  7%|▋         | 65236/874168 [01:45<21:09, 637.14frames/s]\n  8%|▊         | 68136/874168 [01:50<20:46, 646.81frames/s]\n  8%|▊         | 70636/874168 [01:53<19:55, 672.38frames/s]\n  8%|▊         | 73336/874168 [02:05<32:00, 417.09frames/s]\n  9%|▊         | 76236/874168 [02:11<30:01, 442.95frames/s]\n  9%|▉         | 78936/874168 [02:15<26:43, 496.01frames/s]\n  9%|▉         | 81836/874168 [02:21<26:35, 496.71frames/s]\n 10%|▉         | 84536/874168 [02:25<25:14, 521.41frames/s]\n 10%|▉         | 87236/874168 [02:30<24:33, 534.19frames/s]\n 10%|█         | 89936/874168 [02:34<23:14, 562.26frames/s]\n 11%|█         | 92836/874168 [02:41<24:59, 520.95frames/s]\n 11%|█         | 95736/874168 [02:46<25:19, 512.19frames/s]\n 11%|█▏        | 98536/874168 [02:55<29:05, 444.46frames/s]\n 12%|█▏        | 101336/874168 [03:01<28:44, 448.19frames/s]\n 12%|█▏        | 104036/874168 [03:06<27:53, 460.08frames/s]\n 12%|█▏        | 106936/874168 [03:13<28:22, 450.58frames/s]\n 13%|█▎        | 109736/874168 [03:15<22:58, 554.57frames/s]\n 13%|█▎        | 112236/874168 [03:19<21:55, 579.36frames/s]\n 13%|█▎        | 114836/874168 [03:23<20:54, 605.38frames/s]\n 13%|█▎        | 117636/874168 [03:27<20:31, 614.38frames/s]\n 14%|█▎        | 119936/874168 [03:32<21:57, 572.37frames/s]\n 14%|█▍        | 122436/874168 [03:36<21:08, 592.44frames/s]\n 14%|█▍        | 125336/874168 [03:42<21:58, 567.80frames/s]\n 15%|█▍        | 128136/874168 [03:48<23:35, 526.89frames/s]\n 15%|█▍        | 131036/874168 [03:54<23:56, 517.44frames/s]\n 15%|█▌        | 133736/874168 [04:00<25:58, 475.10frames/s]\n 16%|█▌        | 136436/874168 [04:05<24:59, 491.94frames/s]\n 16%|█▌        | 139436/874168 [04:10<23:19, 524.95frames/s]\n 16%|█▋        | 142136/874168 [04:16<23:42, 514.48frames/s]\n 17%|█▋        | 144736/874168 [04:19<21:29, 565.70frames/s]\n 17%|█▋        | 147436/874168 [04:23<19:49, 611.16frames/s]\n 17%|█▋        | 150236/874168 [04:26<18:05, 666.96frames/s]\n 17%|█▋        | 152736/874168 [04:32<20:35, 583.77frames/s]\n 18%|█▊        | 155736/874168 [04:34<16:08, 741.52frames/s]\n 18%|█▊        | 158636/874168 [04:38<16:04, 742.17frames/s]\n 18%|█▊        | 161436/874168 [04:41<14:58, 793.20frames/s]\n 19%|█▊        | 163536/874168 [04:42<13:36, 870.12frames/s]\n 19%|█▉        | 165636/874168 [04:44<12:26, 948.83frames/s]\n 19%|█▉        | 168036/874168 [04:45<10:54, 1078.71frames/s]\n 19%|█▉        | 170436/874168 [04:47<10:31, 1115.13frames/s]\n 20%|█▉        | 172236/874168 [04:49<09:51, 1187.55frames/s]\n 20%|█▉        | 174336/874168 [04:50<08:51, 1315.63frames/s]\n 20%|██        | 177036/874168 [04:52<08:52, 1308.74frames/s]\n 20%|██        | 179136/874168 [04:54<09:16, 1248.87frames/s]\n 21%|██        | 181936/874168 [04:56<09:41, 1190.11frames/s]\n 21%|██        | 183636/874168 [04:57<09:13, 1247.09frames/s]\n 21%|██        | 185236/874168 [04:59<09:35, 1196.66frames/s]\n 21%|██▏       | 187936/874168 [05:00<08:09, 1400.71frames/s]\n 22%|██▏       | 189836/874168 [05:02<09:18, 1225.66frames/s]\n 22%|██▏       | 192536/874168 [05:05<09:49, 1156.27frames/s]\n 22%|██▏       | 195436/874168 [05:08<10:19, 1096.01frames/s]\n 23%|██▎       | 198036/874168 [05:11<11:01, 1022.07frames/s]\n 23%|██▎       | 200936/874168 [05:15<12:33, 892.97frames/s] \n 23%|██▎       | 203636/874168 [05:18<12:53, 867.09frames/s]\n 24%|██▎       | 206436/874168 [05:23<15:25, 721.17frames/s]\n 24%|██▍       | 209336/874168 [05:28<16:17, 680.28frames/s]\n 24%|██▍       | 212036/874168 [05:35<19:52, 555.19frames/s]\n 25%|██▍       | 214836/874168 [05:42<21:34, 509.26frames/s]\n 25%|██▍       | 217136/874168 [05:44<19:15, 568.57frames/s]\n 25%|██▌       | 219936/874168 [05:47<16:33, 658.40frames/s]\n 25%|██▌       | 222636/874168 [05:53<17:54, 606.63frames/s]\n 26%|██▌       | 225236/874168 [05:56<17:26, 620.29frames/s]\n 26%|██▌       | 227736/874168 [06:01<17:49, 604.63frames/s]\n 26%|██▋       | 230436/874168 [06:06<18:48, 570.22frames/s]\n 27%|██▋       | 233336/874168 [06:11<18:48, 567.73frames/s]\n 27%|██▋       | 236036/874168 [06:15<16:55, 628.10frames/s]\n 27%|██▋       | 238436/874168 [06:19<17:33, 603.16frames/s]\n 28%|██▊       | 241036/874168 [06:24<18:37, 566.47frames/s]\n 28%|██▊       | 243836/874168 [06:29<18:39, 562.82frames/s]\n 28%|██▊       | 246036/874168 [06:31<15:59, 654.66frames/s]\n 28%|██▊       | 248436/874168 [06:34<14:54, 699.58frames/s]\n 29%|██▊       | 251036/874168 [06:36<12:11, 851.29frames/s]\n 29%|██▉       | 253836/874168 [06:39<12:55, 799.54frames/s]\n 29%|██▉       | 256136/874168 [06:41<11:28, 897.10frames/s]\n 30%|██▉       | 258936/874168 [06:45<11:48, 868.06frames/s]\n 30%|██▉       | 261636/874168 [06:50<14:40, 695.47frames/s]\n 30%|███       | 264236/874168 [06:55<15:36, 651.28frames/s]\n 31%|███       | 267136/874168 [07:00<16:07, 627.59frames/s]\n 31%|███       | 269636/874168 [07:05<17:02, 591.23frames/s]\n 31%|███       | 272436/874168 [07:10<17:16, 580.45frames/s]\n 31%|███▏      | 275236/874168 [07:16<18:32, 538.14frames/s]\n 32%|███▏      | 278136/874168 [07:21<18:38, 533.01frames/s]\n 32%|███▏      | 280836/874168 [07:28<20:04, 492.62frames/s]\n 32%|███▏      | 283636/874168 [07:35<21:28, 458.16frames/s]\n 33%|███▎      | 286536/874168 [07:42<22:25, 436.68frames/s]\n 33%|███▎      | 289036/874168 [07:47<21:40, 450.02frames/s]\n 33%|███▎      | 291936/874168 [07:51<18:14, 531.95frames/s]\n 34%|███▎      | 294436/874168 [07:57<19:41, 490.56frames/s]\n 34%|███▍      | 297336/874168 [08:02<18:45, 512.48frames/s]\n 34%|███▍      | 299936/874168 [08:08<19:41, 486.22frames/s]\n 35%|███▍      | 302540/874168 [08:13<19:45, 482.26frames/s]\n 35%|███▍      | 305480/874168 [08:20<20:41, 457.90frames/s]\n 35%|███▌      | 308376/874168 [08:28<21:27, 439.38frames/s]\n 36%|███▌      | 311364/874168 [08:36<22:42, 413.10frames/s]\n 36%|███▌      | 314220/874168 [08:43<22:44, 410.31frames/s]\n 36%|███▋      | 317144/874168 [08:49<21:56, 423.08frames/s]\n 37%|███▋      | 319908/874168 [08:55<20:47, 444.40frames/s]\n 37%|███▋      | 322672/874168 [09:00<19:49, 463.47frames/s]\n 37%|███▋      | 325616/874168 [09:07<19:49, 460.97frames/s]\n 38%|███▊      | 328496/874168 [09:13<19:51, 457.90frames/s]\n 38%|███▊      | 331456/874168 [09:18<18:03, 501.09frames/s]\n 38%|███▊      | 333744/874168 [09:22<17:49, 505.30frames/s]\n 38%|███▊      | 336540/874168 [09:29<19:00, 471.30frames/s]\n 39%|███▉      | 339284/874168 [09:35<18:42, 476.48frames/s]\n 39%|███▉      | 342260/874168 [09:37<15:15, 580.71frames/s]\n 39%|███▉      | 345084/874168 [09:41<13:56, 632.58frames/s]\n 40%|███▉      | 347516/874168 [09:43<12:11, 719.92frames/s]\n 40%|████      | 350516/874168 [09:46<11:15, 775.35frames/s]\n 40%|████      | 353516/874168 [09:48<09:26, 918.62frames/s]\n 41%|████      | 356500/874168 [09:51<09:17, 928.27frames/s]\n 41%|████      | 359460/874168 [09:55<09:51, 870.90frames/s]\n 41%|████▏     | 362460/874168 [10:00<10:56, 779.98frames/s]\n 41%|████▏     | 362728/874168 [10:01<11:55, 715.20frames/s]\n 42%|████▏     | 365028/874168 [10:02<09:24, 902.50frames/s]\n 42%|████▏     | 367352/874168 [10:04<08:36, 981.75frames/s]\n 42%|████▏     | 370352/874168 [10:05<06:42, 1252.38frames/s]\n 43%|████▎     | 373352/874168 [10:07<05:53, 1415.45frames/s]\n 43%|████▎     | 376352/874168 [10:08<05:11, 1596.62frames/s]\n 43%|████▎     | 379104/874168 [10:10<05:00, 1649.81frames/s]\n 44%|████▎     | 381856/874168 [10:15<07:47, 1053.37frames/s]\n 44%|████▍     | 384832/874168 [10:17<07:27, 1093.66frames/s]\n 44%|████▍     | 387832/874168 [10:22<08:58, 903.59frames/s] \n 45%|████▍     | 390764/874168 [10:26<09:23, 858.29frames/s]\n 45%|████▌     | 393764/874168 [10:31<11:17, 709.38frames/s]\n 45%|████▌     | 396604/874168 [10:36<11:49, 672.95frames/s]\n 46%|████▌     | 399270/874168 [10:42<13:41, 578.37frames/s]\n 46%|████▌     | 402106/874168 [10:48<14:29, 543.09frames/s]\n 46%|████▋     | 404994/874168 [10:54<14:48, 528.14frames/s]\n 47%|████▋     | 407914/874168 [11:02<16:16, 477.38frames/s]\n 47%|████▋     | 410898/874168 [11:07<15:40, 492.75frames/s]\n 47%|████▋     | 413798/874168 [11:13<15:53, 483.04frames/s]\n 48%|████▊     | 416686/874168 [11:19<15:14, 500.47frames/s]\n 48%|████▊     | 419486/874168 [11:25<15:45, 480.82frames/s]\n 48%|████▊     | 422430/874168 [11:31<15:32, 484.29frames/s]\n 49%|████▊     | 425390/874168 [11:37<15:25, 484.71frames/s]\n 49%|████▉     | 427862/874168 [11:43<15:31, 479.24frames/s]\n 49%|████▉     | 430770/874168 [11:49<15:46, 468.22frames/s]\n 50%|████▉     | 433750/874168 [11:54<14:28, 506.96frames/s]\n 50%|████▉     | 436750/874168 [12:01<14:58, 486.71frames/s]\n 50%|█████     | 439678/874168 [12:07<14:51, 487.49frames/s]\n 51%|█████     | 442666/874168 [12:14<15:28, 464.87frames/s]\n 51%|█████     | 445358/874168 [12:19<15:17, 467.43frames/s]\n 51%|█████▏    | 448134/874168 [12:27<16:12, 437.87frames/s]\n 52%|█████▏    | 451046/874168 [12:33<15:37, 451.16frames/s]\n 52%|█████▏    | 453860/874168 [12:38<14:56, 468.85frames/s]\n 52%|█████▏    | 456676/874168 [12:44<15:01, 463.01frames/s]\n 53%|█████▎    | 459528/874168 [12:50<14:38, 472.05frames/s]\n 53%|█████▎    | 462472/874168 [12:56<14:29, 473.35frames/s]\n 53%|█████▎    | 465460/874168 [13:02<14:06, 482.89frames/s]\n 54%|█████▎    | 468160/874168 [13:09<14:50, 456.14frames/s]\n 54%|█████▍    | 471044/874168 [13:15<14:29, 463.65frames/s]\n 54%|█████▍    | 473648/874168 [13:21<14:30, 460.13frames/s]\n 55%|█████▍    | 476456/874168 [13:26<13:52, 477.90frames/s]\n 55%|█████▍    | 479284/874168 [13:33<14:36, 450.70frames/s]\n 55%|█████▌    | 482024/874168 [13:39<14:19, 456.20frames/s]\n 55%|█████▌    | 484588/874168 [13:43<13:08, 494.16frames/s]\n 56%|█████▌    | 487440/874168 [13:49<12:48, 503.39frames/s]\n 56%|█████▌    | 490174/874168 [13:53<12:15, 522.42frames/s]\n 56%|█████▋    | 493146/874168 [13:57<10:58, 578.60frames/s]\n 57%|█████▋    | 496146/874168 [14:01<10:05, 624.47frames/s]\n 57%|█████▋    | 499018/874168 [14:07<10:38, 587.83frames/s]\n 57%|█████▋    | 501650/874168 [14:12<11:19, 548.49frames/s]\n 58%|█████▊    | 504370/874168 [14:18<11:33, 533.14frames/s]\n 58%|█████▊    | 506778/874168 [14:23<11:46, 519.92frames/s]\n 58%|█████▊    | 509490/874168 [14:29<12:16, 495.00frames/s]\n 59%|█████▊    | 512310/874168 [14:35<12:33, 480.38frames/s]\n 59%|█████▉    | 514678/874168 [14:41<12:59, 460.92frames/s]\n 59%|█████▉    | 517630/874168 [14:45<11:45, 505.72frames/s]\n 60%|█████▉    | 520406/874168 [14:53<12:50, 458.93frames/s]\n 60%|█████▉    | 523174/874168 [14:57<11:30, 508.10frames/s]\n 60%|██████    | 526018/874168 [15:02<11:20, 511.88frames/s]\n 60%|██████    | 528834/874168 [15:07<10:48, 532.85frames/s]\n 61%|██████    | 531678/874168 [15:11<09:55, 575.41frames/s]\n 61%|██████    | 534678/874168 [15:14<08:28, 667.15frames/s]\n 61%|██████▏   | 537542/874168 [15:17<07:34, 740.32frames/s]\n 62%|██████▏   | 539746/874168 [15:19<06:47, 820.23frames/s]\n 62%|██████▏   | 542586/874168 [15:24<08:05, 682.94frames/s]\n 62%|██████▏   | 545510/874168 [15:28<07:20, 746.05frames/s]\n 63%|██████▎   | 548386/874168 [15:33<08:06, 670.24frames/s]\n 63%|██████▎   | 551206/874168 [15:37<08:10, 658.16frames/s]\n 63%|██████▎   | 553898/874168 [15:41<07:35, 702.89frames/s]\n 64%|██████▎   | 556638/874168 [15:47<08:43, 606.39frames/s]\n 64%|██████▍   | 559202/874168 [15:51<08:36, 610.28frames/s]\n 64%|██████▍   | 561830/874168 [15:55<08:20, 624.57frames/s]\n 65%|██████▍   | 564666/874168 [15:58<07:50, 657.66frames/s]\n 65%|██████▍   | 566862/874168 [16:02<07:59, 641.16frames/s]\n 65%|██████▌   | 569794/874168 [16:06<07:47, 651.24frames/s]\n 66%|██████▌   | 572590/874168 [16:11<07:42, 651.72frames/s]\n 66%|██████▌   | 575366/874168 [16:15<07:53, 631.53frames/s]\n 66%|██████▌   | 577890/874168 [16:20<07:51, 628.01frames/s]\n 66%|██████▋   | 580570/874168 [16:22<07:00, 697.83frames/s]\n 67%|██████▋   | 583570/874168 [16:27<07:04, 684.73frames/s]\n 67%|██████▋   | 586570/874168 [16:29<06:03, 790.66frames/s]\n 67%|██████▋   | 589570/874168 [16:33<05:52, 806.33frames/s]\n 68%|██████▊   | 592570/874168 [16:35<04:50, 967.84frames/s]\n 68%|██████▊   | 595570/874168 [16:36<03:50, 1206.90frames/s]\n 68%|██████▊   | 598402/874168 [16:38<03:42, 1240.40frames/s]\n 69%|██████▉   | 601402/874168 [16:41<03:58, 1146.02frames/s]\n 69%|██████▉   | 604402/874168 [16:43<03:45, 1196.68frames/s]\n 69%|██████▉   | 607258/874168 [16:47<04:17, 1035.44frames/s]\n 70%|██████▉   | 610170/874168 [16:52<05:04, 867.75frames/s] \n 70%|███████   | 612730/874168 [16:56<05:44, 758.51frames/s]\n 70%|███████   | 615330/874168 [17:01<06:17, 685.25frames/s]\n 71%|███████   | 618230/874168 [17:06<06:46, 629.94frames/s]\n 71%|███████   | 621114/874168 [17:12<07:07, 592.50frames/s]\n 71%|███████▏  | 624062/874168 [17:17<06:59, 596.58frames/s]\n 72%|███████▏  | 626806/874168 [17:22<07:13, 570.71frames/s]\n 72%|███████▏  | 629610/874168 [17:26<06:52, 592.34frames/s]\n 72%|███████▏  | 632518/874168 [17:29<06:00, 669.91frames/s]\n 73%|███████▎  | 635462/874168 [17:34<06:02, 658.48frames/s]\n 73%|███████▎  | 638286/874168 [17:38<05:57, 660.43frames/s]\n 73%|███████▎  | 641286/874168 [17:43<05:52, 660.81frames/s]\n 74%|███████▎  | 643646/874168 [17:55<09:23, 409.01frames/s]\n 74%|███████▍  | 646646/874168 [17:57<07:18, 518.44frames/s]\n 74%|███████▍  | 648712/874168 [17:59<06:24, 586.48frames/s]\n 75%|███████▍  | 651376/874168 [18:02<05:25, 685.44frames/s]\n 75%|███████▍  | 653816/874168 [18:04<04:36, 795.91frames/s]\n 75%|███████▌  | 656816/874168 [18:06<03:53, 930.88frames/s]\n 75%|███████▌  | 659816/874168 [18:09<03:43, 958.00frames/s]\n 76%|███████▌  | 662816/874168 [18:12<03:39, 964.71frames/s]\n 76%|███████▌  | 665816/874168 [18:14<03:07, 1110.67frames/s]\n 76%|███████▋  | 668452/874168 [18:17<03:33, 965.75frames/s] \n 77%|███████▋  | 671452/874168 [18:21<03:42, 910.29frames/s]\n 77%|███████▋  | 674008/874168 [18:24<03:49, 870.69frames/s]\n 77%|███████▋  | 676872/874168 [18:27<03:33, 924.02frames/s]\n 78%|███████▊  | 678934/874168 [18:31<04:13, 768.91frames/s]\n 78%|███████▊  | 681934/874168 [18:33<03:24, 939.13frames/s]\n 78%|███████▊  | 684934/874168 [18:35<03:02, 1037.86frames/s]\n 79%|███████▊  | 687934/874168 [18:38<03:00, 1029.39frames/s]\n 79%|███████▉  | 690626/874168 [18:44<04:16, 716.51frames/s] \n 79%|███████▉  | 693626/874168 [18:48<03:59, 753.29frames/s]\n 80%|███████▉  | 696326/874168 [18:50<03:32, 837.64frames/s]\n 80%|███████▉  | 698946/874168 [18:53<03:25, 850.88frames/s]\n 80%|████████  | 701370/874168 [18:56<03:26, 836.70frames/s]\n 81%|████████  | 703834/874168 [18:58<02:57, 958.36frames/s]\n 81%|████████  | 704766/874168 [18:59<03:09, 892.93frames/s]\n 81%|████████  | 707766/874168 [19:01<02:29, 1114.84frames/s]\n 81%|████████▏ | 710766/874168 [19:03<02:14, 1210.60frames/s]\n 82%|████████▏ | 713766/874168 [19:06<02:11, 1217.19frames/s]\n 82%|████████▏ | 716590/874168 [19:08<02:10, 1205.48frames/s]\n 82%|████████▏ | 718386/874168 [19:11<02:31, 1030.85frames/s]\n 82%|████████▏ | 721118/874168 [19:13<02:31, 1007.88frames/s]\n 83%|████████▎ | 724118/874168 [19:18<02:46, 898.70frames/s] \n 83%|████████▎ | 726946/874168 [19:20<02:28, 989.40frames/s]\n 84%|████████▎ | 729946/874168 [19:23<02:34, 930.85frames/s]\n 84%|████████▎ | 732038/874168 [19:25<02:22, 995.95frames/s]\n 84%|████████▍ | 734942/874168 [19:28<02:21, 982.97frames/s]\n 84%|████████▍ | 737942/874168 [19:32<02:25, 935.22frames/s]\n 85%|████████▍ | 740942/874168 [19:33<01:54, 1160.22frames/s]\n 85%|████████▌ | 743918/874168 [19:35<01:49, 1184.94frames/s]\n 85%|████████▌ | 746362/874168 [19:39<02:05, 1018.34frames/s]\n 86%|████████▌ | 749352/874168 [19:42<02:05, 994.78frames/s] \n 86%|████████▌ | 752352/874168 [19:45<02:09, 940.76frames/s]\n 86%|████████▋ | 755148/874168 [19:48<01:59, 992.46frames/s]\n 87%|████████▋ | 757936/874168 [19:50<01:53, 1022.53frames/s]\n 87%|████████▋ | 760936/874168 [19:53<01:44, 1083.41frames/s]\n 87%|████████▋ | 763908/874168 [19:55<01:39, 1108.31frames/s]\n 88%|████████▊ | 766860/874168 [19:57<01:30, 1179.44frames/s]\n 88%|████████▊ | 769860/874168 [19:59<01:17, 1353.07frames/s]\n 88%|████████▊ | 772860/874168 [20:01<01:13, 1380.81frames/s]\n 89%|████████▉ | 775860/874168 [20:03<01:06, 1469.00frames/s]\n 89%|████████▉ | 778860/874168 [20:05<01:10, 1349.40frames/s]\n 89%|████████▉ | 781524/874168 [20:10<01:38, 941.46frames/s] \n 90%|████████▉ | 783940/874168 [20:14<01:44, 859.74frames/s]\n 90%|████████▉ | 783940/874168 [20:28<01:44, 859.74frames/s]\n 90%|█████████ | 786840/874168 [20:36<04:37, 314.43frames/s]\n 90%|█████████ | 789768/874168 [20:40<03:39, 384.78frames/s]\n 91%|█████████ | 792768/874168 [20:42<02:45, 491.89frames/s]\n 91%|█████████ | 795628/874168 [20:46<02:24, 542.69frames/s]\n 91%|█████████▏| 797764/874168 [20:48<02:06, 601.83frames/s]\n 92%|█████████▏| 800764/874168 [20:51<01:44, 704.35frames/s]\n 92%|█████████▏| 803428/874168 [20:55<01:42, 691.96frames/s]\n 92%|█████████▏| 806332/874168 [21:00<01:42, 663.40frames/s]\n 93%|█████████▎| 809268/874168 [21:07<01:53, 569.44frames/s]\n 93%|█████████▎| 811928/874168 [21:12<01:53, 546.77frames/s]\n 93%|█████████▎| 814624/874168 [21:18<01:56, 509.34frames/s]\n 94%|█████████▎| 817624/874168 [21:23<01:41, 556.07frames/s]\n 94%|█████████▍| 820524/874168 [21:31<01:52, 476.81frames/s]\n 94%|█████████▍| 823512/874168 [21:36<01:41, 498.47frames/s]\n 95%|█████████▍| 826304/874168 [21:41<01:34, 508.24frames/s]\n 95%|█████████▍| 829152/874168 [21:46<01:25, 528.41frames/s]\n 95%|█████████▌| 832152/874168 [21:50<01:12, 579.50frames/s]\n 95%|█████████▌| 832152/874168 [22:08<01:12, 579.50frames/s]\n 96%|█████████▌| 835072/874168 [22:31<03:31, 184.49frames/s]\n 96%|█████████▌| 837906/874168 [22:36<02:37, 230.94frames/s]\n 96%|█████████▌| 840698/874168 [22:42<02:02, 273.72frames/s]\n 97%|█████████▋| 843590/874168 [22:45<01:29, 340.44frames/s]\n 97%|█████████▋| 846570/874168 [22:51<01:11, 387.91frames/s]\n 97%|█████████▋| 849426/874168 [22:54<00:54, 454.42frames/s]\n 97%|█████████▋| 852294/874168 [22:59<00:43, 501.35frames/s]\n 98%|█████████▊| 854790/874168 [23:03<00:38, 507.32frames/s]\n 98%|█████████▊| 857730/874168 [23:08<00:30, 544.77frames/s]\n 98%|█████████▊| 860690/874168 [23:13<00:24, 555.91frames/s]\n 99%|█████████▉| 863370/874168 [23:18<00:20, 538.95frames/s]\n 99%|█████████▉| 866154/874168 [23:22<00:13, 585.04frames/s]\n 99%|█████████▉| 868930/874168 [23:27<00:09, 571.32frames/s]\n100%|█████████▉| 871850/874168 [23:33<00:04, 546.82frames/s]\n100%|██████████| 874168/874168 [23:39<00:00, 511.09frames/s]\n100%|██████████| 874168/874168 [23:39<00:00, 616.03frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.5521868655556127,
        "compression_ratio": 0.9333333333333333,
        "end": 21.88,
        "id": 0,
        "no_speech_prob": 0.009244673885405064,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " Good afternoon.",
        "tokens": [
          50364,
          2205,
          6499,
          13,
          51458
        ]
      },
      {
        "avg_logprob": -0.5521868655556127,
        "compression_ratio": 0.9333333333333333,
        "end": 26.92,
        "id": 1,
        "no_speech_prob": 0.009244673885405064,
        "seek": 0,
        "start": 21.88,
        "temperature": 0,
        "text": " It is me again here on the coding train.",
        "tokens": [
          51458,
          467,
          307,
          385,
          797,
          510,
          322,
          264,
          17720,
          3847,
          13,
          51710
        ]
      },
      {
        "avg_logprob": -0.3696794208727385,
        "compression_ratio": 1.5391705069124424,
        "end": 29.240000000000002,
        "id": 2,
        "no_speech_prob": 0.0006563516217283905,
        "seek": 2692,
        "start": 26.92,
        "temperature": 0,
        "text": " My name is Dan.",
        "tokens": [
          50364,
          1222,
          1315,
          307,
          3394,
          13,
          50480
        ]
      },
      {
        "avg_logprob": -0.3696794208727385,
        "compression_ratio": 1.5391705069124424,
        "end": 33.160000000000004,
        "id": 3,
        "no_speech_prob": 0.0006563516217283905,
        "seek": 2692,
        "start": 29.240000000000002,
        "temperature": 0,
        "text": " NASA KOP in the chat asks, does it start now?",
        "tokens": [
          50480,
          12077,
          591,
          12059,
          294,
          264,
          5081,
          8962,
          11,
          775,
          309,
          722,
          586,
          30,
          50676
        ]
      },
      {
        "avg_logprob": -0.3696794208727385,
        "compression_ratio": 1.5391705069124424,
        "end": 35.760000000000005,
        "id": 4,
        "no_speech_prob": 0.0006563516217283905,
        "seek": 2692,
        "start": 33.160000000000004,
        "temperature": 0,
        "text": " In fact, it starts now.",
        "tokens": [
          50676,
          682,
          1186,
          11,
          309,
          3719,
          586,
          13,
          50806
        ]
      },
      {
        "avg_logprob": -0.3696794208727385,
        "compression_ratio": 1.5391705069124424,
        "end": 39.64,
        "id": 5,
        "no_speech_prob": 0.0006563516217283905,
        "seek": 2692,
        "start": 35.760000000000005,
        "temperature": 0,
        "text": " Or maybe officially it starts now.",
        "tokens": [
          50806,
          1610,
          1310,
          12053,
          309,
          3719,
          586,
          13,
          51000
        ]
      },
      {
        "avg_logprob": -0.3696794208727385,
        "compression_ratio": 1.5391705069124424,
        "end": 42.760000000000005,
        "id": 6,
        "no_speech_prob": 0.0006563516217283905,
        "seek": 2692,
        "start": 39.64,
        "temperature": 0,
        "text": " Welcome to the coding train afternoon edition.",
        "tokens": [
          51000,
          4027,
          281,
          264,
          17720,
          3847,
          6499,
          11377,
          13,
          51156
        ]
      },
      {
        "avg_logprob": -0.3696794208727385,
        "compression_ratio": 1.5391705069124424,
        "end": 45.68000000000001,
        "id": 7,
        "no_speech_prob": 0.0006563516217283905,
        "seek": 2692,
        "start": 42.760000000000005,
        "temperature": 0,
        "text": " There was a full 2 and 1 1-hour morning edition",
        "tokens": [
          51156,
          821,
          390,
          257,
          1577,
          568,
          293,
          502,
          502,
          12,
          18048,
          2446,
          11377,
          51302
        ]
      },
      {
        "avg_logprob": -0.3696794208727385,
        "compression_ratio": 1.5391705069124424,
        "end": 49.160000000000004,
        "id": 8,
        "no_speech_prob": 0.0006563516217283905,
        "seek": 2692,
        "start": 45.68000000000001,
        "temperature": 0,
        "text": " of the coding train today where I completed.",
        "tokens": [
          51302,
          295,
          264,
          17720,
          3847,
          965,
          689,
          286,
          7365,
          13,
          51476
        ]
      },
      {
        "avg_logprob": -0.3696794208727385,
        "compression_ratio": 1.5391705069124424,
        "end": 54.52,
        "id": 9,
        "no_speech_prob": 0.0006563516217283905,
        "seek": 2692,
        "start": 52.120000000000005,
        "temperature": 0,
        "text": " Completed is perhaps not the most accurate way",
        "tokens": [
          51624,
          33736,
          10993,
          307,
          4317,
          406,
          264,
          881,
          8559,
          636,
          51744
        ]
      },
      {
        "avg_logprob": -0.3696794208727385,
        "compression_ratio": 1.5391705069124424,
        "end": 55.68000000000001,
        "id": 10,
        "no_speech_prob": 0.0006563516217283905,
        "seek": 2692,
        "start": 54.52,
        "temperature": 0,
        "text": " to describe what happened.",
        "tokens": [
          51744,
          281,
          6786,
          437,
          2011,
          13,
          51802
        ]
      },
      {
        "avg_logprob": -0.24922505131474249,
        "compression_ratio": 1.5782608695652174,
        "end": 61.84,
        "id": 11,
        "no_speech_prob": 0.00005561576472246088,
        "seek": 5568,
        "start": 55.68,
        "temperature": 0,
        "text": " But I did attempt to continue to work on the logo coding",
        "tokens": [
          50364,
          583,
          286,
          630,
          5217,
          281,
          2354,
          281,
          589,
          322,
          264,
          9699,
          17720,
          50672
        ]
      },
      {
        "avg_logprob": -0.24922505131474249,
        "compression_ratio": 1.5782608695652174,
        "end": 62.34,
        "id": 12,
        "no_speech_prob": 0.00005561576472246088,
        "seek": 5568,
        "start": 61.84,
        "temperature": 0,
        "text": " challenge.",
        "tokens": [
          50672,
          3430,
          13,
          50697
        ]
      },
      {
        "avg_logprob": -0.24922505131474249,
        "compression_ratio": 1.5782608695652174,
        "end": 63.16,
        "id": 13,
        "no_speech_prob": 0.00005561576472246088,
        "seek": 5568,
        "start": 62.34,
        "temperature": 0,
        "text": " But that's all.",
        "tokens": [
          50697,
          583,
          300,
          311,
          439,
          13,
          50738
        ]
      },
      {
        "avg_logprob": -0.24922505131474249,
        "compression_ratio": 1.5782608695652174,
        "end": 65.44,
        "id": 14,
        "no_speech_prob": 0.00005561576472246088,
        "seek": 5568,
        "start": 63.16,
        "temperature": 0,
        "text": " I'm done with that.",
        "tokens": [
          50738,
          286,
          478,
          1096,
          365,
          300,
          13,
          50852
        ]
      },
      {
        "avg_logprob": -0.24922505131474249,
        "compression_ratio": 1.5782608695652174,
        "end": 67.16,
        "id": 15,
        "no_speech_prob": 0.00005561576472246088,
        "seek": 5568,
        "start": 65.44,
        "temperature": 0,
        "text": " Won't be returning to that anytime soon.",
        "tokens": [
          50852,
          14710,
          380,
          312,
          12678,
          281,
          300,
          13038,
          2321,
          13,
          50938
        ]
      },
      {
        "avg_logprob": -0.24922505131474249,
        "compression_ratio": 1.5782608695652174,
        "end": 70.24,
        "id": 16,
        "no_speech_prob": 0.00005561576472246088,
        "seek": 5568,
        "start": 67.16,
        "temperature": 0,
        "text": " Just in case you weren't here this morning, I will show you.",
        "tokens": [
          50938,
          1449,
          294,
          1389,
          291,
          4999,
          380,
          510,
          341,
          2446,
          11,
          286,
          486,
          855,
          291,
          13,
          51092
        ]
      },
      {
        "avg_logprob": -0.24922505131474249,
        "compression_ratio": 1.5782608695652174,
        "end": 73.68,
        "id": 17,
        "no_speech_prob": 0.00005561576472246088,
        "seek": 5568,
        "start": 70.24,
        "temperature": 0,
        "text": " I will pull this up very briefly.",
        "tokens": [
          51092,
          286,
          486,
          2235,
          341,
          493,
          588,
          10515,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.24922505131474249,
        "compression_ratio": 1.5782608695652174,
        "end": 78.32,
        "id": 18,
        "no_speech_prob": 0.00005561576472246088,
        "seek": 5568,
        "start": 73.68,
        "temperature": 0,
        "text": " If I go to a logo, coding train slash logo,",
        "tokens": [
          51264,
          759,
          286,
          352,
          281,
          257,
          9699,
          11,
          17720,
          3847,
          17330,
          9699,
          11,
          51496
        ]
      },
      {
        "avg_logprob": -0.24922505131474249,
        "compression_ratio": 1.5782608695652174,
        "end": 81.52,
        "id": 19,
        "no_speech_prob": 0.00005561576472246088,
        "seek": 5568,
        "start": 78.32,
        "temperature": 0,
        "text": " this is the GitHub repo.",
        "tokens": [
          51496,
          341,
          307,
          264,
          23331,
          49040,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.24922505131474249,
        "compression_ratio": 1.5782608695652174,
        "end": 85.32,
        "id": 20,
        "no_speech_prob": 0.00005561576472246088,
        "seek": 5568,
        "start": 81.52,
        "temperature": 0,
        "text": " There are some issues here that I would love help with",
        "tokens": [
          51656,
          821,
          366,
          512,
          2663,
          510,
          300,
          286,
          576,
          959,
          854,
          365,
          51846
        ]
      },
      {
        "avg_logprob": -0.29961483514131004,
        "compression_ratio": 1.6911764705882353,
        "end": 86.75999999999999,
        "id": 21,
        "no_speech_prob": 0.00014200365694705397,
        "seek": 8532,
        "start": 85.32,
        "temperature": 0,
        "text": " and thoughts on.",
        "tokens": [
          50364,
          293,
          4598,
          322,
          13,
          50436
        ]
      },
      {
        "avg_logprob": -0.29961483514131004,
        "compression_ratio": 1.6911764705882353,
        "end": 89.39999999999999,
        "id": 22,
        "no_speech_prob": 0.00014200365694705397,
        "seek": 8532,
        "start": 86.75999999999999,
        "temperature": 0,
        "text": " There are a couple of design pull requests.",
        "tokens": [
          50436,
          821,
          366,
          257,
          1916,
          295,
          1715,
          2235,
          12475,
          13,
          50568
        ]
      },
      {
        "avg_logprob": -0.29961483514131004,
        "compression_ratio": 1.6911764705882353,
        "end": 91.75999999999999,
        "id": 23,
        "no_speech_prob": 0.00014200365694705397,
        "seek": 8532,
        "start": 89.39999999999999,
        "temperature": 0,
        "text": " But I merged a couple of things without checking them.",
        "tokens": [
          50568,
          583,
          286,
          36427,
          257,
          1916,
          295,
          721,
          1553,
          8568,
          552,
          13,
          50686
        ]
      },
      {
        "avg_logprob": -0.29961483514131004,
        "compression_ratio": 1.6911764705882353,
        "end": 93.27999999999999,
        "id": 24,
        "no_speech_prob": 0.00014200365694705397,
        "seek": 8532,
        "start": 91.75999999999999,
        "temperature": 0,
        "text": " So let's actually see.",
        "tokens": [
          50686,
          407,
          718,
          311,
          767,
          536,
          13,
          50762
        ]
      },
      {
        "avg_logprob": -0.29961483514131004,
        "compression_ratio": 1.6911764705882353,
        "end": 96.44,
        "id": 25,
        "no_speech_prob": 0.00014200365694705397,
        "seek": 8532,
        "start": 93.27999999999999,
        "temperature": 0,
        "text": " Coding train dot GitHub slash.",
        "tokens": [
          50762,
          383,
          8616,
          3847,
          5893,
          23331,
          17330,
          13,
          50920
        ]
      },
      {
        "avg_logprob": -0.29961483514131004,
        "compression_ratio": 1.6911764705882353,
        "end": 98.67999999999999,
        "id": 26,
        "no_speech_prob": 0.00014200365694705397,
        "seek": 8532,
        "start": 96.44,
        "temperature": 0,
        "text": " This should be the demo.",
        "tokens": [
          50920,
          639,
          820,
          312,
          264,
          10723,
          13,
          51032
        ]
      },
      {
        "avg_logprob": -0.29961483514131004,
        "compression_ratio": 1.6911764705882353,
        "end": 100.52,
        "id": 27,
        "no_speech_prob": 0.00014200365694705397,
        "seek": 8532,
        "start": 98.67999999999999,
        "temperature": 0,
        "text": " And it still works.",
        "tokens": [
          51032,
          400,
          309,
          920,
          1985,
          13,
          51124
        ]
      },
      {
        "avg_logprob": -0.29961483514131004,
        "compression_ratio": 1.6911764705882353,
        "end": 101.17999999999999,
        "id": 28,
        "no_speech_prob": 0.00014200365694705397,
        "seek": 8532,
        "start": 100.52,
        "temperature": 0,
        "text": " So there you go.",
        "tokens": [
          51124,
          407,
          456,
          291,
          352,
          13,
          51157
        ]
      },
      {
        "avg_logprob": -0.29961483514131004,
        "compression_ratio": 1.6911764705882353,
        "end": 102.28,
        "id": 29,
        "no_speech_prob": 0.00014200365694705397,
        "seek": 8532,
        "start": 101.17999999999999,
        "temperature": 0,
        "text": " So this is what it does.",
        "tokens": [
          51157,
          407,
          341,
          307,
          437,
          309,
          775,
          13,
          51212
        ]
      },
      {
        "avg_logprob": -0.29961483514131004,
        "compression_ratio": 1.6911764705882353,
        "end": 105.67999999999999,
        "id": 30,
        "no_speech_prob": 0.00014200365694705397,
        "seek": 8532,
        "start": 102.28,
        "temperature": 0,
        "text": " It is a logo interpreter where you can type logo commands.",
        "tokens": [
          51212,
          467,
          307,
          257,
          9699,
          34132,
          689,
          291,
          393,
          2010,
          9699,
          16901,
          13,
          51382
        ]
      },
      {
        "avg_logprob": -0.29961483514131004,
        "compression_ratio": 1.6911764705882353,
        "end": 106.88,
        "id": 31,
        "no_speech_prob": 0.00014200365694705397,
        "seek": 8532,
        "start": 105.67999999999999,
        "temperature": 0,
        "text": " And it will draw them for you.",
        "tokens": [
          51382,
          400,
          309,
          486,
          2642,
          552,
          337,
          291,
          13,
          51442
        ]
      },
      {
        "avg_logprob": -0.29961483514131004,
        "compression_ratio": 1.6911764705882353,
        "end": 110.6,
        "id": 32,
        "no_speech_prob": 0.00014200365694705397,
        "seek": 8532,
        "start": 106.88,
        "temperature": 0,
        "text": " And apparently now, it supports some new commands",
        "tokens": [
          51442,
          400,
          7970,
          586,
          11,
          309,
          9346,
          512,
          777,
          16901,
          51628
        ]
      },
      {
        "avg_logprob": -0.29961483514131004,
        "compression_ratio": 1.6911764705882353,
        "end": 112.8,
        "id": 33,
        "no_speech_prob": 0.00014200365694705397,
        "seek": 8532,
        "start": 110.6,
        "temperature": 0,
        "text": " that it didn't as of this morning based on a few pull",
        "tokens": [
          51628,
          300,
          309,
          994,
          380,
          382,
          295,
          341,
          2446,
          2361,
          322,
          257,
          1326,
          2235,
          51738
        ]
      },
      {
        "avg_logprob": -0.29961483514131004,
        "compression_ratio": 1.6911764705882353,
        "end": 113.3,
        "id": 34,
        "no_speech_prob": 0.00014200365694705397,
        "seek": 8532,
        "start": 112.8,
        "temperature": 0,
        "text": " requests.",
        "tokens": [
          51738,
          12475,
          13,
          51763
        ]
      },
      {
        "avg_logprob": -0.25633065795898435,
        "compression_ratio": 1.6747967479674797,
        "end": 114.86,
        "id": 35,
        "no_speech_prob": 0.0035380059853196144,
        "seek": 11330,
        "start": 113.3,
        "temperature": 0,
        "text": " I don't want to rehash that too much.",
        "tokens": [
          50364,
          286,
          500,
          380,
          528,
          281,
          22355,
          1299,
          300,
          886,
          709,
          13,
          50442
        ]
      },
      {
        "avg_logprob": -0.25633065795898435,
        "compression_ratio": 1.6747967479674797,
        "end": 120.53999999999999,
        "id": 36,
        "no_speech_prob": 0.0035380059853196144,
        "seek": 11330,
        "start": 117.34,
        "temperature": 0,
        "text": " What I want to do, I'm going to do something.",
        "tokens": [
          50566,
          708,
          286,
          528,
          281,
          360,
          11,
          286,
          478,
          516,
          281,
          360,
          746,
          13,
          50726
        ]
      },
      {
        "avg_logprob": -0.25633065795898435,
        "compression_ratio": 1.6747967479674797,
        "end": 122.5,
        "id": 37,
        "no_speech_prob": 0.0035380059853196144,
        "seek": 11330,
        "start": 120.53999999999999,
        "temperature": 0,
        "text": " Oh, this is going to be good.",
        "tokens": [
          50726,
          876,
          11,
          341,
          307,
          516,
          281,
          312,
          665,
          13,
          50824
        ]
      },
      {
        "avg_logprob": -0.25633065795898435,
        "compression_ratio": 1.6747967479674797,
        "end": 125.82,
        "id": 38,
        "no_speech_prob": 0.0035380059853196144,
        "seek": 11330,
        "start": 122.5,
        "temperature": 0,
        "text": " I'm just going to get right into things, right into things.",
        "tokens": [
          50824,
          286,
          478,
          445,
          516,
          281,
          483,
          558,
          666,
          721,
          11,
          558,
          666,
          721,
          13,
          50990
        ]
      },
      {
        "avg_logprob": -0.25633065795898435,
        "compression_ratio": 1.6747967479674797,
        "end": 129.7,
        "id": 39,
        "no_speech_prob": 0.0035380059853196144,
        "seek": 11330,
        "start": 125.82,
        "temperature": 0,
        "text": " I am going to continue today, The Beginner's Guide",
        "tokens": [
          50990,
          286,
          669,
          516,
          281,
          2354,
          965,
          11,
          440,
          20660,
          1193,
          311,
          18727,
          51184
        ]
      },
      {
        "avg_logprob": -0.25633065795898435,
        "compression_ratio": 1.6747967479674797,
        "end": 132.26,
        "id": 40,
        "no_speech_prob": 0.0035380059853196144,
        "seek": 11330,
        "start": 129.7,
        "temperature": 0,
        "text": " to Machine Learning with ML5.js.",
        "tokens": [
          51184,
          281,
          22155,
          15205,
          365,
          21601,
          20,
          13,
          25530,
          13,
          51312
        ]
      },
      {
        "avg_logprob": -0.25633065795898435,
        "compression_ratio": 1.6747967479674797,
        "end": 134.18,
        "id": 41,
        "no_speech_prob": 0.0035380059853196144,
        "seek": 11330,
        "start": 132.26,
        "temperature": 0,
        "text": " In particular, I am going to make",
        "tokens": [
          51312,
          682,
          1729,
          11,
          286,
          669,
          516,
          281,
          652,
          51408
        ]
      },
      {
        "avg_logprob": -0.25633065795898435,
        "compression_ratio": 1.6747967479674797,
        "end": 136.85999999999999,
        "id": 42,
        "no_speech_prob": 0.0035380059853196144,
        "seek": 11330,
        "start": 134.18,
        "temperature": 0,
        "text": " a new video, which will appear as number seven",
        "tokens": [
          51408,
          257,
          777,
          960,
          11,
          597,
          486,
          4204,
          382,
          1230,
          3407,
          51542
        ]
      },
      {
        "avg_logprob": -0.25633065795898435,
        "compression_ratio": 1.6747967479674797,
        "end": 138.06,
        "id": 43,
        "no_speech_prob": 0.0035380059853196144,
        "seek": 11330,
        "start": 136.85999999999999,
        "temperature": 0,
        "text": " in this playlist.",
        "tokens": [
          51542,
          294,
          341,
          16788,
          13,
          51602
        ]
      },
      {
        "avg_logprob": -0.25633065795898435,
        "compression_ratio": 1.6747967479674797,
        "end": 141.34,
        "id": 44,
        "no_speech_prob": 0.0035380059853196144,
        "seek": 11330,
        "start": 138.06,
        "temperature": 0,
        "text": " In a moment, I'm probably going to repeat myself again.",
        "tokens": [
          51602,
          682,
          257,
          1623,
          11,
          286,
          478,
          1391,
          516,
          281,
          7149,
          2059,
          797,
          13,
          51766
        ]
      },
      {
        "avg_logprob": -0.19798044888478405,
        "compression_ratio": 1.65625,
        "end": 143.5,
        "id": 45,
        "no_speech_prob": 0.0000037266104300215375,
        "seek": 14134,
        "start": 141.34,
        "temperature": 0,
        "text": " And what I'm going to do is I'm going",
        "tokens": [
          50364,
          400,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          50472
        ]
      },
      {
        "avg_logprob": -0.19798044888478405,
        "compression_ratio": 1.65625,
        "end": 147.54,
        "id": 46,
        "no_speech_prob": 0.0000037266104300215375,
        "seek": 14134,
        "start": 143.5,
        "temperature": 0,
        "text": " to take this previous example that I made.",
        "tokens": [
          50472,
          281,
          747,
          341,
          3894,
          1365,
          300,
          286,
          1027,
          13,
          50674
        ]
      },
      {
        "avg_logprob": -0.19798044888478405,
        "compression_ratio": 1.65625,
        "end": 152.22,
        "id": 47,
        "no_speech_prob": 0.0000037266104300215375,
        "seek": 14134,
        "start": 147.54,
        "temperature": 0,
        "text": " And I am going to save, which trains a model.",
        "tokens": [
          50674,
          400,
          286,
          669,
          516,
          281,
          3155,
          11,
          597,
          16329,
          257,
          2316,
          13,
          50908
        ]
      },
      {
        "avg_logprob": -0.19798044888478405,
        "compression_ratio": 1.65625,
        "end": 156.38,
        "id": 48,
        "no_speech_prob": 0.0000037266104300215375,
        "seek": 14134,
        "start": 152.22,
        "temperature": 0,
        "text": " I'm going to save that model and then reload it back",
        "tokens": [
          50908,
          286,
          478,
          516,
          281,
          3155,
          300,
          2316,
          293,
          550,
          25628,
          309,
          646,
          51116
        ]
      },
      {
        "avg_logprob": -0.19798044888478405,
        "compression_ratio": 1.65625,
        "end": 159.98000000000002,
        "id": 49,
        "no_speech_prob": 0.0000037266104300215375,
        "seek": 14134,
        "start": 156.38,
        "temperature": 0,
        "text": " into the sketch so that I don't have to constantly retrain",
        "tokens": [
          51116,
          666,
          264,
          12325,
          370,
          300,
          286,
          500,
          380,
          362,
          281,
          6460,
          1533,
          7146,
          51296
        ]
      },
      {
        "avg_logprob": -0.19798044888478405,
        "compression_ratio": 1.65625,
        "end": 162.26,
        "id": 50,
        "no_speech_prob": 0.0000037266104300215375,
        "seek": 14134,
        "start": 159.98000000000002,
        "temperature": 0,
        "text": " every time I refresh the page, et cetera.",
        "tokens": [
          51296,
          633,
          565,
          286,
          15134,
          264,
          3028,
          11,
          1030,
          11458,
          13,
          51410
        ]
      },
      {
        "avg_logprob": -0.19798044888478405,
        "compression_ratio": 1.65625,
        "end": 165.62,
        "id": 51,
        "no_speech_prob": 0.0000037266104300215375,
        "seek": 14134,
        "start": 162.26,
        "temperature": 0,
        "text": " So this has been a long overdue feature,",
        "tokens": [
          51410,
          407,
          341,
          575,
          668,
          257,
          938,
          19853,
          622,
          4111,
          11,
          51578
        ]
      },
      {
        "avg_logprob": -0.19798044888478405,
        "compression_ratio": 1.65625,
        "end": 168.98000000000002,
        "id": 52,
        "no_speech_prob": 0.0000037266104300215375,
        "seek": 14134,
        "start": 165.62,
        "temperature": 0,
        "text": " or a widely requested feature in the ML5 library.",
        "tokens": [
          51578,
          420,
          257,
          13371,
          16436,
          4111,
          294,
          264,
          21601,
          20,
          6405,
          13,
          51746
        ]
      },
      {
        "avg_logprob": -0.3254291346815766,
        "compression_ratio": 1.3471074380165289,
        "end": 171.85999999999999,
        "id": 53,
        "no_speech_prob": 0.0009849787456914783,
        "seek": 16898,
        "start": 168.98,
        "temperature": 0,
        "text": " Let's go to GitHub.",
        "tokens": [
          50364,
          961,
          311,
          352,
          281,
          23331,
          13,
          50508
        ]
      },
      {
        "avg_logprob": -0.3254291346815766,
        "compression_ratio": 1.3471074380165289,
        "end": 173.01999999999998,
        "id": 54,
        "no_speech_prob": 0.0009849787456914783,
        "seek": 16898,
        "start": 171.85999999999999,
        "temperature": 0,
        "text": " Let's go to Issues.",
        "tokens": [
          50508,
          961,
          311,
          352,
          281,
          38195,
          1247,
          13,
          50566
        ]
      },
      {
        "avg_logprob": -0.3254291346815766,
        "compression_ratio": 1.3471074380165289,
        "end": 173.94,
        "id": 55,
        "no_speech_prob": 0.0009849787456914783,
        "seek": 16898,
        "start": 173.01999999999998,
        "temperature": 0,
        "text": " It might be closed.",
        "tokens": [
          50566,
          467,
          1062,
          312,
          5395,
          13,
          50612
        ]
      },
      {
        "avg_logprob": -0.3254291346815766,
        "compression_ratio": 1.3471074380165289,
        "end": 186.66,
        "id": 56,
        "no_speech_prob": 0.0009849787456914783,
        "seek": 16898,
        "start": 181.66,
        "temperature": 0,
        "text": " Let's look at, where did this get added?",
        "tokens": [
          50998,
          961,
          311,
          574,
          412,
          11,
          689,
          630,
          341,
          483,
          3869,
          30,
          51248
        ]
      },
      {
        "avg_logprob": -0.3254291346815766,
        "compression_ratio": 1.3471074380165289,
        "end": 187.26,
        "id": 57,
        "no_speech_prob": 0.0009849787456914783,
        "seek": 16898,
        "start": 186.66,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51248,
          821,
          321,
          352,
          13,
          51278
        ]
      },
      {
        "avg_logprob": -0.3254291346815766,
        "compression_ratio": 1.3471074380165289,
        "end": 197.14,
        "id": 58,
        "no_speech_prob": 0.0009849787456914783,
        "seek": 16898,
        "start": 189.94,
        "temperature": 0,
        "text": " So this is the support.",
        "tokens": [
          51412,
          407,
          341,
          307,
          264,
          1406,
          13,
          51772
        ]
      },
      {
        "avg_logprob": -0.3254291346815766,
        "compression_ratio": 1.3471074380165289,
        "end": 198.22,
        "id": 59,
        "no_speech_prob": 0.0009849787456914783,
        "seek": 16898,
        "start": 197.14,
        "temperature": 0,
        "text": " This is the pull request.",
        "tokens": [
          51772,
          639,
          307,
          264,
          2235,
          5308,
          13,
          51826
        ]
      },
      {
        "avg_logprob": -0.32317161560058594,
        "compression_ratio": 1.5806451612903225,
        "end": 200.74,
        "id": 60,
        "no_speech_prob": 0.00004400067336973734,
        "seek": 19822,
        "start": 199.22,
        "temperature": 0,
        "text": " So I'm going to leave this open.",
        "tokens": [
          50414,
          407,
          286,
          478,
          516,
          281,
          1856,
          341,
          1269,
          13,
          50490
        ]
      },
      {
        "avg_logprob": -0.32317161560058594,
        "compression_ratio": 1.5806451612903225,
        "end": 207.26,
        "id": 61,
        "no_speech_prob": 0.00004400067336973734,
        "seek": 19822,
        "start": 205.86,
        "temperature": 0,
        "text": " Yes, K. Wichman.",
        "tokens": [
          50746,
          1079,
          11,
          591,
          13,
          343,
          480,
          1601,
          13,
          50816
        ]
      },
      {
        "avg_logprob": -0.32317161560058594,
        "compression_ratio": 1.5806451612903225,
        "end": 208.38,
        "id": 62,
        "no_speech_prob": 0.00004400067336973734,
        "seek": 19822,
        "start": 207.26,
        "temperature": 0,
        "text": " Here we are again.",
        "tokens": [
          50816,
          1692,
          321,
          366,
          797,
          13,
          50872
        ]
      },
      {
        "avg_logprob": -0.32317161560058594,
        "compression_ratio": 1.5806451612903225,
        "end": 211.14,
        "id": 63,
        "no_speech_prob": 0.00004400067336973734,
        "seek": 19822,
        "start": 208.38,
        "temperature": 0,
        "text": " I am streaming extra, a little bit extra.",
        "tokens": [
          50872,
          286,
          669,
          11791,
          2857,
          11,
          257,
          707,
          857,
          2857,
          13,
          51010
        ]
      },
      {
        "avg_logprob": -0.32317161560058594,
        "compression_ratio": 1.5806451612903225,
        "end": 213.82,
        "id": 64,
        "no_speech_prob": 0.00004400067336973734,
        "seek": 19822,
        "start": 211.14,
        "temperature": 0,
        "text": " I've decided to come try to do two streams today,",
        "tokens": [
          51010,
          286,
          600,
          3047,
          281,
          808,
          853,
          281,
          360,
          732,
          15842,
          965,
          11,
          51144
        ]
      },
      {
        "avg_logprob": -0.32317161560058594,
        "compression_ratio": 1.5806451612903225,
        "end": 217.34,
        "id": 65,
        "no_speech_prob": 0.00004400067336973734,
        "seek": 19822,
        "start": 213.82,
        "temperature": 0,
        "text": " because A, I didn't get to last week because I was teaching.",
        "tokens": [
          51144,
          570,
          316,
          11,
          286,
          994,
          380,
          483,
          281,
          1036,
          1243,
          570,
          286,
          390,
          4571,
          13,
          51320
        ]
      },
      {
        "avg_logprob": -0.32317161560058594,
        "compression_ratio": 1.5806451612903225,
        "end": 219.46,
        "id": 66,
        "no_speech_prob": 0.00004400067336973734,
        "seek": 19822,
        "start": 217.34,
        "temperature": 0,
        "text": " And then also, I will just mention again",
        "tokens": [
          51320,
          400,
          550,
          611,
          11,
          286,
          486,
          445,
          2152,
          797,
          51426
        ]
      },
      {
        "avg_logprob": -0.32317161560058594,
        "compression_ratio": 1.5806451612903225,
        "end": 221.94,
        "id": 67,
        "no_speech_prob": 0.00004400067336973734,
        "seek": 19822,
        "start": 219.46,
        "temperature": 0,
        "text": " that I will be next week, next Saturday,",
        "tokens": [
          51426,
          300,
          286,
          486,
          312,
          958,
          1243,
          11,
          958,
          8803,
          11,
          51550
        ]
      },
      {
        "avg_logprob": -0.32317161560058594,
        "compression_ratio": 1.5806451612903225,
        "end": 224.14,
        "id": 68,
        "no_speech_prob": 0.00004400067336973734,
        "seek": 19822,
        "start": 221.94,
        "temperature": 0,
        "text": " at ThinkerCon in Hoodstool, Alabama,",
        "tokens": [
          51550,
          412,
          6557,
          260,
          9838,
          294,
          3631,
          378,
          372,
          1092,
          11,
          20898,
          11,
          51660
        ]
      },
      {
        "avg_logprob": -0.32317161560058594,
        "compression_ratio": 1.5806451612903225,
        "end": 227.7,
        "id": 69,
        "no_speech_prob": 0.00004400067336973734,
        "seek": 19822,
        "start": 224.14,
        "temperature": 0,
        "text": " a place I've never been to, the home of the rocket.",
        "tokens": [
          51660,
          257,
          1081,
          286,
          600,
          1128,
          668,
          281,
          11,
          264,
          1280,
          295,
          264,
          13012,
          13,
          51838
        ]
      },
      {
        "avg_logprob": -0.3297748565673828,
        "compression_ratio": 1.463855421686747,
        "end": 230.17999999999998,
        "id": 70,
        "no_speech_prob": 0.000013845894500263967,
        "seek": 22770,
        "start": 227.73999999999998,
        "temperature": 0,
        "text": " And if any of you are going to be there, please say hello.",
        "tokens": [
          50366,
          400,
          498,
          604,
          295,
          291,
          366,
          516,
          281,
          312,
          456,
          11,
          1767,
          584,
          7751,
          13,
          50488
        ]
      },
      {
        "avg_logprob": -0.3297748565673828,
        "compression_ratio": 1.463855421686747,
        "end": 241.01999999999998,
        "id": 71,
        "no_speech_prob": 0.000013845894500263967,
        "seek": 22770,
        "start": 238.66,
        "temperature": 0,
        "text": " All right, let's just get started here.",
        "tokens": [
          50912,
          1057,
          558,
          11,
          718,
          311,
          445,
          483,
          1409,
          510,
          13,
          51030
        ]
      },
      {
        "avg_logprob": -0.3297748565673828,
        "compression_ratio": 1.463855421686747,
        "end": 246.57999999999998,
        "id": 72,
        "no_speech_prob": 0.000013845894500263967,
        "seek": 22770,
        "start": 244.78,
        "temperature": 0,
        "text": " Let's just get started.",
        "tokens": [
          51218,
          961,
          311,
          445,
          483,
          1409,
          13,
          51308
        ]
      },
      {
        "avg_logprob": -0.3297748565673828,
        "compression_ratio": 1.463855421686747,
        "end": 247.73999999999998,
        "id": 73,
        "no_speech_prob": 0.000013845894500263967,
        "seek": 22770,
        "start": 246.57999999999998,
        "temperature": 0,
        "text": " So what else am I?",
        "tokens": [
          51308,
          407,
          437,
          1646,
          669,
          286,
          30,
          51366
        ]
      },
      {
        "avg_logprob": -0.3297748565673828,
        "compression_ratio": 1.463855421686747,
        "end": 252.5,
        "id": 74,
        "no_speech_prob": 0.000013845894500263967,
        "seek": 22770,
        "start": 247.73999999999998,
        "temperature": 0,
        "text": " I've got an hour or so or two, some amount of time.",
        "tokens": [
          51366,
          286,
          600,
          658,
          364,
          1773,
          420,
          370,
          420,
          732,
          11,
          512,
          2372,
          295,
          565,
          13,
          51604
        ]
      },
      {
        "avg_logprob": -0.3297748565673828,
        "compression_ratio": 1.463855421686747,
        "end": 255.78,
        "id": 75,
        "no_speech_prob": 0.000013845894500263967,
        "seek": 22770,
        "start": 252.5,
        "temperature": 0,
        "text": " I'm going to start with this ML5 save load model.",
        "tokens": [
          51604,
          286,
          478,
          516,
          281,
          722,
          365,
          341,
          21601,
          20,
          3155,
          3677,
          2316,
          13,
          51768
        ]
      },
      {
        "avg_logprob": -0.27463326760388296,
        "compression_ratio": 1.5512820512820513,
        "end": 258.14,
        "id": 76,
        "no_speech_prob": 0.0004442039062269032,
        "seek": 25578,
        "start": 255.78,
        "temperature": 0,
        "text": " I am going to also look at an example",
        "tokens": [
          50364,
          286,
          669,
          516,
          281,
          611,
          574,
          412,
          364,
          1365,
          50482
        ]
      },
      {
        "avg_logprob": -0.27463326760388296,
        "compression_ratio": 1.5512820512820513,
        "end": 260.86,
        "id": 77,
        "no_speech_prob": 0.0004442039062269032,
        "seek": 25578,
        "start": 258.14,
        "temperature": 0,
        "text": " with working with the Google Quick Draw data set,",
        "tokens": [
          50482,
          365,
          1364,
          365,
          264,
          3329,
          12101,
          20386,
          1412,
          992,
          11,
          50618
        ]
      },
      {
        "avg_logprob": -0.27463326760388296,
        "compression_ratio": 1.5512820512820513,
        "end": 267.9,
        "id": 78,
        "no_speech_prob": 0.0004442039062269032,
        "seek": 25578,
        "start": 260.86,
        "temperature": 0,
        "text": " because that is leading up to looking at the Sketch RNN",
        "tokens": [
          50618,
          570,
          300,
          307,
          5775,
          493,
          281,
          1237,
          412,
          264,
          49245,
          45702,
          45,
          50970
        ]
      },
      {
        "avg_logprob": -0.27463326760388296,
        "compression_ratio": 1.5512820512820513,
        "end": 269.22,
        "id": 79,
        "no_speech_prob": 0.0004442039062269032,
        "seek": 25578,
        "start": 267.9,
        "temperature": 0,
        "text": " model in ML5.",
        "tokens": [
          50970,
          2316,
          294,
          21601,
          20,
          13,
          51036
        ]
      },
      {
        "avg_logprob": -0.27463326760388296,
        "compression_ratio": 1.5512820512820513,
        "end": 269.86,
        "id": 80,
        "no_speech_prob": 0.0004442039062269032,
        "seek": 25578,
        "start": 269.22,
        "temperature": 0,
        "text": " So many things.",
        "tokens": [
          51036,
          407,
          867,
          721,
          13,
          51068
        ]
      },
      {
        "avg_logprob": -0.27463326760388296,
        "compression_ratio": 1.5512820512820513,
        "end": 272.58,
        "id": 81,
        "no_speech_prob": 0.0004442039062269032,
        "seek": 25578,
        "start": 269.86,
        "temperature": 0,
        "text": " I've got a long ML5 list of things to cover.",
        "tokens": [
          51068,
          286,
          600,
          658,
          257,
          938,
          21601,
          20,
          1329,
          295,
          721,
          281,
          2060,
          13,
          51204
        ]
      },
      {
        "avg_logprob": -0.27463326760388296,
        "compression_ratio": 1.5512820512820513,
        "end": 274.34,
        "id": 82,
        "no_speech_prob": 0.0004442039062269032,
        "seek": 25578,
        "start": 272.58,
        "temperature": 0,
        "text": " I want to look at some new stuff that's",
        "tokens": [
          51204,
          286,
          528,
          281,
          574,
          412,
          512,
          777,
          1507,
          300,
          311,
          51292
        ]
      },
      {
        "avg_logprob": -0.27463326760388296,
        "compression_ratio": 1.5512820512820513,
        "end": 278.46,
        "id": 83,
        "no_speech_prob": 0.0004442039062269032,
        "seek": 25578,
        "start": 274.34,
        "temperature": 0,
        "text": " been added for recurrent neural networks with text, Sketch RNN,",
        "tokens": [
          51292,
          668,
          3869,
          337,
          18680,
          1753,
          18161,
          9590,
          365,
          2487,
          11,
          49245,
          45702,
          45,
          11,
          51498
        ]
      },
      {
        "avg_logprob": -0.27463326760388296,
        "compression_ratio": 1.5512820512820513,
        "end": 282.58,
        "id": 84,
        "no_speech_prob": 0.0004442039062269032,
        "seek": 25578,
        "start": 278.46,
        "temperature": 0,
        "text": " PoseNet, KNN classifier, so many things.",
        "tokens": [
          51498,
          40174,
          31890,
          11,
          26967,
          45,
          1508,
          9902,
          11,
          370,
          867,
          721,
          13,
          51704
        ]
      },
      {
        "avg_logprob": -0.43032163943884505,
        "compression_ratio": 1.3053435114503817,
        "end": 284.26,
        "id": 85,
        "no_speech_prob": 0.00006814748485339805,
        "seek": 28258,
        "start": 283.26,
        "temperature": 0,
        "text": " So let us begin.",
        "tokens": [
          50398,
          407,
          718,
          505,
          1841,
          13,
          50448
        ]
      },
      {
        "avg_logprob": -0.43032163943884505,
        "compression_ratio": 1.3053435114503817,
        "end": 292.34,
        "id": 86,
        "no_speech_prob": 0.00006814748485339805,
        "seek": 28258,
        "start": 291.41999999999996,
        "temperature": 0,
        "text": " Hello.",
        "tokens": [
          50806,
          2425,
          13,
          50852
        ]
      },
      {
        "avg_logprob": -0.43032163943884505,
        "compression_ratio": 1.3053435114503817,
        "end": 295.58,
        "id": 87,
        "no_speech_prob": 0.00006814748485339805,
        "seek": 28258,
        "start": 292.34,
        "temperature": 0,
        "text": " I am here to make video number seven, which does not yet",
        "tokens": [
          50852,
          286,
          669,
          510,
          281,
          652,
          960,
          1230,
          3407,
          11,
          597,
          775,
          406,
          1939,
          51014
        ]
      },
      {
        "avg_logprob": -0.43032163943884505,
        "compression_ratio": 1.3053435114503817,
        "end": 296.08,
        "id": 88,
        "no_speech_prob": 0.00006814748485339805,
        "seek": 28258,
        "start": 295.58,
        "temperature": 0,
        "text": " exist.",
        "tokens": [
          51014,
          2514,
          13,
          51039
        ]
      },
      {
        "avg_logprob": -0.43032163943884505,
        "compression_ratio": 1.3053435114503817,
        "end": 298.18,
        "id": 89,
        "no_speech_prob": 0.00006814748485339805,
        "seek": 28258,
        "start": 296.08,
        "temperature": 0,
        "text": " If you have been watching this playlist,",
        "tokens": [
          51039,
          759,
          291,
          362,
          668,
          1976,
          341,
          16788,
          11,
          51144
        ]
      },
      {
        "avg_logprob": -0.43032163943884505,
        "compression_ratio": 1.3053435114503817,
        "end": 302.7,
        "id": 90,
        "no_speech_prob": 0.00006814748485339805,
        "seek": 28258,
        "start": 298.18,
        "temperature": 0,
        "text": " the place where I left off was training a.",
        "tokens": [
          51144,
          264,
          1081,
          689,
          286,
          1411,
          766,
          390,
          3097,
          257,
          13,
          51370
        ]
      },
      {
        "avg_logprob": -0.2681690700470455,
        "compression_ratio": 1.5942028985507246,
        "end": 313.38,
        "id": 91,
        "no_speech_prob": 0.00045119464630261064,
        "seek": 31258,
        "start": 312.82,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          50376,
          6962,
          322,
          13,
          50404
        ]
      },
      {
        "avg_logprob": -0.2681690700470455,
        "compression_ratio": 1.5942028985507246,
        "end": 316.06,
        "id": 92,
        "no_speech_prob": 0.00045119464630261064,
        "seek": 31258,
        "start": 313.38,
        "temperature": 0,
        "text": " I forgot to turn on this part of my brain.",
        "tokens": [
          50404,
          286,
          5298,
          281,
          1261,
          322,
          341,
          644,
          295,
          452,
          3567,
          13,
          50538
        ]
      },
      {
        "avg_logprob": -0.2681690700470455,
        "compression_ratio": 1.5942028985507246,
        "end": 323.46,
        "id": 93,
        "no_speech_prob": 0.00045119464630261064,
        "seek": 31258,
        "start": 320.14,
        "temperature": 0,
        "text": " Hello, welcome to a new ML5 beginner's guide",
        "tokens": [
          50742,
          2425,
          11,
          2928,
          281,
          257,
          777,
          21601,
          20,
          22080,
          311,
          5934,
          50908
        ]
      },
      {
        "avg_logprob": -0.2681690700470455,
        "compression_ratio": 1.5942028985507246,
        "end": 324.94,
        "id": 94,
        "no_speech_prob": 0.00045119464630261064,
        "seek": 31258,
        "start": 323.46,
        "temperature": 0,
        "text": " to machine learning video.",
        "tokens": [
          50908,
          281,
          3479,
          2539,
          960,
          13,
          50982
        ]
      },
      {
        "avg_logprob": -0.2681690700470455,
        "compression_ratio": 1.5942028985507246,
        "end": 327.3,
        "id": 95,
        "no_speech_prob": 0.00045119464630261064,
        "seek": 31258,
        "start": 324.94,
        "temperature": 0,
        "text": " I am about to make video number seven.",
        "tokens": [
          50982,
          286,
          669,
          466,
          281,
          652,
          960,
          1230,
          3407,
          13,
          51100
        ]
      },
      {
        "avg_logprob": -0.2681690700470455,
        "compression_ratio": 1.5942028985507246,
        "end": 329.14,
        "id": 96,
        "no_speech_prob": 0.00045119464630261064,
        "seek": 31258,
        "start": 327.3,
        "temperature": 0,
        "text": " Right now, that's what you're watching.",
        "tokens": [
          51100,
          1779,
          586,
          11,
          300,
          311,
          437,
          291,
          434,
          1976,
          13,
          51192
        ]
      },
      {
        "avg_logprob": -0.2681690700470455,
        "compression_ratio": 1.5942028985507246,
        "end": 331.02,
        "id": 97,
        "no_speech_prob": 0.00045119464630261064,
        "seek": 31258,
        "start": 329.14,
        "temperature": 0,
        "text": " Where I left off, I looked at how",
        "tokens": [
          51192,
          2305,
          286,
          1411,
          766,
          11,
          286,
          2956,
          412,
          577,
          51286
        ]
      },
      {
        "avg_logprob": -0.2681690700470455,
        "compression_ratio": 1.5942028985507246,
        "end": 334.28,
        "id": 98,
        "no_speech_prob": 0.00045119464630261064,
        "seek": 31258,
        "start": 331.02,
        "temperature": 0,
        "text": " you could train your own image classifier with images coming",
        "tokens": [
          51286,
          291,
          727,
          3847,
          428,
          1065,
          3256,
          1508,
          9902,
          365,
          5267,
          1348,
          51449
        ]
      },
      {
        "avg_logprob": -0.2681690700470455,
        "compression_ratio": 1.5942028985507246,
        "end": 336.41999999999996,
        "id": 99,
        "no_speech_prob": 0.00045119464630261064,
        "seek": 31258,
        "start": 334.28,
        "temperature": 0,
        "text": " in from the webcam with a technique known",
        "tokens": [
          51449,
          294,
          490,
          264,
          39490,
          365,
          257,
          6532,
          2570,
          51556
        ]
      },
      {
        "avg_logprob": -0.2681690700470455,
        "compression_ratio": 1.5942028985507246,
        "end": 337.34,
        "id": 100,
        "no_speech_prob": 0.00045119464630261064,
        "seek": 31258,
        "start": 336.41999999999996,
        "temperature": 0,
        "text": " as transfer learning.",
        "tokens": [
          51556,
          382,
          5003,
          2539,
          13,
          51602
        ]
      },
      {
        "avg_logprob": -0.2681690700470455,
        "compression_ratio": 1.5942028985507246,
        "end": 338.38,
        "id": 101,
        "no_speech_prob": 0.00045119464630261064,
        "seek": 31258,
        "start": 337.34,
        "temperature": 0,
        "text": " This is the example.",
        "tokens": [
          51602,
          639,
          307,
          264,
          1365,
          13,
          51654
        ]
      },
      {
        "avg_logprob": -0.2681690700470455,
        "compression_ratio": 1.5942028985507246,
        "end": 342.06,
        "id": 102,
        "no_speech_prob": 0.00045119464630261064,
        "seek": 31258,
        "start": 338.38,
        "temperature": 0,
        "text": " So this example needs to be trained, but I could do this.",
        "tokens": [
          51654,
          407,
          341,
          1365,
          2203,
          281,
          312,
          8895,
          11,
          457,
          286,
          727,
          360,
          341,
          13,
          51838
        ]
      },
      {
        "avg_logprob": -0.3804149812865026,
        "compression_ratio": 1.6666666666666667,
        "end": 346.02,
        "id": 103,
        "no_speech_prob": 0.0004954776377417147,
        "seek": 34206,
        "start": 342.06,
        "temperature": 0,
        "text": " I could get a lot of examples of me being happy,",
        "tokens": [
          50364,
          286,
          727,
          483,
          257,
          688,
          295,
          5110,
          295,
          385,
          885,
          2055,
          11,
          50562
        ]
      },
      {
        "avg_logprob": -0.3804149812865026,
        "compression_ratio": 1.6666666666666667,
        "end": 348.38,
        "id": 104,
        "no_speech_prob": 0.0004954776377417147,
        "seek": 34206,
        "start": 346.02,
        "temperature": 0,
        "text": " a lot of examples of me being sad.",
        "tokens": [
          50562,
          257,
          688,
          295,
          5110,
          295,
          385,
          885,
          4227,
          13,
          50680
        ]
      },
      {
        "avg_logprob": -0.3804149812865026,
        "compression_ratio": 1.6666666666666667,
        "end": 350.02,
        "id": 105,
        "no_speech_prob": 0.0004954776377417147,
        "seek": 34206,
        "start": 348.38,
        "temperature": 0,
        "text": " Then I could hit the Train button,",
        "tokens": [
          50680,
          1396,
          286,
          727,
          2045,
          264,
          28029,
          2960,
          11,
          50762
        ]
      },
      {
        "avg_logprob": -0.3804149812865026,
        "compression_ratio": 1.6666666666666667,
        "end": 353.86,
        "id": 106,
        "no_speech_prob": 0.0004954776377417147,
        "seek": 34206,
        "start": 350.02,
        "temperature": 0,
        "text": " and once it finishes training, it is then going to be done.",
        "tokens": [
          50762,
          293,
          1564,
          309,
          23615,
          3097,
          11,
          309,
          307,
          550,
          516,
          281,
          312,
          1096,
          13,
          50954
        ]
      },
      {
        "avg_logprob": -0.3804149812865026,
        "compression_ratio": 1.6666666666666667,
        "end": 354.58,
        "id": 107,
        "no_speech_prob": 0.0004954776377417147,
        "seek": 34206,
        "start": 353.86,
        "temperature": 0,
        "text": " And now I, hi.",
        "tokens": [
          50954,
          400,
          586,
          286,
          11,
          4879,
          13,
          50990
        ]
      },
      {
        "avg_logprob": -0.3804149812865026,
        "compression_ratio": 1.6666666666666667,
        "end": 361.54,
        "id": 108,
        "no_speech_prob": 0.0004954776377417147,
        "seek": 34206,
        "start": 360.62,
        "temperature": 0,
        "text": " This failed.",
        "tokens": [
          51292,
          639,
          7612,
          13,
          51338
        ]
      },
      {
        "avg_logprob": -0.3804149812865026,
        "compression_ratio": 1.6666666666666667,
        "end": 364.22,
        "id": 109,
        "no_speech_prob": 0.0004954776377417147,
        "seek": 34206,
        "start": 361.54,
        "temperature": 0,
        "text": " I shouldn't have been so, I didn't give it enough.",
        "tokens": [
          51338,
          286,
          4659,
          380,
          362,
          668,
          370,
          11,
          286,
          994,
          380,
          976,
          309,
          1547,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -0.3804149812865026,
        "compression_ratio": 1.6666666666666667,
        "end": 364.9,
        "id": 110,
        "no_speech_prob": 0.0004954776377417147,
        "seek": 34206,
        "start": 364.22,
        "temperature": 0,
        "text": " One more try.",
        "tokens": [
          51472,
          1485,
          544,
          853,
          13,
          51506
        ]
      },
      {
        "avg_logprob": -0.3804149812865026,
        "compression_ratio": 1.6666666666666667,
        "end": 369.02,
        "id": 111,
        "no_speech_prob": 0.0004954776377417147,
        "seek": 34206,
        "start": 367.54,
        "temperature": 0,
        "text": " One more try.",
        "tokens": [
          51638,
          1485,
          544,
          853,
          13,
          51712
        ]
      },
      {
        "avg_logprob": -0.3804149812865026,
        "compression_ratio": 1.6666666666666667,
        "end": 371.46,
        "id": 112,
        "no_speech_prob": 0.0004954776377417147,
        "seek": 34206,
        "start": 369.02,
        "temperature": 0,
        "text": " This time with feeling, everybody.",
        "tokens": [
          51712,
          639,
          565,
          365,
          2633,
          11,
          2201,
          13,
          51834
        ]
      },
      {
        "avg_logprob": -0.2447843208587427,
        "compression_ratio": 1.6426229508196721,
        "end": 374.06,
        "id": 113,
        "no_speech_prob": 0.00020342340576462448,
        "seek": 37146,
        "start": 371.46,
        "temperature": 0,
        "text": " Don't you just love watching the live streams where I just",
        "tokens": [
          50364,
          1468,
          380,
          291,
          445,
          959,
          1976,
          264,
          1621,
          15842,
          689,
          286,
          445,
          50494
        ]
      },
      {
        "avg_logprob": -0.2447843208587427,
        "compression_ratio": 1.6426229508196721,
        "end": 377.97999999999996,
        "id": 114,
        "no_speech_prob": 0.00020342340576462448,
        "seek": 37146,
        "start": 374.06,
        "temperature": 0,
        "text": " do the same thing over and over again?",
        "tokens": [
          50494,
          360,
          264,
          912,
          551,
          670,
          293,
          670,
          797,
          30,
          50690
        ]
      },
      {
        "avg_logprob": -0.2447843208587427,
        "compression_ratio": 1.6426229508196721,
        "end": 381.06,
        "id": 115,
        "no_speech_prob": 0.00020342340576462448,
        "seek": 37146,
        "start": 377.97999999999996,
        "temperature": 0,
        "text": " Hello, and welcome to another beginner's guide",
        "tokens": [
          50690,
          2425,
          11,
          293,
          2928,
          281,
          1071,
          22080,
          311,
          5934,
          50844
        ]
      },
      {
        "avg_logprob": -0.2447843208587427,
        "compression_ratio": 1.6426229508196721,
        "end": 383.26,
        "id": 116,
        "no_speech_prob": 0.00020342340576462448,
        "seek": 37146,
        "start": 381.06,
        "temperature": 0,
        "text": " to machine learning with ML5.js video.",
        "tokens": [
          50844,
          281,
          3479,
          2539,
          365,
          21601,
          20,
          13,
          25530,
          960,
          13,
          50954
        ]
      },
      {
        "avg_logprob": -0.2447843208587427,
        "compression_ratio": 1.6426229508196721,
        "end": 385.02,
        "id": 117,
        "no_speech_prob": 0.00020342340576462448,
        "seek": 37146,
        "start": 383.26,
        "temperature": 0,
        "text": " This is video number seven in this playlist.",
        "tokens": [
          50954,
          639,
          307,
          960,
          1230,
          3407,
          294,
          341,
          16788,
          13,
          51042
        ]
      },
      {
        "avg_logprob": -0.2447843208587427,
        "compression_ratio": 1.6426229508196721,
        "end": 386.94,
        "id": 118,
        "no_speech_prob": 0.00020342340576462448,
        "seek": 37146,
        "start": 385.02,
        "temperature": 0,
        "text": " At least that's where I intend it to be.",
        "tokens": [
          51042,
          1711,
          1935,
          300,
          311,
          689,
          286,
          19759,
          309,
          281,
          312,
          13,
          51138
        ]
      },
      {
        "avg_logprob": -0.2447843208587427,
        "compression_ratio": 1.6426229508196721,
        "end": 389.29999999999995,
        "id": 119,
        "no_speech_prob": 0.00020342340576462448,
        "seek": 37146,
        "start": 386.94,
        "temperature": 0,
        "text": " And in this video, I'm going to take a step forward.",
        "tokens": [
          51138,
          400,
          294,
          341,
          960,
          11,
          286,
          478,
          516,
          281,
          747,
          257,
          1823,
          2128,
          13,
          51256
        ]
      },
      {
        "avg_logprob": -0.2447843208587427,
        "compression_ratio": 1.6426229508196721,
        "end": 393.02,
        "id": 120,
        "no_speech_prob": 0.00020342340576462448,
        "seek": 37146,
        "start": 389.29999999999995,
        "temperature": 0,
        "text": " I am going to do something that has been so widely requested.",
        "tokens": [
          51256,
          286,
          669,
          516,
          281,
          360,
          746,
          300,
          575,
          668,
          370,
          13371,
          16436,
          13,
          51442
        ]
      },
      {
        "avg_logprob": -0.2447843208587427,
        "compression_ratio": 1.6426229508196721,
        "end": 395.26,
        "id": 121,
        "no_speech_prob": 0.00020342340576462448,
        "seek": 37146,
        "start": 393.02,
        "temperature": 0,
        "text": " A new feature that was recently added to ML5",
        "tokens": [
          51442,
          316,
          777,
          4111,
          300,
          390,
          3938,
          3869,
          281,
          21601,
          20,
          51554
        ]
      },
      {
        "avg_logprob": -0.2447843208587427,
        "compression_ratio": 1.6426229508196721,
        "end": 398.82,
        "id": 122,
        "no_speech_prob": 0.00020342340576462448,
        "seek": 37146,
        "start": 395.26,
        "temperature": 0,
        "text": " to save and reload a model.",
        "tokens": [
          51554,
          281,
          3155,
          293,
          25628,
          257,
          2316,
          13,
          51732
        ]
      },
      {
        "avg_logprob": -0.2447843208587427,
        "compression_ratio": 1.6426229508196721,
        "end": 400.62,
        "id": 123,
        "no_speech_prob": 0.00020342340576462448,
        "seek": 37146,
        "start": 398.82,
        "temperature": 0,
        "text": " Now, what kind of model am I talking about?",
        "tokens": [
          51732,
          823,
          11,
          437,
          733,
          295,
          2316,
          669,
          286,
          1417,
          466,
          30,
          51822
        ]
      },
      {
        "avg_logprob": -0.34067118962605797,
        "compression_ratio": 1.6651982378854626,
        "end": 402.5,
        "id": 124,
        "no_speech_prob": 0.000009972865882446058,
        "seek": 40062,
        "start": 400.66,
        "temperature": 0,
        "text": " So the last example I left off with",
        "tokens": [
          50366,
          407,
          264,
          1036,
          1365,
          286,
          1411,
          766,
          365,
          50458
        ]
      },
      {
        "avg_logprob": -0.34067118962605797,
        "compression_ratio": 1.6651982378854626,
        "end": 405.58,
        "id": 125,
        "no_speech_prob": 0.000009972865882446058,
        "seek": 40062,
        "start": 402.5,
        "temperature": 0,
        "text": " was this transfer learning example,",
        "tokens": [
          50458,
          390,
          341,
          5003,
          2539,
          1365,
          11,
          50612
        ]
      },
      {
        "avg_logprob": -0.34067118962605797,
        "compression_ratio": 1.6651982378854626,
        "end": 409.74,
        "id": 126,
        "no_speech_prob": 0.000009972865882446058,
        "seek": 40062,
        "start": 405.58,
        "temperature": 0,
        "text": " where I can train my own image classifier with images",
        "tokens": [
          50612,
          689,
          286,
          393,
          3847,
          452,
          1065,
          3256,
          1508,
          9902,
          365,
          5267,
          50820
        ]
      },
      {
        "avg_logprob": -0.34067118962605797,
        "compression_ratio": 1.6651982378854626,
        "end": 410.9,
        "id": 127,
        "no_speech_prob": 0.000009972865882446058,
        "seek": 40062,
        "start": 409.74,
        "temperature": 0,
        "text": " coming in from the webcam.",
        "tokens": [
          50820,
          1348,
          294,
          490,
          264,
          39490,
          13,
          50878
        ]
      },
      {
        "avg_logprob": -0.34067118962605797,
        "compression_ratio": 1.6651982378854626,
        "end": 412.12,
        "id": 128,
        "no_speech_prob": 0.000009972865882446058,
        "seek": 40062,
        "start": 410.9,
        "temperature": 0,
        "text": " So for example, I could say, here's",
        "tokens": [
          50878,
          407,
          337,
          1365,
          11,
          286,
          727,
          584,
          11,
          510,
          311,
          50939
        ]
      },
      {
        "avg_logprob": -0.34067118962605797,
        "compression_ratio": 1.6651982378854626,
        "end": 413.54,
        "id": 129,
        "no_speech_prob": 0.000009972865882446058,
        "seek": 40062,
        "start": 412.12,
        "temperature": 0,
        "text": " a lot of images of me being happy.",
        "tokens": [
          50939,
          257,
          688,
          295,
          5267,
          295,
          385,
          885,
          2055,
          13,
          51010
        ]
      },
      {
        "avg_logprob": -0.34067118962605797,
        "compression_ratio": 1.6651982378854626,
        "end": 419.06,
        "id": 130,
        "no_speech_prob": 0.000009972865882446058,
        "seek": 40062,
        "start": 417.5,
        "temperature": 0,
        "text": " Is this interesting yet?",
        "tokens": [
          51208,
          1119,
          341,
          1880,
          1939,
          30,
          51286
        ]
      },
      {
        "avg_logprob": -0.34067118962605797,
        "compression_ratio": 1.6651982378854626,
        "end": 420.22,
        "id": 131,
        "no_speech_prob": 0.000009972865882446058,
        "seek": 40062,
        "start": 419.06,
        "temperature": 0,
        "text": " What's going on?",
        "tokens": [
          51286,
          708,
          311,
          516,
          322,
          30,
          51344
        ]
      },
      {
        "avg_logprob": -0.34067118962605797,
        "compression_ratio": 1.6651982378854626,
        "end": 421.22,
        "id": 132,
        "no_speech_prob": 0.000009972865882446058,
        "seek": 40062,
        "start": 420.22,
        "temperature": 0,
        "text": " Here's all the images.",
        "tokens": [
          51344,
          1692,
          311,
          439,
          264,
          5267,
          13,
          51394
        ]
      },
      {
        "avg_logprob": -0.34067118962605797,
        "compression_ratio": 1.6651982378854626,
        "end": 422.02,
        "id": 133,
        "no_speech_prob": 0.000009972865882446058,
        "seek": 40062,
        "start": 421.22,
        "temperature": 0,
        "text": " What are you doing?",
        "tokens": [
          51394,
          708,
          366,
          291,
          884,
          30,
          51434
        ]
      },
      {
        "avg_logprob": -0.34067118962605797,
        "compression_ratio": 1.6651982378854626,
        "end": 422.52,
        "id": 134,
        "no_speech_prob": 0.000009972865882446058,
        "seek": 40062,
        "start": 422.02,
        "temperature": 0,
        "text": " I'm sad.",
        "tokens": [
          51434,
          286,
          478,
          4227,
          13,
          51459
        ]
      },
      {
        "avg_logprob": -0.34067118962605797,
        "compression_ratio": 1.6651982378854626,
        "end": 428.46,
        "id": 135,
        "no_speech_prob": 0.000009972865882446058,
        "seek": 40062,
        "start": 426.18,
        "temperature": 0,
        "text": " Then I'm going to train it.",
        "tokens": [
          51642,
          1396,
          286,
          478,
          516,
          281,
          3847,
          309,
          13,
          51756
        ]
      },
      {
        "avg_logprob": -0.34067118962605797,
        "compression_ratio": 1.6651982378854626,
        "end": 429.82,
        "id": 136,
        "no_speech_prob": 0.000009972865882446058,
        "seek": 40062,
        "start": 428.46,
        "temperature": 0,
        "text": " And then I'm going to come back.",
        "tokens": [
          51756,
          400,
          550,
          286,
          478,
          516,
          281,
          808,
          646,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.23691591303399268,
        "compression_ratio": 1.7108433734939759,
        "end": 430.74,
        "id": 137,
        "no_speech_prob": 0.00001670130222919397,
        "seek": 42982,
        "start": 429.82,
        "temperature": 0,
        "text": " It's going to be done.",
        "tokens": [
          50364,
          467,
          311,
          516,
          281,
          312,
          1096,
          13,
          50410
        ]
      },
      {
        "avg_logprob": -0.23691591303399268,
        "compression_ratio": 1.7108433734939759,
        "end": 435.7,
        "id": 138,
        "no_speech_prob": 0.00001670130222919397,
        "seek": 42982,
        "start": 435.06,
        "temperature": 0,
        "text": " So that works.",
        "tokens": [
          50626,
          407,
          300,
          1985,
          13,
          50658
        ]
      },
      {
        "avg_logprob": -0.23691591303399268,
        "compression_ratio": 1.7108433734939759,
        "end": 440.02,
        "id": 139,
        "no_speech_prob": 0.00001670130222919397,
        "seek": 42982,
        "start": 435.7,
        "temperature": 0,
        "text": " But what happens now if I refresh the page?",
        "tokens": [
          50658,
          583,
          437,
          2314,
          586,
          498,
          286,
          15134,
          264,
          3028,
          30,
          50874
        ]
      },
      {
        "avg_logprob": -0.23691591303399268,
        "compression_ratio": 1.7108433734939759,
        "end": 441.74,
        "id": 140,
        "no_speech_prob": 0.00001670130222919397,
        "seek": 42982,
        "start": 440.02,
        "temperature": 0,
        "text": " Need to be trained again.",
        "tokens": [
          50874,
          16984,
          281,
          312,
          8895,
          797,
          13,
          50960
        ]
      },
      {
        "avg_logprob": -0.23691591303399268,
        "compression_ratio": 1.7108433734939759,
        "end": 444.14,
        "id": 141,
        "no_speech_prob": 0.00001670130222919397,
        "seek": 42982,
        "start": 441.74,
        "temperature": 0,
        "text": " That model is lost.",
        "tokens": [
          50960,
          663,
          2316,
          307,
          2731,
          13,
          51080
        ]
      },
      {
        "avg_logprob": -0.23691591303399268,
        "compression_ratio": 1.7108433734939759,
        "end": 447.9,
        "id": 142,
        "no_speech_prob": 0.00001670130222919397,
        "seek": 42982,
        "start": 444.14,
        "temperature": 0,
        "text": " So there is a new feature in ML5, a load function",
        "tokens": [
          51080,
          407,
          456,
          307,
          257,
          777,
          4111,
          294,
          21601,
          20,
          11,
          257,
          3677,
          2445,
          51268
        ]
      },
      {
        "avg_logprob": -0.23691591303399268,
        "compression_ratio": 1.7108433734939759,
        "end": 449.18,
        "id": 143,
        "no_speech_prob": 0.00001670130222919397,
        "seek": 42982,
        "start": 447.9,
        "temperature": 0,
        "text": " and a save function.",
        "tokens": [
          51268,
          293,
          257,
          3155,
          2445,
          13,
          51332
        ]
      },
      {
        "avg_logprob": -0.23691591303399268,
        "compression_ratio": 1.7108433734939759,
        "end": 450.58,
        "id": 144,
        "no_speech_prob": 0.00001670130222919397,
        "seek": 42982,
        "start": 449.18,
        "temperature": 0,
        "text": " A save function and a load function.",
        "tokens": [
          51332,
          316,
          3155,
          2445,
          293,
          257,
          3677,
          2445,
          13,
          51402
        ]
      },
      {
        "avg_logprob": -0.23691591303399268,
        "compression_ratio": 1.7108433734939759,
        "end": 451.65999999999997,
        "id": 145,
        "no_speech_prob": 0.00001670130222919397,
        "seek": 42982,
        "start": 450.58,
        "temperature": 0,
        "text": " This is what I'm going to show you in this video.",
        "tokens": [
          51402,
          639,
          307,
          437,
          286,
          478,
          516,
          281,
          855,
          291,
          294,
          341,
          960,
          13,
          51456
        ]
      },
      {
        "avg_logprob": -0.23691591303399268,
        "compression_ratio": 1.7108433734939759,
        "end": 452.78,
        "id": 146,
        "no_speech_prob": 0.00001670130222919397,
        "seek": 42982,
        "start": 451.65999999999997,
        "temperature": 0,
        "text": " Let's see if we can get it to work.",
        "tokens": [
          51456,
          961,
          311,
          536,
          498,
          321,
          393,
          483,
          309,
          281,
          589,
          13,
          51512
        ]
      },
      {
        "avg_logprob": -0.23691591303399268,
        "compression_ratio": 1.7108433734939759,
        "end": 453.28,
        "id": 147,
        "no_speech_prob": 0.00001670130222919397,
        "seek": 42982,
        "start": 452.78,
        "temperature": 0,
        "text": " That's it.",
        "tokens": [
          51512,
          663,
          311,
          309,
          13,
          51537
        ]
      },
      {
        "avg_logprob": -0.23691591303399268,
        "compression_ratio": 1.7108433734939759,
        "end": 455.06,
        "id": 148,
        "no_speech_prob": 0.00001670130222919397,
        "seek": 42982,
        "start": 453.28,
        "temperature": 0,
        "text": " It's all I'm going to add.",
        "tokens": [
          51537,
          467,
          311,
          439,
          286,
          478,
          516,
          281,
          909,
          13,
          51626
        ]
      },
      {
        "avg_logprob": -0.23691591303399268,
        "compression_ratio": 1.7108433734939759,
        "end": 457.21999999999997,
        "id": 149,
        "no_speech_prob": 0.00001670130222919397,
        "seek": 42982,
        "start": 455.06,
        "temperature": 0,
        "text": " So I've got the code from the previous example",
        "tokens": [
          51626,
          407,
          286,
          600,
          658,
          264,
          3089,
          490,
          264,
          3894,
          1365,
          51734
        ]
      },
      {
        "avg_logprob": -0.23691591303399268,
        "compression_ratio": 1.7108433734939759,
        "end": 459.48,
        "id": 150,
        "no_speech_prob": 0.00001670130222919397,
        "seek": 42982,
        "start": 457.21999999999997,
        "temperature": 0,
        "text": " here to pull it up.",
        "tokens": [
          51734,
          510,
          281,
          2235,
          309,
          493,
          13,
          51847
        ]
      },
      {
        "avg_logprob": -0.3151137942359561,
        "compression_ratio": 1.8622222222222222,
        "end": 461.88,
        "id": 151,
        "no_speech_prob": 0.000058290686865802854,
        "seek": 45948,
        "start": 459.48,
        "temperature": 0,
        "text": " And what I'm going to do, let's add another button.",
        "tokens": [
          50364,
          400,
          437,
          286,
          478,
          516,
          281,
          360,
          11,
          718,
          311,
          909,
          1071,
          2960,
          13,
          50484
        ]
      },
      {
        "avg_logprob": -0.3151137942359561,
        "compression_ratio": 1.8622222222222222,
        "end": 462.84000000000003,
        "id": 152,
        "no_speech_prob": 0.000058290686865802854,
        "seek": 45948,
        "start": 461.88,
        "temperature": 0,
        "text": " Where are the buttons?",
        "tokens": [
          50484,
          2305,
          366,
          264,
          9905,
          30,
          50532
        ]
      },
      {
        "avg_logprob": -0.3151137942359561,
        "compression_ratio": 1.8622222222222222,
        "end": 463.56,
        "id": 153,
        "no_speech_prob": 0.000058290686865802854,
        "seek": 45948,
        "start": 462.84000000000003,
        "temperature": 0,
        "text": " Did I use create?",
        "tokens": [
          50532,
          2589,
          286,
          764,
          1884,
          30,
          50568
        ]
      },
      {
        "avg_logprob": -0.3151137942359561,
        "compression_ratio": 1.8622222222222222,
        "end": 465.40000000000003,
        "id": 154,
        "no_speech_prob": 0.000058290686865802854,
        "seek": 45948,
        "start": 463.56,
        "temperature": 0,
        "text": " Yeah, I used create button, I guess.",
        "tokens": [
          50568,
          865,
          11,
          286,
          1143,
          1884,
          2960,
          11,
          286,
          2041,
          13,
          50660
        ]
      },
      {
        "avg_logprob": -0.3151137942359561,
        "compression_ratio": 1.8622222222222222,
        "end": 467.8,
        "id": 155,
        "no_speech_prob": 0.000058290686865802854,
        "seek": 45948,
        "start": 465.40000000000003,
        "temperature": 0,
        "text": " So I'm going to go into setup.",
        "tokens": [
          50660,
          407,
          286,
          478,
          516,
          281,
          352,
          666,
          8657,
          13,
          50780
        ]
      },
      {
        "avg_logprob": -0.3151137942359561,
        "compression_ratio": 1.8622222222222222,
        "end": 469.6,
        "id": 156,
        "no_speech_prob": 0.000058290686865802854,
        "seek": 45948,
        "start": 467.8,
        "temperature": 0,
        "text": " And I'm going to, I forgot if these are called",
        "tokens": [
          50780,
          400,
          286,
          478,
          516,
          281,
          11,
          286,
          5298,
          498,
          613,
          366,
          1219,
          50870
        ]
      },
      {
        "avg_logprob": -0.3151137942359561,
        "compression_ratio": 1.8622222222222222,
        "end": 474.12,
        "id": 157,
        "no_speech_prob": 0.000058290686865802854,
        "seek": 45948,
        "start": 469.6,
        "temperature": 0,
        "text": " yuke buttons and whistle buttons, because why not?",
        "tokens": [
          50870,
          288,
          2034,
          68,
          9905,
          293,
          23470,
          9905,
          11,
          570,
          983,
          406,
          30,
          51096
        ]
      },
      {
        "avg_logprob": -0.3151137942359561,
        "compression_ratio": 1.8622222222222222,
        "end": 479.72,
        "id": 158,
        "no_speech_prob": 0.000058290686865802854,
        "seek": 45948,
        "start": 474.12,
        "temperature": 0,
        "text": " I'm going to make a save button equals create button, save.",
        "tokens": [
          51096,
          286,
          478,
          516,
          281,
          652,
          257,
          3155,
          2960,
          6915,
          1884,
          2960,
          11,
          3155,
          13,
          51376
        ]
      },
      {
        "avg_logprob": -0.3151137942359561,
        "compression_ratio": 1.8622222222222222,
        "end": 484.32,
        "id": 159,
        "no_speech_prob": 0.000058290686865802854,
        "seek": 45948,
        "start": 479.72,
        "temperature": 0,
        "text": " Then I'm going to say save button dot mouse pressed.",
        "tokens": [
          51376,
          1396,
          286,
          478,
          516,
          281,
          584,
          3155,
          2960,
          5893,
          9719,
          17355,
          13,
          51606
        ]
      },
      {
        "avg_logprob": -0.3151137942359561,
        "compression_ratio": 1.8622222222222222,
        "end": 486.68,
        "id": 160,
        "no_speech_prob": 0.000058290686865802854,
        "seek": 45948,
        "start": 484.32,
        "temperature": 0,
        "text": " I'm going to put an anonymous function in here.",
        "tokens": [
          51606,
          286,
          478,
          516,
          281,
          829,
          364,
          24932,
          2445,
          294,
          510,
          13,
          51724
        ]
      },
      {
        "avg_logprob": -0.21772830550735062,
        "compression_ratio": 1.4242424242424243,
        "end": 491.68,
        "id": 161,
        "no_speech_prob": 0.00004133499169256538,
        "seek": 48668,
        "start": 486.68,
        "temperature": 0,
        "text": " And I am going to now say classifier dot save.",
        "tokens": [
          50364,
          400,
          286,
          669,
          516,
          281,
          586,
          584,
          1508,
          9902,
          5893,
          3155,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.21772830550735062,
        "compression_ratio": 1.4242424242424243,
        "end": 493.24,
        "id": 162,
        "no_speech_prob": 0.00004133499169256538,
        "seek": 48668,
        "start": 491.68,
        "temperature": 0,
        "text": " That's it.",
        "tokens": [
          50614,
          663,
          311,
          309,
          13,
          50692
        ]
      },
      {
        "avg_logprob": -0.21772830550735062,
        "compression_ratio": 1.4242424242424243,
        "end": 496.2,
        "id": 163,
        "no_speech_prob": 0.00004133499169256538,
        "seek": 48668,
        "start": 493.24,
        "temperature": 0,
        "text": " The classifier object, if you remember,",
        "tokens": [
          50692,
          440,
          1508,
          9902,
          2657,
          11,
          498,
          291,
          1604,
          11,
          50840
        ]
      },
      {
        "avg_logprob": -0.21772830550735062,
        "compression_ratio": 1.4242424242424243,
        "end": 503.96000000000004,
        "id": 164,
        "no_speech_prob": 0.00004133499169256538,
        "seek": 48668,
        "start": 496.2,
        "temperature": 0,
        "text": " is a classification object made from a feature extractor",
        "tokens": [
          50840,
          307,
          257,
          21538,
          2657,
          1027,
          490,
          257,
          4111,
          8947,
          284,
          51228
        ]
      },
      {
        "avg_logprob": -0.21772830550735062,
        "compression_ratio": 1.4242424242424243,
        "end": 506.2,
        "id": 165,
        "no_speech_prob": 0.00004133499169256538,
        "seek": 48668,
        "start": 503.96000000000004,
        "temperature": 0,
        "text": " from the MobileNet library.",
        "tokens": [
          51228,
          490,
          264,
          22625,
          31890,
          6405,
          13,
          51340
        ]
      },
      {
        "avg_logprob": -0.21772830550735062,
        "compression_ratio": 1.4242424242424243,
        "end": 508.76,
        "id": 166,
        "no_speech_prob": 0.00004133499169256538,
        "seek": 48668,
        "start": 506.2,
        "temperature": 0,
        "text": " Rattling mic.",
        "tokens": [
          51340,
          497,
          1591,
          1688,
          3123,
          13,
          51468
        ]
      },
      {
        "avg_logprob": -0.21772830550735062,
        "compression_ratio": 1.4242424242424243,
        "end": 509.56,
        "id": 167,
        "no_speech_prob": 0.00004133499169256538,
        "seek": 48668,
        "start": 508.76,
        "temperature": 0,
        "text": " Sorry, time out.",
        "tokens": [
          51468,
          4919,
          11,
          565,
          484,
          13,
          51508
        ]
      },
      {
        "avg_logprob": -0.21772830550735062,
        "compression_ratio": 1.4242424242424243,
        "end": 510.8,
        "id": 168,
        "no_speech_prob": 0.00004133499169256538,
        "seek": 48668,
        "start": 509.56,
        "temperature": 0,
        "text": " Is the mic a problem?",
        "tokens": [
          51508,
          1119,
          264,
          3123,
          257,
          1154,
          30,
          51570
        ]
      },
      {
        "avg_logprob": -0.521333578861121,
        "compression_ratio": 1.0759493670886076,
        "end": 530.04,
        "id": 169,
        "no_speech_prob": 0.00008218484435928985,
        "seek": 51668,
        "start": 516.68,
        "temperature": 0,
        "text": " Is this better now?",
        "tokens": [
          50364,
          1119,
          341,
          1101,
          586,
          30,
          51032
        ]
      },
      {
        "avg_logprob": -0.521333578861121,
        "compression_ratio": 1.0759493670886076,
        "end": 530.88,
        "id": 170,
        "no_speech_prob": 0.00008218484435928985,
        "seek": 51668,
        "start": 530.04,
        "temperature": 0,
        "text": " OK?",
        "tokens": [
          51032,
          2264,
          30,
          51074
        ]
      },
      {
        "avg_logprob": -0.521333578861121,
        "compression_ratio": 1.0759493670886076,
        "end": 532.4799999999999,
        "id": 171,
        "no_speech_prob": 0.00008218484435928985,
        "seek": 51668,
        "start": 530.88,
        "temperature": 0,
        "text": " Is the mic OK?",
        "tokens": [
          51074,
          1119,
          264,
          3123,
          2264,
          30,
          51154
        ]
      },
      {
        "avg_logprob": -0.521333578861121,
        "compression_ratio": 1.0759493670886076,
        "end": 534.4,
        "id": 172,
        "no_speech_prob": 0.00008218484435928985,
        "seek": 51668,
        "start": 532.4799999999999,
        "temperature": 0,
        "text": " I kind of want to start this video over again.",
        "tokens": [
          51154,
          286,
          733,
          295,
          528,
          281,
          722,
          341,
          960,
          670,
          797,
          13,
          51250
        ]
      },
      {
        "avg_logprob": -0.6497393467629603,
        "compression_ratio": 1.876923076923077,
        "end": 538.12,
        "id": 173,
        "no_speech_prob": 0.0001106079071178101,
        "seek": 53440,
        "start": 535.4,
        "temperature": 0,
        "text": " I just, I'm waiting before I keep going to see",
        "tokens": [
          50414,
          286,
          445,
          11,
          286,
          478,
          3806,
          949,
          286,
          1066,
          516,
          281,
          536,
          50550
        ]
      },
      {
        "avg_logprob": -0.6497393467629603,
        "compression_ratio": 1.876923076923077,
        "end": 539.12,
        "id": 174,
        "no_speech_prob": 0.0001106079071178101,
        "seek": 53440,
        "start": 538.12,
        "temperature": 0,
        "text": " that the sound is OK.",
        "tokens": [
          50550,
          300,
          264,
          1626,
          307,
          2264,
          13,
          50600
        ]
      },
      {
        "avg_logprob": -0.6497393467629603,
        "compression_ratio": 1.876923076923077,
        "end": 543.84,
        "id": 175,
        "no_speech_prob": 0.0001106079071178101,
        "seek": 53440,
        "start": 542.12,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          50750,
          1079,
          13,
          50836
        ]
      },
      {
        "avg_logprob": -0.6497393467629603,
        "compression_ratio": 1.876923076923077,
        "end": 546.36,
        "id": 176,
        "no_speech_prob": 0.0001106079071178101,
        "seek": 53440,
        "start": 543.84,
        "temperature": 0,
        "text": " 1, 2, 1, 2, my mic is clattering a lot.",
        "tokens": [
          50836,
          502,
          11,
          568,
          11,
          502,
          11,
          568,
          11,
          452,
          3123,
          307,
          596,
          14849,
          257,
          688,
          13,
          50962
        ]
      },
      {
        "avg_logprob": -0.6497393467629603,
        "compression_ratio": 1.876923076923077,
        "end": 547.68,
        "id": 177,
        "no_speech_prob": 0.0001106079071178101,
        "seek": 53440,
        "start": 546.36,
        "temperature": 0,
        "text": " Is it still clattering?",
        "tokens": [
          50962,
          1119,
          309,
          920,
          596,
          14849,
          30,
          51028
        ]
      },
      {
        "avg_logprob": -0.6497393467629603,
        "compression_ratio": 1.876923076923077,
        "end": 550.04,
        "id": 178,
        "no_speech_prob": 0.0001106079071178101,
        "seek": 53440,
        "start": 547.68,
        "temperature": 0,
        "text": " Maybe I better go back and redo this whole video.",
        "tokens": [
          51028,
          2704,
          286,
          1101,
          352,
          646,
          293,
          29956,
          341,
          1379,
          960,
          13,
          51146
        ]
      },
      {
        "avg_logprob": -0.6497393467629603,
        "compression_ratio": 1.876923076923077,
        "end": 553.1999999999999,
        "id": 179,
        "no_speech_prob": 0.0001106079071178101,
        "seek": 53440,
        "start": 550.04,
        "temperature": 0,
        "text": " Nothing would make me happier.",
        "tokens": [
          51146,
          6693,
          576,
          652,
          385,
          20423,
          13,
          51304
        ]
      },
      {
        "avg_logprob": -0.6497393467629603,
        "compression_ratio": 1.876923076923077,
        "end": 554.56,
        "id": 180,
        "no_speech_prob": 0.0001106079071178101,
        "seek": 53440,
        "start": 553.1999999999999,
        "temperature": 0,
        "text": " Let's actually see if this works.",
        "tokens": [
          51304,
          961,
          311,
          767,
          536,
          498,
          341,
          1985,
          13,
          51372
        ]
      },
      {
        "avg_logprob": -0.6497393467629603,
        "compression_ratio": 1.876923076923077,
        "end": 559.04,
        "id": 181,
        "no_speech_prob": 0.0001106079071178101,
        "seek": 53440,
        "start": 558.56,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51572,
          2264,
          13,
          51596
        ]
      },
      {
        "avg_logprob": -0.6497393467629603,
        "compression_ratio": 1.876923076923077,
        "end": 559.92,
        "id": 182,
        "no_speech_prob": 0.0001106079071178101,
        "seek": 53440,
        "start": 559.04,
        "temperature": 0,
        "text": " I think it's working.",
        "tokens": [
          51596,
          286,
          519,
          309,
          311,
          1364,
          13,
          51640
        ]
      },
      {
        "avg_logprob": -0.6497393467629603,
        "compression_ratio": 1.876923076923077,
        "end": 560.8,
        "id": 183,
        "no_speech_prob": 0.0001106079071178101,
        "seek": 53440,
        "start": 559.92,
        "temperature": 0,
        "text": " I think it's working.",
        "tokens": [
          51640,
          286,
          519,
          309,
          311,
          1364,
          13,
          51684
        ]
      },
      {
        "avg_logprob": -0.6497393467629603,
        "compression_ratio": 1.876923076923077,
        "end": 561.68,
        "id": 184,
        "no_speech_prob": 0.0001106079071178101,
        "seek": 53440,
        "start": 560.8,
        "temperature": 0,
        "text": " I think it's working.",
        "tokens": [
          51684,
          286,
          519,
          309,
          311,
          1364,
          13,
          51728
        ]
      },
      {
        "avg_logprob": -0.6497393467629603,
        "compression_ratio": 1.876923076923077,
        "end": 562.52,
        "id": 185,
        "no_speech_prob": 0.0001106079071178101,
        "seek": 53440,
        "start": 561.68,
        "temperature": 0,
        "text": " I think it's working.",
        "tokens": [
          51728,
          286,
          519,
          309,
          311,
          1364,
          13,
          51770
        ]
      },
      {
        "avg_logprob": -0.6497393467629603,
        "compression_ratio": 1.876923076923077,
        "end": 563.36,
        "id": 186,
        "no_speech_prob": 0.0001106079071178101,
        "seek": 53440,
        "start": 562.52,
        "temperature": 0,
        "text": " I think it's working.",
        "tokens": [
          51770,
          286,
          519,
          309,
          311,
          1364,
          13,
          51812
        ]
      },
      {
        "avg_logprob": -0.49513131481106,
        "compression_ratio": 1.312,
        "end": 565.84,
        "id": 187,
        "no_speech_prob": 0.00024533062241971493,
        "seek": 56336,
        "start": 564.36,
        "temperature": 0,
        "text": " While I'm here, I'm going to redo it.",
        "tokens": [
          50414,
          3987,
          286,
          478,
          510,
          11,
          286,
          478,
          516,
          281,
          29956,
          309,
          13,
          50488
        ]
      },
      {
        "avg_logprob": -0.49513131481106,
        "compression_ratio": 1.312,
        "end": 573.76,
        "id": 188,
        "no_speech_prob": 0.00024533062241971493,
        "seek": 56336,
        "start": 572.8000000000001,
        "temperature": 0,
        "text": " Classifier dot save.",
        "tokens": [
          50836,
          9471,
          9902,
          5893,
          3155,
          13,
          50884
        ]
      },
      {
        "avg_logprob": -0.49513131481106,
        "compression_ratio": 1.312,
        "end": 576.16,
        "id": 189,
        "no_speech_prob": 0.00024533062241971493,
        "seek": 56336,
        "start": 573.76,
        "temperature": 0,
        "text": " Oh, I forgot.",
        "tokens": [
          50884,
          876,
          11,
          286,
          5298,
          13,
          51004
        ]
      },
      {
        "avg_logprob": -0.49513131481106,
        "compression_ratio": 1.312,
        "end": 576.6800000000001,
        "id": 190,
        "no_speech_prob": 0.00024533062241971493,
        "seek": 56336,
        "start": 576.16,
        "temperature": 0,
        "text": " Great.",
        "tokens": [
          51004,
          3769,
          13,
          51030
        ]
      },
      {
        "avg_logprob": -0.49513131481106,
        "compression_ratio": 1.312,
        "end": 579,
        "id": 191,
        "no_speech_prob": 0.00024533062241971493,
        "seek": 56336,
        "start": 576.6800000000001,
        "temperature": 0,
        "text": " So this, I'm going to have this happen,",
        "tokens": [
          51030,
          407,
          341,
          11,
          286,
          478,
          516,
          281,
          362,
          341,
          1051,
          11,
          51146
        ]
      },
      {
        "avg_logprob": -0.49513131481106,
        "compression_ratio": 1.312,
        "end": 580.92,
        "id": 192,
        "no_speech_prob": 0.00024533062241971493,
        "seek": 56336,
        "start": 579,
        "temperature": 0,
        "text": " because I have to upgrade my version of ml5.",
        "tokens": [
          51146,
          570,
          286,
          362,
          281,
          11484,
          452,
          3037,
          295,
          23271,
          20,
          13,
          51242
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 596.36,
        "id": 193,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 593.36,
        "temperature": 0,
        "text": " Yep.",
        "tokens": [
          50364,
          7010,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 597.36,
        "id": 194,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 596.36,
        "temperature": 0,
        "text": " Great.",
        "tokens": [
          50514,
          3769,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 598.36,
        "id": 195,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 597.36,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50564,
          2264,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 599.36,
        "id": 196,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 598.36,
        "temperature": 0,
        "text": " So that worked.",
        "tokens": [
          50614,
          407,
          300,
          2732,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 600.36,
        "id": 197,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 599.36,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50664,
          2264,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 602.36,
        "id": 198,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 600.36,
        "temperature": 0,
        "text": " How do I tell it not to show the warnings?",
        "tokens": [
          50714,
          1012,
          360,
          286,
          980,
          309,
          406,
          281,
          855,
          264,
          30009,
          30,
          50814
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 603.36,
        "id": 199,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 602.36,
        "temperature": 0,
        "text": " Show.",
        "tokens": [
          50814,
          6895,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 605.36,
        "id": 200,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 603.36,
        "temperature": 0,
        "text": " Where's the preference for showing warnings?",
        "tokens": [
          50864,
          2305,
          311,
          264,
          17502,
          337,
          4099,
          30009,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 606.36,
        "id": 201,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 605.36,
        "temperature": 0,
        "text": " Oh, I see.",
        "tokens": [
          50964,
          876,
          11,
          286,
          536,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 607.36,
        "id": 202,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 606.36,
        "temperature": 0,
        "text": " I see.",
        "tokens": [
          51014,
          286,
          536,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 608.36,
        "id": 203,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 607.36,
        "temperature": 0,
        "text": " I see.",
        "tokens": [
          51064,
          286,
          536,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 609.36,
        "id": 204,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 608.36,
        "temperature": 0,
        "text": " I see.",
        "tokens": [
          51114,
          286,
          536,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 610.36,
        "id": 205,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 609.36,
        "temperature": 0,
        "text": " I see.",
        "tokens": [
          51164,
          286,
          536,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 611.36,
        "id": 206,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 610.36,
        "temperature": 0,
        "text": " I see.",
        "tokens": [
          51214,
          286,
          536,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 612.36,
        "id": 207,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 611.36,
        "temperature": 0,
        "text": " I see.",
        "tokens": [
          51264,
          286,
          536,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 613.36,
        "id": 208,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 612.36,
        "temperature": 0,
        "text": " I see.",
        "tokens": [
          51314,
          286,
          536,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 614.36,
        "id": 209,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 613.36,
        "temperature": 0,
        "text": " I see.",
        "tokens": [
          51364,
          286,
          536,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 615.36,
        "id": 210,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 614.36,
        "temperature": 0,
        "text": " I see.",
        "tokens": [
          51414,
          286,
          536,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 616.36,
        "id": 211,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 615.36,
        "temperature": 0,
        "text": " I see.",
        "tokens": [
          51464,
          286,
          536,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 617.36,
        "id": 212,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 616.36,
        "temperature": 0,
        "text": " I see.",
        "tokens": [
          51514,
          286,
          536,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 618.36,
        "id": 213,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 617.36,
        "temperature": 0,
        "text": " I see.",
        "tokens": [
          51564,
          286,
          536,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 619.36,
        "id": 214,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 618.36,
        "temperature": 0,
        "text": " I see.",
        "tokens": [
          51614,
          286,
          536,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 620.36,
        "id": 215,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 619.36,
        "temperature": 0,
        "text": " I see.",
        "tokens": [
          51664,
          286,
          536,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 621.36,
        "id": 216,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 620.36,
        "temperature": 0,
        "text": " I see.",
        "tokens": [
          51714,
          286,
          536,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.3978492902672809,
        "compression_ratio": 2.1538461538461537,
        "end": 622.36,
        "id": 217,
        "no_speech_prob": 0.0007096089539118111,
        "seek": 59336,
        "start": 621.36,
        "temperature": 0,
        "text": " I see.",
        "tokens": [
          51764,
          286,
          536,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.37166153757195725,
        "compression_ratio": 1.5139664804469273,
        "end": 624.36,
        "id": 218,
        "no_speech_prob": 0.1847383826971054,
        "seek": 62236,
        "start": 622.36,
        "temperature": 0,
        "text": " Show warnings.",
        "tokens": [
          50364,
          6895,
          30009,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.37166153757195725,
        "compression_ratio": 1.5139664804469273,
        "end": 627.36,
        "id": 219,
        "no_speech_prob": 0.1847383826971054,
        "seek": 62236,
        "start": 624.36,
        "temperature": 0,
        "text": " Because I kind of would prefer not to see them, frankly.",
        "tokens": [
          50464,
          1436,
          286,
          733,
          295,
          576,
          4382,
          406,
          281,
          536,
          552,
          11,
          11939,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.37166153757195725,
        "compression_ratio": 1.5139664804469273,
        "end": 637.36,
        "id": 220,
        "no_speech_prob": 0.1847383826971054,
        "seek": 62236,
        "start": 630.36,
        "temperature": 0,
        "text": " High network, evaluation, preserve log, show warnings.",
        "tokens": [
          50764,
          5229,
          3209,
          11,
          308,
          46504,
          11,
          15665,
          3565,
          11,
          855,
          30009,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.37166153757195725,
        "compression_ratio": 1.5139664804469273,
        "end": 638.36,
        "id": 221,
        "no_speech_prob": 0.1847383826971054,
        "seek": 62236,
        "start": 637.36,
        "temperature": 0,
        "text": " Somebody will show me.",
        "tokens": [
          51114,
          13463,
          486,
          855,
          385,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.37166153757195725,
        "compression_ratio": 1.5139664804469273,
        "end": 644.36,
        "id": 222,
        "no_speech_prob": 0.1847383826971054,
        "seek": 62236,
        "start": 641.36,
        "temperature": 0,
        "text": " If anyone in the Slack channel could tell me how the mic is",
        "tokens": [
          51314,
          759,
          2878,
          294,
          264,
          37211,
          2269,
          727,
          980,
          385,
          577,
          264,
          3123,
          307,
          51464
        ]
      },
      {
        "avg_logprob": -0.37166153757195725,
        "compression_ratio": 1.5139664804469273,
        "end": 646.36,
        "id": 223,
        "no_speech_prob": 0.1847383826971054,
        "seek": 62236,
        "start": 644.36,
        "temperature": 0,
        "text": " going, I would really appreciate that.",
        "tokens": [
          51464,
          516,
          11,
          286,
          576,
          534,
          4449,
          300,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.37166153757195725,
        "compression_ratio": 1.5139664804469273,
        "end": 647.36,
        "id": 224,
        "no_speech_prob": 0.1847383826971054,
        "seek": 62236,
        "start": 646.36,
        "temperature": 0,
        "text": " Show warnings.",
        "tokens": [
          51564,
          6895,
          30009,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.37166153757195725,
        "compression_ratio": 1.5139664804469273,
        "end": 648.36,
        "id": 225,
        "no_speech_prob": 0.1847383826971054,
        "seek": 62236,
        "start": 647.36,
        "temperature": 0,
        "text": " Chrome.",
        "tokens": [
          51614,
          15327,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19616810306087956,
        "compression_ratio": 1.4275862068965517,
        "end": 655.36,
        "id": 226,
        "no_speech_prob": 0.010316010564565659,
        "seek": 65236,
        "start": 653.36,
        "temperature": 0,
        "text": " Hide warnings in the console window.",
        "tokens": [
          50414,
          35118,
          30009,
          294,
          264,
          11076,
          4910,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.19616810306087956,
        "compression_ratio": 1.4275862068965517,
        "end": 657.36,
        "id": 227,
        "no_speech_prob": 0.010316010564565659,
        "seek": 65236,
        "start": 655.36,
        "temperature": 0,
        "text": " Is there.",
        "tokens": [
          50514,
          1119,
          456,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19616810306087956,
        "compression_ratio": 1.4275862068965517,
        "end": 660.36,
        "id": 228,
        "no_speech_prob": 0.010316010564565659,
        "seek": 65236,
        "start": 657.36,
        "temperature": 0,
        "text": " Top filter, errors, level, warning.",
        "tokens": [
          50614,
          8840,
          6608,
          11,
          13603,
          11,
          1496,
          11,
          9164,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19616810306087956,
        "compression_ratio": 1.4275862068965517,
        "end": 661.36,
        "id": 229,
        "no_speech_prob": 0.010316010564565659,
        "seek": 65236,
        "start": 660.36,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50764,
          2264,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19616810306087956,
        "compression_ratio": 1.4275862068965517,
        "end": 662.36,
        "id": 230,
        "no_speech_prob": 0.010316010564565659,
        "seek": 65236,
        "start": 661.36,
        "temperature": 0,
        "text": " So it must be.",
        "tokens": [
          50814,
          407,
          309,
          1633,
          312,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19616810306087956,
        "compression_ratio": 1.4275862068965517,
        "end": 665.36,
        "id": 231,
        "no_speech_prob": 0.010316010564565659,
        "seek": 65236,
        "start": 662.36,
        "temperature": 0,
        "text": " Oh, I just don't see it here.",
        "tokens": [
          50864,
          876,
          11,
          286,
          445,
          500,
          380,
          536,
          309,
          510,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19616810306087956,
        "compression_ratio": 1.4275862068965517,
        "end": 668.36,
        "id": 232,
        "no_speech_prob": 0.010316010564565659,
        "seek": 65236,
        "start": 665.36,
        "temperature": 0,
        "text": " Because.",
        "tokens": [
          51014,
          1436,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19616810306087956,
        "compression_ratio": 1.4275862068965517,
        "end": 670.36,
        "id": 233,
        "no_speech_prob": 0.010316010564565659,
        "seek": 65236,
        "start": 668.36,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51164,
          821,
          321,
          352,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19616810306087956,
        "compression_ratio": 1.4275862068965517,
        "end": 671.36,
        "id": 234,
        "no_speech_prob": 0.010316010564565659,
        "seek": 65236,
        "start": 670.36,
        "temperature": 0,
        "text": " So let's.",
        "tokens": [
          51264,
          407,
          718,
          311,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19616810306087956,
        "compression_ratio": 1.4275862068965517,
        "end": 672.36,
        "id": 235,
        "no_speech_prob": 0.010316010564565659,
        "seek": 65236,
        "start": 671.36,
        "temperature": 0,
        "text": " Ah.",
        "tokens": [
          51314,
          2438,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19616810306087956,
        "compression_ratio": 1.4275862068965517,
        "end": 673.36,
        "id": 236,
        "no_speech_prob": 0.010316010564565659,
        "seek": 65236,
        "start": 672.36,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51364,
          821,
          321,
          352,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19616810306087956,
        "compression_ratio": 1.4275862068965517,
        "end": 674.36,
        "id": 237,
        "no_speech_prob": 0.010316010564565659,
        "seek": 65236,
        "start": 673.36,
        "temperature": 0,
        "text": " There it is.",
        "tokens": [
          51414,
          821,
          309,
          307,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19616810306087956,
        "compression_ratio": 1.4275862068965517,
        "end": 675.36,
        "id": 238,
        "no_speech_prob": 0.010316010564565659,
        "seek": 65236,
        "start": 674.36,
        "temperature": 0,
        "text": " Got that.",
        "tokens": [
          51464,
          5803,
          300,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19616810306087956,
        "compression_ratio": 1.4275862068965517,
        "end": 681.36,
        "id": 239,
        "no_speech_prob": 0.010316010564565659,
        "seek": 65236,
        "start": 680.36,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51764,
          2264,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.20562521616617838,
        "compression_ratio": 1.3624161073825503,
        "end": 683.36,
        "id": 240,
        "no_speech_prob": 0.004133427515625954,
        "seek": 68136,
        "start": 681.36,
        "temperature": 0,
        "text": " The mic quality is perfect now.",
        "tokens": [
          50364,
          440,
          3123,
          3125,
          307,
          2176,
          586,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.20562521616617838,
        "compression_ratio": 1.3624161073825503,
        "end": 684.36,
        "id": 241,
        "no_speech_prob": 0.004133427515625954,
        "seek": 68136,
        "start": 683.36,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50464,
          2264,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.20562521616617838,
        "compression_ratio": 1.3624161073825503,
        "end": 686.36,
        "id": 242,
        "no_speech_prob": 0.004133427515625954,
        "seek": 68136,
        "start": 684.36,
        "temperature": 0,
        "text": " Apologies to everyone, but just because there were some mic",
        "tokens": [
          50514,
          8723,
          6204,
          281,
          1518,
          11,
          457,
          445,
          570,
          456,
          645,
          512,
          3123,
          50614
        ]
      },
      {
        "avg_logprob": -0.20562521616617838,
        "compression_ratio": 1.3624161073825503,
        "end": 689.36,
        "id": 243,
        "no_speech_prob": 0.004133427515625954,
        "seek": 68136,
        "start": 686.36,
        "temperature": 0,
        "text": " issues, I'm going to start over.",
        "tokens": [
          50614,
          2663,
          11,
          286,
          478,
          516,
          281,
          722,
          670,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20562521616617838,
        "compression_ratio": 1.3624161073825503,
        "end": 692.36,
        "id": 244,
        "no_speech_prob": 0.004133427515625954,
        "seek": 68136,
        "start": 691.36,
        "temperature": 0,
        "text": " And.",
        "tokens": [
          50864,
          400,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20562521616617838,
        "compression_ratio": 1.3624161073825503,
        "end": 702.36,
        "id": 245,
        "no_speech_prob": 0.004133427515625954,
        "seek": 68136,
        "start": 699.36,
        "temperature": 0,
        "text": " So I'm actually going to do this.",
        "tokens": [
          51264,
          407,
          286,
          478,
          767,
          516,
          281,
          360,
          341,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20562521616617838,
        "compression_ratio": 1.3624161073825503,
        "end": 705.36,
        "id": 246,
        "no_speech_prob": 0.004133427515625954,
        "seek": 68136,
        "start": 702.36,
        "temperature": 0,
        "text": " And go back to here.",
        "tokens": [
          51414,
          400,
          352,
          646,
          281,
          510,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20562521616617838,
        "compression_ratio": 1.3624161073825503,
        "end": 706.36,
        "id": 247,
        "no_speech_prob": 0.004133427515625954,
        "seek": 68136,
        "start": 705.36,
        "temperature": 0,
        "text": " Take this out.",
        "tokens": [
          51564,
          3664,
          341,
          484,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2385676520211356,
        "compression_ratio": 1.3614457831325302,
        "end": 707.36,
        "id": 248,
        "no_speech_prob": 0.000245349743636325,
        "seek": 70636,
        "start": 706.36,
        "temperature": 0.2,
        "text": " Take this out.",
        "tokens": [
          50364,
          3664,
          341,
          484,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.2385676520211356,
        "compression_ratio": 1.3614457831325302,
        "end": 713.36,
        "id": 249,
        "no_speech_prob": 0.000245349743636325,
        "seek": 70636,
        "start": 710.36,
        "temperature": 0.2,
        "text": " And refresh.",
        "tokens": [
          50564,
          400,
          15134,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2385676520211356,
        "compression_ratio": 1.3614457831325302,
        "end": 714.36,
        "id": 250,
        "no_speech_prob": 0.000245349743636325,
        "seek": 70636,
        "start": 713.36,
        "temperature": 0.2,
        "text": " OK.",
        "tokens": [
          50714,
          2264,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2385676520211356,
        "compression_ratio": 1.3614457831325302,
        "end": 716.36,
        "id": 251,
        "no_speech_prob": 0.000245349743636325,
        "seek": 70636,
        "start": 714.36,
        "temperature": 0.2,
        "text": " All right, here we go, everybody.",
        "tokens": [
          50764,
          1057,
          558,
          11,
          510,
          321,
          352,
          11,
          2201,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2385676520211356,
        "compression_ratio": 1.3614457831325302,
        "end": 727.36,
        "id": 252,
        "no_speech_prob": 0.000245349743636325,
        "seek": 70636,
        "start": 723.36,
        "temperature": 0.2,
        "text": " So I realize that some of you watching might not have actually",
        "tokens": [
          51214,
          407,
          286,
          4325,
          300,
          512,
          295,
          291,
          1976,
          1062,
          406,
          362,
          767,
          51414
        ]
      },
      {
        "avg_logprob": -0.2385676520211356,
        "compression_ratio": 1.3614457831325302,
        "end": 729.36,
        "id": 253,
        "no_speech_prob": 0.000245349743636325,
        "seek": 70636,
        "start": 727.36,
        "temperature": 0.2,
        "text": " gone through this video tutorial.",
        "tokens": [
          51414,
          2780,
          807,
          341,
          960,
          7073,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2385676520211356,
        "compression_ratio": 1.3614457831325302,
        "end": 732.36,
        "id": 254,
        "no_speech_prob": 0.000245349743636325,
        "seek": 70636,
        "start": 729.36,
        "temperature": 0.2,
        "text": " The idea of ML5 might be totally new to you.",
        "tokens": [
          51514,
          440,
          1558,
          295,
          21601,
          20,
          1062,
          312,
          3879,
          777,
          281,
          291,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2385676520211356,
        "compression_ratio": 1.3614457831325302,
        "end": 733.36,
        "id": 255,
        "no_speech_prob": 0.000245349743636325,
        "seek": 70636,
        "start": 732.36,
        "temperature": 0.2,
        "text": " Just very briefly.",
        "tokens": [
          51664,
          1449,
          588,
          10515,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20322395960489908,
        "compression_ratio": 1.6943396226415095,
        "end": 738.36,
        "id": 256,
        "no_speech_prob": 0.02843361347913742,
        "seek": 73336,
        "start": 733.36,
        "temperature": 0,
        "text": " ML5 is a beginner-friendly JavaScript library for machine learning.",
        "tokens": [
          50364,
          21601,
          20,
          307,
          257,
          22080,
          12,
          22864,
          15778,
          6405,
          337,
          3479,
          2539,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20322395960489908,
        "compression_ratio": 1.6943396226415095,
        "end": 741.36,
        "id": 257,
        "no_speech_prob": 0.02843361347913742,
        "seek": 73336,
        "start": 738.36,
        "temperature": 0,
        "text": " It's built on top of TensorFlow.js, which is an open-source machine",
        "tokens": [
          50614,
          467,
          311,
          3094,
          322,
          1192,
          295,
          37624,
          13,
          25530,
          11,
          597,
          307,
          364,
          1269,
          12,
          41676,
          3479,
          50764
        ]
      },
      {
        "avg_logprob": -0.20322395960489908,
        "compression_ratio": 1.6943396226415095,
        "end": 744.36,
        "id": 258,
        "no_speech_prob": 0.02843361347913742,
        "seek": 73336,
        "start": 741.36,
        "temperature": 0,
        "text": " learning library made by Google.",
        "tokens": [
          50764,
          2539,
          6405,
          1027,
          538,
          3329,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20322395960489908,
        "compression_ratio": 1.6943396226415095,
        "end": 748.36,
        "id": 259,
        "no_speech_prob": 0.02843361347913742,
        "seek": 73336,
        "start": 744.36,
        "temperature": 0,
        "text": " TensorFlow.js is a JavaScript port of TensorFlow, which is C++ and",
        "tokens": [
          50914,
          37624,
          13,
          25530,
          307,
          257,
          15778,
          2436,
          295,
          37624,
          11,
          597,
          307,
          383,
          25472,
          293,
          51114
        ]
      },
      {
        "avg_logprob": -0.20322395960489908,
        "compression_ratio": 1.6943396226415095,
        "end": 752.36,
        "id": 260,
        "no_speech_prob": 0.02843361347913742,
        "seek": 73336,
        "start": 748.36,
        "temperature": 0,
        "text": " Python, and that's about as far as I'm willing to go with that right",
        "tokens": [
          51114,
          15329,
          11,
          293,
          300,
          311,
          466,
          382,
          1400,
          382,
          286,
          478,
          4950,
          281,
          352,
          365,
          300,
          558,
          51314
        ]
      },
      {
        "avg_logprob": -0.20322395960489908,
        "compression_ratio": 1.6943396226415095,
        "end": 754.36,
        "id": 261,
        "no_speech_prob": 0.02843361347913742,
        "seek": 73336,
        "start": 752.36,
        "temperature": 0,
        "text": " now.",
        "tokens": [
          51314,
          586,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20322395960489908,
        "compression_ratio": 1.6943396226415095,
        "end": 758.36,
        "id": 262,
        "no_speech_prob": 0.02843361347913742,
        "seek": 73336,
        "start": 754.36,
        "temperature": 0,
        "text": " And this series explains how image classification works with a",
        "tokens": [
          51414,
          400,
          341,
          2638,
          13948,
          577,
          3256,
          21538,
          1985,
          365,
          257,
          51614
        ]
      },
      {
        "avg_logprob": -0.20322395960489908,
        "compression_ratio": 1.6943396226415095,
        "end": 761.36,
        "id": 263,
        "no_speech_prob": 0.02843361347913742,
        "seek": 73336,
        "start": 758.36,
        "temperature": 0,
        "text": " pre-trained model, and then how you can train your own model on top",
        "tokens": [
          51614,
          659,
          12,
          17227,
          2001,
          2316,
          11,
          293,
          550,
          577,
          291,
          393,
          3847,
          428,
          1065,
          2316,
          322,
          1192,
          51764
        ]
      },
      {
        "avg_logprob": -0.20322395960489908,
        "compression_ratio": 1.6943396226415095,
        "end": 762.36,
        "id": 264,
        "no_speech_prob": 0.02843361347913742,
        "seek": 73336,
        "start": 761.36,
        "temperature": 0,
        "text": " of that.",
        "tokens": [
          51764,
          295,
          300,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2104970863066524,
        "compression_ratio": 1.472636815920398,
        "end": 765.36,
        "id": 265,
        "no_speech_prob": 0.00007602374535053968,
        "seek": 76236,
        "start": 762.36,
        "temperature": 0,
        "text": " So that's where I left off, but you could never save it.",
        "tokens": [
          50364,
          407,
          300,
          311,
          689,
          286,
          1411,
          766,
          11,
          457,
          291,
          727,
          1128,
          3155,
          309,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2104970863066524,
        "compression_ratio": 1.472636815920398,
        "end": 767.36,
        "id": 266,
        "no_speech_prob": 0.00007602374535053968,
        "seek": 76236,
        "start": 765.36,
        "temperature": 0,
        "text": " So now, here we are.",
        "tokens": [
          50514,
          407,
          586,
          11,
          510,
          321,
          366,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2104970863066524,
        "compression_ratio": 1.472636815920398,
        "end": 780.36,
        "id": 267,
        "no_speech_prob": 0.00007602374535053968,
        "seek": 76236,
        "start": 776.36,
        "temperature": 0,
        "text": " Hello, and welcome to another beginner's guide to machine learning",
        "tokens": [
          51064,
          2425,
          11,
          293,
          2928,
          281,
          1071,
          22080,
          311,
          5934,
          281,
          3479,
          2539,
          51264
        ]
      },
      {
        "avg_logprob": -0.2104970863066524,
        "compression_ratio": 1.472636815920398,
        "end": 782.36,
        "id": 268,
        "no_speech_prob": 0.00007602374535053968,
        "seek": 76236,
        "start": 780.36,
        "temperature": 0,
        "text": " with ML5.js video.",
        "tokens": [
          51264,
          365,
          21601,
          20,
          13,
          25530,
          960,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2104970863066524,
        "compression_ratio": 1.472636815920398,
        "end": 786.36,
        "id": 269,
        "no_speech_prob": 0.00007602374535053968,
        "seek": 76236,
        "start": 782.36,
        "temperature": 0,
        "text": " Now, in this video, something very exciting is going to happen.",
        "tokens": [
          51364,
          823,
          11,
          294,
          341,
          960,
          11,
          746,
          588,
          4670,
          307,
          516,
          281,
          1051,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2104970863066524,
        "compression_ratio": 1.472636815920398,
        "end": 789.36,
        "id": 270,
        "no_speech_prob": 0.00007602374535053968,
        "seek": 76236,
        "start": 786.36,
        "temperature": 0,
        "text": " If you happened to watch all the previous videos a while ago and you",
        "tokens": [
          51564,
          759,
          291,
          2011,
          281,
          1159,
          439,
          264,
          3894,
          2145,
          257,
          1339,
          2057,
          293,
          291,
          51714
        ]
      },
      {
        "avg_logprob": -0.17897344190020895,
        "compression_ratio": 1.6770833333333333,
        "end": 793.36,
        "id": 271,
        "no_speech_prob": 0.010327746160328388,
        "seek": 78936,
        "start": 789.36,
        "temperature": 0,
        "text": " discovered this one new, a new feature has been added to ML5, the",
        "tokens": [
          50364,
          6941,
          341,
          472,
          777,
          11,
          257,
          777,
          4111,
          575,
          668,
          3869,
          281,
          21601,
          20,
          11,
          264,
          50564
        ]
      },
      {
        "avg_logprob": -0.17897344190020895,
        "compression_ratio": 1.6770833333333333,
        "end": 796.36,
        "id": 272,
        "no_speech_prob": 0.010327746160328388,
        "seek": 78936,
        "start": 793.36,
        "temperature": 0,
        "text": " save-load feature extractor with ML5 specs.",
        "tokens": [
          50564,
          3155,
          12,
          2907,
          4111,
          8947,
          284,
          365,
          21601,
          20,
          27911,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.17897344190020895,
        "compression_ratio": 1.6770833333333333,
        "end": 799.36,
        "id": 273,
        "no_speech_prob": 0.010327746160328388,
        "seek": 78936,
        "start": 796.36,
        "temperature": 0,
        "text": " So you can find the pull request here if you want to see more about",
        "tokens": [
          50714,
          407,
          291,
          393,
          915,
          264,
          2235,
          5308,
          510,
          498,
          291,
          528,
          281,
          536,
          544,
          466,
          50864
        ]
      },
      {
        "avg_logprob": -0.17897344190020895,
        "compression_ratio": 1.6770833333333333,
        "end": 801.36,
        "id": 274,
        "no_speech_prob": 0.010327746160328388,
        "seek": 78936,
        "start": 799.36,
        "temperature": 0,
        "text": " how that was implemented.",
        "tokens": [
          50864,
          577,
          300,
          390,
          12270,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.17897344190020895,
        "compression_ratio": 1.6770833333333333,
        "end": 804.36,
        "id": 275,
        "no_speech_prob": 0.010327746160328388,
        "seek": 78936,
        "start": 801.36,
        "temperature": 0,
        "text": " But the point of that is the following.",
        "tokens": [
          50964,
          583,
          264,
          935,
          295,
          300,
          307,
          264,
          3480,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17897344190020895,
        "compression_ratio": 1.6770833333333333,
        "end": 806.36,
        "id": 276,
        "no_speech_prob": 0.010327746160328388,
        "seek": 78936,
        "start": 804.36,
        "temperature": 0,
        "text": " Where I left off was this example.",
        "tokens": [
          51114,
          2305,
          286,
          1411,
          766,
          390,
          341,
          1365,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17897344190020895,
        "compression_ratio": 1.6770833333333333,
        "end": 810.36,
        "id": 277,
        "no_speech_prob": 0.010327746160328388,
        "seek": 78936,
        "start": 806.36,
        "temperature": 0,
        "text": " This is an example that loads a pre-trained image classifier called",
        "tokens": [
          51214,
          639,
          307,
          364,
          1365,
          300,
          12668,
          257,
          659,
          12,
          17227,
          2001,
          3256,
          1508,
          9902,
          1219,
          51414
        ]
      },
      {
        "avg_logprob": -0.17897344190020895,
        "compression_ratio": 1.6770833333333333,
        "end": 813.36,
        "id": 278,
        "no_speech_prob": 0.010327746160328388,
        "seek": 78936,
        "start": 810.36,
        "temperature": 0,
        "text": " MobileNet, something that was trained by somebody else, explained in",
        "tokens": [
          51414,
          22625,
          31890,
          11,
          746,
          300,
          390,
          8895,
          538,
          2618,
          1646,
          11,
          8825,
          294,
          51564
        ]
      },
      {
        "avg_logprob": -0.17897344190020895,
        "compression_ratio": 1.6770833333333333,
        "end": 818.36,
        "id": 279,
        "no_speech_prob": 0.010327746160328388,
        "seek": 78936,
        "start": 813.36,
        "temperature": 0,
        "text": " my previous videos, and allows the user, allows the coder, to use a",
        "tokens": [
          51564,
          452,
          3894,
          2145,
          11,
          293,
          4045,
          264,
          4195,
          11,
          4045,
          264,
          17656,
          260,
          11,
          281,
          764,
          257,
          51814
        ]
      },
      {
        "avg_logprob": -0.25487755755988917,
        "compression_ratio": 1.6331877729257642,
        "end": 823.36,
        "id": 280,
        "no_speech_prob": 0.0027148902881890535,
        "seek": 81836,
        "start": 818.36,
        "temperature": 0,
        "text": " process known as transfer learning to extract the features from the,",
        "tokens": [
          50364,
          1399,
          2570,
          382,
          5003,
          2539,
          281,
          8947,
          264,
          4122,
          490,
          264,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.25487755755988917,
        "compression_ratio": 1.6331877729257642,
        "end": 827.36,
        "id": 281,
        "no_speech_prob": 0.0027148902881890535,
        "seek": 81836,
        "start": 823.36,
        "temperature": 0,
        "text": " that the model detects in an image and reassign them to new labels.",
        "tokens": [
          50614,
          300,
          264,
          2316,
          5531,
          82,
          294,
          364,
          3256,
          293,
          19486,
          788,
          552,
          281,
          777,
          16949,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.25487755755988917,
        "compression_ratio": 1.6331877729257642,
        "end": 832.36,
        "id": 282,
        "no_speech_prob": 0.0027148902881890535,
        "seek": 81836,
        "start": 827.36,
        "temperature": 0,
        "text": " So, for example, I can make a very happy face and click on happy a",
        "tokens": [
          50814,
          407,
          11,
          337,
          1365,
          11,
          286,
          393,
          652,
          257,
          588,
          2055,
          1851,
          293,
          2052,
          322,
          2055,
          257,
          51064
        ]
      },
      {
        "avg_logprob": -0.25487755755988917,
        "compression_ratio": 1.6331877729257642,
        "end": 838.36,
        "id": 283,
        "no_speech_prob": 0.0027148902881890535,
        "seek": 81836,
        "start": 832.36,
        "temperature": 0,
        "text": " bunch of times and wonder why my Mac is showing that weird window.",
        "tokens": [
          51064,
          3840,
          295,
          1413,
          293,
          2441,
          983,
          452,
          5707,
          307,
          4099,
          300,
          3657,
          4910,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.25487755755988917,
        "compression_ratio": 1.6331877729257642,
        "end": 843.36,
        "id": 284,
        "no_speech_prob": 0.0027148902881890535,
        "seek": 81836,
        "start": 838.36,
        "temperature": 0,
        "text": " And then I could have said a bunch of times and then click train, and",
        "tokens": [
          51364,
          400,
          550,
          286,
          727,
          362,
          848,
          257,
          3840,
          295,
          1413,
          293,
          550,
          2052,
          3847,
          11,
          293,
          51614
        ]
      },
      {
        "avg_logprob": -0.25487755755988917,
        "compression_ratio": 1.6331877729257642,
        "end": 845.36,
        "id": 285,
        "no_speech_prob": 0.0027148902881890535,
        "seek": 81836,
        "start": 843.36,
        "temperature": 0,
        "text": " now we have to wait for a minute.",
        "tokens": [
          51614,
          586,
          321,
          362,
          281,
          1699,
          337,
          257,
          3456,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.21084346586060757,
        "compression_ratio": 1.6287128712871286,
        "end": 848.36,
        "id": 286,
        "no_speech_prob": 0.006289714481681585,
        "seek": 84536,
        "start": 845.36,
        "temperature": 0,
        "text": " We always blow the train whistle for train.",
        "tokens": [
          50364,
          492,
          1009,
          6327,
          264,
          3847,
          23470,
          337,
          3847,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.21084346586060757,
        "compression_ratio": 1.6287128712871286,
        "end": 850.36,
        "id": 287,
        "no_speech_prob": 0.006289714481681585,
        "seek": 84536,
        "start": 848.36,
        "temperature": 0,
        "text": " And now the training is complete.",
        "tokens": [
          50514,
          400,
          586,
          264,
          3097,
          307,
          3566,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.21084346586060757,
        "compression_ratio": 1.6287128712871286,
        "end": 855.36,
        "id": 288,
        "no_speech_prob": 0.006289714481681585,
        "seek": 84536,
        "start": 850.36,
        "temperature": 0,
        "text": " And I go, hi.",
        "tokens": [
          50614,
          400,
          286,
          352,
          11,
          4879,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.21084346586060757,
        "compression_ratio": 1.6287128712871286,
        "end": 856.36,
        "id": 289,
        "no_speech_prob": 0.006289714481681585,
        "seek": 84536,
        "start": 855.36,
        "temperature": 0,
        "text": " Let me go back and do this again.",
        "tokens": [
          50864,
          961,
          385,
          352,
          646,
          293,
          360,
          341,
          797,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.21084346586060757,
        "compression_ratio": 1.6287128712871286,
        "end": 860.36,
        "id": 290,
        "no_speech_prob": 0.006289714481681585,
        "seek": 84536,
        "start": 856.36,
        "temperature": 0,
        "text": " It's really bothering me that this clicking on this is like, was",
        "tokens": [
          50914,
          467,
          311,
          534,
          31432,
          385,
          300,
          341,
          9697,
          322,
          341,
          307,
          411,
          11,
          390,
          51114
        ]
      },
      {
        "avg_logprob": -0.21084346586060757,
        "compression_ratio": 1.6287128712871286,
        "end": 861.36,
        "id": 291,
        "no_speech_prob": 0.006289714481681585,
        "seek": 84536,
        "start": 860.36,
        "temperature": 0,
        "text": " pulling that thing up.",
        "tokens": [
          51114,
          8407,
          300,
          551,
          493,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.21084346586060757,
        "compression_ratio": 1.6287128712871286,
        "end": 863.36,
        "id": 292,
        "no_speech_prob": 0.006289714481681585,
        "seek": 84536,
        "start": 861.36,
        "temperature": 0,
        "text": " It's because I'm selecting the text.",
        "tokens": [
          51164,
          467,
          311,
          570,
          286,
          478,
          18182,
          264,
          2487,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.21084346586060757,
        "compression_ratio": 1.6287128712871286,
        "end": 866.36,
        "id": 293,
        "no_speech_prob": 0.006289714481681585,
        "seek": 84536,
        "start": 863.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51264,
          1057,
          558,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.21084346586060757,
        "compression_ratio": 1.6287128712871286,
        "end": 870.36,
        "id": 294,
        "no_speech_prob": 0.006289714481681585,
        "seek": 84536,
        "start": 866.36,
        "temperature": 0,
        "text": " I'm going to get this.",
        "tokens": [
          51414,
          286,
          478,
          516,
          281,
          483,
          341,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.21084346586060757,
        "compression_ratio": 1.6287128712871286,
        "end": 872.36,
        "id": 295,
        "no_speech_prob": 0.006289714481681585,
        "seek": 84536,
        "start": 870.36,
        "temperature": 0,
        "text": " And I'm kind of standing in front of it too.",
        "tokens": [
          51614,
          400,
          286,
          478,
          733,
          295,
          4877,
          294,
          1868,
          295,
          309,
          886,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2442827648586697,
        "compression_ratio": 1.6009852216748768,
        "end": 877.36,
        "id": 296,
        "no_speech_prob": 0.0022872008848935366,
        "seek": 87236,
        "start": 872.36,
        "temperature": 0,
        "text": " So, with this example, I can make a happy face and click happy.",
        "tokens": [
          50364,
          407,
          11,
          365,
          341,
          1365,
          11,
          286,
          393,
          652,
          257,
          2055,
          1851,
          293,
          2052,
          2055,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2442827648586697,
        "compression_ratio": 1.6009852216748768,
        "end": 881.36,
        "id": 297,
        "no_speech_prob": 0.0022872008848935366,
        "seek": 87236,
        "start": 877.36,
        "temperature": 0,
        "text": " This is me giving it a bunch of examples of me being happy.",
        "tokens": [
          50614,
          639,
          307,
          385,
          2902,
          309,
          257,
          3840,
          295,
          5110,
          295,
          385,
          885,
          2055,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2442827648586697,
        "compression_ratio": 1.6009852216748768,
        "end": 886.36,
        "id": 298,
        "no_speech_prob": 0.0022872008848935366,
        "seek": 87236,
        "start": 881.36,
        "temperature": 0,
        "text": " And then, sad.",
        "tokens": [
          50814,
          400,
          550,
          11,
          4227,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2442827648586697,
        "compression_ratio": 1.6009852216748768,
        "end": 889.36,
        "id": 299,
        "no_speech_prob": 0.0022872008848935366,
        "seek": 87236,
        "start": 886.36,
        "temperature": 0,
        "text": " Now I can press the train button.",
        "tokens": [
          51064,
          823,
          286,
          393,
          1886,
          264,
          3847,
          2960,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2442827648586697,
        "compression_ratio": 1.6009852216748768,
        "end": 891.36,
        "id": 300,
        "no_speech_prob": 0.0022872008848935366,
        "seek": 87236,
        "start": 889.36,
        "temperature": 0,
        "text": " It is training.",
        "tokens": [
          51214,
          467,
          307,
          3097,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2442827648586697,
        "compression_ratio": 1.6009852216748768,
        "end": 895.36,
        "id": 301,
        "no_speech_prob": 0.0022872008848935366,
        "seek": 87236,
        "start": 891.36,
        "temperature": 0,
        "text": " And now that it has finished training, it will recognize, it will",
        "tokens": [
          51314,
          400,
          586,
          300,
          309,
          575,
          4335,
          3097,
          11,
          309,
          486,
          5521,
          11,
          309,
          486,
          51514
        ]
      },
      {
        "avg_logprob": -0.2442827648586697,
        "compression_ratio": 1.6009852216748768,
        "end": 899.36,
        "id": 302,
        "no_speech_prob": 0.0022872008848935366,
        "seek": 87236,
        "start": 895.36,
        "temperature": 0,
        "text": " determine if the webcam is showing an image that looks more like happy",
        "tokens": [
          51514,
          6997,
          498,
          264,
          39490,
          307,
          4099,
          364,
          3256,
          300,
          1542,
          544,
          411,
          2055,
          51714
        ]
      },
      {
        "avg_logprob": -0.1902144295828683,
        "compression_ratio": 1.6967213114754098,
        "end": 902.36,
        "id": 303,
        "no_speech_prob": 0.009412206709384918,
        "seek": 89936,
        "start": 899.36,
        "temperature": 0,
        "text": " or sad.",
        "tokens": [
          50364,
          420,
          4227,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1902144295828683,
        "compression_ratio": 1.6967213114754098,
        "end": 903.36,
        "id": 304,
        "no_speech_prob": 0.009412206709384918,
        "seek": 89936,
        "start": 902.36,
        "temperature": 0,
        "text": " Happy.",
        "tokens": [
          50514,
          8277,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1902144295828683,
        "compression_ratio": 1.6967213114754098,
        "end": 905.36,
        "id": 305,
        "no_speech_prob": 0.009412206709384918,
        "seek": 89936,
        "start": 903.36,
        "temperature": 0,
        "text": " Good.",
        "tokens": [
          50564,
          2205,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1902144295828683,
        "compression_ratio": 1.6967213114754098,
        "end": 906.36,
        "id": 306,
        "no_speech_prob": 0.009412206709384918,
        "seek": 89936,
        "start": 905.36,
        "temperature": 0,
        "text": " Happy.",
        "tokens": [
          50664,
          8277,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1902144295828683,
        "compression_ratio": 1.6967213114754098,
        "end": 907.36,
        "id": 307,
        "no_speech_prob": 0.009412206709384918,
        "seek": 89936,
        "start": 906.36,
        "temperature": 0,
        "text": " Good.",
        "tokens": [
          50714,
          2205,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1902144295828683,
        "compression_ratio": 1.6967213114754098,
        "end": 908.36,
        "id": 308,
        "no_speech_prob": 0.009412206709384918,
        "seek": 89936,
        "start": 907.36,
        "temperature": 0,
        "text": " Happy.",
        "tokens": [
          50764,
          8277,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1902144295828683,
        "compression_ratio": 1.6967213114754098,
        "end": 909.36,
        "id": 309,
        "no_speech_prob": 0.009412206709384918,
        "seek": 89936,
        "start": 908.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50814,
          1033,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1902144295828683,
        "compression_ratio": 1.6967213114754098,
        "end": 911.36,
        "id": 310,
        "no_speech_prob": 0.009412206709384918,
        "seek": 89936,
        "start": 909.36,
        "temperature": 0,
        "text": " So, that's what the example did before.",
        "tokens": [
          50864,
          407,
          11,
          300,
          311,
          437,
          264,
          1365,
          630,
          949,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1902144295828683,
        "compression_ratio": 1.6967213114754098,
        "end": 915.36,
        "id": 311,
        "no_speech_prob": 0.009412206709384918,
        "seek": 89936,
        "start": 911.36,
        "temperature": 0,
        "text": " If you're still watching, what the problem with this example is, if I",
        "tokens": [
          50964,
          759,
          291,
          434,
          920,
          1976,
          11,
          437,
          264,
          1154,
          365,
          341,
          1365,
          307,
          11,
          498,
          286,
          51164
        ]
      },
      {
        "avg_logprob": -0.1902144295828683,
        "compression_ratio": 1.6967213114754098,
        "end": 917.36,
        "id": 312,
        "no_speech_prob": 0.009412206709384918,
        "seek": 89936,
        "start": 915.36,
        "temperature": 0,
        "text": " hit refresh, it's gone.",
        "tokens": [
          51164,
          2045,
          15134,
          11,
          309,
          311,
          2780,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1902144295828683,
        "compression_ratio": 1.6967213114754098,
        "end": 919.36,
        "id": 313,
        "no_speech_prob": 0.009412206709384918,
        "seek": 89936,
        "start": 917.36,
        "temperature": 0,
        "text": " It needs to be trained again.",
        "tokens": [
          51264,
          467,
          2203,
          281,
          312,
          8895,
          797,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1902144295828683,
        "compression_ratio": 1.6967213114754098,
        "end": 922.36,
        "id": 314,
        "no_speech_prob": 0.009412206709384918,
        "seek": 89936,
        "start": 919.36,
        "temperature": 0,
        "text": " So, what I want to show in this video, and boy, it's taking me a long",
        "tokens": [
          51364,
          407,
          11,
          437,
          286,
          528,
          281,
          855,
          294,
          341,
          960,
          11,
          293,
          3237,
          11,
          309,
          311,
          1940,
          385,
          257,
          938,
          51514
        ]
      },
      {
        "avg_logprob": -0.1902144295828683,
        "compression_ratio": 1.6967213114754098,
        "end": 924.36,
        "id": 315,
        "no_speech_prob": 0.009412206709384918,
        "seek": 89936,
        "start": 922.36,
        "temperature": 0,
        "text": " time to get to it, is how to save.",
        "tokens": [
          51514,
          565,
          281,
          483,
          281,
          309,
          11,
          307,
          577,
          281,
          3155,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1902144295828683,
        "compression_ratio": 1.6967213114754098,
        "end": 926.36,
        "id": 316,
        "no_speech_prob": 0.009412206709384918,
        "seek": 89936,
        "start": 924.36,
        "temperature": 0,
        "text": " And really, there's just two functions we're going to add here.",
        "tokens": [
          51614,
          400,
          534,
          11,
          456,
          311,
          445,
          732,
          6828,
          321,
          434,
          516,
          281,
          909,
          510,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1902144295828683,
        "compression_ratio": 1.6967213114754098,
        "end": 928.36,
        "id": 317,
        "no_speech_prob": 0.009412206709384918,
        "seek": 89936,
        "start": 926.36,
        "temperature": 0,
        "text": " Save function and a load function.",
        "tokens": [
          51714,
          15541,
          2445,
          293,
          257,
          3677,
          2445,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.24558170258052767,
        "compression_ratio": 1.7376425855513309,
        "end": 931.36,
        "id": 318,
        "no_speech_prob": 0.09137218445539474,
        "seek": 92836,
        "start": 928.36,
        "temperature": 0,
        "text": " So, I'm going to take the load from before, and I'm going to go into",
        "tokens": [
          50364,
          407,
          11,
          286,
          478,
          516,
          281,
          747,
          264,
          3677,
          490,
          949,
          11,
          293,
          286,
          478,
          516,
          281,
          352,
          666,
          50514
        ]
      },
      {
        "avg_logprob": -0.24558170258052767,
        "compression_ratio": 1.7376425855513309,
        "end": 934.36,
        "id": 319,
        "no_speech_prob": 0.09137218445539474,
        "seek": 92836,
        "start": 931.36,
        "temperature": 0,
        "text": " setup, and this is where I made the buttons for sad and happy and",
        "tokens": [
          50514,
          8657,
          11,
          293,
          341,
          307,
          689,
          286,
          1027,
          264,
          9905,
          337,
          4227,
          293,
          2055,
          293,
          50664
        ]
      },
      {
        "avg_logprob": -0.24558170258052767,
        "compression_ratio": 1.7376425855513309,
        "end": 936.36,
        "id": 320,
        "no_speech_prob": 0.09137218445539474,
        "seek": 92836,
        "start": 934.36,
        "temperature": 0,
        "text": " train.",
        "tokens": [
          50664,
          3847,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.24558170258052767,
        "compression_ratio": 1.7376425855513309,
        "end": 938.36,
        "id": 321,
        "no_speech_prob": 0.09137218445539474,
        "seek": 92836,
        "start": 936.36,
        "temperature": 0,
        "text": " I gave them weird variable names, which don't have any meaning",
        "tokens": [
          50764,
          286,
          2729,
          552,
          3657,
          7006,
          5288,
          11,
          597,
          500,
          380,
          362,
          604,
          3620,
          50864
        ]
      },
      {
        "avg_logprob": -0.24558170258052767,
        "compression_ratio": 1.7376425855513309,
        "end": 941.36,
        "id": 322,
        "no_speech_prob": 0.09137218445539474,
        "seek": 92836,
        "start": 938.36,
        "temperature": 0,
        "text": " anymore, but I'm going to make a new button called save button",
        "tokens": [
          50864,
          3602,
          11,
          457,
          286,
          478,
          516,
          281,
          652,
          257,
          777,
          2960,
          1219,
          3155,
          2960,
          51014
        ]
      },
      {
        "avg_logprob": -0.24558170258052767,
        "compression_ratio": 1.7376425855513309,
        "end": 943.36,
        "id": 323,
        "no_speech_prob": 0.09137218445539474,
        "seek": 92836,
        "start": 941.36,
        "temperature": 0,
        "text": " equals create button.",
        "tokens": [
          51014,
          6915,
          1884,
          2960,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.24558170258052767,
        "compression_ratio": 1.7376425855513309,
        "end": 945.36,
        "id": 324,
        "no_speech_prob": 0.09137218445539474,
        "seek": 92836,
        "start": 943.36,
        "temperature": 0,
        "text": " Save.",
        "tokens": [
          51114,
          15541,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.24558170258052767,
        "compression_ratio": 1.7376425855513309,
        "end": 949.36,
        "id": 325,
        "no_speech_prob": 0.09137218445539474,
        "seek": 92836,
        "start": 945.36,
        "temperature": 0,
        "text": " I guess I should make this a global variable just to be consistent.",
        "tokens": [
          51214,
          286,
          2041,
          286,
          820,
          652,
          341,
          257,
          4338,
          7006,
          445,
          281,
          312,
          8398,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.24558170258052767,
        "compression_ratio": 1.7376425855513309,
        "end": 951.36,
        "id": 326,
        "no_speech_prob": 0.09137218445539474,
        "seek": 92836,
        "start": 949.36,
        "temperature": 0,
        "text": " That might be unnecessary.",
        "tokens": [
          51414,
          663,
          1062,
          312,
          19350,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.24558170258052767,
        "compression_ratio": 1.7376425855513309,
        "end": 957.36,
        "id": 327,
        "no_speech_prob": 0.09137218445539474,
        "seek": 92836,
        "start": 951.36,
        "temperature": 0,
        "text": " And then, I'm going to add a function to handle the event when the",
        "tokens": [
          51514,
          400,
          550,
          11,
          286,
          478,
          516,
          281,
          909,
          257,
          2445,
          281,
          4813,
          264,
          2280,
          562,
          264,
          51814
        ]
      },
      {
        "avg_logprob": -0.17366315515001834,
        "compression_ratio": 2.019083969465649,
        "end": 959.36,
        "id": 328,
        "no_speech_prob": 0.0018675534520298243,
        "seek": 95736,
        "start": 957.36,
        "temperature": 0,
        "text": " save button is pressed.",
        "tokens": [
          50364,
          3155,
          2960,
          307,
          17355,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.17366315515001834,
        "compression_ratio": 2.019083969465649,
        "end": 961.36,
        "id": 329,
        "no_speech_prob": 0.0018675534520298243,
        "seek": 95736,
        "start": 959.36,
        "temperature": 0,
        "text": " So, what do I need to do when the save button is pressed?",
        "tokens": [
          50464,
          407,
          11,
          437,
          360,
          286,
          643,
          281,
          360,
          562,
          264,
          3155,
          2960,
          307,
          17355,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.17366315515001834,
        "compression_ratio": 2.019083969465649,
        "end": 962.36,
        "id": 330,
        "no_speech_prob": 0.0018675534520298243,
        "seek": 95736,
        "start": 961.36,
        "temperature": 0,
        "text": " Guess what?",
        "tokens": [
          50564,
          17795,
          437,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.17366315515001834,
        "compression_ratio": 2.019083969465649,
        "end": 963.36,
        "id": 331,
        "no_speech_prob": 0.0018675534520298243,
        "seek": 95736,
        "start": 962.36,
        "temperature": 0,
        "text": " This is super simple.",
        "tokens": [
          50614,
          639,
          307,
          1687,
          2199,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17366315515001834,
        "compression_ratio": 2.019083969465649,
        "end": 966.36,
        "id": 332,
        "no_speech_prob": 0.0018675534520298243,
        "seek": 95736,
        "start": 963.36,
        "temperature": 0,
        "text": " All I need to do is say classifier.save.",
        "tokens": [
          50664,
          1057,
          286,
          643,
          281,
          360,
          307,
          584,
          1508,
          9902,
          13,
          82,
          946,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.17366315515001834,
        "compression_ratio": 2.019083969465649,
        "end": 968.36,
        "id": 333,
        "no_speech_prob": 0.0018675534520298243,
        "seek": 95736,
        "start": 966.36,
        "temperature": 0,
        "text": " I'm just saying classifier.save.",
        "tokens": [
          50814,
          286,
          478,
          445,
          1566,
          1508,
          9902,
          13,
          82,
          946,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17366315515001834,
        "compression_ratio": 2.019083969465649,
        "end": 969.36,
        "id": 334,
        "no_speech_prob": 0.0018675534520298243,
        "seek": 95736,
        "start": 968.36,
        "temperature": 0,
        "text": " Now, what's going to happen there?",
        "tokens": [
          50914,
          823,
          11,
          437,
          311,
          516,
          281,
          1051,
          456,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.17366315515001834,
        "compression_ratio": 2.019083969465649,
        "end": 970.36,
        "id": 335,
        "no_speech_prob": 0.0018675534520298243,
        "seek": 95736,
        "start": 969.36,
        "temperature": 0,
        "text": " Let's wait and see.",
        "tokens": [
          50964,
          961,
          311,
          1699,
          293,
          536,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17366315515001834,
        "compression_ratio": 2.019083969465649,
        "end": 971.36,
        "id": 336,
        "no_speech_prob": 0.0018675534520298243,
        "seek": 95736,
        "start": 970.36,
        "temperature": 0,
        "text": " So, I'm going to go here.",
        "tokens": [
          51014,
          407,
          11,
          286,
          478,
          516,
          281,
          352,
          510,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17366315515001834,
        "compression_ratio": 2.019083969465649,
        "end": 974.36,
        "id": 337,
        "no_speech_prob": 0.0018675534520298243,
        "seek": 95736,
        "start": 971.36,
        "temperature": 0,
        "text": " I'm going to, oh, look, the save button is there, and I'm going to be",
        "tokens": [
          51064,
          286,
          478,
          516,
          281,
          11,
          1954,
          11,
          574,
          11,
          264,
          3155,
          2960,
          307,
          456,
          11,
          293,
          286,
          478,
          516,
          281,
          312,
          51214
        ]
      },
      {
        "avg_logprob": -0.17366315515001834,
        "compression_ratio": 2.019083969465649,
        "end": 978.36,
        "id": 338,
        "no_speech_prob": 0.0018675534520298243,
        "seek": 95736,
        "start": 974.36,
        "temperature": 0,
        "text": " happy, I'm going to be sad, I'm going to train, and I have to wait",
        "tokens": [
          51214,
          2055,
          11,
          286,
          478,
          516,
          281,
          312,
          4227,
          11,
          286,
          478,
          516,
          281,
          3847,
          11,
          293,
          286,
          362,
          281,
          1699,
          51414
        ]
      },
      {
        "avg_logprob": -0.17366315515001834,
        "compression_ratio": 2.019083969465649,
        "end": 980.36,
        "id": 339,
        "no_speech_prob": 0.0018675534520298243,
        "seek": 95736,
        "start": 978.36,
        "temperature": 0,
        "text": " for it to finish training.",
        "tokens": [
          51414,
          337,
          309,
          281,
          2413,
          3097,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.17366315515001834,
        "compression_ratio": 2.019083969465649,
        "end": 982.36,
        "id": 340,
        "no_speech_prob": 0.0018675534520298243,
        "seek": 95736,
        "start": 980.36,
        "temperature": 0,
        "text": " Once it's done, I'm going to hit save, and guess what?",
        "tokens": [
          51514,
          3443,
          309,
          311,
          1096,
          11,
          286,
          478,
          516,
          281,
          2045,
          3155,
          11,
          293,
          2041,
          437,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.17366315515001834,
        "compression_ratio": 2.019083969465649,
        "end": 984.36,
        "id": 341,
        "no_speech_prob": 0.0018675534520298243,
        "seek": 95736,
        "start": 982.36,
        "temperature": 0,
        "text": " I got an error.",
        "tokens": [
          51614,
          286,
          658,
          364,
          6713,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17366315515001834,
        "compression_ratio": 2.019083969465649,
        "end": 985.36,
        "id": 342,
        "no_speech_prob": 0.0018675534520298243,
        "seek": 95736,
        "start": 984.36,
        "temperature": 0,
        "text": " Save is not a function.",
        "tokens": [
          51714,
          15541,
          307,
          406,
          257,
          2445,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.15396301834671586,
        "compression_ratio": 1.5992063492063493,
        "end": 987.36,
        "id": 343,
        "no_speech_prob": 0.08388582617044449,
        "seek": 98536,
        "start": 985.36,
        "temperature": 0,
        "text": " I left this error happen on purpose.",
        "tokens": [
          50364,
          286,
          1411,
          341,
          6713,
          1051,
          322,
          4334,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.15396301834671586,
        "compression_ratio": 1.5992063492063493,
        "end": 991.36,
        "id": 344,
        "no_speech_prob": 0.08388582617044449,
        "seek": 98536,
        "start": 987.36,
        "temperature": 0,
        "text": " This is a new feature of the ML5 library, and if I go and look into my",
        "tokens": [
          50464,
          639,
          307,
          257,
          777,
          4111,
          295,
          264,
          21601,
          20,
          6405,
          11,
          293,
          498,
          286,
          352,
          293,
          574,
          666,
          452,
          50664
        ]
      },
      {
        "avg_logprob": -0.15396301834671586,
        "compression_ratio": 1.5992063492063493,
        "end": 996.36,
        "id": 345,
        "no_speech_prob": 0.08388582617044449,
        "seek": 98536,
        "start": 991.36,
        "temperature": 0,
        "text": " HTML, I can see I'm using the ML5 library 0.1.1.",
        "tokens": [
          50664,
          17995,
          11,
          286,
          393,
          536,
          286,
          478,
          1228,
          264,
          21601,
          20,
          6405,
          1958,
          13,
          16,
          13,
          16,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.15396301834671586,
        "compression_ratio": 1.5992063492063493,
        "end": 998.36,
        "id": 346,
        "no_speech_prob": 0.08388582617044449,
        "seek": 98536,
        "start": 996.36,
        "temperature": 0,
        "text": " Maybe you're watching this.",
        "tokens": [
          50914,
          2704,
          291,
          434,
          1976,
          341,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.15396301834671586,
        "compression_ratio": 1.5992063492063493,
        "end": 1003.36,
        "id": 347,
        "no_speech_prob": 0.08388582617044449,
        "seek": 98536,
        "start": 998.36,
        "temperature": 0,
        "text": " Maybe it's like right now it's like 9.4.3, and you're in this future",
        "tokens": [
          51014,
          2704,
          309,
          311,
          411,
          558,
          586,
          309,
          311,
          411,
          1722,
          13,
          19,
          13,
          18,
          11,
          293,
          291,
          434,
          294,
          341,
          2027,
          51264
        ]
      },
      {
        "avg_logprob": -0.15396301834671586,
        "compression_ratio": 1.5992063492063493,
        "end": 1008.36,
        "id": 348,
        "no_speech_prob": 0.08388582617044449,
        "seek": 98536,
        "start": 1003.36,
        "temperature": 0,
        "text": " world of ML5, but the current version is 0.1.3.",
        "tokens": [
          51264,
          1002,
          295,
          21601,
          20,
          11,
          457,
          264,
          2190,
          3037,
          307,
          1958,
          13,
          16,
          13,
          18,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.15396301834671586,
        "compression_ratio": 1.5992063492063493,
        "end": 1011.36,
        "id": 349,
        "no_speech_prob": 0.08388582617044449,
        "seek": 98536,
        "start": 1008.36,
        "temperature": 0,
        "text": " So, if I add that, I'm going to hit refresh.",
        "tokens": [
          51514,
          407,
          11,
          498,
          286,
          909,
          300,
          11,
          286,
          478,
          516,
          281,
          2045,
          15134,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.15396301834671586,
        "compression_ratio": 1.5992063492063493,
        "end": 1013.36,
        "id": 350,
        "no_speech_prob": 0.08388582617044449,
        "seek": 98536,
        "start": 1011.36,
        "temperature": 0,
        "text": " Now, I'm going to really try to train a good model here.",
        "tokens": [
          51664,
          823,
          11,
          286,
          478,
          516,
          281,
          534,
          853,
          281,
          3847,
          257,
          665,
          2316,
          510,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17719983246366858,
        "compression_ratio": 1.9166666666666667,
        "end": 1014.36,
        "id": 351,
        "no_speech_prob": 0.0015247755218297243,
        "seek": 101336,
        "start": 1013.36,
        "temperature": 0,
        "text": " So, let's train.",
        "tokens": [
          50364,
          407,
          11,
          718,
          311,
          3847,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.17719983246366858,
        "compression_ratio": 1.9166666666666667,
        "end": 1015.36,
        "id": 352,
        "no_speech_prob": 0.0015247755218297243,
        "seek": 101336,
        "start": 1014.36,
        "temperature": 0,
        "text": " Oh, I don't have the ukulele.",
        "tokens": [
          50414,
          876,
          11,
          286,
          500,
          380,
          362,
          264,
          26769,
          2271,
          306,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.17719983246366858,
        "compression_ratio": 1.9166666666666667,
        "end": 1018.36,
        "id": 353,
        "no_speech_prob": 0.0015247755218297243,
        "seek": 101336,
        "start": 1015.36,
        "temperature": 0,
        "text": " I do have the train whistle.",
        "tokens": [
          50464,
          286,
          360,
          362,
          264,
          3847,
          23470,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.17719983246366858,
        "compression_ratio": 1.9166666666666667,
        "end": 1019.36,
        "id": 354,
        "no_speech_prob": 0.0015247755218297243,
        "seek": 101336,
        "start": 1018.36,
        "temperature": 0,
        "text": " So, I'll just do happy and sad.",
        "tokens": [
          50614,
          407,
          11,
          286,
          603,
          445,
          360,
          2055,
          293,
          4227,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17719983246366858,
        "compression_ratio": 1.9166666666666667,
        "end": 1030.3600000000001,
        "id": 355,
        "no_speech_prob": 0.0015247755218297243,
        "seek": 101336,
        "start": 1019.36,
        "temperature": 0,
        "text": " I'm happy with the train whistle, and I'm very sad with no train whistle.",
        "tokens": [
          50664,
          286,
          478,
          2055,
          365,
          264,
          3847,
          23470,
          11,
          293,
          286,
          478,
          588,
          4227,
          365,
          572,
          3847,
          23470,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17719983246366858,
        "compression_ratio": 1.9166666666666667,
        "end": 1032.3600000000001,
        "id": 356,
        "no_speech_prob": 0.0015247755218297243,
        "seek": 101336,
        "start": 1030.3600000000001,
        "temperature": 0,
        "text": " I don't have a train whistle.",
        "tokens": [
          51214,
          286,
          500,
          380,
          362,
          257,
          3847,
          23470,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17719983246366858,
        "compression_ratio": 1.9166666666666667,
        "end": 1033.3600000000001,
        "id": 357,
        "no_speech_prob": 0.0015247755218297243,
        "seek": 101336,
        "start": 1032.3600000000001,
        "temperature": 0,
        "text": " I'm so sad.",
        "tokens": [
          51314,
          286,
          478,
          370,
          4227,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.17719983246366858,
        "compression_ratio": 1.9166666666666667,
        "end": 1034.3600000000001,
        "id": 358,
        "no_speech_prob": 0.0015247755218297243,
        "seek": 101336,
        "start": 1033.3600000000001,
        "temperature": 0,
        "text": " No train whistle.",
        "tokens": [
          51364,
          883,
          3847,
          23470,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17719983246366858,
        "compression_ratio": 1.9166666666666667,
        "end": 1035.3600000000001,
        "id": 359,
        "no_speech_prob": 0.0015247755218297243,
        "seek": 101336,
        "start": 1034.3600000000001,
        "temperature": 0,
        "text": " Now, I'm going to train.",
        "tokens": [
          51414,
          823,
          11,
          286,
          478,
          516,
          281,
          3847,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.17719983246366858,
        "compression_ratio": 1.9166666666666667,
        "end": 1040.3600000000001,
        "id": 360,
        "no_speech_prob": 0.0015247755218297243,
        "seek": 101336,
        "start": 1035.3600000000001,
        "temperature": 0,
        "text": " So, I gave it a whole bunch of examples, and something weird is going on here.",
        "tokens": [
          51464,
          407,
          11,
          286,
          2729,
          309,
          257,
          1379,
          3840,
          295,
          5110,
          11,
          293,
          746,
          3657,
          307,
          516,
          322,
          510,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17120282633321268,
        "compression_ratio": 1.8564814814814814,
        "end": 1044.36,
        "id": 361,
        "no_speech_prob": 0.06371187418699265,
        "seek": 104036,
        "start": 1040.36,
        "temperature": 0,
        "text": " Okay, let's see if this works.",
        "tokens": [
          50364,
          1033,
          11,
          718,
          311,
          536,
          498,
          341,
          1985,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.17120282633321268,
        "compression_ratio": 1.8564814814814814,
        "end": 1045.36,
        "id": 362,
        "no_speech_prob": 0.06371187418699265,
        "seek": 104036,
        "start": 1044.36,
        "temperature": 0,
        "text": " I'm happy with the train whistle.",
        "tokens": [
          50564,
          286,
          478,
          2055,
          365,
          264,
          3847,
          23470,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.17120282633321268,
        "compression_ratio": 1.8564814814814814,
        "end": 1046.36,
        "id": 363,
        "no_speech_prob": 0.06371187418699265,
        "seek": 104036,
        "start": 1045.36,
        "temperature": 0,
        "text": " I'm sad.",
        "tokens": [
          50614,
          286,
          478,
          4227,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17120282633321268,
        "compression_ratio": 1.8564814814814814,
        "end": 1047.36,
        "id": 364,
        "no_speech_prob": 0.06371187418699265,
        "seek": 104036,
        "start": 1046.36,
        "temperature": 0,
        "text": " No train whistle.",
        "tokens": [
          50664,
          883,
          3847,
          23470,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.17120282633321268,
        "compression_ratio": 1.8564814814814814,
        "end": 1048.36,
        "id": 365,
        "no_speech_prob": 0.06371187418699265,
        "seek": 104036,
        "start": 1047.36,
        "temperature": 0,
        "text": " I'm happy with the train whistle.",
        "tokens": [
          50714,
          286,
          478,
          2055,
          365,
          264,
          3847,
          23470,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.17120282633321268,
        "compression_ratio": 1.8564814814814814,
        "end": 1049.36,
        "id": 366,
        "no_speech_prob": 0.06371187418699265,
        "seek": 104036,
        "start": 1048.36,
        "temperature": 0,
        "text": " I'm sad.",
        "tokens": [
          50764,
          286,
          478,
          4227,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.17120282633321268,
        "compression_ratio": 1.8564814814814814,
        "end": 1051.36,
        "id": 367,
        "no_speech_prob": 0.06371187418699265,
        "seek": 104036,
        "start": 1049.36,
        "temperature": 0,
        "text": " No train whistle, and I want to keep this model.",
        "tokens": [
          50814,
          883,
          3847,
          23470,
          11,
          293,
          286,
          528,
          281,
          1066,
          341,
          2316,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17120282633321268,
        "compression_ratio": 1.8564814814814814,
        "end": 1055.36,
        "id": 368,
        "no_speech_prob": 0.06371187418699265,
        "seek": 104036,
        "start": 1051.36,
        "temperature": 0,
        "text": " So, I'm now going to click save, and look at this.",
        "tokens": [
          50914,
          407,
          11,
          286,
          478,
          586,
          516,
          281,
          2052,
          3155,
          11,
          293,
          574,
          412,
          341,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17120282633321268,
        "compression_ratio": 1.8564814814814814,
        "end": 1060.36,
        "id": 369,
        "no_speech_prob": 0.06371187418699265,
        "seek": 104036,
        "start": 1055.36,
        "temperature": 0,
        "text": " Look what has downloaded to the download directory.",
        "tokens": [
          51114,
          2053,
          437,
          575,
          21748,
          281,
          264,
          5484,
          21120,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.17120282633321268,
        "compression_ratio": 1.8564814814814814,
        "end": 1062.36,
        "id": 370,
        "no_speech_prob": 0.06371187418699265,
        "seek": 104036,
        "start": 1060.36,
        "temperature": 0,
        "text": " I'm going to go show in finder and see.",
        "tokens": [
          51364,
          286,
          478,
          516,
          281,
          352,
          855,
          294,
          915,
          260,
          293,
          536,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.17120282633321268,
        "compression_ratio": 1.8564814814814814,
        "end": 1063.36,
        "id": 371,
        "no_speech_prob": 0.06371187418699265,
        "seek": 104036,
        "start": 1062.36,
        "temperature": 0,
        "text": " Look at this.",
        "tokens": [
          51464,
          2053,
          412,
          341,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.17120282633321268,
        "compression_ratio": 1.8564814814814814,
        "end": 1064.36,
        "id": 372,
        "no_speech_prob": 0.06371187418699265,
        "seek": 104036,
        "start": 1063.36,
        "temperature": 0,
        "text": " Two files.",
        "tokens": [
          51514,
          4453,
          7098,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.17120282633321268,
        "compression_ratio": 1.8564814814814814,
        "end": 1066.36,
        "id": 373,
        "no_speech_prob": 0.06371187418699265,
        "seek": 104036,
        "start": 1064.36,
        "temperature": 0,
        "text": " Today is 2.17 p.m.",
        "tokens": [
          51564,
          2692,
          307,
          568,
          13,
          7773,
          280,
          13,
          76,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17120282633321268,
        "compression_ratio": 1.8564814814814814,
        "end": 1069.36,
        "id": 374,
        "no_speech_prob": 0.06371187418699265,
        "seek": 104036,
        "start": 1066.36,
        "temperature": 0,
        "text": " Model.json, model.weights.bin.",
        "tokens": [
          51664,
          17105,
          13,
          73,
          3015,
          11,
          2316,
          13,
          826,
          5761,
          13,
          13496,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.299726676940918,
        "compression_ratio": 1.108910891089109,
        "end": 1072.36,
        "id": 375,
        "no_speech_prob": 0.011331534944474697,
        "seek": 106936,
        "start": 1069.36,
        "temperature": 0,
        "text": " Okay, so let's take a moment to explain.",
        "tokens": [
          50364,
          1033,
          11,
          370,
          718,
          311,
          747,
          257,
          1623,
          281,
          2903,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.299726676940918,
        "compression_ratio": 1.108910891089109,
        "end": 1073.36,
        "id": 376,
        "no_speech_prob": 0.011331534944474697,
        "seek": 106936,
        "start": 1072.36,
        "temperature": 0,
        "text": " Oops.",
        "tokens": [
          50514,
          21726,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.299726676940918,
        "compression_ratio": 1.108910891089109,
        "end": 1089.36,
        "id": 377,
        "no_speech_prob": 0.011331534944474697,
        "seek": 106936,
        "start": 1088.36,
        "temperature": 0,
        "text": " Let's see.",
        "tokens": [
          51314,
          961,
          311,
          536,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.299726676940918,
        "compression_ratio": 1.108910891089109,
        "end": 1091.36,
        "id": 378,
        "no_speech_prob": 0.011331534944474697,
        "seek": 106936,
        "start": 1089.36,
        "temperature": 0,
        "text": " Why is the whiteboard not working?",
        "tokens": [
          51364,
          1545,
          307,
          264,
          2418,
          3787,
          406,
          1364,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.299726676940918,
        "compression_ratio": 1.108910891089109,
        "end": 1095.36,
        "id": 379,
        "no_speech_prob": 0.011331534944474697,
        "seek": 106936,
        "start": 1093.36,
        "temperature": 0,
        "text": " Loose cable.",
        "tokens": [
          51564,
          6130,
          541,
          8220,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.299726676940918,
        "compression_ratio": 1.108910891089109,
        "end": 1097.36,
        "id": 380,
        "no_speech_prob": 0.011331534944474697,
        "seek": 106936,
        "start": 1095.36,
        "temperature": 0,
        "text": " Maybe.",
        "tokens": [
          51664,
          2704,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20433354377746582,
        "compression_ratio": 1.4899328859060403,
        "end": 1099.36,
        "id": 381,
        "no_speech_prob": 0.00006605195085285231,
        "seek": 109736,
        "start": 1097.36,
        "temperature": 0,
        "text": " Check, check, no, check.",
        "tokens": [
          50364,
          6881,
          11,
          1520,
          11,
          572,
          11,
          1520,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.20433354377746582,
        "compression_ratio": 1.4899328859060403,
        "end": 1104.36,
        "id": 382,
        "no_speech_prob": 0.00006605195085285231,
        "seek": 109736,
        "start": 1103.36,
        "temperature": 0,
        "text": " Oh, there we go.",
        "tokens": [
          50664,
          876,
          11,
          456,
          321,
          352,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20433354377746582,
        "compression_ratio": 1.4899328859060403,
        "end": 1105.36,
        "id": 383,
        "no_speech_prob": 0.00006605195085285231,
        "seek": 109736,
        "start": 1104.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50714,
          1033,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20433354377746582,
        "compression_ratio": 1.4899328859060403,
        "end": 1108.36,
        "id": 384,
        "no_speech_prob": 0.00006605195085285231,
        "seek": 109736,
        "start": 1105.36,
        "temperature": 0,
        "text": " Let's take a moment to talk about what's in these files.",
        "tokens": [
          50764,
          961,
          311,
          747,
          257,
          1623,
          281,
          751,
          466,
          437,
          311,
          294,
          613,
          7098,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20433354377746582,
        "compression_ratio": 1.4899328859060403,
        "end": 1117.36,
        "id": 385,
        "no_speech_prob": 0.00006605195085285231,
        "seek": 109736,
        "start": 1108.36,
        "temperature": 0,
        "text": " So, why is there a file called model.json, and a file called, I already forgot, model.weights.bin?",
        "tokens": [
          50914,
          407,
          11,
          983,
          307,
          456,
          257,
          3991,
          1219,
          2316,
          13,
          73,
          3015,
          11,
          293,
          257,
          3991,
          1219,
          11,
          286,
          1217,
          5298,
          11,
          2316,
          13,
          826,
          5761,
          13,
          13496,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.20433354377746582,
        "compression_ratio": 1.4899328859060403,
        "end": 1122.36,
        "id": 386,
        "no_speech_prob": 0.00006605195085285231,
        "seek": 109736,
        "start": 1117.36,
        "temperature": 0,
        "text": " Model.weights.bin.",
        "tokens": [
          51364,
          17105,
          13,
          826,
          5761,
          13,
          13496,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.180108380317688,
        "compression_ratio": 1.6210526315789473,
        "end": 1133.36,
        "id": 387,
        "no_speech_prob": 0.003027810249477625,
        "seek": 112236,
        "start": 1123.36,
        "temperature": 0,
        "text": " Okay, so, we haven't really, as part of this video series at least, talked about the details of what a neural network is.",
        "tokens": [
          50414,
          1033,
          11,
          370,
          11,
          321,
          2378,
          380,
          534,
          11,
          382,
          644,
          295,
          341,
          960,
          2638,
          412,
          1935,
          11,
          2825,
          466,
          264,
          4365,
          295,
          437,
          257,
          18161,
          3209,
          307,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.180108380317688,
        "compression_ratio": 1.6210526315789473,
        "end": 1139.36,
        "id": 388,
        "no_speech_prob": 0.003027810249477625,
        "seek": 112236,
        "start": 1133.36,
        "temperature": 0,
        "text": " But, this particular machine learning model is a neural network.",
        "tokens": [
          50914,
          583,
          11,
          341,
          1729,
          3479,
          2539,
          2316,
          307,
          257,
          18161,
          3209,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.180108380317688,
        "compression_ratio": 1.6210526315789473,
        "end": 1142.36,
        "id": 389,
        "no_speech_prob": 0.003027810249477625,
        "seek": 112236,
        "start": 1139.36,
        "temperature": 0,
        "text": " And, a neural network has some kind of architecture to it.",
        "tokens": [
          51214,
          400,
          11,
          257,
          18161,
          3209,
          575,
          512,
          733,
          295,
          9482,
          281,
          309,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.180108380317688,
        "compression_ratio": 1.6210526315789473,
        "end": 1148.36,
        "id": 390,
        "no_speech_prob": 0.003027810249477625,
        "seek": 112236,
        "start": 1142.36,
        "temperature": 0,
        "text": " It has a whole bunch of inputs, and it has a bunch of outputs.",
        "tokens": [
          51364,
          467,
          575,
          257,
          1379,
          3840,
          295,
          15743,
          11,
          293,
          309,
          575,
          257,
          3840,
          295,
          23930,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20155755678812662,
        "compression_ratio": 1.6153846153846154,
        "end": 1151.36,
        "id": 391,
        "no_speech_prob": 0.014281785115599632,
        "seek": 114836,
        "start": 1148.36,
        "temperature": 0,
        "text": " And, in this case, it actually just has two outputs.",
        "tokens": [
          50364,
          400,
          11,
          294,
          341,
          1389,
          11,
          309,
          767,
          445,
          575,
          732,
          23930,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.20155755678812662,
        "compression_ratio": 1.6153846153846154,
        "end": 1154.36,
        "id": 392,
        "no_speech_prob": 0.014281785115599632,
        "seek": 114836,
        "start": 1151.36,
        "temperature": 0,
        "text": " A happy, or a sad.",
        "tokens": [
          50514,
          316,
          2055,
          11,
          420,
          257,
          4227,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20155755678812662,
        "compression_ratio": 1.6153846153846154,
        "end": 1160.36,
        "id": 393,
        "no_speech_prob": 0.014281785115599632,
        "seek": 114836,
        "start": 1154.36,
        "temperature": 0,
        "text": " And, the actual thing the neural network is producing is a probability of one or the other.",
        "tokens": [
          50664,
          400,
          11,
          264,
          3539,
          551,
          264,
          18161,
          3209,
          307,
          10501,
          307,
          257,
          8482,
          295,
          472,
          420,
          264,
          661,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20155755678812662,
        "compression_ratio": 1.6153846153846154,
        "end": 1169.36,
        "id": 394,
        "no_speech_prob": 0.014281785115599632,
        "seek": 114836,
        "start": 1160.36,
        "temperature": 0,
        "text": " Now, in between, oh, and the inputs, sorry, the inputs is an image.",
        "tokens": [
          50964,
          823,
          11,
          294,
          1296,
          11,
          1954,
          11,
          293,
          264,
          15743,
          11,
          2597,
          11,
          264,
          15743,
          307,
          364,
          3256,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20155755678812662,
        "compression_ratio": 1.6153846153846154,
        "end": 1174.36,
        "id": 395,
        "no_speech_prob": 0.014281785115599632,
        "seek": 114836,
        "start": 1169.36,
        "temperature": 0,
        "text": " So, maybe every single pixel of the image is wired to one of these inputs.",
        "tokens": [
          51414,
          407,
          11,
          1310,
          633,
          2167,
          19261,
          295,
          264,
          3256,
          307,
          27415,
          281,
          472,
          295,
          613,
          15743,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20155755678812662,
        "compression_ratio": 1.6153846153846154,
        "end": 1176.36,
        "id": 396,
        "no_speech_prob": 0.014281785115599632,
        "seek": 114836,
        "start": 1174.36,
        "temperature": 0,
        "text": " Then, there are these layers.",
        "tokens": [
          51664,
          1396,
          11,
          456,
          366,
          613,
          7914,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20396158533188904,
        "compression_ratio": 1.6291666666666667,
        "end": 1178.36,
        "id": 397,
        "no_speech_prob": 0.0075771017000079155,
        "seek": 117636,
        "start": 1176.36,
        "temperature": 0,
        "text": " The data is going to be processed forward.",
        "tokens": [
          50364,
          440,
          1412,
          307,
          516,
          281,
          312,
          18846,
          2128,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.20396158533188904,
        "compression_ratio": 1.6291666666666667,
        "end": 1183.36,
        "id": 398,
        "no_speech_prob": 0.0075771017000079155,
        "seek": 117636,
        "start": 1178.36,
        "temperature": 0,
        "text": " Math and various things are going to happen to the data as it goes forward.",
        "tokens": [
          50464,
          15776,
          293,
          3683,
          721,
          366,
          516,
          281,
          1051,
          281,
          264,
          1412,
          382,
          309,
          1709,
          2128,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20396158533188904,
        "compression_ratio": 1.6291666666666667,
        "end": 1190.36,
        "id": 399,
        "no_speech_prob": 0.0075771017000079155,
        "seek": 117636,
        "start": 1183.36,
        "temperature": 0,
        "text": " And, it needs to have some amount of hidden layers, and other types of nodes, and everything is connected.",
        "tokens": [
          50714,
          400,
          11,
          309,
          2203,
          281,
          362,
          512,
          2372,
          295,
          7633,
          7914,
          11,
          293,
          661,
          3467,
          295,
          13891,
          11,
          293,
          1203,
          307,
          4582,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.20396158533188904,
        "compression_ratio": 1.6291666666666667,
        "end": 1193.36,
        "id": 400,
        "no_speech_prob": 0.0075771017000079155,
        "seek": 117636,
        "start": 1190.36,
        "temperature": 0,
        "text": " And, this is stuff that I have described in other videos.",
        "tokens": [
          51064,
          400,
          11,
          341,
          307,
          1507,
          300,
          286,
          362,
          7619,
          294,
          661,
          2145,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20396158533188904,
        "compression_ratio": 1.6291666666666667,
        "end": 1199.36,
        "id": 401,
        "no_speech_prob": 0.0075771017000079155,
        "seek": 117636,
        "start": 1193.36,
        "temperature": 0,
        "text": " And, I'll also refer you to the 3Blue1Brown, What is a Neural Network video, which is terrific to see more.",
        "tokens": [
          51214,
          400,
          11,
          286,
          603,
          611,
          2864,
          291,
          281,
          264,
          805,
          45231,
          16,
          22170,
          648,
          11,
          708,
          307,
          257,
          1734,
          1807,
          12640,
          960,
          11,
          597,
          307,
          20899,
          281,
          536,
          544,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1982596095015363,
        "compression_ratio": 1.7941176470588236,
        "end": 1208.36,
        "id": 402,
        "no_speech_prob": 0.03621842339634895,
        "seek": 119936,
        "start": 1199.36,
        "temperature": 0,
        "text": " But, the reason why I'm mentioning this is, this model.json is a file that describes the architecture.",
        "tokens": [
          50364,
          583,
          11,
          264,
          1778,
          983,
          286,
          478,
          18315,
          341,
          307,
          11,
          341,
          2316,
          13,
          73,
          3015,
          307,
          257,
          3991,
          300,
          15626,
          264,
          9482,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1982596095015363,
        "compression_ratio": 1.7941176470588236,
        "end": 1211.36,
        "id": 403,
        "no_speech_prob": 0.03621842339634895,
        "seek": 119936,
        "start": 1208.36,
        "temperature": 0,
        "text": " Maybe it's architecture of the model.",
        "tokens": [
          50814,
          2704,
          309,
          311,
          9482,
          295,
          264,
          2316,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1982596095015363,
        "compression_ratio": 1.7941176470588236,
        "end": 1217.36,
        "id": 404,
        "no_speech_prob": 0.03621842339634895,
        "seek": 119936,
        "start": 1211.36,
        "temperature": 0,
        "text": " And, this model.weights.bin is a file that describes all the weights.",
        "tokens": [
          50964,
          400,
          11,
          341,
          2316,
          13,
          826,
          5761,
          13,
          13496,
          307,
          257,
          3991,
          300,
          15626,
          439,
          264,
          17443,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1982596095015363,
        "compression_ratio": 1.7941176470588236,
        "end": 1224.36,
        "id": 405,
        "no_speech_prob": 0.03621842339634895,
        "seek": 119936,
        "start": 1217.36,
        "temperature": 0,
        "text": " So, what I mean by architecture is, how many inputs, how many outputs, how many hidden layers,",
        "tokens": [
          51264,
          407,
          11,
          437,
          286,
          914,
          538,
          9482,
          307,
          11,
          577,
          867,
          15743,
          11,
          577,
          867,
          23930,
          11,
          577,
          867,
          7633,
          7914,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.25137025166333204,
        "compression_ratio": 1.773972602739726,
        "end": 1231.36,
        "id": 406,
        "no_speech_prob": 0.10374204069375992,
        "seek": 122436,
        "start": 1224.36,
        "temperature": 0,
        "text": " and all sorts of configuration details about the architecture of this neural network that I've drawn here in a pretty crude way.",
        "tokens": [
          50364,
          293,
          439,
          7527,
          295,
          11694,
          4365,
          466,
          264,
          9482,
          295,
          341,
          18161,
          3209,
          300,
          286,
          600,
          10117,
          510,
          294,
          257,
          1238,
          30796,
          636,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.25137025166333204,
        "compression_ratio": 1.773972602739726,
        "end": 1237.36,
        "id": 407,
        "no_speech_prob": 0.10374204069375992,
        "seek": 122436,
        "start": 1231.36,
        "temperature": 0,
        "text": " The thing that I'm kind of not mentioning, because I don't want to be here for the next 17 hours,",
        "tokens": [
          50714,
          440,
          551,
          300,
          286,
          478,
          733,
          295,
          406,
          18315,
          11,
          570,
          286,
          500,
          380,
          528,
          281,
          312,
          510,
          337,
          264,
          958,
          3282,
          2496,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.25137025166333204,
        "compression_ratio": 1.773972602739726,
        "end": 1243.36,
        "id": 408,
        "no_speech_prob": 0.10374204069375992,
        "seek": 122436,
        "start": 1237.36,
        "temperature": 0,
        "text": " going to every sound, every different road of detail here, is that the data as it's passing through the neural network,",
        "tokens": [
          51014,
          516,
          281,
          633,
          1626,
          11,
          633,
          819,
          3060,
          295,
          2607,
          510,
          11,
          307,
          300,
          264,
          1412,
          382,
          309,
          311,
          8437,
          807,
          264,
          18161,
          3209,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.25137025166333204,
        "compression_ratio": 1.773972602739726,
        "end": 1248.36,
        "id": 409,
        "no_speech_prob": 0.10374204069375992,
        "seek": 122436,
        "start": 1243.36,
        "temperature": 0,
        "text": " all of these different nodes between the inputs, and the outputs, and the hidden layers,",
        "tokens": [
          51314,
          439,
          295,
          613,
          819,
          13891,
          1296,
          264,
          15743,
          11,
          293,
          264,
          23930,
          11,
          293,
          264,
          7633,
          7914,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.25137025166333204,
        "compression_ratio": 1.773972602739726,
        "end": 1251.36,
        "id": 410,
        "no_speech_prob": 0.10374204069375992,
        "seek": 122436,
        "start": 1248.36,
        "temperature": 0,
        "text": " all of these nodes are connected.",
        "tokens": [
          51564,
          439,
          295,
          613,
          13891,
          366,
          4582,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.25137025166333204,
        "compression_ratio": 1.773972602739726,
        "end": 1253.36,
        "id": 411,
        "no_speech_prob": 0.10374204069375992,
        "seek": 122436,
        "start": 1251.36,
        "temperature": 0,
        "text": " And, each one of those connections has a weight.",
        "tokens": [
          51714,
          400,
          11,
          1184,
          472,
          295,
          729,
          9271,
          575,
          257,
          3364,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.18469834865484022,
        "compression_ratio": 1.7272727272727273,
        "end": 1257.36,
        "id": 412,
        "no_speech_prob": 0.004264554008841515,
        "seek": 125336,
        "start": 1253.36,
        "temperature": 0,
        "text": " You can think of the neural network as a thing that has just lots and lots of dials in it.",
        "tokens": [
          50364,
          509,
          393,
          519,
          295,
          264,
          18161,
          3209,
          382,
          257,
          551,
          300,
          575,
          445,
          3195,
          293,
          3195,
          295,
          5502,
          82,
          294,
          309,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18469834865484022,
        "compression_ratio": 1.7272727272727273,
        "end": 1265.36,
        "id": 413,
        "no_speech_prob": 0.004264554008841515,
        "seek": 125336,
        "start": 1257.36,
        "temperature": 0,
        "text": " And, it's trying to learn what the right setting for all the dials is to produce the appropriate happy or sad result based on the input image.",
        "tokens": [
          50564,
          400,
          11,
          309,
          311,
          1382,
          281,
          1466,
          437,
          264,
          558,
          3287,
          337,
          439,
          264,
          5502,
          82,
          307,
          281,
          5258,
          264,
          6854,
          2055,
          420,
          4227,
          1874,
          2361,
          322,
          264,
          4846,
          3256,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18469834865484022,
        "compression_ratio": 1.7272727272727273,
        "end": 1271.36,
        "id": 414,
        "no_speech_prob": 0.004264554008841515,
        "seek": 125336,
        "start": 1265.36,
        "temperature": 0,
        "text": " So, all of the numbers that store the values of all of these weights are all in this file.",
        "tokens": [
          50964,
          407,
          11,
          439,
          295,
          264,
          3547,
          300,
          3531,
          264,
          4190,
          295,
          439,
          295,
          613,
          17443,
          366,
          439,
          294,
          341,
          3991,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18469834865484022,
        "compression_ratio": 1.7272727272727273,
        "end": 1275.36,
        "id": 415,
        "no_speech_prob": 0.004264554008841515,
        "seek": 125336,
        "start": 1271.36,
        "temperature": 0,
        "text": " So, this is actually a file that we could very easily go and look inside.",
        "tokens": [
          51264,
          407,
          11,
          341,
          307,
          767,
          257,
          3991,
          300,
          321,
          727,
          588,
          3612,
          352,
          293,
          574,
          1854,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18469834865484022,
        "compression_ratio": 1.7272727272727273,
        "end": 1278.36,
        "id": 416,
        "no_speech_prob": 0.004264554008841515,
        "seek": 125336,
        "start": 1275.36,
        "temperature": 0,
        "text": " It's JavaScript object notation. It's a JSON file. We will look at that.",
        "tokens": [
          51464,
          467,
          311,
          15778,
          2657,
          24657,
          13,
          467,
          311,
          257,
          31828,
          3991,
          13,
          492,
          486,
          574,
          412,
          300,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18469834865484022,
        "compression_ratio": 1.7272727272727273,
        "end": 1281.36,
        "id": 417,
        "no_speech_prob": 0.004264554008841515,
        "seek": 125336,
        "start": 1278.36,
        "temperature": 0,
        "text": " But, the weights is really the big thing.",
        "tokens": [
          51614,
          583,
          11,
          264,
          17443,
          307,
          534,
          264,
          955,
          551,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19607649074764702,
        "compression_ratio": 1.6296296296296295,
        "end": 1284.36,
        "id": 418,
        "no_speech_prob": 0.005641838535666466,
        "seek": 128136,
        "start": 1281.36,
        "temperature": 0,
        "text": " It's where there's a ton of stuff. There's tons of these connections.",
        "tokens": [
          50364,
          467,
          311,
          689,
          456,
          311,
          257,
          2952,
          295,
          1507,
          13,
          821,
          311,
          9131,
          295,
          613,
          9271,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.19607649074764702,
        "compression_ratio": 1.6296296296296295,
        "end": 1286.36,
        "id": 419,
        "no_speech_prob": 0.005641838535666466,
        "seek": 128136,
        "start": 1284.36,
        "temperature": 0,
        "text": " It's many, many numbers.",
        "tokens": [
          50514,
          467,
          311,
          867,
          11,
          867,
          3547,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19607649074764702,
        "compression_ratio": 1.6296296296296295,
        "end": 1294.36,
        "id": 420,
        "no_speech_prob": 0.005641838535666466,
        "seek": 128136,
        "start": 1286.36,
        "temperature": 0,
        "text": " So, it's typically stored in binary format, raw digital data, so that to sort of have it be the smallest file size.",
        "tokens": [
          50614,
          407,
          11,
          309,
          311,
          5850,
          12187,
          294,
          17434,
          7877,
          11,
          8936,
          4562,
          1412,
          11,
          370,
          300,
          281,
          1333,
          295,
          362,
          309,
          312,
          264,
          16998,
          3991,
          2744,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19607649074764702,
        "compression_ratio": 1.6296296296296295,
        "end": 1297.36,
        "id": 421,
        "no_speech_prob": 0.005641838535666466,
        "seek": 128136,
        "start": 1294.36,
        "temperature": 0,
        "text": " So, these are the two files that we need.",
        "tokens": [
          51014,
          407,
          11,
          613,
          366,
          264,
          732,
          7098,
          300,
          321,
          643,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19607649074764702,
        "compression_ratio": 1.6296296296296295,
        "end": 1298.36,
        "id": 422,
        "no_speech_prob": 0.005641838535666466,
        "seek": 128136,
        "start": 1297.36,
        "temperature": 0,
        "text": " Let's go take a look at those.",
        "tokens": [
          51164,
          961,
          311,
          352,
          747,
          257,
          574,
          412,
          729,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19607649074764702,
        "compression_ratio": 1.6296296296296295,
        "end": 1302.36,
        "id": 423,
        "no_speech_prob": 0.005641838535666466,
        "seek": 128136,
        "start": 1298.36,
        "temperature": 0,
        "text": " So, the next step for us is to take these two files.",
        "tokens": [
          51214,
          407,
          11,
          264,
          958,
          1823,
          337,
          505,
          307,
          281,
          747,
          613,
          732,
          7098,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19607649074764702,
        "compression_ratio": 1.6296296296296295,
        "end": 1305.36,
        "id": 424,
        "no_speech_prob": 0.005641838535666466,
        "seek": 128136,
        "start": 1302.36,
        "temperature": 0,
        "text": " I'm going to copy them.",
        "tokens": [
          51414,
          286,
          478,
          516,
          281,
          5055,
          552,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19607649074764702,
        "compression_ratio": 1.6296296296296295,
        "end": 1310.36,
        "id": 425,
        "no_speech_prob": 0.005641838535666466,
        "seek": 128136,
        "start": 1305.36,
        "temperature": 0,
        "text": " And, actually, I think I could probably just drag them into Visual Studio Code,",
        "tokens": [
          51564,
          400,
          11,
          767,
          11,
          286,
          519,
          286,
          727,
          1391,
          445,
          5286,
          552,
          666,
          23187,
          13500,
          15549,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.1741154020195765,
        "compression_ratio": 1.6971830985915493,
        "end": 1312.36,
        "id": 426,
        "no_speech_prob": 0.0032729965168982744,
        "seek": 131036,
        "start": 1310.36,
        "temperature": 0,
        "text": " because I want them to be part of this example.",
        "tokens": [
          50364,
          570,
          286,
          528,
          552,
          281,
          312,
          644,
          295,
          341,
          1365,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1741154020195765,
        "compression_ratio": 1.6971830985915493,
        "end": 1314.36,
        "id": 427,
        "no_speech_prob": 0.0032729965168982744,
        "seek": 131036,
        "start": 1312.36,
        "temperature": 0,
        "text": " Right. So, we can see that they're here now.",
        "tokens": [
          50464,
          1779,
          13,
          407,
          11,
          321,
          393,
          536,
          300,
          436,
          434,
          510,
          586,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1741154020195765,
        "compression_ratio": 1.6971830985915493,
        "end": 1320.36,
        "id": 428,
        "no_speech_prob": 0.0032729965168982744,
        "seek": 131036,
        "start": 1314.36,
        "temperature": 0,
        "text": " Now that I have model.json and model.weights.bin as part of my project,",
        "tokens": [
          50564,
          823,
          300,
          286,
          362,
          2316,
          13,
          73,
          3015,
          293,
          2316,
          13,
          826,
          5761,
          13,
          13496,
          382,
          644,
          295,
          452,
          1716,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.1741154020195765,
        "compression_ratio": 1.6971830985915493,
        "end": 1323.36,
        "id": 429,
        "no_speech_prob": 0.0032729965168982744,
        "seek": 131036,
        "start": 1320.36,
        "temperature": 0,
        "text": " if I were using the p5 web editor, I'd need to upload these files.",
        "tokens": [
          50864,
          498,
          286,
          645,
          1228,
          264,
          280,
          20,
          3670,
          9839,
          11,
          286,
          1116,
          643,
          281,
          6580,
          613,
          7098,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1741154020195765,
        "compression_ratio": 1.6971830985915493,
        "end": 1325.36,
        "id": 430,
        "no_speech_prob": 0.0032729965168982744,
        "seek": 131036,
        "start": 1323.36,
        "temperature": 0,
        "text": " I'm not sure if that's actually possible. I'll have to look into that.",
        "tokens": [
          51014,
          286,
          478,
          406,
          988,
          498,
          300,
          311,
          767,
          1944,
          13,
          286,
          603,
          362,
          281,
          574,
          666,
          300,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1741154020195765,
        "compression_ratio": 1.6971830985915493,
        "end": 1330.36,
        "id": 431,
        "no_speech_prob": 0.0032729965168982744,
        "seek": 131036,
        "start": 1325.36,
        "temperature": 0,
        "text": " And then, if we look at model.json, for example, you can see, and I'm going to hit save,",
        "tokens": [
          51114,
          400,
          550,
          11,
          498,
          321,
          574,
          412,
          2316,
          13,
          73,
          3015,
          11,
          337,
          1365,
          11,
          291,
          393,
          536,
          11,
          293,
          286,
          478,
          516,
          281,
          2045,
          3155,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.1741154020195765,
        "compression_ratio": 1.6971830985915493,
        "end": 1333.36,
        "id": 432,
        "no_speech_prob": 0.0032729965168982744,
        "seek": 131036,
        "start": 1330.36,
        "temperature": 0,
        "text": " we can see this is the model topology.",
        "tokens": [
          51364,
          321,
          393,
          536,
          341,
          307,
          264,
          2316,
          1192,
          1793,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1741154020195765,
        "compression_ratio": 1.6971830985915493,
        "end": 1335.36,
        "id": 433,
        "no_speech_prob": 0.0032729965168982744,
        "seek": 131036,
        "start": 1333.36,
        "temperature": 0,
        "text": " It's a sequential model.",
        "tokens": [
          51514,
          467,
          311,
          257,
          42881,
          2316,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1741154020195765,
        "compression_ratio": 1.6971830985915493,
        "end": 1337.36,
        "id": 434,
        "no_speech_prob": 0.0032729965168982744,
        "seek": 131036,
        "start": 1335.36,
        "temperature": 0,
        "text": " And, these are the inputs.",
        "tokens": [
          51614,
          400,
          11,
          613,
          366,
          264,
          15743,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19845293249402726,
        "compression_ratio": 1.608695652173913,
        "end": 1340.36,
        "id": 435,
        "no_speech_prob": 0.0030753114260733128,
        "seek": 133736,
        "start": 1337.36,
        "temperature": 0,
        "text": " The inputs are 7x7x256.",
        "tokens": [
          50364,
          440,
          15743,
          366,
          1614,
          87,
          22,
          87,
          6074,
          21,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.19845293249402726,
        "compression_ratio": 1.608695652173913,
        "end": 1345.36,
        "id": 436,
        "no_speech_prob": 0.0030753114260733128,
        "seek": 133736,
        "start": 1340.36,
        "temperature": 0,
        "text": " And, somewhere, ah, yes, ml5 specs.",
        "tokens": [
          50514,
          400,
          11,
          4079,
          11,
          3716,
          11,
          2086,
          11,
          23271,
          20,
          27911,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19845293249402726,
        "compression_ratio": 1.608695652173913,
        "end": 1348.36,
        "id": 437,
        "no_speech_prob": 0.0030753114260733128,
        "seek": 133736,
        "start": 1345.36,
        "temperature": 0,
        "text": " These are the labels, happy and sad.",
        "tokens": [
          50764,
          1981,
          366,
          264,
          16949,
          11,
          2055,
          293,
          4227,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19845293249402726,
        "compression_ratio": 1.608695652173913,
        "end": 1349.36,
        "id": 438,
        "no_speech_prob": 0.0030753114260733128,
        "seek": 133736,
        "start": 1348.36,
        "temperature": 0,
        "text": " There's all sorts of other stuff.",
        "tokens": [
          50914,
          821,
          311,
          439,
          7527,
          295,
          661,
          1507,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19845293249402726,
        "compression_ratio": 1.608695652173913,
        "end": 1353.36,
        "id": 439,
        "no_speech_prob": 0.0030753114260733128,
        "seek": 133736,
        "start": 1349.36,
        "temperature": 0,
        "text": " There's some dense layers, and there's where it gets the weights.",
        "tokens": [
          50964,
          821,
          311,
          512,
          18011,
          7914,
          11,
          293,
          456,
          311,
          689,
          309,
          2170,
          264,
          17443,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19845293249402726,
        "compression_ratio": 1.608695652173913,
        "end": 1356.36,
        "id": 440,
        "no_speech_prob": 0.0030753114260733128,
        "seek": 133736,
        "start": 1353.36,
        "temperature": 0,
        "text": " And, it's using TensorFlow layers and TensorFlow.js.",
        "tokens": [
          51164,
          400,
          11,
          309,
          311,
          1228,
          37624,
          7914,
          293,
          37624,
          13,
          25530,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19845293249402726,
        "compression_ratio": 1.608695652173913,
        "end": 1359.36,
        "id": 441,
        "no_speech_prob": 0.0030753114260733128,
        "seek": 133736,
        "start": 1356.36,
        "temperature": 0,
        "text": " So, all this information is in here.",
        "tokens": [
          51314,
          407,
          11,
          439,
          341,
          1589,
          307,
          294,
          510,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19845293249402726,
        "compression_ratio": 1.608695652173913,
        "end": 1364.36,
        "id": 442,
        "no_speech_prob": 0.0030753114260733128,
        "seek": 133736,
        "start": 1359.36,
        "temperature": 0,
        "text": " The bin file is not something we can really look at, because it's in binary format.",
        "tokens": [
          51464,
          440,
          5171,
          3991,
          307,
          406,
          746,
          321,
          393,
          534,
          574,
          412,
          11,
          570,
          309,
          311,
          294,
          17434,
          7877,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1997745150611514,
        "compression_ratio": 1.5384615384615385,
        "end": 1367.36,
        "id": 443,
        "no_speech_prob": 0.000006748048690496944,
        "seek": 136436,
        "start": 1364.36,
        "temperature": 0,
        "text": " But, we can know that all of the numbers, those weights, are there.",
        "tokens": [
          50364,
          583,
          11,
          321,
          393,
          458,
          300,
          439,
          295,
          264,
          3547,
          11,
          729,
          17443,
          11,
          366,
          456,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1997745150611514,
        "compression_ratio": 1.5384615384615385,
        "end": 1368.36,
        "id": 444,
        "no_speech_prob": 0.000006748048690496944,
        "seek": 136436,
        "start": 1367.36,
        "temperature": 0,
        "text": " So, now, guess what?",
        "tokens": [
          50514,
          407,
          11,
          586,
          11,
          2041,
          437,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.1997745150611514,
        "compression_ratio": 1.5384615384615385,
        "end": 1375.36,
        "id": 445,
        "no_speech_prob": 0.000006748048690496944,
        "seek": 136436,
        "start": 1368.36,
        "temperature": 0,
        "text": " We're going to go back to our code, and I'm going to look at the steps here in setup again.",
        "tokens": [
          50564,
          492,
          434,
          516,
          281,
          352,
          646,
          281,
          527,
          3089,
          11,
          293,
          286,
          478,
          516,
          281,
          574,
          412,
          264,
          4439,
          510,
          294,
          8657,
          797,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1997745150611514,
        "compression_ratio": 1.5384615384615385,
        "end": 1382.36,
        "id": 446,
        "no_speech_prob": 0.000006748048690496944,
        "seek": 136436,
        "start": 1375.36,
        "temperature": 0,
        "text": " So, in setup, the first thing that I do is I create a feature extractor with MobileNet.",
        "tokens": [
          50914,
          407,
          11,
          294,
          8657,
          11,
          264,
          700,
          551,
          300,
          286,
          360,
          307,
          286,
          1884,
          257,
          4111,
          8947,
          284,
          365,
          22625,
          31890,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1997745150611514,
        "compression_ratio": 1.5384615384615385,
        "end": 1385.36,
        "id": 447,
        "no_speech_prob": 0.000006748048690496944,
        "seek": 136436,
        "start": 1382.36,
        "temperature": 0,
        "text": " When that model is ready,",
        "tokens": [
          51264,
          1133,
          300,
          2316,
          307,
          1919,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.1997745150611514,
        "compression_ratio": 1.5384615384615385,
        "end": 1389.36,
        "id": 448,
        "no_speech_prob": 0.000006748048690496944,
        "seek": 136436,
        "start": 1387.36,
        "temperature": 0,
        "text": " hold on, I'm thinking for a second.",
        "tokens": [
          51514,
          1797,
          322,
          11,
          286,
          478,
          1953,
          337,
          257,
          1150,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1997745150611514,
        "compression_ratio": 1.5384615384615385,
        "end": 1392.36,
        "id": 449,
        "no_speech_prob": 0.000006748048690496944,
        "seek": 136436,
        "start": 1391.36,
        "temperature": 0,
        "text": " Oh, yeah.",
        "tokens": [
          51714,
          876,
          11,
          1338,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.14285904566446941,
        "compression_ratio": 1.7219917012448134,
        "end": 1396.36,
        "id": 450,
        "no_speech_prob": 0.00008349560084752738,
        "seek": 139436,
        "start": 1394.36,
        "temperature": 0,
        "text": " Just time out for a second.",
        "tokens": [
          50364,
          1449,
          565,
          484,
          337,
          257,
          1150,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.14285904566446941,
        "compression_ratio": 1.7219917012448134,
        "end": 1397.36,
        "id": 451,
        "no_speech_prob": 0.00008349560084752738,
        "seek": 139436,
        "start": 1396.36,
        "temperature": 0,
        "text": " I just want to look.",
        "tokens": [
          50464,
          286,
          445,
          528,
          281,
          574,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.14285904566446941,
        "compression_ratio": 1.7219917012448134,
        "end": 1401.36,
        "id": 452,
        "no_speech_prob": 0.00008349560084752738,
        "seek": 139436,
        "start": 1397.36,
        "temperature": 0,
        "text": " Unfortunately, the documentation isn't up on the website for this.",
        "tokens": [
          50514,
          8590,
          11,
          264,
          14333,
          1943,
          380,
          493,
          322,
          264,
          3144,
          337,
          341,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.14285904566446941,
        "compression_ratio": 1.7219917012448134,
        "end": 1404.36,
        "id": 453,
        "no_speech_prob": 0.00008349560084752738,
        "seek": 139436,
        "start": 1401.36,
        "temperature": 0,
        "text": " So, I just want to check something to make sure I'm doing it correctly.",
        "tokens": [
          50714,
          407,
          11,
          286,
          445,
          528,
          281,
          1520,
          746,
          281,
          652,
          988,
          286,
          478,
          884,
          309,
          8944,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.14285904566446941,
        "compression_ratio": 1.7219917012448134,
        "end": 1406.36,
        "id": 454,
        "no_speech_prob": 0.00008349560084752738,
        "seek": 139436,
        "start": 1404.36,
        "temperature": 0,
        "text": " I'm going to look at it over here real briefly.",
        "tokens": [
          50864,
          286,
          478,
          516,
          281,
          574,
          412,
          309,
          670,
          510,
          957,
          10515,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.14285904566446941,
        "compression_ratio": 1.7219917012448134,
        "end": 1410.36,
        "id": 455,
        "no_speech_prob": 0.00008349560084752738,
        "seek": 139436,
        "start": 1406.36,
        "temperature": 0,
        "text": " I'm just looking in the existing examples.",
        "tokens": [
          50964,
          286,
          478,
          445,
          1237,
          294,
          264,
          6741,
          5110,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.14285904566446941,
        "compression_ratio": 1.7219917012448134,
        "end": 1412.36,
        "id": 456,
        "no_speech_prob": 0.00008349560084752738,
        "seek": 139436,
        "start": 1410.36,
        "temperature": 0,
        "text": " There actually is an existing example for this.",
        "tokens": [
          51164,
          821,
          767,
          307,
          364,
          6741,
          1365,
          337,
          341,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.14285904566446941,
        "compression_ratio": 1.7219917012448134,
        "end": 1413.36,
        "id": 457,
        "no_speech_prob": 0.00008349560084752738,
        "seek": 139436,
        "start": 1412.36,
        "temperature": 0,
        "text": " I don't know why I'm not pulling it up here.",
        "tokens": [
          51264,
          286,
          500,
          380,
          458,
          983,
          286,
          478,
          406,
          8407,
          309,
          493,
          510,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.14285904566446941,
        "compression_ratio": 1.7219917012448134,
        "end": 1414.36,
        "id": 458,
        "no_speech_prob": 0.00008349560084752738,
        "seek": 139436,
        "start": 1413.36,
        "temperature": 0,
        "text": " I probably should.",
        "tokens": [
          51314,
          286,
          1391,
          820,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.14285904566446941,
        "compression_ratio": 1.7219917012448134,
        "end": 1421.36,
        "id": 459,
        "no_speech_prob": 0.00008349560084752738,
        "seek": 139436,
        "start": 1420.36,
        "temperature": 0,
        "text": " I think it's here, yeah.",
        "tokens": [
          51664,
          286,
          519,
          309,
          311,
          510,
          11,
          1338,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.22069619042532784,
        "compression_ratio": 1.4339622641509433,
        "end": 1424.36,
        "id": 460,
        "no_speech_prob": 0.0001911032886710018,
        "seek": 142136,
        "start": 1422.36,
        "temperature": 0,
        "text": " I just need to understand the order of this.",
        "tokens": [
          50414,
          286,
          445,
          643,
          281,
          1223,
          264,
          1668,
          295,
          341,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.22069619042532784,
        "compression_ratio": 1.4339622641509433,
        "end": 1427.36,
        "id": 461,
        "no_speech_prob": 0.0001911032886710018,
        "seek": 142136,
        "start": 1424.36,
        "temperature": 0,
        "text": " Classifier, oh, yeah, okay.",
        "tokens": [
          50514,
          9471,
          9902,
          11,
          1954,
          11,
          1338,
          11,
          1392,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.22069619042532784,
        "compression_ratio": 1.4339622641509433,
        "end": 1430.36,
        "id": 462,
        "no_speech_prob": 0.0001911032886710018,
        "seek": 142136,
        "start": 1429.36,
        "temperature": 0,
        "text": " That's interesting.",
        "tokens": [
          50764,
          663,
          311,
          1880,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.22069619042532784,
        "compression_ratio": 1.4339622641509433,
        "end": 1433.36,
        "id": 463,
        "no_speech_prob": 0.0001911032886710018,
        "seek": 142136,
        "start": 1432.36,
        "temperature": 0,
        "text": " I guess that works.",
        "tokens": [
          50914,
          286,
          2041,
          300,
          1985,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.22069619042532784,
        "compression_ratio": 1.4339622641509433,
        "end": 1438.36,
        "id": 464,
        "no_speech_prob": 0.0001911032886710018,
        "seek": 142136,
        "start": 1433.36,
        "temperature": 0,
        "text": " The order of all this stuff is weird, and I feel like this is a thing we have to work on with the library.",
        "tokens": [
          50964,
          440,
          1668,
          295,
          439,
          341,
          1507,
          307,
          3657,
          11,
          293,
          286,
          841,
          411,
          341,
          307,
          257,
          551,
          321,
          362,
          281,
          589,
          322,
          365,
          264,
          6405,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.22069619042532784,
        "compression_ratio": 1.4339622641509433,
        "end": 1447.36,
        "id": 465,
        "no_speech_prob": 0.0001911032886710018,
        "seek": 142136,
        "start": 1446.36,
        "temperature": 0,
        "text": " Alright.",
        "tokens": [
          51614,
          2798,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.24732228871938344,
        "compression_ratio": 1.4935897435897436,
        "end": 1451.36,
        "id": 466,
        "no_speech_prob": 0.000044001171772833914,
        "seek": 144736,
        "start": 1448.36,
        "temperature": 0,
        "text": " I'm going to not worry about this too much.",
        "tokens": [
          50414,
          286,
          478,
          516,
          281,
          406,
          3292,
          466,
          341,
          886,
          709,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.24732228871938344,
        "compression_ratio": 1.4935897435897436,
        "end": 1460.36,
        "id": 467,
        "no_speech_prob": 0.000044001171772833914,
        "seek": 144736,
        "start": 1458.36,
        "temperature": 0,
        "text": " Once the model is ready,",
        "tokens": [
          50914,
          3443,
          264,
          2316,
          307,
          1919,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.24732228871938344,
        "compression_ratio": 1.4935897435897436,
        "end": 1464.36,
        "id": 468,
        "no_speech_prob": 0.000044001171772833914,
        "seek": 144736,
        "start": 1461.36,
        "temperature": 0,
        "text": " then I can go ahead.",
        "tokens": [
          51064,
          550,
          286,
          393,
          352,
          2286,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.24732228871938344,
        "compression_ratio": 1.4935897435897436,
        "end": 1465.36,
        "id": 469,
        "no_speech_prob": 0.000044001171772833914,
        "seek": 144736,
        "start": 1464.36,
        "temperature": 0,
        "text": " Where's that?",
        "tokens": [
          51214,
          2305,
          311,
          300,
          30,
          51264
        ]
      },
      {
        "avg_logprob": -0.24732228871938344,
        "compression_ratio": 1.4935897435897436,
        "end": 1469.36,
        "id": 470,
        "no_speech_prob": 0.000044001171772833914,
        "seek": 144736,
        "start": 1465.36,
        "temperature": 0,
        "text": " This is the function for when the model is ready.",
        "tokens": [
          51264,
          639,
          307,
          264,
          2445,
          337,
          562,
          264,
          2316,
          307,
          1919,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.24732228871938344,
        "compression_ratio": 1.4935897435897436,
        "end": 1474.36,
        "id": 471,
        "no_speech_prob": 0.000044001171772833914,
        "seek": 144736,
        "start": 1469.36,
        "temperature": 0,
        "text": " I can now go and say classifier.load, and guess what I want to tell it to load?",
        "tokens": [
          51464,
          286,
          393,
          586,
          352,
          293,
          584,
          1508,
          9902,
          13,
          2907,
          11,
          293,
          2041,
          437,
          286,
          528,
          281,
          980,
          309,
          281,
          3677,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.2218421118600028,
        "compression_ratio": 1.6307692307692307,
        "end": 1480.36,
        "id": 472,
        "no_speech_prob": 0.00426460662856698,
        "seek": 147436,
        "start": 1474.36,
        "temperature": 0,
        "text": " Model.json, and I'm going to say custom model ready.",
        "tokens": [
          50364,
          17105,
          13,
          73,
          3015,
          11,
          293,
          286,
          478,
          516,
          281,
          584,
          2375,
          2316,
          1919,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2218421118600028,
        "compression_ratio": 1.6307692307692307,
        "end": 1484.36,
        "id": 473,
        "no_speech_prob": 0.00426460662856698,
        "seek": 147436,
        "start": 1482.36,
        "temperature": 0,
        "text": " Custom model ready.",
        "tokens": [
          50764,
          16649,
          2316,
          1919,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2218421118600028,
        "compression_ratio": 1.6307692307692307,
        "end": 1491.36,
        "id": 474,
        "no_speech_prob": 0.00426460662856698,
        "seek": 147436,
        "start": 1490.36,
        "temperature": 0,
        "text": " Custom.",
        "tokens": [
          51164,
          16649,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2218421118600028,
        "compression_ratio": 1.6307692307692307,
        "end": 1495.36,
        "id": 475,
        "no_speech_prob": 0.00426460662856698,
        "seek": 147436,
        "start": 1492.36,
        "temperature": 0,
        "text": " Custom model is ready.",
        "tokens": [
          51264,
          16649,
          2316,
          307,
          1919,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2218421118600028,
        "compression_ratio": 1.6307692307692307,
        "end": 1497.36,
        "id": 476,
        "no_speech_prob": 0.00426460662856698,
        "seek": 147436,
        "start": 1495.36,
        "temperature": 0,
        "text": " First, MobileNet has to be loaded.",
        "tokens": [
          51414,
          2386,
          11,
          22625,
          31890,
          575,
          281,
          312,
          13210,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2218421118600028,
        "compression_ratio": 1.6307692307692307,
        "end": 1501.36,
        "id": 477,
        "no_speech_prob": 0.00426460662856698,
        "seek": 147436,
        "start": 1497.36,
        "temperature": 0,
        "text": " Once that's done, then the custom model can be loaded.",
        "tokens": [
          51514,
          3443,
          300,
          311,
          1096,
          11,
          550,
          264,
          2375,
          2316,
          393,
          312,
          13210,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2218421118600028,
        "compression_ratio": 1.6307692307692307,
        "end": 1502.36,
        "id": 478,
        "no_speech_prob": 0.00426460662856698,
        "seek": 147436,
        "start": 1501.36,
        "temperature": 0,
        "text": " Now, look at this.",
        "tokens": [
          51714,
          823,
          11,
          574,
          412,
          341,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1923652801513672,
        "compression_ratio": 1.7096774193548387,
        "end": 1504.36,
        "id": 479,
        "no_speech_prob": 0.00003705287599586882,
        "seek": 150236,
        "start": 1502.36,
        "temperature": 0,
        "text": " Classifier.load, model.json.",
        "tokens": [
          50364,
          9471,
          9902,
          13,
          2907,
          11,
          2316,
          13,
          73,
          3015,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1923652801513672,
        "compression_ratio": 1.7096774193548387,
        "end": 1509.36,
        "id": 480,
        "no_speech_prob": 0.00003705287599586882,
        "seek": 150236,
        "start": 1504.36,
        "temperature": 0,
        "text": " Remember, there are two files, model.weights.bin and model.json.",
        "tokens": [
          50464,
          5459,
          11,
          456,
          366,
          732,
          7098,
          11,
          2316,
          13,
          826,
          5761,
          13,
          13496,
          293,
          2316,
          13,
          73,
          3015,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1923652801513672,
        "compression_ratio": 1.7096774193548387,
        "end": 1515.36,
        "id": 481,
        "no_speech_prob": 0.00003705287599586882,
        "seek": 150236,
        "start": 1509.36,
        "temperature": 0,
        "text": " ml5 is set up to work that if you just tell it where the json file is, model.json,",
        "tokens": [
          50714,
          23271,
          20,
          307,
          992,
          493,
          281,
          589,
          300,
          498,
          291,
          445,
          980,
          309,
          689,
          264,
          361,
          3015,
          3991,
          307,
          11,
          2316,
          13,
          73,
          3015,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.1923652801513672,
        "compression_ratio": 1.7096774193548387,
        "end": 1519.36,
        "id": 482,
        "no_speech_prob": 0.00003705287599586882,
        "seek": 150236,
        "start": 1515.36,
        "temperature": 0,
        "text": " it'll look for the corresponding model.weights.bin file in the same directory.",
        "tokens": [
          51014,
          309,
          603,
          574,
          337,
          264,
          11760,
          2316,
          13,
          826,
          5761,
          13,
          13496,
          3991,
          294,
          264,
          912,
          21120,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1923652801513672,
        "compression_ratio": 1.7096774193548387,
        "end": 1523.36,
        "id": 483,
        "no_speech_prob": 0.00003705287599586882,
        "seek": 150236,
        "start": 1519.36,
        "temperature": 0,
        "text": " There are ways that you can customize what those file names are and have them in different paths,",
        "tokens": [
          51214,
          821,
          366,
          2098,
          300,
          291,
          393,
          19734,
          437,
          729,
          3991,
          5288,
          366,
          293,
          362,
          552,
          294,
          819,
          14518,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.1923652801513672,
        "compression_ratio": 1.7096774193548387,
        "end": 1525.36,
        "id": 484,
        "no_speech_prob": 0.00003705287599586882,
        "seek": 150236,
        "start": 1523.36,
        "temperature": 0,
        "text": " but this is the simplest way of doing it.",
        "tokens": [
          51414,
          457,
          341,
          307,
          264,
          22811,
          636,
          295,
          884,
          309,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1923652801513672,
        "compression_ratio": 1.7096774193548387,
        "end": 1527.36,
        "id": 485,
        "no_speech_prob": 0.00003705287599586882,
        "seek": 150236,
        "start": 1525.36,
        "temperature": 0,
        "text": " Let's see if this works now.",
        "tokens": [
          51514,
          961,
          311,
          536,
          498,
          341,
          1985,
          586,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.3608361446496212,
        "compression_ratio": 1.0379746835443038,
        "end": 1532.36,
        "id": 486,
        "no_speech_prob": 0.006589388940483332,
        "seek": 152736,
        "start": 1528.36,
        "temperature": 0,
        "text": " Model is ready.",
        "tokens": [
          50414,
          17105,
          307,
          1919,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.3608361446496212,
        "compression_ratio": 1.0379746835443038,
        "end": 1536.36,
        "id": 487,
        "no_speech_prob": 0.006589388940483332,
        "seek": 152736,
        "start": 1532.36,
        "temperature": 0,
        "text": " Got an error.",
        "tokens": [
          50614,
          5803,
          364,
          6713,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.3608361446496212,
        "compression_ratio": 1.0379746835443038,
        "end": 1540.36,
        "id": 488,
        "no_speech_prob": 0.006589388940483332,
        "seek": 152736,
        "start": 1536.36,
        "temperature": 0,
        "text": " What is this error?",
        "tokens": [
          50814,
          708,
          307,
          341,
          6713,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.3608361446496212,
        "compression_ratio": 1.0379746835443038,
        "end": 1544.36,
        "id": 489,
        "no_speech_prob": 0.006589388940483332,
        "seek": 152736,
        "start": 1540.36,
        "temperature": 0,
        "text": " That was sad.",
        "tokens": [
          51014,
          663,
          390,
          4227,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.3608361446496212,
        "compression_ratio": 1.0379746835443038,
        "end": 1555.36,
        "id": 490,
        "no_speech_prob": 0.006589388940483332,
        "seek": 152736,
        "start": 1552.36,
        "temperature": 0,
        "text": " Maybe it has zero.",
        "tokens": [
          51614,
          2704,
          309,
          575,
          4018,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18376763274029986,
        "compression_ratio": 1.3986928104575163,
        "end": 1560.36,
        "id": 491,
        "no_speech_prob": 0.0035379782784730196,
        "seek": 155736,
        "start": 1557.36,
        "temperature": 0,
        "text": " Let's look at 5 megabytes.",
        "tokens": [
          50364,
          961,
          311,
          574,
          412,
          1025,
          10816,
          24538,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.18376763274029986,
        "compression_ratio": 1.3986928104575163,
        "end": 1561.36,
        "id": 492,
        "no_speech_prob": 0.0035379782784730196,
        "seek": 155736,
        "start": 1560.36,
        "temperature": 0,
        "text": " That makes sense.",
        "tokens": [
          50514,
          663,
          1669,
          2020,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18376763274029986,
        "compression_ratio": 1.3986928104575163,
        "end": 1562.36,
        "id": 493,
        "no_speech_prob": 0.0035379782784730196,
        "seek": 155736,
        "start": 1561.36,
        "temperature": 0,
        "text": " That's right.",
        "tokens": [
          50564,
          663,
          311,
          558,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18376763274029986,
        "compression_ratio": 1.3986928104575163,
        "end": 1566.36,
        "id": 494,
        "no_speech_prob": 0.0035379782784730196,
        "seek": 155736,
        "start": 1562.36,
        "temperature": 0,
        "text": " There's definitely weights there.",
        "tokens": [
          50614,
          821,
          311,
          2138,
          17443,
          456,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.18376763274029986,
        "compression_ratio": 1.3986928104575163,
        "end": 1568.36,
        "id": 495,
        "no_speech_prob": 0.0035379782784730196,
        "seek": 155736,
        "start": 1566.36,
        "temperature": 0,
        "text": " Oh, it didn't find it.",
        "tokens": [
          50814,
          876,
          11,
          309,
          994,
          380,
          915,
          309,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.18376763274029986,
        "compression_ratio": 1.3986928104575163,
        "end": 1569.36,
        "id": 496,
        "no_speech_prob": 0.0035379782784730196,
        "seek": 155736,
        "start": 1568.36,
        "temperature": 0,
        "text": " Oh, weird.",
        "tokens": [
          50914,
          876,
          11,
          3657,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18376763274029986,
        "compression_ratio": 1.3986928104575163,
        "end": 1575.36,
        "id": 497,
        "no_speech_prob": 0.0035379782784730196,
        "seek": 155736,
        "start": 1569.36,
        "temperature": 0,
        "text": " Oh!",
        "tokens": [
          50964,
          876,
          0,
          51264
        ]
      },
      {
        "avg_logprob": -0.18376763274029986,
        "compression_ratio": 1.3986928104575163,
        "end": 1579.36,
        "id": 498,
        "no_speech_prob": 0.0035379782784730196,
        "seek": 155736,
        "start": 1575.36,
        "temperature": 0,
        "text": " I know what the problem is.",
        "tokens": [
          51264,
          286,
          458,
          437,
          264,
          1154,
          307,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18376763274029986,
        "compression_ratio": 1.3986928104575163,
        "end": 1583.36,
        "id": 499,
        "no_speech_prob": 0.0035379782784730196,
        "seek": 155736,
        "start": 1579.36,
        "temperature": 0,
        "text": " Ugh, I don't like this.",
        "tokens": [
          51464,
          16506,
          11,
          286,
          500,
          380,
          411,
          341,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18376763274029986,
        "compression_ratio": 1.3986928104575163,
        "end": 1586.36,
        "id": 500,
        "no_speech_prob": 0.0035379782784730196,
        "seek": 155736,
        "start": 1583.36,
        "temperature": 0,
        "text": " I think it's going to work now.",
        "tokens": [
          51664,
          286,
          519,
          309,
          311,
          516,
          281,
          589,
          586,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.24643708813575008,
        "compression_ratio": 1.414012738853503,
        "end": 1591.36,
        "id": 501,
        "no_speech_prob": 0.0018969030352309346,
        "seek": 158636,
        "start": 1586.36,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          50364,
          865,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.24643708813575008,
        "compression_ratio": 1.414012738853503,
        "end": 1597.36,
        "id": 502,
        "no_speech_prob": 0.0018969030352309346,
        "seek": 158636,
        "start": 1591.36,
        "temperature": 0,
        "text": " It did load.",
        "tokens": [
          50614,
          467,
          630,
          3677,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.24643708813575008,
        "compression_ratio": 1.414012738853503,
        "end": 1599.36,
        "id": 503,
        "no_speech_prob": 0.0018969030352309346,
        "seek": 158636,
        "start": 1597.36,
        "temperature": 0,
        "text": " The issue is the following.",
        "tokens": [
          50914,
          440,
          2734,
          307,
          264,
          3480,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.24643708813575008,
        "compression_ratio": 1.414012738853503,
        "end": 1609.36,
        "id": 504,
        "no_speech_prob": 0.0018969030352309346,
        "seek": 158636,
        "start": 1599.36,
        "temperature": 0,
        "text": " This is actually kind of like a bug because it's not looking in the local directory unless you specifically do the./.",
        "tokens": [
          51014,
          639,
          307,
          767,
          733,
          295,
          411,
          257,
          7426,
          570,
          309,
          311,
          406,
          1237,
          294,
          264,
          2654,
          21120,
          5969,
          291,
          4682,
          360,
          264,
          2411,
          48550,
          51514
        ]
      },
      {
        "avg_logprob": -0.24643708813575008,
        "compression_ratio": 1.414012738853503,
        "end": 1614.36,
        "id": 505,
        "no_speech_prob": 0.0018969030352309346,
        "seek": 158636,
        "start": 1609.36,
        "temperature": 0,
        "text": " I think it would be simpler to let the user just do this.",
        "tokens": [
          51514,
          286,
          519,
          309,
          576,
          312,
          18587,
          281,
          718,
          264,
          4195,
          445,
          360,
          341,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20967892677553238,
        "compression_ratio": 1.0493827160493827,
        "end": 1618.36,
        "id": 506,
        "no_speech_prob": 0.03409780561923981,
        "seek": 161436,
        "start": 1614.36,
        "temperature": 0,
        "text": " That is a bug to file.",
        "tokens": [
          50364,
          663,
          307,
          257,
          7426,
          281,
          3991,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.20967892677553238,
        "compression_ratio": 1.0493827160493827,
        "end": 1623.36,
        "id": 507,
        "no_speech_prob": 0.03409780561923981,
        "seek": 161436,
        "start": 1618.36,
        "temperature": 0,
        "text": " Let me do that real quick.",
        "tokens": [
          50564,
          961,
          385,
          360,
          300,
          957,
          1702,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20967892677553238,
        "compression_ratio": 1.0493827160493827,
        "end": 1635.36,
        "id": 508,
        "no_speech_prob": 0.03409780561923981,
        "seek": 161436,
        "start": 1623.36,
        "temperature": 0,
        "text": " I won't worry about that right now.",
        "tokens": [
          50814,
          286,
          1582,
          380,
          3292,
          466,
          300,
          558,
          586,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.4694148699442546,
        "compression_ratio": 1.0246913580246915,
        "end": 1638.36,
        "id": 509,
        "no_speech_prob": 0.2421184778213501,
        "seek": 163536,
        "start": 1636.36,
        "temperature": 0,
        "text": " What is this?",
        "tokens": [
          50414,
          708,
          307,
          341,
          30,
          50514
        ]
      },
      {
        "avg_logprob": -0.4694148699442546,
        "compression_ratio": 1.0246913580246915,
        "end": 1650.36,
        "id": 510,
        "no_speech_prob": 0.2421184778213501,
        "seek": 163536,
        "start": 1638.36,
        "temperature": 0,
        "text": " Feature extractor model loading relative path.",
        "tokens": [
          50514,
          3697,
          1503,
          8947,
          284,
          2316,
          15114,
          4972,
          3100,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.4694148699442546,
        "compression_ratio": 1.0246913580246915,
        "end": 1652.36,
        "id": 511,
        "no_speech_prob": 0.2421184778213501,
        "seek": 163536,
        "start": 1650.36,
        "temperature": 0,
        "text": " Is this?",
        "tokens": [
          51114,
          1119,
          341,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.4694148699442546,
        "compression_ratio": 1.0246913580246915,
        "end": 1656.36,
        "id": 512,
        "no_speech_prob": 0.2421184778213501,
        "seek": 163536,
        "start": 1652.36,
        "temperature": 0,
        "text": " Look at this.",
        "tokens": [
          51214,
          2053,
          412,
          341,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.40467552038339466,
        "compression_ratio": 1.2,
        "end": 1660.36,
        "id": 513,
        "no_speech_prob": 0.7052714228630066,
        "seek": 165636,
        "start": 1657.36,
        "temperature": 0,
        "text": " The following works.",
        "tokens": [
          50414,
          440,
          3480,
          1985,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.40467552038339466,
        "compression_ratio": 1.2,
        "end": 1666.36,
        "id": 514,
        "no_speech_prob": 0.7052714228630066,
        "seek": 165636,
        "start": 1660.36,
        "temperature": 0,
        "text": " Making a live example live on YouTube right now.",
        "tokens": [
          50564,
          14595,
          257,
          1621,
          1365,
          1621,
          322,
          3088,
          558,
          586,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.40467552038339466,
        "compression_ratio": 1.2,
        "end": 1680.36,
        "id": 515,
        "no_speech_prob": 0.7052714228630066,
        "seek": 165636,
        "start": 1666.36,
        "temperature": 0,
        "text": " The following works.",
        "tokens": [
          50864,
          440,
          3480,
          1985,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.28064795544272975,
        "compression_ratio": 1.2543859649122806,
        "end": 1688.36,
        "id": 516,
        "no_speech_prob": 0.5075811147689819,
        "seek": 168036,
        "start": 1681.36,
        "temperature": 0,
        "text": " We're just referencing the file name and expecting it to be the local path.",
        "tokens": [
          50414,
          492,
          434,
          445,
          40582,
          264,
          3991,
          1315,
          293,
          9650,
          309,
          281,
          312,
          264,
          2654,
          3100,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.28064795544272975,
        "compression_ratio": 1.2543859649122806,
        "end": 1704.36,
        "id": 517,
        "no_speech_prob": 0.5075811147689819,
        "seek": 168036,
        "start": 1688.36,
        "temperature": 0,
        "text": " Doesn't work because it looks for model.weights.bin somewhere else.",
        "tokens": [
          50764,
          12955,
          380,
          589,
          570,
          309,
          1542,
          337,
          2316,
          13,
          826,
          5761,
          13,
          13496,
          4079,
          1646,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.4533920790019788,
        "compression_ratio": 0.8979591836734694,
        "end": 1713.36,
        "id": 518,
        "no_speech_prob": 0.7823397517204285,
        "seek": 170436,
        "start": 1705.36,
        "temperature": 0,
        "text": " We can get it to work.",
        "tokens": [
          50414,
          492,
          393,
          483,
          309,
          281,
          589,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.4533920790019788,
        "compression_ratio": 0.8979591836734694,
        "end": 1722.36,
        "id": 519,
        "no_speech_prob": 0.7823397517204285,
        "seek": 170436,
        "start": 1713.36,
        "temperature": 0,
        "text": " Let's get this error.",
        "tokens": [
          50814,
          961,
          311,
          483,
          341,
          6713,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.31589582231309676,
        "compression_ratio": 0.8333333333333334,
        "end": 1741.36,
        "id": 520,
        "no_speech_prob": 0.20176346600055695,
        "seek": 172236,
        "start": 1723.36,
        "temperature": 0,
        "text": " Let's go back to GitHub here.",
        "tokens": [
          50414,
          961,
          311,
          352,
          646,
          281,
          23331,
          510,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.31589582231309676,
        "compression_ratio": 0.8333333333333334,
        "end": 1743.36,
        "id": 521,
        "no_speech_prob": 0.20176346600055695,
        "seek": 172236,
        "start": 1741.36,
        "temperature": 0,
        "text": " Oh, weird.",
        "tokens": [
          51314,
          876,
          11,
          3657,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.32118880121331467,
        "compression_ratio": 1.0543478260869565,
        "end": 1746.36,
        "id": 522,
        "no_speech_prob": 0.37748339772224426,
        "seek": 174336,
        "start": 1744.36,
        "temperature": 0,
        "text": " It actually did look in the right place.",
        "tokens": [
          50414,
          467,
          767,
          630,
          574,
          294,
          264,
          558,
          1081,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.32118880121331467,
        "compression_ratio": 1.0543478260869565,
        "end": 1754.36,
        "id": 523,
        "no_speech_prob": 0.37748339772224426,
        "seek": 174336,
        "start": 1746.36,
        "temperature": 0,
        "text": " Huh.",
        "tokens": [
          50514,
          8063,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.32118880121331467,
        "compression_ratio": 1.0543478260869565,
        "end": 1756.36,
        "id": 524,
        "no_speech_prob": 0.37748339772224426,
        "seek": 174336,
        "start": 1754.36,
        "temperature": 0,
        "text": " That's weird.",
        "tokens": [
          50914,
          663,
          311,
          3657,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.32118880121331467,
        "compression_ratio": 1.0543478260869565,
        "end": 1760.36,
        "id": 525,
        "no_speech_prob": 0.37748339772224426,
        "seek": 174336,
        "start": 1756.36,
        "temperature": 0,
        "text": " But this is a thing.",
        "tokens": [
          51014,
          583,
          341,
          307,
          257,
          551,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.32118880121331467,
        "compression_ratio": 1.0543478260869565,
        "end": 1770.36,
        "id": 526,
        "no_speech_prob": 0.37748339772224426,
        "seek": 174336,
        "start": 1760.36,
        "temperature": 0,
        "text": " I'm so confused.",
        "tokens": [
          51214,
          286,
          478,
          370,
          9019,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2999870572771345,
        "compression_ratio": 1.225,
        "end": 1776.36,
        "id": 527,
        "no_speech_prob": 0.07920579612255096,
        "seek": 177036,
        "start": 1771.36,
        "temperature": 0,
        "text": " Oh!",
        "tokens": [
          50414,
          876,
          0,
          50664
        ]
      },
      {
        "avg_logprob": -0.2999870572771345,
        "compression_ratio": 1.225,
        "end": 1778.36,
        "id": 528,
        "no_speech_prob": 0.07920579612255096,
        "seek": 177036,
        "start": 1776.36,
        "temperature": 0,
        "text": " It would have worked.",
        "tokens": [
          50664,
          467,
          576,
          362,
          2732,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2999870572771345,
        "compression_ratio": 1.225,
        "end": 1783.36,
        "id": 529,
        "no_speech_prob": 0.07920579612255096,
        "seek": 177036,
        "start": 1778.36,
        "temperature": 0,
        "text": " This is interesting.",
        "tokens": [
          50764,
          639,
          307,
          1880,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2999870572771345,
        "compression_ratio": 1.225,
        "end": 1787.36,
        "id": 530,
        "no_speech_prob": 0.07920579612255096,
        "seek": 177036,
        "start": 1783.36,
        "temperature": 0,
        "text": " It would have worked.",
        "tokens": [
          51014,
          467,
          576,
          362,
          2732,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2999870572771345,
        "compression_ratio": 1.225,
        "end": 1791.36,
        "id": 531,
        "no_speech_prob": 0.07920579612255096,
        "seek": 177036,
        "start": 1787.36,
        "temperature": 0,
        "text": " I'm not being careful enough.",
        "tokens": [
          51214,
          286,
          478,
          406,
          885,
          5026,
          1547,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.21645992877436618,
        "compression_ratio": 1.305084745762712,
        "end": 1808.36,
        "id": 532,
        "no_speech_prob": 0.31062254309654236,
        "seek": 179136,
        "start": 1792.36,
        "temperature": 0,
        "text": " If I were running the server from here, it works.",
        "tokens": [
          50414,
          759,
          286,
          645,
          2614,
          264,
          7154,
          490,
          510,
          11,
          309,
          1985,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.21645992877436618,
        "compression_ratio": 1.305084745762712,
        "end": 1812.36,
        "id": 533,
        "no_speech_prob": 0.31062254309654236,
        "seek": 179136,
        "start": 1808.36,
        "temperature": 0,
        "text": " It works because it's a subfolder.",
        "tokens": [
          51214,
          467,
          1985,
          570,
          309,
          311,
          257,
          1422,
          18353,
          260,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.21645992877436618,
        "compression_ratio": 1.305084745762712,
        "end": 1817.36,
        "id": 534,
        "no_speech_prob": 0.31062254309654236,
        "seek": 179136,
        "start": 1812.36,
        "temperature": 0,
        "text": " But I feel like it should figure out that it's in a subfolder.",
        "tokens": [
          51414,
          583,
          286,
          841,
          411,
          309,
          820,
          2573,
          484,
          300,
          309,
          311,
          294,
          257,
          1422,
          18353,
          260,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21645992877436618,
        "compression_ratio": 1.305084745762712,
        "end": 1819.36,
        "id": 535,
        "no_speech_prob": 0.31062254309654236,
        "seek": 179136,
        "start": 1817.36,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          51664,
          1779,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.4073792298634847,
        "compression_ratio": 0.8703703703703703,
        "end": 1824.36,
        "id": 536,
        "no_speech_prob": 0.344937801361084,
        "seek": 181936,
        "start": 1819.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.4073792298634847,
        "compression_ratio": 0.8703703703703703,
        "end": 1836.36,
        "id": 537,
        "no_speech_prob": 0.344937801361084,
        "seek": 181936,
        "start": 1824.36,
        "temperature": 0,
        "text": " I've got to change my error message here.",
        "tokens": [
          50614,
          286,
          600,
          658,
          281,
          1319,
          452,
          6713,
          3636,
          510,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.22837127172029936,
        "compression_ratio": 1.1666666666666667,
        "end": 1852.36,
        "id": 538,
        "no_speech_prob": 0.8002147674560547,
        "seek": 183636,
        "start": 1836.36,
        "temperature": 0,
        "text": " If the sketch is not at the root path, I can load the model via a relative path as follows.",
        "tokens": [
          50364,
          759,
          264,
          12325,
          307,
          406,
          412,
          264,
          5593,
          3100,
          11,
          286,
          393,
          3677,
          264,
          2316,
          5766,
          257,
          4972,
          3100,
          382,
          10002,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.26754535328258167,
        "compression_ratio": 1.0136986301369864,
        "end": 1879.36,
        "id": 539,
        "no_speech_prob": 0.7484567165374756,
        "seek": 185236,
        "start": 1852.36,
        "temperature": 0,
        "text": " However, if I look for model.json with a relative path like the following,",
        "tokens": [
          50364,
          2908,
          11,
          498,
          286,
          574,
          337,
          2316,
          13,
          73,
          3015,
          365,
          257,
          4972,
          3100,
          411,
          264,
          3480,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.2453271181155474,
        "compression_ratio": 1.2522522522522523,
        "end": 1888.36,
        "id": 540,
        "no_speech_prob": 0.5846495032310486,
        "seek": 187936,
        "start": 1879.36,
        "temperature": 0,
        "text": " it then looks in the root directory for model.weights.bin.",
        "tokens": [
          50364,
          309,
          550,
          1542,
          294,
          264,
          5593,
          21120,
          337,
          2316,
          13,
          826,
          5761,
          13,
          13496,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2453271181155474,
        "compression_ratio": 1.2522522522522523,
        "end": 1898.36,
        "id": 541,
        "no_speech_prob": 0.5846495032310486,
        "seek": 187936,
        "start": 1888.36,
        "temperature": 0,
        "text": " This is minor for my example, but noting as it's an error people will encounter.",
        "tokens": [
          50814,
          639,
          307,
          6696,
          337,
          452,
          1365,
          11,
          457,
          26801,
          382,
          309,
          311,
          364,
          6713,
          561,
          486,
          8593,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.28956362886248893,
        "compression_ratio": 1.451851851851852,
        "end": 1910.36,
        "id": 542,
        "no_speech_prob": 0.7305411100387573,
        "seek": 189836,
        "start": 1899.36,
        "temperature": 0,
        "text": " Is it trivial to support looking always in...",
        "tokens": [
          50414,
          1119,
          309,
          26703,
          281,
          1406,
          1237,
          1009,
          294,
          485,
          50964
        ]
      },
      {
        "avg_logprob": -0.28956362886248893,
        "compression_ratio": 1.451851851851852,
        "end": 1912.36,
        "id": 543,
        "no_speech_prob": 0.7305411100387573,
        "seek": 189836,
        "start": 1910.36,
        "temperature": 0,
        "text": " So I think this is...",
        "tokens": [
          50964,
          407,
          286,
          519,
          341,
          307,
          485,
          51064
        ]
      },
      {
        "avg_logprob": -0.28956362886248893,
        "compression_ratio": 1.451851851851852,
        "end": 1921.36,
        "id": 544,
        "no_speech_prob": 0.7305411100387573,
        "seek": 189836,
        "start": 1912.36,
        "temperature": 0,
        "text": " If the sketch is not at the root path, I can load the model via the current directory.",
        "tokens": [
          51064,
          759,
          264,
          12325,
          307,
          406,
          412,
          264,
          5593,
          3100,
          11,
          286,
          393,
          3677,
          264,
          2316,
          5766,
          264,
          2190,
          21120,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.28956362886248893,
        "compression_ratio": 1.451851851851852,
        "end": 1925.36,
        "id": 545,
        "no_speech_prob": 0.7305411100387573,
        "seek": 189836,
        "start": 1921.36,
        "temperature": 0,
        "text": " At the current path directory as follows.",
        "tokens": [
          51514,
          1711,
          264,
          2190,
          3100,
          21120,
          382,
          10002,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.25934314727783203,
        "compression_ratio": 1.4435483870967742,
        "end": 1941.36,
        "id": 546,
        "no_speech_prob": 0.21719110012054443,
        "seek": 192536,
        "start": 1925.36,
        "temperature": 0,
        "text": " If I ask for model.json as follow, this way, it then looks in the root directory for model.weights.bin.",
        "tokens": [
          50364,
          759,
          286,
          1029,
          337,
          2316,
          13,
          73,
          3015,
          382,
          1524,
          11,
          341,
          636,
          11,
          309,
          550,
          1542,
          294,
          264,
          5593,
          21120,
          337,
          2316,
          13,
          826,
          5761,
          13,
          13496,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.25934314727783203,
        "compression_ratio": 1.4435483870967742,
        "end": 1949.36,
        "id": 547,
        "no_speech_prob": 0.21719110012054443,
        "seek": 192536,
        "start": 1941.36,
        "temperature": 0,
        "text": " Let me submit this.",
        "tokens": [
          51164,
          961,
          385,
          10315,
          341,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.25934314727783203,
        "compression_ratio": 1.4435483870967742,
        "end": 1952.36,
        "id": 548,
        "no_speech_prob": 0.21719110012054443,
        "seek": 192536,
        "start": 1949.36,
        "temperature": 0,
        "text": " Yeah. Let me submit this.",
        "tokens": [
          51564,
          865,
          13,
          961,
          385,
          10315,
          341,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.25934314727783203,
        "compression_ratio": 1.4435483870967742,
        "end": 1954.36,
        "id": 549,
        "no_speech_prob": 0.21719110012054443,
        "seek": 192536,
        "start": 1952.36,
        "temperature": 0,
        "text": " I think this makes sense now.",
        "tokens": [
          51714,
          286,
          519,
          341,
          1669,
          2020,
          586,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2423944311626887,
        "compression_ratio": 1.4710743801652892,
        "end": 1959.36,
        "id": 550,
        "no_speech_prob": 0.7168744206428528,
        "seek": 195436,
        "start": 1954.36,
        "temperature": 0,
        "text": " Apologies if this issue is weird because I'm doing this in a live stream.",
        "tokens": [
          50364,
          8723,
          6204,
          498,
          341,
          2734,
          307,
          3657,
          570,
          286,
          478,
          884,
          341,
          294,
          257,
          1621,
          4309,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2423944311626887,
        "compression_ratio": 1.4710743801652892,
        "end": 1963.36,
        "id": 551,
        "no_speech_prob": 0.7168744206428528,
        "seek": 195436,
        "start": 1959.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50614,
          1033,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2423944311626887,
        "compression_ratio": 1.4710743801652892,
        "end": 1965.36,
        "id": 552,
        "no_speech_prob": 0.7168744206428528,
        "seek": 195436,
        "start": 1963.36,
        "temperature": 0,
        "text": " I'm actually...",
        "tokens": [
          50814,
          286,
          478,
          767,
          485,
          50914
        ]
      },
      {
        "avg_logprob": -0.2423944311626887,
        "compression_ratio": 1.4710743801652892,
        "end": 1968.36,
        "id": 553,
        "no_speech_prob": 0.7168744206428528,
        "seek": 195436,
        "start": 1965.36,
        "temperature": 0,
        "text": " We're going to fake this here.",
        "tokens": [
          50914,
          492,
          434,
          516,
          281,
          7592,
          341,
          510,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2423944311626887,
        "compression_ratio": 1.4710743801652892,
        "end": 1977.36,
        "id": 554,
        "no_speech_prob": 0.7168744206428528,
        "seek": 195436,
        "start": 1968.36,
        "temperature": 0,
        "text": " No one will notice.",
        "tokens": [
          51064,
          883,
          472,
          486,
          3449,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2423944311626887,
        "compression_ratio": 1.4710743801652892,
        "end": 1980.36,
        "id": 555,
        "no_speech_prob": 0.7168744206428528,
        "seek": 195436,
        "start": 1977.36,
        "temperature": 0,
        "text": " Okay. We're going to fake this.",
        "tokens": [
          51514,
          1033,
          13,
          492,
          434,
          516,
          281,
          7592,
          341,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2145012201887838,
        "compression_ratio": 1.4943820224719102,
        "end": 1992.36,
        "id": 556,
        "no_speech_prob": 0.14408978819847107,
        "seek": 198036,
        "start": 1980.36,
        "temperature": 0,
        "text": " So, Mathieu, I'm not going to show that error, actually, because that error is irrelevant to what I'm doing here.",
        "tokens": [
          50364,
          407,
          11,
          15776,
          19347,
          11,
          286,
          478,
          406,
          516,
          281,
          855,
          300,
          6713,
          11,
          767,
          11,
          570,
          300,
          6713,
          307,
          28682,
          281,
          437,
          286,
          478,
          884,
          510,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2145012201887838,
        "compression_ratio": 1.4943820224719102,
        "end": 1997.36,
        "id": 557,
        "no_speech_prob": 0.14408978819847107,
        "seek": 198036,
        "start": 1992.36,
        "temperature": 0,
        "text": " So let's see if I can get it to work just like this.",
        "tokens": [
          50964,
          407,
          718,
          311,
          536,
          498,
          286,
          393,
          483,
          309,
          281,
          589,
          445,
          411,
          341,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2145012201887838,
        "compression_ratio": 1.4943820224719102,
        "end": 1998.36,
        "id": 558,
        "no_speech_prob": 0.14408978819847107,
        "seek": 198036,
        "start": 1997.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51214,
          1033,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2145012201887838,
        "compression_ratio": 1.4943820224719102,
        "end": 2000.36,
        "id": 559,
        "no_speech_prob": 0.14408978819847107,
        "seek": 198036,
        "start": 1998.36,
        "temperature": 0,
        "text": " Because I think that will get fixed later.",
        "tokens": [
          51264,
          1436,
          286,
          519,
          300,
          486,
          483,
          6806,
          1780,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2145012201887838,
        "compression_ratio": 1.4943820224719102,
        "end": 2002.36,
        "id": 560,
        "no_speech_prob": 0.14408978819847107,
        "seek": 198036,
        "start": 2000.36,
        "temperature": 0,
        "text": " I hope. Okay.",
        "tokens": [
          51364,
          286,
          1454,
          13,
          1033,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2145012201887838,
        "compression_ratio": 1.4943820224719102,
        "end": 2004.36,
        "id": 561,
        "no_speech_prob": 0.14408978819847107,
        "seek": 198036,
        "start": 2002.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51464,
          1033,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2145012201887838,
        "compression_ratio": 1.4943820224719102,
        "end": 2006.36,
        "id": 562,
        "no_speech_prob": 0.14408978819847107,
        "seek": 198036,
        "start": 2004.36,
        "temperature": 0,
        "text": " Let's go back.",
        "tokens": [
          51564,
          961,
          311,
          352,
          646,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2145012201887838,
        "compression_ratio": 1.4943820224719102,
        "end": 2009.36,
        "id": 563,
        "no_speech_prob": 0.14408978819847107,
        "seek": 198036,
        "start": 2006.36,
        "temperature": 0,
        "text": " That's no good.",
        "tokens": [
          51664,
          663,
          311,
          572,
          665,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.24553764567655675,
        "compression_ratio": 1.3656716417910448,
        "end": 2021.36,
        "id": 564,
        "no_speech_prob": 0.001432514633052051,
        "seek": 200936,
        "start": 2009.36,
        "temperature": 0,
        "text": " So how do I... Hold on.",
        "tokens": [
          50364,
          407,
          577,
          360,
          286,
          485,
          6962,
          322,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.24553764567655675,
        "compression_ratio": 1.3656716417910448,
        "end": 2022.36,
        "id": 565,
        "no_speech_prob": 0.001432514633052051,
        "seek": 200936,
        "start": 2021.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50964,
          1057,
          558,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.24553764567655675,
        "compression_ratio": 1.3656716417910448,
        "end": 2026.36,
        "id": 566,
        "no_speech_prob": 0.001432514633052051,
        "seek": 200936,
        "start": 2022.36,
        "temperature": 0,
        "text": " Let's try now loading that model.",
        "tokens": [
          51014,
          961,
          311,
          853,
          586,
          15114,
          300,
          2316,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.24553764567655675,
        "compression_ratio": 1.3656716417910448,
        "end": 2028.36,
        "id": 567,
        "no_speech_prob": 0.001432514633052051,
        "seek": 200936,
        "start": 2026.36,
        "temperature": 0,
        "text": " I'm going to hit refresh.",
        "tokens": [
          51214,
          286,
          478,
          516,
          281,
          2045,
          15134,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.24553764567655675,
        "compression_ratio": 1.3656716417910448,
        "end": 2029.36,
        "id": 568,
        "no_speech_prob": 0.001432514633052051,
        "seek": 200936,
        "start": 2028.36,
        "temperature": 0,
        "text": " Model's ready. Video's ready.",
        "tokens": [
          51314,
          17105,
          311,
          1919,
          13,
          9777,
          311,
          1919,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.24553764567655675,
        "compression_ratio": 1.3656716417910448,
        "end": 2030.36,
        "id": 569,
        "no_speech_prob": 0.001432514633052051,
        "seek": 200936,
        "start": 2029.36,
        "temperature": 0,
        "text": " Custom model is ready.",
        "tokens": [
          51364,
          16649,
          2316,
          307,
          1919,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.24553764567655675,
        "compression_ratio": 1.3656716417910448,
        "end": 2033.36,
        "id": 570,
        "no_speech_prob": 0.001432514633052051,
        "seek": 200936,
        "start": 2030.36,
        "temperature": 0,
        "text": " So it's been loaded.",
        "tokens": [
          51414,
          407,
          309,
          311,
          668,
          13210,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.24553764567655675,
        "compression_ratio": 1.3656716417910448,
        "end": 2036.36,
        "id": 571,
        "no_speech_prob": 0.001432514633052051,
        "seek": 200936,
        "start": 2033.36,
        "temperature": 0,
        "text": " But I'm not...",
        "tokens": [
          51564,
          583,
          286,
          478,
          406,
          485,
          51714
        ]
      },
      {
        "avg_logprob": -0.21832701255535258,
        "compression_ratio": 1.7272727272727273,
        "end": 2038.36,
        "id": 572,
        "no_speech_prob": 0.26890069246292114,
        "seek": 203636,
        "start": 2036.36,
        "temperature": 0,
        "text": " I'm not seeing the labels.",
        "tokens": [
          50364,
          286,
          478,
          406,
          2577,
          264,
          16949,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.21832701255535258,
        "compression_ratio": 1.7272727272727273,
        "end": 2042.36,
        "id": 573,
        "no_speech_prob": 0.26890069246292114,
        "seek": 203636,
        "start": 2038.36,
        "temperature": 0,
        "text": " So even though that model was loaded, I now have to figure out...",
        "tokens": [
          50464,
          407,
          754,
          1673,
          300,
          2316,
          390,
          13210,
          11,
          286,
          586,
          362,
          281,
          2573,
          484,
          485,
          50664
        ]
      },
      {
        "avg_logprob": -0.21832701255535258,
        "compression_ratio": 1.7272727272727273,
        "end": 2047.36,
        "id": 574,
        "no_speech_prob": 0.26890069246292114,
        "seek": 203636,
        "start": 2042.36,
        "temperature": 0,
        "text": " I now have to tell the code no longer really needs to be trained in this case.",
        "tokens": [
          50664,
          286,
          586,
          362,
          281,
          980,
          264,
          3089,
          572,
          2854,
          534,
          2203,
          281,
          312,
          8895,
          294,
          341,
          1389,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.21832701255535258,
        "compression_ratio": 1.7272727272727273,
        "end": 2049.3599999999997,
        "id": 575,
        "no_speech_prob": 0.26890069246292114,
        "seek": 203636,
        "start": 2047.36,
        "temperature": 0,
        "text": " I might want to retrain and do fancy.",
        "tokens": [
          50914,
          286,
          1062,
          528,
          281,
          1533,
          7146,
          293,
          360,
          10247,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.21832701255535258,
        "compression_ratio": 1.7272727272727273,
        "end": 2051.3599999999997,
        "id": 576,
        "no_speech_prob": 0.26890069246292114,
        "seek": 203636,
        "start": 2049.3599999999997,
        "temperature": 0,
        "text": " I'm going to take out the training button.",
        "tokens": [
          51014,
          286,
          478,
          516,
          281,
          747,
          484,
          264,
          3097,
          2960,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21832701255535258,
        "compression_ratio": 1.7272727272727273,
        "end": 2060.3599999999997,
        "id": 577,
        "no_speech_prob": 0.26890069246292114,
        "seek": 203636,
        "start": 2051.3599999999997,
        "temperature": 0,
        "text": " And then somewhere there's like an event where it finished training where I said classifier, classifier got results.",
        "tokens": [
          51114,
          400,
          550,
          4079,
          456,
          311,
          411,
          364,
          2280,
          689,
          309,
          4335,
          3097,
          689,
          286,
          848,
          1508,
          9902,
          11,
          1508,
          9902,
          658,
          3542,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21832701255535258,
        "compression_ratio": 1.7272727272727273,
        "end": 2064.3599999999997,
        "id": 578,
        "no_speech_prob": 0.26890069246292114,
        "seek": 203636,
        "start": 2060.3599999999997,
        "temperature": 0,
        "text": " And so that's what I want to do now when the custom model is ready.",
        "tokens": [
          51564,
          400,
          370,
          300,
          311,
          437,
          286,
          528,
          281,
          360,
          586,
          562,
          264,
          2375,
          2316,
          307,
          1919,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.21804454279880897,
        "compression_ratio": 1.616580310880829,
        "end": 2067.36,
        "id": 579,
        "no_speech_prob": 0.00017674484115559608,
        "seek": 206436,
        "start": 2064.36,
        "temperature": 0,
        "text": " So the events are as follows.",
        "tokens": [
          50364,
          407,
          264,
          3931,
          366,
          382,
          10002,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.21804454279880897,
        "compression_ratio": 1.616580310880829,
        "end": 2070.36,
        "id": 580,
        "no_speech_prob": 0.00017674484115559608,
        "seek": 206436,
        "start": 2067.36,
        "temperature": 0,
        "text": " Let's bring this down here.",
        "tokens": [
          50514,
          961,
          311,
          1565,
          341,
          760,
          510,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.21804454279880897,
        "compression_ratio": 1.616580310880829,
        "end": 2074.36,
        "id": 581,
        "no_speech_prob": 0.00017674484115559608,
        "seek": 206436,
        "start": 2070.36,
        "temperature": 0,
        "text": " First, load the MobileNet model.",
        "tokens": [
          50664,
          2386,
          11,
          3677,
          264,
          22625,
          31890,
          2316,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.21804454279880897,
        "compression_ratio": 1.616580310880829,
        "end": 2079.36,
        "id": 582,
        "no_speech_prob": 0.00017674484115559608,
        "seek": 206436,
        "start": 2074.36,
        "temperature": 0,
        "text": " When the MobileNet model is ready, then load the custom model.",
        "tokens": [
          50864,
          1133,
          264,
          22625,
          31890,
          2316,
          307,
          1919,
          11,
          550,
          3677,
          264,
          2375,
          2316,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21804454279880897,
        "compression_ratio": 1.616580310880829,
        "end": 2082.36,
        "id": 583,
        "no_speech_prob": 0.00017674484115559608,
        "seek": 206436,
        "start": 2079.36,
        "temperature": 0,
        "text": " When the custom model's ready, start classifying the image.",
        "tokens": [
          51114,
          1133,
          264,
          2375,
          2316,
          311,
          1919,
          11,
          722,
          1508,
          5489,
          264,
          3256,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.21804454279880897,
        "compression_ratio": 1.616580310880829,
        "end": 2083.36,
        "id": 584,
        "no_speech_prob": 0.00017674484115559608,
        "seek": 206436,
        "start": 2082.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51264,
          1057,
          558,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.21804454279880897,
        "compression_ratio": 1.616580310880829,
        "end": 2084.36,
        "id": 585,
        "no_speech_prob": 0.00017674484115559608,
        "seek": 206436,
        "start": 2083.36,
        "temperature": 0,
        "text": " So here we go.",
        "tokens": [
          51314,
          407,
          510,
          321,
          352,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.21804454279880897,
        "compression_ratio": 1.616580310880829,
        "end": 2088.36,
        "id": 586,
        "no_speech_prob": 0.00017674484115559608,
        "seek": 206436,
        "start": 2084.36,
        "temperature": 0,
        "text": " Let's...",
        "tokens": [
          51364,
          961,
          311,
          485,
          51564
        ]
      },
      {
        "avg_logprob": -0.21804454279880897,
        "compression_ratio": 1.616580310880829,
        "end": 2091.36,
        "id": 587,
        "no_speech_prob": 0.00017674484115559608,
        "seek": 206436,
        "start": 2088.36,
        "temperature": 0,
        "text": " Ah, yay!",
        "tokens": [
          51564,
          2438,
          11,
          23986,
          0,
          51714
        ]
      },
      {
        "avg_logprob": -0.21804454279880897,
        "compression_ratio": 1.616580310880829,
        "end": 2092.36,
        "id": 588,
        "no_speech_prob": 0.00017674484115559608,
        "seek": 206436,
        "start": 2091.36,
        "temperature": 0,
        "text": " What did I have with this hand?",
        "tokens": [
          51714,
          708,
          630,
          286,
          362,
          365,
          341,
          1011,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.21804454279880897,
        "compression_ratio": 1.616580310880829,
        "end": 2093.36,
        "id": 589,
        "no_speech_prob": 0.00017674484115559608,
        "seek": 206436,
        "start": 2092.36,
        "temperature": 0,
        "text": " I can't even remember.",
        "tokens": [
          51764,
          286,
          393,
          380,
          754,
          1604,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.15189760609676964,
        "compression_ratio": 1.695945945945946,
        "end": 2094.36,
        "id": 590,
        "no_speech_prob": 0.009412388317286968,
        "seek": 209336,
        "start": 2093.36,
        "temperature": 0,
        "text": " No, it was this hand.",
        "tokens": [
          50364,
          883,
          11,
          309,
          390,
          341,
          1011,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.15189760609676964,
        "compression_ratio": 1.695945945945946,
        "end": 2095.36,
        "id": 591,
        "no_speech_prob": 0.009412388317286968,
        "seek": 209336,
        "start": 2094.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50414,
          1057,
          558,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.15189760609676964,
        "compression_ratio": 1.695945945945946,
        "end": 2096.36,
        "id": 592,
        "no_speech_prob": 0.009412388317286968,
        "seek": 209336,
        "start": 2095.36,
        "temperature": 0,
        "text": " So this is working.",
        "tokens": [
          50464,
          407,
          341,
          307,
          1364,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.15189760609676964,
        "compression_ratio": 1.695945945945946,
        "end": 2098.36,
        "id": 593,
        "no_speech_prob": 0.009412388317286968,
        "seek": 209336,
        "start": 2096.36,
        "temperature": 0,
        "text": " Those buttons are now no longer relevant.",
        "tokens": [
          50514,
          3950,
          9905,
          366,
          586,
          572,
          2854,
          7340,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.15189760609676964,
        "compression_ratio": 1.695945945945946,
        "end": 2100.36,
        "id": 594,
        "no_speech_prob": 0.009412388317286968,
        "seek": 209336,
        "start": 2098.36,
        "temperature": 0,
        "text": " So I could actually take all the buttons out.",
        "tokens": [
          50614,
          407,
          286,
          727,
          767,
          747,
          439,
          264,
          9905,
          484,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.15189760609676964,
        "compression_ratio": 1.695945945945946,
        "end": 2101.36,
        "id": 595,
        "no_speech_prob": 0.009412388317286968,
        "seek": 209336,
        "start": 2100.36,
        "temperature": 0,
        "text": " And this is now...",
        "tokens": [
          50714,
          400,
          341,
          307,
          586,
          485,
          50764
        ]
      },
      {
        "avg_logprob": -0.15189760609676964,
        "compression_ratio": 1.695945945945946,
        "end": 2106.36,
        "id": 596,
        "no_speech_prob": 0.009412388317286968,
        "seek": 209336,
        "start": 2101.36,
        "temperature": 0,
        "text": " Again, whether you want to have one sketch where you train and save and load or two different ones.",
        "tokens": [
          50764,
          3764,
          11,
          1968,
          291,
          528,
          281,
          362,
          472,
          12325,
          689,
          291,
          3847,
          293,
          3155,
          293,
          3677,
          420,
          732,
          819,
          2306,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.15189760609676964,
        "compression_ratio": 1.695945945945946,
        "end": 2108.36,
        "id": 597,
        "no_speech_prob": 0.009412388317286968,
        "seek": 209336,
        "start": 2106.36,
        "temperature": 0,
        "text": " But I'll just show you right now.",
        "tokens": [
          51014,
          583,
          286,
          603,
          445,
          855,
          291,
          558,
          586,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.15189760609676964,
        "compression_ratio": 1.695945945945946,
        "end": 2110.36,
        "id": 598,
        "no_speech_prob": 0.009412388317286968,
        "seek": 209336,
        "start": 2108.36,
        "temperature": 0,
        "text": " The idea here is I did my training.",
        "tokens": [
          51114,
          440,
          1558,
          510,
          307,
          286,
          630,
          452,
          3097,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.15189760609676964,
        "compression_ratio": 1.695945945945946,
        "end": 2111.36,
        "id": 599,
        "no_speech_prob": 0.009412388317286968,
        "seek": 209336,
        "start": 2110.36,
        "temperature": 0,
        "text": " I'm done.",
        "tokens": [
          51214,
          286,
          478,
          1096,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.15189760609676964,
        "compression_ratio": 1.695945945945946,
        "end": 2114.36,
        "id": 600,
        "no_speech_prob": 0.009412388317286968,
        "seek": 209336,
        "start": 2111.36,
        "temperature": 0,
        "text": " And now I have something that automatically loads the model.",
        "tokens": [
          51264,
          400,
          586,
          286,
          362,
          746,
          300,
          6772,
          12668,
          264,
          2316,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.15189760609676964,
        "compression_ratio": 1.695945945945946,
        "end": 2115.36,
        "id": 601,
        "no_speech_prob": 0.009412388317286968,
        "seek": 209336,
        "start": 2114.36,
        "temperature": 0,
        "text": " Yay!",
        "tokens": [
          51414,
          13268,
          0,
          51464
        ]
      },
      {
        "avg_logprob": -0.15189760609676964,
        "compression_ratio": 1.695945945945946,
        "end": 2116.36,
        "id": 602,
        "no_speech_prob": 0.009412388317286968,
        "seek": 209336,
        "start": 2115.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51464,
          1057,
          558,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.15189760609676964,
        "compression_ratio": 1.695945945945946,
        "end": 2117.36,
        "id": 603,
        "no_speech_prob": 0.009412388317286968,
        "seek": 209336,
        "start": 2116.36,
        "temperature": 0,
        "text": " So I hope this was helpful.",
        "tokens": [
          51514,
          407,
          286,
          1454,
          341,
          390,
          4961,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.15189760609676964,
        "compression_ratio": 1.695945945945946,
        "end": 2119.36,
        "id": 604,
        "no_speech_prob": 0.009412388317286968,
        "seek": 209336,
        "start": 2117.36,
        "temperature": 0,
        "text": " You can now see that process, right?",
        "tokens": [
          51564,
          509,
          393,
          586,
          536,
          300,
          1399,
          11,
          558,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.15189760609676964,
        "compression_ratio": 1.695945945945946,
        "end": 2120.36,
        "id": 605,
        "no_speech_prob": 0.009412388317286968,
        "seek": 209336,
        "start": 2119.36,
        "temperature": 0,
        "text": " What is the process?",
        "tokens": [
          51664,
          708,
          307,
          264,
          1399,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.183206268836712,
        "compression_ratio": 1.7392857142857143,
        "end": 2122.36,
        "id": 606,
        "no_speech_prob": 0.25382357835769653,
        "seek": 212036,
        "start": 2121.36,
        "temperature": 0,
        "text": " Train the model.",
        "tokens": [
          50414,
          28029,
          264,
          2316,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.183206268836712,
        "compression_ratio": 1.7392857142857143,
        "end": 2127.36,
        "id": 607,
        "no_speech_prob": 0.25382357835769653,
        "seek": 212036,
        "start": 2122.36,
        "temperature": 0,
        "text": " Call the save function to download model.json and model.weights.bin.",
        "tokens": [
          50464,
          7807,
          264,
          3155,
          2445,
          281,
          5484,
          2316,
          13,
          73,
          3015,
          293,
          2316,
          13,
          826,
          5761,
          13,
          13496,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.183206268836712,
        "compression_ratio": 1.7392857142857143,
        "end": 2129.36,
        "id": 608,
        "no_speech_prob": 0.25382357835769653,
        "seek": 212036,
        "start": 2127.36,
        "temperature": 0,
        "text": " Then take those files into your sketch.",
        "tokens": [
          50714,
          1396,
          747,
          729,
          7098,
          666,
          428,
          12325,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.183206268836712,
        "compression_ratio": 1.7392857142857143,
        "end": 2131.36,
        "id": 609,
        "no_speech_prob": 0.25382357835769653,
        "seek": 212036,
        "start": 2129.36,
        "temperature": 0,
        "text": " Use the load function to load them both.",
        "tokens": [
          50814,
          8278,
          264,
          3677,
          2445,
          281,
          3677,
          552,
          1293,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.183206268836712,
        "compression_ratio": 1.7392857142857143,
        "end": 2133.36,
        "id": 610,
        "no_speech_prob": 0.25382357835769653,
        "seek": 212036,
        "start": 2131.36,
        "temperature": 0,
        "text": " And then start classifying.",
        "tokens": [
          50914,
          400,
          550,
          722,
          1508,
          5489,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.183206268836712,
        "compression_ratio": 1.7392857142857143,
        "end": 2134.36,
        "id": 611,
        "no_speech_prob": 0.25382357835769653,
        "seek": 212036,
        "start": 2133.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51014,
          1057,
          558,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.183206268836712,
        "compression_ratio": 1.7392857142857143,
        "end": 2135.36,
        "id": 612,
        "no_speech_prob": 0.25382357835769653,
        "seek": 212036,
        "start": 2134.36,
        "temperature": 0,
        "text": " So give this a try.",
        "tokens": [
          51064,
          407,
          976,
          341,
          257,
          853,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.183206268836712,
        "compression_ratio": 1.7392857142857143,
        "end": 2142.36,
        "id": 613,
        "no_speech_prob": 0.25382357835769653,
        "seek": 212036,
        "start": 2135.36,
        "temperature": 0,
        "text": " See what you can do now that you can spend a lot of time training your model because you can save it and see what you make with it.",
        "tokens": [
          51114,
          3008,
          437,
          291,
          393,
          360,
          586,
          300,
          291,
          393,
          3496,
          257,
          688,
          295,
          565,
          3097,
          428,
          2316,
          570,
          291,
          393,
          3155,
          309,
          293,
          536,
          437,
          291,
          652,
          365,
          309,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.183206268836712,
        "compression_ratio": 1.7392857142857143,
        "end": 2143.36,
        "id": 614,
        "no_speech_prob": 0.25382357835769653,
        "seek": 212036,
        "start": 2142.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51464,
          1057,
          558,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.183206268836712,
        "compression_ratio": 1.7392857142857143,
        "end": 2144.36,
        "id": 615,
        "no_speech_prob": 0.25382357835769653,
        "seek": 212036,
        "start": 2143.36,
        "temperature": 0,
        "text": " Thanks for watching.",
        "tokens": [
          51514,
          2561,
          337,
          1976,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.183206268836712,
        "compression_ratio": 1.7392857142857143,
        "end": 2145.36,
        "id": 616,
        "no_speech_prob": 0.25382357835769653,
        "seek": 212036,
        "start": 2144.36,
        "temperature": 0,
        "text": " And I will see you in another ML...",
        "tokens": [
          51564,
          400,
          286,
          486,
          536,
          291,
          294,
          1071,
          21601,
          485,
          51614
        ]
      },
      {
        "avg_logprob": -0.183206268836712,
        "compression_ratio": 1.7392857142857143,
        "end": 2147.36,
        "id": 617,
        "no_speech_prob": 0.25382357835769653,
        "seek": 212036,
        "start": 2145.36,
        "temperature": 0,
        "text": " There will be more ML5 videos.",
        "tokens": [
          51614,
          821,
          486,
          312,
          544,
          21601,
          20,
          2145,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.183206268836712,
        "compression_ratio": 1.7392857142857143,
        "end": 2148.36,
        "id": 618,
        "no_speech_prob": 0.25382357835769653,
        "seek": 212036,
        "start": 2147.36,
        "temperature": 0,
        "text": " I don't even know what's next.",
        "tokens": [
          51714,
          286,
          500,
          380,
          754,
          458,
          437,
          311,
          958,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2518754959106445,
        "compression_ratio": 1.2907801418439717,
        "end": 2150.36,
        "id": 619,
        "no_speech_prob": 0.06187049672007561,
        "seek": 214836,
        "start": 2148.36,
        "temperature": 0,
        "text": " But if there's a video that's next, you can watch it.",
        "tokens": [
          50364,
          583,
          498,
          456,
          311,
          257,
          960,
          300,
          311,
          958,
          11,
          291,
          393,
          1159,
          309,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2518754959106445,
        "compression_ratio": 1.2907801418439717,
        "end": 2151.36,
        "id": 620,
        "no_speech_prob": 0.06187049672007561,
        "seek": 214836,
        "start": 2150.36,
        "temperature": 0,
        "text": " Goodbye.",
        "tokens": [
          50464,
          15528,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2518754959106445,
        "compression_ratio": 1.2907801418439717,
        "end": 2154.36,
        "id": 621,
        "no_speech_prob": 0.06187049672007561,
        "seek": 214836,
        "start": 2151.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50514,
          1057,
          558,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2518754959106445,
        "compression_ratio": 1.2907801418439717,
        "end": 2169.36,
        "id": 622,
        "no_speech_prob": 0.06187049672007561,
        "seek": 214836,
        "start": 2154.36,
        "temperature": 0,
        "text": " Hopefully that can be made into something understandable.",
        "tokens": [
          50664,
          10429,
          300,
          393,
          312,
          1027,
          666,
          746,
          25648,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2518754959106445,
        "compression_ratio": 1.2907801418439717,
        "end": 2170.36,
        "id": 623,
        "no_speech_prob": 0.06187049672007561,
        "seek": 214836,
        "start": 2169.36,
        "temperature": 0,
        "text": " I wonder what would happen if...",
        "tokens": [
          51414,
          286,
          2441,
          437,
          576,
          1051,
          498,
          485,
          51464
        ]
      },
      {
        "avg_logprob": -0.2518754959106445,
        "compression_ratio": 1.2907801418439717,
        "end": 2171.36,
        "id": 624,
        "no_speech_prob": 0.06187049672007561,
        "seek": 214836,
        "start": 2170.36,
        "temperature": 0,
        "text": " I'm just curious.",
        "tokens": [
          51464,
          286,
          478,
          445,
          6369,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.18538481848580496,
        "compression_ratio": 1.2741935483870968,
        "end": 2185.36,
        "id": 625,
        "no_speech_prob": 0.41100335121154785,
        "seek": 217136,
        "start": 2171.36,
        "temperature": 0,
        "text": " What would happen if I retrained it?",
        "tokens": [
          50364,
          708,
          576,
          1051,
          498,
          286,
          1533,
          31774,
          309,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.18538481848580496,
        "compression_ratio": 1.2741935483870968,
        "end": 2186.36,
        "id": 626,
        "no_speech_prob": 0.41100335121154785,
        "seek": 217136,
        "start": 2185.36,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51064,
          865,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18538481848580496,
        "compression_ratio": 1.2741935483870968,
        "end": 2191.36,
        "id": 627,
        "no_speech_prob": 0.41100335121154785,
        "seek": 217136,
        "start": 2186.36,
        "temperature": 0,
        "text": " I guess it retrains.",
        "tokens": [
          51114,
          286,
          2041,
          309,
          1533,
          424,
          1292,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18538481848580496,
        "compression_ratio": 1.2741935483870968,
        "end": 2192.36,
        "id": 628,
        "no_speech_prob": 0.41100335121154785,
        "seek": 217136,
        "start": 2191.36,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51364,
          865,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18538481848580496,
        "compression_ratio": 1.2741935483870968,
        "end": 2194.36,
        "id": 629,
        "no_speech_prob": 0.41100335121154785,
        "seek": 217136,
        "start": 2192.36,
        "temperature": 0,
        "text": " But then if I refresh, it's loading that previous model.",
        "tokens": [
          51414,
          583,
          550,
          498,
          286,
          15134,
          11,
          309,
          311,
          15114,
          300,
          3894,
          2316,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.18538481848580496,
        "compression_ratio": 1.2741935483870968,
        "end": 2195.36,
        "id": 630,
        "no_speech_prob": 0.41100335121154785,
        "seek": 217136,
        "start": 2194.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51514,
          1033,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18538481848580496,
        "compression_ratio": 1.2741935483870968,
        "end": 2199.36,
        "id": 631,
        "no_speech_prob": 0.41100335121154785,
        "seek": 217136,
        "start": 2195.36,
        "temperature": 0,
        "text": " Any questions about this?",
        "tokens": [
          51564,
          2639,
          1651,
          466,
          341,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.20463602883475168,
        "compression_ratio": 1.7013574660633484,
        "end": 2201.36,
        "id": 632,
        "no_speech_prob": 0.5037551522254944,
        "seek": 219936,
        "start": 2199.36,
        "temperature": 0,
        "text": " Will JS always load the setup function?",
        "tokens": [
          50364,
          3099,
          33063,
          1009,
          3677,
          264,
          8657,
          2445,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.20463602883475168,
        "compression_ratio": 1.7013574660633484,
        "end": 2203.36,
        "id": 633,
        "no_speech_prob": 0.5037551522254944,
        "seek": 219936,
        "start": 2201.36,
        "temperature": 0,
        "text": " Automatic asks Tobias.",
        "tokens": [
          50464,
          6049,
          13143,
          8962,
          26350,
          4609,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.20463602883475168,
        "compression_ratio": 1.7013574660633484,
        "end": 2206.36,
        "id": 634,
        "no_speech_prob": 0.5037551522254944,
        "seek": 219936,
        "start": 2203.36,
        "temperature": 0,
        "text": " So this is a feature of the p5 library.",
        "tokens": [
          50564,
          407,
          341,
          307,
          257,
          4111,
          295,
          264,
          280,
          20,
          6405,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20463602883475168,
        "compression_ratio": 1.7013574660633484,
        "end": 2208.36,
        "id": 635,
        "no_speech_prob": 0.5037551522254944,
        "seek": 219936,
        "start": 2206.36,
        "temperature": 0,
        "text": " So I'm using the p5 library.",
        "tokens": [
          50714,
          407,
          286,
          478,
          1228,
          264,
          280,
          20,
          6405,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20463602883475168,
        "compression_ratio": 1.7013574660633484,
        "end": 2212.36,
        "id": 636,
        "no_speech_prob": 0.5037551522254944,
        "seek": 219936,
        "start": 2208.36,
        "temperature": 0,
        "text": " And the p5 library always calls the setup function first.",
        "tokens": [
          50814,
          400,
          264,
          280,
          20,
          6405,
          1009,
          5498,
          264,
          8657,
          2445,
          700,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20463602883475168,
        "compression_ratio": 1.7013574660633484,
        "end": 2213.36,
        "id": 637,
        "no_speech_prob": 0.5037551522254944,
        "seek": 219936,
        "start": 2212.36,
        "temperature": 0,
        "text": " That's the way it's configured.",
        "tokens": [
          51014,
          663,
          311,
          264,
          636,
          309,
          311,
          30538,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.20463602883475168,
        "compression_ratio": 1.7013574660633484,
        "end": 2216.36,
        "id": 638,
        "no_speech_prob": 0.5037551522254944,
        "seek": 219936,
        "start": 2213.36,
        "temperature": 0,
        "text": " But this is not something that will just happen in any JavaScript environment.",
        "tokens": [
          51064,
          583,
          341,
          307,
          406,
          746,
          300,
          486,
          445,
          1051,
          294,
          604,
          15778,
          2823,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20463602883475168,
        "compression_ratio": 1.7013574660633484,
        "end": 2217.36,
        "id": 639,
        "no_speech_prob": 0.5037551522254944,
        "seek": 219936,
        "start": 2216.36,
        "temperature": 0,
        "text": " It's here...",
        "tokens": [
          51214,
          467,
          311,
          510,
          485,
          51264
        ]
      },
      {
        "avg_logprob": -0.20463602883475168,
        "compression_ratio": 1.7013574660633484,
        "end": 2221.36,
        "id": 640,
        "no_speech_prob": 0.5037551522254944,
        "seek": 219936,
        "start": 2217.36,
        "temperature": 0,
        "text": " It's specifically part of the...",
        "tokens": [
          51264,
          467,
          311,
          4682,
          644,
          295,
          264,
          485,
          51464
        ]
      },
      {
        "avg_logprob": -0.20463602883475168,
        "compression_ratio": 1.7013574660633484,
        "end": 2225.36,
        "id": 641,
        "no_speech_prob": 0.5037551522254944,
        "seek": 219936,
        "start": 2221.36,
        "temperature": 0,
        "text": " Part of the p5 library.",
        "tokens": [
          51464,
          4100,
          295,
          264,
          280,
          20,
          6405,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20463602883475168,
        "compression_ratio": 1.7013574660633484,
        "end": 2226.36,
        "id": 642,
        "no_speech_prob": 0.5037551522254944,
        "seek": 219936,
        "start": 2225.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51664,
          1033,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.23406550997779482,
        "compression_ratio": 1.5055555555555555,
        "end": 2239.36,
        "id": 643,
        "no_speech_prob": 0.03358752280473709,
        "seek": 222636,
        "start": 2226.36,
        "temperature": 0,
        "text": " Copper asks, so save, not save, all the model like in Keras?",
        "tokens": [
          50364,
          47243,
          8962,
          11,
          370,
          3155,
          11,
          406,
          3155,
          11,
          439,
          264,
          2316,
          411,
          294,
          591,
          6985,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.23406550997779482,
        "compression_ratio": 1.5055555555555555,
        "end": 2241.36,
        "id": 644,
        "no_speech_prob": 0.03358752280473709,
        "seek": 222636,
        "start": 2239.36,
        "temperature": 0,
        "text": " I'm not sure I completely understand that question.",
        "tokens": [
          51014,
          286,
          478,
          406,
          988,
          286,
          2584,
          1223,
          300,
          1168,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.23406550997779482,
        "compression_ratio": 1.5055555555555555,
        "end": 2243.36,
        "id": 645,
        "no_speech_prob": 0.03358752280473709,
        "seek": 222636,
        "start": 2241.36,
        "temperature": 0,
        "text": " But let me try to rephrase it.",
        "tokens": [
          51114,
          583,
          718,
          385,
          853,
          281,
          319,
          44598,
          651,
          309,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.23406550997779482,
        "compression_ratio": 1.5055555555555555,
        "end": 2248.36,
        "id": 646,
        "no_speech_prob": 0.03358752280473709,
        "seek": 222636,
        "start": 2243.36,
        "temperature": 0,
        "text": " I think what Copper is asking is, is this like saving a model in Keras?",
        "tokens": [
          51214,
          286,
          519,
          437,
          47243,
          307,
          3365,
          307,
          11,
          307,
          341,
          411,
          6816,
          257,
          2316,
          294,
          591,
          6985,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.23406550997779482,
        "compression_ratio": 1.5055555555555555,
        "end": 2250.36,
        "id": 647,
        "no_speech_prob": 0.03358752280473709,
        "seek": 222636,
        "start": 2248.36,
        "temperature": 0,
        "text": " And the answer is yes.",
        "tokens": [
          51464,
          400,
          264,
          1867,
          307,
          2086,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.23406550997779482,
        "compression_ratio": 1.5055555555555555,
        "end": 2252.36,
        "id": 648,
        "no_speech_prob": 0.03358752280473709,
        "seek": 222636,
        "start": 2250.36,
        "temperature": 0,
        "text": " There's a lot of nuance to this.",
        "tokens": [
          51564,
          821,
          311,
          257,
          688,
          295,
          42625,
          281,
          341,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.205692986647288,
        "compression_ratio": 1.6153846153846154,
        "end": 2257.36,
        "id": 649,
        "no_speech_prob": 0.42240414023399353,
        "seek": 225236,
        "start": 2252.36,
        "temperature": 0,
        "text": " Because number one, it's saving the model in a particular format that is compatible with TensorFlow.js.",
        "tokens": [
          50364,
          1436,
          1230,
          472,
          11,
          309,
          311,
          6816,
          264,
          2316,
          294,
          257,
          1729,
          7877,
          300,
          307,
          18218,
          365,
          37624,
          13,
          25530,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.205692986647288,
        "compression_ratio": 1.6153846153846154,
        "end": 2265.36,
        "id": 650,
        "no_speech_prob": 0.42240414023399353,
        "seek": 225236,
        "start": 2257.36,
        "temperature": 0,
        "text": " So this model that we saved won't necessarily work with a Python Keras example without being sort of converted to what it needs there.",
        "tokens": [
          50614,
          407,
          341,
          2316,
          300,
          321,
          6624,
          1582,
          380,
          4725,
          589,
          365,
          257,
          15329,
          591,
          6985,
          1365,
          1553,
          885,
          1333,
          295,
          16424,
          281,
          437,
          309,
          2203,
          456,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.205692986647288,
        "compression_ratio": 1.6153846153846154,
        "end": 2273.36,
        "id": 651,
        "no_speech_prob": 0.42240414023399353,
        "seek": 225236,
        "start": 2265.36,
        "temperature": 0,
        "text": " And there's also this sort of strange feature of it, which is that it's already like...",
        "tokens": [
          51014,
          400,
          456,
          311,
          611,
          341,
          1333,
          295,
          5861,
          4111,
          295,
          309,
          11,
          597,
          307,
          300,
          309,
          311,
          1217,
          411,
          485,
          51414
        ]
      },
      {
        "avg_logprob": -0.205692986647288,
        "compression_ratio": 1.6153846153846154,
        "end": 2277.36,
        "id": 652,
        "no_speech_prob": 0.42240414023399353,
        "seek": 225236,
        "start": 2273.36,
        "temperature": 0,
        "text": " We're just saving the sort of part that's on top of the MobileNet model.",
        "tokens": [
          51414,
          492,
          434,
          445,
          6816,
          264,
          1333,
          295,
          644,
          300,
          311,
          322,
          1192,
          295,
          264,
          22625,
          31890,
          2316,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2102628127388332,
        "compression_ratio": 1.7256637168141593,
        "end": 2280.36,
        "id": 653,
        "no_speech_prob": 0.2421724498271942,
        "seek": 227736,
        "start": 2277.36,
        "temperature": 0,
        "text": " So I haven't like resaved the entire MobileNet model.",
        "tokens": [
          50364,
          407,
          286,
          2378,
          380,
          411,
          725,
          12865,
          264,
          2302,
          22625,
          31890,
          2316,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2102628127388332,
        "compression_ratio": 1.7256637168141593,
        "end": 2286.36,
        "id": 654,
        "no_speech_prob": 0.2421724498271942,
        "seek": 227736,
        "start": 2280.36,
        "temperature": 0,
        "text": " I'm just saving the transfer learning piece of it that is plugged into the MobileNet model.",
        "tokens": [
          50514,
          286,
          478,
          445,
          6816,
          264,
          5003,
          2539,
          2522,
          295,
          309,
          300,
          307,
          25679,
          666,
          264,
          22625,
          31890,
          2316,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2102628127388332,
        "compression_ratio": 1.7256637168141593,
        "end": 2290.36,
        "id": 655,
        "no_speech_prob": 0.2421724498271942,
        "seek": 227736,
        "start": 2286.36,
        "temperature": 0,
        "text": " Because it's still always loading the MobileNet model.",
        "tokens": [
          50814,
          1436,
          309,
          311,
          920,
          1009,
          15114,
          264,
          22625,
          31890,
          2316,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2102628127388332,
        "compression_ratio": 1.7256637168141593,
        "end": 2296.36,
        "id": 656,
        "no_speech_prob": 0.2421724498271942,
        "seek": 227736,
        "start": 2290.36,
        "temperature": 0,
        "text": " And yes, KWikOne says, as far as I know, you can even import a Keras model into tf.js.",
        "tokens": [
          51014,
          400,
          2086,
          11,
          591,
          54,
          1035,
          15426,
          1619,
          11,
          382,
          1400,
          382,
          286,
          458,
          11,
          291,
          393,
          754,
          974,
          257,
          591,
          6985,
          2316,
          666,
          256,
          69,
          13,
          25530,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2102628127388332,
        "compression_ratio": 1.7256637168141593,
        "end": 2304.36,
        "id": 657,
        "no_speech_prob": 0.2421724498271942,
        "seek": 227736,
        "start": 2296.36,
        "temperature": 0,
        "text": " So yes, if you want to import a Keras model into tf.js, you just need to look for the tf.js converter.",
        "tokens": [
          51314,
          407,
          2086,
          11,
          498,
          291,
          528,
          281,
          974,
          257,
          591,
          6985,
          2316,
          666,
          256,
          69,
          13,
          25530,
          11,
          291,
          445,
          643,
          281,
          574,
          337,
          264,
          256,
          69,
          13,
          25530,
          33905,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18602720615083138,
        "compression_ratio": 1.618867924528302,
        "end": 2311.36,
        "id": 658,
        "no_speech_prob": 0.006388192530721426,
        "seek": 230436,
        "start": 2304.36,
        "temperature": 0,
        "text": " This is a script that will take any TensorFlow or Keras saved model and convert it into TensorFlow.js.",
        "tokens": [
          50364,
          639,
          307,
          257,
          5755,
          300,
          486,
          747,
          604,
          37624,
          420,
          591,
          6985,
          6624,
          2316,
          293,
          7620,
          309,
          666,
          37624,
          13,
          25530,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18602720615083138,
        "compression_ratio": 1.618867924528302,
        "end": 2314.36,
        "id": 659,
        "no_speech_prob": 0.006388192530721426,
        "seek": 230436,
        "start": 2311.36,
        "temperature": 0,
        "text": " This is from the TensorFlow project itself.",
        "tokens": [
          50714,
          639,
          307,
          490,
          264,
          37624,
          1716,
          2564,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.18602720615083138,
        "compression_ratio": 1.618867924528302,
        "end": 2316.36,
        "id": 660,
        "no_speech_prob": 0.006388192530721426,
        "seek": 230436,
        "start": 2314.36,
        "temperature": 0,
        "text": " Does that mean it will work automatically with ml5?",
        "tokens": [
          50864,
          4402,
          300,
          914,
          309,
          486,
          589,
          6772,
          365,
          23271,
          20,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.18602720615083138,
        "compression_ratio": 1.618867924528302,
        "end": 2324.36,
        "id": 661,
        "no_speech_prob": 0.006388192530721426,
        "seek": 230436,
        "start": 2316.36,
        "temperature": 0,
        "text": " In theory, yes, but ml5 is kind of a subset of TensorFlow.js with a bunch of things wrapped to be a little simpler to work with.",
        "tokens": [
          50964,
          682,
          5261,
          11,
          2086,
          11,
          457,
          23271,
          20,
          307,
          733,
          295,
          257,
          25993,
          295,
          37624,
          13,
          25530,
          365,
          257,
          3840,
          295,
          721,
          14226,
          281,
          312,
          257,
          707,
          18587,
          281,
          589,
          365,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18602720615083138,
        "compression_ratio": 1.618867924528302,
        "end": 2327.36,
        "id": 662,
        "no_speech_prob": 0.006388192530721426,
        "seek": 230436,
        "start": 2324.36,
        "temperature": 0,
        "text": " I kind of want to do that video again.",
        "tokens": [
          51364,
          286,
          733,
          295,
          528,
          281,
          360,
          300,
          960,
          797,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.18602720615083138,
        "compression_ratio": 1.618867924528302,
        "end": 2333.36,
        "id": 663,
        "no_speech_prob": 0.006388192530721426,
        "seek": 230436,
        "start": 2327.36,
        "temperature": 0,
        "text": " Because I feel like I don't know if I hit all the right notes.",
        "tokens": [
          51514,
          1436,
          286,
          841,
          411,
          286,
          500,
          380,
          458,
          498,
          286,
          2045,
          439,
          264,
          558,
          5570,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.28214366400419777,
        "compression_ratio": 1.3214285714285714,
        "end": 2335.36,
        "id": 664,
        "no_speech_prob": 0.000480281567433849,
        "seek": 233336,
        "start": 2333.36,
        "temperature": 0,
        "text": " I'm going to do it again.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          360,
          309,
          797,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.28214366400419777,
        "compression_ratio": 1.3214285714285714,
        "end": 2339.36,
        "id": 665,
        "no_speech_prob": 0.000480281567433849,
        "seek": 233336,
        "start": 2335.36,
        "temperature": 0,
        "text": " And then Mathieu can pull.",
        "tokens": [
          50464,
          400,
          550,
          15776,
          19347,
          393,
          2235,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.28214366400419777,
        "compression_ratio": 1.3214285714285714,
        "end": 2341.36,
        "id": 666,
        "no_speech_prob": 0.000480281567433849,
        "seek": 233336,
        "start": 2339.36,
        "temperature": 0,
        "text": " Because I feel like this is a really sort of important one.",
        "tokens": [
          50664,
          1436,
          286,
          841,
          411,
          341,
          307,
          257,
          534,
          1333,
          295,
          1021,
          472,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.28214366400419777,
        "compression_ratio": 1.3214285714285714,
        "end": 2353.36,
        "id": 667,
        "no_speech_prob": 0.000480281567433849,
        "seek": 233336,
        "start": 2351.36,
        "temperature": 0,
        "text": " And then I will do the quick draw stuff.",
        "tokens": [
          51264,
          400,
          550,
          286,
          486,
          360,
          264,
          1702,
          2642,
          1507,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.28214366400419777,
        "compression_ratio": 1.3214285714285714,
        "end": 2360.36,
        "id": 668,
        "no_speech_prob": 0.000480281567433849,
        "seek": 233336,
        "start": 2353.36,
        "temperature": 0,
        "text": " ASDFGHJKL space ASDFGHJKL asks.",
        "tokens": [
          51364,
          7469,
          35,
          37,
          4269,
          41,
          42,
          43,
          1901,
          7469,
          35,
          37,
          4269,
          41,
          42,
          43,
          8962,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.21996118689096103,
        "compression_ratio": 1.5174129353233832,
        "end": 2365.36,
        "id": 669,
        "no_speech_prob": 0.011506441980600357,
        "seek": 236036,
        "start": 2360.36,
        "temperature": 0,
        "text": " Why do you choose p5.js over other JavaScript libraries?",
        "tokens": [
          50364,
          1545,
          360,
          291,
          2826,
          280,
          20,
          13,
          25530,
          670,
          661,
          15778,
          15148,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.21996118689096103,
        "compression_ratio": 1.5174129353233832,
        "end": 2367.36,
        "id": 670,
        "no_speech_prob": 0.011506441980600357,
        "seek": 236036,
        "start": 2365.36,
        "temperature": 0,
        "text": " I love p5.js.",
        "tokens": [
          50614,
          286,
          959,
          280,
          20,
          13,
          25530,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.21996118689096103,
        "compression_ratio": 1.5174129353233832,
        "end": 2370.36,
        "id": 671,
        "no_speech_prob": 0.011506441980600357,
        "seek": 236036,
        "start": 2367.36,
        "temperature": 0,
        "text": " I mean, it's a great question.",
        "tokens": [
          50714,
          286,
          914,
          11,
          309,
          311,
          257,
          869,
          1168,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.21996118689096103,
        "compression_ratio": 1.5174129353233832,
        "end": 2378.36,
        "id": 672,
        "no_speech_prob": 0.011506441980600357,
        "seek": 236036,
        "start": 2370.36,
        "temperature": 0,
        "text": " And I don't think there, I certainly am not here to say please, I think you, the viewer of this channel, should use p5.js.",
        "tokens": [
          50864,
          400,
          286,
          500,
          380,
          519,
          456,
          11,
          286,
          3297,
          669,
          406,
          510,
          281,
          584,
          1767,
          11,
          286,
          519,
          291,
          11,
          264,
          16767,
          295,
          341,
          2269,
          11,
          820,
          764,
          280,
          20,
          13,
          25530,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.21996118689096103,
        "compression_ratio": 1.5174129353233832,
        "end": 2384.36,
        "id": 673,
        "no_speech_prob": 0.011506441980600357,
        "seek": 236036,
        "start": 2378.36,
        "temperature": 0,
        "text": " The reason why I use it is because it's a project that's connected to a project.",
        "tokens": [
          51264,
          440,
          1778,
          983,
          286,
          764,
          309,
          307,
          570,
          309,
          311,
          257,
          1716,
          300,
          311,
          4582,
          281,
          257,
          1716,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20089581138209292,
        "compression_ratio": 1.6642335766423357,
        "end": 2386.36,
        "id": 674,
        "no_speech_prob": 0.051069434732198715,
        "seek": 238436,
        "start": 2385.36,
        "temperature": 0,
        "text": " It is a project.",
        "tokens": [
          50414,
          467,
          307,
          257,
          1716,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.20089581138209292,
        "compression_ratio": 1.6642335766423357,
        "end": 2392.36,
        "id": 675,
        "no_speech_prob": 0.051069434732198715,
        "seek": 238436,
        "start": 2386.36,
        "temperature": 0,
        "text": " It's part of a project called the Processing Foundation, an entity that I've worked on for many years that I have a lot of personal investment in.",
        "tokens": [
          50464,
          467,
          311,
          644,
          295,
          257,
          1716,
          1219,
          264,
          31093,
          278,
          10335,
          11,
          364,
          13977,
          300,
          286,
          600,
          2732,
          322,
          337,
          867,
          924,
          300,
          286,
          362,
          257,
          688,
          295,
          2973,
          6078,
          294,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20089581138209292,
        "compression_ratio": 1.6642335766423357,
        "end": 2402.36,
        "id": 676,
        "no_speech_prob": 0.051069434732198715,
        "seek": 238436,
        "start": 2392.36,
        "temperature": 0,
        "text": " And the goals of that project in terms of being beginner friendly, being inclusive, are values and principles that are close to my heart.",
        "tokens": [
          50764,
          400,
          264,
          5493,
          295,
          300,
          1716,
          294,
          2115,
          295,
          885,
          22080,
          9208,
          11,
          885,
          13429,
          11,
          366,
          4190,
          293,
          9156,
          300,
          366,
          1998,
          281,
          452,
          1917,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20089581138209292,
        "compression_ratio": 1.6642335766423357,
        "end": 2405.36,
        "id": 677,
        "no_speech_prob": 0.051069434732198715,
        "seek": 238436,
        "start": 2402.36,
        "temperature": 0,
        "text": " And that work well with the kind of stuff that I want to do in this channel.",
        "tokens": [
          51264,
          400,
          300,
          589,
          731,
          365,
          264,
          733,
          295,
          1507,
          300,
          286,
          528,
          281,
          360,
          294,
          341,
          2269,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20089581138209292,
        "compression_ratio": 1.6642335766423357,
        "end": 2407.36,
        "id": 678,
        "no_speech_prob": 0.051069434732198715,
        "seek": 238436,
        "start": 2405.36,
        "temperature": 0,
        "text": " Is it perfect? No.",
        "tokens": [
          51414,
          1119,
          309,
          2176,
          30,
          883,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20089581138209292,
        "compression_ratio": 1.6642335766423357,
        "end": 2410.36,
        "id": 679,
        "no_speech_prob": 0.051069434732198715,
        "seek": 238436,
        "start": 2407.36,
        "temperature": 0,
        "text": " Are there other things that you might want to use instead?",
        "tokens": [
          51514,
          2014,
          456,
          661,
          721,
          300,
          291,
          1062,
          528,
          281,
          764,
          2602,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.23094945387406782,
        "compression_ratio": 1.574468085106383,
        "end": 2412.36,
        "id": 680,
        "no_speech_prob": 0.18948417901992798,
        "seek": 241036,
        "start": 2411.36,
        "temperature": 0,
        "text": " Definitely.",
        "tokens": [
          50414,
          12151,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.23094945387406782,
        "compression_ratio": 1.574468085106383,
        "end": 2415.36,
        "id": 681,
        "no_speech_prob": 0.18948417901992798,
        "seek": 241036,
        "start": 2412.36,
        "temperature": 0,
        "text": " But it's a good foundation library for me to build a lot of stuff with.",
        "tokens": [
          50464,
          583,
          309,
          311,
          257,
          665,
          7030,
          6405,
          337,
          385,
          281,
          1322,
          257,
          688,
          295,
          1507,
          365,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.23094945387406782,
        "compression_ratio": 1.574468085106383,
        "end": 2416.36,
        "id": 682,
        "no_speech_prob": 0.18948417901992798,
        "seek": 241036,
        "start": 2415.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50614,
          1057,
          558,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.23094945387406782,
        "compression_ratio": 1.574468085106383,
        "end": 2419.36,
        "id": 683,
        "no_speech_prob": 0.18948417901992798,
        "seek": 241036,
        "start": 2416.36,
        "temperature": 0,
        "text": " I know I've been torturing you all, but I'm going to do this again.",
        "tokens": [
          50664,
          286,
          458,
          286,
          600,
          668,
          10806,
          1345,
          291,
          439,
          11,
          457,
          286,
          478,
          516,
          281,
          360,
          341,
          797,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.23094945387406782,
        "compression_ratio": 1.574468085106383,
        "end": 2422.36,
        "id": 684,
        "no_speech_prob": 0.18948417901992798,
        "seek": 241036,
        "start": 2419.36,
        "temperature": 0,
        "text": " Just to give Matthew more material to work with.",
        "tokens": [
          50814,
          1449,
          281,
          976,
          6789,
          3322,
          86,
          544,
          2527,
          281,
          589,
          365,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.23094945387406782,
        "compression_ratio": 1.574468085106383,
        "end": 2428.36,
        "id": 685,
        "no_speech_prob": 0.18948417901992798,
        "seek": 241036,
        "start": 2422.36,
        "temperature": 0,
        "text": " Now that I have a sense of what the issues are.",
        "tokens": [
          50964,
          823,
          300,
          286,
          362,
          257,
          2020,
          295,
          437,
          264,
          2663,
          366,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.23094945387406782,
        "compression_ratio": 1.574468085106383,
        "end": 2432.36,
        "id": 686,
        "no_speech_prob": 0.18948417901992798,
        "seek": 241036,
        "start": 2428.36,
        "temperature": 0,
        "text": " I'm going to go back to what it was originally.",
        "tokens": [
          51264,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          437,
          309,
          390,
          7993,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.23094945387406782,
        "compression_ratio": 1.574468085106383,
        "end": 2438.36,
        "id": 687,
        "no_speech_prob": 0.18948417901992798,
        "seek": 241036,
        "start": 2432.36,
        "temperature": 0,
        "text": " And I'm going to redo a couple things to make it less awkward.",
        "tokens": [
          51464,
          400,
          286,
          478,
          516,
          281,
          29956,
          257,
          1916,
          721,
          281,
          652,
          309,
          1570,
          11411,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.3919193744659424,
        "compression_ratio": 1.2037037037037037,
        "end": 2445.36,
        "id": 688,
        "no_speech_prob": 0.12246556580066681,
        "seek": 243836,
        "start": 2438.36,
        "temperature": 0,
        "text": " I am going to...",
        "tokens": [
          50364,
          286,
          669,
          516,
          281,
          485,
          50714
        ]
      },
      {
        "avg_logprob": -0.3919193744659424,
        "compression_ratio": 1.2037037037037037,
        "end": 2446.36,
        "id": 689,
        "no_speech_prob": 0.12246556580066681,
        "seek": 243836,
        "start": 2445.36,
        "temperature": 0,
        "text": " Let's just see here.",
        "tokens": [
          50714,
          961,
          311,
          445,
          536,
          510,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.3919193744659424,
        "compression_ratio": 1.2037037037037037,
        "end": 2449.36,
        "id": 690,
        "no_speech_prob": 0.12246556580066681,
        "seek": 243836,
        "start": 2446.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50764,
          1033,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.3919193744659424,
        "compression_ratio": 1.2037037037037037,
        "end": 2459.36,
        "id": 691,
        "no_speech_prob": 0.12246556580066681,
        "seek": 243836,
        "start": 2449.36,
        "temperature": 0,
        "text": " Let's see here.",
        "tokens": [
          50914,
          961,
          311,
          536,
          510,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.3919193744659424,
        "compression_ratio": 1.2037037037037037,
        "end": 2460.36,
        "id": 692,
        "no_speech_prob": 0.12246556580066681,
        "seek": 243836,
        "start": 2459.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51414,
          1033,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.22691515142267402,
        "compression_ratio": 1.344,
        "end": 2463.36,
        "id": 693,
        "no_speech_prob": 0.09137933701276779,
        "seek": 246036,
        "start": 2461.36,
        "temperature": 0,
        "text": " So...",
        "tokens": [
          50414,
          407,
          485,
          50514
        ]
      },
      {
        "avg_logprob": -0.22691515142267402,
        "compression_ratio": 1.344,
        "end": 2474.36,
        "id": 694,
        "no_speech_prob": 0.09137933701276779,
        "seek": 246036,
        "start": 2463.36,
        "temperature": 0,
        "text": " I'm going to move some things around, I think, to make things less awkward.",
        "tokens": [
          50514,
          286,
          478,
          516,
          281,
          1286,
          512,
          721,
          926,
          11,
          286,
          519,
          11,
          281,
          652,
          721,
          1570,
          11411,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.22691515142267402,
        "compression_ratio": 1.344,
        "end": 2480.36,
        "id": 695,
        "no_speech_prob": 0.09137933701276779,
        "seek": 246036,
        "start": 2474.36,
        "temperature": 0,
        "text": " Is that legible, this font size?",
        "tokens": [
          51064,
          1119,
          300,
          1676,
          964,
          11,
          341,
          10703,
          2744,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.22691515142267402,
        "compression_ratio": 1.344,
        "end": 2482.36,
        "id": 696,
        "no_speech_prob": 0.09137933701276779,
        "seek": 246036,
        "start": 2480.36,
        "temperature": 0,
        "text": " Is this legible?",
        "tokens": [
          51364,
          1119,
          341,
          1676,
          964,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.22691515142267402,
        "compression_ratio": 1.344,
        "end": 2484.36,
        "id": 697,
        "no_speech_prob": 0.09137933701276779,
        "seek": 246036,
        "start": 2482.36,
        "temperature": 0,
        "text": " It's smaller than I usually have it.",
        "tokens": [
          51464,
          467,
          311,
          4356,
          813,
          286,
          2673,
          362,
          309,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.23429037094116212,
        "compression_ratio": 1.0666666666666667,
        "end": 2489.36,
        "id": 698,
        "no_speech_prob": 0.3276137411594391,
        "seek": 248436,
        "start": 2485.36,
        "temperature": 0,
        "text": " But...",
        "tokens": [
          50414,
          583,
          485,
          50614
        ]
      },
      {
        "avg_logprob": -0.23429037094116212,
        "compression_ratio": 1.0666666666666667,
        "end": 2510.36,
        "id": 699,
        "no_speech_prob": 0.3276137411594391,
        "seek": 248436,
        "start": 2489.36,
        "temperature": 0,
        "text": " This might be helpful to have a little bit more room to look at the code.",
        "tokens": [
          50614,
          639,
          1062,
          312,
          4961,
          281,
          362,
          257,
          707,
          857,
          544,
          1808,
          281,
          574,
          412,
          264,
          3089,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20345908839528154,
        "compression_ratio": 1.4861111111111112,
        "end": 2512.36,
        "id": 700,
        "no_speech_prob": 0.11753161996603012,
        "seek": 251036,
        "start": 2511.36,
        "temperature": 0,
        "text": " Yeah, let me rename the uke and whistle button.",
        "tokens": [
          50414,
          865,
          11,
          718,
          385,
          36741,
          264,
          344,
          330,
          293,
          23470,
          2960,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.20345908839528154,
        "compression_ratio": 1.4861111111111112,
        "end": 2515.36,
        "id": 701,
        "no_speech_prob": 0.11753161996603012,
        "seek": 251036,
        "start": 2512.36,
        "temperature": 0,
        "text": " Thank you.",
        "tokens": [
          50464,
          1044,
          291,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20345908839528154,
        "compression_ratio": 1.4861111111111112,
        "end": 2516.36,
        "id": 702,
        "no_speech_prob": 0.11753161996603012,
        "seek": 251036,
        "start": 2515.36,
        "temperature": 0,
        "text": " Let me rename those.",
        "tokens": [
          50614,
          961,
          385,
          36741,
          729,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20345908839528154,
        "compression_ratio": 1.4861111111111112,
        "end": 2517.36,
        "id": 703,
        "no_speech_prob": 0.11753161996603012,
        "seek": 251036,
        "start": 2516.36,
        "temperature": 0,
        "text": " Thank you.",
        "tokens": [
          50664,
          1044,
          291,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20345908839528154,
        "compression_ratio": 1.4861111111111112,
        "end": 2518.36,
        "id": 704,
        "no_speech_prob": 0.11753161996603012,
        "seek": 251036,
        "start": 2517.36,
        "temperature": 0,
        "text": " That is...",
        "tokens": [
          50714,
          663,
          307,
          485,
          50764
        ]
      },
      {
        "avg_logprob": -0.20345908839528154,
        "compression_ratio": 1.4861111111111112,
        "end": 2519.36,
        "id": 705,
        "no_speech_prob": 0.11753161996603012,
        "seek": 251036,
        "start": 2518.36,
        "temperature": 0,
        "text": " I don't know why I'm...",
        "tokens": [
          50764,
          286,
          500,
          380,
          458,
          983,
          286,
          478,
          485,
          50814
        ]
      },
      {
        "avg_logprob": -0.20345908839528154,
        "compression_ratio": 1.4861111111111112,
        "end": 2523.36,
        "id": 706,
        "no_speech_prob": 0.11753161996603012,
        "seek": 251036,
        "start": 2519.36,
        "temperature": 0,
        "text": " A happy button.",
        "tokens": [
          50814,
          316,
          2055,
          2960,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20345908839528154,
        "compression_ratio": 1.4861111111111112,
        "end": 2527.36,
        "id": 707,
        "no_speech_prob": 0.11753161996603012,
        "seek": 251036,
        "start": 2523.36,
        "temperature": 0,
        "text": " Sad button.",
        "tokens": [
          51014,
          12269,
          2960,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20345908839528154,
        "compression_ratio": 1.4861111111111112,
        "end": 2528.36,
        "id": 708,
        "no_speech_prob": 0.11753161996603012,
        "seek": 251036,
        "start": 2527.36,
        "temperature": 0,
        "text": " A train button.",
        "tokens": [
          51214,
          316,
          3847,
          2960,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20345908839528154,
        "compression_ratio": 1.4861111111111112,
        "end": 2529.36,
        "id": 709,
        "no_speech_prob": 0.11753161996603012,
        "seek": 251036,
        "start": 2528.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51264,
          1033,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20345908839528154,
        "compression_ratio": 1.4861111111111112,
        "end": 2530.36,
        "id": 710,
        "no_speech_prob": 0.11753161996603012,
        "seek": 251036,
        "start": 2529.36,
        "temperature": 0,
        "text": " So that's good.",
        "tokens": [
          51314,
          407,
          300,
          311,
          665,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20345908839528154,
        "compression_ratio": 1.4861111111111112,
        "end": 2538.36,
        "id": 711,
        "no_speech_prob": 0.11753161996603012,
        "seek": 251036,
        "start": 2530.36,
        "temperature": 0,
        "text": " Any other suggestions?",
        "tokens": [
          51364,
          2639,
          661,
          13396,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.21762732536562027,
        "compression_ratio": 1,
        "end": 2543.36,
        "id": 712,
        "no_speech_prob": 0.03567426651716232,
        "seek": 253836,
        "start": 2538.36,
        "temperature": 0,
        "text": " It's fine.",
        "tokens": [
          50364,
          467,
          311,
          2489,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.21762732536562027,
        "compression_ratio": 1,
        "end": 2544.36,
        "id": 713,
        "no_speech_prob": 0.03567426651716232,
        "seek": 253836,
        "start": 2543.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50614,
          1057,
          558,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.21762732536562027,
        "compression_ratio": 1,
        "end": 2559.36,
        "id": 714,
        "no_speech_prob": 0.03567426651716232,
        "seek": 253836,
        "start": 2544.36,
        "temperature": 0,
        "text": " Let me try it with the code a little bit smaller.",
        "tokens": [
          50664,
          961,
          385,
          853,
          309,
          365,
          264,
          3089,
          257,
          707,
          857,
          4356,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.21762732536562027,
        "compression_ratio": 1,
        "end": 2561.36,
        "id": 715,
        "no_speech_prob": 0.03567426651716232,
        "seek": 253836,
        "start": 2559.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51414,
          1033,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2554105387793647,
        "compression_ratio": 1.4090909090909092,
        "end": 2576.36,
        "id": 716,
        "no_speech_prob": 0.6616407036781311,
        "seek": 256136,
        "start": 2562.36,
        "temperature": 0,
        "text": " Here we go, everybody.",
        "tokens": [
          50414,
          1692,
          321,
          352,
          11,
          2201,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2554105387793647,
        "compression_ratio": 1.4090909090909092,
        "end": 2577.36,
        "id": 717,
        "no_speech_prob": 0.6616407036781311,
        "seek": 256136,
        "start": 2576.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51114,
          1057,
          558,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2554105387793647,
        "compression_ratio": 1.4090909090909092,
        "end": 2579.36,
        "id": 718,
        "no_speech_prob": 0.6616407036781311,
        "seek": 256136,
        "start": 2577.36,
        "temperature": 0,
        "text": " Let's do this ridiculous thing again.",
        "tokens": [
          51164,
          961,
          311,
          360,
          341,
          11083,
          551,
          797,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2554105387793647,
        "compression_ratio": 1.4090909090909092,
        "end": 2585.36,
        "id": 719,
        "no_speech_prob": 0.6616407036781311,
        "seek": 256136,
        "start": 2579.36,
        "temperature": 0,
        "text": " I mean, Mathieu, whenever you watch this, you can take stuff from the first try and mix it if you want.",
        "tokens": [
          51264,
          286,
          914,
          11,
          15776,
          19347,
          11,
          5699,
          291,
          1159,
          341,
          11,
          291,
          393,
          747,
          1507,
          490,
          264,
          700,
          853,
          293,
          2890,
          309,
          498,
          291,
          528,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2554105387793647,
        "compression_ratio": 1.4090909090909092,
        "end": 2589.36,
        "id": 720,
        "no_speech_prob": 0.6616407036781311,
        "seek": 256136,
        "start": 2585.36,
        "temperature": 0,
        "text": " But it's my hope that this will just be a cleaner version of that video.",
        "tokens": [
          51564,
          583,
          309,
          311,
          452,
          1454,
          300,
          341,
          486,
          445,
          312,
          257,
          16532,
          3037,
          295,
          300,
          960,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.24406862646583619,
        "compression_ratio": 1.5430711610486891,
        "end": 2593.36,
        "id": 721,
        "no_speech_prob": 0.17550413310527802,
        "seek": 258936,
        "start": 2589.36,
        "temperature": 0,
        "text": " And apologies to all of you watching live when I make the same jokes again.",
        "tokens": [
          50364,
          400,
          34929,
          281,
          439,
          295,
          291,
          1976,
          1621,
          562,
          286,
          652,
          264,
          912,
          14439,
          797,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.24406862646583619,
        "compression_ratio": 1.5430711610486891,
        "end": 2595.36,
        "id": 722,
        "no_speech_prob": 0.17550413310527802,
        "seek": 258936,
        "start": 2593.36,
        "temperature": 0,
        "text": " Not that I made any jokes, not that any of them were funny.",
        "tokens": [
          50564,
          1726,
          300,
          286,
          1027,
          604,
          14439,
          11,
          406,
          300,
          604,
          295,
          552,
          645,
          4074,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.24406862646583619,
        "compression_ratio": 1.5430711610486891,
        "end": 2598.36,
        "id": 723,
        "no_speech_prob": 0.17550413310527802,
        "seek": 258936,
        "start": 2595.36,
        "temperature": 0,
        "text": " But if I did, I'll probably make them again.",
        "tokens": [
          50664,
          583,
          498,
          286,
          630,
          11,
          286,
          603,
          1391,
          652,
          552,
          797,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.24406862646583619,
        "compression_ratio": 1.5430711610486891,
        "end": 2601.36,
        "id": 724,
        "no_speech_prob": 0.17550413310527802,
        "seek": 258936,
        "start": 2598.36,
        "temperature": 0,
        "text": " More awkwardly.",
        "tokens": [
          50814,
          5048,
          11411,
          356,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.24406862646583619,
        "compression_ratio": 1.5430711610486891,
        "end": 2604.36,
        "id": 725,
        "no_speech_prob": 0.17550413310527802,
        "seek": 258936,
        "start": 2601.36,
        "temperature": 0,
        "text": " Can you continue working on the local project, asks David.",
        "tokens": [
          50964,
          1664,
          291,
          2354,
          1364,
          322,
          264,
          2654,
          1716,
          11,
          8962,
          4389,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.24406862646583619,
        "compression_ratio": 1.5430711610486891,
        "end": 2605.36,
        "id": 726,
        "no_speech_prob": 0.17550413310527802,
        "seek": 258936,
        "start": 2604.36,
        "temperature": 0,
        "text": " I don't think so.",
        "tokens": [
          51114,
          286,
          500,
          380,
          519,
          370,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.24406862646583619,
        "compression_ratio": 1.5430711610486891,
        "end": 2607.36,
        "id": 727,
        "no_speech_prob": 0.17550413310527802,
        "seek": 258936,
        "start": 2605.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51164,
          1033,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.24406862646583619,
        "compression_ratio": 1.5430711610486891,
        "end": 2613.36,
        "id": 728,
        "no_speech_prob": 0.17550413310527802,
        "seek": 258936,
        "start": 2607.36,
        "temperature": 0,
        "text": " Hello and welcome to another ML5 beginner's guide to machine learning with ML5JS video.",
        "tokens": [
          51264,
          2425,
          293,
          2928,
          281,
          1071,
          21601,
          20,
          22080,
          311,
          5934,
          281,
          3479,
          2539,
          365,
          21601,
          20,
          41,
          50,
          960,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.24406862646583619,
        "compression_ratio": 1.5430711610486891,
        "end": 2614.36,
        "id": 729,
        "no_speech_prob": 0.17550413310527802,
        "seek": 258936,
        "start": 2613.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51564,
          1057,
          558,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.24406862646583619,
        "compression_ratio": 1.5430711610486891,
        "end": 2616.36,
        "id": 730,
        "no_speech_prob": 0.17550413310527802,
        "seek": 258936,
        "start": 2614.36,
        "temperature": 0,
        "text": " So this one's a good one, I hope.",
        "tokens": [
          51614,
          407,
          341,
          472,
          311,
          257,
          665,
          472,
          11,
          286,
          1454,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.21136172455136137,
        "compression_ratio": 1.6833333333333333,
        "end": 2619.36,
        "id": 731,
        "no_speech_prob": 0.6401016712188721,
        "seek": 261636,
        "start": 2616.36,
        "temperature": 0,
        "text": " I'm about to make video number seven in this playlist.",
        "tokens": [
          50364,
          286,
          478,
          466,
          281,
          652,
          960,
          1230,
          3407,
          294,
          341,
          16788,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.21136172455136137,
        "compression_ratio": 1.6833333333333333,
        "end": 2625.36,
        "id": 732,
        "no_speech_prob": 0.6401016712188721,
        "seek": 261636,
        "start": 2619.36,
        "temperature": 0,
        "text": " And this, the element in the, oh, I forgot something.",
        "tokens": [
          50514,
          400,
          341,
          11,
          264,
          4478,
          294,
          264,
          11,
          1954,
          11,
          286,
          5298,
          746,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21136172455136137,
        "compression_ratio": 1.6833333333333333,
        "end": 2628.36,
        "id": 733,
        "no_speech_prob": 0.6401016712188721,
        "seek": 261636,
        "start": 2625.36,
        "temperature": 0,
        "text": " I forgot that I have all of this stuff here already.",
        "tokens": [
          50814,
          286,
          5298,
          300,
          286,
          362,
          439,
          295,
          341,
          1507,
          510,
          1217,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.21136172455136137,
        "compression_ratio": 1.6833333333333333,
        "end": 2631.36,
        "id": 734,
        "no_speech_prob": 0.6401016712188721,
        "seek": 261636,
        "start": 2628.36,
        "temperature": 0,
        "text": " And I don't want it to be.",
        "tokens": [
          50964,
          400,
          286,
          500,
          380,
          528,
          309,
          281,
          312,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21136172455136137,
        "compression_ratio": 1.6833333333333333,
        "end": 2633.36,
        "id": 735,
        "no_speech_prob": 0.6401016712188721,
        "seek": 261636,
        "start": 2631.36,
        "temperature": 0,
        "text": " Delete, delete.",
        "tokens": [
          51114,
          49452,
          11,
          12097,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.21136172455136137,
        "compression_ratio": 1.6833333333333333,
        "end": 2634.36,
        "id": 736,
        "no_speech_prob": 0.6401016712188721,
        "seek": 261636,
        "start": 2633.36,
        "temperature": 0,
        "text": " I'm so in love with you.",
        "tokens": [
          51214,
          286,
          478,
          370,
          294,
          959,
          365,
          291,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.21136172455136137,
        "compression_ratio": 1.6833333333333333,
        "end": 2636.36,
        "id": 737,
        "no_speech_prob": 0.6401016712188721,
        "seek": 261636,
        "start": 2634.36,
        "temperature": 0,
        "text": " Delete, delete.",
        "tokens": [
          51264,
          49452,
          11,
          12097,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.21136172455136137,
        "compression_ratio": 1.6833333333333333,
        "end": 2638.36,
        "id": 738,
        "no_speech_prob": 0.6401016712188721,
        "seek": 261636,
        "start": 2636.36,
        "temperature": 0,
        "text": " Oh, with my eyes so blue.",
        "tokens": [
          51364,
          876,
          11,
          365,
          452,
          2575,
          370,
          3344,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.21136172455136137,
        "compression_ratio": 1.6833333333333333,
        "end": 2640.36,
        "id": 739,
        "no_speech_prob": 0.6401016712188721,
        "seek": 261636,
        "start": 2638.36,
        "temperature": 0,
        "text": " Delete, delete.",
        "tokens": [
          51464,
          49452,
          11,
          12097,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21136172455136137,
        "compression_ratio": 1.6833333333333333,
        "end": 2642.36,
        "id": 740,
        "no_speech_prob": 0.6401016712188721,
        "seek": 261636,
        "start": 2640.36,
        "temperature": 0,
        "text": " Delete, delete.",
        "tokens": [
          51564,
          49452,
          11,
          12097,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2009174558851454,
        "compression_ratio": 1.5859030837004404,
        "end": 2645.36,
        "id": 741,
        "no_speech_prob": 0.08034870773553848,
        "seek": 264236,
        "start": 2642.36,
        "temperature": 0,
        "text": " Delete.",
        "tokens": [
          50364,
          49452,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2009174558851454,
        "compression_ratio": 1.5859030837004404,
        "end": 2649.36,
        "id": 742,
        "no_speech_prob": 0.08034870773553848,
        "seek": 264236,
        "start": 2645.36,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          50514,
          865,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2009174558851454,
        "compression_ratio": 1.5859030837004404,
        "end": 2652.36,
        "id": 743,
        "no_speech_prob": 0.08034870773553848,
        "seek": 264236,
        "start": 2649.36,
        "temperature": 0,
        "text": " It's getting hot in here.",
        "tokens": [
          50714,
          467,
          311,
          1242,
          2368,
          294,
          510,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2009174558851454,
        "compression_ratio": 1.5859030837004404,
        "end": 2653.36,
        "id": 744,
        "no_speech_prob": 0.08034870773553848,
        "seek": 264236,
        "start": 2652.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50864,
          1057,
          558,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2009174558851454,
        "compression_ratio": 1.5859030837004404,
        "end": 2656.36,
        "id": 745,
        "no_speech_prob": 0.08034870773553848,
        "seek": 264236,
        "start": 2653.36,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          50914,
          1692,
          321,
          352,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2009174558851454,
        "compression_ratio": 1.5859030837004404,
        "end": 2661.36,
        "id": 746,
        "no_speech_prob": 0.08034870773553848,
        "seek": 264236,
        "start": 2656.36,
        "temperature": 0,
        "text": " Hello and welcome to another beginner's guide to machine learning with ML5JS video.",
        "tokens": [
          51064,
          2425,
          293,
          2928,
          281,
          1071,
          22080,
          311,
          5934,
          281,
          3479,
          2539,
          365,
          21601,
          20,
          41,
          50,
          960,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2009174558851454,
        "compression_ratio": 1.5859030837004404,
        "end": 2665.36,
        "id": 747,
        "no_speech_prob": 0.08034870773553848,
        "seek": 264236,
        "start": 2661.36,
        "temperature": 0,
        "text": " Now, in this video, I am going to unlock something for you.",
        "tokens": [
          51314,
          823,
          11,
          294,
          341,
          960,
          11,
          286,
          669,
          516,
          281,
          11634,
          746,
          337,
          291,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2009174558851454,
        "compression_ratio": 1.5859030837004404,
        "end": 2667.36,
        "id": 748,
        "no_speech_prob": 0.08034870773553848,
        "seek": 264236,
        "start": 2665.36,
        "temperature": 0,
        "text": " It's already unlocked for you, but I'm going to show it to you.",
        "tokens": [
          51514,
          467,
          311,
          1217,
          30180,
          337,
          291,
          11,
          457,
          286,
          478,
          516,
          281,
          855,
          309,
          281,
          291,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2009174558851454,
        "compression_ratio": 1.5859030837004404,
        "end": 2671.36,
        "id": 749,
        "no_speech_prob": 0.08034870773553848,
        "seek": 264236,
        "start": 2667.36,
        "temperature": 0,
        "text": " That is incredibly powerful for what you can do now with ML5 that you couldn't do before.",
        "tokens": [
          51614,
          663,
          307,
          6252,
          4005,
          337,
          437,
          291,
          393,
          360,
          586,
          365,
          21601,
          20,
          300,
          291,
          2809,
          380,
          360,
          949,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1602493649437314,
        "compression_ratio": 1.5627705627705628,
        "end": 2673.36,
        "id": 750,
        "no_speech_prob": 0.00407008221372962,
        "seek": 267136,
        "start": 2671.36,
        "temperature": 0,
        "text": " But many of you asked about in the comments.",
        "tokens": [
          50364,
          583,
          867,
          295,
          291,
          2351,
          466,
          294,
          264,
          3053,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1602493649437314,
        "compression_ratio": 1.5627705627705628,
        "end": 2674.36,
        "id": 751,
        "no_speech_prob": 0.00407008221372962,
        "seek": 267136,
        "start": 2673.36,
        "temperature": 0,
        "text": " And what is that?",
        "tokens": [
          50464,
          400,
          437,
          307,
          300,
          30,
          50514
        ]
      },
      {
        "avg_logprob": -0.1602493649437314,
        "compression_ratio": 1.5627705627705628,
        "end": 2677.36,
        "id": 752,
        "no_speech_prob": 0.00407008221372962,
        "seek": 267136,
        "start": 2674.36,
        "temperature": 0,
        "text": " It is the save load feature extractor.",
        "tokens": [
          50514,
          467,
          307,
          264,
          3155,
          3677,
          4111,
          8947,
          284,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1602493649437314,
        "compression_ratio": 1.5627705627705628,
        "end": 2682.36,
        "id": 753,
        "no_speech_prob": 0.00407008221372962,
        "seek": 267136,
        "start": 2677.36,
        "temperature": 0,
        "text": " This is a new feature that was added to ML5 just five days ago.",
        "tokens": [
          50664,
          639,
          307,
          257,
          777,
          4111,
          300,
          390,
          3869,
          281,
          21601,
          20,
          445,
          1732,
          1708,
          2057,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1602493649437314,
        "compression_ratio": 1.5627705627705628,
        "end": 2691.36,
        "id": 754,
        "no_speech_prob": 0.00407008221372962,
        "seek": 267136,
        "start": 2682.36,
        "temperature": 0,
        "text": " You need to make sure that you are using ML5 0.1.3 or whatever number in the future past that.",
        "tokens": [
          50914,
          509,
          643,
          281,
          652,
          988,
          300,
          291,
          366,
          1228,
          21601,
          20,
          1958,
          13,
          16,
          13,
          18,
          420,
          2035,
          1230,
          294,
          264,
          2027,
          1791,
          300,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1602493649437314,
        "compression_ratio": 1.5627705627705628,
        "end": 2694.36,
        "id": 755,
        "no_speech_prob": 0.00407008221372962,
        "seek": 267136,
        "start": 2691.36,
        "temperature": 0,
        "text": " But certainly this is the version of the library that I'm using in this video.",
        "tokens": [
          51364,
          583,
          3297,
          341,
          307,
          264,
          3037,
          295,
          264,
          6405,
          300,
          286,
          478,
          1228,
          294,
          341,
          960,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1602493649437314,
        "compression_ratio": 1.5627705627705628,
        "end": 2696.36,
        "id": 756,
        "no_speech_prob": 0.00407008221372962,
        "seek": 267136,
        "start": 2694.36,
        "temperature": 0,
        "text": " Now, what does it do?",
        "tokens": [
          51514,
          823,
          11,
          437,
          775,
          309,
          360,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.20336636790522822,
        "compression_ratio": 1.779783393501805,
        "end": 2702.36,
        "id": 757,
        "no_speech_prob": 0.10969644039869308,
        "seek": 269636,
        "start": 2696.36,
        "temperature": 0,
        "text": " So, the last example, if you've been watching this video series in order, was this example.",
        "tokens": [
          50364,
          407,
          11,
          264,
          1036,
          1365,
          11,
          498,
          291,
          600,
          668,
          1976,
          341,
          960,
          2638,
          294,
          1668,
          11,
          390,
          341,
          1365,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20336636790522822,
        "compression_ratio": 1.779783393501805,
        "end": 2708.36,
        "id": 758,
        "no_speech_prob": 0.10969644039869308,
        "seek": 269636,
        "start": 2702.36,
        "temperature": 0,
        "text": " What this example does is it loads a pre-trained image classification model called MobileNet.",
        "tokens": [
          50664,
          708,
          341,
          1365,
          775,
          307,
          309,
          12668,
          257,
          659,
          12,
          17227,
          2001,
          3256,
          21538,
          2316,
          1219,
          22625,
          31890,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20336636790522822,
        "compression_ratio": 1.779783393501805,
        "end": 2714.36,
        "id": 759,
        "no_speech_prob": 0.10969644039869308,
        "seek": 269636,
        "start": 2708.36,
        "temperature": 0,
        "text": " And MobileNet is trained on a thousand different kinds of things and recognizes puppies and dogs and birds and different kinds of objects.",
        "tokens": [
          50964,
          400,
          22625,
          31890,
          307,
          8895,
          322,
          257,
          4714,
          819,
          3685,
          295,
          721,
          293,
          26564,
          33734,
          293,
          7197,
          293,
          9009,
          293,
          819,
          3685,
          295,
          6565,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20336636790522822,
        "compression_ratio": 1.779783393501805,
        "end": 2724.36,
        "id": 760,
        "no_speech_prob": 0.10969644039869308,
        "seek": 269636,
        "start": 2714.36,
        "temperature": 0,
        "text": " Transfer learning is the process by which we take that pre-trained MobileNet model and basically disconnect it from all those labels and reconnect it to our own labels.",
        "tokens": [
          51264,
          35025,
          2539,
          307,
          264,
          1399,
          538,
          597,
          321,
          747,
          300,
          659,
          12,
          17227,
          2001,
          22625,
          31890,
          2316,
          293,
          1936,
          14299,
          309,
          490,
          439,
          729,
          16949,
          293,
          30095,
          309,
          281,
          527,
          1065,
          16949,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18182176575624853,
        "compression_ratio": 1.9259259259259258,
        "end": 2727.36,
        "id": 761,
        "no_speech_prob": 0.025954993441700935,
        "seek": 272436,
        "start": 2724.36,
        "temperature": 0,
        "text": " For example, I'm going to make up a label called happy and a label called sad.",
        "tokens": [
          50364,
          1171,
          1365,
          11,
          286,
          478,
          516,
          281,
          652,
          493,
          257,
          7645,
          1219,
          2055,
          293,
          257,
          7645,
          1219,
          4227,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.18182176575624853,
        "compression_ratio": 1.9259259259259258,
        "end": 2729.36,
        "id": 762,
        "no_speech_prob": 0.025954993441700935,
        "seek": 272436,
        "start": 2727.36,
        "temperature": 0,
        "text": " I can certainly have more than just two.",
        "tokens": [
          50514,
          286,
          393,
          3297,
          362,
          544,
          813,
          445,
          732,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18182176575624853,
        "compression_ratio": 1.9259259259259258,
        "end": 2734.36,
        "id": 763,
        "no_speech_prob": 0.025954993441700935,
        "seek": 272436,
        "start": 2729.36,
        "temperature": 0,
        "text": " And I'm going to show it things like the train whistle is me being happy.",
        "tokens": [
          50614,
          400,
          286,
          478,
          516,
          281,
          855,
          309,
          721,
          411,
          264,
          3847,
          23470,
          307,
          385,
          885,
          2055,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.18182176575624853,
        "compression_ratio": 1.9259259259259258,
        "end": 2742.36,
        "id": 764,
        "no_speech_prob": 0.025954993441700935,
        "seek": 272436,
        "start": 2734.36,
        "temperature": 0,
        "text": " I'm going to show it that train whistle a bunch of times.",
        "tokens": [
          50864,
          286,
          478,
          516,
          281,
          855,
          309,
          300,
          3847,
          23470,
          257,
          3840,
          295,
          1413,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18182176575624853,
        "compression_ratio": 1.9259259259259258,
        "end": 2743.36,
        "id": 765,
        "no_speech_prob": 0.025954993441700935,
        "seek": 272436,
        "start": 2742.36,
        "temperature": 0,
        "text": " Say happy, happy, happy, happy, happy.",
        "tokens": [
          51264,
          6463,
          2055,
          11,
          2055,
          11,
          2055,
          11,
          2055,
          11,
          2055,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18182176575624853,
        "compression_ratio": 1.9259259259259258,
        "end": 2746.36,
        "id": 766,
        "no_speech_prob": 0.025954993441700935,
        "seek": 272436,
        "start": 2743.36,
        "temperature": 0,
        "text": " Now, no train whistle is very sad.",
        "tokens": [
          51314,
          823,
          11,
          572,
          3847,
          23470,
          307,
          588,
          4227,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18182176575624853,
        "compression_ratio": 1.9259259259259258,
        "end": 2747.36,
        "id": 767,
        "no_speech_prob": 0.025954993441700935,
        "seek": 272436,
        "start": 2746.36,
        "temperature": 0,
        "text": " I'm sad.",
        "tokens": [
          51464,
          286,
          478,
          4227,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.18182176575624853,
        "compression_ratio": 1.9259259259259258,
        "end": 2748.36,
        "id": 768,
        "no_speech_prob": 0.025954993441700935,
        "seek": 272436,
        "start": 2747.36,
        "temperature": 0,
        "text": " No train whistle is sad.",
        "tokens": [
          51514,
          883,
          3847,
          23470,
          307,
          4227,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18182176575624853,
        "compression_ratio": 1.9259259259259258,
        "end": 2752.36,
        "id": 769,
        "no_speech_prob": 0.025954993441700935,
        "seek": 272436,
        "start": 2748.36,
        "temperature": 0,
        "text": " Oh, I'm spending way too much time on this because I haven't implemented the thing that I want to implement.",
        "tokens": [
          51564,
          876,
          11,
          286,
          478,
          6434,
          636,
          886,
          709,
          565,
          322,
          341,
          570,
          286,
          2378,
          380,
          12270,
          264,
          551,
          300,
          286,
          528,
          281,
          4445,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.22925392398989297,
        "compression_ratio": 1.6069868995633187,
        "end": 2755.36,
        "id": 770,
        "no_speech_prob": 0.01665651984512806,
        "seek": 275236,
        "start": 2752.36,
        "temperature": 0,
        "text": " Now, I'm going to say train and it's going to train.",
        "tokens": [
          50364,
          823,
          11,
          286,
          478,
          516,
          281,
          584,
          3847,
          293,
          309,
          311,
          516,
          281,
          3847,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.22925392398989297,
        "compression_ratio": 1.6069868995633187,
        "end": 2759.36,
        "id": 771,
        "no_speech_prob": 0.01665651984512806,
        "seek": 275236,
        "start": 2755.36,
        "temperature": 0,
        "text": " And then once it's done, ah!",
        "tokens": [
          50514,
          400,
          550,
          1564,
          309,
          311,
          1096,
          11,
          3716,
          0,
          50714
        ]
      },
      {
        "avg_logprob": -0.22925392398989297,
        "compression_ratio": 1.6069868995633187,
        "end": 2761.36,
        "id": 772,
        "no_speech_prob": 0.01665651984512806,
        "seek": 275236,
        "start": 2759.36,
        "temperature": 0,
        "text": " Happy.",
        "tokens": [
          50714,
          8277,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.22925392398989297,
        "compression_ratio": 1.6069868995633187,
        "end": 2763.36,
        "id": 773,
        "no_speech_prob": 0.01665651984512806,
        "seek": 275236,
        "start": 2761.36,
        "temperature": 0,
        "text": " Sad.",
        "tokens": [
          50814,
          12269,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.22925392398989297,
        "compression_ratio": 1.6069868995633187,
        "end": 2764.36,
        "id": 774,
        "no_speech_prob": 0.01665651984512806,
        "seek": 275236,
        "start": 2763.36,
        "temperature": 0,
        "text": " Happy.",
        "tokens": [
          50914,
          8277,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.22925392398989297,
        "compression_ratio": 1.6069868995633187,
        "end": 2765.36,
        "id": 775,
        "no_speech_prob": 0.01665651984512806,
        "seek": 275236,
        "start": 2764.36,
        "temperature": 0,
        "text": " Train whistle.",
        "tokens": [
          50964,
          28029,
          23470,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.22925392398989297,
        "compression_ratio": 1.6069868995633187,
        "end": 2766.36,
        "id": 776,
        "no_speech_prob": 0.01665651984512806,
        "seek": 275236,
        "start": 2765.36,
        "temperature": 0,
        "text": " Sad.",
        "tokens": [
          51014,
          12269,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.22925392398989297,
        "compression_ratio": 1.6069868995633187,
        "end": 2767.36,
        "id": 777,
        "no_speech_prob": 0.01665651984512806,
        "seek": 275236,
        "start": 2766.36,
        "temperature": 0,
        "text": " Okay, so it works.",
        "tokens": [
          51064,
          1033,
          11,
          370,
          309,
          1985,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.22925392398989297,
        "compression_ratio": 1.6069868995633187,
        "end": 2770.36,
        "id": 778,
        "no_speech_prob": 0.01665651984512806,
        "seek": 275236,
        "start": 2767.36,
        "temperature": 0,
        "text": " It is now learning to classify images in real time according to those two categories.",
        "tokens": [
          51114,
          467,
          307,
          586,
          2539,
          281,
          33872,
          5267,
          294,
          957,
          565,
          4650,
          281,
          729,
          732,
          10479,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.22925392398989297,
        "compression_ratio": 1.6069868995633187,
        "end": 2776.36,
        "id": 779,
        "no_speech_prob": 0.01665651984512806,
        "seek": 275236,
        "start": 2770.36,
        "temperature": 0,
        "text": " But I'm a big spaz and I'm going to just be over here doing refresh.",
        "tokens": [
          51264,
          583,
          286,
          478,
          257,
          955,
          637,
          921,
          293,
          286,
          478,
          516,
          281,
          445,
          312,
          670,
          510,
          884,
          15134,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.22925392398989297,
        "compression_ratio": 1.6069868995633187,
        "end": 2778.36,
        "id": 780,
        "no_speech_prob": 0.01665651984512806,
        "seek": 275236,
        "start": 2776.36,
        "temperature": 0,
        "text": " And I have now lost that forever.",
        "tokens": [
          51564,
          400,
          286,
          362,
          586,
          2731,
          300,
          5680,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.22925392398989297,
        "compression_ratio": 1.6069868995633187,
        "end": 2779.36,
        "id": 781,
        "no_speech_prob": 0.01665651984512806,
        "seek": 275236,
        "start": 2778.36,
        "temperature": 0,
        "text": " I no longer have that model.",
        "tokens": [
          51664,
          286,
          572,
          2854,
          362,
          300,
          2316,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.22925392398989297,
        "compression_ratio": 1.6069868995633187,
        "end": 2781.36,
        "id": 782,
        "no_speech_prob": 0.01665651984512806,
        "seek": 275236,
        "start": 2779.36,
        "temperature": 0,
        "text": " It's gone.",
        "tokens": [
          51714,
          467,
          311,
          2780,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.18060598108503553,
        "compression_ratio": 1.919298245614035,
        "end": 2787.36,
        "id": 783,
        "no_speech_prob": 0.00293492479249835,
        "seek": 278136,
        "start": 2781.36,
        "temperature": 0,
        "text": " The new feature is ability to save that custom trained model and then reload it.",
        "tokens": [
          50364,
          440,
          777,
          4111,
          307,
          3485,
          281,
          3155,
          300,
          2375,
          8895,
          2316,
          293,
          550,
          25628,
          309,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.18060598108503553,
        "compression_ratio": 1.919298245614035,
        "end": 2794.36,
        "id": 784,
        "no_speech_prob": 0.00293492479249835,
        "seek": 278136,
        "start": 2787.36,
        "temperature": 0,
        "text": " So if you're using this for like an installation and you're going to like take down the computer and set it up every day, you can save that model.",
        "tokens": [
          50664,
          407,
          498,
          291,
          434,
          1228,
          341,
          337,
          411,
          364,
          13260,
          293,
          291,
          434,
          516,
          281,
          411,
          747,
          760,
          264,
          3820,
          293,
          992,
          309,
          493,
          633,
          786,
          11,
          291,
          393,
          3155,
          300,
          2316,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18060598108503553,
        "compression_ratio": 1.919298245614035,
        "end": 2795.36,
        "id": 785,
        "no_speech_prob": 0.00293492479249835,
        "seek": 278136,
        "start": 2794.36,
        "temperature": 0,
        "text": " You can imagine.",
        "tokens": [
          51014,
          509,
          393,
          3811,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.18060598108503553,
        "compression_ratio": 1.919298245614035,
        "end": 2796.36,
        "id": 786,
        "no_speech_prob": 0.00293492479249835,
        "seek": 278136,
        "start": 2795.36,
        "temperature": 0,
        "text": " There's lots of possibilities here.",
        "tokens": [
          51064,
          821,
          311,
          3195,
          295,
          12178,
          510,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18060598108503553,
        "compression_ratio": 1.919298245614035,
        "end": 2799.36,
        "id": 787,
        "no_speech_prob": 0.00293492479249835,
        "seek": 278136,
        "start": 2796.36,
        "temperature": 0,
        "text": " So there's only two things that I really need to add to the code.",
        "tokens": [
          51114,
          407,
          456,
          311,
          787,
          732,
          721,
          300,
          286,
          534,
          643,
          281,
          909,
          281,
          264,
          3089,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18060598108503553,
        "compression_ratio": 1.919298245614035,
        "end": 2801.36,
        "id": 788,
        "no_speech_prob": 0.00293492479249835,
        "seek": 278136,
        "start": 2799.36,
        "temperature": 0,
        "text": " There's a save function and a load function.",
        "tokens": [
          51264,
          821,
          311,
          257,
          3155,
          2445,
          293,
          257,
          3677,
          2445,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18060598108503553,
        "compression_ratio": 1.919298245614035,
        "end": 2803.36,
        "id": 789,
        "no_speech_prob": 0.00293492479249835,
        "seek": 278136,
        "start": 2801.36,
        "temperature": 0,
        "text": " There's a bunch of pieces there, but that's what I'm going to do right now.",
        "tokens": [
          51364,
          821,
          311,
          257,
          3840,
          295,
          3755,
          456,
          11,
          457,
          300,
          311,
          437,
          286,
          478,
          516,
          281,
          360,
          558,
          586,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18060598108503553,
        "compression_ratio": 1.919298245614035,
        "end": 2808.36,
        "id": 790,
        "no_speech_prob": 0.00293492479249835,
        "seek": 278136,
        "start": 2803.36,
        "temperature": 0,
        "text": " So I'm going to go here into the code and I'm going to just add another button.",
        "tokens": [
          51464,
          407,
          286,
          478,
          516,
          281,
          352,
          510,
          666,
          264,
          3089,
          293,
          286,
          478,
          516,
          281,
          445,
          909,
          1071,
          2960,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20905064932907683,
        "compression_ratio": 1.9316239316239316,
        "end": 2811.36,
        "id": 791,
        "no_speech_prob": 0.10970118641853333,
        "seek": 280836,
        "start": 2808.36,
        "temperature": 0,
        "text": " Like I have a happy button, a sad button, and a train button.",
        "tokens": [
          50364,
          1743,
          286,
          362,
          257,
          2055,
          2960,
          11,
          257,
          4227,
          2960,
          11,
          293,
          257,
          3847,
          2960,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.20905064932907683,
        "compression_ratio": 1.9316239316239316,
        "end": 2812.36,
        "id": 792,
        "no_speech_prob": 0.10970118641853333,
        "seek": 280836,
        "start": 2811.36,
        "temperature": 0,
        "text": " Choo choo.",
        "tokens": [
          50514,
          761,
          1986,
          1586,
          78,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.20905064932907683,
        "compression_ratio": 1.9316239316239316,
        "end": 2814.36,
        "id": 793,
        "no_speech_prob": 0.10970118641853333,
        "seek": 280836,
        "start": 2812.36,
        "temperature": 0,
        "text": " I'm going to add a sad button.",
        "tokens": [
          50564,
          286,
          478,
          516,
          281,
          909,
          257,
          4227,
          2960,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20905064932907683,
        "compression_ratio": 1.9316239316239316,
        "end": 2816.36,
        "id": 794,
        "no_speech_prob": 0.10970118641853333,
        "seek": 280836,
        "start": 2814.36,
        "temperature": 0,
        "text": " No, no, not sad.",
        "tokens": [
          50664,
          883,
          11,
          572,
          11,
          406,
          4227,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20905064932907683,
        "compression_ratio": 1.9316239316239316,
        "end": 2817.36,
        "id": 795,
        "no_speech_prob": 0.10970118641853333,
        "seek": 280836,
        "start": 2816.36,
        "temperature": 0,
        "text": " A save button.",
        "tokens": [
          50764,
          316,
          3155,
          2960,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20905064932907683,
        "compression_ratio": 1.9316239316239316,
        "end": 2819.36,
        "id": 796,
        "no_speech_prob": 0.10970118641853333,
        "seek": 280836,
        "start": 2817.36,
        "temperature": 0,
        "text": " I'm going to call it save.",
        "tokens": [
          50814,
          286,
          478,
          516,
          281,
          818,
          309,
          3155,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20905064932907683,
        "compression_ratio": 1.9316239316239316,
        "end": 2821.36,
        "id": 797,
        "no_speech_prob": 0.10970118641853333,
        "seek": 280836,
        "start": 2819.36,
        "temperature": 0,
        "text": " And save button when the mouse is pressed.",
        "tokens": [
          50914,
          400,
          3155,
          2960,
          562,
          264,
          9719,
          307,
          17355,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20905064932907683,
        "compression_ratio": 1.9316239316239316,
        "end": 2824.36,
        "id": 798,
        "no_speech_prob": 0.10970118641853333,
        "seek": 280836,
        "start": 2821.36,
        "temperature": 0,
        "text": " I'm just going to say classifier.save.",
        "tokens": [
          51014,
          286,
          478,
          445,
          516,
          281,
          584,
          1508,
          9902,
          13,
          82,
          946,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.20905064932907683,
        "compression_ratio": 1.9316239316239316,
        "end": 2825.36,
        "id": 799,
        "no_speech_prob": 0.10970118641853333,
        "seek": 280836,
        "start": 2824.36,
        "temperature": 0,
        "text": " That's it.",
        "tokens": [
          51164,
          663,
          311,
          309,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20905064932907683,
        "compression_ratio": 1.9316239316239316,
        "end": 2827.36,
        "id": 800,
        "no_speech_prob": 0.10970118641853333,
        "seek": 280836,
        "start": 2825.36,
        "temperature": 0,
        "text": " All I have to do is say classifier.save.",
        "tokens": [
          51214,
          1057,
          286,
          362,
          281,
          360,
          307,
          584,
          1508,
          9902,
          13,
          82,
          946,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20905064932907683,
        "compression_ratio": 1.9316239316239316,
        "end": 2829.36,
        "id": 801,
        "no_speech_prob": 0.10970118641853333,
        "seek": 280836,
        "start": 2827.36,
        "temperature": 0,
        "text": " Let's see what happens.",
        "tokens": [
          51314,
          961,
          311,
          536,
          437,
          2314,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20905064932907683,
        "compression_ratio": 1.9316239316239316,
        "end": 2831.36,
        "id": 802,
        "no_speech_prob": 0.10970118641853333,
        "seek": 280836,
        "start": 2829.36,
        "temperature": 0,
        "text": " So I'm not going to train it very.",
        "tokens": [
          51414,
          407,
          286,
          478,
          406,
          516,
          281,
          3847,
          309,
          588,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20905064932907683,
        "compression_ratio": 1.9316239316239316,
        "end": 2834.36,
        "id": 803,
        "no_speech_prob": 0.10970118641853333,
        "seek": 280836,
        "start": 2831.36,
        "temperature": 0,
        "text": " Actually, no, I am going to train.",
        "tokens": [
          51514,
          5135,
          11,
          572,
          11,
          286,
          669,
          516,
          281,
          3847,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20905064932907683,
        "compression_ratio": 1.9316239316239316,
        "end": 2836.36,
        "id": 804,
        "no_speech_prob": 0.10970118641853333,
        "seek": 280836,
        "start": 2834.36,
        "temperature": 0,
        "text": " I'm going to let's do a really good solid training this time.",
        "tokens": [
          51664,
          286,
          478,
          516,
          281,
          718,
          311,
          360,
          257,
          534,
          665,
          5100,
          3097,
          341,
          565,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17495845556259154,
        "compression_ratio": 1.8958333333333333,
        "end": 2838.36,
        "id": 805,
        "no_speech_prob": 0.007815646938979626,
        "seek": 283636,
        "start": 2836.36,
        "temperature": 0,
        "text": " Because this is the one we're going to save.",
        "tokens": [
          50364,
          1436,
          341,
          307,
          264,
          472,
          321,
          434,
          516,
          281,
          3155,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.17495845556259154,
        "compression_ratio": 1.8958333333333333,
        "end": 2839.36,
        "id": 806,
        "no_speech_prob": 0.007815646938979626,
        "seek": 283636,
        "start": 2838.36,
        "temperature": 0,
        "text": " Once it works.",
        "tokens": [
          50464,
          3443,
          309,
          1985,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.17495845556259154,
        "compression_ratio": 1.8958333333333333,
        "end": 2840.36,
        "id": 807,
        "no_speech_prob": 0.007815646938979626,
        "seek": 283636,
        "start": 2839.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50514,
          1057,
          558,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.17495845556259154,
        "compression_ratio": 1.8958333333333333,
        "end": 2841.36,
        "id": 808,
        "no_speech_prob": 0.007815646938979626,
        "seek": 283636,
        "start": 2840.36,
        "temperature": 0,
        "text": " So let's do the same thing.",
        "tokens": [
          50564,
          407,
          718,
          311,
          360,
          264,
          912,
          551,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.17495845556259154,
        "compression_ratio": 1.8958333333333333,
        "end": 2843.36,
        "id": 809,
        "no_speech_prob": 0.007815646938979626,
        "seek": 283636,
        "start": 2841.36,
        "temperature": 0,
        "text": " Happy, happy, happy, happy.",
        "tokens": [
          50614,
          8277,
          11,
          2055,
          11,
          2055,
          11,
          2055,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.17495845556259154,
        "compression_ratio": 1.8958333333333333,
        "end": 2846.36,
        "id": 810,
        "no_speech_prob": 0.007815646938979626,
        "seek": 283636,
        "start": 2843.36,
        "temperature": 0,
        "text": " Train whistle is a happy thing.",
        "tokens": [
          50714,
          28029,
          23470,
          307,
          257,
          2055,
          551,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.17495845556259154,
        "compression_ratio": 1.8958333333333333,
        "end": 2848.36,
        "id": 811,
        "no_speech_prob": 0.007815646938979626,
        "seek": 283636,
        "start": 2846.36,
        "temperature": 0,
        "text": " A happy, happy, happy thing.",
        "tokens": [
          50864,
          316,
          2055,
          11,
          2055,
          11,
          2055,
          551,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.17495845556259154,
        "compression_ratio": 1.8958333333333333,
        "end": 2850.36,
        "id": 812,
        "no_speech_prob": 0.007815646938979626,
        "seek": 283636,
        "start": 2848.36,
        "temperature": 0,
        "text": " Just me is very sad.",
        "tokens": [
          50964,
          1449,
          385,
          307,
          588,
          4227,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17495845556259154,
        "compression_ratio": 1.8958333333333333,
        "end": 2851.36,
        "id": 813,
        "no_speech_prob": 0.007815646938979626,
        "seek": 283636,
        "start": 2850.36,
        "temperature": 0,
        "text": " There's no train whistle.",
        "tokens": [
          51064,
          821,
          311,
          572,
          3847,
          23470,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17495845556259154,
        "compression_ratio": 1.8958333333333333,
        "end": 2852.36,
        "id": 814,
        "no_speech_prob": 0.007815646938979626,
        "seek": 283636,
        "start": 2851.36,
        "temperature": 0,
        "text": " I'm so sad.",
        "tokens": [
          51114,
          286,
          478,
          370,
          4227,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.17495845556259154,
        "compression_ratio": 1.8958333333333333,
        "end": 2853.36,
        "id": 815,
        "no_speech_prob": 0.007815646938979626,
        "seek": 283636,
        "start": 2852.36,
        "temperature": 0,
        "text": " I'm very sad.",
        "tokens": [
          51164,
          286,
          478,
          588,
          4227,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17495845556259154,
        "compression_ratio": 1.8958333333333333,
        "end": 2854.36,
        "id": 816,
        "no_speech_prob": 0.007815646938979626,
        "seek": 283636,
        "start": 2853.36,
        "temperature": 0,
        "text": " I'm very sad.",
        "tokens": [
          51214,
          286,
          478,
          588,
          4227,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.17495845556259154,
        "compression_ratio": 1.8958333333333333,
        "end": 2856.36,
        "id": 817,
        "no_speech_prob": 0.007815646938979626,
        "seek": 283636,
        "start": 2854.36,
        "temperature": 0,
        "text": " And now I'm going to train this.",
        "tokens": [
          51264,
          400,
          586,
          286,
          478,
          516,
          281,
          3847,
          341,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.17495845556259154,
        "compression_ratio": 1.8958333333333333,
        "end": 2858.36,
        "id": 818,
        "no_speech_prob": 0.007815646938979626,
        "seek": 283636,
        "start": 2856.36,
        "temperature": 0,
        "text": " Weird how the loss is zero.",
        "tokens": [
          51364,
          32033,
          577,
          264,
          4470,
          307,
          4018,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.17495845556259154,
        "compression_ratio": 1.8958333333333333,
        "end": 2860.36,
        "id": 819,
        "no_speech_prob": 0.007815646938979626,
        "seek": 283636,
        "start": 2858.36,
        "temperature": 0,
        "text": " I'm just going to not worry about that too much.",
        "tokens": [
          51464,
          286,
          478,
          445,
          516,
          281,
          406,
          3292,
          466,
          300,
          886,
          709,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.17495845556259154,
        "compression_ratio": 1.8958333333333333,
        "end": 2863.36,
        "id": 820,
        "no_speech_prob": 0.007815646938979626,
        "seek": 283636,
        "start": 2860.36,
        "temperature": 0,
        "text": " I'm going to hit save.",
        "tokens": [
          51564,
          286,
          478,
          516,
          281,
          2045,
          3155,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17495845556259154,
        "compression_ratio": 1.8958333333333333,
        "end": 2865.36,
        "id": 821,
        "no_speech_prob": 0.007815646938979626,
        "seek": 283636,
        "start": 2863.36,
        "temperature": 0,
        "text": " And now you can see that down here, by the way,",
        "tokens": [
          51714,
          400,
          586,
          291,
          393,
          536,
          300,
          760,
          510,
          11,
          538,
          264,
          636,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.1705253016841304,
        "compression_ratio": 1.704035874439462,
        "end": 2867.36,
        "id": 822,
        "no_speech_prob": 0.00006922156899236143,
        "seek": 286536,
        "start": 2865.36,
        "temperature": 0,
        "text": " that I did this a couple times practicing.",
        "tokens": [
          50364,
          300,
          286,
          630,
          341,
          257,
          1916,
          1413,
          11350,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1705253016841304,
        "compression_ratio": 1.704035874439462,
        "end": 2871.36,
        "id": 823,
        "no_speech_prob": 0.00006922156899236143,
        "seek": 286536,
        "start": 2867.36,
        "temperature": 0,
        "text": " Now what it did is it downloaded, come on,",
        "tokens": [
          50464,
          823,
          437,
          309,
          630,
          307,
          309,
          21748,
          11,
          808,
          322,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.1705253016841304,
        "compression_ratio": 1.704035874439462,
        "end": 2876.36,
        "id": 824,
        "no_speech_prob": 0.00006922156899236143,
        "seek": 286536,
        "start": 2871.36,
        "temperature": 0,
        "text": " to my download directory two files, model.json",
        "tokens": [
          50664,
          281,
          452,
          5484,
          21120,
          732,
          7098,
          11,
          2316,
          13,
          73,
          3015,
          50914
        ]
      },
      {
        "avg_logprob": -0.1705253016841304,
        "compression_ratio": 1.704035874439462,
        "end": 2878.36,
        "id": 825,
        "no_speech_prob": 0.00006922156899236143,
        "seek": 286536,
        "start": 2876.36,
        "temperature": 0,
        "text": " and model.weights.bin.",
        "tokens": [
          50914,
          293,
          2316,
          13,
          826,
          5761,
          13,
          13496,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1705253016841304,
        "compression_ratio": 1.704035874439462,
        "end": 2880.36,
        "id": 826,
        "no_speech_prob": 0.00006922156899236143,
        "seek": 286536,
        "start": 2878.36,
        "temperature": 0,
        "text": " So those files will end up wherever",
        "tokens": [
          51014,
          407,
          729,
          7098,
          486,
          917,
          493,
          8660,
          51114
        ]
      },
      {
        "avg_logprob": -0.1705253016841304,
        "compression_ratio": 1.704035874439462,
        "end": 2883.36,
        "id": 827,
        "no_speech_prob": 0.00006922156899236143,
        "seek": 286536,
        "start": 2880.36,
        "temperature": 0,
        "text": " the default downloads directory of your browser is.",
        "tokens": [
          51114,
          264,
          7576,
          36553,
          21120,
          295,
          428,
          11185,
          307,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1705253016841304,
        "compression_ratio": 1.704035874439462,
        "end": 2885.36,
        "id": 828,
        "no_speech_prob": 0.00006922156899236143,
        "seek": 286536,
        "start": 2883.36,
        "temperature": 0,
        "text": " And the next step is just to load those files in.",
        "tokens": [
          51264,
          400,
          264,
          958,
          1823,
          307,
          445,
          281,
          3677,
          729,
          7098,
          294,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1705253016841304,
        "compression_ratio": 1.704035874439462,
        "end": 2887.36,
        "id": 829,
        "no_speech_prob": 0.00006922156899236143,
        "seek": 286536,
        "start": 2885.36,
        "temperature": 0,
        "text": " But before we load them, let's talk about what's",
        "tokens": [
          51364,
          583,
          949,
          321,
          3677,
          552,
          11,
          718,
          311,
          751,
          466,
          437,
          311,
          51464
        ]
      },
      {
        "avg_logprob": -0.1705253016841304,
        "compression_ratio": 1.704035874439462,
        "end": 2889.36,
        "id": 830,
        "no_speech_prob": 0.00006922156899236143,
        "seek": 286536,
        "start": 2887.36,
        "temperature": 0,
        "text": " in those files.",
        "tokens": [
          51464,
          294,
          729,
          7098,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1705253016841304,
        "compression_ratio": 1.704035874439462,
        "end": 2890.36,
        "id": 831,
        "no_speech_prob": 0.00006922156899236143,
        "seek": 286536,
        "start": 2889.36,
        "temperature": 0,
        "text": " So there's two files.",
        "tokens": [
          51564,
          407,
          456,
          311,
          732,
          7098,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2222577263327206,
        "compression_ratio": 1.4863013698630136,
        "end": 2895.36,
        "id": 832,
        "no_speech_prob": 0.004399381577968597,
        "seek": 289036,
        "start": 2890.36,
        "temperature": 0,
        "text": " Model.json and model.weights.bin.",
        "tokens": [
          50364,
          17105,
          13,
          73,
          3015,
          293,
          2316,
          13,
          826,
          5761,
          13,
          13496,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2222577263327206,
        "compression_ratio": 1.4863013698630136,
        "end": 2911.36,
        "id": 833,
        "no_speech_prob": 0.004399381577968597,
        "seek": 289036,
        "start": 2908.36,
        "temperature": 0,
        "text": " OK, so what is a neural network?",
        "tokens": [
          51264,
          2264,
          11,
          370,
          437,
          307,
          257,
          18161,
          3209,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.2222577263327206,
        "compression_ratio": 1.4863013698630136,
        "end": 2913.36,
        "id": 834,
        "no_speech_prob": 0.004399381577968597,
        "seek": 289036,
        "start": 2911.36,
        "temperature": 0,
        "text": " What is a machine learning model?",
        "tokens": [
          51414,
          708,
          307,
          257,
          3479,
          2539,
          2316,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.2222577263327206,
        "compression_ratio": 1.4863013698630136,
        "end": 2914.36,
        "id": 835,
        "no_speech_prob": 0.004399381577968597,
        "seek": 289036,
        "start": 2913.36,
        "temperature": 0,
        "text": " What is the thing that we're saving?",
        "tokens": [
          51514,
          708,
          307,
          264,
          551,
          300,
          321,
          434,
          6816,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.2222577263327206,
        "compression_ratio": 1.4863013698630136,
        "end": 2916.36,
        "id": 836,
        "no_speech_prob": 0.004399381577968597,
        "seek": 289036,
        "start": 2914.36,
        "temperature": 0,
        "text": " Well, in this case, it's actually",
        "tokens": [
          51564,
          1042,
          11,
          294,
          341,
          1389,
          11,
          309,
          311,
          767,
          51664
        ]
      },
      {
        "avg_logprob": -0.2222577263327206,
        "compression_ratio": 1.4863013698630136,
        "end": 2919.36,
        "id": 837,
        "no_speech_prob": 0.004399381577968597,
        "seek": 289036,
        "start": 2916.36,
        "temperature": 0,
        "text": " saving the configuration of a neural network.",
        "tokens": [
          51664,
          6816,
          264,
          11694,
          295,
          257,
          18161,
          3209,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.16441650677444344,
        "compression_ratio": 1.7313432835820894,
        "end": 2921.36,
        "id": 838,
        "no_speech_prob": 0.0002002726832870394,
        "seek": 291936,
        "start": 2919.36,
        "temperature": 0,
        "text": " Now, if you want to know what a neural network is,",
        "tokens": [
          50364,
          823,
          11,
          498,
          291,
          528,
          281,
          458,
          437,
          257,
          18161,
          3209,
          307,
          11,
          50464
        ]
      },
      {
        "avg_logprob": -0.16441650677444344,
        "compression_ratio": 1.7313432835820894,
        "end": 2922.36,
        "id": 839,
        "no_speech_prob": 0.0002002726832870394,
        "seek": 291936,
        "start": 2921.36,
        "temperature": 0,
        "text": " I have some videos about that.",
        "tokens": [
          50464,
          286,
          362,
          512,
          2145,
          466,
          300,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.16441650677444344,
        "compression_ratio": 1.7313432835820894,
        "end": 2926.36,
        "id": 840,
        "no_speech_prob": 0.0002002726832870394,
        "seek": 291936,
        "start": 2922.36,
        "temperature": 0,
        "text": " But I would refer you to the three blue, one brown video,",
        "tokens": [
          50514,
          583,
          286,
          576,
          2864,
          291,
          281,
          264,
          1045,
          3344,
          11,
          472,
          6292,
          960,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.16441650677444344,
        "compression_ratio": 1.7313432835820894,
        "end": 2927.36,
        "id": 841,
        "no_speech_prob": 0.0002002726832870394,
        "seek": 291936,
        "start": 2926.36,
        "temperature": 0,
        "text": " what is a neural network.",
        "tokens": [
          50714,
          437,
          307,
          257,
          18161,
          3209,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.16441650677444344,
        "compression_ratio": 1.7313432835820894,
        "end": 2929.36,
        "id": 842,
        "no_speech_prob": 0.0002002726832870394,
        "seek": 291936,
        "start": 2927.36,
        "temperature": 0,
        "text": " I will link to that in this video's description.",
        "tokens": [
          50764,
          286,
          486,
          2113,
          281,
          300,
          294,
          341,
          960,
          311,
          3855,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.16441650677444344,
        "compression_ratio": 1.7313432835820894,
        "end": 2933.36,
        "id": 843,
        "no_speech_prob": 0.0002002726832870394,
        "seek": 291936,
        "start": 2929.36,
        "temperature": 0,
        "text": " That will give you a much bigger deep dive into those details.",
        "tokens": [
          50864,
          663,
          486,
          976,
          291,
          257,
          709,
          3801,
          2452,
          9192,
          666,
          729,
          4365,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.16441650677444344,
        "compression_ratio": 1.7313432835820894,
        "end": 2935.36,
        "id": 844,
        "no_speech_prob": 0.0002002726832870394,
        "seek": 291936,
        "start": 2933.36,
        "temperature": 0,
        "text": " But if you look at that video, what you'll see",
        "tokens": [
          51064,
          583,
          498,
          291,
          574,
          412,
          300,
          960,
          11,
          437,
          291,
          603,
          536,
          51164
        ]
      },
      {
        "avg_logprob": -0.16441650677444344,
        "compression_ratio": 1.7313432835820894,
        "end": 2937.36,
        "id": 845,
        "no_speech_prob": 0.0002002726832870394,
        "seek": 291936,
        "start": 2935.36,
        "temperature": 0,
        "text": " is there's basically a big diagram.",
        "tokens": [
          51164,
          307,
          456,
          311,
          1936,
          257,
          955,
          10686,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.16441650677444344,
        "compression_ratio": 1.7313432835820894,
        "end": 2941.36,
        "id": 846,
        "no_speech_prob": 0.0002002726832870394,
        "seek": 291936,
        "start": 2937.36,
        "temperature": 0,
        "text": " And the diagram has a bunch of inputs.",
        "tokens": [
          51264,
          400,
          264,
          10686,
          575,
          257,
          3840,
          295,
          15743,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.16441650677444344,
        "compression_ratio": 1.7313432835820894,
        "end": 2942.36,
        "id": 847,
        "no_speech_prob": 0.0002002726832870394,
        "seek": 291936,
        "start": 2941.36,
        "temperature": 0,
        "text": " It has some outputs.",
        "tokens": [
          51464,
          467,
          575,
          512,
          23930,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.16441650677444344,
        "compression_ratio": 1.7313432835820894,
        "end": 2944.36,
        "id": 848,
        "no_speech_prob": 0.0002002726832870394,
        "seek": 291936,
        "start": 2942.36,
        "temperature": 0,
        "text": " By the way, in this case, we could actually",
        "tokens": [
          51514,
          3146,
          264,
          636,
          11,
          294,
          341,
          1389,
          11,
          321,
          727,
          767,
          51614
        ]
      },
      {
        "avg_logprob": -0.1883906466620309,
        "compression_ratio": 1.7973568281938326,
        "end": 2949.36,
        "id": 849,
        "no_speech_prob": 0.0036499667912721634,
        "seek": 294436,
        "start": 2944.36,
        "temperature": 0,
        "text": " say the outputs are just two, a happy and a sad.",
        "tokens": [
          50364,
          584,
          264,
          23930,
          366,
          445,
          732,
          11,
          257,
          2055,
          293,
          257,
          4227,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1883906466620309,
        "compression_ratio": 1.7973568281938326,
        "end": 2951.36,
        "id": 850,
        "no_speech_prob": 0.0036499667912721634,
        "seek": 294436,
        "start": 2949.36,
        "temperature": 0,
        "text": " And what the neural network, what the machine learning",
        "tokens": [
          50614,
          400,
          437,
          264,
          18161,
          3209,
          11,
          437,
          264,
          3479,
          2539,
          50714
        ]
      },
      {
        "avg_logprob": -0.1883906466620309,
        "compression_ratio": 1.7973568281938326,
        "end": 2957.36,
        "id": 851,
        "no_speech_prob": 0.0036499667912721634,
        "seek": 294436,
        "start": 2951.36,
        "temperature": 0,
        "text": " model outputs is a probability, maybe like 80% of it",
        "tokens": [
          50714,
          2316,
          23930,
          307,
          257,
          8482,
          11,
          1310,
          411,
          4688,
          4,
          295,
          309,
          51014
        ]
      },
      {
        "avg_logprob": -0.1883906466620309,
        "compression_ratio": 1.7973568281938326,
        "end": 2961.36,
        "id": 852,
        "no_speech_prob": 0.0036499667912721634,
        "seek": 294436,
        "start": 2957.36,
        "temperature": 0,
        "text": " being happy, of that image being happy, and 20% that image",
        "tokens": [
          51014,
          885,
          2055,
          11,
          295,
          300,
          3256,
          885,
          2055,
          11,
          293,
          945,
          4,
          300,
          3256,
          51214
        ]
      },
      {
        "avg_logprob": -0.1883906466620309,
        "compression_ratio": 1.7973568281938326,
        "end": 2962.36,
        "id": 853,
        "no_speech_prob": 0.0036499667912721634,
        "seek": 294436,
        "start": 2961.36,
        "temperature": 0,
        "text": " is sad.",
        "tokens": [
          51214,
          307,
          4227,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1883906466620309,
        "compression_ratio": 1.7973568281938326,
        "end": 2965.36,
        "id": 854,
        "no_speech_prob": 0.0036499667912721634,
        "seek": 294436,
        "start": 2962.36,
        "temperature": 0,
        "text": " So the whole point of this is to feed in an image.",
        "tokens": [
          51264,
          407,
          264,
          1379,
          935,
          295,
          341,
          307,
          281,
          3154,
          294,
          364,
          3256,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1883906466620309,
        "compression_ratio": 1.7973568281938326,
        "end": 2969.36,
        "id": 855,
        "no_speech_prob": 0.0036499667912721634,
        "seek": 294436,
        "start": 2965.36,
        "temperature": 0,
        "text": " It's the image and maybe all the pixels of the image that",
        "tokens": [
          51414,
          467,
          311,
          264,
          3256,
          293,
          1310,
          439,
          264,
          18668,
          295,
          264,
          3256,
          300,
          51614
        ]
      },
      {
        "avg_logprob": -0.1883906466620309,
        "compression_ratio": 1.7973568281938326,
        "end": 2971.36,
        "id": 856,
        "no_speech_prob": 0.0036499667912721634,
        "seek": 294436,
        "start": 2969.36,
        "temperature": 0,
        "text": " are actually these inputs.",
        "tokens": [
          51614,
          366,
          767,
          613,
          15743,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1883906466620309,
        "compression_ratio": 1.7973568281938326,
        "end": 2973.36,
        "id": 857,
        "no_speech_prob": 0.0036499667912721634,
        "seek": 294436,
        "start": 2971.36,
        "temperature": 0,
        "text": " It goes through this magic neural network thing,",
        "tokens": [
          51714,
          467,
          1709,
          807,
          341,
          5585,
          18161,
          3209,
          551,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.16524072126908737,
        "compression_ratio": 1.6608391608391608,
        "end": 2974.36,
        "id": 858,
        "no_speech_prob": 0.000008013486876734532,
        "seek": 297336,
        "start": 2973.36,
        "temperature": 0,
        "text": " which isn't really magic.",
        "tokens": [
          50364,
          597,
          1943,
          380,
          534,
          5585,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.16524072126908737,
        "compression_ratio": 1.6608391608391608,
        "end": 2976.36,
        "id": 859,
        "no_speech_prob": 0.000008013486876734532,
        "seek": 297336,
        "start": 2974.36,
        "temperature": 0,
        "text": " It's a thing that you can learn about.",
        "tokens": [
          50414,
          467,
          311,
          257,
          551,
          300,
          291,
          393,
          1466,
          466,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.16524072126908737,
        "compression_ratio": 1.6608391608391608,
        "end": 2979.36,
        "id": 860,
        "no_speech_prob": 0.000008013486876734532,
        "seek": 297336,
        "start": 2976.36,
        "temperature": 0,
        "text": " And then out the other end comes a guess as to whether it's",
        "tokens": [
          50514,
          400,
          550,
          484,
          264,
          661,
          917,
          1487,
          257,
          2041,
          382,
          281,
          1968,
          309,
          311,
          50664
        ]
      },
      {
        "avg_logprob": -0.16524072126908737,
        "compression_ratio": 1.6608391608391608,
        "end": 2980.36,
        "id": 861,
        "no_speech_prob": 0.000008013486876734532,
        "seek": 297336,
        "start": 2979.36,
        "temperature": 0,
        "text": " happy or sad.",
        "tokens": [
          50664,
          2055,
          420,
          4227,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.16524072126908737,
        "compression_ratio": 1.6608391608391608,
        "end": 2982.36,
        "id": 862,
        "no_speech_prob": 0.000008013486876734532,
        "seek": 297336,
        "start": 2980.36,
        "temperature": 0,
        "text": " Now, what is all this stuff in the middle?",
        "tokens": [
          50714,
          823,
          11,
          437,
          307,
          439,
          341,
          1507,
          294,
          264,
          2808,
          30,
          50814
        ]
      },
      {
        "avg_logprob": -0.16524072126908737,
        "compression_ratio": 1.6608391608391608,
        "end": 2985.36,
        "id": 863,
        "no_speech_prob": 0.000008013486876734532,
        "seek": 297336,
        "start": 2982.36,
        "temperature": 0,
        "text": " The stuff in the middle is typically referred to,",
        "tokens": [
          50814,
          440,
          1507,
          294,
          264,
          2808,
          307,
          5850,
          10839,
          281,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.16524072126908737,
        "compression_ratio": 1.6608391608391608,
        "end": 2987.36,
        "id": 864,
        "no_speech_prob": 0.000008013486876734532,
        "seek": 297336,
        "start": 2985.36,
        "temperature": 0,
        "text": " and there are many different styles and flavors",
        "tokens": [
          50964,
          293,
          456,
          366,
          867,
          819,
          13273,
          293,
          16303,
          51064
        ]
      },
      {
        "avg_logprob": -0.16524072126908737,
        "compression_ratio": 1.6608391608391608,
        "end": 2988.36,
        "id": 865,
        "no_speech_prob": 0.000008013486876734532,
        "seek": 297336,
        "start": 2987.36,
        "temperature": 0,
        "text": " and kinds of neural network.",
        "tokens": [
          51064,
          293,
          3685,
          295,
          18161,
          3209,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.16524072126908737,
        "compression_ratio": 1.6608391608391608,
        "end": 2991.36,
        "id": 866,
        "no_speech_prob": 0.000008013486876734532,
        "seek": 297336,
        "start": 2988.36,
        "temperature": 0,
        "text": " But in the sort of zoomed out view, in general terms,",
        "tokens": [
          51114,
          583,
          294,
          264,
          1333,
          295,
          8863,
          292,
          484,
          1910,
          11,
          294,
          2674,
          2115,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.16524072126908737,
        "compression_ratio": 1.6608391608391608,
        "end": 2994.36,
        "id": 867,
        "no_speech_prob": 0.000008013486876734532,
        "seek": 297336,
        "start": 2991.36,
        "temperature": 0,
        "text": " is what's known as a hidden layer or hidden layers.",
        "tokens": [
          51264,
          307,
          437,
          311,
          2570,
          382,
          257,
          7633,
          4583,
          420,
          7633,
          7914,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.16524072126908737,
        "compression_ratio": 1.6608391608391608,
        "end": 2999.36,
        "id": 868,
        "no_speech_prob": 0.000008013486876734532,
        "seek": 297336,
        "start": 2994.36,
        "temperature": 0,
        "text": " So every input is connected to the output, but not directly.",
        "tokens": [
          51414,
          407,
          633,
          4846,
          307,
          4582,
          281,
          264,
          5598,
          11,
          457,
          406,
          3838,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.22258617083231608,
        "compression_ratio": 1.9388646288209608,
        "end": 3004.1200000000003,
        "id": 869,
        "no_speech_prob": 0.00002668852175702341,
        "seek": 299936,
        "start": 2999.36,
        "temperature": 0,
        "text": " There are some amount of nodes, maybe two hidden layers, each",
        "tokens": [
          50364,
          821,
          366,
          512,
          2372,
          295,
          13891,
          11,
          1310,
          732,
          7633,
          7914,
          11,
          1184,
          50602
        ]
      },
      {
        "avg_logprob": -0.22258617083231608,
        "compression_ratio": 1.9388646288209608,
        "end": 3005.1600000000003,
        "id": 870,
        "no_speech_prob": 0.00002668852175702341,
        "seek": 299936,
        "start": 3004.1200000000003,
        "temperature": 0,
        "text": " with four nodes.",
        "tokens": [
          50602,
          365,
          1451,
          13891,
          13,
          50654
        ]
      },
      {
        "avg_logprob": -0.22258617083231608,
        "compression_ratio": 1.9388646288209608,
        "end": 3008.7200000000003,
        "id": 871,
        "no_speech_prob": 0.00002668852175702341,
        "seek": 299936,
        "start": 3005.1600000000003,
        "temperature": 0,
        "text": " And every input is connected to every node,",
        "tokens": [
          50654,
          400,
          633,
          4846,
          307,
          4582,
          281,
          633,
          9984,
          11,
          50832
        ]
      },
      {
        "avg_logprob": -0.22258617083231608,
        "compression_ratio": 1.9388646288209608,
        "end": 3010.7200000000003,
        "id": 872,
        "no_speech_prob": 0.00002668852175702341,
        "seek": 299936,
        "start": 3008.7200000000003,
        "temperature": 0,
        "text": " and then every node is connected to every node,",
        "tokens": [
          50832,
          293,
          550,
          633,
          9984,
          307,
          4582,
          281,
          633,
          9984,
          11,
          50932
        ]
      },
      {
        "avg_logprob": -0.22258617083231608,
        "compression_ratio": 1.9388646288209608,
        "end": 3012.52,
        "id": 873,
        "no_speech_prob": 0.00002668852175702341,
        "seek": 299936,
        "start": 3010.7200000000003,
        "temperature": 0,
        "text": " and then every node is connected to every output,",
        "tokens": [
          50932,
          293,
          550,
          633,
          9984,
          307,
          4582,
          281,
          633,
          5598,
          11,
          51022
        ]
      },
      {
        "avg_logprob": -0.22258617083231608,
        "compression_ratio": 1.9388646288209608,
        "end": 3013.52,
        "id": 874,
        "no_speech_prob": 0.00002668852175702341,
        "seek": 299936,
        "start": 3012.52,
        "temperature": 0,
        "text": " and so on and so forth.",
        "tokens": [
          51022,
          293,
          370,
          322,
          293,
          370,
          5220,
          13,
          51072
        ]
      },
      {
        "avg_logprob": -0.22258617083231608,
        "compression_ratio": 1.9388646288209608,
        "end": 3016.04,
        "id": 875,
        "no_speech_prob": 0.00002668852175702341,
        "seek": 299936,
        "start": 3013.52,
        "temperature": 0,
        "text": " So I could be here all day trying to do this diagram",
        "tokens": [
          51072,
          407,
          286,
          727,
          312,
          510,
          439,
          786,
          1382,
          281,
          360,
          341,
          10686,
          51198
        ]
      },
      {
        "avg_logprob": -0.22258617083231608,
        "compression_ratio": 1.9388646288209608,
        "end": 3018.04,
        "id": 876,
        "no_speech_prob": 0.00002668852175702341,
        "seek": 299936,
        "start": 3016.04,
        "temperature": 0,
        "text": " and draw every connection between everything.",
        "tokens": [
          51198,
          293,
          2642,
          633,
          4984,
          1296,
          1203,
          13,
          51298
        ]
      },
      {
        "avg_logprob": -0.22258617083231608,
        "compression_ratio": 1.9388646288209608,
        "end": 3019.32,
        "id": 877,
        "no_speech_prob": 0.00002668852175702341,
        "seek": 299936,
        "start": 3018.04,
        "temperature": 0,
        "text": " I'm not going to do that.",
        "tokens": [
          51298,
          286,
          478,
          406,
          516,
          281,
          360,
          300,
          13,
          51362
        ]
      },
      {
        "avg_logprob": -0.22258617083231608,
        "compression_ratio": 1.9388646288209608,
        "end": 3023.1200000000003,
        "id": 878,
        "no_speech_prob": 0.00002668852175702341,
        "seek": 299936,
        "start": 3019.32,
        "temperature": 0,
        "text": " But all of the information about here",
        "tokens": [
          51362,
          583,
          439,
          295,
          264,
          1589,
          466,
          510,
          51552
        ]
      },
      {
        "avg_logprob": -0.22258617083231608,
        "compression_ratio": 1.9388646288209608,
        "end": 3025.4,
        "id": 879,
        "no_speech_prob": 0.00002668852175702341,
        "seek": 299936,
        "start": 3023.1200000000003,
        "temperature": 0,
        "text": " is what is saved in these two files.",
        "tokens": [
          51552,
          307,
          437,
          307,
          6624,
          294,
          613,
          732,
          7098,
          13,
          51666
        ]
      },
      {
        "avg_logprob": -0.24061254027542794,
        "compression_ratio": 1.8241379310344827,
        "end": 3030.12,
        "id": 880,
        "no_speech_prob": 0.000058291159803047776,
        "seek": 302540,
        "start": 3025.4,
        "temperature": 0,
        "text": " Model.json is a file that just explains all of these pieces,",
        "tokens": [
          50364,
          17105,
          13,
          73,
          3015,
          307,
          257,
          3991,
          300,
          445,
          13948,
          439,
          295,
          613,
          3755,
          11,
          50600
        ]
      },
      {
        "avg_logprob": -0.24061254027542794,
        "compression_ratio": 1.8241379310344827,
        "end": 3033.88,
        "id": 881,
        "no_speech_prob": 0.000058291159803047776,
        "seek": 302540,
        "start": 3030.12,
        "temperature": 0,
        "text": " the layers, the outputs, the inputs, all of that stuff.",
        "tokens": [
          50600,
          264,
          7914,
          11,
          264,
          23930,
          11,
          264,
          15743,
          11,
          439,
          295,
          300,
          1507,
          13,
          50788
        ]
      },
      {
        "avg_logprob": -0.24061254027542794,
        "compression_ratio": 1.8241379310344827,
        "end": 3036.52,
        "id": 882,
        "no_speech_prob": 0.000058291159803047776,
        "seek": 302540,
        "start": 3033.88,
        "temperature": 0,
        "text": " That is what is in model.json.",
        "tokens": [
          50788,
          663,
          307,
          437,
          307,
          294,
          2316,
          13,
          73,
          3015,
          13,
          50920
        ]
      },
      {
        "avg_logprob": -0.24061254027542794,
        "compression_ratio": 1.8241379310344827,
        "end": 3039.04,
        "id": 883,
        "no_speech_prob": 0.000058291159803047776,
        "seek": 302540,
        "start": 3036.52,
        "temperature": 0,
        "text": " And in a moment, I'll just open up that file and look at it.",
        "tokens": [
          50920,
          400,
          294,
          257,
          1623,
          11,
          286,
          603,
          445,
          1269,
          493,
          300,
          3991,
          293,
          574,
          412,
          309,
          13,
          51046
        ]
      },
      {
        "avg_logprob": -0.24061254027542794,
        "compression_ratio": 1.8241379310344827,
        "end": 3041.2400000000002,
        "id": 884,
        "no_speech_prob": 0.000058291159803047776,
        "seek": 302540,
        "start": 3039.04,
        "temperature": 0,
        "text": " Model.weights is an interesting thing.",
        "tokens": [
          51046,
          17105,
          13,
          826,
          5761,
          307,
          364,
          1880,
          551,
          13,
          51156
        ]
      },
      {
        "avg_logprob": -0.24061254027542794,
        "compression_ratio": 1.8241379310344827,
        "end": 3043.08,
        "id": 885,
        "no_speech_prob": 0.000058291159803047776,
        "seek": 302540,
        "start": 3041.2400000000002,
        "temperature": 0,
        "text": " So the magic of a neural network, what",
        "tokens": [
          51156,
          407,
          264,
          5585,
          295,
          257,
          18161,
          3209,
          11,
          437,
          51248
        ]
      },
      {
        "avg_logprob": -0.24061254027542794,
        "compression_ratio": 1.8241379310344827,
        "end": 3045.64,
        "id": 886,
        "no_speech_prob": 0.000058291159803047776,
        "seek": 302540,
        "start": 3043.08,
        "temperature": 0,
        "text": " makes a neural network work, is a number",
        "tokens": [
          51248,
          1669,
          257,
          18161,
          3209,
          589,
          11,
          307,
          257,
          1230,
          51376
        ]
      },
      {
        "avg_logprob": -0.24061254027542794,
        "compression_ratio": 1.8241379310344827,
        "end": 3048.1800000000003,
        "id": 887,
        "no_speech_prob": 0.000058291159803047776,
        "seek": 302540,
        "start": 3045.64,
        "temperature": 0,
        "text": " that's associated with every single one of these connections",
        "tokens": [
          51376,
          300,
          311,
          6615,
          365,
          633,
          2167,
          472,
          295,
          613,
          9271,
          51503
        ]
      },
      {
        "avg_logprob": -0.24061254027542794,
        "compression_ratio": 1.8241379310344827,
        "end": 3048.88,
        "id": 888,
        "no_speech_prob": 0.000058291159803047776,
        "seek": 302540,
        "start": 3048.1800000000003,
        "temperature": 0,
        "text": " known as a weight.",
        "tokens": [
          51503,
          2570,
          382,
          257,
          3364,
          13,
          51538
        ]
      },
      {
        "avg_logprob": -0.24061254027542794,
        "compression_ratio": 1.8241379310344827,
        "end": 3051.44,
        "id": 889,
        "no_speech_prob": 0.000058291159803047776,
        "seek": 302540,
        "start": 3048.88,
        "temperature": 0,
        "text": " You can think of it as a whole bunch of dials.",
        "tokens": [
          51538,
          509,
          393,
          519,
          295,
          309,
          382,
          257,
          1379,
          3840,
          295,
          5502,
          82,
          13,
          51666
        ]
      },
      {
        "avg_logprob": -0.24061254027542794,
        "compression_ratio": 1.8241379310344827,
        "end": 3052.76,
        "id": 890,
        "no_speech_prob": 0.000058291159803047776,
        "seek": 302540,
        "start": 3051.44,
        "temperature": 0,
        "text": " So I'm tuning the dials.",
        "tokens": [
          51666,
          407,
          286,
          478,
          15164,
          264,
          5502,
          82,
          13,
          51732
        ]
      },
      {
        "avg_logprob": -0.24061254027542794,
        "compression_ratio": 1.8241379310344827,
        "end": 3054.8,
        "id": 891,
        "no_speech_prob": 0.000058291159803047776,
        "seek": 302540,
        "start": 3052.76,
        "temperature": 0,
        "text": " I'm trying to get the dials in the right position",
        "tokens": [
          51732,
          286,
          478,
          1382,
          281,
          483,
          264,
          5502,
          82,
          294,
          264,
          558,
          2535,
          51834
        ]
      },
      {
        "avg_logprob": -0.25217907428741454,
        "compression_ratio": 1.8409785932721712,
        "end": 3057.6000000000004,
        "id": 892,
        "no_speech_prob": 0.00004469396662898362,
        "seek": 305480,
        "start": 3054.92,
        "temperature": 0,
        "text": " really makes good guesses about happy versus sad.",
        "tokens": [
          50370,
          534,
          1669,
          665,
          42703,
          466,
          2055,
          5717,
          4227,
          13,
          50504
        ]
      },
      {
        "avg_logprob": -0.25217907428741454,
        "compression_ratio": 1.8409785932721712,
        "end": 3059.1200000000003,
        "id": 893,
        "no_speech_prob": 0.00004469396662898362,
        "seek": 305480,
        "start": 3057.6000000000004,
        "temperature": 0,
        "text": " That's the training process.",
        "tokens": [
          50504,
          663,
          311,
          264,
          3097,
          1399,
          13,
          50580
        ]
      },
      {
        "avg_logprob": -0.25217907428741454,
        "compression_ratio": 1.8409785932721712,
        "end": 3060.6800000000003,
        "id": 894,
        "no_speech_prob": 0.00004469396662898362,
        "seek": 305480,
        "start": 3059.1200000000003,
        "temperature": 0,
        "text": " Once that training process is done,",
        "tokens": [
          50580,
          3443,
          300,
          3097,
          1399,
          307,
          1096,
          11,
          50658
        ]
      },
      {
        "avg_logprob": -0.25217907428741454,
        "compression_ratio": 1.8409785932721712,
        "end": 3062.7200000000003,
        "id": 895,
        "no_speech_prob": 0.00004469396662898362,
        "seek": 305480,
        "start": 3060.6800000000003,
        "temperature": 0,
        "text": " I want to save where all those dials are.",
        "tokens": [
          50658,
          286,
          528,
          281,
          3155,
          689,
          439,
          729,
          5502,
          82,
          366,
          13,
          50760
        ]
      },
      {
        "avg_logprob": -0.25217907428741454,
        "compression_ratio": 1.8409785932721712,
        "end": 3064.6000000000004,
        "id": 896,
        "no_speech_prob": 0.00004469396662898362,
        "seek": 305480,
        "start": 3062.7200000000003,
        "temperature": 0,
        "text": " All of those numbers are in this file.",
        "tokens": [
          50760,
          1057,
          295,
          729,
          3547,
          366,
          294,
          341,
          3991,
          13,
          50854
        ]
      },
      {
        "avg_logprob": -0.25217907428741454,
        "compression_ratio": 1.8409785932721712,
        "end": 3066.6400000000003,
        "id": 897,
        "no_speech_prob": 0.00004469396662898362,
        "seek": 305480,
        "start": 3064.6000000000004,
        "temperature": 0,
        "text": " This is a binary format file because there's",
        "tokens": [
          50854,
          639,
          307,
          257,
          17434,
          7877,
          3991,
          570,
          456,
          311,
          50956
        ]
      },
      {
        "avg_logprob": -0.25217907428741454,
        "compression_ratio": 1.8409785932721712,
        "end": 3069.48,
        "id": 898,
        "no_speech_prob": 0.00004469396662898362,
        "seek": 305480,
        "start": 3066.6400000000003,
        "temperature": 0,
        "text": " a lot of numbers, millions upon millions of connections",
        "tokens": [
          50956,
          257,
          688,
          295,
          3547,
          11,
          6803,
          3564,
          6803,
          295,
          9271,
          51098
        ]
      },
      {
        "avg_logprob": -0.25217907428741454,
        "compression_ratio": 1.8409785932721712,
        "end": 3072.1600000000003,
        "id": 899,
        "no_speech_prob": 0.00004469396662898362,
        "seek": 305480,
        "start": 3069.48,
        "temperature": 0,
        "text": " potentially between a lot of pixels and a lot of labels",
        "tokens": [
          51098,
          7263,
          1296,
          257,
          688,
          295,
          18668,
          293,
          257,
          688,
          295,
          16949,
          51232
        ]
      },
      {
        "avg_logprob": -0.25217907428741454,
        "compression_ratio": 1.8409785932721712,
        "end": 3073.36,
        "id": 900,
        "no_speech_prob": 0.00004469396662898362,
        "seek": 305480,
        "start": 3072.1600000000003,
        "temperature": 0,
        "text": " and a lot of hidden layers.",
        "tokens": [
          51232,
          293,
          257,
          688,
          295,
          7633,
          7914,
          13,
          51292
        ]
      },
      {
        "avg_logprob": -0.25217907428741454,
        "compression_ratio": 1.8409785932721712,
        "end": 3075.4,
        "id": 901,
        "no_speech_prob": 0.00004469396662898362,
        "seek": 305480,
        "start": 3073.36,
        "temperature": 0,
        "text": " So this, you'll notice, the file that we saved",
        "tokens": [
          51292,
          407,
          341,
          11,
          291,
          603,
          3449,
          11,
          264,
          3991,
          300,
          321,
          6624,
          51394
        ]
      },
      {
        "avg_logprob": -0.25217907428741454,
        "compression_ratio": 1.8409785932721712,
        "end": 3078.0800000000004,
        "id": 902,
        "no_speech_prob": 0.00004469396662898362,
        "seek": 305480,
        "start": 3075.4,
        "temperature": 0,
        "text": " is five megabytes because it's tons and tons of numbers.",
        "tokens": [
          51394,
          307,
          1732,
          10816,
          24538,
          570,
          309,
          311,
          9131,
          293,
          9131,
          295,
          3547,
          13,
          51528
        ]
      },
      {
        "avg_logprob": -0.25217907428741454,
        "compression_ratio": 1.8409785932721712,
        "end": 3080.84,
        "id": 903,
        "no_speech_prob": 0.00004469396662898362,
        "seek": 305480,
        "start": 3078.0800000000004,
        "temperature": 0,
        "text": " So it ends up, but this is just a very small file",
        "tokens": [
          51528,
          407,
          309,
          5314,
          493,
          11,
          457,
          341,
          307,
          445,
          257,
          588,
          1359,
          3991,
          51666
        ]
      },
      {
        "avg_logprob": -0.25217907428741454,
        "compression_ratio": 1.8409785932721712,
        "end": 3082.4,
        "id": 904,
        "no_speech_prob": 0.00004469396662898362,
        "seek": 305480,
        "start": 3080.84,
        "temperature": 0,
        "text": " with a little bit of text information",
        "tokens": [
          51666,
          365,
          257,
          707,
          857,
          295,
          2487,
          1589,
          51744
        ]
      },
      {
        "avg_logprob": -0.25217907428741454,
        "compression_ratio": 1.8409785932721712,
        "end": 3083.76,
        "id": 905,
        "no_speech_prob": 0.00004469396662898362,
        "seek": 305480,
        "start": 3082.4,
        "temperature": 0,
        "text": " about how this is configured.",
        "tokens": [
          51744,
          466,
          577,
          341,
          307,
          30538,
          13,
          51812
        ]
      },
      {
        "avg_logprob": -0.2629060533311632,
        "compression_ratio": 1.7560240963855422,
        "end": 3085.1600000000003,
        "id": 906,
        "no_speech_prob": 0.0002737173927016556,
        "seek": 308376,
        "start": 3083.76,
        "temperature": 0,
        "text": " I spent a lot of time on that.",
        "tokens": [
          50364,
          286,
          4418,
          257,
          688,
          295,
          565,
          322,
          300,
          13,
          50434
        ]
      },
      {
        "avg_logprob": -0.2629060533311632,
        "compression_ratio": 1.7560240963855422,
        "end": 3087.2000000000003,
        "id": 907,
        "no_speech_prob": 0.0002737173927016556,
        "seek": 308376,
        "start": 3085.1600000000003,
        "temperature": 0,
        "text": " Hopefully, that's some helpful background to you.",
        "tokens": [
          50434,
          10429,
          11,
          300,
          311,
          512,
          4961,
          3678,
          281,
          291,
          13,
          50536
        ]
      },
      {
        "avg_logprob": -0.2629060533311632,
        "compression_ratio": 1.7560240963855422,
        "end": 3090,
        "id": 908,
        "no_speech_prob": 0.0002737173927016556,
        "seek": 308376,
        "start": 3087.2000000000003,
        "temperature": 0,
        "text": " Let's go back and actually look at those files.",
        "tokens": [
          50536,
          961,
          311,
          352,
          646,
          293,
          767,
          574,
          412,
          729,
          7098,
          13,
          50676
        ]
      },
      {
        "avg_logprob": -0.2629060533311632,
        "compression_ratio": 1.7560240963855422,
        "end": 3091.6400000000003,
        "id": 909,
        "no_speech_prob": 0.0002737173927016556,
        "seek": 308376,
        "start": 3090,
        "temperature": 0,
        "text": " So now, I've got those files.",
        "tokens": [
          50676,
          407,
          586,
          11,
          286,
          600,
          658,
          729,
          7098,
          13,
          50758
        ]
      },
      {
        "avg_logprob": -0.2629060533311632,
        "compression_ratio": 1.7560240963855422,
        "end": 3093.8,
        "id": 910,
        "no_speech_prob": 0.0002737173927016556,
        "seek": 308376,
        "start": 3091.6400000000003,
        "temperature": 0,
        "text": " What I'm going to do is I'm just going to drag them",
        "tokens": [
          50758,
          708,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          445,
          516,
          281,
          5286,
          552,
          50866
        ]
      },
      {
        "avg_logprob": -0.2629060533311632,
        "compression_ratio": 1.7560240963855422,
        "end": 3096.1200000000003,
        "id": 911,
        "no_speech_prob": 0.0002737173927016556,
        "seek": 308376,
        "start": 3093.8,
        "temperature": 0,
        "text": " into Visual Studio Code, which is what I'm",
        "tokens": [
          50866,
          666,
          23187,
          13500,
          15549,
          11,
          597,
          307,
          437,
          286,
          478,
          50982
        ]
      },
      {
        "avg_logprob": -0.2629060533311632,
        "compression_ratio": 1.7560240963855422,
        "end": 3098.0800000000004,
        "id": 912,
        "no_speech_prob": 0.0002737173927016556,
        "seek": 308376,
        "start": 3096.1200000000003,
        "temperature": 0,
        "text": " using to code this right now.",
        "tokens": [
          50982,
          1228,
          281,
          3089,
          341,
          558,
          586,
          13,
          51080
        ]
      },
      {
        "avg_logprob": -0.2629060533311632,
        "compression_ratio": 1.7560240963855422,
        "end": 3100.1200000000003,
        "id": 913,
        "no_speech_prob": 0.0002737173927016556,
        "seek": 308376,
        "start": 3098.0800000000004,
        "temperature": 0,
        "text": " But you could be using any environment.",
        "tokens": [
          51080,
          583,
          291,
          727,
          312,
          1228,
          604,
          2823,
          13,
          51182
        ]
      },
      {
        "avg_logprob": -0.2629060533311632,
        "compression_ratio": 1.7560240963855422,
        "end": 3102.6000000000004,
        "id": 914,
        "no_speech_prob": 0.0002737173927016556,
        "seek": 308376,
        "start": 3100.1200000000003,
        "temperature": 0,
        "text": " Oops, they didn't make it into the right place.",
        "tokens": [
          51182,
          21726,
          11,
          436,
          994,
          380,
          652,
          309,
          666,
          264,
          558,
          1081,
          13,
          51306
        ]
      },
      {
        "avg_logprob": -0.2629060533311632,
        "compression_ratio": 1.7560240963855422,
        "end": 3103.6800000000003,
        "id": 915,
        "no_speech_prob": 0.0002737173927016556,
        "seek": 308376,
        "start": 3102.6000000000004,
        "temperature": 0,
        "text": " Let me try that again.",
        "tokens": [
          51306,
          961,
          385,
          853,
          300,
          797,
          13,
          51360
        ]
      },
      {
        "avg_logprob": -0.2629060533311632,
        "compression_ratio": 1.7560240963855422,
        "end": 3105.88,
        "id": 916,
        "no_speech_prob": 0.0002737173927016556,
        "seek": 308376,
        "start": 3103.6800000000003,
        "temperature": 0,
        "text": " I'll clean this up later, but I want them in this directory.",
        "tokens": [
          51360,
          286,
          603,
          2541,
          341,
          493,
          1780,
          11,
          457,
          286,
          528,
          552,
          294,
          341,
          21120,
          13,
          51470
        ]
      },
      {
        "avg_logprob": -0.2629060533311632,
        "compression_ratio": 1.7560240963855422,
        "end": 3106.28,
        "id": 917,
        "no_speech_prob": 0.0002737173927016556,
        "seek": 308376,
        "start": 3105.88,
        "temperature": 0,
        "text": " Great.",
        "tokens": [
          51470,
          3769,
          13,
          51490
        ]
      },
      {
        "avg_logprob": -0.2629060533311632,
        "compression_ratio": 1.7560240963855422,
        "end": 3107.6400000000003,
        "id": 918,
        "no_speech_prob": 0.0002737173927016556,
        "seek": 308376,
        "start": 3106.28,
        "temperature": 0,
        "text": " So you can see that they're there,",
        "tokens": [
          51490,
          407,
          291,
          393,
          536,
          300,
          436,
          434,
          456,
          11,
          51558
        ]
      },
      {
        "avg_logprob": -0.2629060533311632,
        "compression_ratio": 1.7560240963855422,
        "end": 3109.88,
        "id": 919,
        "no_speech_prob": 0.0002737173927016556,
        "seek": 308376,
        "start": 3107.6400000000003,
        "temperature": 0,
        "text": " model.json, model.weights.bin.",
        "tokens": [
          51558,
          2316,
          13,
          73,
          3015,
          11,
          2316,
          13,
          826,
          5761,
          13,
          13496,
          13,
          51670
        ]
      },
      {
        "avg_logprob": -0.2629060533311632,
        "compression_ratio": 1.7560240963855422,
        "end": 3113.6400000000003,
        "id": 920,
        "no_speech_prob": 0.0002737173927016556,
        "seek": 308376,
        "start": 3109.88,
        "temperature": 0,
        "text": " If I click on this, you can see you could start to see",
        "tokens": [
          51670,
          759,
          286,
          2052,
          322,
          341,
          11,
          291,
          393,
          536,
          291,
          727,
          722,
          281,
          536,
          51858
        ]
      },
      {
        "avg_logprob": -0.28403124809265134,
        "compression_ratio": 1.7469512195121952,
        "end": 3114.48,
        "id": 921,
        "no_speech_prob": 0.0001660379784880206,
        "seek": 311364,
        "start": 3113.64,
        "temperature": 0,
        "text": " all the stuff in it.",
        "tokens": [
          50364,
          439,
          264,
          1507,
          294,
          309,
          13,
          50406
        ]
      },
      {
        "avg_logprob": -0.28403124809265134,
        "compression_ratio": 1.7469512195121952,
        "end": 3116.7999999999997,
        "id": 922,
        "no_speech_prob": 0.0001660379784880206,
        "seek": 311364,
        "start": 3114.48,
        "temperature": 0,
        "text": " There's information about the input shape,",
        "tokens": [
          50406,
          821,
          311,
          1589,
          466,
          264,
          4846,
          3909,
          11,
          50522
        ]
      },
      {
        "avg_logprob": -0.28403124809265134,
        "compression_ratio": 1.7469512195121952,
        "end": 3120.68,
        "id": 923,
        "no_speech_prob": 0.0001660379784880206,
        "seek": 311364,
        "start": 3116.7999999999997,
        "temperature": 0,
        "text": " and is it a sequential model, and what kind of algorithm",
        "tokens": [
          50522,
          293,
          307,
          309,
          257,
          42881,
          2316,
          11,
          293,
          437,
          733,
          295,
          9284,
          50716
        ]
      },
      {
        "avg_logprob": -0.28403124809265134,
        "compression_ratio": 1.7469512195121952,
        "end": 3122.52,
        "id": 924,
        "no_speech_prob": 0.0001660379784880206,
        "seek": 311364,
        "start": 3120.68,
        "temperature": 0,
        "text": " are you using, and oh, is it dense,",
        "tokens": [
          50716,
          366,
          291,
          1228,
          11,
          293,
          1954,
          11,
          307,
          309,
          18011,
          11,
          50808
        ]
      },
      {
        "avg_logprob": -0.28403124809265134,
        "compression_ratio": 1.7469512195121952,
        "end": 3124.72,
        "id": 925,
        "no_speech_prob": 0.0001660379784880206,
        "seek": 311364,
        "start": 3122.52,
        "temperature": 0,
        "text": " and it uses something called softmat, all this stuff.",
        "tokens": [
          50808,
          293,
          309,
          4960,
          746,
          1219,
          2787,
          15677,
          11,
          439,
          341,
          1507,
          13,
          50918
        ]
      },
      {
        "avg_logprob": -0.28403124809265134,
        "compression_ratio": 1.7469512195121952,
        "end": 3127,
        "id": 926,
        "no_speech_prob": 0.0001660379784880206,
        "seek": 311364,
        "start": 3124.72,
        "temperature": 0,
        "text": " So this is way beyond the scope of what",
        "tokens": [
          50918,
          407,
          341,
          307,
          636,
          4399,
          264,
          11923,
          295,
          437,
          51032
        ]
      },
      {
        "avg_logprob": -0.28403124809265134,
        "compression_ratio": 1.7469512195121952,
        "end": 3128.16,
        "id": 927,
        "no_speech_prob": 0.0001660379784880206,
        "seek": 311364,
        "start": 3127,
        "temperature": 0,
        "text": " I'm doing in these videos.",
        "tokens": [
          51032,
          286,
          478,
          884,
          294,
          613,
          2145,
          13,
          51090
        ]
      },
      {
        "avg_logprob": -0.28403124809265134,
        "compression_ratio": 1.7469512195121952,
        "end": 3130.68,
        "id": 928,
        "no_speech_prob": 0.0001660379784880206,
        "seek": 311364,
        "start": 3128.16,
        "temperature": 0,
        "text": " But if you're interested in more about these details,",
        "tokens": [
          51090,
          583,
          498,
          291,
          434,
          3102,
          294,
          544,
          466,
          613,
          4365,
          11,
          51216
        ]
      },
      {
        "avg_logprob": -0.28403124809265134,
        "compression_ratio": 1.7469512195121952,
        "end": 3132.16,
        "id": 929,
        "no_speech_prob": 0.0001660379784880206,
        "seek": 311364,
        "start": 3130.68,
        "temperature": 0,
        "text": " you could look at some of my videos",
        "tokens": [
          51216,
          291,
          727,
          574,
          412,
          512,
          295,
          452,
          2145,
          51290
        ]
      },
      {
        "avg_logprob": -0.28403124809265134,
        "compression_ratio": 1.7469512195121952,
        "end": 3135.2799999999997,
        "id": 930,
        "no_speech_prob": 0.0001660379784880206,
        "seek": 311364,
        "start": 3132.16,
        "temperature": 0,
        "text": " that use TensorFlow.js natively to understand more pieces here.",
        "tokens": [
          51290,
          300,
          764,
          37624,
          13,
          25530,
          8470,
          356,
          281,
          1223,
          544,
          3755,
          510,
          13,
          51446
        ]
      },
      {
        "avg_logprob": -0.28403124809265134,
        "compression_ratio": 1.7469512195121952,
        "end": 3137.7599999999998,
        "id": 931,
        "no_speech_prob": 0.0001660379784880206,
        "seek": 311364,
        "start": 3135.2799999999997,
        "temperature": 0,
        "text": " But you can see here, this is where",
        "tokens": [
          51446,
          583,
          291,
          393,
          536,
          510,
          11,
          341,
          307,
          689,
          51570
        ]
      },
      {
        "avg_logprob": -0.28403124809265134,
        "compression_ratio": 1.7469512195121952,
        "end": 3140.16,
        "id": 932,
        "no_speech_prob": 0.0001660379784880206,
        "seek": 311364,
        "start": 3137.7599999999998,
        "temperature": 0,
        "text": " it's looking for the weights file, et cetera, et cetera.",
        "tokens": [
          51570,
          309,
          311,
          1237,
          337,
          264,
          17443,
          3991,
          11,
          1030,
          11458,
          11,
          1030,
          11458,
          13,
          51690
        ]
      },
      {
        "avg_logprob": -0.28403124809265134,
        "compression_ratio": 1.7469512195121952,
        "end": 3141.48,
        "id": 933,
        "no_speech_prob": 0.0001660379784880206,
        "seek": 311364,
        "start": 3140.16,
        "temperature": 0,
        "text": " And this is really important.",
        "tokens": [
          51690,
          400,
          341,
          307,
          534,
          1021,
          13,
          51756
        ]
      },
      {
        "avg_logprob": -0.28403124809265134,
        "compression_ratio": 1.7469512195121952,
        "end": 3142.2,
        "id": 934,
        "no_speech_prob": 0.0001660379784880206,
        "seek": 311364,
        "start": 3141.48,
        "temperature": 0,
        "text": " This is something.",
        "tokens": [
          51756,
          639,
          307,
          746,
          13,
          51792
        ]
      },
      {
        "avg_logprob": -0.23804506113831425,
        "compression_ratio": 1.6559139784946237,
        "end": 3145.7599999999998,
        "id": 935,
        "no_speech_prob": 0.00005562202932196669,
        "seek": 314220,
        "start": 3142.2,
        "temperature": 0,
        "text": " This is really just what TensorFlow.js would do",
        "tokens": [
          50364,
          639,
          307,
          534,
          445,
          437,
          37624,
          13,
          25530,
          576,
          360,
          50542
        ]
      },
      {
        "avg_logprob": -0.23804506113831425,
        "compression_ratio": 1.6559139784946237,
        "end": 3149.52,
        "id": 936,
        "no_speech_prob": 0.00005562202932196669,
        "seek": 314220,
        "start": 3145.7599999999998,
        "temperature": 0,
        "text": " natively, but ML5 is helping with a little bit on top of it",
        "tokens": [
          50542,
          8470,
          356,
          11,
          457,
          21601,
          20,
          307,
          4315,
          365,
          257,
          707,
          857,
          322,
          1192,
          295,
          309,
          50730
        ]
      },
      {
        "avg_logprob": -0.23804506113831425,
        "compression_ratio": 1.6559139784946237,
        "end": 3151.4399999999996,
        "id": 937,
        "no_speech_prob": 0.00005562202932196669,
        "seek": 314220,
        "start": 3149.52,
        "temperature": 0,
        "text": " by adding these happy and sad labels.",
        "tokens": [
          50730,
          538,
          5127,
          613,
          2055,
          293,
          4227,
          16949,
          13,
          50826
        ]
      },
      {
        "avg_logprob": -0.23804506113831425,
        "compression_ratio": 1.6559139784946237,
        "end": 3153,
        "id": 938,
        "no_speech_prob": 0.00005562202932196669,
        "seek": 314220,
        "start": 3151.4399999999996,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50826,
          2264,
          13,
          50904
        ]
      },
      {
        "avg_logprob": -0.23804506113831425,
        "compression_ratio": 1.6559139784946237,
        "end": 3156.04,
        "id": 939,
        "no_speech_prob": 0.00005562202932196669,
        "seek": 314220,
        "start": 3153,
        "temperature": 0,
        "text": " So now, all we have to do is load the model now.",
        "tokens": [
          50904,
          407,
          586,
          11,
          439,
          321,
          362,
          281,
          360,
          307,
          3677,
          264,
          2316,
          586,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.23804506113831425,
        "compression_ratio": 1.6559139784946237,
        "end": 3157.16,
        "id": 940,
        "no_speech_prob": 0.00005562202932196669,
        "seek": 314220,
        "start": 3156.04,
        "temperature": 0,
        "text": " OK, so we're going to go.",
        "tokens": [
          51056,
          2264,
          11,
          370,
          321,
          434,
          516,
          281,
          352,
          13,
          51112
        ]
      },
      {
        "avg_logprob": -0.23804506113831425,
        "compression_ratio": 1.6559139784946237,
        "end": 3158.52,
        "id": 941,
        "no_speech_prob": 0.00005562202932196669,
        "seek": 314220,
        "start": 3157.16,
        "temperature": 0,
        "text": " We saved that model.",
        "tokens": [
          51112,
          492,
          6624,
          300,
          2316,
          13,
          51180
        ]
      },
      {
        "avg_logprob": -0.23804506113831425,
        "compression_ratio": 1.6559139784946237,
        "end": 3161.64,
        "id": 942,
        "no_speech_prob": 0.00005562202932196669,
        "seek": 314220,
        "start": 3158.52,
        "temperature": 0,
        "text": " And so the steps are, the first thing we have to do",
        "tokens": [
          51180,
          400,
          370,
          264,
          4439,
          366,
          11,
          264,
          700,
          551,
          321,
          362,
          281,
          360,
          51336
        ]
      },
      {
        "avg_logprob": -0.23804506113831425,
        "compression_ratio": 1.6559139784946237,
        "end": 3163.8799999999997,
        "id": 943,
        "no_speech_prob": 0.00005562202932196669,
        "seek": 314220,
        "start": 3161.64,
        "temperature": 0,
        "text": " is load the MobileNet model.",
        "tokens": [
          51336,
          307,
          3677,
          264,
          22625,
          31890,
          2316,
          13,
          51448
        ]
      },
      {
        "avg_logprob": -0.23804506113831425,
        "compression_ratio": 1.6559139784946237,
        "end": 3166.52,
        "id": 944,
        "no_speech_prob": 0.00005562202932196669,
        "seek": 314220,
        "start": 3163.8799999999997,
        "temperature": 0,
        "text": " So we're not actually saving that original pre-trained image",
        "tokens": [
          51448,
          407,
          321,
          434,
          406,
          767,
          6816,
          300,
          3380,
          659,
          12,
          17227,
          2001,
          3256,
          51580
        ]
      },
      {
        "avg_logprob": -0.23804506113831425,
        "compression_ratio": 1.6559139784946237,
        "end": 3167.7,
        "id": 945,
        "no_speech_prob": 0.00005562202932196669,
        "seek": 314220,
        "start": 3166.52,
        "temperature": 0,
        "text": " classifier.",
        "tokens": [
          51580,
          1508,
          9902,
          13,
          51639
        ]
      },
      {
        "avg_logprob": -0.23804506113831425,
        "compression_ratio": 1.6559139784946237,
        "end": 3169.4399999999996,
        "id": 946,
        "no_speech_prob": 0.00005562202932196669,
        "seek": 314220,
        "start": 3167.7,
        "temperature": 0,
        "text": " We're just saving the bits and pieces",
        "tokens": [
          51639,
          492,
          434,
          445,
          6816,
          264,
          9239,
          293,
          3755,
          51726
        ]
      },
      {
        "avg_logprob": -0.23804506113831425,
        "compression_ratio": 1.6559139784946237,
        "end": 3171.4399999999996,
        "id": 947,
        "no_speech_prob": 0.00005562202932196669,
        "seek": 314220,
        "start": 3169.4399999999996,
        "temperature": 0,
        "text": " that are hooked into it.",
        "tokens": [
          51726,
          300,
          366,
          20410,
          666,
          309,
          13,
          51826
        ]
      },
      {
        "avg_logprob": -0.22085656410406443,
        "compression_ratio": 1.6570247933884297,
        "end": 3174.96,
        "id": 948,
        "no_speech_prob": 0.000012606847121787723,
        "seek": 317144,
        "start": 3171.44,
        "temperature": 0,
        "text": " So we can't hook into it until MobileNet is ready.",
        "tokens": [
          50364,
          407,
          321,
          393,
          380,
          6328,
          666,
          309,
          1826,
          22625,
          31890,
          307,
          1919,
          13,
          50540
        ]
      },
      {
        "avg_logprob": -0.22085656410406443,
        "compression_ratio": 1.6570247933884297,
        "end": 3178.4,
        "id": 949,
        "no_speech_prob": 0.000012606847121787723,
        "seek": 317144,
        "start": 3174.96,
        "temperature": 0,
        "text": " So once we've hooked into it, once MobileNet is ready,",
        "tokens": [
          50540,
          407,
          1564,
          321,
          600,
          20410,
          666,
          309,
          11,
          1564,
          22625,
          31890,
          307,
          1919,
          11,
          50712
        ]
      },
      {
        "avg_logprob": -0.22085656410406443,
        "compression_ratio": 1.6570247933884297,
        "end": 3184.2400000000002,
        "id": 950,
        "no_speech_prob": 0.000012606847121787723,
        "seek": 317144,
        "start": 3178.4,
        "temperature": 0,
        "text": " we can then say classifier.load model.json.",
        "tokens": [
          50712,
          321,
          393,
          550,
          584,
          1508,
          9902,
          13,
          2907,
          2316,
          13,
          73,
          3015,
          13,
          51004
        ]
      },
      {
        "avg_logprob": -0.22085656410406443,
        "compression_ratio": 1.6570247933884297,
        "end": 3188.44,
        "id": 951,
        "no_speech_prob": 0.000012606847121787723,
        "seek": 317144,
        "start": 3184.2400000000002,
        "temperature": 0,
        "text": " Now, there are two files, model.json and model.weights.bin.",
        "tokens": [
          51004,
          823,
          11,
          456,
          366,
          732,
          7098,
          11,
          2316,
          13,
          73,
          3015,
          293,
          2316,
          13,
          826,
          5761,
          13,
          13496,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.22085656410406443,
        "compression_ratio": 1.6570247933884297,
        "end": 3192.84,
        "id": 952,
        "no_speech_prob": 0.000012606847121787723,
        "seek": 317144,
        "start": 3188.44,
        "temperature": 0,
        "text": " But ML5 has set up that if you just give it one file,",
        "tokens": [
          51214,
          583,
          21601,
          20,
          575,
          992,
          493,
          300,
          498,
          291,
          445,
          976,
          309,
          472,
          3991,
          11,
          51434
        ]
      },
      {
        "avg_logprob": -0.22085656410406443,
        "compression_ratio": 1.6570247933884297,
        "end": 3195.84,
        "id": 953,
        "no_speech_prob": 0.000012606847121787723,
        "seek": 317144,
        "start": 3192.84,
        "temperature": 0,
        "text": " it'll look automatically for the other file in the same place.",
        "tokens": [
          51434,
          309,
          603,
          574,
          6772,
          337,
          264,
          661,
          3991,
          294,
          264,
          912,
          1081,
          13,
          51584
        ]
      },
      {
        "avg_logprob": -0.22085656410406443,
        "compression_ratio": 1.6570247933884297,
        "end": 3197.84,
        "id": 954,
        "no_speech_prob": 0.000012606847121787723,
        "seek": 317144,
        "start": 3195.84,
        "temperature": 0,
        "text": " There are ways of customizing the file names",
        "tokens": [
          51584,
          821,
          366,
          2098,
          295,
          2375,
          3319,
          264,
          3991,
          5288,
          51684
        ]
      },
      {
        "avg_logprob": -0.22085656410406443,
        "compression_ratio": 1.6570247933884297,
        "end": 3199.08,
        "id": 955,
        "no_speech_prob": 0.000012606847121787723,
        "seek": 317144,
        "start": 3197.84,
        "temperature": 0,
        "text": " and their paths and all that.",
        "tokens": [
          51684,
          293,
          641,
          14518,
          293,
          439,
          300,
          13,
          51746
        ]
      },
      {
        "avg_logprob": -0.2617589347382896,
        "compression_ratio": 1.8341232227488151,
        "end": 3201.7999999999997,
        "id": 956,
        "no_speech_prob": 0.0000080134705058299,
        "seek": 319908,
        "start": 3199.7999999999997,
        "temperature": 0,
        "text": " That you can look into in the documentation.",
        "tokens": [
          50400,
          663,
          291,
          393,
          574,
          666,
          294,
          264,
          14333,
          13,
          50500
        ]
      },
      {
        "avg_logprob": -0.2617589347382896,
        "compression_ratio": 1.8341232227488151,
        "end": 3203.64,
        "id": 957,
        "no_speech_prob": 0.0000080134705058299,
        "seek": 319908,
        "start": 3201.7999999999997,
        "temperature": 0,
        "text": " But the easiest thing for just to do this.",
        "tokens": [
          50500,
          583,
          264,
          12889,
          551,
          337,
          445,
          281,
          360,
          341,
          13,
          50592
        ]
      },
      {
        "avg_logprob": -0.2617589347382896,
        "compression_ratio": 1.8341232227488151,
        "end": 3206.88,
        "id": 958,
        "no_speech_prob": 0.0000080134705058299,
        "seek": 319908,
        "start": 3203.64,
        "temperature": 0,
        "text": " And then I'm going to say custom model ready.",
        "tokens": [
          50592,
          400,
          550,
          286,
          478,
          516,
          281,
          584,
          2375,
          2316,
          1919,
          13,
          50754
        ]
      },
      {
        "avg_logprob": -0.2617589347382896,
        "compression_ratio": 1.8341232227488151,
        "end": 3210.52,
        "id": 959,
        "no_speech_prob": 0.0000080134705058299,
        "seek": 319908,
        "start": 3206.88,
        "temperature": 0,
        "text": " So I'm going to write another event function.",
        "tokens": [
          50754,
          407,
          286,
          478,
          516,
          281,
          2464,
          1071,
          2280,
          2445,
          13,
          50936
        ]
      },
      {
        "avg_logprob": -0.2617589347382896,
        "compression_ratio": 1.8341232227488151,
        "end": 3212.64,
        "id": 960,
        "no_speech_prob": 0.0000080134705058299,
        "seek": 319908,
        "start": 3210.52,
        "temperature": 0,
        "text": " Custom model ready.",
        "tokens": [
          50936,
          16649,
          2316,
          1919,
          13,
          51042
        ]
      },
      {
        "avg_logprob": -0.2617589347382896,
        "compression_ratio": 1.8341232227488151,
        "end": 3217.7999999999997,
        "id": 961,
        "no_speech_prob": 0.0000080134705058299,
        "seek": 319908,
        "start": 3212.64,
        "temperature": 0,
        "text": " And there, I'm going to say custom model is ready.",
        "tokens": [
          51042,
          400,
          456,
          11,
          286,
          478,
          516,
          281,
          584,
          2375,
          2316,
          307,
          1919,
          13,
          51300
        ]
      },
      {
        "avg_logprob": -0.2617589347382896,
        "compression_ratio": 1.8341232227488151,
        "end": 3219.24,
        "id": 962,
        "no_speech_prob": 0.0000080134705058299,
        "seek": 319908,
        "start": 3217.7999999999997,
        "temperature": 0,
        "text": " So it's a two-step process.",
        "tokens": [
          51300,
          407,
          309,
          311,
          257,
          732,
          12,
          16792,
          1399,
          13,
          51372
        ]
      },
      {
        "avg_logprob": -0.2617589347382896,
        "compression_ratio": 1.8341232227488151,
        "end": 3221,
        "id": 963,
        "no_speech_prob": 0.0000080134705058299,
        "seek": 319908,
        "start": 3219.24,
        "temperature": 0,
        "text": " We have to load MobileNet.",
        "tokens": [
          51372,
          492,
          362,
          281,
          3677,
          22625,
          31890,
          13,
          51460
        ]
      },
      {
        "avg_logprob": -0.2617589347382896,
        "compression_ratio": 1.8341232227488151,
        "end": 3222.04,
        "id": 964,
        "no_speech_prob": 0.0000080134705058299,
        "seek": 319908,
        "start": 3221,
        "temperature": 0,
        "text": " MobileNet is ready.",
        "tokens": [
          51460,
          22625,
          31890,
          307,
          1919,
          13,
          51512
        ]
      },
      {
        "avg_logprob": -0.2617589347382896,
        "compression_ratio": 1.8341232227488151,
        "end": 3224.84,
        "id": 965,
        "no_speech_prob": 0.0000080134705058299,
        "seek": 319908,
        "start": 3222.04,
        "temperature": 0,
        "text": " Then load model.json with the weights.",
        "tokens": [
          51512,
          1396,
          3677,
          2316,
          13,
          73,
          3015,
          365,
          264,
          17443,
          13,
          51652
        ]
      },
      {
        "avg_logprob": -0.2617589347382896,
        "compression_ratio": 1.8341232227488151,
        "end": 3226.72,
        "id": 966,
        "no_speech_prob": 0.0000080134705058299,
        "seek": 319908,
        "start": 3224.84,
        "temperature": 0,
        "text": " Custom model is ready.",
        "tokens": [
          51652,
          16649,
          2316,
          307,
          1919,
          13,
          51746
        ]
      },
      {
        "avg_logprob": -0.2466503756863254,
        "compression_ratio": 1.7092198581560283,
        "end": 3229.7999999999997,
        "id": 967,
        "no_speech_prob": 0.00037409394280985,
        "seek": 322672,
        "start": 3226.72,
        "temperature": 0,
        "text": " Let's just run this.",
        "tokens": [
          50364,
          961,
          311,
          445,
          1190,
          341,
          13,
          50518
        ]
      },
      {
        "avg_logprob": -0.2466503756863254,
        "compression_ratio": 1.7092198581560283,
        "end": 3231.8799999999997,
        "id": 968,
        "no_speech_prob": 0.00037409394280985,
        "seek": 322672,
        "start": 3229.7999999999997,
        "temperature": 0,
        "text": " Zoom back out.",
        "tokens": [
          50518,
          13453,
          646,
          484,
          13,
          50622
        ]
      },
      {
        "avg_logprob": -0.2466503756863254,
        "compression_ratio": 1.7092198581560283,
        "end": 3233.3999999999996,
        "id": 969,
        "no_speech_prob": 0.00037409394280985,
        "seek": 322672,
        "start": 3231.8799999999997,
        "temperature": 0,
        "text": " And there we go.",
        "tokens": [
          50622,
          400,
          456,
          321,
          352,
          13,
          50698
        ]
      },
      {
        "avg_logprob": -0.2466503756863254,
        "compression_ratio": 1.7092198581560283,
        "end": 3236.68,
        "id": 970,
        "no_speech_prob": 0.00037409394280985,
        "seek": 322672,
        "start": 3233.3999999999996,
        "temperature": 0,
        "text": " Everything's loaded, but I don't see any results.",
        "tokens": [
          50698,
          5471,
          311,
          13210,
          11,
          457,
          286,
          500,
          380,
          536,
          604,
          3542,
          13,
          50862
        ]
      },
      {
        "avg_logprob": -0.2466503756863254,
        "compression_ratio": 1.7092198581560283,
        "end": 3237.68,
        "id": 971,
        "no_speech_prob": 0.00037409394280985,
        "seek": 322672,
        "start": 3236.68,
        "temperature": 0,
        "text": " I don't see any results.",
        "tokens": [
          50862,
          286,
          500,
          380,
          536,
          604,
          3542,
          13,
          50912
        ]
      },
      {
        "avg_logprob": -0.2466503756863254,
        "compression_ratio": 1.7092198581560283,
        "end": 3238.2,
        "id": 972,
        "no_speech_prob": 0.00037409394280985,
        "seek": 322672,
        "start": 3237.68,
        "temperature": 0,
        "text": " Why?",
        "tokens": [
          50912,
          1545,
          30,
          50938
        ]
      },
      {
        "avg_logprob": -0.2466503756863254,
        "compression_ratio": 1.7092198581560283,
        "end": 3242.56,
        "id": 973,
        "no_speech_prob": 0.00037409394280985,
        "seek": 322672,
        "start": 3238.2,
        "temperature": 0,
        "text": " Well, this sketch was written originally with code to train.",
        "tokens": [
          50938,
          1042,
          11,
          341,
          12325,
          390,
          3720,
          7993,
          365,
          3089,
          281,
          3847,
          13,
          51156
        ]
      },
      {
        "avg_logprob": -0.2466503756863254,
        "compression_ratio": 1.7092198581560283,
        "end": 3244.68,
        "id": 974,
        "no_speech_prob": 0.00037409394280985,
        "seek": 322672,
        "start": 3242.56,
        "temperature": 0,
        "text": " So I'm supposed to press the buttons and hit train.",
        "tokens": [
          51156,
          407,
          286,
          478,
          3442,
          281,
          1886,
          264,
          9905,
          293,
          2045,
          3847,
          13,
          51262
        ]
      },
      {
        "avg_logprob": -0.2466503756863254,
        "compression_ratio": 1.7092198581560283,
        "end": 3247.06,
        "id": 975,
        "no_speech_prob": 0.00037409394280985,
        "seek": 322672,
        "start": 3244.68,
        "temperature": 0,
        "text": " But now I don't need to train because I loaded the model.",
        "tokens": [
          51262,
          583,
          586,
          286,
          500,
          380,
          643,
          281,
          3847,
          570,
          286,
          13210,
          264,
          2316,
          13,
          51381
        ]
      },
      {
        "avg_logprob": -0.2466503756863254,
        "compression_ratio": 1.7092198581560283,
        "end": 3249,
        "id": 976,
        "no_speech_prob": 0.00037409394280985,
        "seek": 322672,
        "start": 3247.06,
        "temperature": 0,
        "text": " So this is where I kind of like, I",
        "tokens": [
          51381,
          407,
          341,
          307,
          689,
          286,
          733,
          295,
          411,
          11,
          286,
          51478
        ]
      },
      {
        "avg_logprob": -0.2466503756863254,
        "compression_ratio": 1.7092198581560283,
        "end": 3250.68,
        "id": 977,
        "no_speech_prob": 0.00037409394280985,
        "seek": 322672,
        "start": 3249,
        "temperature": 0,
        "text": " don't know what you should do next.",
        "tokens": [
          51478,
          500,
          380,
          458,
          437,
          291,
          820,
          360,
          958,
          13,
          51562
        ]
      },
      {
        "avg_logprob": -0.2466503756863254,
        "compression_ratio": 1.7092198581560283,
        "end": 3253.12,
        "id": 978,
        "no_speech_prob": 0.00037409394280985,
        "seek": 322672,
        "start": 3250.68,
        "temperature": 0,
        "text": " Maybe you want to keep two separate web pages,",
        "tokens": [
          51562,
          2704,
          291,
          528,
          281,
          1066,
          732,
          4994,
          3670,
          7183,
          11,
          51684
        ]
      },
      {
        "avg_logprob": -0.2466503756863254,
        "compression_ratio": 1.7092198581560283,
        "end": 3256.16,
        "id": 979,
        "no_speech_prob": 0.00037409394280985,
        "seek": 322672,
        "start": 3253.12,
        "temperature": 0,
        "text": " two separate sketches, one for training and one for loading.",
        "tokens": [
          51684,
          732,
          4994,
          34547,
          11,
          472,
          337,
          3097,
          293,
          472,
          337,
          15114,
          13,
          51836
        ]
      },
      {
        "avg_logprob": -0.21646006447928293,
        "compression_ratio": 1.7097902097902098,
        "end": 3257.64,
        "id": 980,
        "no_speech_prob": 0.00016093031445052475,
        "seek": 325616,
        "start": 3256.16,
        "temperature": 0,
        "text": " Maybe you do it all in one.",
        "tokens": [
          50364,
          2704,
          291,
          360,
          309,
          439,
          294,
          472,
          13,
          50438
        ]
      },
      {
        "avg_logprob": -0.21646006447928293,
        "compression_ratio": 1.7097902097902098,
        "end": 3260.16,
        "id": 981,
        "no_speech_prob": 0.00016093031445052475,
        "seek": 325616,
        "start": 3257.64,
        "temperature": 0,
        "text": " You'll actually see if you go to the ml5 examples,",
        "tokens": [
          50438,
          509,
          603,
          767,
          536,
          498,
          291,
          352,
          281,
          264,
          23271,
          20,
          5110,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.21646006447928293,
        "compression_ratio": 1.7097902097902098,
        "end": 3263.2,
        "id": 982,
        "no_speech_prob": 0.00016093031445052475,
        "seek": 325616,
        "start": 3260.16,
        "temperature": 0,
        "text": " there's one that has a button that you can drag and drop.",
        "tokens": [
          50564,
          456,
          311,
          472,
          300,
          575,
          257,
          2960,
          300,
          291,
          393,
          5286,
          293,
          3270,
          13,
          50716
        ]
      },
      {
        "avg_logprob": -0.21646006447928293,
        "compression_ratio": 1.7097902097902098,
        "end": 3265.64,
        "id": 983,
        "no_speech_prob": 0.00016093031445052475,
        "seek": 325616,
        "start": 3263.2,
        "temperature": 0,
        "text": " You can actually select files and load them and save them",
        "tokens": [
          50716,
          509,
          393,
          767,
          3048,
          7098,
          293,
          3677,
          552,
          293,
          3155,
          552,
          50838
        ]
      },
      {
        "avg_logprob": -0.21646006447928293,
        "compression_ratio": 1.7097902097902098,
        "end": 3266.7599999999998,
        "id": 984,
        "no_speech_prob": 0.00016093031445052475,
        "seek": 325616,
        "start": 3265.64,
        "temperature": 0,
        "text": " all in the same sketch.",
        "tokens": [
          50838,
          439,
          294,
          264,
          912,
          12325,
          13,
          50894
        ]
      },
      {
        "avg_logprob": -0.21646006447928293,
        "compression_ratio": 1.7097902097902098,
        "end": 3269.6,
        "id": 985,
        "no_speech_prob": 0.00016093031445052475,
        "seek": 325616,
        "start": 3266.7599999999998,
        "temperature": 0,
        "text": " But what I want to do now is basically a workflow for,",
        "tokens": [
          50894,
          583,
          437,
          286,
          528,
          281,
          360,
          586,
          307,
          1936,
          257,
          20993,
          337,
          11,
          51036
        ]
      },
      {
        "avg_logprob": -0.21646006447928293,
        "compression_ratio": 1.7097902097902098,
        "end": 3271.52,
        "id": 986,
        "no_speech_prob": 0.00016093031445052475,
        "seek": 325616,
        "start": 3269.6,
        "temperature": 0,
        "text": " I'm done with the training, so I'm not",
        "tokens": [
          51036,
          286,
          478,
          1096,
          365,
          264,
          3097,
          11,
          370,
          286,
          478,
          406,
          51132
        ]
      },
      {
        "avg_logprob": -0.21646006447928293,
        "compression_ratio": 1.7097902097902098,
        "end": 3272.96,
        "id": 987,
        "no_speech_prob": 0.00016093031445052475,
        "seek": 325616,
        "start": 3271.52,
        "temperature": 0,
        "text": " going to ever train again.",
        "tokens": [
          51132,
          516,
          281,
          1562,
          3847,
          797,
          13,
          51204
        ]
      },
      {
        "avg_logprob": -0.21646006447928293,
        "compression_ratio": 1.7097902097902098,
        "end": 3276.04,
        "id": 988,
        "no_speech_prob": 0.00016093031445052475,
        "seek": 325616,
        "start": 3272.96,
        "temperature": 0,
        "text": " So I can actually remove all of these buttons.",
        "tokens": [
          51204,
          407,
          286,
          393,
          767,
          4159,
          439,
          295,
          613,
          9905,
          13,
          51358
        ]
      },
      {
        "avg_logprob": -0.21646006447928293,
        "compression_ratio": 1.7097902097902098,
        "end": 3279.08,
        "id": 989,
        "no_speech_prob": 0.00016093031445052475,
        "seek": 325616,
        "start": 3276.04,
        "temperature": 0,
        "text": " They're no longer relevant to me.",
        "tokens": [
          51358,
          814,
          434,
          572,
          2854,
          7340,
          281,
          385,
          13,
          51510
        ]
      },
      {
        "avg_logprob": -0.21646006447928293,
        "compression_ratio": 1.7097902097902098,
        "end": 3281.66,
        "id": 990,
        "no_speech_prob": 0.00016093031445052475,
        "seek": 325616,
        "start": 3279.08,
        "temperature": 0,
        "text": " The text that should show up at the beginning",
        "tokens": [
          51510,
          440,
          2487,
          300,
          820,
          855,
          493,
          412,
          264,
          2863,
          51639
        ]
      },
      {
        "avg_logprob": -0.21646006447928293,
        "compression_ratio": 1.7097902097902098,
        "end": 3284.96,
        "id": 991,
        "no_speech_prob": 0.00016093031445052475,
        "seek": 325616,
        "start": 3281.66,
        "temperature": 0,
        "text": " is just loading model.",
        "tokens": [
          51639,
          307,
          445,
          15114,
          2316,
          13,
          51804
        ]
      },
      {
        "avg_logprob": -0.23111208747414982,
        "compression_ratio": 1.7794117647058822,
        "end": 3289.4,
        "id": 992,
        "no_speech_prob": 0.000003966980784753105,
        "seek": 328496,
        "start": 3284.96,
        "temperature": 0,
        "text": " And then when the model is ready,",
        "tokens": [
          50364,
          400,
          550,
          562,
          264,
          2316,
          307,
          1919,
          11,
          50586
        ]
      },
      {
        "avg_logprob": -0.23111208747414982,
        "compression_ratio": 1.7794117647058822,
        "end": 3296.2,
        "id": 993,
        "no_speech_prob": 0.000003966980784753105,
        "seek": 328496,
        "start": 3289.4,
        "temperature": 0,
        "text": " I would say label equals model ready.",
        "tokens": [
          50586,
          286,
          576,
          584,
          7645,
          6915,
          2316,
          1919,
          13,
          50926
        ]
      },
      {
        "avg_logprob": -0.23111208747414982,
        "compression_ratio": 1.7794117647058822,
        "end": 3297.92,
        "id": 994,
        "no_speech_prob": 0.000003966980784753105,
        "seek": 328496,
        "start": 3296.2,
        "temperature": 0,
        "text": " So let's run this now.",
        "tokens": [
          50926,
          407,
          718,
          311,
          1190,
          341,
          586,
          13,
          51012
        ]
      },
      {
        "avg_logprob": -0.23111208747414982,
        "compression_ratio": 1.7794117647058822,
        "end": 3300.52,
        "id": 995,
        "no_speech_prob": 0.000003966980784753105,
        "seek": 328496,
        "start": 3297.92,
        "temperature": 0,
        "text": " So loading model, loading model, model ready.",
        "tokens": [
          51012,
          407,
          15114,
          2316,
          11,
          15114,
          2316,
          11,
          2316,
          1919,
          13,
          51142
        ]
      },
      {
        "avg_logprob": -0.23111208747414982,
        "compression_ratio": 1.7794117647058822,
        "end": 3302.8,
        "id": 996,
        "no_speech_prob": 0.000003966980784753105,
        "seek": 328496,
        "start": 3300.52,
        "temperature": 0,
        "text": " And now once the model is ready, all you need to do",
        "tokens": [
          51142,
          400,
          586,
          1564,
          264,
          2316,
          307,
          1919,
          11,
          439,
          291,
          643,
          281,
          360,
          51256
        ]
      },
      {
        "avg_logprob": -0.23111208747414982,
        "compression_ratio": 1.7794117647058822,
        "end": 3303.96,
        "id": 997,
        "no_speech_prob": 0.000003966980784753105,
        "seek": 328496,
        "start": 3302.8,
        "temperature": 0,
        "text": " is start classifying.",
        "tokens": [
          51256,
          307,
          722,
          1508,
          5489,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.23111208747414982,
        "compression_ratio": 1.7794117647058822,
        "end": 3307.92,
        "id": 998,
        "no_speech_prob": 0.000003966980784753105,
        "seek": 328496,
        "start": 3303.96,
        "temperature": 0,
        "text": " And before, I didn't classify until the training",
        "tokens": [
          51314,
          400,
          949,
          11,
          286,
          994,
          380,
          33872,
          1826,
          264,
          3097,
          51512
        ]
      },
      {
        "avg_logprob": -0.23111208747414982,
        "compression_ratio": 1.7794117647058822,
        "end": 3309.32,
        "id": 999,
        "no_speech_prob": 0.000003966980784753105,
        "seek": 328496,
        "start": 3307.92,
        "temperature": 0,
        "text": " was finished.",
        "tokens": [
          51512,
          390,
          4335,
          13,
          51582
        ]
      },
      {
        "avg_logprob": -0.23111208747414982,
        "compression_ratio": 1.7794117647058822,
        "end": 3310.8,
        "id": 1000,
        "no_speech_prob": 0.000003966980784753105,
        "seek": 328496,
        "start": 3309.32,
        "temperature": 0,
        "text": " The training is now irrelevant.",
        "tokens": [
          51582,
          440,
          3097,
          307,
          586,
          28682,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.23111208747414982,
        "compression_ratio": 1.7794117647058822,
        "end": 3314.56,
        "id": 1001,
        "no_speech_prob": 0.000003966980784753105,
        "seek": 328496,
        "start": 3310.8,
        "temperature": 0,
        "text": " I could actually completely comment this out as well.",
        "tokens": [
          51656,
          286,
          727,
          767,
          2584,
          2871,
          341,
          484,
          382,
          731,
          13,
          51844
        ]
      },
      {
        "avg_logprob": -0.29655760907112283,
        "compression_ratio": 1.7425149700598803,
        "end": 3317.64,
        "id": 1002,
        "no_speech_prob": 0.00007254348020069301,
        "seek": 331456,
        "start": 3314.72,
        "temperature": 0,
        "text": " Basically, I want to start training when the model is",
        "tokens": [
          50372,
          8537,
          11,
          286,
          528,
          281,
          722,
          3097,
          562,
          264,
          2316,
          307,
          50518
        ]
      },
      {
        "avg_logprob": -0.29655760907112283,
        "compression_ratio": 1.7425149700598803,
        "end": 3318.14,
        "id": 1003,
        "no_speech_prob": 0.00007254348020069301,
        "seek": 331456,
        "start": 3317.64,
        "temperature": 0,
        "text": " ready.",
        "tokens": [
          50518,
          1919,
          13,
          50543
        ]
      },
      {
        "avg_logprob": -0.29655760907112283,
        "compression_ratio": 1.7425149700598803,
        "end": 3319.12,
        "id": 1004,
        "no_speech_prob": 0.00007254348020069301,
        "seek": 331456,
        "start": 3318.14,
        "temperature": 0,
        "text": " Not training, sorry.",
        "tokens": [
          50543,
          1726,
          3097,
          11,
          2597,
          13,
          50592
        ]
      },
      {
        "avg_logprob": -0.29655760907112283,
        "compression_ratio": 1.7425149700598803,
        "end": 3321.2599999999998,
        "id": 1005,
        "no_speech_prob": 0.00007254348020069301,
        "seek": 331456,
        "start": 3319.12,
        "temperature": 0,
        "text": " I want to start guessing when the model is ready",
        "tokens": [
          50592,
          286,
          528,
          281,
          722,
          17939,
          562,
          264,
          2316,
          307,
          1919,
          50699
        ]
      },
      {
        "avg_logprob": -0.29655760907112283,
        "compression_ratio": 1.7425149700598803,
        "end": 3323.32,
        "id": 1006,
        "no_speech_prob": 0.00007254348020069301,
        "seek": 331456,
        "start": 3321.2599999999998,
        "temperature": 0,
        "text": " by saying classifier to classify.",
        "tokens": [
          50699,
          538,
          1566,
          1508,
          9902,
          281,
          33872,
          13,
          50802
        ]
      },
      {
        "avg_logprob": -0.29655760907112283,
        "compression_ratio": 1.7425149700598803,
        "end": 3324.24,
        "id": 1007,
        "no_speech_prob": 0.00007254348020069301,
        "seek": 331456,
        "start": 3323.32,
        "temperature": 0,
        "text": " Got results.",
        "tokens": [
          50802,
          5803,
          3542,
          13,
          50848
        ]
      },
      {
        "avg_logprob": -0.29655760907112283,
        "compression_ratio": 1.7425149700598803,
        "end": 3326.72,
        "id": 1008,
        "no_speech_prob": 0.00007254348020069301,
        "seek": 331456,
        "start": 3324.24,
        "temperature": 0,
        "text": " And now, here we go.",
        "tokens": [
          50848,
          400,
          586,
          11,
          510,
          321,
          352,
          13,
          50972
        ]
      },
      {
        "avg_logprob": -0.29655760907112283,
        "compression_ratio": 1.7425149700598803,
        "end": 3328.04,
        "id": 1009,
        "no_speech_prob": 0.00007254348020069301,
        "seek": 331456,
        "start": 3326.72,
        "temperature": 0,
        "text": " Loading the model.",
        "tokens": [
          50972,
          6130,
          8166,
          264,
          2316,
          13,
          51038
        ]
      },
      {
        "avg_logprob": -0.29655760907112283,
        "compression_ratio": 1.7425149700598803,
        "end": 3329.16,
        "id": 1010,
        "no_speech_prob": 0.00007254348020069301,
        "seek": 331456,
        "start": 3328.04,
        "temperature": 0,
        "text": " Model is ready.",
        "tokens": [
          51038,
          17105,
          307,
          1919,
          13,
          51094
        ]
      },
      {
        "avg_logprob": -0.29655760907112283,
        "compression_ratio": 1.7425149700598803,
        "end": 3335.12,
        "id": 1011,
        "no_speech_prob": 0.00007254348020069301,
        "seek": 331456,
        "start": 3329.16,
        "temperature": 0,
        "text": " Happy, sad, happy, sad.",
        "tokens": [
          51094,
          8277,
          11,
          4227,
          11,
          2055,
          11,
          4227,
          13,
          51392
        ]
      },
      {
        "avg_logprob": -0.29655760907112283,
        "compression_ratio": 1.7425149700598803,
        "end": 3337.44,
        "id": 1012,
        "no_speech_prob": 0.00007254348020069301,
        "seek": 331456,
        "start": 3335.12,
        "temperature": 0,
        "text": " And I can refresh the page again.",
        "tokens": [
          51392,
          400,
          286,
          393,
          15134,
          264,
          3028,
          797,
          13,
          51508
        ]
      },
      {
        "avg_logprob": -0.32240197533055354,
        "compression_ratio": 1.776061776061776,
        "end": 3344.56,
        "id": 1013,
        "no_speech_prob": 0.0031235655769705772,
        "seek": 333744,
        "start": 3337.44,
        "temperature": 0,
        "text": " And happy, sad, happy, sad.",
        "tokens": [
          50364,
          400,
          2055,
          11,
          4227,
          11,
          2055,
          11,
          4227,
          13,
          50720
        ]
      },
      {
        "avg_logprob": -0.32240197533055354,
        "compression_ratio": 1.776061776061776,
        "end": 3345.52,
        "id": 1014,
        "no_speech_prob": 0.0031235655769705772,
        "seek": 333744,
        "start": 3344.56,
        "temperature": 0,
        "text": " All right, so it works.",
        "tokens": [
          50720,
          1057,
          558,
          11,
          370,
          309,
          1985,
          13,
          50768
        ]
      },
      {
        "avg_logprob": -0.32240197533055354,
        "compression_ratio": 1.776061776061776,
        "end": 3346.28,
        "id": 1015,
        "no_speech_prob": 0.0031235655769705772,
        "seek": 333744,
        "start": 3345.52,
        "temperature": 0,
        "text": " We're done.",
        "tokens": [
          50768,
          492,
          434,
          1096,
          13,
          50806
        ]
      },
      {
        "avg_logprob": -0.32240197533055354,
        "compression_ratio": 1.776061776061776,
        "end": 3346.78,
        "id": 1016,
        "no_speech_prob": 0.0031235655769705772,
        "seek": 333744,
        "start": 3346.28,
        "temperature": 0,
        "text": " Yay.",
        "tokens": [
          50806,
          13268,
          13,
          50831
        ]
      },
      {
        "avg_logprob": -0.32240197533055354,
        "compression_ratio": 1.776061776061776,
        "end": 3348.56,
        "id": 1017,
        "no_speech_prob": 0.0031235655769705772,
        "seek": 333744,
        "start": 3346.78,
        "temperature": 0,
        "text": " OK, so this is a thing you can do now.",
        "tokens": [
          50831,
          2264,
          11,
          370,
          341,
          307,
          257,
          551,
          291,
          393,
          360,
          586,
          13,
          50920
        ]
      },
      {
        "avg_logprob": -0.32240197533055354,
        "compression_ratio": 1.776061776061776,
        "end": 3350.76,
        "id": 1018,
        "no_speech_prob": 0.0031235655769705772,
        "seek": 333744,
        "start": 3348.56,
        "temperature": 0,
        "text": " You can train your own transfer learning model.",
        "tokens": [
          50920,
          509,
          393,
          3847,
          428,
          1065,
          5003,
          2539,
          2316,
          13,
          51030
        ]
      },
      {
        "avg_logprob": -0.32240197533055354,
        "compression_ratio": 1.776061776061776,
        "end": 3352.48,
        "id": 1019,
        "no_speech_prob": 0.0031235655769705772,
        "seek": 333744,
        "start": 3350.76,
        "temperature": 0,
        "text": " You can do this with the regression example too,",
        "tokens": [
          51030,
          509,
          393,
          360,
          341,
          365,
          264,
          24590,
          1365,
          886,
          11,
          51116
        ]
      },
      {
        "avg_logprob": -0.32240197533055354,
        "compression_ratio": 1.776061776061776,
        "end": 3353.64,
        "id": 1020,
        "no_speech_prob": 0.0031235655769705772,
        "seek": 333744,
        "start": 3352.48,
        "temperature": 0,
        "text": " if you watched that video.",
        "tokens": [
          51116,
          498,
          291,
          6337,
          300,
          960,
          13,
          51174
        ]
      },
      {
        "avg_logprob": -0.32240197533055354,
        "compression_ratio": 1.776061776061776,
        "end": 3354.28,
        "id": 1021,
        "no_speech_prob": 0.0031235655769705772,
        "seek": 333744,
        "start": 3353.64,
        "temperature": 0,
        "text": " You can save it.",
        "tokens": [
          51174,
          509,
          393,
          3155,
          309,
          13,
          51206
        ]
      },
      {
        "avg_logprob": -0.32240197533055354,
        "compression_ratio": 1.776061776061776,
        "end": 3355.12,
        "id": 1022,
        "no_speech_prob": 0.0031235655769705772,
        "seek": 333744,
        "start": 3354.28,
        "temperature": 0,
        "text": " So I don't know.",
        "tokens": [
          51206,
          407,
          286,
          500,
          380,
          458,
          13,
          51248
        ]
      },
      {
        "avg_logprob": -0.32240197533055354,
        "compression_ratio": 1.776061776061776,
        "end": 3355.76,
        "id": 1023,
        "no_speech_prob": 0.0031235655769705772,
        "seek": 333744,
        "start": 3355.12,
        "temperature": 0,
        "text": " Share.",
        "tokens": [
          51248,
          14945,
          13,
          51280
        ]
      },
      {
        "avg_logprob": -0.32240197533055354,
        "compression_ratio": 1.776061776061776,
        "end": 3356.84,
        "id": 1024,
        "no_speech_prob": 0.0031235655769705772,
        "seek": 333744,
        "start": 3355.76,
        "temperature": 0,
        "text": " You can share models.",
        "tokens": [
          51280,
          509,
          393,
          2073,
          5245,
          13,
          51334
        ]
      },
      {
        "avg_logprob": -0.32240197533055354,
        "compression_ratio": 1.776061776061776,
        "end": 3359.12,
        "id": 1025,
        "no_speech_prob": 0.0031235655769705772,
        "seek": 333744,
        "start": 3356.84,
        "temperature": 0,
        "text": " Let's all share models with each other.",
        "tokens": [
          51334,
          961,
          311,
          439,
          2073,
          5245,
          365,
          1184,
          661,
          13,
          51448
        ]
      },
      {
        "avg_logprob": -0.32240197533055354,
        "compression_ratio": 1.776061776061776,
        "end": 3360.44,
        "id": 1026,
        "no_speech_prob": 0.0031235655769705772,
        "seek": 333744,
        "start": 3359.12,
        "temperature": 0,
        "text": " Share your model with me.",
        "tokens": [
          51448,
          14945,
          428,
          2316,
          365,
          385,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.32240197533055354,
        "compression_ratio": 1.776061776061776,
        "end": 3361.56,
        "id": 1027,
        "no_speech_prob": 0.0031235655769705772,
        "seek": 333744,
        "start": 3360.44,
        "temperature": 0,
        "text": " Let's see what happens.",
        "tokens": [
          51514,
          961,
          311,
          536,
          437,
          2314,
          13,
          51570
        ]
      },
      {
        "avg_logprob": -0.32240197533055354,
        "compression_ratio": 1.776061776061776,
        "end": 3364.08,
        "id": 1028,
        "no_speech_prob": 0.0031235655769705772,
        "seek": 333744,
        "start": 3361.56,
        "temperature": 0,
        "text": " All right, I'm curious to see what kind of creative stuff",
        "tokens": [
          51570,
          1057,
          558,
          11,
          286,
          478,
          6369,
          281,
          536,
          437,
          733,
          295,
          5880,
          1507,
          51696
        ]
      },
      {
        "avg_logprob": -0.32240197533055354,
        "compression_ratio": 1.776061776061776,
        "end": 3365.4,
        "id": 1029,
        "no_speech_prob": 0.0031235655769705772,
        "seek": 333744,
        "start": 3364.08,
        "temperature": 0,
        "text": " you come up with.",
        "tokens": [
          51696,
          291,
          808,
          493,
          365,
          13,
          51762
        ]
      },
      {
        "avg_logprob": -0.30528028549686553,
        "compression_ratio": 1.5643939393939394,
        "end": 3367.76,
        "id": 1030,
        "no_speech_prob": 0.0031725612934678793,
        "seek": 336540,
        "start": 3365.4,
        "temperature": 0,
        "text": " The interaction that I've done here is super awkward.",
        "tokens": [
          50364,
          440,
          9285,
          300,
          286,
          600,
          1096,
          510,
          307,
          1687,
          11411,
          13,
          50482
        ]
      },
      {
        "avg_logprob": -0.30528028549686553,
        "compression_ratio": 1.5643939393939394,
        "end": 3369.32,
        "id": 1031,
        "no_speech_prob": 0.0031725612934678793,
        "seek": 336540,
        "start": 3367.76,
        "temperature": 0,
        "text": " I'm going to press the button all the time.",
        "tokens": [
          50482,
          286,
          478,
          516,
          281,
          1886,
          264,
          2960,
          439,
          264,
          565,
          13,
          50560
        ]
      },
      {
        "avg_logprob": -0.30528028549686553,
        "compression_ratio": 1.5643939393939394,
        "end": 3371.52,
        "id": 1032,
        "no_speech_prob": 0.0031725612934678793,
        "seek": 336540,
        "start": 3369.32,
        "temperature": 0,
        "text": " And you don't actually have to train with just video.",
        "tokens": [
          50560,
          400,
          291,
          500,
          380,
          767,
          362,
          281,
          3847,
          365,
          445,
          960,
          13,
          50670
        ]
      },
      {
        "avg_logprob": -0.30528028549686553,
        "compression_ratio": 1.5643939393939394,
        "end": 3373.04,
        "id": 1033,
        "no_speech_prob": 0.0031725612934678793,
        "seek": 336540,
        "start": 3371.52,
        "temperature": 0,
        "text": " You could load a bunch of images.",
        "tokens": [
          50670,
          509,
          727,
          3677,
          257,
          3840,
          295,
          5267,
          13,
          50746
        ]
      },
      {
        "avg_logprob": -0.30528028549686553,
        "compression_ratio": 1.5643939393939394,
        "end": 3374.62,
        "id": 1034,
        "no_speech_prob": 0.0031725612934678793,
        "seek": 336540,
        "start": 3373.04,
        "temperature": 0,
        "text": " So there's so many possibilities here.",
        "tokens": [
          50746,
          407,
          456,
          311,
          370,
          867,
          12178,
          510,
          13,
          50825
        ]
      },
      {
        "avg_logprob": -0.30528028549686553,
        "compression_ratio": 1.5643939393939394,
        "end": 3376.8,
        "id": 1035,
        "no_speech_prob": 0.0031725612934678793,
        "seek": 336540,
        "start": 3374.62,
        "temperature": 0,
        "text": " And I look forward to seeing what you make.",
        "tokens": [
          50825,
          400,
          286,
          574,
          2128,
          281,
          2577,
          437,
          291,
          652,
          13,
          50934
        ]
      },
      {
        "avg_logprob": -0.30528028549686553,
        "compression_ratio": 1.5643939393939394,
        "end": 3379.7200000000003,
        "id": 1036,
        "no_speech_prob": 0.0031725612934678793,
        "seek": 336540,
        "start": 3376.8,
        "temperature": 0,
        "text": " And stay tuned for more ml5 videos.",
        "tokens": [
          50934,
          400,
          1754,
          10870,
          337,
          544,
          23271,
          20,
          2145,
          13,
          51080
        ]
      },
      {
        "avg_logprob": -0.30528028549686553,
        "compression_ratio": 1.5643939393939394,
        "end": 3380.6800000000003,
        "id": 1037,
        "no_speech_prob": 0.0031725612934678793,
        "seek": 336540,
        "start": 3379.7200000000003,
        "temperature": 0,
        "text": " More stuff is coming.",
        "tokens": [
          51080,
          5048,
          1507,
          307,
          1348,
          13,
          51128
        ]
      },
      {
        "avg_logprob": -0.30528028549686553,
        "compression_ratio": 1.5643939393939394,
        "end": 3382.6800000000003,
        "id": 1038,
        "no_speech_prob": 0.0031725612934678793,
        "seek": 336540,
        "start": 3380.6800000000003,
        "temperature": 0,
        "text": " I don't know yet what, but more stuff is coming.",
        "tokens": [
          51128,
          286,
          500,
          380,
          458,
          1939,
          437,
          11,
          457,
          544,
          1507,
          307,
          1348,
          13,
          51228
        ]
      },
      {
        "avg_logprob": -0.30528028549686553,
        "compression_ratio": 1.5643939393939394,
        "end": 3383.1800000000003,
        "id": 1039,
        "no_speech_prob": 0.0031725612934678793,
        "seek": 336540,
        "start": 3382.6800000000003,
        "temperature": 0,
        "text": " Goodbye.",
        "tokens": [
          51228,
          15528,
          13,
          51253
        ]
      },
      {
        "avg_logprob": -0.30528028549686553,
        "compression_ratio": 1.5643939393939394,
        "end": 3386.52,
        "id": 1040,
        "no_speech_prob": 0.0031725612934678793,
        "seek": 336540,
        "start": 3383.1800000000003,
        "temperature": 0,
        "text": " Ah, OK.",
        "tokens": [
          51253,
          2438,
          11,
          2264,
          13,
          51420
        ]
      },
      {
        "avg_logprob": -0.30528028549686553,
        "compression_ratio": 1.5643939393939394,
        "end": 3392.84,
        "id": 1041,
        "no_speech_prob": 0.0031725612934678793,
        "seek": 336540,
        "start": 3391.64,
        "temperature": 0,
        "text": " All right, everyone.",
        "tokens": [
          51676,
          1057,
          558,
          11,
          1518,
          13,
          51736
        ]
      },
      {
        "avg_logprob": -0.2954434628756541,
        "compression_ratio": 1.2734375,
        "end": 3394.48,
        "id": 1042,
        "no_speech_prob": 0.00008349366544280201,
        "seek": 339284,
        "start": 3392.84,
        "temperature": 0,
        "text": " I'm glad that I did that a second time.",
        "tokens": [
          50364,
          286,
          478,
          5404,
          300,
          286,
          630,
          300,
          257,
          1150,
          565,
          13,
          50446
        ]
      },
      {
        "avg_logprob": -0.2954434628756541,
        "compression_ratio": 1.2734375,
        "end": 3401.52,
        "id": 1043,
        "no_speech_prob": 0.00008349366544280201,
        "seek": 339284,
        "start": 3399.7200000000003,
        "temperature": 0,
        "text": " This computer went to sleep for no reason.",
        "tokens": [
          50708,
          639,
          3820,
          1437,
          281,
          2817,
          337,
          572,
          1778,
          13,
          50798
        ]
      },
      {
        "avg_logprob": -0.2954434628756541,
        "compression_ratio": 1.2734375,
        "end": 3408.76,
        "id": 1044,
        "no_speech_prob": 0.00008349366544280201,
        "seek": 339284,
        "start": 3405.1200000000003,
        "temperature": 0,
        "text": " And there's very little going on in this computer.",
        "tokens": [
          50978,
          400,
          456,
          311,
          588,
          707,
          516,
          322,
          294,
          341,
          3820,
          13,
          51160
        ]
      },
      {
        "avg_logprob": -0.2954434628756541,
        "compression_ratio": 1.2734375,
        "end": 3420.56,
        "id": 1045,
        "no_speech_prob": 0.00008349366544280201,
        "seek": 339284,
        "start": 3418.2000000000003,
        "temperature": 0,
        "text": " Oh, OK.",
        "tokens": [
          51632,
          876,
          11,
          2264,
          13,
          51750
        ]
      },
      {
        "avg_logprob": -0.2954434628756541,
        "compression_ratio": 1.2734375,
        "end": 3422.6000000000004,
        "id": 1046,
        "no_speech_prob": 0.00008349366544280201,
        "seek": 339284,
        "start": 3420.56,
        "temperature": 0,
        "text": " So maybe that's fine.",
        "tokens": [
          51750,
          407,
          1310,
          300,
          311,
          2489,
          13,
          51852
        ]
      },
      {
        "avg_logprob": -0.3774297841389974,
        "compression_ratio": 1.3818181818181818,
        "end": 3426.7599999999998,
        "id": 1047,
        "no_speech_prob": 0.00007967164856381714,
        "seek": 342260,
        "start": 3422.88,
        "temperature": 0,
        "text": " Somebody wrote a comment on my issue.",
        "tokens": [
          50378,
          13463,
          4114,
          257,
          2871,
          322,
          452,
          2734,
          13,
          50572
        ]
      },
      {
        "avg_logprob": -0.3774297841389974,
        "compression_ratio": 1.3818181818181818,
        "end": 3436.68,
        "id": 1048,
        "no_speech_prob": 0.00007967164856381714,
        "seek": 342260,
        "start": 3432.72,
        "temperature": 0,
        "text": " All right, so I'm done there.",
        "tokens": [
          50870,
          1057,
          558,
          11,
          370,
          286,
          478,
          1096,
          456,
          13,
          51068
        ]
      },
      {
        "avg_logprob": -0.3774297841389974,
        "compression_ratio": 1.3818181818181818,
        "end": 3438.56,
        "id": 1049,
        "no_speech_prob": 0.00007967164856381714,
        "seek": 342260,
        "start": 3436.68,
        "temperature": 0,
        "text": " OK, that's going to be a good one to release.",
        "tokens": [
          51068,
          2264,
          11,
          300,
          311,
          516,
          281,
          312,
          257,
          665,
          472,
          281,
          4374,
          13,
          51162
        ]
      },
      {
        "avg_logprob": -0.3774297841389974,
        "compression_ratio": 1.3818181818181818,
        "end": 3445.56,
        "id": 1050,
        "no_speech_prob": 0.00007967164856381714,
        "seek": 342260,
        "start": 3438.56,
        "temperature": 0,
        "text": " Now we are going to move on to something totally different.",
        "tokens": [
          51162,
          823,
          321,
          366,
          516,
          281,
          1286,
          322,
          281,
          746,
          3879,
          819,
          13,
          51512
        ]
      },
      {
        "avg_logprob": -0.3774297841389974,
        "compression_ratio": 1.3818181818181818,
        "end": 3446.2799999999997,
        "id": 1051,
        "no_speech_prob": 0.00007967164856381714,
        "seek": 342260,
        "start": 3445.56,
        "temperature": 0,
        "text": " What time is it?",
        "tokens": [
          51512,
          708,
          565,
          307,
          309,
          30,
          51548
        ]
      },
      {
        "avg_logprob": -0.3774297841389974,
        "compression_ratio": 1.3818181818181818,
        "end": 3448.04,
        "id": 1052,
        "no_speech_prob": 0.00007967164856381714,
        "seek": 342260,
        "start": 3446.2799999999997,
        "temperature": 0,
        "text": " 3 o'clock.",
        "tokens": [
          51548,
          805,
          277,
          6,
          9023,
          13,
          51636
        ]
      },
      {
        "avg_logprob": -0.3774297841389974,
        "compression_ratio": 1.3818181818181818,
        "end": 3450.8399999999997,
        "id": 1053,
        "no_speech_prob": 0.00007967164856381714,
        "seek": 342260,
        "start": 3448.04,
        "temperature": 0,
        "text": " It's getting warm in here.",
        "tokens": [
          51636,
          467,
          311,
          1242,
          4561,
          294,
          510,
          13,
          51776
        ]
      },
      {
        "avg_logprob": -0.45783192770821707,
        "compression_ratio": 1.5934065934065933,
        "end": 3460.2400000000002,
        "id": 1054,
        "no_speech_prob": 0.00011774449376389384,
        "seek": 345084,
        "start": 3450.84,
        "temperature": 0,
        "text": " Actually, so now I need to release this example.",
        "tokens": [
          50364,
          5135,
          11,
          370,
          586,
          286,
          643,
          281,
          4374,
          341,
          1365,
          13,
          50834
        ]
      },
      {
        "avg_logprob": -0.45783192770821707,
        "compression_ratio": 1.5934065934065933,
        "end": 3464.76,
        "id": 1055,
        "no_speech_prob": 0.00011774449376389384,
        "seek": 345084,
        "start": 3460.2400000000002,
        "temperature": 0,
        "text": " So I'm going to delete the model and the weights.",
        "tokens": [
          50834,
          407,
          286,
          478,
          516,
          281,
          12097,
          264,
          2316,
          293,
          264,
          17443,
          13,
          51060
        ]
      },
      {
        "avg_logprob": -0.45783192770821707,
        "compression_ratio": 1.5934065934065933,
        "end": 3475.1600000000003,
        "id": 1056,
        "no_speech_prob": 0.00011774449376389384,
        "seek": 345084,
        "start": 3469.56,
        "temperature": 0,
        "text": " I'm going to delete the model and the weights.",
        "tokens": [
          51300,
          286,
          478,
          516,
          281,
          12097,
          264,
          2316,
          293,
          264,
          17443,
          13,
          51580
        ]
      },
      {
        "avg_logprob": -0.5942497840294472,
        "compression_ratio": 1.5611510791366907,
        "end": 3479.3199999999997,
        "id": 1057,
        "no_speech_prob": 0.00042388233123347163,
        "seek": 347516,
        "start": 3475.6,
        "temperature": 0,
        "text": " I'm going to leave this.",
        "tokens": [
          50386,
          286,
          478,
          516,
          281,
          1856,
          341,
          13,
          50572
        ]
      },
      {
        "avg_logprob": -0.5942497840294472,
        "compression_ratio": 1.5611510791366907,
        "end": 3482.6,
        "id": 1058,
        "no_speech_prob": 0.00042388233123347163,
        "seek": 347516,
        "start": 3479.3199999999997,
        "temperature": 0,
        "text": " I think what I'm going to do is leave this example",
        "tokens": [
          50572,
          286,
          519,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          1856,
          341,
          1365,
          50736
        ]
      },
      {
        "avg_logprob": -0.5942497840294472,
        "compression_ratio": 1.5611510791366907,
        "end": 3485.56,
        "id": 1059,
        "no_speech_prob": 0.00042388233123347163,
        "seek": 347516,
        "start": 3482.6,
        "temperature": 0,
        "text": " with this stuff here.",
        "tokens": [
          50736,
          365,
          341,
          1507,
          510,
          13,
          50884
        ]
      },
      {
        "avg_logprob": -0.5942497840294472,
        "compression_ratio": 1.5611510791366907,
        "end": 3487.7999999999997,
        "id": 1060,
        "no_speech_prob": 0.00042388233123347163,
        "seek": 347516,
        "start": 3485.56,
        "temperature": 0,
        "text": " And then this is tricky.",
        "tokens": [
          50884,
          400,
          550,
          341,
          307,
          12414,
          13,
          50996
        ]
      },
      {
        "avg_logprob": -0.5942497840294472,
        "compression_ratio": 1.5611510791366907,
        "end": 3492.92,
        "id": 1061,
        "no_speech_prob": 0.00042388233123347163,
        "seek": 347516,
        "start": 3491.3199999999997,
        "temperature": 0,
        "text": " Comment out loading this.",
        "tokens": [
          51172,
          16328,
          484,
          15114,
          341,
          13,
          51252
        ]
      },
      {
        "avg_logprob": -0.5942497840294472,
        "compression_ratio": 1.5611510791366907,
        "end": 3498.72,
        "id": 1062,
        "no_speech_prob": 0.00042388233123347163,
        "seek": 347516,
        "start": 3497.44,
        "temperature": 0,
        "text": " Comment this out.",
        "tokens": [
          51478,
          16328,
          341,
          484,
          13,
          51542
        ]
      },
      {
        "avg_logprob": -0.5942497840294472,
        "compression_ratio": 1.5611510791366907,
        "end": 3502.3599999999997,
        "id": 1063,
        "no_speech_prob": 0.00042388233123347163,
        "seek": 347516,
        "start": 3498.72,
        "temperature": 0,
        "text": " So this example is now left in the training state.",
        "tokens": [
          51542,
          407,
          341,
          1365,
          307,
          586,
          1411,
          294,
          264,
          3097,
          1785,
          13,
          51724
        ]
      },
      {
        "avg_logprob": -0.5056113165778082,
        "compression_ratio": 1.2233009708737863,
        "end": 3512.16,
        "id": 1064,
        "no_speech_prob": 0.000060140791902085766,
        "seek": 350516,
        "start": 3506.16,
        "temperature": 0,
        "text": " But it has the loading code in it, but commented out.",
        "tokens": [
          50414,
          583,
          309,
          575,
          264,
          15114,
          3089,
          294,
          309,
          11,
          457,
          26940,
          484,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.5056113165778082,
        "compression_ratio": 1.2233009708737863,
        "end": 3519.2,
        "id": 1065,
        "no_speech_prob": 0.000060140791902085766,
        "seek": 350516,
        "start": 3512.16,
        "temperature": 0,
        "text": " And so now let me just put this online.",
        "tokens": [
          50714,
          400,
          370,
          586,
          718,
          385,
          445,
          829,
          341,
          2950,
          13,
          51066
        ]
      },
      {
        "avg_logprob": -0.5056113165778082,
        "compression_ratio": 1.2233009708737863,
        "end": 3532.2,
        "id": 1066,
        "no_speech_prob": 0.000060140791902085766,
        "seek": 350516,
        "start": 3527.64,
        "temperature": 0,
        "text": " Code from save load live stream.",
        "tokens": [
          51488,
          15549,
          490,
          3155,
          3677,
          1621,
          4309,
          13,
          51716
        ]
      },
      {
        "avg_logprob": -0.35215665423680864,
        "compression_ratio": 1.3428571428571427,
        "end": 3537.16,
        "id": 1067,
        "no_speech_prob": 0.004330705851316452,
        "seek": 353516,
        "start": 3536.16,
        "temperature": 0,
        "text": " Save load ml5.",
        "tokens": [
          50414,
          15541,
          3677,
          23271,
          20,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.35215665423680864,
        "compression_ratio": 1.3428571428571427,
        "end": 3544.96,
        "id": 1068,
        "no_speech_prob": 0.004330705851316452,
        "seek": 353516,
        "start": 3543.6,
        "temperature": 0,
        "text": " So this is now.",
        "tokens": [
          50786,
          407,
          341,
          307,
          586,
          13,
          50854
        ]
      },
      {
        "avg_logprob": -0.35215665423680864,
        "compression_ratio": 1.3428571428571427,
        "end": 3548.8399999999997,
        "id": 1069,
        "no_speech_prob": 0.004330705851316452,
        "seek": 353516,
        "start": 3544.96,
        "temperature": 0,
        "text": " It should be in the website.",
        "tokens": [
          50854,
          467,
          820,
          312,
          294,
          264,
          3144,
          13,
          51048
        ]
      },
      {
        "avg_logprob": -0.35215665423680864,
        "compression_ratio": 1.3428571428571427,
        "end": 3551.44,
        "id": 1070,
        "no_speech_prob": 0.004330705851316452,
        "seek": 353516,
        "start": 3548.8399999999997,
        "temperature": 0,
        "text": " I'm going to create a pull request here.",
        "tokens": [
          51048,
          286,
          478,
          516,
          281,
          1884,
          257,
          2235,
          5308,
          510,
          13,
          51178
        ]
      },
      {
        "avg_logprob": -0.35215665423680864,
        "compression_ratio": 1.3428571428571427,
        "end": 3561.44,
        "id": 1071,
        "no_speech_prob": 0.004330705851316452,
        "seek": 353516,
        "start": 3554.56,
        "temperature": 0,
        "text": " This is the code from 11.9 live stream.",
        "tokens": [
          51334,
          639,
          307,
          264,
          3089,
          490,
          2975,
          13,
          24,
          1621,
          4309,
          13,
          51678
        ]
      },
      {
        "avg_logprob": -0.35215665423680864,
        "compression_ratio": 1.3428571428571427,
        "end": 3565,
        "id": 1072,
        "no_speech_prob": 0.004330705851316452,
        "seek": 353516,
        "start": 3561.44,
        "temperature": 0,
        "text": " I'm not sure if I should make this two examples",
        "tokens": [
          51678,
          286,
          478,
          406,
          988,
          498,
          286,
          820,
          652,
          341,
          732,
          5110,
          51856
        ]
      },
      {
        "avg_logprob": -0.3140980790301067,
        "compression_ratio": 1.4318181818181819,
        "end": 3567.16,
        "id": 1073,
        "no_speech_prob": 0.00018813859787769616,
        "seek": 356500,
        "start": 3565.84,
        "temperature": 0,
        "text": " or just one.",
        "tokens": [
          50406,
          420,
          445,
          472,
          13,
          50472
        ]
      },
      {
        "avg_logprob": -0.3140980790301067,
        "compression_ratio": 1.4318181818181819,
        "end": 3572.96,
        "id": 1074,
        "no_speech_prob": 0.00018813859787769616,
        "seek": 356500,
        "start": 3567.16,
        "temperature": 0,
        "text": " For now, the loading code is commented out.",
        "tokens": [
          50472,
          1171,
          586,
          11,
          264,
          15114,
          3089,
          307,
          26940,
          484,
          13,
          50762
        ]
      },
      {
        "avg_logprob": -0.3140980790301067,
        "compression_ratio": 1.4318181818181819,
        "end": 3579.12,
        "id": 1075,
        "no_speech_prob": 0.00018813859787769616,
        "seek": 356500,
        "start": 3575.68,
        "temperature": 0,
        "text": " So I'm going to create this pull request.",
        "tokens": [
          50898,
          407,
          286,
          478,
          516,
          281,
          1884,
          341,
          2235,
          5308,
          13,
          51070
        ]
      },
      {
        "avg_logprob": -0.3140980790301067,
        "compression_ratio": 1.4318181818181819,
        "end": 3582,
        "id": 1076,
        "no_speech_prob": 0.00018813859787769616,
        "seek": 356500,
        "start": 3579.12,
        "temperature": 0,
        "text": " And it should be just these files.",
        "tokens": [
          51070,
          400,
          309,
          820,
          312,
          445,
          613,
          7098,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.3140980790301067,
        "compression_ratio": 1.4318181818181819,
        "end": 3583.08,
        "id": 1077,
        "no_speech_prob": 0.00018813859787769616,
        "seek": 356500,
        "start": 3582,
        "temperature": 0,
        "text": " Yep.",
        "tokens": [
          51214,
          7010,
          13,
          51268
        ]
      },
      {
        "avg_logprob": -0.3140980790301067,
        "compression_ratio": 1.4318181818181819,
        "end": 3583.92,
        "id": 1078,
        "no_speech_prob": 0.00018813859787769616,
        "seek": 356500,
        "start": 3583.08,
        "temperature": 0,
        "text": " OK, good.",
        "tokens": [
          51268,
          2264,
          11,
          665,
          13,
          51310
        ]
      },
      {
        "avg_logprob": -0.3140980790301067,
        "compression_ratio": 1.4318181818181819,
        "end": 3584.72,
        "id": 1079,
        "no_speech_prob": 0.00018813859787769616,
        "seek": 356500,
        "start": 3583.92,
        "temperature": 0,
        "text": " Great.",
        "tokens": [
          51310,
          3769,
          13,
          51350
        ]
      },
      {
        "avg_logprob": -0.3140980790301067,
        "compression_ratio": 1.4318181818181819,
        "end": 3588.4,
        "id": 1080,
        "no_speech_prob": 0.00018813859787769616,
        "seek": 356500,
        "start": 3584.72,
        "temperature": 0,
        "text": " So that code will be on the Coding Train website.",
        "tokens": [
          51350,
          407,
          300,
          3089,
          486,
          312,
          322,
          264,
          383,
          8616,
          28029,
          3144,
          13,
          51534
        ]
      },
      {
        "avg_logprob": -0.3140980790301067,
        "compression_ratio": 1.4318181818181819,
        "end": 3594.6,
        "id": 1081,
        "no_speech_prob": 0.00018813859787769616,
        "seek": 356500,
        "start": 3588.4,
        "temperature": 0,
        "text": " Just for people who are looking, there is also",
        "tokens": [
          51534,
          1449,
          337,
          561,
          567,
          366,
          1237,
          11,
          456,
          307,
          611,
          51844
        ]
      },
      {
        "avg_logprob": -0.2679925515101506,
        "compression_ratio": 1.6732673267326732,
        "end": 3596.44,
        "id": 1082,
        "no_speech_prob": 0.0000991517590591684,
        "seek": 359460,
        "start": 3595.6,
        "temperature": 0,
        "text": " this example.",
        "tokens": [
          50414,
          341,
          1365,
          13,
          50456
        ]
      },
      {
        "avg_logprob": -0.2679925515101506,
        "compression_ratio": 1.6732673267326732,
        "end": 3597.88,
        "id": 1083,
        "no_speech_prob": 0.0000991517590591684,
        "seek": 359460,
        "start": 3596.44,
        "temperature": 0,
        "text": " I had it open.",
        "tokens": [
          50456,
          286,
          632,
          309,
          1269,
          13,
          50528
        ]
      },
      {
        "avg_logprob": -0.2679925515101506,
        "compression_ratio": 1.6732673267326732,
        "end": 3599.48,
        "id": 1084,
        "no_speech_prob": 0.0000991517590591684,
        "seek": 359460,
        "start": 3597.88,
        "temperature": 0,
        "text": " So this is the same exact example.",
        "tokens": [
          50528,
          407,
          341,
          307,
          264,
          912,
          1900,
          1365,
          13,
          50608
        ]
      },
      {
        "avg_logprob": -0.2679925515101506,
        "compression_ratio": 1.6732673267326732,
        "end": 3602.72,
        "id": 1085,
        "no_speech_prob": 0.0000991517590591684,
        "seek": 359460,
        "start": 3599.48,
        "temperature": 0,
        "text": " I'll note, though, that this example uses a button",
        "tokens": [
          50608,
          286,
          603,
          3637,
          11,
          1673,
          11,
          300,
          341,
          1365,
          4960,
          257,
          2960,
          50770
        ]
      },
      {
        "avg_logprob": -0.2679925515101506,
        "compression_ratio": 1.6732673267326732,
        "end": 3605.36,
        "id": 1086,
        "no_speech_prob": 0.0000991517590591684,
        "seek": 359460,
        "start": 3602.72,
        "temperature": 0,
        "text": " that you can select and then select files and load them.",
        "tokens": [
          50770,
          300,
          291,
          393,
          3048,
          293,
          550,
          3048,
          7098,
          293,
          3677,
          552,
          13,
          50902
        ]
      },
      {
        "avg_logprob": -0.2679925515101506,
        "compression_ratio": 1.6732673267326732,
        "end": 3607.48,
        "id": 1087,
        "no_speech_prob": 0.0000991517590591684,
        "seek": 359460,
        "start": 3605.36,
        "temperature": 0,
        "text": " So there's a lot of other ways of approaching this.",
        "tokens": [
          50902,
          407,
          456,
          311,
          257,
          688,
          295,
          661,
          2098,
          295,
          14908,
          341,
          13,
          51008
        ]
      },
      {
        "avg_logprob": -0.2679925515101506,
        "compression_ratio": 1.6732673267326732,
        "end": 3610.36,
        "id": 1088,
        "no_speech_prob": 0.0000991517590591684,
        "seek": 359460,
        "start": 3607.48,
        "temperature": 0,
        "text": " So here's yet another example with more features",
        "tokens": [
          51008,
          407,
          510,
          311,
          1939,
          1071,
          1365,
          365,
          544,
          4122,
          51152
        ]
      },
      {
        "avg_logprob": -0.2679925515101506,
        "compression_ratio": 1.6732673267326732,
        "end": 3611.72,
        "id": 1089,
        "no_speech_prob": 0.0000991517590591684,
        "seek": 359460,
        "start": 3610.36,
        "temperature": 0,
        "text": " that you can look at.",
        "tokens": [
          51152,
          300,
          291,
          393,
          574,
          412,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.2679925515101506,
        "compression_ratio": 1.6732673267326732,
        "end": 3612.24,
        "id": 1090,
        "no_speech_prob": 0.0000991517590591684,
        "seek": 359460,
        "start": 3611.72,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51220,
          2264,
          13,
          51246
        ]
      },
      {
        "avg_logprob": -0.2679925515101506,
        "compression_ratio": 1.6732673267326732,
        "end": 3617.64,
        "id": 1091,
        "no_speech_prob": 0.0000991517590591684,
        "seek": 359460,
        "start": 3617.12,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51490,
          1057,
          558,
          13,
          51516
        ]
      },
      {
        "avg_logprob": -0.2679925515101506,
        "compression_ratio": 1.6732673267326732,
        "end": 3620.16,
        "id": 1092,
        "no_speech_prob": 0.0000991517590591684,
        "seek": 359460,
        "start": 3617.64,
        "temperature": 0,
        "text": " So now what do I want to do?",
        "tokens": [
          51516,
          407,
          586,
          437,
          360,
          286,
          528,
          281,
          360,
          30,
          51642
        ]
      },
      {
        "avg_logprob": -0.46865638097127277,
        "compression_ratio": 0.9148936170212766,
        "end": 3625.6,
        "id": 1093,
        "no_speech_prob": 0.0037650091107934713,
        "seek": 362460,
        "start": 3625.12,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50390,
          1057,
          558,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.46865638097127277,
        "compression_ratio": 0.9148936170212766,
        "end": 3627.2799999999997,
        "id": 1094,
        "no_speech_prob": 0.0037650091107934713,
        "seek": 362460,
        "start": 3625.6,
        "temperature": 0,
        "text": " I am going to go to the desktop.",
        "tokens": [
          50414,
          286,
          669,
          516,
          281,
          352,
          281,
          264,
          14502,
          13,
          50498
        ]
      },
      {
        "avg_logprob": -0.8454492092132568,
        "compression_ratio": 0.8095238095238095,
        "end": 3627.78,
        "id": 1095,
        "no_speech_prob": 0.32022109627723694,
        "seek": 362728,
        "start": 3627.28,
        "temperature": 0,
        "text": " Desktop.",
        "tokens": [
          50364,
          49044,
          13,
          50389
        ]
      },
      {
        "avg_logprob": -0.8454492092132568,
        "compression_ratio": 0.8095238095238095,
        "end": 3650.28,
        "id": 1096,
        "no_speech_prob": 0.32022109627723694,
        "seek": 362728,
        "start": 3633.1200000000003,
        "temperature": 0,
        "text": " And I just want to get a.",
        "tokens": [
          50656,
          400,
          286,
          445,
          528,
          281,
          483,
          257,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.4858080546061198,
        "compression_ratio": 1.163265306122449,
        "end": 3659.96,
        "id": 1097,
        "no_speech_prob": 0.020642299205064774,
        "seek": 365028,
        "start": 3650.28,
        "temperature": 0,
        "text": " I just want to have a p5 sketch in that directory",
        "tokens": [
          50364,
          286,
          445,
          528,
          281,
          362,
          257,
          280,
          20,
          12325,
          294,
          300,
          21120,
          50848
        ]
      },
      {
        "avg_logprob": -0.4858080546061198,
        "compression_ratio": 1.163265306122449,
        "end": 3662.6800000000003,
        "id": 1098,
        "no_speech_prob": 0.020642299205064774,
        "seek": 365028,
        "start": 3659.96,
        "temperature": 0,
        "text": " that I can start using.",
        "tokens": [
          50848,
          300,
          286,
          393,
          722,
          1228,
          13,
          50984
        ]
      },
      {
        "avg_logprob": -0.4858080546061198,
        "compression_ratio": 1.163265306122449,
        "end": 3673.52,
        "id": 1099,
        "no_speech_prob": 0.020642299205064774,
        "seek": 365028,
        "start": 3668.28,
        "temperature": 0,
        "text": " And so let's get rid of everything here.",
        "tokens": [
          51264,
          400,
          370,
          718,
          311,
          483,
          3973,
          295,
          1203,
          510,
          13,
          51526
        ]
      },
      {
        "avg_logprob": -0.7291692733764649,
        "compression_ratio": 0.8571428571428571,
        "end": 3679.96,
        "id": 1100,
        "no_speech_prob": 0.05581309273838997,
        "seek": 367352,
        "start": 3673.52,
        "temperature": 0,
        "text": " And here.",
        "tokens": [
          50364,
          400,
          510,
          13,
          50686
        ]
      },
      {
        "avg_logprob": -0.7291692733764649,
        "compression_ratio": 0.8571428571428571,
        "end": 3686.16,
        "id": 1101,
        "no_speech_prob": 0.05581309273838997,
        "seek": 367352,
        "start": 3683.04,
        "temperature": 0,
        "text": " And index.",
        "tokens": [
          50840,
          400,
          8186,
          13,
          50996
        ]
      },
      {
        "avg_logprob": -0.7291692733764649,
        "compression_ratio": 0.8571428571428571,
        "end": 3688.72,
        "id": 1102,
        "no_speech_prob": 0.05581309273838997,
        "seek": 367352,
        "start": 3686.16,
        "temperature": 0,
        "text": " Quick draw.",
        "tokens": [
          50996,
          12101,
          2642,
          13,
          51124
        ]
      },
      {
        "avg_logprob": -0.7291692733764649,
        "compression_ratio": 0.8571428571428571,
        "end": 3689.22,
        "id": 1103,
        "no_speech_prob": 0.05581309273838997,
        "seek": 367352,
        "start": 3688.72,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51124,
          2264,
          13,
          51149
        ]
      },
      {
        "avg_logprob": -0.5379261793913664,
        "compression_ratio": 0.9393939393939394,
        "end": 3705.48,
        "id": 1104,
        "no_speech_prob": 0.04958231374621391,
        "seek": 370352,
        "start": 3704.08,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50392,
          2264,
          13,
          50462
        ]
      },
      {
        "avg_logprob": -0.5379261793913664,
        "compression_ratio": 0.9393939393939394,
        "end": 3709.08,
        "id": 1105,
        "no_speech_prob": 0.04958231374621391,
        "seek": 370352,
        "start": 3705.48,
        "temperature": 0,
        "text": " Now, what did I minimize that?",
        "tokens": [
          50462,
          823,
          11,
          437,
          630,
          286,
          17522,
          300,
          30,
          50642
        ]
      },
      {
        "avg_logprob": -0.5379261793913664,
        "compression_ratio": 0.9393939393939394,
        "end": 3711.96,
        "id": 1106,
        "no_speech_prob": 0.04958231374621391,
        "seek": 370352,
        "start": 3709.08,
        "temperature": 0,
        "text": " So I need the browser.",
        "tokens": [
          50642,
          407,
          286,
          643,
          264,
          11185,
          13,
          50786
        ]
      },
      {
        "avg_logprob": -0.5379261793913664,
        "compression_ratio": 0.9393939393939394,
        "end": 3712.46,
        "id": 1107,
        "no_speech_prob": 0.04958231374621391,
        "seek": 370352,
        "start": 3711.96,
        "temperature": 0,
        "text": " And.",
        "tokens": [
          50786,
          400,
          13,
          50811
        ]
      },
      {
        "avg_logprob": -0.7257443303647249,
        "compression_ratio": 0.9183673469387755,
        "end": 3734.02,
        "id": 1108,
        "no_speech_prob": 0.09257214516401291,
        "seek": 373352,
        "start": 3733.52,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          50364,
          876,
          13,
          50389
        ]
      },
      {
        "avg_logprob": -0.7257443303647249,
        "compression_ratio": 0.9183673469387755,
        "end": 3747.7599999999998,
        "id": 1109,
        "no_speech_prob": 0.09257214516401291,
        "seek": 373352,
        "start": 3744.44,
        "temperature": 0,
        "text": " And quick draw data.",
        "tokens": [
          50910,
          400,
          1702,
          2642,
          1412,
          13,
          51076
        ]
      },
      {
        "avg_logprob": -0.7257443303647249,
        "compression_ratio": 0.9183673469387755,
        "end": 3758.64,
        "id": 1110,
        "no_speech_prob": 0.09257214516401291,
        "seek": 373352,
        "start": 3753.6,
        "temperature": 0,
        "text": " And there we go.",
        "tokens": [
          51368,
          400,
          456,
          321,
          352,
          13,
          51620
        ]
      },
      {
        "avg_logprob": -0.7257443303647249,
        "compression_ratio": 0.9183673469387755,
        "end": 3759.14,
        "id": 1111,
        "no_speech_prob": 0.09257214516401291,
        "seek": 373352,
        "start": 3758.64,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51620,
          2264,
          13,
          51645
        ]
      },
      {
        "avg_logprob": -0.5456129709879557,
        "compression_ratio": 0.9605263157894737,
        "end": 3782.72,
        "id": 1112,
        "no_speech_prob": 0.00581971462816,
        "seek": 376352,
        "start": 3763.52,
        "temperature": 0,
        "text": " And then this is part of build your own API with node.",
        "tokens": [
          50364,
          400,
          550,
          341,
          307,
          644,
          295,
          1322,
          428,
          1065,
          9362,
          365,
          9984,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.5456129709879557,
        "compression_ratio": 0.9605263157894737,
        "end": 3783.4,
        "id": 1113,
        "no_speech_prob": 0.00581971462816,
        "seek": 376352,
        "start": 3782.72,
        "temperature": 0,
        "text": " Where is that?",
        "tokens": [
          51324,
          2305,
          307,
          300,
          30,
          51358
        ]
      },
      {
        "avg_logprob": -0.5456129709879557,
        "compression_ratio": 0.9605263157894737,
        "end": 3791.04,
        "id": 1114,
        "no_speech_prob": 0.00581971462816,
        "seek": 376352,
        "start": 3789.04,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51640,
          2264,
          13,
          51740
        ]
      },
      {
        "avg_logprob": -0.2799651554652623,
        "compression_ratio": 1.5462555066079295,
        "end": 3791.54,
        "id": 1115,
        "no_speech_prob": 0.00012931475066579878,
        "seek": 379104,
        "start": 3791.04,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50364,
          2264,
          13,
          50389
        ]
      },
      {
        "avg_logprob": -0.2799651554652623,
        "compression_ratio": 1.5462555066079295,
        "end": 3799.4,
        "id": 1116,
        "no_speech_prob": 0.00012931475066579878,
        "seek": 379104,
        "start": 3796.72,
        "temperature": 0,
        "text": " Yeah, that looks like there's a discussion in the chat",
        "tokens": [
          50648,
          865,
          11,
          300,
          1542,
          411,
          456,
          311,
          257,
          5017,
          294,
          264,
          5081,
          50782
        ]
      },
      {
        "avg_logprob": -0.2799651554652623,
        "compression_ratio": 1.5462555066079295,
        "end": 3803.36,
        "id": 1117,
        "no_speech_prob": 0.00012931475066579878,
        "seek": 379104,
        "start": 3799.4,
        "temperature": 0,
        "text": " about why I'm using a separate terminal instead",
        "tokens": [
          50782,
          466,
          983,
          286,
          478,
          1228,
          257,
          4994,
          14709,
          2602,
          50980
        ]
      },
      {
        "avg_logprob": -0.2799651554652623,
        "compression_ratio": 1.5462555066079295,
        "end": 3805.12,
        "id": 1118,
        "no_speech_prob": 0.00012931475066579878,
        "seek": 379104,
        "start": 3803.36,
        "temperature": 0,
        "text": " of the built-in terminal in VS Code,",
        "tokens": [
          50980,
          295,
          264,
          3094,
          12,
          259,
          14709,
          294,
          25091,
          15549,
          11,
          51068
        ]
      },
      {
        "avg_logprob": -0.2799651554652623,
        "compression_ratio": 1.5462555066079295,
        "end": 3807.84,
        "id": 1119,
        "no_speech_prob": 0.00012931475066579878,
        "seek": 379104,
        "start": 3805.12,
        "temperature": 0,
        "text": " and why not just use the VS Code live server.",
        "tokens": [
          51068,
          293,
          983,
          406,
          445,
          764,
          264,
          25091,
          15549,
          1621,
          7154,
          13,
          51204
        ]
      },
      {
        "avg_logprob": -0.2799651554652623,
        "compression_ratio": 1.5462555066079295,
        "end": 3810.68,
        "id": 1120,
        "no_speech_prob": 0.00012931475066579878,
        "seek": 379104,
        "start": 3807.84,
        "temperature": 0,
        "text": " Those are all very good questions.",
        "tokens": [
          51204,
          3950,
          366,
          439,
          588,
          665,
          1651,
          13,
          51346
        ]
      },
      {
        "avg_logprob": -0.2799651554652623,
        "compression_ratio": 1.5462555066079295,
        "end": 3812.52,
        "id": 1121,
        "no_speech_prob": 0.00012931475066579878,
        "seek": 379104,
        "start": 3810.68,
        "temperature": 0,
        "text": " Sometimes I don't like to feel like I'm just",
        "tokens": [
          51346,
          4803,
          286,
          500,
          380,
          411,
          281,
          841,
          411,
          286,
          478,
          445,
          51438
        ]
      },
      {
        "avg_logprob": -0.2799651554652623,
        "compression_ratio": 1.5462555066079295,
        "end": 3814.24,
        "id": 1122,
        "no_speech_prob": 0.00012931475066579878,
        "seek": 379104,
        "start": 3812.52,
        "temperature": 0,
        "text": " only using one thing.",
        "tokens": [
          51438,
          787,
          1228,
          472,
          551,
          13,
          51524
        ]
      },
      {
        "avg_logprob": -0.2799651554652623,
        "compression_ratio": 1.5462555066079295,
        "end": 3816.96,
        "id": 1123,
        "no_speech_prob": 0.00012931475066579878,
        "seek": 379104,
        "start": 3814.24,
        "temperature": 0,
        "text": " And then what if that one thing goes away?",
        "tokens": [
          51524,
          400,
          550,
          437,
          498,
          300,
          472,
          551,
          1709,
          1314,
          30,
          51660
        ]
      },
      {
        "avg_logprob": -0.2799651554652623,
        "compression_ratio": 1.5462555066079295,
        "end": 3818.56,
        "id": 1124,
        "no_speech_prob": 0.00012931475066579878,
        "seek": 379104,
        "start": 3816.96,
        "temperature": 0,
        "text": " So I don't know.",
        "tokens": [
          51660,
          407,
          286,
          500,
          380,
          458,
          13,
          51740
        ]
      },
      {
        "avg_logprob": -0.4699556778888313,
        "compression_ratio": 1.1894736842105262,
        "end": 3823.6,
        "id": 1125,
        "no_speech_prob": 0.0034833350218832493,
        "seek": 381856,
        "start": 3818.56,
        "temperature": 0,
        "text": " Why does this camera keep going out?",
        "tokens": [
          50364,
          1545,
          775,
          341,
          2799,
          1066,
          516,
          484,
          30,
          50616
        ]
      },
      {
        "avg_logprob": -0.4699556778888313,
        "compression_ratio": 1.1894736842105262,
        "end": 3825.2,
        "id": 1126,
        "no_speech_prob": 0.0034833350218832493,
        "seek": 381856,
        "start": 3823.6,
        "temperature": 0,
        "text": " Is there a loose cable or something?",
        "tokens": [
          50616,
          1119,
          456,
          257,
          9612,
          8220,
          420,
          746,
          30,
          50696
        ]
      },
      {
        "avg_logprob": -0.4699556778888313,
        "compression_ratio": 1.1894736842105262,
        "end": 3825.7,
        "id": 1127,
        "no_speech_prob": 0.0034833350218832493,
        "seek": 381856,
        "start": 3825.2,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50696,
          821,
          321,
          352,
          13,
          50721
        ]
      },
      {
        "avg_logprob": -0.4699556778888313,
        "compression_ratio": 1.1894736842105262,
        "end": 3831.94,
        "id": 1128,
        "no_speech_prob": 0.0034833350218832493,
        "seek": 381856,
        "start": 3831.44,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51008,
          1057,
          558,
          13,
          51033
        ]
      },
      {
        "avg_logprob": -0.4699556778888313,
        "compression_ratio": 1.1894736842105262,
        "end": 3845.52,
        "id": 1129,
        "no_speech_prob": 0.0034833350218832493,
        "seek": 381856,
        "start": 3842.88,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51580,
          2264,
          13,
          51712
        ]
      },
      {
        "avg_logprob": -0.4699556778888313,
        "compression_ratio": 1.1894736842105262,
        "end": 3846.68,
        "id": 1130,
        "no_speech_prob": 0.0034833350218832493,
        "seek": 381856,
        "start": 3845.52,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51712,
          2264,
          13,
          51770
        ]
      },
      {
        "avg_logprob": -0.4699556778888313,
        "compression_ratio": 1.1894736842105262,
        "end": 3847.44,
        "id": 1131,
        "no_speech_prob": 0.0034833350218832493,
        "seek": 381856,
        "start": 3846.68,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51770,
          2264,
          13,
          51808
        ]
      },
      {
        "avg_logprob": -0.4699556778888313,
        "compression_ratio": 1.1894736842105262,
        "end": 3848.32,
        "id": 1132,
        "no_speech_prob": 0.0034833350218832493,
        "seek": 381856,
        "start": 3847.44,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51808,
          2264,
          13,
          51852
        ]
      },
      {
        "avg_logprob": -0.3470200607457112,
        "compression_ratio": 1.5260663507109005,
        "end": 3849.88,
        "id": 1133,
        "no_speech_prob": 0.000041985942516475916,
        "seek": 384832,
        "start": 3849.0800000000004,
        "temperature": 0,
        "text": " OK, everybody.",
        "tokens": [
          50402,
          2264,
          11,
          2201,
          13,
          50442
        ]
      },
      {
        "avg_logprob": -0.3470200607457112,
        "compression_ratio": 1.5260663507109005,
        "end": 3850.92,
        "id": 1134,
        "no_speech_prob": 0.000041985942516475916,
        "seek": 384832,
        "start": 3849.88,
        "temperature": 0,
        "text": " Everybody settle down.",
        "tokens": [
          50442,
          7646,
          11852,
          760,
          13,
          50494
        ]
      },
      {
        "avg_logprob": -0.3470200607457112,
        "compression_ratio": 1.5260663507109005,
        "end": 3856.2000000000003,
        "id": 1135,
        "no_speech_prob": 0.000041985942516475916,
        "seek": 384832,
        "start": 3853.7200000000003,
        "temperature": 0,
        "text": " We're going to do something really fun.",
        "tokens": [
          50634,
          492,
          434,
          516,
          281,
          360,
          746,
          534,
          1019,
          13,
          50758
        ]
      },
      {
        "avg_logprob": -0.3470200607457112,
        "compression_ratio": 1.5260663507109005,
        "end": 3857.2000000000003,
        "id": 1136,
        "no_speech_prob": 0.000041985942516475916,
        "seek": 384832,
        "start": 3856.2000000000003,
        "temperature": 0,
        "text": " Oh, this is empty.",
        "tokens": [
          50758,
          876,
          11,
          341,
          307,
          6707,
          13,
          50808
        ]
      },
      {
        "avg_logprob": -0.3470200607457112,
        "compression_ratio": 1.5260663507109005,
        "end": 3863.2400000000002,
        "id": 1137,
        "no_speech_prob": 0.000041985942516475916,
        "seek": 384832,
        "start": 3859.6400000000003,
        "temperature": 0,
        "text": " This is the last thing I'm going to do before the weekend.",
        "tokens": [
          50930,
          639,
          307,
          264,
          1036,
          551,
          286,
          478,
          516,
          281,
          360,
          949,
          264,
          6711,
          13,
          51110
        ]
      },
      {
        "avg_logprob": -0.3470200607457112,
        "compression_ratio": 1.5260663507109005,
        "end": 3866,
        "id": 1138,
        "no_speech_prob": 0.000041985942516475916,
        "seek": 384832,
        "start": 3863.2400000000002,
        "temperature": 0,
        "text": " There will not be any live streams next week,",
        "tokens": [
          51110,
          821,
          486,
          406,
          312,
          604,
          1621,
          15842,
          958,
          1243,
          11,
          51248
        ]
      },
      {
        "avg_logprob": -0.3470200607457112,
        "compression_ratio": 1.5260663507109005,
        "end": 3867.96,
        "id": 1139,
        "no_speech_prob": 0.000041985942516475916,
        "seek": 384832,
        "start": 3866,
        "temperature": 0,
        "text": " unless somehow I figure out some magic way",
        "tokens": [
          51248,
          5969,
          6063,
          286,
          2573,
          484,
          512,
          5585,
          636,
          51346
        ]
      },
      {
        "avg_logprob": -0.3470200607457112,
        "compression_ratio": 1.5260663507109005,
        "end": 3869.56,
        "id": 1140,
        "no_speech_prob": 0.000041985942516475916,
        "seek": 384832,
        "start": 3867.96,
        "temperature": 0,
        "text": " to live stream from ThinkerCon.",
        "tokens": [
          51346,
          281,
          1621,
          4309,
          490,
          6557,
          260,
          9838,
          13,
          51426
        ]
      },
      {
        "avg_logprob": -0.3470200607457112,
        "compression_ratio": 1.5260663507109005,
        "end": 3872.76,
        "id": 1141,
        "no_speech_prob": 0.000041985942516475916,
        "seek": 384832,
        "start": 3869.56,
        "temperature": 0,
        "text": " But we'll see if that's possible or not.",
        "tokens": [
          51426,
          583,
          321,
          603,
          536,
          498,
          300,
          311,
          1944,
          420,
          406,
          13,
          51586
        ]
      },
      {
        "avg_logprob": -0.3470200607457112,
        "compression_ratio": 1.5260663507109005,
        "end": 3873.26,
        "id": 1142,
        "no_speech_prob": 0.000041985942516475916,
        "seek": 384832,
        "start": 3872.76,
        "temperature": 0,
        "text": " And.",
        "tokens": [
          51586,
          400,
          13,
          51611
        ]
      },
      {
        "avg_logprob": -0.36457127700617287,
        "compression_ratio": 1.375,
        "end": 3880.44,
        "id": 1143,
        "no_speech_prob": 0.000031692230550106615,
        "seek": 387832,
        "start": 3879.32,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50414,
          1057,
          558,
          13,
          50470
        ]
      },
      {
        "avg_logprob": -0.36457127700617287,
        "compression_ratio": 1.375,
        "end": 3884,
        "id": 1144,
        "no_speech_prob": 0.000031692230550106615,
        "seek": 387832,
        "start": 3880.44,
        "temperature": 0,
        "text": " Now I think I am ready.",
        "tokens": [
          50470,
          823,
          286,
          519,
          286,
          669,
          1919,
          13,
          50648
        ]
      },
      {
        "avg_logprob": -0.36457127700617287,
        "compression_ratio": 1.375,
        "end": 3893.28,
        "id": 1145,
        "no_speech_prob": 0.000031692230550106615,
        "seek": 387832,
        "start": 3889.1200000000003,
        "temperature": 0,
        "text": " I think I am ready of all the pieces that I want.",
        "tokens": [
          50904,
          286,
          519,
          286,
          669,
          1919,
          295,
          439,
          264,
          3755,
          300,
          286,
          528,
          13,
          51112
        ]
      },
      {
        "avg_logprob": -0.36457127700617287,
        "compression_ratio": 1.375,
        "end": 3895.7200000000003,
        "id": 1146,
        "no_speech_prob": 0.000031692230550106615,
        "seek": 387832,
        "start": 3893.28,
        "temperature": 0,
        "text": " This is actually, I'm going to make this a coding challenge.",
        "tokens": [
          51112,
          639,
          307,
          767,
          11,
          286,
          478,
          516,
          281,
          652,
          341,
          257,
          17720,
          3430,
          13,
          51234
        ]
      },
      {
        "avg_logprob": -0.36457127700617287,
        "compression_ratio": 1.375,
        "end": 3899.2000000000003,
        "id": 1147,
        "no_speech_prob": 0.000031692230550106615,
        "seek": 387832,
        "start": 3895.7200000000003,
        "temperature": 0,
        "text": " Maybe the Sketch RNN stuff will be tutorial-ish with ml5,",
        "tokens": [
          51234,
          2704,
          264,
          49245,
          45702,
          45,
          1507,
          486,
          312,
          7073,
          12,
          742,
          365,
          23271,
          20,
          11,
          51408
        ]
      },
      {
        "avg_logprob": -0.36457127700617287,
        "compression_ratio": 1.375,
        "end": 3901.0800000000004,
        "id": 1148,
        "no_speech_prob": 0.000031692230550106615,
        "seek": 387832,
        "start": 3899.2000000000003,
        "temperature": 0,
        "text": " but OK.",
        "tokens": [
          51408,
          457,
          2264,
          13,
          51502
        ]
      },
      {
        "avg_logprob": -0.36457127700617287,
        "compression_ratio": 1.375,
        "end": 3907.6400000000003,
        "id": 1149,
        "no_speech_prob": 0.000031692230550106615,
        "seek": 387832,
        "start": 3906.4,
        "temperature": 0,
        "text": " Well, I don't know what to do.",
        "tokens": [
          51768,
          1042,
          11,
          286,
          500,
          380,
          458,
          437,
          281,
          360,
          13,
          51830
        ]
      },
      {
        "avg_logprob": -0.4557740218996063,
        "compression_ratio": 1.606060606060606,
        "end": 3909.4,
        "id": 1150,
        "no_speech_prob": 0.00024155757273547351,
        "seek": 390764,
        "start": 3907.64,
        "temperature": 0,
        "text": " I'm going to make this a coding challenge.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          652,
          341,
          257,
          17720,
          3430,
          13,
          50452
        ]
      },
      {
        "avg_logprob": -0.4557740218996063,
        "compression_ratio": 1.606060606060606,
        "end": 3911.8799999999997,
        "id": 1151,
        "no_speech_prob": 0.00024155757273547351,
        "seek": 390764,
        "start": 3909.4,
        "temperature": 0,
        "text": " People watch the coding challenges more than if they're",
        "tokens": [
          50452,
          3432,
          1159,
          264,
          17720,
          4759,
          544,
          813,
          498,
          436,
          434,
          50576
        ]
      },
      {
        "avg_logprob": -0.4557740218996063,
        "compression_ratio": 1.606060606060606,
        "end": 3914.2,
        "id": 1152,
        "no_speech_prob": 0.00024155757273547351,
        "seek": 390764,
        "start": 3911.8799999999997,
        "temperature": 0,
        "text": " in the tutorial videos.",
        "tokens": [
          50576,
          294,
          264,
          7073,
          2145,
          13,
          50692
        ]
      },
      {
        "avg_logprob": -0.4557740218996063,
        "compression_ratio": 1.606060606060606,
        "end": 3914.8799999999997,
        "id": 1153,
        "no_speech_prob": 0.00024155757273547351,
        "seek": 390764,
        "start": 3914.2,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50692,
          2264,
          13,
          50726
        ]
      },
      {
        "avg_logprob": -0.4557740218996063,
        "compression_ratio": 1.606060606060606,
        "end": 3916.46,
        "id": 1154,
        "no_speech_prob": 0.00024155757273547351,
        "seek": 390764,
        "start": 3914.8799999999997,
        "temperature": 0,
        "text": " I'm just trying to do my stretching,",
        "tokens": [
          50726,
          286,
          478,
          445,
          1382,
          281,
          360,
          452,
          19632,
          11,
          50805
        ]
      },
      {
        "avg_logprob": -0.4557740218996063,
        "compression_ratio": 1.606060606060606,
        "end": 3918.2,
        "id": 1155,
        "no_speech_prob": 0.00024155757273547351,
        "seek": 390764,
        "start": 3916.46,
        "temperature": 0,
        "text": " because my back issues.",
        "tokens": [
          50805,
          570,
          452,
          646,
          2663,
          13,
          50892
        ]
      },
      {
        "avg_logprob": -0.4557740218996063,
        "compression_ratio": 1.606060606060606,
        "end": 3918.7,
        "id": 1156,
        "no_speech_prob": 0.00024155757273547351,
        "seek": 390764,
        "start": 3918.2,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50892,
          2264,
          13,
          50917
        ]
      },
      {
        "avg_logprob": -0.4557740218996063,
        "compression_ratio": 1.606060606060606,
        "end": 3923.56,
        "id": 1157,
        "no_speech_prob": 0.00024155757273547351,
        "seek": 390764,
        "start": 3922.08,
        "temperature": 0,
        "text": " Woof, woof.",
        "tokens": [
          51086,
          10468,
          69,
          11,
          21657,
          69,
          13,
          51160
        ]
      },
      {
        "avg_logprob": -0.4557740218996063,
        "compression_ratio": 1.606060606060606,
        "end": 3924.3599999999997,
        "id": 1158,
        "no_speech_prob": 0.00024155757273547351,
        "seek": 390764,
        "start": 3923.56,
        "temperature": 0,
        "text": " You know?",
        "tokens": [
          51160,
          509,
          458,
          30,
          51200
        ]
      },
      {
        "avg_logprob": -0.4557740218996063,
        "compression_ratio": 1.606060606060606,
        "end": 3925.08,
        "id": 1159,
        "no_speech_prob": 0.00024155757273547351,
        "seek": 390764,
        "start": 3924.3599999999997,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          51200,
          6962,
          322,
          13,
          51236
        ]
      },
      {
        "avg_logprob": -0.4557740218996063,
        "compression_ratio": 1.606060606060606,
        "end": 3926.44,
        "id": 1160,
        "no_speech_prob": 0.00024155757273547351,
        "seek": 390764,
        "start": 3925.08,
        "temperature": 0,
        "text": " Matthew.",
        "tokens": [
          51236,
          6789,
          3322,
          86,
          13,
          51304
        ]
      },
      {
        "avg_logprob": -0.4557740218996063,
        "compression_ratio": 1.606060606060606,
        "end": 3927.16,
        "id": 1161,
        "no_speech_prob": 0.00024155757273547351,
        "seek": 390764,
        "start": 3926.44,
        "temperature": 0,
        "text": " I'll make a thumb.",
        "tokens": [
          51304,
          286,
          603,
          652,
          257,
          9298,
          13,
          51340
        ]
      },
      {
        "avg_logprob": -0.4557740218996063,
        "compression_ratio": 1.606060606060606,
        "end": 3928.8199999999997,
        "id": 1162,
        "no_speech_prob": 0.00024155757273547351,
        "seek": 390764,
        "start": 3927.16,
        "temperature": 0,
        "text": " I better make a good thumbnail for this.",
        "tokens": [
          51340,
          286,
          1101,
          652,
          257,
          665,
          26746,
          337,
          341,
          13,
          51423
        ]
      },
      {
        "avg_logprob": -0.4557740218996063,
        "compression_ratio": 1.606060606060606,
        "end": 3931.64,
        "id": 1163,
        "no_speech_prob": 0.00024155757273547351,
        "seek": 390764,
        "start": 3928.8199999999997,
        "temperature": 0,
        "text": " Remind me to make some thumbnails.",
        "tokens": [
          51423,
          4080,
          471,
          385,
          281,
          652,
          512,
          46987,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.4557740218996063,
        "compression_ratio": 1.606060606060606,
        "end": 3933.7599999999998,
        "id": 1164,
        "no_speech_prob": 0.00024155757273547351,
        "seek": 390764,
        "start": 3931.64,
        "temperature": 0,
        "text": " I mean, just like pose with the results.",
        "tokens": [
          51564,
          286,
          914,
          11,
          445,
          411,
          10774,
          365,
          264,
          3542,
          13,
          51670
        ]
      },
      {
        "avg_logprob": -0.4557740218996063,
        "compression_ratio": 1.606060606060606,
        "end": 3934.2599999999998,
        "id": 1165,
        "no_speech_prob": 0.00024155757273547351,
        "seek": 390764,
        "start": 3933.7599999999998,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51670,
          2264,
          13,
          51695
        ]
      },
      {
        "avg_logprob": -0.41474038303488553,
        "compression_ratio": 1.4968152866242037,
        "end": 3940.12,
        "id": 1166,
        "no_speech_prob": 0.001700662076473236,
        "seek": 393764,
        "start": 3937.64,
        "temperature": 0,
        "text": " Woof, woof.",
        "tokens": [
          50364,
          10468,
          69,
          11,
          21657,
          69,
          13,
          50488
        ]
      },
      {
        "avg_logprob": -0.41474038303488553,
        "compression_ratio": 1.4968152866242037,
        "end": 3940.62,
        "id": 1167,
        "no_speech_prob": 0.001700662076473236,
        "seek": 393764,
        "start": 3940.12,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50488,
          2264,
          13,
          50513
        ]
      },
      {
        "avg_logprob": -0.41474038303488553,
        "compression_ratio": 1.4968152866242037,
        "end": 3946.7599999999998,
        "id": 1168,
        "no_speech_prob": 0.001700662076473236,
        "seek": 393764,
        "start": 3945,
        "temperature": 0,
        "text": " Hello, and welcome to a coding challenge.",
        "tokens": [
          50732,
          2425,
          11,
          293,
          2928,
          281,
          257,
          17720,
          3430,
          13,
          50820
        ]
      },
      {
        "avg_logprob": -0.41474038303488553,
        "compression_ratio": 1.4968152866242037,
        "end": 3947.08,
        "id": 1169,
        "no_speech_prob": 0.001700662076473236,
        "seek": 393764,
        "start": 3946.7599999999998,
        "temperature": 0,
        "text": " Actually, you know what?",
        "tokens": [
          50820,
          5135,
          11,
          291,
          458,
          437,
          30,
          50836
        ]
      },
      {
        "avg_logprob": -0.41474038303488553,
        "compression_ratio": 1.4968152866242037,
        "end": 3947.92,
        "id": 1170,
        "no_speech_prob": 0.001700662076473236,
        "seek": 393764,
        "start": 3947.08,
        "temperature": 0,
        "text": " No, no, no, no, no.",
        "tokens": [
          50836,
          883,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          13,
          50878
        ]
      },
      {
        "avg_logprob": -0.41474038303488553,
        "compression_ratio": 1.4968152866242037,
        "end": 3948.7999999999997,
        "id": 1171,
        "no_speech_prob": 0.001700662076473236,
        "seek": 393764,
        "start": 3947.92,
        "temperature": 0,
        "text": " No, no, no, no, no.",
        "tokens": [
          50878,
          883,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          13,
          50922
        ]
      },
      {
        "avg_logprob": -0.41474038303488553,
        "compression_ratio": 1.4968152866242037,
        "end": 3951.44,
        "id": 1172,
        "no_speech_prob": 0.001700662076473236,
        "seek": 393764,
        "start": 3948.7999999999997,
        "temperature": 0,
        "text": " This is what it's going to be.",
        "tokens": [
          50922,
          639,
          307,
          437,
          309,
          311,
          516,
          281,
          312,
          13,
          51054
        ]
      },
      {
        "avg_logprob": -0.41474038303488553,
        "compression_ratio": 1.4968152866242037,
        "end": 3951.92,
        "id": 1173,
        "no_speech_prob": 0.001700662076473236,
        "seek": 393764,
        "start": 3951.44,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51054,
          2264,
          13,
          51078
        ]
      },
      {
        "avg_logprob": -0.41474038303488553,
        "compression_ratio": 1.4968152866242037,
        "end": 3953.6,
        "id": 1174,
        "no_speech_prob": 0.001700662076473236,
        "seek": 393764,
        "start": 3951.92,
        "temperature": 0,
        "text": " I'm going to start with this behind me.",
        "tokens": [
          51078,
          286,
          478,
          516,
          281,
          722,
          365,
          341,
          2261,
          385,
          13,
          51162
        ]
      },
      {
        "avg_logprob": -0.41474038303488553,
        "compression_ratio": 1.4968152866242037,
        "end": 3954.1,
        "id": 1175,
        "no_speech_prob": 0.001700662076473236,
        "seek": 393764,
        "start": 3953.6,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51162,
          2264,
          13,
          51187
        ]
      },
      {
        "avg_logprob": -0.41474038303488553,
        "compression_ratio": 1.4968152866242037,
        "end": 3959.8799999999997,
        "id": 1176,
        "no_speech_prob": 0.001700662076473236,
        "seek": 393764,
        "start": 3958.7599999999998,
        "temperature": 0,
        "text": " Can I do a grand entrance?",
        "tokens": [
          51420,
          1664,
          286,
          360,
          257,
          2697,
          12014,
          30,
          51476
        ]
      },
      {
        "avg_logprob": -0.41474038303488553,
        "compression_ratio": 1.4968152866242037,
        "end": 3966.04,
        "id": 1177,
        "no_speech_prob": 0.001700662076473236,
        "seek": 393764,
        "start": 3963.56,
        "temperature": 0,
        "text": " Hello.",
        "tokens": [
          51660,
          2425,
          13,
          51784
        ]
      },
      {
        "avg_logprob": -0.2586950533317797,
        "compression_ratio": 1.7234042553191489,
        "end": 3969.64,
        "id": 1178,
        "no_speech_prob": 0.0003250303561799228,
        "seek": 396604,
        "start": 3966.04,
        "temperature": 0,
        "text": " Hello, and welcome to a coding challenge, quick draw edition.",
        "tokens": [
          50364,
          2425,
          11,
          293,
          2928,
          281,
          257,
          17720,
          3430,
          11,
          1702,
          2642,
          11377,
          13,
          50544
        ]
      },
      {
        "avg_logprob": -0.2586950533317797,
        "compression_ratio": 1.7234042553191489,
        "end": 3972.6,
        "id": 1179,
        "no_speech_prob": 0.0003250303561799228,
        "seek": 396604,
        "start": 3969.64,
        "temperature": 0,
        "text": " Now, I have been talking about doing this for a very long time,",
        "tokens": [
          50544,
          823,
          11,
          286,
          362,
          668,
          1417,
          466,
          884,
          341,
          337,
          257,
          588,
          938,
          565,
          11,
          50692
        ]
      },
      {
        "avg_logprob": -0.2586950533317797,
        "compression_ratio": 1.7234042553191489,
        "end": 3974.68,
        "id": 1180,
        "no_speech_prob": 0.0003250303561799228,
        "seek": 396604,
        "start": 3972.6,
        "temperature": 0,
        "text": " and I'm excited to finally try this on my channel.",
        "tokens": [
          50692,
          293,
          286,
          478,
          2919,
          281,
          2721,
          853,
          341,
          322,
          452,
          2269,
          13,
          50796
        ]
      },
      {
        "avg_logprob": -0.2586950533317797,
        "compression_ratio": 1.7234042553191489,
        "end": 3977.2799999999997,
        "id": 1181,
        "no_speech_prob": 0.0003250303561799228,
        "seek": 396604,
        "start": 3974.68,
        "temperature": 0,
        "text": " One of my favorite data sets that is out there in the world",
        "tokens": [
          50796,
          1485,
          295,
          452,
          2954,
          1412,
          6352,
          300,
          307,
          484,
          456,
          294,
          264,
          1002,
          50926
        ]
      },
      {
        "avg_logprob": -0.2586950533317797,
        "compression_ratio": 1.7234042553191489,
        "end": 3978.96,
        "id": 1182,
        "no_speech_prob": 0.0003250303561799228,
        "seek": 396604,
        "start": 3977.2799999999997,
        "temperature": 0,
        "text": " is the quick draw data set.",
        "tokens": [
          50926,
          307,
          264,
          1702,
          2642,
          1412,
          992,
          13,
          51010
        ]
      },
      {
        "avg_logprob": -0.2586950533317797,
        "compression_ratio": 1.7234042553191489,
        "end": 3980.96,
        "id": 1183,
        "no_speech_prob": 0.0003250303561799228,
        "seek": 396604,
        "start": 3978.96,
        "temperature": 0,
        "text": " Now, here's the reason.",
        "tokens": [
          51010,
          823,
          11,
          510,
          311,
          264,
          1778,
          13,
          51110
        ]
      },
      {
        "avg_logprob": -0.2586950533317797,
        "compression_ratio": 1.7234042553191489,
        "end": 3983.72,
        "id": 1184,
        "no_speech_prob": 0.0003250303561799228,
        "seek": 396604,
        "start": 3980.96,
        "temperature": 0,
        "text": " One of the reasons why I'm interested in this is not just",
        "tokens": [
          51110,
          1485,
          295,
          264,
          4112,
          983,
          286,
          478,
          3102,
          294,
          341,
          307,
          406,
          445,
          51248
        ]
      },
      {
        "avg_logprob": -0.2586950533317797,
        "compression_ratio": 1.7234042553191489,
        "end": 3986.16,
        "id": 1185,
        "no_speech_prob": 0.0003250303561799228,
        "seek": 396604,
        "start": 3983.72,
        "temperature": 0,
        "text": " this data set of 50 million drawings, which",
        "tokens": [
          51248,
          341,
          1412,
          992,
          295,
          2625,
          2459,
          18618,
          11,
          597,
          51370
        ]
      },
      {
        "avg_logprob": -0.2586950533317797,
        "compression_ratio": 1.7234042553191489,
        "end": 3988.56,
        "id": 1186,
        "no_speech_prob": 0.0003250303561799228,
        "seek": 396604,
        "start": 3986.16,
        "temperature": 0,
        "text": " is interesting and fun to play with on its own,",
        "tokens": [
          51370,
          307,
          1880,
          293,
          1019,
          281,
          862,
          365,
          322,
          1080,
          1065,
          11,
          51490
        ]
      },
      {
        "avg_logprob": -0.2586950533317797,
        "compression_ratio": 1.7234042553191489,
        "end": 3992.7,
        "id": 1187,
        "no_speech_prob": 0.0003250303561799228,
        "seek": 396604,
        "start": 3988.56,
        "temperature": 0,
        "text": " but there is something called Sketch RNN, which",
        "tokens": [
          51490,
          457,
          456,
          307,
          746,
          1219,
          49245,
          45702,
          45,
          11,
          597,
          51697
        ]
      },
      {
        "avg_logprob": -0.24273042900617733,
        "compression_ratio": 1.7,
        "end": 3996.02,
        "id": 1188,
        "no_speech_prob": 0.00353805348277092,
        "seek": 399270,
        "start": 3992.7,
        "temperature": 0,
        "text": " was developed by a set of researchers at Google,",
        "tokens": [
          50364,
          390,
          4743,
          538,
          257,
          992,
          295,
          10309,
          412,
          3329,
          11,
          50530
        ]
      },
      {
        "avg_logprob": -0.24273042900617733,
        "compression_ratio": 1.7,
        "end": 3996.7799999999997,
        "id": 1189,
        "no_speech_prob": 0.00353805348277092,
        "seek": 399270,
        "start": 3996.02,
        "temperature": 0,
        "text": " Google Brain.",
        "tokens": [
          50530,
          3329,
          29783,
          13,
          50568
        ]
      },
      {
        "avg_logprob": -0.24273042900617733,
        "compression_ratio": 1.7,
        "end": 4000.02,
        "id": 1190,
        "no_speech_prob": 0.00353805348277092,
        "seek": 399270,
        "start": 3996.7799999999997,
        "temperature": 0,
        "text": " And you can see some of them here, who wrote this paper,",
        "tokens": [
          50568,
          400,
          291,
          393,
          536,
          512,
          295,
          552,
          510,
          11,
          567,
          4114,
          341,
          3035,
          11,
          50730
        ]
      },
      {
        "avg_logprob": -0.24273042900617733,
        "compression_ratio": 1.7,
        "end": 4004.4199999999996,
        "id": 1191,
        "no_speech_prob": 0.00353805348277092,
        "seek": 399270,
        "start": 4000.02,
        "temperature": 0,
        "text": " and explained how Sketch RNN is a neural network,",
        "tokens": [
          50730,
          293,
          8825,
          577,
          49245,
          45702,
          45,
          307,
          257,
          18161,
          3209,
          11,
          50950
        ]
      },
      {
        "avg_logprob": -0.24273042900617733,
        "compression_ratio": 1.7,
        "end": 4006.8999999999996,
        "id": 1192,
        "no_speech_prob": 0.00353805348277092,
        "seek": 399270,
        "start": 4004.4199999999996,
        "temperature": 0,
        "text": " a recurrent neural network, that learned",
        "tokens": [
          50950,
          257,
          18680,
          1753,
          18161,
          3209,
          11,
          300,
          3264,
          51074
        ]
      },
      {
        "avg_logprob": -0.24273042900617733,
        "compression_ratio": 1.7,
        "end": 4010.8599999999997,
        "id": 1193,
        "no_speech_prob": 0.00353805348277092,
        "seek": 399270,
        "start": 4006.8999999999996,
        "temperature": 0,
        "text": " about how to draw various things from the quick draw data set,",
        "tokens": [
          51074,
          466,
          577,
          281,
          2642,
          3683,
          721,
          490,
          264,
          1702,
          2642,
          1412,
          992,
          11,
          51272
        ]
      },
      {
        "avg_logprob": -0.24273042900617733,
        "compression_ratio": 1.7,
        "end": 4014.66,
        "id": 1194,
        "no_speech_prob": 0.00353805348277092,
        "seek": 399270,
        "start": 4010.8599999999997,
        "temperature": 0,
        "text": " and then can try and imagine and create new drawings based",
        "tokens": [
          51272,
          293,
          550,
          393,
          853,
          293,
          3811,
          293,
          1884,
          777,
          18618,
          2361,
          51462
        ]
      },
      {
        "avg_logprob": -0.24273042900617733,
        "compression_ratio": 1.7,
        "end": 4017.22,
        "id": 1195,
        "no_speech_prob": 0.00353805348277092,
        "seek": 399270,
        "start": 4014.66,
        "temperature": 0,
        "text": " on how it learned, and can even interact and draw with you.",
        "tokens": [
          51462,
          322,
          577,
          309,
          3264,
          11,
          293,
          393,
          754,
          4648,
          293,
          2642,
          365,
          291,
          13,
          51590
        ]
      },
      {
        "avg_logprob": -0.24273042900617733,
        "compression_ratio": 1.7,
        "end": 4018.3399999999997,
        "id": 1196,
        "no_speech_prob": 0.00353805348277092,
        "seek": 399270,
        "start": 4017.22,
        "temperature": 0,
        "text": " So many possibilities.",
        "tokens": [
          51590,
          407,
          867,
          12178,
          13,
          51646
        ]
      },
      {
        "avg_logprob": -0.24273042900617733,
        "compression_ratio": 1.7,
        "end": 4019.8599999999997,
        "id": 1197,
        "no_speech_prob": 0.00353805348277092,
        "seek": 399270,
        "start": 4018.3399999999997,
        "temperature": 0,
        "text": " So this is where I'm going with this.",
        "tokens": [
          51646,
          407,
          341,
          307,
          689,
          286,
          478,
          516,
          365,
          341,
          13,
          51722
        ]
      },
      {
        "avg_logprob": -0.24273042900617733,
        "compression_ratio": 1.7,
        "end": 4021.06,
        "id": 1198,
        "no_speech_prob": 0.00353805348277092,
        "seek": 399270,
        "start": 4019.8599999999997,
        "temperature": 0,
        "text": " I am going to make it.",
        "tokens": [
          51722,
          286,
          669,
          516,
          281,
          652,
          309,
          13,
          51782
        ]
      },
      {
        "avg_logprob": -0.24276415506998697,
        "compression_ratio": 1.5818815331010454,
        "end": 4024.74,
        "id": 1199,
        "no_speech_prob": 0.00005829093061038293,
        "seek": 402106,
        "start": 4021.06,
        "temperature": 0,
        "text": " Sketch RNN has recently been added to the ML5 library.",
        "tokens": [
          50364,
          49245,
          45702,
          45,
          575,
          3938,
          668,
          3869,
          281,
          264,
          21601,
          20,
          6405,
          13,
          50548
        ]
      },
      {
        "avg_logprob": -0.24276415506998697,
        "compression_ratio": 1.5818815331010454,
        "end": 4028.62,
        "id": 1200,
        "no_speech_prob": 0.00005829093061038293,
        "seek": 402106,
        "start": 4024.74,
        "temperature": 0,
        "text": " And I'm going to show you an example.",
        "tokens": [
          50548,
          400,
          286,
          478,
          516,
          281,
          855,
          291,
          364,
          1365,
          13,
          50742
        ]
      },
      {
        "avg_logprob": -0.24276415506998697,
        "compression_ratio": 1.5818815331010454,
        "end": 4030.54,
        "id": 1201,
        "no_speech_prob": 0.00005829093061038293,
        "seek": 402106,
        "start": 4028.62,
        "temperature": 0,
        "text": " And I'm going to build that with Sketch RNN ML5.",
        "tokens": [
          50742,
          400,
          286,
          478,
          516,
          281,
          1322,
          300,
          365,
          49245,
          45702,
          45,
          21601,
          20,
          13,
          50838
        ]
      },
      {
        "avg_logprob": -0.24276415506998697,
        "compression_ratio": 1.5818815331010454,
        "end": 4034.18,
        "id": 1202,
        "no_speech_prob": 0.00005829093061038293,
        "seek": 402106,
        "start": 4030.54,
        "temperature": 0,
        "text": " But I feel like before we start making",
        "tokens": [
          50838,
          583,
          286,
          841,
          411,
          949,
          321,
          722,
          1455,
          51020
        ]
      },
      {
        "avg_logprob": -0.24276415506998697,
        "compression_ratio": 1.5818815331010454,
        "end": 4036.7,
        "id": 1203,
        "no_speech_prob": 0.00005829093061038293,
        "seek": 402106,
        "start": 4034.18,
        "temperature": 0,
        "text": " the artificially intelligent system that",
        "tokens": [
          51020,
          264,
          39905,
          2270,
          13232,
          1185,
          300,
          51146
        ]
      },
      {
        "avg_logprob": -0.24276415506998697,
        "compression_ratio": 1.5818815331010454,
        "end": 4040.62,
        "id": 1204,
        "no_speech_prob": 0.00005829093061038293,
        "seek": 402106,
        "start": 4036.7,
        "temperature": 0,
        "text": " generates the drawings, let's look at the actual data itself",
        "tokens": [
          51146,
          23815,
          264,
          18618,
          11,
          718,
          311,
          574,
          412,
          264,
          3539,
          1412,
          2564,
          51342
        ]
      },
      {
        "avg_logprob": -0.24276415506998697,
        "compression_ratio": 1.5818815331010454,
        "end": 4041.58,
        "id": 1205,
        "no_speech_prob": 0.00005829093061038293,
        "seek": 402106,
        "start": 4040.62,
        "temperature": 0,
        "text": " that it was trained on.",
        "tokens": [
          51342,
          300,
          309,
          390,
          8895,
          322,
          13,
          51390
        ]
      },
      {
        "avg_logprob": -0.24276415506998697,
        "compression_ratio": 1.5818815331010454,
        "end": 4044.98,
        "id": 1206,
        "no_speech_prob": 0.00005829093061038293,
        "seek": 402106,
        "start": 4041.58,
        "temperature": 0,
        "text": " So first, where did that data come from?",
        "tokens": [
          51390,
          407,
          700,
          11,
          689,
          630,
          300,
          1412,
          808,
          490,
          30,
          51560
        ]
      },
      {
        "avg_logprob": -0.24276415506998697,
        "compression_ratio": 1.5818815331010454,
        "end": 4046.58,
        "id": 1207,
        "no_speech_prob": 0.00005829093061038293,
        "seek": 402106,
        "start": 4044.98,
        "temperature": 0,
        "text": " And apologies if I get anything wrong.",
        "tokens": [
          51560,
          400,
          34929,
          498,
          286,
          483,
          1340,
          2085,
          13,
          51640
        ]
      },
      {
        "avg_logprob": -0.24276415506998697,
        "compression_ratio": 1.5818815331010454,
        "end": 4048.66,
        "id": 1208,
        "no_speech_prob": 0.00005829093061038293,
        "seek": 402106,
        "start": 4046.58,
        "temperature": 0,
        "text": " Please let me know in the comments.",
        "tokens": [
          51640,
          2555,
          718,
          385,
          458,
          294,
          264,
          3053,
          13,
          51744
        ]
      },
      {
        "avg_logprob": -0.24276415506998697,
        "compression_ratio": 1.5818815331010454,
        "end": 4049.94,
        "id": 1209,
        "no_speech_prob": 0.00005829093061038293,
        "seek": 402106,
        "start": 4048.66,
        "temperature": 0,
        "text": " Because this is not my project.",
        "tokens": [
          51744,
          1436,
          341,
          307,
          406,
          452,
          1716,
          13,
          51808
        ]
      },
      {
        "avg_logprob": -0.3081623635640958,
        "compression_ratio": 1.6560283687943262,
        "end": 4052.18,
        "id": 1210,
        "no_speech_prob": 0.00035695507540367544,
        "seek": 404994,
        "start": 4049.94,
        "temperature": 0,
        "text": " I am just inspired and enthused by it.",
        "tokens": [
          50364,
          286,
          669,
          445,
          7547,
          293,
          948,
          71,
          4717,
          538,
          309,
          13,
          50476
        ]
      },
      {
        "avg_logprob": -0.3081623635640958,
        "compression_ratio": 1.6560283687943262,
        "end": 4055.94,
        "id": 1211,
        "no_speech_prob": 0.00035695507540367544,
        "seek": 404994,
        "start": 4052.18,
        "temperature": 0,
        "text": " So the quick draw project is a project, an AI experiment,",
        "tokens": [
          50476,
          407,
          264,
          1702,
          2642,
          1716,
          307,
          257,
          1716,
          11,
          364,
          7318,
          5120,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.3081623635640958,
        "compression_ratio": 1.6560283687943262,
        "end": 4057.78,
        "id": 1212,
        "no_speech_prob": 0.00035695507540367544,
        "seek": 404994,
        "start": 4055.94,
        "temperature": 0,
        "text": " made by friends from Google.",
        "tokens": [
          50664,
          1027,
          538,
          1855,
          490,
          3329,
          13,
          50756
        ]
      },
      {
        "avg_logprob": -0.3081623635640958,
        "compression_ratio": 1.6560283687943262,
        "end": 4061.26,
        "id": 1213,
        "no_speech_prob": 0.00035695507540367544,
        "seek": 404994,
        "start": 4057.78,
        "temperature": 0,
        "text": " And it is a game that you could play, where you say,",
        "tokens": [
          50756,
          400,
          309,
          307,
          257,
          1216,
          300,
          291,
          727,
          862,
          11,
          689,
          291,
          584,
          11,
          50930
        ]
      },
      {
        "avg_logprob": -0.3081623635640958,
        "compression_ratio": 1.6560283687943262,
        "end": 4062.82,
        "id": 1214,
        "no_speech_prob": 0.00035695507540367544,
        "seek": 404994,
        "start": 4061.26,
        "temperature": 0,
        "text": " draw a pencil in under 20 seconds.",
        "tokens": [
          50930,
          2642,
          257,
          10985,
          294,
          833,
          945,
          3949,
          13,
          51008
        ]
      },
      {
        "avg_logprob": -0.3081623635640958,
        "compression_ratio": 1.6560283687943262,
        "end": 4063.42,
        "id": 1215,
        "no_speech_prob": 0.00035695507540367544,
        "seek": 404994,
        "start": 4062.82,
        "temperature": 0,
        "text": " OK, here we go.",
        "tokens": [
          51008,
          2264,
          11,
          510,
          321,
          352,
          13,
          51038
        ]
      },
      {
        "avg_logprob": -0.3081623635640958,
        "compression_ratio": 1.6560283687943262,
        "end": 4064.62,
        "id": 1216,
        "no_speech_prob": 0.00035695507540367544,
        "seek": 404994,
        "start": 4063.42,
        "temperature": 0,
        "text": " Ooh, doo, doo, doo.",
        "tokens": [
          51038,
          7951,
          11,
          27572,
          11,
          27572,
          11,
          27572,
          13,
          51098
        ]
      },
      {
        "avg_logprob": -0.3081623635640958,
        "compression_ratio": 1.6560283687943262,
        "end": 4066.86,
        "id": 1217,
        "no_speech_prob": 0.00035695507540367544,
        "seek": 404994,
        "start": 4064.62,
        "temperature": 0,
        "text": " I see marker, or lipstick, or crayon.",
        "tokens": [
          51098,
          286,
          536,
          15247,
          11,
          420,
          22543,
          11,
          420,
          33073,
          266,
          13,
          51210
        ]
      },
      {
        "avg_logprob": -0.3081623635640958,
        "compression_ratio": 1.6560283687943262,
        "end": 4067.86,
        "id": 1218,
        "no_speech_prob": 0.00035695507540367544,
        "seek": 404994,
        "start": 4066.86,
        "temperature": 0,
        "text": " No.",
        "tokens": [
          51210,
          883,
          13,
          51260
        ]
      },
      {
        "avg_logprob": -0.3081623635640958,
        "compression_ratio": 1.6560283687943262,
        "end": 4069.26,
        "id": 1219,
        "no_speech_prob": 0.00035695507540367544,
        "seek": 404994,
        "start": 4067.86,
        "temperature": 0,
        "text": " No, that's not really like a pencil.",
        "tokens": [
          51260,
          883,
          11,
          300,
          311,
          406,
          534,
          411,
          257,
          10985,
          13,
          51330
        ]
      },
      {
        "avg_logprob": -0.3081623635640958,
        "compression_ratio": 1.6560283687943262,
        "end": 4071.02,
        "id": 1220,
        "no_speech_prob": 0.00035695507540367544,
        "seek": 404994,
        "start": 4069.26,
        "temperature": 0,
        "text": " Is it if I put an eraser here?",
        "tokens": [
          51330,
          1119,
          309,
          498,
          286,
          829,
          364,
          46018,
          510,
          30,
          51418
        ]
      },
      {
        "avg_logprob": -0.3081623635640958,
        "compression_ratio": 1.6560283687943262,
        "end": 4071.86,
        "id": 1221,
        "no_speech_prob": 0.00035695507540367544,
        "seek": 404994,
        "start": 4071.02,
        "temperature": 0,
        "text": " I see rocket.",
        "tokens": [
          51418,
          286,
          536,
          13012,
          13,
          51460
        ]
      },
      {
        "avg_logprob": -0.3081623635640958,
        "compression_ratio": 1.6560283687943262,
        "end": 4072.78,
        "id": 1222,
        "no_speech_prob": 0.00035695507540367544,
        "seek": 404994,
        "start": 4071.86,
        "temperature": 0,
        "text": " No, rocket.",
        "tokens": [
          51460,
          883,
          11,
          13012,
          13,
          51506
        ]
      },
      {
        "avg_logprob": -0.3081623635640958,
        "compression_ratio": 1.6560283687943262,
        "end": 4074.54,
        "id": 1223,
        "no_speech_prob": 0.00035695507540367544,
        "seek": 404994,
        "start": 4072.78,
        "temperature": 0,
        "text": " I'm the worst.",
        "tokens": [
          51506,
          286,
          478,
          264,
          5855,
          13,
          51594
        ]
      },
      {
        "avg_logprob": -0.3081623635640958,
        "compression_ratio": 1.6560283687943262,
        "end": 4076.5,
        "id": 1224,
        "no_speech_prob": 0.00035695507540367544,
        "seek": 404994,
        "start": 4074.54,
        "temperature": 0,
        "text": " I'm not sure what that is.",
        "tokens": [
          51594,
          286,
          478,
          406,
          988,
          437,
          300,
          307,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.3081623635640958,
        "compression_ratio": 1.6560283687943262,
        "end": 4079.14,
        "id": 1225,
        "no_speech_prob": 0.00035695507540367544,
        "seek": 404994,
        "start": 4076.5,
        "temperature": 0,
        "text": " Yeah, I don't know what that is either.",
        "tokens": [
          51692,
          865,
          11,
          286,
          500,
          380,
          458,
          437,
          300,
          307,
          2139,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.24802567528896644,
        "compression_ratio": 1.5495867768595042,
        "end": 4082.66,
        "id": 1226,
        "no_speech_prob": 0.000006747963197994977,
        "seek": 407914,
        "start": 4079.18,
        "temperature": 0,
        "text": " Time is running out.",
        "tokens": [
          50366,
          6161,
          307,
          2614,
          484,
          13,
          50540
        ]
      },
      {
        "avg_logprob": -0.24802567528896644,
        "compression_ratio": 1.5495867768595042,
        "end": 4084.06,
        "id": 1227,
        "no_speech_prob": 0.000006747963197994977,
        "seek": 407914,
        "start": 4082.66,
        "temperature": 0,
        "text": " Sorry, I couldn't guess it.",
        "tokens": [
          50540,
          4919,
          11,
          286,
          2809,
          380,
          2041,
          309,
          13,
          50610
        ]
      },
      {
        "avg_logprob": -0.24802567528896644,
        "compression_ratio": 1.5495867768595042,
        "end": 4087.62,
        "id": 1228,
        "no_speech_prob": 0.000006747963197994977,
        "seek": 407914,
        "start": 4084.06,
        "temperature": 0,
        "text": " All right, let's try basketball.",
        "tokens": [
          50610,
          1057,
          558,
          11,
          718,
          311,
          853,
          11767,
          13,
          50788
        ]
      },
      {
        "avg_logprob": -0.24802567528896644,
        "compression_ratio": 1.5495867768595042,
        "end": 4090.74,
        "id": 1229,
        "no_speech_prob": 0.000006747963197994977,
        "seek": 407914,
        "start": 4087.62,
        "temperature": 0,
        "text": " I see nose, or moon, or blueberry, or baseball,",
        "tokens": [
          50788,
          286,
          536,
          6690,
          11,
          420,
          7135,
          11,
          420,
          48243,
          11,
          420,
          14323,
          11,
          50944
        ]
      },
      {
        "avg_logprob": -0.24802567528896644,
        "compression_ratio": 1.5495867768595042,
        "end": 4092.3799999999997,
        "id": 1230,
        "no_speech_prob": 0.000006747963197994977,
        "seek": 407914,
        "start": 4090.74,
        "temperature": 0,
        "text": " or bracelet.",
        "tokens": [
          50944,
          420,
          23021,
          13,
          51026
        ]
      },
      {
        "avg_logprob": -0.24802567528896644,
        "compression_ratio": 1.5495867768595042,
        "end": 4093.22,
        "id": 1231,
        "no_speech_prob": 0.000006747963197994977,
        "seek": 407914,
        "start": 4092.3799999999997,
        "temperature": 0,
        "text": " Oh, I know.",
        "tokens": [
          51026,
          876,
          11,
          286,
          458,
          13,
          51068
        ]
      },
      {
        "avg_logprob": -0.24802567528896644,
        "compression_ratio": 1.5495867768595042,
        "end": 4094.62,
        "id": 1232,
        "no_speech_prob": 0.000006747963197994977,
        "seek": 407914,
        "start": 4093.22,
        "temperature": 0,
        "text": " It's basketball.",
        "tokens": [
          51068,
          467,
          311,
          11767,
          13,
          51138
        ]
      },
      {
        "avg_logprob": -0.24802567528896644,
        "compression_ratio": 1.5495867768595042,
        "end": 4095.7,
        "id": 1233,
        "no_speech_prob": 0.000006747963197994977,
        "seek": 407914,
        "start": 4094.62,
        "temperature": 0,
        "text": " All right, I win.",
        "tokens": [
          51138,
          1057,
          558,
          11,
          286,
          1942,
          13,
          51192
        ]
      },
      {
        "avg_logprob": -0.24802567528896644,
        "compression_ratio": 1.5495867768595042,
        "end": 4096.66,
        "id": 1234,
        "no_speech_prob": 0.000006747963197994977,
        "seek": 407914,
        "start": 4095.7,
        "temperature": 0,
        "text": " OK, so you get the idea.",
        "tokens": [
          51192,
          2264,
          11,
          370,
          291,
          483,
          264,
          1558,
          13,
          51240
        ]
      },
      {
        "avg_logprob": -0.24802567528896644,
        "compression_ratio": 1.5495867768595042,
        "end": 4099.0599999999995,
        "id": 1235,
        "no_speech_prob": 0.000006747963197994977,
        "seek": 407914,
        "start": 4096.66,
        "temperature": 0,
        "text": " I could be stuck here for quite a while.",
        "tokens": [
          51240,
          286,
          727,
          312,
          5541,
          510,
          337,
          1596,
          257,
          1339,
          13,
          51360
        ]
      },
      {
        "avg_logprob": -0.24802567528896644,
        "compression_ratio": 1.5495867768595042,
        "end": 4103.22,
        "id": 1236,
        "no_speech_prob": 0.000006747963197994977,
        "seek": 407914,
        "start": 4099.0599999999995,
        "temperature": 0,
        "text": " Now, when you are playing this game,",
        "tokens": [
          51360,
          823,
          11,
          562,
          291,
          366,
          2433,
          341,
          1216,
          11,
          51568
        ]
      },
      {
        "avg_logprob": -0.24802567528896644,
        "compression_ratio": 1.5495867768595042,
        "end": 4105.58,
        "id": 1237,
        "no_speech_prob": 0.000006747963197994977,
        "seek": 407914,
        "start": 4103.22,
        "temperature": 0,
        "text": " your doodles are being collected.",
        "tokens": [
          51568,
          428,
          360,
          35192,
          366,
          885,
          11087,
          13,
          51686
        ]
      },
      {
        "avg_logprob": -0.24802567528896644,
        "compression_ratio": 1.5495867768595042,
        "end": 4108.98,
        "id": 1238,
        "no_speech_prob": 0.000006747963197994977,
        "seek": 407914,
        "start": 4105.58,
        "temperature": 0,
        "text": " And over 15 millions of players have contributed",
        "tokens": [
          51686,
          400,
          670,
          2119,
          6803,
          295,
          4150,
          362,
          18434,
          51856
        ]
      },
      {
        "avg_logprob": -0.28925978619119397,
        "compression_ratio": 1.8166089965397925,
        "end": 4110.299999999999,
        "id": 1239,
        "no_speech_prob": 0.00009314568160334602,
        "seek": 410898,
        "start": 4108.98,
        "temperature": 0,
        "text": " millions of drawings playing Quick Draw.",
        "tokens": [
          50364,
          6803,
          295,
          18618,
          2433,
          12101,
          20386,
          13,
          50430
        ]
      },
      {
        "avg_logprob": -0.28925978619119397,
        "compression_ratio": 1.8166089965397925,
        "end": 4111.74,
        "id": 1240,
        "no_speech_prob": 0.00009314568160334602,
        "seek": 410898,
        "start": 4110.299999999999,
        "temperature": 0,
        "text": " Oh, and I've used this before.",
        "tokens": [
          50430,
          876,
          11,
          293,
          286,
          600,
          1143,
          341,
          949,
          13,
          50502
        ]
      },
      {
        "avg_logprob": -0.28925978619119397,
        "compression_ratio": 1.8166089965397925,
        "end": 4114.459999999999,
        "id": 1241,
        "no_speech_prob": 0.00009314568160334602,
        "seek": 410898,
        "start": 4111.74,
        "temperature": 0,
        "text": " I made a example with a neural network",
        "tokens": [
          50502,
          286,
          1027,
          257,
          1365,
          365,
          257,
          18161,
          3209,
          50638
        ]
      },
      {
        "avg_logprob": -0.28925978619119397,
        "compression_ratio": 1.8166089965397925,
        "end": 4116.86,
        "id": 1242,
        "no_speech_prob": 0.00009314568160334602,
        "seek": 410898,
        "start": 4114.459999999999,
        "temperature": 0,
        "text": " that tried to recognize your drawing.",
        "tokens": [
          50638,
          300,
          3031,
          281,
          5521,
          428,
          6316,
          13,
          50758
        ]
      },
      {
        "avg_logprob": -0.28925978619119397,
        "compression_ratio": 1.8166089965397925,
        "end": 4118.86,
        "id": 1243,
        "no_speech_prob": 0.00009314568160334602,
        "seek": 410898,
        "start": 4116.86,
        "temperature": 0,
        "text": " This has been done on my channel before.",
        "tokens": [
          50758,
          639,
          575,
          668,
          1096,
          322,
          452,
          2269,
          949,
          13,
          50858
        ]
      },
      {
        "avg_logprob": -0.28925978619119397,
        "compression_ratio": 1.8166089965397925,
        "end": 4120.259999999999,
        "id": 1244,
        "no_speech_prob": 0.00009314568160334602,
        "seek": 410898,
        "start": 4118.86,
        "temperature": 0,
        "text": " But what I haven't actually looked at,",
        "tokens": [
          50858,
          583,
          437,
          286,
          2378,
          380,
          767,
          2956,
          412,
          11,
          50928
        ]
      },
      {
        "avg_logprob": -0.28925978619119397,
        "compression_ratio": 1.8166089965397925,
        "end": 4121.759999999999,
        "id": 1245,
        "no_speech_prob": 0.00009314568160334602,
        "seek": 410898,
        "start": 4120.259999999999,
        "temperature": 0,
        "text": " what I looked at before was I looked",
        "tokens": [
          50928,
          437,
          286,
          2956,
          412,
          949,
          390,
          286,
          2956,
          51003
        ]
      },
      {
        "avg_logprob": -0.28925978619119397,
        "compression_ratio": 1.8166089965397925,
        "end": 4123.5,
        "id": 1246,
        "no_speech_prob": 0.00009314568160334602,
        "seek": 410898,
        "start": 4121.759999999999,
        "temperature": 0,
        "text": " at all the drawings as pixels.",
        "tokens": [
          51003,
          412,
          439,
          264,
          18618,
          382,
          18668,
          13,
          51090
        ]
      },
      {
        "avg_logprob": -0.28925978619119397,
        "compression_ratio": 1.8166089965397925,
        "end": 4126.379999999999,
        "id": 1247,
        "no_speech_prob": 0.00009314568160334602,
        "seek": 410898,
        "start": 4123.5,
        "temperature": 0,
        "text": " What's actually what's interesting about the data",
        "tokens": [
          51090,
          708,
          311,
          767,
          437,
          311,
          1880,
          466,
          264,
          1412,
          51234
        ]
      },
      {
        "avg_logprob": -0.28925978619119397,
        "compression_ratio": 1.8166089965397925,
        "end": 4128.66,
        "id": 1248,
        "no_speech_prob": 0.00009314568160334602,
        "seek": 410898,
        "start": 4126.379999999999,
        "temperature": 0,
        "text": " is that the data, which you can find here,",
        "tokens": [
          51234,
          307,
          300,
          264,
          1412,
          11,
          597,
          291,
          393,
          915,
          510,
          11,
          51348
        ]
      },
      {
        "avg_logprob": -0.28925978619119397,
        "compression_ratio": 1.8166089965397925,
        "end": 4131.7,
        "id": 1249,
        "no_speech_prob": 0.00009314568160334602,
        "seek": 410898,
        "start": 4128.66,
        "temperature": 0,
        "text": " information about it on GitHub, is not pixels.",
        "tokens": [
          51348,
          1589,
          466,
          309,
          322,
          23331,
          11,
          307,
          406,
          18668,
          13,
          51500
        ]
      },
      {
        "avg_logprob": -0.28925978619119397,
        "compression_ratio": 1.8166089965397925,
        "end": 4135.82,
        "id": 1250,
        "no_speech_prob": 0.00009314568160334602,
        "seek": 410898,
        "start": 4131.7,
        "temperature": 0,
        "text": " It's actually the pixel paths of the people making the drawings",
        "tokens": [
          51500,
          467,
          311,
          767,
          264,
          19261,
          14518,
          295,
          264,
          561,
          1455,
          264,
          18618,
          51706
        ]
      },
      {
        "avg_logprob": -0.28925978619119397,
        "compression_ratio": 1.8166089965397925,
        "end": 4137.98,
        "id": 1251,
        "no_speech_prob": 0.00009314568160334602,
        "seek": 410898,
        "start": 4135.82,
        "temperature": 0,
        "text": " with timing information.",
        "tokens": [
          51706,
          365,
          10822,
          1589,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2373205820719401,
        "compression_ratio": 1.6877637130801688,
        "end": 4142.459999999999,
        "id": 1252,
        "no_speech_prob": 0.00007141866808524355,
        "seek": 413798,
        "start": 4137.98,
        "temperature": 0,
        "text": " So you could load that data and replay any drawing back.",
        "tokens": [
          50364,
          407,
          291,
          727,
          3677,
          300,
          1412,
          293,
          23836,
          604,
          6316,
          646,
          13,
          50588
        ]
      },
      {
        "avg_logprob": -0.2373205820719401,
        "compression_ratio": 1.6877637130801688,
        "end": 4148.179999999999,
        "id": 1253,
        "no_speech_prob": 0.00007141866808524355,
        "seek": 413798,
        "start": 4142.459999999999,
        "temperature": 0,
        "text": " And each drawing has the word that was associated with it,",
        "tokens": [
          50588,
          400,
          1184,
          6316,
          575,
          264,
          1349,
          300,
          390,
          6615,
          365,
          309,
          11,
          50874
        ]
      },
      {
        "avg_logprob": -0.2373205820719401,
        "compression_ratio": 1.6877637130801688,
        "end": 4150.299999999999,
        "id": 1254,
        "no_speech_prob": 0.00007141866808524355,
        "seek": 413798,
        "start": 4148.179999999999,
        "temperature": 0,
        "text": " the country where the person is from who drew it,",
        "tokens": [
          50874,
          264,
          1941,
          689,
          264,
          954,
          307,
          490,
          567,
          12804,
          309,
          11,
          50980
        ]
      },
      {
        "avg_logprob": -0.2373205820719401,
        "compression_ratio": 1.6877637130801688,
        "end": 4152.0599999999995,
        "id": 1255,
        "no_speech_prob": 0.00007141866808524355,
        "seek": 413798,
        "start": 4150.299999999999,
        "temperature": 0,
        "text": " at least the IP address presumably,",
        "tokens": [
          50980,
          412,
          1935,
          264,
          8671,
          2985,
          26742,
          11,
          51068
        ]
      },
      {
        "avg_logprob": -0.2373205820719401,
        "compression_ratio": 1.6877637130801688,
        "end": 4154.04,
        "id": 1256,
        "no_speech_prob": 0.00007141866808524355,
        "seek": 413798,
        "start": 4152.0599999999995,
        "temperature": 0,
        "text": " and then whether it was recognized,",
        "tokens": [
          51068,
          293,
          550,
          1968,
          309,
          390,
          9823,
          11,
          51167
        ]
      },
      {
        "avg_logprob": -0.2373205820719401,
        "compression_ratio": 1.6877637130801688,
        "end": 4156.86,
        "id": 1257,
        "no_speech_prob": 0.00007141866808524355,
        "seek": 413798,
        "start": 4154.04,
        "temperature": 0,
        "text": " and then the actual drawing itself.",
        "tokens": [
          51167,
          293,
          550,
          264,
          3539,
          6316,
          2564,
          13,
          51308
        ]
      },
      {
        "avg_logprob": -0.2373205820719401,
        "compression_ratio": 1.6877637130801688,
        "end": 4160.0599999999995,
        "id": 1258,
        "no_speech_prob": 0.00007141866808524355,
        "seek": 413798,
        "start": 4156.86,
        "temperature": 0,
        "text": " So what I want to do, and you can see here",
        "tokens": [
          51308,
          407,
          437,
          286,
          528,
          281,
          360,
          11,
          293,
          291,
          393,
          536,
          510,
          51468
        ]
      },
      {
        "avg_logprob": -0.2373205820719401,
        "compression_ratio": 1.6877637130801688,
        "end": 4164.339999999999,
        "id": 1259,
        "no_speech_prob": 0.00007141866808524355,
        "seek": 413798,
        "start": 4160.0599999999995,
        "temperature": 0,
        "text": " that the format of the data is a whole lot of xy positions.",
        "tokens": [
          51468,
          300,
          264,
          7877,
          295,
          264,
          1412,
          307,
          257,
          1379,
          688,
          295,
          2031,
          88,
          8432,
          13,
          51682
        ]
      },
      {
        "avg_logprob": -0.2373205820719401,
        "compression_ratio": 1.6877637130801688,
        "end": 4166.86,
        "id": 1260,
        "no_speech_prob": 0.00007141866808524355,
        "seek": 413798,
        "start": 4164.339999999999,
        "temperature": 0,
        "text": " xy, xy, xy with timing.",
        "tokens": [
          51682,
          2031,
          88,
          11,
          2031,
          88,
          11,
          2031,
          88,
          365,
          10822,
          13,
          51808
        ]
      },
      {
        "avg_logprob": -0.19425117385970964,
        "compression_ratio": 1.694736842105263,
        "end": 4169.099999999999,
        "id": 1261,
        "no_speech_prob": 0.00009761553519638255,
        "seek": 416686,
        "start": 4166.86,
        "temperature": 0,
        "text": " What time was I at the first point, the second point,",
        "tokens": [
          50364,
          708,
          565,
          390,
          286,
          412,
          264,
          700,
          935,
          11,
          264,
          1150,
          935,
          11,
          50476
        ]
      },
      {
        "avg_logprob": -0.19425117385970964,
        "compression_ratio": 1.694736842105263,
        "end": 4170.0199999999995,
        "id": 1262,
        "no_speech_prob": 0.00009761553519638255,
        "seek": 416686,
        "start": 4169.099999999999,
        "temperature": 0,
        "text": " the third point?",
        "tokens": [
          50476,
          264,
          2636,
          935,
          30,
          50522
        ]
      },
      {
        "avg_logprob": -0.19425117385970964,
        "compression_ratio": 1.694736842105263,
        "end": 4172.139999999999,
        "id": 1263,
        "no_speech_prob": 0.00009761553519638255,
        "seek": 416686,
        "start": 4170.0199999999995,
        "temperature": 0,
        "text": " Then I might have lifted up my pen,",
        "tokens": [
          50522,
          1396,
          286,
          1062,
          362,
          17854,
          493,
          452,
          3435,
          11,
          50628
        ]
      },
      {
        "avg_logprob": -0.19425117385970964,
        "compression_ratio": 1.694736842105263,
        "end": 4173.82,
        "id": 1264,
        "no_speech_prob": 0.00009761553519638255,
        "seek": 416686,
        "start": 4172.139999999999,
        "temperature": 0,
        "text": " moved, and started doing another one.",
        "tokens": [
          50628,
          4259,
          11,
          293,
          1409,
          884,
          1071,
          472,
          13,
          50712
        ]
      },
      {
        "avg_logprob": -0.19425117385970964,
        "compression_ratio": 1.694736842105263,
        "end": 4175.299999999999,
        "id": 1265,
        "no_speech_prob": 0.00009761553519638255,
        "seek": 416686,
        "start": 4173.82,
        "temperature": 0,
        "text": " So it's a bunch of strokes.",
        "tokens": [
          50712,
          407,
          309,
          311,
          257,
          3840,
          295,
          24493,
          13,
          50786
        ]
      },
      {
        "avg_logprob": -0.19425117385970964,
        "compression_ratio": 1.694736842105263,
        "end": 4176.9,
        "id": 1266,
        "no_speech_prob": 0.00009761553519638255,
        "seek": 416686,
        "start": 4175.299999999999,
        "temperature": 0,
        "text": " So this is a little tricky because I",
        "tokens": [
          50786,
          407,
          341,
          307,
          257,
          707,
          12414,
          570,
          286,
          50866
        ]
      },
      {
        "avg_logprob": -0.19425117385970964,
        "compression_ratio": 1.694736842105263,
        "end": 4180.54,
        "id": 1267,
        "no_speech_prob": 0.00009761553519638255,
        "seek": 416686,
        "start": 4176.9,
        "temperature": 0,
        "text": " can't use the word stroke as a variable name in p5",
        "tokens": [
          50866,
          393,
          380,
          764,
          264,
          1349,
          12403,
          382,
          257,
          7006,
          1315,
          294,
          280,
          20,
          51048
        ]
      },
      {
        "avg_logprob": -0.19425117385970964,
        "compression_ratio": 1.694736842105263,
        "end": 4182.82,
        "id": 1268,
        "no_speech_prob": 0.00009761553519638255,
        "seek": 416686,
        "start": 4180.54,
        "temperature": 0,
        "text": " because stroke is a function that actually sets the pen",
        "tokens": [
          51048,
          570,
          12403,
          307,
          257,
          2445,
          300,
          767,
          6352,
          264,
          3435,
          51162
        ]
      },
      {
        "avg_logprob": -0.19425117385970964,
        "compression_ratio": 1.694736842105263,
        "end": 4183.38,
        "id": 1269,
        "no_speech_prob": 0.00009761553519638255,
        "seek": 416686,
        "start": 4182.82,
        "temperature": 0,
        "text": " color.",
        "tokens": [
          51162,
          2017,
          13,
          51190
        ]
      },
      {
        "avg_logprob": -0.19425117385970964,
        "compression_ratio": 1.694736842105263,
        "end": 4187.179999999999,
        "id": 1270,
        "no_speech_prob": 0.00009761553519638255,
        "seek": 416686,
        "start": 4183.38,
        "temperature": 0,
        "text": " But the idea is that if I do this,",
        "tokens": [
          51190,
          583,
          264,
          1558,
          307,
          300,
          498,
          286,
          360,
          341,
          11,
          51380
        ]
      },
      {
        "avg_logprob": -0.19425117385970964,
        "compression_ratio": 1.694736842105263,
        "end": 4189.58,
        "id": 1271,
        "no_speech_prob": 0.00009761553519638255,
        "seek": 416686,
        "start": 4187.179999999999,
        "temperature": 0,
        "text": " it's sampling a bunch of my points",
        "tokens": [
          51380,
          309,
          311,
          21179,
          257,
          3840,
          295,
          452,
          2793,
          51500
        ]
      },
      {
        "avg_logprob": -0.19425117385970964,
        "compression_ratio": 1.694736842105263,
        "end": 4191.0599999999995,
        "id": 1272,
        "no_speech_prob": 0.00009761553519638255,
        "seek": 416686,
        "start": 4189.58,
        "temperature": 0,
        "text": " as I drew along that path.",
        "tokens": [
          51500,
          382,
          286,
          12804,
          2051,
          300,
          3100,
          13,
          51574
        ]
      },
      {
        "avg_logprob": -0.19425117385970964,
        "compression_ratio": 1.694736842105263,
        "end": 4194.86,
        "id": 1273,
        "no_speech_prob": 0.00009761553519638255,
        "seek": 416686,
        "start": 4191.0599999999995,
        "temperature": 0,
        "text": " Each one of these is an xy point associated with a given time.",
        "tokens": [
          51574,
          6947,
          472,
          295,
          613,
          307,
          364,
          2031,
          88,
          935,
          6615,
          365,
          257,
          2212,
          565,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.21260248530994763,
        "compression_ratio": 1.907258064516129,
        "end": 4198.299999999999,
        "id": 1274,
        "no_speech_prob": 0.0000036688620639324654,
        "seek": 419486,
        "start": 4194.86,
        "temperature": 0,
        "text": " And then there is an array with all of the x's,",
        "tokens": [
          50364,
          400,
          550,
          456,
          307,
          364,
          10225,
          365,
          439,
          295,
          264,
          2031,
          311,
          11,
          50536
        ]
      },
      {
        "avg_logprob": -0.21260248530994763,
        "compression_ratio": 1.907258064516129,
        "end": 4202.0599999999995,
        "id": 1275,
        "no_speech_prob": 0.0000036688620639324654,
        "seek": 419486,
        "start": 4198.299999999999,
        "temperature": 0,
        "text": " all of the corresponding y's, and the corresponding times.",
        "tokens": [
          50536,
          439,
          295,
          264,
          11760,
          288,
          311,
          11,
          293,
          264,
          11760,
          1413,
          13,
          50724
        ]
      },
      {
        "avg_logprob": -0.21260248530994763,
        "compression_ratio": 1.907258064516129,
        "end": 4204.7,
        "id": 1276,
        "no_speech_prob": 0.0000036688620639324654,
        "seek": 419486,
        "start": 4202.0599999999995,
        "temperature": 0,
        "text": " Now, what I'm actually going to use in this video",
        "tokens": [
          50724,
          823,
          11,
          437,
          286,
          478,
          767,
          516,
          281,
          764,
          294,
          341,
          960,
          50856
        ]
      },
      {
        "avg_logprob": -0.21260248530994763,
        "compression_ratio": 1.907258064516129,
        "end": 4207.299999999999,
        "id": 1277,
        "no_speech_prob": 0.0000036688620639324654,
        "seek": 419486,
        "start": 4204.7,
        "temperature": 0,
        "text": " is if there are a bunch of different versions of the data,",
        "tokens": [
          50856,
          307,
          498,
          456,
          366,
          257,
          3840,
          295,
          819,
          9606,
          295,
          264,
          1412,
          11,
          50986
        ]
      },
      {
        "avg_logprob": -0.21260248530994763,
        "compression_ratio": 1.907258064516129,
        "end": 4209.54,
        "id": 1278,
        "no_speech_prob": 0.0000036688620639324654,
        "seek": 419486,
        "start": 4207.299999999999,
        "temperature": 0,
        "text": " I'm going to use a simplified version of it",
        "tokens": [
          50986,
          286,
          478,
          516,
          281,
          764,
          257,
          26335,
          3037,
          295,
          309,
          51098
        ]
      },
      {
        "avg_logprob": -0.21260248530994763,
        "compression_ratio": 1.907258064516129,
        "end": 4211.46,
        "id": 1279,
        "no_speech_prob": 0.0000036688620639324654,
        "seek": 419486,
        "start": 4209.54,
        "temperature": 0,
        "text": " because these are huge data files.",
        "tokens": [
          51098,
          570,
          613,
          366,
          2603,
          1412,
          7098,
          13,
          51194
        ]
      },
      {
        "avg_logprob": -0.21260248530994763,
        "compression_ratio": 1.907258064516129,
        "end": 4212.96,
        "id": 1280,
        "no_speech_prob": 0.0000036688620639324654,
        "seek": 419486,
        "start": 4211.46,
        "temperature": 0,
        "text": " But I encourage you as an exercise",
        "tokens": [
          51194,
          583,
          286,
          5373,
          291,
          382,
          364,
          5380,
          51269
        ]
      },
      {
        "avg_logprob": -0.21260248530994763,
        "compression_ratio": 1.907258064516129,
        "end": 4214.339999999999,
        "id": 1281,
        "no_speech_prob": 0.0000036688620639324654,
        "seek": 419486,
        "start": 4212.96,
        "temperature": 0,
        "text": " to try to do what I'm going to do",
        "tokens": [
          51269,
          281,
          853,
          281,
          360,
          437,
          286,
          478,
          516,
          281,
          360,
          51338
        ]
      },
      {
        "avg_logprob": -0.21260248530994763,
        "compression_ratio": 1.907258064516129,
        "end": 4216.099999999999,
        "id": 1282,
        "no_speech_prob": 0.0000036688620639324654,
        "seek": 419486,
        "start": 4214.339999999999,
        "temperature": 0,
        "text": " but with the non-simplified version,",
        "tokens": [
          51338,
          457,
          365,
          264,
          2107,
          12,
          30937,
          564,
          2587,
          3037,
          11,
          51426
        ]
      },
      {
        "avg_logprob": -0.21260248530994763,
        "compression_ratio": 1.907258064516129,
        "end": 4217.98,
        "id": 1283,
        "no_speech_prob": 0.0000036688620639324654,
        "seek": 419486,
        "start": 4216.099999999999,
        "temperature": 0,
        "text": " maybe with the timing aspect of it.",
        "tokens": [
          51426,
          1310,
          365,
          264,
          10822,
          4171,
          295,
          309,
          13,
          51520
        ]
      },
      {
        "avg_logprob": -0.21260248530994763,
        "compression_ratio": 1.907258064516129,
        "end": 4224.299999999999,
        "id": 1284,
        "no_speech_prob": 0.0000036688620639324654,
        "seek": 419486,
        "start": 4217.98,
        "temperature": 0,
        "text": " But the simplified drawing files are",
        "tokens": [
          51520,
          583,
          264,
          26335,
          6316,
          7098,
          366,
          51836
        ]
      },
      {
        "avg_logprob": -0.27143885294596354,
        "compression_ratio": 1.6609589041095891,
        "end": 4227.1,
        "id": 1285,
        "no_speech_prob": 0.000007766946509946138,
        "seek": 422430,
        "start": 4224.3,
        "temperature": 0,
        "text": " the same exact thing, the same exact thing,",
        "tokens": [
          50364,
          264,
          912,
          1900,
          551,
          11,
          264,
          912,
          1900,
          551,
          11,
          50504
        ]
      },
      {
        "avg_logprob": -0.27143885294596354,
        "compression_ratio": 1.6609589041095891,
        "end": 4229.860000000001,
        "id": 1286,
        "no_speech_prob": 0.000007766946509946138,
        "seek": 422430,
        "start": 4227.1,
        "temperature": 0,
        "text": " but no timing information.",
        "tokens": [
          50504,
          457,
          572,
          10822,
          1589,
          13,
          50642
        ]
      },
      {
        "avg_logprob": -0.27143885294596354,
        "compression_ratio": 1.6609589041095891,
        "end": 4233.06,
        "id": 1287,
        "no_speech_prob": 0.000007766946509946138,
        "seek": 422430,
        "start": 4229.860000000001,
        "temperature": 0,
        "text": " And also, they have been sub-sampled,",
        "tokens": [
          50642,
          400,
          611,
          11,
          436,
          362,
          668,
          1422,
          12,
          19988,
          15551,
          11,
          50802
        ]
      },
      {
        "avg_logprob": -0.27143885294596354,
        "compression_ratio": 1.6609589041095891,
        "end": 4236.9800000000005,
        "id": 1288,
        "no_speech_prob": 0.000007766946509946138,
        "seek": 422430,
        "start": 4233.06,
        "temperature": 0,
        "text": " meaning in theory, as the person is drawing,",
        "tokens": [
          50802,
          3620,
          294,
          5261,
          11,
          382,
          264,
          954,
          307,
          6316,
          11,
          50998
        ]
      },
      {
        "avg_logprob": -0.27143885294596354,
        "compression_ratio": 1.6609589041095891,
        "end": 4239.66,
        "id": 1289,
        "no_speech_prob": 0.000007766946509946138,
        "seek": 422430,
        "start": 4236.9800000000005,
        "temperature": 0,
        "text": " as the user is drawing, a lot of points are being captured.",
        "tokens": [
          50998,
          382,
          264,
          4195,
          307,
          6316,
          11,
          257,
          688,
          295,
          2793,
          366,
          885,
          11828,
          13,
          51132
        ]
      },
      {
        "avg_logprob": -0.27143885294596354,
        "compression_ratio": 1.6609589041095891,
        "end": 4242.06,
        "id": 1290,
        "no_speech_prob": 0.000007766946509946138,
        "seek": 422430,
        "start": 4239.66,
        "temperature": 0,
        "text": " But maybe you don't need that level of detail.",
        "tokens": [
          51132,
          583,
          1310,
          291,
          500,
          380,
          643,
          300,
          1496,
          295,
          2607,
          13,
          51252
        ]
      },
      {
        "avg_logprob": -0.27143885294596354,
        "compression_ratio": 1.6609589041095891,
        "end": 4245.14,
        "id": 1291,
        "no_speech_prob": 0.000007766946509946138,
        "seek": 422430,
        "start": 4242.06,
        "temperature": 0,
        "text": " And that's often referred to as pixel factor or scale factor,",
        "tokens": [
          51252,
          400,
          300,
          311,
          2049,
          10839,
          281,
          382,
          19261,
          5952,
          420,
          4373,
          5952,
          11,
          51406
        ]
      },
      {
        "avg_logprob": -0.27143885294596354,
        "compression_ratio": 1.6609589041095891,
        "end": 4247.06,
        "id": 1292,
        "no_speech_prob": 0.000007766946509946138,
        "seek": 422430,
        "start": 4245.14,
        "temperature": 0,
        "text": " I believe, or epsilon value, I guess.",
        "tokens": [
          51406,
          286,
          1697,
          11,
          420,
          17889,
          2158,
          11,
          286,
          2041,
          13,
          51502
        ]
      },
      {
        "avg_logprob": -0.27143885294596354,
        "compression_ratio": 1.6609589041095891,
        "end": 4249.34,
        "id": 1293,
        "no_speech_prob": 0.000007766946509946138,
        "seek": 422430,
        "start": 4247.06,
        "temperature": 0,
        "text": " So you could say simplify all strokes using the Rammer",
        "tokens": [
          51502,
          407,
          291,
          727,
          584,
          20460,
          439,
          24493,
          1228,
          264,
          9078,
          936,
          51616
        ]
      },
      {
        "avg_logprob": -0.27143885294596354,
        "compression_ratio": 1.6609589041095891,
        "end": 4251.1,
        "id": 1294,
        "no_speech_prob": 0.000007766946509946138,
        "seek": 422430,
        "start": 4249.34,
        "temperature": 0,
        "text": " Douglas Puker algorithm.",
        "tokens": [
          51616,
          23010,
          430,
          2034,
          260,
          9284,
          13,
          51704
        ]
      },
      {
        "avg_logprob": -0.27143885294596354,
        "compression_ratio": 1.6609589041095891,
        "end": 4253.900000000001,
        "id": 1295,
        "no_speech_prob": 0.000007766946509946138,
        "seek": 422430,
        "start": 4251.1,
        "temperature": 0,
        "text": " I don't know if I pronounced that correctly.",
        "tokens": [
          51704,
          286,
          500,
          380,
          458,
          498,
          286,
          23155,
          300,
          8944,
          13,
          51844
        ]
      },
      {
        "avg_logprob": -0.26997113435164743,
        "compression_ratio": 1.615702479338843,
        "end": 4255.5,
        "id": 1296,
        "no_speech_prob": 0.002050708746537566,
        "seek": 425390,
        "start": 4253.9,
        "temperature": 0,
        "text": " With an epsilon value of 2.",
        "tokens": [
          50364,
          2022,
          364,
          17889,
          2158,
          295,
          568,
          13,
          50444
        ]
      },
      {
        "avg_logprob": -0.26997113435164743,
        "compression_ratio": 1.615702479338843,
        "end": 4259.0599999999995,
        "id": 1297,
        "no_speech_prob": 0.002050708746537566,
        "seek": 425390,
        "start": 4255.5,
        "temperature": 0,
        "text": " So these are available as something called NDJSON.",
        "tokens": [
          50444,
          407,
          613,
          366,
          2435,
          382,
          746,
          1219,
          40709,
          41,
          10388,
          13,
          50622
        ]
      },
      {
        "avg_logprob": -0.26997113435164743,
        "compression_ratio": 1.615702479338843,
        "end": 4261.0599999999995,
        "id": 1298,
        "no_speech_prob": 0.002050708746537566,
        "seek": 425390,
        "start": 4259.0599999999995,
        "temperature": 0,
        "text": " Now, if you've watched my videos before,",
        "tokens": [
          50622,
          823,
          11,
          498,
          291,
          600,
          6337,
          452,
          2145,
          949,
          11,
          50722
        ]
      },
      {
        "avg_logprob": -0.26997113435164743,
        "compression_ratio": 1.615702479338843,
        "end": 4262.94,
        "id": 1299,
        "no_speech_prob": 0.002050708746537566,
        "seek": 425390,
        "start": 4261.0599999999995,
        "temperature": 0,
        "text": " you're probably familiar with JSON,",
        "tokens": [
          50722,
          291,
          434,
          1391,
          4963,
          365,
          31828,
          11,
          50816
        ]
      },
      {
        "avg_logprob": -0.26997113435164743,
        "compression_ratio": 1.615702479338843,
        "end": 4264.66,
        "id": 1300,
        "no_speech_prob": 0.002050708746537566,
        "seek": 425390,
        "start": 4262.94,
        "temperature": 0,
        "text": " JavaScript Object Notation.",
        "tokens": [
          50816,
          15778,
          24753,
          1726,
          399,
          13,
          50902
        ]
      },
      {
        "avg_logprob": -0.26997113435164743,
        "compression_ratio": 1.615702479338843,
        "end": 4267.86,
        "id": 1301,
        "no_speech_prob": 0.002050708746537566,
        "seek": 425390,
        "start": 4264.66,
        "temperature": 0,
        "text": " That is a format where you can store data.",
        "tokens": [
          50902,
          663,
          307,
          257,
          7877,
          689,
          291,
          393,
          3531,
          1412,
          13,
          51062
        ]
      },
      {
        "avg_logprob": -0.26997113435164743,
        "compression_ratio": 1.615702479338843,
        "end": 4269.82,
        "id": 1302,
        "no_speech_prob": 0.002050708746537566,
        "seek": 425390,
        "start": 4267.86,
        "temperature": 0,
        "text": " That's in JavaScript Object Notation.",
        "tokens": [
          51062,
          663,
          311,
          294,
          15778,
          24753,
          1726,
          399,
          13,
          51160
        ]
      },
      {
        "avg_logprob": -0.26997113435164743,
        "compression_ratio": 1.615702479338843,
        "end": 4271.5,
        "id": 1303,
        "no_speech_prob": 0.002050708746537566,
        "seek": 425390,
        "start": 4269.82,
        "temperature": 0,
        "text": " I have some videos about what is JSON.",
        "tokens": [
          51160,
          286,
          362,
          512,
          2145,
          466,
          437,
          307,
          31828,
          13,
          51244
        ]
      },
      {
        "avg_logprob": -0.26997113435164743,
        "compression_ratio": 1.615702479338843,
        "end": 4273.099999999999,
        "id": 1304,
        "no_speech_prob": 0.002050708746537566,
        "seek": 425390,
        "start": 4271.5,
        "temperature": 0,
        "text": " NDJSON is a funny thing.",
        "tokens": [
          51244,
          40709,
          41,
          10388,
          307,
          257,
          4074,
          551,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.26997113435164743,
        "compression_ratio": 1.615702479338843,
        "end": 4274.62,
        "id": 1305,
        "no_speech_prob": 0.002050708746537566,
        "seek": 425390,
        "start": 4273.099999999999,
        "temperature": 0,
        "text": " Ha ha, it's hilarious.",
        "tokens": [
          51324,
          4064,
          324,
          11,
          309,
          311,
          19796,
          13,
          51400
        ]
      },
      {
        "avg_logprob": -0.26997113435164743,
        "compression_ratio": 1.615702479338843,
        "end": 4278.62,
        "id": 1306,
        "no_speech_prob": 0.002050708746537566,
        "seek": 425390,
        "start": 4274.62,
        "temperature": 0,
        "text": " It's like the funniest version of JSON.",
        "tokens": [
          51400,
          467,
          311,
          411,
          264,
          42681,
          3037,
          295,
          31828,
          13,
          51600
        ]
      },
      {
        "avg_logprob": -0.2609309105023946,
        "compression_ratio": 1.7003610108303249,
        "end": 4284.3,
        "id": 1307,
        "no_speech_prob": 0.00012339426029939204,
        "seek": 427862,
        "start": 4278.62,
        "temperature": 0,
        "text": " And it actually is a set of multiple JSON elements,",
        "tokens": [
          50364,
          400,
          309,
          767,
          307,
          257,
          992,
          295,
          3866,
          31828,
          4959,
          11,
          50648
        ]
      },
      {
        "avg_logprob": -0.2609309105023946,
        "compression_ratio": 1.7003610108303249,
        "end": 4285.94,
        "id": 1308,
        "no_speech_prob": 0.00012339426029939204,
        "seek": 427862,
        "start": 4284.3,
        "temperature": 0,
        "text": " each on a different line in a file.",
        "tokens": [
          50648,
          1184,
          322,
          257,
          819,
          1622,
          294,
          257,
          3991,
          13,
          50730
        ]
      },
      {
        "avg_logprob": -0.2609309105023946,
        "compression_ratio": 1.7003610108303249,
        "end": 4287.18,
        "id": 1309,
        "no_speech_prob": 0.00012339426029939204,
        "seek": 427862,
        "start": 4285.94,
        "temperature": 0,
        "text": " So it makes sense to do that.",
        "tokens": [
          50730,
          407,
          309,
          1669,
          2020,
          281,
          360,
          300,
          13,
          50792
        ]
      },
      {
        "avg_logprob": -0.2609309105023946,
        "compression_ratio": 1.7003610108303249,
        "end": 4290.18,
        "id": 1310,
        "no_speech_prob": 0.00012339426029939204,
        "seek": 427862,
        "start": 4287.18,
        "temperature": 0,
        "text": " Each drawing is its own JSON object",
        "tokens": [
          50792,
          6947,
          6316,
          307,
          1080,
          1065,
          31828,
          2657,
          50942
        ]
      },
      {
        "avg_logprob": -0.2609309105023946,
        "compression_ratio": 1.7003610108303249,
        "end": 4292.0199999999995,
        "id": 1311,
        "no_speech_prob": 0.00012339426029939204,
        "seek": 427862,
        "start": 4290.18,
        "temperature": 0,
        "text": " on a different line in the file.",
        "tokens": [
          50942,
          322,
          257,
          819,
          1622,
          294,
          264,
          3991,
          13,
          51034
        ]
      },
      {
        "avg_logprob": -0.2609309105023946,
        "compression_ratio": 1.7003610108303249,
        "end": 4293.5599999999995,
        "id": 1312,
        "no_speech_prob": 0.00012339426029939204,
        "seek": 427862,
        "start": 4292.0199999999995,
        "temperature": 0,
        "text": " So let's go grab one of these files.",
        "tokens": [
          51034,
          407,
          718,
          311,
          352,
          4444,
          472,
          295,
          613,
          7098,
          13,
          51111
        ]
      },
      {
        "avg_logprob": -0.2609309105023946,
        "compression_ratio": 1.7003610108303249,
        "end": 4295.38,
        "id": 1313,
        "no_speech_prob": 0.00012339426029939204,
        "seek": 427862,
        "start": 4293.5599999999995,
        "temperature": 0,
        "text": " So getting the data, we can actually",
        "tokens": [
          51111,
          407,
          1242,
          264,
          1412,
          11,
          321,
          393,
          767,
          51202
        ]
      },
      {
        "avg_logprob": -0.2609309105023946,
        "compression_ratio": 1.7003610108303249,
        "end": 4298.26,
        "id": 1314,
        "no_speech_prob": 0.00012339426029939204,
        "seek": 427862,
        "start": 4295.38,
        "temperature": 0,
        "text": " go to the public data sets.",
        "tokens": [
          51202,
          352,
          281,
          264,
          1908,
          1412,
          6352,
          13,
          51346
        ]
      },
      {
        "avg_logprob": -0.2609309105023946,
        "compression_ratio": 1.7003610108303249,
        "end": 4299.22,
        "id": 1315,
        "no_speech_prob": 0.00012339426029939204,
        "seek": 427862,
        "start": 4298.26,
        "temperature": 0,
        "text": " Oops, no, I'm sorry.",
        "tokens": [
          51346,
          21726,
          11,
          572,
          11,
          286,
          478,
          2597,
          13,
          51394
        ]
      },
      {
        "avg_logprob": -0.2609309105023946,
        "compression_ratio": 1.7003610108303249,
        "end": 4301.84,
        "id": 1316,
        "no_speech_prob": 0.00012339426029939204,
        "seek": 427862,
        "start": 4299.22,
        "temperature": 0,
        "text": " I just want to go to the list of the files in the Cloud Console,",
        "tokens": [
          51394,
          286,
          445,
          528,
          281,
          352,
          281,
          264,
          1329,
          295,
          264,
          7098,
          294,
          264,
          8061,
          44152,
          11,
          51525
        ]
      },
      {
        "avg_logprob": -0.2609309105023946,
        "compression_ratio": 1.7003610108303249,
        "end": 4303.74,
        "id": 1317,
        "no_speech_prob": 0.00012339426029939204,
        "seek": 427862,
        "start": 4301.84,
        "temperature": 0,
        "text": " which is right here.",
        "tokens": [
          51525,
          597,
          307,
          558,
          510,
          13,
          51620
        ]
      },
      {
        "avg_logprob": -0.2609309105023946,
        "compression_ratio": 1.7003610108303249,
        "end": 4305.58,
        "id": 1318,
        "no_speech_prob": 0.00012339426029939204,
        "seek": 427862,
        "start": 4303.74,
        "temperature": 0,
        "text": " I'm going to say I agree.",
        "tokens": [
          51620,
          286,
          478,
          516,
          281,
          584,
          286,
          3986,
          13,
          51712
        ]
      },
      {
        "avg_logprob": -0.2609309105023946,
        "compression_ratio": 1.7003610108303249,
        "end": 4307.7,
        "id": 1319,
        "no_speech_prob": 0.00012339426029939204,
        "seek": 427862,
        "start": 4305.58,
        "temperature": 0,
        "text": " And I don't want any email updates, but I accept.",
        "tokens": [
          51712,
          400,
          286,
          500,
          380,
          528,
          604,
          3796,
          9205,
          11,
          457,
          286,
          3241,
          13,
          51818
        ]
      },
      {
        "avg_logprob": -0.3322042817050971,
        "compression_ratio": 1.49009900990099,
        "end": 4309.46,
        "id": 1320,
        "no_speech_prob": 0.000012606859854713548,
        "seek": 430770,
        "start": 4307.7,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50364,
          2264,
          13,
          50452
        ]
      },
      {
        "avg_logprob": -0.3322042817050971,
        "compression_ratio": 1.49009900990099,
        "end": 4311.34,
        "id": 1321,
        "no_speech_prob": 0.000012606859854713548,
        "seek": 430770,
        "start": 4309.46,
        "temperature": 0,
        "text": " Accept.",
        "tokens": [
          50452,
          39957,
          13,
          50546
        ]
      },
      {
        "avg_logprob": -0.3322042817050971,
        "compression_ratio": 1.49009900990099,
        "end": 4313.86,
        "id": 1322,
        "no_speech_prob": 0.000012606859854713548,
        "seek": 430770,
        "start": 4311.34,
        "temperature": 0,
        "text": " So I'm going to go to full.",
        "tokens": [
          50546,
          407,
          286,
          478,
          516,
          281,
          352,
          281,
          1577,
          13,
          50672
        ]
      },
      {
        "avg_logprob": -0.3322042817050971,
        "compression_ratio": 1.49009900990099,
        "end": 4314.38,
        "id": 1323,
        "no_speech_prob": 0.000012606859854713548,
        "seek": 430770,
        "start": 4313.86,
        "temperature": 0,
        "text": " And oops.",
        "tokens": [
          50672,
          400,
          34166,
          13,
          50698
        ]
      },
      {
        "avg_logprob": -0.3322042817050971,
        "compression_ratio": 1.49009900990099,
        "end": 4324.94,
        "id": 1324,
        "no_speech_prob": 0.000012606859854713548,
        "seek": 430770,
        "start": 4323.38,
        "temperature": 0,
        "text": " I realize you can't see anything here,",
        "tokens": [
          51148,
          286,
          4325,
          291,
          393,
          380,
          536,
          1340,
          510,
          11,
          51226
        ]
      },
      {
        "avg_logprob": -0.3322042817050971,
        "compression_ratio": 1.49009900990099,
        "end": 4327.38,
        "id": 1325,
        "no_speech_prob": 0.000012606859854713548,
        "seek": 430770,
        "start": 4324.94,
        "temperature": 0,
        "text": " so let's try to make this a bigger.",
        "tokens": [
          51226,
          370,
          718,
          311,
          853,
          281,
          652,
          341,
          257,
          3801,
          13,
          51348
        ]
      },
      {
        "avg_logprob": -0.3322042817050971,
        "compression_ratio": 1.49009900990099,
        "end": 4329.3,
        "id": 1326,
        "no_speech_prob": 0.000012606859854713548,
        "seek": 430770,
        "start": 4327.38,
        "temperature": 0,
        "text": " Let me dismiss this right now.",
        "tokens": [
          51348,
          961,
          385,
          16974,
          341,
          558,
          586,
          13,
          51444
        ]
      },
      {
        "avg_logprob": -0.3322042817050971,
        "compression_ratio": 1.49009900990099,
        "end": 4331.34,
        "id": 1327,
        "no_speech_prob": 0.000012606859854713548,
        "seek": 430770,
        "start": 4329.3,
        "temperature": 0,
        "text": " And come on.",
        "tokens": [
          51444,
          400,
          808,
          322,
          13,
          51546
        ]
      },
      {
        "avg_logprob": -0.3322042817050971,
        "compression_ratio": 1.49009900990099,
        "end": 4332.58,
        "id": 1328,
        "no_speech_prob": 0.000012606859854713548,
        "seek": 430770,
        "start": 4331.34,
        "temperature": 0,
        "text": " I guess I'll make this smaller.",
        "tokens": [
          51546,
          286,
          2041,
          286,
          603,
          652,
          341,
          4356,
          13,
          51608
        ]
      },
      {
        "avg_logprob": -0.3322042817050971,
        "compression_ratio": 1.49009900990099,
        "end": 4333.38,
        "id": 1329,
        "no_speech_prob": 0.000012606859854713548,
        "seek": 430770,
        "start": 4332.58,
        "temperature": 0,
        "text": " I'll just zoom in.",
        "tokens": [
          51608,
          286,
          603,
          445,
          8863,
          294,
          13,
          51648
        ]
      },
      {
        "avg_logprob": -0.3322042817050971,
        "compression_ratio": 1.49009900990099,
        "end": 4335.54,
        "id": 1330,
        "no_speech_prob": 0.000012606859854713548,
        "seek": 430770,
        "start": 4333.38,
        "temperature": 0,
        "text": " So these are the different formats.",
        "tokens": [
          51648,
          407,
          613,
          366,
          264,
          819,
          25879,
          13,
          51756
        ]
      },
      {
        "avg_logprob": -0.3322042817050971,
        "compression_ratio": 1.49009900990099,
        "end": 4337.5,
        "id": 1331,
        "no_speech_prob": 0.000012606859854713548,
        "seek": 430770,
        "start": 4335.54,
        "temperature": 0,
        "text": " They're actually all the data in just binary.",
        "tokens": [
          51756,
          814,
          434,
          767,
          439,
          264,
          1412,
          294,
          445,
          17434,
          13,
          51854
        ]
      },
      {
        "avg_logprob": -0.23540210723876953,
        "compression_ratio": 1.627177700348432,
        "end": 4339.1,
        "id": 1332,
        "no_speech_prob": 0.00011591923248488456,
        "seek": 433750,
        "start": 4337.5,
        "temperature": 0,
        "text": " There's this NumPy bitmap, which is",
        "tokens": [
          50364,
          821,
          311,
          341,
          22592,
          47,
          88,
          857,
          24223,
          11,
          597,
          307,
          50444
        ]
      },
      {
        "avg_logprob": -0.23540210723876953,
        "compression_ratio": 1.627177700348432,
        "end": 4341.1,
        "id": 1333,
        "no_speech_prob": 0.00011591923248488456,
        "seek": 433750,
        "start": 4339.1,
        "temperature": 0,
        "text": " useful for other kinds of machine learning,",
        "tokens": [
          50444,
          4420,
          337,
          661,
          3685,
          295,
          3479,
          2539,
          11,
          50544
        ]
      },
      {
        "avg_logprob": -0.23540210723876953,
        "compression_ratio": 1.627177700348432,
        "end": 4343.26,
        "id": 1334,
        "no_speech_prob": 0.00011591923248488456,
        "seek": 433750,
        "start": 4341.1,
        "temperature": 0,
        "text": " different things you might want to try, the raw data.",
        "tokens": [
          50544,
          819,
          721,
          291,
          1062,
          528,
          281,
          853,
          11,
          264,
          8936,
          1412,
          13,
          50652
        ]
      },
      {
        "avg_logprob": -0.23540210723876953,
        "compression_ratio": 1.627177700348432,
        "end": 4345.38,
        "id": 1335,
        "no_speech_prob": 0.00011591923248488456,
        "seek": 433750,
        "start": 4343.26,
        "temperature": 0,
        "text": " But let's look at the simplified data.",
        "tokens": [
          50652,
          583,
          718,
          311,
          574,
          412,
          264,
          26335,
          1412,
          13,
          50758
        ]
      },
      {
        "avg_logprob": -0.23540210723876953,
        "compression_ratio": 1.627177700348432,
        "end": 4348.14,
        "id": 1336,
        "no_speech_prob": 0.00011591923248488456,
        "seek": 433750,
        "start": 4345.38,
        "temperature": 0,
        "text": " And let's pick, oh, I don't know.",
        "tokens": [
          50758,
          400,
          718,
          311,
          1888,
          11,
          1954,
          11,
          286,
          500,
          380,
          458,
          13,
          50896
        ]
      },
      {
        "avg_logprob": -0.23540210723876953,
        "compression_ratio": 1.627177700348432,
        "end": 4349.42,
        "id": 1337,
        "no_speech_prob": 0.00011591923248488456,
        "seek": 433750,
        "start": 4348.14,
        "temperature": 0,
        "text": " Which model should I pick?",
        "tokens": [
          50896,
          3013,
          2316,
          820,
          286,
          1888,
          30,
          50960
        ]
      },
      {
        "avg_logprob": -0.23540210723876953,
        "compression_ratio": 1.627177700348432,
        "end": 4350.06,
        "id": 1338,
        "no_speech_prob": 0.00011591923248488456,
        "seek": 433750,
        "start": 4349.42,
        "temperature": 0,
        "text": " There's so many.",
        "tokens": [
          50960,
          821,
          311,
          370,
          867,
          13,
          50992
        ]
      },
      {
        "avg_logprob": -0.23540210723876953,
        "compression_ratio": 1.627177700348432,
        "end": 4354.14,
        "id": 1339,
        "no_speech_prob": 0.00011591923248488456,
        "seek": 433750,
        "start": 4350.06,
        "temperature": 0,
        "text": " Banana, bandage, baseball, basketball, bat, beach, bear,",
        "tokens": [
          50992,
          39588,
          11,
          4116,
          609,
          11,
          14323,
          11,
          11767,
          11,
          7362,
          11,
          7534,
          11,
          6155,
          11,
          51196
        ]
      },
      {
        "avg_logprob": -0.23540210723876953,
        "compression_ratio": 1.627177700348432,
        "end": 4354.7,
        "id": 1340,
        "no_speech_prob": 0.00011591923248488456,
        "seek": 433750,
        "start": 4354.14,
        "temperature": 0,
        "text": " beard.",
        "tokens": [
          51196,
          17455,
          13,
          51224
        ]
      },
      {
        "avg_logprob": -0.23540210723876953,
        "compression_ratio": 1.627177700348432,
        "end": 4356.66,
        "id": 1341,
        "no_speech_prob": 0.00011591923248488456,
        "seek": 433750,
        "start": 4354.7,
        "temperature": 0,
        "text": " I guess I should do beard.",
        "tokens": [
          51224,
          286,
          2041,
          286,
          820,
          360,
          17455,
          13,
          51322
        ]
      },
      {
        "avg_logprob": -0.23540210723876953,
        "compression_ratio": 1.627177700348432,
        "end": 4358.06,
        "id": 1342,
        "no_speech_prob": 0.00011591923248488456,
        "seek": 433750,
        "start": 4356.66,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          51322,
          1779,
          30,
          51392
        ]
      },
      {
        "avg_logprob": -0.23540210723876953,
        "compression_ratio": 1.627177700348432,
        "end": 4359.62,
        "id": 1343,
        "no_speech_prob": 0.00011591923248488456,
        "seek": 433750,
        "start": 4358.06,
        "temperature": 0,
        "text": " That's kind of lame, though.",
        "tokens": [
          51392,
          663,
          311,
          733,
          295,
          27635,
          11,
          1673,
          13,
          51470
        ]
      },
      {
        "avg_logprob": -0.23540210723876953,
        "compression_ratio": 1.627177700348432,
        "end": 4360.46,
        "id": 1344,
        "no_speech_prob": 0.00011591923248488456,
        "seek": 433750,
        "start": 4359.62,
        "temperature": 0,
        "text": " Birthday cake.",
        "tokens": [
          51470,
          29236,
          5908,
          13,
          51512
        ]
      },
      {
        "avg_logprob": -0.23540210723876953,
        "compression_ratio": 1.627177700348432,
        "end": 4361.98,
        "id": 1345,
        "no_speech_prob": 0.00011591923248488456,
        "seek": 433750,
        "start": 4360.46,
        "temperature": 0,
        "text": " Is there like a unicorn?",
        "tokens": [
          51512,
          1119,
          456,
          411,
          257,
          28122,
          30,
          51588
        ]
      },
      {
        "avg_logprob": -0.23540210723876953,
        "compression_ratio": 1.627177700348432,
        "end": 4364.78,
        "id": 1346,
        "no_speech_prob": 0.00011591923248488456,
        "seek": 433750,
        "start": 4361.98,
        "temperature": 0,
        "text": " Maybe there's a unicorn.",
        "tokens": [
          51588,
          2704,
          456,
          311,
          257,
          28122,
          13,
          51728
        ]
      },
      {
        "avg_logprob": -0.23540210723876953,
        "compression_ratio": 1.627177700348432,
        "end": 4365.7,
        "id": 1347,
        "no_speech_prob": 0.00011591923248488456,
        "seek": 433750,
        "start": 4364.78,
        "temperature": 0,
        "text": " No, was there a rainbow?",
        "tokens": [
          51728,
          883,
          11,
          390,
          456,
          257,
          18526,
          30,
          51774
        ]
      },
      {
        "avg_logprob": -0.20797674164517235,
        "compression_ratio": 1.6317829457364341,
        "end": 4370.5,
        "id": 1348,
        "no_speech_prob": 0.00000685431268721004,
        "seek": 436750,
        "start": 4368.34,
        "temperature": 0,
        "text": " Yes, there's a rainbow.",
        "tokens": [
          50406,
          1079,
          11,
          456,
          311,
          257,
          18526,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.20797674164517235,
        "compression_ratio": 1.6317829457364341,
        "end": 4372.06,
        "id": 1349,
        "no_speech_prob": 0.00000685431268721004,
        "seek": 436750,
        "start": 4370.5,
        "temperature": 0,
        "text": " All right, so we'll use the rainbow.",
        "tokens": [
          50514,
          1057,
          558,
          11,
          370,
          321,
          603,
          764,
          264,
          18526,
          13,
          50592
        ]
      },
      {
        "avg_logprob": -0.20797674164517235,
        "compression_ratio": 1.6317829457364341,
        "end": 4375.98,
        "id": 1350,
        "no_speech_prob": 0.00000685431268721004,
        "seek": 436750,
        "start": 4372.06,
        "temperature": 0,
        "text": " So I am going to download this file.",
        "tokens": [
          50592,
          407,
          286,
          669,
          516,
          281,
          5484,
          341,
          3991,
          13,
          50788
        ]
      },
      {
        "avg_logprob": -0.20797674164517235,
        "compression_ratio": 1.6317829457364341,
        "end": 4378.1,
        "id": 1351,
        "no_speech_prob": 0.00000685431268721004,
        "seek": 436750,
        "start": 4375.98,
        "temperature": 0,
        "text": " So here's the thing.",
        "tokens": [
          50788,
          407,
          510,
          311,
          264,
          551,
          13,
          50894
        ]
      },
      {
        "avg_logprob": -0.20797674164517235,
        "compression_ratio": 1.6317829457364341,
        "end": 4380.42,
        "id": 1352,
        "no_speech_prob": 0.00000685431268721004,
        "seek": 436750,
        "start": 4378.1,
        "temperature": 0,
        "text": " This is a very large file.",
        "tokens": [
          50894,
          639,
          307,
          257,
          588,
          2416,
          3991,
          13,
          51010
        ]
      },
      {
        "avg_logprob": -0.20797674164517235,
        "compression_ratio": 1.6317829457364341,
        "end": 4383.5,
        "id": 1353,
        "no_speech_prob": 0.00000685431268721004,
        "seek": 436750,
        "start": 4380.42,
        "temperature": 0,
        "text": " I had a reason why I was doing this challenge also.",
        "tokens": [
          51010,
          286,
          632,
          257,
          1778,
          983,
          286,
          390,
          884,
          341,
          3430,
          611,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.20797674164517235,
        "compression_ratio": 1.6317829457364341,
        "end": 4385.06,
        "id": 1354,
        "no_speech_prob": 0.00000685431268721004,
        "seek": 436750,
        "start": 4383.5,
        "temperature": 0,
        "text": " This is a 43 megabyte file.",
        "tokens": [
          51164,
          639,
          307,
          257,
          17914,
          10816,
          34529,
          3991,
          13,
          51242
        ]
      },
      {
        "avg_logprob": -0.20797674164517235,
        "compression_ratio": 1.6317829457364341,
        "end": 4388.78,
        "id": 1355,
        "no_speech_prob": 0.00000685431268721004,
        "seek": 436750,
        "start": 4385.06,
        "temperature": 0,
        "text": " Now, I could just use some code in my client-side JavaScript",
        "tokens": [
          51242,
          823,
          11,
          286,
          727,
          445,
          764,
          512,
          3089,
          294,
          452,
          6423,
          12,
          1812,
          15778,
          51428
        ]
      },
      {
        "avg_logprob": -0.20797674164517235,
        "compression_ratio": 1.6317829457364341,
        "end": 4391.86,
        "id": 1356,
        "no_speech_prob": 0.00000685431268721004,
        "seek": 436750,
        "start": 4388.78,
        "temperature": 0,
        "text": " to load that file and put it on the web.",
        "tokens": [
          51428,
          281,
          3677,
          300,
          3991,
          293,
          829,
          309,
          322,
          264,
          3670,
          13,
          51582
        ]
      },
      {
        "avg_logprob": -0.20797674164517235,
        "compression_ratio": 1.6317829457364341,
        "end": 4393.58,
        "id": 1357,
        "no_speech_prob": 0.00000685431268721004,
        "seek": 436750,
        "start": 4391.86,
        "temperature": 0,
        "text": " And at some point, I might show you",
        "tokens": [
          51582,
          400,
          412,
          512,
          935,
          11,
          286,
          1062,
          855,
          291,
          51668
        ]
      },
      {
        "avg_logprob": -0.20797674164517235,
        "compression_ratio": 1.6317829457364341,
        "end": 4395.1,
        "id": 1358,
        "no_speech_prob": 0.00000685431268721004,
        "seek": 436750,
        "start": 4393.58,
        "temperature": 0,
        "text": " some techniques for doing that.",
        "tokens": [
          51668,
          512,
          7512,
          337,
          884,
          300,
          13,
          51744
        ]
      },
      {
        "avg_logprob": -0.20797674164517235,
        "compression_ratio": 1.6317829457364341,
        "end": 4396.78,
        "id": 1359,
        "no_speech_prob": 0.00000685431268721004,
        "seek": 436750,
        "start": 4395.1,
        "temperature": 0,
        "text": " Stay tuned in the future.",
        "tokens": [
          51744,
          8691,
          10870,
          294,
          264,
          2027,
          13,
          51828
        ]
      },
      {
        "avg_logprob": -0.24332754235518606,
        "compression_ratio": 1.7383177570093458,
        "end": 4401.219999999999,
        "id": 1360,
        "no_speech_prob": 0.0001465309615014121,
        "seek": 439678,
        "start": 4396.78,
        "temperature": 0,
        "text": " But I think this is a good case where my video series,",
        "tokens": [
          50364,
          583,
          286,
          519,
          341,
          307,
          257,
          665,
          1389,
          689,
          452,
          960,
          2638,
          11,
          50586
        ]
      },
      {
        "avg_logprob": -0.24332754235518606,
        "compression_ratio": 1.7383177570093458,
        "end": 4403.58,
        "id": 1361,
        "no_speech_prob": 0.0001465309615014121,
        "seek": 439678,
        "start": 4401.219999999999,
        "temperature": 0,
        "text": " the module for my programming from A to Z class,",
        "tokens": [
          50586,
          264,
          10088,
          337,
          452,
          9410,
          490,
          316,
          281,
          1176,
          1508,
          11,
          50704
        ]
      },
      {
        "avg_logprob": -0.24332754235518606,
        "compression_ratio": 1.7383177570093458,
        "end": 4405.98,
        "id": 1362,
        "no_speech_prob": 0.0001465309615014121,
        "seek": 439678,
        "start": 4403.58,
        "temperature": 0,
        "text": " or the program with text class, building an API with Node",
        "tokens": [
          50704,
          420,
          264,
          1461,
          365,
          2487,
          1508,
          11,
          2390,
          364,
          9362,
          365,
          38640,
          50824
        ]
      },
      {
        "avg_logprob": -0.24332754235518606,
        "compression_ratio": 1.7383177570093458,
        "end": 4408.34,
        "id": 1363,
        "no_speech_prob": 0.0001465309615014121,
        "seek": 439678,
        "start": 4405.98,
        "temperature": 0,
        "text": " and Express, this is a case where I've got this.",
        "tokens": [
          50824,
          293,
          20212,
          11,
          341,
          307,
          257,
          1389,
          689,
          286,
          600,
          658,
          341,
          13,
          50942
        ]
      },
      {
        "avg_logprob": -0.24332754235518606,
        "compression_ratio": 1.7383177570093458,
        "end": 4410.9,
        "id": 1364,
        "no_speech_prob": 0.0001465309615014121,
        "seek": 439678,
        "start": 4408.34,
        "temperature": 0,
        "text": " What if I want to have every drawing?",
        "tokens": [
          50942,
          708,
          498,
          286,
          528,
          281,
          362,
          633,
          6316,
          30,
          51070
        ]
      },
      {
        "avg_logprob": -0.24332754235518606,
        "compression_ratio": 1.7383177570093458,
        "end": 4412.38,
        "id": 1365,
        "no_speech_prob": 0.0001465309615014121,
        "seek": 439678,
        "start": 4410.9,
        "temperature": 0,
        "text": " There's just millions of them.",
        "tokens": [
          51070,
          821,
          311,
          445,
          6803,
          295,
          552,
          13,
          51144
        ]
      },
      {
        "avg_logprob": -0.24332754235518606,
        "compression_ratio": 1.7383177570093458,
        "end": 4415.3,
        "id": 1366,
        "no_speech_prob": 0.0001465309615014121,
        "seek": 439678,
        "start": 4412.38,
        "temperature": 0,
        "text": " I don't want to load hundreds of megabytes and gigabytes",
        "tokens": [
          51144,
          286,
          500,
          380,
          528,
          281,
          3677,
          6779,
          295,
          10816,
          24538,
          293,
          42741,
          51290
        ]
      },
      {
        "avg_logprob": -0.24332754235518606,
        "compression_ratio": 1.7383177570093458,
        "end": 4417.3,
        "id": 1367,
        "no_speech_prob": 0.0001465309615014121,
        "seek": 439678,
        "start": 4415.3,
        "temperature": 0,
        "text": " of files in my client-side JavaScript.",
        "tokens": [
          51290,
          295,
          7098,
          294,
          452,
          6423,
          12,
          1812,
          15778,
          13,
          51390
        ]
      },
      {
        "avg_logprob": -0.24332754235518606,
        "compression_ratio": 1.7383177570093458,
        "end": 4420.219999999999,
        "id": 1368,
        "no_speech_prob": 0.0001465309615014121,
        "seek": 439678,
        "start": 4417.3,
        "temperature": 0,
        "text": " I could write a little Node program whose sole purpose",
        "tokens": [
          51390,
          286,
          727,
          2464,
          257,
          707,
          38640,
          1461,
          6104,
          12321,
          4334,
          51536
        ]
      },
      {
        "avg_logprob": -0.24332754235518606,
        "compression_ratio": 1.7383177570093458,
        "end": 4422.099999999999,
        "id": 1369,
        "no_speech_prob": 0.0001465309615014121,
        "seek": 439678,
        "start": 4420.219999999999,
        "temperature": 0,
        "text": " is to hold on to all that data.",
        "tokens": [
          51536,
          307,
          281,
          1797,
          322,
          281,
          439,
          300,
          1412,
          13,
          51630
        ]
      },
      {
        "avg_logprob": -0.24332754235518606,
        "compression_ratio": 1.7383177570093458,
        "end": 4424.66,
        "id": 1370,
        "no_speech_prob": 0.0001465309615014121,
        "seek": 439678,
        "start": 4422.099999999999,
        "temperature": 0,
        "text": " And my client-side JavaScript could just request it.",
        "tokens": [
          51630,
          400,
          452,
          6423,
          12,
          1812,
          15778,
          727,
          445,
          5308,
          309,
          13,
          51758
        ]
      },
      {
        "avg_logprob": -0.24332754235518606,
        "compression_ratio": 1.7383177570093458,
        "end": 4426.66,
        "id": 1371,
        "no_speech_prob": 0.0001465309615014121,
        "seek": 439678,
        "start": 4424.66,
        "temperature": 0,
        "text": " So this could be because what I want to do",
        "tokens": [
          51758,
          407,
          341,
          727,
          312,
          570,
          437,
          286,
          528,
          281,
          360,
          51858
        ]
      },
      {
        "avg_logprob": -0.22076249733949319,
        "compression_ratio": 1.6514522821576763,
        "end": 4429.26,
        "id": 1372,
        "no_speech_prob": 0.000012029338904540055,
        "seek": 442666,
        "start": 4427.54,
        "temperature": 0,
        "text": " is create an API out in the world for people",
        "tokens": [
          50408,
          307,
          1884,
          364,
          9362,
          484,
          294,
          264,
          1002,
          337,
          561,
          50494
        ]
      },
      {
        "avg_logprob": -0.22076249733949319,
        "compression_ratio": 1.6514522821576763,
        "end": 4430.66,
        "id": 1373,
        "no_speech_prob": 0.000012029338904540055,
        "seek": 442666,
        "start": 4429.26,
        "temperature": 0,
        "text": " to get drawing information.",
        "tokens": [
          50494,
          281,
          483,
          6316,
          1589,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.22076249733949319,
        "compression_ratio": 1.6514522821576763,
        "end": 4432.26,
        "id": 1374,
        "no_speech_prob": 0.000012029338904540055,
        "seek": 442666,
        "start": 4430.66,
        "temperature": 0,
        "text": " But this isn't data that I own in a way",
        "tokens": [
          50564,
          583,
          341,
          1943,
          380,
          1412,
          300,
          286,
          1065,
          294,
          257,
          636,
          50644
        ]
      },
      {
        "avg_logprob": -0.22076249733949319,
        "compression_ratio": 1.6514522821576763,
        "end": 4434.099999999999,
        "id": 1375,
        "no_speech_prob": 0.000012029338904540055,
        "seek": 442666,
        "start": 4432.26,
        "temperature": 0,
        "text": " that I would necessarily do that.",
        "tokens": [
          50644,
          300,
          286,
          576,
          4725,
          360,
          300,
          13,
          50736
        ]
      },
      {
        "avg_logprob": -0.22076249733949319,
        "compression_ratio": 1.6514522821576763,
        "end": 4435.78,
        "id": 1376,
        "no_speech_prob": 0.000012029338904540055,
        "seek": 442666,
        "start": 4434.099999999999,
        "temperature": 0,
        "text": " We'd have to look at the licensing to see",
        "tokens": [
          50736,
          492,
          1116,
          362,
          281,
          574,
          412,
          264,
          29759,
          281,
          536,
          50820
        ]
      },
      {
        "avg_logprob": -0.22076249733949319,
        "compression_ratio": 1.6514522821576763,
        "end": 4437.82,
        "id": 1377,
        "no_speech_prob": 0.000012029338904540055,
        "seek": 442666,
        "start": 4435.78,
        "temperature": 0,
        "text": " if that's even something reasonable to do.",
        "tokens": [
          50820,
          498,
          300,
          311,
          754,
          746,
          10585,
          281,
          360,
          13,
          50922
        ]
      },
      {
        "avg_logprob": -0.22076249733949319,
        "compression_ratio": 1.6514522821576763,
        "end": 4439.86,
        "id": 1378,
        "no_speech_prob": 0.000012029338904540055,
        "seek": 442666,
        "start": 4437.82,
        "temperature": 0,
        "text": " Where is that eraser?",
        "tokens": [
          50922,
          2305,
          307,
          300,
          46018,
          30,
          51024
        ]
      },
      {
        "avg_logprob": -0.22076249733949319,
        "compression_ratio": 1.6514522821576763,
        "end": 4444.86,
        "id": 1379,
        "no_speech_prob": 0.000012029338904540055,
        "seek": 442666,
        "start": 4439.86,
        "temperature": 0,
        "text": " But what I can do is on my computer here,",
        "tokens": [
          51024,
          583,
          437,
          286,
          393,
          360,
          307,
          322,
          452,
          3820,
          510,
          11,
          51274
        ]
      },
      {
        "avg_logprob": -0.22076249733949319,
        "compression_ratio": 1.6514522821576763,
        "end": 4450.26,
        "id": 1380,
        "no_speech_prob": 0.000012029338904540055,
        "seek": 442666,
        "start": 4447.26,
        "temperature": 0,
        "text": " the idea here is, oh, I'm going to make a server.",
        "tokens": [
          51394,
          264,
          1558,
          510,
          307,
          11,
          1954,
          11,
          286,
          478,
          516,
          281,
          652,
          257,
          7154,
          13,
          51544
        ]
      },
      {
        "avg_logprob": -0.22076249733949319,
        "compression_ratio": 1.6514522821576763,
        "end": 4453.58,
        "id": 1381,
        "no_speech_prob": 0.000012029338904540055,
        "seek": 442666,
        "start": 4450.26,
        "temperature": 0,
        "text": " And the server is going to hold all of the drawings.",
        "tokens": [
          51544,
          400,
          264,
          7154,
          307,
          516,
          281,
          1797,
          439,
          295,
          264,
          18618,
          13,
          51710
        ]
      },
      {
        "avg_logprob": -0.254035404750279,
        "compression_ratio": 1.8103448275862069,
        "end": 4455.94,
        "id": 1382,
        "no_speech_prob": 0.000004785086730407784,
        "seek": 445358,
        "start": 4453.58,
        "temperature": 0,
        "text": " And then my p5 sketch can just say,",
        "tokens": [
          50364,
          400,
          550,
          452,
          280,
          20,
          12325,
          393,
          445,
          584,
          11,
          50482
        ]
      },
      {
        "avg_logprob": -0.254035404750279,
        "compression_ratio": 1.8103448275862069,
        "end": 4459.42,
        "id": 1383,
        "no_speech_prob": 0.000004785086730407784,
        "seek": 445358,
        "start": 4455.94,
        "temperature": 0,
        "text": " hey, can make a request, like a get request.",
        "tokens": [
          50482,
          4177,
          11,
          393,
          652,
          257,
          5308,
          11,
          411,
          257,
          483,
          5308,
          13,
          50656
        ]
      },
      {
        "avg_logprob": -0.254035404750279,
        "compression_ratio": 1.8103448275862069,
        "end": 4462.1,
        "id": 1384,
        "no_speech_prob": 0.000004785086730407784,
        "seek": 445358,
        "start": 4459.42,
        "temperature": 0,
        "text": " Please, could I have a rainbow?",
        "tokens": [
          50656,
          2555,
          11,
          727,
          286,
          362,
          257,
          18526,
          30,
          50790
        ]
      },
      {
        "avg_logprob": -0.254035404750279,
        "compression_ratio": 1.8103448275862069,
        "end": 4464.14,
        "id": 1385,
        "no_speech_prob": 0.000004785086730407784,
        "seek": 445358,
        "start": 4462.1,
        "temperature": 0,
        "text": " And then the server is going to send back",
        "tokens": [
          50790,
          400,
          550,
          264,
          7154,
          307,
          516,
          281,
          2845,
          646,
          50892
        ]
      },
      {
        "avg_logprob": -0.254035404750279,
        "compression_ratio": 1.8103448275862069,
        "end": 4465.22,
        "id": 1386,
        "no_speech_prob": 0.000004785086730407784,
        "seek": 445358,
        "start": 4464.14,
        "temperature": 0,
        "text": " just a single drawing.",
        "tokens": [
          50892,
          445,
          257,
          2167,
          6316,
          13,
          50946
        ]
      },
      {
        "avg_logprob": -0.254035404750279,
        "compression_ratio": 1.8103448275862069,
        "end": 4467.3,
        "id": 1387,
        "no_speech_prob": 0.000004785086730407784,
        "seek": 445358,
        "start": 4465.22,
        "temperature": 0,
        "text": " It's not going to send back hundreds of megabytes of data.",
        "tokens": [
          50946,
          467,
          311,
          406,
          516,
          281,
          2845,
          646,
          6779,
          295,
          10816,
          24538,
          295,
          1412,
          13,
          51050
        ]
      },
      {
        "avg_logprob": -0.254035404750279,
        "compression_ratio": 1.8103448275862069,
        "end": 4469.0599999999995,
        "id": 1388,
        "no_speech_prob": 0.000004785086730407784,
        "seek": 445358,
        "start": 4467.3,
        "temperature": 0,
        "text": " It's storing all that data, but it's",
        "tokens": [
          51050,
          467,
          311,
          26085,
          439,
          300,
          1412,
          11,
          457,
          309,
          311,
          51138
        ]
      },
      {
        "avg_logprob": -0.254035404750279,
        "compression_ratio": 1.8103448275862069,
        "end": 4470.54,
        "id": 1389,
        "no_speech_prob": 0.000004785086730407784,
        "seek": 445358,
        "start": 4469.0599999999995,
        "temperature": 0,
        "text": " going to send back just one piece.",
        "tokens": [
          51138,
          516,
          281,
          2845,
          646,
          445,
          472,
          2522,
          13,
          51212
        ]
      },
      {
        "avg_logprob": -0.254035404750279,
        "compression_ratio": 1.8103448275862069,
        "end": 4472.94,
        "id": 1390,
        "no_speech_prob": 0.000004785086730407784,
        "seek": 445358,
        "start": 4470.54,
        "temperature": 0,
        "text": " The interesting thing is this server can easily just also",
        "tokens": [
          51212,
          440,
          1880,
          551,
          307,
          341,
          7154,
          393,
          3612,
          445,
          611,
          51332
        ]
      },
      {
        "avg_logprob": -0.254035404750279,
        "compression_ratio": 1.8103448275862069,
        "end": 4474.58,
        "id": 1391,
        "no_speech_prob": 0.000004785086730407784,
        "seek": 445358,
        "start": 4472.94,
        "temperature": 0,
        "text": " run on the laptop.",
        "tokens": [
          51332,
          1190,
          322,
          264,
          10732,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.254035404750279,
        "compression_ratio": 1.8103448275862069,
        "end": 4476.26,
        "id": 1392,
        "no_speech_prob": 0.000004785086730407784,
        "seek": 445358,
        "start": 4474.58,
        "temperature": 0,
        "text": " So and I could connect to it.",
        "tokens": [
          51414,
          407,
          293,
          286,
          727,
          1745,
          281,
          309,
          13,
          51498
        ]
      },
      {
        "avg_logprob": -0.254035404750279,
        "compression_ratio": 1.8103448275862069,
        "end": 4479.18,
        "id": 1393,
        "no_speech_prob": 0.000004785086730407784,
        "seek": 445358,
        "start": 4476.26,
        "temperature": 0,
        "text": " So there's a variety of ways you could deploy this and use this.",
        "tokens": [
          51498,
          407,
          456,
          311,
          257,
          5673,
          295,
          2098,
          291,
          727,
          7274,
          341,
          293,
          764,
          341,
          13,
          51644
        ]
      },
      {
        "avg_logprob": -0.254035404750279,
        "compression_ratio": 1.8103448275862069,
        "end": 4481.34,
        "id": 1394,
        "no_speech_prob": 0.000004785086730407784,
        "seek": 445358,
        "start": 4479.18,
        "temperature": 0,
        "text": " But I'm going to do it all from this laptop.",
        "tokens": [
          51644,
          583,
          286,
          478,
          516,
          281,
          360,
          309,
          439,
          490,
          341,
          10732,
          13,
          51752
        ]
      },
      {
        "avg_logprob": -0.24933333069313574,
        "compression_ratio": 1.6944444444444444,
        "end": 4483.18,
        "id": 1395,
        "no_speech_prob": 0.0000147388736877474,
        "seek": 448134,
        "start": 4481.34,
        "temperature": 0,
        "text": " So to run a server with Node and Express,",
        "tokens": [
          50364,
          407,
          281,
          1190,
          257,
          7154,
          365,
          38640,
          293,
          20212,
          11,
          50456
        ]
      },
      {
        "avg_logprob": -0.24933333069313574,
        "compression_ratio": 1.6944444444444444,
        "end": 4485.3,
        "id": 1396,
        "no_speech_prob": 0.0000147388736877474,
        "seek": 448134,
        "start": 4483.18,
        "temperature": 0,
        "text": " you can go back and watch some of these videos where",
        "tokens": [
          50456,
          291,
          393,
          352,
          646,
          293,
          1159,
          512,
          295,
          613,
          2145,
          689,
          50562
        ]
      },
      {
        "avg_logprob": -0.24933333069313574,
        "compression_ratio": 1.6944444444444444,
        "end": 4486.9800000000005,
        "id": 1397,
        "no_speech_prob": 0.0000147388736877474,
        "seek": 448134,
        "start": 4485.3,
        "temperature": 0,
        "text": " I step through this in more detail.",
        "tokens": [
          50562,
          286,
          1823,
          807,
          341,
          294,
          544,
          2607,
          13,
          50646
        ]
      },
      {
        "avg_logprob": -0.24933333069313574,
        "compression_ratio": 1.6944444444444444,
        "end": 4490.9400000000005,
        "id": 1398,
        "no_speech_prob": 0.0000147388736877474,
        "seek": 448134,
        "start": 4486.9800000000005,
        "temperature": 0,
        "text": " I'm just going to start it in the directory in my console.",
        "tokens": [
          50646,
          286,
          478,
          445,
          516,
          281,
          722,
          309,
          294,
          264,
          21120,
          294,
          452,
          11076,
          13,
          50844
        ]
      },
      {
        "avg_logprob": -0.24933333069313574,
        "compression_ratio": 1.6944444444444444,
        "end": 4493.26,
        "id": 1399,
        "no_speech_prob": 0.0000147388736877474,
        "seek": 448134,
        "start": 4490.9400000000005,
        "temperature": 0,
        "text": " And I'm going to say npm init.",
        "tokens": [
          50844,
          400,
          286,
          478,
          516,
          281,
          584,
          297,
          14395,
          3157,
          13,
          50960
        ]
      },
      {
        "avg_logprob": -0.24933333069313574,
        "compression_ratio": 1.6944444444444444,
        "end": 4497.78,
        "id": 1400,
        "no_speech_prob": 0.0000147388736877474,
        "seek": 448134,
        "start": 4493.26,
        "temperature": 0,
        "text": " And I'm going to call this a coding train quick draw",
        "tokens": [
          50960,
          400,
          286,
          478,
          516,
          281,
          818,
          341,
          257,
          17720,
          3847,
          1702,
          2642,
          51186
        ]
      },
      {
        "avg_logprob": -0.24933333069313574,
        "compression_ratio": 1.6944444444444444,
        "end": 4499.5,
        "id": 1401,
        "no_speech_prob": 0.0000147388736877474,
        "seek": 448134,
        "start": 4497.78,
        "temperature": 0,
        "text": " example.",
        "tokens": [
          51186,
          1365,
          13,
          51272
        ]
      },
      {
        "avg_logprob": -0.24933333069313574,
        "compression_ratio": 1.6944444444444444,
        "end": 4502.18,
        "id": 1402,
        "no_speech_prob": 0.0000147388736877474,
        "seek": 448134,
        "start": 4499.5,
        "temperature": 0,
        "text": " And it's version 0.0.1.",
        "tokens": [
          51272,
          400,
          309,
          311,
          3037,
          1958,
          13,
          15,
          13,
          16,
          13,
          51406
        ]
      },
      {
        "avg_logprob": -0.24933333069313574,
        "compression_ratio": 1.6944444444444444,
        "end": 4506.82,
        "id": 1403,
        "no_speech_prob": 0.0000147388736877474,
        "seek": 448134,
        "start": 4502.18,
        "temperature": 0,
        "text": " It is an example that I am making on the coding train.",
        "tokens": [
          51406,
          467,
          307,
          364,
          1365,
          300,
          286,
          669,
          1455,
          322,
          264,
          17720,
          3847,
          13,
          51638
        ]
      },
      {
        "avg_logprob": -0.24933333069313574,
        "compression_ratio": 1.6944444444444444,
        "end": 4509.66,
        "id": 1404,
        "no_speech_prob": 0.0000147388736877474,
        "seek": 448134,
        "start": 4506.82,
        "temperature": 0,
        "text": " And whatever, I'm going to skip through a lot of this stuff.",
        "tokens": [
          51638,
          400,
          2035,
          11,
          286,
          478,
          516,
          281,
          10023,
          807,
          257,
          688,
          295,
          341,
          1507,
          13,
          51780
        ]
      },
      {
        "avg_logprob": -0.24933333069313574,
        "compression_ratio": 1.6944444444444444,
        "end": 4510.46,
        "id": 1405,
        "no_speech_prob": 0.0000147388736877474,
        "seek": 448134,
        "start": 4509.66,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          51780,
          1079,
          13,
          51820
        ]
      },
      {
        "avg_logprob": -0.20407429388013937,
        "compression_ratio": 1.6954732510288066,
        "end": 4513.62,
        "id": 1406,
        "no_speech_prob": 0.000005594313734036405,
        "seek": 451046,
        "start": 4510.74,
        "temperature": 0,
        "text": " So now if I go to my code, you can actually",
        "tokens": [
          50378,
          407,
          586,
          498,
          286,
          352,
          281,
          452,
          3089,
          11,
          291,
          393,
          767,
          50522
        ]
      },
      {
        "avg_logprob": -0.20407429388013937,
        "compression_ratio": 1.6954732510288066,
        "end": 4516.22,
        "id": 1407,
        "no_speech_prob": 0.000005594313734036405,
        "seek": 451046,
        "start": 4513.62,
        "temperature": 0,
        "text": " see I have this package.json file.",
        "tokens": [
          50522,
          536,
          286,
          362,
          341,
          7372,
          13,
          73,
          3015,
          3991,
          13,
          50652
        ]
      },
      {
        "avg_logprob": -0.20407429388013937,
        "compression_ratio": 1.6954732510288066,
        "end": 4518.58,
        "id": 1408,
        "no_speech_prob": 0.000005594313734036405,
        "seek": 451046,
        "start": 4516.22,
        "temperature": 0,
        "text": " The package.json file has all that information",
        "tokens": [
          50652,
          440,
          7372,
          13,
          73,
          3015,
          3991,
          575,
          439,
          300,
          1589,
          50770
        ]
      },
      {
        "avg_logprob": -0.20407429388013937,
        "compression_ratio": 1.6954732510288066,
        "end": 4519.62,
        "id": 1409,
        "no_speech_prob": 0.000005594313734036405,
        "seek": 451046,
        "start": 4518.58,
        "temperature": 0,
        "text": " that I just entered.",
        "tokens": [
          50770,
          300,
          286,
          445,
          9065,
          13,
          50822
        ]
      },
      {
        "avg_logprob": -0.20407429388013937,
        "compression_ratio": 1.6954732510288066,
        "end": 4523.22,
        "id": 1410,
        "no_speech_prob": 0.000005594313734036405,
        "seek": 451046,
        "start": 4519.62,
        "temperature": 0,
        "text": " This is the configuration file for my project.",
        "tokens": [
          50822,
          639,
          307,
          264,
          11694,
          3991,
          337,
          452,
          1716,
          13,
          51002
        ]
      },
      {
        "avg_logprob": -0.20407429388013937,
        "compression_ratio": 1.6954732510288066,
        "end": 4526.32,
        "id": 1411,
        "no_speech_prob": 0.000005594313734036405,
        "seek": 451046,
        "start": 4523.22,
        "temperature": 0,
        "text": " Node is the central manager of this project now.",
        "tokens": [
          51002,
          38640,
          307,
          264,
          5777,
          6598,
          295,
          341,
          1716,
          586,
          13,
          51157
        ]
      },
      {
        "avg_logprob": -0.20407429388013937,
        "compression_ratio": 1.6954732510288066,
        "end": 4530.26,
        "id": 1412,
        "no_speech_prob": 0.000005594313734036405,
        "seek": 451046,
        "start": 4526.32,
        "temperature": 0,
        "text": " So I need a couple Node packages to be able to make this work.",
        "tokens": [
          51157,
          407,
          286,
          643,
          257,
          1916,
          38640,
          17401,
          281,
          312,
          1075,
          281,
          652,
          341,
          589,
          13,
          51354
        ]
      },
      {
        "avg_logprob": -0.20407429388013937,
        "compression_ratio": 1.6954732510288066,
        "end": 4532.3,
        "id": 1413,
        "no_speech_prob": 0.000005594313734036405,
        "seek": 451046,
        "start": 4530.26,
        "temperature": 0,
        "text": " I need to use Express.",
        "tokens": [
          51354,
          286,
          643,
          281,
          764,
          20212,
          13,
          51456
        ]
      },
      {
        "avg_logprob": -0.20407429388013937,
        "compression_ratio": 1.6954732510288066,
        "end": 4535.9800000000005,
        "id": 1414,
        "no_speech_prob": 0.000005594313734036405,
        "seek": 451046,
        "start": 4532.3,
        "temperature": 0,
        "text": " Express is what I'm going to use to handle that get request,",
        "tokens": [
          51456,
          20212,
          307,
          437,
          286,
          478,
          516,
          281,
          764,
          281,
          4813,
          300,
          483,
          5308,
          11,
          51640
        ]
      },
      {
        "avg_logprob": -0.20407429388013937,
        "compression_ratio": 1.6954732510288066,
        "end": 4538.6,
        "id": 1415,
        "no_speech_prob": 0.000005594313734036405,
        "seek": 451046,
        "start": 4535.9800000000005,
        "temperature": 0,
        "text": " this HTTP get request.",
        "tokens": [
          51640,
          341,
          33283,
          483,
          5308,
          13,
          51771
        ]
      },
      {
        "avg_logprob": -0.2174765458747522,
        "compression_ratio": 1.7320574162679425,
        "end": 4541.160000000001,
        "id": 1416,
        "no_speech_prob": 0.00007031066343188286,
        "seek": 453860,
        "start": 4538.6,
        "temperature": 0,
        "text": " So I'm going to say npm install express.",
        "tokens": [
          50364,
          407,
          286,
          478,
          516,
          281,
          584,
          297,
          14395,
          3625,
          5109,
          13,
          50492
        ]
      },
      {
        "avg_logprob": -0.2174765458747522,
        "compression_ratio": 1.7320574162679425,
        "end": 4545.200000000001,
        "id": 1417,
        "no_speech_prob": 0.00007031066343188286,
        "seek": 453860,
        "start": 4541.160000000001,
        "temperature": 0,
        "text": " And then I also need something to load that nd.json file.",
        "tokens": [
          50492,
          400,
          550,
          286,
          611,
          643,
          746,
          281,
          3677,
          300,
          220,
          273,
          13,
          73,
          3015,
          3991,
          13,
          50694
        ]
      },
      {
        "avg_logprob": -0.2174765458747522,
        "compression_ratio": 1.7320574162679425,
        "end": 4548.320000000001,
        "id": 1418,
        "no_speech_prob": 0.00007031066343188286,
        "seek": 453860,
        "start": 4545.200000000001,
        "temperature": 0,
        "text": " So nd.json node.",
        "tokens": [
          50694,
          407,
          220,
          273,
          13,
          73,
          3015,
          9984,
          13,
          50850
        ]
      },
      {
        "avg_logprob": -0.2174765458747522,
        "compression_ratio": 1.7320574162679425,
        "end": 4549.92,
        "id": 1419,
        "no_speech_prob": 0.00007031066343188286,
        "seek": 453860,
        "start": 4548.320000000001,
        "temperature": 0,
        "text": " I've actually used this before.",
        "tokens": [
          50850,
          286,
          600,
          767,
          1143,
          341,
          949,
          13,
          50930
        ]
      },
      {
        "avg_logprob": -0.2174765458747522,
        "compression_ratio": 1.7320574162679425,
        "end": 4550.6,
        "id": 1420,
        "no_speech_prob": 0.00007031066343188286,
        "seek": 453860,
        "start": 4549.92,
        "temperature": 0,
        "text": " But let's look.",
        "tokens": [
          50930,
          583,
          718,
          311,
          574,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2174765458747522,
        "compression_ratio": 1.7320574162679425,
        "end": 4555.360000000001,
        "id": 1421,
        "no_speech_prob": 0.00007031066343188286,
        "seek": 453860,
        "start": 4550.6,
        "temperature": 0,
        "text": " So this is a Node package for loading an nd.json file.",
        "tokens": [
          50964,
          407,
          341,
          307,
          257,
          38640,
          7372,
          337,
          15114,
          364,
          220,
          273,
          13,
          73,
          3015,
          3991,
          13,
          51202
        ]
      },
      {
        "avg_logprob": -0.2174765458747522,
        "compression_ratio": 1.7320574162679425,
        "end": 4559.88,
        "id": 1422,
        "no_speech_prob": 0.00007031066343188286,
        "seek": 453860,
        "start": 4555.360000000001,
        "temperature": 0,
        "text": " So I'm going to say npm install nd.json.",
        "tokens": [
          51202,
          407,
          286,
          478,
          516,
          281,
          584,
          297,
          14395,
          3625,
          220,
          273,
          13,
          73,
          3015,
          13,
          51428
        ]
      },
      {
        "avg_logprob": -0.2174765458747522,
        "compression_ratio": 1.7320574162679425,
        "end": 4560.64,
        "id": 1423,
        "no_speech_prob": 0.00007031066343188286,
        "seek": 453860,
        "start": 4559.88,
        "temperature": 0,
        "text": " Great.",
        "tokens": [
          51428,
          3769,
          13,
          51466
        ]
      },
      {
        "avg_logprob": -0.2174765458747522,
        "compression_ratio": 1.7320574162679425,
        "end": 4561.240000000001,
        "id": 1424,
        "no_speech_prob": 0.00007031066343188286,
        "seek": 453860,
        "start": 4560.64,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51466,
          821,
          321,
          352,
          13,
          51496
        ]
      },
      {
        "avg_logprob": -0.2174765458747522,
        "compression_ratio": 1.7320574162679425,
        "end": 4564.04,
        "id": 1425,
        "no_speech_prob": 0.00007031066343188286,
        "seek": 453860,
        "start": 4561.240000000001,
        "temperature": 0,
        "text": " And now I meant to show you what is that nd.json.",
        "tokens": [
          51496,
          400,
          586,
          286,
          4140,
          281,
          855,
          291,
          437,
          307,
          300,
          220,
          273,
          13,
          73,
          3015,
          13,
          51636
        ]
      },
      {
        "avg_logprob": -0.2174765458747522,
        "compression_ratio": 1.7320574162679425,
        "end": 4566.76,
        "id": 1426,
        "no_speech_prob": 0.00007031066343188286,
        "seek": 453860,
        "start": 4564.04,
        "temperature": 0,
        "text": " Oh, I got to grab that file now.",
        "tokens": [
          51636,
          876,
          11,
          286,
          658,
          281,
          4444,
          300,
          3991,
          586,
          13,
          51772
        ]
      },
      {
        "avg_logprob": -0.24840916089775147,
        "compression_ratio": 1.6906779661016949,
        "end": 4571.2,
        "id": 1427,
        "no_speech_prob": 0.000005338141363608884,
        "seek": 456676,
        "start": 4567.56,
        "temperature": 0,
        "text": " I'm just going to rename this to rainbow.nd.json.",
        "tokens": [
          50404,
          286,
          478,
          445,
          516,
          281,
          36741,
          341,
          281,
          18526,
          13,
          273,
          13,
          73,
          3015,
          13,
          50586
        ]
      },
      {
        "avg_logprob": -0.24840916089775147,
        "compression_ratio": 1.6906779661016949,
        "end": 4574.08,
        "id": 1428,
        "no_speech_prob": 0.000005338141363608884,
        "seek": 456676,
        "start": 4571.2,
        "temperature": 0,
        "text": " I'm going to drag it here into my project.",
        "tokens": [
          50586,
          286,
          478,
          516,
          281,
          5286,
          309,
          510,
          666,
          452,
          1716,
          13,
          50730
        ]
      },
      {
        "avg_logprob": -0.24840916089775147,
        "compression_ratio": 1.6906779661016949,
        "end": 4576.04,
        "id": 1429,
        "no_speech_prob": 0.000005338141363608884,
        "seek": 456676,
        "start": 4574.08,
        "temperature": 0,
        "text": " So now this is a huge file.",
        "tokens": [
          50730,
          407,
          586,
          341,
          307,
          257,
          2603,
          3991,
          13,
          50828
        ]
      },
      {
        "avg_logprob": -0.24840916089775147,
        "compression_ratio": 1.6906779661016949,
        "end": 4579.12,
        "id": 1430,
        "no_speech_prob": 0.000005338141363608884,
        "seek": 456676,
        "start": 4576.04,
        "temperature": 0,
        "text": " And so you can see that Visual Studio Code is freaking out.",
        "tokens": [
          50828,
          400,
          370,
          291,
          393,
          536,
          300,
          23187,
          13500,
          15549,
          307,
          14612,
          484,
          13,
          50982
        ]
      },
      {
        "avg_logprob": -0.24840916089775147,
        "compression_ratio": 1.6906779661016949,
        "end": 4582.08,
        "id": 1431,
        "no_speech_prob": 0.000005338141363608884,
        "seek": 456676,
        "start": 4579.12,
        "temperature": 0,
        "text": " It's like, I don't want to deal with this file",
        "tokens": [
          50982,
          467,
          311,
          411,
          11,
          286,
          500,
          380,
          528,
          281,
          2028,
          365,
          341,
          3991,
          51130
        ]
      },
      {
        "avg_logprob": -0.24840916089775147,
        "compression_ratio": 1.6906779661016949,
        "end": 4584.88,
        "id": 1432,
        "no_speech_prob": 0.000005338141363608884,
        "seek": 456676,
        "start": 4582.08,
        "temperature": 0,
        "text": " because it's too big.",
        "tokens": [
          51130,
          570,
          309,
          311,
          886,
          955,
          13,
          51270
        ]
      },
      {
        "avg_logprob": -0.24840916089775147,
        "compression_ratio": 1.6906779661016949,
        "end": 4586.72,
        "id": 1433,
        "no_speech_prob": 0.000005338141363608884,
        "seek": 456676,
        "start": 4584.88,
        "temperature": 0,
        "text": " But you can see that what this is",
        "tokens": [
          51270,
          583,
          291,
          393,
          536,
          300,
          437,
          341,
          307,
          51362
        ]
      },
      {
        "avg_logprob": -0.24840916089775147,
        "compression_ratio": 1.6906779661016949,
        "end": 4590.72,
        "id": 1434,
        "no_speech_prob": 0.000005338141363608884,
        "seek": 456676,
        "start": 4586.72,
        "temperature": 0,
        "text": " is every single drawing on one line.",
        "tokens": [
          51362,
          307,
          633,
          2167,
          6316,
          322,
          472,
          1622,
          13,
          51562
        ]
      },
      {
        "avg_logprob": -0.24840916089775147,
        "compression_ratio": 1.6906779661016949,
        "end": 4593.12,
        "id": 1435,
        "no_speech_prob": 0.000005338141363608884,
        "seek": 456676,
        "start": 4590.72,
        "temperature": 0,
        "text": " So it's like this is my database, essentially,",
        "tokens": [
          51562,
          407,
          309,
          311,
          411,
          341,
          307,
          452,
          8149,
          11,
          4476,
          11,
          51682
        ]
      },
      {
        "avg_logprob": -0.24840916089775147,
        "compression_ratio": 1.6906779661016949,
        "end": 4595.280000000001,
        "id": 1436,
        "no_speech_prob": 0.000005338141363608884,
        "seek": 456676,
        "start": 4593.12,
        "temperature": 0,
        "text": " a database of rainbow drawings.",
        "tokens": [
          51682,
          257,
          8149,
          295,
          18526,
          18618,
          13,
          51790
        ]
      },
      {
        "avg_logprob": -0.24440664994089226,
        "compression_ratio": 1.7056277056277056,
        "end": 4597.04,
        "id": 1437,
        "no_speech_prob": 0.000057387449487578124,
        "seek": 459528,
        "start": 4595.28,
        "temperature": 0,
        "text": " I have a database of rainbow drawings.",
        "tokens": [
          50364,
          286,
          362,
          257,
          8149,
          295,
          18526,
          18618,
          13,
          50452
        ]
      },
      {
        "avg_logprob": -0.24440664994089226,
        "compression_ratio": 1.7056277056277056,
        "end": 4599.16,
        "id": 1438,
        "no_speech_prob": 0.000057387449487578124,
        "seek": 459528,
        "start": 4597.04,
        "temperature": 0,
        "text": " What could be better?",
        "tokens": [
          50452,
          708,
          727,
          312,
          1101,
          30,
          50558
        ]
      },
      {
        "avg_logprob": -0.24440664994089226,
        "compression_ratio": 1.7056277056277056,
        "end": 4600.84,
        "id": 1439,
        "no_speech_prob": 0.000057387449487578124,
        "seek": 459528,
        "start": 4599.16,
        "temperature": 0,
        "text": " OK, so what was I doing?",
        "tokens": [
          50558,
          2264,
          11,
          370,
          437,
          390,
          286,
          884,
          30,
          50642
        ]
      },
      {
        "avg_logprob": -0.24440664994089226,
        "compression_ratio": 1.7056277056277056,
        "end": 4604.88,
        "id": 1440,
        "no_speech_prob": 0.000057387449487578124,
        "seek": 459528,
        "start": 4600.84,
        "temperature": 0,
        "text": " Back to the code in the server.",
        "tokens": [
          50642,
          5833,
          281,
          264,
          3089,
          294,
          264,
          7154,
          13,
          50844
        ]
      },
      {
        "avg_logprob": -0.24440664994089226,
        "compression_ratio": 1.7056277056277056,
        "end": 4606.719999999999,
        "id": 1441,
        "no_speech_prob": 0.000057387449487578124,
        "seek": 459528,
        "start": 4604.88,
        "temperature": 0,
        "text": " Oh, I don't have a server yet.",
        "tokens": [
          50844,
          876,
          11,
          286,
          500,
          380,
          362,
          257,
          7154,
          1939,
          13,
          50936
        ]
      },
      {
        "avg_logprob": -0.24440664994089226,
        "compression_ratio": 1.7056277056277056,
        "end": 4607.639999999999,
        "id": 1442,
        "no_speech_prob": 0.000057387449487578124,
        "seek": 459528,
        "start": 4606.719999999999,
        "temperature": 0,
        "text": " I'm going to add one.",
        "tokens": [
          50936,
          286,
          478,
          516,
          281,
          909,
          472,
          13,
          50982
        ]
      },
      {
        "avg_logprob": -0.24440664994089226,
        "compression_ratio": 1.7056277056277056,
        "end": 4610.44,
        "id": 1443,
        "no_speech_prob": 0.000057387449487578124,
        "seek": 459528,
        "start": 4607.639999999999,
        "temperature": 0,
        "text": " I'm going to call it server.js.",
        "tokens": [
          50982,
          286,
          478,
          516,
          281,
          818,
          309,
          7154,
          13,
          25530,
          13,
          51122
        ]
      },
      {
        "avg_logprob": -0.24440664994089226,
        "compression_ratio": 1.7056277056277056,
        "end": 4613.4,
        "id": 1444,
        "no_speech_prob": 0.000057387449487578124,
        "seek": 459528,
        "start": 4610.44,
        "temperature": 0,
        "text": " I could call it app.js or index.js.",
        "tokens": [
          51122,
          286,
          727,
          818,
          309,
          724,
          13,
          25530,
          420,
          8186,
          13,
          25530,
          13,
          51270
        ]
      },
      {
        "avg_logprob": -0.24440664994089226,
        "compression_ratio": 1.7056277056277056,
        "end": 4615.36,
        "id": 1445,
        "no_speech_prob": 0.000057387449487578124,
        "seek": 459528,
        "start": 4613.4,
        "temperature": 0,
        "text": " And here I'm going to go back to this.",
        "tokens": [
          51270,
          400,
          510,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          341,
          13,
          51368
        ]
      },
      {
        "avg_logprob": -0.24440664994089226,
        "compression_ratio": 1.7056277056277056,
        "end": 4619.96,
        "id": 1446,
        "no_speech_prob": 0.000057387449487578124,
        "seek": 459528,
        "start": 4615.36,
        "temperature": 0,
        "text": " And basically, I just want to do exactly this.",
        "tokens": [
          51368,
          400,
          1936,
          11,
          286,
          445,
          528,
          281,
          360,
          2293,
          341,
          13,
          51598
        ]
      },
      {
        "avg_logprob": -0.24440664994089226,
        "compression_ratio": 1.7056277056277056,
        "end": 4622.679999999999,
        "id": 1447,
        "no_speech_prob": 0.000057387449487578124,
        "seek": 459528,
        "start": 4619.96,
        "temperature": 0,
        "text": " So the first thing I want to use this,",
        "tokens": [
          51598,
          407,
          264,
          700,
          551,
          286,
          528,
          281,
          764,
          341,
          11,
          51734
        ]
      },
      {
        "avg_logprob": -0.24440664994089226,
        "compression_ratio": 1.7056277056277056,
        "end": 4624.719999999999,
        "id": 1448,
        "no_speech_prob": 0.000057387449487578124,
        "seek": 459528,
        "start": 4622.679999999999,
        "temperature": 0,
        "text": " I need the file system module.",
        "tokens": [
          51734,
          286,
          643,
          264,
          3991,
          1185,
          10088,
          13,
          51836
        ]
      },
      {
        "avg_logprob": -0.2387665445490401,
        "compression_ratio": 1.6768558951965065,
        "end": 4628.04,
        "id": 1449,
        "no_speech_prob": 0.000004222821644361829,
        "seek": 462472,
        "start": 4624.72,
        "temperature": 0,
        "text": " So I'm going to say const fs equals require file system.",
        "tokens": [
          50364,
          407,
          286,
          478,
          516,
          281,
          584,
          1817,
          283,
          82,
          6915,
          3651,
          3991,
          1185,
          13,
          50530
        ]
      },
      {
        "avg_logprob": -0.2387665445490401,
        "compression_ratio": 1.6768558951965065,
        "end": 4631.12,
        "id": 1450,
        "no_speech_prob": 0.000004222821644361829,
        "seek": 462472,
        "start": 4628.04,
        "temperature": 0,
        "text": " File system is a module that comes with Node.",
        "tokens": [
          50530,
          26196,
          1185,
          307,
          257,
          10088,
          300,
          1487,
          365,
          38640,
          13,
          50684
        ]
      },
      {
        "avg_logprob": -0.2387665445490401,
        "compression_ratio": 1.6768558951965065,
        "end": 4632.4800000000005,
        "id": 1451,
        "no_speech_prob": 0.000004222821644361829,
        "seek": 462472,
        "start": 4631.12,
        "temperature": 0,
        "text": " I don't have to install it.",
        "tokens": [
          50684,
          286,
          500,
          380,
          362,
          281,
          3625,
          309,
          13,
          50752
        ]
      },
      {
        "avg_logprob": -0.2387665445490401,
        "compression_ratio": 1.6768558951965065,
        "end": 4638,
        "id": 1452,
        "no_speech_prob": 0.000004222821644361829,
        "seek": 462472,
        "start": 4632.4800000000005,
        "temperature": 0,
        "text": " But I also want the nd.json module,",
        "tokens": [
          50752,
          583,
          286,
          611,
          528,
          264,
          220,
          273,
          13,
          73,
          3015,
          10088,
          11,
          51028
        ]
      },
      {
        "avg_logprob": -0.2387665445490401,
        "compression_ratio": 1.6768558951965065,
        "end": 4642.76,
        "id": 1453,
        "no_speech_prob": 0.000004222821644361829,
        "seek": 462472,
        "start": 4638,
        "temperature": 0,
        "text": " which doesn't come with Node, but I added it.",
        "tokens": [
          51028,
          597,
          1177,
          380,
          808,
          365,
          38640,
          11,
          457,
          286,
          3869,
          309,
          13,
          51266
        ]
      },
      {
        "avg_logprob": -0.2387665445490401,
        "compression_ratio": 1.6768558951965065,
        "end": 4644.96,
        "id": 1454,
        "no_speech_prob": 0.000004222821644361829,
        "seek": 462472,
        "start": 4642.76,
        "temperature": 0,
        "text": " And here we go.",
        "tokens": [
          51266,
          400,
          510,
          321,
          352,
          13,
          51376
        ]
      },
      {
        "avg_logprob": -0.2387665445490401,
        "compression_ratio": 1.6768558951965065,
        "end": 4647.280000000001,
        "id": 1455,
        "no_speech_prob": 0.000004222821644361829,
        "seek": 462472,
        "start": 4644.96,
        "temperature": 0,
        "text": " And we can see, by the way, that when I installed those,",
        "tokens": [
          51376,
          400,
          321,
          393,
          536,
          11,
          538,
          264,
          636,
          11,
          300,
          562,
          286,
          8899,
          729,
          11,
          51492
        ]
      },
      {
        "avg_logprob": -0.2387665445490401,
        "compression_ratio": 1.6768558951965065,
        "end": 4650.96,
        "id": 1456,
        "no_speech_prob": 0.000004222821644361829,
        "seek": 462472,
        "start": 4647.280000000001,
        "temperature": 0,
        "text": " they are now dependencies in the package.json file.",
        "tokens": [
          51492,
          436,
          366,
          586,
          36606,
          294,
          264,
          7372,
          13,
          73,
          3015,
          3991,
          13,
          51676
        ]
      },
      {
        "avg_logprob": -0.2387665445490401,
        "compression_ratio": 1.6768558951965065,
        "end": 4653.8,
        "id": 1457,
        "no_speech_prob": 0.000004222821644361829,
        "seek": 462472,
        "start": 4650.96,
        "temperature": 0,
        "text": " And now, doo-doo-doo-doo-doo.",
        "tokens": [
          51676,
          400,
          586,
          11,
          27572,
          12,
          48302,
          12,
          48302,
          12,
          48302,
          12,
          48302,
          13,
          51818
        ]
      },
      {
        "avg_logprob": -0.2387665445490401,
        "compression_ratio": 1.6768558951965065,
        "end": 4654.6,
        "id": 1458,
        "no_speech_prob": 0.000004222821644361829,
        "seek": 462472,
        "start": 4653.8,
        "temperature": 0,
        "text": " Ah, there we go.",
        "tokens": [
          51818,
          2438,
          11,
          456,
          321,
          352,
          13,
          51858
        ]
      },
      {
        "avg_logprob": -0.20475781304495674,
        "compression_ratio": 1.688715953307393,
        "end": 4656.52,
        "id": 1459,
        "no_speech_prob": 0.00001497103221481666,
        "seek": 465460,
        "start": 4655.6,
        "temperature": 0,
        "text": " So what is this doing?",
        "tokens": [
          50414,
          407,
          437,
          307,
          341,
          884,
          30,
          50460
        ]
      },
      {
        "avg_logprob": -0.20475781304495674,
        "compression_ratio": 1.688715953307393,
        "end": 4657.96,
        "id": 1460,
        "no_speech_prob": 0.00001497103221481666,
        "seek": 465460,
        "start": 4656.52,
        "temperature": 0,
        "text": " This is streaming it.",
        "tokens": [
          50460,
          639,
          307,
          11791,
          309,
          13,
          50532
        ]
      },
      {
        "avg_logprob": -0.20475781304495674,
        "compression_ratio": 1.688715953307393,
        "end": 4659.120000000001,
        "id": 1461,
        "no_speech_prob": 0.00001497103221481666,
        "seek": 465460,
        "start": 4657.96,
        "temperature": 0,
        "text": " So this is really useful.",
        "tokens": [
          50532,
          407,
          341,
          307,
          534,
          4420,
          13,
          50590
        ]
      },
      {
        "avg_logprob": -0.20475781304495674,
        "compression_ratio": 1.688715953307393,
        "end": 4663.52,
        "id": 1462,
        "no_speech_prob": 0.00001497103221481666,
        "seek": 465460,
        "start": 4659.120000000001,
        "temperature": 0,
        "text": " It's a huge file, rainbow.ndjson.",
        "tokens": [
          50590,
          467,
          311,
          257,
          2603,
          3991,
          11,
          18526,
          13,
          273,
          73,
          3015,
          13,
          50810
        ]
      },
      {
        "avg_logprob": -0.20475781304495674,
        "compression_ratio": 1.688715953307393,
        "end": 4666.88,
        "id": 1463,
        "no_speech_prob": 0.00001497103221481666,
        "seek": 465460,
        "start": 4663.52,
        "temperature": 0,
        "text": " I certainly could load it, just loading the file",
        "tokens": [
          50810,
          286,
          3297,
          727,
          3677,
          309,
          11,
          445,
          15114,
          264,
          3991,
          50978
        ]
      },
      {
        "avg_logprob": -0.20475781304495674,
        "compression_ratio": 1.688715953307393,
        "end": 4669.360000000001,
        "id": 1464,
        "no_speech_prob": 0.00001497103221481666,
        "seek": 465460,
        "start": 4666.88,
        "temperature": 0,
        "text": " into a big string, chopping it up, and parsing it.",
        "tokens": [
          50978,
          666,
          257,
          955,
          6798,
          11,
          35205,
          309,
          493,
          11,
          293,
          21156,
          278,
          309,
          13,
          51102
        ]
      },
      {
        "avg_logprob": -0.20475781304495674,
        "compression_ratio": 1.688715953307393,
        "end": 4671.76,
        "id": 1465,
        "no_speech_prob": 0.00001497103221481666,
        "seek": 465460,
        "start": 4669.360000000001,
        "temperature": 0,
        "text": " But when you have a big file, like an nd.json file,",
        "tokens": [
          51102,
          583,
          562,
          291,
          362,
          257,
          955,
          3991,
          11,
          411,
          364,
          220,
          273,
          13,
          73,
          3015,
          3991,
          11,
          51222
        ]
      },
      {
        "avg_logprob": -0.20475781304495674,
        "compression_ratio": 1.688715953307393,
        "end": 4674.56,
        "id": 1466,
        "no_speech_prob": 0.00001497103221481666,
        "seek": 465460,
        "start": 4671.76,
        "temperature": 0,
        "text": " you want to read it as a stream, essentially one line at a time,",
        "tokens": [
          51222,
          291,
          528,
          281,
          1401,
          309,
          382,
          257,
          4309,
          11,
          4476,
          472,
          1622,
          412,
          257,
          565,
          11,
          51362
        ]
      },
      {
        "avg_logprob": -0.20475781304495674,
        "compression_ratio": 1.688715953307393,
        "end": 4677,
        "id": 1467,
        "no_speech_prob": 0.00001497103221481666,
        "seek": 465460,
        "start": 4674.56,
        "temperature": 0,
        "text": " because it could be like a gigabyte file.",
        "tokens": [
          51362,
          570,
          309,
          727,
          312,
          411,
          257,
          8741,
          34529,
          3991,
          13,
          51484
        ]
      },
      {
        "avg_logprob": -0.20475781304495674,
        "compression_ratio": 1.688715953307393,
        "end": 4679.08,
        "id": 1468,
        "no_speech_prob": 0.00001497103221481666,
        "seek": 465460,
        "start": 4677,
        "temperature": 0,
        "text": " In this case, I'm just going to say,",
        "tokens": [
          51484,
          682,
          341,
          1389,
          11,
          286,
          478,
          445,
          516,
          281,
          584,
          11,
          51588
        ]
      },
      {
        "avg_logprob": -0.20475781304495674,
        "compression_ratio": 1.688715953307393,
        "end": 4681.6,
        "id": 1469,
        "no_speech_prob": 0.00001497103221481666,
        "seek": 465460,
        "start": 4679.08,
        "temperature": 0,
        "text": " I'm going to make an empty array.",
        "tokens": [
          51588,
          286,
          478,
          516,
          281,
          652,
          364,
          6707,
          10225,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2355451984565799,
        "compression_ratio": 1.6650485436893203,
        "end": 4684,
        "id": 1470,
        "no_speech_prob": 0.00002753556145762559,
        "seek": 468160,
        "start": 4681.6,
        "temperature": 0,
        "text": " And every single object, I'm just",
        "tokens": [
          50364,
          400,
          633,
          2167,
          2657,
          11,
          286,
          478,
          445,
          50484
        ]
      },
      {
        "avg_logprob": -0.2355451984565799,
        "compression_ratio": 1.6650485436893203,
        "end": 4689.120000000001,
        "id": 1471,
        "no_speech_prob": 0.00002753556145762559,
        "seek": 468160,
        "start": 4684,
        "temperature": 0,
        "text": " going to push into that array.",
        "tokens": [
          50484,
          516,
          281,
          2944,
          666,
          300,
          10225,
          13,
          50740
        ]
      },
      {
        "avg_logprob": -0.2355451984565799,
        "compression_ratio": 1.6650485436893203,
        "end": 4693.160000000001,
        "id": 1472,
        "no_speech_prob": 0.00002753556145762559,
        "seek": 468160,
        "start": 4689.120000000001,
        "temperature": 0,
        "text": " But let's console.log them, just to see that this is working.",
        "tokens": [
          50740,
          583,
          718,
          311,
          11076,
          13,
          4987,
          552,
          11,
          445,
          281,
          536,
          300,
          341,
          307,
          1364,
          13,
          50942
        ]
      },
      {
        "avg_logprob": -0.2355451984565799,
        "compression_ratio": 1.6650485436893203,
        "end": 4694.76,
        "id": 1473,
        "no_speech_prob": 0.00002753556145762559,
        "seek": 468160,
        "start": 4693.160000000001,
        "temperature": 0,
        "text": " So this is the stream.",
        "tokens": [
          50942,
          407,
          341,
          307,
          264,
          4309,
          13,
          51022
        ]
      },
      {
        "avg_logprob": -0.2355451984565799,
        "compression_ratio": 1.6650485436893203,
        "end": 4698.6,
        "id": 1474,
        "no_speech_prob": 0.00002753556145762559,
        "seek": 468160,
        "start": 4694.76,
        "temperature": 0,
        "text": " As it reads line by line by line, the nd.json file,",
        "tokens": [
          51022,
          1018,
          309,
          15700,
          1622,
          538,
          1622,
          538,
          1622,
          11,
          264,
          220,
          273,
          13,
          73,
          3015,
          3991,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.2355451984565799,
        "compression_ratio": 1.6650485436893203,
        "end": 4701.8,
        "id": 1475,
        "no_speech_prob": 0.00002753556145762559,
        "seek": 468160,
        "start": 4698.6,
        "temperature": 0,
        "text": " it's going to console.log that object.",
        "tokens": [
          51214,
          309,
          311,
          516,
          281,
          11076,
          13,
          4987,
          300,
          2657,
          13,
          51374
        ]
      },
      {
        "avg_logprob": -0.2355451984565799,
        "compression_ratio": 1.6650485436893203,
        "end": 4704.88,
        "id": 1476,
        "no_speech_prob": 0.00002753556145762559,
        "seek": 468160,
        "start": 4701.8,
        "temperature": 0,
        "text": " OK, so let's go here.",
        "tokens": [
          51374,
          2264,
          11,
          370,
          718,
          311,
          352,
          510,
          13,
          51528
        ]
      },
      {
        "avg_logprob": -0.2355451984565799,
        "compression_ratio": 1.6650485436893203,
        "end": 4708.64,
        "id": 1477,
        "no_speech_prob": 0.00002753556145762559,
        "seek": 468160,
        "start": 4704.88,
        "temperature": 0,
        "text": " And I'm going to say, node server.js.",
        "tokens": [
          51528,
          400,
          286,
          478,
          516,
          281,
          584,
          11,
          9984,
          7154,
          13,
          25530,
          13,
          51716
        ]
      },
      {
        "avg_logprob": -0.2355451984565799,
        "compression_ratio": 1.6650485436893203,
        "end": 4709.4400000000005,
        "id": 1478,
        "no_speech_prob": 0.00002753556145762559,
        "seek": 468160,
        "start": 4708.64,
        "temperature": 0,
        "text": " And there you go.",
        "tokens": [
          51716,
          400,
          456,
          291,
          352,
          13,
          51756
        ]
      },
      {
        "avg_logprob": -0.2355451984565799,
        "compression_ratio": 1.6650485436893203,
        "end": 4710.4400000000005,
        "id": 1479,
        "no_speech_prob": 0.00002753556145762559,
        "seek": 468160,
        "start": 4709.4400000000005,
        "temperature": 0,
        "text": " You can see, this is it.",
        "tokens": [
          51756,
          509,
          393,
          536,
          11,
          341,
          307,
          309,
          13,
          51806
        ]
      },
      {
        "avg_logprob": -0.2605521545410156,
        "compression_ratio": 1.74,
        "end": 4713.16,
        "id": 1480,
        "no_speech_prob": 0.00001805831925594248,
        "seek": 471044,
        "start": 4710.44,
        "temperature": 0,
        "text": " Every single drawing, it's going to take quite a while,",
        "tokens": [
          50364,
          2048,
          2167,
          6316,
          11,
          309,
          311,
          516,
          281,
          747,
          1596,
          257,
          1339,
          11,
          50500
        ]
      },
      {
        "avg_logprob": -0.2605521545410156,
        "compression_ratio": 1.74,
        "end": 4715.799999999999,
        "id": 1481,
        "no_speech_prob": 0.00001805831925594248,
        "seek": 471044,
        "start": 4713.16,
        "temperature": 0,
        "text": " because there's thousands and thousands and thousands of them.",
        "tokens": [
          50500,
          570,
          456,
          311,
          5383,
          293,
          5383,
          293,
          5383,
          295,
          552,
          13,
          50632
        ]
      },
      {
        "avg_logprob": -0.2605521545410156,
        "compression_ratio": 1.74,
        "end": 4717.5199999999995,
        "id": 1482,
        "no_speech_prob": 0.00001805831925594248,
        "seek": 471044,
        "start": 4715.799999999999,
        "temperature": 0,
        "text": " But you can see, this is the word.",
        "tokens": [
          50632,
          583,
          291,
          393,
          536,
          11,
          341,
          307,
          264,
          1349,
          13,
          50718
        ]
      },
      {
        "avg_logprob": -0.2605521545410156,
        "compression_ratio": 1.74,
        "end": 4718.5599999999995,
        "id": 1483,
        "no_speech_prob": 0.00001805831925594248,
        "seek": 471044,
        "start": 4717.5199999999995,
        "temperature": 0,
        "text": " This was the country code.",
        "tokens": [
          50718,
          639,
          390,
          264,
          1941,
          3089,
          13,
          50770
        ]
      },
      {
        "avg_logprob": -0.2605521545410156,
        "compression_ratio": 1.74,
        "end": 4720.16,
        "id": 1484,
        "no_speech_prob": 0.00001805831925594248,
        "seek": 471044,
        "start": 4718.5599999999995,
        "temperature": 0,
        "text": " This is whether it was recognized.",
        "tokens": [
          50770,
          639,
          307,
          1968,
          309,
          390,
          9823,
          13,
          50850
        ]
      },
      {
        "avg_logprob": -0.2605521545410156,
        "compression_ratio": 1.74,
        "end": 4720.879999999999,
        "id": 1485,
        "no_speech_prob": 0.00001805831925594248,
        "seek": 471044,
        "start": 4720.16,
        "temperature": 0,
        "text": " It has an ID.",
        "tokens": [
          50850,
          467,
          575,
          364,
          7348,
          13,
          50886
        ]
      },
      {
        "avg_logprob": -0.2605521545410156,
        "compression_ratio": 1.74,
        "end": 4722.5599999999995,
        "id": 1486,
        "no_speech_prob": 0.00001805831925594248,
        "seek": 471044,
        "start": 4720.879999999999,
        "temperature": 0,
        "text": " And then the drawing is in these arrays,",
        "tokens": [
          50886,
          400,
          550,
          264,
          6316,
          307,
          294,
          613,
          41011,
          11,
          50970
        ]
      },
      {
        "avg_logprob": -0.2605521545410156,
        "compression_ratio": 1.74,
        "end": 4724.96,
        "id": 1487,
        "no_speech_prob": 0.00001805831925594248,
        "seek": 471044,
        "start": 4722.5599999999995,
        "temperature": 0,
        "text": " which aren't console logging, but I can get access to them.",
        "tokens": [
          50970,
          597,
          3212,
          380,
          11076,
          27991,
          11,
          457,
          286,
          393,
          483,
          2105,
          281,
          552,
          13,
          51090
        ]
      },
      {
        "avg_logprob": -0.2605521545410156,
        "compression_ratio": 1.74,
        "end": 4725.719999999999,
        "id": 1488,
        "no_speech_prob": 0.00001805831925594248,
        "seek": 471044,
        "start": 4724.96,
        "temperature": 0,
        "text": " Wonderful.",
        "tokens": [
          51090,
          22768,
          13,
          51128
        ]
      },
      {
        "avg_logprob": -0.2605521545410156,
        "compression_ratio": 1.74,
        "end": 4733.96,
        "id": 1489,
        "no_speech_prob": 0.00001805831925594248,
        "seek": 471044,
        "start": 4725.719999999999,
        "temperature": 0,
        "text": " So I now have an array that has every single drawing in it.",
        "tokens": [
          51128,
          407,
          286,
          586,
          362,
          364,
          10225,
          300,
          575,
          633,
          2167,
          6316,
          294,
          309,
          13,
          51540
        ]
      },
      {
        "avg_logprob": -0.2605521545410156,
        "compression_ratio": 1.74,
        "end": 4736.48,
        "id": 1490,
        "no_speech_prob": 0.00001805831925594248,
        "seek": 471044,
        "start": 4733.96,
        "temperature": 0,
        "text": " Now, how do I get access to that?",
        "tokens": [
          51540,
          823,
          11,
          577,
          360,
          286,
          483,
          2105,
          281,
          300,
          30,
          51666
        ]
      },
      {
        "avg_logprob": -0.23990820150459763,
        "compression_ratio": 1.6271929824561404,
        "end": 4740.919999999999,
        "id": 1491,
        "no_speech_prob": 0.00001863173019955866,
        "seek": 473648,
        "start": 4736.48,
        "temperature": 0,
        "text": " I need to be able to make a get request to the server.",
        "tokens": [
          50364,
          286,
          643,
          281,
          312,
          1075,
          281,
          652,
          257,
          483,
          5308,
          281,
          264,
          7154,
          13,
          50586
        ]
      },
      {
        "avg_logprob": -0.23990820150459763,
        "compression_ratio": 1.6271929824561404,
        "end": 4742.639999999999,
        "id": 1492,
        "no_speech_prob": 0.00001863173019955866,
        "seek": 473648,
        "start": 4740.919999999999,
        "temperature": 0,
        "text": " So let's see how we would do that.",
        "tokens": [
          50586,
          407,
          718,
          311,
          536,
          577,
          321,
          576,
          360,
          300,
          13,
          50672
        ]
      },
      {
        "avg_logprob": -0.23990820150459763,
        "compression_ratio": 1.6271929824561404,
        "end": 4746.759999999999,
        "id": 1493,
        "no_speech_prob": 0.00001863173019955866,
        "seek": 473648,
        "start": 4742.639999999999,
        "temperature": 0,
        "text": " So I need to make an Express servery thing.",
        "tokens": [
          50672,
          407,
          286,
          643,
          281,
          652,
          364,
          20212,
          7154,
          88,
          551,
          13,
          50878
        ]
      },
      {
        "avg_logprob": -0.23990820150459763,
        "compression_ratio": 1.6271929824561404,
        "end": 4752.839999999999,
        "id": 1494,
        "no_speech_prob": 0.00001863173019955866,
        "seek": 473648,
        "start": 4746.759999999999,
        "temperature": 0,
        "text": " Let's just look up Express Node and go to the kind of quick",
        "tokens": [
          50878,
          961,
          311,
          445,
          574,
          493,
          20212,
          38640,
          293,
          352,
          281,
          264,
          733,
          295,
          1702,
          51182
        ]
      },
      {
        "avg_logprob": -0.23990820150459763,
        "compression_ratio": 1.6271929824561404,
        "end": 4755.04,
        "id": 1495,
        "no_speech_prob": 0.00001863173019955866,
        "seek": 473648,
        "start": 4752.839999999999,
        "temperature": 0,
        "text": " getting started, hello world.",
        "tokens": [
          51182,
          1242,
          1409,
          11,
          7751,
          1002,
          13,
          51292
        ]
      },
      {
        "avg_logprob": -0.23990820150459763,
        "compression_ratio": 1.6271929824561404,
        "end": 4758.259999999999,
        "id": 1496,
        "no_speech_prob": 0.00001863173019955866,
        "seek": 473648,
        "start": 4755.04,
        "temperature": 0,
        "text": " The hello world Express example is all we need, basically.",
        "tokens": [
          51292,
          440,
          7751,
          1002,
          20212,
          1365,
          307,
          439,
          321,
          643,
          11,
          1936,
          13,
          51453
        ]
      },
      {
        "avg_logprob": -0.23990820150459763,
        "compression_ratio": 1.6271929824561404,
        "end": 4761.2,
        "id": 1497,
        "no_speech_prob": 0.00001863173019955866,
        "seek": 473648,
        "start": 4758.259999999999,
        "temperature": 0,
        "text": " I'm going to grab all of this.",
        "tokens": [
          51453,
          286,
          478,
          516,
          281,
          4444,
          439,
          295,
          341,
          13,
          51600
        ]
      },
      {
        "avg_logprob": -0.23990820150459763,
        "compression_ratio": 1.6271929824561404,
        "end": 4763.719999999999,
        "id": 1498,
        "no_speech_prob": 0.00001863173019955866,
        "seek": 473648,
        "start": 4761.2,
        "temperature": 0,
        "text": " And I'm going to put it into my code.",
        "tokens": [
          51600,
          400,
          286,
          478,
          516,
          281,
          829,
          309,
          666,
          452,
          3089,
          13,
          51726
        ]
      },
      {
        "avg_logprob": -0.23990820150459763,
        "compression_ratio": 1.6271929824561404,
        "end": 4764.5599999999995,
        "id": 1499,
        "no_speech_prob": 0.00001863173019955866,
        "seek": 473648,
        "start": 4763.719999999999,
        "temperature": 0,
        "text": " So what's going on?",
        "tokens": [
          51726,
          407,
          437,
          311,
          516,
          322,
          30,
          51768
        ]
      },
      {
        "avg_logprob": -0.23272664388020833,
        "compression_ratio": 1.6836363636363636,
        "end": 4768.04,
        "id": 1500,
        "no_speech_prob": 0.0000660518417134881,
        "seek": 476456,
        "start": 4764.56,
        "temperature": 0,
        "text": " Number one is I need to require the Express library.",
        "tokens": [
          50364,
          5118,
          472,
          307,
          286,
          643,
          281,
          3651,
          264,
          20212,
          6405,
          13,
          50538
        ]
      },
      {
        "avg_logprob": -0.23272664388020833,
        "compression_ratio": 1.6836363636363636,
        "end": 4769.4400000000005,
        "id": 1501,
        "no_speech_prob": 0.0000660518417134881,
        "seek": 476456,
        "start": 4768.04,
        "temperature": 0,
        "text": " I need to create an app, which is",
        "tokens": [
          50538,
          286,
          643,
          281,
          1884,
          364,
          724,
          11,
          597,
          307,
          50608
        ]
      },
      {
        "avg_logprob": -0.23272664388020833,
        "compression_ratio": 1.6836363636363636,
        "end": 4770.64,
        "id": 1502,
        "no_speech_prob": 0.0000660518417134881,
        "seek": 476456,
        "start": 4769.4400000000005,
        "temperature": 0,
        "text": " calling the Express function.",
        "tokens": [
          50608,
          5141,
          264,
          20212,
          2445,
          13,
          50668
        ]
      },
      {
        "avg_logprob": -0.23272664388020833,
        "compression_ratio": 1.6836363636363636,
        "end": 4772.080000000001,
        "id": 1503,
        "no_speech_prob": 0.0000660518417134881,
        "seek": 476456,
        "start": 4770.64,
        "temperature": 0,
        "text": " I'm adding the semicolons.",
        "tokens": [
          50668,
          286,
          478,
          5127,
          264,
          27515,
          401,
          892,
          13,
          50740
        ]
      },
      {
        "avg_logprob": -0.23272664388020833,
        "compression_ratio": 1.6836363636363636,
        "end": 4773.4800000000005,
        "id": 1504,
        "no_speech_prob": 0.0000660518417134881,
        "seek": 476456,
        "start": 4772.080000000001,
        "temperature": 0,
        "text": " Gosh darn it.",
        "tokens": [
          50740,
          19185,
          29063,
          309,
          13,
          50810
        ]
      },
      {
        "avg_logprob": -0.23272664388020833,
        "compression_ratio": 1.6836363636363636,
        "end": 4775.200000000001,
        "id": 1505,
        "no_speech_prob": 0.0000660518417134881,
        "seek": 476456,
        "start": 4773.4800000000005,
        "temperature": 0,
        "text": " I need semicolons to live.",
        "tokens": [
          50810,
          286,
          643,
          27515,
          401,
          892,
          281,
          1621,
          13,
          50896
        ]
      },
      {
        "avg_logprob": -0.23272664388020833,
        "compression_ratio": 1.6836363636363636,
        "end": 4777.200000000001,
        "id": 1506,
        "no_speech_prob": 0.0000660518417134881,
        "seek": 476456,
        "start": 4775.200000000001,
        "temperature": 0,
        "text": " I can't do without.",
        "tokens": [
          50896,
          286,
          393,
          380,
          360,
          1553,
          13,
          50996
        ]
      },
      {
        "avg_logprob": -0.23272664388020833,
        "compression_ratio": 1.6836363636363636,
        "end": 4778.120000000001,
        "id": 1507,
        "no_speech_prob": 0.0000660518417134881,
        "seek": 476456,
        "start": 4777.200000000001,
        "temperature": 0,
        "text": " I need to pick a port.",
        "tokens": [
          50996,
          286,
          643,
          281,
          1888,
          257,
          2436,
          13,
          51042
        ]
      },
      {
        "avg_logprob": -0.23272664388020833,
        "compression_ratio": 1.6836363636363636,
        "end": 4779.72,
        "id": 1508,
        "no_speech_prob": 0.0000660518417134881,
        "seek": 476456,
        "start": 4778.120000000001,
        "temperature": 0,
        "text": " So port, this is somewhat arbitrary,",
        "tokens": [
          51042,
          407,
          2436,
          11,
          341,
          307,
          8344,
          23211,
          11,
          51122
        ]
      },
      {
        "avg_logprob": -0.23272664388020833,
        "compression_ratio": 1.6836363636363636,
        "end": 4781.68,
        "id": 1509,
        "no_speech_prob": 0.0000660518417134881,
        "seek": 476456,
        "start": 4779.72,
        "temperature": 0,
        "text": " but I'm going to use the port 3000.",
        "tokens": [
          51122,
          457,
          286,
          478,
          516,
          281,
          764,
          264,
          2436,
          20984,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.23272664388020833,
        "compression_ratio": 1.6836363636363636,
        "end": 4784.52,
        "id": 1510,
        "no_speech_prob": 0.0000660518417134881,
        "seek": 476456,
        "start": 4781.68,
        "temperature": 0,
        "text": " And then I'm going to set up a route.",
        "tokens": [
          51220,
          400,
          550,
          286,
          478,
          516,
          281,
          992,
          493,
          257,
          7955,
          13,
          51362
        ]
      },
      {
        "avg_logprob": -0.23272664388020833,
        "compression_ratio": 1.6836363636363636,
        "end": 4786.320000000001,
        "id": 1511,
        "no_speech_prob": 0.0000660518417134881,
        "seek": 476456,
        "start": 4784.52,
        "temperature": 0,
        "text": " So the idea, and I prefer to be a little more",
        "tokens": [
          51362,
          407,
          264,
          1558,
          11,
          293,
          286,
          4382,
          281,
          312,
          257,
          707,
          544,
          51452
        ]
      },
      {
        "avg_logprob": -0.23272664388020833,
        "compression_ratio": 1.6836363636363636,
        "end": 4789.160000000001,
        "id": 1512,
        "no_speech_prob": 0.0000660518417134881,
        "seek": 476456,
        "start": 4786.320000000001,
        "temperature": 0,
        "text": " long-winded about this.",
        "tokens": [
          51452,
          938,
          12,
          12199,
          292,
          466,
          341,
          13,
          51594
        ]
      },
      {
        "avg_logprob": -0.23272664388020833,
        "compression_ratio": 1.6836363636363636,
        "end": 4792.84,
        "id": 1513,
        "no_speech_prob": 0.0000660518417134881,
        "seek": 476456,
        "start": 4789.160000000001,
        "temperature": 0,
        "text": " This is using the arrow syntax, which is a kind of ES6",
        "tokens": [
          51594,
          639,
          307,
          1228,
          264,
          11610,
          28431,
          11,
          597,
          307,
          257,
          733,
          295,
          12564,
          21,
          51778
        ]
      },
      {
        "avg_logprob": -0.23905865620758573,
        "compression_ratio": 1.6909871244635193,
        "end": 4793.92,
        "id": 1514,
        "no_speech_prob": 0.000015446237739524804,
        "seek": 479284,
        "start": 4792.84,
        "temperature": 0,
        "text": " JavaScript syntax.",
        "tokens": [
          50364,
          15778,
          28431,
          13,
          50418
        ]
      },
      {
        "avg_logprob": -0.23905865620758573,
        "compression_ratio": 1.6909871244635193,
        "end": 4804.32,
        "id": 1515,
        "no_speech_prob": 0.000015446237739524804,
        "seek": 479284,
        "start": 4798.2,
        "temperature": 0,
        "text": " And I'm just going to, I just have to do things",
        "tokens": [
          50632,
          400,
          286,
          478,
          445,
          516,
          281,
          11,
          286,
          445,
          362,
          281,
          360,
          721,
          50938
        ]
      },
      {
        "avg_logprob": -0.23905865620758573,
        "compression_ratio": 1.6909871244635193,
        "end": 4806.24,
        "id": 1516,
        "no_speech_prob": 0.000015446237739524804,
        "seek": 479284,
        "start": 4804.32,
        "temperature": 0,
        "text": " the way that I do them.",
        "tokens": [
          50938,
          264,
          636,
          300,
          286,
          360,
          552,
          13,
          51034
        ]
      },
      {
        "avg_logprob": -0.23905865620758573,
        "compression_ratio": 1.6909871244635193,
        "end": 4809.68,
        "id": 1517,
        "no_speech_prob": 0.000015446237739524804,
        "seek": 479284,
        "start": 4806.24,
        "temperature": 0,
        "text": " So there's two functions that I care about with my app.",
        "tokens": [
          51034,
          407,
          456,
          311,
          732,
          6828,
          300,
          286,
          1127,
          466,
          365,
          452,
          724,
          13,
          51206
        ]
      },
      {
        "avg_logprob": -0.23905865620758573,
        "compression_ratio": 1.6909871244635193,
        "end": 4811.92,
        "id": 1518,
        "no_speech_prob": 0.000015446237739524804,
        "seek": 479284,
        "start": 4809.68,
        "temperature": 0,
        "text": " One is that I need it to listen on the port.",
        "tokens": [
          51206,
          1485,
          307,
          300,
          286,
          643,
          309,
          281,
          2140,
          322,
          264,
          2436,
          13,
          51318
        ]
      },
      {
        "avg_logprob": -0.23905865620758573,
        "compression_ratio": 1.6909871244635193,
        "end": 4814.32,
        "id": 1519,
        "no_speech_prob": 0.000015446237739524804,
        "seek": 479284,
        "start": 4811.92,
        "temperature": 0,
        "text": " So this, I'm setting up the server, creating a server,",
        "tokens": [
          51318,
          407,
          341,
          11,
          286,
          478,
          3287,
          493,
          264,
          7154,
          11,
          4084,
          257,
          7154,
          11,
          51438
        ]
      },
      {
        "avg_logprob": -0.23905865620758573,
        "compression_ratio": 1.6909871244635193,
        "end": 4815.52,
        "id": 1520,
        "no_speech_prob": 0.000015446237739524804,
        "seek": 479284,
        "start": 4814.32,
        "temperature": 0,
        "text": " and that server is listening.",
        "tokens": [
          51438,
          293,
          300,
          7154,
          307,
          4764,
          13,
          51498
        ]
      },
      {
        "avg_logprob": -0.23905865620758573,
        "compression_ratio": 1.6909871244635193,
        "end": 4817.4400000000005,
        "id": 1521,
        "no_speech_prob": 0.000015446237739524804,
        "seek": 479284,
        "start": 4815.52,
        "temperature": 0,
        "text": " Because ultimately, I got to get to that p5 sketch that's",
        "tokens": [
          51498,
          1436,
          6284,
          11,
          286,
          658,
          281,
          483,
          281,
          300,
          280,
          20,
          12325,
          300,
          311,
          51594
        ]
      },
      {
        "avg_logprob": -0.23905865620758573,
        "compression_ratio": 1.6909871244635193,
        "end": 4818.56,
        "id": 1522,
        "no_speech_prob": 0.000015446237739524804,
        "seek": 479284,
        "start": 4817.4400000000005,
        "temperature": 0,
        "text": " going to make the drawing.",
        "tokens": [
          51594,
          516,
          281,
          652,
          264,
          6316,
          13,
          51650
        ]
      },
      {
        "avg_logprob": -0.23905865620758573,
        "compression_ratio": 1.6909871244635193,
        "end": 4820.24,
        "id": 1523,
        "no_speech_prob": 0.000015446237739524804,
        "seek": 479284,
        "start": 4818.56,
        "temperature": 0,
        "text": " I haven't even gotten there yet.",
        "tokens": [
          51650,
          286,
          2378,
          380,
          754,
          5768,
          456,
          1939,
          13,
          51734
        ]
      },
      {
        "avg_logprob": -0.22695207595825195,
        "compression_ratio": 1.521978021978022,
        "end": 4825.5199999999995,
        "id": 1524,
        "no_speech_prob": 0.0000011726403954526177,
        "seek": 482024,
        "start": 4820.24,
        "temperature": 0,
        "text": " Now, I then want to set up a route.",
        "tokens": [
          50364,
          823,
          11,
          286,
          550,
          528,
          281,
          992,
          493,
          257,
          7955,
          13,
          50628
        ]
      },
      {
        "avg_logprob": -0.22695207595825195,
        "compression_ratio": 1.521978021978022,
        "end": 4828.76,
        "id": 1525,
        "no_speech_prob": 0.0000011726403954526177,
        "seek": 482024,
        "start": 4825.5199999999995,
        "temperature": 0,
        "text": " And then when the user makes a request to that route,",
        "tokens": [
          50628,
          400,
          550,
          562,
          264,
          4195,
          1669,
          257,
          5308,
          281,
          300,
          7955,
          11,
          50790
        ]
      },
      {
        "avg_logprob": -0.22695207595825195,
        "compression_ratio": 1.521978021978022,
        "end": 4829.599999999999,
        "id": 1526,
        "no_speech_prob": 0.0000011726403954526177,
        "seek": 482024,
        "start": 4828.76,
        "temperature": 0,
        "text": " send something back.",
        "tokens": [
          50790,
          2845,
          746,
          646,
          13,
          50832
        ]
      },
      {
        "avg_logprob": -0.22695207595825195,
        "compression_ratio": 1.521978021978022,
        "end": 4835.84,
        "id": 1527,
        "no_speech_prob": 0.0000011726403954526177,
        "seek": 482024,
        "start": 4829.599999999999,
        "temperature": 0,
        "text": " So in this hello world example, if I run the server",
        "tokens": [
          50832,
          407,
          294,
          341,
          7751,
          1002,
          1365,
          11,
          498,
          286,
          1190,
          264,
          7154,
          51144
        ]
      },
      {
        "avg_logprob": -0.22695207595825195,
        "compression_ratio": 1.521978021978022,
        "end": 4840.76,
        "id": 1528,
        "no_speech_prob": 0.0000011726403954526177,
        "seek": 482024,
        "start": 4835.84,
        "temperature": 0,
        "text": " and go to localhost 3000, it says hello world.",
        "tokens": [
          51144,
          293,
          352,
          281,
          2654,
          6037,
          20984,
          11,
          309,
          1619,
          7751,
          1002,
          13,
          51390
        ]
      },
      {
        "avg_logprob": -0.22695207595825195,
        "compression_ratio": 1.521978021978022,
        "end": 4842.599999999999,
        "id": 1529,
        "no_speech_prob": 0.0000011726403954526177,
        "seek": 482024,
        "start": 4840.76,
        "temperature": 0,
        "text": " But that's not what I want.",
        "tokens": [
          51390,
          583,
          300,
          311,
          406,
          437,
          286,
          528,
          13,
          51482
        ]
      },
      {
        "avg_logprob": -0.22695207595825195,
        "compression_ratio": 1.521978021978022,
        "end": 4845.88,
        "id": 1530,
        "no_speech_prob": 0.0000011726403954526177,
        "seek": 482024,
        "start": 4842.599999999999,
        "temperature": 0,
        "text": " I don't care about sending hello world.",
        "tokens": [
          51482,
          286,
          500,
          380,
          1127,
          466,
          7750,
          7751,
          1002,
          13,
          51646
        ]
      },
      {
        "avg_logprob": -0.23418615589971128,
        "compression_ratio": 1.7443946188340806,
        "end": 4850.4800000000005,
        "id": 1531,
        "no_speech_prob": 0.00004264743984094821,
        "seek": 484588,
        "start": 4845.88,
        "temperature": 0,
        "text": " What I want to do is let me make a route called rainbow.",
        "tokens": [
          50364,
          708,
          286,
          528,
          281,
          360,
          307,
          718,
          385,
          652,
          257,
          7955,
          1219,
          18526,
          13,
          50594
        ]
      },
      {
        "avg_logprob": -0.23418615589971128,
        "compression_ratio": 1.7443946188340806,
        "end": 4852.56,
        "id": 1532,
        "no_speech_prob": 0.00004264743984094821,
        "seek": 484588,
        "start": 4850.4800000000005,
        "temperature": 0,
        "text": " Then what I'm going to do is I'm going to say,",
        "tokens": [
          50594,
          1396,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          584,
          11,
          50698
        ]
      },
      {
        "avg_logprob": -0.23418615589971128,
        "compression_ratio": 1.7443946188340806,
        "end": 4859.84,
        "id": 1533,
        "no_speech_prob": 0.00004264743984094821,
        "seek": 484588,
        "start": 4852.56,
        "temperature": 0,
        "text": " let a random number equals math.floor, math.random,",
        "tokens": [
          50698,
          718,
          257,
          4974,
          1230,
          6915,
          5221,
          13,
          43645,
          284,
          11,
          5221,
          13,
          3699,
          298,
          11,
          51062
        ]
      },
      {
        "avg_logprob": -0.23418615589971128,
        "compression_ratio": 1.7443946188340806,
        "end": 4862.6,
        "id": 1534,
        "no_speech_prob": 0.00004264743984094821,
        "seek": 484588,
        "start": 4859.84,
        "temperature": 0,
        "text": " times drawings.length.",
        "tokens": [
          51062,
          1413,
          18618,
          13,
          45390,
          13,
          51200
        ]
      },
      {
        "avg_logprob": -0.23418615589971128,
        "compression_ratio": 1.7443946188340806,
        "end": 4864.88,
        "id": 1535,
        "no_speech_prob": 0.00004264743984094821,
        "seek": 484588,
        "start": 4862.6,
        "temperature": 0,
        "text": " So however many drawings have been loaded when somebody goes",
        "tokens": [
          51200,
          407,
          4461,
          867,
          18618,
          362,
          668,
          13210,
          562,
          2618,
          1709,
          51314
        ]
      },
      {
        "avg_logprob": -0.23418615589971128,
        "compression_ratio": 1.7443946188340806,
        "end": 4867.2,
        "id": 1536,
        "no_speech_prob": 0.00004264743984094821,
        "seek": 484588,
        "start": 4864.88,
        "temperature": 0,
        "text": " to this route, pick a random one.",
        "tokens": [
          51314,
          281,
          341,
          7955,
          11,
          1888,
          257,
          4974,
          472,
          13,
          51430
        ]
      },
      {
        "avg_logprob": -0.23418615589971128,
        "compression_ratio": 1.7443946188340806,
        "end": 4870.52,
        "id": 1537,
        "no_speech_prob": 0.00004264743984094821,
        "seek": 484588,
        "start": 4867.2,
        "temperature": 0,
        "text": " And then I'm going to say, and this could be a const, I guess.",
        "tokens": [
          51430,
          400,
          550,
          286,
          478,
          516,
          281,
          584,
          11,
          293,
          341,
          727,
          312,
          257,
          1817,
          11,
          286,
          2041,
          13,
          51596
        ]
      },
      {
        "avg_logprob": -0.23418615589971128,
        "compression_ratio": 1.7443946188340806,
        "end": 4874.400000000001,
        "id": 1538,
        "no_speech_prob": 0.00004264743984094821,
        "seek": 484588,
        "start": 4870.52,
        "temperature": 0,
        "text": " And I'm going to say response send drawings index r.",
        "tokens": [
          51596,
          400,
          286,
          478,
          516,
          281,
          584,
          4134,
          2845,
          18618,
          8186,
          367,
          13,
          51790
        ]
      },
      {
        "avg_logprob": -0.22524525137508616,
        "compression_ratio": 1.5853658536585367,
        "end": 4877.679999999999,
        "id": 1539,
        "no_speech_prob": 0.000013211931218393147,
        "seek": 487440,
        "start": 4874.4,
        "temperature": 0,
        "text": " And I suppose I should call this index.",
        "tokens": [
          50364,
          400,
          286,
          7297,
          286,
          820,
          818,
          341,
          8186,
          13,
          50528
        ]
      },
      {
        "avg_logprob": -0.22524525137508616,
        "compression_ratio": 1.5853658536585367,
        "end": 4882.2,
        "id": 1540,
        "no_speech_prob": 0.000013211931218393147,
        "seek": 487440,
        "start": 4877.679999999999,
        "temperature": 0,
        "text": " So now, oops, index.",
        "tokens": [
          50528,
          407,
          586,
          11,
          34166,
          11,
          8186,
          13,
          50754
        ]
      },
      {
        "avg_logprob": -0.22524525137508616,
        "compression_ratio": 1.5853658536585367,
        "end": 4883.96,
        "id": 1541,
        "no_speech_prob": 0.000013211931218393147,
        "seek": 487440,
        "start": 4882.2,
        "temperature": 0,
        "text": " Let's rerun the server.",
        "tokens": [
          50754,
          961,
          311,
          43819,
          409,
          264,
          7154,
          13,
          50842
        ]
      },
      {
        "avg_logprob": -0.22524525137508616,
        "compression_ratio": 1.5853658536585367,
        "end": 4885.5199999999995,
        "id": 1542,
        "no_speech_prob": 0.000013211931218393147,
        "seek": 487440,
        "start": 4883.96,
        "temperature": 0,
        "text": " And there is a tool called NodeMon,",
        "tokens": [
          50842,
          400,
          456,
          307,
          257,
          2290,
          1219,
          38640,
          32498,
          11,
          50920
        ]
      },
      {
        "avg_logprob": -0.22524525137508616,
        "compression_ratio": 1.5853658536585367,
        "end": 4887.24,
        "id": 1543,
        "no_speech_prob": 0.000013211931218393147,
        "seek": 487440,
        "start": 4885.5199999999995,
        "temperature": 0,
        "text": " which will restart the server for you.",
        "tokens": [
          50920,
          597,
          486,
          21022,
          264,
          7154,
          337,
          291,
          13,
          51006
        ]
      },
      {
        "avg_logprob": -0.22524525137508616,
        "compression_ratio": 1.5853658536585367,
        "end": 4889.2,
        "id": 1544,
        "no_speech_prob": 0.000013211931218393147,
        "seek": 487440,
        "start": 4887.24,
        "temperature": 0,
        "text": " I'm going to do this manually.",
        "tokens": [
          51006,
          286,
          478,
          516,
          281,
          360,
          341,
          16945,
          13,
          51104
        ]
      },
      {
        "avg_logprob": -0.22524525137508616,
        "compression_ratio": 1.5853658536585367,
        "end": 4890.599999999999,
        "id": 1545,
        "no_speech_prob": 0.000013211931218393147,
        "seek": 487440,
        "start": 4889.2,
        "temperature": 0,
        "text": " And then I'm going to go here.",
        "tokens": [
          51104,
          400,
          550,
          286,
          478,
          516,
          281,
          352,
          510,
          13,
          51174
        ]
      },
      {
        "avg_logprob": -0.22524525137508616,
        "compression_ratio": 1.5853658536585367,
        "end": 4896.2,
        "id": 1546,
        "no_speech_prob": 0.000013211931218393147,
        "seek": 487440,
        "start": 4890.599999999999,
        "temperature": 0,
        "text": " Cannot get slash because there is no route anymore at slash.",
        "tokens": [
          51174,
          29866,
          310,
          483,
          17330,
          570,
          456,
          307,
          572,
          7955,
          3602,
          412,
          17330,
          13,
          51454
        ]
      },
      {
        "avg_logprob": -0.22524525137508616,
        "compression_ratio": 1.5853658536585367,
        "end": 4901.74,
        "id": 1547,
        "no_speech_prob": 0.000013211931218393147,
        "seek": 487440,
        "start": 4896.2,
        "temperature": 0,
        "text": " But if I go to slash rainbow, there we go.",
        "tokens": [
          51454,
          583,
          498,
          286,
          352,
          281,
          17330,
          18526,
          11,
          456,
          321,
          352,
          13,
          51731
        ]
      },
      {
        "avg_logprob": -0.3030377813132413,
        "compression_ratio": 1.5290697674418605,
        "end": 4905.0199999999995,
        "id": 1548,
        "no_speech_prob": 0.00035143463173881173,
        "seek": 490174,
        "start": 4901.74,
        "temperature": 0,
        "text": " There is the drawing.",
        "tokens": [
          50364,
          821,
          307,
          264,
          6316,
          13,
          50528
        ]
      },
      {
        "avg_logprob": -0.3030377813132413,
        "compression_ratio": 1.5290697674418605,
        "end": 4906.0599999999995,
        "id": 1549,
        "no_speech_prob": 0.00035143463173881173,
        "seek": 490174,
        "start": 4905.0199999999995,
        "temperature": 0,
        "text": " Hold on a sec.",
        "tokens": [
          50528,
          6962,
          322,
          257,
          907,
          13,
          50580
        ]
      },
      {
        "avg_logprob": -0.3030377813132413,
        "compression_ratio": 1.5290697674418605,
        "end": 4907.099999999999,
        "id": 1550,
        "no_speech_prob": 0.00035143463173881173,
        "seek": 490174,
        "start": 4906.0599999999995,
        "temperature": 0,
        "text": " Time out for a second.",
        "tokens": [
          50580,
          6161,
          484,
          337,
          257,
          1150,
          13,
          50632
        ]
      },
      {
        "avg_logprob": -0.3030377813132413,
        "compression_ratio": 1.5290697674418605,
        "end": 4917.34,
        "id": 1551,
        "no_speech_prob": 0.00035143463173881173,
        "seek": 490174,
        "start": 4912.66,
        "temperature": 0,
        "text": " I could have sworn I have this extension that",
        "tokens": [
          50910,
          286,
          727,
          362,
          40068,
          286,
          362,
          341,
          10320,
          300,
          51144
        ]
      },
      {
        "avg_logprob": -0.3030377813132413,
        "compression_ratio": 1.5290697674418605,
        "end": 4918.42,
        "id": 1552,
        "no_speech_prob": 0.00035143463173881173,
        "seek": 490174,
        "start": 4917.34,
        "temperature": 0,
        "text": " will format the JSON.",
        "tokens": [
          51144,
          486,
          7877,
          264,
          31828,
          13,
          51198
        ]
      },
      {
        "avg_logprob": -0.3030377813132413,
        "compression_ratio": 1.5290697674418605,
        "end": 4919.3,
        "id": 1553,
        "no_speech_prob": 0.00035143463173881173,
        "seek": 490174,
        "start": 4918.42,
        "temperature": 0,
        "text": " But I guess I didn't.",
        "tokens": [
          51198,
          583,
          286,
          2041,
          286,
          994,
          380,
          13,
          51242
        ]
      },
      {
        "avg_logprob": -0.3030377813132413,
        "compression_ratio": 1.5290697674418605,
        "end": 4927.98,
        "id": 1554,
        "no_speech_prob": 0.00035143463173881173,
        "seek": 490174,
        "start": 4925.82,
        "temperature": 0,
        "text": " All right, I just installed a Chrome extension",
        "tokens": [
          51568,
          1057,
          558,
          11,
          286,
          445,
          8899,
          257,
          15327,
          10320,
          51676
        ]
      },
      {
        "avg_logprob": -0.3030377813132413,
        "compression_ratio": 1.5290697674418605,
        "end": 4929.82,
        "id": 1555,
        "no_speech_prob": 0.00035143463173881173,
        "seek": 490174,
        "start": 4927.98,
        "temperature": 0,
        "text": " to format the JSON so I could see it.",
        "tokens": [
          51676,
          281,
          7877,
          264,
          31828,
          370,
          286,
          727,
          536,
          309,
          13,
          51768
        ]
      },
      {
        "avg_logprob": -0.3030377813132413,
        "compression_ratio": 1.5290697674418605,
        "end": 4931.46,
        "id": 1556,
        "no_speech_prob": 0.00035143463173881173,
        "seek": 490174,
        "start": 4929.82,
        "temperature": 0,
        "text": " So here is a random drawing.",
        "tokens": [
          51768,
          407,
          510,
          307,
          257,
          4974,
          6316,
          13,
          51850
        ]
      },
      {
        "avg_logprob": -0.3010863122485933,
        "compression_ratio": 1.418848167539267,
        "end": 4933.06,
        "id": 1557,
        "no_speech_prob": 0.00003071805986110121,
        "seek": 493146,
        "start": 4931.46,
        "temperature": 0,
        "text": " And this is all the information.",
        "tokens": [
          50364,
          400,
          341,
          307,
          439,
          264,
          1589,
          13,
          50444
        ]
      },
      {
        "avg_logprob": -0.3010863122485933,
        "compression_ratio": 1.418848167539267,
        "end": 4939.82,
        "id": 1558,
        "no_speech_prob": 0.00003071805986110121,
        "seek": 493146,
        "start": 4933.06,
        "temperature": 0,
        "text": " Now, all I need to do is have p5 request JSON from this route",
        "tokens": [
          50444,
          823,
          11,
          439,
          286,
          643,
          281,
          360,
          307,
          362,
          280,
          20,
          5308,
          31828,
          490,
          341,
          7955,
          50782
        ]
      },
      {
        "avg_logprob": -0.3010863122485933,
        "compression_ratio": 1.418848167539267,
        "end": 4943.1,
        "id": 1559,
        "no_speech_prob": 0.00003071805986110121,
        "seek": 493146,
        "start": 4939.82,
        "temperature": 0,
        "text": " and then render the drawing.",
        "tokens": [
          50782,
          293,
          550,
          15529,
          264,
          6316,
          13,
          50946
        ]
      },
      {
        "avg_logprob": -0.3010863122485933,
        "compression_ratio": 1.418848167539267,
        "end": 4946.14,
        "id": 1560,
        "no_speech_prob": 0.00003071805986110121,
        "seek": 493146,
        "start": 4943.1,
        "temperature": 0,
        "text": " Pause for a second.",
        "tokens": [
          50946,
          31973,
          337,
          257,
          1150,
          13,
          51098
        ]
      },
      {
        "avg_logprob": -0.3010863122485933,
        "compression_ratio": 1.418848167539267,
        "end": 4948.66,
        "id": 1561,
        "no_speech_prob": 0.00003071805986110121,
        "seek": 493146,
        "start": 4946.14,
        "temperature": 0,
        "text": " I think I'm not doing multi-part videos this day.",
        "tokens": [
          51098,
          286,
          519,
          286,
          478,
          406,
          884,
          4825,
          12,
          6971,
          2145,
          341,
          786,
          13,
          51224
        ]
      },
      {
        "avg_logprob": -0.3010863122485933,
        "compression_ratio": 1.418848167539267,
        "end": 4954.9,
        "id": 1562,
        "no_speech_prob": 0.00003071805986110121,
        "seek": 493146,
        "start": 4952.1,
        "temperature": 0,
        "text": " All right, oh, there's been some new members.",
        "tokens": [
          51396,
          1057,
          558,
          11,
          1954,
          11,
          456,
          311,
          668,
          512,
          777,
          2679,
          13,
          51536
        ]
      },
      {
        "avg_logprob": -0.3010863122485933,
        "compression_ratio": 1.418848167539267,
        "end": 4956.38,
        "id": 1563,
        "no_speech_prob": 0.00003071805986110121,
        "seek": 493146,
        "start": 4954.9,
        "temperature": 0,
        "text": " Thank you very much.",
        "tokens": [
          51536,
          1044,
          291,
          588,
          709,
          13,
          51610
        ]
      },
      {
        "avg_logprob": -0.3010863122485933,
        "compression_ratio": 1.418848167539267,
        "end": 4956.88,
        "id": 1564,
        "no_speech_prob": 0.00003071805986110121,
        "seek": 493146,
        "start": 4956.38,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51610,
          1057,
          558,
          13,
          51635
        ]
      },
      {
        "avg_logprob": -0.2413976527442617,
        "compression_ratio": 1.6324110671936758,
        "end": 4962.38,
        "id": 1565,
        "no_speech_prob": 0.00003535587165970355,
        "seek": 496146,
        "start": 4961.9,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50386,
          1057,
          558,
          13,
          50410
        ]
      },
      {
        "avg_logprob": -0.2413976527442617,
        "compression_ratio": 1.6324110671936758,
        "end": 4970.1,
        "id": 1566,
        "no_speech_prob": 0.00003535587165970355,
        "seek": 496146,
        "start": 4966.42,
        "temperature": 0,
        "text": " So now the question is, where do I run my p5 sketch?",
        "tokens": [
          50612,
          407,
          586,
          264,
          1168,
          307,
          11,
          689,
          360,
          286,
          1190,
          452,
          280,
          20,
          12325,
          30,
          50796
        ]
      },
      {
        "avg_logprob": -0.2413976527442617,
        "compression_ratio": 1.6324110671936758,
        "end": 4971.38,
        "id": 1567,
        "no_speech_prob": 0.00003535587165970355,
        "seek": 496146,
        "start": 4970.1,
        "temperature": 0,
        "text": " And there are a variety of ways.",
        "tokens": [
          50796,
          400,
          456,
          366,
          257,
          5673,
          295,
          2098,
          13,
          50860
        ]
      },
      {
        "avg_logprob": -0.2413976527442617,
        "compression_ratio": 1.6324110671936758,
        "end": 4975.3,
        "id": 1568,
        "no_speech_prob": 0.00003535587165970355,
        "seek": 496146,
        "start": 4971.38,
        "temperature": 0,
        "text": " In theory, this is an API that anyone could make a request to.",
        "tokens": [
          50860,
          682,
          5261,
          11,
          341,
          307,
          364,
          9362,
          300,
          2878,
          727,
          652,
          257,
          5308,
          281,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.2413976527442617,
        "compression_ratio": 1.6324110671936758,
        "end": 4978.5,
        "id": 1569,
        "no_speech_prob": 0.00003535587165970355,
        "seek": 496146,
        "start": 4975.3,
        "temperature": 0,
        "text": " Whether or not I'm opening it up for other people to request",
        "tokens": [
          51056,
          8503,
          420,
          406,
          286,
          478,
          5193,
          309,
          493,
          337,
          661,
          561,
          281,
          5308,
          51216
        ]
      },
      {
        "avg_logprob": -0.2413976527442617,
        "compression_ratio": 1.6324110671936758,
        "end": 4980.7,
        "id": 1570,
        "no_speech_prob": 0.00003535587165970355,
        "seek": 496146,
        "start": 4978.5,
        "temperature": 0,
        "text": " to it or not is a complicated question.",
        "tokens": [
          51216,
          281,
          309,
          420,
          406,
          307,
          257,
          6179,
          1168,
          13,
          51326
        ]
      },
      {
        "avg_logprob": -0.2413976527442617,
        "compression_ratio": 1.6324110671936758,
        "end": 4983.06,
        "id": 1571,
        "no_speech_prob": 0.00003535587165970355,
        "seek": 496146,
        "start": 4980.7,
        "temperature": 0,
        "text": " But one way that I could use it is just",
        "tokens": [
          51326,
          583,
          472,
          636,
          300,
          286,
          727,
          764,
          309,
          307,
          445,
          51444
        ]
      },
      {
        "avg_logprob": -0.2413976527442617,
        "compression_ratio": 1.6324110671936758,
        "end": 4986.86,
        "id": 1572,
        "no_speech_prob": 0.00003535587165970355,
        "seek": 496146,
        "start": 4983.06,
        "temperature": 0,
        "text": " have this particular server host a p5 sketch in the first place.",
        "tokens": [
          51444,
          362,
          341,
          1729,
          7154,
          3975,
          257,
          280,
          20,
          12325,
          294,
          264,
          700,
          1081,
          13,
          51634
        ]
      },
      {
        "avg_logprob": -0.2413976527442617,
        "compression_ratio": 1.6324110671936758,
        "end": 4990.18,
        "id": 1573,
        "no_speech_prob": 0.00003535587165970355,
        "seek": 496146,
        "start": 4986.86,
        "temperature": 0,
        "text": " So the way to do that, if I go back to my files",
        "tokens": [
          51634,
          407,
          264,
          636,
          281,
          360,
          300,
          11,
          498,
          286,
          352,
          646,
          281,
          452,
          7098,
          51800
        ]
      },
      {
        "avg_logprob": -0.30364495616848186,
        "compression_ratio": 1.5362903225806452,
        "end": 4993.06,
        "id": 1574,
        "no_speech_prob": 0.00014883717813063413,
        "seek": 499018,
        "start": 4990.18,
        "temperature": 0,
        "text": " and I go to desktop, Quick Draw, this",
        "tokens": [
          50364,
          293,
          286,
          352,
          281,
          14502,
          11,
          12101,
          20386,
          11,
          341,
          50508
        ]
      },
      {
        "avg_logprob": -0.30364495616848186,
        "compression_ratio": 1.5362903225806452,
        "end": 4994.18,
        "id": 1575,
        "no_speech_prob": 0.00014883717813063413,
        "seek": 499018,
        "start": 4993.06,
        "temperature": 0,
        "text": " is where all the files are.",
        "tokens": [
          50508,
          307,
          689,
          439,
          264,
          7098,
          366,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.30364495616848186,
        "compression_ratio": 1.5362903225806452,
        "end": 4999.1,
        "id": 1576,
        "no_speech_prob": 0.00014883717813063413,
        "seek": 499018,
        "start": 4994.18,
        "temperature": 0,
        "text": " I'm actually going, I have a p5 HTML file and a Sketch.js file",
        "tokens": [
          50564,
          286,
          478,
          767,
          516,
          11,
          286,
          362,
          257,
          280,
          20,
          17995,
          3991,
          293,
          257,
          49245,
          13,
          25530,
          3991,
          50810
        ]
      },
      {
        "avg_logprob": -0.30364495616848186,
        "compression_ratio": 1.5362903225806452,
        "end": 4999.6,
        "id": 1577,
        "no_speech_prob": 0.00014883717813063413,
        "seek": 499018,
        "start": 4999.1,
        "temperature": 0,
        "text": " in here.",
        "tokens": [
          50810,
          294,
          510,
          13,
          50835
        ]
      },
      {
        "avg_logprob": -0.30364495616848186,
        "compression_ratio": 1.5362903225806452,
        "end": 5001.900000000001,
        "id": 1578,
        "no_speech_prob": 0.00014883717813063413,
        "seek": 499018,
        "start": 4999.6,
        "temperature": 0,
        "text": " But I'm going to make another directory called public.",
        "tokens": [
          50835,
          583,
          286,
          478,
          516,
          281,
          652,
          1071,
          21120,
          1219,
          1908,
          13,
          50950
        ]
      },
      {
        "avg_logprob": -0.30364495616848186,
        "compression_ratio": 1.5362903225806452,
        "end": 5004.5,
        "id": 1579,
        "no_speech_prob": 0.00014883717813063413,
        "seek": 499018,
        "start": 5001.900000000001,
        "temperature": 0,
        "text": " So these would be where I want files",
        "tokens": [
          50950,
          407,
          613,
          576,
          312,
          689,
          286,
          528,
          7098,
          51080
        ]
      },
      {
        "avg_logprob": -0.30364495616848186,
        "compression_ratio": 1.5362903225806452,
        "end": 5008.700000000001,
        "id": 1580,
        "no_speech_prob": 0.00014883717813063413,
        "seek": 499018,
        "start": 5004.5,
        "temperature": 0,
        "text": " that are hosted by the server to live, public.",
        "tokens": [
          51080,
          300,
          366,
          19204,
          538,
          264,
          7154,
          281,
          1621,
          11,
          1908,
          13,
          51290
        ]
      },
      {
        "avg_logprob": -0.30364495616848186,
        "compression_ratio": 1.5362903225806452,
        "end": 5012.22,
        "id": 1581,
        "no_speech_prob": 0.00014883717813063413,
        "seek": 499018,
        "start": 5008.700000000001,
        "temperature": 0,
        "text": " And then I'm going to say something like in my code,",
        "tokens": [
          51290,
          400,
          550,
          286,
          478,
          516,
          281,
          584,
          746,
          411,
          294,
          452,
          3089,
          11,
          51466
        ]
      },
      {
        "avg_logprob": -0.30364495616848186,
        "compression_ratio": 1.5362903225806452,
        "end": 5013.26,
        "id": 1582,
        "no_speech_prob": 0.00014883717813063413,
        "seek": 499018,
        "start": 5012.22,
        "temperature": 0,
        "text": " app.",
        "tokens": [
          51466,
          724,
          13,
          51518
        ]
      },
      {
        "avg_logprob": -0.30364495616848186,
        "compression_ratio": 1.5362903225806452,
        "end": 5014.46,
        "id": 1583,
        "no_speech_prob": 0.00014883717813063413,
        "seek": 499018,
        "start": 5013.26,
        "temperature": 0,
        "text": " I don't remember.",
        "tokens": [
          51518,
          286,
          500,
          380,
          1604,
          13,
          51578
        ]
      },
      {
        "avg_logprob": -0.30364495616848186,
        "compression_ratio": 1.5362903225806452,
        "end": 5016.5,
        "id": 1584,
        "no_speech_prob": 0.00014883717813063413,
        "seek": 499018,
        "start": 5014.46,
        "temperature": 0,
        "text": " Static file hosting express.",
        "tokens": [
          51578,
          745,
          2399,
          3991,
          16058,
          5109,
          13,
          51680
        ]
      },
      {
        "avg_logprob": -0.3370997565133231,
        "compression_ratio": 1.6296296296296295,
        "end": 5020.02,
        "id": 1585,
        "no_speech_prob": 0.000009972936823032796,
        "seek": 501650,
        "start": 5017.06,
        "temperature": 0,
        "text": " Serving static files in express is just this.",
        "tokens": [
          50392,
          4210,
          798,
          13437,
          7098,
          294,
          5109,
          307,
          445,
          341,
          13,
          50540
        ]
      },
      {
        "avg_logprob": -0.3370997565133231,
        "compression_ratio": 1.6296296296296295,
        "end": 5023.42,
        "id": 1586,
        "no_speech_prob": 0.000009972936823032796,
        "seek": 501650,
        "start": 5020.02,
        "temperature": 0,
        "text": " So basically, what I want to do is serve up",
        "tokens": [
          50540,
          407,
          1936,
          11,
          437,
          286,
          528,
          281,
          360,
          307,
          4596,
          493,
          50710
        ]
      },
      {
        "avg_logprob": -0.3370997565133231,
        "compression_ratio": 1.6296296296296295,
        "end": 5026.74,
        "id": 1587,
        "no_speech_prob": 0.000009972936823032796,
        "seek": 501650,
        "start": 5023.42,
        "temperature": 0,
        "text": " the HTML and the JavaScript files as well.",
        "tokens": [
          50710,
          264,
          17995,
          293,
          264,
          15778,
          7098,
          382,
          731,
          13,
          50876
        ]
      },
      {
        "avg_logprob": -0.3370997565133231,
        "compression_ratio": 1.6296296296296295,
        "end": 5027.94,
        "id": 1588,
        "no_speech_prob": 0.000009972936823032796,
        "seek": 501650,
        "start": 5026.74,
        "temperature": 0,
        "text": " So I'm going to do that here.",
        "tokens": [
          50876,
          407,
          286,
          478,
          516,
          281,
          360,
          300,
          510,
          13,
          50936
        ]
      },
      {
        "avg_logprob": -0.3370997565133231,
        "compression_ratio": 1.6296296296296295,
        "end": 5030.5,
        "id": 1589,
        "no_speech_prob": 0.000009972936823032796,
        "seek": 501650,
        "start": 5027.94,
        "temperature": 0,
        "text": " I'm going to add this.",
        "tokens": [
          50936,
          286,
          478,
          516,
          281,
          909,
          341,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.3370997565133231,
        "compression_ratio": 1.6296296296296295,
        "end": 5031.58,
        "id": 1590,
        "no_speech_prob": 0.000009972936823032796,
        "seek": 501650,
        "start": 5030.5,
        "temperature": 0,
        "text": " So now, look at this.",
        "tokens": [
          51064,
          407,
          586,
          11,
          574,
          412,
          341,
          13,
          51118
        ]
      },
      {
        "avg_logprob": -0.3370997565133231,
        "compression_ratio": 1.6296296296296295,
        "end": 5038.58,
        "id": 1591,
        "no_speech_prob": 0.000009972936823032796,
        "seek": 501650,
        "start": 5031.58,
        "temperature": 0,
        "text": " Now, and let's go to the p5 code and let's say background 0.",
        "tokens": [
          51118,
          823,
          11,
          293,
          718,
          311,
          352,
          281,
          264,
          280,
          20,
          3089,
          293,
          718,
          311,
          584,
          3678,
          1958,
          13,
          51468
        ]
      },
      {
        "avg_logprob": -0.3370997565133231,
        "compression_ratio": 1.6296296296296295,
        "end": 5042.5,
        "id": 1592,
        "no_speech_prob": 0.000009972936823032796,
        "seek": 501650,
        "start": 5038.58,
        "temperature": 0,
        "text": " So all that this p5 code does is create a 100 by 100 canvas",
        "tokens": [
          51468,
          407,
          439,
          300,
          341,
          280,
          20,
          3089,
          775,
          307,
          1884,
          257,
          2319,
          538,
          2319,
          16267,
          51664
        ]
      },
      {
        "avg_logprob": -0.3370997565133231,
        "compression_ratio": 1.6296296296296295,
        "end": 5043.7,
        "id": 1593,
        "no_speech_prob": 0.000009972936823032796,
        "seek": 501650,
        "start": 5042.5,
        "temperature": 0,
        "text": " with a background of 0.",
        "tokens": [
          51664,
          365,
          257,
          3678,
          295,
          1958,
          13,
          51724
        ]
      },
      {
        "avg_logprob": -0.23045740422514296,
        "compression_ratio": 1.5555555555555556,
        "end": 5046.34,
        "id": 1594,
        "no_speech_prob": 0.001367021817713976,
        "seek": 504370,
        "start": 5043.7,
        "temperature": 0,
        "text": " 100 by 100 canvas with a background of 0.",
        "tokens": [
          50364,
          2319,
          538,
          2319,
          16267,
          365,
          257,
          3678,
          295,
          1958,
          13,
          50496
        ]
      },
      {
        "avg_logprob": -0.23045740422514296,
        "compression_ratio": 1.5555555555555556,
        "end": 5047.66,
        "id": 1595,
        "no_speech_prob": 0.001367021817713976,
        "seek": 504370,
        "start": 5046.34,
        "temperature": 0,
        "text": " So now, guess what?",
        "tokens": [
          50496,
          407,
          586,
          11,
          2041,
          437,
          30,
          50562
        ]
      },
      {
        "avg_logprob": -0.23045740422514296,
        "compression_ratio": 1.5555555555555556,
        "end": 5051.139999999999,
        "id": 1596,
        "no_speech_prob": 0.001367021817713976,
        "seek": 504370,
        "start": 5047.66,
        "temperature": 0,
        "text": " If I go to localhost 3000 slash rainbow,",
        "tokens": [
          50562,
          759,
          286,
          352,
          281,
          2654,
          6037,
          20984,
          17330,
          18526,
          11,
          50736
        ]
      },
      {
        "avg_logprob": -0.23045740422514296,
        "compression_ratio": 1.5555555555555556,
        "end": 5056.66,
        "id": 1597,
        "no_speech_prob": 0.001367021817713976,
        "seek": 504370,
        "start": 5051.139999999999,
        "temperature": 0,
        "text": " I get a drawing because I'm handling that rainbow route",
        "tokens": [
          50736,
          286,
          483,
          257,
          6316,
          570,
          286,
          478,
          13175,
          300,
          18526,
          7955,
          51012
        ]
      },
      {
        "avg_logprob": -0.23045740422514296,
        "compression_ratio": 1.5555555555555556,
        "end": 5058.86,
        "id": 1598,
        "no_speech_prob": 0.001367021817713976,
        "seek": 504370,
        "start": 5056.66,
        "temperature": 0,
        "text": " by sending back a drawing.",
        "tokens": [
          51012,
          538,
          7750,
          646,
          257,
          6316,
          13,
          51122
        ]
      },
      {
        "avg_logprob": -0.23045740422514296,
        "compression_ratio": 1.5555555555555556,
        "end": 5062.86,
        "id": 1599,
        "no_speech_prob": 0.001367021817713976,
        "seek": 504370,
        "start": 5058.86,
        "temperature": 0,
        "text": " But if I go to just slash, oh, I didn't restart the server,",
        "tokens": [
          51122,
          583,
          498,
          286,
          352,
          281,
          445,
          17330,
          11,
          1954,
          11,
          286,
          994,
          380,
          21022,
          264,
          7154,
          11,
          51322
        ]
      },
      {
        "avg_logprob": -0.23045740422514296,
        "compression_ratio": 1.5555555555555556,
        "end": 5064.26,
        "id": 1600,
        "no_speech_prob": 0.001367021817713976,
        "seek": 504370,
        "start": 5062.86,
        "temperature": 0,
        "text": " did I?",
        "tokens": [
          51322,
          630,
          286,
          30,
          51392
        ]
      },
      {
        "avg_logprob": -0.23045740422514296,
        "compression_ratio": 1.5555555555555556,
        "end": 5067.78,
        "id": 1601,
        "no_speech_prob": 0.001367021817713976,
        "seek": 504370,
        "start": 5064.26,
        "temperature": 0,
        "text": " Restart the server, go to slash, there's the p5 sketch.",
        "tokens": [
          51392,
          13094,
          446,
          264,
          7154,
          11,
          352,
          281,
          17330,
          11,
          456,
          311,
          264,
          280,
          20,
          12325,
          13,
          51568
        ]
      },
      {
        "avg_logprob": -0.24579410254955292,
        "compression_ratio": 1.6857142857142857,
        "end": 5073.3,
        "id": 1602,
        "no_speech_prob": 0.000001903384486467985,
        "seek": 506778,
        "start": 5067.78,
        "temperature": 0,
        "text": " So now, my p5 sketch can finally ask",
        "tokens": [
          50364,
          407,
          586,
          11,
          452,
          280,
          20,
          12325,
          393,
          2721,
          1029,
          50640
        ]
      },
      {
        "avg_logprob": -0.24579410254955292,
        "compression_ratio": 1.6857142857142857,
        "end": 5075.34,
        "id": 1603,
        "no_speech_prob": 0.000001903384486467985,
        "seek": 506778,
        "start": 5073.3,
        "temperature": 0,
        "text": " for the server for the drawing.",
        "tokens": [
          50640,
          337,
          264,
          7154,
          337,
          264,
          6316,
          13,
          50742
        ]
      },
      {
        "avg_logprob": -0.24579410254955292,
        "compression_ratio": 1.6857142857142857,
        "end": 5076.62,
        "id": 1604,
        "no_speech_prob": 0.000001903384486467985,
        "seek": 506778,
        "start": 5075.34,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50742,
          2264,
          13,
          50806
        ]
      },
      {
        "avg_logprob": -0.24579410254955292,
        "compression_ratio": 1.6857142857142857,
        "end": 5078.3,
        "id": 1605,
        "no_speech_prob": 0.000001903384486467985,
        "seek": 506778,
        "start": 5076.62,
        "temperature": 0,
        "text": " I'm going to go over here and I'm going to say it.",
        "tokens": [
          50806,
          286,
          478,
          516,
          281,
          352,
          670,
          510,
          293,
          286,
          478,
          516,
          281,
          584,
          309,
          13,
          50890
        ]
      },
      {
        "avg_logprob": -0.24579410254955292,
        "compression_ratio": 1.6857142857142857,
        "end": 5079.96,
        "id": 1606,
        "no_speech_prob": 0.000001903384486467985,
        "seek": 506778,
        "start": 5078.3,
        "temperature": 0,
        "text": " First of all, one thing is, by the way,",
        "tokens": [
          50890,
          2386,
          295,
          439,
          11,
          472,
          551,
          307,
          11,
          538,
          264,
          636,
          11,
          50973
        ]
      },
      {
        "avg_logprob": -0.24579410254955292,
        "compression_ratio": 1.6857142857142857,
        "end": 5083.099999999999,
        "id": 1607,
        "no_speech_prob": 0.000001903384486467985,
        "seek": 506778,
        "start": 5079.96,
        "temperature": 0,
        "text": " that simplified data set, all of the simplified version",
        "tokens": [
          50973,
          300,
          26335,
          1412,
          992,
          11,
          439,
          295,
          264,
          26335,
          3037,
          51130
        ]
      },
      {
        "avg_logprob": -0.24579410254955292,
        "compression_ratio": 1.6857142857142857,
        "end": 5085.34,
        "id": 1608,
        "no_speech_prob": 0.000001903384486467985,
        "seek": 506778,
        "start": 5083.099999999999,
        "temperature": 0,
        "text": " of the QuickDraw data set, all of the drawings",
        "tokens": [
          51130,
          295,
          264,
          12101,
          35,
          5131,
          1412,
          992,
          11,
          439,
          295,
          264,
          18618,
          51242
        ]
      },
      {
        "avg_logprob": -0.24579410254955292,
        "compression_ratio": 1.6857142857142857,
        "end": 5089.34,
        "id": 1609,
        "no_speech_prob": 0.000001903384486467985,
        "seek": 506778,
        "start": 5085.34,
        "temperature": 0,
        "text": " were simplified or scaled to 255 by 255 pixels.",
        "tokens": [
          51242,
          645,
          26335,
          420,
          36039,
          281,
          3552,
          20,
          538,
          3552,
          20,
          18668,
          13,
          51442
        ]
      },
      {
        "avg_logprob": -0.24579410254955292,
        "compression_ratio": 1.6857142857142857,
        "end": 5091.62,
        "id": 1610,
        "no_speech_prob": 0.000001903384486467985,
        "seek": 506778,
        "start": 5089.34,
        "temperature": 0,
        "text": " So that makes things easier to work with.",
        "tokens": [
          51442,
          407,
          300,
          1669,
          721,
          3571,
          281,
          589,
          365,
          13,
          51556
        ]
      },
      {
        "avg_logprob": -0.24579410254955292,
        "compression_ratio": 1.6857142857142857,
        "end": 5093.86,
        "id": 1611,
        "no_speech_prob": 0.000001903384486467985,
        "seek": 506778,
        "start": 5091.62,
        "temperature": 0,
        "text": " I'm going to call the function loadJSON.",
        "tokens": [
          51556,
          286,
          478,
          516,
          281,
          818,
          264,
          2445,
          3677,
          41,
          10388,
          13,
          51668
        ]
      },
      {
        "avg_logprob": -0.24579410254955292,
        "compression_ratio": 1.6857142857142857,
        "end": 5094.9,
        "id": 1612,
        "no_speech_prob": 0.000001903384486467985,
        "seek": 506778,
        "start": 5093.86,
        "temperature": 0,
        "text": " And guess what?",
        "tokens": [
          51668,
          400,
          2041,
          437,
          30,
          51720
        ]
      },
      {
        "avg_logprob": -0.253626963671516,
        "compression_ratio": 1.7222222222222223,
        "end": 5100.139999999999,
        "id": 1613,
        "no_speech_prob": 0.0002234160783700645,
        "seek": 509490,
        "start": 5094.9,
        "temperature": 0,
        "text": " I'm just going to say loadJSON rainbow got rainbow.",
        "tokens": [
          50364,
          286,
          478,
          445,
          516,
          281,
          584,
          3677,
          41,
          10388,
          18526,
          658,
          18526,
          13,
          50626
        ]
      },
      {
        "avg_logprob": -0.253626963671516,
        "compression_ratio": 1.7222222222222223,
        "end": 5102.46,
        "id": 1614,
        "no_speech_prob": 0.0002234160783700645,
        "seek": 509490,
        "start": 5100.139999999999,
        "temperature": 0,
        "text": " And then I'm going to write a function,",
        "tokens": [
          50626,
          400,
          550,
          286,
          478,
          516,
          281,
          2464,
          257,
          2445,
          11,
          50742
        ]
      },
      {
        "avg_logprob": -0.253626963671516,
        "compression_ratio": 1.7222222222222223,
        "end": 5105.62,
        "id": 1615,
        "no_speech_prob": 0.0002234160783700645,
        "seek": 509490,
        "start": 5102.46,
        "temperature": 0,
        "text": " gotRainbow, that gets some data.",
        "tokens": [
          50742,
          658,
          49,
          491,
          8202,
          11,
          300,
          2170,
          512,
          1412,
          13,
          50900
        ]
      },
      {
        "avg_logprob": -0.253626963671516,
        "compression_ratio": 1.7222222222222223,
        "end": 5107.78,
        "id": 1616,
        "no_speech_prob": 0.0002234160783700645,
        "seek": 509490,
        "start": 5105.62,
        "temperature": 0,
        "text": " And I'm going to say console.log data.",
        "tokens": [
          50900,
          400,
          286,
          478,
          516,
          281,
          584,
          11076,
          13,
          4987,
          1412,
          13,
          51008
        ]
      },
      {
        "avg_logprob": -0.253626963671516,
        "compression_ratio": 1.7222222222222223,
        "end": 5108.66,
        "id": 1617,
        "no_speech_prob": 0.0002234160783700645,
        "seek": 509490,
        "start": 5107.78,
        "temperature": 0,
        "text": " So this is the idea.",
        "tokens": [
          51008,
          407,
          341,
          307,
          264,
          1558,
          13,
          51052
        ]
      },
      {
        "avg_logprob": -0.253626963671516,
        "compression_ratio": 1.7222222222222223,
        "end": 5111.44,
        "id": 1618,
        "no_speech_prob": 0.0002234160783700645,
        "seek": 509490,
        "start": 5108.66,
        "temperature": 0,
        "text": " Now, if you've seen loadJSON before,",
        "tokens": [
          51052,
          823,
          11,
          498,
          291,
          600,
          1612,
          3677,
          41,
          10388,
          949,
          11,
          51191
        ]
      },
      {
        "avg_logprob": -0.253626963671516,
        "compression_ratio": 1.7222222222222223,
        "end": 5115.54,
        "id": 1619,
        "no_speech_prob": 0.0002234160783700645,
        "seek": 509490,
        "start": 5111.44,
        "temperature": 0,
        "text": " maybe before I've used it for load this actual JSON file.",
        "tokens": [
          51191,
          1310,
          949,
          286,
          600,
          1143,
          309,
          337,
          3677,
          341,
          3539,
          31828,
          3991,
          13,
          51396
        ]
      },
      {
        "avg_logprob": -0.253626963671516,
        "compression_ratio": 1.7222222222222223,
        "end": 5118.58,
        "id": 1620,
        "no_speech_prob": 0.0002234160783700645,
        "seek": 509490,
        "start": 5115.54,
        "temperature": 0,
        "text": " Or maybe I've said loadJSON from an API like Wordnik.",
        "tokens": [
          51396,
          1610,
          1310,
          286,
          600,
          848,
          3677,
          41,
          10388,
          490,
          364,
          9362,
          411,
          8725,
          13123,
          13,
          51548
        ]
      },
      {
        "avg_logprob": -0.253626963671516,
        "compression_ratio": 1.7222222222222223,
        "end": 5121.139999999999,
        "id": 1621,
        "no_speech_prob": 0.0002234160783700645,
        "seek": 509490,
        "start": 5118.58,
        "temperature": 0,
        "text": " Now, I'm going to the slash rainbow route, which",
        "tokens": [
          51548,
          823,
          11,
          286,
          478,
          516,
          281,
          264,
          17330,
          18526,
          7955,
          11,
          597,
          51676
        ]
      },
      {
        "avg_logprob": -0.253626963671516,
        "compression_ratio": 1.7222222222222223,
        "end": 5122.74,
        "id": 1622,
        "no_speech_prob": 0.0002234160783700645,
        "seek": 509490,
        "start": 5121.139999999999,
        "temperature": 0,
        "text": " is local to this particular server.",
        "tokens": [
          51676,
          307,
          2654,
          281,
          341,
          1729,
          7154,
          13,
          51756
        ]
      },
      {
        "avg_logprob": -0.253626963671516,
        "compression_ratio": 1.7222222222222223,
        "end": 5123.099999999999,
        "id": 1623,
        "no_speech_prob": 0.0002234160783700645,
        "seek": 509490,
        "start": 5122.74,
        "temperature": 0,
        "text": " And guess what?",
        "tokens": [
          51756,
          400,
          2041,
          437,
          30,
          51774
        ]
      },
      {
        "avg_logprob": -0.2506206512451172,
        "compression_ratio": 1.6182572614107884,
        "end": 5125.3,
        "id": 1624,
        "no_speech_prob": 0.000057387496781302616,
        "seek": 512310,
        "start": 5123.1,
        "temperature": 0,
        "text": " I don't actually even need to restart the server,",
        "tokens": [
          50364,
          286,
          500,
          380,
          767,
          754,
          643,
          281,
          21022,
          264,
          7154,
          11,
          50474
        ]
      },
      {
        "avg_logprob": -0.2506206512451172,
        "compression_ratio": 1.6182572614107884,
        "end": 5127.860000000001,
        "id": 1625,
        "no_speech_prob": 0.000057387496781302616,
        "seek": 512310,
        "start": 5125.3,
        "temperature": 0,
        "text": " because this will be loaded dynamically.",
        "tokens": [
          50474,
          570,
          341,
          486,
          312,
          13210,
          43492,
          13,
          50602
        ]
      },
      {
        "avg_logprob": -0.2506206512451172,
        "compression_ratio": 1.6182572614107884,
        "end": 5129.18,
        "id": 1626,
        "no_speech_prob": 0.000057387496781302616,
        "seek": 512310,
        "start": 5127.860000000001,
        "temperature": 0,
        "text": " So let's go here.",
        "tokens": [
          50602,
          407,
          718,
          311,
          352,
          510,
          13,
          50668
        ]
      },
      {
        "avg_logprob": -0.2506206512451172,
        "compression_ratio": 1.6182572614107884,
        "end": 5130.9400000000005,
        "id": 1627,
        "no_speech_prob": 0.000057387496781302616,
        "seek": 512310,
        "start": 5129.18,
        "temperature": 0,
        "text": " And we can see, there it is.",
        "tokens": [
          50668,
          400,
          321,
          393,
          536,
          11,
          456,
          309,
          307,
          13,
          50756
        ]
      },
      {
        "avg_logprob": -0.2506206512451172,
        "compression_ratio": 1.6182572614107884,
        "end": 5133.5,
        "id": 1628,
        "no_speech_prob": 0.000057387496781302616,
        "seek": 512310,
        "start": 5130.9400000000005,
        "temperature": 0,
        "text": " This is the rainbow drawing right here.",
        "tokens": [
          50756,
          639,
          307,
          264,
          18526,
          6316,
          558,
          510,
          13,
          50884
        ]
      },
      {
        "avg_logprob": -0.2506206512451172,
        "compression_ratio": 1.6182572614107884,
        "end": 5134.92,
        "id": 1629,
        "no_speech_prob": 0.000057387496781302616,
        "seek": 512310,
        "start": 5133.5,
        "temperature": 0,
        "text": " Let me give myself some more room.",
        "tokens": [
          50884,
          961,
          385,
          976,
          2059,
          512,
          544,
          1808,
          13,
          50955
        ]
      },
      {
        "avg_logprob": -0.2506206512451172,
        "compression_ratio": 1.6182572614107884,
        "end": 5136.34,
        "id": 1630,
        "no_speech_prob": 0.000057387496781302616,
        "seek": 512310,
        "start": 5134.92,
        "temperature": 0,
        "text": " And here's the drawing itself.",
        "tokens": [
          50955,
          400,
          510,
          311,
          264,
          6316,
          2564,
          13,
          51026
        ]
      },
      {
        "avg_logprob": -0.2506206512451172,
        "compression_ratio": 1.6182572614107884,
        "end": 5138.58,
        "id": 1631,
        "no_speech_prob": 0.000057387496781302616,
        "seek": 512310,
        "start": 5136.34,
        "temperature": 0,
        "text": " So all I need to do now is write an algorithm",
        "tokens": [
          51026,
          407,
          439,
          286,
          643,
          281,
          360,
          586,
          307,
          2464,
          364,
          9284,
          51138
        ]
      },
      {
        "avg_logprob": -0.2506206512451172,
        "compression_ratio": 1.6182572614107884,
        "end": 5141.58,
        "id": 1632,
        "no_speech_prob": 0.000057387496781302616,
        "seek": 512310,
        "start": 5138.58,
        "temperature": 0,
        "text": " to go through and draw this drawing.",
        "tokens": [
          51138,
          281,
          352,
          807,
          293,
          2642,
          341,
          6316,
          13,
          51288
        ]
      },
      {
        "avg_logprob": -0.2506206512451172,
        "compression_ratio": 1.6182572614107884,
        "end": 5142.860000000001,
        "id": 1633,
        "no_speech_prob": 0.000057387496781302616,
        "seek": 512310,
        "start": 5141.58,
        "temperature": 0,
        "text": " All right, we're ready.",
        "tokens": [
          51288,
          1057,
          558,
          11,
          321,
          434,
          1919,
          13,
          51352
        ]
      },
      {
        "avg_logprob": -0.2506206512451172,
        "compression_ratio": 1.6182572614107884,
        "end": 5146.780000000001,
        "id": 1634,
        "no_speech_prob": 0.000057387496781302616,
        "seek": 512310,
        "start": 5142.860000000001,
        "temperature": 0,
        "text": " So let me make the background like 200.",
        "tokens": [
          51352,
          407,
          718,
          385,
          652,
          264,
          3678,
          411,
          2331,
          13,
          51548
        ]
      },
      {
        "avg_logprob": -0.30582213888362964,
        "compression_ratio": 1.532258064516129,
        "end": 5153.9,
        "id": 1635,
        "no_speech_prob": 0.00020988266624044627,
        "seek": 514678,
        "start": 5146.78,
        "temperature": 0,
        "text": " Let me say the drawing is in data.drawing.",
        "tokens": [
          50364,
          961,
          385,
          584,
          264,
          6316,
          307,
          294,
          1412,
          13,
          48848,
          278,
          13,
          50720
        ]
      },
      {
        "avg_logprob": -0.30582213888362964,
        "compression_ratio": 1.532258064516129,
        "end": 5155.66,
        "id": 1636,
        "no_speech_prob": 0.00020988266624044627,
        "seek": 514678,
        "start": 5153.9,
        "temperature": 0,
        "text": " Is that right?",
        "tokens": [
          50720,
          1119,
          300,
          558,
          30,
          50808
        ]
      },
      {
        "avg_logprob": -0.30582213888362964,
        "compression_ratio": 1.532258064516129,
        "end": 5157.54,
        "id": 1637,
        "no_speech_prob": 0.00020988266624044627,
        "seek": 514678,
        "start": 5155.66,
        "temperature": 0,
        "text": " Console.log drawing.",
        "tokens": [
          50808,
          44152,
          13,
          4987,
          6316,
          13,
          50902
        ]
      },
      {
        "avg_logprob": -0.30582213888362964,
        "compression_ratio": 1.532258064516129,
        "end": 5158.58,
        "id": 1638,
        "no_speech_prob": 0.00020988266624044627,
        "seek": 514678,
        "start": 5157.54,
        "temperature": 0,
        "text": " Let's look at that.",
        "tokens": [
          50902,
          961,
          311,
          574,
          412,
          300,
          13,
          50954
        ]
      },
      {
        "avg_logprob": -0.30582213888362964,
        "compression_ratio": 1.532258064516129,
        "end": 5159.0599999999995,
        "id": 1639,
        "no_speech_prob": 0.00020988266624044627,
        "seek": 514678,
        "start": 5158.58,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          50954,
          865,
          13,
          50978
        ]
      },
      {
        "avg_logprob": -0.30582213888362964,
        "compression_ratio": 1.532258064516129,
        "end": 5160.62,
        "id": 1640,
        "no_speech_prob": 0.00020988266624044627,
        "seek": 514678,
        "start": 5159.0599999999995,
        "temperature": 0,
        "text": " So this is the actual drawing.",
        "tokens": [
          50978,
          407,
          341,
          307,
          264,
          3539,
          6316,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.30582213888362964,
        "compression_ratio": 1.532258064516129,
        "end": 5163.219999999999,
        "id": 1641,
        "no_speech_prob": 0.00020988266624044627,
        "seek": 514678,
        "start": 5160.62,
        "temperature": 0,
        "text": " It's just two arrays, because it was just two strokes.",
        "tokens": [
          51056,
          467,
          311,
          445,
          732,
          41011,
          11,
          570,
          309,
          390,
          445,
          732,
          24493,
          13,
          51186
        ]
      },
      {
        "avg_logprob": -0.30582213888362964,
        "compression_ratio": 1.532258064516129,
        "end": 5168.42,
        "id": 1642,
        "no_speech_prob": 0.00020988266624044627,
        "seek": 514678,
        "start": 5163.219999999999,
        "temperature": 0,
        "text": " Now, I am going to say for let i equals 0,",
        "tokens": [
          51186,
          823,
          11,
          286,
          669,
          516,
          281,
          584,
          337,
          718,
          741,
          6915,
          1958,
          11,
          51446
        ]
      },
      {
        "avg_logprob": -0.30582213888362964,
        "compression_ratio": 1.532258064516129,
        "end": 5169.9,
        "id": 1643,
        "no_speech_prob": 0.00020988266624044627,
        "seek": 514678,
        "start": 5168.42,
        "temperature": 0,
        "text": " i is less than drawing.",
        "tokens": [
          51446,
          741,
          307,
          1570,
          813,
          6316,
          13,
          51520
        ]
      },
      {
        "avg_logprob": -0.30582213888362964,
        "compression_ratio": 1.532258064516129,
        "end": 5176.3,
        "id": 1644,
        "no_speech_prob": 0.00020988266624044627,
        "seek": 514678,
        "start": 5173.58,
        "temperature": 0,
        "text": " Oh, let me figure this out.",
        "tokens": [
          51704,
          876,
          11,
          718,
          385,
          2573,
          341,
          484,
          13,
          51840
        ]
      },
      {
        "avg_logprob": -0.2467374986217868,
        "compression_ratio": 1.7605042016806722,
        "end": 5177.860000000001,
        "id": 1645,
        "no_speech_prob": 0.000012029624485876411,
        "seek": 517630,
        "start": 5177.02,
        "temperature": 0,
        "text": " This is an array.",
        "tokens": [
          50400,
          639,
          307,
          364,
          10225,
          13,
          50442
        ]
      },
      {
        "avg_logprob": -0.2467374986217868,
        "compression_ratio": 1.7605042016806722,
        "end": 5178.900000000001,
        "id": 1646,
        "no_speech_prob": 0.000012029624485876411,
        "seek": 517630,
        "start": 5177.860000000001,
        "temperature": 0,
        "text": " Oh, right.",
        "tokens": [
          50442,
          876,
          11,
          558,
          13,
          50494
        ]
      },
      {
        "avg_logprob": -0.2467374986217868,
        "compression_ratio": 1.7605042016806722,
        "end": 5180.14,
        "id": 1647,
        "no_speech_prob": 0.000012029624485876411,
        "seek": 517630,
        "start": 5178.900000000001,
        "temperature": 0,
        "text": " Oh, weird.",
        "tokens": [
          50494,
          876,
          11,
          3657,
          13,
          50556
        ]
      },
      {
        "avg_logprob": -0.2467374986217868,
        "compression_ratio": 1.7605042016806722,
        "end": 5180.78,
        "id": 1648,
        "no_speech_prob": 0.000012029624485876411,
        "seek": 517630,
        "start": 5180.14,
        "temperature": 0,
        "text": " I'm sorry.",
        "tokens": [
          50556,
          286,
          478,
          2597,
          13,
          50588
        ]
      },
      {
        "avg_logprob": -0.2467374986217868,
        "compression_ratio": 1.7605042016806722,
        "end": 5181.38,
        "id": 1649,
        "no_speech_prob": 0.000012029624485876411,
        "seek": 517630,
        "start": 5180.78,
        "temperature": 0,
        "text": " Oh, right.",
        "tokens": [
          50588,
          876,
          11,
          558,
          13,
          50618
        ]
      },
      {
        "avg_logprob": -0.2467374986217868,
        "compression_ratio": 1.7605042016806722,
        "end": 5181.900000000001,
        "id": 1650,
        "no_speech_prob": 0.000012029624485876411,
        "seek": 517630,
        "start": 5181.38,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50618,
          2264,
          13,
          50644
        ]
      },
      {
        "avg_logprob": -0.2467374986217868,
        "compression_ratio": 1.7605042016806722,
        "end": 5184.14,
        "id": 1651,
        "no_speech_prob": 0.000012029624485876411,
        "seek": 517630,
        "start": 5181.900000000001,
        "temperature": 0,
        "text": " So this was only one stroke.",
        "tokens": [
          50644,
          407,
          341,
          390,
          787,
          472,
          12403,
          13,
          50756
        ]
      },
      {
        "avg_logprob": -0.2467374986217868,
        "compression_ratio": 1.7605042016806722,
        "end": 5185.78,
        "id": 1652,
        "no_speech_prob": 0.000012029624485876411,
        "seek": 517630,
        "start": 5184.14,
        "temperature": 0,
        "text": " That's why this was confusing here.",
        "tokens": [
          50756,
          663,
          311,
          983,
          341,
          390,
          13181,
          510,
          13,
          50838
        ]
      },
      {
        "avg_logprob": -0.2467374986217868,
        "compression_ratio": 1.7605042016806722,
        "end": 5186.66,
        "id": 1653,
        "no_speech_prob": 0.000012029624485876411,
        "seek": 517630,
        "start": 5185.78,
        "temperature": 0,
        "text": " Some of these rainbows.",
        "tokens": [
          50838,
          2188,
          295,
          613,
          4830,
          21118,
          13,
          50882
        ]
      },
      {
        "avg_logprob": -0.2467374986217868,
        "compression_ratio": 1.7605042016806722,
        "end": 5186.9400000000005,
        "id": 1654,
        "no_speech_prob": 0.000012029624485876411,
        "seek": 517630,
        "start": 5186.66,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50882,
          821,
          321,
          352,
          13,
          50896
        ]
      },
      {
        "avg_logprob": -0.2467374986217868,
        "compression_ratio": 1.7605042016806722,
        "end": 5188.24,
        "id": 1655,
        "no_speech_prob": 0.000012029624485876411,
        "seek": 517630,
        "start": 5186.9400000000005,
        "temperature": 0,
        "text": " This is what I want to look at.",
        "tokens": [
          50896,
          639,
          307,
          437,
          286,
          528,
          281,
          574,
          412,
          13,
          50961
        ]
      },
      {
        "avg_logprob": -0.2467374986217868,
        "compression_ratio": 1.7605042016806722,
        "end": 5191.34,
        "id": 1656,
        "no_speech_prob": 0.000012029624485876411,
        "seek": 517630,
        "start": 5188.24,
        "temperature": 0,
        "text": " I have three different strokes.",
        "tokens": [
          50961,
          286,
          362,
          1045,
          819,
          24493,
          13,
          51116
        ]
      },
      {
        "avg_logprob": -0.2467374986217868,
        "compression_ratio": 1.7605042016806722,
        "end": 5193.14,
        "id": 1657,
        "no_speech_prob": 0.000012029624485876411,
        "seek": 517630,
        "start": 5191.34,
        "temperature": 0,
        "text": " So first, I need to look at all the strokes.",
        "tokens": [
          51116,
          407,
          700,
          11,
          286,
          643,
          281,
          574,
          412,
          439,
          264,
          24493,
          13,
          51206
        ]
      },
      {
        "avg_logprob": -0.2467374986217868,
        "compression_ratio": 1.7605042016806722,
        "end": 5193.9800000000005,
        "id": 1658,
        "no_speech_prob": 0.000012029624485876411,
        "seek": 517630,
        "start": 5193.14,
        "temperature": 0,
        "text": " Sorry.",
        "tokens": [
          51206,
          4919,
          13,
          51248
        ]
      },
      {
        "avg_logprob": -0.2467374986217868,
        "compression_ratio": 1.7605042016806722,
        "end": 5197.860000000001,
        "id": 1659,
        "no_speech_prob": 0.000012029624485876411,
        "seek": 517630,
        "start": 5193.9800000000005,
        "temperature": 0,
        "text": " So I want to say let, and I'm going to call it a path.",
        "tokens": [
          51248,
          407,
          286,
          528,
          281,
          584,
          718,
          11,
          293,
          286,
          478,
          516,
          281,
          818,
          309,
          257,
          3100,
          13,
          51442
        ]
      },
      {
        "avg_logprob": -0.2467374986217868,
        "compression_ratio": 1.7605042016806722,
        "end": 5200.38,
        "id": 1660,
        "no_speech_prob": 0.000012029624485876411,
        "seek": 517630,
        "start": 5197.860000000001,
        "temperature": 0,
        "text": " So for let path of drawing.",
        "tokens": [
          51442,
          407,
          337,
          718,
          3100,
          295,
          6316,
          13,
          51568
        ]
      },
      {
        "avg_logprob": -0.2467374986217868,
        "compression_ratio": 1.7605042016806722,
        "end": 5202.3,
        "id": 1661,
        "no_speech_prob": 0.000012029624485876411,
        "seek": 517630,
        "start": 5200.38,
        "temperature": 0,
        "text": " This is each and every path.",
        "tokens": [
          51568,
          639,
          307,
          1184,
          293,
          633,
          3100,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2467374986217868,
        "compression_ratio": 1.7605042016806722,
        "end": 5204.06,
        "id": 1662,
        "no_speech_prob": 0.000012029624485876411,
        "seek": 517630,
        "start": 5202.3,
        "temperature": 0,
        "text": " Path 0, path 1, path 2.",
        "tokens": [
          51664,
          21914,
          1958,
          11,
          3100,
          502,
          11,
          3100,
          568,
          13,
          51752
        ]
      },
      {
        "avg_logprob": -0.26850253138048896,
        "compression_ratio": 1.49079754601227,
        "end": 5206.820000000001,
        "id": 1663,
        "no_speech_prob": 0.000021444941012305208,
        "seek": 520406,
        "start": 5204.06,
        "temperature": 0,
        "text": " Then each path has a bunch of points.",
        "tokens": [
          50364,
          1396,
          1184,
          3100,
          575,
          257,
          3840,
          295,
          2793,
          13,
          50502
        ]
      },
      {
        "avg_logprob": -0.26850253138048896,
        "compression_ratio": 1.49079754601227,
        "end": 5212.14,
        "id": 1664,
        "no_speech_prob": 0.000021444941012305208,
        "seek": 520406,
        "start": 5206.820000000001,
        "temperature": 0,
        "text": " Path 0 has 15, path 1 has 10, path 2 has 6.",
        "tokens": [
          50502,
          21914,
          1958,
          575,
          2119,
          11,
          3100,
          502,
          575,
          1266,
          11,
          3100,
          568,
          575,
          1386,
          13,
          50768
        ]
      },
      {
        "avg_logprob": -0.26850253138048896,
        "compression_ratio": 1.49079754601227,
        "end": 5214.820000000001,
        "id": 1665,
        "no_speech_prob": 0.000021444941012305208,
        "seek": 520406,
        "start": 5212.14,
        "temperature": 0,
        "text": " I'm going to say for let i equals 0,",
        "tokens": [
          50768,
          286,
          478,
          516,
          281,
          584,
          337,
          718,
          741,
          6915,
          1958,
          11,
          50902
        ]
      },
      {
        "avg_logprob": -0.26850253138048896,
        "compression_ratio": 1.49079754601227,
        "end": 5221.26,
        "id": 1666,
        "no_speech_prob": 0.000021444941012305208,
        "seek": 520406,
        "start": 5214.820000000001,
        "temperature": 0,
        "text": " i is less than path index 0 dot length.",
        "tokens": [
          50902,
          741,
          307,
          1570,
          813,
          3100,
          8186,
          1958,
          5893,
          4641,
          13,
          51224
        ]
      },
      {
        "avg_logprob": -0.26850253138048896,
        "compression_ratio": 1.49079754601227,
        "end": 5228.38,
        "id": 1667,
        "no_speech_prob": 0.000021444941012305208,
        "seek": 520406,
        "start": 5221.26,
        "temperature": 0,
        "text": " And then the x is path index 0 index 1.",
        "tokens": [
          51224,
          400,
          550,
          264,
          2031,
          307,
          3100,
          8186,
          1958,
          8186,
          502,
          13,
          51580
        ]
      },
      {
        "avg_logprob": -0.26850253138048896,
        "compression_ratio": 1.49079754601227,
        "end": 5230.1,
        "id": 1668,
        "no_speech_prob": 0.000021444941012305208,
        "seek": 520406,
        "start": 5228.38,
        "temperature": 0,
        "text": " Wait, no, index i.",
        "tokens": [
          51580,
          3802,
          11,
          572,
          11,
          8186,
          741,
          13,
          51666
        ]
      },
      {
        "avg_logprob": -0.26850253138048896,
        "compression_ratio": 1.49079754601227,
        "end": 5230.740000000001,
        "id": 1669,
        "no_speech_prob": 0.000021444941012305208,
        "seek": 520406,
        "start": 5230.1,
        "temperature": 0,
        "text": " Sorry.",
        "tokens": [
          51666,
          4919,
          13,
          51698
        ]
      },
      {
        "avg_logprob": -0.26850253138048896,
        "compression_ratio": 1.49079754601227,
        "end": 5231.740000000001,
        "id": 1670,
        "no_speech_prob": 0.000021444941012305208,
        "seek": 520406,
        "start": 5230.740000000001,
        "temperature": 0,
        "text": " This is confusing.",
        "tokens": [
          51698,
          639,
          307,
          13181,
          13,
          51748
        ]
      },
      {
        "avg_logprob": -0.19563369427697133,
        "compression_ratio": 1.638743455497382,
        "end": 5235.54,
        "id": 1671,
        "no_speech_prob": 0.00003883108729496598,
        "seek": 523174,
        "start": 5231.74,
        "temperature": 0,
        "text": " And the y is path index 1 index i.",
        "tokens": [
          50364,
          400,
          264,
          288,
          307,
          3100,
          8186,
          502,
          8186,
          741,
          13,
          50554
        ]
      },
      {
        "avg_logprob": -0.19563369427697133,
        "compression_ratio": 1.638743455497382,
        "end": 5236.7,
        "id": 1672,
        "no_speech_prob": 0.00003883108729496598,
        "seek": 523174,
        "start": 5235.54,
        "temperature": 0,
        "text": " So this is what I'm doing.",
        "tokens": [
          50554,
          407,
          341,
          307,
          437,
          286,
          478,
          884,
          13,
          50612
        ]
      },
      {
        "avg_logprob": -0.19563369427697133,
        "compression_ratio": 1.638743455497382,
        "end": 5240.179999999999,
        "id": 1673,
        "no_speech_prob": 0.00003883108729496598,
        "seek": 523174,
        "start": 5236.7,
        "temperature": 0,
        "text": " I am looping through 0, 1, 2.",
        "tokens": [
          50612,
          286,
          669,
          6367,
          278,
          807,
          1958,
          11,
          502,
          11,
          568,
          13,
          50786
        ]
      },
      {
        "avg_logprob": -0.19563369427697133,
        "compression_ratio": 1.638743455497382,
        "end": 5242.26,
        "id": 1674,
        "no_speech_prob": 0.00003883108729496598,
        "seek": 523174,
        "start": 5240.179999999999,
        "temperature": 0,
        "text": " That's the outer loop.",
        "tokens": [
          50786,
          663,
          311,
          264,
          10847,
          6367,
          13,
          50890
        ]
      },
      {
        "avg_logprob": -0.19563369427697133,
        "compression_ratio": 1.638743455497382,
        "end": 5242.98,
        "id": 1675,
        "no_speech_prob": 0.00003883108729496598,
        "seek": 523174,
        "start": 5242.26,
        "temperature": 0,
        "text": " Each path.",
        "tokens": [
          50890,
          6947,
          3100,
          13,
          50926
        ]
      },
      {
        "avg_logprob": -0.19563369427697133,
        "compression_ratio": 1.638743455497382,
        "end": 5246.82,
        "id": 1676,
        "no_speech_prob": 0.00003883108729496598,
        "seek": 523174,
        "start": 5242.98,
        "temperature": 0,
        "text": " Each path is two arrays.",
        "tokens": [
          50926,
          6947,
          3100,
          307,
          732,
          41011,
          13,
          51118
        ]
      },
      {
        "avg_logprob": -0.19563369427697133,
        "compression_ratio": 1.638743455497382,
        "end": 5248.219999999999,
        "id": 1677,
        "no_speech_prob": 0.00003883108729496598,
        "seek": 523174,
        "start": 5246.82,
        "temperature": 0,
        "text": " Path 0 is all the x's.",
        "tokens": [
          51118,
          21914,
          1958,
          307,
          439,
          264,
          2031,
          311,
          13,
          51188
        ]
      },
      {
        "avg_logprob": -0.19563369427697133,
        "compression_ratio": 1.638743455497382,
        "end": 5249.78,
        "id": 1678,
        "no_speech_prob": 0.00003883108729496598,
        "seek": 523174,
        "start": 5248.219999999999,
        "temperature": 0,
        "text": " Path 1 is all the y's.",
        "tokens": [
          51188,
          21914,
          502,
          307,
          439,
          264,
          288,
          311,
          13,
          51266
        ]
      },
      {
        "avg_logprob": -0.19563369427697133,
        "compression_ratio": 1.638743455497382,
        "end": 5251.74,
        "id": 1679,
        "no_speech_prob": 0.00003883108729496598,
        "seek": 523174,
        "start": 5249.78,
        "temperature": 0,
        "text": " I need to look at all the x's and all the y's,",
        "tokens": [
          51266,
          286,
          643,
          281,
          574,
          412,
          439,
          264,
          2031,
          311,
          293,
          439,
          264,
          288,
          311,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.19563369427697133,
        "compression_ratio": 1.638743455497382,
        "end": 5254.9,
        "id": 1680,
        "no_speech_prob": 0.00003883108729496598,
        "seek": 523174,
        "start": 5251.74,
        "temperature": 0,
        "text": " and then set a vertex x comma y.",
        "tokens": [
          51364,
          293,
          550,
          992,
          257,
          28162,
          2031,
          22117,
          288,
          13,
          51522
        ]
      },
      {
        "avg_logprob": -0.19563369427697133,
        "compression_ratio": 1.638743455497382,
        "end": 5260.179999999999,
        "id": 1681,
        "no_speech_prob": 0.00003883108729496598,
        "seek": 523174,
        "start": 5254.9,
        "temperature": 0,
        "text": " So I can say begin shape, end shape.",
        "tokens": [
          51522,
          407,
          286,
          393,
          584,
          1841,
          3909,
          11,
          917,
          3909,
          13,
          51786
        ]
      },
      {
        "avg_logprob": -0.20012815475463866,
        "compression_ratio": 1.4773869346733668,
        "end": 5265.54,
        "id": 1682,
        "no_speech_prob": 0.00003883108729496598,
        "seek": 526018,
        "start": 5260.18,
        "temperature": 0,
        "text": " I can say no fill stroke 0.",
        "tokens": [
          50364,
          286,
          393,
          584,
          572,
          2836,
          12403,
          1958,
          13,
          50632
        ]
      },
      {
        "avg_logprob": -0.20012815475463866,
        "compression_ratio": 1.4773869346733668,
        "end": 5266.5,
        "id": 1683,
        "no_speech_prob": 0.00003883108729496598,
        "seek": 526018,
        "start": 5265.54,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          50632,
          45263,
          13,
          50680
        ]
      },
      {
        "avg_logprob": -0.20012815475463866,
        "compression_ratio": 1.4773869346733668,
        "end": 5267.38,
        "id": 1684,
        "no_speech_prob": 0.00003883108729496598,
        "seek": 526018,
        "start": 5266.5,
        "temperature": 0,
        "text": " Stroke 0.",
        "tokens": [
          50680,
          42196,
          330,
          1958,
          13,
          50724
        ]
      },
      {
        "avg_logprob": -0.20012815475463866,
        "compression_ratio": 1.4773869346733668,
        "end": 5271.9800000000005,
        "id": 1685,
        "no_speech_prob": 0.00003883108729496598,
        "seek": 526018,
        "start": 5267.38,
        "temperature": 0,
        "text": " And maybe I'll say stroke weight 3,",
        "tokens": [
          50724,
          400,
          1310,
          286,
          603,
          584,
          12403,
          3364,
          805,
          11,
          50954
        ]
      },
      {
        "avg_logprob": -0.20012815475463866,
        "compression_ratio": 1.4773869346733668,
        "end": 5274.14,
        "id": 1686,
        "no_speech_prob": 0.00003883108729496598,
        "seek": 526018,
        "start": 5271.9800000000005,
        "temperature": 0,
        "text": " just to make the lines a little bit thicker.",
        "tokens": [
          50954,
          445,
          281,
          652,
          264,
          3876,
          257,
          707,
          857,
          18142,
          13,
          51062
        ]
      },
      {
        "avg_logprob": -0.20012815475463866,
        "compression_ratio": 1.4773869346733668,
        "end": 5276.42,
        "id": 1687,
        "no_speech_prob": 0.00003883108729496598,
        "seek": 526018,
        "start": 5274.14,
        "temperature": 0,
        "text": " And let's see what I see.",
        "tokens": [
          51062,
          400,
          718,
          311,
          536,
          437,
          286,
          536,
          13,
          51176
        ]
      },
      {
        "avg_logprob": -0.20012815475463866,
        "compression_ratio": 1.4773869346733668,
        "end": 5277.820000000001,
        "id": 1688,
        "no_speech_prob": 0.00003883108729496598,
        "seek": 526018,
        "start": 5276.42,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51176,
          821,
          321,
          352,
          13,
          51246
        ]
      },
      {
        "avg_logprob": -0.20012815475463866,
        "compression_ratio": 1.4773869346733668,
        "end": 5278.740000000001,
        "id": 1689,
        "no_speech_prob": 0.00003883108729496598,
        "seek": 526018,
        "start": 5277.820000000001,
        "temperature": 0,
        "text": " Rainbows.",
        "tokens": [
          51246,
          14487,
          21118,
          13,
          51292
        ]
      },
      {
        "avg_logprob": -0.20012815475463866,
        "compression_ratio": 1.4773869346733668,
        "end": 5280.700000000001,
        "id": 1690,
        "no_speech_prob": 0.00003883108729496598,
        "seek": 526018,
        "start": 5278.740000000001,
        "temperature": 0,
        "text": " Rainbows galore.",
        "tokens": [
          51292,
          14487,
          21118,
          7660,
          418,
          13,
          51390
        ]
      },
      {
        "avg_logprob": -0.20012815475463866,
        "compression_ratio": 1.4773869346733668,
        "end": 5284.9400000000005,
        "id": 1691,
        "no_speech_prob": 0.00003883108729496598,
        "seek": 526018,
        "start": 5280.700000000001,
        "temperature": 0,
        "text": " These are everybody's rainbows each time I hit refresh.",
        "tokens": [
          51390,
          1981,
          366,
          2201,
          311,
          4830,
          21118,
          1184,
          565,
          286,
          2045,
          15134,
          13,
          51602
        ]
      },
      {
        "avg_logprob": -0.20012815475463866,
        "compression_ratio": 1.4773869346733668,
        "end": 5288.34,
        "id": 1692,
        "no_speech_prob": 0.00003883108729496598,
        "seek": 526018,
        "start": 5284.9400000000005,
        "temperature": 0,
        "text": " One thing I could do now is when it finishes,",
        "tokens": [
          51602,
          1485,
          551,
          286,
          727,
          360,
          586,
          307,
          562,
          309,
          23615,
          11,
          51772
        ]
      },
      {
        "avg_logprob": -0.2747640494840691,
        "compression_ratio": 1.52,
        "end": 5290.5,
        "id": 1693,
        "no_speech_prob": 0.000021782634576084092,
        "seek": 528834,
        "start": 5288.34,
        "temperature": 0,
        "text": " I could just say load JSON again.",
        "tokens": [
          50364,
          286,
          727,
          445,
          584,
          3677,
          31828,
          797,
          13,
          50472
        ]
      },
      {
        "avg_logprob": -0.2747640494840691,
        "compression_ratio": 1.52,
        "end": 5300.74,
        "id": 1694,
        "no_speech_prob": 0.000021782634576084092,
        "seek": 528834,
        "start": 5294.9800000000005,
        "temperature": 0,
        "text": " Maybe I would want to redraw the background every time.",
        "tokens": [
          50696,
          2704,
          286,
          576,
          528,
          281,
          2182,
          5131,
          264,
          3678,
          633,
          565,
          13,
          50984
        ]
      },
      {
        "avg_logprob": -0.2747640494840691,
        "compression_ratio": 1.52,
        "end": 5303.9800000000005,
        "id": 1695,
        "no_speech_prob": 0.000021782634576084092,
        "seek": 528834,
        "start": 5300.74,
        "temperature": 0,
        "text": " That might make sense.",
        "tokens": [
          50984,
          663,
          1062,
          652,
          2020,
          13,
          51146
        ]
      },
      {
        "avg_logprob": -0.2747640494840691,
        "compression_ratio": 1.52,
        "end": 5304.860000000001,
        "id": 1696,
        "no_speech_prob": 0.000021782634576084092,
        "seek": 528834,
        "start": 5303.9800000000005,
        "temperature": 0,
        "text": " And here we go.",
        "tokens": [
          51146,
          400,
          510,
          321,
          352,
          13,
          51190
        ]
      },
      {
        "avg_logprob": -0.2747640494840691,
        "compression_ratio": 1.52,
        "end": 5307.34,
        "id": 1697,
        "no_speech_prob": 0.000021782634576084092,
        "seek": 528834,
        "start": 5304.860000000001,
        "temperature": 0,
        "text": " This is a random drawing over and over and over again.",
        "tokens": [
          51190,
          639,
          307,
          257,
          4974,
          6316,
          670,
          293,
          670,
          293,
          670,
          797,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2747640494840691,
        "compression_ratio": 1.52,
        "end": 5310.42,
        "id": 1698,
        "no_speech_prob": 0.000021782634576084092,
        "seek": 528834,
        "start": 5307.34,
        "temperature": 0,
        "text": " So I could start to do things like request a specific drawing",
        "tokens": [
          51314,
          407,
          286,
          727,
          722,
          281,
          360,
          721,
          411,
          5308,
          257,
          2685,
          6316,
          51468
        ]
      },
      {
        "avg_logprob": -0.2747640494840691,
        "compression_ratio": 1.52,
        "end": 5312.02,
        "id": 1699,
        "no_speech_prob": 0.000021782634576084092,
        "seek": 528834,
        "start": 5310.42,
        "temperature": 0,
        "text": " from a certain country.",
        "tokens": [
          51468,
          490,
          257,
          1629,
          1941,
          13,
          51548
        ]
      },
      {
        "avg_logprob": -0.2747640494840691,
        "compression_ratio": 1.52,
        "end": 5316.78,
        "id": 1700,
        "no_speech_prob": 0.000021782634576084092,
        "seek": 528834,
        "start": 5312.02,
        "temperature": 0,
        "text": " I could download different models.",
        "tokens": [
          51548,
          286,
          727,
          5484,
          819,
          5245,
          13,
          51786
        ]
      },
      {
        "avg_logprob": -0.32024108757406977,
        "compression_ratio": 1.303030303030303,
        "end": 5318.82,
        "id": 1701,
        "no_speech_prob": 0.0002415661874692887,
        "seek": 531678,
        "start": 5316.78,
        "temperature": 0,
        "text": " Let me pause for a second and grab another model.",
        "tokens": [
          50364,
          961,
          385,
          10465,
          337,
          257,
          1150,
          293,
          4444,
          1071,
          2316,
          13,
          50466
        ]
      },
      {
        "avg_logprob": -0.32024108757406977,
        "compression_ratio": 1.303030303030303,
        "end": 5328.62,
        "id": 1702,
        "no_speech_prob": 0.0002415661874692887,
        "seek": 531678,
        "start": 5323.7,
        "temperature": 0,
        "text": " So let's get, what's a good one?",
        "tokens": [
          50710,
          407,
          718,
          311,
          483,
          11,
          437,
          311,
          257,
          665,
          472,
          30,
          50956
        ]
      },
      {
        "avg_logprob": -0.32024108757406977,
        "compression_ratio": 1.303030303030303,
        "end": 5339.0199999999995,
        "id": 1703,
        "no_speech_prob": 0.0002415661874692887,
        "seek": 531678,
        "start": 5337.0199999999995,
        "temperature": 0,
        "text": " Apple, asparagus, ax.",
        "tokens": [
          51376,
          6373,
          11,
          382,
          49537,
          11,
          6360,
          13,
          51476
        ]
      },
      {
        "avg_logprob": -0.32024108757406977,
        "compression_ratio": 1.303030303030303,
        "end": 5342.139999999999,
        "id": 1704,
        "no_speech_prob": 0.0002415661874692887,
        "seek": 531678,
        "start": 5339.0199999999995,
        "temperature": 0,
        "text": " I mean, cat is sort of like this typical one.",
        "tokens": [
          51476,
          286,
          914,
          11,
          3857,
          307,
          1333,
          295,
          411,
          341,
          7476,
          472,
          13,
          51632
        ]
      },
      {
        "avg_logprob": -0.32024108757406977,
        "compression_ratio": 1.303030303030303,
        "end": 5343.219999999999,
        "id": 1705,
        "no_speech_prob": 0.0002415661874692887,
        "seek": 531678,
        "start": 5342.139999999999,
        "temperature": 0,
        "text": " So let's just do cat.",
        "tokens": [
          51632,
          407,
          718,
          311,
          445,
          360,
          3857,
          13,
          51686
        ]
      },
      {
        "avg_logprob": -0.37668402441616716,
        "compression_ratio": 1.2440944881889764,
        "end": 5348.78,
        "id": 1706,
        "no_speech_prob": 0.00007843765342840925,
        "seek": 534678,
        "start": 5347.78,
        "temperature": 0,
        "text": " So many.",
        "tokens": [
          50414,
          407,
          867,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.37668402441616716,
        "compression_ratio": 1.2440944881889764,
        "end": 5368.38,
        "id": 1707,
        "no_speech_prob": 0.00007843765342840925,
        "seek": 534678,
        "start": 5365.78,
        "temperature": 0,
        "text": " All right, I downloaded the cat file now.",
        "tokens": [
          51314,
          1057,
          558,
          11,
          286,
          21748,
          264,
          3857,
          3991,
          586,
          13,
          51444
        ]
      },
      {
        "avg_logprob": -0.37668402441616716,
        "compression_ratio": 1.2440944881889764,
        "end": 5370.78,
        "id": 1708,
        "no_speech_prob": 0.00007843765342840925,
        "seek": 534678,
        "start": 5368.38,
        "temperature": 0,
        "text": " And I'm just going to put that in here as well.",
        "tokens": [
          51444,
          400,
          286,
          478,
          445,
          516,
          281,
          829,
          300,
          294,
          510,
          382,
          731,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.37668402441616716,
        "compression_ratio": 1.2440944881889764,
        "end": 5371.74,
        "id": 1709,
        "no_speech_prob": 0.00007843765342840925,
        "seek": 534678,
        "start": 5370.78,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          51564,
          45263,
          13,
          51612
        ]
      },
      {
        "avg_logprob": -0.37668402441616716,
        "compression_ratio": 1.2440944881889764,
        "end": 5373.219999999999,
        "id": 1710,
        "no_speech_prob": 0.00007843765342840925,
        "seek": 534678,
        "start": 5371.74,
        "temperature": 0,
        "text": " Did I put that somewhere weird?",
        "tokens": [
          51612,
          2589,
          286,
          829,
          300,
          4079,
          3657,
          30,
          51686
        ]
      },
      {
        "avg_logprob": -0.37668402441616716,
        "compression_ratio": 1.2440944881889764,
        "end": 5375.42,
        "id": 1711,
        "no_speech_prob": 0.00007843765342840925,
        "seek": 534678,
        "start": 5373.219999999999,
        "temperature": 0,
        "text": " No, I'm, ah, sorry.",
        "tokens": [
          51686,
          883,
          11,
          286,
          478,
          11,
          3716,
          11,
          2597,
          13,
          51796
        ]
      },
      {
        "avg_logprob": -0.6329430972828585,
        "compression_ratio": 1.0129870129870129,
        "end": 5376.34,
        "id": 1712,
        "no_speech_prob": 0.0003682698297780007,
        "seek": 537542,
        "start": 5375.42,
        "temperature": 0,
        "text": " Let me do that again.",
        "tokens": [
          50364,
          961,
          385,
          360,
          300,
          797,
          13,
          50410
        ]
      },
      {
        "avg_logprob": -0.6329430972828585,
        "compression_ratio": 1.0129870129870129,
        "end": 5382.62,
        "id": 1713,
        "no_speech_prob": 0.0003682698297780007,
        "seek": 537542,
        "start": 5379.62,
        "temperature": 0,
        "text": " Delete.",
        "tokens": [
          50574,
          49452,
          13,
          50724
        ]
      },
      {
        "avg_logprob": -0.6329430972828585,
        "compression_ratio": 1.0129870129870129,
        "end": 5384.06,
        "id": 1714,
        "no_speech_prob": 0.0003682698297780007,
        "seek": 537542,
        "start": 5382.62,
        "temperature": 0,
        "text": " Ah, shoot.",
        "tokens": [
          50724,
          2438,
          11,
          3076,
          13,
          50796
        ]
      },
      {
        "avg_logprob": -0.6329430972828585,
        "compression_ratio": 1.0129870129870129,
        "end": 5396.9400000000005,
        "id": 1715,
        "no_speech_prob": 0.0003682698297780007,
        "seek": 537542,
        "start": 5394.9400000000005,
        "temperature": 0,
        "text": " Hold on, sorry everybody.",
        "tokens": [
          51340,
          6962,
          322,
          11,
          2597,
          2201,
          13,
          51440
        ]
      },
      {
        "avg_logprob": -0.6329430972828585,
        "compression_ratio": 1.0129870129870129,
        "end": 5397.46,
        "id": 1716,
        "no_speech_prob": 0.0003682698297780007,
        "seek": 537542,
        "start": 5396.9400000000005,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          51440,
          1692,
          321,
          352,
          13,
          51466
        ]
      },
      {
        "avg_logprob": -0.4709435729980469,
        "compression_ratio": 1.9322916666666667,
        "end": 5402.86,
        "id": 1717,
        "no_speech_prob": 0.00007484592060791329,
        "seek": 539746,
        "start": 5398.46,
        "temperature": 0,
        "text": " OK, so I downloaded one more set of drawings, the cat files.",
        "tokens": [
          50414,
          2264,
          11,
          370,
          286,
          21748,
          472,
          544,
          992,
          295,
          18618,
          11,
          264,
          3857,
          7098,
          13,
          50634
        ]
      },
      {
        "avg_logprob": -0.4709435729980469,
        "compression_ratio": 1.9322916666666667,
        "end": 5404.26,
        "id": 1718,
        "no_speech_prob": 0.00007484592060791329,
        "seek": 539746,
        "start": 5402.86,
        "temperature": 0,
        "text": " So I'm going to, the cat drawings,",
        "tokens": [
          50634,
          407,
          286,
          478,
          516,
          281,
          11,
          264,
          3857,
          18618,
          11,
          50704
        ]
      },
      {
        "avg_logprob": -0.4709435729980469,
        "compression_ratio": 1.9322916666666667,
        "end": 5406.74,
        "id": 1719,
        "no_speech_prob": 0.00007484592060791329,
        "seek": 539746,
        "start": 5404.26,
        "temperature": 0,
        "text": " I'm going to copy that into here.",
        "tokens": [
          50704,
          286,
          478,
          516,
          281,
          5055,
          300,
          666,
          510,
          13,
          50828
        ]
      },
      {
        "avg_logprob": -0.4709435729980469,
        "compression_ratio": 1.9322916666666667,
        "end": 5409.1,
        "id": 1720,
        "no_speech_prob": 0.00007484592060791329,
        "seek": 539746,
        "start": 5406.74,
        "temperature": 0,
        "text": " And we can see now I have cat nd JSON.",
        "tokens": [
          50828,
          400,
          321,
          393,
          536,
          586,
          286,
          362,
          3857,
          220,
          273,
          31828,
          13,
          50946
        ]
      },
      {
        "avg_logprob": -0.4709435729980469,
        "compression_ratio": 1.9322916666666667,
        "end": 5413.86,
        "id": 1721,
        "no_speech_prob": 0.00007484592060791329,
        "seek": 539746,
        "start": 5409.1,
        "temperature": 0,
        "text": " If I go back to my server, I could do, I'm going to say,",
        "tokens": [
          50946,
          759,
          286,
          352,
          646,
          281,
          452,
          7154,
          11,
          286,
          727,
          360,
          11,
          286,
          478,
          516,
          281,
          584,
          11,
          51184
        ]
      },
      {
        "avg_logprob": -0.4709435729980469,
        "compression_ratio": 1.9322916666666667,
        "end": 5416.42,
        "id": 1722,
        "no_speech_prob": 0.00007484592060791329,
        "seek": 539746,
        "start": 5413.86,
        "temperature": 0,
        "text": " I'm going to call this rainbows.",
        "tokens": [
          51184,
          286,
          478,
          516,
          281,
          818,
          341,
          4830,
          21118,
          13,
          51312
        ]
      },
      {
        "avg_logprob": -0.4709435729980469,
        "compression_ratio": 1.9322916666666667,
        "end": 5420.66,
        "id": 1723,
        "no_speech_prob": 0.00007484592060791329,
        "seek": 539746,
        "start": 5416.42,
        "temperature": 0,
        "text": " And I'm going to do a different one for cat.",
        "tokens": [
          51312,
          400,
          286,
          478,
          516,
          281,
          360,
          257,
          819,
          472,
          337,
          3857,
          13,
          51524
        ]
      },
      {
        "avg_logprob": -0.4709435729980469,
        "compression_ratio": 1.9322916666666667,
        "end": 5424.86,
        "id": 1724,
        "no_speech_prob": 0.00007484592060791329,
        "seek": 539746,
        "start": 5420.66,
        "temperature": 0,
        "text": " And I'm also going to, ah, I'm going to do a different one",
        "tokens": [
          51524,
          400,
          286,
          478,
          611,
          516,
          281,
          11,
          3716,
          11,
          286,
          478,
          516,
          281,
          360,
          257,
          819,
          472,
          51734
        ]
      },
      {
        "avg_logprob": -0.4709435729980469,
        "compression_ratio": 1.9322916666666667,
        "end": 5425.86,
        "id": 1725,
        "no_speech_prob": 0.00007484592060791329,
        "seek": 539746,
        "start": 5424.86,
        "temperature": 0,
        "text": " for cat.",
        "tokens": [
          51734,
          337,
          3857,
          13,
          51784
        ]
      },
      {
        "avg_logprob": -0.23981153048001802,
        "compression_ratio": 1.457142857142857,
        "end": 5431.66,
        "id": 1726,
        "no_speech_prob": 0.00008750213601160794,
        "seek": 542586,
        "start": 5425.94,
        "temperature": 0,
        "text": " And I'm also going to do cats, cats push object.",
        "tokens": [
          50368,
          400,
          286,
          478,
          611,
          516,
          281,
          360,
          11111,
          11,
          11111,
          2944,
          2657,
          13,
          50654
        ]
      },
      {
        "avg_logprob": -0.23981153048001802,
        "compression_ratio": 1.457142857142857,
        "end": 5438.179999999999,
        "id": 1727,
        "no_speech_prob": 0.00008750213601160794,
        "seek": 542586,
        "start": 5431.66,
        "temperature": 0,
        "text": " And then I'm going to make another route for cats.",
        "tokens": [
          50654,
          400,
          550,
          286,
          478,
          516,
          281,
          652,
          1071,
          7955,
          337,
          11111,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.23981153048001802,
        "compression_ratio": 1.457142857142857,
        "end": 5448.7,
        "id": 1728,
        "no_speech_prob": 0.00008750213601160794,
        "seek": 542586,
        "start": 5441.94,
        "temperature": 0,
        "text": " So now if I rerun the server, and I go back",
        "tokens": [
          51168,
          407,
          586,
          498,
          286,
          43819,
          409,
          264,
          7154,
          11,
          293,
          286,
          352,
          646,
          51506
        ]
      },
      {
        "avg_logprob": -0.23981153048001802,
        "compression_ratio": 1.457142857142857,
        "end": 5452.0599999999995,
        "id": 1729,
        "no_speech_prob": 0.00008750213601160794,
        "seek": 542586,
        "start": 5448.7,
        "temperature": 0,
        "text": " to my actual sketch, and I switch",
        "tokens": [
          51506,
          281,
          452,
          3539,
          12325,
          11,
          293,
          286,
          3679,
          51674
        ]
      },
      {
        "avg_logprob": -0.23981153048001802,
        "compression_ratio": 1.457142857142857,
        "end": 5455.099999999999,
        "id": 1730,
        "no_speech_prob": 0.00008750213601160794,
        "seek": 542586,
        "start": 5452.0599999999995,
        "temperature": 0,
        "text": " to going to the cat route.",
        "tokens": [
          51674,
          281,
          516,
          281,
          264,
          3857,
          7955,
          13,
          51826
        ]
      },
      {
        "avg_logprob": -0.2525357619575832,
        "compression_ratio": 1.543778801843318,
        "end": 5456.9400000000005,
        "id": 1731,
        "no_speech_prob": 0.000018058439309243113,
        "seek": 545510,
        "start": 5455.1,
        "temperature": 0,
        "text": " Now where was that?",
        "tokens": [
          50364,
          823,
          689,
          390,
          300,
          30,
          50456
        ]
      },
      {
        "avg_logprob": -0.2525357619575832,
        "compression_ratio": 1.543778801843318,
        "end": 5457.54,
        "id": 1732,
        "no_speech_prob": 0.000018058439309243113,
        "seek": 545510,
        "start": 5456.9400000000005,
        "temperature": 0,
        "text": " Here I am.",
        "tokens": [
          50456,
          1692,
          286,
          669,
          13,
          50486
        ]
      },
      {
        "avg_logprob": -0.2525357619575832,
        "compression_ratio": 1.543778801843318,
        "end": 5459.5,
        "id": 1733,
        "no_speech_prob": 0.000018058439309243113,
        "seek": 545510,
        "start": 5457.54,
        "temperature": 0,
        "text": " I'm going to hit Enter.",
        "tokens": [
          50486,
          286,
          478,
          516,
          281,
          2045,
          10399,
          13,
          50584
        ]
      },
      {
        "avg_logprob": -0.2525357619575832,
        "compression_ratio": 1.543778801843318,
        "end": 5461.620000000001,
        "id": 1734,
        "no_speech_prob": 0.000018058439309243113,
        "seek": 545510,
        "start": 5459.5,
        "temperature": 0,
        "text": " Ooh, I got some issue.",
        "tokens": [
          50584,
          7951,
          11,
          286,
          658,
          512,
          2734,
          13,
          50690
        ]
      },
      {
        "avg_logprob": -0.2525357619575832,
        "compression_ratio": 1.543778801843318,
        "end": 5463.660000000001,
        "id": 1735,
        "no_speech_prob": 0.000018058439309243113,
        "seek": 545510,
        "start": 5461.620000000001,
        "temperature": 0,
        "text": " Cat internal server error.",
        "tokens": [
          50690,
          9565,
          6920,
          7154,
          6713,
          13,
          50792
        ]
      },
      {
        "avg_logprob": -0.2525357619575832,
        "compression_ratio": 1.543778801843318,
        "end": 5466.820000000001,
        "id": 1736,
        "no_speech_prob": 0.000018058439309243113,
        "seek": 545510,
        "start": 5463.660000000001,
        "temperature": 0,
        "text": " So what's going on here?",
        "tokens": [
          50792,
          407,
          437,
          311,
          516,
          322,
          510,
          30,
          50950
        ]
      },
      {
        "avg_logprob": -0.2525357619575832,
        "compression_ratio": 1.543778801843318,
        "end": 5468.780000000001,
        "id": 1737,
        "no_speech_prob": 0.000018058439309243113,
        "seek": 545510,
        "start": 5466.820000000001,
        "temperature": 0,
        "text": " Drawings is not defined.",
        "tokens": [
          50950,
          20386,
          1109,
          307,
          406,
          7642,
          13,
          51048
        ]
      },
      {
        "avg_logprob": -0.2525357619575832,
        "compression_ratio": 1.543778801843318,
        "end": 5471.58,
        "id": 1738,
        "no_speech_prob": 0.000018058439309243113,
        "seek": 545510,
        "start": 5468.780000000001,
        "temperature": 0,
        "text": " So I made a mistake in my server.",
        "tokens": [
          51048,
          407,
          286,
          1027,
          257,
          6146,
          294,
          452,
          7154,
          13,
          51188
        ]
      },
      {
        "avg_logprob": -0.2525357619575832,
        "compression_ratio": 1.543778801843318,
        "end": 5476.54,
        "id": 1739,
        "no_speech_prob": 0.000018058439309243113,
        "seek": 545510,
        "start": 5471.58,
        "temperature": 0,
        "text": " Oh, this is, over here is rainbows.length.",
        "tokens": [
          51188,
          876,
          11,
          341,
          307,
          11,
          670,
          510,
          307,
          4830,
          21118,
          13,
          45390,
          13,
          51436
        ]
      },
      {
        "avg_logprob": -0.2525357619575832,
        "compression_ratio": 1.543778801843318,
        "end": 5479.46,
        "id": 1740,
        "no_speech_prob": 0.000018058439309243113,
        "seek": 545510,
        "start": 5476.54,
        "temperature": 0,
        "text": " And this is cats.length.",
        "tokens": [
          51436,
          400,
          341,
          307,
          11111,
          13,
          45390,
          13,
          51582
        ]
      },
      {
        "avg_logprob": -0.2525357619575832,
        "compression_ratio": 1.543778801843318,
        "end": 5480.9800000000005,
        "id": 1741,
        "no_speech_prob": 0.000018058439309243113,
        "seek": 545510,
        "start": 5479.46,
        "temperature": 0,
        "text": " And I would have seen that error here",
        "tokens": [
          51582,
          400,
          286,
          576,
          362,
          1612,
          300,
          6713,
          510,
          51658
        ]
      },
      {
        "avg_logprob": -0.2525357619575832,
        "compression_ratio": 1.543778801843318,
        "end": 5483.38,
        "id": 1742,
        "no_speech_prob": 0.000018058439309243113,
        "seek": 545510,
        "start": 5480.9800000000005,
        "temperature": 0,
        "text": " if I was paying closer attention.",
        "tokens": [
          51658,
          498,
          286,
          390,
          6229,
          4966,
          3202,
          13,
          51778
        ]
      },
      {
        "avg_logprob": -0.2525357619575832,
        "compression_ratio": 1.543778801843318,
        "end": 5483.860000000001,
        "id": 1743,
        "no_speech_prob": 0.000018058439309243113,
        "seek": 545510,
        "start": 5483.38,
        "temperature": 0,
        "text": " There.",
        "tokens": [
          51778,
          821,
          13,
          51802
        ]
      },
      {
        "avg_logprob": -0.30483005956276177,
        "compression_ratio": 1.4715909090909092,
        "end": 5485.86,
        "id": 1744,
        "no_speech_prob": 0.0014103443827480078,
        "seek": 548386,
        "start": 5483.9,
        "temperature": 0,
        "text": " I've got cats.",
        "tokens": [
          50366,
          286,
          600,
          658,
          11111,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.30483005956276177,
        "compression_ratio": 1.4715909090909092,
        "end": 5489.98,
        "id": 1745,
        "no_speech_prob": 0.0014103443827480078,
        "seek": 548386,
        "start": 5485.86,
        "temperature": 0,
        "text": " And now let's look at a lot of cats.",
        "tokens": [
          50464,
          400,
          586,
          718,
          311,
          574,
          412,
          257,
          688,
          295,
          11111,
          13,
          50670
        ]
      },
      {
        "avg_logprob": -0.30483005956276177,
        "compression_ratio": 1.4715909090909092,
        "end": 5491.82,
        "id": 1746,
        "no_speech_prob": 0.0014103443827480078,
        "seek": 548386,
        "start": 5489.98,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          50670,
          876,
          13,
          50762
        ]
      },
      {
        "avg_logprob": -0.30483005956276177,
        "compression_ratio": 1.4715909090909092,
        "end": 5494.219999999999,
        "id": 1747,
        "no_speech_prob": 0.0014103443827480078,
        "seek": 548386,
        "start": 5491.82,
        "temperature": 0,
        "text": " Oh, it's still giving me rainbows.",
        "tokens": [
          50762,
          876,
          11,
          309,
          311,
          920,
          2902,
          385,
          4830,
          21118,
          13,
          50882
        ]
      },
      {
        "avg_logprob": -0.30483005956276177,
        "compression_ratio": 1.4715909090909092,
        "end": 5497.259999999999,
        "id": 1748,
        "no_speech_prob": 0.0014103443827480078,
        "seek": 548386,
        "start": 5494.219999999999,
        "temperature": 0,
        "text": " Did I not hit Save?",
        "tokens": [
          50882,
          2589,
          286,
          406,
          2045,
          15541,
          30,
          51034
        ]
      },
      {
        "avg_logprob": -0.30483005956276177,
        "compression_ratio": 1.4715909090909092,
        "end": 5499.82,
        "id": 1749,
        "no_speech_prob": 0.0014103443827480078,
        "seek": 548386,
        "start": 5497.259999999999,
        "temperature": 0,
        "text": " Load JSON cat.",
        "tokens": [
          51034,
          48408,
          31828,
          3857,
          13,
          51162
        ]
      },
      {
        "avg_logprob": -0.30483005956276177,
        "compression_ratio": 1.4715909090909092,
        "end": 5501.38,
        "id": 1750,
        "no_speech_prob": 0.0014103443827480078,
        "seek": 548386,
        "start": 5499.82,
        "temperature": 0,
        "text": " Oh, load JSON cat.",
        "tokens": [
          51162,
          876,
          11,
          3677,
          31828,
          3857,
          13,
          51240
        ]
      },
      {
        "avg_logprob": -0.30483005956276177,
        "compression_ratio": 1.4715909090909092,
        "end": 5504.66,
        "id": 1751,
        "no_speech_prob": 0.0014103443827480078,
        "seek": 548386,
        "start": 5501.38,
        "temperature": 0,
        "text": " Whatever, I'm not being too thoughtful about this.",
        "tokens": [
          51240,
          8541,
          11,
          286,
          478,
          406,
          885,
          886,
          21566,
          466,
          341,
          13,
          51404
        ]
      },
      {
        "avg_logprob": -0.30483005956276177,
        "compression_ratio": 1.4715909090909092,
        "end": 5505.74,
        "id": 1752,
        "no_speech_prob": 0.0014103443827480078,
        "seek": 548386,
        "start": 5504.66,
        "temperature": 0,
        "text": " Give me the cats.",
        "tokens": [
          51404,
          5303,
          385,
          264,
          11111,
          13,
          51458
        ]
      },
      {
        "avg_logprob": -0.30483005956276177,
        "compression_ratio": 1.4715909090909092,
        "end": 5508.9,
        "id": 1753,
        "no_speech_prob": 0.0014103443827480078,
        "seek": 548386,
        "start": 5505.74,
        "temperature": 0,
        "text": " I want to see the meow meow.",
        "tokens": [
          51458,
          286,
          528,
          281,
          536,
          264,
          45132,
          45132,
          13,
          51616
        ]
      },
      {
        "avg_logprob": -0.30483005956276177,
        "compression_ratio": 1.4715909090909092,
        "end": 5512.0599999999995,
        "id": 1754,
        "no_speech_prob": 0.0014103443827480078,
        "seek": 548386,
        "start": 5508.9,
        "temperature": 0,
        "text": " What's going on?",
        "tokens": [
          51616,
          708,
          311,
          516,
          322,
          30,
          51774
        ]
      },
      {
        "avg_logprob": -0.3450973395145301,
        "compression_ratio": 1.295774647887324,
        "end": 5513.22,
        "id": 1755,
        "no_speech_prob": 0.0015011769719421864,
        "seek": 551206,
        "start": 5512.06,
        "temperature": 0,
        "text": " Run the server again.",
        "tokens": [
          50364,
          8950,
          264,
          7154,
          797,
          13,
          50422
        ]
      },
      {
        "avg_logprob": -0.3450973395145301,
        "compression_ratio": 1.295774647887324,
        "end": 5521.700000000001,
        "id": 1756,
        "no_speech_prob": 0.0015011769719421864,
        "seek": 551206,
        "start": 5519.38,
        "temperature": 0,
        "text": " Let me refresh this page.",
        "tokens": [
          50730,
          961,
          385,
          15134,
          341,
          3028,
          13,
          50846
        ]
      },
      {
        "avg_logprob": -0.3450973395145301,
        "compression_ratio": 1.295774647887324,
        "end": 5524.34,
        "id": 1757,
        "no_speech_prob": 0.0015011769719421864,
        "seek": 551206,
        "start": 5521.700000000001,
        "temperature": 0,
        "text": " It's still rainbows.",
        "tokens": [
          50846,
          467,
          311,
          920,
          4830,
          21118,
          13,
          50978
        ]
      },
      {
        "avg_logprob": -0.3450973395145301,
        "compression_ratio": 1.295774647887324,
        "end": 5527.9400000000005,
        "id": 1758,
        "no_speech_prob": 0.0015011769719421864,
        "seek": 551206,
        "start": 5524.34,
        "temperature": 0,
        "text": " Cat, cat, got rainbow.",
        "tokens": [
          50978,
          9565,
          11,
          3857,
          11,
          658,
          18526,
          13,
          51158
        ]
      },
      {
        "avg_logprob": -0.3450973395145301,
        "compression_ratio": 1.295774647887324,
        "end": 5530.22,
        "id": 1759,
        "no_speech_prob": 0.0015011769719421864,
        "seek": 551206,
        "start": 5527.9400000000005,
        "temperature": 0,
        "text": " Somewhere I messed this up.",
        "tokens": [
          51158,
          34500,
          286,
          16507,
          341,
          493,
          13,
          51272
        ]
      },
      {
        "avg_logprob": -0.3450973395145301,
        "compression_ratio": 1.295774647887324,
        "end": 5532.780000000001,
        "id": 1760,
        "no_speech_prob": 0.0015011769719421864,
        "seek": 551206,
        "start": 5530.22,
        "temperature": 0,
        "text": " Cat, cats.",
        "tokens": [
          51272,
          9565,
          11,
          11111,
          13,
          51400
        ]
      },
      {
        "avg_logprob": -0.3450973395145301,
        "compression_ratio": 1.295774647887324,
        "end": 5533.280000000001,
        "id": 1761,
        "no_speech_prob": 0.0015011769719421864,
        "seek": 551206,
        "start": 5532.780000000001,
        "temperature": 0,
        "text": " Ah!",
        "tokens": [
          51400,
          2438,
          0,
          51425
        ]
      },
      {
        "avg_logprob": -0.3450973395145301,
        "compression_ratio": 1.295774647887324,
        "end": 5538.9800000000005,
        "id": 1762,
        "no_speech_prob": 0.0015011769719421864,
        "seek": 551206,
        "start": 5536.740000000001,
        "temperature": 0,
        "text": " This is what I get for trying to code so quickly.",
        "tokens": [
          51598,
          639,
          307,
          437,
          286,
          483,
          337,
          1382,
          281,
          3089,
          370,
          2661,
          13,
          51710
        ]
      },
      {
        "avg_logprob": -0.2547975308967359,
        "compression_ratio": 1.6431535269709543,
        "end": 5542.9,
        "id": 1763,
        "no_speech_prob": 0.0000022603226170758717,
        "seek": 553898,
        "start": 5538.98,
        "temperature": 0,
        "text": " This is supposed to say cat.json.",
        "tokens": [
          50364,
          639,
          307,
          3442,
          281,
          584,
          3857,
          13,
          73,
          3015,
          13,
          50560
        ]
      },
      {
        "avg_logprob": -0.2547975308967359,
        "compression_ratio": 1.6431535269709543,
        "end": 5544.219999999999,
        "id": 1764,
        "no_speech_prob": 0.0000022603226170758717,
        "seek": 553898,
        "start": 5542.9,
        "temperature": 0,
        "text": " Cat.ndjson.",
        "tokens": [
          50560,
          9565,
          13,
          273,
          73,
          3015,
          13,
          50626
        ]
      },
      {
        "avg_logprob": -0.2547975308967359,
        "compression_ratio": 1.6431535269709543,
        "end": 5546.82,
        "id": 1765,
        "no_speech_prob": 0.0000022603226170758717,
        "seek": 553898,
        "start": 5544.219999999999,
        "temperature": 0,
        "text": " Now here we go.",
        "tokens": [
          50626,
          823,
          510,
          321,
          352,
          13,
          50756
        ]
      },
      {
        "avg_logprob": -0.2547975308967359,
        "compression_ratio": 1.6431535269709543,
        "end": 5549.86,
        "id": 1766,
        "no_speech_prob": 0.0000022603226170758717,
        "seek": 553898,
        "start": 5546.82,
        "temperature": 0,
        "text": " Oh, I have to restart the server.",
        "tokens": [
          50756,
          876,
          11,
          286,
          362,
          281,
          21022,
          264,
          7154,
          13,
          50908
        ]
      },
      {
        "avg_logprob": -0.2547975308967359,
        "compression_ratio": 1.6431535269709543,
        "end": 5551.78,
        "id": 1767,
        "no_speech_prob": 0.0000022603226170758717,
        "seek": 553898,
        "start": 5549.86,
        "temperature": 0,
        "text": " And here we go.",
        "tokens": [
          50908,
          400,
          510,
          321,
          352,
          13,
          51004
        ]
      },
      {
        "avg_logprob": -0.2547975308967359,
        "compression_ratio": 1.6431535269709543,
        "end": 5553.0199999999995,
        "id": 1768,
        "no_speech_prob": 0.0000022603226170758717,
        "seek": 553898,
        "start": 5551.78,
        "temperature": 0,
        "text": " Finally, cats.",
        "tokens": [
          51004,
          6288,
          11,
          11111,
          13,
          51066
        ]
      },
      {
        "avg_logprob": -0.2547975308967359,
        "compression_ratio": 1.6431535269709543,
        "end": 5554.66,
        "id": 1769,
        "no_speech_prob": 0.0000022603226170758717,
        "seek": 553898,
        "start": 5553.0199999999995,
        "temperature": 0,
        "text": " There's a lot of different cat drawings.",
        "tokens": [
          51066,
          821,
          311,
          257,
          688,
          295,
          819,
          3857,
          18618,
          13,
          51148
        ]
      },
      {
        "avg_logprob": -0.2547975308967359,
        "compression_ratio": 1.6431535269709543,
        "end": 5556.459999999999,
        "id": 1770,
        "no_speech_prob": 0.0000022603226170758717,
        "seek": 553898,
        "start": 5554.66,
        "temperature": 0,
        "text": " I really should slow this down.",
        "tokens": [
          51148,
          286,
          534,
          820,
          2964,
          341,
          760,
          13,
          51238
        ]
      },
      {
        "avg_logprob": -0.2547975308967359,
        "compression_ratio": 1.6431535269709543,
        "end": 5558.0599999999995,
        "id": 1771,
        "no_speech_prob": 0.0000022603226170758717,
        "seek": 553898,
        "start": 5556.459999999999,
        "temperature": 0,
        "text": " Let me just slow this down a little bit.",
        "tokens": [
          51238,
          961,
          385,
          445,
          2964,
          341,
          760,
          257,
          707,
          857,
          13,
          51318
        ]
      },
      {
        "avg_logprob": -0.2547975308967359,
        "compression_ratio": 1.6431535269709543,
        "end": 5559.9,
        "id": 1772,
        "no_speech_prob": 0.0000022603226170758717,
        "seek": 553898,
        "start": 5558.0599999999995,
        "temperature": 0,
        "text": " Oh, here's what I want to do, actually.",
        "tokens": [
          51318,
          876,
          11,
          510,
          311,
          437,
          286,
          528,
          281,
          360,
          11,
          767,
          13,
          51410
        ]
      },
      {
        "avg_logprob": -0.2547975308967359,
        "compression_ratio": 1.6431535269709543,
        "end": 5561.54,
        "id": 1773,
        "no_speech_prob": 0.0000022603226170758717,
        "seek": 553898,
        "start": 5559.9,
        "temperature": 0,
        "text": " Oh, this video should really be over.",
        "tokens": [
          51410,
          876,
          11,
          341,
          960,
          820,
          534,
          312,
          670,
          13,
          51492
        ]
      },
      {
        "avg_logprob": -0.2547975308967359,
        "compression_ratio": 1.6431535269709543,
        "end": 5563.78,
        "id": 1774,
        "no_speech_prob": 0.0000022603226170758717,
        "seek": 553898,
        "start": 5561.54,
        "temperature": 0,
        "text": " But you've already watched this much.",
        "tokens": [
          51492,
          583,
          291,
          600,
          1217,
          6337,
          341,
          709,
          13,
          51604
        ]
      },
      {
        "avg_logprob": -0.2547975308967359,
        "compression_ratio": 1.6431535269709543,
        "end": 5566.379999999999,
        "id": 1775,
        "no_speech_prob": 0.0000022603226170758717,
        "seek": 553898,
        "start": 5563.78,
        "temperature": 0,
        "text": " You can watch a little bit more, right?",
        "tokens": [
          51604,
          509,
          393,
          1159,
          257,
          707,
          857,
          544,
          11,
          558,
          30,
          51734
        ]
      },
      {
        "avg_logprob": -0.20418459718877618,
        "compression_ratio": 1.544502617801047,
        "end": 5571.1,
        "id": 1776,
        "no_speech_prob": 0.00002546639007050544,
        "seek": 556638,
        "start": 5566.38,
        "temperature": 0,
        "text": " I really want to draw the drawing in sequence.",
        "tokens": [
          50364,
          286,
          534,
          528,
          281,
          2642,
          264,
          6316,
          294,
          8310,
          13,
          50600
        ]
      },
      {
        "avg_logprob": -0.20418459718877618,
        "compression_ratio": 1.544502617801047,
        "end": 5574.34,
        "id": 1777,
        "no_speech_prob": 0.00002546639007050544,
        "seek": 556638,
        "start": 5571.1,
        "temperature": 0,
        "text": " Now I don't have the timing information.",
        "tokens": [
          50600,
          823,
          286,
          500,
          380,
          362,
          264,
          10822,
          1589,
          13,
          50762
        ]
      },
      {
        "avg_logprob": -0.20418459718877618,
        "compression_ratio": 1.544502617801047,
        "end": 5575.9400000000005,
        "id": 1778,
        "no_speech_prob": 0.00002546639007050544,
        "seek": 556638,
        "start": 5574.34,
        "temperature": 0,
        "text": " And that would be useful to have.",
        "tokens": [
          50762,
          400,
          300,
          576,
          312,
          4420,
          281,
          362,
          13,
          50842
        ]
      },
      {
        "avg_logprob": -0.20418459718877618,
        "compression_ratio": 1.544502617801047,
        "end": 5578.46,
        "id": 1779,
        "no_speech_prob": 0.00002546639007050544,
        "seek": 556638,
        "start": 5575.9400000000005,
        "temperature": 0,
        "text": " But let's make it actually animate.",
        "tokens": [
          50842,
          583,
          718,
          311,
          652,
          309,
          767,
          36439,
          13,
          50968
        ]
      },
      {
        "avg_logprob": -0.20418459718877618,
        "compression_ratio": 1.544502617801047,
        "end": 5580.82,
        "id": 1780,
        "no_speech_prob": 0.00002546639007050544,
        "seek": 556638,
        "start": 5578.46,
        "temperature": 0,
        "text": " So I'm going to add a draw function.",
        "tokens": [
          50968,
          407,
          286,
          478,
          516,
          281,
          909,
          257,
          2642,
          2445,
          13,
          51086
        ]
      },
      {
        "avg_logprob": -0.20418459718877618,
        "compression_ratio": 1.544502617801047,
        "end": 5586.82,
        "id": 1781,
        "no_speech_prob": 0.00002546639007050544,
        "seek": 556638,
        "start": 5584.46,
        "temperature": 0,
        "text": " I'm not going to add a page transition event.",
        "tokens": [
          51268,
          286,
          478,
          406,
          516,
          281,
          909,
          257,
          3028,
          6034,
          2280,
          13,
          51386
        ]
      },
      {
        "avg_logprob": -0.20418459718877618,
        "compression_ratio": 1.544502617801047,
        "end": 5592.02,
        "id": 1782,
        "no_speech_prob": 0.00002546639007050544,
        "seek": 556638,
        "start": 5586.82,
        "temperature": 0,
        "text": " And so when I've got a cat, and I'll just change this,",
        "tokens": [
          51386,
          400,
          370,
          562,
          286,
          600,
          658,
          257,
          3857,
          11,
          293,
          286,
          603,
          445,
          1319,
          341,
          11,
          51646
        ]
      },
      {
        "avg_logprob": -0.2679285670435706,
        "compression_ratio": 1.7162162162162162,
        "end": 5597.580000000001,
        "id": 1783,
        "no_speech_prob": 0.000004356872068456141,
        "seek": 559202,
        "start": 5592.02,
        "temperature": 0,
        "text": " what I'm actually going to do is just set current.",
        "tokens": [
          50364,
          437,
          286,
          478,
          767,
          516,
          281,
          360,
          307,
          445,
          992,
          2190,
          13,
          50642
        ]
      },
      {
        "avg_logprob": -0.2679285670435706,
        "compression_ratio": 1.7162162162162162,
        "end": 5602.38,
        "id": 1784,
        "no_speech_prob": 0.000004356872068456141,
        "seek": 559202,
        "start": 5600.18,
        "temperature": 0,
        "text": " I'm going to just say set cat equal to data.",
        "tokens": [
          50772,
          286,
          478,
          516,
          281,
          445,
          584,
          992,
          3857,
          2681,
          281,
          1412,
          13,
          50882
        ]
      },
      {
        "avg_logprob": -0.2679285670435706,
        "compression_ratio": 1.7162162162162162,
        "end": 5604.02,
        "id": 1785,
        "no_speech_prob": 0.000004356872068456141,
        "seek": 559202,
        "start": 5602.38,
        "temperature": 0,
        "text": " So I'm going to take out all of this.",
        "tokens": [
          50882,
          407,
          286,
          478,
          516,
          281,
          747,
          484,
          439,
          295,
          341,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2679285670435706,
        "compression_ratio": 1.7162162162162162,
        "end": 5607.700000000001,
        "id": 1786,
        "no_speech_prob": 0.000004356872068456141,
        "seek": 559202,
        "start": 5604.02,
        "temperature": 0,
        "text": " Cat equal to data.drawing.",
        "tokens": [
          50964,
          9565,
          2681,
          281,
          1412,
          13,
          48848,
          278,
          13,
          51148
        ]
      },
      {
        "avg_logprob": -0.2679285670435706,
        "compression_ratio": 1.7162162162162162,
        "end": 5611.3,
        "id": 1787,
        "no_speech_prob": 0.000004356872068456141,
        "seek": 559202,
        "start": 5607.700000000001,
        "temperature": 0,
        "text": " So I'm going to comment this out.",
        "tokens": [
          51148,
          407,
          286,
          478,
          516,
          281,
          2871,
          341,
          484,
          13,
          51328
        ]
      },
      {
        "avg_logprob": -0.2679285670435706,
        "compression_ratio": 1.7162162162162162,
        "end": 5613.18,
        "id": 1788,
        "no_speech_prob": 0.000004356872068456141,
        "seek": 559202,
        "start": 5611.3,
        "temperature": 0,
        "text": " Let's think about this.",
        "tokens": [
          51328,
          961,
          311,
          519,
          466,
          341,
          13,
          51422
        ]
      },
      {
        "avg_logprob": -0.2679285670435706,
        "compression_ratio": 1.7162162162162162,
        "end": 5618.3,
        "id": 1789,
        "no_speech_prob": 0.000004356872068456141,
        "seek": 559202,
        "start": 5613.18,
        "temperature": 0,
        "text": " And then I'm going to say let x, y.",
        "tokens": [
          51422,
          400,
          550,
          286,
          478,
          516,
          281,
          584,
          718,
          2031,
          11,
          288,
          13,
          51678
        ]
      },
      {
        "avg_logprob": -0.23717810232428055,
        "compression_ratio": 1.5822784810126582,
        "end": 5624.18,
        "id": 1790,
        "no_speech_prob": 0.0000019333563159307232,
        "seek": 561830,
        "start": 5618.3,
        "temperature": 0,
        "text": " And I'm going to say if cat, then I now",
        "tokens": [
          50364,
          400,
          286,
          478,
          516,
          281,
          584,
          498,
          3857,
          11,
          550,
          286,
          586,
          50658
        ]
      },
      {
        "avg_logprob": -0.23717810232428055,
        "compression_ratio": 1.5822784810126582,
        "end": 5626.820000000001,
        "id": 1791,
        "no_speech_prob": 0.0000019333563159307232,
        "seek": 561830,
        "start": 5624.18,
        "temperature": 0,
        "text": " need to keep track of where I am.",
        "tokens": [
          50658,
          643,
          281,
          1066,
          2837,
          295,
          689,
          286,
          669,
          13,
          50790
        ]
      },
      {
        "avg_logprob": -0.23717810232428055,
        "compression_ratio": 1.5822784810126582,
        "end": 5631.78,
        "id": 1792,
        "no_speech_prob": 0.0000019333563159307232,
        "seek": 561830,
        "start": 5626.820000000001,
        "temperature": 0,
        "text": " Let stroke index equal 0.",
        "tokens": [
          50790,
          961,
          12403,
          8186,
          2681,
          1958,
          13,
          51038
        ]
      },
      {
        "avg_logprob": -0.23717810232428055,
        "compression_ratio": 1.5822784810126582,
        "end": 5637.1,
        "id": 1793,
        "no_speech_prob": 0.0000019333563159307232,
        "seek": 561830,
        "start": 5631.78,
        "temperature": 0,
        "text": " Let pen index equal 0.",
        "tokens": [
          51038,
          961,
          3435,
          8186,
          2681,
          1958,
          13,
          51304
        ]
      },
      {
        "avg_logprob": -0.23717810232428055,
        "compression_ratio": 1.5822784810126582,
        "end": 5639.38,
        "id": 1794,
        "no_speech_prob": 0.0000019333563159307232,
        "seek": 561830,
        "start": 5637.1,
        "temperature": 0,
        "text": " So I need to keep track of two indices, right?",
        "tokens": [
          51304,
          407,
          286,
          643,
          281,
          1066,
          2837,
          295,
          732,
          43840,
          11,
          558,
          30,
          51418
        ]
      },
      {
        "avg_logprob": -0.23717810232428055,
        "compression_ratio": 1.5822784810126582,
        "end": 5642.3,
        "id": 1795,
        "no_speech_prob": 0.0000019333563159307232,
        "seek": 561830,
        "start": 5639.38,
        "temperature": 0,
        "text": " Because I'm going to walk through one at a time",
        "tokens": [
          51418,
          1436,
          286,
          478,
          516,
          281,
          1792,
          807,
          472,
          412,
          257,
          565,
          51564
        ]
      },
      {
        "avg_logprob": -0.23717810232428055,
        "compression_ratio": 1.5822784810126582,
        "end": 5646.66,
        "id": 1796,
        "no_speech_prob": 0.0000019333563159307232,
        "seek": 561830,
        "start": 5642.3,
        "temperature": 0,
        "text": " each vector of the first stroke.",
        "tokens": [
          51564,
          1184,
          8062,
          295,
          264,
          700,
          12403,
          13,
          51782
        ]
      },
      {
        "avg_logprob": -0.25007657368977865,
        "compression_ratio": 1.4166666666666667,
        "end": 5648.42,
        "id": 1797,
        "no_speech_prob": 0.000014738977370143402,
        "seek": 564666,
        "start": 5646.66,
        "temperature": 0,
        "text": " And then stroke's going to go from 0 to 1",
        "tokens": [
          50364,
          400,
          550,
          12403,
          311,
          516,
          281,
          352,
          490,
          1958,
          281,
          502,
          50452
        ]
      },
      {
        "avg_logprob": -0.25007657368977865,
        "compression_ratio": 1.4166666666666667,
        "end": 5650.0199999999995,
        "id": 1798,
        "no_speech_prob": 0.000014738977370143402,
        "seek": 564666,
        "start": 5648.42,
        "temperature": 0,
        "text": " and go through each of the other ones.",
        "tokens": [
          50452,
          293,
          352,
          807,
          1184,
          295,
          264,
          661,
          2306,
          13,
          50532
        ]
      },
      {
        "avg_logprob": -0.25007657368977865,
        "compression_ratio": 1.4166666666666667,
        "end": 5657.98,
        "id": 1799,
        "no_speech_prob": 0.000014738977370143402,
        "seek": 564666,
        "start": 5650.0199999999995,
        "temperature": 0,
        "text": " So if there's a cat, the first thing I need to do is say,",
        "tokens": [
          50532,
          407,
          498,
          456,
          311,
          257,
          3857,
          11,
          264,
          700,
          551,
          286,
          643,
          281,
          360,
          307,
          584,
          11,
          50930
        ]
      },
      {
        "avg_logprob": -0.25007657368977865,
        "compression_ratio": 1.4166666666666667,
        "end": 5663.34,
        "id": 1800,
        "no_speech_prob": 0.000014738977370143402,
        "seek": 564666,
        "start": 5657.98,
        "temperature": 0,
        "text": " so if I'm going to say x equals, and what was this stuff?",
        "tokens": [
          50930,
          370,
          498,
          286,
          478,
          516,
          281,
          584,
          2031,
          6915,
          11,
          293,
          437,
          390,
          341,
          1507,
          30,
          51198
        ]
      },
      {
        "avg_logprob": -0.25007657368977865,
        "compression_ratio": 1.4166666666666667,
        "end": 5664.82,
        "id": 1801,
        "no_speech_prob": 0.000014738977370143402,
        "seek": 564666,
        "start": 5663.34,
        "temperature": 0,
        "text": " It is path.",
        "tokens": [
          51198,
          467,
          307,
          3100,
          13,
          51272
        ]
      },
      {
        "avg_logprob": -0.25007657368977865,
        "compression_ratio": 1.4166666666666667,
        "end": 5668.62,
        "id": 1802,
        "no_speech_prob": 0.000014738977370143402,
        "seek": 564666,
        "start": 5667.62,
        "temperature": 0,
        "text": " Oh, drawing.",
        "tokens": [
          51412,
          876,
          11,
          6316,
          13,
          51462
        ]
      },
      {
        "avg_logprob": -0.3162602769567611,
        "compression_ratio": 1.6218905472636815,
        "end": 5684.66,
        "id": 1803,
        "no_speech_prob": 0.000374095281586051,
        "seek": 566862,
        "start": 5668.62,
        "temperature": 0,
        "text": " So cat index stroke index index pen index, index 0.",
        "tokens": [
          50364,
          407,
          3857,
          8186,
          12403,
          8186,
          8186,
          3435,
          8186,
          11,
          8186,
          1958,
          13,
          51166
        ]
      },
      {
        "avg_logprob": -0.3162602769567611,
        "compression_ratio": 1.6218905472636815,
        "end": 5686.98,
        "id": 1804,
        "no_speech_prob": 0.000374095281586051,
        "seek": 566862,
        "start": 5684.66,
        "temperature": 0,
        "text": " Boy, this is really awkward about how it's using just",
        "tokens": [
          51166,
          9486,
          11,
          341,
          307,
          534,
          11411,
          466,
          577,
          309,
          311,
          1228,
          445,
          51282
        ]
      },
      {
        "avg_logprob": -0.3162602769567611,
        "compression_ratio": 1.6218905472636815,
        "end": 5688.0199999999995,
        "id": 1805,
        "no_speech_prob": 0.000374095281586051,
        "seek": 566862,
        "start": 5686.98,
        "temperature": 0,
        "text": " arrays for everything.",
        "tokens": [
          51282,
          41011,
          337,
          1203,
          13,
          51334
        ]
      },
      {
        "avg_logprob": -0.3162602769567611,
        "compression_ratio": 1.6218905472636815,
        "end": 5689.62,
        "id": 1806,
        "no_speech_prob": 0.000374095281586051,
        "seek": 566862,
        "start": 5688.0199999999995,
        "temperature": 0,
        "text": " But I'm in the first stroke.",
        "tokens": [
          51334,
          583,
          286,
          478,
          294,
          264,
          700,
          12403,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.3162602769567611,
        "compression_ratio": 1.6218905472636815,
        "end": 5691.36,
        "id": 1807,
        "no_speech_prob": 0.000374095281586051,
        "seek": 566862,
        "start": 5689.62,
        "temperature": 0,
        "text": " In the first pen is not the right term.",
        "tokens": [
          51414,
          682,
          264,
          700,
          3435,
          307,
          406,
          264,
          558,
          1433,
          13,
          51501
        ]
      },
      {
        "avg_logprob": -0.3162602769567611,
        "compression_ratio": 1.6218905472636815,
        "end": 5693.48,
        "id": 1808,
        "no_speech_prob": 0.000374095281586051,
        "seek": 566862,
        "start": 5691.36,
        "temperature": 0,
        "text": " I don't know what to call it, vertex, but whatever.",
        "tokens": [
          51501,
          286,
          500,
          380,
          458,
          437,
          281,
          818,
          309,
          11,
          28162,
          11,
          457,
          2035,
          13,
          51607
        ]
      },
      {
        "avg_logprob": -0.3162602769567611,
        "compression_ratio": 1.6218905472636815,
        "end": 5696.62,
        "id": 1809,
        "no_speech_prob": 0.000374095281586051,
        "seek": 566862,
        "start": 5693.48,
        "temperature": 0,
        "text": " I could actually just call this index maybe.",
        "tokens": [
          51607,
          286,
          727,
          767,
          445,
          818,
          341,
          8186,
          1310,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.3162602769567611,
        "compression_ratio": 1.6218905472636815,
        "end": 5697.94,
        "id": 1810,
        "no_speech_prob": 0.000374095281586051,
        "seek": 566862,
        "start": 5696.62,
        "temperature": 0,
        "text": " The stroke index and the index.",
        "tokens": [
          51764,
          440,
          12403,
          8186,
          293,
          264,
          8186,
          13,
          51830
        ]
      },
      {
        "avg_logprob": -0.26442393012668775,
        "compression_ratio": 1.5900621118012421,
        "end": 5700.9,
        "id": 1811,
        "no_speech_prob": 0.000009818320904741995,
        "seek": 569794,
        "start": 5697.94,
        "temperature": 0,
        "text": " 0 is for x.",
        "tokens": [
          50364,
          1958,
          307,
          337,
          2031,
          13,
          50512
        ]
      },
      {
        "avg_logprob": -0.26442393012668775,
        "compression_ratio": 1.5900621118012421,
        "end": 5703.74,
        "id": 1812,
        "no_speech_prob": 0.000009818320904741995,
        "seek": 569794,
        "start": 5700.9,
        "temperature": 0,
        "text": " And then 1 is for y.",
        "tokens": [
          50512,
          400,
          550,
          502,
          307,
          337,
          288,
          13,
          50654
        ]
      },
      {
        "avg_logprob": -0.26442393012668775,
        "compression_ratio": 1.5900621118012421,
        "end": 5706.099999999999,
        "id": 1813,
        "no_speech_prob": 0.000009818320904741995,
        "seek": 569794,
        "start": 5703.74,
        "temperature": 0,
        "text": " And let me just, just to see that this works,",
        "tokens": [
          50654,
          400,
          718,
          385,
          445,
          11,
          445,
          281,
          536,
          300,
          341,
          1985,
          11,
          50772
        ]
      },
      {
        "avg_logprob": -0.26442393012668775,
        "compression_ratio": 1.5900621118012421,
        "end": 5715.259999999999,
        "id": 1814,
        "no_speech_prob": 0.000009818320904741995,
        "seek": 569794,
        "start": 5706.099999999999,
        "temperature": 0,
        "text": " let me say point, let me say point x comma y.",
        "tokens": [
          50772,
          718,
          385,
          584,
          935,
          11,
          718,
          385,
          584,
          935,
          2031,
          22117,
          288,
          13,
          51230
        ]
      },
      {
        "avg_logprob": -0.26442393012668775,
        "compression_ratio": 1.5900621118012421,
        "end": 5716.7,
        "id": 1815,
        "no_speech_prob": 0.000009818320904741995,
        "seek": 569794,
        "start": 5715.259999999999,
        "temperature": 0,
        "text": " And these don't need to be global.",
        "tokens": [
          51230,
          400,
          613,
          500,
          380,
          643,
          281,
          312,
          4338,
          13,
          51302
        ]
      },
      {
        "avg_logprob": -0.26442393012668775,
        "compression_ratio": 1.5900621118012421,
        "end": 5720.62,
        "id": 1816,
        "no_speech_prob": 0.000009818320904741995,
        "seek": 569794,
        "start": 5719.339999999999,
        "temperature": 0,
        "text": " So let's see what this does.",
        "tokens": [
          51434,
          407,
          718,
          311,
          536,
          437,
          341,
          775,
          13,
          51498
        ]
      },
      {
        "avg_logprob": -0.26442393012668775,
        "compression_ratio": 1.5900621118012421,
        "end": 5724.58,
        "id": 1817,
        "no_speech_prob": 0.000009818320904741995,
        "seek": 569794,
        "start": 5720.62,
        "temperature": 0,
        "text": " And so first of all, let's just run this.",
        "tokens": [
          51498,
          400,
          370,
          700,
          295,
          439,
          11,
          718,
          311,
          445,
          1190,
          341,
          13,
          51696
        ]
      },
      {
        "avg_logprob": -0.26442393012668775,
        "compression_ratio": 1.5900621118012421,
        "end": 5725.9,
        "id": 1818,
        "no_speech_prob": 0.000009818320904741995,
        "seek": 569794,
        "start": 5724.58,
        "temperature": 0,
        "text": " Oh boy, I freaked it out.",
        "tokens": [
          51696,
          876,
          3237,
          11,
          286,
          37853,
          309,
          484,
          13,
          51762
        ]
      },
      {
        "avg_logprob": -0.2700342477536669,
        "compression_ratio": 1.419811320754717,
        "end": 5726.78,
        "id": 1819,
        "no_speech_prob": 0.000008801091098575853,
        "seek": 572590,
        "start": 5725.9,
        "temperature": 0,
        "text": " It won't ever stop.",
        "tokens": [
          50364,
          467,
          1582,
          380,
          1562,
          1590,
          13,
          50408
        ]
      },
      {
        "avg_logprob": -0.2700342477536669,
        "compression_ratio": 1.419811320754717,
        "end": 5733.0199999999995,
        "id": 1820,
        "no_speech_prob": 0.000008801091098575853,
        "seek": 572590,
        "start": 5731.339999999999,
        "temperature": 0,
        "text": " Well, I think, by the way, I killed this.",
        "tokens": [
          50636,
          1042,
          11,
          286,
          519,
          11,
          538,
          264,
          636,
          11,
          286,
          4652,
          341,
          13,
          50720
        ]
      },
      {
        "avg_logprob": -0.2700342477536669,
        "compression_ratio": 1.419811320754717,
        "end": 5736.299999999999,
        "id": 1821,
        "no_speech_prob": 0.000008801091098575853,
        "seek": 572590,
        "start": 5733.0199999999995,
        "temperature": 0,
        "text": " I need to build in a little more of a delay with these API calls.",
        "tokens": [
          50720,
          286,
          643,
          281,
          1322,
          294,
          257,
          707,
          544,
          295,
          257,
          8577,
          365,
          613,
          9362,
          5498,
          13,
          50884
        ]
      },
      {
        "avg_logprob": -0.2700342477536669,
        "compression_ratio": 1.419811320754717,
        "end": 5740.379999999999,
        "id": 1822,
        "no_speech_prob": 0.000008801091098575853,
        "seek": 572590,
        "start": 5736.299999999999,
        "temperature": 0,
        "text": " So cat is not defined, sketch.js line 12.",
        "tokens": [
          50884,
          407,
          3857,
          307,
          406,
          7642,
          11,
          12325,
          13,
          25530,
          1622,
          2272,
          13,
          51088
        ]
      },
      {
        "avg_logprob": -0.2700342477536669,
        "compression_ratio": 1.419811320754717,
        "end": 5742.139999999999,
        "id": 1823,
        "no_speech_prob": 0.000008801091098575853,
        "seek": 572590,
        "start": 5740.379999999999,
        "temperature": 0,
        "text": " If cat, that needs to be a global variable.",
        "tokens": [
          51088,
          759,
          3857,
          11,
          300,
          2203,
          281,
          312,
          257,
          4338,
          7006,
          13,
          51176
        ]
      },
      {
        "avg_logprob": -0.2700342477536669,
        "compression_ratio": 1.419811320754717,
        "end": 5751.78,
        "id": 1824,
        "no_speech_prob": 0.000008801091098575853,
        "seek": 572590,
        "start": 5746.5,
        "temperature": 0,
        "text": " And let me just say here console log x comma y.",
        "tokens": [
          51394,
          400,
          718,
          385,
          445,
          584,
          510,
          11076,
          3565,
          2031,
          22117,
          288,
          13,
          51658
        ]
      },
      {
        "avg_logprob": -0.2700342477536669,
        "compression_ratio": 1.419811320754717,
        "end": 5753.139999999999,
        "id": 1825,
        "no_speech_prob": 0.000008801091098575853,
        "seek": 572590,
        "start": 5751.78,
        "temperature": 0,
        "text": " Let's see, did I get an x comma y?",
        "tokens": [
          51658,
          961,
          311,
          536,
          11,
          630,
          286,
          483,
          364,
          2031,
          22117,
          288,
          30,
          51726
        ]
      },
      {
        "avg_logprob": -0.2700342477536669,
        "compression_ratio": 1.419811320754717,
        "end": 5753.66,
        "id": 1826,
        "no_speech_prob": 0.000008801091098575853,
        "seek": 572590,
        "start": 5753.139999999999,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          51726,
          1079,
          13,
          51752
        ]
      },
      {
        "avg_logprob": -0.22044840524362963,
        "compression_ratio": 1.5146198830409356,
        "end": 5756.18,
        "id": 1827,
        "no_speech_prob": 0.000045397813664749265,
        "seek": 575366,
        "start": 5753.66,
        "temperature": 0,
        "text": " So I've got that first point over and over again.",
        "tokens": [
          50364,
          407,
          286,
          600,
          658,
          300,
          700,
          935,
          670,
          293,
          670,
          797,
          13,
          50490
        ]
      },
      {
        "avg_logprob": -0.22044840524362963,
        "compression_ratio": 1.5146198830409356,
        "end": 5759.82,
        "id": 1828,
        "no_speech_prob": 0.000045397813664749265,
        "seek": 575366,
        "start": 5756.18,
        "temperature": 0,
        "text": " And presumably, 52 comma 48, I don't know why I don't see.",
        "tokens": [
          50490,
          400,
          26742,
          11,
          18079,
          22117,
          11174,
          11,
          286,
          500,
          380,
          458,
          983,
          286,
          500,
          380,
          536,
          13,
          50672
        ]
      },
      {
        "avg_logprob": -0.22044840524362963,
        "compression_ratio": 1.5146198830409356,
        "end": 5769.82,
        "id": 1829,
        "no_speech_prob": 0.000045397813664749265,
        "seek": 575366,
        "start": 5759.82,
        "temperature": 0,
        "text": " I guess I need to say stroke 0, stroke weight 3.",
        "tokens": [
          50672,
          286,
          2041,
          286,
          643,
          281,
          584,
          12403,
          1958,
          11,
          12403,
          3364,
          805,
          13,
          51172
        ]
      },
      {
        "avg_logprob": -0.22044840524362963,
        "compression_ratio": 1.5146198830409356,
        "end": 5770.34,
        "id": 1830,
        "no_speech_prob": 0.000045397813664749265,
        "seek": 575366,
        "start": 5769.82,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51172,
          821,
          321,
          352,
          13,
          51198
        ]
      },
      {
        "avg_logprob": -0.22044840524362963,
        "compression_ratio": 1.5146198830409356,
        "end": 5771.26,
        "id": 1831,
        "no_speech_prob": 0.000045397813664749265,
        "seek": 575366,
        "start": 5770.34,
        "temperature": 0,
        "text": " So there it is.",
        "tokens": [
          51198,
          407,
          456,
          309,
          307,
          13,
          51244
        ]
      },
      {
        "avg_logprob": -0.22044840524362963,
        "compression_ratio": 1.5146198830409356,
        "end": 5772.82,
        "id": 1832,
        "no_speech_prob": 0.000045397813664749265,
        "seek": 575366,
        "start": 5771.26,
        "temperature": 0,
        "text": " That's the first point.",
        "tokens": [
          51244,
          663,
          311,
          264,
          700,
          935,
          13,
          51322
        ]
      },
      {
        "avg_logprob": -0.22044840524362963,
        "compression_ratio": 1.5146198830409356,
        "end": 5778.9,
        "id": 1833,
        "no_speech_prob": 0.000045397813664749265,
        "seek": 575366,
        "start": 5772.82,
        "temperature": 0,
        "text": " So now what I need to do is say index plus plus.",
        "tokens": [
          51322,
          407,
          586,
          437,
          286,
          643,
          281,
          360,
          307,
          584,
          8186,
          1804,
          1804,
          13,
          51626
        ]
      },
      {
        "avg_logprob": -0.2982104117410225,
        "compression_ratio": 1.462686567164179,
        "end": 5787.299999999999,
        "id": 1834,
        "no_speech_prob": 0.000011300804544589482,
        "seek": 577890,
        "start": 5778.9,
        "temperature": 0,
        "text": " If index is greater than or equal to cat stroke index dot",
        "tokens": [
          50364,
          759,
          8186,
          307,
          5044,
          813,
          420,
          2681,
          281,
          3857,
          12403,
          8186,
          5893,
          50784
        ]
      },
      {
        "avg_logprob": -0.2982104117410225,
        "compression_ratio": 1.462686567164179,
        "end": 5796.62,
        "id": 1835,
        "no_speech_prob": 0.000011300804544589482,
        "seek": 577890,
        "start": 5787.299999999999,
        "temperature": 0,
        "text": " length, then stroke index plus plus and index equals 0.",
        "tokens": [
          50784,
          4641,
          11,
          550,
          12403,
          8186,
          1804,
          1804,
          293,
          8186,
          6915,
          1958,
          13,
          51250
        ]
      },
      {
        "avg_logprob": -0.2982104117410225,
        "compression_ratio": 1.462686567164179,
        "end": 5798.7,
        "id": 1836,
        "no_speech_prob": 0.000011300804544589482,
        "seek": 577890,
        "start": 5796.62,
        "temperature": 0,
        "text": " So this is me marching through them one at a time.",
        "tokens": [
          51250,
          407,
          341,
          307,
          385,
          30523,
          807,
          552,
          472,
          412,
          257,
          565,
          13,
          51354
        ]
      },
      {
        "avg_logprob": -0.2982104117410225,
        "compression_ratio": 1.462686567164179,
        "end": 5805.7,
        "id": 1837,
        "no_speech_prob": 0.000011300804544589482,
        "seek": 577890,
        "start": 5801.379999999999,
        "temperature": 0,
        "text": " So ooh, and I don't have the y.",
        "tokens": [
          51488,
          407,
          17024,
          11,
          293,
          286,
          500,
          380,
          362,
          264,
          288,
          13,
          51704
        ]
      },
      {
        "avg_logprob": -0.33009525221221303,
        "compression_ratio": 1.555,
        "end": 5809.62,
        "id": 1838,
        "no_speech_prob": 0.00005144209717400372,
        "seek": 580570,
        "start": 5805.9,
        "temperature": 0,
        "text": " You can see that something's wrong here.",
        "tokens": [
          50374,
          509,
          393,
          536,
          300,
          746,
          311,
          2085,
          510,
          13,
          50560
        ]
      },
      {
        "avg_logprob": -0.33009525221221303,
        "compression_ratio": 1.555,
        "end": 5812.5,
        "id": 1839,
        "no_speech_prob": 0.00005144209717400372,
        "seek": 580570,
        "start": 5809.62,
        "temperature": 0,
        "text": " I mean, this, let's see.",
        "tokens": [
          50560,
          286,
          914,
          11,
          341,
          11,
          718,
          311,
          536,
          13,
          50704
        ]
      },
      {
        "avg_logprob": -0.33009525221221303,
        "compression_ratio": 1.555,
        "end": 5816.22,
        "id": 1840,
        "no_speech_prob": 0.00005144209717400372,
        "seek": 580570,
        "start": 5812.5,
        "temperature": 0,
        "text": " Stroke index plus plus.",
        "tokens": [
          50704,
          42196,
          330,
          8186,
          1804,
          1804,
          13,
          50890
        ]
      },
      {
        "avg_logprob": -0.33009525221221303,
        "compression_ratio": 1.555,
        "end": 5817.34,
        "id": 1841,
        "no_speech_prob": 0.00005144209717400372,
        "seek": 580570,
        "start": 5816.22,
        "temperature": 0,
        "text": " I think this is right.",
        "tokens": [
          50890,
          286,
          519,
          341,
          307,
          558,
          13,
          50946
        ]
      },
      {
        "avg_logprob": -0.33009525221221303,
        "compression_ratio": 1.555,
        "end": 5825.9,
        "id": 1842,
        "no_speech_prob": 0.00005144209717400372,
        "seek": 580570,
        "start": 5822.0199999999995,
        "temperature": 0,
        "text": " Well, the point of this is what I actually want to do.",
        "tokens": [
          51180,
          1042,
          11,
          264,
          935,
          295,
          341,
          307,
          437,
          286,
          767,
          528,
          281,
          360,
          13,
          51374
        ]
      },
      {
        "avg_logprob": -0.33009525221221303,
        "compression_ratio": 1.555,
        "end": 5827.179999999999,
        "id": 1843,
        "no_speech_prob": 0.00005144209717400372,
        "seek": 580570,
        "start": 5825.9,
        "temperature": 0,
        "text": " So time out for a second.",
        "tokens": [
          51374,
          407,
          565,
          484,
          337,
          257,
          1150,
          13,
          51438
        ]
      },
      {
        "avg_logprob": -0.33009525221221303,
        "compression_ratio": 1.555,
        "end": 5828.26,
        "id": 1844,
        "no_speech_prob": 0.00005144209717400372,
        "seek": 580570,
        "start": 5827.179999999999,
        "temperature": 0,
        "text": " I forgot the variable.",
        "tokens": [
          51438,
          286,
          5298,
          264,
          7006,
          13,
          51492
        ]
      },
      {
        "avg_logprob": -0.33009525221221303,
        "compression_ratio": 1.555,
        "end": 5830.86,
        "id": 1845,
        "no_speech_prob": 0.00005144209717400372,
        "seek": 580570,
        "start": 5828.26,
        "temperature": 0,
        "text": " Well, that's probably an old comment from before.",
        "tokens": [
          51492,
          1042,
          11,
          300,
          311,
          1391,
          364,
          1331,
          2871,
          490,
          949,
          13,
          51622
        ]
      },
      {
        "avg_logprob": -0.33009525221221303,
        "compression_ratio": 1.555,
        "end": 5832.9,
        "id": 1846,
        "no_speech_prob": 0.00005144209717400372,
        "seek": 580570,
        "start": 5830.86,
        "temperature": 0,
        "text": " Hold on, I need a little break for a second.",
        "tokens": [
          51622,
          6962,
          322,
          11,
          286,
          643,
          257,
          707,
          1821,
          337,
          257,
          1150,
          13,
          51724
        ]
      },
      {
        "avg_logprob": -0.5764709200177874,
        "compression_ratio": 0.9649122807017544,
        "end": 5837.2,
        "id": 1847,
        "no_speech_prob": 0.002287214156240225,
        "seek": 583570,
        "start": 5836.7,
        "temperature": 0.2,
        "text": " OK.",
        "tokens": [
          50414,
          2264,
          13,
          50439
        ]
      },
      {
        "avg_logprob": -0.5764709200177874,
        "compression_ratio": 0.9649122807017544,
        "end": 5847.46,
        "id": 1848,
        "no_speech_prob": 0.002287214156240225,
        "seek": 583570,
        "start": 5844.9,
        "temperature": 0.2,
        "text": " Why did this not work?",
        "tokens": [
          50824,
          1545,
          630,
          341,
          406,
          589,
          30,
          50952
        ]
      },
      {
        "avg_logprob": -0.5764709200177874,
        "compression_ratio": 0.9649122807017544,
        "end": 5849.099999999999,
        "id": 1849,
        "no_speech_prob": 0.002287214156240225,
        "seek": 583570,
        "start": 5847.46,
        "temperature": 0.2,
        "text": " Something is off about this.",
        "tokens": [
          50952,
          6595,
          307,
          766,
          466,
          341,
          13,
          51034
        ]
      },
      {
        "avg_logprob": -0.36731894810994464,
        "compression_ratio": 1.5825242718446602,
        "end": 5869.82,
        "id": 1850,
        "no_speech_prob": 0.000007071888830978423,
        "seek": 586570,
        "start": 5866.7,
        "temperature": 0,
        "text": " Do I have these in the wrong order?",
        "tokens": [
          50414,
          1144,
          286,
          362,
          613,
          294,
          264,
          2085,
          1668,
          30,
          50570
        ]
      },
      {
        "avg_logprob": -0.36731894810994464,
        "compression_ratio": 1.5825242718446602,
        "end": 5875.48,
        "id": 1851,
        "no_speech_prob": 0.000007071888830978423,
        "seek": 586570,
        "start": 5874.98,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          50828,
          6962,
          322,
          13,
          50853
        ]
      },
      {
        "avg_logprob": -0.36731894810994464,
        "compression_ratio": 1.5825242718446602,
        "end": 5882.5,
        "id": 1852,
        "no_speech_prob": 0.000007071888830978423,
        "seek": 586570,
        "start": 5880.0599999999995,
        "temperature": 0,
        "text": " It's going 0, 0, 0, 1, 1, 0.",
        "tokens": [
          51082,
          467,
          311,
          516,
          1958,
          11,
          1958,
          11,
          1958,
          11,
          502,
          11,
          502,
          11,
          1958,
          13,
          51204
        ]
      },
      {
        "avg_logprob": -0.36731894810994464,
        "compression_ratio": 1.5825242718446602,
        "end": 5887.86,
        "id": 1853,
        "no_speech_prob": 0.000007071888830978423,
        "seek": 586570,
        "start": 5886.42,
        "temperature": 0,
        "text": " There were 17.",
        "tokens": [
          51400,
          821,
          645,
          3282,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -0.36731894810994464,
        "compression_ratio": 1.5825242718446602,
        "end": 5890.139999999999,
        "id": 1854,
        "no_speech_prob": 0.000007071888830978423,
        "seek": 586570,
        "start": 5887.86,
        "temperature": 0,
        "text": " Oh, no, no, no, no, no, no.",
        "tokens": [
          51472,
          876,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          13,
          51586
        ]
      },
      {
        "avg_logprob": -0.36731894810994464,
        "compression_ratio": 1.5825242718446602,
        "end": 5891.98,
        "id": 1855,
        "no_speech_prob": 0.000007071888830978423,
        "seek": 586570,
        "start": 5890.139999999999,
        "temperature": 0,
        "text": " I have these in the wrong order.",
        "tokens": [
          51586,
          286,
          362,
          613,
          294,
          264,
          2085,
          1668,
          13,
          51678
        ]
      },
      {
        "avg_logprob": -0.36731894810994464,
        "compression_ratio": 1.5825242718446602,
        "end": 5892.58,
        "id": 1856,
        "no_speech_prob": 0.000007071888830978423,
        "seek": 586570,
        "start": 5891.98,
        "temperature": 0,
        "text": " That's weird.",
        "tokens": [
          51678,
          663,
          311,
          3657,
          13,
          51708
        ]
      },
      {
        "avg_logprob": -0.4936492673812374,
        "compression_ratio": 1.0681818181818181,
        "end": 5902.66,
        "id": 1857,
        "no_speech_prob": 0.00012533724657259881,
        "seek": 589570,
        "start": 5895.7,
        "temperature": 0,
        "text": " Oh, I have these in the wrong order.",
        "tokens": [
          50364,
          876,
          11,
          286,
          362,
          613,
          294,
          264,
          2085,
          1668,
          13,
          50712
        ]
      },
      {
        "avg_logprob": -0.4936492673812374,
        "compression_ratio": 1.0681818181818181,
        "end": 5920.0199999999995,
        "id": 1858,
        "no_speech_prob": 0.00012533724657259881,
        "seek": 589570,
        "start": 5918.3,
        "temperature": 0,
        "text": " I think it should be 0 index.",
        "tokens": [
          51494,
          286,
          519,
          309,
          820,
          312,
          1958,
          8186,
          13,
          51580
        ]
      },
      {
        "avg_logprob": -0.4936492673812374,
        "compression_ratio": 1.0681818181818181,
        "end": 5924.46,
        "id": 1859,
        "no_speech_prob": 0.00012533724657259881,
        "seek": 589570,
        "start": 5923.0599999999995,
        "temperature": 0,
        "text": " It actually works this way?",
        "tokens": [
          51732,
          467,
          767,
          1985,
          341,
          636,
          30,
          51802
        ]
      },
      {
        "avg_logprob": -0.5938627123832703,
        "compression_ratio": 0.8260869565217391,
        "end": 5926.2,
        "id": 1860,
        "no_speech_prob": 0.01406159345060587,
        "seek": 592570,
        "start": 5925.7,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50364,
          2264,
          13,
          50389
        ]
      },
      {
        "avg_logprob": -0.5938627123832703,
        "compression_ratio": 0.8260869565217391,
        "end": 5946.98,
        "id": 1861,
        "no_speech_prob": 0.01406159345060587,
        "seek": 592570,
        "start": 5945.46,
        "temperature": 0,
        "text": " It doesn't seem more like the cat.",
        "tokens": [
          51352,
          467,
          1177,
          380,
          1643,
          544,
          411,
          264,
          3857,
          13,
          51428
        ]
      },
      {
        "avg_logprob": -0.36526534557342527,
        "compression_ratio": 1.0909090909090908,
        "end": 5957.46,
        "id": 1862,
        "no_speech_prob": 0.0000888801077962853,
        "seek": 595570,
        "start": 5956.7,
        "temperature": 0,
        "text": " It's this.",
        "tokens": [
          50414,
          467,
          311,
          341,
          13,
          50452
        ]
      },
      {
        "avg_logprob": -0.36526534557342527,
        "compression_ratio": 1.0909090909090908,
        "end": 5963.58,
        "id": 1863,
        "no_speech_prob": 0.0000888801077962853,
        "seek": 595570,
        "start": 5961.9,
        "temperature": 0,
        "text": " This is what it is.",
        "tokens": [
          50674,
          639,
          307,
          437,
          309,
          307,
          13,
          50758
        ]
      },
      {
        "avg_logprob": -0.36526534557342527,
        "compression_ratio": 1.0909090909090908,
        "end": 5964.08,
        "id": 1864,
        "no_speech_prob": 0.0000888801077962853,
        "seek": 595570,
        "start": 5963.58,
        "temperature": 0,
        "text": " Of course.",
        "tokens": [
          50758,
          2720,
          1164,
          13,
          50783
        ]
      },
      {
        "avg_logprob": -0.36526534557342527,
        "compression_ratio": 1.0909090909090908,
        "end": 5984.0199999999995,
        "id": 1865,
        "no_speech_prob": 0.0000888801077962853,
        "seek": 595570,
        "start": 5976.0199999999995,
        "temperature": 0,
        "text": " Because stroke index, then 0 is the x's, 1 is the y's.",
        "tokens": [
          51380,
          1436,
          12403,
          8186,
          11,
          550,
          1958,
          307,
          264,
          2031,
          311,
          11,
          502,
          307,
          264,
          288,
          311,
          13,
          51780
        ]
      },
      {
        "avg_logprob": -0.36318632032050463,
        "compression_ratio": 1.232,
        "end": 5987.22,
        "id": 1866,
        "no_speech_prob": 0.0004878510080743581,
        "seek": 598402,
        "start": 5984.02,
        "temperature": 0,
        "text": " Index is going up.",
        "tokens": [
          50364,
          33552,
          307,
          516,
          493,
          13,
          50524
        ]
      },
      {
        "avg_logprob": -0.36318632032050463,
        "compression_ratio": 1.232,
        "end": 5988.660000000001,
        "id": 1867,
        "no_speech_prob": 0.0004878510080743581,
        "seek": 598402,
        "start": 5987.22,
        "temperature": 0,
        "text": " And then this.",
        "tokens": [
          50524,
          400,
          550,
          341,
          13,
          50596
        ]
      },
      {
        "avg_logprob": -0.36318632032050463,
        "compression_ratio": 1.232,
        "end": 5989.26,
        "id": 1868,
        "no_speech_prob": 0.0004878510080743581,
        "seek": 598402,
        "start": 5988.660000000001,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50596,
          821,
          321,
          352,
          13,
          50626
        ]
      },
      {
        "avg_logprob": -0.36318632032050463,
        "compression_ratio": 1.232,
        "end": 5997.780000000001,
        "id": 1869,
        "no_speech_prob": 0.0004878510080743581,
        "seek": 598402,
        "start": 5995.780000000001,
        "temperature": 0,
        "text": " Yeah, it's hard to see, but these are the cats.",
        "tokens": [
          50952,
          865,
          11,
          309,
          311,
          1152,
          281,
          536,
          11,
          457,
          613,
          366,
          264,
          11111,
          13,
          51052
        ]
      },
      {
        "avg_logprob": -0.36318632032050463,
        "compression_ratio": 1.232,
        "end": 5999.620000000001,
        "id": 1870,
        "no_speech_prob": 0.0004878510080743581,
        "seek": 598402,
        "start": 5997.780000000001,
        "temperature": 0,
        "text": " OK, I got it now.",
        "tokens": [
          51052,
          2264,
          11,
          286,
          658,
          309,
          586,
          13,
          51144
        ]
      },
      {
        "avg_logprob": -0.36318632032050463,
        "compression_ratio": 1.232,
        "end": 6000.120000000001,
        "id": 1871,
        "no_speech_prob": 0.0004878510080743581,
        "seek": 598402,
        "start": 5999.620000000001,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51144,
          1057,
          558,
          13,
          51169
        ]
      },
      {
        "avg_logprob": -0.36318632032050463,
        "compression_ratio": 1.232,
        "end": 6004.900000000001,
        "id": 1872,
        "no_speech_prob": 0.0004878510080743581,
        "seek": 598402,
        "start": 6003.540000000001,
        "temperature": 0,
        "text": " Let me go back to where I was.",
        "tokens": [
          51340,
          961,
          385,
          352,
          646,
          281,
          689,
          286,
          390,
          13,
          51408
        ]
      },
      {
        "avg_logprob": -0.45964118412562777,
        "compression_ratio": 1.2222222222222223,
        "end": 6017.780000000001,
        "id": 1873,
        "no_speech_prob": 0.004264601040631533,
        "seek": 601402,
        "start": 6015.02,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50414,
          1057,
          558,
          13,
          50552
        ]
      },
      {
        "avg_logprob": -0.45964118412562777,
        "compression_ratio": 1.2222222222222223,
        "end": 6019.860000000001,
        "id": 1874,
        "no_speech_prob": 0.004264601040631533,
        "seek": 601402,
        "start": 6017.780000000001,
        "temperature": 0,
        "text": " I wasn't paying attention.",
        "tokens": [
          50552,
          286,
          2067,
          380,
          6229,
          3202,
          13,
          50656
        ]
      },
      {
        "avg_logprob": -0.45964118412562777,
        "compression_ratio": 1.2222222222222223,
        "end": 6024.14,
        "id": 1875,
        "no_speech_prob": 0.004264601040631533,
        "seek": 601402,
        "start": 6019.860000000001,
        "temperature": 0,
        "text": " If I look at how those arrays are organized, the first,",
        "tokens": [
          50656,
          759,
          286,
          574,
          412,
          577,
          729,
          41011,
          366,
          9983,
          11,
          264,
          700,
          11,
          50870
        ]
      },
      {
        "avg_logprob": -0.45964118412562777,
        "compression_ratio": 1.2222222222222223,
        "end": 6027.06,
        "id": 1876,
        "no_speech_prob": 0.004264601040631533,
        "seek": 601402,
        "start": 6024.14,
        "temperature": 0,
        "text": " the, the, the, it's, sorry.",
        "tokens": [
          50870,
          264,
          11,
          264,
          11,
          264,
          11,
          309,
          311,
          11,
          2597,
          13,
          51016
        ]
      },
      {
        "avg_logprob": -0.29344464619954425,
        "compression_ratio": 1.4555555555555555,
        "end": 6045.5,
        "id": 1877,
        "no_speech_prob": 0.00020342641801107675,
        "seek": 604402,
        "start": 6045.02,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50414,
          2264,
          13,
          50438
        ]
      },
      {
        "avg_logprob": -0.29344464619954425,
        "compression_ratio": 1.4555555555555555,
        "end": 6054.580000000001,
        "id": 1878,
        "no_speech_prob": 0.00020342641801107675,
        "seek": 604402,
        "start": 6052.9400000000005,
        "temperature": 0,
        "text": " OK, something is terribly wrong here.",
        "tokens": [
          50810,
          2264,
          11,
          746,
          307,
          22903,
          2085,
          510,
          13,
          50892
        ]
      },
      {
        "avg_logprob": -0.29344464619954425,
        "compression_ratio": 1.4555555555555555,
        "end": 6056.9800000000005,
        "id": 1879,
        "no_speech_prob": 0.00020342641801107675,
        "seek": 604402,
        "start": 6054.580000000001,
        "temperature": 0,
        "text": " And actually, I have not been carefully looking",
        "tokens": [
          50892,
          400,
          767,
          11,
          286,
          362,
          406,
          668,
          7500,
          1237,
          51012
        ]
      },
      {
        "avg_logprob": -0.29344464619954425,
        "compression_ratio": 1.4555555555555555,
        "end": 6058.780000000001,
        "id": 1880,
        "no_speech_prob": 0.00020342641801107675,
        "seek": 604402,
        "start": 6056.9800000000005,
        "temperature": 0,
        "text": " at how those arrays are organized.",
        "tokens": [
          51012,
          412,
          577,
          729,
          41011,
          366,
          9983,
          13,
          51102
        ]
      },
      {
        "avg_logprob": -0.29344464619954425,
        "compression_ratio": 1.4555555555555555,
        "end": 6061.820000000001,
        "id": 1881,
        "no_speech_prob": 0.00020342641801107675,
        "seek": 604402,
        "start": 6058.780000000001,
        "temperature": 0,
        "text": " It's very confusing to store all these data in arrays.",
        "tokens": [
          51102,
          467,
          311,
          588,
          13181,
          281,
          3531,
          439,
          613,
          1412,
          294,
          41011,
          13,
          51254
        ]
      },
      {
        "avg_logprob": -0.29344464619954425,
        "compression_ratio": 1.4555555555555555,
        "end": 6067.46,
        "id": 1882,
        "no_speech_prob": 0.00020342641801107675,
        "seek": 604402,
        "start": 6061.820000000001,
        "temperature": 0,
        "text": " But there are 11 strokes.",
        "tokens": [
          51254,
          583,
          456,
          366,
          2975,
          24493,
          13,
          51536
        ]
      },
      {
        "avg_logprob": -0.29344464619954425,
        "compression_ratio": 1.4555555555555555,
        "end": 6070.820000000001,
        "id": 1883,
        "no_speech_prob": 0.00020342641801107675,
        "seek": 604402,
        "start": 6067.46,
        "temperature": 0,
        "text": " And this stroke has 23 points.",
        "tokens": [
          51536,
          400,
          341,
          12403,
          575,
          6673,
          2793,
          13,
          51704
        ]
      },
      {
        "avg_logprob": -0.29344464619954425,
        "compression_ratio": 1.4555555555555555,
        "end": 6072.580000000001,
        "id": 1884,
        "no_speech_prob": 0.00020342641801107675,
        "seek": 604402,
        "start": 6070.820000000001,
        "temperature": 0,
        "text": " This stroke has 9 points.",
        "tokens": [
          51704,
          639,
          12403,
          575,
          1722,
          2793,
          13,
          51792
        ]
      },
      {
        "avg_logprob": -0.20414018139396747,
        "compression_ratio": 1.899441340782123,
        "end": 6077.3,
        "id": 1885,
        "no_speech_prob": 0.0000016280512227240251,
        "seek": 607258,
        "start": 6072.58,
        "temperature": 0,
        "text": " But notice that the, I have the order wrong.",
        "tokens": [
          50364,
          583,
          3449,
          300,
          264,
          11,
          286,
          362,
          264,
          1668,
          2085,
          13,
          50600
        ]
      },
      {
        "avg_logprob": -0.20414018139396747,
        "compression_ratio": 1.899441340782123,
        "end": 6080.38,
        "id": 1886,
        "no_speech_prob": 0.0000016280512227240251,
        "seek": 607258,
        "start": 6077.3,
        "temperature": 0,
        "text": " This is an array of an array of arrays.",
        "tokens": [
          50600,
          639,
          307,
          364,
          10225,
          295,
          364,
          10225,
          295,
          41011,
          13,
          50754
        ]
      },
      {
        "avg_logprob": -0.20414018139396747,
        "compression_ratio": 1.899441340782123,
        "end": 6086.9,
        "id": 1887,
        "no_speech_prob": 0.0000016280512227240251,
        "seek": 607258,
        "start": 6080.38,
        "temperature": 0,
        "text": " And so basically, the stroke, the 0 element of the stroke",
        "tokens": [
          50754,
          400,
          370,
          1936,
          11,
          264,
          12403,
          11,
          264,
          1958,
          4478,
          295,
          264,
          12403,
          51080
        ]
      },
      {
        "avg_logprob": -0.20414018139396747,
        "compression_ratio": 1.899441340782123,
        "end": 6089.22,
        "id": 1888,
        "no_speech_prob": 0.0000016280512227240251,
        "seek": 607258,
        "start": 6086.9,
        "temperature": 0,
        "text": " is all the different x values.",
        "tokens": [
          51080,
          307,
          439,
          264,
          819,
          2031,
          4190,
          13,
          51196
        ]
      },
      {
        "avg_logprob": -0.20414018139396747,
        "compression_ratio": 1.899441340782123,
        "end": 6094.1,
        "id": 1889,
        "no_speech_prob": 0.0000016280512227240251,
        "seek": 607258,
        "start": 6089.22,
        "temperature": 0,
        "text": " And this 1 element of the stroke is all the different y values.",
        "tokens": [
          51196,
          400,
          341,
          502,
          4478,
          295,
          264,
          12403,
          307,
          439,
          264,
          819,
          288,
          4190,
          13,
          51440
        ]
      },
      {
        "avg_logprob": -0.20414018139396747,
        "compression_ratio": 1.899441340782123,
        "end": 6095.46,
        "id": 1890,
        "no_speech_prob": 0.0000016280512227240251,
        "seek": 607258,
        "start": 6094.1,
        "temperature": 0,
        "text": " I had those out of order.",
        "tokens": [
          51440,
          286,
          632,
          729,
          484,
          295,
          1668,
          13,
          51508
        ]
      },
      {
        "avg_logprob": -0.20414018139396747,
        "compression_ratio": 1.899441340782123,
        "end": 6098.1,
        "id": 1891,
        "no_speech_prob": 0.0000016280512227240251,
        "seek": 607258,
        "start": 6095.46,
        "temperature": 0,
        "text": " And then here, the number of points",
        "tokens": [
          51508,
          400,
          550,
          510,
          11,
          264,
          1230,
          295,
          2793,
          51640
        ]
      },
      {
        "avg_logprob": -0.20414018139396747,
        "compression_ratio": 1.899441340782123,
        "end": 6101.7,
        "id": 1892,
        "no_speech_prob": 0.0000016280512227240251,
        "seek": 607258,
        "start": 6098.1,
        "temperature": 0,
        "text": " is not the number of strokes, but rather",
        "tokens": [
          51640,
          307,
          406,
          264,
          1230,
          295,
          24493,
          11,
          457,
          2831,
          51820
        ]
      },
      {
        "avg_logprob": -0.2324195901552836,
        "compression_ratio": 1.6369047619047619,
        "end": 6103.179999999999,
        "id": 1893,
        "no_speech_prob": 0.000011300801816105377,
        "seek": 610170,
        "start": 6101.7,
        "temperature": 0,
        "text": " the number of x's.",
        "tokens": [
          50364,
          264,
          1230,
          295,
          2031,
          311,
          13,
          50438
        ]
      },
      {
        "avg_logprob": -0.2324195901552836,
        "compression_ratio": 1.6369047619047619,
        "end": 6106.82,
        "id": 1894,
        "no_speech_prob": 0.000011300801816105377,
        "seek": 610170,
        "start": 6103.179999999999,
        "temperature": 0,
        "text": " So now, if I redo this, I should see,",
        "tokens": [
          50438,
          407,
          586,
          11,
          498,
          286,
          29956,
          341,
          11,
          286,
          820,
          536,
          11,
          50620
        ]
      },
      {
        "avg_logprob": -0.2324195901552836,
        "compression_ratio": 1.6369047619047619,
        "end": 6108.139999999999,
        "id": 1895,
        "no_speech_prob": 0.000011300801816105377,
        "seek": 610170,
        "start": 6106.82,
        "temperature": 0,
        "text": " I can sort of see it drawing.",
        "tokens": [
          50620,
          286,
          393,
          1333,
          295,
          536,
          309,
          6316,
          13,
          50686
        ]
      },
      {
        "avg_logprob": -0.2324195901552836,
        "compression_ratio": 1.6369047619047619,
        "end": 6108.639999999999,
        "id": 1896,
        "no_speech_prob": 0.000011300801816105377,
        "seek": 610170,
        "start": 6108.139999999999,
        "temperature": 0,
        "text": " Oops.",
        "tokens": [
          50686,
          21726,
          13,
          50711
        ]
      },
      {
        "avg_logprob": -0.2324195901552836,
        "compression_ratio": 1.6369047619047619,
        "end": 6120.099999999999,
        "id": 1897,
        "no_speech_prob": 0.000011300801816105377,
        "seek": 610170,
        "start": 6116.639999999999,
        "temperature": 0,
        "text": " You can see the outline of a cat there.",
        "tokens": [
          51111,
          509,
          393,
          536,
          264,
          16387,
          295,
          257,
          3857,
          456,
          13,
          51284
        ]
      },
      {
        "avg_logprob": -0.2324195901552836,
        "compression_ratio": 1.6369047619047619,
        "end": 6122.58,
        "id": 1898,
        "no_speech_prob": 0.000011300801816105377,
        "seek": 610170,
        "start": 6120.099999999999,
        "temperature": 0,
        "text": " You can start to see the outline of a cat here.",
        "tokens": [
          51284,
          509,
          393,
          722,
          281,
          536,
          264,
          16387,
          295,
          257,
          3857,
          510,
          13,
          51408
        ]
      },
      {
        "avg_logprob": -0.2324195901552836,
        "compression_ratio": 1.6369047619047619,
        "end": 6124.099999999999,
        "id": 1899,
        "no_speech_prob": 0.000011300801816105377,
        "seek": 610170,
        "start": 6122.58,
        "temperature": 0,
        "text": " Of course, it gets stuck at the end.",
        "tokens": [
          51408,
          2720,
          1164,
          11,
          309,
          2170,
          5541,
          412,
          264,
          917,
          13,
          51484
        ]
      },
      {
        "avg_logprob": -0.2324195901552836,
        "compression_ratio": 1.6369047619047619,
        "end": 6125.42,
        "id": 1900,
        "no_speech_prob": 0.000011300801816105377,
        "seek": 610170,
        "start": 6124.099999999999,
        "temperature": 0,
        "text": " It's giving me an error.",
        "tokens": [
          51484,
          467,
          311,
          2902,
          385,
          364,
          6713,
          13,
          51550
        ]
      },
      {
        "avg_logprob": -0.2324195901552836,
        "compression_ratio": 1.6369047619047619,
        "end": 6127.3,
        "id": 1901,
        "no_speech_prob": 0.000011300801816105377,
        "seek": 610170,
        "start": 6125.42,
        "temperature": 0,
        "text": " So first, let me fix that error.",
        "tokens": [
          51550,
          407,
          700,
          11,
          718,
          385,
          3191,
          300,
          6713,
          13,
          51644
        ]
      },
      {
        "avg_logprob": -0.22436395645141602,
        "compression_ratio": 1.7180851063829787,
        "end": 6128.7,
        "id": 1902,
        "no_speech_prob": 0.00001723156492516864,
        "seek": 612730,
        "start": 6127.3,
        "temperature": 0,
        "text": " So the error that I need to check",
        "tokens": [
          50364,
          407,
          264,
          6713,
          300,
          286,
          643,
          281,
          1520,
          50434
        ]
      },
      {
        "avg_logprob": -0.22436395645141602,
        "compression_ratio": 1.7180851063829787,
        "end": 6139.3,
        "id": 1903,
        "no_speech_prob": 0.00001723156492516864,
        "seek": 612730,
        "start": 6128.7,
        "temperature": 0,
        "text": " is if stroke index equals cat.length, then I'm done.",
        "tokens": [
          50434,
          307,
          498,
          12403,
          8186,
          6915,
          3857,
          13,
          45390,
          11,
          550,
          286,
          478,
          1096,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.22436395645141602,
        "compression_ratio": 1.7180851063829787,
        "end": 6141.820000000001,
        "id": 1904,
        "no_speech_prob": 0.00001723156492516864,
        "seek": 612730,
        "start": 6139.3,
        "temperature": 0,
        "text": " Then I'm going to say cat equals null.",
        "tokens": [
          50964,
          1396,
          286,
          478,
          516,
          281,
          584,
          3857,
          6915,
          18184,
          13,
          51090
        ]
      },
      {
        "avg_logprob": -0.22436395645141602,
        "compression_ratio": 1.7180851063829787,
        "end": 6144.74,
        "id": 1905,
        "no_speech_prob": 0.00001723156492516864,
        "seek": 612730,
        "start": 6141.820000000001,
        "temperature": 0,
        "text": " I am going to say no more to the cat.",
        "tokens": [
          51090,
          286,
          669,
          516,
          281,
          584,
          572,
          544,
          281,
          264,
          3857,
          13,
          51236
        ]
      },
      {
        "avg_logprob": -0.22436395645141602,
        "compression_ratio": 1.7180851063829787,
        "end": 6145.860000000001,
        "id": 1906,
        "no_speech_prob": 0.00001723156492516864,
        "seek": 612730,
        "start": 6144.74,
        "temperature": 0,
        "text": " And there we go.",
        "tokens": [
          51236,
          400,
          456,
          321,
          352,
          13,
          51292
        ]
      },
      {
        "avg_logprob": -0.22436395645141602,
        "compression_ratio": 1.7180851063829787,
        "end": 6147.3,
        "id": 1907,
        "no_speech_prob": 0.00001723156492516864,
        "seek": 612730,
        "start": 6145.860000000001,
        "temperature": 0,
        "text": " So this is the drawing of the cat.",
        "tokens": [
          51292,
          407,
          341,
          307,
          264,
          6316,
          295,
          264,
          3857,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.22436395645141602,
        "compression_ratio": 1.7180851063829787,
        "end": 6149.3,
        "id": 1908,
        "no_speech_prob": 0.00001723156492516864,
        "seek": 612730,
        "start": 6147.3,
        "temperature": 0,
        "text": " Now, of course, I'm just drawing all the points.",
        "tokens": [
          51364,
          823,
          11,
          295,
          1164,
          11,
          286,
          478,
          445,
          6316,
          439,
          264,
          2793,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.22436395645141602,
        "compression_ratio": 1.7180851063829787,
        "end": 6153.3,
        "id": 1909,
        "no_speech_prob": 0.00001723156492516864,
        "seek": 612730,
        "start": 6149.3,
        "temperature": 0,
        "text": " I need to connect the previous points to the other points.",
        "tokens": [
          51464,
          286,
          643,
          281,
          1745,
          264,
          3894,
          2793,
          281,
          264,
          661,
          2793,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2095481938329236,
        "compression_ratio": 1.9195402298850575,
        "end": 6157.34,
        "id": 1910,
        "no_speech_prob": 0.0003799837431870401,
        "seek": 615330,
        "start": 6153.3,
        "temperature": 0,
        "text": " So I'm going to add a previous x, previous y.",
        "tokens": [
          50364,
          407,
          286,
          478,
          516,
          281,
          909,
          257,
          3894,
          2031,
          11,
          3894,
          288,
          13,
          50566
        ]
      },
      {
        "avg_logprob": -0.2095481938329236,
        "compression_ratio": 1.9195402298850575,
        "end": 6161.820000000001,
        "id": 1911,
        "no_speech_prob": 0.0003799837431870401,
        "seek": 615330,
        "start": 6157.34,
        "temperature": 0,
        "text": " And then I'm going to say here, down here,",
        "tokens": [
          50566,
          400,
          550,
          286,
          478,
          516,
          281,
          584,
          510,
          11,
          760,
          510,
          11,
          50790
        ]
      },
      {
        "avg_logprob": -0.2095481938329236,
        "compression_ratio": 1.9195402298850575,
        "end": 6166.5,
        "id": 1912,
        "no_speech_prob": 0.0003799837431870401,
        "seek": 615330,
        "start": 6161.820000000001,
        "temperature": 0,
        "text": " previous x equals x, previous y equals y.",
        "tokens": [
          50790,
          3894,
          2031,
          6915,
          2031,
          11,
          3894,
          288,
          6915,
          288,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.2095481938329236,
        "compression_ratio": 1.9195402298850575,
        "end": 6171.38,
        "id": 1913,
        "no_speech_prob": 0.0003799837431870401,
        "seek": 615330,
        "start": 6166.5,
        "temperature": 0,
        "text": " And then here, I'm going to say a line between previous x,",
        "tokens": [
          51024,
          400,
          550,
          510,
          11,
          286,
          478,
          516,
          281,
          584,
          257,
          1622,
          1296,
          3894,
          2031,
          11,
          51268
        ]
      },
      {
        "avg_logprob": -0.2095481938329236,
        "compression_ratio": 1.9195402298850575,
        "end": 6173.34,
        "id": 1914,
        "no_speech_prob": 0.0003799837431870401,
        "seek": 615330,
        "start": 6171.38,
        "temperature": 0,
        "text": " previous y, and x and y.",
        "tokens": [
          51268,
          3894,
          288,
          11,
          293,
          2031,
          293,
          288,
          13,
          51366
        ]
      },
      {
        "avg_logprob": -0.2095481938329236,
        "compression_ratio": 1.9195402298850575,
        "end": 6176.820000000001,
        "id": 1915,
        "no_speech_prob": 0.0003799837431870401,
        "seek": 615330,
        "start": 6173.34,
        "temperature": 0,
        "text": " Now, it should do nothing when those values are null.",
        "tokens": [
          51366,
          823,
          11,
          309,
          820,
          360,
          1825,
          562,
          729,
          4190,
          366,
          18184,
          13,
          51540
        ]
      },
      {
        "avg_logprob": -0.2095481938329236,
        "compression_ratio": 1.9195402298850575,
        "end": 6179.22,
        "id": 1916,
        "no_speech_prob": 0.0003799837431870401,
        "seek": 615330,
        "start": 6176.820000000001,
        "temperature": 0,
        "text": " So now we see there, ooh.",
        "tokens": [
          51540,
          407,
          586,
          321,
          536,
          456,
          11,
          17024,
          13,
          51660
        ]
      },
      {
        "avg_logprob": -0.2095481938329236,
        "compression_ratio": 1.9195402298850575,
        "end": 6180.54,
        "id": 1917,
        "no_speech_prob": 0.0003799837431870401,
        "seek": 615330,
        "start": 6179.22,
        "temperature": 0,
        "text": " Oh, wait a sec.",
        "tokens": [
          51660,
          876,
          11,
          1699,
          257,
          907,
          13,
          51726
        ]
      },
      {
        "avg_logprob": -0.2095481938329236,
        "compression_ratio": 1.9195402298850575,
        "end": 6182.3,
        "id": 1918,
        "no_speech_prob": 0.0003799837431870401,
        "seek": 615330,
        "start": 6180.54,
        "temperature": 0,
        "text": " No, no, no, no, no, no.",
        "tokens": [
          51726,
          883,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.23691806320316536,
        "compression_ratio": 1.7104072398190044,
        "end": 6185.02,
        "id": 1919,
        "no_speech_prob": 3.632675884546188e-7,
        "seek": 618230,
        "start": 6182.3,
        "temperature": 0,
        "text": " When I get to the next stroke, then I",
        "tokens": [
          50364,
          1133,
          286,
          483,
          281,
          264,
          958,
          12403,
          11,
          550,
          286,
          50500
        ]
      },
      {
        "avg_logprob": -0.23691806320316536,
        "compression_ratio": 1.7104072398190044,
        "end": 6189.1,
        "id": 1920,
        "no_speech_prob": 3.632675884546188e-7,
        "seek": 618230,
        "start": 6185.02,
        "temperature": 0,
        "text": " need to say previous x equals undefined again,",
        "tokens": [
          50500,
          643,
          281,
          584,
          3894,
          2031,
          6915,
          674,
          5666,
          2001,
          797,
          11,
          50704
        ]
      },
      {
        "avg_logprob": -0.23691806320316536,
        "compression_ratio": 1.7104072398190044,
        "end": 6191.42,
        "id": 1921,
        "no_speech_prob": 3.632675884546188e-7,
        "seek": 618230,
        "start": 6189.1,
        "temperature": 0,
        "text": " and previous y equals undefined.",
        "tokens": [
          50704,
          293,
          3894,
          288,
          6915,
          674,
          5666,
          2001,
          13,
          50820
        ]
      },
      {
        "avg_logprob": -0.23691806320316536,
        "compression_ratio": 1.7104072398190044,
        "end": 6193.06,
        "id": 1922,
        "no_speech_prob": 3.632675884546188e-7,
        "seek": 618230,
        "start": 6191.42,
        "temperature": 0,
        "text": " I don't want to connect the strokes.",
        "tokens": [
          50820,
          286,
          500,
          380,
          528,
          281,
          1745,
          264,
          24493,
          13,
          50902
        ]
      },
      {
        "avg_logprob": -0.23691806320316536,
        "compression_ratio": 1.7104072398190044,
        "end": 6195.34,
        "id": 1923,
        "no_speech_prob": 3.632675884546188e-7,
        "seek": 618230,
        "start": 6193.06,
        "temperature": 0,
        "text": " So that's a little bit of an awkward way of doing it.",
        "tokens": [
          50902,
          407,
          300,
          311,
          257,
          707,
          857,
          295,
          364,
          11411,
          636,
          295,
          884,
          309,
          13,
          51016
        ]
      },
      {
        "avg_logprob": -0.23691806320316536,
        "compression_ratio": 1.7104072398190044,
        "end": 6199.38,
        "id": 1924,
        "no_speech_prob": 3.632675884546188e-7,
        "seek": 618230,
        "start": 6195.34,
        "temperature": 0,
        "text": " It's still doing that, isn't it?",
        "tokens": [
          51016,
          467,
          311,
          920,
          884,
          300,
          11,
          1943,
          380,
          309,
          30,
          51218
        ]
      },
      {
        "avg_logprob": -0.23691806320316536,
        "compression_ratio": 1.7104072398190044,
        "end": 6203.9400000000005,
        "id": 1925,
        "no_speech_prob": 3.632675884546188e-7,
        "seek": 618230,
        "start": 6199.38,
        "temperature": 0,
        "text": " And then I want to say if previous x, maybe if I do this,",
        "tokens": [
          51218,
          400,
          550,
          286,
          528,
          281,
          584,
          498,
          3894,
          2031,
          11,
          1310,
          498,
          286,
          360,
          341,
          11,
          51446
        ]
      },
      {
        "avg_logprob": -0.23691806320316536,
        "compression_ratio": 1.7104072398190044,
        "end": 6208.7,
        "id": 1926,
        "no_speech_prob": 3.632675884546188e-7,
        "seek": 618230,
        "start": 6203.9400000000005,
        "temperature": 0,
        "text": " does not equal undefined, then draw the line.",
        "tokens": [
          51446,
          775,
          406,
          2681,
          674,
          5666,
          2001,
          11,
          550,
          2642,
          264,
          1622,
          13,
          51684
        ]
      },
      {
        "avg_logprob": -0.23691806320316536,
        "compression_ratio": 1.7104072398190044,
        "end": 6210.38,
        "id": 1927,
        "no_speech_prob": 3.632675884546188e-7,
        "seek": 618230,
        "start": 6208.7,
        "temperature": 0,
        "text": " Let's see if this works.",
        "tokens": [
          51684,
          961,
          311,
          536,
          498,
          341,
          1985,
          13,
          51768
        ]
      },
      {
        "avg_logprob": -0.23691806320316536,
        "compression_ratio": 1.7104072398190044,
        "end": 6211.14,
        "id": 1928,
        "no_speech_prob": 3.632675884546188e-7,
        "seek": 618230,
        "start": 6210.38,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          51768,
          45263,
          13,
          51806
        ]
      },
      {
        "avg_logprob": -0.27525117262354437,
        "compression_ratio": 1.4926829268292683,
        "end": 6212.900000000001,
        "id": 1929,
        "no_speech_prob": 0.00000951624951994745,
        "seek": 621114,
        "start": 6211.14,
        "temperature": 0,
        "text": " Sketch the line 19.",
        "tokens": [
          50364,
          49245,
          264,
          1622,
          1294,
          13,
          50452
        ]
      },
      {
        "avg_logprob": -0.27525117262354437,
        "compression_ratio": 1.4926829268292683,
        "end": 6216.06,
        "id": 1930,
        "no_speech_prob": 0.00000951624951994745,
        "seek": 621114,
        "start": 6212.900000000001,
        "temperature": 0,
        "text": " I always have this extra equals there.",
        "tokens": [
          50452,
          286,
          1009,
          362,
          341,
          2857,
          6915,
          456,
          13,
          50610
        ]
      },
      {
        "avg_logprob": -0.27525117262354437,
        "compression_ratio": 1.4926829268292683,
        "end": 6216.740000000001,
        "id": 1931,
        "no_speech_prob": 0.00000951624951994745,
        "seek": 621114,
        "start": 6216.06,
        "temperature": 0,
        "text": " Oh, weird.",
        "tokens": [
          50610,
          876,
          11,
          3657,
          13,
          50644
        ]
      },
      {
        "avg_logprob": -0.27525117262354437,
        "compression_ratio": 1.4926829268292683,
        "end": 6221.3,
        "id": 1932,
        "no_speech_prob": 0.00000951624951994745,
        "seek": 621114,
        "start": 6219.22,
        "temperature": 0,
        "text": " It's still connecting everything.",
        "tokens": [
          50768,
          467,
          311,
          920,
          11015,
          1203,
          13,
          50872
        ]
      },
      {
        "avg_logprob": -0.27525117262354437,
        "compression_ratio": 1.4926829268292683,
        "end": 6222.900000000001,
        "id": 1933,
        "no_speech_prob": 0.00000951624951994745,
        "seek": 621114,
        "start": 6221.3,
        "temperature": 0,
        "text": " A lovely little cat there.",
        "tokens": [
          50872,
          316,
          7496,
          707,
          3857,
          456,
          13,
          50952
        ]
      },
      {
        "avg_logprob": -0.27525117262354437,
        "compression_ratio": 1.4926829268292683,
        "end": 6224.900000000001,
        "id": 1934,
        "no_speech_prob": 0.00000951624951994745,
        "seek": 621114,
        "start": 6222.900000000001,
        "temperature": 0,
        "text": " What am I missing?",
        "tokens": [
          50952,
          708,
          669,
          286,
          5361,
          30,
          51052
        ]
      },
      {
        "avg_logprob": -0.27525117262354437,
        "compression_ratio": 1.4926829268292683,
        "end": 6229.02,
        "id": 1935,
        "no_speech_prob": 0.00000951624951994745,
        "seek": 621114,
        "start": 6224.900000000001,
        "temperature": 0,
        "text": " I don't want to draw the line.",
        "tokens": [
          51052,
          286,
          500,
          380,
          528,
          281,
          2642,
          264,
          1622,
          13,
          51258
        ]
      },
      {
        "avg_logprob": -0.27525117262354437,
        "compression_ratio": 1.4926829268292683,
        "end": 6231.9400000000005,
        "id": 1936,
        "no_speech_prob": 0.00000951624951994745,
        "seek": 621114,
        "start": 6229.02,
        "temperature": 0,
        "text": " These are undefined at the beginning.",
        "tokens": [
          51258,
          1981,
          366,
          674,
          5666,
          2001,
          412,
          264,
          2863,
          13,
          51404
        ]
      },
      {
        "avg_logprob": -0.27525117262354437,
        "compression_ratio": 1.4926829268292683,
        "end": 6234.06,
        "id": 1937,
        "no_speech_prob": 0.00000951624951994745,
        "seek": 621114,
        "start": 6231.9400000000005,
        "temperature": 0,
        "text": " Oh, it gets set to here.",
        "tokens": [
          51404,
          876,
          11,
          309,
          2170,
          992,
          281,
          510,
          13,
          51510
        ]
      },
      {
        "avg_logprob": -0.27525117262354437,
        "compression_ratio": 1.4926829268292683,
        "end": 6235.58,
        "id": 1938,
        "no_speech_prob": 0.00000951624951994745,
        "seek": 621114,
        "start": 6234.06,
        "temperature": 0,
        "text": " So I need an else here.",
        "tokens": [
          51510,
          407,
          286,
          643,
          364,
          1646,
          510,
          13,
          51586
        ]
      },
      {
        "avg_logprob": -0.27525117262354437,
        "compression_ratio": 1.4926829268292683,
        "end": 6237.9400000000005,
        "id": 1939,
        "no_speech_prob": 0.00000951624951994745,
        "seek": 621114,
        "start": 6235.58,
        "temperature": 0,
        "text": " Else.",
        "tokens": [
          51586,
          45472,
          13,
          51704
        ]
      },
      {
        "avg_logprob": -0.27525117262354437,
        "compression_ratio": 1.4926829268292683,
        "end": 6240.62,
        "id": 1940,
        "no_speech_prob": 0.00000951624951994745,
        "seek": 621114,
        "start": 6237.9400000000005,
        "temperature": 0,
        "text": " Don't set it if it's at the end.",
        "tokens": [
          51704,
          1468,
          380,
          992,
          309,
          498,
          309,
          311,
          412,
          264,
          917,
          13,
          51838
        ]
      },
      {
        "avg_logprob": -0.2165037340822473,
        "compression_ratio": 1.6102564102564103,
        "end": 6243.26,
        "id": 1941,
        "no_speech_prob": 0.000011659479241643567,
        "seek": 624062,
        "start": 6240.62,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50364,
          2264,
          13,
          50496
        ]
      },
      {
        "avg_logprob": -0.2165037340822473,
        "compression_ratio": 1.6102564102564103,
        "end": 6243.82,
        "id": 1942,
        "no_speech_prob": 0.000011659479241643567,
        "seek": 624062,
        "start": 6243.26,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50496,
          821,
          321,
          352,
          13,
          50524
        ]
      },
      {
        "avg_logprob": -0.2165037340822473,
        "compression_ratio": 1.6102564102564103,
        "end": 6245.7,
        "id": 1943,
        "no_speech_prob": 0.000011659479241643567,
        "seek": 624062,
        "start": 6243.82,
        "temperature": 0,
        "text": " Finally, we are drawing cats.",
        "tokens": [
          50524,
          6288,
          11,
          321,
          366,
          6316,
          11111,
          13,
          50618
        ]
      },
      {
        "avg_logprob": -0.2165037340822473,
        "compression_ratio": 1.6102564102564103,
        "end": 6250.38,
        "id": 1944,
        "no_speech_prob": 0.000011659479241643567,
        "seek": 624062,
        "start": 6245.7,
        "temperature": 0,
        "text": " Now, all I have to do is then, when I reset there,",
        "tokens": [
          50618,
          823,
          11,
          439,
          286,
          362,
          281,
          360,
          307,
          550,
          11,
          562,
          286,
          14322,
          456,
          11,
          50852
        ]
      },
      {
        "avg_logprob": -0.2165037340822473,
        "compression_ratio": 1.6102564102564103,
        "end": 6253.46,
        "id": 1945,
        "no_speech_prob": 0.000011659479241643567,
        "seek": 624062,
        "start": 6250.38,
        "temperature": 0,
        "text": " I can just ask for a new one.",
        "tokens": [
          50852,
          286,
          393,
          445,
          1029,
          337,
          257,
          777,
          472,
          13,
          51006
        ]
      },
      {
        "avg_logprob": -0.2165037340822473,
        "compression_ratio": 1.6102564102564103,
        "end": 6255.42,
        "id": 1946,
        "no_speech_prob": 0.000011659479241643567,
        "seek": 624062,
        "start": 6253.46,
        "temperature": 0,
        "text": " So let's ask for a new cat.",
        "tokens": [
          51006,
          407,
          718,
          311,
          1029,
          337,
          257,
          777,
          3857,
          13,
          51104
        ]
      },
      {
        "avg_logprob": -0.2165037340822473,
        "compression_ratio": 1.6102564102564103,
        "end": 6261.14,
        "id": 1947,
        "no_speech_prob": 0.000011659479241643567,
        "seek": 624062,
        "start": 6255.42,
        "temperature": 0,
        "text": " And whenever I've got a cat, let's draw a white background.",
        "tokens": [
          51104,
          400,
          5699,
          286,
          600,
          658,
          257,
          3857,
          11,
          718,
          311,
          2642,
          257,
          2418,
          3678,
          13,
          51390
        ]
      },
      {
        "avg_logprob": -0.2165037340822473,
        "compression_ratio": 1.6102564102564103,
        "end": 6264.42,
        "id": 1948,
        "no_speech_prob": 0.000011659479241643567,
        "seek": 624062,
        "start": 6261.14,
        "temperature": 0,
        "text": " Let's make it a little bit gray.",
        "tokens": [
          51390,
          961,
          311,
          652,
          309,
          257,
          707,
          857,
          10855,
          13,
          51554
        ]
      },
      {
        "avg_logprob": -0.2165037340822473,
        "compression_ratio": 1.6102564102564103,
        "end": 6266.34,
        "id": 1949,
        "no_speech_prob": 0.000011659479241643567,
        "seek": 624062,
        "start": 6264.42,
        "temperature": 0,
        "text": " We'll set it gray at the beginning.",
        "tokens": [
          51554,
          492,
          603,
          992,
          309,
          10855,
          412,
          264,
          2863,
          13,
          51650
        ]
      },
      {
        "avg_logprob": -0.2165037340822473,
        "compression_ratio": 1.6102564102564103,
        "end": 6266.86,
        "id": 1950,
        "no_speech_prob": 0.000011659479241643567,
        "seek": 624062,
        "start": 6266.34,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51650,
          821,
          321,
          352,
          13,
          51676
        ]
      },
      {
        "avg_logprob": -0.2165037340822473,
        "compression_ratio": 1.6102564102564103,
        "end": 6268.0599999999995,
        "id": 1951,
        "no_speech_prob": 0.000011659479241643567,
        "seek": 624062,
        "start": 6266.86,
        "temperature": 0,
        "text": " Now, here we go.",
        "tokens": [
          51676,
          823,
          11,
          510,
          321,
          352,
          13,
          51736
        ]
      },
      {
        "avg_logprob": -0.32790724079260664,
        "compression_ratio": 1.417142857142857,
        "end": 6271.46,
        "id": 1952,
        "no_speech_prob": 0.000035912671592086554,
        "seek": 626806,
        "start": 6268.06,
        "temperature": 0,
        "text": " We are now going to draw lots of cats.",
        "tokens": [
          50364,
          492,
          366,
          586,
          516,
          281,
          2642,
          3195,
          295,
          11111,
          13,
          50534
        ]
      },
      {
        "avg_logprob": -0.32790724079260664,
        "compression_ratio": 1.417142857142857,
        "end": 6272.42,
        "id": 1953,
        "no_speech_prob": 0.000035912671592086554,
        "seek": 626806,
        "start": 6271.46,
        "temperature": 0,
        "text": " It should finish one.",
        "tokens": [
          50534,
          467,
          820,
          2413,
          472,
          13,
          50582
        ]
      },
      {
        "avg_logprob": -0.32790724079260664,
        "compression_ratio": 1.417142857142857,
        "end": 6274.42,
        "id": 1954,
        "no_speech_prob": 0.000035912671592086554,
        "seek": 626806,
        "start": 6272.42,
        "temperature": 0,
        "text": " Oh, didn't get another one.",
        "tokens": [
          50582,
          876,
          11,
          994,
          380,
          483,
          1071,
          472,
          13,
          50682
        ]
      },
      {
        "avg_logprob": -0.32790724079260664,
        "compression_ratio": 1.417142857142857,
        "end": 6275.46,
        "id": 1955,
        "no_speech_prob": 0.000035912671592086554,
        "seek": 626806,
        "start": 6274.42,
        "temperature": 0,
        "text": " Sketch the line 13.",
        "tokens": [
          50682,
          49245,
          264,
          1622,
          3705,
          13,
          50734
        ]
      },
      {
        "avg_logprob": -0.32790724079260664,
        "compression_ratio": 1.417142857142857,
        "end": 6284.46,
        "id": 1956,
        "no_speech_prob": 0.000035912671592086554,
        "seek": 626806,
        "start": 6280.22,
        "temperature": 0,
        "text": " Cat is undefined.",
        "tokens": [
          50972,
          9565,
          307,
          674,
          5666,
          2001,
          13,
          51184
        ]
      },
      {
        "avg_logprob": -0.32790724079260664,
        "compression_ratio": 1.417142857142857,
        "end": 6288.9400000000005,
        "id": 1957,
        "no_speech_prob": 0.000035912671592086554,
        "seek": 626806,
        "start": 6284.46,
        "temperature": 0,
        "text": " And then there should be no more cat until I've got a cat.",
        "tokens": [
          51184,
          400,
          550,
          456,
          820,
          312,
          572,
          544,
          3857,
          1826,
          286,
          600,
          658,
          257,
          3857,
          13,
          51408
        ]
      },
      {
        "avg_logprob": -0.32790724079260664,
        "compression_ratio": 1.417142857142857,
        "end": 6289.580000000001,
        "id": 1958,
        "no_speech_prob": 0.000035912671592086554,
        "seek": 626806,
        "start": 6288.9400000000005,
        "temperature": 0,
        "text": " Try that again.",
        "tokens": [
          51408,
          6526,
          300,
          797,
          13,
          51440
        ]
      },
      {
        "avg_logprob": -0.32790724079260664,
        "compression_ratio": 1.417142857142857,
        "end": 6292.660000000001,
        "id": 1959,
        "no_speech_prob": 0.000035912671592086554,
        "seek": 626806,
        "start": 6292.06,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51564,
          821,
          321,
          352,
          13,
          51594
        ]
      },
      {
        "avg_logprob": -0.32790724079260664,
        "compression_ratio": 1.417142857142857,
        "end": 6293.820000000001,
        "id": 1960,
        "no_speech_prob": 0.000035912671592086554,
        "seek": 626806,
        "start": 6292.660000000001,
        "temperature": 0,
        "text": " I don't know what did wrong.",
        "tokens": [
          51594,
          286,
          500,
          380,
          458,
          437,
          630,
          2085,
          13,
          51652
        ]
      },
      {
        "avg_logprob": -0.32790724079260664,
        "compression_ratio": 1.417142857142857,
        "end": 6296.1,
        "id": 1961,
        "no_speech_prob": 0.000035912671592086554,
        "seek": 626806,
        "start": 6293.820000000001,
        "temperature": 0,
        "text": " Ooh.",
        "tokens": [
          51652,
          7951,
          13,
          51766
        ]
      },
      {
        "avg_logprob": -0.3247834205627441,
        "compression_ratio": 1.3358778625954197,
        "end": 6298.660000000001,
        "id": 1962,
        "no_speech_prob": 0.0004955346812494099,
        "seek": 629610,
        "start": 6296.1,
        "temperature": 0,
        "text": " It drew a bunch of them and then didn't get one.",
        "tokens": [
          50364,
          467,
          12804,
          257,
          3840,
          295,
          552,
          293,
          550,
          994,
          380,
          483,
          472,
          13,
          50492
        ]
      },
      {
        "avg_logprob": -0.3247834205627441,
        "compression_ratio": 1.3358778625954197,
        "end": 6299.620000000001,
        "id": 1963,
        "no_speech_prob": 0.0004955346812494099,
        "seek": 629610,
        "start": 6298.660000000001,
        "temperature": 0,
        "text": " Where is it breaking?",
        "tokens": [
          50492,
          2305,
          307,
          309,
          7697,
          30,
          50540
        ]
      },
      {
        "avg_logprob": -0.3247834205627441,
        "compression_ratio": 1.3358778625954197,
        "end": 6304.860000000001,
        "id": 1964,
        "no_speech_prob": 0.0004955346812494099,
        "seek": 629610,
        "start": 6302.900000000001,
        "temperature": 0,
        "text": " Is it like a sequencing thing?",
        "tokens": [
          50704,
          1119,
          309,
          411,
          257,
          32693,
          551,
          30,
          50802
        ]
      },
      {
        "avg_logprob": -0.3247834205627441,
        "compression_ratio": 1.3358778625954197,
        "end": 6311.3,
        "id": 1965,
        "no_speech_prob": 0.0004955346812494099,
        "seek": 629610,
        "start": 6309.780000000001,
        "temperature": 0,
        "text": " Like it's drew the cat.",
        "tokens": [
          51048,
          1743,
          309,
          311,
          12804,
          264,
          3857,
          13,
          51124
        ]
      },
      {
        "avg_logprob": -0.3247834205627441,
        "compression_ratio": 1.3358778625954197,
        "end": 6321.860000000001,
        "id": 1966,
        "no_speech_prob": 0.0004955346812494099,
        "seek": 629610,
        "start": 6317.34,
        "temperature": 0,
        "text": " Is it asking for a new cat?",
        "tokens": [
          51426,
          1119,
          309,
          3365,
          337,
          257,
          777,
          3857,
          30,
          51652
        ]
      },
      {
        "avg_logprob": -0.3247834205627441,
        "compression_ratio": 1.3358778625954197,
        "end": 6325.18,
        "id": 1967,
        "no_speech_prob": 0.0004955346812494099,
        "seek": 629610,
        "start": 6321.860000000001,
        "temperature": 0,
        "text": " Should I say no loop?",
        "tokens": [
          51652,
          6454,
          286,
          584,
          572,
          6367,
          30,
          51818
        ]
      },
      {
        "avg_logprob": -0.3636792500813802,
        "compression_ratio": 1.5,
        "end": 6330.26,
        "id": 1968,
        "no_speech_prob": 0.00003024190300493501,
        "seek": 632518,
        "start": 6325.18,
        "temperature": 0,
        "text": " And then when it gets a cat, say loop.",
        "tokens": [
          50364,
          400,
          550,
          562,
          309,
          2170,
          257,
          3857,
          11,
          584,
          6367,
          13,
          50618
        ]
      },
      {
        "avg_logprob": -0.3636792500813802,
        "compression_ratio": 1.5,
        "end": 6332.58,
        "id": 1969,
        "no_speech_prob": 0.00003024190300493501,
        "seek": 632518,
        "start": 6330.26,
        "temperature": 0,
        "text": " Oh, stroke index needs to be set to zero.",
        "tokens": [
          50618,
          876,
          11,
          12403,
          8186,
          2203,
          281,
          312,
          992,
          281,
          4018,
          13,
          50734
        ]
      },
      {
        "avg_logprob": -0.3636792500813802,
        "compression_ratio": 1.5,
        "end": 6333.34,
        "id": 1970,
        "no_speech_prob": 0.00003024190300493501,
        "seek": 632518,
        "start": 6332.58,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50734,
          2264,
          13,
          50772
        ]
      },
      {
        "avg_logprob": -0.3636792500813802,
        "compression_ratio": 1.5,
        "end": 6336.22,
        "id": 1971,
        "no_speech_prob": 0.00003024190300493501,
        "seek": 632518,
        "start": 6333.34,
        "temperature": 0,
        "text": " Thank you to the chat.",
        "tokens": [
          50772,
          1044,
          291,
          281,
          264,
          5081,
          13,
          50916
        ]
      },
      {
        "avg_logprob": -0.3636792500813802,
        "compression_ratio": 1.5,
        "end": 6338.860000000001,
        "id": 1972,
        "no_speech_prob": 0.00003024190300493501,
        "seek": 632518,
        "start": 6336.22,
        "temperature": 0,
        "text": " OK, hold on.",
        "tokens": [
          50916,
          2264,
          11,
          1797,
          322,
          13,
          51048
        ]
      },
      {
        "avg_logprob": -0.3636792500813802,
        "compression_ratio": 1.5,
        "end": 6340.34,
        "id": 1973,
        "no_speech_prob": 0.00003024190300493501,
        "seek": 632518,
        "start": 6338.860000000001,
        "temperature": 0,
        "text": " Matthew, you can edit out me trying",
        "tokens": [
          51048,
          6789,
          3322,
          86,
          11,
          291,
          393,
          8129,
          484,
          385,
          1382,
          51122
        ]
      },
      {
        "avg_logprob": -0.3636792500813802,
        "compression_ratio": 1.5,
        "end": 6341.68,
        "id": 1974,
        "no_speech_prob": 0.00003024190300493501,
        "seek": 632518,
        "start": 6340.34,
        "temperature": 0,
        "text": " to think about this for a minute.",
        "tokens": [
          51122,
          281,
          519,
          466,
          341,
          337,
          257,
          3456,
          13,
          51189
        ]
      },
      {
        "avg_logprob": -0.3636792500813802,
        "compression_ratio": 1.5,
        "end": 6350.18,
        "id": 1975,
        "no_speech_prob": 0.00003024190300493501,
        "seek": 632518,
        "start": 6345.860000000001,
        "temperature": 0,
        "text": " Thank you to BIMsoMe and Louise, both in the chat,",
        "tokens": [
          51398,
          1044,
          291,
          281,
          363,
          6324,
          539,
          12671,
          293,
          35962,
          11,
          1293,
          294,
          264,
          5081,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.3636792500813802,
        "compression_ratio": 1.5,
        "end": 6354.62,
        "id": 1976,
        "no_speech_prob": 0.00003024190300493501,
        "seek": 632518,
        "start": 6350.18,
        "temperature": 0,
        "text": " who just pointed out that my technique here is correct,",
        "tokens": [
          51614,
          567,
          445,
          10932,
          484,
          300,
          452,
          6532,
          510,
          307,
          3006,
          11,
          51836
        ]
      },
      {
        "avg_logprob": -0.25270960881159854,
        "compression_ratio": 1.7173913043478262,
        "end": 6358.5,
        "id": 1977,
        "no_speech_prob": 0.0000539105967618525,
        "seek": 635462,
        "start": 6354.62,
        "temperature": 0,
        "text": " but the issue is that I need to reset everything back to zero.",
        "tokens": [
          50364,
          457,
          264,
          2734,
          307,
          300,
          286,
          643,
          281,
          14322,
          1203,
          646,
          281,
          4018,
          13,
          50558
        ]
      },
      {
        "avg_logprob": -0.25270960881159854,
        "compression_ratio": 1.7173913043478262,
        "end": 6362.54,
        "id": 1978,
        "no_speech_prob": 0.0000539105967618525,
        "seek": 635462,
        "start": 6358.5,
        "temperature": 0,
        "text": " So here, I need to set stroke index back to zero.",
        "tokens": [
          50558,
          407,
          510,
          11,
          286,
          643,
          281,
          992,
          12403,
          8186,
          646,
          281,
          4018,
          13,
          50760
        ]
      },
      {
        "avg_logprob": -0.25270960881159854,
        "compression_ratio": 1.7173913043478262,
        "end": 6364.58,
        "id": 1979,
        "no_speech_prob": 0.0000539105967618525,
        "seek": 635462,
        "start": 6362.54,
        "temperature": 0,
        "text": " And I think index will already be zero.",
        "tokens": [
          50760,
          400,
          286,
          519,
          8186,
          486,
          1217,
          312,
          4018,
          13,
          50862
        ]
      },
      {
        "avg_logprob": -0.25270960881159854,
        "compression_ratio": 1.7173913043478262,
        "end": 6365.86,
        "id": 1980,
        "no_speech_prob": 0.0000539105967618525,
        "seek": 635462,
        "start": 6364.58,
        "temperature": 0,
        "text": " Yeah, index is already zero.",
        "tokens": [
          50862,
          865,
          11,
          8186,
          307,
          1217,
          4018,
          13,
          50926
        ]
      },
      {
        "avg_logprob": -0.25270960881159854,
        "compression_ratio": 1.7173913043478262,
        "end": 6368.36,
        "id": 1981,
        "no_speech_prob": 0.0000539105967618525,
        "seek": 635462,
        "start": 6365.86,
        "temperature": 0,
        "text": " So yes, that stroke index needs to go back to the beginning.",
        "tokens": [
          50926,
          407,
          2086,
          11,
          300,
          12403,
          8186,
          2203,
          281,
          352,
          646,
          281,
          264,
          2863,
          13,
          51051
        ]
      },
      {
        "avg_logprob": -0.25270960881159854,
        "compression_ratio": 1.7173913043478262,
        "end": 6373.18,
        "id": 1982,
        "no_speech_prob": 0.0000539105967618525,
        "seek": 635462,
        "start": 6368.36,
        "temperature": 0,
        "text": " And now I think we're ready to enjoy a whole bunch of cats.",
        "tokens": [
          51051,
          400,
          586,
          286,
          519,
          321,
          434,
          1919,
          281,
          2103,
          257,
          1379,
          3840,
          295,
          11111,
          13,
          51292
        ]
      },
      {
        "avg_logprob": -0.25270960881159854,
        "compression_ratio": 1.7173913043478262,
        "end": 6382.86,
        "id": 1983,
        "no_speech_prob": 0.0000539105967618525,
        "seek": 635462,
        "start": 6380.9,
        "temperature": 0,
        "text": " Cat drawings.",
        "tokens": [
          51678,
          9565,
          18618,
          13,
          51776
        ]
      },
      {
        "avg_logprob": -0.29481325344163545,
        "compression_ratio": 1.6695652173913043,
        "end": 6386.259999999999,
        "id": 1984,
        "no_speech_prob": 0.001674309722147882,
        "seek": 638286,
        "start": 6382.86,
        "temperature": 0,
        "text": " All right, thanks for watching this coding challenge",
        "tokens": [
          50364,
          1057,
          558,
          11,
          3231,
          337,
          1976,
          341,
          17720,
          3430,
          50534
        ]
      },
      {
        "avg_logprob": -0.29481325344163545,
        "compression_ratio": 1.6695652173913043,
        "end": 6388.46,
        "id": 1985,
        "no_speech_prob": 0.001674309722147882,
        "seek": 638286,
        "start": 6386.259999999999,
        "temperature": 0,
        "text": " with the Google Quick Draw data set.",
        "tokens": [
          50534,
          365,
          264,
          3329,
          12101,
          20386,
          1412,
          992,
          13,
          50644
        ]
      },
      {
        "avg_logprob": -0.29481325344163545,
        "compression_ratio": 1.6695652173913043,
        "end": 6399.38,
        "id": 1986,
        "no_speech_prob": 0.001674309722147882,
        "seek": 638286,
        "start": 6388.46,
        "temperature": 0,
        "text": " Stay tuned for a future video where I show how to create",
        "tokens": [
          50644,
          8691,
          10870,
          337,
          257,
          2027,
          960,
          689,
          286,
          855,
          577,
          281,
          1884,
          51190
        ]
      },
      {
        "avg_logprob": -0.29481325344163545,
        "compression_ratio": 1.6695652173913043,
        "end": 6402.38,
        "id": 1987,
        "no_speech_prob": 0.001674309722147882,
        "seek": 638286,
        "start": 6399.38,
        "temperature": 0,
        "text": " new drawings with the Sketch RNN model, the machine learning",
        "tokens": [
          51190,
          777,
          18618,
          365,
          264,
          49245,
          45702,
          45,
          2316,
          11,
          264,
          3479,
          2539,
          51340
        ]
      },
      {
        "avg_logprob": -0.29481325344163545,
        "compression_ratio": 1.6695652173913043,
        "end": 6404.339999999999,
        "id": 1988,
        "no_speech_prob": 0.001674309722147882,
        "seek": 638286,
        "start": 6402.38,
        "temperature": 0,
        "text": " model that was trained on these drawings.",
        "tokens": [
          51340,
          2316,
          300,
          390,
          8895,
          322,
          613,
          18618,
          13,
          51438
        ]
      },
      {
        "avg_logprob": -0.29481325344163545,
        "compression_ratio": 1.6695652173913043,
        "end": 6406.259999999999,
        "id": 1989,
        "no_speech_prob": 0.001674309722147882,
        "seek": 638286,
        "start": 6404.339999999999,
        "temperature": 0,
        "text": " And if this was one of your drawings,",
        "tokens": [
          51438,
          400,
          498,
          341,
          390,
          472,
          295,
          428,
          18618,
          11,
          51534
        ]
      },
      {
        "avg_logprob": -0.29481325344163545,
        "compression_ratio": 1.6695652173913043,
        "end": 6408.099999999999,
        "id": 1990,
        "no_speech_prob": 0.001674309722147882,
        "seek": 638286,
        "start": 6406.259999999999,
        "temperature": 0,
        "text": " thank you for making this beautiful cat.",
        "tokens": [
          51534,
          1309,
          291,
          337,
          1455,
          341,
          2238,
          3857,
          13,
          51626
        ]
      },
      {
        "avg_logprob": -0.29481325344163545,
        "compression_ratio": 1.6695652173913043,
        "end": 6410.0199999999995,
        "id": 1991,
        "no_speech_prob": 0.001674309722147882,
        "seek": 638286,
        "start": 6408.099999999999,
        "temperature": 0,
        "text": " And I'll see you in a future coding challenge.",
        "tokens": [
          51626,
          400,
          286,
          603,
          536,
          291,
          294,
          257,
          2027,
          17720,
          3430,
          13,
          51722
        ]
      },
      {
        "avg_logprob": -0.29481325344163545,
        "compression_ratio": 1.6695652173913043,
        "end": 6411.58,
        "id": 1992,
        "no_speech_prob": 0.001674309722147882,
        "seek": 638286,
        "start": 6410.0199999999995,
        "temperature": 0,
        "text": " Goodbye.",
        "tokens": [
          51722,
          15528,
          13,
          51800
        ]
      },
      {
        "avg_logprob": -2.5384398429624495,
        "compression_ratio": 1.3695652173913044,
        "end": 6416.44,
        "id": 1993,
        "no_speech_prob": 0.03209301084280014,
        "seek": 641286,
        "start": 6412.86,
        "temperature": 1,
        "text": " Muchacho for coming to my colon, chat.",
        "tokens": [
          50364,
          12313,
          608,
          78,
          337,
          1348,
          281,
          452,
          8255,
          11,
          5081,
          13,
          50543
        ]
      },
      {
        "avg_logprob": -2.5384398429624495,
        "compression_ratio": 1.3695652173913044,
        "end": 6419.0199999999995,
        "id": 1994,
        "no_speech_prob": 0.03209301084280014,
        "seek": 641286,
        "start": 6416.44,
        "temperature": 1,
        "text": " Thanks for watching the code challenge.",
        "tokens": [
          50543,
          2561,
          337,
          1976,
          264,
          3089,
          3430,
          13,
          50672
        ]
      },
      {
        "avg_logprob": -2.5384398429624495,
        "compression_ratio": 1.3695652173913044,
        "end": 6427,
        "id": 1995,
        "no_speech_prob": 0.03209301084280014,
        "seek": 641286,
        "start": 6419.0199999999995,
        "temperature": 1,
        "text": " And don't forget subscribe to the channel",
        "tokens": [
          50672,
          400,
          500,
          380,
          2870,
          3022,
          281,
          256,
          675,
          2269,
          51071
        ]
      },
      {
        "avg_logprob": -2.5384398429624495,
        "compression_ratio": 1.3695652173913044,
        "end": 6432.48,
        "id": 1996,
        "no_speech_prob": 0.03209301084280014,
        "seek": 641286,
        "start": 6427,
        "temperature": 1,
        "text": " and follow me on all the socials.",
        "tokens": [
          51071,
          293,
          1524,
          385,
          322,
          439,
          264,
          2093,
          82,
          13,
          51345
        ]
      },
      {
        "avg_logprob": -2.5384398429624495,
        "compression_ratio": 1.3695652173913044,
        "end": 6436.46,
        "id": 1997,
        "no_speech_prob": 0.03209301084280014,
        "seek": 641286,
        "start": 6434.96,
        "temperature": 1,
        "text": " This is, like, inensely satisfying",
        "tokens": [
          51469,
          639,
          741,
          82,
          11,
          287,
          1035,
          68,
          11,
          294,
          694,
          736,
          3227,
          4937,
          1840,
          51544
        ]
      },
      {
        "avg_logprob": -0.48656709988911945,
        "compression_ratio": 1.2672413793103448,
        "end": 6445.74,
        "id": 1998,
        "no_speech_prob": 0.002510750200599432,
        "seek": 643646,
        "start": 6436.46,
        "temperature": 0,
        "text": " Like, I could just watch this all day.",
        "tokens": [
          50364,
          1743,
          11,
          286,
          727,
          445,
          1159,
          341,
          439,
          786,
          13,
          50828
        ]
      },
      {
        "avg_logprob": -0.48656709988911945,
        "compression_ratio": 1.2672413793103448,
        "end": 6451.46,
        "id": 1999,
        "no_speech_prob": 0.002510750200599432,
        "seek": 643646,
        "start": 6449.9800000000005,
        "temperature": 0,
        "text": " Is it not finishing the drawings?",
        "tokens": [
          51040,
          1119,
          309,
          406,
          12693,
          264,
          18618,
          30,
          51114
        ]
      },
      {
        "avg_logprob": -0.48656709988911945,
        "compression_ratio": 1.2672413793103448,
        "end": 6459.7,
        "id": 2000,
        "no_speech_prob": 0.002510750200599432,
        "seek": 643646,
        "start": 6456.26,
        "temperature": 0,
        "text": " Well, I should give it a little, like, delay.",
        "tokens": [
          51354,
          1042,
          11,
          286,
          820,
          976,
          309,
          257,
          707,
          11,
          411,
          11,
          8577,
          13,
          51526
        ]
      },
      {
        "avg_logprob": -0.48656709988911945,
        "compression_ratio": 1.2672413793103448,
        "end": 6462.34,
        "id": 2001,
        "no_speech_prob": 0.002510750200599432,
        "seek": 643646,
        "start": 6459.7,
        "temperature": 0,
        "text": " Like, if I did set time out.",
        "tokens": [
          51526,
          1743,
          11,
          498,
          286,
          630,
          992,
          565,
          484,
          13,
          51658
        ]
      },
      {
        "avg_logprob": -0.7718600248679136,
        "compression_ratio": 1.125,
        "end": 6466.96,
        "id": 2002,
        "no_speech_prob": 0.0006162685458548367,
        "seek": 646646,
        "start": 6466.46,
        "temperature": 0,
        "text": " I should.",
        "tokens": [
          50364,
          286,
          820,
          13,
          50389
        ]
      },
      {
        "avg_logprob": -0.7718600248679136,
        "compression_ratio": 1.125,
        "end": 6475.2,
        "id": 2003,
        "no_speech_prob": 0.0006162685458548367,
        "seek": 646646,
        "start": 6472.96,
        "temperature": 0,
        "text": " Actually, let me just make a function called new cat.",
        "tokens": [
          50689,
          5135,
          11,
          718,
          385,
          445,
          652,
          257,
          2445,
          1219,
          777,
          3857,
          13,
          50801
        ]
      },
      {
        "avg_logprob": -0.7718600248679136,
        "compression_ratio": 1.125,
        "end": 6486.16,
        "id": 2004,
        "no_speech_prob": 0.0006162685458548367,
        "seek": 646646,
        "start": 6484.12,
        "temperature": 0,
        "text": " I don't know what music I just played.",
        "tokens": [
          51247,
          286,
          500,
          380,
          458,
          437,
          1318,
          286,
          445,
          3737,
          13,
          51349
        ]
      },
      {
        "avg_logprob": -0.7718600248679136,
        "compression_ratio": 1.125,
        "end": 6487.12,
        "id": 2005,
        "no_speech_prob": 0.0006162685458548367,
        "seek": 646646,
        "start": 6486.16,
        "temperature": 0,
        "text": " This is weird.",
        "tokens": [
          51349,
          639,
          307,
          3657,
          13,
          51397
        ]
      },
      {
        "avg_logprob": -0.5558271408081055,
        "compression_ratio": 1.1195652173913044,
        "end": 6497.24,
        "id": 2006,
        "no_speech_prob": 0.0008165084873326123,
        "seek": 648712,
        "start": 6487.94,
        "temperature": 0,
        "text": " So now let's take a look.",
        "tokens": [
          50405,
          407,
          586,
          718,
          311,
          747,
          257,
          574,
          13,
          50870
        ]
      },
      {
        "avg_logprob": -0.5558271408081055,
        "compression_ratio": 1.1195652173913044,
        "end": 6498.66,
        "id": 2007,
        "no_speech_prob": 0.0008165084873326123,
        "seek": 648712,
        "start": 6497.24,
        "temperature": 0,
        "text": " Now I just give it a little delay.",
        "tokens": [
          50870,
          823,
          286,
          445,
          976,
          309,
          257,
          707,
          8577,
          13,
          50941
        ]
      },
      {
        "avg_logprob": -0.5558271408081055,
        "compression_ratio": 1.1195652173913044,
        "end": 6505.68,
        "id": 2008,
        "no_speech_prob": 0.0008165084873326123,
        "seek": 648712,
        "start": 6505.04,
        "temperature": 0,
        "text": " What?",
        "tokens": [
          51260,
          708,
          30,
          51292
        ]
      },
      {
        "avg_logprob": -0.5558271408081055,
        "compression_ratio": 1.1195652173913044,
        "end": 6506.32,
        "id": 2009,
        "no_speech_prob": 0.0008165084873326123,
        "seek": 648712,
        "start": 6505.68,
        "temperature": 0,
        "text": " What?",
        "tokens": [
          51292,
          708,
          30,
          51324
        ]
      },
      {
        "avg_logprob": -0.5558271408081055,
        "compression_ratio": 1.1195652173913044,
        "end": 6508.36,
        "id": 2010,
        "no_speech_prob": 0.0008165084873326123,
        "seek": 648712,
        "start": 6506.32,
        "temperature": 0,
        "text": " What?",
        "tokens": [
          51324,
          708,
          30,
          51426
        ]
      },
      {
        "avg_logprob": -0.5558271408081055,
        "compression_ratio": 1.1195652173913044,
        "end": 6510.64,
        "id": 2011,
        "no_speech_prob": 0.0008165084873326123,
        "seek": 648712,
        "start": 6508.36,
        "temperature": 0,
        "text": " 38.",
        "tokens": [
          51426,
          12843,
          13,
          51540
        ]
      },
      {
        "avg_logprob": -0.5558271408081055,
        "compression_ratio": 1.1195652173913044,
        "end": 6513.76,
        "id": 2012,
        "no_speech_prob": 0.0008165084873326123,
        "seek": 648712,
        "start": 6510.64,
        "temperature": 0,
        "text": " Messed something up.",
        "tokens": [
          51540,
          9847,
          292,
          746,
          493,
          13,
          51696
        ]
      },
      {
        "avg_logprob": -0.5622316248276654,
        "compression_ratio": 1.0602409638554218,
        "end": 6517.76,
        "id": 2013,
        "no_speech_prob": 0.002216426655650139,
        "seek": 651376,
        "start": 6513.76,
        "temperature": 0,
        "text": " I messed something up with my, oh, yeah.",
        "tokens": [
          50364,
          286,
          16507,
          746,
          493,
          365,
          452,
          11,
          1954,
          11,
          1338,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.5622316248276654,
        "compression_ratio": 1.0602409638554218,
        "end": 6528.8,
        "id": 2014,
        "no_speech_prob": 0.002216426655650139,
        "seek": 651376,
        "start": 6527.280000000001,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51040,
          865,
          13,
          51116
        ]
      },
      {
        "avg_logprob": -0.5622316248276654,
        "compression_ratio": 1.0602409638554218,
        "end": 6530.280000000001,
        "id": 2015,
        "no_speech_prob": 0.002216426655650139,
        "seek": 651376,
        "start": 6528.8,
        "temperature": 0,
        "text": " I think that's right.",
        "tokens": [
          51116,
          286,
          519,
          300,
          311,
          558,
          13,
          51190
        ]
      },
      {
        "avg_logprob": -0.5622316248276654,
        "compression_ratio": 1.0602409638554218,
        "end": 6538.16,
        "id": 2016,
        "no_speech_prob": 0.002216426655650139,
        "seek": 651376,
        "start": 6537.2,
        "temperature": 0,
        "text": " Is it finishing it?",
        "tokens": [
          51536,
          1119,
          309,
          12693,
          309,
          30,
          51584
        ]
      },
      {
        "avg_logprob": -0.41927519077207986,
        "compression_ratio": 1.2040816326530612,
        "end": 6544.84,
        "id": 2017,
        "no_speech_prob": 0.00004331668606027961,
        "seek": 653816,
        "start": 6538.16,
        "temperature": 0,
        "text": " I think it's finishing the cat.",
        "tokens": [
          50364,
          286,
          519,
          309,
          311,
          12693,
          264,
          3857,
          13,
          50698
        ]
      },
      {
        "avg_logprob": -0.41927519077207986,
        "compression_ratio": 1.2040816326530612,
        "end": 6552.88,
        "id": 2018,
        "no_speech_prob": 0.00004331668606027961,
        "seek": 653816,
        "start": 6550.04,
        "temperature": 0,
        "text": " It does sort of seem like it's not doing the very last one,",
        "tokens": [
          50958,
          467,
          775,
          1333,
          295,
          1643,
          411,
          309,
          311,
          406,
          884,
          264,
          588,
          1036,
          472,
          11,
          51100
        ]
      },
      {
        "avg_logprob": -0.41927519077207986,
        "compression_ratio": 1.2040816326530612,
        "end": 6553.38,
        "id": 2019,
        "no_speech_prob": 0.00004331668606027961,
        "seek": 653816,
        "start": 6552.88,
        "temperature": 0,
        "text": " right?",
        "tokens": [
          51100,
          558,
          30,
          51125
        ]
      },
      {
        "avg_logprob": -0.41927519077207986,
        "compression_ratio": 1.2040816326530612,
        "end": 6565.5599999999995,
        "id": 2020,
        "no_speech_prob": 0.00004331668606027961,
        "seek": 653816,
        "start": 6564.76,
        "temperature": 0,
        "text": " Yeah, I don't know.",
        "tokens": [
          51694,
          865,
          11,
          286,
          500,
          380,
          458,
          13,
          51734
        ]
      },
      {
        "avg_logprob": -0.3461607635998335,
        "compression_ratio": 1.197080291970803,
        "end": 6569.84,
        "id": 2021,
        "no_speech_prob": 0.000017778153051040135,
        "seek": 656816,
        "start": 6568.5599999999995,
        "temperature": 0,
        "text": " That's way too long to wait.",
        "tokens": [
          50384,
          663,
          311,
          636,
          886,
          938,
          281,
          1699,
          13,
          50448
        ]
      },
      {
        "avg_logprob": -0.3461607635998335,
        "compression_ratio": 1.197080291970803,
        "end": 6579.04,
        "id": 2022,
        "no_speech_prob": 0.000017778153051040135,
        "seek": 656816,
        "start": 6577.28,
        "temperature": 0,
        "text": " People who draw it didn't finish it, yeah.",
        "tokens": [
          50820,
          3432,
          567,
          2642,
          309,
          994,
          380,
          2413,
          309,
          11,
          1338,
          13,
          50908
        ]
      },
      {
        "avg_logprob": -0.3461607635998335,
        "compression_ratio": 1.197080291970803,
        "end": 6589,
        "id": 2023,
        "no_speech_prob": 0.000017778153051040135,
        "seek": 656816,
        "start": 6588.16,
        "temperature": 0,
        "text": " All right, everybody.",
        "tokens": [
          51364,
          1057,
          558,
          11,
          2201,
          13,
          51406
        ]
      },
      {
        "avg_logprob": -0.3461607635998335,
        "compression_ratio": 1.197080291970803,
        "end": 6590.5199999999995,
        "id": 2024,
        "no_speech_prob": 0.000017778153051040135,
        "seek": 656816,
        "start": 6589,
        "temperature": 0,
        "text": " Now is it?",
        "tokens": [
          51406,
          823,
          307,
          309,
          30,
          51482
        ]
      },
      {
        "avg_logprob": -0.3461607635998335,
        "compression_ratio": 1.197080291970803,
        "end": 6592.12,
        "id": 2025,
        "no_speech_prob": 0.000017778153051040135,
        "seek": 656816,
        "start": 6590.5199999999995,
        "temperature": 0,
        "text": " It's not even 4 o'clock yet.",
        "tokens": [
          51482,
          467,
          311,
          406,
          754,
          1017,
          277,
          6,
          9023,
          1939,
          13,
          51562
        ]
      },
      {
        "avg_logprob": -0.3461607635998335,
        "compression_ratio": 1.197080291970803,
        "end": 6597.36,
        "id": 2026,
        "no_speech_prob": 0.000017778153051040135,
        "seek": 656816,
        "start": 6592.12,
        "temperature": 0,
        "text": " Do I dare, dare to sketch RNN?",
        "tokens": [
          51562,
          1144,
          286,
          8955,
          11,
          8955,
          281,
          12325,
          45702,
          45,
          30,
          51824
        ]
      },
      {
        "avg_logprob": -0.34010779473089403,
        "compression_ratio": 1.3096774193548386,
        "end": 6602.36,
        "id": 2027,
        "no_speech_prob": 0.000040694350900594145,
        "seek": 659816,
        "start": 6599.16,
        "temperature": 0,
        "text": " Oh, right, because the Google Quick Draw guessed it",
        "tokens": [
          50414,
          876,
          11,
          558,
          11,
          570,
          264,
          3329,
          12101,
          20386,
          21852,
          309,
          50574
        ]
      },
      {
        "avg_logprob": -0.34010779473089403,
        "compression_ratio": 1.3096774193548386,
        "end": 6603.76,
        "id": 2028,
        "no_speech_prob": 0.000040694350900594145,
        "seek": 659816,
        "start": 6602.36,
        "temperature": 0,
        "text": " before the person finished.",
        "tokens": [
          50574,
          949,
          264,
          954,
          4335,
          13,
          50644
        ]
      },
      {
        "avg_logprob": -0.34010779473089403,
        "compression_ratio": 1.3096774193548386,
        "end": 6605.08,
        "id": 2029,
        "no_speech_prob": 0.000040694350900594145,
        "seek": 659816,
        "start": 6603.76,
        "temperature": 0,
        "text": " That's interesting, yeah.",
        "tokens": [
          50644,
          663,
          311,
          1880,
          11,
          1338,
          13,
          50710
        ]
      },
      {
        "avg_logprob": -0.34010779473089403,
        "compression_ratio": 1.3096774193548386,
        "end": 6617.48,
        "id": 2030,
        "no_speech_prob": 0.000040694350900594145,
        "seek": 659816,
        "start": 6614.84,
        "temperature": 0,
        "text": " I think I might be done for today.",
        "tokens": [
          51198,
          286,
          519,
          286,
          1062,
          312,
          1096,
          337,
          965,
          13,
          51330
        ]
      },
      {
        "avg_logprob": -0.34010779473089403,
        "compression_ratio": 1.3096774193548386,
        "end": 6624.32,
        "id": 2031,
        "no_speech_prob": 0.000040694350900594145,
        "seek": 659816,
        "start": 6620.08,
        "temperature": 0,
        "text": " Did I do what I said I was going to do?",
        "tokens": [
          51460,
          2589,
          286,
          360,
          437,
          286,
          848,
          286,
          390,
          516,
          281,
          360,
          30,
          51672
        ]
      },
      {
        "avg_logprob": -0.34010779473089403,
        "compression_ratio": 1.3096774193548386,
        "end": 6625.28,
        "id": 2032,
        "no_speech_prob": 0.000040694350900594145,
        "seek": 659816,
        "start": 6624.32,
        "temperature": 0,
        "text": " Let me just look here.",
        "tokens": [
          51672,
          961,
          385,
          445,
          574,
          510,
          13,
          51720
        ]
      },
      {
        "avg_logprob": -0.6947259902954102,
        "compression_ratio": 1.03125,
        "end": 6628.66,
        "id": 2033,
        "no_speech_prob": 0.31357645988464355,
        "seek": 662816,
        "start": 6628.16,
        "temperature": 0,
        "text": " Mm.",
        "tokens": [
          50364,
          8266,
          13,
          50389
        ]
      },
      {
        "avg_logprob": -0.6947259902954102,
        "compression_ratio": 1.03125,
        "end": 6632.66,
        "id": 2034,
        "no_speech_prob": 0.31357645988464355,
        "seek": 662816,
        "start": 6632.16,
        "temperature": 0,
        "text": " Mm.",
        "tokens": [
          50564,
          8266,
          13,
          50589
        ]
      },
      {
        "avg_logprob": -0.6947259902954102,
        "compression_ratio": 1.03125,
        "end": 6636.66,
        "id": 2035,
        "no_speech_prob": 0.31357645988464355,
        "seek": 662816,
        "start": 6636.16,
        "temperature": 0,
        "text": " Mm.",
        "tokens": [
          50764,
          8266,
          13,
          50789
        ]
      },
      {
        "avg_logprob": -0.6947259902954102,
        "compression_ratio": 1.03125,
        "end": 6654.639999999999,
        "id": 2036,
        "no_speech_prob": 0.31357645988464355,
        "seek": 662816,
        "start": 6653.16,
        "temperature": 0,
        "text": " Mm.",
        "tokens": [
          51614,
          8266,
          13,
          51688
        ]
      },
      {
        "avg_logprob": -0.6947259902954102,
        "compression_ratio": 1.03125,
        "end": 6657.04,
        "id": 2037,
        "no_speech_prob": 0.31357645988464355,
        "seek": 662816,
        "start": 6654.639999999999,
        "temperature": 0,
        "text": " Sorry, I'm looking here to think about sketch RNN.",
        "tokens": [
          51688,
          4919,
          11,
          286,
          478,
          1237,
          510,
          281,
          519,
          466,
          12325,
          45702,
          45,
          13,
          51808
        ]
      },
      {
        "avg_logprob": -0.2606696319580078,
        "compression_ratio": 1.4088050314465408,
        "end": 6658.66,
        "id": 2038,
        "no_speech_prob": 0.0000017603337028049282,
        "seek": 665816,
        "start": 6658.16,
        "temperature": 0,
        "text": " Mm.",
        "tokens": [
          50364,
          8266,
          13,
          50389
        ]
      },
      {
        "avg_logprob": -0.2606696319580078,
        "compression_ratio": 1.4088050314465408,
        "end": 6669.32,
        "id": 2039,
        "no_speech_prob": 0.0000017603337028049282,
        "seek": 665816,
        "start": 6662.4,
        "temperature": 0,
        "text": " So people are, this, by the way, is not sketch RNN.",
        "tokens": [
          50576,
          407,
          561,
          366,
          11,
          341,
          11,
          538,
          264,
          636,
          11,
          307,
          406,
          12325,
          45702,
          45,
          13,
          50922
        ]
      },
      {
        "avg_logprob": -0.2606696319580078,
        "compression_ratio": 1.4088050314465408,
        "end": 6672.88,
        "id": 2040,
        "no_speech_prob": 0.0000017603337028049282,
        "seek": 665816,
        "start": 6669.32,
        "temperature": 0,
        "text": " Just to be clear, these are the actual drawings, not",
        "tokens": [
          50922,
          1449,
          281,
          312,
          1850,
          11,
          613,
          366,
          264,
          3539,
          18618,
          11,
          406,
          51100
        ]
      },
      {
        "avg_logprob": -0.2606696319580078,
        "compression_ratio": 1.4088050314465408,
        "end": 6674.68,
        "id": 2041,
        "no_speech_prob": 0.0000017603337028049282,
        "seek": 665816,
        "start": 6672.88,
        "temperature": 0,
        "text": " the imagined drawings.",
        "tokens": [
          51100,
          264,
          16590,
          18618,
          13,
          51190
        ]
      },
      {
        "avg_logprob": -0.2606696319580078,
        "compression_ratio": 1.4088050314465408,
        "end": 6679.12,
        "id": 2042,
        "no_speech_prob": 0.0000017603337028049282,
        "seek": 665816,
        "start": 6674.68,
        "temperature": 0,
        "text": " I feel like I think I'm done for today.",
        "tokens": [
          51190,
          286,
          841,
          411,
          286,
          519,
          286,
          478,
          1096,
          337,
          965,
          13,
          51412
        ]
      },
      {
        "avg_logprob": -0.2606696319580078,
        "compression_ratio": 1.4088050314465408,
        "end": 6680.5199999999995,
        "id": 2043,
        "no_speech_prob": 0.0000017603337028049282,
        "seek": 665816,
        "start": 6679.12,
        "temperature": 0,
        "text": " What did I make today?",
        "tokens": [
          51412,
          708,
          630,
          286,
          652,
          965,
          30,
          51482
        ]
      },
      {
        "avg_logprob": -0.2606696319580078,
        "compression_ratio": 1.4088050314465408,
        "end": 6684.5199999999995,
        "id": 2044,
        "no_speech_prob": 0.0000017603337028049282,
        "seek": 665816,
        "start": 6680.5199999999995,
        "temperature": 0,
        "text": " I got the logo part two done.",
        "tokens": [
          51482,
          286,
          658,
          264,
          9699,
          644,
          732,
          1096,
          13,
          51682
        ]
      },
      {
        "avg_logprob": -0.2971067930522718,
        "compression_ratio": 1.3823529411764706,
        "end": 6696.68,
        "id": 2045,
        "no_speech_prob": 0.0005792599404230714,
        "seek": 668452,
        "start": 6684.52,
        "temperature": 0,
        "text": " I got the, I got the, sorry, logo part two, the ML5 save",
        "tokens": [
          50364,
          286,
          658,
          264,
          11,
          286,
          658,
          264,
          11,
          2597,
          11,
          9699,
          644,
          732,
          11,
          264,
          21601,
          20,
          3155,
          50972
        ]
      },
      {
        "avg_logprob": -0.2971067930522718,
        "compression_ratio": 1.3823529411764706,
        "end": 6699.040000000001,
        "id": 2046,
        "no_speech_prob": 0.0005792599404230714,
        "seek": 668452,
        "start": 6696.68,
        "temperature": 0,
        "text": " model, and the Quick Draw stuff.",
        "tokens": [
          50972,
          2316,
          11,
          293,
          264,
          12101,
          20386,
          1507,
          13,
          51090
        ]
      },
      {
        "avg_logprob": -0.2971067930522718,
        "compression_ratio": 1.3823529411764706,
        "end": 6702.040000000001,
        "id": 2047,
        "no_speech_prob": 0.0005792599404230714,
        "seek": 668452,
        "start": 6699.040000000001,
        "temperature": 0,
        "text": " I think I want to wait till sketch RNN is",
        "tokens": [
          51090,
          286,
          519,
          286,
          528,
          281,
          1699,
          4288,
          12325,
          45702,
          45,
          307,
          51240
        ]
      },
      {
        "avg_logprob": -0.2971067930522718,
        "compression_ratio": 1.3823529411764706,
        "end": 6705.080000000001,
        "id": 2048,
        "no_speech_prob": 0.0005792599404230714,
        "seek": 668452,
        "start": 6702.040000000001,
        "temperature": 0,
        "text": " within the documentation of ML5.",
        "tokens": [
          51240,
          1951,
          264,
          14333,
          295,
          21601,
          20,
          13,
          51392
        ]
      },
      {
        "avg_logprob": -0.2971067930522718,
        "compression_ratio": 1.3823529411764706,
        "end": 6706.92,
        "id": 2049,
        "no_speech_prob": 0.0005792599404230714,
        "seek": 668452,
        "start": 6705.080000000001,
        "temperature": 0,
        "text": " So I will come back and do that another time.",
        "tokens": [
          51392,
          407,
          286,
          486,
          808,
          646,
          293,
          360,
          300,
          1071,
          565,
          13,
          51484
        ]
      },
      {
        "avg_logprob": -0.2971067930522718,
        "compression_ratio": 1.3823529411764706,
        "end": 6710.120000000001,
        "id": 2050,
        "no_speech_prob": 0.0005792599404230714,
        "seek": 668452,
        "start": 6706.92,
        "temperature": 0,
        "text": " Plus, I feel like, yeah.",
        "tokens": [
          51484,
          7721,
          11,
          286,
          841,
          411,
          11,
          1338,
          13,
          51644
        ]
      },
      {
        "avg_logprob": -0.3157111576625279,
        "compression_ratio": 1.3680555555555556,
        "end": 6716.200000000001,
        "id": 2051,
        "no_speech_prob": 0.0005703120841644704,
        "seek": 671452,
        "start": 6714.96,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50386,
          1057,
          558,
          13,
          50448
        ]
      },
      {
        "avg_logprob": -0.3157111576625279,
        "compression_ratio": 1.3680555555555556,
        "end": 6717.68,
        "id": 2052,
        "no_speech_prob": 0.0005703120841644704,
        "seek": 671452,
        "start": 6716.200000000001,
        "temperature": 0,
        "text": " I could watch this all day.",
        "tokens": [
          50448,
          286,
          727,
          1159,
          341,
          439,
          786,
          13,
          50522
        ]
      },
      {
        "avg_logprob": -0.3157111576625279,
        "compression_ratio": 1.3680555555555556,
        "end": 6723.64,
        "id": 2053,
        "no_speech_prob": 0.0005703120841644704,
        "seek": 671452,
        "start": 6720.64,
        "temperature": 0,
        "text": " Let me make sure it's actually doing the last bit.",
        "tokens": [
          50670,
          961,
          385,
          652,
          988,
          309,
          311,
          767,
          884,
          264,
          1036,
          857,
          13,
          50820
        ]
      },
      {
        "avg_logprob": -0.3157111576625279,
        "compression_ratio": 1.3680555555555556,
        "end": 6724.64,
        "id": 2054,
        "no_speech_prob": 0.0005703120841644704,
        "seek": 671452,
        "start": 6723.64,
        "temperature": 0,
        "text": " Let's think about this.",
        "tokens": [
          50820,
          961,
          311,
          519,
          466,
          341,
          13,
          50870
        ]
      },
      {
        "avg_logprob": -0.3157111576625279,
        "compression_ratio": 1.3680555555555556,
        "end": 6736.8,
        "id": 2055,
        "no_speech_prob": 0.0005703120841644704,
        "seek": 671452,
        "start": 6730.4400000000005,
        "temperature": 0,
        "text": " If stroke index equals cat.length,",
        "tokens": [
          51160,
          759,
          12403,
          8186,
          6915,
          3857,
          13,
          45390,
          11,
          51478
        ]
      },
      {
        "avg_logprob": -0.3157111576625279,
        "compression_ratio": 1.3680555555555556,
        "end": 6740.080000000001,
        "id": 2056,
        "no_speech_prob": 0.0005703120841644704,
        "seek": 671452,
        "start": 6736.8,
        "temperature": 0,
        "text": " yeah, this has to have done the last one, right?",
        "tokens": [
          51478,
          1338,
          11,
          341,
          575,
          281,
          362,
          1096,
          264,
          1036,
          472,
          11,
          558,
          30,
          51642
        ]
      },
      {
        "avg_logprob": -0.3314334324428013,
        "compression_ratio": 1.2962962962962963,
        "end": 6748.5599999999995,
        "id": 2057,
        "no_speech_prob": 0.0000388309417758137,
        "seek": 674008,
        "start": 6740.08,
        "temperature": 0,
        "text": " So let's not do this for a second.",
        "tokens": [
          50364,
          407,
          718,
          311,
          406,
          360,
          341,
          337,
          257,
          1150,
          13,
          50788
        ]
      },
      {
        "avg_logprob": -0.3314334324428013,
        "compression_ratio": 1.2962962962962963,
        "end": 6750.16,
        "id": 2058,
        "no_speech_prob": 0.0000388309417758137,
        "seek": 674008,
        "start": 6748.5599999999995,
        "temperature": 0,
        "text": " And let's console log.",
        "tokens": [
          50788,
          400,
          718,
          311,
          11076,
          3565,
          13,
          50868
        ]
      },
      {
        "avg_logprob": -0.3314334324428013,
        "compression_ratio": 1.2962962962962963,
        "end": 6767.04,
        "id": 2059,
        "no_speech_prob": 0.0000388309417758137,
        "seek": 674008,
        "start": 6761.32,
        "temperature": 0,
        "text": " Yeah, it's greater than, I think it's doing all of them.",
        "tokens": [
          51426,
          865,
          11,
          309,
          311,
          5044,
          813,
          11,
          286,
          519,
          309,
          311,
          884,
          439,
          295,
          552,
          13,
          51712
        ]
      },
      {
        "avg_logprob": -0.3314334324428013,
        "compression_ratio": 1.2962962962962963,
        "end": 6768.72,
        "id": 2060,
        "no_speech_prob": 0.0000388309417758137,
        "seek": 674008,
        "start": 6767.04,
        "temperature": 0,
        "text": " I'm looking at this code.",
        "tokens": [
          51712,
          286,
          478,
          1237,
          412,
          341,
          3089,
          13,
          51796
        ]
      },
      {
        "avg_logprob": -0.3429345299215878,
        "compression_ratio": 1.52,
        "end": 6772.16,
        "id": 2061,
        "no_speech_prob": 0.0000066434272412152495,
        "seek": 676872,
        "start": 6768.76,
        "temperature": 0,
        "text": " It wouldn't be skipping one, because this is an index",
        "tokens": [
          50366,
          467,
          2759,
          380,
          312,
          31533,
          472,
          11,
          570,
          341,
          307,
          364,
          8186,
          50536
        ]
      },
      {
        "avg_logprob": -0.3429345299215878,
        "compression_ratio": 1.52,
        "end": 6776.320000000001,
        "id": 2062,
        "no_speech_prob": 0.0000066434272412152495,
        "seek": 676872,
        "start": 6772.16,
        "temperature": 0,
        "text": " is invalid here, and then it goes up.",
        "tokens": [
          50536,
          307,
          34702,
          510,
          11,
          293,
          550,
          309,
          1709,
          493,
          13,
          50744
        ]
      },
      {
        "avg_logprob": -0.3429345299215878,
        "compression_ratio": 1.52,
        "end": 6779,
        "id": 2063,
        "no_speech_prob": 0.0000066434272412152495,
        "seek": 676872,
        "start": 6776.320000000001,
        "temperature": 0,
        "text": " It resets index to zero.",
        "tokens": [
          50744,
          467,
          725,
          1385,
          8186,
          281,
          4018,
          13,
          50878
        ]
      },
      {
        "avg_logprob": -0.3429345299215878,
        "compression_ratio": 1.52,
        "end": 6782.16,
        "id": 2064,
        "no_speech_prob": 0.0000066434272412152495,
        "seek": 676872,
        "start": 6779,
        "temperature": 0,
        "text": " It loops back around and starts over.",
        "tokens": [
          50878,
          467,
          16121,
          646,
          926,
          293,
          3719,
          670,
          13,
          51036
        ]
      },
      {
        "avg_logprob": -0.3429345299215878,
        "compression_ratio": 1.52,
        "end": 6785.240000000001,
        "id": 2065,
        "no_speech_prob": 0.0000066434272412152495,
        "seek": 676872,
        "start": 6782.16,
        "temperature": 0,
        "text": " Yeah, it's got to have gotten the last one.",
        "tokens": [
          51036,
          865,
          11,
          309,
          311,
          658,
          281,
          362,
          5768,
          264,
          1036,
          472,
          13,
          51190
        ]
      },
      {
        "avg_logprob": -0.3429345299215878,
        "compression_ratio": 1.52,
        "end": 6786.64,
        "id": 2066,
        "no_speech_prob": 0.0000066434272412152495,
        "seek": 676872,
        "start": 6785.240000000001,
        "temperature": 0,
        "text": " Just try going one further.",
        "tokens": [
          51190,
          1449,
          853,
          516,
          472,
          3052,
          13,
          51260
        ]
      },
      {
        "avg_logprob": -0.3429345299215878,
        "compression_ratio": 1.52,
        "end": 6788.84,
        "id": 2067,
        "no_speech_prob": 0.0000066434272412152495,
        "seek": 676872,
        "start": 6786.64,
        "temperature": 0,
        "text": " It'll break, and you'll be right.",
        "tokens": [
          51260,
          467,
          603,
          1821,
          11,
          293,
          291,
          603,
          312,
          558,
          13,
          51370
        ]
      },
      {
        "avg_logprob": -0.3429345299215878,
        "compression_ratio": 1.52,
        "end": 6789.34,
        "id": 2068,
        "no_speech_prob": 0.0000066434272412152495,
        "seek": 676872,
        "start": 6788.84,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51370,
          865,
          13,
          51395
        ]
      },
      {
        "avg_logprob": -0.5773594975471497,
        "compression_ratio": 0.9493670886075949,
        "end": 6790.84,
        "id": 2069,
        "no_speech_prob": 0.0005614643450826406,
        "seek": 678934,
        "start": 6790.34,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          50414,
          865,
          13,
          50439
        ]
      },
      {
        "avg_logprob": -0.5773594975471497,
        "compression_ratio": 0.9493670886075949,
        "end": 6799.5,
        "id": 2070,
        "no_speech_prob": 0.0005614643450826406,
        "seek": 678934,
        "start": 6793.9400000000005,
        "temperature": 0,
        "text": " I mean, I could say, or something.",
        "tokens": [
          50594,
          286,
          914,
          11,
          286,
          727,
          584,
          11,
          420,
          746,
          13,
          50872
        ]
      },
      {
        "avg_logprob": -0.5773594975471497,
        "compression_ratio": 0.9493670886075949,
        "end": 6808.900000000001,
        "id": 2071,
        "no_speech_prob": 0.0005614643450826406,
        "seek": 678934,
        "start": 6806.9400000000005,
        "temperature": 0,
        "text": " Yeah, it broke.",
        "tokens": [
          51244,
          865,
          11,
          309,
          6902,
          13,
          51342
        ]
      },
      {
        "avg_logprob": -0.5773594975471497,
        "compression_ratio": 0.9493670886075949,
        "end": 6810.26,
        "id": 2072,
        "no_speech_prob": 0.0005614643450826406,
        "seek": 678934,
        "start": 6808.900000000001,
        "temperature": 0,
        "text": " Sketch.js line 18.",
        "tokens": [
          51342,
          49245,
          13,
          25530,
          1622,
          2443,
          13,
          51410
        ]
      },
      {
        "avg_logprob": -0.3843738644622093,
        "compression_ratio": 1.1346153846153846,
        "end": 6820.4400000000005,
        "id": 2073,
        "no_speech_prob": 0.00006709163426421583,
        "seek": 681934,
        "start": 6819.9400000000005,
        "temperature": 0,
        "text": " Broke.",
        "tokens": [
          50394,
          5425,
          330,
          13,
          50419
        ]
      },
      {
        "avg_logprob": -0.3843738644622093,
        "compression_ratio": 1.1346153846153846,
        "end": 6830.1,
        "id": 2074,
        "no_speech_prob": 0.00006709163426421583,
        "seek": 681934,
        "start": 6828.18,
        "temperature": 0,
        "text": " Interesting.",
        "tokens": [
          50806,
          14711,
          13,
          50902
        ]
      },
      {
        "avg_logprob": -0.3843738644622093,
        "compression_ratio": 1.1346153846153846,
        "end": 6837.3,
        "id": 2075,
        "no_speech_prob": 0.00006709163426421583,
        "seek": 681934,
        "start": 6830.1,
        "temperature": 0,
        "text": " So I think maybe it was not getting the very last one",
        "tokens": [
          50902,
          407,
          286,
          519,
          1310,
          309,
          390,
          406,
          1242,
          264,
          588,
          1036,
          472,
          51262
        ]
      },
      {
        "avg_logprob": -0.3843738644622093,
        "compression_ratio": 1.1346153846153846,
        "end": 6840.34,
        "id": 2076,
        "no_speech_prob": 0.00006709163426421583,
        "seek": 681934,
        "start": 6837.3,
        "temperature": 0,
        "text": " of each stroke.",
        "tokens": [
          51262,
          295,
          1184,
          12403,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.3843738644622093,
        "compression_ratio": 1.1346153846153846,
        "end": 6842.3,
        "id": 2077,
        "no_speech_prob": 0.00006709163426421583,
        "seek": 681934,
        "start": 6840.34,
        "temperature": 0,
        "text": " Why is that?",
        "tokens": [
          51414,
          1545,
          307,
          300,
          30,
          51512
        ]
      },
      {
        "avg_logprob": -0.3843738644622093,
        "compression_ratio": 1.1346153846153846,
        "end": 6843.38,
        "id": 2078,
        "no_speech_prob": 0.00006709163426421583,
        "seek": 681934,
        "start": 6842.3,
        "temperature": 0,
        "text": " It's crazy cat.",
        "tokens": [
          51512,
          467,
          311,
          3219,
          3857,
          13,
          51566
        ]
      },
      {
        "avg_logprob": -0.4168152889962924,
        "compression_ratio": 1.3095238095238095,
        "end": 6849.84,
        "id": 2079,
        "no_speech_prob": 0.000029773053029202856,
        "seek": 684934,
        "start": 6849.34,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          50364,
          865,
          13,
          50389
        ]
      },
      {
        "avg_logprob": -0.4168152889962924,
        "compression_ratio": 1.3095238095238095,
        "end": 6853.860000000001,
        "id": 2080,
        "no_speech_prob": 0.000029773053029202856,
        "seek": 684934,
        "start": 6852.7,
        "temperature": 0,
        "text": " Length plus one.",
        "tokens": [
          50532,
          441,
          4206,
          1804,
          472,
          13,
          50590
        ]
      },
      {
        "avg_logprob": -0.4168152889962924,
        "compression_ratio": 1.3095238095238095,
        "end": 6858.18,
        "id": 2081,
        "no_speech_prob": 0.000029773053029202856,
        "seek": 684934,
        "start": 6856.9400000000005,
        "temperature": 0,
        "text": " Index goes up.",
        "tokens": [
          50744,
          33552,
          1709,
          493,
          13,
          50806
        ]
      },
      {
        "avg_logprob": -0.4168152889962924,
        "compression_ratio": 1.3095238095238095,
        "end": 6869.62,
        "id": 2082,
        "no_speech_prob": 0.000029773053029202856,
        "seek": 684934,
        "start": 6861.58,
        "temperature": 0,
        "text": " Oh, because I'm pulling it here, and then index goes up by one.",
        "tokens": [
          50976,
          876,
          11,
          570,
          286,
          478,
          8407,
          309,
          510,
          11,
          293,
          550,
          8186,
          1709,
          493,
          538,
          472,
          13,
          51378
        ]
      },
      {
        "avg_logprob": -0.4168152889962924,
        "compression_ratio": 1.3095238095238095,
        "end": 6870.58,
        "id": 2083,
        "no_speech_prob": 0.000029773053029202856,
        "seek": 684934,
        "start": 6869.62,
        "temperature": 0,
        "text": " That doesn't make sense.",
        "tokens": [
          51378,
          663,
          1177,
          380,
          652,
          2020,
          13,
          51426
        ]
      },
      {
        "avg_logprob": -0.4168152889962924,
        "compression_ratio": 1.3095238095238095,
        "end": 6875.66,
        "id": 2084,
        "no_speech_prob": 0.000029773053029202856,
        "seek": 684934,
        "start": 6874.66,
        "temperature": 0,
        "text": " I'm so confused.",
        "tokens": [
          51630,
          286,
          478,
          370,
          9019,
          13,
          51680
        ]
      },
      {
        "avg_logprob": -0.4168152889962924,
        "compression_ratio": 1.3095238095238095,
        "end": 6877.02,
        "id": 2085,
        "no_speech_prob": 0.000029773053029202856,
        "seek": 684934,
        "start": 6875.66,
        "temperature": 0,
        "text": " My brain is confused.",
        "tokens": [
          51680,
          1222,
          3567,
          307,
          9019,
          13,
          51748
        ]
      },
      {
        "avg_logprob": -0.24800269485365414,
        "compression_ratio": 1.676595744680851,
        "end": 6880.9800000000005,
        "id": 2086,
        "no_speech_prob": 0.00003373714935150929,
        "seek": 687934,
        "start": 6879.58,
        "temperature": 0,
        "text": " May I am so me is typing.",
        "tokens": [
          50376,
          1891,
          286,
          669,
          370,
          385,
          307,
          18444,
          13,
          50446
        ]
      },
      {
        "avg_logprob": -0.24800269485365414,
        "compression_ratio": 1.676595744680851,
        "end": 6883.3,
        "id": 2087,
        "no_speech_prob": 0.00003373714935150929,
        "seek": 687934,
        "start": 6880.9800000000005,
        "temperature": 0,
        "text": " This means the answer is about to come through.",
        "tokens": [
          50446,
          639,
          1355,
          264,
          1867,
          307,
          466,
          281,
          808,
          807,
          13,
          50562
        ]
      },
      {
        "avg_logprob": -0.24800269485365414,
        "compression_ratio": 1.676595744680851,
        "end": 6885.78,
        "id": 2088,
        "no_speech_prob": 0.00003373714935150929,
        "seek": 687934,
        "start": 6883.3,
        "temperature": 0,
        "text": " The last index won't error.",
        "tokens": [
          50562,
          440,
          1036,
          8186,
          1582,
          380,
          6713,
          13,
          50686
        ]
      },
      {
        "avg_logprob": -0.24800269485365414,
        "compression_ratio": 1.676595744680851,
        "end": 6886.78,
        "id": 2089,
        "no_speech_prob": 0.00003373714935150929,
        "seek": 687934,
        "start": 6885.78,
        "temperature": 0,
        "text": " It won't error.",
        "tokens": [
          50686,
          467,
          1582,
          380,
          6713,
          13,
          50736
        ]
      },
      {
        "avg_logprob": -0.24800269485365414,
        "compression_ratio": 1.676595744680851,
        "end": 6888.38,
        "id": 2090,
        "no_speech_prob": 0.00003373714935150929,
        "seek": 687934,
        "start": 6886.78,
        "temperature": 0,
        "text": " It's just going to be undefined.",
        "tokens": [
          50736,
          467,
          311,
          445,
          516,
          281,
          312,
          674,
          5666,
          2001,
          13,
          50816
        ]
      },
      {
        "avg_logprob": -0.24800269485365414,
        "compression_ratio": 1.676595744680851,
        "end": 6889.38,
        "id": 2091,
        "no_speech_prob": 0.00003373714935150929,
        "seek": 687934,
        "start": 6888.38,
        "temperature": 0,
        "text": " So I'm good.",
        "tokens": [
          50816,
          407,
          286,
          478,
          665,
          13,
          50866
        ]
      },
      {
        "avg_logprob": -0.24800269485365414,
        "compression_ratio": 1.676595744680851,
        "end": 6891.78,
        "id": 2092,
        "no_speech_prob": 0.00003373714935150929,
        "seek": 687934,
        "start": 6889.38,
        "temperature": 0,
        "text": " It's the same.",
        "tokens": [
          50866,
          467,
          311,
          264,
          912,
          13,
          50986
        ]
      },
      {
        "avg_logprob": -0.24800269485365414,
        "compression_ratio": 1.676595744680851,
        "end": 6892.9800000000005,
        "id": 2093,
        "no_speech_prob": 0.00003373714935150929,
        "seek": 687934,
        "start": 6891.78,
        "temperature": 0,
        "text": " It'll just be undefined.",
        "tokens": [
          50986,
          467,
          603,
          445,
          312,
          674,
          5666,
          2001,
          13,
          51046
        ]
      },
      {
        "avg_logprob": -0.24800269485365414,
        "compression_ratio": 1.676595744680851,
        "end": 6893.900000000001,
        "id": 2094,
        "no_speech_prob": 0.00003373714935150929,
        "seek": 687934,
        "start": 6892.9800000000005,
        "temperature": 0,
        "text": " All right, we're good.",
        "tokens": [
          51046,
          1057,
          558,
          11,
          321,
          434,
          665,
          13,
          51092
        ]
      },
      {
        "avg_logprob": -0.24800269485365414,
        "compression_ratio": 1.676595744680851,
        "end": 6894.82,
        "id": 2095,
        "no_speech_prob": 0.00003373714935150929,
        "seek": 687934,
        "start": 6893.900000000001,
        "temperature": 0,
        "text": " We're good, everybody.",
        "tokens": [
          51092,
          492,
          434,
          665,
          11,
          2201,
          13,
          51138
        ]
      },
      {
        "avg_logprob": -0.24800269485365414,
        "compression_ratio": 1.676595744680851,
        "end": 6898.78,
        "id": 2096,
        "no_speech_prob": 0.00003373714935150929,
        "seek": 687934,
        "start": 6894.82,
        "temperature": 0,
        "text": " My mental math is still correct.",
        "tokens": [
          51138,
          1222,
          4973,
          5221,
          307,
          920,
          3006,
          13,
          51336
        ]
      },
      {
        "avg_logprob": -0.24800269485365414,
        "compression_ratio": 1.676595744680851,
        "end": 6900.1,
        "id": 2097,
        "no_speech_prob": 0.00003373714935150929,
        "seek": 687934,
        "start": 6898.78,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51336,
          1057,
          558,
          13,
          51402
        ]
      },
      {
        "avg_logprob": -0.24800269485365414,
        "compression_ratio": 1.676595744680851,
        "end": 6900.9800000000005,
        "id": 2098,
        "no_speech_prob": 0.00003373714935150929,
        "seek": 687934,
        "start": 6900.1,
        "temperature": 0,
        "text": " Thank you, everybody.",
        "tokens": [
          51402,
          1044,
          291,
          11,
          2201,
          13,
          51446
        ]
      },
      {
        "avg_logprob": -0.24800269485365414,
        "compression_ratio": 1.676595744680851,
        "end": 6902.22,
        "id": 2099,
        "no_speech_prob": 0.00003373714935150929,
        "seek": 687934,
        "start": 6900.9800000000005,
        "temperature": 0,
        "text": " It is 4 o'clock.",
        "tokens": [
          51446,
          467,
          307,
          1017,
          277,
          6,
          9023,
          13,
          51508
        ]
      },
      {
        "avg_logprob": -0.24800269485365414,
        "compression_ratio": 1.676595744680851,
        "end": 6904.18,
        "id": 2100,
        "no_speech_prob": 0.00003373714935150929,
        "seek": 687934,
        "start": 6902.22,
        "temperature": 0,
        "text": " I think I am finished.",
        "tokens": [
          51508,
          286,
          519,
          286,
          669,
          4335,
          13,
          51606
        ]
      },
      {
        "avg_logprob": -0.24800269485365414,
        "compression_ratio": 1.676595744680851,
        "end": 6906.26,
        "id": 2101,
        "no_speech_prob": 0.00003373714935150929,
        "seek": 687934,
        "start": 6904.18,
        "temperature": 0,
        "text": " Is there any last little bits of stuff",
        "tokens": [
          51606,
          1119,
          456,
          604,
          1036,
          707,
          9239,
          295,
          1507,
          51710
        ]
      },
      {
        "avg_logprob": -0.3760312951129416,
        "compression_ratio": 1.3243243243243243,
        "end": 6908.54,
        "id": 2102,
        "no_speech_prob": 0.007577158976346254,
        "seek": 690626,
        "start": 6906.3,
        "temperature": 0,
        "text": " that I want to cover or talk about today?",
        "tokens": [
          50366,
          300,
          286,
          528,
          281,
          2060,
          420,
          751,
          466,
          965,
          30,
          50478
        ]
      },
      {
        "avg_logprob": -0.3760312951129416,
        "compression_ratio": 1.3243243243243243,
        "end": 6917.9800000000005,
        "id": 2103,
        "no_speech_prob": 0.007577158976346254,
        "seek": 690626,
        "start": 6915.900000000001,
        "temperature": 0,
        "text": " Pac-Man.",
        "tokens": [
          50846,
          10702,
          12,
          6652,
          13,
          50950
        ]
      },
      {
        "avg_logprob": -0.3760312951129416,
        "compression_ratio": 1.3243243243243243,
        "end": 6919.38,
        "id": 2104,
        "no_speech_prob": 0.007577158976346254,
        "seek": 690626,
        "start": 6917.9800000000005,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          50950,
          865,
          13,
          51020
        ]
      },
      {
        "avg_logprob": -0.3760312951129416,
        "compression_ratio": 1.3243243243243243,
        "end": 6921.5,
        "id": 2105,
        "no_speech_prob": 0.007577158976346254,
        "seek": 690626,
        "start": 6919.38,
        "temperature": 0,
        "text": " Thank you, everybody.",
        "tokens": [
          51020,
          1044,
          291,
          11,
          2201,
          13,
          51126
        ]
      },
      {
        "avg_logprob": -0.3760312951129416,
        "compression_ratio": 1.3243243243243243,
        "end": 6922.3,
        "id": 2106,
        "no_speech_prob": 0.007577158976346254,
        "seek": 690626,
        "start": 6921.5,
        "temperature": 0,
        "text": " So let's see.",
        "tokens": [
          51126,
          407,
          718,
          311,
          536,
          13,
          51166
        ]
      },
      {
        "avg_logprob": -0.3760312951129416,
        "compression_ratio": 1.3243243243243243,
        "end": 6926.58,
        "id": 2107,
        "no_speech_prob": 0.007577158976346254,
        "seek": 690626,
        "start": 6922.3,
        "temperature": 0,
        "text": " I should put this code somewhere.",
        "tokens": [
          51166,
          286,
          820,
          829,
          341,
          3089,
          4079,
          13,
          51380
        ]
      },
      {
        "avg_logprob": -0.3760312951129416,
        "compression_ratio": 1.3243243243243243,
        "end": 6927.22,
        "id": 2108,
        "no_speech_prob": 0.007577158976346254,
        "seek": 690626,
        "start": 6926.58,
        "temperature": 0,
        "text": " This will be.",
        "tokens": [
          51380,
          639,
          486,
          312,
          13,
          51412
        ]
      },
      {
        "avg_logprob": -0.3760312951129416,
        "compression_ratio": 1.3243243243243243,
        "end": 6935.74,
        "id": 2109,
        "no_speech_prob": 0.007577158976346254,
        "seek": 690626,
        "start": 6931.66,
        "temperature": 0,
        "text": " So let me do a little quick, just so the code is ready.",
        "tokens": [
          51634,
          407,
          718,
          385,
          360,
          257,
          707,
          1702,
          11,
          445,
          370,
          264,
          3089,
          307,
          1919,
          13,
          51838
        ]
      },
      {
        "avg_logprob": -0.32797881884452623,
        "compression_ratio": 1.2872340425531914,
        "end": 6937.74,
        "id": 2110,
        "no_speech_prob": 0.000053910418500890955,
        "seek": 693626,
        "start": 6936.66,
        "temperature": 0,
        "text": " I'm going to do this now.",
        "tokens": [
          50384,
          286,
          478,
          516,
          281,
          360,
          341,
          586,
          13,
          50438
        ]
      },
      {
        "avg_logprob": -0.32797881884452623,
        "compression_ratio": 1.2872340425531914,
        "end": 6950.860000000001,
        "id": 2111,
        "no_speech_prob": 0.000053910418500890955,
        "seek": 693626,
        "start": 6943.22,
        "temperature": 0,
        "text": " So I am going to grab these three files.",
        "tokens": [
          50712,
          407,
          286,
          669,
          516,
          281,
          4444,
          613,
          1045,
          7098,
          13,
          51094
        ]
      },
      {
        "avg_logprob": -0.32797881884452623,
        "compression_ratio": 1.2872340425531914,
        "end": 6963.26,
        "id": 2112,
        "no_speech_prob": 0.000053910418500890955,
        "seek": 693626,
        "start": 6950.860000000001,
        "temperature": 0,
        "text": " I'm going to put them in a website, coding challenges.",
        "tokens": [
          51094,
          286,
          478,
          516,
          281,
          829,
          552,
          294,
          257,
          3144,
          11,
          17720,
          4759,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.41073315484183176,
        "compression_ratio": 1.264,
        "end": 6964.22,
        "id": 2113,
        "no_speech_prob": 0.00010889625991694629,
        "seek": 696326,
        "start": 6963.26,
        "temperature": 0,
        "text": " So I need to make.",
        "tokens": [
          50364,
          407,
          286,
          643,
          281,
          652,
          13,
          50412
        ]
      },
      {
        "avg_logprob": -0.41073315484183176,
        "compression_ratio": 1.264,
        "end": 6974.5,
        "id": 2114,
        "no_speech_prob": 0.00010889625991694629,
        "seek": 696326,
        "start": 6968.34,
        "temperature": 0,
        "text": " Question is, was this morning like part two of Logo?",
        "tokens": [
          50618,
          14464,
          307,
          11,
          390,
          341,
          2446,
          411,
          644,
          732,
          295,
          10824,
          78,
          30,
          50926
        ]
      },
      {
        "avg_logprob": -0.41073315484183176,
        "compression_ratio": 1.264,
        "end": 6977.900000000001,
        "id": 2115,
        "no_speech_prob": 0.00010889625991694629,
        "seek": 696326,
        "start": 6974.5,
        "temperature": 0,
        "text": " I think it kind of was.",
        "tokens": [
          50926,
          286,
          519,
          309,
          733,
          295,
          390,
          13,
          51096
        ]
      },
      {
        "avg_logprob": -0.41073315484183176,
        "compression_ratio": 1.264,
        "end": 6980.66,
        "id": 2116,
        "no_speech_prob": 0.00010889625991694629,
        "seek": 696326,
        "start": 6977.900000000001,
        "temperature": 0,
        "text": " So this will be 1.22, quick draw.",
        "tokens": [
          51096,
          407,
          341,
          486,
          312,
          502,
          13,
          7490,
          11,
          1702,
          2642,
          13,
          51234
        ]
      },
      {
        "avg_logprob": -0.41073315484183176,
        "compression_ratio": 1.264,
        "end": 6989.46,
        "id": 2117,
        "no_speech_prob": 0.00010889625991694629,
        "seek": 696326,
        "start": 6986.14,
        "temperature": 0,
        "text": " So that stuff goes in there.",
        "tokens": [
          51508,
          407,
          300,
          1507,
          1709,
          294,
          456,
          13,
          51674
        ]
      },
      {
        "avg_logprob": -0.2981046608516148,
        "compression_ratio": 1.3257575757575757,
        "end": 6998.22,
        "id": 2118,
        "no_speech_prob": 0.0001293141394853592,
        "seek": 698946,
        "start": 6989.46,
        "temperature": 0,
        "text": " And let's change this to 1.",
        "tokens": [
          50364,
          400,
          718,
          311,
          1319,
          341,
          281,
          502,
          13,
          50802
        ]
      },
      {
        "avg_logprob": -0.2981046608516148,
        "compression_ratio": 1.3257575757575757,
        "end": 7001.22,
        "id": 2119,
        "no_speech_prob": 0.0001293141394853592,
        "seek": 698946,
        "start": 6998.22,
        "temperature": 0,
        "text": " And then also make a version 2.",
        "tokens": [
          50802,
          400,
          550,
          611,
          652,
          257,
          3037,
          568,
          13,
          50952
        ]
      },
      {
        "avg_logprob": -0.2981046608516148,
        "compression_ratio": 1.3257575757575757,
        "end": 7002.62,
        "id": 2120,
        "no_speech_prob": 0.0001293141394853592,
        "seek": 698946,
        "start": 7001.22,
        "temperature": 0,
        "text": " Sorry if you can't see this.",
        "tokens": [
          50952,
          4919,
          498,
          291,
          393,
          380,
          536,
          341,
          13,
          51022
        ]
      },
      {
        "avg_logprob": -0.2981046608516148,
        "compression_ratio": 1.3257575757575757,
        "end": 7010.22,
        "id": 2121,
        "no_speech_prob": 0.0001293141394853592,
        "seek": 698946,
        "start": 7005.3,
        "temperature": 0,
        "text": " And then I'm going to go to desktop, logo.",
        "tokens": [
          51156,
          400,
          550,
          286,
          478,
          516,
          281,
          352,
          281,
          14502,
          11,
          9699,
          13,
          51402
        ]
      },
      {
        "avg_logprob": -0.2981046608516148,
        "compression_ratio": 1.3257575757575757,
        "end": 7013.7,
        "id": 2122,
        "no_speech_prob": 0.0001293141394853592,
        "seek": 698946,
        "start": 7010.22,
        "temperature": 0,
        "text": " This should be everything for this version.",
        "tokens": [
          51402,
          639,
          820,
          312,
          1203,
          337,
          341,
          3037,
          13,
          51576
        ]
      },
      {
        "avg_logprob": -0.5947563030101635,
        "compression_ratio": 1.0125,
        "end": 7032.42,
        "id": 2123,
        "no_speech_prob": 0.0003406252362765372,
        "seek": 701370,
        "start": 7014.7,
        "temperature": 0,
        "text": " So now if I go to really messed up here because I didn't.",
        "tokens": [
          50414,
          407,
          586,
          498,
          286,
          352,
          281,
          534,
          16507,
          493,
          510,
          570,
          286,
          994,
          380,
          13,
          51300
        ]
      },
      {
        "avg_logprob": -0.5947563030101635,
        "compression_ratio": 1.0125,
        "end": 7038.34,
        "id": 2124,
        "no_speech_prob": 0.0003406252362765372,
        "seek": 701370,
        "start": 7035.099999999999,
        "temperature": 0,
        "text": " Let me just merge this.",
        "tokens": [
          51434,
          961,
          385,
          445,
          22183,
          341,
          13,
          51596
        ]
      },
      {
        "avg_logprob": -0.584963688483605,
        "compression_ratio": 1.0125,
        "end": 7046.18,
        "id": 2125,
        "no_speech_prob": 0.0014324842486530542,
        "seek": 703834,
        "start": 7038.34,
        "temperature": 0,
        "text": " This was the code from save load live stream.",
        "tokens": [
          50364,
          639,
          390,
          264,
          3089,
          490,
          3155,
          3677,
          1621,
          4309,
          13,
          50756
        ]
      },
      {
        "avg_logprob": -0.584963688483605,
        "compression_ratio": 1.0125,
        "end": 7047.66,
        "id": 2126,
        "no_speech_prob": 0.0014324842486530542,
        "seek": 703834,
        "start": 7046.18,
        "temperature": 0,
        "text": " All right, I'm going to merge this.",
        "tokens": [
          50756,
          1057,
          558,
          11,
          286,
          478,
          516,
          281,
          22183,
          341,
          13,
          50830
        ]
      },
      {
        "avg_logprob": -0.6056093286584925,
        "compression_ratio": 1.0714285714285714,
        "end": 7056.0599999999995,
        "id": 2127,
        "no_speech_prob": 0.048131391406059265,
        "seek": 704766,
        "start": 7047.66,
        "temperature": 0,
        "text": " And then, OK.",
        "tokens": [
          50364,
          400,
          550,
          11,
          2264,
          13,
          50784
        ]
      },
      {
        "avg_logprob": -0.6056093286584925,
        "compression_ratio": 1.0714285714285714,
        "end": 7067.94,
        "id": 2128,
        "no_speech_prob": 0.048131391406059265,
        "seek": 704766,
        "start": 7060.0199999999995,
        "temperature": 0,
        "text": " And I'm going to get branch quick draw.",
        "tokens": [
          50982,
          400,
          286,
          478,
          516,
          281,
          483,
          9819,
          1702,
          2642,
          13,
          51378
        ]
      },
      {
        "avg_logprob": -0.6056093286584925,
        "compression_ratio": 1.0714285714285714,
        "end": 7073.82,
        "id": 2129,
        "no_speech_prob": 0.048131391406059265,
        "seek": 704766,
        "start": 7071.099999999999,
        "temperature": 0,
        "text": " Check out quick draw.",
        "tokens": [
          51536,
          6881,
          484,
          1702,
          2642,
          13,
          51672
        ]
      },
      {
        "avg_logprob": -0.5468827799746865,
        "compression_ratio": 1.297029702970297,
        "end": 7089.0199999999995,
        "id": 2130,
        "no_speech_prob": 0.006003174465149641,
        "seek": 707766,
        "start": 7078.66,
        "temperature": 0,
        "text": " Get add coding challenges on 22 quick draw.",
        "tokens": [
          50414,
          3240,
          909,
          17720,
          4759,
          322,
          5853,
          1702,
          2642,
          13,
          50932
        ]
      },
      {
        "avg_logprob": -0.5468827799746865,
        "compression_ratio": 1.297029702970297,
        "end": 7095.54,
        "id": 2131,
        "no_speech_prob": 0.006003174465149641,
        "seek": 707766,
        "start": 7089.0199999999995,
        "temperature": 0,
        "text": " Code from quick draw challenge.",
        "tokens": [
          50932,
          15549,
          490,
          1702,
          2642,
          3430,
          13,
          51258
        ]
      },
      {
        "avg_logprob": -0.5468827799746865,
        "compression_ratio": 1.297029702970297,
        "end": 7097.62,
        "id": 2132,
        "no_speech_prob": 0.006003174465149641,
        "seek": 707766,
        "start": 7095.54,
        "temperature": 0,
        "text": " Push origin quick draw.",
        "tokens": [
          51258,
          18229,
          4957,
          1702,
          2642,
          13,
          51362
        ]
      },
      {
        "avg_logprob": -0.5468827799746865,
        "compression_ratio": 1.297029702970297,
        "end": 7105.7,
        "id": 2133,
        "no_speech_prob": 0.006003174465149641,
        "seek": 707766,
        "start": 7101.58,
        "temperature": 0,
        "text": " OK, let me go check out master.",
        "tokens": [
          51560,
          2264,
          11,
          718,
          385,
          352,
          1520,
          484,
          4505,
          13,
          51766
        ]
      },
      {
        "avg_logprob": -0.42343393961588544,
        "compression_ratio": 1.2566371681415929,
        "end": 7114.34,
        "id": 2134,
        "no_speech_prob": 0.0015247617848217487,
        "seek": 710766,
        "start": 7108.66,
        "temperature": 0,
        "text": " And what I want to do is, shoot.",
        "tokens": [
          50414,
          400,
          437,
          286,
          528,
          281,
          360,
          307,
          11,
          3076,
          13,
          50698
        ]
      },
      {
        "avg_logprob": -0.42343393961588544,
        "compression_ratio": 1.2566371681415929,
        "end": 7119.42,
        "id": 2135,
        "no_speech_prob": 0.0015247617848217487,
        "seek": 710766,
        "start": 7118.26,
        "temperature": 0,
        "text": " I have an idea here.",
        "tokens": [
          50894,
          286,
          362,
          364,
          1558,
          510,
          13,
          50952
        ]
      },
      {
        "avg_logprob": -0.42343393961588544,
        "compression_ratio": 1.2566371681415929,
        "end": 7129.5,
        "id": 2136,
        "no_speech_prob": 0.0015247617848217487,
        "seek": 710766,
        "start": 7125.9,
        "temperature": 0,
        "text": " Where is this nonsense?",
        "tokens": [
          51276,
          2305,
          307,
          341,
          14925,
          30,
          51456
        ]
      },
      {
        "avg_logprob": -0.42343393961588544,
        "compression_ratio": 1.2566371681415929,
        "end": 7131.3,
        "id": 2137,
        "no_speech_prob": 0.0015247617848217487,
        "seek": 710766,
        "start": 7129.5,
        "temperature": 0,
        "text": " There's some extra thing here that I'm",
        "tokens": [
          51456,
          821,
          311,
          512,
          2857,
          551,
          510,
          300,
          286,
          478,
          51546
        ]
      },
      {
        "avg_logprob": -0.42343393961588544,
        "compression_ratio": 1.2566371681415929,
        "end": 7132.74,
        "id": 2138,
        "no_speech_prob": 0.0015247617848217487,
        "seek": 710766,
        "start": 7131.3,
        "temperature": 0,
        "text": " going to just get rid of.",
        "tokens": [
          51546,
          516,
          281,
          445,
          483,
          3973,
          295,
          13,
          51618
        ]
      },
      {
        "avg_logprob": -0.4158500247531467,
        "compression_ratio": 1.288659793814433,
        "end": 7142.62,
        "id": 2139,
        "no_speech_prob": 0.00658946018666029,
        "seek": 713766,
        "start": 7138.66,
        "temperature": 0,
        "text": " Get branch logo.",
        "tokens": [
          50414,
          3240,
          9819,
          9699,
          13,
          50612
        ]
      },
      {
        "avg_logprob": -0.4158500247531467,
        "compression_ratio": 1.288659793814433,
        "end": 7144.54,
        "id": 2140,
        "no_speech_prob": 0.00658946018666029,
        "seek": 713766,
        "start": 7142.62,
        "temperature": 0,
        "text": " Get check out logo.",
        "tokens": [
          50612,
          3240,
          1520,
          484,
          9699,
          13,
          50708
        ]
      },
      {
        "avg_logprob": -0.4158500247531467,
        "compression_ratio": 1.288659793814433,
        "end": 7152.34,
        "id": 2141,
        "no_speech_prob": 0.00658946018666029,
        "seek": 713766,
        "start": 7151.46,
        "temperature": 0,
        "text": " And hold on.",
        "tokens": [
          51054,
          400,
          1797,
          322,
          13,
          51098
        ]
      },
      {
        "avg_logprob": -0.4158500247531467,
        "compression_ratio": 1.288659793814433,
        "end": 7156.66,
        "id": 2142,
        "no_speech_prob": 0.00658946018666029,
        "seek": 713766,
        "start": 7152.34,
        "temperature": 0,
        "text": " Now, logo 1, logo 2.",
        "tokens": [
          51098,
          823,
          11,
          9699,
          502,
          11,
          9699,
          568,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.4158500247531467,
        "compression_ratio": 1.288659793814433,
        "end": 7165.9,
        "id": 2143,
        "no_speech_prob": 0.00658946018666029,
        "seek": 713766,
        "start": 7156.66,
        "temperature": 0,
        "text": " Get add dot dash A. Moving logo code around and adding",
        "tokens": [
          51314,
          3240,
          909,
          5893,
          8240,
          316,
          13,
          14242,
          9699,
          3089,
          926,
          293,
          5127,
          51776
        ]
      },
      {
        "avg_logprob": -0.2654559326171875,
        "compression_ratio": 1.401639344262295,
        "end": 7168.46,
        "id": 2144,
        "no_speech_prob": 0.018263323232531548,
        "seek": 716590,
        "start": 7165.94,
        "temperature": 0,
        "text": " second part.",
        "tokens": [
          50366,
          1150,
          644,
          13,
          50492
        ]
      },
      {
        "avg_logprob": -0.2654559326171875,
        "compression_ratio": 1.401639344262295,
        "end": 7173.259999999999,
        "id": 2145,
        "no_speech_prob": 0.018263323232531548,
        "seek": 716590,
        "start": 7168.46,
        "temperature": 0,
        "text": " And now, get push origin logo.",
        "tokens": [
          50492,
          400,
          586,
          11,
          483,
          2944,
          4957,
          9699,
          13,
          50732
        ]
      },
      {
        "avg_logprob": -0.2654559326171875,
        "compression_ratio": 1.401639344262295,
        "end": 7177.74,
        "id": 2146,
        "no_speech_prob": 0.018263323232531548,
        "seek": 716590,
        "start": 7173.259999999999,
        "temperature": 0,
        "text": " So I should have two separate pull requests now.",
        "tokens": [
          50732,
          407,
          286,
          820,
          362,
          732,
          4994,
          2235,
          12475,
          586,
          13,
          50956
        ]
      },
      {
        "avg_logprob": -0.2654559326171875,
        "compression_ratio": 1.401639344262295,
        "end": 7181.86,
        "id": 2147,
        "no_speech_prob": 0.018263323232531548,
        "seek": 716590,
        "start": 7177.74,
        "temperature": 0,
        "text": " Welcome to weird things with GitHub.",
        "tokens": [
          50956,
          4027,
          281,
          3657,
          721,
          365,
          23331,
          13,
          51162
        ]
      },
      {
        "avg_logprob": -0.2654559326171875,
        "compression_ratio": 1.401639344262295,
        "end": 7183.86,
        "id": 2148,
        "no_speech_prob": 0.018263323232531548,
        "seek": 716590,
        "start": 7181.86,
        "temperature": 0,
        "text": " So I should be able to pull request this.",
        "tokens": [
          51162,
          407,
          286,
          820,
          312,
          1075,
          281,
          2235,
          5308,
          341,
          13,
          51262
        ]
      },
      {
        "avg_logprob": -0.8174770900181362,
        "compression_ratio": 1.184,
        "end": 7194.86,
        "id": 2149,
        "no_speech_prob": 0.0005527759785763919,
        "seek": 718386,
        "start": 7184.42,
        "temperature": 0,
        "text": " This is the quick draw code for challenge 1.22.",
        "tokens": [
          50392,
          639,
          307,
          264,
          1702,
          2642,
          3089,
          337,
          3430,
          502,
          13,
          7490,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.8174770900181362,
        "compression_ratio": 1.184,
        "end": 7195.66,
        "id": 2150,
        "no_speech_prob": 0.0005527759785763919,
        "seek": 718386,
        "start": 7194.86,
        "temperature": 0,
        "text": " Ooh, well.",
        "tokens": [
          50914,
          7951,
          11,
          731,
          13,
          50954
        ]
      },
      {
        "avg_logprob": -0.8174770900181362,
        "compression_ratio": 1.184,
        "end": 7204.099999999999,
        "id": 2151,
        "no_speech_prob": 0.0005527759785763919,
        "seek": 718386,
        "start": 7201.38,
        "temperature": 0,
        "text": " Wait, why is my?",
        "tokens": [
          51240,
          3802,
          11,
          983,
          307,
          452,
          30,
          51376
        ]
      },
      {
        "avg_logprob": -0.8174770900181362,
        "compression_ratio": 1.184,
        "end": 7206.099999999999,
        "id": 2152,
        "no_speech_prob": 0.0005527759785763919,
        "seek": 718386,
        "start": 7204.099999999999,
        "temperature": 0,
        "text": " What sort of set of tabs is this?",
        "tokens": [
          51376,
          708,
          1333,
          295,
          992,
          295,
          20743,
          307,
          341,
          30,
          51476
        ]
      },
      {
        "avg_logprob": -0.8174770900181362,
        "compression_ratio": 1.184,
        "end": 7209.78,
        "id": 2153,
        "no_speech_prob": 0.0005527759785763919,
        "seek": 718386,
        "start": 7208.78,
        "temperature": 0,
        "text": " What?",
        "tokens": [
          51610,
          708,
          30,
          51660
        ]
      },
      {
        "avg_logprob": -0.8174770900181362,
        "compression_ratio": 1.184,
        "end": 7211.179999999999,
        "id": 2154,
        "no_speech_prob": 0.0005527759785763919,
        "seek": 718386,
        "start": 7209.78,
        "temperature": 0,
        "text": " Have I been using forward space?",
        "tokens": [
          51660,
          3560,
          286,
          668,
          1228,
          337,
          6925,
          67,
          1901,
          30,
          51730
        ]
      },
      {
        "avg_logprob": -0.39390613331514246,
        "compression_ratio": 1.5031446540880504,
        "end": 7212.58,
        "id": 2155,
        "no_speech_prob": 0.0000931458780542016,
        "seek": 721118,
        "start": 7211.900000000001,
        "temperature": 0,
        "text": " What?",
        "tokens": [
          50400,
          708,
          30,
          50434
        ]
      },
      {
        "avg_logprob": -0.39390613331514246,
        "compression_ratio": 1.5031446540880504,
        "end": 7215.1,
        "id": 2156,
        "no_speech_prob": 0.0000931458780542016,
        "seek": 721118,
        "start": 7212.58,
        "temperature": 0,
        "text": " Have I been using forward space tabs all this time",
        "tokens": [
          50434,
          3560,
          286,
          668,
          1228,
          2128,
          1901,
          20743,
          439,
          341,
          565,
          50560
        ]
      },
      {
        "avg_logprob": -0.39390613331514246,
        "compression_ratio": 1.5031446540880504,
        "end": 7215.9400000000005,
        "id": 2157,
        "no_speech_prob": 0.0000931458780542016,
        "seek": 721118,
        "start": 7215.1,
        "temperature": 0,
        "text": " and not noticing?",
        "tokens": [
          50560,
          293,
          406,
          21814,
          30,
          50602
        ]
      },
      {
        "avg_logprob": -0.39390613331514246,
        "compression_ratio": 1.5031446540880504,
        "end": 7219.02,
        "id": 2158,
        "no_speech_prob": 0.0000931458780542016,
        "seek": 721118,
        "start": 7215.9400000000005,
        "temperature": 0,
        "text": " Those are like 18 space tabs.",
        "tokens": [
          50602,
          3950,
          366,
          411,
          2443,
          1901,
          20743,
          13,
          50756
        ]
      },
      {
        "avg_logprob": -0.39390613331514246,
        "compression_ratio": 1.5031446540880504,
        "end": 7221.02,
        "id": 2159,
        "no_speech_prob": 0.0000931458780542016,
        "seek": 721118,
        "start": 7219.02,
        "temperature": 0,
        "text": " This is insane.",
        "tokens": [
          50756,
          639,
          307,
          10838,
          13,
          50856
        ]
      },
      {
        "avg_logprob": -0.39390613331514246,
        "compression_ratio": 1.5031446540880504,
        "end": 7222.02,
        "id": 2160,
        "no_speech_prob": 0.0000931458780542016,
        "seek": 721118,
        "start": 7221.02,
        "temperature": 0,
        "text": " What is going on?",
        "tokens": [
          50856,
          708,
          307,
          516,
          322,
          30,
          50906
        ]
      },
      {
        "avg_logprob": -0.39390613331514246,
        "compression_ratio": 1.5031446540880504,
        "end": 7225.700000000001,
        "id": 2161,
        "no_speech_prob": 0.0000931458780542016,
        "seek": 721118,
        "start": 7224.700000000001,
        "temperature": 0,
        "text": " This look like two spaces.",
        "tokens": [
          51040,
          639,
          574,
          411,
          732,
          7673,
          13,
          51090
        ]
      },
      {
        "avg_logprob": -0.39390613331514246,
        "compression_ratio": 1.5031446540880504,
        "end": 7229.780000000001,
        "id": 2162,
        "no_speech_prob": 0.0000931458780542016,
        "seek": 721118,
        "start": 7228.58,
        "temperature": 0,
        "text": " What's going on?",
        "tokens": [
          51234,
          708,
          311,
          516,
          322,
          30,
          51294
        ]
      },
      {
        "avg_logprob": -0.39390613331514246,
        "compression_ratio": 1.5031446540880504,
        "end": 7230.860000000001,
        "id": 2163,
        "no_speech_prob": 0.0000931458780542016,
        "seek": 721118,
        "start": 7229.780000000001,
        "temperature": 0,
        "text": " Tab size 2.",
        "tokens": [
          51294,
          14106,
          2744,
          568,
          13,
          51348
        ]
      },
      {
        "avg_logprob": -0.39390613331514246,
        "compression_ratio": 1.5031446540880504,
        "end": 7232.34,
        "id": 2164,
        "no_speech_prob": 0.0000931458780542016,
        "seek": 721118,
        "start": 7230.860000000001,
        "temperature": 0,
        "text": " Render white space.",
        "tokens": [
          51348,
          497,
          3216,
          2418,
          1901,
          13,
          51422
        ]
      },
      {
        "avg_logprob": -0.39390613331514246,
        "compression_ratio": 1.5031446540880504,
        "end": 7232.820000000001,
        "id": 2165,
        "no_speech_prob": 0.0000931458780542016,
        "seek": 721118,
        "start": 7232.34,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          51422,
          876,
          13,
          51446
        ]
      },
      {
        "avg_logprob": -0.39390613331514246,
        "compression_ratio": 1.5031446540880504,
        "end": 7239.740000000001,
        "id": 2166,
        "no_speech_prob": 0.0000931458780542016,
        "seek": 721118,
        "start": 7238.820000000001,
        "temperature": 0,
        "text": " Ooh, those are tabs.",
        "tokens": [
          51746,
          7951,
          11,
          729,
          366,
          20743,
          13,
          51792
        ]
      },
      {
        "avg_logprob": -0.36057995640954305,
        "compression_ratio": 1.1682242990654206,
        "end": 7243.62,
        "id": 2167,
        "no_speech_prob": 0.000059209083701716736,
        "seek": 724118,
        "start": 7242.18,
        "temperature": 0,
        "text": " Why is it?",
        "tokens": [
          50414,
          1545,
          307,
          309,
          30,
          50486
        ]
      },
      {
        "avg_logprob": -0.36057995640954305,
        "compression_ratio": 1.1682242990654206,
        "end": 7248.1,
        "id": 2168,
        "no_speech_prob": 0.000059209083701716736,
        "seek": 724118,
        "start": 7243.62,
        "temperature": 0,
        "text": " What setting in VS Code is changing those to tabs?",
        "tokens": [
          50486,
          708,
          3287,
          294,
          25091,
          15549,
          307,
          4473,
          729,
          281,
          20743,
          30,
          50710
        ]
      },
      {
        "avg_logprob": -0.36057995640954305,
        "compression_ratio": 1.1682242990654206,
        "end": 7250.900000000001,
        "id": 2169,
        "no_speech_prob": 0.000059209083701716736,
        "seek": 724118,
        "start": 7248.1,
        "temperature": 0,
        "text": " Oh my goodness.",
        "tokens": [
          50710,
          876,
          452,
          8387,
          13,
          50850
        ]
      },
      {
        "avg_logprob": -0.36057995640954305,
        "compression_ratio": 1.1682242990654206,
        "end": 7251.9800000000005,
        "id": 2170,
        "no_speech_prob": 0.000059209083701716736,
        "seek": 724118,
        "start": 7250.900000000001,
        "temperature": 0,
        "text": " This cannot be.",
        "tokens": [
          50850,
          639,
          2644,
          312,
          13,
          50904
        ]
      },
      {
        "avg_logprob": -0.36057995640954305,
        "compression_ratio": 1.1682242990654206,
        "end": 7269.46,
        "id": 2171,
        "no_speech_prob": 0.000059209083701716736,
        "seek": 724118,
        "start": 7268.1,
        "temperature": 0,
        "text": " I forgot if I'm using prettier.",
        "tokens": [
          51710,
          286,
          5298,
          498,
          286,
          478,
          1228,
          36825,
          13,
          51778
        ]
      },
      {
        "avg_logprob": -0.41668673197428385,
        "compression_ratio": 1.380281690140845,
        "end": 7272.02,
        "id": 2172,
        "no_speech_prob": 0.00045830931048840284,
        "seek": 726946,
        "start": 7269.86,
        "temperature": 0,
        "text": " I switched everything in my workflow,",
        "tokens": [
          50384,
          286,
          16858,
          1203,
          294,
          452,
          20993,
          11,
          50492
        ]
      },
      {
        "avg_logprob": -0.41668673197428385,
        "compression_ratio": 1.380281690140845,
        "end": 7275.54,
        "id": 2173,
        "no_speech_prob": 0.00045830931048840284,
        "seek": 726946,
        "start": 7272.02,
        "temperature": 0,
        "text": " but I never actually did it on this.",
        "tokens": [
          50492,
          457,
          286,
          1128,
          767,
          630,
          309,
          322,
          341,
          13,
          50668
        ]
      },
      {
        "avg_logprob": -0.41668673197428385,
        "compression_ratio": 1.380281690140845,
        "end": 7276.06,
        "id": 2174,
        "no_speech_prob": 0.00045830931048840284,
        "seek": 726946,
        "start": 7275.54,
        "temperature": 0,
        "text": " Am I?",
        "tokens": [
          50668,
          2012,
          286,
          30,
          50694
        ]
      },
      {
        "avg_logprob": -0.41668673197428385,
        "compression_ratio": 1.380281690140845,
        "end": 7276.82,
        "id": 2175,
        "no_speech_prob": 0.00045830931048840284,
        "seek": 726946,
        "start": 7276.06,
        "temperature": 0,
        "text": " Do not I have?",
        "tokens": [
          50694,
          1144,
          406,
          286,
          362,
          30,
          50732
        ]
      },
      {
        "avg_logprob": -0.41668673197428385,
        "compression_ratio": 1.380281690140845,
        "end": 7277.34,
        "id": 2176,
        "no_speech_prob": 0.00045830931048840284,
        "seek": 726946,
        "start": 7276.82,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50732,
          1057,
          558,
          13,
          50758
        ]
      },
      {
        "avg_logprob": -0.41668673197428385,
        "compression_ratio": 1.380281690140845,
        "end": 7282.7,
        "id": 2177,
        "no_speech_prob": 0.00045830931048840284,
        "seek": 726946,
        "start": 7281.74,
        "temperature": 0,
        "text": " All right, let's see.",
        "tokens": [
          50978,
          1057,
          558,
          11,
          718,
          311,
          536,
          13,
          51026
        ]
      },
      {
        "avg_logprob": -0.41668673197428385,
        "compression_ratio": 1.380281690140845,
        "end": 7288.9,
        "id": 2178,
        "no_speech_prob": 0.00045830931048840284,
        "seek": 726946,
        "start": 7287.3,
        "temperature": 0,
        "text": " Oh, this.",
        "tokens": [
          51256,
          876,
          11,
          341,
          13,
          51336
        ]
      },
      {
        "avg_logprob": -0.41668673197428385,
        "compression_ratio": 1.380281690140845,
        "end": 7290.42,
        "id": 2179,
        "no_speech_prob": 0.00045830931048840284,
        "seek": 726946,
        "start": 7288.9,
        "temperature": 0,
        "text": " I have this crazy thing.",
        "tokens": [
          51336,
          286,
          362,
          341,
          3219,
          551,
          13,
          51412
        ]
      },
      {
        "avg_logprob": -0.41668673197428385,
        "compression_ratio": 1.380281690140845,
        "end": 7291.5,
        "id": 2180,
        "no_speech_prob": 0.00045830931048840284,
        "seek": 726946,
        "start": 7290.42,
        "temperature": 0,
        "text": " Indent with tabs.",
        "tokens": [
          51412,
          2333,
          317,
          365,
          20743,
          13,
          51466
        ]
      },
      {
        "avg_logprob": -0.41668673197428385,
        "compression_ratio": 1.380281690140845,
        "end": 7296.3,
        "id": 2181,
        "no_speech_prob": 0.00045830931048840284,
        "seek": 726946,
        "start": 7294.9,
        "temperature": 0,
        "text": " Indent size 4.",
        "tokens": [
          51636,
          2333,
          317,
          2744,
          1017,
          13,
          51706
        ]
      },
      {
        "avg_logprob": -0.5895281824572333,
        "compression_ratio": 1.0869565217391304,
        "end": 7300.56,
        "id": 2182,
        "no_speech_prob": 0.00021318245853763074,
        "seek": 729946,
        "start": 7300.06,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          50394,
          876,
          13,
          50419
        ]
      },
      {
        "avg_logprob": -0.5895281824572333,
        "compression_ratio": 1.0869565217391304,
        "end": 7304.52,
        "id": 2183,
        "no_speech_prob": 0.00021318245853763074,
        "seek": 729946,
        "start": 7304.02,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          50592,
          876,
          13,
          50617
        ]
      },
      {
        "avg_logprob": -0.5895281824572333,
        "compression_ratio": 1.0869565217391304,
        "end": 7309.94,
        "id": 2184,
        "no_speech_prob": 0.00021318245853763074,
        "seek": 729946,
        "start": 7308.26,
        "temperature": 0,
        "text": " Let's disable this for a second.",
        "tokens": [
          50804,
          961,
          311,
          28362,
          341,
          337,
          257,
          1150,
          13,
          50888
        ]
      },
      {
        "avg_logprob": -0.5895281824572333,
        "compression_ratio": 1.0869565217391304,
        "end": 7320.38,
        "id": 2185,
        "no_speech_prob": 0.00021318245853763074,
        "seek": 729946,
        "start": 7318.34,
        "temperature": 0,
        "text": " Let's install this prettier thing.",
        "tokens": [
          51308,
          961,
          311,
          3625,
          341,
          36825,
          551,
          13,
          51410
        ]
      },
      {
        "avg_logprob": -0.5371520134710497,
        "compression_ratio": 1.0736842105263158,
        "end": 7321.86,
        "id": 2186,
        "no_speech_prob": 0.0016484495718032122,
        "seek": 732038,
        "start": 7321.38,
        "temperature": 0,
        "text": " Let's see.",
        "tokens": [
          50414,
          961,
          311,
          536,
          13,
          50438
        ]
      },
      {
        "avg_logprob": -0.5371520134710497,
        "compression_ratio": 1.0736842105263158,
        "end": 7332.86,
        "id": 2187,
        "no_speech_prob": 0.0016484495718032122,
        "seek": 732038,
        "start": 7329.86,
        "temperature": 0,
        "text": " Reload.",
        "tokens": [
          50838,
          8738,
          78,
          345,
          13,
          50988
        ]
      },
      {
        "avg_logprob": -0.5371520134710497,
        "compression_ratio": 1.0736842105263158,
        "end": 7333.36,
        "id": 2188,
        "no_speech_prob": 0.0016484495718032122,
        "seek": 732038,
        "start": 7332.86,
        "temperature": 0,
        "text": " Yay!",
        "tokens": [
          50988,
          13268,
          0,
          51013
        ]
      },
      {
        "avg_logprob": -0.5371520134710497,
        "compression_ratio": 1.0736842105263158,
        "end": 7338.34,
        "id": 2189,
        "no_speech_prob": 0.0016484495718032122,
        "seek": 732038,
        "start": 7336.86,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51188,
          2264,
          13,
          51262
        ]
      },
      {
        "avg_logprob": -0.5371520134710497,
        "compression_ratio": 1.0736842105263158,
        "end": 7341.42,
        "id": 2190,
        "no_speech_prob": 0.0016484495718032122,
        "seek": 732038,
        "start": 7338.34,
        "temperature": 0,
        "text": " Oh, what a mess.",
        "tokens": [
          51262,
          876,
          11,
          437,
          257,
          2082,
          13,
          51416
        ]
      },
      {
        "avg_logprob": -0.5371520134710497,
        "compression_ratio": 1.0736842105263158,
        "end": 7344.22,
        "id": 2191,
        "no_speech_prob": 0.0016484495718032122,
        "seek": 732038,
        "start": 7341.42,
        "temperature": 0,
        "text": " Where am I?",
        "tokens": [
          51416,
          2305,
          669,
          286,
          30,
          51556
        ]
      },
      {
        "avg_logprob": -0.5371520134710497,
        "compression_ratio": 1.0736842105263158,
        "end": 7345.66,
        "id": 2192,
        "no_speech_prob": 0.0016484495718032122,
        "seek": 732038,
        "start": 7344.22,
        "temperature": 0,
        "text": " Uh-oh.",
        "tokens": [
          51556,
          4019,
          12,
          1445,
          13,
          51628
        ]
      },
      {
        "avg_logprob": -0.5371520134710497,
        "compression_ratio": 1.0736842105263158,
        "end": 7347.5,
        "id": 2193,
        "no_speech_prob": 0.0016484495718032122,
        "seek": 732038,
        "start": 7345.66,
        "temperature": 0,
        "text": " Uh-oh.",
        "tokens": [
          51628,
          4019,
          12,
          1445,
          13,
          51720
        ]
      },
      {
        "avg_logprob": -0.5371520134710497,
        "compression_ratio": 1.0736842105263158,
        "end": 7348.42,
        "id": 2194,
        "no_speech_prob": 0.0016484495718032122,
        "seek": 732038,
        "start": 7347.5,
        "temperature": 0,
        "text": " Who knows where I am?",
        "tokens": [
          51720,
          2102,
          3255,
          689,
          286,
          669,
          30,
          51766
        ]
      },
      {
        "avg_logprob": -0.5371520134710497,
        "compression_ratio": 1.0736842105263158,
        "end": 7349.42,
        "id": 2195,
        "no_speech_prob": 0.0016484495718032122,
        "seek": 732038,
        "start": 7348.42,
        "temperature": 0,
        "text": " I'm lost.",
        "tokens": [
          51766,
          286,
          478,
          2731,
          13,
          51816
        ]
      },
      {
        "avg_logprob": -0.42441245301129066,
        "compression_ratio": 1.3043478260869565,
        "end": 7352.54,
        "id": 2196,
        "no_speech_prob": 0.004198763985186815,
        "seek": 734942,
        "start": 7350.02,
        "temperature": 0,
        "text": " I'm in the Quick Draw thing.",
        "tokens": [
          50394,
          286,
          478,
          294,
          264,
          12101,
          20386,
          551,
          13,
          50520
        ]
      },
      {
        "avg_logprob": -0.42441245301129066,
        "compression_ratio": 1.3043478260869565,
        "end": 7353.9800000000005,
        "id": 2197,
        "no_speech_prob": 0.004198763985186815,
        "seek": 734942,
        "start": 7352.54,
        "temperature": 0,
        "text": " I want to be in the website thing.",
        "tokens": [
          50520,
          286,
          528,
          281,
          312,
          294,
          264,
          3144,
          551,
          13,
          50592
        ]
      },
      {
        "avg_logprob": -0.42441245301129066,
        "compression_ratio": 1.3043478260869565,
        "end": 7359.04,
        "id": 2198,
        "no_speech_prob": 0.004198763985186815,
        "seek": 734942,
        "start": 7358.54,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          50820,
          45263,
          13,
          50845
        ]
      },
      {
        "avg_logprob": -0.42441245301129066,
        "compression_ratio": 1.3043478260869565,
        "end": 7365.06,
        "id": 2199,
        "no_speech_prob": 0.004198763985186815,
        "seek": 734942,
        "start": 7361.9,
        "temperature": 0,
        "text": " What a mess I've made of everything.",
        "tokens": [
          50988,
          708,
          257,
          2082,
          286,
          600,
          1027,
          295,
          1203,
          13,
          51146
        ]
      },
      {
        "avg_logprob": -0.42441245301129066,
        "compression_ratio": 1.3043478260869565,
        "end": 7368.82,
        "id": 2200,
        "no_speech_prob": 0.004198763985186815,
        "seek": 734942,
        "start": 7365.06,
        "temperature": 0,
        "text": " Logo 1, 2.",
        "tokens": [
          51146,
          10824,
          78,
          502,
          11,
          568,
          13,
          51334
        ]
      },
      {
        "avg_logprob": -0.42441245301129066,
        "compression_ratio": 1.3043478260869565,
        "end": 7370.26,
        "id": 2201,
        "no_speech_prob": 0.004198763985186815,
        "seek": 734942,
        "start": 7368.82,
        "temperature": 0,
        "text": " Oh, these are fine.",
        "tokens": [
          51334,
          876,
          11,
          613,
          366,
          2489,
          13,
          51406
        ]
      },
      {
        "avg_logprob": -0.42441245301129066,
        "compression_ratio": 1.3043478260869565,
        "end": 7374.82,
        "id": 2202,
        "no_speech_prob": 0.004198763985186815,
        "seek": 734942,
        "start": 7374.3,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51608,
          821,
          321,
          352,
          13,
          51634
        ]
      },
      {
        "avg_logprob": -0.42441245301129066,
        "compression_ratio": 1.3043478260869565,
        "end": 7377.18,
        "id": 2203,
        "no_speech_prob": 0.004198763985186815,
        "seek": 734942,
        "start": 7374.82,
        "temperature": 0,
        "text": " Ah!",
        "tokens": [
          51634,
          2438,
          0,
          51752
        ]
      },
      {
        "avg_logprob": -0.42441245301129066,
        "compression_ratio": 1.3043478260869565,
        "end": 7378.54,
        "id": 2204,
        "no_speech_prob": 0.004198763985186815,
        "seek": 734942,
        "start": 7377.18,
        "temperature": 0,
        "text": " Oh no, it's inheriting.",
        "tokens": [
          51752,
          876,
          572,
          11,
          309,
          311,
          9484,
          1748,
          13,
          51820
        ]
      },
      {
        "avg_logprob": -0.5492988109588623,
        "compression_ratio": 0.9183673469387755,
        "end": 7387.1,
        "id": 2205,
        "no_speech_prob": 0.0006263259565457702,
        "seek": 737942,
        "start": 7380.42,
        "temperature": 0,
        "text": " Do I need to reload this thing?",
        "tokens": [
          50414,
          1144,
          286,
          643,
          281,
          25628,
          341,
          551,
          30,
          50748
        ]
      },
      {
        "avg_logprob": -0.5492988109588623,
        "compression_ratio": 0.9183673469387755,
        "end": 7387.6,
        "id": 2206,
        "no_speech_prob": 0.0006263259565457702,
        "seek": 737942,
        "start": 7387.1,
        "temperature": 0,
        "text": " No?",
        "tokens": [
          50748,
          883,
          30,
          50773
        ]
      },
      {
        "avg_logprob": -0.5492988109588623,
        "compression_ratio": 0.9183673469387755,
        "end": 7406.28,
        "id": 2207,
        "no_speech_prob": 0.0006263259565457702,
        "seek": 737942,
        "start": 7405.78,
        "temperature": 0,
        "text": " Prettier.",
        "tokens": [
          51682,
          9739,
          25402,
          13,
          51707
        ]
      },
      {
        "avg_logprob": -0.529217983813996,
        "compression_ratio": 1.11,
        "end": 7417.9400000000005,
        "id": 2208,
        "no_speech_prob": 0.0005792861338704824,
        "seek": 740942,
        "start": 7409.42,
        "temperature": 0,
        "text": " Uh, default 2.",
        "tokens": [
          50364,
          4019,
          11,
          7576,
          568,
          13,
          50790
        ]
      },
      {
        "avg_logprob": -0.529217983813996,
        "compression_ratio": 1.11,
        "end": 7420.66,
        "id": 2209,
        "no_speech_prob": 0.0005792861338704824,
        "seek": 740942,
        "start": 7417.9400000000005,
        "temperature": 0,
        "text": " Tabs, false.",
        "tokens": [
          50790,
          14106,
          82,
          11,
          7908,
          13,
          50926
        ]
      },
      {
        "avg_logprob": -0.529217983813996,
        "compression_ratio": 1.11,
        "end": 7427.14,
        "id": 2210,
        "no_speech_prob": 0.0005792861338704824,
        "seek": 740942,
        "start": 7425.78,
        "temperature": 0,
        "text": " Semicolons, true.",
        "tokens": [
          51182,
          318,
          3438,
          401,
          892,
          11,
          2074,
          13,
          51250
        ]
      },
      {
        "avg_logprob": -0.529217983813996,
        "compression_ratio": 1.11,
        "end": 7431.3,
        "id": 2211,
        "no_speech_prob": 0.0005792861338704824,
        "seek": 740942,
        "start": 7429.7,
        "temperature": 0,
        "text": " So these are all the settings.",
        "tokens": [
          51378,
          407,
          613,
          366,
          439,
          264,
          6257,
          13,
          51458
        ]
      },
      {
        "avg_logprob": -0.529217983813996,
        "compression_ratio": 1.11,
        "end": 7439.18,
        "id": 2212,
        "no_speech_prob": 0.0005792861338704824,
        "seek": 740942,
        "start": 7435.86,
        "temperature": 0,
        "text": " Oh, I've gone off a deep end here.",
        "tokens": [
          51686,
          876,
          11,
          286,
          600,
          2780,
          766,
          257,
          2452,
          917,
          510,
          13,
          51852
        ]
      },
      {
        "avg_logprob": -0.5276557136984432,
        "compression_ratio": 1.2340425531914894,
        "end": 7442.820000000001,
        "id": 2213,
        "no_speech_prob": 0.0006563690840266645,
        "seek": 743918,
        "start": 7439.18,
        "temperature": 0,
        "text": " Are people really watching me do this right now?",
        "tokens": [
          50364,
          2014,
          561,
          534,
          1976,
          385,
          360,
          341,
          558,
          586,
          30,
          50546
        ]
      },
      {
        "avg_logprob": -0.5276557136984432,
        "compression_ratio": 1.2340425531914894,
        "end": 7443.9400000000005,
        "id": 2214,
        "no_speech_prob": 0.0006563690840266645,
        "seek": 743918,
        "start": 7442.820000000001,
        "temperature": 0,
        "text": " Right, where is?",
        "tokens": [
          50546,
          1779,
          11,
          689,
          307,
          30,
          50602
        ]
      },
      {
        "avg_logprob": -0.5276557136984432,
        "compression_ratio": 1.2340425531914894,
        "end": 7444.4400000000005,
        "id": 2215,
        "no_speech_prob": 0.0006563690840266645,
        "seek": 743918,
        "start": 7443.9400000000005,
        "temperature": 0,
        "text": " Uh.",
        "tokens": [
          50602,
          4019,
          13,
          50627
        ]
      },
      {
        "avg_logprob": -0.5276557136984432,
        "compression_ratio": 1.2340425531914894,
        "end": 7449.26,
        "id": 2216,
        "no_speech_prob": 0.0006563690840266645,
        "seek": 743918,
        "start": 7448.34,
        "temperature": 0,
        "text": " Look at the chat.",
        "tokens": [
          50822,
          2053,
          412,
          264,
          5081,
          13,
          50868
        ]
      },
      {
        "avg_logprob": -0.5276557136984432,
        "compression_ratio": 1.2340425531914894,
        "end": 7451.740000000001,
        "id": 2217,
        "no_speech_prob": 0.0006563690840266645,
        "seek": 743918,
        "start": 7449.26,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          50868,
          6962,
          322,
          13,
          50992
        ]
      },
      {
        "avg_logprob": -0.5276557136984432,
        "compression_ratio": 1.2340425531914894,
        "end": 7452.240000000001,
        "id": 2218,
        "no_speech_prob": 0.0006563690840266645,
        "seek": 743918,
        "start": 7451.740000000001,
        "temperature": 0,
        "text": " Tab.",
        "tokens": [
          50992,
          14106,
          13,
          51017
        ]
      },
      {
        "avg_logprob": -0.5276557136984432,
        "compression_ratio": 1.2340425531914894,
        "end": 7460.900000000001,
        "id": 2219,
        "no_speech_prob": 0.0006563690840266645,
        "seek": 743918,
        "start": 7458.5,
        "temperature": 0,
        "text": " Oh, GitHub is rendering a six-space tab.",
        "tokens": [
          51330,
          876,
          11,
          23331,
          307,
          22407,
          257,
          2309,
          12,
          24824,
          4421,
          13,
          51450
        ]
      },
      {
        "avg_logprob": -0.5276557136984432,
        "compression_ratio": 1.2340425531914894,
        "end": 7461.900000000001,
        "id": 2220,
        "no_speech_prob": 0.0006563690840266645,
        "seek": 743918,
        "start": 7460.900000000001,
        "temperature": 0,
        "text": " OK, hold on.",
        "tokens": [
          51450,
          2264,
          11,
          1797,
          322,
          13,
          51500
        ]
      },
      {
        "avg_logprob": -0.5276557136984432,
        "compression_ratio": 1.2340425531914894,
        "end": 7463.62,
        "id": 2221,
        "no_speech_prob": 0.0006563690840266645,
        "seek": 743918,
        "start": 7461.900000000001,
        "temperature": 0,
        "text": " Editor tab size 2.",
        "tokens": [
          51500,
          24281,
          4421,
          2744,
          568,
          13,
          51586
        ]
      },
      {
        "avg_logprob": -0.5659526037791419,
        "compression_ratio": 1.3904761904761904,
        "end": 7469.0599999999995,
        "id": 2222,
        "no_speech_prob": 0.012240455485880375,
        "seek": 746362,
        "start": 7464.18,
        "temperature": 0,
        "text": " VS Code prettier settings.",
        "tokens": [
          50392,
          25091,
          15549,
          36825,
          6257,
          13,
          50636
        ]
      },
      {
        "avg_logprob": -0.5659526037791419,
        "compression_ratio": 1.3904761904761904,
        "end": 7472.5599999999995,
        "id": 2223,
        "no_speech_prob": 0.012240455485880375,
        "seek": 746362,
        "start": 7472.0599999999995,
        "temperature": 0,
        "text": " Let's see.",
        "tokens": [
          50786,
          961,
          311,
          536,
          13,
          50811
        ]
      },
      {
        "avg_logprob": -0.5659526037791419,
        "compression_ratio": 1.3904761904761904,
        "end": 7473.0599999999995,
        "id": 2224,
        "no_speech_prob": 0.012240455485880375,
        "seek": 746362,
        "start": 7472.5599999999995,
        "temperature": 0,
        "text": " This.",
        "tokens": [
          50811,
          639,
          13,
          50836
        ]
      },
      {
        "avg_logprob": -0.5659526037791419,
        "compression_ratio": 1.3904761904761904,
        "end": 7478.82,
        "id": 2225,
        "no_speech_prob": 0.012240455485880375,
        "seek": 746362,
        "start": 7475.78,
        "temperature": 0,
        "text": " Yes, yes.",
        "tokens": [
          50972,
          1079,
          11,
          2086,
          13,
          51124
        ]
      },
      {
        "avg_logprob": -0.5659526037791419,
        "compression_ratio": 1.3904761904761904,
        "end": 7479.82,
        "id": 2226,
        "no_speech_prob": 0.012240455485880375,
        "seek": 746362,
        "start": 7478.82,
        "temperature": 0,
        "text": " Pretty, ah, here we go.",
        "tokens": [
          51124,
          10693,
          11,
          3716,
          11,
          510,
          321,
          352,
          13,
          51174
        ]
      },
      {
        "avg_logprob": -0.5659526037791419,
        "compression_ratio": 1.3904761904761904,
        "end": 7480.32,
        "id": 2227,
        "no_speech_prob": 0.012240455485880375,
        "seek": 746362,
        "start": 7479.82,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          51174,
          1692,
          321,
          352,
          13,
          51199
        ]
      },
      {
        "avg_logprob": -0.5659526037791419,
        "compression_ratio": 1.3904761904761904,
        "end": 7480.82,
        "id": 2228,
        "no_speech_prob": 0.012240455485880375,
        "seek": 746362,
        "start": 7480.32,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          51199,
          1692,
          321,
          352,
          13,
          51224
        ]
      },
      {
        "avg_logprob": -0.5659526037791419,
        "compression_ratio": 1.3904761904761904,
        "end": 7492.0599999999995,
        "id": 2229,
        "no_speech_prob": 0.012240455485880375,
        "seek": 746362,
        "start": 7491.54,
        "temperature": 0,
        "text": " Prettier.",
        "tokens": [
          51760,
          9739,
          25402,
          13,
          51786
        ]
      },
      {
        "avg_logprob": -0.5659526037791419,
        "compression_ratio": 1.3904761904761904,
        "end": 7493.5199999999995,
        "id": 2230,
        "no_speech_prob": 0.012240455485880375,
        "seek": 746362,
        "start": 7492.0599999999995,
        "temperature": 0,
        "text": " Oh, there's all these things here.",
        "tokens": [
          51786,
          876,
          11,
          456,
          311,
          439,
          613,
          721,
          510,
          13,
          51859
        ]
      },
      {
        "avg_logprob": -0.43125397050884406,
        "compression_ratio": 1.4242424242424243,
        "end": 7495.56,
        "id": 2231,
        "no_speech_prob": 0.0013249986805021763,
        "seek": 749352,
        "start": 7493.52,
        "temperature": 0,
        "text": " Great, great, great, great, great.",
        "tokens": [
          50364,
          3769,
          11,
          869,
          11,
          869,
          11,
          869,
          11,
          869,
          13,
          50466
        ]
      },
      {
        "avg_logprob": -0.43125397050884406,
        "compression_ratio": 1.4242424242424243,
        "end": 7501.080000000001,
        "id": 2232,
        "no_speech_prob": 0.0013249986805021763,
        "seek": 749352,
        "start": 7495.56,
        "temperature": 0,
        "text": " Prettier tab width 2.",
        "tokens": [
          50466,
          9739,
          25402,
          4421,
          11402,
          568,
          13,
          50742
        ]
      },
      {
        "avg_logprob": -0.43125397050884406,
        "compression_ratio": 1.4242424242424243,
        "end": 7502.040000000001,
        "id": 2233,
        "no_speech_prob": 0.0013249986805021763,
        "seek": 749352,
        "start": 7501.080000000001,
        "temperature": 0,
        "text": " So let's see.",
        "tokens": [
          50742,
          407,
          718,
          311,
          536,
          13,
          50790
        ]
      },
      {
        "avg_logprob": -0.43125397050884406,
        "compression_ratio": 1.4242424242424243,
        "end": 7509.400000000001,
        "id": 2234,
        "no_speech_prob": 0.0013249986805021763,
        "seek": 749352,
        "start": 7508.68,
        "temperature": 0,
        "text": " That's nice.",
        "tokens": [
          51122,
          663,
          311,
          1481,
          13,
          51158
        ]
      },
      {
        "avg_logprob": -0.43125397050884406,
        "compression_ratio": 1.4242424242424243,
        "end": 7511.76,
        "id": 2235,
        "no_speech_prob": 0.0013249986805021763,
        "seek": 749352,
        "start": 7509.400000000001,
        "temperature": 0,
        "text": " OK, I've fixed that.",
        "tokens": [
          51158,
          2264,
          11,
          286,
          600,
          6806,
          300,
          13,
          51276
        ]
      },
      {
        "avg_logprob": -0.43125397050884406,
        "compression_ratio": 1.4242424242424243,
        "end": 7515.96,
        "id": 2236,
        "no_speech_prob": 0.0013249986805021763,
        "seek": 749352,
        "start": 7511.76,
        "temperature": 0,
        "text": " And then what was the other thing that I want now is, oh,",
        "tokens": [
          51276,
          400,
          550,
          437,
          390,
          264,
          661,
          551,
          300,
          286,
          528,
          586,
          307,
          11,
          1954,
          11,
          51486
        ]
      },
      {
        "avg_logprob": -0.43125397050884406,
        "compression_ratio": 1.4242424242424243,
        "end": 7517.76,
        "id": 2237,
        "no_speech_prob": 0.0013249986805021763,
        "seek": 749352,
        "start": 7515.96,
        "temperature": 0,
        "text": " hold on.",
        "tokens": [
          51486,
          1797,
          322,
          13,
          51576
        ]
      },
      {
        "avg_logprob": -0.43125397050884406,
        "compression_ratio": 1.4242424242424243,
        "end": 7520,
        "id": 2238,
        "no_speech_prob": 0.0013249986805021763,
        "seek": 749352,
        "start": 7517.76,
        "temperature": 0,
        "text": " Prettier spaces.",
        "tokens": [
          51576,
          9739,
          25402,
          7673,
          13,
          51688
        ]
      },
      {
        "avg_logprob": -0.5623782078425089,
        "compression_ratio": 1.1320754716981132,
        "end": 7524.02,
        "id": 2239,
        "no_speech_prob": 0.0008968667825683951,
        "seek": 752352,
        "start": 7523.52,
        "temperature": 0,
        "text": " Uh.",
        "tokens": [
          50364,
          4019,
          13,
          50389
        ]
      },
      {
        "avg_logprob": -0.5623782078425089,
        "compression_ratio": 1.1320754716981132,
        "end": 7533.280000000001,
        "id": 2240,
        "no_speech_prob": 0.0008968667825683951,
        "seek": 752352,
        "start": 7530.360000000001,
        "temperature": 0,
        "text": " Use tabs, that must be.",
        "tokens": [
          50706,
          8278,
          20743,
          11,
          300,
          1633,
          312,
          13,
          50852
        ]
      },
      {
        "avg_logprob": -0.5623782078425089,
        "compression_ratio": 1.1320754716981132,
        "end": 7533.780000000001,
        "id": 2241,
        "no_speech_prob": 0.0008968667825683951,
        "seek": 752352,
        "start": 7533.280000000001,
        "temperature": 0,
        "text": " Right.",
        "tokens": [
          50852,
          1779,
          13,
          50877
        ]
      },
      {
        "avg_logprob": -0.5623782078425089,
        "compression_ratio": 1.1320754716981132,
        "end": 7539.4800000000005,
        "id": 2242,
        "no_speech_prob": 0.0008968667825683951,
        "seek": 752352,
        "start": 7538.200000000001,
        "temperature": 0,
        "text": " False.",
        "tokens": [
          51098,
          50040,
          13,
          51162
        ]
      },
      {
        "avg_logprob": -0.5623782078425089,
        "compression_ratio": 1.1320754716981132,
        "end": 7540.56,
        "id": 2243,
        "no_speech_prob": 0.0008968667825683951,
        "seek": 752352,
        "start": 7539.4800000000005,
        "temperature": 0,
        "text": " That's the default value.",
        "tokens": [
          51162,
          663,
          311,
          264,
          7576,
          2158,
          13,
          51216
        ]
      },
      {
        "avg_logprob": -0.5623782078425089,
        "compression_ratio": 1.1320754716981132,
        "end": 7550.6,
        "id": 2244,
        "no_speech_prob": 0.0008968667825683951,
        "seek": 752352,
        "start": 7547,
        "temperature": 0,
        "text": " This is very important what I'm doing right now.",
        "tokens": [
          51538,
          639,
          307,
          588,
          1021,
          437,
          286,
          478,
          884,
          558,
          586,
          13,
          51718
        ]
      },
      {
        "avg_logprob": -0.5623782078425089,
        "compression_ratio": 1.1320754716981132,
        "end": 7551.4800000000005,
        "id": 2245,
        "no_speech_prob": 0.0008968667825683951,
        "seek": 752352,
        "start": 7550.6,
        "temperature": 0,
        "text": " No!",
        "tokens": [
          51718,
          883,
          0,
          51762
        ]
      },
      {
        "avg_logprob": -0.3937373647884447,
        "compression_ratio": 1.5365853658536586,
        "end": 7552.44,
        "id": 2246,
        "no_speech_prob": 0.000743700482416898,
        "seek": 755148,
        "start": 7551.48,
        "temperature": 0,
        "text": " Wait, do I have to?",
        "tokens": [
          50364,
          3802,
          11,
          360,
          286,
          362,
          281,
          30,
          50412
        ]
      },
      {
        "avg_logprob": -0.3937373647884447,
        "compression_ratio": 1.5365853658536586,
        "end": 7562.759999999999,
        "id": 2247,
        "no_speech_prob": 0.000743700482416898,
        "seek": 755148,
        "start": 7560.28,
        "temperature": 0,
        "text": " Why?",
        "tokens": [
          50804,
          1545,
          30,
          50928
        ]
      },
      {
        "avg_logprob": -0.3937373647884447,
        "compression_ratio": 1.5365853658536586,
        "end": 7565.679999999999,
        "id": 2248,
        "no_speech_prob": 0.000743700482416898,
        "seek": 755148,
        "start": 7562.759999999999,
        "temperature": 0,
        "text": " Why is this one still tabs?",
        "tokens": [
          50928,
          1545,
          307,
          341,
          472,
          920,
          20743,
          30,
          51074
        ]
      },
      {
        "avg_logprob": -0.3937373647884447,
        "compression_ratio": 1.5365853658536586,
        "end": 7575.799999999999,
        "id": 2249,
        "no_speech_prob": 0.000743700482416898,
        "seek": 755148,
        "start": 7574.5199999999995,
        "temperature": 0,
        "text": " Why is this one tabs?",
        "tokens": [
          51516,
          1545,
          307,
          341,
          472,
          20743,
          30,
          51580
        ]
      },
      {
        "avg_logprob": -0.3937373647884447,
        "compression_ratio": 1.5365853658536586,
        "end": 7576.48,
        "id": 2250,
        "no_speech_prob": 0.000743700482416898,
        "seek": 755148,
        "start": 7575.799999999999,
        "temperature": 0,
        "text": " What have I done?",
        "tokens": [
          51580,
          708,
          362,
          286,
          1096,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.3937373647884447,
        "compression_ratio": 1.5365853658536586,
        "end": 7579.36,
        "id": 2251,
        "no_speech_prob": 0.000743700482416898,
        "seek": 755148,
        "start": 7576.48,
        "temperature": 0,
        "text": " What have I done to deserve this?",
        "tokens": [
          51614,
          708,
          362,
          286,
          1096,
          281,
          9948,
          341,
          30,
          51758
        ]
      },
      {
        "avg_logprob": -0.5250508202446832,
        "compression_ratio": 1.174757281553398,
        "end": 7581.12,
        "id": 2252,
        "no_speech_prob": 0.00031503697391599417,
        "seek": 757936,
        "start": 7579.36,
        "temperature": 0,
        "text": " Insert spaces when pressing tab.",
        "tokens": [
          50364,
          36487,
          7673,
          562,
          12417,
          4421,
          13,
          50452
        ]
      },
      {
        "avg_logprob": -0.5250508202446832,
        "compression_ratio": 1.174757281553398,
        "end": 7588.04,
        "id": 2253,
        "no_speech_prob": 0.00031503697391599417,
        "seek": 757936,
        "start": 7585,
        "temperature": 0,
        "text": " Text editor auto indent.",
        "tokens": [
          50646,
          18643,
          9839,
          8399,
          44494,
          13,
          50798
        ]
      },
      {
        "avg_logprob": -0.5250508202446832,
        "compression_ratio": 1.174757281553398,
        "end": 7591.5,
        "id": 2254,
        "no_speech_prob": 0.00031503697391599417,
        "seek": 757936,
        "start": 7591,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          50946,
          1079,
          13,
          50971
        ]
      },
      {
        "avg_logprob": -0.5250508202446832,
        "compression_ratio": 1.174757281553398,
        "end": 7604.639999999999,
        "id": 2255,
        "no_speech_prob": 0.00031503697391599417,
        "seek": 757936,
        "start": 7601.48,
        "temperature": 0,
        "text": " Detect, ah.",
        "tokens": [
          51470,
          4237,
          557,
          11,
          3716,
          13,
          51628
        ]
      },
      {
        "avg_logprob": -0.5250508202446832,
        "compression_ratio": 1.174757281553398,
        "end": 7607.599999999999,
        "id": 2256,
        "no_speech_prob": 0.00031503697391599417,
        "seek": 757936,
        "start": 7604.639999999999,
        "temperature": 0,
        "text": " I don't ever want to use tabs.",
        "tokens": [
          51628,
          286,
          500,
          380,
          1562,
          528,
          281,
          764,
          20743,
          13,
          51776
        ]
      },
      {
        "avg_logprob": -0.5250508202446832,
        "compression_ratio": 1.174757281553398,
        "end": 7608.28,
        "id": 2257,
        "no_speech_prob": 0.00031503697391599417,
        "seek": 757936,
        "start": 7607.599999999999,
        "temperature": 0,
        "text": " Let's try that.",
        "tokens": [
          51776,
          961,
          311,
          853,
          300,
          13,
          51810
        ]
      },
      {
        "avg_logprob": -0.43964070689921475,
        "compression_ratio": 1.2105263157894737,
        "end": 7610.46,
        "id": 2258,
        "no_speech_prob": 0.00008888048614608124,
        "seek": 760936,
        "start": 7609.96,
        "temperature": 0,
        "text": " No.",
        "tokens": [
          50394,
          883,
          13,
          50419
        ]
      },
      {
        "avg_logprob": -0.43964070689921475,
        "compression_ratio": 1.2105263157894737,
        "end": 7616.92,
        "id": 2259,
        "no_speech_prob": 0.00008888048614608124,
        "seek": 760936,
        "start": 7613.96,
        "temperature": 0,
        "text": " It's not even formatting it.",
        "tokens": [
          50594,
          467,
          311,
          406,
          754,
          39366,
          309,
          13,
          50742
        ]
      },
      {
        "avg_logprob": -0.43964070689921475,
        "compression_ratio": 1.2105263157894737,
        "end": 7617.42,
        "id": 2260,
        "no_speech_prob": 0.00008888048614608124,
        "seek": 760936,
        "start": 7616.92,
        "temperature": 0,
        "text": " Huh.",
        "tokens": [
          50742,
          8063,
          13,
          50767
        ]
      },
      {
        "avg_logprob": -0.43964070689921475,
        "compression_ratio": 1.2105263157894737,
        "end": 7621.42,
        "id": 2261,
        "no_speech_prob": 0.00008888048614608124,
        "seek": 760936,
        "start": 7620.92,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          50942,
          6962,
          322,
          13,
          50967
        ]
      },
      {
        "avg_logprob": -0.43964070689921475,
        "compression_ratio": 1.2105263157894737,
        "end": 7627.32,
        "id": 2262,
        "no_speech_prob": 0.00008888048614608124,
        "seek": 760936,
        "start": 7624.32,
        "temperature": 0,
        "text": " Why is this?",
        "tokens": [
          51112,
          1545,
          307,
          341,
          30,
          51262
        ]
      },
      {
        "avg_logprob": -0.43964070689921475,
        "compression_ratio": 1.2105263157894737,
        "end": 7629.48,
        "id": 2263,
        "no_speech_prob": 0.00008888048614608124,
        "seek": 760936,
        "start": 7627.32,
        "temperature": 0,
        "text": " Why have I lost my format on save?",
        "tokens": [
          51262,
          1545,
          362,
          286,
          2731,
          452,
          7877,
          322,
          3155,
          30,
          51370
        ]
      },
      {
        "avg_logprob": -0.43964070689921475,
        "compression_ratio": 1.2105263157894737,
        "end": 7639.08,
        "id": 2264,
        "no_speech_prob": 0.00008888048614608124,
        "seek": 760936,
        "start": 7636.679999999999,
        "temperature": 0,
        "text": " Format on save true.",
        "tokens": [
          51730,
          10126,
          267,
          322,
          3155,
          2074,
          13,
          51850
        ]
      },
      {
        "avg_logprob": -0.3564510107040405,
        "compression_ratio": 1.1313131313131313,
        "end": 7640.68,
        "id": 2265,
        "no_speech_prob": 0.000019223158233216964,
        "seek": 763908,
        "start": 7639.28,
        "temperature": 0,
        "text": " Detect indentation false.",
        "tokens": [
          50374,
          4237,
          557,
          44494,
          399,
          7908,
          13,
          50444
        ]
      },
      {
        "avg_logprob": -0.3564510107040405,
        "compression_ratio": 1.1313131313131313,
        "end": 7652.8,
        "id": 2266,
        "no_speech_prob": 0.000019223158233216964,
        "seek": 763908,
        "start": 7651.6,
        "temperature": 0,
        "text": " Restart prettier.",
        "tokens": [
          50990,
          13094,
          446,
          36825,
          13,
          51050
        ]
      },
      {
        "avg_logprob": -0.3564510107040405,
        "compression_ratio": 1.1313131313131313,
        "end": 7654.2,
        "id": 2267,
        "no_speech_prob": 0.000019223158233216964,
        "seek": 763908,
        "start": 7652.8,
        "temperature": 0,
        "text": " Yeah, that's a good idea.",
        "tokens": [
          51050,
          865,
          11,
          300,
          311,
          257,
          665,
          1558,
          13,
          51120
        ]
      },
      {
        "avg_logprob": -0.3564510107040405,
        "compression_ratio": 1.1313131313131313,
        "end": 7656.96,
        "id": 2268,
        "no_speech_prob": 0.000019223158233216964,
        "seek": 763908,
        "start": 7654.2,
        "temperature": 0,
        "text": " Let's just restart the whole thing.",
        "tokens": [
          51120,
          961,
          311,
          445,
          21022,
          264,
          1379,
          551,
          13,
          51258
        ]
      },
      {
        "avg_logprob": -0.3564510107040405,
        "compression_ratio": 1.1313131313131313,
        "end": 7668.6,
        "id": 2269,
        "no_speech_prob": 0.000019223158233216964,
        "seek": 763908,
        "start": 7666.8,
        "temperature": 0,
        "text": " Weird.",
        "tokens": [
          51750,
          32033,
          13,
          51840
        ]
      },
      {
        "avg_logprob": -0.4148194122314453,
        "compression_ratio": 0.9411764705882353,
        "end": 7672.76,
        "id": 2270,
        "no_speech_prob": 0.0021155946888029575,
        "seek": 766860,
        "start": 7668.6,
        "temperature": 0,
        "text": " Let's go to extensions, prettier.",
        "tokens": [
          50364,
          961,
          311,
          352,
          281,
          25129,
          11,
          36825,
          13,
          50572
        ]
      },
      {
        "avg_logprob": -0.4148194122314453,
        "compression_ratio": 0.9411764705882353,
        "end": 7673.26,
        "id": 2271,
        "no_speech_prob": 0.0021155946888029575,
        "seek": 766860,
        "start": 7672.76,
        "temperature": 0,
        "text": " No.",
        "tokens": [
          50572,
          883,
          13,
          50597
        ]
      },
      {
        "avg_logprob": -0.4148194122314453,
        "compression_ratio": 0.9411764705882353,
        "end": 7679.84,
        "id": 2272,
        "no_speech_prob": 0.0021155946888029575,
        "seek": 766860,
        "start": 7678.76,
        "temperature": 0,
        "text": " All right, let's try this.",
        "tokens": [
          50872,
          1057,
          558,
          11,
          718,
          311,
          853,
          341,
          13,
          50926
        ]
      },
      {
        "avg_logprob": -0.9742905466180098,
        "compression_ratio": 1.1772151898734178,
        "end": 7701.200000000001,
        "id": 2273,
        "no_speech_prob": 0.0005792901501990855,
        "seek": 769860,
        "start": 7699.6,
        "temperature": 0,
        "text": " Oh, it's not formatting on save.",
        "tokens": [
          50414,
          876,
          11,
          309,
          311,
          406,
          39366,
          322,
          3155,
          13,
          50494
        ]
      },
      {
        "avg_logprob": -0.9742905466180098,
        "compression_ratio": 1.1772151898734178,
        "end": 7707.92,
        "id": 2274,
        "no_speech_prob": 0.0005792901501990855,
        "seek": 769860,
        "start": 7707.200000000001,
        "temperature": 0,
        "text": " OK, now it is.",
        "tokens": [
          50794,
          2264,
          11,
          586,
          309,
          307,
          13,
          50830
        ]
      },
      {
        "avg_logprob": -0.9742905466180098,
        "compression_ratio": 1.1772151898734178,
        "end": 7712.6,
        "id": 2275,
        "no_speech_prob": 0.0005792901501990855,
        "seek": 769860,
        "start": 7711.52,
        "temperature": 0,
        "text": " I don't need this, though.",
        "tokens": [
          51010,
          286,
          500,
          380,
          643,
          341,
          11,
          1673,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.9742905466180098,
        "compression_ratio": 1.1772151898734178,
        "end": 7723.400000000001,
        "id": 2276,
        "no_speech_prob": 0.0005792901501990855,
        "seek": 769860,
        "start": 7722.6,
        "temperature": 0,
        "text": " I don't need this.",
        "tokens": [
          51564,
          286,
          500,
          380,
          643,
          341,
          13,
          51604
        ]
      },
      {
        "avg_logprob": -0.5476092676962575,
        "compression_ratio": 1.0555555555555556,
        "end": 7730.06,
        "id": 2277,
        "no_speech_prob": 0.0028448377270251513,
        "seek": 772860,
        "start": 7729.56,
        "temperature": 0,
        "text": " Ugh.",
        "tokens": [
          50412,
          16506,
          13,
          50437
        ]
      },
      {
        "avg_logprob": -0.5476092676962575,
        "compression_ratio": 1.0555555555555556,
        "end": 7743.160000000001,
        "id": 2278,
        "no_speech_prob": 0.0028448377270251513,
        "seek": 772860,
        "start": 7740.200000000001,
        "temperature": 0,
        "text": " I saved it as a new file and it reformatted it.",
        "tokens": [
          50944,
          286,
          6624,
          309,
          382,
          257,
          777,
          3991,
          293,
          309,
          8290,
          32509,
          309,
          13,
          51092
        ]
      },
      {
        "avg_logprob": -0.5476092676962575,
        "compression_ratio": 1.0555555555555556,
        "end": 7749.1,
        "id": 2279,
        "no_speech_prob": 0.0028448377270251513,
        "seek": 772860,
        "start": 7748.6,
        "temperature": 0,
        "text": " Weird.",
        "tokens": [
          51364,
          32033,
          13,
          51389
        ]
      },
      {
        "avg_logprob": -0.5476092676962575,
        "compression_ratio": 1.0555555555555556,
        "end": 7756.64,
        "id": 2280,
        "no_speech_prob": 0.0028448377270251513,
        "seek": 772860,
        "start": 7755.4400000000005,
        "temperature": 0,
        "text": " There, fixed it.",
        "tokens": [
          51706,
          821,
          11,
          6806,
          309,
          13,
          51766
        ]
      },
      {
        "avg_logprob": -0.3874197006225586,
        "compression_ratio": 1.5473684210526315,
        "end": 7762.08,
        "id": 2281,
        "no_speech_prob": 0.0005112515646032989,
        "seek": 775860,
        "start": 7759.6,
        "temperature": 0,
        "text": " This is fine.",
        "tokens": [
          50414,
          639,
          307,
          2489,
          13,
          50538
        ]
      },
      {
        "avg_logprob": -0.3874197006225586,
        "compression_ratio": 1.5473684210526315,
        "end": 7763.4400000000005,
        "id": 2282,
        "no_speech_prob": 0.0005112515646032989,
        "seek": 775860,
        "start": 7762.08,
        "temperature": 0,
        "text": " This is fine.",
        "tokens": [
          50538,
          639,
          307,
          2489,
          13,
          50606
        ]
      },
      {
        "avg_logprob": -0.3874197006225586,
        "compression_ratio": 1.5473684210526315,
        "end": 7764.160000000001,
        "id": 2283,
        "no_speech_prob": 0.0005112515646032989,
        "seek": 775860,
        "start": 7763.4400000000005,
        "temperature": 0,
        "text": " And this is fine.",
        "tokens": [
          50606,
          400,
          341,
          307,
          2489,
          13,
          50642
        ]
      },
      {
        "avg_logprob": -0.3874197006225586,
        "compression_ratio": 1.5473684210526315,
        "end": 7767.52,
        "id": 2284,
        "no_speech_prob": 0.0005112515646032989,
        "seek": 775860,
        "start": 7764.160000000001,
        "temperature": 0,
        "text": " I don't know what was wrong with that one file.",
        "tokens": [
          50642,
          286,
          500,
          380,
          458,
          437,
          390,
          2085,
          365,
          300,
          472,
          3991,
          13,
          50810
        ]
      },
      {
        "avg_logprob": -0.3874197006225586,
        "compression_ratio": 1.5473684210526315,
        "end": 7768.56,
        "id": 2285,
        "no_speech_prob": 0.0005112515646032989,
        "seek": 775860,
        "start": 7767.52,
        "temperature": 0,
        "text": " This is spaces.",
        "tokens": [
          50810,
          639,
          307,
          7673,
          13,
          50862
        ]
      },
      {
        "avg_logprob": -0.3874197006225586,
        "compression_ratio": 1.5473684210526315,
        "end": 7769.360000000001,
        "id": 2286,
        "no_speech_prob": 0.0005112515646032989,
        "seek": 775860,
        "start": 7768.56,
        "temperature": 0,
        "text": " This is spaces.",
        "tokens": [
          50862,
          639,
          307,
          7673,
          13,
          50902
        ]
      },
      {
        "avg_logprob": -0.3874197006225586,
        "compression_ratio": 1.5473684210526315,
        "end": 7784.68,
        "id": 2287,
        "no_speech_prob": 0.0005112515646032989,
        "seek": 775860,
        "start": 7775.08,
        "temperature": 0,
        "text": " And spaces, not tabs.",
        "tokens": [
          51188,
          400,
          7673,
          11,
          406,
          20743,
          13,
          51668
        ]
      },
      {
        "avg_logprob": -0.6509104037503584,
        "compression_ratio": 1.53475935828877,
        "end": 7790.76,
        "id": 2288,
        "no_speech_prob": 0.0031235679052770138,
        "seek": 778860,
        "start": 7788.6,
        "temperature": 0,
        "text": " Oh, that was scary.",
        "tokens": [
          50364,
          876,
          11,
          300,
          390,
          6958,
          13,
          50472
        ]
      },
      {
        "avg_logprob": -0.6509104037503584,
        "compression_ratio": 1.53475935828877,
        "end": 7792.88,
        "id": 2289,
        "no_speech_prob": 0.0031235679052770138,
        "seek": 778860,
        "start": 7790.76,
        "temperature": 0,
        "text": " Oh, but my quick draw stuff.",
        "tokens": [
          50472,
          876,
          11,
          457,
          452,
          1702,
          2642,
          1507,
          13,
          50578
        ]
      },
      {
        "avg_logprob": -0.6509104037503584,
        "compression_ratio": 1.53475935828877,
        "end": 7794.360000000001,
        "id": 2290,
        "no_speech_prob": 0.0031235679052770138,
        "seek": 778860,
        "start": 7792.88,
        "temperature": 0,
        "text": " Ooh.",
        "tokens": [
          50578,
          7951,
          13,
          50652
        ]
      },
      {
        "avg_logprob": -0.6509104037503584,
        "compression_ratio": 1.53475935828877,
        "end": 7796.360000000001,
        "id": 2291,
        "no_speech_prob": 0.0031235679052770138,
        "seek": 778860,
        "start": 7794.360000000001,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          50652,
          6962,
          322,
          13,
          50752
        ]
      },
      {
        "avg_logprob": -0.6509104037503584,
        "compression_ratio": 1.53475935828877,
        "end": 7796.860000000001,
        "id": 2292,
        "no_speech_prob": 0.0031235679052770138,
        "seek": 778860,
        "start": 7796.360000000001,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          50752,
          6962,
          322,
          13,
          50777
        ]
      },
      {
        "avg_logprob": -0.6509104037503584,
        "compression_ratio": 1.53475935828877,
        "end": 7799.280000000001,
        "id": 2293,
        "no_speech_prob": 0.0031235679052770138,
        "seek": 778860,
        "start": 7796.860000000001,
        "temperature": 0,
        "text": " Ah, pull requests.",
        "tokens": [
          50777,
          2438,
          11,
          2235,
          12475,
          13,
          50898
        ]
      },
      {
        "avg_logprob": -0.6509104037503584,
        "compression_ratio": 1.53475935828877,
        "end": 7801.120000000001,
        "id": 2294,
        "no_speech_prob": 0.0031235679052770138,
        "seek": 778860,
        "start": 7799.280000000001,
        "temperature": 0,
        "text": " Oh, I didn't actually make the pull request.",
        "tokens": [
          50898,
          876,
          11,
          286,
          994,
          380,
          767,
          652,
          264,
          2235,
          5308,
          13,
          50990
        ]
      },
      {
        "avg_logprob": -0.6509104037503584,
        "compression_ratio": 1.53475935828877,
        "end": 7801.88,
        "id": 2295,
        "no_speech_prob": 0.0031235679052770138,
        "seek": 778860,
        "start": 7801.120000000001,
        "temperature": 0,
        "text": " OK, so hold on.",
        "tokens": [
          50990,
          2264,
          11,
          370,
          1797,
          322,
          13,
          51028
        ]
      },
      {
        "avg_logprob": -0.6509104037503584,
        "compression_ratio": 1.53475935828877,
        "end": 7805.360000000001,
        "id": 2296,
        "no_speech_prob": 0.0031235679052770138,
        "seek": 778860,
        "start": 7801.88,
        "temperature": 0,
        "text": " Now, everybody just relax.",
        "tokens": [
          51028,
          823,
          11,
          2201,
          445,
          5789,
          13,
          51202
        ]
      },
      {
        "avg_logprob": -0.6509104037503584,
        "compression_ratio": 1.53475935828877,
        "end": 7807.84,
        "id": 2297,
        "no_speech_prob": 0.0031235679052770138,
        "seek": 778860,
        "start": 7805.360000000001,
        "temperature": 0,
        "text": " I can't believe how much time I've been doing this.",
        "tokens": [
          51202,
          286,
          393,
          380,
          1697,
          577,
          709,
          565,
          286,
          600,
          668,
          884,
          341,
          13,
          51326
        ]
      },
      {
        "avg_logprob": -0.6509104037503584,
        "compression_ratio": 1.53475935828877,
        "end": 7808.56,
        "id": 2298,
        "no_speech_prob": 0.0031235679052770138,
        "seek": 778860,
        "start": 7807.84,
        "temperature": 0,
        "text": " What was it called?",
        "tokens": [
          51326,
          708,
          390,
          309,
          1219,
          30,
          51362
        ]
      },
      {
        "avg_logprob": -0.6509104037503584,
        "compression_ratio": 1.53475935828877,
        "end": 7809.280000000001,
        "id": 2299,
        "no_speech_prob": 0.0031235679052770138,
        "seek": 778860,
        "start": 7808.56,
        "temperature": 0,
        "text": " Quick draw?",
        "tokens": [
          51362,
          12101,
          2642,
          30,
          51398
        ]
      },
      {
        "avg_logprob": -0.6509104037503584,
        "compression_ratio": 1.53475935828877,
        "end": 7809.76,
        "id": 2300,
        "no_speech_prob": 0.0031235679052770138,
        "seek": 778860,
        "start": 7809.280000000001,
        "temperature": 0,
        "text": " Oh, hold on.",
        "tokens": [
          51398,
          876,
          11,
          1797,
          322,
          13,
          51422
        ]
      },
      {
        "avg_logprob": -0.6509104037503584,
        "compression_ratio": 1.53475935828877,
        "end": 7815.240000000001,
        "id": 2301,
        "no_speech_prob": 0.0031235679052770138,
        "seek": 778860,
        "start": 7814.76,
        "temperature": 0,
        "text": " Quick draw.",
        "tokens": [
          51672,
          12101,
          2642,
          13,
          51696
        ]
      },
      {
        "avg_logprob": -0.6749386787414551,
        "compression_ratio": 1.3617021276595744,
        "end": 7817.44,
        "id": 2302,
        "no_speech_prob": 0.00017674481205176562,
        "seek": 781524,
        "start": 7816.24,
        "temperature": 0,
        "text": " Wait, where's my quick draw?",
        "tokens": [
          50414,
          3802,
          11,
          689,
          311,
          452,
          1702,
          2642,
          30,
          50474
        ]
      },
      {
        "avg_logprob": -0.6749386787414551,
        "compression_ratio": 1.3617021276595744,
        "end": 7817.94,
        "id": 2303,
        "no_speech_prob": 0.00017674481205176562,
        "seek": 781524,
        "start": 7817.44,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          50474,
          865,
          13,
          50499
        ]
      },
      {
        "avg_logprob": -0.6749386787414551,
        "compression_ratio": 1.3617021276595744,
        "end": 7823.639999999999,
        "id": 2304,
        "no_speech_prob": 0.00017674481205176562,
        "seek": 781524,
        "start": 7821.44,
        "temperature": 0,
        "text": " We go to this branch.",
        "tokens": [
          50674,
          492,
          352,
          281,
          341,
          9819,
          13,
          50784
        ]
      },
      {
        "avg_logprob": -0.6749386787414551,
        "compression_ratio": 1.3617021276595744,
        "end": 7828.36,
        "id": 2305,
        "no_speech_prob": 0.00017674481205176562,
        "seek": 781524,
        "start": 7823.639999999999,
        "temperature": 0,
        "text": " And then here, that's spaces.",
        "tokens": [
          50784,
          400,
          550,
          510,
          11,
          300,
          311,
          7673,
          13,
          51020
        ]
      },
      {
        "avg_logprob": -0.6749386787414551,
        "compression_ratio": 1.3617021276595744,
        "end": 7831.04,
        "id": 2306,
        "no_speech_prob": 0.00017674481205176562,
        "seek": 781524,
        "start": 7828.36,
        "temperature": 0,
        "text": " Oh, tabs.",
        "tokens": [
          51020,
          876,
          11,
          20743,
          13,
          51154
        ]
      },
      {
        "avg_logprob": -0.6749386787414551,
        "compression_ratio": 1.3617021276595744,
        "end": 7833.76,
        "id": 2307,
        "no_speech_prob": 0.00017674481205176562,
        "seek": 781524,
        "start": 7831.04,
        "temperature": 0,
        "text": " Oh, this file, too.",
        "tokens": [
          51154,
          876,
          11,
          341,
          3991,
          11,
          886,
          13,
          51290
        ]
      },
      {
        "avg_logprob": -0.6749386787414551,
        "compression_ratio": 1.3617021276595744,
        "end": 7834.96,
        "id": 2308,
        "no_speech_prob": 0.00017674481205176562,
        "seek": 781524,
        "start": 7833.76,
        "temperature": 0,
        "text": " What is it with the files?",
        "tokens": [
          51290,
          708,
          307,
          309,
          365,
          264,
          7098,
          30,
          51350
        ]
      },
      {
        "avg_logprob": -0.6749386787414551,
        "compression_ratio": 1.3617021276595744,
        "end": 7839.4,
        "id": 2309,
        "no_speech_prob": 0.00017674481205176562,
        "seek": 781524,
        "start": 7834.96,
        "temperature": 0,
        "text": " What if I manually, like, why are certain files?",
        "tokens": [
          51350,
          708,
          498,
          286,
          16945,
          11,
          411,
          11,
          983,
          366,
          1629,
          7098,
          30,
          51572
        ]
      },
      {
        "avg_logprob": -0.8653446495110262,
        "compression_ratio": 2.2485549132947975,
        "end": 7842.799999999999,
        "id": 2310,
        "no_speech_prob": 0.0007916282629594207,
        "seek": 783940,
        "start": 7839.96,
        "temperature": 0.4,
        "text": " Not formatting.",
        "tokens": [
          50392,
          1726,
          39366,
          13,
          50534
        ]
      },
      {
        "avg_logprob": -0.8653446495110262,
        "compression_ratio": 2.2485549132947975,
        "end": 7843.799999999999,
        "id": 2311,
        "no_speech_prob": 0.0007916282629594207,
        "seek": 783940,
        "start": 7842.799999999999,
        "temperature": 0.4,
        "text": " That's so weird.",
        "tokens": [
          50534,
          663,
          311,
          370,
          3657,
          13,
          50584
        ]
      },
      {
        "avg_logprob": -0.8653446495110262,
        "compression_ratio": 2.2485549132947975,
        "end": 7844.719999999999,
        "id": 2312,
        "no_speech_prob": 0.0007916282629594207,
        "seek": 783940,
        "start": 7843.799999999999,
        "temperature": 0.4,
        "text": " I've never seen this.",
        "tokens": [
          50584,
          286,
          600,
          1128,
          1612,
          341,
          13,
          50630
        ]
      },
      {
        "avg_logprob": -0.8653446495110262,
        "compression_ratio": 2.2485549132947975,
        "end": 7846.28,
        "id": 2313,
        "no_speech_prob": 0.0007916282629594207,
        "seek": 783940,
        "start": 7844.719999999999,
        "temperature": 0.4,
        "text": " Whoops.",
        "tokens": [
          50630,
          45263,
          13,
          50708
        ]
      },
      {
        "avg_logprob": -0.8653446495110262,
        "compression_ratio": 2.2485549132947975,
        "end": 7849.44,
        "id": 2314,
        "no_speech_prob": 0.0007916282629594207,
        "seek": 783940,
        "start": 7846.28,
        "temperature": 0.4,
        "text": " Format, document, format.",
        "tokens": [
          50708,
          10126,
          267,
          11,
          4166,
          11,
          7877,
          13,
          50866
        ]
      },
      {
        "avg_logprob": -0.8653446495110262,
        "compression_ratio": 2.2485549132947975,
        "end": 7849.92,
        "id": 2315,
        "no_speech_prob": 0.0007916282629594207,
        "seek": 783940,
        "start": 7849.44,
        "temperature": 0.4,
        "text": " Save.",
        "tokens": [
          50866,
          15541,
          13,
          50890
        ]
      },
      {
        "avg_logprob": -0.8653446495110262,
        "compression_ratio": 2.2485549132947975,
        "end": 7852.12,
        "id": 2316,
        "no_speech_prob": 0.0007916282629594207,
        "seek": 783940,
        "start": 7849.92,
        "temperature": 0.4,
        "text": " Format selection.",
        "tokens": [
          50890,
          10126,
          267,
          9450,
          13,
          51000
        ]
      },
      {
        "avg_logprob": -0.8653446495110262,
        "compression_ratio": 2.2485549132947975,
        "end": 7853.28,
        "id": 2317,
        "no_speech_prob": 0.0007916282629594207,
        "seek": 783940,
        "start": 7852.12,
        "temperature": 0.4,
        "text": " Whoops.",
        "tokens": [
          51000,
          45263,
          13,
          51058
        ]
      },
      {
        "avg_logprob": -0.8653446495110262,
        "compression_ratio": 2.2485549132947975,
        "end": 7854.2,
        "id": 2318,
        "no_speech_prob": 0.0007916282629594207,
        "seek": 783940,
        "start": 7853.28,
        "temperature": 0.4,
        "text": " Oh, that did it.",
        "tokens": [
          51058,
          876,
          11,
          300,
          630,
          309,
          13,
          51104
        ]
      },
      {
        "avg_logprob": -0.8653446495110262,
        "compression_ratio": 2.2485549132947975,
        "end": 7857.5199999999995,
        "id": 2319,
        "no_speech_prob": 0.0007916282629594207,
        "seek": 783940,
        "start": 7854.2,
        "temperature": 0.4,
        "text": " Format selection did it.",
        "tokens": [
          51104,
          10126,
          267,
          9450,
          630,
          309,
          13,
          51270
        ]
      },
      {
        "avg_logprob": -0.8653446495110262,
        "compression_ratio": 2.2485549132947975,
        "end": 7859.16,
        "id": 2320,
        "no_speech_prob": 0.0007916282629594207,
        "seek": 783940,
        "start": 7857.5199999999995,
        "temperature": 0.4,
        "text": " I can't explain it.",
        "tokens": [
          51270,
          286,
          393,
          380,
          2903,
          309,
          13,
          51352
        ]
      },
      {
        "avg_logprob": -0.8653446495110262,
        "compression_ratio": 2.2485549132947975,
        "end": 7860.679999999999,
        "id": 2321,
        "no_speech_prob": 0.0007916282629594207,
        "seek": 783940,
        "start": 7859.16,
        "temperature": 0.4,
        "text": " I'm not sure what's going on here.",
        "tokens": [
          51352,
          286,
          478,
          406,
          988,
          437,
          311,
          516,
          322,
          510,
          13,
          51428
        ]
      },
      {
        "avg_logprob": -0.8653446495110262,
        "compression_ratio": 2.2485549132947975,
        "end": 7862.2,
        "id": 2322,
        "no_speech_prob": 0.0007916282629594207,
        "seek": 783940,
        "start": 7860.679999999999,
        "temperature": 0.4,
        "text": " I'm going to go back to my document.",
        "tokens": [
          51428,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          452,
          4166,
          13,
          51504
        ]
      },
      {
        "avg_logprob": -0.8653446495110262,
        "compression_ratio": 2.2485549132947975,
        "end": 7863.719999999999,
        "id": 2323,
        "no_speech_prob": 0.0007916282629594207,
        "seek": 783940,
        "start": 7862.2,
        "temperature": 0.4,
        "text": " I'm going to go back to my document.",
        "tokens": [
          51504,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          452,
          4166,
          13,
          51580
        ]
      },
      {
        "avg_logprob": -0.8653446495110262,
        "compression_ratio": 2.2485549132947975,
        "end": 7865.36,
        "id": 2324,
        "no_speech_prob": 0.0007916282629594207,
        "seek": 783940,
        "start": 7863.719999999999,
        "temperature": 0.4,
        "text": " I'm going to go back to my document.",
        "tokens": [
          51580,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          452,
          4166,
          13,
          51662
        ]
      },
      {
        "avg_logprob": -0.8653446495110262,
        "compression_ratio": 2.2485549132947975,
        "end": 7866.839999999999,
        "id": 2325,
        "no_speech_prob": 0.0007916282629594207,
        "seek": 783940,
        "start": 7865.36,
        "temperature": 0.4,
        "text": " And here's my document.",
        "tokens": [
          51662,
          400,
          510,
          311,
          452,
          4166,
          13,
          51736
        ]
      },
      {
        "avg_logprob": -0.8653446495110262,
        "compression_ratio": 2.2485549132947975,
        "end": 7868.4,
        "id": 2326,
        "no_speech_prob": 0.0007916282629594207,
        "seek": 783940,
        "start": 7866.839999999999,
        "temperature": 0.4,
        "text": " I'm going to go back to my document.",
        "tokens": [
          51736,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          452,
          4166,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.32914726643622677,
        "compression_ratio": 1.2653061224489797,
        "end": 7869.599999999999,
        "id": 2327,
        "no_speech_prob": 0.00006204966484801844,
        "seek": 786840,
        "start": 7868.48,
        "temperature": 0,
        "text": " I can't explain it.",
        "tokens": [
          50368,
          286,
          393,
          380,
          2903,
          309,
          13,
          50424
        ]
      },
      {
        "avg_logprob": -0.32914726643622677,
        "compression_ratio": 1.2653061224489797,
        "end": 7873.719999999999,
        "id": 2328,
        "no_speech_prob": 0.00006204966484801844,
        "seek": 786840,
        "start": 7872.639999999999,
        "temperature": 0,
        "text": " Where am I?",
        "tokens": [
          50576,
          2305,
          669,
          286,
          30,
          50630
        ]
      },
      {
        "avg_logprob": -0.32914726643622677,
        "compression_ratio": 1.2653061224489797,
        "end": 7875.719999999999,
        "id": 2329,
        "no_speech_prob": 0.00006204966484801844,
        "seek": 786840,
        "start": 7873.719999999999,
        "temperature": 0,
        "text": " But that did it.",
        "tokens": [
          50630,
          583,
          300,
          630,
          309,
          13,
          50730
        ]
      },
      {
        "avg_logprob": -0.32914726643622677,
        "compression_ratio": 1.2653061224489797,
        "end": 7881.839999999999,
        "id": 2330,
        "no_speech_prob": 0.00006204966484801844,
        "seek": 786840,
        "start": 7881.24,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          51006,
          1779,
          30,
          51036
        ]
      },
      {
        "avg_logprob": -0.32914726643622677,
        "compression_ratio": 1.2653061224489797,
        "end": 7883.839999999999,
        "id": 2331,
        "no_speech_prob": 0.00006204966484801844,
        "seek": 786840,
        "start": 7881.839999999999,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51036,
          865,
          13,
          51136
        ]
      },
      {
        "avg_logprob": -0.32914726643622677,
        "compression_ratio": 1.2653061224489797,
        "end": 7884.339999999999,
        "id": 2332,
        "no_speech_prob": 0.00006204966484801844,
        "seek": 786840,
        "start": 7883.839999999999,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51136,
          2264,
          13,
          51161
        ]
      },
      {
        "avg_logprob": -0.32914726643622677,
        "compression_ratio": 1.2653061224489797,
        "end": 7890.04,
        "id": 2333,
        "no_speech_prob": 0.00006204966484801844,
        "seek": 786840,
        "start": 7887.04,
        "temperature": 0,
        "text": " Oh, it's because of this file, maybe.",
        "tokens": [
          51296,
          876,
          11,
          309,
          311,
          570,
          295,
          341,
          3991,
          11,
          1310,
          13,
          51446
        ]
      },
      {
        "avg_logprob": -0.32914726643622677,
        "compression_ratio": 1.2653061224489797,
        "end": 7891.4,
        "id": 2334,
        "no_speech_prob": 0.00006204966484801844,
        "seek": 786840,
        "start": 7890.04,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51446,
          865,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.32914726643622677,
        "compression_ratio": 1.2653061224489797,
        "end": 7892.5599999999995,
        "id": 2335,
        "no_speech_prob": 0.00006204966484801844,
        "seek": 786840,
        "start": 7891.4,
        "temperature": 0,
        "text": " Because I'm in this repo.",
        "tokens": [
          51514,
          1436,
          286,
          478,
          294,
          341,
          49040,
          13,
          51572
        ]
      },
      {
        "avg_logprob": -0.32914726643622677,
        "compression_ratio": 1.2653061224489797,
        "end": 7893.719999999999,
        "id": 2336,
        "no_speech_prob": 0.00006204966484801844,
        "seek": 786840,
        "start": 7892.5599999999995,
        "temperature": 0,
        "text": " That's probably why.",
        "tokens": [
          51572,
          663,
          311,
          1391,
          983,
          13,
          51630
        ]
      },
      {
        "avg_logprob": -0.32914726643622677,
        "compression_ratio": 1.2653061224489797,
        "end": 7897.679999999999,
        "id": 2337,
        "no_speech_prob": 0.00006204966484801844,
        "seek": 786840,
        "start": 7896.36,
        "temperature": 0,
        "text": " It must be, like, picking up.",
        "tokens": [
          51762,
          467,
          1633,
          312,
          11,
          411,
          11,
          8867,
          493,
          13,
          51828
        ]
      },
      {
        "avg_logprob": -0.3210588879055447,
        "compression_ratio": 1.1717171717171717,
        "end": 7899.360000000001,
        "id": 2338,
        "no_speech_prob": 0.000045397686335491017,
        "seek": 789768,
        "start": 7897.68,
        "temperature": 0,
        "text": " Oh, it's picking up settings from here.",
        "tokens": [
          50364,
          876,
          11,
          309,
          311,
          8867,
          493,
          6257,
          490,
          510,
          13,
          50448
        ]
      },
      {
        "avg_logprob": -0.3210588879055447,
        "compression_ratio": 1.1717171717171717,
        "end": 7903.320000000001,
        "id": 2339,
        "no_speech_prob": 0.000045397686335491017,
        "seek": 789768,
        "start": 7902.4800000000005,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          50604,
          865,
          13,
          50646
        ]
      },
      {
        "avg_logprob": -0.3210588879055447,
        "compression_ratio": 1.1717171717171717,
        "end": 7904.72,
        "id": 2340,
        "no_speech_prob": 0.000045397686335491017,
        "seek": 789768,
        "start": 7903.320000000001,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50646,
          1057,
          558,
          13,
          50716
        ]
      },
      {
        "avg_logprob": -0.3210588879055447,
        "compression_ratio": 1.1717171717171717,
        "end": 7905.64,
        "id": 2341,
        "no_speech_prob": 0.000045397686335491017,
        "seek": 789768,
        "start": 7904.72,
        "temperature": 0,
        "text": " That's got to be it.",
        "tokens": [
          50716,
          663,
          311,
          658,
          281,
          312,
          309,
          13,
          50762
        ]
      },
      {
        "avg_logprob": -0.3210588879055447,
        "compression_ratio": 1.1717171717171717,
        "end": 7906.14,
        "id": 2342,
        "no_speech_prob": 0.000045397686335491017,
        "seek": 789768,
        "start": 7905.64,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50762,
          1057,
          558,
          13,
          50787
        ]
      },
      {
        "avg_logprob": -0.3210588879055447,
        "compression_ratio": 1.1717171717171717,
        "end": 7914.400000000001,
        "id": 2343,
        "no_speech_prob": 0.000045397686335491017,
        "seek": 789768,
        "start": 7913.200000000001,
        "temperature": 0,
        "text": " I know the camera went off.",
        "tokens": [
          51140,
          286,
          458,
          264,
          2799,
          1437,
          766,
          13,
          51200
        ]
      },
      {
        "avg_logprob": -0.3801288604736328,
        "compression_ratio": 1.4968944099378882,
        "end": 7928.8,
        "id": 2344,
        "no_speech_prob": 0.00014653027756139636,
        "seek": 792768,
        "start": 7928.200000000001,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50390,
          1057,
          558,
          13,
          50420
        ]
      },
      {
        "avg_logprob": -0.3801288604736328,
        "compression_ratio": 1.4968944099378882,
        "end": 7930.68,
        "id": 2345,
        "no_speech_prob": 0.00014653027756139636,
        "seek": 792768,
        "start": 7928.8,
        "temperature": 0,
        "text": " Let's finish these pull requests, people.",
        "tokens": [
          50420,
          961,
          311,
          2413,
          613,
          2235,
          12475,
          11,
          561,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.3801288604736328,
        "compression_ratio": 1.4968944099378882,
        "end": 7938.72,
        "id": 2346,
        "no_speech_prob": 0.00014653027756139636,
        "seek": 792768,
        "start": 7938.12,
        "temperature": 0,
        "text": " Oh, wait, no.",
        "tokens": [
          50886,
          876,
          11,
          1699,
          11,
          572,
          13,
          50916
        ]
      },
      {
        "avg_logprob": -0.3801288604736328,
        "compression_ratio": 1.4968944099378882,
        "end": 7939.22,
        "id": 2347,
        "no_speech_prob": 0.00014653027756139636,
        "seek": 792768,
        "start": 7938.72,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          50916,
          6962,
          322,
          13,
          50941
        ]
      },
      {
        "avg_logprob": -0.3801288604736328,
        "compression_ratio": 1.4968944099378882,
        "end": 7942.72,
        "id": 2348,
        "no_speech_prob": 0.00014653027756139636,
        "seek": 792768,
        "start": 7939.22,
        "temperature": 0,
        "text": " Let's do the quick draw one first.",
        "tokens": [
          50941,
          961,
          311,
          360,
          264,
          1702,
          2642,
          472,
          700,
          13,
          51116
        ]
      },
      {
        "avg_logprob": -0.3801288604736328,
        "compression_ratio": 1.4968944099378882,
        "end": 7950.96,
        "id": 2349,
        "no_speech_prob": 0.00014653027756139636,
        "seek": 792768,
        "start": 7942.72,
        "temperature": 0,
        "text": " This is the quick draw code for challenge 122.",
        "tokens": [
          51116,
          639,
          307,
          264,
          1702,
          2642,
          3089,
          337,
          3430,
          2272,
          17,
          13,
          51528
        ]
      },
      {
        "avg_logprob": -0.3801288604736328,
        "compression_ratio": 1.4968944099378882,
        "end": 7952.08,
        "id": 2350,
        "no_speech_prob": 0.00014653027756139636,
        "seek": 792768,
        "start": 7950.96,
        "temperature": 0,
        "text": " If we look at this, there.",
        "tokens": [
          51528,
          759,
          321,
          574,
          412,
          341,
          11,
          456,
          13,
          51584
        ]
      },
      {
        "avg_logprob": -0.3801288604736328,
        "compression_ratio": 1.4968944099378882,
        "end": 7952.62,
        "id": 2351,
        "no_speech_prob": 0.00014653027756139636,
        "seek": 792768,
        "start": 7952.08,
        "temperature": 0,
        "text": " Look at this.",
        "tokens": [
          51584,
          2053,
          412,
          341,
          13,
          51611
        ]
      },
      {
        "avg_logprob": -0.3801288604736328,
        "compression_ratio": 1.4968944099378882,
        "end": 7956.280000000001,
        "id": 2352,
        "no_speech_prob": 0.00014653027756139636,
        "seek": 792768,
        "start": 7952.62,
        "temperature": 0,
        "text": " Look at this nice, normally indented code.",
        "tokens": [
          51611,
          2053,
          412,
          341,
          1481,
          11,
          5646,
          1016,
          6003,
          3089,
          13,
          51794
        ]
      },
      {
        "avg_logprob": -0.30324471515157947,
        "compression_ratio": 1.3333333333333333,
        "end": 7957.639999999999,
        "id": 2353,
        "no_speech_prob": 0.0002694770519156009,
        "seek": 795628,
        "start": 7956.8,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50390,
          2264,
          13,
          50432
        ]
      },
      {
        "avg_logprob": -0.30324471515157947,
        "compression_ratio": 1.3333333333333333,
        "end": 7959.96,
        "id": 2354,
        "no_speech_prob": 0.0002694770519156009,
        "seek": 795628,
        "start": 7957.639999999999,
        "temperature": 0,
        "text": " Now, let me do this.",
        "tokens": [
          50432,
          823,
          11,
          718,
          385,
          360,
          341,
          13,
          50548
        ]
      },
      {
        "avg_logprob": -0.30324471515157947,
        "compression_ratio": 1.3333333333333333,
        "end": 7970.28,
        "id": 2355,
        "no_speech_prob": 0.0002694770519156009,
        "seek": 795628,
        "start": 7964.92,
        "temperature": 0,
        "text": " This moves challenge 121 into 121 underscore 1",
        "tokens": [
          50796,
          639,
          6067,
          3430,
          2272,
          16,
          666,
          2272,
          16,
          37556,
          502,
          51064
        ]
      },
      {
        "avg_logprob": -0.30324471515157947,
        "compression_ratio": 1.3333333333333333,
        "end": 7976.5199999999995,
        "id": 2356,
        "no_speech_prob": 0.0002694770519156009,
        "seek": 795628,
        "start": 7970.28,
        "temperature": 0,
        "text": " and adds 121 underscore 2 for the second part of the logo",
        "tokens": [
          51064,
          293,
          10860,
          2272,
          16,
          37556,
          568,
          337,
          264,
          1150,
          644,
          295,
          264,
          9699,
          51376
        ]
      },
      {
        "avg_logprob": -0.30324471515157947,
        "compression_ratio": 1.3333333333333333,
        "end": 7977.639999999999,
        "id": 2357,
        "no_speech_prob": 0.0002694770519156009,
        "seek": 795628,
        "start": 7976.5199999999995,
        "temperature": 0,
        "text": " challenge.",
        "tokens": [
          51376,
          3430,
          13,
          51432
        ]
      },
      {
        "avg_logprob": -0.42779742154208095,
        "compression_ratio": 1.1968503937007875,
        "end": 7986.96,
        "id": 2358,
        "no_speech_prob": 0.049586549401283264,
        "seek": 797764,
        "start": 7977.68,
        "temperature": 0,
        "text": " It shouldn't be merged without fixing the markdown file",
        "tokens": [
          50366,
          467,
          4659,
          380,
          312,
          36427,
          1553,
          19442,
          264,
          1491,
          5093,
          3991,
          50830
        ]
      },
      {
        "avg_logprob": -0.42779742154208095,
        "compression_ratio": 1.1968503937007875,
        "end": 7990.400000000001,
        "id": 2359,
        "no_speech_prob": 0.049586549401283264,
        "seek": 797764,
        "start": 7986.96,
        "temperature": 0,
        "text": " for challenge 121 part 1 first.",
        "tokens": [
          50830,
          337,
          3430,
          2272,
          16,
          644,
          502,
          700,
          13,
          51002
        ]
      },
      {
        "avg_logprob": -0.42779742154208095,
        "compression_ratio": 1.1968503937007875,
        "end": 7998.88,
        "id": 2360,
        "no_speech_prob": 0.049586549401283264,
        "seek": 797764,
        "start": 7996.8,
        "temperature": 0,
        "text": " So let me do that.",
        "tokens": [
          51322,
          407,
          718,
          385,
          360,
          300,
          13,
          51426
        ]
      },
      {
        "avg_logprob": -0.42779742154208095,
        "compression_ratio": 1.1968503937007875,
        "end": 8004.96,
        "id": 2361,
        "no_speech_prob": 0.049586549401283264,
        "seek": 797764,
        "start": 8004.08,
        "temperature": 0,
        "text": " What is this?",
        "tokens": [
          51686,
          708,
          307,
          341,
          30,
          51730
        ]
      },
      {
        "avg_logprob": -0.42779742154208095,
        "compression_ratio": 1.1968503937007875,
        "end": 8005.72,
        "id": 2362,
        "no_speech_prob": 0.049586549401283264,
        "seek": 797764,
        "start": 8004.96,
        "temperature": 0,
        "text": " Get repeat?",
        "tokens": [
          51730,
          3240,
          7149,
          30,
          51768
        ]
      },
      {
        "avg_logprob": -0.42779742154208095,
        "compression_ratio": 1.1968503937007875,
        "end": 8006.360000000001,
        "id": 2363,
        "no_speech_prob": 0.049586549401283264,
        "seek": 797764,
        "start": 8005.72,
        "temperature": 0,
        "text": " Oh, yeah, yeah.",
        "tokens": [
          51768,
          876,
          11,
          1338,
          11,
          1338,
          13,
          51800
        ]
      },
      {
        "avg_logprob": -0.42779742154208095,
        "compression_ratio": 1.1968503937007875,
        "end": 8006.860000000001,
        "id": 2364,
        "no_speech_prob": 0.049586549401283264,
        "seek": 797764,
        "start": 8006.360000000001,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51800,
          2264,
          13,
          51825
        ]
      },
      {
        "avg_logprob": -0.3616209262754859,
        "compression_ratio": 1.4457831325301205,
        "end": 8011.400000000001,
        "id": 2365,
        "no_speech_prob": 0.000743686396162957,
        "seek": 800764,
        "start": 8008.240000000001,
        "temperature": 0,
        "text": " What kind of crazy code did I write earlier today?",
        "tokens": [
          50394,
          708,
          733,
          295,
          3219,
          3089,
          630,
          286,
          2464,
          3071,
          965,
          30,
          50552
        ]
      },
      {
        "avg_logprob": -0.3616209262754859,
        "compression_ratio": 1.4457831325301205,
        "end": 8013.160000000001,
        "id": 2366,
        "no_speech_prob": 0.000743686396162957,
        "seek": 800764,
        "start": 8011.400000000001,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50552,
          2264,
          13,
          50640
        ]
      },
      {
        "avg_logprob": -0.3616209262754859,
        "compression_ratio": 1.4457831325301205,
        "end": 8013.68,
        "id": 2367,
        "no_speech_prob": 0.000743686396162957,
        "seek": 800764,
        "start": 8013.160000000001,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50640,
          1057,
          558,
          13,
          50666
        ]
      },
      {
        "avg_logprob": -0.3616209262754859,
        "compression_ratio": 1.4457831325301205,
        "end": 8018,
        "id": 2368,
        "no_speech_prob": 0.000743686396162957,
        "seek": 800764,
        "start": 8017.200000000001,
        "temperature": 0,
        "text": " Oh, my goodness.",
        "tokens": [
          50842,
          876,
          11,
          452,
          8387,
          13,
          50882
        ]
      },
      {
        "avg_logprob": -0.3616209262754859,
        "compression_ratio": 1.4457831325301205,
        "end": 8018.5,
        "id": 2369,
        "no_speech_prob": 0.000743686396162957,
        "seek": 800764,
        "start": 8018,
        "temperature": 0,
        "text": " Ugh.",
        "tokens": [
          50882,
          16506,
          13,
          50907
        ]
      },
      {
        "avg_logprob": -0.3616209262754859,
        "compression_ratio": 1.4457831325301205,
        "end": 8025.96,
        "id": 2370,
        "no_speech_prob": 0.000743686396162957,
        "seek": 800764,
        "start": 8024.160000000001,
        "temperature": 0,
        "text": " All right, everyone.",
        "tokens": [
          51190,
          1057,
          558,
          11,
          1518,
          13,
          51280
        ]
      },
      {
        "avg_logprob": -0.3616209262754859,
        "compression_ratio": 1.4457831325301205,
        "end": 8027.96,
        "id": 2371,
        "no_speech_prob": 0.000743686396162957,
        "seek": 800764,
        "start": 8025.96,
        "temperature": 0,
        "text": " I'm definitely done.",
        "tokens": [
          51280,
          286,
          478,
          2138,
          1096,
          13,
          51380
        ]
      },
      {
        "avg_logprob": -0.3616209262754859,
        "compression_ratio": 1.4457831325301205,
        "end": 8030.400000000001,
        "id": 2372,
        "no_speech_prob": 0.000743686396162957,
        "seek": 800764,
        "start": 8027.96,
        "temperature": 0,
        "text": " I really want to do more, but sometimes you just",
        "tokens": [
          51380,
          286,
          534,
          528,
          281,
          360,
          544,
          11,
          457,
          2171,
          291,
          445,
          51502
        ]
      },
      {
        "avg_logprob": -0.3616209262754859,
        "compression_ratio": 1.4457831325301205,
        "end": 8031.52,
        "id": 2373,
        "no_speech_prob": 0.000743686396162957,
        "seek": 800764,
        "start": 8030.400000000001,
        "temperature": 0,
        "text": " have to know when to quit.",
        "tokens": [
          51502,
          362,
          281,
          458,
          562,
          281,
          10366,
          13,
          51558
        ]
      },
      {
        "avg_logprob": -0.3616209262754859,
        "compression_ratio": 1.4457831325301205,
        "end": 8034.280000000001,
        "id": 2374,
        "no_speech_prob": 0.000743686396162957,
        "seek": 800764,
        "start": 8031.52,
        "temperature": 0,
        "text": " I don't usually know when to quit.",
        "tokens": [
          51558,
          286,
          500,
          380,
          2673,
          458,
          562,
          281,
          10366,
          13,
          51696
        ]
      },
      {
        "avg_logprob": -0.22790373588094906,
        "compression_ratio": 1.511111111111111,
        "end": 8041,
        "id": 2375,
        "no_speech_prob": 0.00159781938418746,
        "seek": 803428,
        "start": 8034.28,
        "temperature": 0,
        "text": " I would be glad to take any questions, a few questions.",
        "tokens": [
          50364,
          286,
          576,
          312,
          5404,
          281,
          747,
          604,
          1651,
          11,
          257,
          1326,
          1651,
          13,
          50700
        ]
      },
      {
        "avg_logprob": -0.22790373588094906,
        "compression_ratio": 1.511111111111111,
        "end": 8045.2,
        "id": 2376,
        "no_speech_prob": 0.00159781938418746,
        "seek": 803428,
        "start": 8041,
        "temperature": 0,
        "text": " Thank you to new members who joined.",
        "tokens": [
          50700,
          1044,
          291,
          281,
          777,
          2679,
          567,
          6869,
          13,
          50910
        ]
      },
      {
        "avg_logprob": -0.22790373588094906,
        "compression_ratio": 1.511111111111111,
        "end": 8045.8,
        "id": 2377,
        "no_speech_prob": 0.00159781938418746,
        "seek": 803428,
        "start": 8045.2,
        "temperature": 0,
        "text": " Actually, OK.",
        "tokens": [
          50910,
          5135,
          11,
          2264,
          13,
          50940
        ]
      },
      {
        "avg_logprob": -0.22790373588094906,
        "compression_ratio": 1.511111111111111,
        "end": 8047.5599999999995,
        "id": 2378,
        "no_speech_prob": 0.00159781938418746,
        "seek": 803428,
        "start": 8045.8,
        "temperature": 0,
        "text": " So let me do a little few housekeeping.",
        "tokens": [
          50940,
          407,
          718,
          385,
          360,
          257,
          707,
          1326,
          48033,
          13,
          51028
        ]
      },
      {
        "avg_logprob": -0.22790373588094906,
        "compression_ratio": 1.511111111111111,
        "end": 8050.24,
        "id": 2379,
        "no_speech_prob": 0.00159781938418746,
        "seek": 803428,
        "start": 8047.5599999999995,
        "temperature": 0,
        "text": " I can't imagine that anybody's still watching.",
        "tokens": [
          51028,
          286,
          393,
          380,
          3811,
          300,
          4472,
          311,
          920,
          1976,
          13,
          51162
        ]
      },
      {
        "avg_logprob": -0.22790373588094906,
        "compression_ratio": 1.511111111111111,
        "end": 8052.88,
        "id": 2380,
        "no_speech_prob": 0.00159781938418746,
        "seek": 803428,
        "start": 8050.24,
        "temperature": 0,
        "text": " But if you are, I will mention that I",
        "tokens": [
          51162,
          583,
          498,
          291,
          366,
          11,
          286,
          486,
          2152,
          300,
          286,
          51294
        ]
      },
      {
        "avg_logprob": -0.22790373588094906,
        "compression_ratio": 1.511111111111111,
        "end": 8057.24,
        "id": 2381,
        "no_speech_prob": 0.00159781938418746,
        "seek": 803428,
        "start": 8052.88,
        "temperature": 0,
        "text": " am way behind on sending out stickers and books",
        "tokens": [
          51294,
          669,
          636,
          2261,
          322,
          7750,
          484,
          21019,
          293,
          3642,
          51512
        ]
      },
      {
        "avg_logprob": -0.22790373588094906,
        "compression_ratio": 1.511111111111111,
        "end": 8061.639999999999,
        "id": 2382,
        "no_speech_prob": 0.00159781938418746,
        "seek": 803428,
        "start": 8057.24,
        "temperature": 0,
        "text": " to patron and YouTube members.",
        "tokens": [
          51512,
          281,
          21843,
          293,
          3088,
          2679,
          13,
          51732
        ]
      },
      {
        "avg_logprob": -0.22790373588094906,
        "compression_ratio": 1.511111111111111,
        "end": 8063.32,
        "id": 2383,
        "no_speech_prob": 0.00159781938418746,
        "seek": 803428,
        "start": 8061.639999999999,
        "temperature": 0,
        "text": " I am really, this is my goal.",
        "tokens": [
          51732,
          286,
          669,
          534,
          11,
          341,
          307,
          452,
          3387,
          13,
          51816
        ]
      },
      {
        "avg_logprob": -0.2340415340141962,
        "compression_ratio": 1.7341772151898733,
        "end": 8065.5199999999995,
        "id": 2384,
        "no_speech_prob": 0.003272964619100094,
        "seek": 806332,
        "start": 8063.36,
        "temperature": 0,
        "text": " Everyone who joined November 1st or earlier,",
        "tokens": [
          50366,
          5198,
          567,
          6869,
          7674,
          502,
          372,
          420,
          3071,
          11,
          50474
        ]
      },
      {
        "avg_logprob": -0.2340415340141962,
        "compression_ratio": 1.7341772151898733,
        "end": 8066.96,
        "id": 2385,
        "no_speech_prob": 0.003272964619100094,
        "seek": 806332,
        "start": 8065.5199999999995,
        "temperature": 0,
        "text": " sorry if you joined in the last week,",
        "tokens": [
          50474,
          2597,
          498,
          291,
          6869,
          294,
          264,
          1036,
          1243,
          11,
          50546
        ]
      },
      {
        "avg_logprob": -0.2340415340141962,
        "compression_ratio": 1.7341772151898733,
        "end": 8068.44,
        "id": 2386,
        "no_speech_prob": 0.003272964619100094,
        "seek": 806332,
        "start": 8066.96,
        "temperature": 0,
        "text": " because I'm compiling everything.",
        "tokens": [
          50546,
          570,
          286,
          478,
          715,
          4883,
          1203,
          13,
          50620
        ]
      },
      {
        "avg_logprob": -0.2340415340141962,
        "compression_ratio": 1.7341772151898733,
        "end": 8071.32,
        "id": 2387,
        "no_speech_prob": 0.003272964619100094,
        "seek": 806332,
        "start": 8068.44,
        "temperature": 0,
        "text": " I've got to get everybody everything by the holidays.",
        "tokens": [
          50620,
          286,
          600,
          658,
          281,
          483,
          2201,
          1203,
          538,
          264,
          15734,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2340415340141962,
        "compression_ratio": 1.7341772151898733,
        "end": 8073.599999999999,
        "id": 2388,
        "no_speech_prob": 0.003272964619100094,
        "seek": 806332,
        "start": 8071.32,
        "temperature": 0,
        "text": " If you do not have something and are",
        "tokens": [
          50764,
          759,
          291,
          360,
          406,
          362,
          746,
          293,
          366,
          50878
        ]
      },
      {
        "avg_logprob": -0.2340415340141962,
        "compression_ratio": 1.7341772151898733,
        "end": 8075,
        "id": 2389,
        "no_speech_prob": 0.003272964619100094,
        "seek": 806332,
        "start": 8073.599999999999,
        "temperature": 0,
        "text": " wondering about the status of it,",
        "tokens": [
          50878,
          6359,
          466,
          264,
          6558,
          295,
          309,
          11,
          50948
        ]
      },
      {
        "avg_logprob": -0.2340415340141962,
        "compression_ratio": 1.7341772151898733,
        "end": 8077.44,
        "id": 2390,
        "no_speech_prob": 0.003272964619100094,
        "seek": 806332,
        "start": 8075,
        "temperature": 0,
        "text": " please send me a message on Slack.",
        "tokens": [
          50948,
          1767,
          2845,
          385,
          257,
          3636,
          322,
          37211,
          13,
          51070
        ]
      },
      {
        "avg_logprob": -0.2340415340141962,
        "compression_ratio": 1.7341772151898733,
        "end": 8080.12,
        "id": 2391,
        "no_speech_prob": 0.003272964619100094,
        "seek": 806332,
        "start": 8077.44,
        "temperature": 0,
        "text": " If you're a YouTube member, you don't have a Slack invite,",
        "tokens": [
          51070,
          759,
          291,
          434,
          257,
          3088,
          4006,
          11,
          291,
          500,
          380,
          362,
          257,
          37211,
          7980,
          11,
          51204
        ]
      },
      {
        "avg_logprob": -0.2340415340141962,
        "compression_ratio": 1.7341772151898733,
        "end": 8082.28,
        "id": 2392,
        "no_speech_prob": 0.003272964619100094,
        "seek": 806332,
        "start": 8080.12,
        "temperature": 0,
        "text": " then make sure you find the community post, which",
        "tokens": [
          51204,
          550,
          652,
          988,
          291,
          915,
          264,
          1768,
          2183,
          11,
          597,
          51312
        ]
      },
      {
        "avg_logprob": -0.2340415340141962,
        "compression_ratio": 1.7341772151898733,
        "end": 8084.5199999999995,
        "id": 2393,
        "no_speech_prob": 0.003272964619100094,
        "seek": 806332,
        "start": 8082.28,
        "temperature": 0,
        "text": " has the forum to get a Slack invite.",
        "tokens": [
          51312,
          575,
          264,
          17542,
          281,
          483,
          257,
          37211,
          7980,
          13,
          51424
        ]
      },
      {
        "avg_logprob": -0.2340415340141962,
        "compression_ratio": 1.7341772151898733,
        "end": 8086.5599999999995,
        "id": 2394,
        "no_speech_prob": 0.003272964619100094,
        "seek": 806332,
        "start": 8084.5199999999995,
        "temperature": 0,
        "text": " And also, you can message at math blank",
        "tokens": [
          51424,
          400,
          611,
          11,
          291,
          393,
          3636,
          412,
          5221,
          8247,
          51526
        ]
      },
      {
        "avg_logprob": -0.2340415340141962,
        "compression_ratio": 1.7341772151898733,
        "end": 8088.48,
        "id": 2395,
        "no_speech_prob": 0.003272964619100094,
        "seek": 806332,
        "start": 8086.5599999999995,
        "temperature": 0,
        "text": " on Slack, who is doing this stuff.",
        "tokens": [
          51526,
          322,
          37211,
          11,
          567,
          307,
          884,
          341,
          1507,
          13,
          51622
        ]
      },
      {
        "avg_logprob": -0.2340415340141962,
        "compression_ratio": 1.7341772151898733,
        "end": 8092.679999999999,
        "id": 2396,
        "no_speech_prob": 0.003272964619100094,
        "seek": 806332,
        "start": 8088.48,
        "temperature": 0,
        "text": " If you are interested in Coding Train merchandise,",
        "tokens": [
          51622,
          759,
          291,
          366,
          3102,
          294,
          383,
          8616,
          28029,
          34485,
          11,
          51832
        ]
      },
      {
        "avg_logprob": -0.2969625058381454,
        "compression_ratio": 1.6375,
        "end": 8097.280000000001,
        "id": 2397,
        "no_speech_prob": 0.00001750286901369691,
        "seek": 809268,
        "start": 8092.68,
        "temperature": 0,
        "text": " I might as well plug this just for a second, because it's new.",
        "tokens": [
          50364,
          286,
          1062,
          382,
          731,
          5452,
          341,
          445,
          337,
          257,
          1150,
          11,
          570,
          309,
          311,
          777,
          13,
          50594
        ]
      },
      {
        "avg_logprob": -0.2969625058381454,
        "compression_ratio": 1.6375,
        "end": 8101.56,
        "id": 2398,
        "no_speech_prob": 0.00001750286901369691,
        "seek": 809268,
        "start": 8097.280000000001,
        "temperature": 0,
        "text": " Actually, I am wearing right now, this is one of these shirts.",
        "tokens": [
          50594,
          5135,
          11,
          286,
          669,
          4769,
          558,
          586,
          11,
          341,
          307,
          472,
          295,
          613,
          20832,
          13,
          50808
        ]
      },
      {
        "avg_logprob": -0.2969625058381454,
        "compression_ratio": 1.6375,
        "end": 8105.88,
        "id": 2399,
        "no_speech_prob": 0.00001750286901369691,
        "seek": 809268,
        "start": 8104.64,
        "temperature": 0,
        "text": " It looks like I'm disrobing.",
        "tokens": [
          50962,
          467,
          1542,
          411,
          286,
          478,
          717,
          340,
          4324,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.2969625058381454,
        "compression_ratio": 1.6375,
        "end": 8106.96,
        "id": 2400,
        "no_speech_prob": 0.00001750286901369691,
        "seek": 809268,
        "start": 8105.88,
        "temperature": 0,
        "text": " Don't worry, I am not.",
        "tokens": [
          51024,
          1468,
          380,
          3292,
          11,
          286,
          669,
          406,
          13,
          51078
        ]
      },
      {
        "avg_logprob": -0.2969625058381454,
        "compression_ratio": 1.6375,
        "end": 8109.240000000001,
        "id": 2401,
        "no_speech_prob": 0.00001750286901369691,
        "seek": 809268,
        "start": 8106.96,
        "temperature": 0,
        "text": " I'm just showing you my Never Forget.",
        "tokens": [
          51078,
          286,
          478,
          445,
          4099,
          291,
          452,
          7344,
          18675,
          13,
          51192
        ]
      },
      {
        "avg_logprob": -0.2969625058381454,
        "compression_ratio": 1.6375,
        "end": 8110.6,
        "id": 2402,
        "no_speech_prob": 0.00001750286901369691,
        "seek": 809268,
        "start": 8109.240000000001,
        "temperature": 0,
        "text": " It's kind of like translucent.",
        "tokens": [
          51192,
          467,
          311,
          733,
          295,
          411,
          48236,
          13,
          51260
        ]
      },
      {
        "avg_logprob": -0.2969625058381454,
        "compression_ratio": 1.6375,
        "end": 8113.12,
        "id": 2403,
        "no_speech_prob": 0.00001750286901369691,
        "seek": 809268,
        "start": 8110.6,
        "temperature": 0,
        "text": " Never Forget, the This Dot shirt.",
        "tokens": [
          51260,
          7344,
          18675,
          11,
          264,
          639,
          38753,
          8336,
          13,
          51386
        ]
      },
      {
        "avg_logprob": -0.2969625058381454,
        "compression_ratio": 1.6375,
        "end": 8115.84,
        "id": 2404,
        "no_speech_prob": 0.00001750286901369691,
        "seek": 809268,
        "start": 8113.12,
        "temperature": 0,
        "text": " You can get your own Never Forget the This Dot shirt",
        "tokens": [
          51386,
          509,
          393,
          483,
          428,
          1065,
          7344,
          18675,
          264,
          639,
          38753,
          8336,
          51522
        ]
      },
      {
        "avg_logprob": -0.2969625058381454,
        "compression_ratio": 1.6375,
        "end": 8119.280000000001,
        "id": 2405,
        "no_speech_prob": 0.00001750286901369691,
        "seek": 809268,
        "start": 8115.84,
        "temperature": 0,
        "text": " designed by human slash shop slash coding train, I believe.",
        "tokens": [
          51522,
          4761,
          538,
          1952,
          17330,
          3945,
          17330,
          17720,
          3847,
          11,
          286,
          1697,
          13,
          51694
        ]
      },
      {
        "avg_logprob": -0.40882662872769937,
        "compression_ratio": 1.5925925925925926,
        "end": 8122.84,
        "id": 2406,
        "no_speech_prob": 0.000003555976945790462,
        "seek": 811928,
        "start": 8120,
        "temperature": 0,
        "text": " So you can see, these are the various shirts and things.",
        "tokens": [
          50400,
          407,
          291,
          393,
          536,
          11,
          613,
          366,
          264,
          3683,
          20832,
          293,
          721,
          13,
          50542
        ]
      },
      {
        "avg_logprob": -0.40882662872769937,
        "compression_ratio": 1.5925925925925926,
        "end": 8126,
        "id": 2407,
        "no_speech_prob": 0.000003555976945790462,
        "seek": 811928,
        "start": 8122.84,
        "temperature": 0,
        "text": " And I wanted to mention, people, it's hard to notice this,",
        "tokens": [
          50542,
          400,
          286,
          1415,
          281,
          2152,
          11,
          561,
          11,
          309,
          311,
          1152,
          281,
          3449,
          341,
          11,
          50700
        ]
      },
      {
        "avg_logprob": -0.40882662872769937,
        "compression_ratio": 1.5925925925925926,
        "end": 8129.96,
        "id": 2408,
        "no_speech_prob": 0.000003555976945790462,
        "seek": 811928,
        "start": 8126,
        "temperature": 0,
        "text": " but this phone case here is $35.",
        "tokens": [
          50700,
          457,
          341,
          2593,
          1389,
          510,
          307,
          1848,
          8794,
          13,
          50898
        ]
      },
      {
        "avg_logprob": -0.40882662872769937,
        "compression_ratio": 1.5925925925925926,
        "end": 8131.28,
        "id": 2409,
        "no_speech_prob": 0.000003555976945790462,
        "seek": 811928,
        "start": 8129.96,
        "temperature": 0,
        "text": " That's crazy.",
        "tokens": [
          50898,
          663,
          311,
          3219,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.40882662872769937,
        "compression_ratio": 1.5925925925925926,
        "end": 8133.12,
        "id": 2410,
        "no_speech_prob": 0.000003555976945790462,
        "seek": 811928,
        "start": 8131.28,
        "temperature": 0,
        "text": " But this is actually designed, actually,",
        "tokens": [
          50964,
          583,
          341,
          307,
          767,
          4761,
          11,
          767,
          11,
          51056
        ]
      },
      {
        "avg_logprob": -0.40882662872769937,
        "compression_ratio": 1.5925925925925926,
        "end": 8135.719999999999,
        "id": 2411,
        "no_speech_prob": 0.000003555976945790462,
        "seek": 811928,
        "start": 8133.12,
        "temperature": 0,
        "text": " to probably make this a default for a zip hoodie,",
        "tokens": [
          51056,
          281,
          1391,
          652,
          341,
          257,
          7576,
          337,
          257,
          20730,
          41191,
          11,
          51186
        ]
      },
      {
        "avg_logprob": -0.40882662872769937,
        "compression_ratio": 1.5925925925925926,
        "end": 8137.8,
        "id": 2412,
        "no_speech_prob": 0.000003555976945790462,
        "seek": 811928,
        "start": 8135.719999999999,
        "temperature": 0,
        "text": " where the Never Forget the This Dot is on this side.",
        "tokens": [
          51186,
          689,
          264,
          7344,
          18675,
          264,
          639,
          38753,
          307,
          322,
          341,
          1252,
          13,
          51290
        ]
      },
      {
        "avg_logprob": -0.40882662872769937,
        "compression_ratio": 1.5925925925925926,
        "end": 8139.96,
        "id": 2413,
        "no_speech_prob": 0.000003555976945790462,
        "seek": 811928,
        "start": 8137.8,
        "temperature": 0,
        "text": " All right, I just wanted to mention that.",
        "tokens": [
          51290,
          1057,
          558,
          11,
          286,
          445,
          1415,
          281,
          2152,
          300,
          13,
          51398
        ]
      },
      {
        "avg_logprob": -0.40882662872769937,
        "compression_ratio": 1.5925925925925926,
        "end": 8141.759999999999,
        "id": 2414,
        "no_speech_prob": 0.000003555976945790462,
        "seek": 811928,
        "start": 8139.96,
        "temperature": 0,
        "text": " Other housekeeping things, let's see",
        "tokens": [
          51398,
          5358,
          48033,
          721,
          11,
          718,
          311,
          536,
          51488
        ]
      },
      {
        "avg_logprob": -0.40882662872769937,
        "compression_ratio": 1.5925925925925926,
        "end": 8143.12,
        "id": 2415,
        "no_speech_prob": 0.000003555976945790462,
        "seek": 811928,
        "start": 8141.759999999999,
        "temperature": 0,
        "text": " what other questions there are.",
        "tokens": [
          51488,
          437,
          661,
          1651,
          456,
          366,
          13,
          51556
        ]
      },
      {
        "avg_logprob": -0.40882662872769937,
        "compression_ratio": 1.5925925925925926,
        "end": 8146.24,
        "id": 2416,
        "no_speech_prob": 0.000003555976945790462,
        "seek": 811928,
        "start": 8143.12,
        "temperature": 0,
        "text": " What do you think about GANs, or Generative Adversarial",
        "tokens": [
          51556,
          708,
          360,
          291,
          519,
          466,
          460,
          1770,
          82,
          11,
          420,
          15409,
          1166,
          1999,
          840,
          44745,
          51712
        ]
      },
      {
        "avg_logprob": -0.49877095484471584,
        "compression_ratio": 1.4413145539906103,
        "end": 8147.5599999999995,
        "id": 2417,
        "no_speech_prob": 0.006488146726042032,
        "seek": 814624,
        "start": 8147.08,
        "temperature": 0,
        "text": " Networks?",
        "tokens": [
          50406,
          12640,
          82,
          30,
          50430
        ]
      },
      {
        "avg_logprob": -0.49877095484471584,
        "compression_ratio": 1.4413145539906103,
        "end": 8149.84,
        "id": 2418,
        "no_speech_prob": 0.006488146726042032,
        "seek": 814624,
        "start": 8147.5599999999995,
        "temperature": 0,
        "text": " They are very interesting to me, and I",
        "tokens": [
          50430,
          814,
          366,
          588,
          1880,
          281,
          385,
          11,
          293,
          286,
          50544
        ]
      },
      {
        "avg_logprob": -0.49877095484471584,
        "compression_ratio": 1.4413145539906103,
        "end": 8152.84,
        "id": 2419,
        "no_speech_prob": 0.006488146726042032,
        "seek": 814624,
        "start": 8149.84,
        "temperature": 0,
        "text": " would love to learn more about them",
        "tokens": [
          50544,
          576,
          959,
          281,
          1466,
          544,
          466,
          552,
          50694
        ]
      },
      {
        "avg_logprob": -0.49877095484471584,
        "compression_ratio": 1.4413145539906103,
        "end": 8155.96,
        "id": 2420,
        "no_speech_prob": 0.006488146726042032,
        "seek": 814624,
        "start": 8152.84,
        "temperature": 0,
        "text": " and maybe do some tutorials about them.",
        "tokens": [
          50694,
          293,
          1310,
          360,
          512,
          17616,
          466,
          552,
          13,
          50850
        ]
      },
      {
        "avg_logprob": -0.49877095484471584,
        "compression_ratio": 1.4413145539906103,
        "end": 8158.5199999999995,
        "id": 2421,
        "no_speech_prob": 0.006488146726042032,
        "seek": 814624,
        "start": 8155.96,
        "temperature": 0,
        "text": " A wonderful artist who does wonderful things with GAN",
        "tokens": [
          50850,
          316,
          3715,
          5748,
          567,
          775,
          3715,
          721,
          365,
          460,
          1770,
          50978
        ]
      },
      {
        "avg_logprob": -0.49877095484471584,
        "compression_ratio": 1.4413145539906103,
        "end": 8162.84,
        "id": 2422,
        "no_speech_prob": 0.006488146726042032,
        "seek": 814624,
        "start": 8158.5199999999995,
        "temperature": 0,
        "text": " is Helena Sisserman.",
        "tokens": [
          50978,
          307,
          49294,
          318,
          891,
          11821,
          13,
          51194
        ]
      },
      {
        "avg_logprob": -0.49877095484471584,
        "compression_ratio": 1.4413145539906103,
        "end": 8167.44,
        "id": 2423,
        "no_speech_prob": 0.006488146726042032,
        "seek": 814624,
        "start": 8162.84,
        "temperature": 0,
        "text": " Yes, you should check out GLAGOLISTA on Twitter,",
        "tokens": [
          51194,
          1079,
          11,
          291,
          820,
          1520,
          484,
          460,
          11435,
          38,
          5046,
          2343,
          8241,
          322,
          5794,
          11,
          51424
        ]
      },
      {
        "avg_logprob": -0.49877095484471584,
        "compression_ratio": 1.4413145539906103,
        "end": 8172.4,
        "id": 2424,
        "no_speech_prob": 0.006488146726042032,
        "seek": 814624,
        "start": 8167.44,
        "temperature": 0,
        "text": " who makes all sorts of amazing GAN-related projects.",
        "tokens": [
          51424,
          567,
          1669,
          439,
          7527,
          295,
          2243,
          460,
          1770,
          12,
          12004,
          4455,
          13,
          51672
        ]
      },
      {
        "avg_logprob": -0.49877095484471584,
        "compression_ratio": 1.4413145539906103,
        "end": 8172.88,
        "id": 2425,
        "no_speech_prob": 0.006488146726042032,
        "seek": 814624,
        "start": 8172.4,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51672,
          865,
          13,
          51696
        ]
      },
      {
        "avg_logprob": -0.41118264809632915,
        "compression_ratio": 1.7548076923076923,
        "end": 8178.24,
        "id": 2426,
        "no_speech_prob": 0.0017541665583848953,
        "seek": 817624,
        "start": 8177.24,
        "temperature": 0,
        "text": " I'm not going yet.",
        "tokens": [
          50414,
          286,
          478,
          406,
          516,
          1939,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.41118264809632915,
        "compression_ratio": 1.7548076923076923,
        "end": 8180.24,
        "id": 2427,
        "no_speech_prob": 0.0017541665583848953,
        "seek": 817624,
        "start": 8178.24,
        "temperature": 0,
        "text": " Waiting to see if there's any more questions.",
        "tokens": [
          50464,
          37291,
          281,
          536,
          498,
          456,
          311,
          604,
          544,
          1651,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.41118264809632915,
        "compression_ratio": 1.7548076923076923,
        "end": 8181.24,
        "id": 2428,
        "no_speech_prob": 0.0017541665583848953,
        "seek": 817624,
        "start": 8180.24,
        "temperature": 0,
        "text": " My mic is very quiet.",
        "tokens": [
          50564,
          1222,
          3123,
          307,
          588,
          5677,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.41118264809632915,
        "compression_ratio": 1.7548076923076923,
        "end": 8183.24,
        "id": 2429,
        "no_speech_prob": 0.0017541665583848953,
        "seek": 817624,
        "start": 8181.24,
        "temperature": 0,
        "text": " That doesn't surprise me, because it got moved around.",
        "tokens": [
          50614,
          663,
          1177,
          380,
          6365,
          385,
          11,
          570,
          309,
          658,
          4259,
          926,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.41118264809632915,
        "compression_ratio": 1.7548076923076923,
        "end": 8184.24,
        "id": 2430,
        "no_speech_prob": 0.0017541665583848953,
        "seek": 817624,
        "start": 8183.24,
        "temperature": 0,
        "text": " But hopefully, it's fine now.",
        "tokens": [
          50714,
          583,
          4696,
          11,
          309,
          311,
          2489,
          586,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.41118264809632915,
        "compression_ratio": 1.7548076923076923,
        "end": 8186.24,
        "id": 2431,
        "no_speech_prob": 0.0017541665583848953,
        "seek": 817624,
        "start": 8184.24,
        "temperature": 0,
        "text": " Thank you, Aufec, for letting me know.",
        "tokens": [
          50764,
          1044,
          291,
          11,
          12160,
          2106,
          66,
          11,
          337,
          8295,
          385,
          458,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.41118264809632915,
        "compression_ratio": 1.7548076923076923,
        "end": 8188.24,
        "id": 2432,
        "no_speech_prob": 0.0017541665583848953,
        "seek": 817624,
        "start": 8186.24,
        "temperature": 0,
        "text": " This is the end of today's talk.",
        "tokens": [
          50864,
          639,
          307,
          264,
          917,
          295,
          965,
          311,
          751,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.41118264809632915,
        "compression_ratio": 1.7548076923076923,
        "end": 8189.24,
        "id": 2433,
        "no_speech_prob": 0.0017541665583848953,
        "seek": 817624,
        "start": 8188.24,
        "temperature": 0,
        "text": " I hope you enjoyed it.",
        "tokens": [
          50964,
          286,
          1454,
          291,
          4626,
          309,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.41118264809632915,
        "compression_ratio": 1.7548076923076923,
        "end": 8190.24,
        "id": 2434,
        "no_speech_prob": 0.0017541665583848953,
        "seek": 817624,
        "start": 8189.24,
        "temperature": 0,
        "text": " I'll see you next time.",
        "tokens": [
          51014,
          286,
          603,
          536,
          291,
          958,
          565,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.41118264809632915,
        "compression_ratio": 1.7548076923076923,
        "end": 8191.24,
        "id": 2435,
        "no_speech_prob": 0.0017541665583848953,
        "seek": 817624,
        "start": 8190.24,
        "temperature": 0,
        "text": " Bye.",
        "tokens": [
          51064,
          4621,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.41118264809632915,
        "compression_ratio": 1.7548076923076923,
        "end": 8192.24,
        "id": 2436,
        "no_speech_prob": 0.0017541665583848953,
        "seek": 817624,
        "start": 8191.24,
        "temperature": 0,
        "text": " Bye.",
        "tokens": [
          51114,
          4621,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.41118264809632915,
        "compression_ratio": 1.7548076923076923,
        "end": 8193.24,
        "id": 2437,
        "no_speech_prob": 0.0017541665583848953,
        "seek": 817624,
        "start": 8192.24,
        "temperature": 0,
        "text": " Bye.",
        "tokens": [
          51164,
          4621,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.41118264809632915,
        "compression_ratio": 1.7548076923076923,
        "end": 8194.24,
        "id": 2438,
        "no_speech_prob": 0.0017541665583848953,
        "seek": 817624,
        "start": 8193.24,
        "temperature": 0,
        "text": " Bye.",
        "tokens": [
          51214,
          4621,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.41118264809632915,
        "compression_ratio": 1.7548076923076923,
        "end": 8195.24,
        "id": 2439,
        "no_speech_prob": 0.0017541665583848953,
        "seek": 817624,
        "start": 8194.24,
        "temperature": 0,
        "text": " Bye.",
        "tokens": [
          51264,
          4621,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.41118264809632915,
        "compression_ratio": 1.7548076923076923,
        "end": 8196.24,
        "id": 2440,
        "no_speech_prob": 0.0017541665583848953,
        "seek": 817624,
        "start": 8195.24,
        "temperature": 0,
        "text": " Bye.",
        "tokens": [
          51314,
          4621,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.41118264809632915,
        "compression_ratio": 1.7548076923076923,
        "end": 8197.24,
        "id": 2441,
        "no_speech_prob": 0.0017541665583848953,
        "seek": 817624,
        "start": 8196.24,
        "temperature": 0,
        "text": " Bye.",
        "tokens": [
          51364,
          4621,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.41118264809632915,
        "compression_ratio": 1.7548076923076923,
        "end": 8198.24,
        "id": 2442,
        "no_speech_prob": 0.0017541665583848953,
        "seek": 817624,
        "start": 8197.24,
        "temperature": 0,
        "text": " Bye.",
        "tokens": [
          51414,
          4621,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.41118264809632915,
        "compression_ratio": 1.7548076923076923,
        "end": 8199.24,
        "id": 2443,
        "no_speech_prob": 0.0017541665583848953,
        "seek": 817624,
        "start": 8198.24,
        "temperature": 0,
        "text": " Bye.",
        "tokens": [
          51464,
          4621,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.41118264809632915,
        "compression_ratio": 1.7548076923076923,
        "end": 8200.24,
        "id": 2444,
        "no_speech_prob": 0.0017541665583848953,
        "seek": 817624,
        "start": 8199.24,
        "temperature": 0,
        "text": " Bye.",
        "tokens": [
          51514,
          4621,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.41118264809632915,
        "compression_ratio": 1.7548076923076923,
        "end": 8201.24,
        "id": 2445,
        "no_speech_prob": 0.0017541665583848953,
        "seek": 817624,
        "start": 8200.24,
        "temperature": 0,
        "text": " Bye.",
        "tokens": [
          51564,
          4621,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.41118264809632915,
        "compression_ratio": 1.7548076923076923,
        "end": 8202.24,
        "id": 2446,
        "no_speech_prob": 0.0017541665583848953,
        "seek": 817624,
        "start": 8201.24,
        "temperature": 0,
        "text": " Bye.",
        "tokens": [
          51614,
          4621,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.41118264809632915,
        "compression_ratio": 1.7548076923076923,
        "end": 8203.24,
        "id": 2447,
        "no_speech_prob": 0.0017541665583848953,
        "seek": 817624,
        "start": 8202.24,
        "temperature": 0,
        "text": " Bye.",
        "tokens": [
          51664,
          4621,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.41118264809632915,
        "compression_ratio": 1.7548076923076923,
        "end": 8204.24,
        "id": 2448,
        "no_speech_prob": 0.0017541665583848953,
        "seek": 817624,
        "start": 8203.24,
        "temperature": 0,
        "text": " Bye.",
        "tokens": [
          51714,
          4621,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.41118264809632915,
        "compression_ratio": 1.7548076923076923,
        "end": 8205.24,
        "id": 2449,
        "no_speech_prob": 0.0017541665583848953,
        "seek": 817624,
        "start": 8204.24,
        "temperature": 0,
        "text": " Bye.",
        "tokens": [
          51764,
          4621,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2665506817045666,
        "compression_ratio": 1.5603448275862069,
        "end": 8206.84,
        "id": 2450,
        "no_speech_prob": 0.8305388689041138,
        "seek": 820524,
        "start": 8205.24,
        "temperature": 0,
        "text": " This is the end of today's live stream.",
        "tokens": [
          50364,
          639,
          307,
          264,
          917,
          295,
          965,
          311,
          1621,
          4309,
          13,
          50444
        ]
      },
      {
        "avg_logprob": -0.2665506817045666,
        "compression_ratio": 1.5603448275862069,
        "end": 8212.52,
        "id": 2451,
        "no_speech_prob": 0.8305388689041138,
        "seek": 820524,
        "start": 8206.84,
        "temperature": 0,
        "text": " Today, I think I had about four hours of live streaming today.",
        "tokens": [
          50444,
          2692,
          11,
          286,
          519,
          286,
          632,
          466,
          1451,
          2496,
          295,
          1621,
          11791,
          965,
          13,
          50728
        ]
      },
      {
        "avg_logprob": -0.2665506817045666,
        "compression_ratio": 1.5603448275862069,
        "end": 8220.72,
        "id": 2452,
        "no_speech_prob": 0.8305388689041138,
        "seek": 820524,
        "start": 8217,
        "temperature": 0,
        "text": " I'm going to be gone for quite a while because of ThinkerCon",
        "tokens": [
          50952,
          286,
          478,
          516,
          281,
          312,
          2780,
          337,
          1596,
          257,
          1339,
          570,
          295,
          6557,
          260,
          9838,
          51138
        ]
      },
      {
        "avg_logprob": -0.2665506817045666,
        "compression_ratio": 1.5603448275862069,
        "end": 8221.68,
        "id": 2453,
        "no_speech_prob": 0.8305388689041138,
        "seek": 820524,
        "start": 8220.72,
        "temperature": 0,
        "text": " and Thanksgiving.",
        "tokens": [
          51138,
          293,
          21230,
          13,
          51186
        ]
      },
      {
        "avg_logprob": -0.2665506817045666,
        "compression_ratio": 1.5603448275862069,
        "end": 8224.4,
        "id": 2454,
        "no_speech_prob": 0.8305388689041138,
        "seek": 820524,
        "start": 8221.68,
        "temperature": 0,
        "text": " So apologies in advance for that.",
        "tokens": [
          51186,
          407,
          34929,
          294,
          7295,
          337,
          300,
          13,
          51322
        ]
      },
      {
        "avg_logprob": -0.2665506817045666,
        "compression_ratio": 1.5603448275862069,
        "end": 8227,
        "id": 2455,
        "no_speech_prob": 0.8305388689041138,
        "seek": 820524,
        "start": 8224.4,
        "temperature": 0,
        "text": " Hopefully, I'll be able to catch up on a lot of content",
        "tokens": [
          51322,
          10429,
          11,
          286,
          603,
          312,
          1075,
          281,
          3745,
          493,
          322,
          257,
          688,
          295,
          2701,
          51452
        ]
      },
      {
        "avg_logprob": -0.2665506817045666,
        "compression_ratio": 1.5603448275862069,
        "end": 8229.56,
        "id": 2456,
        "no_speech_prob": 0.8305388689041138,
        "seek": 820524,
        "start": 8227,
        "temperature": 0,
        "text": " when I get back.",
        "tokens": [
          51452,
          562,
          286,
          483,
          646,
          13,
          51580
        ]
      },
      {
        "avg_logprob": -0.2665506817045666,
        "compression_ratio": 1.5603448275862069,
        "end": 8233.92,
        "id": 2457,
        "no_speech_prob": 0.8305388689041138,
        "seek": 820524,
        "start": 8229.56,
        "temperature": 0,
        "text": " We have a lot of notifications here on Twitter.",
        "tokens": [
          51580,
          492,
          362,
          257,
          688,
          295,
          13426,
          510,
          322,
          5794,
          13,
          51798
        ]
      },
      {
        "avg_logprob": -0.2665506817045666,
        "compression_ratio": 1.5603448275862069,
        "end": 8235.119999999999,
        "id": 2458,
        "no_speech_prob": 0.8305388689041138,
        "seek": 820524,
        "start": 8233.92,
        "temperature": 0,
        "text": " I'll look at these later.",
        "tokens": [
          51798,
          286,
          603,
          574,
          412,
          613,
          1780,
          13,
          51858
        ]
      },
      {
        "avg_logprob": -0.389834098445559,
        "compression_ratio": 1.5223880597014925,
        "end": 8238.76,
        "id": 2459,
        "no_speech_prob": 0.0038836810272186995,
        "seek": 823512,
        "start": 8235.12,
        "temperature": 0,
        "text": " This is the Coding Train account.",
        "tokens": [
          50364,
          639,
          307,
          264,
          383,
          8616,
          28029,
          2696,
          13,
          50546
        ]
      },
      {
        "avg_logprob": -0.389834098445559,
        "compression_ratio": 1.5223880597014925,
        "end": 8242.6,
        "id": 2460,
        "no_speech_prob": 0.0038836810272186995,
        "seek": 823512,
        "start": 8238.76,
        "temperature": 0,
        "text": " I should do a Coding Train gift basket option for an X-mas shop.",
        "tokens": [
          50546,
          286,
          820,
          360,
          257,
          383,
          8616,
          28029,
          5306,
          8390,
          3614,
          337,
          364,
          1783,
          12,
          3799,
          3945,
          13,
          50738
        ]
      },
      {
        "avg_logprob": -0.389834098445559,
        "compression_ratio": 1.5223880597014925,
        "end": 8243.1,
        "id": 2461,
        "no_speech_prob": 0.0038836810272186995,
        "seek": 823512,
        "start": 8242.6,
        "temperature": 0,
        "text": " Sure.",
        "tokens": [
          50738,
          4894,
          13,
          50763
        ]
      },
      {
        "avg_logprob": -0.389834098445559,
        "compression_ratio": 1.5223880597014925,
        "end": 8248.92,
        "id": 2462,
        "no_speech_prob": 0.0038836810272186995,
        "seek": 823512,
        "start": 8245.92,
        "temperature": 0,
        "text": " Or Sensei Cloco asked, are you planning to step up",
        "tokens": [
          50904,
          1610,
          33123,
          72,
          31901,
          1291,
          2351,
          11,
          366,
          291,
          5038,
          281,
          1823,
          493,
          51054
        ]
      },
      {
        "avg_logprob": -0.389834098445559,
        "compression_ratio": 1.5223880597014925,
        "end": 8250.04,
        "id": 2463,
        "no_speech_prob": 0.0038836810272186995,
        "seek": 823512,
        "start": 8248.92,
        "temperature": 0,
        "text": " on your debugging game?",
        "tokens": [
          51054,
          322,
          428,
          45592,
          1216,
          30,
          51110
        ]
      },
      {
        "avg_logprob": -0.389834098445559,
        "compression_ratio": 1.5223880597014925,
        "end": 8255.84,
        "id": 2464,
        "no_speech_prob": 0.0038836810272186995,
        "seek": 823512,
        "start": 8252.800000000001,
        "temperature": 0,
        "text": " What's wrong with my debugging game?",
        "tokens": [
          51248,
          708,
          311,
          2085,
          365,
          452,
          45592,
          1216,
          30,
          51400
        ]
      },
      {
        "avg_logprob": -0.389834098445559,
        "compression_ratio": 1.5223880597014925,
        "end": 8256.76,
        "id": 2465,
        "no_speech_prob": 0.0038836810272186995,
        "seek": 823512,
        "start": 8255.84,
        "temperature": 0,
        "text": " I know.",
        "tokens": [
          51400,
          286,
          458,
          13,
          51446
        ]
      },
      {
        "avg_logprob": -0.389834098445559,
        "compression_ratio": 1.5223880597014925,
        "end": 8257.6,
        "id": 2466,
        "no_speech_prob": 0.0038836810272186995,
        "seek": 823512,
        "start": 8256.76,
        "temperature": 0,
        "text": " I could do better.",
        "tokens": [
          51446,
          286,
          727,
          360,
          1101,
          13,
          51488
        ]
      },
      {
        "avg_logprob": -0.389834098445559,
        "compression_ratio": 1.5223880597014925,
        "end": 8258.12,
        "id": 2467,
        "no_speech_prob": 0.0038836810272186995,
        "seek": 823512,
        "start": 8257.6,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          51488,
          1079,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.389834098445559,
        "compression_ratio": 1.5223880597014925,
        "end": 8260.36,
        "id": 2468,
        "no_speech_prob": 0.0038836810272186995,
        "seek": 823512,
        "start": 8258.12,
        "temperature": 0,
        "text": " No, I'm not planning to, but I appreciate your help.",
        "tokens": [
          51514,
          883,
          11,
          286,
          478,
          406,
          5038,
          281,
          11,
          457,
          286,
          4449,
          428,
          854,
          13,
          51626
        ]
      },
      {
        "avg_logprob": -0.389834098445559,
        "compression_ratio": 1.5223880597014925,
        "end": 8263.04,
        "id": 2469,
        "no_speech_prob": 0.0038836810272186995,
        "seek": 823512,
        "start": 8260.36,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          51626,
          1079,
          13,
          51760
        ]
      },
      {
        "avg_logprob": -0.22393469907799546,
        "compression_ratio": 1.5466101694915255,
        "end": 8264.880000000001,
        "id": 2470,
        "no_speech_prob": 0.0008426002459600568,
        "seek": 826304,
        "start": 8263.04,
        "temperature": 0,
        "text": " I think that it would be helpful for me",
        "tokens": [
          50364,
          286,
          519,
          300,
          309,
          576,
          312,
          4961,
          337,
          385,
          50456
        ]
      },
      {
        "avg_logprob": -0.22393469907799546,
        "compression_ratio": 1.5466101694915255,
        "end": 8269.36,
        "id": 2471,
        "no_speech_prob": 0.0008426002459600568,
        "seek": 826304,
        "start": 8264.880000000001,
        "temperature": 0,
        "text": " to continue to develop better strategies for debugging",
        "tokens": [
          50456,
          281,
          2354,
          281,
          1499,
          1101,
          9029,
          337,
          45592,
          50680
        ]
      },
      {
        "avg_logprob": -0.22393469907799546,
        "compression_ratio": 1.5466101694915255,
        "end": 8270.400000000001,
        "id": 2472,
        "no_speech_prob": 0.0008426002459600568,
        "seek": 826304,
        "start": 8269.36,
        "temperature": 0,
        "text": " to demonstrate.",
        "tokens": [
          50680,
          281,
          11698,
          13,
          50732
        ]
      },
      {
        "avg_logprob": -0.22393469907799546,
        "compression_ratio": 1.5466101694915255,
        "end": 8272.960000000001,
        "id": 2473,
        "no_speech_prob": 0.0008426002459600568,
        "seek": 826304,
        "start": 8270.400000000001,
        "temperature": 0,
        "text": " You mean you don't like my technique of having a bug",
        "tokens": [
          50732,
          509,
          914,
          291,
          500,
          380,
          411,
          452,
          6532,
          295,
          1419,
          257,
          7426,
          50860
        ]
      },
      {
        "avg_logprob": -0.22393469907799546,
        "compression_ratio": 1.5466101694915255,
        "end": 8274.960000000001,
        "id": 2474,
        "no_speech_prob": 0.0008426002459600568,
        "seek": 826304,
        "start": 8272.960000000001,
        "temperature": 0,
        "text": " and just sitting there going like this?",
        "tokens": [
          50860,
          293,
          445,
          3798,
          456,
          516,
          411,
          341,
          30,
          50960
        ]
      },
      {
        "avg_logprob": -0.22393469907799546,
        "compression_ratio": 1.5466101694915255,
        "end": 8277.720000000001,
        "id": 2475,
        "no_speech_prob": 0.0008426002459600568,
        "seek": 826304,
        "start": 8274.960000000001,
        "temperature": 0,
        "text": " Maybe the chat will tell me what's wrong in just a minute.",
        "tokens": [
          50960,
          2704,
          264,
          5081,
          486,
          980,
          385,
          437,
          311,
          2085,
          294,
          445,
          257,
          3456,
          13,
          51098
        ]
      },
      {
        "avg_logprob": -0.22393469907799546,
        "compression_ratio": 1.5466101694915255,
        "end": 8287.080000000002,
        "id": 2476,
        "no_speech_prob": 0.0008426002459600568,
        "seek": 826304,
        "start": 8282.560000000001,
        "temperature": 0,
        "text": " Tim asked, do you code any other languages than JavaScript?",
        "tokens": [
          51340,
          7172,
          2351,
          11,
          360,
          291,
          3089,
          604,
          661,
          8650,
          813,
          15778,
          30,
          51566
        ]
      },
      {
        "avg_logprob": -0.22393469907799546,
        "compression_ratio": 1.5466101694915255,
        "end": 8288.400000000001,
        "id": 2477,
        "no_speech_prob": 0.0008426002459600568,
        "seek": 826304,
        "start": 8287.080000000002,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          51566,
          1079,
          13,
          51632
        ]
      },
      {
        "avg_logprob": -0.22393469907799546,
        "compression_ratio": 1.5466101694915255,
        "end": 8291.52,
        "id": 2478,
        "no_speech_prob": 0.0008426002459600568,
        "seek": 826304,
        "start": 8288.400000000001,
        "temperature": 0,
        "text": " So I do a lot of programming in Java,",
        "tokens": [
          51632,
          407,
          286,
          360,
          257,
          688,
          295,
          9410,
          294,
          10745,
          11,
          51788
        ]
      },
      {
        "avg_logprob": -0.33379554748535156,
        "compression_ratio": 1.5380952380952382,
        "end": 8296.16,
        "id": 2479,
        "no_speech_prob": 0.0005109558114781976,
        "seek": 829152,
        "start": 8291.52,
        "temperature": 0,
        "text": " specifically using Processing, which is a Java-based platform",
        "tokens": [
          50364,
          4682,
          1228,
          31093,
          278,
          11,
          597,
          307,
          257,
          10745,
          12,
          6032,
          3663,
          50596
        ]
      },
      {
        "avg_logprob": -0.33379554748535156,
        "compression_ratio": 1.5380952380952382,
        "end": 8298.28,
        "id": 2480,
        "no_speech_prob": 0.0005109558114781976,
        "seek": 829152,
        "start": 8296.16,
        "temperature": 0,
        "text": " you can download here.",
        "tokens": [
          50596,
          291,
          393,
          5484,
          510,
          13,
          50702
        ]
      },
      {
        "avg_logprob": -0.33379554748535156,
        "compression_ratio": 1.5380952380952382,
        "end": 8300.32,
        "id": 2481,
        "no_speech_prob": 0.0005109558114781976,
        "seek": 829152,
        "start": 8298.28,
        "temperature": 0,
        "text": " I actually was thinking of doing the Quick Draw",
        "tokens": [
          50702,
          286,
          767,
          390,
          1953,
          295,
          884,
          264,
          12101,
          20386,
          50804
        ]
      },
      {
        "avg_logprob": -0.33379554748535156,
        "compression_ratio": 1.5380952380952382,
        "end": 8303.76,
        "id": 2482,
        "no_speech_prob": 0.0005109558114781976,
        "seek": 829152,
        "start": 8300.32,
        "temperature": 0,
        "text": " stuff in Processing because of loading the big files.",
        "tokens": [
          50804,
          1507,
          294,
          31093,
          278,
          570,
          295,
          15114,
          264,
          955,
          7098,
          13,
          50976
        ]
      },
      {
        "avg_logprob": -0.33379554748535156,
        "compression_ratio": 1.5380952380952382,
        "end": 8305.720000000001,
        "id": 2483,
        "no_speech_prob": 0.0005109558114781976,
        "seek": 829152,
        "start": 8303.76,
        "temperature": 0,
        "text": " I didn't want to deal with setting up a server,",
        "tokens": [
          50976,
          286,
          994,
          380,
          528,
          281,
          2028,
          365,
          3287,
          493,
          257,
          7154,
          11,
          51074
        ]
      },
      {
        "avg_logprob": -0.33379554748535156,
        "compression_ratio": 1.5380952380952382,
        "end": 8307.560000000001,
        "id": 2484,
        "no_speech_prob": 0.0005109558114781976,
        "seek": 829152,
        "start": 8305.720000000001,
        "temperature": 0,
        "text": " but then I went ahead and did the Node thing",
        "tokens": [
          51074,
          457,
          550,
          286,
          1437,
          2286,
          293,
          630,
          264,
          38640,
          551,
          51166
        ]
      },
      {
        "avg_logprob": -0.33379554748535156,
        "compression_ratio": 1.5380952380952382,
        "end": 8310,
        "id": 2485,
        "no_speech_prob": 0.0005109558114781976,
        "seek": 829152,
        "start": 8307.560000000001,
        "temperature": 0,
        "text": " because I thought that was interesting.",
        "tokens": [
          51166,
          570,
          286,
          1194,
          300,
          390,
          1880,
          13,
          51288
        ]
      },
      {
        "avg_logprob": -0.33379554748535156,
        "compression_ratio": 1.5380952380952382,
        "end": 8310.5,
        "id": 2486,
        "no_speech_prob": 0.0005109558114781976,
        "seek": 829152,
        "start": 8310,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51288,
          2264,
          13,
          51313
        ]
      },
      {
        "avg_logprob": -0.6477773961886554,
        "compression_ratio": 1.4144736842105263,
        "end": 8322.52,
        "id": 2487,
        "no_speech_prob": 0.015899108722805977,
        "seek": 832152,
        "start": 8321.54,
        "temperature": 0.8,
        "text": " Thank you.",
        "tokens": [
          50365,
          1044,
          291,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.6477773961886554,
        "compression_ratio": 1.4144736842105263,
        "end": 8341.24,
        "id": 2488,
        "no_speech_prob": 0.015899108722805977,
        "seek": 832152,
        "start": 8338.5,
        "temperature": 0.8,
        "text": " Just use debugger in the JS file and Chrome",
        "tokens": [
          51213,
          508,
          301,
          83,
          764,
          368,
          44455,
          1321,
          741,
          77,
          264,
          33063,
          3991,
          293,
          15327,
          51350
        ]
      },
      {
        "avg_logprob": -0.6477773961886554,
        "compression_ratio": 1.4144736842105263,
        "end": 8343.48,
        "id": 2489,
        "no_speech_prob": 0.015899108722805977,
        "seek": 832152,
        "start": 8341.24,
        "temperature": 0.8,
        "text": " will stop at that breakpoint for you.",
        "tokens": [
          51350,
          486,
          1590,
          412,
          300,
          1821,
          6053,
          337,
          291,
          13,
          51462
        ]
      },
      {
        "avg_logprob": -0.6477773961886554,
        "compression_ratio": 1.4144736842105263,
        "end": 8345.28,
        "id": 2490,
        "no_speech_prob": 0.015899108722805977,
        "seek": 832152,
        "start": 8343.48,
        "temperature": 0.8,
        "text": " I should probably try that at some point.",
        "tokens": [
          51462,
          286,
          820,
          1391,
          853,
          300,
          412,
          512,
          935,
          13,
          51552
        ]
      },
      {
        "avg_logprob": -0.6477773961886554,
        "compression_ratio": 1.4144736842105263,
        "end": 8346.560000000001,
        "id": 2491,
        "no_speech_prob": 0.015899108722805977,
        "seek": 832152,
        "start": 8345.28,
        "temperature": 0.8,
        "text": " That's a very good suggestion.",
        "tokens": [
          51552,
          663,
          311,
          257,
          588,
          665,
          16541,
          13,
          51616
        ]
      },
      {
        "avg_logprob": -0.6477773961886554,
        "compression_ratio": 1.4144736842105263,
        "end": 8348.7,
        "id": 2492,
        "no_speech_prob": 0.015899108722805977,
        "seek": 832152,
        "start": 8346.560000000001,
        "temperature": 0.8,
        "text": " Thank you.",
        "tokens": [
          51616,
          1044,
          291,
          13,
          51723
        ]
      },
      {
        "avg_logprob": -0.6477773961886554,
        "compression_ratio": 1.4144736842105263,
        "end": 8350.720000000001,
        "id": 2493,
        "no_speech_prob": 0.015899108722805977,
        "seek": 832152,
        "start": 8348.7,
        "temperature": 0.8,
        "text": " Thank you, Joop for your kind comment.",
        "tokens": [
          51723,
          1044,
          291,
          11,
          35169,
          79,
          337,
          428,
          733,
          2871,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.3526119085458609,
        "compression_ratio": 1.5040650406504066,
        "end": 8353.58,
        "id": 2494,
        "no_speech_prob": 0.004608622752130032,
        "seek": 835072,
        "start": 8350.72,
        "temperature": 0,
        "text": " What classes do you teach and what are they about code?",
        "tokens": [
          50364,
          708,
          5359,
          360,
          291,
          2924,
          293,
          437,
          366,
          436,
          466,
          3089,
          30,
          50507
        ]
      },
      {
        "avg_logprob": -0.3526119085458609,
        "compression_ratio": 1.5040650406504066,
        "end": 8361.42,
        "id": 2495,
        "no_speech_prob": 0.004608622752130032,
        "seek": 835072,
        "start": 8356.22,
        "temperature": 0,
        "text": " So very quickly, I will answer Aki MC's question.",
        "tokens": [
          50639,
          407,
          588,
          2661,
          11,
          286,
          486,
          1867,
          316,
          2984,
          8797,
          311,
          1168,
          13,
          50899
        ]
      },
      {
        "avg_logprob": -0.3526119085458609,
        "compression_ratio": 1.5040650406504066,
        "end": 8367.74,
        "id": 2496,
        "no_speech_prob": 0.004608622752130032,
        "seek": 835072,
        "start": 8361.42,
        "temperature": 0,
        "text": " Thank you to ILouisSmith who has added two pull requests.",
        "tokens": [
          50899,
          1044,
          291,
          281,
          286,
          46316,
          271,
          26578,
          355,
          567,
          575,
          3869,
          732,
          2235,
          12475,
          13,
          51215
        ]
      },
      {
        "avg_logprob": -0.3526119085458609,
        "compression_ratio": 1.5040650406504066,
        "end": 8369.74,
        "id": 2497,
        "no_speech_prob": 0.004608622752130032,
        "seek": 835072,
        "start": 8367.74,
        "temperature": 0,
        "text": " So I teach classes at New York University,",
        "tokens": [
          51215,
          407,
          286,
          2924,
          5359,
          412,
          1873,
          3609,
          3535,
          11,
          51315
        ]
      },
      {
        "avg_logprob": -0.3526119085458609,
        "compression_ratio": 1.5040650406504066,
        "end": 8371.179999999998,
        "id": 2498,
        "no_speech_prob": 0.004608622752130032,
        "seek": 835072,
        "start": 8369.74,
        "temperature": 0,
        "text": " a part of Tisch School of the Arts.",
        "tokens": [
          51315,
          257,
          644,
          295,
          48192,
          5070,
          295,
          264,
          12407,
          13,
          51387
        ]
      },
      {
        "avg_logprob": -0.3526119085458609,
        "compression_ratio": 1.5040650406504066,
        "end": 8372.859999999999,
        "id": 2499,
        "no_speech_prob": 0.004608622752130032,
        "seek": 835072,
        "start": 8371.179999999998,
        "temperature": 0,
        "text": " There's a grad program called ITP",
        "tokens": [
          51387,
          821,
          311,
          257,
          2771,
          1461,
          1219,
          6783,
          47,
          51471
        ]
      },
      {
        "avg_logprob": -0.3526119085458609,
        "compression_ratio": 1.5040650406504066,
        "end": 8375.619999999999,
        "id": 2500,
        "no_speech_prob": 0.004608622752130032,
        "seek": 835072,
        "start": 8372.859999999999,
        "temperature": 0,
        "text": " and an undergrad program called IMA.",
        "tokens": [
          51471,
          293,
          364,
          14295,
          1461,
          1219,
          286,
          9998,
          13,
          51609
        ]
      },
      {
        "avg_logprob": -0.3526119085458609,
        "compression_ratio": 1.5040650406504066,
        "end": 8379.06,
        "id": 2501,
        "no_speech_prob": 0.004608622752130032,
        "seek": 835072,
        "start": 8375.619999999999,
        "temperature": 0,
        "text": " And then online, I make videos for this YouTube channel.",
        "tokens": [
          51609,
          400,
          550,
          2950,
          11,
          286,
          652,
          2145,
          337,
          341,
          3088,
          2269,
          13,
          51781
        ]
      },
      {
        "avg_logprob": -0.24791798400878906,
        "compression_ratio": 1.7335766423357664,
        "end": 8381.019999999999,
        "id": 2502,
        "no_speech_prob": 0.0004238768306095153,
        "seek": 837906,
        "start": 8379.08,
        "temperature": 0,
        "text": " And some of them are loosely grouped",
        "tokens": [
          50365,
          400,
          512,
          295,
          552,
          366,
          37966,
          41877,
          50462
        ]
      },
      {
        "avg_logprob": -0.24791798400878906,
        "compression_ratio": 1.7335766423357664,
        "end": 8384.06,
        "id": 2503,
        "no_speech_prob": 0.0004238768306095153,
        "seek": 837906,
        "start": 8381.019999999999,
        "temperature": 0,
        "text": " into things that could possibly somewhat be classes.",
        "tokens": [
          50462,
          666,
          721,
          300,
          727,
          6264,
          8344,
          312,
          5359,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.24791798400878906,
        "compression_ratio": 1.7335766423357664,
        "end": 8387.14,
        "id": 2504,
        "no_speech_prob": 0.0004238768306095153,
        "seek": 837906,
        "start": 8384.06,
        "temperature": 0,
        "text": " But I haven't really cracked that nut yet of like,",
        "tokens": [
          50614,
          583,
          286,
          2378,
          380,
          534,
          25140,
          300,
          5393,
          1939,
          295,
          411,
          11,
          50768
        ]
      },
      {
        "avg_logprob": -0.24791798400878906,
        "compression_ratio": 1.7335766423357664,
        "end": 8390.539999999999,
        "id": 2505,
        "no_speech_prob": 0.0004238768306095153,
        "seek": 837906,
        "start": 8387.14,
        "temperature": 0,
        "text": " this thing on YouTube is a course that you could take.",
        "tokens": [
          50768,
          341,
          551,
          322,
          3088,
          307,
          257,
          1164,
          300,
          291,
          727,
          747,
          13,
          50938
        ]
      },
      {
        "avg_logprob": -0.24791798400878906,
        "compression_ratio": 1.7335766423357664,
        "end": 8392.06,
        "id": 2506,
        "no_speech_prob": 0.0004238768306095153,
        "seek": 837906,
        "start": 8390.539999999999,
        "temperature": 0,
        "text": " It's really just a lot of content",
        "tokens": [
          50938,
          467,
          311,
          534,
          445,
          257,
          688,
          295,
          2701,
          51014
        ]
      },
      {
        "avg_logprob": -0.24791798400878906,
        "compression_ratio": 1.7335766423357664,
        "end": 8394.34,
        "id": 2507,
        "no_speech_prob": 0.0004238768306095153,
        "seek": 837906,
        "start": 8392.06,
        "temperature": 0,
        "text": " and hopefully inspirational and helpful.",
        "tokens": [
          51014,
          293,
          4696,
          33554,
          293,
          4961,
          13,
          51128
        ]
      },
      {
        "avg_logprob": -0.24791798400878906,
        "compression_ratio": 1.7335766423357664,
        "end": 8396.859999999999,
        "id": 2508,
        "no_speech_prob": 0.0004238768306095153,
        "seek": 837906,
        "start": 8394.34,
        "temperature": 0,
        "text": " But in terms of the actual things being a course,",
        "tokens": [
          51128,
          583,
          294,
          2115,
          295,
          264,
          3539,
          721,
          885,
          257,
          1164,
          11,
          51254
        ]
      },
      {
        "avg_logprob": -0.24791798400878906,
        "compression_ratio": 1.7335766423357664,
        "end": 8400.06,
        "id": 2509,
        "no_speech_prob": 0.0004238768306095153,
        "seek": 837906,
        "start": 8396.859999999999,
        "temperature": 0,
        "text": " the place where you can look, and one thing",
        "tokens": [
          51254,
          264,
          1081,
          689,
          291,
          393,
          574,
          11,
          293,
          472,
          551,
          51414
        ]
      },
      {
        "avg_logprob": -0.24791798400878906,
        "compression_ratio": 1.7335766423357664,
        "end": 8402.5,
        "id": 2510,
        "no_speech_prob": 0.0004238768306095153,
        "seek": 837906,
        "start": 8400.06,
        "temperature": 0,
        "text": " is I'm really trying to do is, in theory,",
        "tokens": [
          51414,
          307,
          286,
          478,
          534,
          1382,
          281,
          360,
          307,
          11,
          294,
          5261,
          11,
          51536
        ]
      },
      {
        "avg_logprob": -0.24791798400878906,
        "compression_ratio": 1.7335766423357664,
        "end": 8405.34,
        "id": 2511,
        "no_speech_prob": 0.0004238768306095153,
        "seek": 837906,
        "start": 8402.5,
        "temperature": 0,
        "text": " I would like to continue to work on and improve",
        "tokens": [
          51536,
          286,
          576,
          411,
          281,
          2354,
          281,
          589,
          322,
          293,
          3470,
          51678
        ]
      },
      {
        "avg_logprob": -0.24791798400878906,
        "compression_ratio": 1.7335766423357664,
        "end": 8406.98,
        "id": 2512,
        "no_speech_prob": 0.0004238768306095153,
        "seek": 837906,
        "start": 8405.34,
        "temperature": 0,
        "text": " the navigation here.",
        "tokens": [
          51678,
          264,
          17346,
          510,
          13,
          51760
        ]
      },
      {
        "avg_logprob": -0.2791838460154348,
        "compression_ratio": 1.4482758620689655,
        "end": 8411.66,
        "id": 2513,
        "no_speech_prob": 0.00001165914272860391,
        "seek": 840698,
        "start": 8406.98,
        "temperature": 0,
        "text": " So there are some, so in theory, I",
        "tokens": [
          50364,
          407,
          456,
          366,
          512,
          11,
          370,
          294,
          5261,
          11,
          286,
          50598
        ]
      },
      {
        "avg_logprob": -0.2791838460154348,
        "compression_ratio": 1.4482758620689655,
        "end": 8415.58,
        "id": 2514,
        "no_speech_prob": 0.00001165914272860391,
        "seek": 840698,
        "start": 8411.66,
        "temperature": 0,
        "text": " would like this website to be a place where it's easier",
        "tokens": [
          50598,
          576,
          411,
          341,
          3144,
          281,
          312,
          257,
          1081,
          689,
          309,
          311,
          3571,
          50794
        ]
      },
      {
        "avg_logprob": -0.2791838460154348,
        "compression_ratio": 1.4482758620689655,
        "end": 8418.22,
        "id": 2515,
        "no_speech_prob": 0.00001165914272860391,
        "seek": 840698,
        "start": 8415.58,
        "temperature": 0,
        "text": " to find the packaged courses.",
        "tokens": [
          50794,
          281,
          915,
          264,
          38162,
          7712,
          13,
          50926
        ]
      },
      {
        "avg_logprob": -0.2791838460154348,
        "compression_ratio": 1.4482758620689655,
        "end": 8419.82,
        "id": 2516,
        "no_speech_prob": 0.00001165914272860391,
        "seek": 840698,
        "start": 8418.22,
        "temperature": 0,
        "text": " Right now, if you're looking for that,",
        "tokens": [
          50926,
          1779,
          586,
          11,
          498,
          291,
          434,
          1237,
          337,
          300,
          11,
          51006
        ]
      },
      {
        "avg_logprob": -0.2791838460154348,
        "compression_ratio": 1.4482758620689655,
        "end": 8427.74,
        "id": 2517,
        "no_speech_prob": 0.00001165914272860391,
        "seek": 840698,
        "start": 8419.82,
        "temperature": 0,
        "text": " I think if you go to YouTube Coding Train Playlists,",
        "tokens": [
          51006,
          286,
          519,
          498,
          291,
          352,
          281,
          3088,
          383,
          8616,
          28029,
          5506,
          36693,
          11,
          51402
        ]
      },
      {
        "avg_logprob": -0.2791838460154348,
        "compression_ratio": 1.4482758620689655,
        "end": 8435.9,
        "id": 2518,
        "no_speech_prob": 0.00001165914272860391,
        "seek": 840698,
        "start": 8427.74,
        "temperature": 0,
        "text": " and if I do All Playlists, you can see.",
        "tokens": [
          51402,
          293,
          498,
          286,
          360,
          1057,
          5506,
          36693,
          11,
          291,
          393,
          536,
          13,
          51810
        ]
      },
      {
        "avg_logprob": -0.23276308963173314,
        "compression_ratio": 1.6130268199233717,
        "end": 8438.46,
        "id": 2519,
        "no_speech_prob": 0.0000069622424234694336,
        "seek": 843590,
        "start": 8435.9,
        "temperature": 0,
        "text": " But this is a big mess of things.",
        "tokens": [
          50364,
          583,
          341,
          307,
          257,
          955,
          2082,
          295,
          721,
          13,
          50492
        ]
      },
      {
        "avg_logprob": -0.23276308963173314,
        "compression_ratio": 1.6130268199233717,
        "end": 8441.02,
        "id": 2520,
        "no_speech_prob": 0.0000069622424234694336,
        "seek": 843590,
        "start": 8438.46,
        "temperature": 0,
        "text": " So I'm trying to figure this out.",
        "tokens": [
          50492,
          407,
          286,
          478,
          1382,
          281,
          2573,
          341,
          484,
          13,
          50620
        ]
      },
      {
        "avg_logprob": -0.23276308963173314,
        "compression_ratio": 1.6130268199233717,
        "end": 8442.3,
        "id": 2521,
        "no_speech_prob": 0.0000069622424234694336,
        "seek": 843590,
        "start": 8441.02,
        "temperature": 0,
        "text": " Some things are organized.",
        "tokens": [
          50620,
          2188,
          721,
          366,
          9983,
          13,
          50684
        ]
      },
      {
        "avg_logprob": -0.23276308963173314,
        "compression_ratio": 1.6130268199233717,
        "end": 8449.3,
        "id": 2522,
        "no_speech_prob": 0.0000069622424234694336,
        "seek": 843590,
        "start": 8442.3,
        "temperature": 0,
        "text": " For example, you can see here, these",
        "tokens": [
          50684,
          1171,
          1365,
          11,
          291,
          393,
          536,
          510,
          11,
          613,
          51034
        ]
      },
      {
        "avg_logprob": -0.23276308963173314,
        "compression_ratio": 1.6130268199233717,
        "end": 8452.82,
        "id": 2523,
        "no_speech_prob": 0.0000069622424234694336,
        "seek": 843590,
        "start": 8449.3,
        "temperature": 0,
        "text": " are the beginner JavaScript tutorials, Playlists 1",
        "tokens": [
          51034,
          366,
          264,
          22080,
          15778,
          17616,
          11,
          5506,
          36693,
          502,
          51210
        ]
      },
      {
        "avg_logprob": -0.23276308963173314,
        "compression_ratio": 1.6130268199233717,
        "end": 8456.1,
        "id": 2524,
        "no_speech_prob": 0.0000069622424234694336,
        "seek": 843590,
        "start": 8452.82,
        "temperature": 0,
        "text": " through 7, Playlist 8, et cetera.",
        "tokens": [
          51210,
          807,
          1614,
          11,
          5506,
          8264,
          1649,
          11,
          1030,
          11458,
          13,
          51374
        ]
      },
      {
        "avg_logprob": -0.23276308963173314,
        "compression_ratio": 1.6130268199233717,
        "end": 8457.74,
        "id": 2525,
        "no_speech_prob": 0.0000069622424234694336,
        "seek": 843590,
        "start": 8456.1,
        "temperature": 0,
        "text": " These are some playlists associated",
        "tokens": [
          51374,
          1981,
          366,
          512,
          862,
          36693,
          6615,
          51456
        ]
      },
      {
        "avg_logprob": -0.23276308963173314,
        "compression_ratio": 1.6130268199233717,
        "end": 8460.22,
        "id": 2526,
        "no_speech_prob": 0.0000069622424234694336,
        "seek": 843590,
        "start": 8457.74,
        "temperature": 0,
        "text": " with neural networks and machine learning.",
        "tokens": [
          51456,
          365,
          18161,
          9590,
          293,
          3479,
          2539,
          13,
          51580
        ]
      },
      {
        "avg_logprob": -0.23276308963173314,
        "compression_ratio": 1.6130268199233717,
        "end": 8462.359999999999,
        "id": 2527,
        "no_speech_prob": 0.0000069622424234694336,
        "seek": 843590,
        "start": 8460.22,
        "temperature": 0,
        "text": " This is an old, antiquated Twitter bot tutorial",
        "tokens": [
          51580,
          639,
          307,
          364,
          1331,
          11,
          41036,
          770,
          5794,
          10592,
          7073,
          51687
        ]
      },
      {
        "avg_logprob": -0.23276308963173314,
        "compression_ratio": 1.6130268199233717,
        "end": 8463.82,
        "id": 2528,
        "no_speech_prob": 0.0000069622424234694336,
        "seek": 843590,
        "start": 8462.359999999999,
        "temperature": 0,
        "text": " that probably doesn't work anymore.",
        "tokens": [
          51687,
          300,
          1391,
          1177,
          380,
          589,
          3602,
          13,
          51760
        ]
      },
      {
        "avg_logprob": -0.23276308963173314,
        "compression_ratio": 1.6130268199233717,
        "end": 8465.699999999999,
        "id": 2529,
        "no_speech_prob": 0.0000069622424234694336,
        "seek": 843590,
        "start": 8463.82,
        "temperature": 0,
        "text": " These are some old nature of code videos.",
        "tokens": [
          51760,
          1981,
          366,
          512,
          1331,
          3687,
          295,
          3089,
          2145,
          13,
          51854
        ]
      },
      {
        "avg_logprob": -0.3015338213015825,
        "compression_ratio": 1.421875,
        "end": 8468.380000000001,
        "id": 2530,
        "no_speech_prob": 0.00018522384925745428,
        "seek": 846570,
        "start": 8465.7,
        "temperature": 0,
        "text": " Here's the beginner processing videos, Git and GitHub.",
        "tokens": [
          50364,
          1692,
          311,
          264,
          22080,
          9007,
          2145,
          11,
          16939,
          293,
          23331,
          13,
          50498
        ]
      },
      {
        "avg_logprob": -0.3015338213015825,
        "compression_ratio": 1.421875,
        "end": 8473.300000000001,
        "id": 2531,
        "no_speech_prob": 0.00018522384925745428,
        "seek": 846570,
        "start": 8468.380000000001,
        "temperature": 0,
        "text": " But again, please, somebody save me",
        "tokens": [
          50498,
          583,
          797,
          11,
          1767,
          11,
          2618,
          3155,
          385,
          50744
        ]
      },
      {
        "avg_logprob": -0.3015338213015825,
        "compression_ratio": 1.421875,
        "end": 8476.140000000001,
        "id": 2532,
        "no_speech_prob": 0.00018522384925745428,
        "seek": 846570,
        "start": 8473.300000000001,
        "temperature": 0,
        "text": " and help me figure out how to organize all this stuff.",
        "tokens": [
          50744,
          293,
          854,
          385,
          2573,
          484,
          577,
          281,
          13859,
          439,
          341,
          1507,
          13,
          50886
        ]
      },
      {
        "avg_logprob": -0.3015338213015825,
        "compression_ratio": 1.421875,
        "end": 8476.640000000001,
        "id": 2533,
        "no_speech_prob": 0.00018522384925745428,
        "seek": 846570,
        "start": 8476.140000000001,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50886,
          2264,
          13,
          50911
        ]
      },
      {
        "avg_logprob": -0.3015338213015825,
        "compression_ratio": 1.421875,
        "end": 8486.5,
        "id": 2534,
        "no_speech_prob": 0.00018522384925745428,
        "seek": 846570,
        "start": 8476.640000000001,
        "temperature": 0,
        "text": " Why not create a storyboard for the website?",
        "tokens": [
          50911,
          220,
          8429,
          406,
          1884,
          257,
          1657,
          3787,
          337,
          264,
          3144,
          30,
          51404
        ]
      },
      {
        "avg_logprob": -0.3015338213015825,
        "compression_ratio": 1.421875,
        "end": 8489.220000000001,
        "id": 2535,
        "no_speech_prob": 0.00018522384925745428,
        "seek": 846570,
        "start": 8486.5,
        "temperature": 0,
        "text": " Yes, actually, so Matthew, if you",
        "tokens": [
          51404,
          1079,
          11,
          767,
          11,
          370,
          12434,
          11,
          498,
          291,
          51540
        ]
      },
      {
        "avg_logprob": -0.3015338213015825,
        "compression_ratio": 1.421875,
        "end": 8494.26,
        "id": 2536,
        "no_speech_prob": 0.00018522384925745428,
        "seek": 846570,
        "start": 8489.220000000001,
        "temperature": 0,
        "text": " go to the GitHub repository for the website,",
        "tokens": [
          51540,
          352,
          281,
          264,
          23331,
          25841,
          337,
          264,
          3144,
          11,
          51792
        ]
      },
      {
        "avg_logprob": -0.29723932409799225,
        "compression_ratio": 1.6527777777777777,
        "end": 8498.62,
        "id": 2537,
        "no_speech_prob": 0.0000382287944376003,
        "seek": 849426,
        "start": 8494.26,
        "temperature": 0,
        "text": " if you go under Issues, there are a few different issues",
        "tokens": [
          50364,
          498,
          291,
          352,
          833,
          38195,
          1247,
          11,
          456,
          366,
          257,
          1326,
          819,
          2663,
          50582
        ]
      },
      {
        "avg_logprob": -0.29723932409799225,
        "compression_ratio": 1.6527777777777777,
        "end": 8503.62,
        "id": 2538,
        "no_speech_prob": 0.0000382287944376003,
        "seek": 849426,
        "start": 8498.62,
        "temperature": 0,
        "text": " that are currently tracking this discussion.",
        "tokens": [
          50582,
          300,
          366,
          4362,
          11603,
          341,
          5017,
          13,
          50832
        ]
      },
      {
        "avg_logprob": -0.29723932409799225,
        "compression_ratio": 1.6527777777777777,
        "end": 8508.42,
        "id": 2539,
        "no_speech_prob": 0.0000382287944376003,
        "seek": 849426,
        "start": 8503.62,
        "temperature": 0,
        "text": " So this is one proposal to have the website organized",
        "tokens": [
          50832,
          407,
          341,
          307,
          472,
          11494,
          281,
          362,
          264,
          3144,
          9983,
          51072
        ]
      },
      {
        "avg_logprob": -0.29723932409799225,
        "compression_ratio": 1.6527777777777777,
        "end": 8511.98,
        "id": 2540,
        "no_speech_prob": 0.0000382287944376003,
        "seek": 849426,
        "start": 8508.42,
        "temperature": 0,
        "text": " as coding challenges, beginner playlists,",
        "tokens": [
          51072,
          382,
          17720,
          4759,
          11,
          22080,
          862,
          36693,
          11,
          51250
        ]
      },
      {
        "avg_logprob": -0.29723932409799225,
        "compression_ratio": 1.6527777777777777,
        "end": 8516.9,
        "id": 2541,
        "no_speech_prob": 0.0000382287944376003,
        "seek": 849426,
        "start": 8511.98,
        "temperature": 0,
        "text": " and then other courses that are not for beginners.",
        "tokens": [
          51250,
          293,
          550,
          661,
          7712,
          300,
          366,
          406,
          337,
          26992,
          13,
          51496
        ]
      },
      {
        "avg_logprob": -0.29723932409799225,
        "compression_ratio": 1.6527777777777777,
        "end": 8519.42,
        "id": 2542,
        "no_speech_prob": 0.0000382287944376003,
        "seek": 849426,
        "start": 8516.9,
        "temperature": 0,
        "text": " So that's one thing that, and then all the live stream",
        "tokens": [
          51496,
          407,
          300,
          311,
          472,
          551,
          300,
          11,
          293,
          550,
          439,
          264,
          1621,
          4309,
          51622
        ]
      },
      {
        "avg_logprob": -0.29723932409799225,
        "compression_ratio": 1.6527777777777777,
        "end": 8519.94,
        "id": 2543,
        "no_speech_prob": 0.0000382287944376003,
        "seek": 849426,
        "start": 8519.42,
        "temperature": 0,
        "text": " archives.",
        "tokens": [
          51622,
          25607,
          13,
          51648
        ]
      },
      {
        "avg_logprob": -0.29723932409799225,
        "compression_ratio": 1.6527777777777777,
        "end": 8522.94,
        "id": 2544,
        "no_speech_prob": 0.0000382287944376003,
        "seek": 849426,
        "start": 8519.94,
        "temperature": 0,
        "text": " So again, this is like Neil's web has done,",
        "tokens": [
          51648,
          407,
          797,
          11,
          341,
          307,
          411,
          18615,
          311,
          3670,
          575,
          1096,
          11,
          51798
        ]
      },
      {
        "avg_logprob": -0.2711784816024327,
        "compression_ratio": 1.6092436974789917,
        "end": 8525.94,
        "id": 2545,
        "no_speech_prob": 0.0000490813072246965,
        "seek": 852294,
        "start": 8522.94,
        "temperature": 0,
        "text": " and many other contributors, but Neil's web in particular",
        "tokens": [
          50364,
          293,
          867,
          661,
          45627,
          11,
          457,
          18615,
          311,
          3670,
          294,
          1729,
          50514
        ]
      },
      {
        "avg_logprob": -0.2711784816024327,
        "compression_ratio": 1.6092436974789917,
        "end": 8528.62,
        "id": 2546,
        "no_speech_prob": 0.0000490813072246965,
        "seek": 852294,
        "start": 8525.94,
        "temperature": 0,
        "text": " has done a tremendous amount of work.",
        "tokens": [
          50514,
          575,
          1096,
          257,
          10048,
          2372,
          295,
          589,
          13,
          50648
        ]
      },
      {
        "avg_logprob": -0.2711784816024327,
        "compression_ratio": 1.6092436974789917,
        "end": 8533.060000000001,
        "id": 2547,
        "no_speech_prob": 0.0000490813072246965,
        "seek": 852294,
        "start": 8528.62,
        "temperature": 0,
        "text": " Neil's Webber is a student and web developer in Germany.",
        "tokens": [
          50648,
          18615,
          311,
          9573,
          607,
          307,
          257,
          3107,
          293,
          3670,
          10754,
          294,
          7244,
          13,
          50870
        ]
      },
      {
        "avg_logprob": -0.2711784816024327,
        "compression_ratio": 1.6092436974789917,
        "end": 8537.74,
        "id": 2548,
        "no_speech_prob": 0.0000490813072246965,
        "seek": 852294,
        "start": 8533.060000000001,
        "temperature": 0,
        "text": " And so thank you so much to Neil's web.",
        "tokens": [
          50870,
          400,
          370,
          1309,
          291,
          370,
          709,
          281,
          18615,
          311,
          3670,
          13,
          51104
        ]
      },
      {
        "avg_logprob": -0.2711784816024327,
        "compression_ratio": 1.6092436974789917,
        "end": 8540.54,
        "id": 2549,
        "no_speech_prob": 0.0000490813072246965,
        "seek": 852294,
        "start": 8537.74,
        "temperature": 0,
        "text": " And I am certainly happy for people",
        "tokens": [
          51104,
          400,
          286,
          669,
          3297,
          2055,
          337,
          561,
          51244
        ]
      },
      {
        "avg_logprob": -0.2711784816024327,
        "compression_ratio": 1.6092436974789917,
        "end": 8543.380000000001,
        "id": 2550,
        "no_speech_prob": 0.0000490813072246965,
        "seek": 852294,
        "start": 8540.54,
        "temperature": 0,
        "text": " to contribute and participate in the development of a website.",
        "tokens": [
          51244,
          281,
          10586,
          293,
          8197,
          294,
          264,
          3250,
          295,
          257,
          3144,
          13,
          51386
        ]
      },
      {
        "avg_logprob": -0.2711784816024327,
        "compression_ratio": 1.6092436974789917,
        "end": 8545.86,
        "id": 2551,
        "no_speech_prob": 0.0000490813072246965,
        "seek": 852294,
        "start": 8543.380000000001,
        "temperature": 0,
        "text": " I haven't figured out really a structure to do that,",
        "tokens": [
          51386,
          286,
          2378,
          380,
          8932,
          484,
          534,
          257,
          3877,
          281,
          360,
          300,
          11,
          51510
        ]
      },
      {
        "avg_logprob": -0.2711784816024327,
        "compression_ratio": 1.6092436974789917,
        "end": 8547.9,
        "id": 2552,
        "no_speech_prob": 0.0000490813072246965,
        "seek": 852294,
        "start": 8545.86,
        "temperature": 0,
        "text": " but it's happening in an ad hoc basis.",
        "tokens": [
          51510,
          457,
          309,
          311,
          2737,
          294,
          364,
          614,
          16708,
          5143,
          13,
          51612
        ]
      },
      {
        "avg_logprob": -0.6365666439658717,
        "compression_ratio": 1.4390243902439024,
        "end": 8548.84,
        "id": 2553,
        "no_speech_prob": 0.0005613110843114555,
        "seek": 854790,
        "start": 8548.34,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50386,
          220,
          9443,
          13,
          50411
        ]
      },
      {
        "avg_logprob": -0.6365666439658717,
        "compression_ratio": 1.4390243902439024,
        "end": 8551.34,
        "id": 2554,
        "no_speech_prob": 0.0005613110843114555,
        "seek": 854790,
        "start": 8548.84,
        "temperature": 0,
        "text": " So I'm going to go ahead and move on to the next question.",
        "tokens": [
          50411,
          407,
          286,
          478,
          516,
          281,
          352,
          2286,
          293,
          1286,
          322,
          281,
          264,
          958,
          1168,
          13,
          50536
        ]
      },
      {
        "avg_logprob": -0.6365666439658717,
        "compression_ratio": 1.4390243902439024,
        "end": 8553.34,
        "id": 2555,
        "no_speech_prob": 0.0005613110843114555,
        "seek": 854790,
        "start": 8551.34,
        "temperature": 0,
        "text": " And this is from Tushar Mitra.",
        "tokens": [
          50536,
          400,
          341,
          307,
          490,
          314,
          1498,
          289,
          10821,
          424,
          13,
          50636
        ]
      },
      {
        "avg_logprob": -0.6365666439658717,
        "compression_ratio": 1.4390243902439024,
        "end": 8556.66,
        "id": 2556,
        "no_speech_prob": 0.0005613110843114555,
        "seek": 854790,
        "start": 8553.34,
        "temperature": 0,
        "text": " Tushar Mitra asks, last question, do you game?",
        "tokens": [
          50636,
          314,
          1498,
          289,
          10821,
          424,
          8962,
          11,
          1036,
          1168,
          11,
          360,
          291,
          1216,
          30,
          50802
        ]
      },
      {
        "avg_logprob": -0.6365666439658717,
        "compression_ratio": 1.4390243902439024,
        "end": 8560.34,
        "id": 2557,
        "no_speech_prob": 0.0005613110843114555,
        "seek": 854790,
        "start": 8556.66,
        "temperature": 0,
        "text": " All right, you're going to be sorry you asked.",
        "tokens": [
          50802,
          1057,
          558,
          11,
          291,
          434,
          516,
          281,
          312,
          2597,
          291,
          2351,
          13,
          50986
        ]
      },
      {
        "avg_logprob": -0.6365666439658717,
        "compression_ratio": 1.4390243902439024,
        "end": 8569.38,
        "id": 2558,
        "no_speech_prob": 0.0005613110843114555,
        "seek": 854790,
        "start": 8560.34,
        "temperature": 0,
        "text": " If you go to YouTube.com and you search for EOD Gaming,",
        "tokens": [
          50986,
          759,
          291,
          352,
          281,
          3088,
          13,
          1112,
          293,
          291,
          3164,
          337,
          462,
          14632,
          30288,
          11,
          51438
        ]
      },
      {
        "avg_logprob": -0.6365666439658717,
        "compression_ratio": 1.4390243902439024,
        "end": 8577.3,
        "id": 2559,
        "no_speech_prob": 0.0005613110843114555,
        "seek": 854790,
        "start": 8569.38,
        "temperature": 0,
        "text": " this here with 166 subscribers is my gaming channel",
        "tokens": [
          51438,
          341,
          510,
          365,
          3165,
          21,
          11092,
          307,
          452,
          9703,
          2269,
          51834
        ]
      },
      {
        "avg_logprob": -0.2664718452943574,
        "compression_ratio": 1.4938271604938271,
        "end": 8579.74,
        "id": 2560,
        "no_speech_prob": 0.001754222554154694,
        "seek": 857730,
        "start": 8577.3,
        "temperature": 0,
        "text": " with my kids, who I'm very conflicted about.",
        "tokens": [
          50364,
          365,
          452,
          2301,
          11,
          567,
          286,
          478,
          588,
          6596,
          292,
          466,
          13,
          50486
        ]
      },
      {
        "avg_logprob": -0.2664718452943574,
        "compression_ratio": 1.4938271604938271,
        "end": 8583.82,
        "id": 2561,
        "no_speech_prob": 0.001754222554154694,
        "seek": 857730,
        "start": 8579.74,
        "temperature": 0,
        "text": " But this video is really what I would recommend.",
        "tokens": [
          50486,
          583,
          341,
          960,
          307,
          534,
          437,
          286,
          576,
          2748,
          13,
          50690
        ]
      },
      {
        "avg_logprob": -0.2664718452943574,
        "compression_ratio": 1.4938271604938271,
        "end": 8587.019999999999,
        "id": 2562,
        "no_speech_prob": 0.001754222554154694,
        "seek": 857730,
        "start": 8583.82,
        "temperature": 0,
        "text": " My daughter and I played Snipperclips",
        "tokens": [
          50690,
          1222,
          4653,
          293,
          286,
          3737,
          9264,
          2488,
          2869,
          75,
          2600,
          50850
        ]
      },
      {
        "avg_logprob": -0.2664718452943574,
        "compression_ratio": 1.4938271604938271,
        "end": 8588.539999999999,
        "id": 2563,
        "no_speech_prob": 0.001754222554154694,
        "seek": 857730,
        "start": 8587.019999999999,
        "temperature": 0,
        "text": " for an hour and 40 minutes.",
        "tokens": [
          50850,
          337,
          364,
          1773,
          293,
          3356,
          2077,
          13,
          50926
        ]
      },
      {
        "avg_logprob": -0.2664718452943574,
        "compression_ratio": 1.4938271604938271,
        "end": 8594.019999999999,
        "id": 2564,
        "no_speech_prob": 0.001754222554154694,
        "seek": 857730,
        "start": 8591.3,
        "temperature": 0,
        "text": " And it's a wonderful game.",
        "tokens": [
          51064,
          400,
          309,
          311,
          257,
          3715,
          1216,
          13,
          51200
        ]
      },
      {
        "avg_logprob": -0.2664718452943574,
        "compression_ratio": 1.4938271604938271,
        "end": 8596.48,
        "id": 2565,
        "no_speech_prob": 0.001754222554154694,
        "seek": 857730,
        "start": 8594.019999999999,
        "temperature": 0,
        "text": " And hopefully we'll do this again this weekend sometimes,",
        "tokens": [
          51200,
          400,
          4696,
          321,
          603,
          360,
          341,
          797,
          341,
          6711,
          2171,
          11,
          51323
        ]
      },
      {
        "avg_logprob": -0.2664718452943574,
        "compression_ratio": 1.4938271604938271,
        "end": 8599.779999999999,
        "id": 2566,
        "no_speech_prob": 0.001754222554154694,
        "seek": 857730,
        "start": 8596.48,
        "temperature": 0,
        "text": " but we do live streams trying to play.",
        "tokens": [
          51323,
          457,
          321,
          360,
          1621,
          15842,
          1382,
          281,
          862,
          13,
          51488
        ]
      },
      {
        "avg_logprob": -0.2664718452943574,
        "compression_ratio": 1.4938271604938271,
        "end": 8601.22,
        "id": 2567,
        "no_speech_prob": 0.001754222554154694,
        "seek": 857730,
        "start": 8599.779999999999,
        "temperature": 0,
        "text": " I love this game so much.",
        "tokens": [
          51488,
          286,
          959,
          341,
          1216,
          370,
          709,
          13,
          51560
        ]
      },
      {
        "avg_logprob": -0.2664718452943574,
        "compression_ratio": 1.4938271604938271,
        "end": 8601.98,
        "id": 2568,
        "no_speech_prob": 0.001754222554154694,
        "seek": 857730,
        "start": 8601.22,
        "temperature": 0,
        "text": " It's so much fun.",
        "tokens": [
          51560,
          467,
          311,
          370,
          709,
          1019,
          13,
          51598
        ]
      },
      {
        "avg_logprob": -0.2664718452943574,
        "compression_ratio": 1.4938271604938271,
        "end": 8606.9,
        "id": 2569,
        "no_speech_prob": 0.001754222554154694,
        "seek": 857730,
        "start": 8605.3,
        "temperature": 0,
        "text": " Of course, I got a copyright notice",
        "tokens": [
          51764,
          2720,
          1164,
          11,
          286,
          658,
          257,
          17996,
          3449,
          51844
        ]
      },
      {
        "avg_logprob": -0.33563883551235857,
        "compression_ratio": 1.5192307692307692,
        "end": 8608.3,
        "id": 2570,
        "no_speech_prob": 0.00013341766316443682,
        "seek": 860690,
        "start": 8606.98,
        "temperature": 0,
        "text": " because I used the Snipperclips.",
        "tokens": [
          50368,
          570,
          286,
          1143,
          264,
          9264,
          2488,
          2869,
          75,
          2600,
          13,
          50434
        ]
      },
      {
        "avg_logprob": -0.33563883551235857,
        "compression_ratio": 1.5192307692307692,
        "end": 8612.82,
        "id": 2571,
        "no_speech_prob": 0.00013341766316443682,
        "seek": 860690,
        "start": 8611.18,
        "temperature": 0,
        "text": " Oh, look at this.",
        "tokens": [
          50578,
          876,
          11,
          574,
          412,
          341,
          13,
          50660
        ]
      },
      {
        "avg_logprob": -0.33563883551235857,
        "compression_ratio": 1.5192307692307692,
        "end": 8614.619999999999,
        "id": 2572,
        "no_speech_prob": 0.00013341766316443682,
        "seek": 860690,
        "start": 8612.82,
        "temperature": 0,
        "text": " Oh, am I on YouTube Gaming?",
        "tokens": [
          50660,
          876,
          11,
          669,
          286,
          322,
          3088,
          30288,
          30,
          50750
        ]
      },
      {
        "avg_logprob": -0.33563883551235857,
        "compression_ratio": 1.5192307692307692,
        "end": 8619.06,
        "id": 2573,
        "no_speech_prob": 0.00013341766316443682,
        "seek": 860690,
        "start": 8614.619999999999,
        "temperature": 0,
        "text": " So if I go to gaming.youtube.com.",
        "tokens": [
          50750,
          407,
          498,
          286,
          352,
          281,
          9703,
          13,
          88,
          346,
          1977,
          13,
          1112,
          13,
          50972
        ]
      },
      {
        "avg_logprob": -0.33563883551235857,
        "compression_ratio": 1.5192307692307692,
        "end": 8620.18,
        "id": 2574,
        "no_speech_prob": 0.00013341766316443682,
        "seek": 860690,
        "start": 8619.06,
        "temperature": 0,
        "text": " Whoa, look at this.",
        "tokens": [
          50972,
          7521,
          11,
          574,
          412,
          341,
          13,
          51028
        ]
      },
      {
        "avg_logprob": -0.33563883551235857,
        "compression_ratio": 1.5192307692307692,
        "end": 8622.46,
        "id": 2575,
        "no_speech_prob": 0.00013341766316443682,
        "seek": 860690,
        "start": 8620.18,
        "temperature": 0,
        "text": " You already got the plan.",
        "tokens": [
          51028,
          509,
          1217,
          658,
          264,
          1393,
          13,
          51142
        ]
      },
      {
        "avg_logprob": -0.33563883551235857,
        "compression_ratio": 1.5192307692307692,
        "end": 8623.46,
        "id": 2576,
        "no_speech_prob": 0.00013341766316443682,
        "seek": 860690,
        "start": 8622.46,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51142,
          865,
          13,
          51192
        ]
      },
      {
        "avg_logprob": -0.33563883551235857,
        "compression_ratio": 1.5192307692307692,
        "end": 8628.1,
        "id": 2577,
        "no_speech_prob": 0.00013341766316443682,
        "seek": 860690,
        "start": 8623.46,
        "temperature": 0,
        "text": " So someday this is going to be even bigger",
        "tokens": [
          51192,
          407,
          19412,
          341,
          307,
          516,
          281,
          312,
          754,
          3801,
          51424
        ]
      },
      {
        "avg_logprob": -0.33563883551235857,
        "compression_ratio": 1.5192307692307692,
        "end": 8629.38,
        "id": 2578,
        "no_speech_prob": 0.00013341766316443682,
        "seek": 860690,
        "start": 8628.1,
        "temperature": 0,
        "text": " than the coding train.",
        "tokens": [
          51424,
          813,
          264,
          17720,
          3847,
          13,
          51488
        ]
      },
      {
        "avg_logprob": -0.33563883551235857,
        "compression_ratio": 1.5192307692307692,
        "end": 8630.26,
        "id": 2579,
        "no_speech_prob": 0.00013341766316443682,
        "seek": 860690,
        "start": 8629.38,
        "temperature": 0,
        "text": " Oh, I don't think so.",
        "tokens": [
          51488,
          876,
          11,
          286,
          500,
          380,
          519,
          370,
          13,
          51532
        ]
      },
      {
        "avg_logprob": -0.33563883551235857,
        "compression_ratio": 1.5192307692307692,
        "end": 8631.42,
        "id": 2580,
        "no_speech_prob": 0.00013341766316443682,
        "seek": 860690,
        "start": 8630.26,
        "temperature": 0,
        "text": " All right, everybody.",
        "tokens": [
          51532,
          1057,
          558,
          11,
          2201,
          13,
          51590
        ]
      },
      {
        "avg_logprob": -0.33563883551235857,
        "compression_ratio": 1.5192307692307692,
        "end": 8632.06,
        "id": 2581,
        "no_speech_prob": 0.00013341766316443682,
        "seek": 860690,
        "start": 8631.42,
        "temperature": 0,
        "text": " Goodbye.",
        "tokens": [
          51590,
          15528,
          13,
          51622
        ]
      },
      {
        "avg_logprob": -0.33563883551235857,
        "compression_ratio": 1.5192307692307692,
        "end": 8633.699999999999,
        "id": 2582,
        "no_speech_prob": 0.00013341766316443682,
        "seek": 860690,
        "start": 8632.06,
        "temperature": 0,
        "text": " Thank you so much for tuning in.",
        "tokens": [
          51622,
          1044,
          291,
          370,
          709,
          337,
          15164,
          294,
          13,
          51704
        ]
      },
      {
        "avg_logprob": -0.26971944977965534,
        "compression_ratio": 1.3855421686746987,
        "end": 8635.740000000002,
        "id": 2583,
        "no_speech_prob": 0.00009027971827890724,
        "seek": 863370,
        "start": 8633.7,
        "temperature": 0,
        "text": " I am going to now stop this live stream",
        "tokens": [
          50364,
          286,
          669,
          516,
          281,
          586,
          1590,
          341,
          1621,
          4309,
          50466
        ]
      },
      {
        "avg_logprob": -0.26971944977965534,
        "compression_ratio": 1.3855421686746987,
        "end": 8640.7,
        "id": 2584,
        "no_speech_prob": 0.00009027971827890724,
        "seek": 863370,
        "start": 8635.740000000002,
        "temperature": 0,
        "text": " and go on with my life.",
        "tokens": [
          50466,
          293,
          352,
          322,
          365,
          452,
          993,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.26971944977965534,
        "compression_ratio": 1.3855421686746987,
        "end": 8643.220000000001,
        "id": 2585,
        "no_speech_prob": 0.00009027971827890724,
        "seek": 863370,
        "start": 8640.7,
        "temperature": 0,
        "text": " And I hope to hear from you, see you.",
        "tokens": [
          50714,
          400,
          286,
          1454,
          281,
          1568,
          490,
          291,
          11,
          536,
          291,
          13,
          50840
        ]
      },
      {
        "avg_logprob": -0.26971944977965534,
        "compression_ratio": 1.3855421686746987,
        "end": 8645.900000000001,
        "id": 2586,
        "no_speech_prob": 0.00009027971827890724,
        "seek": 863370,
        "start": 8643.220000000001,
        "temperature": 0,
        "text": " If you're coming to ThinkerCon, let me know.",
        "tokens": [
          50840,
          759,
          291,
          434,
          1348,
          281,
          6557,
          260,
          9838,
          11,
          718,
          385,
          458,
          13,
          50974
        ]
      },
      {
        "avg_logprob": -0.26971944977965534,
        "compression_ratio": 1.3855421686746987,
        "end": 8647.26,
        "id": 2587,
        "no_speech_prob": 0.00009027971827890724,
        "seek": 863370,
        "start": 8645.900000000001,
        "temperature": 0,
        "text": " I would love to see you there.",
        "tokens": [
          50974,
          286,
          576,
          959,
          281,
          536,
          291,
          456,
          13,
          51042
        ]
      },
      {
        "avg_logprob": -0.26971944977965534,
        "compression_ratio": 1.3855421686746987,
        "end": 8648.380000000001,
        "id": 2588,
        "no_speech_prob": 0.00009027971827890724,
        "seek": 863370,
        "start": 8647.26,
        "temperature": 0,
        "text": " I'm so excited about it.",
        "tokens": [
          51042,
          286,
          478,
          370,
          2919,
          466,
          309,
          13,
          51098
        ]
      },
      {
        "avg_logprob": -0.26971944977965534,
        "compression_ratio": 1.3855421686746987,
        "end": 8661.54,
        "id": 2589,
        "no_speech_prob": 0.00009027971827890724,
        "seek": 863370,
        "start": 8651.94,
        "temperature": 0,
        "text": " OK, and is this playing at?",
        "tokens": [
          51276,
          2264,
          11,
          293,
          307,
          341,
          2433,
          412,
          30,
          51756
        ]
      },
      {
        "avg_logprob": -0.4107985833678583,
        "compression_ratio": 1.4591836734693877,
        "end": 8664.78,
        "id": 2590,
        "no_speech_prob": 0.013636641204357147,
        "seek": 866154,
        "start": 8661.54,
        "temperature": 0,
        "text": " What's fun is to put this on double speed.",
        "tokens": [
          50364,
          708,
          311,
          1019,
          307,
          281,
          829,
          341,
          322,
          3834,
          3073,
          13,
          50526
        ]
      },
      {
        "avg_logprob": -0.4107985833678583,
        "compression_ratio": 1.4591836734693877,
        "end": 8666.580000000002,
        "id": 2591,
        "no_speech_prob": 0.013636641204357147,
        "seek": 866154,
        "start": 8664.78,
        "temperature": 0,
        "text": " Come on, we can get it in that basket.",
        "tokens": [
          50526,
          2492,
          322,
          11,
          321,
          393,
          483,
          309,
          294,
          300,
          8390,
          13,
          50616
        ]
      },
      {
        "avg_logprob": -0.4107985833678583,
        "compression_ratio": 1.4591836734693877,
        "end": 8667.380000000001,
        "id": 2592,
        "no_speech_prob": 0.013636641204357147,
        "seek": 866154,
        "start": 8666.580000000002,
        "temperature": 0,
        "text": " Hold on, I have to.",
        "tokens": [
          50616,
          6962,
          322,
          11,
          286,
          362,
          281,
          13,
          50656
        ]
      },
      {
        "avg_logprob": -0.4107985833678583,
        "compression_ratio": 1.4591836734693877,
        "end": 8672.580000000002,
        "id": 2593,
        "no_speech_prob": 0.013636641204357147,
        "seek": 866154,
        "start": 8670.78,
        "temperature": 0,
        "text": " Sorry, I just have to wait.",
        "tokens": [
          50826,
          4919,
          11,
          286,
          445,
          362,
          281,
          1699,
          13,
          50916
        ]
      },
      {
        "avg_logprob": -0.4107985833678583,
        "compression_ratio": 1.4591836734693877,
        "end": 8675.94,
        "id": 2594,
        "no_speech_prob": 0.013636641204357147,
        "seek": 866154,
        "start": 8672.580000000002,
        "temperature": 0,
        "text": " This took us so long.",
        "tokens": [
          50916,
          639,
          1890,
          505,
          370,
          938,
          13,
          51084
        ]
      },
      {
        "avg_logprob": -0.4107985833678583,
        "compression_ratio": 1.4591836734693877,
        "end": 8677.34,
        "id": 2595,
        "no_speech_prob": 0.013636641204357147,
        "seek": 866154,
        "start": 8675.94,
        "temperature": 0,
        "text": " OK, come on.",
        "tokens": [
          51084,
          2264,
          11,
          808,
          322,
          13,
          51154
        ]
      },
      {
        "avg_logprob": -0.4107985833678583,
        "compression_ratio": 1.4591836734693877,
        "end": 8678.34,
        "id": 2596,
        "no_speech_prob": 0.013636641204357147,
        "seek": 866154,
        "start": 8677.34,
        "temperature": 0,
        "text": " Oh, am I going to get?",
        "tokens": [
          51154,
          876,
          11,
          669,
          286,
          516,
          281,
          483,
          30,
          51204
        ]
      },
      {
        "avg_logprob": -0.4107985833678583,
        "compression_ratio": 1.4591836734693877,
        "end": 8684.740000000002,
        "id": 2597,
        "no_speech_prob": 0.013636641204357147,
        "seek": 866154,
        "start": 8682.34,
        "temperature": 0,
        "text": " I'm probably going to get copyright notice now",
        "tokens": [
          51404,
          286,
          478,
          1391,
          516,
          281,
          483,
          17996,
          3449,
          586,
          51524
        ]
      },
      {
        "avg_logprob": -0.4107985833678583,
        "compression_ratio": 1.4591836734693877,
        "end": 8685.380000000001,
        "id": 2598,
        "no_speech_prob": 0.013636641204357147,
        "seek": 866154,
        "start": 8684.740000000002,
        "temperature": 0,
        "text": " in this video.",
        "tokens": [
          51524,
          294,
          341,
          960,
          13,
          51556
        ]
      },
      {
        "avg_logprob": -0.4107985833678583,
        "compression_ratio": 1.4591836734693877,
        "end": 8689.300000000001,
        "id": 2599,
        "no_speech_prob": 0.013636641204357147,
        "seek": 866154,
        "start": 8685.380000000001,
        "temperature": 0,
        "text": " You probably can't really hear this.",
        "tokens": [
          51556,
          509,
          1391,
          393,
          380,
          534,
          1568,
          341,
          13,
          51752
        ]
      },
      {
        "avg_logprob": -0.39245196751185824,
        "compression_ratio": 1.675531914893617,
        "end": 8691.619999999999,
        "id": 2600,
        "no_speech_prob": 0.00348317576572299,
        "seek": 868930,
        "start": 8689.5,
        "temperature": 0,
        "text": " I'm going to turn the music off.",
        "tokens": [
          50374,
          286,
          478,
          516,
          281,
          1261,
          264,
          1318,
          766,
          13,
          50480
        ]
      },
      {
        "avg_logprob": -0.39245196751185824,
        "compression_ratio": 1.675531914893617,
        "end": 8693.099999999999,
        "id": 2601,
        "no_speech_prob": 0.00348317576572299,
        "seek": 868930,
        "start": 8691.619999999999,
        "temperature": 0,
        "text": " Oh, so close.",
        "tokens": [
          50480,
          876,
          11,
          370,
          1998,
          13,
          50554
        ]
      },
      {
        "avg_logprob": -0.39245196751185824,
        "compression_ratio": 1.675531914893617,
        "end": 8700.5,
        "id": 2602,
        "no_speech_prob": 0.00348317576572299,
        "seek": 868930,
        "start": 8697.34,
        "temperature": 0,
        "text": " Come on, come on, come on, come on, come on.",
        "tokens": [
          50766,
          2492,
          322,
          11,
          808,
          322,
          11,
          808,
          322,
          11,
          808,
          322,
          11,
          808,
          322,
          13,
          50924
        ]
      },
      {
        "avg_logprob": -0.39245196751185824,
        "compression_ratio": 1.675531914893617,
        "end": 8703.06,
        "id": 2603,
        "no_speech_prob": 0.00348317576572299,
        "seek": 868930,
        "start": 8700.5,
        "temperature": 0,
        "text": " Oh, up, up, go on.",
        "tokens": [
          50924,
          876,
          11,
          493,
          11,
          493,
          11,
          352,
          322,
          13,
          51052
        ]
      },
      {
        "avg_logprob": -0.39245196751185824,
        "compression_ratio": 1.675531914893617,
        "end": 8704.06,
        "id": 2604,
        "no_speech_prob": 0.00348317576572299,
        "seek": 868930,
        "start": 8703.06,
        "temperature": 0,
        "text": " Oh, there you go.",
        "tokens": [
          51052,
          876,
          11,
          456,
          291,
          352,
          13,
          51102
        ]
      },
      {
        "avg_logprob": -0.39245196751185824,
        "compression_ratio": 1.675531914893617,
        "end": 8706.06,
        "id": 2605,
        "no_speech_prob": 0.00348317576572299,
        "seek": 868930,
        "start": 8704.06,
        "temperature": 0,
        "text": " Oh, oh boy.",
        "tokens": [
          51102,
          876,
          11,
          1954,
          3237,
          13,
          51202
        ]
      },
      {
        "avg_logprob": -0.39245196751185824,
        "compression_ratio": 1.675531914893617,
        "end": 8706.98,
        "id": 2606,
        "no_speech_prob": 0.00348317576572299,
        "seek": 868930,
        "start": 8706.06,
        "temperature": 0,
        "text": " Oh, come on.",
        "tokens": [
          51202,
          876,
          11,
          808,
          322,
          13,
          51248
        ]
      },
      {
        "avg_logprob": -0.39245196751185824,
        "compression_ratio": 1.675531914893617,
        "end": 8708.42,
        "id": 2607,
        "no_speech_prob": 0.00348317576572299,
        "seek": 868930,
        "start": 8706.98,
        "temperature": 0,
        "text": " I'm like reliving this.",
        "tokens": [
          51248,
          286,
          478,
          411,
          1039,
          2123,
          341,
          13,
          51320
        ]
      },
      {
        "avg_logprob": -0.39245196751185824,
        "compression_ratio": 1.675531914893617,
        "end": 8711.42,
        "id": 2608,
        "no_speech_prob": 0.00348317576572299,
        "seek": 868930,
        "start": 8708.42,
        "temperature": 0,
        "text": " It's so painful.",
        "tokens": [
          51320,
          467,
          311,
          370,
          11697,
          13,
          51470
        ]
      },
      {
        "avg_logprob": -0.39245196751185824,
        "compression_ratio": 1.675531914893617,
        "end": 8712.38,
        "id": 2609,
        "no_speech_prob": 0.00348317576572299,
        "seek": 868930,
        "start": 8711.42,
        "temperature": 0,
        "text": " I really have to go.",
        "tokens": [
          51470,
          286,
          534,
          362,
          281,
          352,
          13,
          51518
        ]
      },
      {
        "avg_logprob": -0.39245196751185824,
        "compression_ratio": 1.675531914893617,
        "end": 8713.42,
        "id": 2610,
        "no_speech_prob": 0.00348317576572299,
        "seek": 868930,
        "start": 8712.38,
        "temperature": 0,
        "text": " OK, goodbye, everybody.",
        "tokens": [
          51518,
          2264,
          11,
          12084,
          11,
          2201,
          13,
          51570
        ]
      },
      {
        "avg_logprob": -0.39245196751185824,
        "compression_ratio": 1.675531914893617,
        "end": 8716.3,
        "id": 2611,
        "no_speech_prob": 0.00348317576572299,
        "seek": 868930,
        "start": 8713.42,
        "temperature": 0,
        "text": " You can go and watch this video on your own.",
        "tokens": [
          51570,
          509,
          393,
          352,
          293,
          1159,
          341,
          960,
          322,
          428,
          1065,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.39245196751185824,
        "compression_ratio": 1.675531914893617,
        "end": 8718.5,
        "id": 2612,
        "no_speech_prob": 0.00348317576572299,
        "seek": 868930,
        "start": 8716.3,
        "temperature": 0,
        "text": " I will link to it in the chat.",
        "tokens": [
          51714,
          286,
          486,
          2113,
          281,
          309,
          294,
          264,
          5081,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.26553782587466035,
        "compression_ratio": 1.5166666666666666,
        "end": 8720.38,
        "id": 2613,
        "no_speech_prob": 0.003074997803196311,
        "seek": 871850,
        "start": 8718.5,
        "temperature": 0,
        "text": " Or somebody can link to it in the chat for me.",
        "tokens": [
          50364,
          1610,
          2618,
          393,
          2113,
          281,
          309,
          294,
          264,
          5081,
          337,
          385,
          13,
          50458
        ]
      },
      {
        "avg_logprob": -0.26553782587466035,
        "compression_ratio": 1.5166666666666666,
        "end": 8722.34,
        "id": 2614,
        "no_speech_prob": 0.003074997803196311,
        "seek": 871850,
        "start": 8720.38,
        "temperature": 0,
        "text": " It is this.",
        "tokens": [
          50458,
          467,
          307,
          341,
          13,
          50556
        ]
      },
      {
        "avg_logprob": -0.26553782587466035,
        "compression_ratio": 1.5166666666666666,
        "end": 8723.82,
        "id": 2615,
        "no_speech_prob": 0.003074997803196311,
        "seek": 871850,
        "start": 8722.34,
        "temperature": 0,
        "text": " We had so much fun.",
        "tokens": [
          50556,
          492,
          632,
          370,
          709,
          1019,
          13,
          50630
        ]
      },
      {
        "avg_logprob": -0.26553782587466035,
        "compression_ratio": 1.5166666666666666,
        "end": 8726.14,
        "id": 2616,
        "no_speech_prob": 0.003074997803196311,
        "seek": 871850,
        "start": 8723.82,
        "temperature": 0,
        "text": " All right, goodbye, everybody.",
        "tokens": [
          50630,
          1057,
          558,
          11,
          12084,
          11,
          2201,
          13,
          50746
        ]
      },
      {
        "avg_logprob": -0.26553782587466035,
        "compression_ratio": 1.5166666666666666,
        "end": 8729.06,
        "id": 2617,
        "no_speech_prob": 0.003074997803196311,
        "seek": 871850,
        "start": 8726.14,
        "temperature": 0,
        "text": " I'm going to stop streaming now.",
        "tokens": [
          50746,
          286,
          478,
          516,
          281,
          1590,
          11791,
          586,
          13,
          50892
        ]
      },
      {
        "avg_logprob": -0.26553782587466035,
        "compression_ratio": 1.5166666666666666,
        "end": 8729.86,
        "id": 2618,
        "no_speech_prob": 0.003074997803196311,
        "seek": 871850,
        "start": 8729.06,
        "temperature": 0,
        "text": " See you next time.",
        "tokens": [
          50892,
          3008,
          291,
          958,
          565,
          13,
          50932
        ]
      },
      {
        "avg_logprob": -0.26553782587466035,
        "compression_ratio": 1.5166666666666666,
        "end": 8732.42,
        "id": 2619,
        "no_speech_prob": 0.003074997803196311,
        "seek": 871850,
        "start": 8729.86,
        "temperature": 0,
        "text": " Won't be for a few weeks, so stay tuned.",
        "tokens": [
          50932,
          14710,
          380,
          312,
          337,
          257,
          1326,
          3259,
          11,
          370,
          1754,
          10870,
          13,
          51060
        ]
      },
      {
        "avg_logprob": -0.26553782587466035,
        "compression_ratio": 1.5166666666666666,
        "end": 8737.34,
        "id": 2620,
        "no_speech_prob": 0.003074997803196311,
        "seek": 871850,
        "start": 8732.42,
        "temperature": 0,
        "text": " If you want to get an alert when I schedule the next live stream,",
        "tokens": [
          51060,
          759,
          291,
          528,
          281,
          483,
          364,
          9615,
          562,
          286,
          7567,
          264,
          958,
          1621,
          4309,
          11,
          51306
        ]
      },
      {
        "avg_logprob": -0.26553782587466035,
        "compression_ratio": 1.5166666666666666,
        "end": 8739.26,
        "id": 2621,
        "no_speech_prob": 0.003074997803196311,
        "seek": 871850,
        "start": 8737.34,
        "temperature": 0,
        "text": " subscribe and then click that alarm bell.",
        "tokens": [
          51306,
          3022,
          293,
          550,
          2052,
          300,
          14183,
          4549,
          13,
          51402
        ]
      },
      {
        "avg_logprob": -0.26553782587466035,
        "compression_ratio": 1.5166666666666666,
        "end": 8741.26,
        "id": 2622,
        "no_speech_prob": 0.003074997803196311,
        "seek": 871850,
        "start": 8739.26,
        "temperature": 0,
        "text": " It's the thing you're supposed to do if you want.",
        "tokens": [
          51402,
          467,
          311,
          264,
          551,
          291,
          434,
          3442,
          281,
          360,
          498,
          291,
          528,
          13,
          51502
        ]
      },
      {
        "avg_logprob": -0.26553782587466035,
        "compression_ratio": 1.5166666666666666,
        "end": 8742.82,
        "id": 2623,
        "no_speech_prob": 0.003074997803196311,
        "seek": 871850,
        "start": 8741.26,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51502,
          2264,
          13,
          51580
        ]
      }
    ],
    "transcription": " Good afternoon. It is me again here on the coding train. My name is Dan. NASA KOP in the chat asks, does it start now? In fact, it starts now. Or maybe officially it starts now. Welcome to the coding train afternoon edition. There was a full 2 and 1 1-hour morning edition of the coding train today where I completed. Completed is perhaps not the most accurate way to describe what happened. But I did attempt to continue to work on the logo coding challenge. But that's all. I'm done with that. Won't be returning to that anytime soon. Just in case you weren't here this morning, I will show you. I will pull this up very briefly. If I go to a logo, coding train slash logo, this is the GitHub repo. There are some issues here that I would love help with and thoughts on. There are a couple of design pull requests. But I merged a couple of things without checking them. So let's actually see. Coding train dot GitHub slash. This should be the demo. And it still works. So there you go. So this is what it does. It is a logo interpreter where you can type logo commands. And it will draw them for you. And apparently now, it supports some new commands that it didn't as of this morning based on a few pull requests. I don't want to rehash that too much. What I want to do, I'm going to do something. Oh, this is going to be good. I'm just going to get right into things, right into things. I am going to continue today, The Beginner's Guide to Machine Learning with ML5.js. In particular, I am going to make a new video, which will appear as number seven in this playlist. In a moment, I'm probably going to repeat myself again. And what I'm going to do is I'm going to take this previous example that I made. And I am going to save, which trains a model. I'm going to save that model and then reload it back into the sketch so that I don't have to constantly retrain every time I refresh the page, et cetera. So this has been a long overdue feature, or a widely requested feature in the ML5 library. Let's go to GitHub. Let's go to Issues. It might be closed. Let's look at, where did this get added? There we go. So this is the support. This is the pull request. So I'm going to leave this open. Yes, K. Wichman. Here we are again. I am streaming extra, a little bit extra. I've decided to come try to do two streams today, because A, I didn't get to last week because I was teaching. And then also, I will just mention again that I will be next week, next Saturday, at ThinkerCon in Hoodstool, Alabama, a place I've never been to, the home of the rocket. And if any of you are going to be there, please say hello. All right, let's just get started here. Let's just get started. So what else am I? I've got an hour or so or two, some amount of time. I'm going to start with this ML5 save load model. I am going to also look at an example with working with the Google Quick Draw data set, because that is leading up to looking at the Sketch RNN model in ML5. So many things. I've got a long ML5 list of things to cover. I want to look at some new stuff that's been added for recurrent neural networks with text, Sketch RNN, PoseNet, KNN classifier, so many things. So let us begin. Hello. I am here to make video number seven, which does not yet exist. If you have been watching this playlist, the place where I left off was training a. Hold on. I forgot to turn on this part of my brain. Hello, welcome to a new ML5 beginner's guide to machine learning video. I am about to make video number seven. Right now, that's what you're watching. Where I left off, I looked at how you could train your own image classifier with images coming in from the webcam with a technique known as transfer learning. This is the example. So this example needs to be trained, but I could do this. I could get a lot of examples of me being happy, a lot of examples of me being sad. Then I could hit the Train button, and once it finishes training, it is then going to be done. And now I, hi. This failed. I shouldn't have been so, I didn't give it enough. One more try. One more try. This time with feeling, everybody. Don't you just love watching the live streams where I just do the same thing over and over again? Hello, and welcome to another beginner's guide to machine learning with ML5.js video. This is video number seven in this playlist. At least that's where I intend it to be. And in this video, I'm going to take a step forward. I am going to do something that has been so widely requested. A new feature that was recently added to ML5 to save and reload a model. Now, what kind of model am I talking about? So the last example I left off with was this transfer learning example, where I can train my own image classifier with images coming in from the webcam. So for example, I could say, here's a lot of images of me being happy. Is this interesting yet? What's going on? Here's all the images. What are you doing? I'm sad. Then I'm going to train it. And then I'm going to come back. It's going to be done. So that works. But what happens now if I refresh the page? Need to be trained again. That model is lost. So there is a new feature in ML5, a load function and a save function. A save function and a load function. This is what I'm going to show you in this video. Let's see if we can get it to work. That's it. It's all I'm going to add. So I've got the code from the previous example here to pull it up. And what I'm going to do, let's add another button. Where are the buttons? Did I use create? Yeah, I used create button, I guess. So I'm going to go into setup. And I'm going to, I forgot if these are called yuke buttons and whistle buttons, because why not? I'm going to make a save button equals create button, save. Then I'm going to say save button dot mouse pressed. I'm going to put an anonymous function in here. And I am going to now say classifier dot save. That's it. The classifier object, if you remember, is a classification object made from a feature extractor from the MobileNet library. Rattling mic. Sorry, time out. Is the mic a problem? Is this better now? OK? Is the mic OK? I kind of want to start this video over again. I just, I'm waiting before I keep going to see that the sound is OK. Yes. 1, 2, 1, 2, my mic is clattering a lot. Is it still clattering? Maybe I better go back and redo this whole video. Nothing would make me happier. Let's actually see if this works. OK. I think it's working. I think it's working. I think it's working. I think it's working. I think it's working. While I'm here, I'm going to redo it. Classifier dot save. Oh, I forgot. Great. So this, I'm going to have this happen, because I have to upgrade my version of ml5. Yep. Great. OK. So that worked. OK. How do I tell it not to show the warnings? Show. Where's the preference for showing warnings? Oh, I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. Show warnings. Because I kind of would prefer not to see them, frankly. High network, evaluation, preserve log, show warnings. Somebody will show me. If anyone in the Slack channel could tell me how the mic is going, I would really appreciate that. Show warnings. Chrome. Hide warnings in the console window. Is there. Top filter, errors, level, warning. OK. So it must be. Oh, I just don't see it here. Because. There we go. So let's. Ah. There we go. There it is. Got that. OK. The mic quality is perfect now. OK. Apologies to everyone, but just because there were some mic issues, I'm going to start over. And. So I'm actually going to do this. And go back to here. Take this out. Take this out. And refresh. OK. All right, here we go, everybody. So I realize that some of you watching might not have actually gone through this video tutorial. The idea of ML5 might be totally new to you. Just very briefly. ML5 is a beginner-friendly JavaScript library for machine learning. It's built on top of TensorFlow.js, which is an open-source machine learning library made by Google. TensorFlow.js is a JavaScript port of TensorFlow, which is C++ and Python, and that's about as far as I'm willing to go with that right now. And this series explains how image classification works with a pre-trained model, and then how you can train your own model on top of that. So that's where I left off, but you could never save it. So now, here we are. Hello, and welcome to another beginner's guide to machine learning with ML5.js video. Now, in this video, something very exciting is going to happen. If you happened to watch all the previous videos a while ago and you discovered this one new, a new feature has been added to ML5, the save-load feature extractor with ML5 specs. So you can find the pull request here if you want to see more about how that was implemented. But the point of that is the following. Where I left off was this example. This is an example that loads a pre-trained image classifier called MobileNet, something that was trained by somebody else, explained in my previous videos, and allows the user, allows the coder, to use a process known as transfer learning to extract the features from the, that the model detects in an image and reassign them to new labels. So, for example, I can make a very happy face and click on happy a bunch of times and wonder why my Mac is showing that weird window. And then I could have said a bunch of times and then click train, and now we have to wait for a minute. We always blow the train whistle for train. And now the training is complete. And I go, hi. Let me go back and do this again. It's really bothering me that this clicking on this is like, was pulling that thing up. It's because I'm selecting the text. All right. I'm going to get this. And I'm kind of standing in front of it too. So, with this example, I can make a happy face and click happy. This is me giving it a bunch of examples of me being happy. And then, sad. Now I can press the train button. It is training. And now that it has finished training, it will recognize, it will determine if the webcam is showing an image that looks more like happy or sad. Happy. Good. Happy. Good. Happy. Okay. So, that's what the example did before. If you're still watching, what the problem with this example is, if I hit refresh, it's gone. It needs to be trained again. So, what I want to show in this video, and boy, it's taking me a long time to get to it, is how to save. And really, there's just two functions we're going to add here. Save function and a load function. So, I'm going to take the load from before, and I'm going to go into setup, and this is where I made the buttons for sad and happy and train. I gave them weird variable names, which don't have any meaning anymore, but I'm going to make a new button called save button equals create button. Save. I guess I should make this a global variable just to be consistent. That might be unnecessary. And then, I'm going to add a function to handle the event when the save button is pressed. So, what do I need to do when the save button is pressed? Guess what? This is super simple. All I need to do is say classifier.save. I'm just saying classifier.save. Now, what's going to happen there? Let's wait and see. So, I'm going to go here. I'm going to, oh, look, the save button is there, and I'm going to be happy, I'm going to be sad, I'm going to train, and I have to wait for it to finish training. Once it's done, I'm going to hit save, and guess what? I got an error. Save is not a function. I left this error happen on purpose. This is a new feature of the ML5 library, and if I go and look into my HTML, I can see I'm using the ML5 library 0.1.1. Maybe you're watching this. Maybe it's like right now it's like 9.4.3, and you're in this future world of ML5, but the current version is 0.1.3. So, if I add that, I'm going to hit refresh. Now, I'm going to really try to train a good model here. So, let's train. Oh, I don't have the ukulele. I do have the train whistle. So, I'll just do happy and sad. I'm happy with the train whistle, and I'm very sad with no train whistle. I don't have a train whistle. I'm so sad. No train whistle. Now, I'm going to train. So, I gave it a whole bunch of examples, and something weird is going on here. Okay, let's see if this works. I'm happy with the train whistle. I'm sad. No train whistle. I'm happy with the train whistle. I'm sad. No train whistle, and I want to keep this model. So, I'm now going to click save, and look at this. Look what has downloaded to the download directory. I'm going to go show in finder and see. Look at this. Two files. Today is 2.17 p.m. Model.json, model.weights.bin. Okay, so let's take a moment to explain. Oops. Let's see. Why is the whiteboard not working? Loose cable. Maybe. Check, check, no, check. Oh, there we go. Okay. Let's take a moment to talk about what's in these files. So, why is there a file called model.json, and a file called, I already forgot, model.weights.bin? Model.weights.bin. Okay, so, we haven't really, as part of this video series at least, talked about the details of what a neural network is. But, this particular machine learning model is a neural network. And, a neural network has some kind of architecture to it. It has a whole bunch of inputs, and it has a bunch of outputs. And, in this case, it actually just has two outputs. A happy, or a sad. And, the actual thing the neural network is producing is a probability of one or the other. Now, in between, oh, and the inputs, sorry, the inputs is an image. So, maybe every single pixel of the image is wired to one of these inputs. Then, there are these layers. The data is going to be processed forward. Math and various things are going to happen to the data as it goes forward. And, it needs to have some amount of hidden layers, and other types of nodes, and everything is connected. And, this is stuff that I have described in other videos. And, I'll also refer you to the 3Blue1Brown, What is a Neural Network video, which is terrific to see more. But, the reason why I'm mentioning this is, this model.json is a file that describes the architecture. Maybe it's architecture of the model. And, this model.weights.bin is a file that describes all the weights. So, what I mean by architecture is, how many inputs, how many outputs, how many hidden layers, and all sorts of configuration details about the architecture of this neural network that I've drawn here in a pretty crude way. The thing that I'm kind of not mentioning, because I don't want to be here for the next 17 hours, going to every sound, every different road of detail here, is that the data as it's passing through the neural network, all of these different nodes between the inputs, and the outputs, and the hidden layers, all of these nodes are connected. And, each one of those connections has a weight. You can think of the neural network as a thing that has just lots and lots of dials in it. And, it's trying to learn what the right setting for all the dials is to produce the appropriate happy or sad result based on the input image. So, all of the numbers that store the values of all of these weights are all in this file. So, this is actually a file that we could very easily go and look inside. It's JavaScript object notation. It's a JSON file. We will look at that. But, the weights is really the big thing. It's where there's a ton of stuff. There's tons of these connections. It's many, many numbers. So, it's typically stored in binary format, raw digital data, so that to sort of have it be the smallest file size. So, these are the two files that we need. Let's go take a look at those. So, the next step for us is to take these two files. I'm going to copy them. And, actually, I think I could probably just drag them into Visual Studio Code, because I want them to be part of this example. Right. So, we can see that they're here now. Now that I have model.json and model.weights.bin as part of my project, if I were using the p5 web editor, I'd need to upload these files. I'm not sure if that's actually possible. I'll have to look into that. And then, if we look at model.json, for example, you can see, and I'm going to hit save, we can see this is the model topology. It's a sequential model. And, these are the inputs. The inputs are 7x7x256. And, somewhere, ah, yes, ml5 specs. These are the labels, happy and sad. There's all sorts of other stuff. There's some dense layers, and there's where it gets the weights. And, it's using TensorFlow layers and TensorFlow.js. So, all this information is in here. The bin file is not something we can really look at, because it's in binary format. But, we can know that all of the numbers, those weights, are there. So, now, guess what? We're going to go back to our code, and I'm going to look at the steps here in setup again. So, in setup, the first thing that I do is I create a feature extractor with MobileNet. When that model is ready, hold on, I'm thinking for a second. Oh, yeah. Just time out for a second. I just want to look. Unfortunately, the documentation isn't up on the website for this. So, I just want to check something to make sure I'm doing it correctly. I'm going to look at it over here real briefly. I'm just looking in the existing examples. There actually is an existing example for this. I don't know why I'm not pulling it up here. I probably should. I think it's here, yeah. I just need to understand the order of this. Classifier, oh, yeah, okay. That's interesting. I guess that works. The order of all this stuff is weird, and I feel like this is a thing we have to work on with the library. Alright. I'm going to not worry about this too much. Once the model is ready, then I can go ahead. Where's that? This is the function for when the model is ready. I can now go and say classifier.load, and guess what I want to tell it to load? Model.json, and I'm going to say custom model ready. Custom model ready. Custom. Custom model is ready. First, MobileNet has to be loaded. Once that's done, then the custom model can be loaded. Now, look at this. Classifier.load, model.json. Remember, there are two files, model.weights.bin and model.json. ml5 is set up to work that if you just tell it where the json file is, model.json, it'll look for the corresponding model.weights.bin file in the same directory. There are ways that you can customize what those file names are and have them in different paths, but this is the simplest way of doing it. Let's see if this works now. Model is ready. Got an error. What is this error? That was sad. Maybe it has zero. Let's look at 5 megabytes. That makes sense. That's right. There's definitely weights there. Oh, it didn't find it. Oh, weird. Oh! I know what the problem is. Ugh, I don't like this. I think it's going to work now. Yeah. It did load. The issue is the following. This is actually kind of like a bug because it's not looking in the local directory unless you specifically do the./. I think it would be simpler to let the user just do this. That is a bug to file. Let me do that real quick. I won't worry about that right now. What is this? Feature extractor model loading relative path. Is this? Look at this. The following works. Making a live example live on YouTube right now. The following works. We're just referencing the file name and expecting it to be the local path. Doesn't work because it looks for model.weights.bin somewhere else. We can get it to work. Let's get this error. Let's go back to GitHub here. Oh, weird. It actually did look in the right place. Huh. That's weird. But this is a thing. I'm so confused. Oh! It would have worked. This is interesting. It would have worked. I'm not being careful enough. If I were running the server from here, it works. It works because it's a subfolder. But I feel like it should figure out that it's in a subfolder. Right? Okay. I've got to change my error message here. If the sketch is not at the root path, I can load the model via a relative path as follows. However, if I look for model.json with a relative path like the following, it then looks in the root directory for model.weights.bin. This is minor for my example, but noting as it's an error people will encounter. Is it trivial to support looking always in... So I think this is... If the sketch is not at the root path, I can load the model via the current directory. At the current path directory as follows. If I ask for model.json as follow, this way, it then looks in the root directory for model.weights.bin. Let me submit this. Yeah. Let me submit this. I think this makes sense now. Apologies if this issue is weird because I'm doing this in a live stream. Okay. I'm actually... We're going to fake this here. No one will notice. Okay. We're going to fake this. So, Mathieu, I'm not going to show that error, actually, because that error is irrelevant to what I'm doing here. So let's see if I can get it to work just like this. Okay. Because I think that will get fixed later. I hope. Okay. Okay. Let's go back. That's no good. So how do I... Hold on. All right. Let's try now loading that model. I'm going to hit refresh. Model's ready. Video's ready. Custom model is ready. So it's been loaded. But I'm not... I'm not seeing the labels. So even though that model was loaded, I now have to figure out... I now have to tell the code no longer really needs to be trained in this case. I might want to retrain and do fancy. I'm going to take out the training button. And then somewhere there's like an event where it finished training where I said classifier, classifier got results. And so that's what I want to do now when the custom model is ready. So the events are as follows. Let's bring this down here. First, load the MobileNet model. When the MobileNet model is ready, then load the custom model. When the custom model's ready, start classifying the image. All right. So here we go. Let's... Ah, yay! What did I have with this hand? I can't even remember. No, it was this hand. All right. So this is working. Those buttons are now no longer relevant. So I could actually take all the buttons out. And this is now... Again, whether you want to have one sketch where you train and save and load or two different ones. But I'll just show you right now. The idea here is I did my training. I'm done. And now I have something that automatically loads the model. Yay! All right. So I hope this was helpful. You can now see that process, right? What is the process? Train the model. Call the save function to download model.json and model.weights.bin. Then take those files into your sketch. Use the load function to load them both. And then start classifying. All right. So give this a try. See what you can do now that you can spend a lot of time training your model because you can save it and see what you make with it. All right. Thanks for watching. And I will see you in another ML... There will be more ML5 videos. I don't even know what's next. But if there's a video that's next, you can watch it. Goodbye. All right. Hopefully that can be made into something understandable. I wonder what would happen if... I'm just curious. What would happen if I retrained it? Yeah. I guess it retrains. Yeah. But then if I refresh, it's loading that previous model. Okay. Any questions about this? Will JS always load the setup function? Automatic asks Tobias. So this is a feature of the p5 library. So I'm using the p5 library. And the p5 library always calls the setup function first. That's the way it's configured. But this is not something that will just happen in any JavaScript environment. It's here... It's specifically part of the... Part of the p5 library. Okay. Copper asks, so save, not save, all the model like in Keras? I'm not sure I completely understand that question. But let me try to rephrase it. I think what Copper is asking is, is this like saving a model in Keras? And the answer is yes. There's a lot of nuance to this. Because number one, it's saving the model in a particular format that is compatible with TensorFlow.js. So this model that we saved won't necessarily work with a Python Keras example without being sort of converted to what it needs there. And there's also this sort of strange feature of it, which is that it's already like... We're just saving the sort of part that's on top of the MobileNet model. So I haven't like resaved the entire MobileNet model. I'm just saving the transfer learning piece of it that is plugged into the MobileNet model. Because it's still always loading the MobileNet model. And yes, KWikOne says, as far as I know, you can even import a Keras model into tf.js. So yes, if you want to import a Keras model into tf.js, you just need to look for the tf.js converter. This is a script that will take any TensorFlow or Keras saved model and convert it into TensorFlow.js. This is from the TensorFlow project itself. Does that mean it will work automatically with ml5? In theory, yes, but ml5 is kind of a subset of TensorFlow.js with a bunch of things wrapped to be a little simpler to work with. I kind of want to do that video again. Because I feel like I don't know if I hit all the right notes. I'm going to do it again. And then Mathieu can pull. Because I feel like this is a really sort of important one. And then I will do the quick draw stuff. ASDFGHJKL space ASDFGHJKL asks. Why do you choose p5.js over other JavaScript libraries? I love p5.js. I mean, it's a great question. And I don't think there, I certainly am not here to say please, I think you, the viewer of this channel, should use p5.js. The reason why I use it is because it's a project that's connected to a project. It is a project. It's part of a project called the Processing Foundation, an entity that I've worked on for many years that I have a lot of personal investment in. And the goals of that project in terms of being beginner friendly, being inclusive, are values and principles that are close to my heart. And that work well with the kind of stuff that I want to do in this channel. Is it perfect? No. Are there other things that you might want to use instead? Definitely. But it's a good foundation library for me to build a lot of stuff with. All right. I know I've been torturing you all, but I'm going to do this again. Just to give Matthew more material to work with. Now that I have a sense of what the issues are. I'm going to go back to what it was originally. And I'm going to redo a couple things to make it less awkward. I am going to... Let's just see here. Okay. Let's see here. Okay. So... I'm going to move some things around, I think, to make things less awkward. Is that legible, this font size? Is this legible? It's smaller than I usually have it. But... This might be helpful to have a little bit more room to look at the code. Yeah, let me rename the uke and whistle button. Thank you. Let me rename those. Thank you. That is... I don't know why I'm... A happy button. Sad button. A train button. Okay. So that's good. Any other suggestions? It's fine. All right. Let me try it with the code a little bit smaller. Okay. Here we go, everybody. All right. Let's do this ridiculous thing again. I mean, Mathieu, whenever you watch this, you can take stuff from the first try and mix it if you want. But it's my hope that this will just be a cleaner version of that video. And apologies to all of you watching live when I make the same jokes again. Not that I made any jokes, not that any of them were funny. But if I did, I'll probably make them again. More awkwardly. Can you continue working on the local project, asks David. I don't think so. Okay. Hello and welcome to another ML5 beginner's guide to machine learning with ML5JS video. All right. So this one's a good one, I hope. I'm about to make video number seven in this playlist. And this, the element in the, oh, I forgot something. I forgot that I have all of this stuff here already. And I don't want it to be. Delete, delete. I'm so in love with you. Delete, delete. Oh, with my eyes so blue. Delete, delete. Delete, delete. Delete. Yeah. It's getting hot in here. All right. Here we go. Hello and welcome to another beginner's guide to machine learning with ML5JS video. Now, in this video, I am going to unlock something for you. It's already unlocked for you, but I'm going to show it to you. That is incredibly powerful for what you can do now with ML5 that you couldn't do before. But many of you asked about in the comments. And what is that? It is the save load feature extractor. This is a new feature that was added to ML5 just five days ago. You need to make sure that you are using ML5 0.1.3 or whatever number in the future past that. But certainly this is the version of the library that I'm using in this video. Now, what does it do? So, the last example, if you've been watching this video series in order, was this example. What this example does is it loads a pre-trained image classification model called MobileNet. And MobileNet is trained on a thousand different kinds of things and recognizes puppies and dogs and birds and different kinds of objects. Transfer learning is the process by which we take that pre-trained MobileNet model and basically disconnect it from all those labels and reconnect it to our own labels. For example, I'm going to make up a label called happy and a label called sad. I can certainly have more than just two. And I'm going to show it things like the train whistle is me being happy. I'm going to show it that train whistle a bunch of times. Say happy, happy, happy, happy, happy. Now, no train whistle is very sad. I'm sad. No train whistle is sad. Oh, I'm spending way too much time on this because I haven't implemented the thing that I want to implement. Now, I'm going to say train and it's going to train. And then once it's done, ah! Happy. Sad. Happy. Train whistle. Sad. Okay, so it works. It is now learning to classify images in real time according to those two categories. But I'm a big spaz and I'm going to just be over here doing refresh. And I have now lost that forever. I no longer have that model. It's gone. The new feature is ability to save that custom trained model and then reload it. So if you're using this for like an installation and you're going to like take down the computer and set it up every day, you can save that model. You can imagine. There's lots of possibilities here. So there's only two things that I really need to add to the code. There's a save function and a load function. There's a bunch of pieces there, but that's what I'm going to do right now. So I'm going to go here into the code and I'm going to just add another button. Like I have a happy button, a sad button, and a train button. Choo choo. I'm going to add a sad button. No, no, not sad. A save button. I'm going to call it save. And save button when the mouse is pressed. I'm just going to say classifier.save. That's it. All I have to do is say classifier.save. Let's see what happens. So I'm not going to train it very. Actually, no, I am going to train. I'm going to let's do a really good solid training this time. Because this is the one we're going to save. Once it works. All right. So let's do the same thing. Happy, happy, happy, happy. Train whistle is a happy thing. A happy, happy, happy thing. Just me is very sad. There's no train whistle. I'm so sad. I'm very sad. I'm very sad. And now I'm going to train this. Weird how the loss is zero. I'm just going to not worry about that too much. I'm going to hit save. And now you can see that down here, by the way, that I did this a couple times practicing. Now what it did is it downloaded, come on, to my download directory two files, model.json and model.weights.bin. So those files will end up wherever the default downloads directory of your browser is. And the next step is just to load those files in. But before we load them, let's talk about what's in those files. So there's two files. Model.json and model.weights.bin. OK, so what is a neural network? What is a machine learning model? What is the thing that we're saving? Well, in this case, it's actually saving the configuration of a neural network. Now, if you want to know what a neural network is, I have some videos about that. But I would refer you to the three blue, one brown video, what is a neural network. I will link to that in this video's description. That will give you a much bigger deep dive into those details. But if you look at that video, what you'll see is there's basically a big diagram. And the diagram has a bunch of inputs. It has some outputs. By the way, in this case, we could actually say the outputs are just two, a happy and a sad. And what the neural network, what the machine learning model outputs is a probability, maybe like 80% of it being happy, of that image being happy, and 20% that image is sad. So the whole point of this is to feed in an image. It's the image and maybe all the pixels of the image that are actually these inputs. It goes through this magic neural network thing, which isn't really magic. It's a thing that you can learn about. And then out the other end comes a guess as to whether it's happy or sad. Now, what is all this stuff in the middle? The stuff in the middle is typically referred to, and there are many different styles and flavors and kinds of neural network. But in the sort of zoomed out view, in general terms, is what's known as a hidden layer or hidden layers. So every input is connected to the output, but not directly. There are some amount of nodes, maybe two hidden layers, each with four nodes. And every input is connected to every node, and then every node is connected to every node, and then every node is connected to every output, and so on and so forth. So I could be here all day trying to do this diagram and draw every connection between everything. I'm not going to do that. But all of the information about here is what is saved in these two files. Model.json is a file that just explains all of these pieces, the layers, the outputs, the inputs, all of that stuff. That is what is in model.json. And in a moment, I'll just open up that file and look at it. Model.weights is an interesting thing. So the magic of a neural network, what makes a neural network work, is a number that's associated with every single one of these connections known as a weight. You can think of it as a whole bunch of dials. So I'm tuning the dials. I'm trying to get the dials in the right position really makes good guesses about happy versus sad. That's the training process. Once that training process is done, I want to save where all those dials are. All of those numbers are in this file. This is a binary format file because there's a lot of numbers, millions upon millions of connections potentially between a lot of pixels and a lot of labels and a lot of hidden layers. So this, you'll notice, the file that we saved is five megabytes because it's tons and tons of numbers. So it ends up, but this is just a very small file with a little bit of text information about how this is configured. I spent a lot of time on that. Hopefully, that's some helpful background to you. Let's go back and actually look at those files. So now, I've got those files. What I'm going to do is I'm just going to drag them into Visual Studio Code, which is what I'm using to code this right now. But you could be using any environment. Oops, they didn't make it into the right place. Let me try that again. I'll clean this up later, but I want them in this directory. Great. So you can see that they're there, model.json, model.weights.bin. If I click on this, you can see you could start to see all the stuff in it. There's information about the input shape, and is it a sequential model, and what kind of algorithm are you using, and oh, is it dense, and it uses something called softmat, all this stuff. So this is way beyond the scope of what I'm doing in these videos. But if you're interested in more about these details, you could look at some of my videos that use TensorFlow.js natively to understand more pieces here. But you can see here, this is where it's looking for the weights file, et cetera, et cetera. And this is really important. This is something. This is really just what TensorFlow.js would do natively, but ML5 is helping with a little bit on top of it by adding these happy and sad labels. OK. So now, all we have to do is load the model now. OK, so we're going to go. We saved that model. And so the steps are, the first thing we have to do is load the MobileNet model. So we're not actually saving that original pre-trained image classifier. We're just saving the bits and pieces that are hooked into it. So we can't hook into it until MobileNet is ready. So once we've hooked into it, once MobileNet is ready, we can then say classifier.load model.json. Now, there are two files, model.json and model.weights.bin. But ML5 has set up that if you just give it one file, it'll look automatically for the other file in the same place. There are ways of customizing the file names and their paths and all that. That you can look into in the documentation. But the easiest thing for just to do this. And then I'm going to say custom model ready. So I'm going to write another event function. Custom model ready. And there, I'm going to say custom model is ready. So it's a two-step process. We have to load MobileNet. MobileNet is ready. Then load model.json with the weights. Custom model is ready. Let's just run this. Zoom back out. And there we go. Everything's loaded, but I don't see any results. I don't see any results. Why? Well, this sketch was written originally with code to train. So I'm supposed to press the buttons and hit train. But now I don't need to train because I loaded the model. So this is where I kind of like, I don't know what you should do next. Maybe you want to keep two separate web pages, two separate sketches, one for training and one for loading. Maybe you do it all in one. You'll actually see if you go to the ml5 examples, there's one that has a button that you can drag and drop. You can actually select files and load them and save them all in the same sketch. But what I want to do now is basically a workflow for, I'm done with the training, so I'm not going to ever train again. So I can actually remove all of these buttons. They're no longer relevant to me. The text that should show up at the beginning is just loading model. And then when the model is ready, I would say label equals model ready. So let's run this now. So loading model, loading model, model ready. And now once the model is ready, all you need to do is start classifying. And before, I didn't classify until the training was finished. The training is now irrelevant. I could actually completely comment this out as well. Basically, I want to start training when the model is ready. Not training, sorry. I want to start guessing when the model is ready by saying classifier to classify. Got results. And now, here we go. Loading the model. Model is ready. Happy, sad, happy, sad. And I can refresh the page again. And happy, sad, happy, sad. All right, so it works. We're done. Yay. OK, so this is a thing you can do now. You can train your own transfer learning model. You can do this with the regression example too, if you watched that video. You can save it. So I don't know. Share. You can share models. Let's all share models with each other. Share your model with me. Let's see what happens. All right, I'm curious to see what kind of creative stuff you come up with. The interaction that I've done here is super awkward. I'm going to press the button all the time. And you don't actually have to train with just video. You could load a bunch of images. So there's so many possibilities here. And I look forward to seeing what you make. And stay tuned for more ml5 videos. More stuff is coming. I don't know yet what, but more stuff is coming. Goodbye. Ah, OK. All right, everyone. I'm glad that I did that a second time. This computer went to sleep for no reason. And there's very little going on in this computer. Oh, OK. So maybe that's fine. Somebody wrote a comment on my issue. All right, so I'm done there. OK, that's going to be a good one to release. Now we are going to move on to something totally different. What time is it? 3 o'clock. It's getting warm in here. Actually, so now I need to release this example. So I'm going to delete the model and the weights. I'm going to delete the model and the weights. I'm going to leave this. I think what I'm going to do is leave this example with this stuff here. And then this is tricky. Comment out loading this. Comment this out. So this example is now left in the training state. But it has the loading code in it, but commented out. And so now let me just put this online. Code from save load live stream. Save load ml5. So this is now. It should be in the website. I'm going to create a pull request here. This is the code from 11.9 live stream. I'm not sure if I should make this two examples or just one. For now, the loading code is commented out. So I'm going to create this pull request. And it should be just these files. Yep. OK, good. Great. So that code will be on the Coding Train website. Just for people who are looking, there is also this example. I had it open. So this is the same exact example. I'll note, though, that this example uses a button that you can select and then select files and load them. So there's a lot of other ways of approaching this. So here's yet another example with more features that you can look at. OK. All right. So now what do I want to do? All right. I am going to go to the desktop. Desktop. And I just want to get a. I just want to have a p5 sketch in that directory that I can start using. And so let's get rid of everything here. And here. And index. Quick draw. OK. OK. Now, what did I minimize that? So I need the browser. And. Oh. And quick draw data. And there we go. OK. And then this is part of build your own API with node. Where is that? OK. OK. Yeah, that looks like there's a discussion in the chat about why I'm using a separate terminal instead of the built-in terminal in VS Code, and why not just use the VS Code live server. Those are all very good questions. Sometimes I don't like to feel like I'm just only using one thing. And then what if that one thing goes away? So I don't know. Why does this camera keep going out? Is there a loose cable or something? There we go. All right. OK. OK. OK. OK. OK, everybody. Everybody settle down. We're going to do something really fun. Oh, this is empty. This is the last thing I'm going to do before the weekend. There will not be any live streams next week, unless somehow I figure out some magic way to live stream from ThinkerCon. But we'll see if that's possible or not. And. All right. Now I think I am ready. I think I am ready of all the pieces that I want. This is actually, I'm going to make this a coding challenge. Maybe the Sketch RNN stuff will be tutorial-ish with ml5, but OK. Well, I don't know what to do. I'm going to make this a coding challenge. People watch the coding challenges more than if they're in the tutorial videos. OK. I'm just trying to do my stretching, because my back issues. OK. Woof, woof. You know? Hold on. Matthew. I'll make a thumb. I better make a good thumbnail for this. Remind me to make some thumbnails. I mean, just like pose with the results. OK. Woof, woof. OK. Hello, and welcome to a coding challenge. Actually, you know what? No, no, no, no, no. No, no, no, no, no. This is what it's going to be. OK. I'm going to start with this behind me. OK. Can I do a grand entrance? Hello. Hello, and welcome to a coding challenge, quick draw edition. Now, I have been talking about doing this for a very long time, and I'm excited to finally try this on my channel. One of my favorite data sets that is out there in the world is the quick draw data set. Now, here's the reason. One of the reasons why I'm interested in this is not just this data set of 50 million drawings, which is interesting and fun to play with on its own, but there is something called Sketch RNN, which was developed by a set of researchers at Google, Google Brain. And you can see some of them here, who wrote this paper, and explained how Sketch RNN is a neural network, a recurrent neural network, that learned about how to draw various things from the quick draw data set, and then can try and imagine and create new drawings based on how it learned, and can even interact and draw with you. So many possibilities. So this is where I'm going with this. I am going to make it. Sketch RNN has recently been added to the ML5 library. And I'm going to show you an example. And I'm going to build that with Sketch RNN ML5. But I feel like before we start making the artificially intelligent system that generates the drawings, let's look at the actual data itself that it was trained on. So first, where did that data come from? And apologies if I get anything wrong. Please let me know in the comments. Because this is not my project. I am just inspired and enthused by it. So the quick draw project is a project, an AI experiment, made by friends from Google. And it is a game that you could play, where you say, draw a pencil in under 20 seconds. OK, here we go. Ooh, doo, doo, doo. I see marker, or lipstick, or crayon. No. No, that's not really like a pencil. Is it if I put an eraser here? I see rocket. No, rocket. I'm the worst. I'm not sure what that is. Yeah, I don't know what that is either. Time is running out. Sorry, I couldn't guess it. All right, let's try basketball. I see nose, or moon, or blueberry, or baseball, or bracelet. Oh, I know. It's basketball. All right, I win. OK, so you get the idea. I could be stuck here for quite a while. Now, when you are playing this game, your doodles are being collected. And over 15 millions of players have contributed millions of drawings playing Quick Draw. Oh, and I've used this before. I made a example with a neural network that tried to recognize your drawing. This has been done on my channel before. But what I haven't actually looked at, what I looked at before was I looked at all the drawings as pixels. What's actually what's interesting about the data is that the data, which you can find here, information about it on GitHub, is not pixels. It's actually the pixel paths of the people making the drawings with timing information. So you could load that data and replay any drawing back. And each drawing has the word that was associated with it, the country where the person is from who drew it, at least the IP address presumably, and then whether it was recognized, and then the actual drawing itself. So what I want to do, and you can see here that the format of the data is a whole lot of xy positions. xy, xy, xy with timing. What time was I at the first point, the second point, the third point? Then I might have lifted up my pen, moved, and started doing another one. So it's a bunch of strokes. So this is a little tricky because I can't use the word stroke as a variable name in p5 because stroke is a function that actually sets the pen color. But the idea is that if I do this, it's sampling a bunch of my points as I drew along that path. Each one of these is an xy point associated with a given time. And then there is an array with all of the x's, all of the corresponding y's, and the corresponding times. Now, what I'm actually going to use in this video is if there are a bunch of different versions of the data, I'm going to use a simplified version of it because these are huge data files. But I encourage you as an exercise to try to do what I'm going to do but with the non-simplified version, maybe with the timing aspect of it. But the simplified drawing files are the same exact thing, the same exact thing, but no timing information. And also, they have been sub-sampled, meaning in theory, as the person is drawing, as the user is drawing, a lot of points are being captured. But maybe you don't need that level of detail. And that's often referred to as pixel factor or scale factor, I believe, or epsilon value, I guess. So you could say simplify all strokes using the Rammer Douglas Puker algorithm. I don't know if I pronounced that correctly. With an epsilon value of 2. So these are available as something called NDJSON. Now, if you've watched my videos before, you're probably familiar with JSON, JavaScript Object Notation. That is a format where you can store data. That's in JavaScript Object Notation. I have some videos about what is JSON. NDJSON is a funny thing. Ha ha, it's hilarious. It's like the funniest version of JSON. And it actually is a set of multiple JSON elements, each on a different line in a file. So it makes sense to do that. Each drawing is its own JSON object on a different line in the file. So let's go grab one of these files. So getting the data, we can actually go to the public data sets. Oops, no, I'm sorry. I just want to go to the list of the files in the Cloud Console, which is right here. I'm going to say I agree. And I don't want any email updates, but I accept. OK. Accept. So I'm going to go to full. And oops. I realize you can't see anything here, so let's try to make this a bigger. Let me dismiss this right now. And come on. I guess I'll make this smaller. I'll just zoom in. So these are the different formats. They're actually all the data in just binary. There's this NumPy bitmap, which is useful for other kinds of machine learning, different things you might want to try, the raw data. But let's look at the simplified data. And let's pick, oh, I don't know. Which model should I pick? There's so many. Banana, bandage, baseball, basketball, bat, beach, bear, beard. I guess I should do beard. Right? That's kind of lame, though. Birthday cake. Is there like a unicorn? Maybe there's a unicorn. No, was there a rainbow? Yes, there's a rainbow. All right, so we'll use the rainbow. So I am going to download this file. So here's the thing. This is a very large file. I had a reason why I was doing this challenge also. This is a 43 megabyte file. Now, I could just use some code in my client-side JavaScript to load that file and put it on the web. And at some point, I might show you some techniques for doing that. Stay tuned in the future. But I think this is a good case where my video series, the module for my programming from A to Z class, or the program with text class, building an API with Node and Express, this is a case where I've got this. What if I want to have every drawing? There's just millions of them. I don't want to load hundreds of megabytes and gigabytes of files in my client-side JavaScript. I could write a little Node program whose sole purpose is to hold on to all that data. And my client-side JavaScript could just request it. So this could be because what I want to do is create an API out in the world for people to get drawing information. But this isn't data that I own in a way that I would necessarily do that. We'd have to look at the licensing to see if that's even something reasonable to do. Where is that eraser? But what I can do is on my computer here, the idea here is, oh, I'm going to make a server. And the server is going to hold all of the drawings. And then my p5 sketch can just say, hey, can make a request, like a get request. Please, could I have a rainbow? And then the server is going to send back just a single drawing. It's not going to send back hundreds of megabytes of data. It's storing all that data, but it's going to send back just one piece. The interesting thing is this server can easily just also run on the laptop. So and I could connect to it. So there's a variety of ways you could deploy this and use this. But I'm going to do it all from this laptop. So to run a server with Node and Express, you can go back and watch some of these videos where I step through this in more detail. I'm just going to start it in the directory in my console. And I'm going to say npm init. And I'm going to call this a coding train quick draw example. And it's version 0.0.1. It is an example that I am making on the coding train. And whatever, I'm going to skip through a lot of this stuff. Yes. So now if I go to my code, you can actually see I have this package.json file. The package.json file has all that information that I just entered. This is the configuration file for my project. Node is the central manager of this project now. So I need a couple Node packages to be able to make this work. I need to use Express. Express is what I'm going to use to handle that get request, this HTTP get request. So I'm going to say npm install express. And then I also need something to load that nd.json file. So nd.json node. I've actually used this before. But let's look. So this is a Node package for loading an nd.json file. So I'm going to say npm install nd.json. Great. There we go. And now I meant to show you what is that nd.json. Oh, I got to grab that file now. I'm just going to rename this to rainbow.nd.json. I'm going to drag it here into my project. So now this is a huge file. And so you can see that Visual Studio Code is freaking out. It's like, I don't want to deal with this file because it's too big. But you can see that what this is is every single drawing on one line. So it's like this is my database, essentially, a database of rainbow drawings. I have a database of rainbow drawings. What could be better? OK, so what was I doing? Back to the code in the server. Oh, I don't have a server yet. I'm going to add one. I'm going to call it server.js. I could call it app.js or index.js. And here I'm going to go back to this. And basically, I just want to do exactly this. So the first thing I want to use this, I need the file system module. So I'm going to say const fs equals require file system. File system is a module that comes with Node. I don't have to install it. But I also want the nd.json module, which doesn't come with Node, but I added it. And here we go. And we can see, by the way, that when I installed those, they are now dependencies in the package.json file. And now, doo-doo-doo-doo-doo. Ah, there we go. So what is this doing? This is streaming it. So this is really useful. It's a huge file, rainbow.ndjson. I certainly could load it, just loading the file into a big string, chopping it up, and parsing it. But when you have a big file, like an nd.json file, you want to read it as a stream, essentially one line at a time, because it could be like a gigabyte file. In this case, I'm just going to say, I'm going to make an empty array. And every single object, I'm just going to push into that array. But let's console.log them, just to see that this is working. So this is the stream. As it reads line by line by line, the nd.json file, it's going to console.log that object. OK, so let's go here. And I'm going to say, node server.js. And there you go. You can see, this is it. Every single drawing, it's going to take quite a while, because there's thousands and thousands and thousands of them. But you can see, this is the word. This was the country code. This is whether it was recognized. It has an ID. And then the drawing is in these arrays, which aren't console logging, but I can get access to them. Wonderful. So I now have an array that has every single drawing in it. Now, how do I get access to that? I need to be able to make a get request to the server. So let's see how we would do that. So I need to make an Express servery thing. Let's just look up Express Node and go to the kind of quick getting started, hello world. The hello world Express example is all we need, basically. I'm going to grab all of this. And I'm going to put it into my code. So what's going on? Number one is I need to require the Express library. I need to create an app, which is calling the Express function. I'm adding the semicolons. Gosh darn it. I need semicolons to live. I can't do without. I need to pick a port. So port, this is somewhat arbitrary, but I'm going to use the port 3000. And then I'm going to set up a route. So the idea, and I prefer to be a little more long-winded about this. This is using the arrow syntax, which is a kind of ES6 JavaScript syntax. And I'm just going to, I just have to do things the way that I do them. So there's two functions that I care about with my app. One is that I need it to listen on the port. So this, I'm setting up the server, creating a server, and that server is listening. Because ultimately, I got to get to that p5 sketch that's going to make the drawing. I haven't even gotten there yet. Now, I then want to set up a route. And then when the user makes a request to that route, send something back. So in this hello world example, if I run the server and go to localhost 3000, it says hello world. But that's not what I want. I don't care about sending hello world. What I want to do is let me make a route called rainbow. Then what I'm going to do is I'm going to say, let a random number equals math.floor, math.random, times drawings.length. So however many drawings have been loaded when somebody goes to this route, pick a random one. And then I'm going to say, and this could be a const, I guess. And I'm going to say response send drawings index r. And I suppose I should call this index. So now, oops, index. Let's rerun the server. And there is a tool called NodeMon, which will restart the server for you. I'm going to do this manually. And then I'm going to go here. Cannot get slash because there is no route anymore at slash. But if I go to slash rainbow, there we go. There is the drawing. Hold on a sec. Time out for a second. I could have sworn I have this extension that will format the JSON. But I guess I didn't. All right, I just installed a Chrome extension to format the JSON so I could see it. So here is a random drawing. And this is all the information. Now, all I need to do is have p5 request JSON from this route and then render the drawing. Pause for a second. I think I'm not doing multi-part videos this day. All right, oh, there's been some new members. Thank you very much. All right. All right. So now the question is, where do I run my p5 sketch? And there are a variety of ways. In theory, this is an API that anyone could make a request to. Whether or not I'm opening it up for other people to request to it or not is a complicated question. But one way that I could use it is just have this particular server host a p5 sketch in the first place. So the way to do that, if I go back to my files and I go to desktop, Quick Draw, this is where all the files are. I'm actually going, I have a p5 HTML file and a Sketch.js file in here. But I'm going to make another directory called public. So these would be where I want files that are hosted by the server to live, public. And then I'm going to say something like in my code, app. I don't remember. Static file hosting express. Serving static files in express is just this. So basically, what I want to do is serve up the HTML and the JavaScript files as well. So I'm going to do that here. I'm going to add this. So now, look at this. Now, and let's go to the p5 code and let's say background 0. So all that this p5 code does is create a 100 by 100 canvas with a background of 0. 100 by 100 canvas with a background of 0. So now, guess what? If I go to localhost 3000 slash rainbow, I get a drawing because I'm handling that rainbow route by sending back a drawing. But if I go to just slash, oh, I didn't restart the server, did I? Restart the server, go to slash, there's the p5 sketch. So now, my p5 sketch can finally ask for the server for the drawing. OK. I'm going to go over here and I'm going to say it. First of all, one thing is, by the way, that simplified data set, all of the simplified version of the QuickDraw data set, all of the drawings were simplified or scaled to 255 by 255 pixels. So that makes things easier to work with. I'm going to call the function loadJSON. And guess what? I'm just going to say loadJSON rainbow got rainbow. And then I'm going to write a function, gotRainbow, that gets some data. And I'm going to say console.log data. So this is the idea. Now, if you've seen loadJSON before, maybe before I've used it for load this actual JSON file. Or maybe I've said loadJSON from an API like Wordnik. Now, I'm going to the slash rainbow route, which is local to this particular server. And guess what? I don't actually even need to restart the server, because this will be loaded dynamically. So let's go here. And we can see, there it is. This is the rainbow drawing right here. Let me give myself some more room. And here's the drawing itself. So all I need to do now is write an algorithm to go through and draw this drawing. All right, we're ready. So let me make the background like 200. Let me say the drawing is in data.drawing. Is that right? Console.log drawing. Let's look at that. Yeah. So this is the actual drawing. It's just two arrays, because it was just two strokes. Now, I am going to say for let i equals 0, i is less than drawing. Oh, let me figure this out. This is an array. Oh, right. Oh, weird. I'm sorry. Oh, right. OK. So this was only one stroke. That's why this was confusing here. Some of these rainbows. There we go. This is what I want to look at. I have three different strokes. So first, I need to look at all the strokes. Sorry. So I want to say let, and I'm going to call it a path. So for let path of drawing. This is each and every path. Path 0, path 1, path 2. Then each path has a bunch of points. Path 0 has 15, path 1 has 10, path 2 has 6. I'm going to say for let i equals 0, i is less than path index 0 dot length. And then the x is path index 0 index 1. Wait, no, index i. Sorry. This is confusing. And the y is path index 1 index i. So this is what I'm doing. I am looping through 0, 1, 2. That's the outer loop. Each path. Each path is two arrays. Path 0 is all the x's. Path 1 is all the y's. I need to look at all the x's and all the y's, and then set a vertex x comma y. So I can say begin shape, end shape. I can say no fill stroke 0. Whoops. Stroke 0. And maybe I'll say stroke weight 3, just to make the lines a little bit thicker. And let's see what I see. There we go. Rainbows. Rainbows galore. These are everybody's rainbows each time I hit refresh. One thing I could do now is when it finishes, I could just say load JSON again. Maybe I would want to redraw the background every time. That might make sense. And here we go. This is a random drawing over and over and over again. So I could start to do things like request a specific drawing from a certain country. I could download different models. Let me pause for a second and grab another model. So let's get, what's a good one? Apple, asparagus, ax. I mean, cat is sort of like this typical one. So let's just do cat. So many. All right, I downloaded the cat file now. And I'm just going to put that in here as well. Whoops. Did I put that somewhere weird? No, I'm, ah, sorry. Let me do that again. Delete. Ah, shoot. Hold on, sorry everybody. Here we go. OK, so I downloaded one more set of drawings, the cat files. So I'm going to, the cat drawings, I'm going to copy that into here. And we can see now I have cat nd JSON. If I go back to my server, I could do, I'm going to say, I'm going to call this rainbows. And I'm going to do a different one for cat. And I'm also going to, ah, I'm going to do a different one for cat. And I'm also going to do cats, cats push object. And then I'm going to make another route for cats. So now if I rerun the server, and I go back to my actual sketch, and I switch to going to the cat route. Now where was that? Here I am. I'm going to hit Enter. Ooh, I got some issue. Cat internal server error. So what's going on here? Drawings is not defined. So I made a mistake in my server. Oh, this is, over here is rainbows.length. And this is cats.length. And I would have seen that error here if I was paying closer attention. There. I've got cats. And now let's look at a lot of cats. Oh. Oh, it's still giving me rainbows. Did I not hit Save? Load JSON cat. Oh, load JSON cat. Whatever, I'm not being too thoughtful about this. Give me the cats. I want to see the meow meow. What's going on? Run the server again. Let me refresh this page. It's still rainbows. Cat, cat, got rainbow. Somewhere I messed this up. Cat, cats. Ah! This is what I get for trying to code so quickly. This is supposed to say cat.json. Cat.ndjson. Now here we go. Oh, I have to restart the server. And here we go. Finally, cats. There's a lot of different cat drawings. I really should slow this down. Let me just slow this down a little bit. Oh, here's what I want to do, actually. Oh, this video should really be over. But you've already watched this much. You can watch a little bit more, right? I really want to draw the drawing in sequence. Now I don't have the timing information. And that would be useful to have. But let's make it actually animate. So I'm going to add a draw function. I'm not going to add a page transition event. And so when I've got a cat, and I'll just change this, what I'm actually going to do is just set current. I'm going to just say set cat equal to data. So I'm going to take out all of this. Cat equal to data.drawing. So I'm going to comment this out. Let's think about this. And then I'm going to say let x, y. And I'm going to say if cat, then I now need to keep track of where I am. Let stroke index equal 0. Let pen index equal 0. So I need to keep track of two indices, right? Because I'm going to walk through one at a time each vector of the first stroke. And then stroke's going to go from 0 to 1 and go through each of the other ones. So if there's a cat, the first thing I need to do is say, so if I'm going to say x equals, and what was this stuff? It is path. Oh, drawing. So cat index stroke index index pen index, index 0. Boy, this is really awkward about how it's using just arrays for everything. But I'm in the first stroke. In the first pen is not the right term. I don't know what to call it, vertex, but whatever. I could actually just call this index maybe. The stroke index and the index. 0 is for x. And then 1 is for y. And let me just, just to see that this works, let me say point, let me say point x comma y. And these don't need to be global. So let's see what this does. And so first of all, let's just run this. Oh boy, I freaked it out. It won't ever stop. Well, I think, by the way, I killed this. I need to build in a little more of a delay with these API calls. So cat is not defined, sketch.js line 12. If cat, that needs to be a global variable. And let me just say here console log x comma y. Let's see, did I get an x comma y? Yes. So I've got that first point over and over again. And presumably, 52 comma 48, I don't know why I don't see. I guess I need to say stroke 0, stroke weight 3. There we go. So there it is. That's the first point. So now what I need to do is say index plus plus. If index is greater than or equal to cat stroke index dot length, then stroke index plus plus and index equals 0. So this is me marching through them one at a time. So ooh, and I don't have the y. You can see that something's wrong here. I mean, this, let's see. Stroke index plus plus. I think this is right. Well, the point of this is what I actually want to do. So time out for a second. I forgot the variable. Well, that's probably an old comment from before. Hold on, I need a little break for a second. OK. Why did this not work? Something is off about this. Do I have these in the wrong order? Hold on. It's going 0, 0, 0, 1, 1, 0. There were 17. Oh, no, no, no, no, no, no. I have these in the wrong order. That's weird. Oh, I have these in the wrong order. I think it should be 0 index. It actually works this way? OK. It doesn't seem more like the cat. It's this. This is what it is. Of course. Because stroke index, then 0 is the x's, 1 is the y's. Index is going up. And then this. There we go. Yeah, it's hard to see, but these are the cats. OK, I got it now. All right. Let me go back to where I was. All right. I wasn't paying attention. If I look at how those arrays are organized, the first, the, the, the, it's, sorry. OK. OK, something is terribly wrong here. And actually, I have not been carefully looking at how those arrays are organized. It's very confusing to store all these data in arrays. But there are 11 strokes. And this stroke has 23 points. This stroke has 9 points. But notice that the, I have the order wrong. This is an array of an array of arrays. And so basically, the stroke, the 0 element of the stroke is all the different x values. And this 1 element of the stroke is all the different y values. I had those out of order. And then here, the number of points is not the number of strokes, but rather the number of x's. So now, if I redo this, I should see, I can sort of see it drawing. Oops. You can see the outline of a cat there. You can start to see the outline of a cat here. Of course, it gets stuck at the end. It's giving me an error. So first, let me fix that error. So the error that I need to check is if stroke index equals cat.length, then I'm done. Then I'm going to say cat equals null. I am going to say no more to the cat. And there we go. So this is the drawing of the cat. Now, of course, I'm just drawing all the points. I need to connect the previous points to the other points. So I'm going to add a previous x, previous y. And then I'm going to say here, down here, previous x equals x, previous y equals y. And then here, I'm going to say a line between previous x, previous y, and x and y. Now, it should do nothing when those values are null. So now we see there, ooh. Oh, wait a sec. No, no, no, no, no, no. When I get to the next stroke, then I need to say previous x equals undefined again, and previous y equals undefined. I don't want to connect the strokes. So that's a little bit of an awkward way of doing it. It's still doing that, isn't it? And then I want to say if previous x, maybe if I do this, does not equal undefined, then draw the line. Let's see if this works. Whoops. Sketch the line 19. I always have this extra equals there. Oh, weird. It's still connecting everything. A lovely little cat there. What am I missing? I don't want to draw the line. These are undefined at the beginning. Oh, it gets set to here. So I need an else here. Else. Don't set it if it's at the end. OK. There we go. Finally, we are drawing cats. Now, all I have to do is then, when I reset there, I can just ask for a new one. So let's ask for a new cat. And whenever I've got a cat, let's draw a white background. Let's make it a little bit gray. We'll set it gray at the beginning. There we go. Now, here we go. We are now going to draw lots of cats. It should finish one. Oh, didn't get another one. Sketch the line 13. Cat is undefined. And then there should be no more cat until I've got a cat. Try that again. There we go. I don't know what did wrong. Ooh. It drew a bunch of them and then didn't get one. Where is it breaking? Is it like a sequencing thing? Like it's drew the cat. Is it asking for a new cat? Should I say no loop? And then when it gets a cat, say loop. Oh, stroke index needs to be set to zero. OK. Thank you to the chat. OK, hold on. Matthew, you can edit out me trying to think about this for a minute. Thank you to BIMsoMe and Louise, both in the chat, who just pointed out that my technique here is correct, but the issue is that I need to reset everything back to zero. So here, I need to set stroke index back to zero. And I think index will already be zero. Yeah, index is already zero. So yes, that stroke index needs to go back to the beginning. And now I think we're ready to enjoy a whole bunch of cats. Cat drawings. All right, thanks for watching this coding challenge with the Google Quick Draw data set. Stay tuned for a future video where I show how to create new drawings with the Sketch RNN model, the machine learning model that was trained on these drawings. And if this was one of your drawings, thank you for making this beautiful cat. And I'll see you in a future coding challenge. Goodbye. Muchacho for coming to my colon, chat. Thanks for watching the code challenge. And don't forget subscribe to the channel and follow me on all the socials. This is, like, inensely satisfying Like, I could just watch this all day. Is it not finishing the drawings? Well, I should give it a little, like, delay. Like, if I did set time out. I should. Actually, let me just make a function called new cat. I don't know what music I just played. This is weird. So now let's take a look. Now I just give it a little delay. What? What? What? 38. Messed something up. I messed something up with my, oh, yeah. Yeah. I think that's right. Is it finishing it? I think it's finishing the cat. It does sort of seem like it's not doing the very last one, right? Yeah, I don't know. That's way too long to wait. People who draw it didn't finish it, yeah. All right, everybody. Now is it? It's not even 4 o'clock yet. Do I dare, dare to sketch RNN? Oh, right, because the Google Quick Draw guessed it before the person finished. That's interesting, yeah. I think I might be done for today. Did I do what I said I was going to do? Let me just look here. Mm. Mm. Mm. Mm. Sorry, I'm looking here to think about sketch RNN. Mm. So people are, this, by the way, is not sketch RNN. Just to be clear, these are the actual drawings, not the imagined drawings. I feel like I think I'm done for today. What did I make today? I got the logo part two done. I got the, I got the, sorry, logo part two, the ML5 save model, and the Quick Draw stuff. I think I want to wait till sketch RNN is within the documentation of ML5. So I will come back and do that another time. Plus, I feel like, yeah. All right. I could watch this all day. Let me make sure it's actually doing the last bit. Let's think about this. If stroke index equals cat.length, yeah, this has to have done the last one, right? So let's not do this for a second. And let's console log. Yeah, it's greater than, I think it's doing all of them. I'm looking at this code. It wouldn't be skipping one, because this is an index is invalid here, and then it goes up. It resets index to zero. It loops back around and starts over. Yeah, it's got to have gotten the last one. Just try going one further. It'll break, and you'll be right. Yeah. Yeah. I mean, I could say, or something. Yeah, it broke. Sketch.js line 18. Broke. Interesting. So I think maybe it was not getting the very last one of each stroke. Why is that? It's crazy cat. Yeah. Length plus one. Index goes up. Oh, because I'm pulling it here, and then index goes up by one. That doesn't make sense. I'm so confused. My brain is confused. May I am so me is typing. This means the answer is about to come through. The last index won't error. It won't error. It's just going to be undefined. So I'm good. It's the same. It'll just be undefined. All right, we're good. We're good, everybody. My mental math is still correct. All right. Thank you, everybody. It is 4 o'clock. I think I am finished. Is there any last little bits of stuff that I want to cover or talk about today? Pac-Man. Yeah. Thank you, everybody. So let's see. I should put this code somewhere. This will be. So let me do a little quick, just so the code is ready. I'm going to do this now. So I am going to grab these three files. I'm going to put them in a website, coding challenges. So I need to make. Question is, was this morning like part two of Logo? I think it kind of was. So this will be 1.22, quick draw. So that stuff goes in there. And let's change this to 1. And then also make a version 2. Sorry if you can't see this. And then I'm going to go to desktop, logo. This should be everything for this version. So now if I go to really messed up here because I didn't. Let me just merge this. This was the code from save load live stream. All right, I'm going to merge this. And then, OK. And I'm going to get branch quick draw. Check out quick draw. Get add coding challenges on 22 quick draw. Code from quick draw challenge. Push origin quick draw. OK, let me go check out master. And what I want to do is, shoot. I have an idea here. Where is this nonsense? There's some extra thing here that I'm going to just get rid of. Get branch logo. Get check out logo. And hold on. Now, logo 1, logo 2. Get add dot dash A. Moving logo code around and adding second part. And now, get push origin logo. So I should have two separate pull requests now. Welcome to weird things with GitHub. So I should be able to pull request this. This is the quick draw code for challenge 1.22. Ooh, well. Wait, why is my? What sort of set of tabs is this? What? Have I been using forward space? What? Have I been using forward space tabs all this time and not noticing? Those are like 18 space tabs. This is insane. What is going on? This look like two spaces. What's going on? Tab size 2. Render white space. Oh. Ooh, those are tabs. Why is it? What setting in VS Code is changing those to tabs? Oh my goodness. This cannot be. I forgot if I'm using prettier. I switched everything in my workflow, but I never actually did it on this. Am I? Do not I have? All right. All right, let's see. Oh, this. I have this crazy thing. Indent with tabs. Indent size 4. Oh. Oh. Let's disable this for a second. Let's install this prettier thing. Let's see. Reload. Yay! OK. Oh, what a mess. Where am I? Uh-oh. Uh-oh. Who knows where I am? I'm lost. I'm in the Quick Draw thing. I want to be in the website thing. Whoops. What a mess I've made of everything. Logo 1, 2. Oh, these are fine. There we go. Ah! Oh no, it's inheriting. Do I need to reload this thing? No? Prettier. Uh, default 2. Tabs, false. Semicolons, true. So these are all the settings. Oh, I've gone off a deep end here. Are people really watching me do this right now? Right, where is? Uh. Look at the chat. Hold on. Tab. Oh, GitHub is rendering a six-space tab. OK, hold on. Editor tab size 2. VS Code prettier settings. Let's see. This. Yes, yes. Pretty, ah, here we go. Here we go. Here we go. Prettier. Oh, there's all these things here. Great, great, great, great, great. Prettier tab width 2. So let's see. That's nice. OK, I've fixed that. And then what was the other thing that I want now is, oh, hold on. Prettier spaces. Uh. Use tabs, that must be. Right. False. That's the default value. This is very important what I'm doing right now. No! Wait, do I have to? Why? Why is this one still tabs? Why is this one tabs? What have I done? What have I done to deserve this? Insert spaces when pressing tab. Text editor auto indent. Yes. Detect, ah. I don't ever want to use tabs. Let's try that. No. It's not even formatting it. Huh. Hold on. Why is this? Why have I lost my format on save? Format on save true. Detect indentation false. Restart prettier. Yeah, that's a good idea. Let's just restart the whole thing. Weird. Let's go to extensions, prettier. No. All right, let's try this. Oh, it's not formatting on save. OK, now it is. I don't need this, though. I don't need this. Ugh. I saved it as a new file and it reformatted it. Weird. There, fixed it. This is fine. This is fine. And this is fine. I don't know what was wrong with that one file. This is spaces. This is spaces. And spaces, not tabs. Oh, that was scary. Oh, but my quick draw stuff. Ooh. Hold on. Hold on. Ah, pull requests. Oh, I didn't actually make the pull request. OK, so hold on. Now, everybody just relax. I can't believe how much time I've been doing this. What was it called? Quick draw? Oh, hold on. Quick draw. Wait, where's my quick draw? Yeah. We go to this branch. And then here, that's spaces. Oh, tabs. Oh, this file, too. What is it with the files? What if I manually, like, why are certain files? Not formatting. That's so weird. I've never seen this. Whoops. Format, document, format. Save. Format selection. Whoops. Oh, that did it. Format selection did it. I can't explain it. I'm not sure what's going on here. I'm going to go back to my document. I'm going to go back to my document. I'm going to go back to my document. And here's my document. I'm going to go back to my document. I can't explain it. Where am I? But that did it. Right? Yeah. OK. Oh, it's because of this file, maybe. Yeah. Because I'm in this repo. That's probably why. It must be, like, picking up. Oh, it's picking up settings from here. Yeah. All right. That's got to be it. All right. I know the camera went off. All right. Let's finish these pull requests, people. Oh, wait, no. Hold on. Let's do the quick draw one first. This is the quick draw code for challenge 122. If we look at this, there. Look at this. Look at this nice, normally indented code. OK. Now, let me do this. This moves challenge 121 into 121 underscore 1 and adds 121 underscore 2 for the second part of the logo challenge. It shouldn't be merged without fixing the markdown file for challenge 121 part 1 first. So let me do that. What is this? Get repeat? Oh, yeah, yeah. OK. What kind of crazy code did I write earlier today? OK. All right. Oh, my goodness. Ugh. All right, everyone. I'm definitely done. I really want to do more, but sometimes you just have to know when to quit. I don't usually know when to quit. I would be glad to take any questions, a few questions. Thank you to new members who joined. Actually, OK. So let me do a little few housekeeping. I can't imagine that anybody's still watching. But if you are, I will mention that I am way behind on sending out stickers and books to patron and YouTube members. I am really, this is my goal. Everyone who joined November 1st or earlier, sorry if you joined in the last week, because I'm compiling everything. I've got to get everybody everything by the holidays. If you do not have something and are wondering about the status of it, please send me a message on Slack. If you're a YouTube member, you don't have a Slack invite, then make sure you find the community post, which has the forum to get a Slack invite. And also, you can message at math blank on Slack, who is doing this stuff. If you are interested in Coding Train merchandise, I might as well plug this just for a second, because it's new. Actually, I am wearing right now, this is one of these shirts. It looks like I'm disrobing. Don't worry, I am not. I'm just showing you my Never Forget. It's kind of like translucent. Never Forget, the This Dot shirt. You can get your own Never Forget the This Dot shirt designed by human slash shop slash coding train, I believe. So you can see, these are the various shirts and things. And I wanted to mention, people, it's hard to notice this, but this phone case here is $35. That's crazy. But this is actually designed, actually, to probably make this a default for a zip hoodie, where the Never Forget the This Dot is on this side. All right, I just wanted to mention that. Other housekeeping things, let's see what other questions there are. What do you think about GANs, or Generative Adversarial Networks? They are very interesting to me, and I would love to learn more about them and maybe do some tutorials about them. A wonderful artist who does wonderful things with GAN is Helena Sisserman. Yes, you should check out GLAGOLISTA on Twitter, who makes all sorts of amazing GAN-related projects. Yeah. I'm not going yet. Waiting to see if there's any more questions. My mic is very quiet. That doesn't surprise me, because it got moved around. But hopefully, it's fine now. Thank you, Aufec, for letting me know. This is the end of today's talk. I hope you enjoyed it. I'll see you next time. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. This is the end of today's live stream. Today, I think I had about four hours of live streaming today. I'm going to be gone for quite a while because of ThinkerCon and Thanksgiving. So apologies in advance for that. Hopefully, I'll be able to catch up on a lot of content when I get back. We have a lot of notifications here on Twitter. I'll look at these later. This is the Coding Train account. I should do a Coding Train gift basket option for an X-mas shop. Sure. Or Sensei Cloco asked, are you planning to step up on your debugging game? What's wrong with my debugging game? I know. I could do better. Yes. No, I'm not planning to, but I appreciate your help. Yes. I think that it would be helpful for me to continue to develop better strategies for debugging to demonstrate. You mean you don't like my technique of having a bug and just sitting there going like this? Maybe the chat will tell me what's wrong in just a minute. Tim asked, do you code any other languages than JavaScript? Yes. So I do a lot of programming in Java, specifically using Processing, which is a Java-based platform you can download here. I actually was thinking of doing the Quick Draw stuff in Processing because of loading the big files. I didn't want to deal with setting up a server, but then I went ahead and did the Node thing because I thought that was interesting. OK. Thank you. Just use debugger in the JS file and Chrome will stop at that breakpoint for you. I should probably try that at some point. That's a very good suggestion. Thank you. Thank you, Joop for your kind comment. What classes do you teach and what are they about code? So very quickly, I will answer Aki MC's question. Thank you to ILouisSmith who has added two pull requests. So I teach classes at New York University, a part of Tisch School of the Arts. There's a grad program called ITP and an undergrad program called IMA. And then online, I make videos for this YouTube channel. And some of them are loosely grouped into things that could possibly somewhat be classes. But I haven't really cracked that nut yet of like, this thing on YouTube is a course that you could take. It's really just a lot of content and hopefully inspirational and helpful. But in terms of the actual things being a course, the place where you can look, and one thing is I'm really trying to do is, in theory, I would like to continue to work on and improve the navigation here. So there are some, so in theory, I would like this website to be a place where it's easier to find the packaged courses. Right now, if you're looking for that, I think if you go to YouTube Coding Train Playlists, and if I do All Playlists, you can see. But this is a big mess of things. So I'm trying to figure this out. Some things are organized. For example, you can see here, these are the beginner JavaScript tutorials, Playlists 1 through 7, Playlist 8, et cetera. These are some playlists associated with neural networks and machine learning. This is an old, antiquated Twitter bot tutorial that probably doesn't work anymore. These are some old nature of code videos. Here's the beginner processing videos, Git and GitHub. But again, please, somebody save me and help me figure out how to organize all this stuff. OK. Why not create a storyboard for the website? Yes, actually, so Matthew, if you go to the GitHub repository for the website, if you go under Issues, there are a few different issues that are currently tracking this discussion. So this is one proposal to have the website organized as coding challenges, beginner playlists, and then other courses that are not for beginners. So that's one thing that, and then all the live stream archives. So again, this is like Neil's web has done, and many other contributors, but Neil's web in particular has done a tremendous amount of work. Neil's Webber is a student and web developer in Germany. And so thank you so much to Neil's web. And I am certainly happy for people to contribute and participate in the development of a website. I haven't figured out really a structure to do that, but it's happening in an ad hoc basis. OK. So I'm going to go ahead and move on to the next question. And this is from Tushar Mitra. Tushar Mitra asks, last question, do you game? All right, you're going to be sorry you asked. If you go to YouTube.com and you search for EOD Gaming, this here with 166 subscribers is my gaming channel with my kids, who I'm very conflicted about. But this video is really what I would recommend. My daughter and I played Snipperclips for an hour and 40 minutes. And it's a wonderful game. And hopefully we'll do this again this weekend sometimes, but we do live streams trying to play. I love this game so much. It's so much fun. Of course, I got a copyright notice because I used the Snipperclips. Oh, look at this. Oh, am I on YouTube Gaming? So if I go to gaming.youtube.com. Whoa, look at this. You already got the plan. Yeah. So someday this is going to be even bigger than the coding train. Oh, I don't think so. All right, everybody. Goodbye. Thank you so much for tuning in. I am going to now stop this live stream and go on with my life. And I hope to hear from you, see you. If you're coming to ThinkerCon, let me know. I would love to see you there. I'm so excited about it. OK, and is this playing at? What's fun is to put this on double speed. Come on, we can get it in that basket. Hold on, I have to. Sorry, I just have to wait. This took us so long. OK, come on. Oh, am I going to get? I'm probably going to get copyright notice now in this video. You probably can't really hear this. I'm going to turn the music off. Oh, so close. Come on, come on, come on, come on, come on. Oh, up, up, go on. Oh, there you go. Oh, oh boy. Oh, come on. I'm like reliving this. It's so painful. I really have to go. OK, goodbye, everybody. You can go and watch this video on your own. I will link to it in the chat. Or somebody can link to it in the chat for me. It is this. We had so much fun. All right, goodbye, everybody. I'm going to stop streaming now. See you next time. Won't be for a few weeks, so stay tuned. If you want to get an alert when I schedule the next live stream, subscribe and then click that alarm bell. It's the thing you're supposed to do if you want. OK.",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:50:05.299148Z",
  "started_at": "2023-09-26T21:56:53.328232Z",
  "completed_at": "2023-09-26T22:20:55.641786Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=fnoOFQK3tPQ",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 1442.313554
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/eaumccbbl5gmrgeao3t7dnvduq/cancel",
    "get": "https://api.replicate.com/v1/predictions/eaumccbbl5gmrgeao3t7dnvduq"
  }
}