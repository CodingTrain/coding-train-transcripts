{
  "id": "h4rujpjbl7wmon5mzrz4imhwma",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/L9InSe46jkw.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/349699 [00:00<?, ?frames/s]\n  1%|          | 2806/349699 [00:06<12:42, 455.15frames/s]\n  2%|▏         | 5776/349699 [00:14<14:18, 400.76frames/s]\n  2%|▏         | 8454/349699 [00:24<17:52, 318.14frames/s]\n  3%|▎         | 11310/349699 [00:33<17:45, 317.57frames/s]\n  4%|▍         | 14142/349699 [00:42<17:34, 318.29frames/s]\n  5%|▍         | 17026/349699 [00:50<16:24, 338.03frames/s]\n  6%|▌         | 19806/349699 [00:57<15:46, 348.62frames/s]\n  6%|▋         | 22670/349699 [01:04<14:59, 363.39frames/s]\n  7%|▋         | 25354/349699 [01:11<14:16, 378.59frames/s]\n  8%|▊         | 28122/349699 [01:17<13:22, 400.86frames/s]\n  9%|▉         | 30728/349699 [01:25<14:18, 371.39frames/s]\n 10%|▉         | 33540/349699 [01:32<14:02, 375.21frames/s]\n 10%|█         | 36468/349699 [01:42<15:12, 343.16frames/s]\n 11%|█▏        | 39460/349699 [01:52<15:28, 334.12frames/s]\n 12%|█▏        | 42332/349699 [02:02<15:53, 322.33frames/s]\n 13%|█▎        | 44984/349699 [02:12<16:42, 303.82frames/s]\n 14%|█▎        | 47892/349699 [02:21<16:44, 300.50frames/s]\n 15%|█▍        | 50888/349699 [02:31<16:29, 302.02frames/s]\n 15%|█▌        | 53788/349699 [02:39<15:25, 319.70frames/s]\n 16%|█▌        | 56442/349699 [02:48<15:33, 314.13frames/s]\n 17%|█▋        | 59298/349699 [02:55<14:27, 334.75frames/s]\n 18%|█▊        | 62090/349699 [03:02<13:40, 350.62frames/s]\n 19%|█▊        | 64910/349699 [03:12<14:21, 330.46frames/s]\n 19%|█▉        | 67832/349699 [03:20<13:43, 342.31frames/s]\n 20%|██        | 70696/349699 [03:27<13:05, 355.21frames/s]\n 21%|██        | 73544/349699 [03:37<13:39, 337.11frames/s]\n 22%|██▏       | 76424/349699 [03:46<14:03, 324.04frames/s]\n 23%|██▎       | 79272/349699 [03:55<13:49, 325.98frames/s]\n 23%|██▎       | 81828/349699 [04:03<13:55, 320.75frames/s]\n 24%|██▍       | 84620/349699 [04:11<13:14, 333.84frames/s]\n 25%|██▌       | 87572/349699 [04:20<13:24, 325.83frames/s]\n 26%|██▌       | 90440/349699 [04:28<12:49, 336.91frames/s]\n 26%|██▌       | 90440/349699 [04:40<12:49, 336.91frames/s]\n 27%|██▋       | 93390/349699 [04:40<14:10, 301.26frames/s]\n 28%|██▊       | 96290/349699 [04:47<12:34, 336.04frames/s]\n 28%|██▊       | 99206/349699 [04:54<11:46, 354.73frames/s]\n 29%|██▉       | 102130/349699 [05:00<10:56, 377.14frames/s]\n 30%|███       | 105052/349699 [05:09<11:14, 362.74frames/s]\n 31%|███       | 107888/349699 [05:17<11:01, 365.81frames/s]\n 32%|███▏      | 110700/349699 [05:24<10:54, 365.12frames/s]\n 32%|███▏      | 113624/349699 [05:32<10:35, 371.66frames/s]\n 33%|███▎      | 116542/349699 [05:38<09:50, 394.93frames/s]\n 34%|███▍      | 119490/349699 [05:47<10:04, 380.67frames/s]\n 35%|███▌      | 122412/349699 [05:54<09:49, 385.61frames/s]\n 36%|███▌      | 125388/349699 [06:01<09:14, 404.48frames/s]\n 37%|███▋      | 128148/349699 [06:06<08:40, 425.76frames/s]\n 37%|███▋      | 131088/349699 [06:19<10:55, 333.32frames/s]\n 38%|███▊      | 134012/349699 [06:29<11:14, 319.88frames/s]\n 39%|███▉      | 136628/349699 [06:37<10:59, 323.23frames/s]\n 40%|███▉      | 139516/349699 [06:44<10:06, 346.83frames/s]\n 41%|████      | 142084/349699 [06:52<10:08, 341.16frames/s]\n 41%|████▏     | 144916/349699 [06:59<09:25, 361.88frames/s]\n 42%|████▏     | 147648/349699 [07:07<09:33, 352.53frames/s]\n 43%|████▎     | 150436/349699 [07:15<09:17, 357.51frames/s]\n 44%|████▍     | 153436/349699 [07:21<08:17, 394.11frames/s]\n 45%|████▍     | 156316/349699 [07:25<07:17, 442.51frames/s]\n 45%|████▌     | 158880/349699 [07:31<07:20, 433.08frames/s]\n 46%|████▋     | 161804/349699 [07:40<07:41, 407.45frames/s]\n 47%|████▋     | 164652/349699 [07:46<07:19, 420.87frames/s]\n 48%|████▊     | 167448/349699 [07:52<07:06, 427.17frames/s]\n 49%|████▊     | 170100/349699 [07:57<06:39, 449.61frames/s]\n 49%|████▉     | 172528/349699 [08:04<06:55, 426.73frames/s]\n 50%|█████     | 175452/349699 [08:10<06:35, 440.51frames/s]\n 51%|█████     | 178292/349699 [08:14<05:53, 485.47frames/s]\n 52%|█████▏    | 181240/349699 [08:21<05:49, 481.77frames/s]\n 53%|█████▎    | 184120/349699 [08:29<06:22, 432.65frames/s]\n 53%|█████▎    | 186696/349699 [08:33<05:45, 471.11frames/s]\n 54%|█████▍    | 189512/349699 [08:40<05:52, 454.13frames/s]\n 55%|█████▍    | 192244/349699 [08:45<05:39, 463.12frames/s]\n 56%|█████▌    | 195184/349699 [08:50<05:08, 501.21frames/s]\n 57%|█████▋    | 198028/349699 [08:56<05:01, 503.20frames/s]\n 57%|█████▋    | 201024/349699 [09:04<05:37, 440.79frames/s]\n 58%|█████▊    | 203956/349699 [09:11<05:25, 448.05frames/s]\n 59%|█████▉    | 206556/349699 [09:17<05:21, 445.06frames/s]\n 60%|█████▉    | 209204/349699 [09:24<05:33, 421.58frames/s]\n 61%|██████    | 212168/349699 [09:28<04:44, 482.58frames/s]\n 61%|██████▏   | 215006/349699 [09:34<04:44, 473.02frames/s]\n 62%|██████▏   | 217986/349699 [09:40<04:36, 476.84frames/s]\n 63%|██████▎   | 220630/349699 [09:49<05:05, 421.95frames/s]\n 64%|██████▍   | 223594/349699 [09:55<04:57, 424.19frames/s]\n 65%|██████▍   | 226394/349699 [10:02<04:46, 430.03frames/s]\n 66%|██████▌   | 229290/349699 [10:10<05:01, 398.90frames/s]\n 66%|██████▋   | 232086/349699 [10:19<05:22, 365.03frames/s]\n 67%|██████▋   | 234918/349699 [10:28<05:25, 352.85frames/s]\n 68%|██████▊   | 237906/349699 [10:38<05:37, 331.15frames/s]\n 69%|██████▉   | 240582/349699 [10:48<05:50, 311.73frames/s]\n 70%|██████▉   | 243350/349699 [10:57<05:38, 314.58frames/s]\n 70%|███████   | 246090/349699 [11:06<05:33, 310.71frames/s]\n 71%|███████   | 248910/349699 [11:15<05:22, 312.50frames/s]\n 72%|███████▏  | 251878/349699 [11:27<05:43, 284.63frames/s]\n 73%|███████▎  | 254838/349699 [11:33<04:46, 331.30frames/s]\n 74%|███████▎  | 257220/349699 [11:38<04:17, 359.79frames/s]\n 74%|███████▍  | 260210/349699 [11:44<03:44, 398.53frames/s]\n 75%|███████▌  | 263204/349699 [11:51<03:37, 397.04frames/s]\n 76%|███████▌  | 265912/349699 [12:00<03:45, 371.29frames/s]\n 77%|███████▋  | 268544/349699 [12:08<03:51, 351.00frames/s]\n 78%|███████▊  | 271384/349699 [12:17<03:51, 338.10frames/s]\n 78%|███████▊  | 274354/349699 [12:29<04:04, 308.23frames/s]\n 79%|███████▉  | 277210/349699 [12:39<04:04, 296.91frames/s]\n 79%|███████▉  | 277210/349699 [12:50<04:04, 296.91frames/s]\n 80%|████████  | 280002/349699 [12:50<04:07, 281.67frames/s]\n 81%|████████  | 282970/349699 [13:00<03:53, 285.65frames/s]\n 82%|████████▏ | 285918/349699 [13:10<03:38, 291.99frames/s]\n 83%|████████▎ | 288734/349699 [13:17<03:10, 320.59frames/s]\n 83%|████████▎ | 291666/349699 [13:27<03:09, 305.95frames/s]\n 83%|████████▎ | 291666/349699 [13:40<03:09, 305.95frames/s]\n 84%|████████▍ | 294646/349699 [13:41<03:20, 274.44frames/s]\n 85%|████████▌ | 297630/349699 [13:52<03:11, 271.37frames/s]\n 86%|████████▌ | 300498/349699 [14:02<02:59, 274.32frames/s]\n 87%|████████▋ | 303442/349699 [14:12<02:42, 285.18frames/s]\n 88%|████████▊ | 306238/349699 [14:22<02:36, 277.90frames/s]\n 88%|████████▊ | 309166/349699 [14:27<02:02, 330.08frames/s]\n 89%|████████▉ | 312130/349699 [14:35<01:48, 347.43frames/s]\n 90%|█████████ | 315098/349699 [14:43<01:37, 353.16frames/s]\n 91%|█████████ | 318054/349699 [14:51<01:29, 352.12frames/s]\n 92%|█████████▏| 320740/349699 [15:00<01:24, 342.52frames/s]\n 93%|█████████▎| 323576/349699 [15:11<01:23, 311.62frames/s]\n 93%|█████████▎| 326176/349699 [15:18<01:11, 329.31frames/s]\n 94%|█████████▍| 328828/349699 [15:26<01:04, 325.32frames/s]\n 95%|█████████▍| 331828/349699 [15:33<00:51, 345.99frames/s]\n 96%|█████████▌| 334724/349699 [15:43<00:44, 334.00frames/s]\n 96%|█████████▋| 337388/349699 [15:48<00:33, 366.49frames/s]\n 97%|█████████▋| 340388/349699 [15:52<00:21, 434.65frames/s]\n 98%|█████████▊| 343272/349699 [16:01<00:16, 394.06frames/s]\n 99%|█████████▉| 346116/349699 [16:09<00:09, 386.41frames/s]\n100%|█████████▉| 349016/349699 [16:19<00:01, 351.07frames/s]\n100%|██████████| 349699/349699 [16:22<00:00, 334.78frames/s]\n100%|██████████| 349699/349699 [16:22<00:00, 355.95frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.4252845839698716,
        "compression_ratio": 1.5314009661835748,
        "end": 0.84,
        "id": 0,
        "no_speech_prob": 0.007002075202763081,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          50364,
          1079,
          13,
          50406
        ]
      },
      {
        "avg_logprob": -0.4252845839698716,
        "compression_ratio": 1.5314009661835748,
        "end": 6.16,
        "id": 1,
        "no_speech_prob": 0.007002075202763081,
        "seek": 0,
        "start": 4.6000000000000005,
        "temperature": 0,
        "text": " My event is starting.",
        "tokens": [
          50594,
          1222,
          2280,
          307,
          2891,
          13,
          50672
        ]
      },
      {
        "avg_logprob": -0.4252845839698716,
        "compression_ratio": 1.5314009661835748,
        "end": 7.76,
        "id": 2,
        "no_speech_prob": 0.007002075202763081,
        "seek": 0,
        "start": 6.16,
        "temperature": 0,
        "text": " Oh wait, maybe I shouldn't be showing this yet.",
        "tokens": [
          50672,
          876,
          1699,
          11,
          1310,
          286,
          4659,
          380,
          312,
          4099,
          341,
          1939,
          13,
          50752
        ]
      },
      {
        "avg_logprob": -0.4252845839698716,
        "compression_ratio": 1.5314009661835748,
        "end": 9.82,
        "id": 3,
        "no_speech_prob": 0.007002075202763081,
        "seek": 0,
        "start": 7.76,
        "temperature": 0,
        "text": " That's fine, it could be back here.",
        "tokens": [
          50752,
          663,
          311,
          2489,
          11,
          309,
          727,
          312,
          646,
          510,
          13,
          50855
        ]
      },
      {
        "avg_logprob": -0.4252845839698716,
        "compression_ratio": 1.5314009661835748,
        "end": 11.200000000000001,
        "id": 4,
        "no_speech_prob": 0.007002075202763081,
        "seek": 0,
        "start": 9.82,
        "temperature": 0,
        "text": " Hello!",
        "tokens": [
          50855,
          2425,
          0,
          50924
        ]
      },
      {
        "avg_logprob": -0.4252845839698716,
        "compression_ratio": 1.5314009661835748,
        "end": 12.8,
        "id": 5,
        "no_speech_prob": 0.007002075202763081,
        "seek": 0,
        "start": 11.200000000000001,
        "temperature": 0,
        "text": " I think I've started streaming.",
        "tokens": [
          50924,
          286,
          519,
          286,
          600,
          1409,
          11791,
          13,
          51004
        ]
      },
      {
        "avg_logprob": -0.4252845839698716,
        "compression_ratio": 1.5314009661835748,
        "end": 13.96,
        "id": 6,
        "no_speech_prob": 0.007002075202763081,
        "seek": 0,
        "start": 12.8,
        "temperature": 0,
        "text": " Welcome to...",
        "tokens": [
          51004,
          4027,
          281,
          485,
          51062
        ]
      },
      {
        "avg_logprob": -0.4252845839698716,
        "compression_ratio": 1.5314009661835748,
        "end": 19.2,
        "id": 7,
        "no_speech_prob": 0.007002075202763081,
        "seek": 0,
        "start": 16.28,
        "temperature": 0,
        "text": " The Coding Train, live on a Friday.",
        "tokens": [
          51178,
          440,
          383,
          8616,
          28029,
          11,
          1621,
          322,
          257,
          6984,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.4252845839698716,
        "compression_ratio": 1.5314009661835748,
        "end": 23.64,
        "id": 8,
        "no_speech_prob": 0.007002075202763081,
        "seek": 0,
        "start": 20.16,
        "temperature": 0,
        "text": " So this is a special Friday Coding Train episode.",
        "tokens": [
          51372,
          407,
          341,
          307,
          257,
          2121,
          6984,
          383,
          8616,
          28029,
          3500,
          13,
          51546
        ]
      },
      {
        "avg_logprob": -0.4252845839698716,
        "compression_ratio": 1.5314009661835748,
        "end": 25.64,
        "id": 9,
        "no_speech_prob": 0.007002075202763081,
        "seek": 0,
        "start": 23.64,
        "temperature": 0,
        "text": " I have a very special guest,",
        "tokens": [
          51546,
          286,
          362,
          257,
          588,
          2121,
          8341,
          11,
          51646
        ]
      },
      {
        "avg_logprob": -0.4252845839698716,
        "compression_ratio": 1.5314009661835748,
        "end": 28.060000000000002,
        "id": 10,
        "no_speech_prob": 0.007002075202763081,
        "seek": 0,
        "start": 25.64,
        "temperature": 0,
        "text": " and this is my special guest's project",
        "tokens": [
          51646,
          293,
          341,
          307,
          452,
          2121,
          8341,
          311,
          1716,
          51767
        ]
      },
      {
        "avg_logprob": -0.39100207051923197,
        "compression_ratio": 1.548148148148148,
        "end": 32.22,
        "id": 11,
        "no_speech_prob": 0.00010549168655415997,
        "seek": 2806,
        "start": 28.06,
        "temperature": 0,
        "text": " that this approximately one hour livestream will be about.",
        "tokens": [
          50364,
          300,
          341,
          10447,
          472,
          1773,
          29782,
          486,
          312,
          466,
          13,
          50572
        ]
      },
      {
        "avg_logprob": -0.39100207051923197,
        "compression_ratio": 1.548148148148148,
        "end": 34.019999999999996,
        "id": 12,
        "no_speech_prob": 0.00010549168655415997,
        "seek": 2806,
        "start": 32.22,
        "temperature": 0,
        "text": " You should, oh, audio is low.",
        "tokens": [
          50572,
          509,
          820,
          11,
          1954,
          11,
          6278,
          307,
          2295,
          13,
          50662
        ]
      },
      {
        "avg_logprob": -0.39100207051923197,
        "compression_ratio": 1.548148148148148,
        "end": 34.839999999999996,
        "id": 13,
        "no_speech_prob": 0.00010549168655415997,
        "seek": 2806,
        "start": 34.019999999999996,
        "temperature": 0,
        "text": " This is good.",
        "tokens": [
          50662,
          639,
          307,
          665,
          13,
          50703
        ]
      },
      {
        "avg_logprob": -0.39100207051923197,
        "compression_ratio": 1.548148148148148,
        "end": 37.56,
        "id": 14,
        "no_speech_prob": 0.00010549168655415997,
        "seek": 2806,
        "start": 34.839999999999996,
        "temperature": 0,
        "text": " So I have a two mic setup going,",
        "tokens": [
          50703,
          407,
          286,
          362,
          257,
          732,
          3123,
          8657,
          516,
          11,
          50839
        ]
      },
      {
        "avg_logprob": -0.39100207051923197,
        "compression_ratio": 1.548148148148148,
        "end": 40.18,
        "id": 15,
        "no_speech_prob": 0.00010549168655415997,
        "seek": 2806,
        "start": 37.56,
        "temperature": 0,
        "text": " and so let me debug that a little bit here",
        "tokens": [
          50839,
          293,
          370,
          718,
          385,
          24083,
          300,
          257,
          707,
          857,
          510,
          50970
        ]
      },
      {
        "avg_logprob": -0.39100207051923197,
        "compression_ratio": 1.548148148148148,
        "end": 41.9,
        "id": 16,
        "no_speech_prob": 0.00010549168655415997,
        "seek": 2806,
        "start": 40.18,
        "temperature": 0,
        "text": " before I get started.",
        "tokens": [
          50970,
          949,
          286,
          483,
          1409,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.39100207051923197,
        "compression_ratio": 1.548148148148148,
        "end": 46.06,
        "id": 17,
        "no_speech_prob": 0.00010549168655415997,
        "seek": 2806,
        "start": 41.9,
        "temperature": 0,
        "text": " I'm opening up the Slack channel, which is for patrons.",
        "tokens": [
          51056,
          286,
          478,
          5193,
          493,
          264,
          37211,
          2269,
          11,
          597,
          307,
          337,
          27559,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.39100207051923197,
        "compression_ratio": 1.548148148148148,
        "end": 49.16,
        "id": 18,
        "no_speech_prob": 0.00010549168655415997,
        "seek": 2806,
        "start": 47.16,
        "temperature": 0,
        "text": " So make it louder.",
        "tokens": [
          51319,
          407,
          652,
          309,
          22717,
          13,
          51419
        ]
      },
      {
        "avg_logprob": -0.39100207051923197,
        "compression_ratio": 1.548148148148148,
        "end": 51.08,
        "id": 19,
        "no_speech_prob": 0.00010549168655415997,
        "seek": 2806,
        "start": 49.16,
        "temperature": 0,
        "text": " So hold on, special guest.",
        "tokens": [
          51419,
          407,
          1797,
          322,
          11,
          2121,
          8341,
          13,
          51515
        ]
      },
      {
        "avg_logprob": -0.39100207051923197,
        "compression_ratio": 1.548148148148148,
        "end": 51.96,
        "id": 20,
        "no_speech_prob": 0.00010549168655415997,
        "seek": 2806,
        "start": 51.08,
        "temperature": 0,
        "text": " I don't know why I'm making this",
        "tokens": [
          51515,
          286,
          500,
          380,
          458,
          983,
          286,
          478,
          1455,
          341,
          51559
        ]
      },
      {
        "avg_logprob": -0.39100207051923197,
        "compression_ratio": 1.548148148148148,
        "end": 54.480000000000004,
        "id": 21,
        "no_speech_prob": 0.00010549168655415997,
        "seek": 2806,
        "start": 51.96,
        "temperature": 0,
        "text": " like some sort of surprise reveal.",
        "tokens": [
          51559,
          411,
          512,
          1333,
          295,
          6365,
          10658,
          13,
          51685
        ]
      },
      {
        "avg_logprob": -0.39100207051923197,
        "compression_ratio": 1.548148148148148,
        "end": 57.76,
        "id": 22,
        "no_speech_prob": 0.00010549168655415997,
        "seek": 2806,
        "start": 54.480000000000004,
        "temperature": 0,
        "text": " But special guest, just say a couple sentences,",
        "tokens": [
          51685,
          583,
          2121,
          8341,
          11,
          445,
          584,
          257,
          1916,
          16579,
          11,
          51849
        ]
      },
      {
        "avg_logprob": -0.3634578525620019,
        "compression_ratio": 1.8222222222222222,
        "end": 59.04,
        "id": 23,
        "no_speech_prob": 0.001596285030245781,
        "seek": 5776,
        "start": 57.76,
        "temperature": 0,
        "text": " and let's test your audio.",
        "tokens": [
          50364,
          293,
          718,
          311,
          1500,
          428,
          6278,
          13,
          50428
        ]
      },
      {
        "avg_logprob": -0.3634578525620019,
        "compression_ratio": 1.8222222222222222,
        "end": 61.08,
        "id": 24,
        "no_speech_prob": 0.001596285030245781,
        "seek": 5776,
        "start": 59.04,
        "temperature": 0,
        "text": " Hello, testing, testing.",
        "tokens": [
          50428,
          2425,
          11,
          4997,
          11,
          4997,
          13,
          50530
        ]
      },
      {
        "avg_logprob": -0.3634578525620019,
        "compression_ratio": 1.8222222222222222,
        "end": 62.92,
        "id": 25,
        "no_speech_prob": 0.001596285030245781,
        "seek": 5776,
        "start": 61.08,
        "temperature": 0,
        "text": " Can you do a cut to me while I'm testing audio?",
        "tokens": [
          50530,
          1664,
          291,
          360,
          257,
          1723,
          281,
          385,
          1339,
          286,
          478,
          4997,
          6278,
          30,
          50622
        ]
      },
      {
        "avg_logprob": -0.3634578525620019,
        "compression_ratio": 1.8222222222222222,
        "end": 64.67999999999999,
        "id": 26,
        "no_speech_prob": 0.001596285030245781,
        "seek": 5776,
        "start": 62.92,
        "temperature": 0,
        "text": " I can, actually.",
        "tokens": [
          50622,
          286,
          393,
          11,
          767,
          13,
          50710
        ]
      },
      {
        "avg_logprob": -0.3634578525620019,
        "compression_ratio": 1.8222222222222222,
        "end": 65.52,
        "id": 27,
        "no_speech_prob": 0.001596285030245781,
        "seek": 5776,
        "start": 64.67999999999999,
        "temperature": 0,
        "text": " Hello.",
        "tokens": [
          50710,
          2425,
          13,
          50752
        ]
      },
      {
        "avg_logprob": -0.3634578525620019,
        "compression_ratio": 1.8222222222222222,
        "end": 67.24,
        "id": 28,
        "no_speech_prob": 0.001596285030245781,
        "seek": 5776,
        "start": 65.52,
        "temperature": 0,
        "text": " Wrong, wrong, cut to special guest.",
        "tokens": [
          50752,
          28150,
          11,
          2085,
          11,
          1723,
          281,
          2121,
          8341,
          13,
          50838
        ]
      },
      {
        "avg_logprob": -0.3634578525620019,
        "compression_ratio": 1.8222222222222222,
        "end": 68.82,
        "id": 29,
        "no_speech_prob": 0.001596285030245781,
        "seek": 5776,
        "start": 67.24,
        "temperature": 0,
        "text": " Oh, hello, testing.",
        "tokens": [
          50838,
          876,
          11,
          7751,
          11,
          4997,
          13,
          50917
        ]
      },
      {
        "avg_logprob": -0.3634578525620019,
        "compression_ratio": 1.8222222222222222,
        "end": 71.56,
        "id": 30,
        "no_speech_prob": 0.001596285030245781,
        "seek": 5776,
        "start": 68.82,
        "temperature": 0,
        "text": " Ding, ding, ding, ding, ding, ding, ding, ding.",
        "tokens": [
          50917,
          220,
          35,
          278,
          11,
          21211,
          11,
          21211,
          11,
          21211,
          11,
          21211,
          11,
          21211,
          11,
          21211,
          11,
          21211,
          13,
          51054
        ]
      },
      {
        "avg_logprob": -0.3634578525620019,
        "compression_ratio": 1.8222222222222222,
        "end": 72.4,
        "id": 31,
        "no_speech_prob": 0.001596285030245781,
        "seek": 5776,
        "start": 71.56,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51054,
          1057,
          558,
          13,
          51096
        ]
      },
      {
        "avg_logprob": -0.3634578525620019,
        "compression_ratio": 1.8222222222222222,
        "end": 76.46,
        "id": 32,
        "no_speech_prob": 0.001596285030245781,
        "seek": 5776,
        "start": 74.4,
        "temperature": 0,
        "text": " So is it just my mic that's low?",
        "tokens": [
          51196,
          407,
          307,
          309,
          445,
          452,
          3123,
          300,
          311,
          2295,
          30,
          51299
        ]
      },
      {
        "avg_logprob": -0.3634578525620019,
        "compression_ratio": 1.8222222222222222,
        "end": 78.28,
        "id": 33,
        "no_speech_prob": 0.001596285030245781,
        "seek": 5776,
        "start": 76.46,
        "temperature": 0,
        "text": " I can hear him, but I can't see him.",
        "tokens": [
          51299,
          286,
          393,
          1568,
          796,
          11,
          457,
          286,
          393,
          380,
          536,
          796,
          13,
          51390
        ]
      },
      {
        "avg_logprob": -0.3634578525620019,
        "compression_ratio": 1.8222222222222222,
        "end": 80.38,
        "id": 34,
        "no_speech_prob": 0.001596285030245781,
        "seek": 5776,
        "start": 78.28,
        "temperature": 0,
        "text": " No, that, you know, that's, you will in a second.",
        "tokens": [
          51390,
          883,
          11,
          300,
          11,
          291,
          458,
          11,
          300,
          311,
          11,
          291,
          486,
          294,
          257,
          1150,
          13,
          51495
        ]
      },
      {
        "avg_logprob": -0.3634578525620019,
        "compression_ratio": 1.8222222222222222,
        "end": 84.53999999999999,
        "id": 35,
        "no_speech_prob": 0.001596285030245781,
        "seek": 5776,
        "start": 80.38,
        "temperature": 0,
        "text": " Is it, is my mic lower than my special guest's mic?",
        "tokens": [
          51495,
          1119,
          309,
          11,
          307,
          452,
          3123,
          3126,
          813,
          452,
          2121,
          8341,
          311,
          3123,
          30,
          51703
        ]
      },
      {
        "avg_logprob": -0.3963925581711989,
        "compression_ratio": 1.5809128630705394,
        "end": 88.12,
        "id": 36,
        "no_speech_prob": 0.00010388398368377239,
        "seek": 8454,
        "start": 85.38000000000001,
        "temperature": 0,
        "text": " Because you don't know who it is.",
        "tokens": [
          50406,
          1436,
          291,
          500,
          380,
          458,
          567,
          309,
          307,
          13,
          50543
        ]
      },
      {
        "avg_logprob": -0.3963925581711989,
        "compression_ratio": 1.5809128630705394,
        "end": 92.52000000000001,
        "id": 37,
        "no_speech_prob": 0.00010388398368377239,
        "seek": 8454,
        "start": 91.54,
        "temperature": 0,
        "text": " That's gonna take a minute.",
        "tokens": [
          50714,
          663,
          311,
          799,
          747,
          257,
          3456,
          13,
          50763
        ]
      },
      {
        "avg_logprob": -0.3963925581711989,
        "compression_ratio": 1.5809128630705394,
        "end": 95.94000000000001,
        "id": 38,
        "no_speech_prob": 0.00010388398368377239,
        "seek": 8454,
        "start": 92.52000000000001,
        "temperature": 0,
        "text": " The one issue with live streaming is the chat",
        "tokens": [
          50763,
          440,
          472,
          2734,
          365,
          1621,
          11791,
          307,
          264,
          5081,
          50934
        ]
      },
      {
        "avg_logprob": -0.3963925581711989,
        "compression_ratio": 1.5809128630705394,
        "end": 99.52000000000001,
        "id": 39,
        "no_speech_prob": 0.00010388398368377239,
        "seek": 8454,
        "start": 95.94000000000001,
        "temperature": 0,
        "text": " is about 20 seconds behind us in real time.",
        "tokens": [
          50934,
          307,
          466,
          945,
          3949,
          2261,
          505,
          294,
          957,
          565,
          13,
          51113
        ]
      },
      {
        "avg_logprob": -0.3963925581711989,
        "compression_ratio": 1.5809128630705394,
        "end": 101.24000000000001,
        "id": 40,
        "no_speech_prob": 0.00010388398368377239,
        "seek": 8454,
        "start": 99.52000000000001,
        "temperature": 0,
        "text": " So that question, they won't actually hear it",
        "tokens": [
          51113,
          407,
          300,
          1168,
          11,
          436,
          1582,
          380,
          767,
          1568,
          309,
          51199
        ]
      },
      {
        "avg_logprob": -0.3963925581711989,
        "compression_ratio": 1.5809128630705394,
        "end": 102.2,
        "id": 41,
        "no_speech_prob": 0.00010388398368377239,
        "seek": 8454,
        "start": 101.24000000000001,
        "temperature": 0,
        "text": " for about 20 seconds.",
        "tokens": [
          51199,
          337,
          466,
          945,
          3949,
          13,
          51247
        ]
      },
      {
        "avg_logprob": -0.3963925581711989,
        "compression_ratio": 1.5809128630705394,
        "end": 103.04,
        "id": 42,
        "no_speech_prob": 0.00010388398368377239,
        "seek": 8454,
        "start": 102.2,
        "temperature": 0,
        "text": " I love it, it's awesome.",
        "tokens": [
          51247,
          286,
          959,
          309,
          11,
          309,
          311,
          3476,
          13,
          51289
        ]
      },
      {
        "avg_logprob": -0.3963925581711989,
        "compression_ratio": 1.5809128630705394,
        "end": 104.38000000000001,
        "id": 43,
        "no_speech_prob": 0.00010388398368377239,
        "seek": 8454,
        "start": 103.04,
        "temperature": 0,
        "text": " My mic is fine.",
        "tokens": [
          51289,
          1222,
          3123,
          307,
          2489,
          13,
          51356
        ]
      },
      {
        "avg_logprob": -0.3963925581711989,
        "compression_ratio": 1.5809128630705394,
        "end": 105.72,
        "id": 44,
        "no_speech_prob": 0.00010388398368377239,
        "seek": 8454,
        "start": 104.38000000000001,
        "temperature": 0,
        "text": " Hi, mine is low.",
        "tokens": [
          51356,
          2421,
          11,
          3892,
          307,
          2295,
          13,
          51423
        ]
      },
      {
        "avg_logprob": -0.3963925581711989,
        "compression_ratio": 1.5809128630705394,
        "end": 108.60000000000001,
        "id": 45,
        "no_speech_prob": 0.00010388398368377239,
        "seek": 8454,
        "start": 106.9,
        "temperature": 0,
        "text": " Shiftman mic is low only.",
        "tokens": [
          51482,
          1160,
          351,
          83,
          1601,
          3123,
          307,
          2295,
          787,
          13,
          51567
        ]
      },
      {
        "avg_logprob": -0.3963925581711989,
        "compression_ratio": 1.5809128630705394,
        "end": 110.06,
        "id": 46,
        "no_speech_prob": 0.00010388398368377239,
        "seek": 8454,
        "start": 108.60000000000001,
        "temperature": 0,
        "text": " Is my mic low?",
        "tokens": [
          51567,
          1119,
          452,
          3123,
          2295,
          30,
          51640
        ]
      },
      {
        "avg_logprob": -0.3963925581711989,
        "compression_ratio": 1.5809128630705394,
        "end": 111.06,
        "id": 47,
        "no_speech_prob": 0.00010388398368377239,
        "seek": 8454,
        "start": 110.06,
        "temperature": 0,
        "text": " Is my mic tested?",
        "tokens": [
          51640,
          1119,
          452,
          3123,
          8246,
          30,
          51690
        ]
      },
      {
        "avg_logprob": -0.3963925581711989,
        "compression_ratio": 1.5809128630705394,
        "end": 112.06,
        "id": 48,
        "no_speech_prob": 0.00010388398368377239,
        "seek": 8454,
        "start": 111.06,
        "temperature": 0,
        "text": " No, yours was fine.",
        "tokens": [
          51690,
          883,
          11,
          6342,
          390,
          2489,
          13,
          51740
        ]
      },
      {
        "avg_logprob": -0.3963925581711989,
        "compression_ratio": 1.5809128630705394,
        "end": 113.10000000000001,
        "id": 49,
        "no_speech_prob": 0.00010388398368377239,
        "seek": 8454,
        "start": 112.06,
        "temperature": 0,
        "text": " And I can actually turn.",
        "tokens": [
          51740,
          400,
          286,
          393,
          767,
          1261,
          13,
          51792
        ]
      },
      {
        "avg_logprob": -0.2938269147221346,
        "compression_ratio": 1.7419354838709677,
        "end": 116.58,
        "id": 50,
        "no_speech_prob": 0.00001618546957615763,
        "seek": 11310,
        "start": 113.1,
        "temperature": 0,
        "text": " So first of all, I'm kind of okay with my mic being low.",
        "tokens": [
          50364,
          407,
          700,
          295,
          439,
          11,
          286,
          478,
          733,
          295,
          1392,
          365,
          452,
          3123,
          885,
          2295,
          13,
          50538
        ]
      },
      {
        "avg_logprob": -0.2938269147221346,
        "compression_ratio": 1.7419354838709677,
        "end": 119.14,
        "id": 51,
        "no_speech_prob": 0.00001618546957615763,
        "seek": 11310,
        "start": 116.58,
        "temperature": 0,
        "text": " First of all, is it actually registering my mic?",
        "tokens": [
          50538,
          2386,
          295,
          439,
          11,
          307,
          309,
          767,
          47329,
          452,
          3123,
          30,
          50666
        ]
      },
      {
        "avg_logprob": -0.2938269147221346,
        "compression_ratio": 1.7419354838709677,
        "end": 122.86,
        "id": 52,
        "no_speech_prob": 0.00001618546957615763,
        "seek": 11310,
        "start": 119.14,
        "temperature": 0,
        "text": " If I'm tapping on here, are you hearing like a tapping?",
        "tokens": [
          50666,
          759,
          286,
          478,
          21444,
          322,
          510,
          11,
          366,
          291,
          4763,
          411,
          257,
          21444,
          30,
          50852
        ]
      },
      {
        "avg_logprob": -0.2938269147221346,
        "compression_ratio": 1.7419354838709677,
        "end": 123.69999999999999,
        "id": 53,
        "no_speech_prob": 0.00001618546957615763,
        "seek": 11310,
        "start": 122.86,
        "temperature": 0,
        "text": " Both mics are fine.",
        "tokens": [
          50852,
          6767,
          45481,
          366,
          2489,
          13,
          50894
        ]
      },
      {
        "avg_logprob": -0.2938269147221346,
        "compression_ratio": 1.7419354838709677,
        "end": 124.82,
        "id": 54,
        "no_speech_prob": 0.00001618546957615763,
        "seek": 11310,
        "start": 123.69999999999999,
        "temperature": 0,
        "text": " I'm gonna up mine.",
        "tokens": [
          50894,
          286,
          478,
          799,
          493,
          3892,
          13,
          50950
        ]
      },
      {
        "avg_logprob": -0.2938269147221346,
        "compression_ratio": 1.7419354838709677,
        "end": 126.1,
        "id": 55,
        "no_speech_prob": 0.00001618546957615763,
        "seek": 11310,
        "start": 124.82,
        "temperature": 0,
        "text": " I'm tapping mine now.",
        "tokens": [
          50950,
          286,
          478,
          21444,
          3892,
          586,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2938269147221346,
        "compression_ratio": 1.7419354838709677,
        "end": 126.94,
        "id": 56,
        "no_speech_prob": 0.00001618546957615763,
        "seek": 11310,
        "start": 126.1,
        "temperature": 0,
        "text": " I have to tap on mine.",
        "tokens": [
          51014,
          286,
          362,
          281,
          5119,
          322,
          3892,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.2938269147221346,
        "compression_ratio": 1.7419354838709677,
        "end": 128.14,
        "id": 57,
        "no_speech_prob": 0.00001618546957615763,
        "seek": 11310,
        "start": 126.94,
        "temperature": 0,
        "text": " Because it could be I'm low",
        "tokens": [
          51056,
          1436,
          309,
          727,
          312,
          286,
          478,
          2295,
          51116
        ]
      },
      {
        "avg_logprob": -0.2938269147221346,
        "compression_ratio": 1.7419354838709677,
        "end": 130.14,
        "id": 58,
        "no_speech_prob": 0.00001618546957615763,
        "seek": 11310,
        "start": 128.14,
        "temperature": 0,
        "text": " just because they're only hearing it through your mic.",
        "tokens": [
          51116,
          445,
          570,
          436,
          434,
          787,
          4763,
          309,
          807,
          428,
          3123,
          13,
          51216
        ]
      },
      {
        "avg_logprob": -0.2938269147221346,
        "compression_ratio": 1.7419354838709677,
        "end": 131.14,
        "id": 59,
        "no_speech_prob": 0.00001618546957615763,
        "seek": 11310,
        "start": 130.14,
        "temperature": 0,
        "text": " That'd be interesting.",
        "tokens": [
          51216,
          663,
          1116,
          312,
          1880,
          13,
          51266
        ]
      },
      {
        "avg_logprob": -0.2938269147221346,
        "compression_ratio": 1.7419354838709677,
        "end": 132.42,
        "id": 60,
        "no_speech_prob": 0.00001618546957615763,
        "seek": 11310,
        "start": 131.14,
        "temperature": 0,
        "text": " No, no, it's mine's here.",
        "tokens": [
          51266,
          883,
          11,
          572,
          11,
          309,
          311,
          3892,
          311,
          510,
          13,
          51330
        ]
      },
      {
        "avg_logprob": -0.2938269147221346,
        "compression_ratio": 1.7419354838709677,
        "end": 133.92,
        "id": 61,
        "no_speech_prob": 0.00001618546957615763,
        "seek": 11310,
        "start": 132.42,
        "temperature": 0,
        "text": " I turned mine up a little bit.",
        "tokens": [
          51330,
          286,
          3574,
          3892,
          493,
          257,
          707,
          857,
          13,
          51405
        ]
      },
      {
        "avg_logprob": -0.2938269147221346,
        "compression_ratio": 1.7419354838709677,
        "end": 135.94,
        "id": 62,
        "no_speech_prob": 0.00001618546957615763,
        "seek": 11310,
        "start": 135.1,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51464,
          1033,
          13,
          51506
        ]
      },
      {
        "avg_logprob": -0.2938269147221346,
        "compression_ratio": 1.7419354838709677,
        "end": 138.5,
        "id": 63,
        "no_speech_prob": 0.00001618546957615763,
        "seek": 11310,
        "start": 137.54,
        "temperature": 0,
        "text": " I hear tapping on both.",
        "tokens": [
          51586,
          286,
          1568,
          21444,
          322,
          1293,
          13,
          51634
        ]
      },
      {
        "avg_logprob": -0.2938269147221346,
        "compression_ratio": 1.7419354838709677,
        "end": 139.38,
        "id": 64,
        "no_speech_prob": 0.00001618546957615763,
        "seek": 11310,
        "start": 138.5,
        "temperature": 0,
        "text": " I can hear you both fine.",
        "tokens": [
          51634,
          286,
          393,
          1568,
          291,
          1293,
          2489,
          13,
          51678
        ]
      },
      {
        "avg_logprob": -0.2938269147221346,
        "compression_ratio": 1.7419354838709677,
        "end": 141.42,
        "id": 65,
        "no_speech_prob": 0.00001618546957615763,
        "seek": 11310,
        "start": 139.38,
        "temperature": 0,
        "text": " Okay, hello, welcome.",
        "tokens": [
          51678,
          1033,
          11,
          7751,
          11,
          2928,
          13,
          51780
        ]
      },
      {
        "avg_logprob": -0.32054364013671877,
        "compression_ratio": 1.462882096069869,
        "end": 146.26,
        "id": 66,
        "no_speech_prob": 0.00015841881395317614,
        "seek": 14142,
        "start": 142.22,
        "temperature": 0,
        "text": " I have a very special guest here",
        "tokens": [
          50404,
          286,
          362,
          257,
          588,
          2121,
          8341,
          510,
          50606
        ]
      },
      {
        "avg_logprob": -0.32054364013671877,
        "compression_ratio": 1.462882096069869,
        "end": 147.66,
        "id": 67,
        "no_speech_prob": 0.00015841881395317614,
        "seek": 14142,
        "start": 146.26,
        "temperature": 0,
        "text": " in the Coding Train studio.",
        "tokens": [
          50606,
          294,
          264,
          383,
          8616,
          28029,
          6811,
          13,
          50676
        ]
      },
      {
        "avg_logprob": -0.32054364013671877,
        "compression_ratio": 1.462882096069869,
        "end": 149.94,
        "id": 68,
        "no_speech_prob": 0.00015841881395317614,
        "seek": 14142,
        "start": 147.66,
        "temperature": 0,
        "text": " I'm gonna cut to a special guest.",
        "tokens": [
          50676,
          286,
          478,
          799,
          1723,
          281,
          257,
          2121,
          8341,
          13,
          50790
        ]
      },
      {
        "avg_logprob": -0.32054364013671877,
        "compression_ratio": 1.462882096069869,
        "end": 151.01999999999998,
        "id": 69,
        "no_speech_prob": 0.00015841881395317614,
        "seek": 14142,
        "start": 149.94,
        "temperature": 0,
        "text": " Welcome to Jabril.",
        "tokens": [
          50790,
          4027,
          281,
          40319,
          24216,
          13,
          50844
        ]
      },
      {
        "avg_logprob": -0.32054364013671877,
        "compression_ratio": 1.462882096069869,
        "end": 155.95999999999998,
        "id": 70,
        "no_speech_prob": 0.00015841881395317614,
        "seek": 14142,
        "start": 152.26,
        "temperature": 0,
        "text": " If you're not familiar with Jabril's YouTube channel,",
        "tokens": [
          50906,
          759,
          291,
          434,
          406,
          4963,
          365,
          40319,
          24216,
          311,
          3088,
          2269,
          11,
          51091
        ]
      },
      {
        "avg_logprob": -0.32054364013671877,
        "compression_ratio": 1.462882096069869,
        "end": 161.38,
        "id": 71,
        "no_speech_prob": 0.00015841881395317614,
        "seek": 14142,
        "start": 157.33999999999997,
        "temperature": 0,
        "text": " I probably just Googled J-A-B-R-I-L-S on YouTube.",
        "tokens": [
          51160,
          286,
          1391,
          445,
          45005,
          1493,
          508,
          12,
          32,
          12,
          33,
          12,
          49,
          12,
          40,
          12,
          43,
          12,
          50,
          322,
          3088,
          13,
          51362
        ]
      },
      {
        "avg_logprob": -0.32054364013671877,
        "compression_ratio": 1.462882096069869,
        "end": 163.33999999999997,
        "id": 72,
        "no_speech_prob": 0.00015841881395317614,
        "seek": 14142,
        "start": 161.38,
        "temperature": 0,
        "text": " It's also, I learned how to say it now.",
        "tokens": [
          51362,
          467,
          311,
          611,
          11,
          286,
          3264,
          577,
          281,
          584,
          309,
          586,
          13,
          51460
        ]
      },
      {
        "avg_logprob": -0.32054364013671877,
        "compression_ratio": 1.462882096069869,
        "end": 166.29999999999998,
        "id": 73,
        "no_speech_prob": 0.00015841881395317614,
        "seek": 14142,
        "start": 164.22,
        "temperature": 0,
        "text": " F stuff, Seth stuff.",
        "tokens": [
          51504,
          479,
          1507,
          11,
          25353,
          1507,
          13,
          51608
        ]
      },
      {
        "avg_logprob": -0.32054364013671877,
        "compression_ratio": 1.462882096069869,
        "end": 167.14,
        "id": 74,
        "no_speech_prob": 0.00015841881395317614,
        "seek": 14142,
        "start": 166.29999999999998,
        "temperature": 0,
        "text": " You're wrong.",
        "tokens": [
          51608,
          509,
          434,
          2085,
          13,
          51650
        ]
      },
      {
        "avg_logprob": -0.32054364013671877,
        "compression_ratio": 1.462882096069869,
        "end": 167.98,
        "id": 75,
        "no_speech_prob": 0.00015841881395317614,
        "seek": 14142,
        "start": 167.14,
        "temperature": 0,
        "text": " No, I'm joking.",
        "tokens": [
          51650,
          883,
          11,
          286,
          478,
          17396,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.32054364013671877,
        "compression_ratio": 1.462882096069869,
        "end": 170.26,
        "id": 76,
        "no_speech_prob": 0.00015841881395317614,
        "seek": 14142,
        "start": 167.98,
        "temperature": 0,
        "text": " Seth stuff, S-E-F-D stuff.",
        "tokens": [
          51692,
          25353,
          1507,
          11,
          318,
          12,
          36,
          12,
          37,
          12,
          35,
          1507,
          13,
          51806
        ]
      },
      {
        "avg_logprob": -0.2889580529583387,
        "compression_ratio": 1.6223776223776223,
        "end": 174.22,
        "id": 77,
        "no_speech_prob": 0.000021764271878055297,
        "seek": 17026,
        "start": 171.17999999999998,
        "temperature": 0,
        "text": " On YouTube, Jabril has been teaching himself",
        "tokens": [
          50410,
          1282,
          3088,
          11,
          40319,
          24216,
          575,
          668,
          4571,
          3647,
          50562
        ]
      },
      {
        "avg_logprob": -0.2889580529583387,
        "compression_ratio": 1.6223776223776223,
        "end": 178.98,
        "id": 78,
        "no_speech_prob": 0.000021764271878055297,
        "seek": 17026,
        "start": 174.22,
        "temperature": 0,
        "text": " machine learning for the last, around nine months.",
        "tokens": [
          50562,
          3479,
          2539,
          337,
          264,
          1036,
          11,
          926,
          4949,
          2493,
          13,
          50800
        ]
      },
      {
        "avg_logprob": -0.2889580529583387,
        "compression_ratio": 1.6223776223776223,
        "end": 181.89999999999998,
        "id": 79,
        "no_speech_prob": 0.000021764271878055297,
        "seek": 17026,
        "start": 178.98,
        "temperature": 0,
        "text": " And has discovered and made all sorts of exciting",
        "tokens": [
          50800,
          400,
          575,
          6941,
          293,
          1027,
          439,
          7527,
          295,
          4670,
          50946
        ]
      },
      {
        "avg_logprob": -0.2889580529583387,
        "compression_ratio": 1.6223776223776223,
        "end": 183.26,
        "id": 80,
        "no_speech_prob": 0.000021764271878055297,
        "seek": 17026,
        "start": 181.89999999999998,
        "temperature": 0,
        "text": " and interesting projects.",
        "tokens": [
          50946,
          293,
          1880,
          4455,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2889580529583387,
        "compression_ratio": 1.6223776223776223,
        "end": 185.94,
        "id": 81,
        "no_speech_prob": 0.000021764271878055297,
        "seek": 17026,
        "start": 183.26,
        "temperature": 0,
        "text": " Has made a bunch of videos about those projects.",
        "tokens": [
          51014,
          8646,
          1027,
          257,
          3840,
          295,
          2145,
          466,
          729,
          4455,
          13,
          51148
        ]
      },
      {
        "avg_logprob": -0.2889580529583387,
        "compression_ratio": 1.6223776223776223,
        "end": 187.54,
        "id": 82,
        "no_speech_prob": 0.000021764271878055297,
        "seek": 17026,
        "start": 185.94,
        "temperature": 0,
        "text": " Happened to be in New York this week.",
        "tokens": [
          51148,
          7412,
          5320,
          281,
          312,
          294,
          1873,
          3609,
          341,
          1243,
          13,
          51228
        ]
      },
      {
        "avg_logprob": -0.2889580529583387,
        "compression_ratio": 1.6223776223776223,
        "end": 190.42,
        "id": 83,
        "no_speech_prob": 0.000021764271878055297,
        "seek": 17026,
        "start": 187.54,
        "temperature": 0,
        "text": " Is actually doing a short term residency at ITP,",
        "tokens": [
          51228,
          1119,
          767,
          884,
          257,
          2099,
          1433,
          34014,
          412,
          6783,
          47,
          11,
          51372
        ]
      },
      {
        "avg_logprob": -0.2889580529583387,
        "compression_ratio": 1.6223776223776223,
        "end": 191.82,
        "id": 84,
        "no_speech_prob": 0.000021764271878055297,
        "seek": 17026,
        "start": 190.42,
        "temperature": 0,
        "text": " which is a program where I teach.",
        "tokens": [
          51372,
          597,
          307,
          257,
          1461,
          689,
          286,
          2924,
          13,
          51442
        ]
      },
      {
        "avg_logprob": -0.2889580529583387,
        "compression_ratio": 1.6223776223776223,
        "end": 193.34,
        "id": 85,
        "no_speech_prob": 0.000021764271878055297,
        "seek": 17026,
        "start": 191.82,
        "temperature": 0,
        "text": " And has taught a workshop here this week",
        "tokens": [
          51442,
          400,
          575,
          5928,
          257,
          13541,
          510,
          341,
          1243,
          51518
        ]
      },
      {
        "avg_logprob": -0.2889580529583387,
        "compression_ratio": 1.6223776223776223,
        "end": 194.92,
        "id": 86,
        "no_speech_prob": 0.000021764271878055297,
        "seek": 17026,
        "start": 193.34,
        "temperature": 0,
        "text": " and gave a presentation on his work.",
        "tokens": [
          51518,
          293,
          2729,
          257,
          5860,
          322,
          702,
          589,
          13,
          51597
        ]
      },
      {
        "avg_logprob": -0.2889580529583387,
        "compression_ratio": 1.6223776223776223,
        "end": 198.06,
        "id": 87,
        "no_speech_prob": 0.000021764271878055297,
        "seek": 17026,
        "start": 194.92,
        "temperature": 0,
        "text": " So it's Friday afternoon, coding train time.",
        "tokens": [
          51597,
          407,
          309,
          311,
          6984,
          6499,
          11,
          17720,
          3847,
          565,
          13,
          51754
        ]
      },
      {
        "avg_logprob": -0.246795688356672,
        "compression_ratio": 1.6292134831460674,
        "end": 203.18,
        "id": 88,
        "no_speech_prob": 0.000021097495846333914,
        "seek": 19806,
        "start": 199.06,
        "temperature": 0,
        "text": " And so, I thought I would bring him here",
        "tokens": [
          50414,
          400,
          370,
          11,
          286,
          1194,
          286,
          576,
          1565,
          796,
          510,
          50620
        ]
      },
      {
        "avg_logprob": -0.246795688356672,
        "compression_ratio": 1.6292134831460674,
        "end": 205.52,
        "id": 89,
        "no_speech_prob": 0.000021097495846333914,
        "seek": 19806,
        "start": 203.18,
        "temperature": 0,
        "text": " to talk about a new project that he's making.",
        "tokens": [
          50620,
          281,
          751,
          466,
          257,
          777,
          1716,
          300,
          415,
          311,
          1455,
          13,
          50737
        ]
      },
      {
        "avg_logprob": -0.246795688356672,
        "compression_ratio": 1.6292134831460674,
        "end": 208.72,
        "id": 90,
        "no_speech_prob": 0.000021097495846333914,
        "seek": 19806,
        "start": 205.52,
        "temperature": 0,
        "text": " So before I get to that, let me just do some housekeeping.",
        "tokens": [
          50737,
          407,
          949,
          286,
          483,
          281,
          300,
          11,
          718,
          385,
          445,
          360,
          512,
          48033,
          13,
          50897
        ]
      },
      {
        "avg_logprob": -0.246795688356672,
        "compression_ratio": 1.6292134831460674,
        "end": 212.42000000000002,
        "id": 91,
        "no_speech_prob": 0.000021097495846333914,
        "seek": 19806,
        "start": 209.98,
        "temperature": 0,
        "text": " Today is going to be a shorter livestream than usual.",
        "tokens": [
          50960,
          2692,
          307,
          516,
          281,
          312,
          257,
          11639,
          29782,
          813,
          7713,
          13,
          51082
        ]
      },
      {
        "avg_logprob": -0.246795688356672,
        "compression_ratio": 1.6292134831460674,
        "end": 216.02,
        "id": 92,
        "no_speech_prob": 0.000021097495846333914,
        "seek": 19806,
        "start": 212.42000000000002,
        "temperature": 0,
        "text": " There won't be any coding challenges or tutorials from me.",
        "tokens": [
          51082,
          821,
          1582,
          380,
          312,
          604,
          17720,
          4759,
          420,
          17616,
          490,
          385,
          13,
          51262
        ]
      },
      {
        "avg_logprob": -0.246795688356672,
        "compression_ratio": 1.6292134831460674,
        "end": 218.38,
        "id": 93,
        "no_speech_prob": 0.000021097495846333914,
        "seek": 19806,
        "start": 216.02,
        "temperature": 0,
        "text": " I hope to make that up with a bonus livestream",
        "tokens": [
          51262,
          286,
          1454,
          281,
          652,
          300,
          493,
          365,
          257,
          10882,
          29782,
          51380
        ]
      },
      {
        "avg_logprob": -0.246795688356672,
        "compression_ratio": 1.6292134831460674,
        "end": 219.96,
        "id": 94,
        "no_speech_prob": 0.000021097495846333914,
        "seek": 19806,
        "start": 218.38,
        "temperature": 0,
        "text": " next week or the week after.",
        "tokens": [
          51380,
          958,
          1243,
          420,
          264,
          1243,
          934,
          13,
          51459
        ]
      },
      {
        "avg_logprob": -0.246795688356672,
        "compression_ratio": 1.6292134831460674,
        "end": 224.64000000000001,
        "id": 95,
        "no_speech_prob": 0.000021097495846333914,
        "seek": 19806,
        "start": 221.7,
        "temperature": 0,
        "text": " But happy whatever holidays that are happening today",
        "tokens": [
          51546,
          583,
          2055,
          2035,
          15734,
          300,
          366,
          2737,
          965,
          51693
        ]
      },
      {
        "avg_logprob": -0.246795688356672,
        "compression_ratio": 1.6292134831460674,
        "end": 226.7,
        "id": 96,
        "no_speech_prob": 0.000021097495846333914,
        "seek": 19806,
        "start": 224.64000000000001,
        "temperature": 0,
        "text": " and this weekend that you might be celebrating.",
        "tokens": [
          51693,
          293,
          341,
          6711,
          300,
          291,
          1062,
          312,
          15252,
          13,
          51796
        ]
      },
      {
        "avg_logprob": -0.3123453313654119,
        "compression_ratio": 1.603864734299517,
        "end": 229.14,
        "id": 97,
        "no_speech_prob": 0.000005952471383352531,
        "seek": 22670,
        "start": 226.7,
        "temperature": 0,
        "text": " I have to catch a train in a couple hours.",
        "tokens": [
          50364,
          286,
          362,
          281,
          3745,
          257,
          3847,
          294,
          257,
          1916,
          2496,
          13,
          50486
        ]
      },
      {
        "avg_logprob": -0.3123453313654119,
        "compression_ratio": 1.603864734299517,
        "end": 232.85999999999999,
        "id": 98,
        "no_speech_prob": 0.000005952471383352531,
        "seek": 22670,
        "start": 229.14,
        "temperature": 0,
        "text": " So, it's funny how I have to catch an actual",
        "tokens": [
          50486,
          407,
          11,
          309,
          311,
          4074,
          577,
          286,
          362,
          281,
          3745,
          364,
          3539,
          50672
        ]
      },
      {
        "avg_logprob": -0.3123453313654119,
        "compression_ratio": 1.603864734299517,
        "end": 235.56,
        "id": 99,
        "no_speech_prob": 0.000005952471383352531,
        "seek": 22670,
        "start": 232.85999999999999,
        "temperature": 0,
        "text": " real life train in a couple hours to head out of town.",
        "tokens": [
          50672,
          957,
          993,
          3847,
          294,
          257,
          1916,
          2496,
          281,
          1378,
          484,
          295,
          3954,
          13,
          50807
        ]
      },
      {
        "avg_logprob": -0.3123453313654119,
        "compression_ratio": 1.603864734299517,
        "end": 241.66,
        "id": 100,
        "no_speech_prob": 0.000005952471383352531,
        "seek": 22670,
        "start": 236.66,
        "temperature": 0,
        "text": " So, this is just gonna be a guest session.",
        "tokens": [
          50862,
          407,
          11,
          341,
          307,
          445,
          799,
          312,
          257,
          8341,
          5481,
          13,
          51112
        ]
      },
      {
        "avg_logprob": -0.3123453313654119,
        "compression_ratio": 1.603864734299517,
        "end": 245.1,
        "id": 101,
        "no_speech_prob": 0.000005952471383352531,
        "seek": 22670,
        "start": 242.45999999999998,
        "temperature": 0,
        "text": " I will say though that if you don't subscribe,",
        "tokens": [
          51152,
          286,
          486,
          584,
          1673,
          300,
          498,
          291,
          500,
          380,
          3022,
          11,
          51284
        ]
      },
      {
        "avg_logprob": -0.3123453313654119,
        "compression_ratio": 1.603864734299517,
        "end": 248.54,
        "id": 102,
        "no_speech_prob": 0.000005952471383352531,
        "seek": 22670,
        "start": 245.1,
        "temperature": 0,
        "text": " I don't know why I'm pretending I don't have a computer here.",
        "tokens": [
          51284,
          286,
          500,
          380,
          458,
          983,
          286,
          478,
          22106,
          286,
          500,
          380,
          362,
          257,
          3820,
          510,
          13,
          51456
        ]
      },
      {
        "avg_logprob": -0.3123453313654119,
        "compression_ratio": 1.603864734299517,
        "end": 253.54,
        "id": 103,
        "no_speech_prob": 0.000005952471383352531,
        "seek": 22670,
        "start": 248.54,
        "temperature": 0,
        "text": " YouTube, let's search for Seth Stuff.",
        "tokens": [
          51456,
          3088,
          11,
          718,
          311,
          3164,
          337,
          25353,
          31347,
          13,
          51706
        ]
      },
      {
        "avg_logprob": -0.3574454152685964,
        "compression_ratio": 1.6401673640167365,
        "end": 258.53999999999996,
        "id": 104,
        "no_speech_prob": 0.00003822635335382074,
        "seek": 25354,
        "start": 253.54,
        "temperature": 0,
        "text": " So this is, hey you have two YouTube channels.",
        "tokens": [
          50364,
          407,
          341,
          307,
          11,
          4177,
          291,
          362,
          732,
          3088,
          9235,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.3574454152685964,
        "compression_ratio": 1.6401673640167365,
        "end": 261.86,
        "id": 105,
        "no_speech_prob": 0.00003822635335382074,
        "seek": 25354,
        "start": 258.62,
        "temperature": 0,
        "text": " I have a million channels to be honest.",
        "tokens": [
          50618,
          286,
          362,
          257,
          2459,
          9235,
          281,
          312,
          3245,
          13,
          50780
        ]
      },
      {
        "avg_logprob": -0.3574454152685964,
        "compression_ratio": 1.6401673640167365,
        "end": 264.26,
        "id": 106,
        "no_speech_prob": 0.00003822635335382074,
        "seek": 25354,
        "start": 261.86,
        "temperature": 0,
        "text": " I kind of knew that but I forgot about that.",
        "tokens": [
          50780,
          286,
          733,
          295,
          2586,
          300,
          457,
          286,
          5298,
          466,
          300,
          13,
          50900
        ]
      },
      {
        "avg_logprob": -0.3574454152685964,
        "compression_ratio": 1.6401673640167365,
        "end": 266.38,
        "id": 107,
        "no_speech_prob": 0.00003822635335382074,
        "seek": 25354,
        "start": 264.26,
        "temperature": 0,
        "text": " Do you work on all of them still?",
        "tokens": [
          50900,
          1144,
          291,
          589,
          322,
          439,
          295,
          552,
          920,
          30,
          51006
        ]
      },
      {
        "avg_logprob": -0.3574454152685964,
        "compression_ratio": 1.6401673640167365,
        "end": 268.53999999999996,
        "id": 108,
        "no_speech_prob": 0.00003822635335382074,
        "seek": 25354,
        "start": 266.38,
        "temperature": 0,
        "text": " So this is the one you're actively maintaining still.",
        "tokens": [
          51006,
          407,
          341,
          307,
          264,
          472,
          291,
          434,
          13022,
          14916,
          920,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.3574454152685964,
        "compression_ratio": 1.6401673640167365,
        "end": 269.46,
        "id": 109,
        "no_speech_prob": 0.00003822635335382074,
        "seek": 25354,
        "start": 268.53999999999996,
        "temperature": 0,
        "text": " Just this one.",
        "tokens": [
          51114,
          1449,
          341,
          472,
          13,
          51160
        ]
      },
      {
        "avg_logprob": -0.3574454152685964,
        "compression_ratio": 1.6401673640167365,
        "end": 272.65999999999997,
        "id": 110,
        "no_speech_prob": 0.00003822635335382074,
        "seek": 25354,
        "start": 269.46,
        "temperature": 0,
        "text": " So this is Jabril's YouTube channel.",
        "tokens": [
          51160,
          407,
          341,
          307,
          40319,
          24216,
          311,
          3088,
          2269,
          13,
          51320
        ]
      },
      {
        "avg_logprob": -0.3574454152685964,
        "compression_ratio": 1.6401673640167365,
        "end": 276.21999999999997,
        "id": 111,
        "no_speech_prob": 0.00003822635335382074,
        "seek": 25354,
        "start": 272.65999999999997,
        "temperature": 0,
        "text": " And you can see, just memorize this channel ID,",
        "tokens": [
          51320,
          400,
          291,
          393,
          536,
          11,
          445,
          27478,
          341,
          2269,
          7348,
          11,
          51498
        ]
      },
      {
        "avg_logprob": -0.3574454152685964,
        "compression_ratio": 1.6401673640167365,
        "end": 277.09999999999997,
        "id": 112,
        "no_speech_prob": 0.00003822635335382074,
        "seek": 25354,
        "start": 276.21999999999997,
        "temperature": 0,
        "text": " I'll read it to you.",
        "tokens": [
          51498,
          286,
          603,
          1401,
          309,
          281,
          291,
          13,
          51542
        ]
      },
      {
        "avg_logprob": -0.3574454152685964,
        "compression_ratio": 1.6401673640167365,
        "end": 281.21999999999997,
        "id": 113,
        "no_speech_prob": 0.00003822635335382074,
        "seek": 25354,
        "start": 277.09999999999997,
        "temperature": 0,
        "text": " Capital U, capital C, getting this down, capital Q.",
        "tokens": [
          51542,
          21502,
          624,
          11,
          4238,
          383,
          11,
          1242,
          341,
          760,
          11,
          4238,
          1249,
          13,
          51748
        ]
      },
      {
        "avg_logprob": -0.2716208237868089,
        "compression_ratio": 1.7007575757575757,
        "end": 283.58000000000004,
        "id": 114,
        "no_speech_prob": 0.00022340430587064475,
        "seek": 28122,
        "start": 281.22,
        "temperature": 0,
        "text": " Oh, you're cheating on your numbers book today.",
        "tokens": [
          50364,
          876,
          11,
          291,
          434,
          18309,
          322,
          428,
          3547,
          1446,
          965,
          13,
          50482
        ]
      },
      {
        "avg_logprob": -0.2716208237868089,
        "compression_ratio": 1.7007575757575757,
        "end": 286.5,
        "id": 115,
        "no_speech_prob": 0.00022340430587064475,
        "seek": 28122,
        "start": 283.58000000000004,
        "temperature": 0,
        "text": " Oh yeah, we're gonna have you read some random numbers.",
        "tokens": [
          50482,
          876,
          1338,
          11,
          321,
          434,
          799,
          362,
          291,
          1401,
          512,
          4974,
          3547,
          13,
          50628
        ]
      },
      {
        "avg_logprob": -0.2716208237868089,
        "compression_ratio": 1.7007575757575757,
        "end": 290.34000000000003,
        "id": 116,
        "no_speech_prob": 0.00022340430587064475,
        "seek": 28122,
        "start": 288.38000000000005,
        "temperature": 0,
        "text": " So, what was I saying?",
        "tokens": [
          50722,
          407,
          11,
          437,
          390,
          286,
          1566,
          30,
          50820
        ]
      },
      {
        "avg_logprob": -0.2716208237868089,
        "compression_ratio": 1.7007575757575757,
        "end": 291.90000000000003,
        "id": 117,
        "no_speech_prob": 0.00022340430587064475,
        "seek": 28122,
        "start": 290.34000000000003,
        "temperature": 0,
        "text": " So you should definitely subscribe.",
        "tokens": [
          50820,
          407,
          291,
          820,
          2138,
          3022,
          13,
          50898
        ]
      },
      {
        "avg_logprob": -0.2716208237868089,
        "compression_ratio": 1.7007575757575757,
        "end": 293.98,
        "id": 118,
        "no_speech_prob": 0.00022340430587064475,
        "seek": 28122,
        "start": 291.90000000000003,
        "temperature": 0,
        "text": " You should click, look, oh I'm gonna subscribe.",
        "tokens": [
          50898,
          509,
          820,
          2052,
          11,
          574,
          11,
          1954,
          286,
          478,
          799,
          3022,
          13,
          51002
        ]
      },
      {
        "avg_logprob": -0.2716208237868089,
        "compression_ratio": 1.7007575757575757,
        "end": 296.22,
        "id": 119,
        "no_speech_prob": 0.00022340430587064475,
        "seek": 28122,
        "start": 293.98,
        "temperature": 0,
        "text": " So the reason why I'm not subscribed",
        "tokens": [
          51002,
          407,
          264,
          1778,
          983,
          286,
          478,
          406,
          16665,
          51114
        ]
      },
      {
        "avg_logprob": -0.2716208237868089,
        "compression_ratio": 1.7007575757575757,
        "end": 298.5,
        "id": 120,
        "no_speech_prob": 0.00022340430587064475,
        "seek": 28122,
        "start": 296.22,
        "temperature": 0,
        "text": " is not because I'm not subscribed.",
        "tokens": [
          51114,
          307,
          406,
          570,
          286,
          478,
          406,
          16665,
          13,
          51228
        ]
      },
      {
        "avg_logprob": -0.2716208237868089,
        "compression_ratio": 1.7007575757575757,
        "end": 301.18,
        "id": 121,
        "no_speech_prob": 0.00022340430587064475,
        "seek": 28122,
        "start": 298.5,
        "temperature": 0,
        "text": " It's because this is a fake account",
        "tokens": [
          51228,
          467,
          311,
          570,
          341,
          307,
          257,
          7592,
          2696,
          51362
        ]
      },
      {
        "avg_logprob": -0.2716208237868089,
        "compression_ratio": 1.7007575757575757,
        "end": 303.58000000000004,
        "id": 122,
        "no_speech_prob": 0.00022340430587064475,
        "seek": 28122,
        "start": 301.18,
        "temperature": 0,
        "text": " that I set up just, that I bought YouTube Red with",
        "tokens": [
          51362,
          300,
          286,
          992,
          493,
          445,
          11,
          300,
          286,
          4243,
          3088,
          4477,
          365,
          51482
        ]
      },
      {
        "avg_logprob": -0.2716208237868089,
        "compression_ratio": 1.7007575757575757,
        "end": 306.02000000000004,
        "id": 123,
        "no_speech_prob": 0.00022340430587064475,
        "seek": 28122,
        "start": 303.58000000000004,
        "temperature": 0,
        "text": " so that if I look at stuff on YouTube on my live stream,",
        "tokens": [
          51482,
          370,
          300,
          498,
          286,
          574,
          412,
          1507,
          322,
          3088,
          322,
          452,
          1621,
          4309,
          11,
          51604
        ]
      },
      {
        "avg_logprob": -0.2716208237868089,
        "compression_ratio": 1.7007575757575757,
        "end": 307.28000000000003,
        "id": 124,
        "no_speech_prob": 0.00022340430587064475,
        "seek": 28122,
        "start": 306.02000000000004,
        "temperature": 0,
        "text": " the ads don't show up.",
        "tokens": [
          51604,
          264,
          10342,
          500,
          380,
          855,
          493,
          13,
          51667
        ]
      },
      {
        "avg_logprob": -0.2526259712550951,
        "compression_ratio": 1.7118644067796611,
        "end": 312.28,
        "id": 125,
        "no_speech_prob": 0.000013840929568686988,
        "seek": 30728,
        "start": 307.28,
        "temperature": 0,
        "text": " It's also a YouTube channel,",
        "tokens": [
          50364,
          467,
          311,
          611,
          257,
          3088,
          2269,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.2526259712550951,
        "compression_ratio": 1.7118644067796611,
        "end": 315.67999999999995,
        "id": 126,
        "no_speech_prob": 0.000013840929568686988,
        "seek": 30728,
        "start": 313,
        "temperature": 0,
        "text": " an account that my kids use when they watch YouTube",
        "tokens": [
          50650,
          364,
          2696,
          300,
          452,
          2301,
          764,
          562,
          436,
          1159,
          3088,
          50784
        ]
      },
      {
        "avg_logprob": -0.2526259712550951,
        "compression_ratio": 1.7118644067796611,
        "end": 320.67999999999995,
        "id": 127,
        "no_speech_prob": 0.000013840929568686988,
        "seek": 30728,
        "start": 315.67999999999995,
        "temperature": 0,
        "text": " because I don't want them to have to watch the ads either",
        "tokens": [
          50784,
          570,
          286,
          500,
          380,
          528,
          552,
          281,
          362,
          281,
          1159,
          264,
          10342,
          2139,
          51034
        ]
      },
      {
        "avg_logprob": -0.2526259712550951,
        "compression_ratio": 1.7118644067796611,
        "end": 323.44,
        "id": 128,
        "no_speech_prob": 0.000013840929568686988,
        "seek": 30728,
        "start": 320.67999999999995,
        "temperature": 0,
        "text": " so you can see what kind of videos they like to watch.",
        "tokens": [
          51034,
          370,
          291,
          393,
          536,
          437,
          733,
          295,
          2145,
          436,
          411,
          281,
          1159,
          13,
          51172
        ]
      },
      {
        "avg_logprob": -0.2526259712550951,
        "compression_ratio": 1.7118644067796611,
        "end": 327.88,
        "id": 129,
        "no_speech_prob": 0.000013840929568686988,
        "seek": 30728,
        "start": 324.67999999999995,
        "temperature": 0,
        "text": " And look, Jabril's visits the coding train.",
        "tokens": [
          51234,
          400,
          574,
          11,
          40319,
          24216,
          311,
          17753,
          264,
          17720,
          3847,
          13,
          51394
        ]
      },
      {
        "avg_logprob": -0.2526259712550951,
        "compression_ratio": 1.7118644067796611,
        "end": 330.67999999999995,
        "id": 130,
        "no_speech_prob": 0.000013840929568686988,
        "seek": 30728,
        "start": 327.88,
        "temperature": 0,
        "text": " Now let me go back and I'm gonna give you a clue here.",
        "tokens": [
          51394,
          823,
          718,
          385,
          352,
          646,
          293,
          286,
          478,
          799,
          976,
          291,
          257,
          13602,
          510,
          13,
          51534
        ]
      },
      {
        "avg_logprob": -0.2526259712550951,
        "compression_ratio": 1.7118644067796611,
        "end": 331.76,
        "id": 131,
        "no_speech_prob": 0.000013840929568686988,
        "seek": 30728,
        "start": 330.67999999999995,
        "temperature": 0,
        "text": " You're gonna, what you're gonna wanna do",
        "tokens": [
          51534,
          509,
          434,
          799,
          11,
          437,
          291,
          434,
          799,
          1948,
          360,
          51588
        ]
      },
      {
        "avg_logprob": -0.2526259712550951,
        "compression_ratio": 1.7118644067796611,
        "end": 333.35999999999996,
        "id": 132,
        "no_speech_prob": 0.000013840929568686988,
        "seek": 30728,
        "start": 331.76,
        "temperature": 0,
        "text": " is you're gonna go to his channel,",
        "tokens": [
          51588,
          307,
          291,
          434,
          799,
          352,
          281,
          702,
          2269,
          11,
          51668
        ]
      },
      {
        "avg_logprob": -0.2526259712550951,
        "compression_ratio": 1.7118644067796611,
        "end": 335.4,
        "id": 133,
        "no_speech_prob": 0.000013840929568686988,
        "seek": 30728,
        "start": 333.35999999999996,
        "temperature": 0,
        "text": " you're gonna wanna click subscribe,",
        "tokens": [
          51668,
          291,
          434,
          799,
          1948,
          2052,
          3022,
          11,
          51770
        ]
      },
      {
        "avg_logprob": -0.2392145416440343,
        "compression_ratio": 1.9185667752442996,
        "end": 338.47999999999996,
        "id": 134,
        "no_speech_prob": 0.00003822371945716441,
        "seek": 33540,
        "start": 335.4,
        "temperature": 0,
        "text": " then you're gonna wanna click this alarm bell.",
        "tokens": [
          50364,
          550,
          291,
          434,
          799,
          1948,
          2052,
          341,
          14183,
          4549,
          13,
          50518
        ]
      },
      {
        "avg_logprob": -0.2392145416440343,
        "compression_ratio": 1.9185667752442996,
        "end": 339.84,
        "id": 135,
        "no_speech_prob": 0.00003822371945716441,
        "seek": 33540,
        "start": 338.47999999999996,
        "temperature": 0,
        "text": " I learned about this today.",
        "tokens": [
          50518,
          286,
          3264,
          466,
          341,
          965,
          13,
          50586
        ]
      },
      {
        "avg_logprob": -0.2392145416440343,
        "compression_ratio": 1.9185667752442996,
        "end": 340.84,
        "id": 136,
        "no_speech_prob": 0.00003822371945716441,
        "seek": 33540,
        "start": 339.84,
        "temperature": 0,
        "text": " Actually, I already knew about this.",
        "tokens": [
          50586,
          5135,
          11,
          286,
          1217,
          2586,
          466,
          341,
          13,
          50636
        ]
      },
      {
        "avg_logprob": -0.2392145416440343,
        "compression_ratio": 1.9185667752442996,
        "end": 342.2,
        "id": 137,
        "no_speech_prob": 0.00003822371945716441,
        "seek": 33540,
        "start": 340.84,
        "temperature": 0,
        "text": " But the alarm bell's gonna,",
        "tokens": [
          50636,
          583,
          264,
          14183,
          4549,
          311,
          799,
          11,
          50704
        ]
      },
      {
        "avg_logprob": -0.2392145416440343,
        "compression_ratio": 1.9185667752442996,
        "end": 343.88,
        "id": 138,
        "no_speech_prob": 0.00003822371945716441,
        "seek": 33540,
        "start": 342.2,
        "temperature": 0,
        "text": " you could do this with my channel too if you want.",
        "tokens": [
          50704,
          291,
          727,
          360,
          341,
          365,
          452,
          2269,
          886,
          498,
          291,
          528,
          13,
          50788
        ]
      },
      {
        "avg_logprob": -0.2392145416440343,
        "compression_ratio": 1.9185667752442996,
        "end": 345.03999999999996,
        "id": 139,
        "no_speech_prob": 0.00003822371945716441,
        "seek": 33540,
        "start": 343.88,
        "temperature": 0,
        "text": " I guess you're probably already subscribed",
        "tokens": [
          50788,
          286,
          2041,
          291,
          434,
          1391,
          1217,
          16665,
          50846
        ]
      },
      {
        "avg_logprob": -0.2392145416440343,
        "compression_ratio": 1.9185667752442996,
        "end": 345.88,
        "id": 140,
        "no_speech_prob": 0.00003822371945716441,
        "seek": 33540,
        "start": 345.03999999999996,
        "temperature": 0,
        "text": " if you're watching.",
        "tokens": [
          50846,
          498,
          291,
          434,
          1976,
          13,
          50888
        ]
      },
      {
        "avg_logprob": -0.2392145416440343,
        "compression_ratio": 1.9185667752442996,
        "end": 347.21999999999997,
        "id": 141,
        "no_speech_prob": 0.00003822371945716441,
        "seek": 33540,
        "start": 345.88,
        "temperature": 0,
        "text": " But it'll give you a,",
        "tokens": [
          50888,
          583,
          309,
          603,
          976,
          291,
          257,
          11,
          50955
        ]
      },
      {
        "avg_logprob": -0.2392145416440343,
        "compression_ratio": 1.9185667752442996,
        "end": 351.03999999999996,
        "id": 142,
        "no_speech_prob": 0.00003822371945716441,
        "seek": 33540,
        "start": 349.23999999999995,
        "temperature": 0,
        "text": " it will give you a notification",
        "tokens": [
          51056,
          309,
          486,
          976,
          291,
          257,
          11554,
          51146
        ]
      },
      {
        "avg_logprob": -0.2392145416440343,
        "compression_ratio": 1.9185667752442996,
        "end": 352.12,
        "id": 143,
        "no_speech_prob": 0.00003822371945716441,
        "seek": 33540,
        "start": 351.03999999999996,
        "temperature": 0,
        "text": " as soon as there's a new video",
        "tokens": [
          51146,
          382,
          2321,
          382,
          456,
          311,
          257,
          777,
          960,
          51200
        ]
      },
      {
        "avg_logprob": -0.2392145416440343,
        "compression_ratio": 1.9185667752442996,
        "end": 353.91999999999996,
        "id": 144,
        "no_speech_prob": 0.00003822371945716441,
        "seek": 33540,
        "start": 352.12,
        "temperature": 0,
        "text": " and the reason why you might wanna do this",
        "tokens": [
          51200,
          293,
          264,
          1778,
          983,
          291,
          1062,
          1948,
          360,
          341,
          51290
        ]
      },
      {
        "avg_logprob": -0.2392145416440343,
        "compression_ratio": 1.9185667752442996,
        "end": 358.91999999999996,
        "id": 145,
        "no_speech_prob": 0.00003822371945716441,
        "seek": 33540,
        "start": 353.91999999999996,
        "temperature": 0,
        "text": " is there's, Jabril will be publishing a new video on Sunday",
        "tokens": [
          51290,
          307,
          456,
          311,
          11,
          40319,
          24216,
          486,
          312,
          17832,
          257,
          777,
          960,
          322,
          7776,
          51540
        ]
      },
      {
        "avg_logprob": -0.2392145416440343,
        "compression_ratio": 1.9185667752442996,
        "end": 360.4,
        "id": 146,
        "no_speech_prob": 0.00003822371945716441,
        "seek": 33540,
        "start": 359.12,
        "temperature": 0,
        "text": " that I think you're gonna wanna watch.",
        "tokens": [
          51550,
          300,
          286,
          519,
          291,
          434,
          799,
          1948,
          1159,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2392145416440343,
        "compression_ratio": 1.9185667752442996,
        "end": 361.47999999999996,
        "id": 147,
        "no_speech_prob": 0.00003822371945716441,
        "seek": 33540,
        "start": 360.4,
        "temperature": 0,
        "text": " That's all I'm gonna say about it.",
        "tokens": [
          51614,
          663,
          311,
          439,
          286,
          478,
          799,
          584,
          466,
          309,
          13,
          51668
        ]
      },
      {
        "avg_logprob": -0.2392145416440343,
        "compression_ratio": 1.9185667752442996,
        "end": 363.71999999999997,
        "id": 148,
        "no_speech_prob": 0.00003822371945716441,
        "seek": 33540,
        "start": 361.47999999999996,
        "temperature": 0,
        "text": " Okay, so if you wanna get that notification,",
        "tokens": [
          51668,
          1033,
          11,
          370,
          498,
          291,
          1948,
          483,
          300,
          11554,
          11,
          51780
        ]
      },
      {
        "avg_logprob": -0.2392145416440343,
        "compression_ratio": 1.9185667752442996,
        "end": 364.67999999999995,
        "id": 149,
        "no_speech_prob": 0.00003822371945716441,
        "seek": 33540,
        "start": 363.71999999999997,
        "temperature": 0,
        "text": " it's gonna be on his channel",
        "tokens": [
          51780,
          309,
          311,
          799,
          312,
          322,
          702,
          2269,
          51828
        ]
      },
      {
        "avg_logprob": -0.27766106128692625,
        "compression_ratio": 1.7849462365591398,
        "end": 365.84000000000003,
        "id": 150,
        "no_speech_prob": 0.0001233869988936931,
        "seek": 36468,
        "start": 365,
        "temperature": 0,
        "text": " so you're gonna have to subscribe.",
        "tokens": [
          50380,
          370,
          291,
          434,
          799,
          362,
          281,
          3022,
          13,
          50422
        ]
      },
      {
        "avg_logprob": -0.27766106128692625,
        "compression_ratio": 1.7849462365591398,
        "end": 367.32,
        "id": 151,
        "no_speech_prob": 0.0001233869988936931,
        "seek": 36468,
        "start": 365.84000000000003,
        "temperature": 0,
        "text": " There.",
        "tokens": [
          50422,
          821,
          13,
          50496
        ]
      },
      {
        "avg_logprob": -0.27766106128692625,
        "compression_ratio": 1.7849462365591398,
        "end": 368.16,
        "id": 152,
        "no_speech_prob": 0.0001233869988936931,
        "seek": 36468,
        "start": 367.32,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50496,
          1033,
          13,
          50538
        ]
      },
      {
        "avg_logprob": -0.27766106128692625,
        "compression_ratio": 1.7849462365591398,
        "end": 370.68,
        "id": 153,
        "no_speech_prob": 0.0001233869988936931,
        "seek": 36468,
        "start": 369.28000000000003,
        "temperature": 0,
        "text": " I'm looking at the chat.",
        "tokens": [
          50594,
          286,
          478,
          1237,
          412,
          264,
          5081,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.27766106128692625,
        "compression_ratio": 1.7849462365591398,
        "end": 375.08,
        "id": 154,
        "no_speech_prob": 0.0001233869988936931,
        "seek": 36468,
        "start": 370.68,
        "temperature": 0,
        "text": " So, I think that, oh, these are, look at this.",
        "tokens": [
          50664,
          407,
          11,
          286,
          519,
          300,
          11,
          1954,
          11,
          613,
          366,
          11,
          574,
          412,
          341,
          13,
          50884
        ]
      },
      {
        "avg_logprob": -0.27766106128692625,
        "compression_ratio": 1.7849462365591398,
        "end": 376.56,
        "id": 155,
        "no_speech_prob": 0.0001233869988936931,
        "seek": 36468,
        "start": 375.08,
        "temperature": 0,
        "text": " These are some great, let's look at these.",
        "tokens": [
          50884,
          1981,
          366,
          512,
          869,
          11,
          718,
          311,
          574,
          412,
          613,
          13,
          50958
        ]
      },
      {
        "avg_logprob": -0.27766106128692625,
        "compression_ratio": 1.7849462365591398,
        "end": 378.24,
        "id": 156,
        "no_speech_prob": 0.0001233869988936931,
        "seek": 36468,
        "start": 376.56,
        "temperature": 0,
        "text": " Oh, look at your friends.",
        "tokens": [
          50958,
          876,
          11,
          574,
          412,
          428,
          1855,
          13,
          51042
        ]
      },
      {
        "avg_logprob": -0.27766106128692625,
        "compression_ratio": 1.7849462365591398,
        "end": 380,
        "id": 157,
        "no_speech_prob": 0.0001233869988936931,
        "seek": 36468,
        "start": 378.24,
        "temperature": 0,
        "text": " Oh, that, okay, so also, by the way,",
        "tokens": [
          51042,
          876,
          11,
          300,
          11,
          1392,
          11,
          370,
          611,
          11,
          538,
          264,
          636,
          11,
          51130
        ]
      },
      {
        "avg_logprob": -0.27766106128692625,
        "compression_ratio": 1.7849462365591398,
        "end": 381.68,
        "id": 158,
        "no_speech_prob": 0.0001233869988936931,
        "seek": 36468,
        "start": 380,
        "temperature": 0,
        "text": " this I learned about recently too.",
        "tokens": [
          51130,
          341,
          286,
          3264,
          466,
          3938,
          886,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.27766106128692625,
        "compression_ratio": 1.7849462365591398,
        "end": 383.3,
        "id": 159,
        "no_speech_prob": 0.0001233869988936931,
        "seek": 36468,
        "start": 381.68,
        "temperature": 0,
        "text": " Jabril is doing live streams.",
        "tokens": [
          51214,
          40319,
          24216,
          307,
          884,
          1621,
          15842,
          13,
          51295
        ]
      },
      {
        "avg_logprob": -0.27766106128692625,
        "compression_ratio": 1.7849462365591398,
        "end": 384.82,
        "id": 160,
        "no_speech_prob": 0.0001233869988936931,
        "seek": 36468,
        "start": 383.3,
        "temperature": 0,
        "text": " I guess I could let you talk about your own stuff.",
        "tokens": [
          51295,
          286,
          2041,
          286,
          727,
          718,
          291,
          751,
          466,
          428,
          1065,
          1507,
          13,
          51371
        ]
      },
      {
        "avg_logprob": -0.27766106128692625,
        "compression_ratio": 1.7849462365591398,
        "end": 387.16,
        "id": 161,
        "no_speech_prob": 0.0001233869988936931,
        "seek": 36468,
        "start": 384.82,
        "temperature": 0,
        "text": " I don't know why I'm doing, I can't stop talking.",
        "tokens": [
          51371,
          286,
          500,
          380,
          458,
          983,
          286,
          478,
          884,
          11,
          286,
          393,
          380,
          1590,
          1417,
          13,
          51488
        ]
      },
      {
        "avg_logprob": -0.27766106128692625,
        "compression_ratio": 1.7849462365591398,
        "end": 390,
        "id": 162,
        "no_speech_prob": 0.0001233869988936931,
        "seek": 36468,
        "start": 387.16,
        "temperature": 0,
        "text": " This is my channel, I guess I'm in charge here.",
        "tokens": [
          51488,
          639,
          307,
          452,
          2269,
          11,
          286,
          2041,
          286,
          478,
          294,
          4602,
          510,
          13,
          51630
        ]
      },
      {
        "avg_logprob": -0.27766106128692625,
        "compression_ratio": 1.7849462365591398,
        "end": 394.6,
        "id": 163,
        "no_speech_prob": 0.0001233869988936931,
        "seek": 36468,
        "start": 390,
        "temperature": 0,
        "text": " This channel is where Jabril does his live stream archives",
        "tokens": [
          51630,
          639,
          2269,
          307,
          689,
          40319,
          24216,
          775,
          702,
          1621,
          4309,
          25607,
          51860
        ]
      },
      {
        "avg_logprob": -0.5807223477206387,
        "compression_ratio": 1.7222222222222223,
        "end": 396.68,
        "id": 164,
        "no_speech_prob": 0.007455762475728989,
        "seek": 39460,
        "start": 395.44,
        "temperature": 0,
        "text": " and he does his live streams.",
        "tokens": [
          50406,
          293,
          415,
          775,
          702,
          1621,
          15842,
          13,
          50468
        ]
      },
      {
        "avg_logprob": -0.5807223477206387,
        "compression_ratio": 1.7222222222222223,
        "end": 398.32000000000005,
        "id": 165,
        "no_speech_prob": 0.007455762475728989,
        "seek": 39460,
        "start": 396.68,
        "temperature": 0,
        "text": " So, I'm not sure if you're gonna be able to see it",
        "tokens": [
          50468,
          407,
          11,
          286,
          478,
          406,
          988,
          498,
          291,
          434,
          799,
          312,
          1075,
          281,
          536,
          309,
          50550
        ]
      },
      {
        "avg_logprob": -0.5807223477206387,
        "compression_ratio": 1.7222222222222223,
        "end": 399.40000000000003,
        "id": 166,
        "no_speech_prob": 0.007455762475728989,
        "seek": 39460,
        "start": 398.32000000000005,
        "temperature": 0,
        "text": " published here, but your live streams",
        "tokens": [
          50550,
          6572,
          510,
          11,
          457,
          428,
          1621,
          15842,
          50604
        ]
      },
      {
        "avg_logprob": -0.5807223477206387,
        "compression_ratio": 1.7222222222222223,
        "end": 400.24,
        "id": 167,
        "no_speech_prob": 0.007455762475728989,
        "seek": 39460,
        "start": 399.40000000000003,
        "temperature": 0,
        "text": " are actually on Twitch.",
        "tokens": [
          50604,
          366,
          767,
          322,
          22222,
          13,
          50646
        ]
      },
      {
        "avg_logprob": -0.5807223477206387,
        "compression_ratio": 1.7222222222222223,
        "end": 401.08000000000004,
        "id": 168,
        "no_speech_prob": 0.007455762475728989,
        "seek": 39460,
        "start": 400.24,
        "temperature": 0,
        "text": " Correct, yes.",
        "tokens": [
          50646,
          12753,
          11,
          2086,
          13,
          50688
        ]
      },
      {
        "avg_logprob": -0.5807223477206387,
        "compression_ratio": 1.7222222222222223,
        "end": 402.88,
        "id": 169,
        "no_speech_prob": 0.007455762475728989,
        "seek": 39460,
        "start": 401.08000000000004,
        "temperature": 0,
        "text": " Okay, and then also, some nice,",
        "tokens": [
          50688,
          1033,
          11,
          293,
          550,
          611,
          11,
          512,
          1481,
          11,
          50778
        ]
      },
      {
        "avg_logprob": -0.5807223477206387,
        "compression_ratio": 1.7222222222222223,
        "end": 405.04,
        "id": 170,
        "no_speech_prob": 0.007455762475728989,
        "seek": 39460,
        "start": 402.88,
        "temperature": 0,
        "text": " the Physics Girl is an awesome channel.",
        "tokens": [
          50778,
          264,
          38355,
          8502,
          307,
          364,
          3476,
          2269,
          13,
          50886
        ]
      },
      {
        "avg_logprob": -0.5807223477206387,
        "compression_ratio": 1.7222222222222223,
        "end": 407.6,
        "id": 171,
        "no_speech_prob": 0.007455762475728989,
        "seek": 39460,
        "start": 405.04,
        "temperature": 0,
        "text": " Coding Train is, it's kind of okay.",
        "tokens": [
          50886,
          383,
          8616,
          28029,
          307,
          11,
          309,
          311,
          733,
          295,
          1392,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.5807223477206387,
        "compression_ratio": 1.7222222222222223,
        "end": 408.84000000000003,
        "id": 172,
        "no_speech_prob": 0.007455762475728989,
        "seek": 39460,
        "start": 407.6,
        "temperature": 0,
        "text": " And I don't know some of these other channels,",
        "tokens": [
          51014,
          400,
          286,
          500,
          380,
          458,
          512,
          295,
          613,
          661,
          9235,
          11,
          51076
        ]
      },
      {
        "avg_logprob": -0.5807223477206387,
        "compression_ratio": 1.7222222222222223,
        "end": 410.20000000000005,
        "id": 173,
        "no_speech_prob": 0.007455762475728989,
        "seek": 39460,
        "start": 408.84000000000003,
        "temperature": 0,
        "text": " but I'm definitely gonna have to check them out.",
        "tokens": [
          51076,
          457,
          286,
          478,
          2138,
          799,
          362,
          281,
          1520,
          552,
          484,
          13,
          51144
        ]
      },
      {
        "avg_logprob": -0.5807223477206387,
        "compression_ratio": 1.7222222222222223,
        "end": 411.04,
        "id": 174,
        "no_speech_prob": 0.007455762475728989,
        "seek": 39460,
        "start": 410.20000000000005,
        "temperature": 0,
        "text": " They look cool.",
        "tokens": [
          51144,
          814,
          574,
          1627,
          13,
          51186
        ]
      },
      {
        "avg_logprob": -0.5807223477206387,
        "compression_ratio": 1.7222222222222223,
        "end": 413.72,
        "id": 175,
        "no_speech_prob": 0.007455762475728989,
        "seek": 39460,
        "start": 411.04,
        "temperature": 0,
        "text": " All right, so, and here you can see here,",
        "tokens": [
          51186,
          1057,
          558,
          11,
          370,
          11,
          293,
          510,
          291,
          393,
          536,
          510,
          11,
          51320
        ]
      },
      {
        "avg_logprob": -0.5807223477206387,
        "compression_ratio": 1.7222222222222223,
        "end": 418.16,
        "id": 176,
        "no_speech_prob": 0.007455762475728989,
        "seek": 39460,
        "start": 413.72,
        "temperature": 0,
        "text": " you can see YouTube, Jabril, Real Life, Jabril,",
        "tokens": [
          51320,
          291,
          393,
          536,
          3088,
          11,
          40319,
          24216,
          11,
          8467,
          7720,
          11,
          40319,
          24216,
          11,
          51542
        ]
      },
      {
        "avg_logprob": -0.5807223477206387,
        "compression_ratio": 1.7222222222222223,
        "end": 420,
        "id": 177,
        "no_speech_prob": 0.007455762475728989,
        "seek": 39460,
        "start": 418.16,
        "temperature": 0,
        "text": " YouTube, Jabril, Real Life, Jabril.",
        "tokens": [
          51542,
          3088,
          11,
          40319,
          24216,
          11,
          8467,
          7720,
          11,
          40319,
          24216,
          13,
          51634
        ]
      },
      {
        "avg_logprob": -0.5807223477206387,
        "compression_ratio": 1.7222222222222223,
        "end": 420.84000000000003,
        "id": 178,
        "no_speech_prob": 0.007455762475728989,
        "seek": 39460,
        "start": 420,
        "temperature": 0,
        "text": " Oh, oh, oh.",
        "tokens": [
          51634,
          876,
          11,
          1954,
          11,
          1954,
          13,
          51676
        ]
      },
      {
        "avg_logprob": -0.5807223477206387,
        "compression_ratio": 1.7222222222222223,
        "end": 422.48,
        "id": 179,
        "no_speech_prob": 0.007455762475728989,
        "seek": 39460,
        "start": 420.84000000000003,
        "temperature": 0,
        "text": " If you're reading this.",
        "tokens": [
          51676,
          759,
          291,
          434,
          3760,
          341,
          13,
          51758
        ]
      },
      {
        "avg_logprob": -0.5807223477206387,
        "compression_ratio": 1.7222222222222223,
        "end": 423.32000000000005,
        "id": 180,
        "no_speech_prob": 0.007455762475728989,
        "seek": 39460,
        "start": 422.48,
        "temperature": 0,
        "text": " You've been hacked.",
        "tokens": [
          51758,
          509,
          600,
          668,
          36218,
          13,
          51800
        ]
      },
      {
        "avg_logprob": -0.25188407345094543,
        "compression_ratio": 1.625925925925926,
        "end": 427.32,
        "id": 181,
        "no_speech_prob": 0.000049853708333102986,
        "seek": 42332,
        "start": 424.04,
        "temperature": 0,
        "text": " He's like a real life YouTuber in person.",
        "tokens": [
          50400,
          634,
          311,
          411,
          257,
          957,
          993,
          23349,
          294,
          954,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.25188407345094543,
        "compression_ratio": 1.625925925925926,
        "end": 428.96,
        "id": 182,
        "no_speech_prob": 0.000049853708333102986,
        "seek": 42332,
        "start": 427.32,
        "temperature": 0,
        "text": " I don't think of myself as that",
        "tokens": [
          50564,
          286,
          500,
          380,
          519,
          295,
          2059,
          382,
          300,
          50646
        ]
      },
      {
        "avg_logprob": -0.25188407345094543,
        "compression_ratio": 1.625925925925926,
        "end": 432.96,
        "id": 183,
        "no_speech_prob": 0.000049853708333102986,
        "seek": 42332,
        "start": 428.96,
        "temperature": 0,
        "text": " because I'm like an old person, but he's like a full of,",
        "tokens": [
          50646,
          570,
          286,
          478,
          411,
          364,
          1331,
          954,
          11,
          457,
          415,
          311,
          411,
          257,
          1577,
          295,
          11,
          50846
        ]
      },
      {
        "avg_logprob": -0.25188407345094543,
        "compression_ratio": 1.625925925925926,
        "end": 434.71999999999997,
        "id": 184,
        "no_speech_prob": 0.000049853708333102986,
        "seek": 42332,
        "start": 432.96,
        "temperature": 0,
        "text": " I don't know, youthful energy.",
        "tokens": [
          50846,
          286,
          500,
          380,
          458,
          11,
          7503,
          906,
          2281,
          13,
          50934
        ]
      },
      {
        "avg_logprob": -0.25188407345094543,
        "compression_ratio": 1.625925925925926,
        "end": 438.04,
        "id": 185,
        "no_speech_prob": 0.000049853708333102986,
        "seek": 42332,
        "start": 434.71999999999997,
        "temperature": 0,
        "text": " Okay, I have, all right, so I think,",
        "tokens": [
          50934,
          1033,
          11,
          286,
          362,
          11,
          439,
          558,
          11,
          370,
          286,
          519,
          11,
          51100
        ]
      },
      {
        "avg_logprob": -0.25188407345094543,
        "compression_ratio": 1.625925925925926,
        "end": 440.03999999999996,
        "id": 186,
        "no_speech_prob": 0.000049853708333102986,
        "seek": 42332,
        "start": 438.04,
        "temperature": 0,
        "text": " okay, let me mention two other things.",
        "tokens": [
          51100,
          1392,
          11,
          718,
          385,
          2152,
          732,
          661,
          721,
          13,
          51200
        ]
      },
      {
        "avg_logprob": -0.25188407345094543,
        "compression_ratio": 1.625925925925926,
        "end": 441.6,
        "id": 187,
        "no_speech_prob": 0.000049853708333102986,
        "seek": 42332,
        "start": 440.03999999999996,
        "temperature": 0,
        "text": " Number one is there's a lot of live streams",
        "tokens": [
          51200,
          5118,
          472,
          307,
          456,
          311,
          257,
          688,
          295,
          1621,
          15842,
          51278
        ]
      },
      {
        "avg_logprob": -0.25188407345094543,
        "compression_ratio": 1.625925925925926,
        "end": 442.44,
        "id": 188,
        "no_speech_prob": 0.000049853708333102986,
        "seek": 42332,
        "start": 441.6,
        "temperature": 0,
        "text": " going on right now.",
        "tokens": [
          51278,
          516,
          322,
          558,
          586,
          13,
          51320
        ]
      },
      {
        "avg_logprob": -0.25188407345094543,
        "compression_ratio": 1.625925925925926,
        "end": 446.32,
        "id": 189,
        "no_speech_prob": 0.000049853708333102986,
        "seek": 42332,
        "start": 442.44,
        "temperature": 0,
        "text": " I saw that, just in case, normally I would tell you",
        "tokens": [
          51320,
          286,
          1866,
          300,
          11,
          445,
          294,
          1389,
          11,
          5646,
          286,
          576,
          980,
          291,
          51514
        ]
      },
      {
        "avg_logprob": -0.25188407345094543,
        "compression_ratio": 1.625925925925926,
        "end": 447.68,
        "id": 190,
        "no_speech_prob": 0.000049853708333102986,
        "seek": 42332,
        "start": 446.32,
        "temperature": 0,
        "text": " to watch something else if it's just me,",
        "tokens": [
          51514,
          281,
          1159,
          746,
          1646,
          498,
          309,
          311,
          445,
          385,
          11,
          51582
        ]
      },
      {
        "avg_logprob": -0.25188407345094543,
        "compression_ratio": 1.625925925925926,
        "end": 449.84,
        "id": 191,
        "no_speech_prob": 0.000049853708333102986,
        "seek": 42332,
        "start": 447.68,
        "temperature": 0,
        "text": " but since it's Jabril, you should stay here.",
        "tokens": [
          51582,
          457,
          1670,
          309,
          311,
          40319,
          24216,
          11,
          291,
          820,
          1754,
          510,
          13,
          51690
        ]
      },
      {
        "avg_logprob": -0.21510410985202655,
        "compression_ratio": 1.682170542635659,
        "end": 453.47999999999996,
        "id": 192,
        "no_speech_prob": 0.000054758591431891546,
        "seek": 44984,
        "start": 449.84,
        "temperature": 0,
        "text": " But there is, oh no, there's the Glitch channel.",
        "tokens": [
          50364,
          583,
          456,
          307,
          11,
          1954,
          572,
          11,
          456,
          311,
          264,
          5209,
          1549,
          2269,
          13,
          50546
        ]
      },
      {
        "avg_logprob": -0.21510410985202655,
        "compression_ratio": 1.682170542635659,
        "end": 456.08,
        "id": 193,
        "no_speech_prob": 0.000054758591431891546,
        "seek": 44984,
        "start": 453.47999999999996,
        "temperature": 0,
        "text": " This is totally giving me the wrong stuff.",
        "tokens": [
          50546,
          639,
          307,
          3879,
          2902,
          385,
          264,
          2085,
          1507,
          13,
          50676
        ]
      },
      {
        "avg_logprob": -0.21510410985202655,
        "compression_ratio": 1.682170542635659,
        "end": 461.08,
        "id": 194,
        "no_speech_prob": 0.000054758591431891546,
        "seek": 44984,
        "start": 456.08,
        "temperature": 0,
        "text": " Ugh, Glitch, a code editor, YouTube.",
        "tokens": [
          50676,
          16506,
          11,
          5209,
          1549,
          11,
          257,
          3089,
          9839,
          11,
          3088,
          13,
          50926
        ]
      },
      {
        "avg_logprob": -0.21510410985202655,
        "compression_ratio": 1.682170542635659,
        "end": 462.56,
        "id": 195,
        "no_speech_prob": 0.000054758591431891546,
        "seek": 44984,
        "start": 461.71999999999997,
        "temperature": 0,
        "text": " I don't know why.",
        "tokens": [
          50958,
          286,
          500,
          380,
          458,
          983,
          13,
          51000
        ]
      },
      {
        "avg_logprob": -0.21510410985202655,
        "compression_ratio": 1.682170542635659,
        "end": 463.64,
        "id": 196,
        "no_speech_prob": 0.000054758591431891546,
        "seek": 44984,
        "start": 462.56,
        "temperature": 0,
        "text": " I saw that they were live streaming.",
        "tokens": [
          51000,
          286,
          1866,
          300,
          436,
          645,
          1621,
          11791,
          13,
          51054
        ]
      },
      {
        "avg_logprob": -0.21510410985202655,
        "compression_ratio": 1.682170542635659,
        "end": 464.96,
        "id": 197,
        "no_speech_prob": 0.000054758591431891546,
        "seek": 44984,
        "start": 463.64,
        "temperature": 0,
        "text": " I can't find it.",
        "tokens": [
          51054,
          286,
          393,
          380,
          915,
          309,
          13,
          51120
        ]
      },
      {
        "avg_logprob": -0.21510410985202655,
        "compression_ratio": 1.682170542635659,
        "end": 466.67999999999995,
        "id": 198,
        "no_speech_prob": 0.000054758591431891546,
        "seek": 44984,
        "start": 464.96,
        "temperature": 0,
        "text": " Nevermind, Glitch.",
        "tokens": [
          51120,
          7344,
          13733,
          11,
          5209,
          1549,
          13,
          51206
        ]
      },
      {
        "avg_logprob": -0.21510410985202655,
        "compression_ratio": 1.682170542635659,
        "end": 468.88,
        "id": 199,
        "no_speech_prob": 0.000054758591431891546,
        "seek": 44984,
        "start": 466.67999999999995,
        "temperature": 0,
        "text": " Glitch, I don't know why I'm plugging Glitch,",
        "tokens": [
          51206,
          5209,
          1549,
          11,
          286,
          500,
          380,
          458,
          983,
          286,
          478,
          42975,
          5209,
          1549,
          11,
          51316
        ]
      },
      {
        "avg_logprob": -0.21510410985202655,
        "compression_ratio": 1.682170542635659,
        "end": 469.79999999999995,
        "id": 200,
        "no_speech_prob": 0.000054758591431891546,
        "seek": 44984,
        "start": 468.88,
        "temperature": 0,
        "text": " but I love Glitch.",
        "tokens": [
          51316,
          457,
          286,
          959,
          5209,
          1549,
          13,
          51362
        ]
      },
      {
        "avg_logprob": -0.21510410985202655,
        "compression_ratio": 1.682170542635659,
        "end": 470.88,
        "id": 201,
        "no_speech_prob": 0.000054758591431891546,
        "seek": 44984,
        "start": 469.79999999999995,
        "temperature": 0,
        "text": " It's a code editor.",
        "tokens": [
          51362,
          467,
          311,
          257,
          3089,
          9839,
          13,
          51416
        ]
      },
      {
        "avg_logprob": -0.21510410985202655,
        "compression_ratio": 1.682170542635659,
        "end": 473.55999999999995,
        "id": 202,
        "no_speech_prob": 0.000054758591431891546,
        "seek": 44984,
        "start": 470.88,
        "temperature": 0,
        "text": " Not an official sponsor or anything,",
        "tokens": [
          51416,
          1726,
          364,
          4783,
          16198,
          420,
          1340,
          11,
          51550
        ]
      },
      {
        "avg_logprob": -0.21510410985202655,
        "compression_ratio": 1.682170542635659,
        "end": 475.47999999999996,
        "id": 203,
        "no_speech_prob": 0.000054758591431891546,
        "seek": 44984,
        "start": 473.55999999999995,
        "temperature": 0,
        "text": " but they have a live stream going on today.",
        "tokens": [
          51550,
          457,
          436,
          362,
          257,
          1621,
          4309,
          516,
          322,
          965,
          13,
          51646
        ]
      },
      {
        "avg_logprob": -0.21510410985202655,
        "compression_ratio": 1.682170542635659,
        "end": 478.91999999999996,
        "id": 204,
        "no_speech_prob": 0.000054758591431891546,
        "seek": 44984,
        "start": 475.47999999999996,
        "temperature": 0,
        "text": " And then there's also the TensorFlow Dev Summit.",
        "tokens": [
          51646,
          400,
          550,
          456,
          311,
          611,
          264,
          37624,
          9096,
          28726,
          13,
          51818
        ]
      },
      {
        "avg_logprob": -0.4662220357990951,
        "compression_ratio": 1.5928571428571427,
        "end": 480.64000000000004,
        "id": 205,
        "no_speech_prob": 0.00014650601951871067,
        "seek": 47892,
        "start": 478.96000000000004,
        "temperature": 0,
        "text": " This, in particular, I wanted to mention.",
        "tokens": [
          50366,
          639,
          11,
          294,
          1729,
          11,
          286,
          1415,
          281,
          2152,
          13,
          50450
        ]
      },
      {
        "avg_logprob": -0.4662220357990951,
        "compression_ratio": 1.5928571428571427,
        "end": 481.64000000000004,
        "id": 206,
        "no_speech_prob": 0.00014650601951871067,
        "seek": 47892,
        "start": 480.64000000000004,
        "temperature": 0,
        "text": " Let's see if we can tune in",
        "tokens": [
          50450,
          961,
          311,
          536,
          498,
          321,
          393,
          10864,
          294,
          50500
        ]
      },
      {
        "avg_logprob": -0.4662220357990951,
        "compression_ratio": 1.5928571428571427,
        "end": 483.32,
        "id": 207,
        "no_speech_prob": 0.00014650601951871067,
        "seek": 47892,
        "start": 481.64000000000004,
        "temperature": 0,
        "text": " to the live stream really briefly.",
        "tokens": [
          50500,
          281,
          264,
          1621,
          4309,
          534,
          10515,
          13,
          50584
        ]
      },
      {
        "avg_logprob": -0.4662220357990951,
        "compression_ratio": 1.5928571428571427,
        "end": 487.28000000000003,
        "id": 208,
        "no_speech_prob": 0.00014650601951871067,
        "seek": 47892,
        "start": 485.88,
        "temperature": 0,
        "text": " What are we learning about now?",
        "tokens": [
          50712,
          708,
          366,
          321,
          2539,
          466,
          586,
          30,
          50782
        ]
      },
      {
        "avg_logprob": -0.4662220357990951,
        "compression_ratio": 1.5928571428571427,
        "end": 488.12,
        "id": 209,
        "no_speech_prob": 0.00014650601951871067,
        "seek": 47892,
        "start": 487.28000000000003,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50782,
          1057,
          558,
          13,
          50824
        ]
      },
      {
        "avg_logprob": -0.4662220357990951,
        "compression_ratio": 1.5928571428571427,
        "end": 488.96000000000004,
        "id": 210,
        "no_speech_prob": 0.00014650601951871067,
        "seek": 47892,
        "start": 488.12,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50824,
          1057,
          558,
          13,
          50866
        ]
      },
      {
        "avg_logprob": -0.4662220357990951,
        "compression_ratio": 1.5928571428571427,
        "end": 489.8,
        "id": 211,
        "no_speech_prob": 0.00014650601951871067,
        "seek": 47892,
        "start": 488.96000000000004,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50866,
          1057,
          558,
          13,
          50908
        ]
      },
      {
        "avg_logprob": -0.4662220357990951,
        "compression_ratio": 1.5928571428571427,
        "end": 492.40000000000003,
        "id": 212,
        "no_speech_prob": 0.00014650601951871067,
        "seek": 47892,
        "start": 489.8,
        "temperature": 0,
        "text": " All of you may want to distribute.",
        "tokens": [
          50908,
          1057,
          295,
          291,
          815,
          528,
          281,
          20594,
          13,
          51038
        ]
      },
      {
        "avg_logprob": -0.4662220357990951,
        "compression_ratio": 1.5928571428571427,
        "end": 493.68,
        "id": 213,
        "no_speech_prob": 0.00014650601951871067,
        "seek": 47892,
        "start": 492.40000000000003,
        "temperature": 0,
        "text": " You're tuning to multiple devices.",
        "tokens": [
          51038,
          509,
          434,
          15164,
          281,
          3866,
          5759,
          13,
          51102
        ]
      },
      {
        "avg_logprob": -0.4662220357990951,
        "compression_ratio": 1.5928571428571427,
        "end": 495.56,
        "id": 214,
        "no_speech_prob": 0.00014650601951871067,
        "seek": 47892,
        "start": 493.68,
        "temperature": 0,
        "text": " See, now you don't hear the audio from this",
        "tokens": [
          51102,
          3008,
          11,
          586,
          291,
          500,
          380,
          1568,
          264,
          6278,
          490,
          341,
          51196
        ]
      },
      {
        "avg_logprob": -0.4662220357990951,
        "compression_ratio": 1.5928571428571427,
        "end": 497.44,
        "id": 215,
        "no_speech_prob": 0.00014650601951871067,
        "seek": 47892,
        "start": 495.56,
        "temperature": 0,
        "text": " except through my mic,",
        "tokens": [
          51196,
          3993,
          807,
          452,
          3123,
          11,
          51290
        ]
      },
      {
        "avg_logprob": -0.4662220357990951,
        "compression_ratio": 1.5928571428571427,
        "end": 499.44,
        "id": 216,
        "no_speech_prob": 0.00014650601951871067,
        "seek": 47892,
        "start": 497.44,
        "temperature": 0,
        "text": " so maybe I should just do a voiceover.",
        "tokens": [
          51290,
          370,
          1310,
          286,
          820,
          445,
          360,
          257,
          3177,
          3570,
          13,
          51390
        ]
      },
      {
        "avg_logprob": -0.4662220357990951,
        "compression_ratio": 1.5928571428571427,
        "end": 502.72,
        "id": 217,
        "no_speech_prob": 0.00014650601951871067,
        "seek": 47892,
        "start": 501.16,
        "temperature": 0,
        "text": " Saying these workers,",
        "tokens": [
          51476,
          34087,
          613,
          5600,
          11,
          51554
        ]
      },
      {
        "avg_logprob": -0.4662220357990951,
        "compression_ratio": 1.5928571428571427,
        "end": 507,
        "id": 218,
        "no_speech_prob": 0.00014650601951871067,
        "seek": 47892,
        "start": 505.68,
        "temperature": 0,
        "text": " servers, and there's very little going on,",
        "tokens": [
          51702,
          15909,
          11,
          293,
          456,
          311,
          588,
          707,
          516,
          322,
          11,
          51768
        ]
      },
      {
        "avg_logprob": -0.4662220357990951,
        "compression_ratio": 1.5928571428571427,
        "end": 508.88,
        "id": 219,
        "no_speech_prob": 0.00014650601951871067,
        "seek": 47892,
        "start": 507,
        "temperature": 0,
        "text": " saying, to estimate, I can't do it.",
        "tokens": [
          51768,
          1566,
          11,
          281,
          12539,
          11,
          286,
          393,
          380,
          360,
          309,
          13,
          51862
        ]
      },
      {
        "avg_logprob": -0.20201564038920605,
        "compression_ratio": 1.488,
        "end": 513.2,
        "id": 220,
        "no_speech_prob": 0.00006301752728177235,
        "seek": 50888,
        "start": 509.68,
        "temperature": 0,
        "text": " So, the TensorFlow Dev Summit is going on live right now.",
        "tokens": [
          50404,
          407,
          11,
          264,
          37624,
          9096,
          28726,
          307,
          516,
          322,
          1621,
          558,
          586,
          13,
          50580
        ]
      },
      {
        "avg_logprob": -0.20201564038920605,
        "compression_ratio": 1.488,
        "end": 515.36,
        "id": 221,
        "no_speech_prob": 0.00006301752728177235,
        "seek": 50888,
        "start": 513.2,
        "temperature": 0,
        "text": " I don't know what this is about.",
        "tokens": [
          50580,
          286,
          500,
          380,
          458,
          437,
          341,
          307,
          466,
          13,
          50688
        ]
      },
      {
        "avg_logprob": -0.20201564038920605,
        "compression_ratio": 1.488,
        "end": 517.32,
        "id": 222,
        "no_speech_prob": 0.00006301752728177235,
        "seek": 50888,
        "start": 515.36,
        "temperature": 0,
        "text": " And I think earlier already today,",
        "tokens": [
          50688,
          400,
          286,
          519,
          3071,
          1217,
          965,
          11,
          50786
        ]
      },
      {
        "avg_logprob": -0.20201564038920605,
        "compression_ratio": 1.488,
        "end": 520.12,
        "id": 223,
        "no_speech_prob": 0.00006301752728177235,
        "seek": 50888,
        "start": 517.32,
        "temperature": 0,
        "text": " there was a very exciting announcement.",
        "tokens": [
          50786,
          456,
          390,
          257,
          588,
          4670,
          12847,
          13,
          50926
        ]
      },
      {
        "avg_logprob": -0.20201564038920605,
        "compression_ratio": 1.488,
        "end": 524.8,
        "id": 224,
        "no_speech_prob": 0.00006301752728177235,
        "seek": 50888,
        "start": 520.12,
        "temperature": 0,
        "text": " If I go to js.tensorflow.org, I think.",
        "tokens": [
          50926,
          759,
          286,
          352,
          281,
          42713,
          13,
          83,
          23153,
          10565,
          13,
          4646,
          11,
          286,
          519,
          13,
          51160
        ]
      },
      {
        "avg_logprob": -0.20201564038920605,
        "compression_ratio": 1.488,
        "end": 525.64,
        "id": 225,
        "no_speech_prob": 0.00006301752728177235,
        "seek": 50888,
        "start": 524.8,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          51160,
          1079,
          13,
          51202
        ]
      },
      {
        "avg_logprob": -0.20201564038920605,
        "compression_ratio": 1.488,
        "end": 528.96,
        "id": 226,
        "no_speech_prob": 0.00006301752728177235,
        "seek": 50888,
        "start": 525.64,
        "temperature": 0,
        "text": " So, you might have heard me talk about",
        "tokens": [
          51202,
          407,
          11,
          291,
          1062,
          362,
          2198,
          385,
          751,
          466,
          51368
        ]
      },
      {
        "avg_logprob": -0.20201564038920605,
        "compression_ratio": 1.488,
        "end": 533.56,
        "id": 227,
        "no_speech_prob": 0.00006301752728177235,
        "seek": 50888,
        "start": 528.96,
        "temperature": 0,
        "text": " a project called Deep Learn JS on this channel.",
        "tokens": [
          51368,
          257,
          1716,
          1219,
          14895,
          17216,
          33063,
          322,
          341,
          2269,
          13,
          51598
        ]
      },
      {
        "avg_logprob": -0.20201564038920605,
        "compression_ratio": 1.488,
        "end": 535.88,
        "id": 228,
        "no_speech_prob": 0.00006301752728177235,
        "seek": 50888,
        "start": 533.56,
        "temperature": 0,
        "text": " What happens if I go to deeplearnjs.org?",
        "tokens": [
          51598,
          708,
          2314,
          498,
          286,
          352,
          281,
          2452,
          306,
          1083,
          25530,
          13,
          4646,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.20201564038920605,
        "compression_ratio": 1.488,
        "end": 537.88,
        "id": 229,
        "no_speech_prob": 0.00006301752728177235,
        "seek": 50888,
        "start": 535.88,
        "temperature": 0,
        "text": " It's still there, but it now says,",
        "tokens": [
          51714,
          467,
          311,
          920,
          456,
          11,
          457,
          309,
          586,
          1619,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.30182133164516717,
        "compression_ratio": 1.630952380952381,
        "end": 538.92,
        "id": 230,
        "no_speech_prob": 0.000010288995326845907,
        "seek": 53788,
        "start": 537.88,
        "temperature": 0,
        "text": " exactly what I wanted to tell you,",
        "tokens": [
          50364,
          2293,
          437,
          286,
          1415,
          281,
          980,
          291,
          11,
          50416
        ]
      },
      {
        "avg_logprob": -0.30182133164516717,
        "compression_ratio": 1.630952380952381,
        "end": 541.2,
        "id": 231,
        "no_speech_prob": 0.000010288995326845907,
        "seek": 53788,
        "start": 538.92,
        "temperature": 0,
        "text": " is that deeplearn.js has become",
        "tokens": [
          50416,
          307,
          300,
          2452,
          306,
          1083,
          13,
          25530,
          575,
          1813,
          50530
        ]
      },
      {
        "avg_logprob": -0.30182133164516717,
        "compression_ratio": 1.630952380952381,
        "end": 544.4399999999999,
        "id": 232,
        "no_speech_prob": 0.000010288995326845907,
        "seek": 53788,
        "start": 542.64,
        "temperature": 0,
        "text": " tensorflow.js.",
        "tokens": [
          50602,
          40863,
          10565,
          13,
          25530,
          13,
          50692
        ]
      },
      {
        "avg_logprob": -0.30182133164516717,
        "compression_ratio": 1.630952380952381,
        "end": 546.96,
        "id": 233,
        "no_speech_prob": 0.000010288995326845907,
        "seek": 53788,
        "start": 544.4399999999999,
        "temperature": 0,
        "text": " So, that's pretty exciting.",
        "tokens": [
          50692,
          407,
          11,
          300,
          311,
          1238,
          4670,
          13,
          50818
        ]
      },
      {
        "avg_logprob": -0.30182133164516717,
        "compression_ratio": 1.630952380952381,
        "end": 548.08,
        "id": 234,
        "no_speech_prob": 0.000010288995326845907,
        "seek": 53788,
        "start": 546.96,
        "temperature": 0,
        "text": " Like, it graduated.",
        "tokens": [
          50818,
          1743,
          11,
          309,
          13693,
          13,
          50874
        ]
      },
      {
        "avg_logprob": -0.30182133164516717,
        "compression_ratio": 1.630952380952381,
        "end": 549.36,
        "id": 235,
        "no_speech_prob": 0.000010288995326845907,
        "seek": 53788,
        "start": 548.08,
        "temperature": 0,
        "text": " It grew up, it graduated.",
        "tokens": [
          50874,
          467,
          6109,
          493,
          11,
          309,
          13693,
          13,
          50938
        ]
      },
      {
        "avg_logprob": -0.30182133164516717,
        "compression_ratio": 1.630952380952381,
        "end": 552.48,
        "id": 236,
        "no_speech_prob": 0.000010288995326845907,
        "seek": 53788,
        "start": 549.36,
        "temperature": 0,
        "text": " It's a teenager now, maybe, in whatever,",
        "tokens": [
          50938,
          467,
          311,
          257,
          21440,
          586,
          11,
          1310,
          11,
          294,
          2035,
          11,
          51094
        ]
      },
      {
        "avg_logprob": -0.30182133164516717,
        "compression_ratio": 1.630952380952381,
        "end": 554.32,
        "id": 237,
        "no_speech_prob": 0.000010288995326845907,
        "seek": 53788,
        "start": 552.48,
        "temperature": 0,
        "text": " computing years, open source years.",
        "tokens": [
          51094,
          15866,
          924,
          11,
          1269,
          4009,
          924,
          13,
          51186
        ]
      },
      {
        "avg_logprob": -0.30182133164516717,
        "compression_ratio": 1.630952380952381,
        "end": 556.24,
        "id": 238,
        "no_speech_prob": 0.000010288995326845907,
        "seek": 53788,
        "start": 554.32,
        "temperature": 0,
        "text": " I don't know how that translates to dog year.",
        "tokens": [
          51186,
          286,
          500,
          380,
          458,
          577,
          300,
          28468,
          281,
          3000,
          1064,
          13,
          51282
        ]
      },
      {
        "avg_logprob": -0.30182133164516717,
        "compression_ratio": 1.630952380952381,
        "end": 560.8,
        "id": 239,
        "no_speech_prob": 0.000010288995326845907,
        "seek": 53788,
        "start": 556.24,
        "temperature": 0,
        "text": " But, a member asked in the chat, can we get to the point?",
        "tokens": [
          51282,
          583,
          11,
          257,
          4006,
          2351,
          294,
          264,
          5081,
          11,
          393,
          321,
          483,
          281,
          264,
          935,
          30,
          51510
        ]
      },
      {
        "avg_logprob": -0.30182133164516717,
        "compression_ratio": 1.630952380952381,
        "end": 563.12,
        "id": 240,
        "no_speech_prob": 0.000010288995326845907,
        "seek": 53788,
        "start": 560.8,
        "temperature": 0,
        "text": " Very unlikely that's gonna happen anytime soon.",
        "tokens": [
          51510,
          4372,
          17518,
          300,
          311,
          799,
          1051,
          13038,
          2321,
          13,
          51626
        ]
      },
      {
        "avg_logprob": -0.30182133164516717,
        "compression_ratio": 1.630952380952381,
        "end": 564.42,
        "id": 241,
        "no_speech_prob": 0.000010288995326845907,
        "seek": 53788,
        "start": 563.12,
        "temperature": 0,
        "text": " I do not get to the point.",
        "tokens": [
          51626,
          286,
          360,
          406,
          483,
          281,
          264,
          935,
          13,
          51691
        ]
      },
      {
        "avg_logprob": -0.2553083295019988,
        "compression_ratio": 1.5390946502057614,
        "end": 570.14,
        "id": 242,
        "no_speech_prob": 0.000028834361728513613,
        "seek": 56442,
        "start": 565.26,
        "temperature": 0,
        "text": " And so, it's really exciting how this project is growing",
        "tokens": [
          50406,
          400,
          370,
          11,
          309,
          311,
          534,
          4670,
          577,
          341,
          1716,
          307,
          4194,
          50650
        ]
      },
      {
        "avg_logprob": -0.2553083295019988,
        "compression_ratio": 1.5390946502057614,
        "end": 572.42,
        "id": 243,
        "no_speech_prob": 0.000028834361728513613,
        "seek": 56442,
        "start": 570.14,
        "temperature": 0,
        "text": " to be able to unlock and make possible",
        "tokens": [
          50650,
          281,
          312,
          1075,
          281,
          11634,
          293,
          652,
          1944,
          50764
        ]
      },
      {
        "avg_logprob": -0.2553083295019988,
        "compression_ratio": 1.5390946502057614,
        "end": 575.38,
        "id": 244,
        "no_speech_prob": 0.000028834361728513613,
        "seek": 56442,
        "start": 572.42,
        "temperature": 0,
        "text": " more types of machine learning algorithms",
        "tokens": [
          50764,
          544,
          3467,
          295,
          3479,
          2539,
          14642,
          50912
        ]
      },
      {
        "avg_logprob": -0.2553083295019988,
        "compression_ratio": 1.5390946502057614,
        "end": 577.06,
        "id": 245,
        "no_speech_prob": 0.000028834361728513613,
        "seek": 56442,
        "start": 575.38,
        "temperature": 0,
        "text": " and possibilities in the browser.",
        "tokens": [
          50912,
          293,
          12178,
          294,
          264,
          11185,
          13,
          50996
        ]
      },
      {
        "avg_logprob": -0.2553083295019988,
        "compression_ratio": 1.5390946502057614,
        "end": 580.9,
        "id": 246,
        "no_speech_prob": 0.000028834361728513613,
        "seek": 56442,
        "start": 577.06,
        "temperature": 0,
        "text": " And I have been working on a project at ITP",
        "tokens": [
          50996,
          400,
          286,
          362,
          668,
          1364,
          322,
          257,
          1716,
          412,
          6783,
          47,
          51188
        ]
      },
      {
        "avg_logprob": -0.2553083295019988,
        "compression_ratio": 1.5390946502057614,
        "end": 582.0999999999999,
        "id": 247,
        "no_speech_prob": 0.000028834361728513613,
        "seek": 56442,
        "start": 580.9,
        "temperature": 0,
        "text": " with a bunch of researchers.",
        "tokens": [
          51188,
          365,
          257,
          3840,
          295,
          10309,
          13,
          51248
        ]
      },
      {
        "avg_logprob": -0.2553083295019988,
        "compression_ratio": 1.5390946502057614,
        "end": 584.14,
        "id": 248,
        "no_speech_prob": 0.000028834361728513613,
        "seek": 56442,
        "start": 582.0999999999999,
        "temperature": 0,
        "text": " I know Jibril has been experimenting with it",
        "tokens": [
          51248,
          286,
          458,
          508,
          6414,
          388,
          575,
          668,
          29070,
          365,
          309,
          51350
        ]
      },
      {
        "avg_logprob": -0.2553083295019988,
        "compression_ratio": 1.5390946502057614,
        "end": 587.0999999999999,
        "id": 249,
        "no_speech_prob": 0.000028834361728513613,
        "seek": 56442,
        "start": 584.14,
        "temperature": 0,
        "text": " for maybe an upcoming project.",
        "tokens": [
          51350,
          337,
          1310,
          364,
          11500,
          1716,
          13,
          51498
        ]
      },
      {
        "avg_logprob": -0.2553083295019988,
        "compression_ratio": 1.5390946502057614,
        "end": 591.98,
        "id": 250,
        "no_speech_prob": 0.000028834361728513613,
        "seek": 56442,
        "start": 587.0999999999999,
        "temperature": 0,
        "text": " If I go to github.com slash ml5js,",
        "tokens": [
          51498,
          759,
          286,
          352,
          281,
          290,
          355,
          836,
          13,
          1112,
          17330,
          23271,
          20,
          25530,
          11,
          51742
        ]
      },
      {
        "avg_logprob": -0.2553083295019988,
        "compression_ratio": 1.5390946502057614,
        "end": 592.98,
        "id": 251,
        "no_speech_prob": 0.000028834361728513613,
        "seek": 56442,
        "start": 591.98,
        "temperature": 0,
        "text": " I'm gonna go here.",
        "tokens": [
          51742,
          286,
          478,
          799,
          352,
          510,
          13,
          51792
        ]
      },
      {
        "avg_logprob": -0.24288233271184959,
        "compression_ratio": 1.6990740740740742,
        "end": 595.0600000000001,
        "id": 252,
        "no_speech_prob": 0.000002443694256726303,
        "seek": 59298,
        "start": 592.98,
        "temperature": 0,
        "text": " So, this is a machine learning library,",
        "tokens": [
          50364,
          407,
          11,
          341,
          307,
          257,
          3479,
          2539,
          6405,
          11,
          50468
        ]
      },
      {
        "avg_logprob": -0.24288233271184959,
        "compression_ratio": 1.6990740740740742,
        "end": 598.5,
        "id": 253,
        "no_speech_prob": 0.000002443694256726303,
        "seek": 59298,
        "start": 595.0600000000001,
        "temperature": 0,
        "text": " kind of like a higher level, simple, basic library",
        "tokens": [
          50468,
          733,
          295,
          411,
          257,
          2946,
          1496,
          11,
          2199,
          11,
          3875,
          6405,
          50640
        ]
      },
      {
        "avg_logprob": -0.24288233271184959,
        "compression_ratio": 1.6990740740740742,
        "end": 601.62,
        "id": 254,
        "no_speech_prob": 0.000002443694256726303,
        "seek": 59298,
        "start": 598.5,
        "temperature": 0,
        "text": " to do some machine learning stuff",
        "tokens": [
          50640,
          281,
          360,
          512,
          3479,
          2539,
          1507,
          50796
        ]
      },
      {
        "avg_logprob": -0.24288233271184959,
        "compression_ratio": 1.6990740740740742,
        "end": 607.22,
        "id": 255,
        "no_speech_prob": 0.000002443694256726303,
        "seek": 59298,
        "start": 603.1,
        "temperature": 0,
        "text": " that is built on top of deeplearn.js,",
        "tokens": [
          50870,
          300,
          307,
          3094,
          322,
          1192,
          295,
          2452,
          306,
          1083,
          13,
          25530,
          11,
          51076
        ]
      },
      {
        "avg_logprob": -0.24288233271184959,
        "compression_ratio": 1.6990740740740742,
        "end": 608.54,
        "id": 256,
        "no_speech_prob": 0.000002443694256726303,
        "seek": 59298,
        "start": 607.22,
        "temperature": 0,
        "text": " wherever that went away.",
        "tokens": [
          51076,
          8660,
          300,
          1437,
          1314,
          13,
          51142
        ]
      },
      {
        "avg_logprob": -0.24288233271184959,
        "compression_ratio": 1.6990740740740742,
        "end": 613.1800000000001,
        "id": 257,
        "no_speech_prob": 0.000002443694256726303,
        "seek": 59298,
        "start": 609.6800000000001,
        "temperature": 0,
        "text": " And now that deeplearn.js has become tensorflow.js,",
        "tokens": [
          51199,
          400,
          586,
          300,
          2452,
          306,
          1083,
          13,
          25530,
          575,
          1813,
          40863,
          10565,
          13,
          25530,
          11,
          51374
        ]
      },
      {
        "avg_logprob": -0.24288233271184959,
        "compression_ratio": 1.6990740740740742,
        "end": 616.24,
        "id": 258,
        "no_speech_prob": 0.000002443694256726303,
        "seek": 59298,
        "start": 613.1800000000001,
        "temperature": 0,
        "text": " this means we're going to do a lot more work on this",
        "tokens": [
          51374,
          341,
          1355,
          321,
          434,
          516,
          281,
          360,
          257,
          688,
          544,
          589,
          322,
          341,
          51527
        ]
      },
      {
        "avg_logprob": -0.24288233271184959,
        "compression_ratio": 1.6990740740740742,
        "end": 618.7,
        "id": 259,
        "no_speech_prob": 0.000002443694256726303,
        "seek": 59298,
        "start": 616.24,
        "temperature": 0,
        "text": " to support all the new possibilities",
        "tokens": [
          51527,
          281,
          1406,
          439,
          264,
          777,
          12178,
          51650
        ]
      },
      {
        "avg_logprob": -0.24288233271184959,
        "compression_ratio": 1.6990740740740742,
        "end": 620.9,
        "id": 260,
        "no_speech_prob": 0.000002443694256726303,
        "seek": 59298,
        "start": 618.7,
        "temperature": 0,
        "text": " that are unlocked from tensorflow.js.",
        "tokens": [
          51650,
          300,
          366,
          30180,
          490,
          40863,
          10565,
          13,
          25530,
          13,
          51760
        ]
      },
      {
        "avg_logprob": -0.1990646335250097,
        "compression_ratio": 1.6064516129032258,
        "end": 624.06,
        "id": 261,
        "no_speech_prob": 0.0000024059270344878314,
        "seek": 62090,
        "start": 620.9,
        "temperature": 0,
        "text": " In particular, most of our examples in this library",
        "tokens": [
          50364,
          682,
          1729,
          11,
          881,
          295,
          527,
          5110,
          294,
          341,
          6405,
          50522
        ]
      },
      {
        "avg_logprob": -0.1990646335250097,
        "compression_ratio": 1.6064516129032258,
        "end": 626.5799999999999,
        "id": 262,
        "no_speech_prob": 0.0000024059270344878314,
        "seek": 62090,
        "start": 624.06,
        "temperature": 0,
        "text": " involve using pre-trained models.",
        "tokens": [
          50522,
          9494,
          1228,
          659,
          12,
          17227,
          2001,
          5245,
          13,
          50648
        ]
      },
      {
        "avg_logprob": -0.1990646335250097,
        "compression_ratio": 1.6064516129032258,
        "end": 628.5,
        "id": 263,
        "no_speech_prob": 0.0000024059270344878314,
        "seek": 62090,
        "start": 626.5799999999999,
        "temperature": 0,
        "text": " And if you wanna train your own model,",
        "tokens": [
          50648,
          400,
          498,
          291,
          1948,
          3847,
          428,
          1065,
          2316,
          11,
          50744
        ]
      },
      {
        "avg_logprob": -0.1990646335250097,
        "compression_ratio": 1.6064516129032258,
        "end": 630.5799999999999,
        "id": 264,
        "no_speech_prob": 0.0000024059270344878314,
        "seek": 62090,
        "start": 628.5,
        "temperature": 0,
        "text": " you've gotta go and set up your Python environment.",
        "tokens": [
          50744,
          291,
          600,
          3428,
          352,
          293,
          992,
          493,
          428,
          15329,
          2823,
          13,
          50848
        ]
      },
      {
        "avg_logprob": -0.1990646335250097,
        "compression_ratio": 1.6064516129032258,
        "end": 632.22,
        "id": 265,
        "no_speech_prob": 0.0000024059270344878314,
        "seek": 62090,
        "start": 630.5799999999999,
        "temperature": 0,
        "text": " We have some tutorials for that.",
        "tokens": [
          50848,
          492,
          362,
          512,
          17616,
          337,
          300,
          13,
          50930
        ]
      },
      {
        "avg_logprob": -0.1990646335250097,
        "compression_ratio": 1.6064516129032258,
        "end": 634.22,
        "id": 266,
        "no_speech_prob": 0.0000024059270344878314,
        "seek": 62090,
        "start": 632.22,
        "temperature": 0,
        "text": " But now, we're gonna start to be able",
        "tokens": [
          50930,
          583,
          586,
          11,
          321,
          434,
          799,
          722,
          281,
          312,
          1075,
          51030
        ]
      },
      {
        "avg_logprob": -0.1990646335250097,
        "compression_ratio": 1.6064516129032258,
        "end": 635.5,
        "id": 267,
        "no_speech_prob": 0.0000024059270344878314,
        "seek": 62090,
        "start": 634.22,
        "temperature": 0,
        "text": " to make some examples and things",
        "tokens": [
          51030,
          281,
          652,
          512,
          5110,
          293,
          721,
          51094
        ]
      },
      {
        "avg_logprob": -0.1990646335250097,
        "compression_ratio": 1.6064516129032258,
        "end": 637.5799999999999,
        "id": 268,
        "no_speech_prob": 0.0000024059270344878314,
        "seek": 62090,
        "start": 635.5,
        "temperature": 0,
        "text": " where you can actually do the training in the browser.",
        "tokens": [
          51094,
          689,
          291,
          393,
          767,
          360,
          264,
          3097,
          294,
          264,
          11185,
          13,
          51198
        ]
      },
      {
        "avg_logprob": -0.1990646335250097,
        "compression_ratio": 1.6064516129032258,
        "end": 639.86,
        "id": 269,
        "no_speech_prob": 0.0000024059270344878314,
        "seek": 62090,
        "start": 637.5799999999999,
        "temperature": 0,
        "text": " So, I'm slowly getting to it,",
        "tokens": [
          51198,
          407,
          11,
          286,
          478,
          5692,
          1242,
          281,
          309,
          11,
          51312
        ]
      },
      {
        "avg_logprob": -0.1990646335250097,
        "compression_ratio": 1.6064516129032258,
        "end": 642.1,
        "id": 270,
        "no_speech_prob": 0.0000024059270344878314,
        "seek": 62090,
        "start": 639.86,
        "temperature": 0,
        "text": " but this is, I hope, gonna be a big focus",
        "tokens": [
          51312,
          457,
          341,
          307,
          11,
          286,
          1454,
          11,
          799,
          312,
          257,
          955,
          1879,
          51424
        ]
      },
      {
        "avg_logprob": -0.1990646335250097,
        "compression_ratio": 1.6064516129032258,
        "end": 644.86,
        "id": 271,
        "no_speech_prob": 0.0000024059270344878314,
        "seek": 62090,
        "start": 642.1,
        "temperature": 0,
        "text": " of my channel April, May, June,",
        "tokens": [
          51424,
          295,
          452,
          2269,
          6929,
          11,
          1891,
          11,
          6928,
          11,
          51562
        ]
      },
      {
        "avg_logprob": -0.1990646335250097,
        "compression_ratio": 1.6064516129032258,
        "end": 649.1,
        "id": 272,
        "no_speech_prob": 0.0000024059270344878314,
        "seek": 62090,
        "start": 645.78,
        "temperature": 0,
        "text": " however long I have the energy to do this over the summer.",
        "tokens": [
          51608,
          4461,
          938,
          286,
          362,
          264,
          2281,
          281,
          360,
          341,
          670,
          264,
          4266,
          13,
          51774
        ]
      },
      {
        "avg_logprob": -0.24038575653337005,
        "compression_ratio": 1.6022727272727273,
        "end": 650.98,
        "id": 273,
        "no_speech_prob": 0.000004092222297913395,
        "seek": 64910,
        "start": 649.1,
        "temperature": 0,
        "text": " So, that's coming.",
        "tokens": [
          50364,
          407,
          11,
          300,
          311,
          1348,
          13,
          50458
        ]
      },
      {
        "avg_logprob": -0.24038575653337005,
        "compression_ratio": 1.6022727272727273,
        "end": 653.74,
        "id": 274,
        "no_speech_prob": 0.000004092222297913395,
        "seek": 64910,
        "start": 650.98,
        "temperature": 0,
        "text": " Let me see if there are any questions in the chat.",
        "tokens": [
          50458,
          961,
          385,
          536,
          498,
          456,
          366,
          604,
          1651,
          294,
          264,
          5081,
          13,
          50596
        ]
      },
      {
        "avg_logprob": -0.24038575653337005,
        "compression_ratio": 1.6022727272727273,
        "end": 655.86,
        "id": 275,
        "no_speech_prob": 0.000004092222297913395,
        "seek": 64910,
        "start": 653.74,
        "temperature": 0,
        "text": " Is it efficient to learn in the web?",
        "tokens": [
          50596,
          1119,
          309,
          7148,
          281,
          1466,
          294,
          264,
          3670,
          30,
          50702
        ]
      },
      {
        "avg_logprob": -0.24038575653337005,
        "compression_ratio": 1.6022727272727273,
        "end": 659.0600000000001,
        "id": 276,
        "no_speech_prob": 0.000004092222297913395,
        "seek": 64910,
        "start": 658.02,
        "temperature": 0,
        "text": " I don't have an answer to that question.",
        "tokens": [
          50810,
          286,
          500,
          380,
          362,
          364,
          1867,
          281,
          300,
          1168,
          13,
          50862
        ]
      },
      {
        "avg_logprob": -0.24038575653337005,
        "compression_ratio": 1.6022727272727273,
        "end": 660.22,
        "id": 277,
        "no_speech_prob": 0.000004092222297913395,
        "seek": 64910,
        "start": 659.0600000000001,
        "temperature": 0,
        "text": " It definitely does not.",
        "tokens": [
          50862,
          467,
          2138,
          775,
          406,
          13,
          50920
        ]
      },
      {
        "avg_logprob": -0.24038575653337005,
        "compression_ratio": 1.6022727272727273,
        "end": 663.5400000000001,
        "id": 278,
        "no_speech_prob": 0.000004092222297913395,
        "seek": 64910,
        "start": 661.7,
        "temperature": 0,
        "text": " What the researchers at Google have done",
        "tokens": [
          50994,
          708,
          264,
          10309,
          412,
          3329,
          362,
          1096,
          51086
        ]
      },
      {
        "avg_logprob": -0.24038575653337005,
        "compression_ratio": 1.6022727272727273,
        "end": 667.24,
        "id": 279,
        "no_speech_prob": 0.000004092222297913395,
        "seek": 64910,
        "start": 663.5400000000001,
        "temperature": 0,
        "text": " in making tensorflow.js is nothing short of heroic",
        "tokens": [
          51086,
          294,
          1455,
          40863,
          10565,
          13,
          25530,
          307,
          1825,
          2099,
          295,
          32915,
          51271
        ]
      },
      {
        "avg_logprob": -0.24038575653337005,
        "compression_ratio": 1.6022727272727273,
        "end": 670.02,
        "id": 280,
        "no_speech_prob": 0.000004092222297913395,
        "seek": 64910,
        "start": 667.24,
        "temperature": 0,
        "text": " in getting all of the matrix operations",
        "tokens": [
          51271,
          294,
          1242,
          439,
          295,
          264,
          8141,
          7705,
          51410
        ]
      },
      {
        "avg_logprob": -0.24038575653337005,
        "compression_ratio": 1.6022727272727273,
        "end": 672.94,
        "id": 281,
        "no_speech_prob": 0.000004092222297913395,
        "seek": 64910,
        "start": 670.02,
        "temperature": 0,
        "text": " that need to happen in WebGL",
        "tokens": [
          51410,
          300,
          643,
          281,
          1051,
          294,
          9573,
          19440,
          51556
        ]
      },
      {
        "avg_logprob": -0.24038575653337005,
        "compression_ratio": 1.6022727272727273,
        "end": 675.86,
        "id": 282,
        "no_speech_prob": 0.000004092222297913395,
        "seek": 64910,
        "start": 672.94,
        "temperature": 0,
        "text": " using the GPU of the computer in the browser.",
        "tokens": [
          51556,
          1228,
          264,
          18407,
          295,
          264,
          3820,
          294,
          264,
          11185,
          13,
          51702
        ]
      },
      {
        "avg_logprob": -0.24038575653337005,
        "compression_ratio": 1.6022727272727273,
        "end": 678.32,
        "id": 283,
        "no_speech_prob": 0.000004092222297913395,
        "seek": 64910,
        "start": 675.86,
        "temperature": 0,
        "text": " But its performance is still not going to be",
        "tokens": [
          51702,
          583,
          1080,
          3389,
          307,
          920,
          406,
          516,
          281,
          312,
          51825
        ]
      },
      {
        "avg_logprob": -0.2908806039505646,
        "compression_ratio": 1.5668016194331984,
        "end": 681.6800000000001,
        "id": 284,
        "no_speech_prob": 0.0000011364425063220551,
        "seek": 67832,
        "start": 678.32,
        "temperature": 0,
        "text": " as fast as native C++ tensorflow,",
        "tokens": [
          50364,
          382,
          2370,
          382,
          8470,
          383,
          25472,
          40863,
          10565,
          11,
          50532
        ]
      },
      {
        "avg_logprob": -0.2908806039505646,
        "compression_ratio": 1.5668016194331984,
        "end": 683.9200000000001,
        "id": 285,
        "no_speech_prob": 0.0000011364425063220551,
        "seek": 67832,
        "start": 681.6800000000001,
        "temperature": 0,
        "text": " but it's remarkable how fast it is,",
        "tokens": [
          50532,
          457,
          309,
          311,
          12802,
          577,
          2370,
          309,
          307,
          11,
          50644
        ]
      },
      {
        "avg_logprob": -0.2908806039505646,
        "compression_ratio": 1.5668016194331984,
        "end": 685.88,
        "id": 286,
        "no_speech_prob": 0.0000011364425063220551,
        "seek": 67832,
        "start": 683.9200000000001,
        "temperature": 0,
        "text": " and the ease of not having to set up an environment",
        "tokens": [
          50644,
          293,
          264,
          12708,
          295,
          406,
          1419,
          281,
          992,
          493,
          364,
          2823,
          50742
        ]
      },
      {
        "avg_logprob": -0.2908806039505646,
        "compression_ratio": 1.5668016194331984,
        "end": 688.46,
        "id": 287,
        "no_speech_prob": 0.0000011364425063220551,
        "seek": 67832,
        "start": 685.88,
        "temperature": 0,
        "text": " and just go to a web page to execute a task,",
        "tokens": [
          50742,
          293,
          445,
          352,
          281,
          257,
          3670,
          3028,
          281,
          14483,
          257,
          5633,
          11,
          50871
        ]
      },
      {
        "avg_logprob": -0.2908806039505646,
        "compression_ratio": 1.5668016194331984,
        "end": 690.5600000000001,
        "id": 288,
        "no_speech_prob": 0.0000011364425063220551,
        "seek": 67832,
        "start": 688.46,
        "temperature": 0,
        "text": " to program something, to make an animation.",
        "tokens": [
          50871,
          281,
          1461,
          746,
          11,
          281,
          652,
          364,
          9603,
          13,
          50976
        ]
      },
      {
        "avg_logprob": -0.2908806039505646,
        "compression_ratio": 1.5668016194331984,
        "end": 692.96,
        "id": 289,
        "no_speech_prob": 0.0000011364425063220551,
        "seek": 67832,
        "start": 690.5600000000001,
        "temperature": 0,
        "text": " I think there's a lot of exciting possibilities there.",
        "tokens": [
          50976,
          286,
          519,
          456,
          311,
          257,
          688,
          295,
          4670,
          12178,
          456,
          13,
          51096
        ]
      },
      {
        "avg_logprob": -0.2908806039505646,
        "compression_ratio": 1.5668016194331984,
        "end": 696.3000000000001,
        "id": 290,
        "no_speech_prob": 0.0000011364425063220551,
        "seek": 67832,
        "start": 694.88,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51192,
          1033,
          13,
          51263
        ]
      },
      {
        "avg_logprob": -0.2908806039505646,
        "compression_ratio": 1.5668016194331984,
        "end": 701.3000000000001,
        "id": 291,
        "no_speech_prob": 0.0000011364425063220551,
        "seek": 67832,
        "start": 696.3000000000001,
        "temperature": 0,
        "text": " So, let's transition now to our guest.",
        "tokens": [
          51263,
          407,
          11,
          718,
          311,
          6034,
          586,
          281,
          527,
          8341,
          13,
          51513
        ]
      },
      {
        "avg_logprob": -0.2908806039505646,
        "compression_ratio": 1.5668016194331984,
        "end": 704.34,
        "id": 292,
        "no_speech_prob": 0.0000011364425063220551,
        "seek": 67832,
        "start": 702.8800000000001,
        "temperature": 0,
        "text": " And so, I'm gonna, let me see.",
        "tokens": [
          51592,
          400,
          370,
          11,
          286,
          478,
          799,
          11,
          718,
          385,
          536,
          13,
          51665
        ]
      },
      {
        "avg_logprob": -0.2908806039505646,
        "compression_ratio": 1.5668016194331984,
        "end": 706.96,
        "id": 293,
        "no_speech_prob": 0.0000011364425063220551,
        "seek": 67832,
        "start": 704.34,
        "temperature": 0,
        "text": " So, I don't remember, I'm trying to remember.",
        "tokens": [
          51665,
          407,
          11,
          286,
          500,
          380,
          1604,
          11,
          286,
          478,
          1382,
          281,
          1604,
          13,
          51796
        ]
      },
      {
        "avg_logprob": -0.2821425591315423,
        "compression_ratio": 1.8024691358024691,
        "end": 709.32,
        "id": 294,
        "no_speech_prob": 0.00000866381378727965,
        "seek": 70696,
        "start": 707.96,
        "temperature": 0,
        "text": " Oops, I'm like.",
        "tokens": [
          50414,
          21726,
          11,
          286,
          478,
          411,
          13,
          50482
        ]
      },
      {
        "avg_logprob": -0.2821425591315423,
        "compression_ratio": 1.8024691358024691,
        "end": 710.46,
        "id": 295,
        "no_speech_prob": 0.00000866381378727965,
        "seek": 70696,
        "start": 709.32,
        "temperature": 0,
        "text": " You can step into the frame.",
        "tokens": [
          50482,
          509,
          393,
          1823,
          666,
          264,
          3920,
          13,
          50539
        ]
      },
      {
        "avg_logprob": -0.2821425591315423,
        "compression_ratio": 1.8024691358024691,
        "end": 711.3000000000001,
        "id": 296,
        "no_speech_prob": 0.00000866381378727965,
        "seek": 70696,
        "start": 710.46,
        "temperature": 0,
        "text": " Welcome, Jabril.",
        "tokens": [
          50539,
          4027,
          11,
          40319,
          24216,
          13,
          50581
        ]
      },
      {
        "avg_logprob": -0.2821425591315423,
        "compression_ratio": 1.8024691358024691,
        "end": 715,
        "id": 297,
        "no_speech_prob": 0.00000866381378727965,
        "seek": 70696,
        "start": 713.8000000000001,
        "temperature": 0,
        "text": " So, I'm looking over here",
        "tokens": [
          50706,
          407,
          11,
          286,
          478,
          1237,
          670,
          510,
          50766
        ]
      },
      {
        "avg_logprob": -0.2821425591315423,
        "compression_ratio": 1.8024691358024691,
        "end": 715.96,
        "id": 298,
        "no_speech_prob": 0.00000866381378727965,
        "seek": 70696,
        "start": 715,
        "temperature": 0,
        "text": " because I have a monitor over here.",
        "tokens": [
          50766,
          570,
          286,
          362,
          257,
          6002,
          670,
          510,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2821425591315423,
        "compression_ratio": 1.8024691358024691,
        "end": 719.5600000000001,
        "id": 299,
        "no_speech_prob": 0.00000866381378727965,
        "seek": 70696,
        "start": 715.96,
        "temperature": 0,
        "text": " So, one thing, by the way, is that I have to practice",
        "tokens": [
          50814,
          407,
          11,
          472,
          551,
          11,
          538,
          264,
          636,
          11,
          307,
          300,
          286,
          362,
          281,
          3124,
          50994
        ]
      },
      {
        "avg_logprob": -0.2821425591315423,
        "compression_ratio": 1.8024691358024691,
        "end": 722.32,
        "id": 300,
        "no_speech_prob": 0.00000866381378727965,
        "seek": 70696,
        "start": 719.5600000000001,
        "temperature": 0,
        "text": " is that the people we are speaking to are there,",
        "tokens": [
          50994,
          307,
          300,
          264,
          561,
          321,
          366,
          4124,
          281,
          366,
          456,
          11,
          51132
        ]
      },
      {
        "avg_logprob": -0.2821425591315423,
        "compression_ratio": 1.8024691358024691,
        "end": 723.74,
        "id": 301,
        "no_speech_prob": 0.00000866381378727965,
        "seek": 70696,
        "start": 722.32,
        "temperature": 0,
        "text": " but you'll notice I do this a lot,",
        "tokens": [
          51132,
          457,
          291,
          603,
          3449,
          286,
          360,
          341,
          257,
          688,
          11,
          51203
        ]
      },
      {
        "avg_logprob": -0.2821425591315423,
        "compression_ratio": 1.8024691358024691,
        "end": 725.5600000000001,
        "id": 302,
        "no_speech_prob": 0.00000866381378727965,
        "seek": 70696,
        "start": 723.74,
        "temperature": 0,
        "text": " like blah, blah, blah, blah, blah,",
        "tokens": [
          51203,
          411,
          12288,
          11,
          12288,
          11,
          12288,
          11,
          12288,
          11,
          12288,
          11,
          51294
        ]
      },
      {
        "avg_logprob": -0.2821425591315423,
        "compression_ratio": 1.8024691358024691,
        "end": 727.12,
        "id": 303,
        "no_speech_prob": 0.00000866381378727965,
        "seek": 70696,
        "start": 725.5600000000001,
        "temperature": 0,
        "text": " because I'm staring at the monitor I have over here.",
        "tokens": [
          51294,
          570,
          286,
          478,
          18043,
          412,
          264,
          6002,
          286,
          362,
          670,
          510,
          13,
          51372
        ]
      },
      {
        "avg_logprob": -0.2821425591315423,
        "compression_ratio": 1.8024691358024691,
        "end": 728.88,
        "id": 304,
        "no_speech_prob": 0.00000866381378727965,
        "seek": 70696,
        "start": 727.12,
        "temperature": 0,
        "text": " You're very pro.",
        "tokens": [
          51372,
          509,
          434,
          588,
          447,
          13,
          51460
        ]
      },
      {
        "avg_logprob": -0.2821425591315423,
        "compression_ratio": 1.8024691358024691,
        "end": 731,
        "id": 305,
        "no_speech_prob": 0.00000866381378727965,
        "seek": 70696,
        "start": 728.88,
        "temperature": 0,
        "text": " Okay, so, I'm trying to think",
        "tokens": [
          51460,
          1033,
          11,
          370,
          11,
          286,
          478,
          1382,
          281,
          519,
          51566
        ]
      },
      {
        "avg_logprob": -0.2821425591315423,
        "compression_ratio": 1.8024691358024691,
        "end": 735.44,
        "id": 306,
        "no_speech_prob": 0.00000866381378727965,
        "seek": 70696,
        "start": 731,
        "temperature": 0,
        "text": " when I first discovered Jabril's channel,",
        "tokens": [
          51566,
          562,
          286,
          700,
          6941,
          40319,
          24216,
          311,
          2269,
          11,
          51788
        ]
      },
      {
        "avg_logprob": -0.22284260692212404,
        "compression_ratio": 1.6604938271604939,
        "end": 738.74,
        "id": 307,
        "no_speech_prob": 0.000014969023141020443,
        "seek": 73544,
        "start": 735.44,
        "temperature": 0,
        "text": " and I wish I had a good memory of this or story of this,",
        "tokens": [
          50364,
          293,
          286,
          3172,
          286,
          632,
          257,
          665,
          4675,
          295,
          341,
          420,
          1657,
          295,
          341,
          11,
          50529
        ]
      },
      {
        "avg_logprob": -0.22284260692212404,
        "compression_ratio": 1.6604938271604939,
        "end": 742.84,
        "id": 308,
        "no_speech_prob": 0.000014969023141020443,
        "seek": 73544,
        "start": 738.74,
        "temperature": 0,
        "text": " but I definitely remember when I first saw his video",
        "tokens": [
          50529,
          457,
          286,
          2138,
          1604,
          562,
          286,
          700,
          1866,
          702,
          960,
          50734
        ]
      },
      {
        "avg_logprob": -0.22284260692212404,
        "compression_ratio": 1.6604938271604939,
        "end": 744.6600000000001,
        "id": 309,
        "no_speech_prob": 0.000014969023141020443,
        "seek": 73544,
        "start": 742.84,
        "temperature": 0,
        "text": " on the Run Forest project.",
        "tokens": [
          50734,
          322,
          264,
          8950,
          18124,
          1716,
          13,
          50825
        ]
      },
      {
        "avg_logprob": -0.22284260692212404,
        "compression_ratio": 1.6604938271604939,
        "end": 748.08,
        "id": 310,
        "no_speech_prob": 0.000014969023141020443,
        "seek": 73544,
        "start": 745.8800000000001,
        "temperature": 0,
        "text": " So, I'll let Jabril introduce himself",
        "tokens": [
          50886,
          407,
          11,
          286,
          603,
          718,
          40319,
          24216,
          5366,
          3647,
          50996
        ]
      },
      {
        "avg_logprob": -0.22284260692212404,
        "compression_ratio": 1.6604938271604939,
        "end": 749.2800000000001,
        "id": 311,
        "no_speech_prob": 0.000014969023141020443,
        "seek": 73544,
        "start": 748.08,
        "temperature": 0,
        "text": " and say more about his background",
        "tokens": [
          50996,
          293,
          584,
          544,
          466,
          702,
          3678,
          51056
        ]
      },
      {
        "avg_logprob": -0.22284260692212404,
        "compression_ratio": 1.6604938271604939,
        "end": 751.4200000000001,
        "id": 312,
        "no_speech_prob": 0.000014969023141020443,
        "seek": 73544,
        "start": 749.2800000000001,
        "temperature": 0,
        "text": " and how he got into this machine learning stuff,",
        "tokens": [
          51056,
          293,
          577,
          415,
          658,
          666,
          341,
          3479,
          2539,
          1507,
          11,
          51163
        ]
      },
      {
        "avg_logprob": -0.22284260692212404,
        "compression_ratio": 1.6604938271604939,
        "end": 753.44,
        "id": 313,
        "no_speech_prob": 0.000014969023141020443,
        "seek": 73544,
        "start": 751.4200000000001,
        "temperature": 0,
        "text": " if you like, rather than try to do it myself.",
        "tokens": [
          51163,
          498,
          291,
          411,
          11,
          2831,
          813,
          853,
          281,
          360,
          309,
          2059,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.22284260692212404,
        "compression_ratio": 1.6604938271604939,
        "end": 755,
        "id": 314,
        "no_speech_prob": 0.000014969023141020443,
        "seek": 73544,
        "start": 753.44,
        "temperature": 0,
        "text": " But what I loved about that,",
        "tokens": [
          51264,
          583,
          437,
          286,
          4333,
          466,
          300,
          11,
          51342
        ]
      },
      {
        "avg_logprob": -0.22284260692212404,
        "compression_ratio": 1.6604938271604939,
        "end": 757.08,
        "id": 315,
        "no_speech_prob": 0.000014969023141020443,
        "seek": 73544,
        "start": 755,
        "temperature": 0,
        "text": " I have a book that some of you might be familiar with",
        "tokens": [
          51342,
          286,
          362,
          257,
          1446,
          300,
          512,
          295,
          291,
          1062,
          312,
          4963,
          365,
          51446
        ]
      },
      {
        "avg_logprob": -0.22284260692212404,
        "compression_ratio": 1.6604938271604939,
        "end": 758.62,
        "id": 316,
        "no_speech_prob": 0.000014969023141020443,
        "seek": 73544,
        "start": 757.08,
        "temperature": 0,
        "text": " called Nature of Code,",
        "tokens": [
          51446,
          1219,
          20159,
          295,
          15549,
          11,
          51523
        ]
      },
      {
        "avg_logprob": -0.22284260692212404,
        "compression_ratio": 1.6604938271604939,
        "end": 761.2,
        "id": 317,
        "no_speech_prob": 0.000014969023141020443,
        "seek": 73544,
        "start": 758.62,
        "temperature": 0,
        "text": " where I have a kind of a chapter on neural networks",
        "tokens": [
          51523,
          689,
          286,
          362,
          257,
          733,
          295,
          257,
          7187,
          322,
          18161,
          9590,
          51652
        ]
      },
      {
        "avg_logprob": -0.22284260692212404,
        "compression_ratio": 1.6604938271604939,
        "end": 762.6800000000001,
        "id": 318,
        "no_speech_prob": 0.000014969023141020443,
        "seek": 73544,
        "start": 761.2,
        "temperature": 0,
        "text": " and a chapter on genetic algorithm,",
        "tokens": [
          51652,
          293,
          257,
          7187,
          322,
          12462,
          9284,
          11,
          51726
        ]
      },
      {
        "avg_logprob": -0.22284260692212404,
        "compression_ratio": 1.6604938271604939,
        "end": 764.24,
        "id": 319,
        "no_speech_prob": 0.000014969023141020443,
        "seek": 73544,
        "start": 762.6800000000001,
        "temperature": 0,
        "text": " and they're kind of old and out of date,",
        "tokens": [
          51726,
          293,
          436,
          434,
          733,
          295,
          1331,
          293,
          484,
          295,
          4002,
          11,
          51804
        ]
      },
      {
        "avg_logprob": -0.27153973049587676,
        "compression_ratio": 1.5923566878980893,
        "end": 766.4,
        "id": 320,
        "no_speech_prob": 0.000008136948054016102,
        "seek": 76424,
        "start": 764.36,
        "temperature": 0,
        "text": " and I've kind of been wanting to expand that",
        "tokens": [
          50370,
          293,
          286,
          600,
          733,
          295,
          668,
          7935,
          281,
          5268,
          300,
          50472
        ]
      },
      {
        "avg_logprob": -0.27153973049587676,
        "compression_ratio": 1.5923566878980893,
        "end": 767.24,
        "id": 321,
        "no_speech_prob": 0.000008136948054016102,
        "seek": 76424,
        "start": 766.4,
        "temperature": 0,
        "text": " and do more with it.",
        "tokens": [
          50472,
          293,
          360,
          544,
          365,
          309,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.27153973049587676,
        "compression_ratio": 1.5923566878980893,
        "end": 769.48,
        "id": 322,
        "no_speech_prob": 0.000008136948054016102,
        "seek": 76424,
        "start": 767.24,
        "temperature": 0,
        "text": " This is my camera, it goes off every 30 minutes.",
        "tokens": [
          50514,
          639,
          307,
          452,
          2799,
          11,
          309,
          1709,
          766,
          633,
          2217,
          2077,
          13,
          50626
        ]
      },
      {
        "avg_logprob": -0.27153973049587676,
        "compression_ratio": 1.5923566878980893,
        "end": 771.64,
        "id": 323,
        "no_speech_prob": 0.000008136948054016102,
        "seek": 76424,
        "start": 769.48,
        "temperature": 0,
        "text": " Now you know you're experiencing this live.",
        "tokens": [
          50626,
          823,
          291,
          458,
          291,
          434,
          11139,
          341,
          1621,
          13,
          50734
        ]
      },
      {
        "avg_logprob": -0.27153973049587676,
        "compression_ratio": 1.5923566878980893,
        "end": 776.2,
        "id": 324,
        "no_speech_prob": 0.000008136948054016102,
        "seek": 76424,
        "start": 772.6,
        "temperature": 0,
        "text": " And so, when I saw that project,",
        "tokens": [
          50782,
          400,
          370,
          11,
          562,
          286,
          1866,
          300,
          1716,
          11,
          50962
        ]
      },
      {
        "avg_logprob": -0.27153973049587676,
        "compression_ratio": 1.5923566878980893,
        "end": 778.88,
        "id": 325,
        "no_speech_prob": 0.000008136948054016102,
        "seek": 76424,
        "start": 776.2,
        "temperature": 0,
        "text": " the Run Forest project, which if you haven't seen,",
        "tokens": [
          50962,
          264,
          8950,
          18124,
          1716,
          11,
          597,
          498,
          291,
          2378,
          380,
          1612,
          11,
          51096
        ]
      },
      {
        "avg_logprob": -0.27153973049587676,
        "compression_ratio": 1.5923566878980893,
        "end": 780.88,
        "id": 326,
        "no_speech_prob": 0.000008136948054016102,
        "seek": 76424,
        "start": 778.88,
        "temperature": 0,
        "text": " it's a Unity-based simulation",
        "tokens": [
          51096,
          309,
          311,
          257,
          27913,
          12,
          6032,
          16575,
          51196
        ]
      },
      {
        "avg_logprob": -0.27153973049587676,
        "compression_ratio": 1.5923566878980893,
        "end": 784.12,
        "id": 327,
        "no_speech_prob": 0.000008136948054016102,
        "seek": 76424,
        "start": 780.88,
        "temperature": 0,
        "text": " that trains a simulation forest gum, basically,",
        "tokens": [
          51196,
          300,
          16329,
          257,
          16575,
          6719,
          19973,
          11,
          1936,
          11,
          51358
        ]
      },
      {
        "avg_logprob": -0.27153973049587676,
        "compression_ratio": 1.5923566878980893,
        "end": 785.88,
        "id": 328,
        "no_speech_prob": 0.000008136948054016102,
        "seek": 76424,
        "start": 784.12,
        "temperature": 0,
        "text": " character to run around a maze",
        "tokens": [
          51358,
          2517,
          281,
          1190,
          926,
          257,
          33032,
          51446
        ]
      },
      {
        "avg_logprob": -0.27153973049587676,
        "compression_ratio": 1.5923566878980893,
        "end": 787.92,
        "id": 329,
        "no_speech_prob": 0.000008136948054016102,
        "seek": 76424,
        "start": 785.88,
        "temperature": 0,
        "text": " using both neural networks and genetic algorithms,",
        "tokens": [
          51446,
          1228,
          1293,
          18161,
          9590,
          293,
          12462,
          14642,
          11,
          51548
        ]
      },
      {
        "avg_logprob": -0.27153973049587676,
        "compression_ratio": 1.5923566878980893,
        "end": 789.24,
        "id": 330,
        "no_speech_prob": 0.000008136948054016102,
        "seek": 76424,
        "start": 787.92,
        "temperature": 0,
        "text": " and it was really like I looked at it like,",
        "tokens": [
          51548,
          293,
          309,
          390,
          534,
          411,
          286,
          2956,
          412,
          309,
          411,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.27153973049587676,
        "compression_ratio": 1.5923566878980893,
        "end": 792.72,
        "id": 331,
        "no_speech_prob": 0.000008136948054016102,
        "seek": 76424,
        "start": 789.24,
        "temperature": 0,
        "text": " oh, this is the perfect kind of demonstration example",
        "tokens": [
          51614,
          1954,
          11,
          341,
          307,
          264,
          2176,
          733,
          295,
          16520,
          1365,
          51788
        ]
      },
      {
        "avg_logprob": -0.25521288894292876,
        "compression_ratio": 1.6691176470588236,
        "end": 795.28,
        "id": 332,
        "no_speech_prob": 0.00001951242120412644,
        "seek": 79272,
        "start": 792.72,
        "temperature": 0,
        "text": " in the kind of creative coding or game making",
        "tokens": [
          50364,
          294,
          264,
          733,
          295,
          5880,
          17720,
          420,
          1216,
          1455,
          50492
        ]
      },
      {
        "avg_logprob": -0.25521288894292876,
        "compression_ratio": 1.6691176470588236,
        "end": 798.4,
        "id": 333,
        "no_speech_prob": 0.00001951242120412644,
        "seek": 79272,
        "start": 795.28,
        "temperature": 0,
        "text": " or art making context of how to apply machine learning",
        "tokens": [
          50492,
          420,
          1523,
          1455,
          4319,
          295,
          577,
          281,
          3079,
          3479,
          2539,
          50648
        ]
      },
      {
        "avg_logprob": -0.25521288894292876,
        "compression_ratio": 1.6691176470588236,
        "end": 800.88,
        "id": 334,
        "no_speech_prob": 0.00001951242120412644,
        "seek": 79272,
        "start": 798.4,
        "temperature": 0,
        "text": " to a simple, I mean, it's not that simple,",
        "tokens": [
          50648,
          281,
          257,
          2199,
          11,
          286,
          914,
          11,
          309,
          311,
          406,
          300,
          2199,
          11,
          50772
        ]
      },
      {
        "avg_logprob": -0.25521288894292876,
        "compression_ratio": 1.6691176470588236,
        "end": 804.6800000000001,
        "id": 335,
        "no_speech_prob": 0.00001951242120412644,
        "seek": 79272,
        "start": 800.88,
        "temperature": 0,
        "text": " but to a graphics motion-based simulation.",
        "tokens": [
          50772,
          457,
          281,
          257,
          11837,
          5394,
          12,
          6032,
          16575,
          13,
          50962
        ]
      },
      {
        "avg_logprob": -0.25521288894292876,
        "compression_ratio": 1.6691176470588236,
        "end": 806.24,
        "id": 336,
        "no_speech_prob": 0.00001951242120412644,
        "seek": 79272,
        "start": 804.6800000000001,
        "temperature": 0,
        "text": " So I was super excited to see that,",
        "tokens": [
          50962,
          407,
          286,
          390,
          1687,
          2919,
          281,
          536,
          300,
          11,
          51040
        ]
      },
      {
        "avg_logprob": -0.25521288894292876,
        "compression_ratio": 1.6691176470588236,
        "end": 808.0400000000001,
        "id": 337,
        "no_speech_prob": 0.00001951242120412644,
        "seek": 79272,
        "start": 806.24,
        "temperature": 0,
        "text": " inspired me to think about some new stuff",
        "tokens": [
          51040,
          7547,
          385,
          281,
          519,
          466,
          512,
          777,
          1507,
          51130
        ]
      },
      {
        "avg_logprob": -0.25521288894292876,
        "compression_ratio": 1.6691176470588236,
        "end": 809.96,
        "id": 338,
        "no_speech_prob": 0.00001951242120412644,
        "seek": 79272,
        "start": 808.0400000000001,
        "temperature": 0,
        "text": " and where I wanted to take some of my tutorials",
        "tokens": [
          51130,
          293,
          689,
          286,
          1415,
          281,
          747,
          512,
          295,
          452,
          17616,
          51226
        ]
      },
      {
        "avg_logprob": -0.25521288894292876,
        "compression_ratio": 1.6691176470588236,
        "end": 811.6,
        "id": 339,
        "no_speech_prob": 0.00001951242120412644,
        "seek": 79272,
        "start": 809.96,
        "temperature": 0,
        "text": " in JavaScript, I don't know.",
        "tokens": [
          51226,
          294,
          15778,
          11,
          286,
          500,
          380,
          458,
          13,
          51308
        ]
      },
      {
        "avg_logprob": -0.25521288894292876,
        "compression_ratio": 1.6691176470588236,
        "end": 814.28,
        "id": 340,
        "no_speech_prob": 0.00001951242120412644,
        "seek": 79272,
        "start": 811.6,
        "temperature": 0,
        "text": " The internet puts people in touch.",
        "tokens": [
          51308,
          440,
          4705,
          8137,
          561,
          294,
          2557,
          13,
          51442
        ]
      },
      {
        "avg_logprob": -0.25521288894292876,
        "compression_ratio": 1.6691176470588236,
        "end": 815.4,
        "id": 341,
        "no_speech_prob": 0.00001951242120412644,
        "seek": 79272,
        "start": 814.28,
        "temperature": 0,
        "text": " I've been watching his videos,",
        "tokens": [
          51442,
          286,
          600,
          668,
          1976,
          702,
          2145,
          11,
          51498
        ]
      },
      {
        "avg_logprob": -0.25521288894292876,
        "compression_ratio": 1.6691176470588236,
        "end": 818.28,
        "id": 342,
        "no_speech_prob": 0.00001951242120412644,
        "seek": 79272,
        "start": 815.4,
        "temperature": 0,
        "text": " I think he's watching some of mine, we'll see.",
        "tokens": [
          51498,
          286,
          519,
          415,
          311,
          1976,
          512,
          295,
          3892,
          11,
          321,
          603,
          536,
          13,
          51642
        ]
      },
      {
        "avg_logprob": -0.2220130532474841,
        "compression_ratio": 1.6538461538461537,
        "end": 823.28,
        "id": 343,
        "no_speech_prob": 0.00003425375689403154,
        "seek": 81828,
        "start": 818.28,
        "temperature": 0,
        "text": " And so, welcome to the coding train.",
        "tokens": [
          50364,
          400,
          370,
          11,
          2928,
          281,
          264,
          17720,
          3847,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2220130532474841,
        "compression_ratio": 1.6538461538461537,
        "end": 825.48,
        "id": 344,
        "no_speech_prob": 0.00003425375689403154,
        "seek": 81828,
        "start": 823.52,
        "temperature": 0,
        "text": " So what I'm gonna do, awkwardly,",
        "tokens": [
          50626,
          407,
          437,
          286,
          478,
          799,
          360,
          11,
          11411,
          356,
          11,
          50724
        ]
      },
      {
        "avg_logprob": -0.2220130532474841,
        "compression_ratio": 1.6538461538461537,
        "end": 829.76,
        "id": 345,
        "no_speech_prob": 0.00003425375689403154,
        "seek": 81828,
        "start": 825.48,
        "temperature": 0,
        "text": " is I'm going to take my coffee and my laptop",
        "tokens": [
          50724,
          307,
          286,
          478,
          516,
          281,
          747,
          452,
          4982,
          293,
          452,
          10732,
          50938
        ]
      },
      {
        "avg_logprob": -0.2220130532474841,
        "compression_ratio": 1.6538461538461537,
        "end": 831.64,
        "id": 346,
        "no_speech_prob": 0.00003425375689403154,
        "seek": 81828,
        "start": 829.76,
        "temperature": 0,
        "text": " and I'm gonna slide out of the way and go sit,",
        "tokens": [
          50938,
          293,
          286,
          478,
          799,
          4137,
          484,
          295,
          264,
          636,
          293,
          352,
          1394,
          11,
          51032
        ]
      },
      {
        "avg_logprob": -0.2220130532474841,
        "compression_ratio": 1.6538461538461537,
        "end": 833,
        "id": 347,
        "no_speech_prob": 0.00003425375689403154,
        "seek": 81828,
        "start": 831.64,
        "temperature": 0,
        "text": " there's a chair over there,",
        "tokens": [
          51032,
          456,
          311,
          257,
          6090,
          670,
          456,
          11,
          51100
        ]
      },
      {
        "avg_logprob": -0.2220130532474841,
        "compression_ratio": 1.6538461538461537,
        "end": 835.12,
        "id": 348,
        "no_speech_prob": 0.00003425375689403154,
        "seek": 81828,
        "start": 833,
        "temperature": 0,
        "text": " and then I'm gonna turn it over to you.",
        "tokens": [
          51100,
          293,
          550,
          286,
          478,
          799,
          1261,
          309,
          670,
          281,
          291,
          13,
          51206
        ]
      },
      {
        "avg_logprob": -0.2220130532474841,
        "compression_ratio": 1.6538461538461537,
        "end": 836.64,
        "id": 349,
        "no_speech_prob": 0.00003425375689403154,
        "seek": 81828,
        "start": 835.12,
        "temperature": 0,
        "text": " I might mute my microphone",
        "tokens": [
          51206,
          286,
          1062,
          24523,
          452,
          10952,
          51282
        ]
      },
      {
        "avg_logprob": -0.2220130532474841,
        "compression_ratio": 1.6538461538461537,
        "end": 839.9599999999999,
        "id": 350,
        "no_speech_prob": 0.00003425375689403154,
        "seek": 81828,
        "start": 836.64,
        "temperature": 0,
        "text": " and you can talk about your project and code",
        "tokens": [
          51282,
          293,
          291,
          393,
          751,
          466,
          428,
          1716,
          293,
          3089,
          51448
        ]
      },
      {
        "avg_logprob": -0.2220130532474841,
        "compression_ratio": 1.6538461538461537,
        "end": 844.56,
        "id": 351,
        "no_speech_prob": 0.00003425375689403154,
        "seek": 81828,
        "start": 839.9599999999999,
        "temperature": 0,
        "text": " and I'll watch the chat to see if there are questions.",
        "tokens": [
          51448,
          293,
          286,
          603,
          1159,
          264,
          5081,
          281,
          536,
          498,
          456,
          366,
          1651,
          13,
          51678
        ]
      },
      {
        "avg_logprob": -0.2220130532474841,
        "compression_ratio": 1.6538461538461537,
        "end": 846.1999999999999,
        "id": 352,
        "no_speech_prob": 0.00003425375689403154,
        "seek": 81828,
        "start": 844.56,
        "temperature": 0,
        "text": " So after a little bit of time,",
        "tokens": [
          51678,
          407,
          934,
          257,
          707,
          857,
          295,
          565,
          11,
          51760
        ]
      },
      {
        "avg_logprob": -0.25164395650227867,
        "compression_ratio": 1.617363344051447,
        "end": 848.2800000000001,
        "id": 353,
        "no_speech_prob": 0.009548095054924488,
        "seek": 84620,
        "start": 846.2,
        "temperature": 0,
        "text": " I'll come back and ask you some of the questions",
        "tokens": [
          50364,
          286,
          603,
          808,
          646,
          293,
          1029,
          291,
          512,
          295,
          264,
          1651,
          50468
        ]
      },
      {
        "avg_logprob": -0.25164395650227867,
        "compression_ratio": 1.617363344051447,
        "end": 849.12,
        "id": 354,
        "no_speech_prob": 0.009548095054924488,
        "seek": 84620,
        "start": 848.2800000000001,
        "temperature": 0,
        "text": " that people have asked.",
        "tokens": [
          50468,
          300,
          561,
          362,
          2351,
          13,
          50510
        ]
      },
      {
        "avg_logprob": -0.25164395650227867,
        "compression_ratio": 1.617363344051447,
        "end": 849.96,
        "id": 355,
        "no_speech_prob": 0.009548095054924488,
        "seek": 84620,
        "start": 849.12,
        "temperature": 0,
        "text": " Sweet.",
        "tokens": [
          50510,
          14653,
          13,
          50552
        ]
      },
      {
        "avg_logprob": -0.25164395650227867,
        "compression_ratio": 1.617363344051447,
        "end": 850.8000000000001,
        "id": 356,
        "no_speech_prob": 0.009548095054924488,
        "seek": 84620,
        "start": 849.96,
        "temperature": 0,
        "text": " Make sense?",
        "tokens": [
          50552,
          4387,
          2020,
          30,
          50594
        ]
      },
      {
        "avg_logprob": -0.25164395650227867,
        "compression_ratio": 1.617363344051447,
        "end": 851.6400000000001,
        "id": 357,
        "no_speech_prob": 0.009548095054924488,
        "seek": 84620,
        "start": 850.8000000000001,
        "temperature": 0,
        "text": " Very cool.",
        "tokens": [
          50594,
          4372,
          1627,
          13,
          50636
        ]
      },
      {
        "avg_logprob": -0.25164395650227867,
        "compression_ratio": 1.617363344051447,
        "end": 854.96,
        "id": 358,
        "no_speech_prob": 0.009548095054924488,
        "seek": 84620,
        "start": 851.6400000000001,
        "temperature": 0,
        "text": " Okay, shuffle, awkward, shuffle, awkward, okay.",
        "tokens": [
          50636,
          1033,
          11,
          39426,
          11,
          11411,
          11,
          39426,
          11,
          11411,
          11,
          1392,
          13,
          50802
        ]
      },
      {
        "avg_logprob": -0.25164395650227867,
        "compression_ratio": 1.617363344051447,
        "end": 858.36,
        "id": 359,
        "no_speech_prob": 0.009548095054924488,
        "seek": 84620,
        "start": 854.96,
        "temperature": 0,
        "text": " All right, howdy, everyone, how is it going?",
        "tokens": [
          50802,
          1057,
          558,
          11,
          577,
          3173,
          11,
          1518,
          11,
          577,
          307,
          309,
          516,
          30,
          50972
        ]
      },
      {
        "avg_logprob": -0.25164395650227867,
        "compression_ratio": 1.617363344051447,
        "end": 860.36,
        "id": 360,
        "no_speech_prob": 0.009548095054924488,
        "seek": 84620,
        "start": 858.36,
        "temperature": 0,
        "text": " So yeah, I'm gonna give a little brief overview",
        "tokens": [
          50972,
          407,
          1338,
          11,
          286,
          478,
          799,
          976,
          257,
          707,
          5353,
          12492,
          51072
        ]
      },
      {
        "avg_logprob": -0.25164395650227867,
        "compression_ratio": 1.617363344051447,
        "end": 863.24,
        "id": 361,
        "no_speech_prob": 0.009548095054924488,
        "seek": 84620,
        "start": 860.36,
        "temperature": 0,
        "text": " about who I am for those of you that do not know,",
        "tokens": [
          51072,
          466,
          567,
          286,
          669,
          337,
          729,
          295,
          291,
          300,
          360,
          406,
          458,
          11,
          51216
        ]
      },
      {
        "avg_logprob": -0.25164395650227867,
        "compression_ratio": 1.617363344051447,
        "end": 865.36,
        "id": 362,
        "no_speech_prob": 0.009548095054924488,
        "seek": 84620,
        "start": 863.24,
        "temperature": 0,
        "text": " which I'm sure is all of you.",
        "tokens": [
          51216,
          597,
          286,
          478,
          988,
          307,
          439,
          295,
          291,
          13,
          51322
        ]
      },
      {
        "avg_logprob": -0.25164395650227867,
        "compression_ratio": 1.617363344051447,
        "end": 868.2,
        "id": 363,
        "no_speech_prob": 0.009548095054924488,
        "seek": 84620,
        "start": 865.36,
        "temperature": 0,
        "text": " So my name is Jabril, I run a little YouTube channel",
        "tokens": [
          51322,
          407,
          452,
          1315,
          307,
          40319,
          24216,
          11,
          286,
          1190,
          257,
          707,
          3088,
          2269,
          51464
        ]
      },
      {
        "avg_logprob": -0.25164395650227867,
        "compression_ratio": 1.617363344051447,
        "end": 870,
        "id": 364,
        "no_speech_prob": 0.009548095054924488,
        "seek": 84620,
        "start": 868.2,
        "temperature": 0,
        "text": " called Jabril's here on YouTube.",
        "tokens": [
          51464,
          1219,
          40319,
          24216,
          311,
          510,
          322,
          3088,
          13,
          51554
        ]
      },
      {
        "avg_logprob": -0.25164395650227867,
        "compression_ratio": 1.617363344051447,
        "end": 872.6800000000001,
        "id": 365,
        "no_speech_prob": 0.009548095054924488,
        "seek": 84620,
        "start": 870,
        "temperature": 0,
        "text": " And recently I converted my channel",
        "tokens": [
          51554,
          400,
          3938,
          286,
          16424,
          452,
          2269,
          51688
        ]
      },
      {
        "avg_logprob": -0.25164395650227867,
        "compression_ratio": 1.617363344051447,
        "end": 875.72,
        "id": 366,
        "no_speech_prob": 0.009548095054924488,
        "seek": 84620,
        "start": 872.6800000000001,
        "temperature": 0,
        "text": " to focus on computer science, that happened in September,",
        "tokens": [
          51688,
          281,
          1879,
          322,
          3820,
          3497,
          11,
          300,
          2011,
          294,
          7216,
          11,
          51840
        ]
      },
      {
        "avg_logprob": -0.23549672762552898,
        "compression_ratio": 1.75,
        "end": 878.1600000000001,
        "id": 367,
        "no_speech_prob": 0.000709302257746458,
        "seek": 87572,
        "start": 875.72,
        "temperature": 0,
        "text": " and that was probably one of the best things I've ever done",
        "tokens": [
          50364,
          293,
          300,
          390,
          1391,
          472,
          295,
          264,
          1151,
          721,
          286,
          600,
          1562,
          1096,
          50486
        ]
      },
      {
        "avg_logprob": -0.23549672762552898,
        "compression_ratio": 1.75,
        "end": 880.36,
        "id": 368,
        "no_speech_prob": 0.000709302257746458,
        "seek": 87572,
        "start": 878.1600000000001,
        "temperature": 0,
        "text": " because I learned that, you know,",
        "tokens": [
          50486,
          570,
          286,
          3264,
          300,
          11,
          291,
          458,
          11,
          50596
        ]
      },
      {
        "avg_logprob": -0.23549672762552898,
        "compression_ratio": 1.75,
        "end": 882.2,
        "id": 369,
        "no_speech_prob": 0.000709302257746458,
        "seek": 87572,
        "start": 880.36,
        "temperature": 0,
        "text": " I had a great passion for writing code",
        "tokens": [
          50596,
          286,
          632,
          257,
          869,
          5418,
          337,
          3579,
          3089,
          50688
        ]
      },
      {
        "avg_logprob": -0.23549672762552898,
        "compression_ratio": 1.75,
        "end": 885.1600000000001,
        "id": 370,
        "no_speech_prob": 0.000709302257746458,
        "seek": 87572,
        "start": 882.2,
        "temperature": 0,
        "text": " and making products and projects",
        "tokens": [
          50688,
          293,
          1455,
          3383,
          293,
          4455,
          50836
        ]
      },
      {
        "avg_logprob": -0.23549672762552898,
        "compression_ratio": 1.75,
        "end": 886.84,
        "id": 371,
        "no_speech_prob": 0.000709302257746458,
        "seek": 87572,
        "start": 885.1600000000001,
        "temperature": 0,
        "text": " that were based on computer science.",
        "tokens": [
          50836,
          300,
          645,
          2361,
          322,
          3820,
          3497,
          13,
          50920
        ]
      },
      {
        "avg_logprob": -0.23549672762552898,
        "compression_ratio": 1.75,
        "end": 891.28,
        "id": 372,
        "no_speech_prob": 0.000709302257746458,
        "seek": 87572,
        "start": 886.84,
        "temperature": 0,
        "text": " And so, yeah, I mean, obviously, if I had a passion for that",
        "tokens": [
          50920,
          400,
          370,
          11,
          1338,
          11,
          286,
          914,
          11,
          2745,
          11,
          498,
          286,
          632,
          257,
          5418,
          337,
          300,
          51142
        ]
      },
      {
        "avg_logprob": -0.23549672762552898,
        "compression_ratio": 1.75,
        "end": 896.28,
        "id": 373,
        "no_speech_prob": 0.000709302257746458,
        "seek": 87572,
        "start": 891.28,
        "temperature": 0,
        "text": " it was easy to show that in video projects as well.",
        "tokens": [
          51142,
          309,
          390,
          1858,
          281,
          855,
          300,
          294,
          960,
          4455,
          382,
          731,
          13,
          51392
        ]
      },
      {
        "avg_logprob": -0.23549672762552898,
        "compression_ratio": 1.75,
        "end": 900.08,
        "id": 374,
        "no_speech_prob": 0.000709302257746458,
        "seek": 87572,
        "start": 896.4,
        "temperature": 0,
        "text": " And fast forward, so one of the biggest projects",
        "tokens": [
          51398,
          400,
          2370,
          2128,
          11,
          370,
          472,
          295,
          264,
          3880,
          4455,
          51582
        ]
      },
      {
        "avg_logprob": -0.23549672762552898,
        "compression_ratio": 1.75,
        "end": 902.24,
        "id": 375,
        "no_speech_prob": 0.000709302257746458,
        "seek": 87572,
        "start": 900.08,
        "temperature": 0,
        "text": " that I've produced to date is the Run Forest project",
        "tokens": [
          51582,
          300,
          286,
          600,
          7126,
          281,
          4002,
          307,
          264,
          8950,
          18124,
          1716,
          51690
        ]
      },
      {
        "avg_logprob": -0.23549672762552898,
        "compression_ratio": 1.75,
        "end": 904.4,
        "id": 376,
        "no_speech_prob": 0.000709302257746458,
        "seek": 87572,
        "start": 902.24,
        "temperature": 0,
        "text": " that got a lot of eyes.",
        "tokens": [
          51690,
          300,
          658,
          257,
          688,
          295,
          2575,
          13,
          51798
        ]
      },
      {
        "avg_logprob": -0.2673501312417328,
        "compression_ratio": 1.7002881844380404,
        "end": 905.9599999999999,
        "id": 377,
        "no_speech_prob": 0.004752190783619881,
        "seek": 90440,
        "start": 904.4399999999999,
        "temperature": 0,
        "text": " I'm really grateful for,",
        "tokens": [
          50366,
          286,
          478,
          534,
          7941,
          337,
          11,
          50442
        ]
      },
      {
        "avg_logprob": -0.2673501312417328,
        "compression_ratio": 1.7002881844380404,
        "end": 908.88,
        "id": 378,
        "no_speech_prob": 0.004752190783619881,
        "seek": 90440,
        "start": 905.9599999999999,
        "temperature": 0,
        "text": " and that really harnessed the power of machine learning,",
        "tokens": [
          50442,
          293,
          300,
          534,
          276,
          1083,
          10830,
          264,
          1347,
          295,
          3479,
          2539,
          11,
          50588
        ]
      },
      {
        "avg_logprob": -0.2673501312417328,
        "compression_ratio": 1.7002881844380404,
        "end": 911.88,
        "id": 379,
        "no_speech_prob": 0.004752190783619881,
        "seek": 90440,
        "start": 908.88,
        "temperature": 0,
        "text": " which is a really big buzzword these days.",
        "tokens": [
          50588,
          597,
          307,
          257,
          534,
          955,
          13036,
          7462,
          613,
          1708,
          13,
          50738
        ]
      },
      {
        "avg_logprob": -0.2673501312417328,
        "compression_ratio": 1.7002881844380404,
        "end": 915.04,
        "id": 380,
        "no_speech_prob": 0.004752190783619881,
        "seek": 90440,
        "start": 911.88,
        "temperature": 0,
        "text": " And yeah, that's pretty much overview.",
        "tokens": [
          50738,
          400,
          1338,
          11,
          300,
          311,
          1238,
          709,
          12492,
          13,
          50896
        ]
      },
      {
        "avg_logprob": -0.2673501312417328,
        "compression_ratio": 1.7002881844380404,
        "end": 916.9599999999999,
        "id": 381,
        "no_speech_prob": 0.004752190783619881,
        "seek": 90440,
        "start": 915.04,
        "temperature": 0,
        "text": " I spent nine months learning on how to write",
        "tokens": [
          50896,
          286,
          4418,
          4949,
          2493,
          2539,
          322,
          577,
          281,
          2464,
          50992
        ]
      },
      {
        "avg_logprob": -0.2673501312417328,
        "compression_ratio": 1.7002881844380404,
        "end": 919.3199999999999,
        "id": 382,
        "no_speech_prob": 0.004752190783619881,
        "seek": 90440,
        "start": 916.9599999999999,
        "temperature": 0,
        "text": " neural networks from scratch, which I-",
        "tokens": [
          50992,
          18161,
          9590,
          490,
          8459,
          11,
          597,
          286,
          12,
          51110
        ]
      },
      {
        "avg_logprob": -0.2673501312417328,
        "compression_ratio": 1.7002881844380404,
        "end": 920.4,
        "id": 383,
        "no_speech_prob": 0.004752190783619881,
        "seek": 90440,
        "start": 919.3199999999999,
        "temperature": 0,
        "text": " Sorry, I'm gonna pause you for a second.",
        "tokens": [
          51110,
          4919,
          11,
          286,
          478,
          799,
          10465,
          291,
          337,
          257,
          1150,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2673501312417328,
        "compression_ratio": 1.7002881844380404,
        "end": 922.04,
        "id": 384,
        "no_speech_prob": 0.004752190783619881,
        "seek": 90440,
        "start": 920.4,
        "temperature": 0,
        "text": " People are telling me the audio is low.",
        "tokens": [
          51164,
          3432,
          366,
          3585,
          385,
          264,
          6278,
          307,
          2295,
          13,
          51246
        ]
      },
      {
        "avg_logprob": -0.2673501312417328,
        "compression_ratio": 1.7002881844380404,
        "end": 923.1999999999999,
        "id": 385,
        "no_speech_prob": 0.004752190783619881,
        "seek": 90440,
        "start": 922.04,
        "temperature": 0,
        "text": " Oh, okay.",
        "tokens": [
          51246,
          876,
          11,
          1392,
          13,
          51304
        ]
      },
      {
        "avg_logprob": -0.2673501312417328,
        "compression_ratio": 1.7002881844380404,
        "end": 924.4399999999999,
        "id": 386,
        "no_speech_prob": 0.004752190783619881,
        "seek": 90440,
        "start": 923.1999999999999,
        "temperature": 0,
        "text": " So let's do a little,",
        "tokens": [
          51304,
          407,
          718,
          311,
          360,
          257,
          707,
          11,
          51366
        ]
      },
      {
        "avg_logprob": -0.2673501312417328,
        "compression_ratio": 1.7002881844380404,
        "end": 925.8,
        "id": 387,
        "no_speech_prob": 0.004752190783619881,
        "seek": 90440,
        "start": 924.4399999999999,
        "temperature": 0,
        "text": " I'm sorry to interrupt you in the middle.",
        "tokens": [
          51366,
          286,
          478,
          2597,
          281,
          12729,
          291,
          294,
          264,
          2808,
          13,
          51434
        ]
      },
      {
        "avg_logprob": -0.2673501312417328,
        "compression_ratio": 1.7002881844380404,
        "end": 928.3199999999999,
        "id": 388,
        "no_speech_prob": 0.004752190783619881,
        "seek": 90440,
        "start": 925.8,
        "temperature": 0,
        "text": " Let's do a little- No, no worries, no worries.",
        "tokens": [
          51434,
          961,
          311,
          360,
          257,
          707,
          12,
          883,
          11,
          572,
          16340,
          11,
          572,
          16340,
          13,
          51560
        ]
      },
      {
        "avg_logprob": -0.2673501312417328,
        "compression_ratio": 1.7002881844380404,
        "end": 929.4,
        "id": 389,
        "no_speech_prob": 0.004752190783619881,
        "seek": 90440,
        "start": 928.3199999999999,
        "temperature": 0,
        "text": " Is my placing good?",
        "tokens": [
          51560,
          1119,
          452,
          17221,
          665,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.2673501312417328,
        "compression_ratio": 1.7002881844380404,
        "end": 930.24,
        "id": 390,
        "no_speech_prob": 0.004752190783619881,
        "seek": 90440,
        "start": 929.4,
        "temperature": 0,
        "text": " Oh, you know what?",
        "tokens": [
          51614,
          876,
          11,
          291,
          458,
          437,
          30,
          51656
        ]
      },
      {
        "avg_logprob": -0.2673501312417328,
        "compression_ratio": 1.7002881844380404,
        "end": 931.4,
        "id": 391,
        "no_speech_prob": 0.004752190783619881,
        "seek": 90440,
        "start": 930.24,
        "temperature": 0,
        "text": " It's because it's going through, it's fine.",
        "tokens": [
          51656,
          467,
          311,
          570,
          309,
          311,
          516,
          807,
          11,
          309,
          311,
          2489,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2673501312417328,
        "compression_ratio": 1.7002881844380404,
        "end": 932.24,
        "id": 392,
        "no_speech_prob": 0.004752190783619881,
        "seek": 90440,
        "start": 931.4,
        "temperature": 0,
        "text": " You're good, you're good.",
        "tokens": [
          51714,
          509,
          434,
          665,
          11,
          291,
          434,
          665,
          13,
          51756
        ]
      },
      {
        "avg_logprob": -0.2673501312417328,
        "compression_ratio": 1.7002881844380404,
        "end": 933.0799999999999,
        "id": 393,
        "no_speech_prob": 0.004752190783619881,
        "seek": 90440,
        "start": 932.24,
        "temperature": 0,
        "text": " Okay. I got it.",
        "tokens": [
          51756,
          1033,
          13,
          286,
          658,
          309,
          13,
          51798
        ]
      },
      {
        "avg_logprob": -0.2673501312417328,
        "compression_ratio": 1.7002881844380404,
        "end": 933.9,
        "id": 394,
        "no_speech_prob": 0.004752190783619881,
        "seek": 90440,
        "start": 933.0799999999999,
        "temperature": 0,
        "text": " I have an idea.",
        "tokens": [
          51798,
          286,
          362,
          364,
          1558,
          13,
          51839
        ]
      },
      {
        "avg_logprob": -0.3278346342198989,
        "compression_ratio": 1.5272727272727273,
        "end": 935.86,
        "id": 395,
        "no_speech_prob": 0.052599094808101654,
        "seek": 93390,
        "start": 934.86,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50412,
          1033,
          13,
          50462
        ]
      },
      {
        "avg_logprob": -0.3278346342198989,
        "compression_ratio": 1.5272727272727273,
        "end": 937.66,
        "id": 396,
        "no_speech_prob": 0.052599094808101654,
        "seek": 93390,
        "start": 935.86,
        "temperature": 0,
        "text": " I got a little time, so I'll dance.",
        "tokens": [
          50462,
          286,
          658,
          257,
          707,
          565,
          11,
          370,
          286,
          603,
          4489,
          13,
          50552
        ]
      },
      {
        "avg_logprob": -0.3278346342198989,
        "compression_ratio": 1.5272727272727273,
        "end": 940.22,
        "id": 397,
        "no_speech_prob": 0.052599094808101654,
        "seek": 93390,
        "start": 938.6999999999999,
        "temperature": 0,
        "text": " I actually muted myself.",
        "tokens": [
          50604,
          286,
          767,
          32808,
          2059,
          13,
          50680
        ]
      },
      {
        "avg_logprob": -0.3278346342198989,
        "compression_ratio": 1.5272727272727273,
        "end": 948.4599999999999,
        "id": 398,
        "no_speech_prob": 0.052599094808101654,
        "seek": 93390,
        "start": 947.3,
        "temperature": 0,
        "text": " Tap your mic for a second.",
        "tokens": [
          51034,
          13445,
          428,
          3123,
          337,
          257,
          1150,
          13,
          51092
        ]
      },
      {
        "avg_logprob": -0.3278346342198989,
        "compression_ratio": 1.5272727272727273,
        "end": 949.3,
        "id": 399,
        "no_speech_prob": 0.052599094808101654,
        "seek": 93390,
        "start": 948.4599999999999,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51092,
          1033,
          13,
          51134
        ]
      },
      {
        "avg_logprob": -0.3278346342198989,
        "compression_ratio": 1.5272727272727273,
        "end": 952.02,
        "id": 400,
        "no_speech_prob": 0.052599094808101654,
        "seek": 93390,
        "start": 951.18,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51228,
          1057,
          558,
          13,
          51270
        ]
      },
      {
        "avg_logprob": -0.3278346342198989,
        "compression_ratio": 1.5272727272727273,
        "end": 952.86,
        "id": 401,
        "no_speech_prob": 0.052599094808101654,
        "seek": 93390,
        "start": 952.02,
        "temperature": 0,
        "text": " Let's see if this is better for people.",
        "tokens": [
          51270,
          961,
          311,
          536,
          498,
          341,
          307,
          1101,
          337,
          561,
          13,
          51312
        ]
      },
      {
        "avg_logprob": -0.3278346342198989,
        "compression_ratio": 1.5272727272727273,
        "end": 955.9,
        "id": 402,
        "no_speech_prob": 0.052599094808101654,
        "seek": 93390,
        "start": 952.86,
        "temperature": 0,
        "text": " All right, just let us know if this mic is still too low.",
        "tokens": [
          51312,
          1057,
          558,
          11,
          445,
          718,
          505,
          458,
          498,
          341,
          3123,
          307,
          920,
          886,
          2295,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.3278346342198989,
        "compression_ratio": 1.5272727272727273,
        "end": 957.3,
        "id": 403,
        "no_speech_prob": 0.052599094808101654,
        "seek": 93390,
        "start": 955.9,
        "temperature": 0,
        "text": " But yeah, that's pretty much overview.",
        "tokens": [
          51464,
          583,
          1338,
          11,
          300,
          311,
          1238,
          709,
          12492,
          13,
          51534
        ]
      },
      {
        "avg_logprob": -0.3278346342198989,
        "compression_ratio": 1.5272727272727273,
        "end": 959.02,
        "id": 404,
        "no_speech_prob": 0.052599094808101654,
        "seek": 93390,
        "start": 957.3,
        "temperature": 0,
        "text": " I spent about nine months learning",
        "tokens": [
          51534,
          286,
          4418,
          466,
          4949,
          2493,
          2539,
          51620
        ]
      },
      {
        "avg_logprob": -0.3278346342198989,
        "compression_ratio": 1.5272727272727273,
        "end": 962.9,
        "id": 405,
        "no_speech_prob": 0.052599094808101654,
        "seek": 93390,
        "start": 959.02,
        "temperature": 0,
        "text": " how to write machine learning algorithms from scratch",
        "tokens": [
          51620,
          577,
          281,
          2464,
          3479,
          2539,
          14642,
          490,
          8459,
          51814
        ]
      },
      {
        "avg_logprob": -0.2546819654004327,
        "compression_ratio": 1.6919831223628692,
        "end": 964.3,
        "id": 406,
        "no_speech_prob": 0.0023228677455335855,
        "seek": 96290,
        "start": 962.9,
        "temperature": 0,
        "text": " because it was something,",
        "tokens": [
          50364,
          570,
          309,
          390,
          746,
          11,
          50434
        ]
      },
      {
        "avg_logprob": -0.2546819654004327,
        "compression_ratio": 1.6919831223628692,
        "end": 967,
        "id": 407,
        "no_speech_prob": 0.0023228677455335855,
        "seek": 96290,
        "start": 964.3,
        "temperature": 0,
        "text": " AI is really cool to me, I think.",
        "tokens": [
          50434,
          7318,
          307,
          534,
          1627,
          281,
          385,
          11,
          286,
          519,
          13,
          50569
        ]
      },
      {
        "avg_logprob": -0.2546819654004327,
        "compression_ratio": 1.6919831223628692,
        "end": 969.64,
        "id": 408,
        "no_speech_prob": 0.0023228677455335855,
        "seek": 96290,
        "start": 967,
        "temperature": 0,
        "text": " And so yeah, the Runforest was released.",
        "tokens": [
          50569,
          400,
          370,
          1338,
          11,
          264,
          8950,
          2994,
          377,
          390,
          4736,
          13,
          50701
        ]
      },
      {
        "avg_logprob": -0.2546819654004327,
        "compression_ratio": 1.6919831223628692,
        "end": 972.34,
        "id": 409,
        "no_speech_prob": 0.0023228677455335855,
        "seek": 96290,
        "start": 969.64,
        "temperature": 0,
        "text": " And today, today, what we're gonna do",
        "tokens": [
          50701,
          400,
          965,
          11,
          965,
          11,
          437,
          321,
          434,
          799,
          360,
          50836
        ]
      },
      {
        "avg_logprob": -0.2546819654004327,
        "compression_ratio": 1.6919831223628692,
        "end": 975.9399999999999,
        "id": 410,
        "no_speech_prob": 0.0023228677455335855,
        "seek": 96290,
        "start": 972.34,
        "temperature": 0,
        "text": " is we're going to examine this really simple",
        "tokens": [
          50836,
          307,
          321,
          434,
          516,
          281,
          17496,
          341,
          534,
          2199,
          51016
        ]
      },
      {
        "avg_logprob": -0.2546819654004327,
        "compression_ratio": 1.6919831223628692,
        "end": 978.9,
        "id": 411,
        "no_speech_prob": 0.0023228677455335855,
        "seek": 96290,
        "start": 975.9399999999999,
        "temperature": 0,
        "text": " JavaScript machine learning application,",
        "tokens": [
          51016,
          15778,
          3479,
          2539,
          3861,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.2546819654004327,
        "compression_ratio": 1.6919831223628692,
        "end": 980.9399999999999,
        "id": 412,
        "no_speech_prob": 0.0023228677455335855,
        "seek": 96290,
        "start": 978.9,
        "temperature": 0,
        "text": " kind of how it was done.",
        "tokens": [
          51164,
          733,
          295,
          577,
          309,
          390,
          1096,
          13,
          51266
        ]
      },
      {
        "avg_logprob": -0.2546819654004327,
        "compression_ratio": 1.6919831223628692,
        "end": 984.42,
        "id": 413,
        "no_speech_prob": 0.0023228677455335855,
        "seek": 96290,
        "start": 980.9399999999999,
        "temperature": 0,
        "text": " It's another machine learning application",
        "tokens": [
          51266,
          467,
          311,
          1071,
          3479,
          2539,
          3861,
          51440
        ]
      },
      {
        "avg_logprob": -0.2546819654004327,
        "compression_ratio": 1.6919831223628692,
        "end": 985.98,
        "id": 414,
        "no_speech_prob": 0.0023228677455335855,
        "seek": 96290,
        "start": 984.42,
        "temperature": 0,
        "text": " written from scratch.",
        "tokens": [
          51440,
          3720,
          490,
          8459,
          13,
          51518
        ]
      },
      {
        "avg_logprob": -0.2546819654004327,
        "compression_ratio": 1.6919831223628692,
        "end": 987.8199999999999,
        "id": 415,
        "no_speech_prob": 0.0023228677455335855,
        "seek": 96290,
        "start": 985.98,
        "temperature": 0,
        "text": " So we're gonna take a look at the code",
        "tokens": [
          51518,
          407,
          321,
          434,
          799,
          747,
          257,
          574,
          412,
          264,
          3089,
          51610
        ]
      },
      {
        "avg_logprob": -0.2546819654004327,
        "compression_ratio": 1.6919831223628692,
        "end": 989.24,
        "id": 416,
        "no_speech_prob": 0.0023228677455335855,
        "seek": 96290,
        "start": 987.8199999999999,
        "temperature": 0,
        "text": " and all that good stuff.",
        "tokens": [
          51610,
          293,
          439,
          300,
          665,
          1507,
          13,
          51681
        ]
      },
      {
        "avg_logprob": -0.2546819654004327,
        "compression_ratio": 1.6919831223628692,
        "end": 992.06,
        "id": 417,
        "no_speech_prob": 0.0023228677455335855,
        "seek": 96290,
        "start": 989.24,
        "temperature": 0,
        "text": " So let's get into this.",
        "tokens": [
          51681,
          407,
          718,
          311,
          483,
          666,
          341,
          13,
          51822
        ]
      },
      {
        "avg_logprob": -0.29300581670440407,
        "compression_ratio": 1.5339366515837105,
        "end": 994.14,
        "id": 418,
        "no_speech_prob": 0.0015976742142811418,
        "seek": 99206,
        "start": 992.06,
        "temperature": 0,
        "text": " So here we have this example.",
        "tokens": [
          50364,
          407,
          510,
          321,
          362,
          341,
          1365,
          13,
          50468
        ]
      },
      {
        "avg_logprob": -0.29300581670440407,
        "compression_ratio": 1.5339366515837105,
        "end": 998.4599999999999,
        "id": 419,
        "no_speech_prob": 0.0015976742142811418,
        "seek": 99206,
        "start": 994.14,
        "temperature": 0,
        "text": " It's what I call a color predictor neural network demo.",
        "tokens": [
          50468,
          467,
          311,
          437,
          286,
          818,
          257,
          2017,
          6069,
          284,
          18161,
          3209,
          10723,
          13,
          50684
        ]
      },
      {
        "avg_logprob": -0.29300581670440407,
        "compression_ratio": 1.5339366515837105,
        "end": 1001.06,
        "id": 420,
        "no_speech_prob": 0.0015976742142811418,
        "seek": 99206,
        "start": 998.4599999999999,
        "temperature": 0,
        "text": " And it asks you a simple question.",
        "tokens": [
          50684,
          400,
          309,
          8962,
          291,
          257,
          2199,
          1168,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.29300581670440407,
        "compression_ratio": 1.5339366515837105,
        "end": 1004.54,
        "id": 421,
        "no_speech_prob": 0.0015976742142811418,
        "seek": 99206,
        "start": 1001.06,
        "temperature": 0,
        "text": " Does white or black look better over this color?",
        "tokens": [
          50814,
          4402,
          2418,
          420,
          2211,
          574,
          1101,
          670,
          341,
          2017,
          30,
          50988
        ]
      },
      {
        "avg_logprob": -0.29300581670440407,
        "compression_ratio": 1.5339366515837105,
        "end": 1007.6199999999999,
        "id": 422,
        "no_speech_prob": 0.0015976742142811418,
        "seek": 99206,
        "start": 1004.54,
        "temperature": 0,
        "text": " And so the color is within the circle",
        "tokens": [
          50988,
          400,
          370,
          264,
          2017,
          307,
          1951,
          264,
          6329,
          51142
        ]
      },
      {
        "avg_logprob": -0.29300581670440407,
        "compression_ratio": 1.5339366515837105,
        "end": 1009.18,
        "id": 423,
        "no_speech_prob": 0.0015976742142811418,
        "seek": 99206,
        "start": 1007.6199999999999,
        "temperature": 0,
        "text": " and it's randomly generated.",
        "tokens": [
          51142,
          293,
          309,
          311,
          16979,
          10833,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.29300581670440407,
        "compression_ratio": 1.5339366515837105,
        "end": 1010.02,
        "id": 424,
        "no_speech_prob": 0.0015976742142811418,
        "seek": 99206,
        "start": 1009.18,
        "temperature": 0,
        "text": " So,",
        "tokens": [
          51220,
          407,
          11,
          51262
        ]
      },
      {
        "avg_logprob": -0.29300581670440407,
        "compression_ratio": 1.5339366515837105,
        "end": 1012.7199999999999,
        "id": 425,
        "no_speech_prob": 0.0015976742142811418,
        "seek": 99206,
        "start": 1011.88,
        "temperature": 0,
        "text": " so,",
        "tokens": [
          51355,
          370,
          11,
          51397
        ]
      },
      {
        "avg_logprob": -0.29300581670440407,
        "compression_ratio": 1.5339366515837105,
        "end": 1016.14,
        "id": 426,
        "no_speech_prob": 0.0015976742142811418,
        "seek": 99206,
        "start": 1013.68,
        "temperature": 0,
        "text": " we use a, can I use the whiteboard?",
        "tokens": [
          51445,
          321,
          764,
          257,
          11,
          393,
          286,
          764,
          264,
          2418,
          3787,
          30,
          51568
        ]
      },
      {
        "avg_logprob": -0.29300581670440407,
        "compression_ratio": 1.5339366515837105,
        "end": 1016.9799999999999,
        "id": 427,
        "no_speech_prob": 0.0015976742142811418,
        "seek": 99206,
        "start": 1016.14,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51568,
          1033,
          13,
          51610
        ]
      },
      {
        "avg_logprob": -0.29300581670440407,
        "compression_ratio": 1.5339366515837105,
        "end": 1019.6199999999999,
        "id": 428,
        "no_speech_prob": 0.0015976742142811418,
        "seek": 99206,
        "start": 1016.9799999999999,
        "temperature": 0,
        "text": " So what you have to do is press two.",
        "tokens": [
          51610,
          407,
          437,
          291,
          362,
          281,
          360,
          307,
          1886,
          732,
          13,
          51742
        ]
      },
      {
        "avg_logprob": -0.29300581670440407,
        "compression_ratio": 1.5339366515837105,
        "end": 1020.4599999999999,
        "id": 429,
        "no_speech_prob": 0.0015976742142811418,
        "seek": 99206,
        "start": 1019.6199999999999,
        "temperature": 0,
        "text": " Two.",
        "tokens": [
          51742,
          4453,
          13,
          51784
        ]
      },
      {
        "avg_logprob": -0.29300581670440407,
        "compression_ratio": 1.5339366515837105,
        "end": 1021.3,
        "id": 430,
        "no_speech_prob": 0.0015976742142811418,
        "seek": 99206,
        "start": 1020.4599999999999,
        "temperature": 0,
        "text": " That's it.",
        "tokens": [
          51784,
          663,
          311,
          309,
          13,
          51826
        ]
      },
      {
        "avg_logprob": -0.27559195624457467,
        "compression_ratio": 1.6194331983805668,
        "end": 1023.14,
        "id": 431,
        "no_speech_prob": 0.006487611681222916,
        "seek": 102130,
        "start": 1022.3,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50456
        ]
      },
      {
        "avg_logprob": -0.27559195624457467,
        "compression_ratio": 1.6194331983805668,
        "end": 1026.5,
        "id": 432,
        "no_speech_prob": 0.006487611681222916,
        "seek": 102130,
        "start": 1025.1,
        "temperature": 0,
        "text": " Sweet.",
        "tokens": [
          50554,
          14653,
          13,
          50624
        ]
      },
      {
        "avg_logprob": -0.27559195624457467,
        "compression_ratio": 1.6194331983805668,
        "end": 1027.34,
        "id": 433,
        "no_speech_prob": 0.006487611681222916,
        "seek": 102130,
        "start": 1026.5,
        "temperature": 0,
        "text": " And then you come over here.",
        "tokens": [
          50624,
          400,
          550,
          291,
          808,
          670,
          510,
          13,
          50666
        ]
      },
      {
        "avg_logprob": -0.27559195624457467,
        "compression_ratio": 1.6194331983805668,
        "end": 1028.54,
        "id": 434,
        "no_speech_prob": 0.006487611681222916,
        "seek": 102130,
        "start": 1027.34,
        "temperature": 0,
        "text": " And I just walk, that's it?",
        "tokens": [
          50666,
          400,
          286,
          445,
          1792,
          11,
          300,
          311,
          309,
          30,
          50726
        ]
      },
      {
        "avg_logprob": -0.27559195624457467,
        "compression_ratio": 1.6194331983805668,
        "end": 1030.1,
        "id": 435,
        "no_speech_prob": 0.006487611681222916,
        "seek": 102130,
        "start": 1028.54,
        "temperature": 0,
        "text": " If I'm sitting here, am I in the shot?",
        "tokens": [
          50726,
          759,
          286,
          478,
          3798,
          510,
          11,
          669,
          286,
          294,
          264,
          3347,
          30,
          50804
        ]
      },
      {
        "avg_logprob": -0.27559195624457467,
        "compression_ratio": 1.6194331983805668,
        "end": 1031.06,
        "id": 436,
        "no_speech_prob": 0.006487611681222916,
        "seek": 102130,
        "start": 1030.1,
        "temperature": 0,
        "text": " No.",
        "tokens": [
          50804,
          883,
          13,
          50852
        ]
      },
      {
        "avg_logprob": -0.27559195624457467,
        "compression_ratio": 1.6194331983805668,
        "end": 1033.6,
        "id": 437,
        "no_speech_prob": 0.006487611681222916,
        "seek": 102130,
        "start": 1031.06,
        "temperature": 0,
        "text": " Okay, so what's important for us to start",
        "tokens": [
          50852,
          1033,
          11,
          370,
          437,
          311,
          1021,
          337,
          505,
          281,
          722,
          50979
        ]
      },
      {
        "avg_logprob": -0.27559195624457467,
        "compression_ratio": 1.6194331983805668,
        "end": 1036.54,
        "id": 438,
        "no_speech_prob": 0.006487611681222916,
        "seek": 102130,
        "start": 1033.6,
        "temperature": 0,
        "text": " before we can get into the application,",
        "tokens": [
          50979,
          949,
          321,
          393,
          483,
          666,
          264,
          3861,
          11,
          51126
        ]
      },
      {
        "avg_logprob": -0.27559195624457467,
        "compression_ratio": 1.6194331983805668,
        "end": 1039.8999999999999,
        "id": 439,
        "no_speech_prob": 0.006487611681222916,
        "seek": 102130,
        "start": 1036.54,
        "temperature": 0,
        "text": " we have to understand the main computational part",
        "tokens": [
          51126,
          321,
          362,
          281,
          1223,
          264,
          2135,
          28270,
          644,
          51294
        ]
      },
      {
        "avg_logprob": -0.27559195624457467,
        "compression_ratio": 1.6194331983805668,
        "end": 1041.3799999999999,
        "id": 440,
        "no_speech_prob": 0.006487611681222916,
        "seek": 102130,
        "start": 1039.8999999999999,
        "temperature": 0,
        "text": " of this application.",
        "tokens": [
          51294,
          295,
          341,
          3861,
          13,
          51368
        ]
      },
      {
        "avg_logprob": -0.27559195624457467,
        "compression_ratio": 1.6194331983805668,
        "end": 1042.94,
        "id": 441,
        "no_speech_prob": 0.006487611681222916,
        "seek": 102130,
        "start": 1041.3799999999999,
        "temperature": 0,
        "text": " So we have a color.",
        "tokens": [
          51368,
          407,
          321,
          362,
          257,
          2017,
          13,
          51446
        ]
      },
      {
        "avg_logprob": -0.27559195624457467,
        "compression_ratio": 1.6194331983805668,
        "end": 1044.7,
        "id": 442,
        "no_speech_prob": 0.006487611681222916,
        "seek": 102130,
        "start": 1042.94,
        "temperature": 0,
        "text": " And as you know, colors are,",
        "tokens": [
          51446,
          400,
          382,
          291,
          458,
          11,
          4577,
          366,
          11,
          51534
        ]
      },
      {
        "avg_logprob": -0.27559195624457467,
        "compression_ratio": 1.6194331983805668,
        "end": 1048.02,
        "id": 443,
        "no_speech_prob": 0.006487611681222916,
        "seek": 102130,
        "start": 1044.7,
        "temperature": 0,
        "text": " they're represented as a vector of three,",
        "tokens": [
          51534,
          436,
          434,
          10379,
          382,
          257,
          8062,
          295,
          1045,
          11,
          51700
        ]
      },
      {
        "avg_logprob": -0.27559195624457467,
        "compression_ratio": 1.6194331983805668,
        "end": 1050.52,
        "id": 444,
        "no_speech_prob": 0.006487611681222916,
        "seek": 102130,
        "start": 1048.02,
        "temperature": 0,
        "text": " or sometimes four if you include the alpha.",
        "tokens": [
          51700,
          420,
          2171,
          1451,
          498,
          291,
          4090,
          264,
          8961,
          13,
          51825
        ]
      },
      {
        "avg_logprob": -0.2246694119177132,
        "compression_ratio": 1.509433962264151,
        "end": 1051.9,
        "id": 445,
        "no_speech_prob": 0.000607067602686584,
        "seek": 105052,
        "start": 1050.52,
        "temperature": 0,
        "text": " But we're not including the alpha.",
        "tokens": [
          50364,
          583,
          321,
          434,
          406,
          3009,
          264,
          8961,
          13,
          50433
        ]
      },
      {
        "avg_logprob": -0.2246694119177132,
        "compression_ratio": 1.509433962264151,
        "end": 1054.82,
        "id": 446,
        "no_speech_prob": 0.000607067602686584,
        "seek": 105052,
        "start": 1051.9,
        "temperature": 0,
        "text": " We're only gonna use the RGB values.",
        "tokens": [
          50433,
          492,
          434,
          787,
          799,
          764,
          264,
          31231,
          4190,
          13,
          50579
        ]
      },
      {
        "avg_logprob": -0.2246694119177132,
        "compression_ratio": 1.509433962264151,
        "end": 1056.68,
        "id": 447,
        "no_speech_prob": 0.000607067602686584,
        "seek": 105052,
        "start": 1054.82,
        "temperature": 0,
        "text": " So we have our inputs,",
        "tokens": [
          50579,
          407,
          321,
          362,
          527,
          15743,
          11,
          50672
        ]
      },
      {
        "avg_logprob": -0.2246694119177132,
        "compression_ratio": 1.509433962264151,
        "end": 1059.92,
        "id": 448,
        "no_speech_prob": 0.000607067602686584,
        "seek": 105052,
        "start": 1057.68,
        "temperature": 0,
        "text": " which is three.",
        "tokens": [
          50722,
          597,
          307,
          1045,
          13,
          50834
        ]
      },
      {
        "avg_logprob": -0.2246694119177132,
        "compression_ratio": 1.509433962264151,
        "end": 1060.8799999999999,
        "id": 449,
        "no_speech_prob": 0.000607067602686584,
        "seek": 105052,
        "start": 1059.92,
        "temperature": 0,
        "text": " Is that all in the frame?",
        "tokens": [
          50834,
          1119,
          300,
          439,
          294,
          264,
          3920,
          30,
          50882
        ]
      },
      {
        "avg_logprob": -0.2246694119177132,
        "compression_ratio": 1.509433962264151,
        "end": 1061.72,
        "id": 450,
        "no_speech_prob": 0.000607067602686584,
        "seek": 105052,
        "start": 1060.8799999999999,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          50882,
          1079,
          13,
          50924
        ]
      },
      {
        "avg_logprob": -0.2246694119177132,
        "compression_ratio": 1.509433962264151,
        "end": 1062.54,
        "id": 451,
        "no_speech_prob": 0.000607067602686584,
        "seek": 105052,
        "start": 1061.72,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50924,
          1057,
          558,
          13,
          50965
        ]
      },
      {
        "avg_logprob": -0.2246694119177132,
        "compression_ratio": 1.509433962264151,
        "end": 1066.28,
        "id": 452,
        "no_speech_prob": 0.000607067602686584,
        "seek": 105052,
        "start": 1062.54,
        "temperature": 0,
        "text": " So we have red, green, and blue.",
        "tokens": [
          50965,
          407,
          321,
          362,
          2182,
          11,
          3092,
          11,
          293,
          3344,
          13,
          51152
        ]
      },
      {
        "avg_logprob": -0.2246694119177132,
        "compression_ratio": 1.509433962264151,
        "end": 1071.28,
        "id": 453,
        "no_speech_prob": 0.000607067602686584,
        "seek": 105052,
        "start": 1066.28,
        "temperature": 0,
        "text": " And these are values between zero and 255",
        "tokens": [
          51152,
          400,
          613,
          366,
          4190,
          1296,
          4018,
          293,
          3552,
          20,
          51402
        ]
      },
      {
        "avg_logprob": -0.2246694119177132,
        "compression_ratio": 1.509433962264151,
        "end": 1072.4,
        "id": 454,
        "no_speech_prob": 0.000607067602686584,
        "seek": 105052,
        "start": 1071.28,
        "temperature": 0,
        "text": " for each input.",
        "tokens": [
          51402,
          337,
          1184,
          4846,
          13,
          51458
        ]
      },
      {
        "avg_logprob": -0.2246694119177132,
        "compression_ratio": 1.509433962264151,
        "end": 1075.04,
        "id": 455,
        "no_speech_prob": 0.000607067602686584,
        "seek": 105052,
        "start": 1073.4,
        "temperature": 0,
        "text": " So,",
        "tokens": [
          51508,
          407,
          11,
          51590
        ]
      },
      {
        "avg_logprob": -0.2246694119177132,
        "compression_ratio": 1.509433962264151,
        "end": 1076.96,
        "id": 456,
        "no_speech_prob": 0.000607067602686584,
        "seek": 105052,
        "start": 1075.04,
        "temperature": 0,
        "text": " we need to build a neural network",
        "tokens": [
          51590,
          321,
          643,
          281,
          1322,
          257,
          18161,
          3209,
          51686
        ]
      },
      {
        "avg_logprob": -0.2246694119177132,
        "compression_ratio": 1.509433962264151,
        "end": 1078.8799999999999,
        "id": 457,
        "no_speech_prob": 0.000607067602686584,
        "seek": 105052,
        "start": 1076.96,
        "temperature": 0,
        "text": " that will be able to take these inputs",
        "tokens": [
          51686,
          300,
          486,
          312,
          1075,
          281,
          747,
          613,
          15743,
          51782
        ]
      },
      {
        "avg_logprob": -0.25177068034494954,
        "compression_ratio": 1.7768595041322315,
        "end": 1080.8000000000002,
        "id": 458,
        "no_speech_prob": 0.0005193014512769878,
        "seek": 107888,
        "start": 1078.88,
        "temperature": 0,
        "text": " and then do a computation on them",
        "tokens": [
          50364,
          293,
          550,
          360,
          257,
          24903,
          322,
          552,
          50460
        ]
      },
      {
        "avg_logprob": -0.25177068034494954,
        "compression_ratio": 1.7768595041322315,
        "end": 1082.68,
        "id": 459,
        "no_speech_prob": 0.0005193014512769878,
        "seek": 107888,
        "start": 1080.8000000000002,
        "temperature": 0,
        "text": " and then pass them to an output to predict",
        "tokens": [
          50460,
          293,
          550,
          1320,
          552,
          281,
          364,
          5598,
          281,
          6069,
          50554
        ]
      },
      {
        "avg_logprob": -0.25177068034494954,
        "compression_ratio": 1.7768595041322315,
        "end": 1085.46,
        "id": 460,
        "no_speech_prob": 0.0005193014512769878,
        "seek": 107888,
        "start": 1082.68,
        "temperature": 0,
        "text": " if it looks better over black or white.",
        "tokens": [
          50554,
          498,
          309,
          1542,
          1101,
          670,
          2211,
          420,
          2418,
          13,
          50693
        ]
      },
      {
        "avg_logprob": -0.25177068034494954,
        "compression_ratio": 1.7768595041322315,
        "end": 1088.1200000000001,
        "id": 461,
        "no_speech_prob": 0.0005193014512769878,
        "seek": 107888,
        "start": 1086.4,
        "temperature": 0,
        "text": " So let's first draw our outputs.",
        "tokens": [
          50740,
          407,
          718,
          311,
          700,
          2642,
          527,
          23930,
          13,
          50826
        ]
      },
      {
        "avg_logprob": -0.25177068034494954,
        "compression_ratio": 1.7768595041322315,
        "end": 1090.48,
        "id": 462,
        "no_speech_prob": 0.0005193014512769878,
        "seek": 107888,
        "start": 1088.1200000000001,
        "temperature": 0,
        "text": " Just make sure it's all in frame.",
        "tokens": [
          50826,
          1449,
          652,
          988,
          309,
          311,
          439,
          294,
          3920,
          13,
          50944
        ]
      },
      {
        "avg_logprob": -0.25177068034494954,
        "compression_ratio": 1.7768595041322315,
        "end": 1091.8400000000001,
        "id": 463,
        "no_speech_prob": 0.0005193014512769878,
        "seek": 107888,
        "start": 1090.48,
        "temperature": 0,
        "text": " Yes, that's good.",
        "tokens": [
          50944,
          1079,
          11,
          300,
          311,
          665,
          13,
          51012
        ]
      },
      {
        "avg_logprob": -0.25177068034494954,
        "compression_ratio": 1.7768595041322315,
        "end": 1093.92,
        "id": 464,
        "no_speech_prob": 0.0005193014512769878,
        "seek": 107888,
        "start": 1092.74,
        "temperature": 0,
        "text": " And this is gonna be,",
        "tokens": [
          51057,
          400,
          341,
          307,
          799,
          312,
          11,
          51116
        ]
      },
      {
        "avg_logprob": -0.25177068034494954,
        "compression_ratio": 1.7768595041322315,
        "end": 1096.74,
        "id": 465,
        "no_speech_prob": 0.0005193014512769878,
        "seek": 107888,
        "start": 1093.92,
        "temperature": 0,
        "text": " it predicts black and this predicts white.",
        "tokens": [
          51116,
          309,
          6069,
          82,
          2211,
          293,
          341,
          6069,
          82,
          2418,
          13,
          51257
        ]
      },
      {
        "avg_logprob": -0.25177068034494954,
        "compression_ratio": 1.7768595041322315,
        "end": 1099.4,
        "id": 466,
        "no_speech_prob": 0.0005193014512769878,
        "seek": 107888,
        "start": 1096.74,
        "temperature": 0,
        "text": " So now we need a hidden layer,",
        "tokens": [
          51257,
          407,
          586,
          321,
          643,
          257,
          7633,
          4583,
          11,
          51390
        ]
      },
      {
        "avg_logprob": -0.25177068034494954,
        "compression_ratio": 1.7768595041322315,
        "end": 1101.5200000000002,
        "id": 467,
        "no_speech_prob": 0.0005193014512769878,
        "seek": 107888,
        "start": 1099.4,
        "temperature": 0,
        "text": " is what we call a hidden layer,",
        "tokens": [
          51390,
          307,
          437,
          321,
          818,
          257,
          7633,
          4583,
          11,
          51496
        ]
      },
      {
        "avg_logprob": -0.25177068034494954,
        "compression_ratio": 1.7768595041322315,
        "end": 1103.5,
        "id": 468,
        "no_speech_prob": 0.0005193014512769878,
        "seek": 107888,
        "start": 1101.5200000000002,
        "temperature": 0,
        "text": " with artificial neural networks in the middle",
        "tokens": [
          51496,
          365,
          11677,
          18161,
          9590,
          294,
          264,
          2808,
          51595
        ]
      },
      {
        "avg_logprob": -0.25177068034494954,
        "compression_ratio": 1.7768595041322315,
        "end": 1105.44,
        "id": 469,
        "no_speech_prob": 0.0005193014512769878,
        "seek": 107888,
        "start": 1103.5,
        "temperature": 0,
        "text": " that does the computation part.",
        "tokens": [
          51595,
          300,
          775,
          264,
          24903,
          644,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.25177068034494954,
        "compression_ratio": 1.7768595041322315,
        "end": 1107,
        "id": 470,
        "no_speech_prob": 0.0005193014512769878,
        "seek": 107888,
        "start": 1105.44,
        "temperature": 0,
        "text": " And this is our guess.",
        "tokens": [
          51692,
          400,
          341,
          307,
          527,
          2041,
          13,
          51770
        ]
      },
      {
        "avg_logprob": -0.2384216802583324,
        "compression_ratio": 1.6802973977695168,
        "end": 1110.52,
        "id": 471,
        "no_speech_prob": 0.0002066281158477068,
        "seek": 110700,
        "start": 1108,
        "temperature": 0,
        "text": " And so we are just gonna arbitrarily",
        "tokens": [
          50414,
          400,
          370,
          321,
          366,
          445,
          799,
          19071,
          3289,
          50540
        ]
      },
      {
        "avg_logprob": -0.2384216802583324,
        "compression_ratio": 1.6802973977695168,
        "end": 1113.6,
        "id": 472,
        "no_speech_prob": 0.0002066281158477068,
        "seek": 110700,
        "start": 1110.52,
        "temperature": 0,
        "text": " just duplicate the same size of our inputs",
        "tokens": [
          50540,
          445,
          23976,
          264,
          912,
          2744,
          295,
          527,
          15743,
          50694
        ]
      },
      {
        "avg_logprob": -0.2384216802583324,
        "compression_ratio": 1.6802973977695168,
        "end": 1114.84,
        "id": 473,
        "no_speech_prob": 0.0002066281158477068,
        "seek": 110700,
        "start": 1113.6,
        "temperature": 0,
        "text": " for our hidden layer nodes.",
        "tokens": [
          50694,
          337,
          527,
          7633,
          4583,
          13891,
          13,
          50756
        ]
      },
      {
        "avg_logprob": -0.2384216802583324,
        "compression_ratio": 1.6802973977695168,
        "end": 1116.4,
        "id": 474,
        "no_speech_prob": 0.0002066281158477068,
        "seek": 110700,
        "start": 1114.84,
        "temperature": 0,
        "text": " We're just gonna say three.",
        "tokens": [
          50756,
          492,
          434,
          445,
          799,
          584,
          1045,
          13,
          50834
        ]
      },
      {
        "avg_logprob": -0.2384216802583324,
        "compression_ratio": 1.6802973977695168,
        "end": 1118.36,
        "id": 475,
        "no_speech_prob": 0.0002066281158477068,
        "seek": 110700,
        "start": 1116.4,
        "temperature": 0,
        "text": " It's a good place to start.",
        "tokens": [
          50834,
          467,
          311,
          257,
          665,
          1081,
          281,
          722,
          13,
          50932
        ]
      },
      {
        "avg_logprob": -0.2384216802583324,
        "compression_ratio": 1.6802973977695168,
        "end": 1119.76,
        "id": 476,
        "no_speech_prob": 0.0002066281158477068,
        "seek": 110700,
        "start": 1118.36,
        "temperature": 0,
        "text": " If we're really serious about this,",
        "tokens": [
          50932,
          759,
          321,
          434,
          534,
          3156,
          466,
          341,
          11,
          51002
        ]
      },
      {
        "avg_logprob": -0.2384216802583324,
        "compression_ratio": 1.6802973977695168,
        "end": 1122.32,
        "id": 477,
        "no_speech_prob": 0.0002066281158477068,
        "seek": 110700,
        "start": 1119.76,
        "temperature": 0,
        "text": " we could expand it, try five, try seven,",
        "tokens": [
          51002,
          321,
          727,
          5268,
          309,
          11,
          853,
          1732,
          11,
          853,
          3407,
          11,
          51130
        ]
      },
      {
        "avg_logprob": -0.2384216802583324,
        "compression_ratio": 1.6802973977695168,
        "end": 1125.08,
        "id": 478,
        "no_speech_prob": 0.0002066281158477068,
        "seek": 110700,
        "start": 1122.32,
        "temperature": 0,
        "text": " and just log the results for all of them",
        "tokens": [
          51130,
          293,
          445,
          3565,
          264,
          3542,
          337,
          439,
          295,
          552,
          51268
        ]
      },
      {
        "avg_logprob": -0.2384216802583324,
        "compression_ratio": 1.6802973977695168,
        "end": 1126.24,
        "id": 479,
        "no_speech_prob": 0.0002066281158477068,
        "seek": 110700,
        "start": 1125.08,
        "temperature": 0,
        "text": " and see which one works the best.",
        "tokens": [
          51268,
          293,
          536,
          597,
          472,
          1985,
          264,
          1151,
          13,
          51326
        ]
      },
      {
        "avg_logprob": -0.2384216802583324,
        "compression_ratio": 1.6802973977695168,
        "end": 1128.16,
        "id": 480,
        "no_speech_prob": 0.0002066281158477068,
        "seek": 110700,
        "start": 1126.24,
        "temperature": 0,
        "text": " But we're just gonna say three for this example,",
        "tokens": [
          51326,
          583,
          321,
          434,
          445,
          799,
          584,
          1045,
          337,
          341,
          1365,
          11,
          51422
        ]
      },
      {
        "avg_logprob": -0.2384216802583324,
        "compression_ratio": 1.6802973977695168,
        "end": 1129.52,
        "id": 481,
        "no_speech_prob": 0.0002066281158477068,
        "seek": 110700,
        "start": 1128.16,
        "temperature": 0,
        "text": " make it nice and simple.",
        "tokens": [
          51422,
          652,
          309,
          1481,
          293,
          2199,
          13,
          51490
        ]
      },
      {
        "avg_logprob": -0.2384216802583324,
        "compression_ratio": 1.6802973977695168,
        "end": 1133.12,
        "id": 482,
        "no_speech_prob": 0.0002066281158477068,
        "seek": 110700,
        "start": 1130.84,
        "temperature": 0,
        "text": " And so, we have our RGB,",
        "tokens": [
          51556,
          400,
          370,
          11,
          321,
          362,
          527,
          31231,
          11,
          51670
        ]
      },
      {
        "avg_logprob": -0.2384216802583324,
        "compression_ratio": 1.6802973977695168,
        "end": 1135.2,
        "id": 483,
        "no_speech_prob": 0.0002066281158477068,
        "seek": 110700,
        "start": 1133.12,
        "temperature": 0,
        "text": " and if we go back to",
        "tokens": [
          51670,
          293,
          498,
          321,
          352,
          646,
          281,
          51774
        ]
      },
      {
        "avg_logprob": -0.2384216802583324,
        "compression_ratio": 1.6802973977695168,
        "end": 1136.24,
        "id": 484,
        "no_speech_prob": 0.0002066281158477068,
        "seek": 110700,
        "start": 1135.2,
        "temperature": 0,
        "text": " press one, yeah.",
        "tokens": [
          51774,
          1886,
          472,
          11,
          1338,
          13,
          51826
        ]
      },
      {
        "avg_logprob": -0.32949311998155384,
        "compression_ratio": 1.546583850931677,
        "end": 1137.36,
        "id": 485,
        "no_speech_prob": 0.004069949500262737,
        "seek": 113624,
        "start": 1136.32,
        "temperature": 0,
        "text": " Our example.",
        "tokens": [
          50368,
          2621,
          1365,
          13,
          50420
        ]
      },
      {
        "avg_logprob": -0.32949311998155384,
        "compression_ratio": 1.546583850931677,
        "end": 1139.2,
        "id": 486,
        "no_speech_prob": 0.004069949500262737,
        "seek": 113624,
        "start": 1137.36,
        "temperature": 0,
        "text": " What's happening here is",
        "tokens": [
          50420,
          708,
          311,
          2737,
          510,
          307,
          50512
        ]
      },
      {
        "avg_logprob": -0.32949311998155384,
        "compression_ratio": 1.546583850931677,
        "end": 1143.88,
        "id": 487,
        "no_speech_prob": 0.004069949500262737,
        "seek": 113624,
        "start": 1140.64,
        "temperature": 0,
        "text": " there's a computation that happens",
        "tokens": [
          50584,
          456,
          311,
          257,
          24903,
          300,
          2314,
          50746
        ]
      },
      {
        "avg_logprob": -0.32949311998155384,
        "compression_ratio": 1.546583850931677,
        "end": 1147.22,
        "id": 488,
        "no_speech_prob": 0.004069949500262737,
        "seek": 113624,
        "start": 1145.36,
        "temperature": 0,
        "text": " within our network.",
        "tokens": [
          50820,
          1951,
          527,
          3209,
          13,
          50913
        ]
      },
      {
        "avg_logprob": -0.32949311998155384,
        "compression_ratio": 1.546583850931677,
        "end": 1152.04,
        "id": 489,
        "no_speech_prob": 0.004069949500262737,
        "seek": 113624,
        "start": 1148.68,
        "temperature": 0,
        "text": " Two, three, one, two, three,",
        "tokens": [
          50986,
          4453,
          11,
          1045,
          11,
          472,
          11,
          732,
          11,
          1045,
          11,
          51154
        ]
      },
      {
        "avg_logprob": -0.32949311998155384,
        "compression_ratio": 1.546583850931677,
        "end": 1154.28,
        "id": 490,
        "no_speech_prob": 0.004069949500262737,
        "seek": 113624,
        "start": 1152.04,
        "temperature": 0,
        "text": " one, two, three.",
        "tokens": [
          51154,
          472,
          11,
          732,
          11,
          1045,
          13,
          51266
        ]
      },
      {
        "avg_logprob": -0.32949311998155384,
        "compression_ratio": 1.546583850931677,
        "end": 1156.04,
        "id": 491,
        "no_speech_prob": 0.004069949500262737,
        "seek": 113624,
        "start": 1154.28,
        "temperature": 0,
        "text": " And Dan, feel free to interrupt",
        "tokens": [
          51266,
          400,
          3394,
          11,
          841,
          1737,
          281,
          12729,
          51354
        ]
      },
      {
        "avg_logprob": -0.32949311998155384,
        "compression_ratio": 1.546583850931677,
        "end": 1158.74,
        "id": 492,
        "no_speech_prob": 0.004069949500262737,
        "seek": 113624,
        "start": 1156.04,
        "temperature": 0,
        "text": " if you think that I'm a little off base with anything.",
        "tokens": [
          51354,
          498,
          291,
          519,
          300,
          286,
          478,
          257,
          707,
          766,
          3096,
          365,
          1340,
          13,
          51489
        ]
      },
      {
        "avg_logprob": -0.32949311998155384,
        "compression_ratio": 1.546583850931677,
        "end": 1160.6,
        "id": 493,
        "no_speech_prob": 0.004069949500262737,
        "seek": 113624,
        "start": 1159.76,
        "temperature": 0,
        "text": " Uh-huh.",
        "tokens": [
          51540,
          4019,
          12,
          18710,
          13,
          51582
        ]
      },
      {
        "avg_logprob": -0.32949311998155384,
        "compression_ratio": 1.546583850931677,
        "end": 1162.84,
        "id": 494,
        "no_speech_prob": 0.004069949500262737,
        "seek": 113624,
        "start": 1162,
        "temperature": 0,
        "text": " Uh-huh.",
        "tokens": [
          51652,
          4019,
          12,
          18710,
          13,
          51694
        ]
      },
      {
        "avg_logprob": -0.32949311998155384,
        "compression_ratio": 1.546583850931677,
        "end": 1165.42,
        "id": 495,
        "no_speech_prob": 0.004069949500262737,
        "seek": 113624,
        "start": 1164.2,
        "temperature": 0,
        "text": " Uh-huh.",
        "tokens": [
          51762,
          4019,
          12,
          18710,
          13,
          51823
        ]
      },
      {
        "avg_logprob": -0.24464770952860515,
        "compression_ratio": 1.6666666666666667,
        "end": 1167.54,
        "id": 496,
        "no_speech_prob": 0.0001253361551789567,
        "seek": 116542,
        "start": 1165.42,
        "temperature": 0,
        "text": " Okay, so this, what did I just do?",
        "tokens": [
          50364,
          1033,
          11,
          370,
          341,
          11,
          437,
          630,
          286,
          445,
          360,
          30,
          50470
        ]
      },
      {
        "avg_logprob": -0.24464770952860515,
        "compression_ratio": 1.6666666666666667,
        "end": 1168.5800000000002,
        "id": 497,
        "no_speech_prob": 0.0001253361551789567,
        "seek": 116542,
        "start": 1167.54,
        "temperature": 0,
        "text": " That looks really confusing,",
        "tokens": [
          50470,
          663,
          1542,
          534,
          13181,
          11,
          50522
        ]
      },
      {
        "avg_logprob": -0.24464770952860515,
        "compression_ratio": 1.6666666666666667,
        "end": 1170.26,
        "id": 498,
        "no_speech_prob": 0.0001253361551789567,
        "seek": 116542,
        "start": 1168.5800000000002,
        "temperature": 0,
        "text": " but it's actually really simple.",
        "tokens": [
          50522,
          457,
          309,
          311,
          767,
          534,
          2199,
          13,
          50606
        ]
      },
      {
        "avg_logprob": -0.24464770952860515,
        "compression_ratio": 1.6666666666666667,
        "end": 1174.94,
        "id": 499,
        "no_speech_prob": 0.0001253361551789567,
        "seek": 116542,
        "start": 1170.26,
        "temperature": 0,
        "text": " So, we need to somehow get our inputs,",
        "tokens": [
          50606,
          407,
          11,
          321,
          643,
          281,
          6063,
          483,
          527,
          15743,
          11,
          50840
        ]
      },
      {
        "avg_logprob": -0.24464770952860515,
        "compression_ratio": 1.6666666666666667,
        "end": 1177.1000000000001,
        "id": 500,
        "no_speech_prob": 0.0001253361551789567,
        "seek": 116542,
        "start": 1174.94,
        "temperature": 0,
        "text": " computation, and then to our outputs.",
        "tokens": [
          50840,
          24903,
          11,
          293,
          550,
          281,
          527,
          23930,
          13,
          50948
        ]
      },
      {
        "avg_logprob": -0.24464770952860515,
        "compression_ratio": 1.6666666666666667,
        "end": 1179.02,
        "id": 501,
        "no_speech_prob": 0.0001253361551789567,
        "seek": 116542,
        "start": 1177.1000000000001,
        "temperature": 0,
        "text": " And the way that we do that is we use",
        "tokens": [
          50948,
          400,
          264,
          636,
          300,
          321,
          360,
          300,
          307,
          321,
          764,
          51044
        ]
      },
      {
        "avg_logprob": -0.24464770952860515,
        "compression_ratio": 1.6666666666666667,
        "end": 1181.18,
        "id": 502,
        "no_speech_prob": 0.0001253361551789567,
        "seek": 116542,
        "start": 1179.02,
        "temperature": 0,
        "text": " what I'm using, bubbles, to represent",
        "tokens": [
          51044,
          437,
          286,
          478,
          1228,
          11,
          16295,
          11,
          281,
          2906,
          51152
        ]
      },
      {
        "avg_logprob": -0.24464770952860515,
        "compression_ratio": 1.6666666666666667,
        "end": 1184.14,
        "id": 503,
        "no_speech_prob": 0.0001253361551789567,
        "seek": 116542,
        "start": 1181.18,
        "temperature": 0,
        "text": " what are called weights within our neural network.",
        "tokens": [
          51152,
          437,
          366,
          1219,
          17443,
          1951,
          527,
          18161,
          3209,
          13,
          51300
        ]
      },
      {
        "avg_logprob": -0.24464770952860515,
        "compression_ratio": 1.6666666666666667,
        "end": 1188.14,
        "id": 504,
        "no_speech_prob": 0.0001253361551789567,
        "seek": 116542,
        "start": 1184.14,
        "temperature": 0,
        "text": " And so, every single node within our hidden layer",
        "tokens": [
          51300,
          400,
          370,
          11,
          633,
          2167,
          9984,
          1951,
          527,
          7633,
          4583,
          51500
        ]
      },
      {
        "avg_logprob": -0.24464770952860515,
        "compression_ratio": 1.6666666666666667,
        "end": 1192.5,
        "id": 505,
        "no_speech_prob": 0.0001253361551789567,
        "seek": 116542,
        "start": 1188.14,
        "temperature": 0,
        "text": " has the same amount of weights as there are inputs.",
        "tokens": [
          51500,
          575,
          264,
          912,
          2372,
          295,
          17443,
          382,
          456,
          366,
          15743,
          13,
          51718
        ]
      },
      {
        "avg_logprob": -0.24464770952860515,
        "compression_ratio": 1.6666666666666667,
        "end": 1194.9,
        "id": 506,
        "no_speech_prob": 0.0001253361551789567,
        "seek": 116542,
        "start": 1192.5,
        "temperature": 0,
        "text": " So, what that means is",
        "tokens": [
          51718,
          407,
          11,
          437,
          300,
          1355,
          307,
          51838
        ]
      },
      {
        "avg_logprob": -0.2265964206174123,
        "compression_ratio": 2.208955223880597,
        "end": 1197.42,
        "id": 507,
        "no_speech_prob": 0.00028685061261057854,
        "seek": 119490,
        "start": 1194.9,
        "temperature": 0,
        "text": " there's one weight for this input,",
        "tokens": [
          50364,
          456,
          311,
          472,
          3364,
          337,
          341,
          4846,
          11,
          50490
        ]
      },
      {
        "avg_logprob": -0.2265964206174123,
        "compression_ratio": 2.208955223880597,
        "end": 1199.02,
        "id": 508,
        "no_speech_prob": 0.00028685061261057854,
        "seek": 119490,
        "start": 1197.42,
        "temperature": 0,
        "text": " there's one weight for this input,",
        "tokens": [
          50490,
          456,
          311,
          472,
          3364,
          337,
          341,
          4846,
          11,
          50570
        ]
      },
      {
        "avg_logprob": -0.2265964206174123,
        "compression_ratio": 2.208955223880597,
        "end": 1200.8200000000002,
        "id": 509,
        "no_speech_prob": 0.00028685061261057854,
        "seek": 119490,
        "start": 1199.02,
        "temperature": 0,
        "text": " and there's one weight for this input.",
        "tokens": [
          50570,
          293,
          456,
          311,
          472,
          3364,
          337,
          341,
          4846,
          13,
          50660
        ]
      },
      {
        "avg_logprob": -0.2265964206174123,
        "compression_ratio": 2.208955223880597,
        "end": 1202.26,
        "id": 510,
        "no_speech_prob": 0.00028685061261057854,
        "seek": 119490,
        "start": 1200.8200000000002,
        "temperature": 0,
        "text": " And the same for the rest of them.",
        "tokens": [
          50660,
          400,
          264,
          912,
          337,
          264,
          1472,
          295,
          552,
          13,
          50732
        ]
      },
      {
        "avg_logprob": -0.2265964206174123,
        "compression_ratio": 2.208955223880597,
        "end": 1204.1000000000001,
        "id": 511,
        "no_speech_prob": 0.00028685061261057854,
        "seek": 119490,
        "start": 1202.26,
        "temperature": 0,
        "text": " One weight for this input,",
        "tokens": [
          50732,
          1485,
          3364,
          337,
          341,
          4846,
          11,
          50824
        ]
      },
      {
        "avg_logprob": -0.2265964206174123,
        "compression_ratio": 2.208955223880597,
        "end": 1205.5800000000002,
        "id": 512,
        "no_speech_prob": 0.00028685061261057854,
        "seek": 119490,
        "start": 1204.1000000000001,
        "temperature": 0,
        "text": " one weight for this input,",
        "tokens": [
          50824,
          472,
          3364,
          337,
          341,
          4846,
          11,
          50898
        ]
      },
      {
        "avg_logprob": -0.2265964206174123,
        "compression_ratio": 2.208955223880597,
        "end": 1207.9,
        "id": 513,
        "no_speech_prob": 0.00028685061261057854,
        "seek": 119490,
        "start": 1205.5800000000002,
        "temperature": 0,
        "text": " one weight for that input,",
        "tokens": [
          50898,
          472,
          3364,
          337,
          300,
          4846,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.2265964206174123,
        "compression_ratio": 2.208955223880597,
        "end": 1209.42,
        "id": 514,
        "no_speech_prob": 0.00028685061261057854,
        "seek": 119490,
        "start": 1207.9,
        "temperature": 0,
        "text": " and repeat.",
        "tokens": [
          51014,
          293,
          7149,
          13,
          51090
        ]
      },
      {
        "avg_logprob": -0.2265964206174123,
        "compression_ratio": 2.208955223880597,
        "end": 1211.42,
        "id": 515,
        "no_speech_prob": 0.00028685061261057854,
        "seek": 119490,
        "start": 1210.5800000000002,
        "temperature": 0,
        "text": " I didn't do that right.",
        "tokens": [
          51148,
          286,
          994,
          380,
          360,
          300,
          558,
          13,
          51190
        ]
      },
      {
        "avg_logprob": -0.2265964206174123,
        "compression_ratio": 2.208955223880597,
        "end": 1212.5800000000002,
        "id": 516,
        "no_speech_prob": 0.00028685061261057854,
        "seek": 119490,
        "start": 1211.42,
        "temperature": 0,
        "text": " Boom, boom.",
        "tokens": [
          51190,
          15523,
          11,
          9351,
          13,
          51248
        ]
      },
      {
        "avg_logprob": -0.2265964206174123,
        "compression_ratio": 2.208955223880597,
        "end": 1216.46,
        "id": 517,
        "no_speech_prob": 0.00028685061261057854,
        "seek": 119490,
        "start": 1213.5800000000002,
        "temperature": 0,
        "text": " And so, what then happens is that we pass this through,",
        "tokens": [
          51298,
          400,
          370,
          11,
          437,
          550,
          2314,
          307,
          300,
          321,
          1320,
          341,
          807,
          11,
          51442
        ]
      },
      {
        "avg_logprob": -0.2265964206174123,
        "compression_ratio": 2.208955223880597,
        "end": 1219.5,
        "id": 518,
        "no_speech_prob": 0.00028685061261057854,
        "seek": 119490,
        "start": 1216.46,
        "temperature": 0,
        "text": " we do our input times the weight,",
        "tokens": [
          51442,
          321,
          360,
          527,
          4846,
          1413,
          264,
          3364,
          11,
          51594
        ]
      },
      {
        "avg_logprob": -0.2265964206174123,
        "compression_ratio": 2.208955223880597,
        "end": 1221.1000000000001,
        "id": 519,
        "no_speech_prob": 0.00028685061261057854,
        "seek": 119490,
        "start": 1219.5,
        "temperature": 0,
        "text": " and then plus our bias,",
        "tokens": [
          51594,
          293,
          550,
          1804,
          527,
          12577,
          11,
          51674
        ]
      },
      {
        "avg_logprob": -0.2265964206174123,
        "compression_ratio": 2.208955223880597,
        "end": 1223.02,
        "id": 520,
        "no_speech_prob": 0.00028685061261057854,
        "seek": 119490,
        "start": 1221.1000000000001,
        "temperature": 0,
        "text": " and we can repeat the process.",
        "tokens": [
          51674,
          293,
          321,
          393,
          7149,
          264,
          1399,
          13,
          51770
        ]
      },
      {
        "avg_logprob": -0.2265964206174123,
        "compression_ratio": 2.208955223880597,
        "end": 1224.1200000000001,
        "id": 521,
        "no_speech_prob": 0.00028685061261057854,
        "seek": 119490,
        "start": 1223.02,
        "temperature": 0,
        "text": " This will give us a value.",
        "tokens": [
          51770,
          639,
          486,
          976,
          505,
          257,
          2158,
          13,
          51825
        ]
      },
      {
        "avg_logprob": -0.2670421755410791,
        "compression_ratio": 1.7326732673267327,
        "end": 1226.84,
        "id": 522,
        "no_speech_prob": 0.011157466098666191,
        "seek": 122412,
        "start": 1224.7199999999998,
        "temperature": 0,
        "text": " After we compute all these, sum them up,",
        "tokens": [
          50394,
          2381,
          321,
          14722,
          439,
          613,
          11,
          2408,
          552,
          493,
          11,
          50500
        ]
      },
      {
        "avg_logprob": -0.2670421755410791,
        "compression_ratio": 1.7326732673267327,
        "end": 1230.6399999999999,
        "id": 523,
        "no_speech_prob": 0.011157466098666191,
        "seek": 122412,
        "start": 1226.84,
        "temperature": 0,
        "text": " add a bias, it will give us, let's just say, 0.5.",
        "tokens": [
          50500,
          909,
          257,
          12577,
          11,
          309,
          486,
          976,
          505,
          11,
          718,
          311,
          445,
          584,
          11,
          1958,
          13,
          20,
          13,
          50690
        ]
      },
      {
        "avg_logprob": -0.2670421755410791,
        "compression_ratio": 1.7326732673267327,
        "end": 1233.12,
        "id": 524,
        "no_speech_prob": 0.011157466098666191,
        "seek": 122412,
        "start": 1230.6399999999999,
        "temperature": 0,
        "text": " And then we'll pass that to our outputs,",
        "tokens": [
          50690,
          400,
          550,
          321,
          603,
          1320,
          300,
          281,
          527,
          23930,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.2670421755410791,
        "compression_ratio": 1.7326732673267327,
        "end": 1234.28,
        "id": 525,
        "no_speech_prob": 0.011157466098666191,
        "seek": 122412,
        "start": 1233.12,
        "temperature": 0,
        "text": " which is three.",
        "tokens": [
          50814,
          597,
          307,
          1045,
          13,
          50872
        ]
      },
      {
        "avg_logprob": -0.2670421755410791,
        "compression_ratio": 1.7326732673267327,
        "end": 1240.7199999999998,
        "id": 526,
        "no_speech_prob": 0.011157466098666191,
        "seek": 122412,
        "start": 1239.8799999999999,
        "temperature": 0,
        "text": " Boom.",
        "tokens": [
          51152,
          15523,
          13,
          51194
        ]
      },
      {
        "avg_logprob": -0.2670421755410791,
        "compression_ratio": 1.7326732673267327,
        "end": 1245.4799999999998,
        "id": 527,
        "no_speech_prob": 0.011157466098666191,
        "seek": 122412,
        "start": 1244.28,
        "temperature": 0,
        "text": " Pass this to our output,",
        "tokens": [
          51372,
          10319,
          341,
          281,
          527,
          5598,
          11,
          51432
        ]
      },
      {
        "avg_logprob": -0.2670421755410791,
        "compression_ratio": 1.7326732673267327,
        "end": 1247.56,
        "id": 528,
        "no_speech_prob": 0.011157466098666191,
        "seek": 122412,
        "start": 1245.4799999999998,
        "temperature": 0,
        "text": " and then that will give us a value for each of these.",
        "tokens": [
          51432,
          293,
          550,
          300,
          486,
          976,
          505,
          257,
          2158,
          337,
          1184,
          295,
          613,
          13,
          51536
        ]
      },
      {
        "avg_logprob": -0.2670421755410791,
        "compression_ratio": 1.7326732673267327,
        "end": 1250.6399999999999,
        "id": 529,
        "no_speech_prob": 0.011157466098666191,
        "seek": 122412,
        "start": 1247.56,
        "temperature": 0,
        "text": " Let's say this is 0.3, and then this is 0.7.",
        "tokens": [
          51536,
          961,
          311,
          584,
          341,
          307,
          1958,
          13,
          18,
          11,
          293,
          550,
          341,
          307,
          1958,
          13,
          22,
          13,
          51690
        ]
      },
      {
        "avg_logprob": -0.2670421755410791,
        "compression_ratio": 1.7326732673267327,
        "end": 1252.4399999999998,
        "id": 530,
        "no_speech_prob": 0.011157466098666191,
        "seek": 122412,
        "start": 1250.6399999999999,
        "temperature": 0,
        "text": " And then it's just as simple as we'll just say",
        "tokens": [
          51690,
          400,
          550,
          309,
          311,
          445,
          382,
          2199,
          382,
          321,
          603,
          445,
          584,
          51780
        ]
      },
      {
        "avg_logprob": -0.2670421755410791,
        "compression_ratio": 1.7326732673267327,
        "end": 1253.8799999999999,
        "id": 531,
        "no_speech_prob": 0.011157466098666191,
        "seek": 122412,
        "start": 1252.4399999999998,
        "temperature": 0,
        "text": " that this is higher, 0.7.",
        "tokens": [
          51780,
          300,
          341,
          307,
          2946,
          11,
          1958,
          13,
          22,
          13,
          51852
        ]
      },
      {
        "avg_logprob": -0.2730978897639683,
        "compression_ratio": 1.568,
        "end": 1256.3600000000001,
        "id": 532,
        "no_speech_prob": 0.00024156396102625877,
        "seek": 125388,
        "start": 1254.64,
        "temperature": 0,
        "text": " And so it's guessing why.",
        "tokens": [
          50402,
          400,
          370,
          309,
          311,
          17939,
          983,
          13,
          50488
        ]
      },
      {
        "avg_logprob": -0.2730978897639683,
        "compression_ratio": 1.568,
        "end": 1259.2800000000002,
        "id": 533,
        "no_speech_prob": 0.00024156396102625877,
        "seek": 125388,
        "start": 1256.3600000000001,
        "temperature": 0,
        "text": " So, that's a quick overview on what's going on here.",
        "tokens": [
          50488,
          407,
          11,
          300,
          311,
          257,
          1702,
          12492,
          322,
          437,
          311,
          516,
          322,
          510,
          13,
          50634
        ]
      },
      {
        "avg_logprob": -0.2730978897639683,
        "compression_ratio": 1.568,
        "end": 1264.1200000000001,
        "id": 534,
        "no_speech_prob": 0.00024156396102625877,
        "seek": 125388,
        "start": 1261.2800000000002,
        "temperature": 0,
        "text": " Daniel's gonna post a more in-depth tutorial on this,",
        "tokens": [
          50734,
          8033,
          311,
          799,
          2183,
          257,
          544,
          294,
          12,
          25478,
          7073,
          322,
          341,
          11,
          50876
        ]
      },
      {
        "avg_logprob": -0.2730978897639683,
        "compression_ratio": 1.568,
        "end": 1265.3200000000002,
        "id": 535,
        "no_speech_prob": 0.00024156396102625877,
        "seek": 125388,
        "start": 1264.1200000000001,
        "temperature": 0,
        "text": " or you already have.",
        "tokens": [
          50876,
          420,
          291,
          1217,
          362,
          13,
          50936
        ]
      },
      {
        "avg_logprob": -0.2730978897639683,
        "compression_ratio": 1.568,
        "end": 1270.96,
        "id": 536,
        "no_speech_prob": 0.00024156396102625877,
        "seek": 125388,
        "start": 1266.4,
        "temperature": 0,
        "text": " Well, so I have tutorials on neural network stuff",
        "tokens": [
          50990,
          1042,
          11,
          370,
          286,
          362,
          17616,
          322,
          18161,
          3209,
          1507,
          51218
        ]
      },
      {
        "avg_logprob": -0.2730978897639683,
        "compression_ratio": 1.568,
        "end": 1272.48,
        "id": 537,
        "no_speech_prob": 0.00024156396102625877,
        "seek": 125388,
        "start": 1270.96,
        "temperature": 0,
        "text": " like this that people could go back.",
        "tokens": [
          51218,
          411,
          341,
          300,
          561,
          727,
          352,
          646,
          13,
          51294
        ]
      },
      {
        "avg_logprob": -0.2730978897639683,
        "compression_ratio": 1.568,
        "end": 1274.64,
        "id": 538,
        "no_speech_prob": 0.00024156396102625877,
        "seek": 125388,
        "start": 1272.48,
        "temperature": 0,
        "text": " So this is the same kind of structure",
        "tokens": [
          51294,
          407,
          341,
          307,
          264,
          912,
          733,
          295,
          3877,
          51402
        ]
      },
      {
        "avg_logprob": -0.2730978897639683,
        "compression_ratio": 1.568,
        "end": 1277.92,
        "id": 539,
        "no_speech_prob": 0.00024156396102625877,
        "seek": 125388,
        "start": 1274.64,
        "temperature": 0,
        "text": " that I've used in my neural network library videos.",
        "tokens": [
          51402,
          300,
          286,
          600,
          1143,
          294,
          452,
          18161,
          3209,
          6405,
          2145,
          13,
          51566
        ]
      },
      {
        "avg_logprob": -0.2730978897639683,
        "compression_ratio": 1.568,
        "end": 1280.4,
        "id": 540,
        "no_speech_prob": 0.00024156396102625877,
        "seek": 125388,
        "start": 1277.92,
        "temperature": 0,
        "text": " And I was thinking at some point,",
        "tokens": [
          51566,
          400,
          286,
          390,
          1953,
          412,
          512,
          935,
          11,
          51690
        ]
      },
      {
        "avg_logprob": -0.2730978897639683,
        "compression_ratio": 1.568,
        "end": 1281.48,
        "id": 541,
        "no_speech_prob": 0.00024156396102625877,
        "seek": 125388,
        "start": 1280.4,
        "temperature": 0,
        "text": " maybe next week, hopefully,",
        "tokens": [
          51690,
          1310,
          958,
          1243,
          11,
          4696,
          11,
          51744
        ]
      },
      {
        "avg_logprob": -0.28027692631860474,
        "compression_ratio": 1.7397260273972603,
        "end": 1283.3600000000001,
        "id": 542,
        "no_speech_prob": 0.05920262262225151,
        "seek": 128148,
        "start": 1281.48,
        "temperature": 0,
        "text": " I might try to recreate your project",
        "tokens": [
          50364,
          286,
          1062,
          853,
          281,
          25833,
          428,
          1716,
          50458
        ]
      },
      {
        "avg_logprob": -0.28027692631860474,
        "compression_ratio": 1.7397260273972603,
        "end": 1284.4,
        "id": 543,
        "no_speech_prob": 0.05920262262225151,
        "seek": 128148,
        "start": 1283.3600000000001,
        "temperature": 0,
        "text": " as a coding challenge.",
        "tokens": [
          50458,
          382,
          257,
          17720,
          3430,
          13,
          50510
        ]
      },
      {
        "avg_logprob": -0.28027692631860474,
        "compression_ratio": 1.7397260273972603,
        "end": 1286.3600000000001,
        "id": 544,
        "no_speech_prob": 0.05920262262225151,
        "seek": 128148,
        "start": 1284.4,
        "temperature": 0,
        "text": " In which case, I'll revisit this.",
        "tokens": [
          50510,
          682,
          597,
          1389,
          11,
          286,
          603,
          32676,
          341,
          13,
          50608
        ]
      },
      {
        "avg_logprob": -0.28027692631860474,
        "compression_ratio": 1.7397260273972603,
        "end": 1288.44,
        "id": 545,
        "no_speech_prob": 0.05920262262225151,
        "seek": 128148,
        "start": 1286.3600000000001,
        "temperature": 0,
        "text": " So we can put a link to your, okay.",
        "tokens": [
          50608,
          407,
          321,
          393,
          829,
          257,
          2113,
          281,
          428,
          11,
          1392,
          13,
          50712
        ]
      },
      {
        "avg_logprob": -0.28027692631860474,
        "compression_ratio": 1.7397260273972603,
        "end": 1290.3600000000001,
        "id": 546,
        "no_speech_prob": 0.05920262262225151,
        "seek": 128148,
        "start": 1288.44,
        "temperature": 0,
        "text": " So we'll put a link to Daniel's Shipman series",
        "tokens": [
          50712,
          407,
          321,
          603,
          829,
          257,
          2113,
          281,
          8033,
          311,
          38407,
          1601,
          2638,
          50808
        ]
      },
      {
        "avg_logprob": -0.28027692631860474,
        "compression_ratio": 1.7397260273972603,
        "end": 1292.4,
        "id": 547,
        "no_speech_prob": 0.05920262262225151,
        "seek": 128148,
        "start": 1290.3600000000001,
        "temperature": 0,
        "text": " in which he goes in-depth with this.",
        "tokens": [
          50808,
          294,
          597,
          415,
          1709,
          294,
          12,
          25478,
          365,
          341,
          13,
          50910
        ]
      },
      {
        "avg_logprob": -0.28027692631860474,
        "compression_ratio": 1.7397260273972603,
        "end": 1294.24,
        "id": 548,
        "no_speech_prob": 0.05920262262225151,
        "seek": 128148,
        "start": 1292.4,
        "temperature": 0,
        "text": " So if you wanna learn more about what's going on here.",
        "tokens": [
          50910,
          407,
          498,
          291,
          1948,
          1466,
          544,
          466,
          437,
          311,
          516,
          322,
          510,
          13,
          51002
        ]
      },
      {
        "avg_logprob": -0.28027692631860474,
        "compression_ratio": 1.7397260273972603,
        "end": 1296.04,
        "id": 549,
        "no_speech_prob": 0.05920262262225151,
        "seek": 128148,
        "start": 1294.24,
        "temperature": 0,
        "text": " But that's a quick overview on the math,",
        "tokens": [
          51002,
          583,
          300,
          311,
          257,
          1702,
          12492,
          322,
          264,
          5221,
          11,
          51092
        ]
      },
      {
        "avg_logprob": -0.28027692631860474,
        "compression_ratio": 1.7397260273972603,
        "end": 1297.1200000000001,
        "id": 550,
        "no_speech_prob": 0.05920262262225151,
        "seek": 128148,
        "start": 1296.04,
        "temperature": 0,
        "text": " on the computation.",
        "tokens": [
          51092,
          322,
          264,
          24903,
          13,
          51146
        ]
      },
      {
        "avg_logprob": -0.28027692631860474,
        "compression_ratio": 1.7397260273972603,
        "end": 1299.8,
        "id": 551,
        "no_speech_prob": 0.05920262262225151,
        "seek": 128148,
        "start": 1297.1200000000001,
        "temperature": 0,
        "text": " So our inputs, it gets times by weight and biases,",
        "tokens": [
          51146,
          407,
          527,
          15743,
          11,
          309,
          2170,
          1413,
          538,
          3364,
          293,
          32152,
          11,
          51280
        ]
      },
      {
        "avg_logprob": -0.28027692631860474,
        "compression_ratio": 1.7397260273972603,
        "end": 1302.4,
        "id": 552,
        "no_speech_prob": 0.05920262262225151,
        "seek": 128148,
        "start": 1299.8,
        "temperature": 0,
        "text": " then we get a value, and then we pass that to our output,",
        "tokens": [
          51280,
          550,
          321,
          483,
          257,
          2158,
          11,
          293,
          550,
          321,
          1320,
          300,
          281,
          527,
          5598,
          11,
          51410
        ]
      },
      {
        "avg_logprob": -0.28027692631860474,
        "compression_ratio": 1.7397260273972603,
        "end": 1304.56,
        "id": 553,
        "no_speech_prob": 0.05920262262225151,
        "seek": 128148,
        "start": 1302.4,
        "temperature": 0,
        "text": " same computation, and then gives us a prediction.",
        "tokens": [
          51410,
          912,
          24903,
          11,
          293,
          550,
          2709,
          505,
          257,
          17630,
          13,
          51518
        ]
      },
      {
        "avg_logprob": -0.28027692631860474,
        "compression_ratio": 1.7397260273972603,
        "end": 1305.4,
        "id": 554,
        "no_speech_prob": 0.05920262262225151,
        "seek": 128148,
        "start": 1304.56,
        "temperature": 0,
        "text": " So.",
        "tokens": [
          51518,
          407,
          13,
          51560
        ]
      },
      {
        "avg_logprob": -0.28027692631860474,
        "compression_ratio": 1.7397260273972603,
        "end": 1306.68,
        "id": 555,
        "no_speech_prob": 0.05920262262225151,
        "seek": 128148,
        "start": 1305.4,
        "temperature": 0,
        "text": " Oh, and actually, there's a bunch of questions.",
        "tokens": [
          51560,
          876,
          11,
          293,
          767,
          11,
          456,
          311,
          257,
          3840,
          295,
          1651,
          13,
          51624
        ]
      },
      {
        "avg_logprob": -0.28027692631860474,
        "compression_ratio": 1.7397260273972603,
        "end": 1307.52,
        "id": 556,
        "no_speech_prob": 0.05920262262225151,
        "seek": 128148,
        "start": 1306.68,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          51624,
          876,
          13,
          51666
        ]
      },
      {
        "avg_logprob": -0.28027692631860474,
        "compression_ratio": 1.7397260273972603,
        "end": 1308.3600000000001,
        "id": 557,
        "no_speech_prob": 0.05920262262225151,
        "seek": 128148,
        "start": 1307.52,
        "temperature": 0,
        "text": " I might as well ask,",
        "tokens": [
          51666,
          286,
          1062,
          382,
          731,
          1029,
          11,
          51708
        ]
      },
      {
        "avg_logprob": -0.28027692631860474,
        "compression_ratio": 1.7397260273972603,
        "end": 1309.2,
        "id": 558,
        "no_speech_prob": 0.05920262262225151,
        "seek": 128148,
        "start": 1308.3600000000001,
        "temperature": 0,
        "text": " may I interrupt you and ask a question?",
        "tokens": [
          51708,
          815,
          286,
          12729,
          291,
          293,
          1029,
          257,
          1168,
          30,
          51750
        ]
      },
      {
        "avg_logprob": -0.28027692631860474,
        "compression_ratio": 1.7397260273972603,
        "end": 1310.04,
        "id": 559,
        "no_speech_prob": 0.05920262262225151,
        "seek": 128148,
        "start": 1309.2,
        "temperature": 0,
        "text": " Yeah, let's do it.",
        "tokens": [
          51750,
          865,
          11,
          718,
          311,
          360,
          309,
          13,
          51792
        ]
      },
      {
        "avg_logprob": -0.28027692631860474,
        "compression_ratio": 1.7397260273972603,
        "end": 1310.88,
        "id": 560,
        "no_speech_prob": 0.05920262262225151,
        "seek": 128148,
        "start": 1310.04,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51792,
          1057,
          558,
          13,
          51834
        ]
      },
      {
        "avg_logprob": -0.28911327671360326,
        "compression_ratio": 1.7878787878787878,
        "end": 1313,
        "id": 561,
        "no_speech_prob": 0.009409759193658829,
        "seek": 131088,
        "start": 1311.2800000000002,
        "temperature": 0,
        "text": " People are asking, are you using libraries?",
        "tokens": [
          50384,
          3432,
          366,
          3365,
          11,
          366,
          291,
          1228,
          15148,
          30,
          50470
        ]
      },
      {
        "avg_logprob": -0.28911327671360326,
        "compression_ratio": 1.7878787878787878,
        "end": 1314.3200000000002,
        "id": 562,
        "no_speech_prob": 0.009409759193658829,
        "seek": 131088,
        "start": 1313,
        "temperature": 0,
        "text": " Let me just give you a bunch of questions",
        "tokens": [
          50470,
          961,
          385,
          445,
          976,
          291,
          257,
          3840,
          295,
          1651,
          50536
        ]
      },
      {
        "avg_logprob": -0.28911327671360326,
        "compression_ratio": 1.7878787878787878,
        "end": 1316.2800000000002,
        "id": 563,
        "no_speech_prob": 0.009409759193658829,
        "seek": 131088,
        "start": 1314.3200000000002,
        "temperature": 0,
        "text": " just because the chat's gonna scroll too fast.",
        "tokens": [
          50536,
          445,
          570,
          264,
          5081,
          311,
          799,
          11369,
          886,
          2370,
          13,
          50634
        ]
      },
      {
        "avg_logprob": -0.28911327671360326,
        "compression_ratio": 1.7878787878787878,
        "end": 1317.1200000000001,
        "id": 564,
        "no_speech_prob": 0.009409759193658829,
        "seek": 131088,
        "start": 1316.2800000000002,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50634,
          1033,
          13,
          50676
        ]
      },
      {
        "avg_logprob": -0.28911327671360326,
        "compression_ratio": 1.7878787878787878,
        "end": 1317.96,
        "id": 565,
        "no_speech_prob": 0.009409759193658829,
        "seek": 131088,
        "start": 1317.1200000000001,
        "temperature": 0,
        "text": " Or actually, no, it's fine.",
        "tokens": [
          50676,
          1610,
          767,
          11,
          572,
          11,
          309,
          311,
          2489,
          13,
          50718
        ]
      },
      {
        "avg_logprob": -0.28911327671360326,
        "compression_ratio": 1.7878787878787878,
        "end": 1318.7800000000002,
        "id": 566,
        "no_speech_prob": 0.009409759193658829,
        "seek": 131088,
        "start": 1317.96,
        "temperature": 0,
        "text": " I've stopped it from scrolling.",
        "tokens": [
          50718,
          286,
          600,
          5936,
          309,
          490,
          29053,
          13,
          50759
        ]
      },
      {
        "avg_logprob": -0.28911327671360326,
        "compression_ratio": 1.7878787878787878,
        "end": 1320.24,
        "id": 567,
        "no_speech_prob": 0.009409759193658829,
        "seek": 131088,
        "start": 1318.7800000000002,
        "temperature": 0,
        "text": " So question number one.",
        "tokens": [
          50759,
          407,
          1168,
          1230,
          472,
          13,
          50832
        ]
      },
      {
        "avg_logprob": -0.28911327671360326,
        "compression_ratio": 1.7878787878787878,
        "end": 1321.4,
        "id": 568,
        "no_speech_prob": 0.009409759193658829,
        "seek": 131088,
        "start": 1320.24,
        "temperature": 0,
        "text": " Are you using any libraries,",
        "tokens": [
          50832,
          2014,
          291,
          1228,
          604,
          15148,
          11,
          50890
        ]
      },
      {
        "avg_logprob": -0.28911327671360326,
        "compression_ratio": 1.7878787878787878,
        "end": 1322.8000000000002,
        "id": 569,
        "no_speech_prob": 0.009409759193658829,
        "seek": 131088,
        "start": 1321.4,
        "temperature": 0,
        "text": " or are you building this from scratch?",
        "tokens": [
          50890,
          420,
          366,
          291,
          2390,
          341,
          490,
          8459,
          30,
          50960
        ]
      },
      {
        "avg_logprob": -0.28911327671360326,
        "compression_ratio": 1.7878787878787878,
        "end": 1323.8000000000002,
        "id": 570,
        "no_speech_prob": 0.009409759193658829,
        "seek": 131088,
        "start": 1322.8000000000002,
        "temperature": 0,
        "text": " Okay, so yeah.",
        "tokens": [
          50960,
          1033,
          11,
          370,
          1338,
          13,
          51010
        ]
      },
      {
        "avg_logprob": -0.28911327671360326,
        "compression_ratio": 1.7878787878787878,
        "end": 1326.24,
        "id": 571,
        "no_speech_prob": 0.009409759193658829,
        "seek": 131088,
        "start": 1323.8000000000002,
        "temperature": 0,
        "text": " So this is a from scratch computation.",
        "tokens": [
          51010,
          407,
          341,
          307,
          257,
          490,
          8459,
          24903,
          13,
          51132
        ]
      },
      {
        "avg_logprob": -0.28911327671360326,
        "compression_ratio": 1.7878787878787878,
        "end": 1328.8400000000001,
        "id": 572,
        "no_speech_prob": 0.009409759193658829,
        "seek": 131088,
        "start": 1326.24,
        "temperature": 0,
        "text": " We're doing this completely from scratch.",
        "tokens": [
          51132,
          492,
          434,
          884,
          341,
          2584,
          490,
          8459,
          13,
          51262
        ]
      },
      {
        "avg_logprob": -0.28911327671360326,
        "compression_ratio": 1.7878787878787878,
        "end": 1333.8400000000001,
        "id": 573,
        "no_speech_prob": 0.009409759193658829,
        "seek": 131088,
        "start": 1328.8400000000001,
        "temperature": 0,
        "text": " And it's not necessarily important",
        "tokens": [
          51262,
          400,
          309,
          311,
          406,
          4725,
          1021,
          51512
        ]
      },
      {
        "avg_logprob": -0.28911327671360326,
        "compression_ratio": 1.7878787878787878,
        "end": 1336.3200000000002,
        "id": 574,
        "no_speech_prob": 0.009409759193658829,
        "seek": 131088,
        "start": 1334.48,
        "temperature": 0,
        "text": " that you do from scratch neural networks.",
        "tokens": [
          51544,
          300,
          291,
          360,
          490,
          8459,
          18161,
          9590,
          13,
          51636
        ]
      },
      {
        "avg_logprob": -0.28911327671360326,
        "compression_ratio": 1.7878787878787878,
        "end": 1338.68,
        "id": 575,
        "no_speech_prob": 0.009409759193658829,
        "seek": 131088,
        "start": 1336.3200000000002,
        "temperature": 0,
        "text": " But if you wanna get a good understanding",
        "tokens": [
          51636,
          583,
          498,
          291,
          1948,
          483,
          257,
          665,
          3701,
          51754
        ]
      },
      {
        "avg_logprob": -0.28911327671360326,
        "compression_ratio": 1.7878787878787878,
        "end": 1340.1200000000001,
        "id": 576,
        "no_speech_prob": 0.009409759193658829,
        "seek": 131088,
        "start": 1338.68,
        "temperature": 0,
        "text": " on how to debug networks,",
        "tokens": [
          51754,
          322,
          577,
          281,
          24083,
          9590,
          11,
          51826
        ]
      },
      {
        "avg_logprob": -0.261828988285388,
        "compression_ratio": 1.6681614349775784,
        "end": 1342.52,
        "id": 577,
        "no_speech_prob": 0.0015010880306363106,
        "seek": 134012,
        "start": 1340.12,
        "temperature": 0,
        "text": " this is a really good,",
        "tokens": [
          50364,
          341,
          307,
          257,
          534,
          665,
          11,
          50484
        ]
      },
      {
        "avg_logprob": -0.261828988285388,
        "compression_ratio": 1.6681614349775784,
        "end": 1344.36,
        "id": 578,
        "no_speech_prob": 0.0015010880306363106,
        "seek": 134012,
        "start": 1342.52,
        "temperature": 0,
        "text": " it's a really good way to go about",
        "tokens": [
          50484,
          309,
          311,
          257,
          534,
          665,
          636,
          281,
          352,
          466,
          50576
        ]
      },
      {
        "avg_logprob": -0.261828988285388,
        "compression_ratio": 1.6681614349775784,
        "end": 1345.8799999999999,
        "id": 579,
        "no_speech_prob": 0.0015010880306363106,
        "seek": 134012,
        "start": 1344.36,
        "temperature": 0,
        "text": " ensuring that you can do that.",
        "tokens": [
          50576,
          16882,
          300,
          291,
          393,
          360,
          300,
          13,
          50652
        ]
      },
      {
        "avg_logprob": -0.261828988285388,
        "compression_ratio": 1.6681614349775784,
        "end": 1349.28,
        "id": 580,
        "no_speech_prob": 0.0015010880306363106,
        "seek": 134012,
        "start": 1348.4399999999998,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          50780,
          865,
          13,
          50822
        ]
      },
      {
        "avg_logprob": -0.261828988285388,
        "compression_ratio": 1.6681614349775784,
        "end": 1350.84,
        "id": 581,
        "no_speech_prob": 0.0015010880306363106,
        "seek": 134012,
        "start": 1349.28,
        "temperature": 0,
        "text": " Okay, next question is,",
        "tokens": [
          50822,
          1033,
          11,
          958,
          1168,
          307,
          11,
          50900
        ]
      },
      {
        "avg_logprob": -0.261828988285388,
        "compression_ratio": 1.6681614349775784,
        "end": 1353.6,
        "id": 582,
        "no_speech_prob": 0.0015010880306363106,
        "seek": 134012,
        "start": 1350.84,
        "temperature": 0,
        "text": " does the input have to be from zero to 255?",
        "tokens": [
          50900,
          775,
          264,
          4846,
          362,
          281,
          312,
          490,
          4018,
          281,
          3552,
          20,
          30,
          51038
        ]
      },
      {
        "avg_logprob": -0.261828988285388,
        "compression_ratio": 1.6681614349775784,
        "end": 1354.4399999999998,
        "id": 583,
        "no_speech_prob": 0.0015010880306363106,
        "seek": 134012,
        "start": 1353.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51038,
          1033,
          13,
          51080
        ]
      },
      {
        "avg_logprob": -0.261828988285388,
        "compression_ratio": 1.6681614349775784,
        "end": 1356.1599999999999,
        "id": 584,
        "no_speech_prob": 0.0015010880306363106,
        "seek": 134012,
        "start": 1354.4399999999998,
        "temperature": 0,
        "text": " Should inputs have to be normalized?",
        "tokens": [
          51080,
          6454,
          15743,
          362,
          281,
          312,
          48704,
          30,
          51166
        ]
      },
      {
        "avg_logprob": -0.261828988285388,
        "compression_ratio": 1.6681614349775784,
        "end": 1357.7199999999998,
        "id": 585,
        "no_speech_prob": 0.0015010880306363106,
        "seek": 134012,
        "start": 1356.1599999999999,
        "temperature": 0,
        "text": " What's the, from zero to one?",
        "tokens": [
          51166,
          708,
          311,
          264,
          11,
          490,
          4018,
          281,
          472,
          30,
          51244
        ]
      },
      {
        "avg_logprob": -0.261828988285388,
        "compression_ratio": 1.6681614349775784,
        "end": 1359.9199999999998,
        "id": 586,
        "no_speech_prob": 0.0015010880306363106,
        "seek": 134012,
        "start": 1357.7199999999998,
        "temperature": 0,
        "text": " Yes, great question, great question.",
        "tokens": [
          51244,
          1079,
          11,
          869,
          1168,
          11,
          869,
          1168,
          13,
          51354
        ]
      },
      {
        "avg_logprob": -0.261828988285388,
        "compression_ratio": 1.6681614349775784,
        "end": 1361.9199999999998,
        "id": 587,
        "no_speech_prob": 0.0015010880306363106,
        "seek": 134012,
        "start": 1359.9199999999998,
        "temperature": 0,
        "text": " So again, I just glossed over this,",
        "tokens": [
          51354,
          407,
          797,
          11,
          286,
          445,
          19574,
          292,
          670,
          341,
          11,
          51454
        ]
      },
      {
        "avg_logprob": -0.261828988285388,
        "compression_ratio": 1.6681614349775784,
        "end": 1365.2399999999998,
        "id": 588,
        "no_speech_prob": 0.0015010880306363106,
        "seek": 134012,
        "start": 1361.9199999999998,
        "temperature": 0,
        "text": " but so normalizing inputs for colors",
        "tokens": [
          51454,
          457,
          370,
          2710,
          3319,
          15743,
          337,
          4577,
          51620
        ]
      },
      {
        "avg_logprob": -0.261828988285388,
        "compression_ratio": 1.6681614349775784,
        "end": 1366.28,
        "id": 589,
        "no_speech_prob": 0.0015010880306363106,
        "seek": 134012,
        "start": 1365.2399999999998,
        "temperature": 0,
        "text": " is actually really simple.",
        "tokens": [
          51620,
          307,
          767,
          534,
          2199,
          13,
          51672
        ]
      },
      {
        "avg_logprob": -0.2287398697039403,
        "compression_ratio": 1.6031746031746033,
        "end": 1371.28,
        "id": 590,
        "no_speech_prob": 0.04023594409227371,
        "seek": 136628,
        "start": 1366.28,
        "temperature": 0,
        "text": " And it is always best to normalize your input data.",
        "tokens": [
          50364,
          400,
          309,
          307,
          1009,
          1151,
          281,
          2710,
          1125,
          428,
          4846,
          1412,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2287398697039403,
        "compression_ratio": 1.6031746031746033,
        "end": 1374.56,
        "id": 591,
        "no_speech_prob": 0.04023594409227371,
        "seek": 136628,
        "start": 1371.8,
        "temperature": 0,
        "text": " So because we know that the domain",
        "tokens": [
          50640,
          407,
          570,
          321,
          458,
          300,
          264,
          9274,
          50778
        ]
      },
      {
        "avg_logprob": -0.2287398697039403,
        "compression_ratio": 1.6031746031746033,
        "end": 1379.04,
        "id": 592,
        "no_speech_prob": 0.04023594409227371,
        "seek": 136628,
        "start": 1374.56,
        "temperature": 0,
        "text": " for a color value is always gonna be one to 256,",
        "tokens": [
          50778,
          337,
          257,
          2017,
          2158,
          307,
          1009,
          799,
          312,
          472,
          281,
          38882,
          11,
          51002
        ]
      },
      {
        "avg_logprob": -0.2287398697039403,
        "compression_ratio": 1.6031746031746033,
        "end": 1382.6,
        "id": 593,
        "no_speech_prob": 0.04023594409227371,
        "seek": 136628,
        "start": 1379.04,
        "temperature": 0,
        "text": " or in computer language, we shift that by one, zero to 255,",
        "tokens": [
          51002,
          420,
          294,
          3820,
          2856,
          11,
          321,
          5513,
          300,
          538,
          472,
          11,
          4018,
          281,
          3552,
          20,
          11,
          51180
        ]
      },
      {
        "avg_logprob": -0.2287398697039403,
        "compression_ratio": 1.6031746031746033,
        "end": 1386.12,
        "id": 594,
        "no_speech_prob": 0.04023594409227371,
        "seek": 136628,
        "start": 1382.6,
        "temperature": 0,
        "text": " we can simply just divide whatever this value is over 255.",
        "tokens": [
          51180,
          321,
          393,
          2935,
          445,
          9845,
          2035,
          341,
          2158,
          307,
          670,
          3552,
          20,
          13,
          51356
        ]
      },
      {
        "avg_logprob": -0.2287398697039403,
        "compression_ratio": 1.6031746031746033,
        "end": 1388.56,
        "id": 595,
        "no_speech_prob": 0.04023594409227371,
        "seek": 136628,
        "start": 1386.12,
        "temperature": 0,
        "text": " And that will remap this between zero and one.",
        "tokens": [
          51356,
          400,
          300,
          486,
          890,
          569,
          341,
          1296,
          4018,
          293,
          472,
          13,
          51478
        ]
      },
      {
        "avg_logprob": -0.2287398697039403,
        "compression_ratio": 1.6031746031746033,
        "end": 1391.56,
        "id": 596,
        "no_speech_prob": 0.04023594409227371,
        "seek": 136628,
        "start": 1388.56,
        "temperature": 0,
        "text": " And so essentially, when you're writing your program,",
        "tokens": [
          51478,
          400,
          370,
          4476,
          11,
          562,
          291,
          434,
          3579,
          428,
          1461,
          11,
          51628
        ]
      },
      {
        "avg_logprob": -0.2287398697039403,
        "compression_ratio": 1.6031746031746033,
        "end": 1395.16,
        "id": 597,
        "no_speech_prob": 0.04023594409227371,
        "seek": 136628,
        "start": 1391.56,
        "temperature": 0,
        "text": " you would just pass the input through a function",
        "tokens": [
          51628,
          291,
          576,
          445,
          1320,
          264,
          4846,
          807,
          257,
          2445,
          51808
        ]
      },
      {
        "avg_logprob": -0.28005795362519054,
        "compression_ratio": 1.6307692307692307,
        "end": 1396.96,
        "id": 598,
        "no_speech_prob": 0.0004511999140959233,
        "seek": 139516,
        "start": 1395.16,
        "temperature": 0,
        "text": " that would just divide it by 255.",
        "tokens": [
          50364,
          300,
          576,
          445,
          9845,
          309,
          538,
          3552,
          20,
          13,
          50454
        ]
      },
      {
        "avg_logprob": -0.28005795362519054,
        "compression_ratio": 1.6307692307692307,
        "end": 1398.96,
        "id": 599,
        "no_speech_prob": 0.0004511999140959233,
        "seek": 139516,
        "start": 1396.96,
        "temperature": 0,
        "text": " So yes, great question.",
        "tokens": [
          50454,
          407,
          2086,
          11,
          869,
          1168,
          13,
          50554
        ]
      },
      {
        "avg_logprob": -0.28005795362519054,
        "compression_ratio": 1.6307692307692307,
        "end": 1400.28,
        "id": 600,
        "no_speech_prob": 0.0004511999140959233,
        "seek": 139516,
        "start": 1398.96,
        "temperature": 0,
        "text": " All right, one more question.",
        "tokens": [
          50554,
          1057,
          558,
          11,
          472,
          544,
          1168,
          13,
          50620
        ]
      },
      {
        "avg_logprob": -0.28005795362519054,
        "compression_ratio": 1.6307692307692307,
        "end": 1402.28,
        "id": 601,
        "no_speech_prob": 0.0004511999140959233,
        "seek": 139516,
        "start": 1400.28,
        "temperature": 0,
        "text": " So I'm kind of curious about this too.",
        "tokens": [
          50620,
          407,
          286,
          478,
          733,
          295,
          6369,
          466,
          341,
          886,
          13,
          50720
        ]
      },
      {
        "avg_logprob": -0.28005795362519054,
        "compression_ratio": 1.6307692307692307,
        "end": 1404,
        "id": 602,
        "no_speech_prob": 0.0004511999140959233,
        "seek": 139516,
        "start": 1402.28,
        "temperature": 0,
        "text": " I sort of think it's probably,",
        "tokens": [
          50720,
          286,
          1333,
          295,
          519,
          309,
          311,
          1391,
          11,
          50806
        ]
      },
      {
        "avg_logprob": -0.28005795362519054,
        "compression_ratio": 1.6307692307692307,
        "end": 1406.72,
        "id": 603,
        "no_speech_prob": 0.0004511999140959233,
        "seek": 139516,
        "start": 1404,
        "temperature": 0,
        "text": " I feel like I answered the question before I ask it.",
        "tokens": [
          50806,
          286,
          841,
          411,
          286,
          10103,
          264,
          1168,
          949,
          286,
          1029,
          309,
          13,
          50942
        ]
      },
      {
        "avg_logprob": -0.28005795362519054,
        "compression_ratio": 1.6307692307692307,
        "end": 1411.0400000000002,
        "id": 604,
        "no_speech_prob": 0.0004511999140959233,
        "seek": 139516,
        "start": 1406.72,
        "temperature": 0,
        "text": " But is there a benefit to having two output nodes",
        "tokens": [
          50942,
          583,
          307,
          456,
          257,
          5121,
          281,
          1419,
          732,
          5598,
          13891,
          51158
        ]
      },
      {
        "avg_logprob": -0.28005795362519054,
        "compression_ratio": 1.6307692307692307,
        "end": 1414.3600000000001,
        "id": 605,
        "no_speech_prob": 0.0004511999140959233,
        "seek": 139516,
        "start": 1412.96,
        "temperature": 0,
        "text": " rather than just have one,",
        "tokens": [
          51254,
          2831,
          813,
          445,
          362,
          472,
          11,
          51324
        ]
      },
      {
        "avg_logprob": -0.28005795362519054,
        "compression_ratio": 1.6307692307692307,
        "end": 1415.92,
        "id": 606,
        "no_speech_prob": 0.0004511999140959233,
        "seek": 139516,
        "start": 1414.3600000000001,
        "temperature": 0,
        "text": " since there's only like this like a range",
        "tokens": [
          51324,
          1670,
          456,
          311,
          787,
          411,
          341,
          411,
          257,
          3613,
          51402
        ]
      },
      {
        "avg_logprob": -0.28005795362519054,
        "compression_ratio": 1.6307692307692307,
        "end": 1417.44,
        "id": 607,
        "no_speech_prob": 0.0004511999140959233,
        "seek": 139516,
        "start": 1415.92,
        "temperature": 0,
        "text": " between negative one and one or something like that?",
        "tokens": [
          51402,
          1296,
          3671,
          472,
          293,
          472,
          420,
          746,
          411,
          300,
          30,
          51478
        ]
      },
      {
        "avg_logprob": -0.28005795362519054,
        "compression_ratio": 1.6307692307692307,
        "end": 1420.8400000000001,
        "id": 608,
        "no_speech_prob": 0.0004511999140959233,
        "seek": 139516,
        "start": 1417.44,
        "temperature": 0,
        "text": " Yeah, so there's a lot of debate on this.",
        "tokens": [
          51478,
          865,
          11,
          370,
          456,
          311,
          257,
          688,
          295,
          7958,
          322,
          341,
          13,
          51648
        ]
      },
      {
        "avg_logprob": -0.19423710051037016,
        "compression_ratio": 1.679245283018868,
        "end": 1425.4399999999998,
        "id": 609,
        "no_speech_prob": 0.0004373307165224105,
        "seek": 142084,
        "start": 1420.84,
        "temperature": 0,
        "text": " And I agree with the side that it's easier",
        "tokens": [
          50364,
          400,
          286,
          3986,
          365,
          264,
          1252,
          300,
          309,
          311,
          3571,
          50594
        ]
      },
      {
        "avg_logprob": -0.19423710051037016,
        "compression_ratio": 1.679245283018868,
        "end": 1429.48,
        "id": 610,
        "no_speech_prob": 0.0004373307165224105,
        "seek": 142084,
        "start": 1425.4399999999998,
        "temperature": 0,
        "text": " when you have like classifiers versus like,",
        "tokens": [
          50594,
          562,
          291,
          362,
          411,
          1508,
          23463,
          5717,
          411,
          11,
          50796
        ]
      },
      {
        "avg_logprob": -0.19423710051037016,
        "compression_ratio": 1.679245283018868,
        "end": 1431.24,
        "id": 611,
        "no_speech_prob": 0.0004373307165224105,
        "seek": 142084,
        "start": 1429.48,
        "temperature": 0,
        "text": " if you have just one output node",
        "tokens": [
          50796,
          498,
          291,
          362,
          445,
          472,
          5598,
          9984,
          50884
        ]
      },
      {
        "avg_logprob": -0.19423710051037016,
        "compression_ratio": 1.679245283018868,
        "end": 1434.9599999999998,
        "id": 612,
        "no_speech_prob": 0.0004373307165224105,
        "seek": 142084,
        "start": 1431.24,
        "temperature": 0,
        "text": " that is mapped between negative one and one, right?",
        "tokens": [
          50884,
          300,
          307,
          33318,
          1296,
          3671,
          472,
          293,
          472,
          11,
          558,
          30,
          51070
        ]
      },
      {
        "avg_logprob": -0.19423710051037016,
        "compression_ratio": 1.679245283018868,
        "end": 1438.8799999999999,
        "id": 613,
        "no_speech_prob": 0.0004373307165224105,
        "seek": 142084,
        "start": 1434.9599999999998,
        "temperature": 0,
        "text": " And then if it's above zero, then it's gonna be white.",
        "tokens": [
          51070,
          400,
          550,
          498,
          309,
          311,
          3673,
          4018,
          11,
          550,
          309,
          311,
          799,
          312,
          2418,
          13,
          51266
        ]
      },
      {
        "avg_logprob": -0.19423710051037016,
        "compression_ratio": 1.679245283018868,
        "end": 1442.04,
        "id": 614,
        "no_speech_prob": 0.0004373307165224105,
        "seek": 142084,
        "start": 1438.8799999999999,
        "temperature": 0,
        "text": " If it's below zero, then it's gonna be black.",
        "tokens": [
          51266,
          759,
          309,
          311,
          2507,
          4018,
          11,
          550,
          309,
          311,
          799,
          312,
          2211,
          13,
          51424
        ]
      },
      {
        "avg_logprob": -0.19423710051037016,
        "compression_ratio": 1.679245283018868,
        "end": 1446.84,
        "id": 615,
        "no_speech_prob": 0.0004373307165224105,
        "seek": 142084,
        "start": 1444.56,
        "temperature": 0,
        "text": " Yeah, based on the research that I've read,",
        "tokens": [
          51550,
          865,
          11,
          2361,
          322,
          264,
          2132,
          300,
          286,
          600,
          1401,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.19423710051037016,
        "compression_ratio": 1.679245283018868,
        "end": 1449.1599999999999,
        "id": 616,
        "no_speech_prob": 0.0004373307165224105,
        "seek": 142084,
        "start": 1446.84,
        "temperature": 0,
        "text": " it's always best to go on a classifier.",
        "tokens": [
          51664,
          309,
          311,
          1009,
          1151,
          281,
          352,
          322,
          257,
          1508,
          9902,
          13,
          51780
        ]
      },
      {
        "avg_logprob": -0.21570292115211487,
        "compression_ratio": 1.7272727272727273,
        "end": 1452.6000000000001,
        "id": 617,
        "no_speech_prob": 0.00039817087235860527,
        "seek": 144916,
        "start": 1449.64,
        "temperature": 0,
        "text": " And it seems to me like maybe this would be fine",
        "tokens": [
          50388,
          400,
          309,
          2544,
          281,
          385,
          411,
          1310,
          341,
          576,
          312,
          2489,
          50536
        ]
      },
      {
        "avg_logprob": -0.21570292115211487,
        "compression_ratio": 1.7272727272727273,
        "end": 1456.16,
        "id": 618,
        "no_speech_prob": 0.00039817087235860527,
        "seek": 144916,
        "start": 1452.6000000000001,
        "temperature": 0,
        "text": " in the case of there's only two labels or two classes,",
        "tokens": [
          50536,
          294,
          264,
          1389,
          295,
          456,
          311,
          787,
          732,
          16949,
          420,
          732,
          5359,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.21570292115211487,
        "compression_ratio": 1.7272727272727273,
        "end": 1458.2,
        "id": 619,
        "no_speech_prob": 0.00039817087235860527,
        "seek": 144916,
        "start": 1456.16,
        "temperature": 0,
        "text": " but once you have more than two,",
        "tokens": [
          50714,
          457,
          1564,
          291,
          362,
          544,
          813,
          732,
          11,
          50816
        ]
      },
      {
        "avg_logprob": -0.21570292115211487,
        "compression_ratio": 1.7272727272727273,
        "end": 1459.52,
        "id": 620,
        "no_speech_prob": 0.00039817087235860527,
        "seek": 144916,
        "start": 1458.2,
        "temperature": 0,
        "text": " it's gonna be problematic.",
        "tokens": [
          50816,
          309,
          311,
          799,
          312,
          19011,
          13,
          50882
        ]
      },
      {
        "avg_logprob": -0.21570292115211487,
        "compression_ratio": 1.7272727272727273,
        "end": 1461.88,
        "id": 621,
        "no_speech_prob": 0.00039817087235860527,
        "seek": 144916,
        "start": 1459.52,
        "temperature": 0,
        "text": " And so as a like demonstration and learning,",
        "tokens": [
          50882,
          400,
          370,
          382,
          257,
          411,
          16520,
          293,
          2539,
          11,
          51000
        ]
      },
      {
        "avg_logprob": -0.21570292115211487,
        "compression_ratio": 1.7272727272727273,
        "end": 1464.28,
        "id": 622,
        "no_speech_prob": 0.00039817087235860527,
        "seek": 144916,
        "start": 1461.88,
        "temperature": 0,
        "text": " even though this might be a very like basic scenario,",
        "tokens": [
          51000,
          754,
          1673,
          341,
          1062,
          312,
          257,
          588,
          411,
          3875,
          9005,
          11,
          51120
        ]
      },
      {
        "avg_logprob": -0.21570292115211487,
        "compression_ratio": 1.7272727272727273,
        "end": 1466.88,
        "id": 623,
        "no_speech_prob": 0.00039817087235860527,
        "seek": 144916,
        "start": 1464.28,
        "temperature": 0,
        "text": " it's useful to demonstrate the multiple outputs",
        "tokens": [
          51120,
          309,
          311,
          4420,
          281,
          11698,
          264,
          3866,
          23930,
          51250
        ]
      },
      {
        "avg_logprob": -0.21570292115211487,
        "compression_ratio": 1.7272727272727273,
        "end": 1468.0800000000002,
        "id": 624,
        "no_speech_prob": 0.00039817087235860527,
        "seek": 144916,
        "start": 1466.88,
        "temperature": 0,
        "text": " because you're gonna need to do that",
        "tokens": [
          51250,
          570,
          291,
          434,
          799,
          643,
          281,
          360,
          300,
          51310
        ]
      },
      {
        "avg_logprob": -0.21570292115211487,
        "compression_ratio": 1.7272727272727273,
        "end": 1469,
        "id": 625,
        "no_speech_prob": 0.00039817087235860527,
        "seek": 144916,
        "start": 1468.0800000000002,
        "temperature": 0,
        "text": " if you were to expand this further.",
        "tokens": [
          51310,
          498,
          291,
          645,
          281,
          5268,
          341,
          3052,
          13,
          51356
        ]
      },
      {
        "avg_logprob": -0.21570292115211487,
        "compression_ratio": 1.7272727272727273,
        "end": 1472.3600000000001,
        "id": 626,
        "no_speech_prob": 0.00039817087235860527,
        "seek": 144916,
        "start": 1469,
        "temperature": 0,
        "text": " Correct, and the whole reason for that",
        "tokens": [
          51356,
          12753,
          11,
          293,
          264,
          1379,
          1778,
          337,
          300,
          51524
        ]
      },
      {
        "avg_logprob": -0.21570292115211487,
        "compression_ratio": 1.7272727272727273,
        "end": 1475,
        "id": 627,
        "no_speech_prob": 0.00039817087235860527,
        "seek": 144916,
        "start": 1472.3600000000001,
        "temperature": 0,
        "text": " is because what happens when you separate them",
        "tokens": [
          51524,
          307,
          570,
          437,
          2314,
          562,
          291,
          4994,
          552,
          51656
        ]
      },
      {
        "avg_logprob": -0.21570292115211487,
        "compression_ratio": 1.7272727272727273,
        "end": 1476.48,
        "id": 628,
        "no_speech_prob": 0.00039817087235860527,
        "seek": 144916,
        "start": 1475,
        "temperature": 0,
        "text": " is you get probabilities",
        "tokens": [
          51656,
          307,
          291,
          483,
          33783,
          51730
        ]
      },
      {
        "avg_logprob": -0.21325020168138586,
        "compression_ratio": 1.6359832635983265,
        "end": 1479.24,
        "id": 629,
        "no_speech_prob": 0.0010162275284528732,
        "seek": 147648,
        "start": 1476.48,
        "temperature": 0,
        "text": " versus like you get a map of between zero and one,",
        "tokens": [
          50364,
          5717,
          411,
          291,
          483,
          257,
          4471,
          295,
          1296,
          4018,
          293,
          472,
          11,
          50502
        ]
      },
      {
        "avg_logprob": -0.21325020168138586,
        "compression_ratio": 1.6359832635983265,
        "end": 1481.84,
        "id": 630,
        "no_speech_prob": 0.0010162275284528732,
        "seek": 147648,
        "start": 1479.24,
        "temperature": 0,
        "text": " which again, if it's one output, you can get away with that.",
        "tokens": [
          50502,
          597,
          797,
          11,
          498,
          309,
          311,
          472,
          5598,
          11,
          291,
          393,
          483,
          1314,
          365,
          300,
          13,
          50632
        ]
      },
      {
        "avg_logprob": -0.21325020168138586,
        "compression_ratio": 1.6359832635983265,
        "end": 1484.44,
        "id": 631,
        "no_speech_prob": 0.0010162275284528732,
        "seek": 147648,
        "start": 1481.84,
        "temperature": 0,
        "text": " But if you try and encode your outputs",
        "tokens": [
          50632,
          583,
          498,
          291,
          853,
          293,
          2058,
          1429,
          428,
          23930,
          50762
        ]
      },
      {
        "avg_logprob": -0.21325020168138586,
        "compression_ratio": 1.6359832635983265,
        "end": 1487.44,
        "id": 632,
        "no_speech_prob": 0.0010162275284528732,
        "seek": 147648,
        "start": 1484.44,
        "temperature": 0,
        "text": " using this for like 30 different,",
        "tokens": [
          50762,
          1228,
          341,
          337,
          411,
          2217,
          819,
          11,
          50912
        ]
      },
      {
        "avg_logprob": -0.21325020168138586,
        "compression_ratio": 1.6359832635983265,
        "end": 1490.4,
        "id": 633,
        "no_speech_prob": 0.0010162275284528732,
        "seek": 147648,
        "start": 1487.44,
        "temperature": 0,
        "text": " the neural network might not make good sense of that.",
        "tokens": [
          50912,
          264,
          18161,
          3209,
          1062,
          406,
          652,
          665,
          2020,
          295,
          300,
          13,
          51060
        ]
      },
      {
        "avg_logprob": -0.21325020168138586,
        "compression_ratio": 1.6359832635983265,
        "end": 1491.4,
        "id": 634,
        "no_speech_prob": 0.0010162275284528732,
        "seek": 147648,
        "start": 1490.4,
        "temperature": 0,
        "text": " Cool, all right.",
        "tokens": [
          51060,
          8561,
          11,
          439,
          558,
          13,
          51110
        ]
      },
      {
        "avg_logprob": -0.21325020168138586,
        "compression_ratio": 1.6359832635983265,
        "end": 1493.24,
        "id": 635,
        "no_speech_prob": 0.0010162275284528732,
        "seek": 147648,
        "start": 1491.4,
        "temperature": 0,
        "text": " Cool, so let's continue on",
        "tokens": [
          51110,
          8561,
          11,
          370,
          718,
          311,
          2354,
          322,
          51202
        ]
      },
      {
        "avg_logprob": -0.21325020168138586,
        "compression_ratio": 1.6359832635983265,
        "end": 1496.68,
        "id": 636,
        "no_speech_prob": 0.0010162275284528732,
        "seek": 147648,
        "start": 1493.24,
        "temperature": 0,
        "text": " because we need to get into the code part.",
        "tokens": [
          51202,
          570,
          321,
          643,
          281,
          483,
          666,
          264,
          3089,
          644,
          13,
          51374
        ]
      },
      {
        "avg_logprob": -0.21325020168138586,
        "compression_ratio": 1.6359832635983265,
        "end": 1501.92,
        "id": 637,
        "no_speech_prob": 0.0010162275284528732,
        "seek": 147648,
        "start": 1497.96,
        "temperature": 0,
        "text": " So let's look at some of the code",
        "tokens": [
          51438,
          407,
          718,
          311,
          574,
          412,
          512,
          295,
          264,
          3089,
          51636
        ]
      },
      {
        "avg_logprob": -0.21325020168138586,
        "compression_ratio": 1.6359832635983265,
        "end": 1504.3600000000001,
        "id": 638,
        "no_speech_prob": 0.0010162275284528732,
        "seek": 147648,
        "start": 1501.92,
        "temperature": 0,
        "text": " as to how we went about writing",
        "tokens": [
          51636,
          382,
          281,
          577,
          321,
          1437,
          466,
          3579,
          51758
        ]
      },
      {
        "avg_logprob": -0.3038509759035977,
        "compression_ratio": 1.446236559139785,
        "end": 1506.76,
        "id": 639,
        "no_speech_prob": 0.0025908974930644035,
        "seek": 150436,
        "start": 1504.36,
        "temperature": 0,
        "text": " that part of our neural network.",
        "tokens": [
          50364,
          300,
          644,
          295,
          527,
          18161,
          3209,
          13,
          50484
        ]
      },
      {
        "avg_logprob": -0.3038509759035977,
        "compression_ratio": 1.446236559139785,
        "end": 1510.8,
        "id": 640,
        "no_speech_prob": 0.0025908974930644035,
        "seek": 150436,
        "start": 1508.9599999999998,
        "temperature": 0,
        "text": " Right, down is up, I keep forgetting.",
        "tokens": [
          50594,
          1779,
          11,
          760,
          307,
          493,
          11,
          286,
          1066,
          25428,
          13,
          50686
        ]
      },
      {
        "avg_logprob": -0.3038509759035977,
        "compression_ratio": 1.446236559139785,
        "end": 1513.1999999999998,
        "id": 641,
        "no_speech_prob": 0.0025908974930644035,
        "seek": 150436,
        "start": 1510.8,
        "temperature": 0,
        "text": " I'm new to Mac, so please forgive me here.",
        "tokens": [
          50686,
          286,
          478,
          777,
          281,
          5707,
          11,
          370,
          1767,
          10718,
          385,
          510,
          13,
          50806
        ]
      },
      {
        "avg_logprob": -0.3038509759035977,
        "compression_ratio": 1.446236559139785,
        "end": 1516,
        "id": 642,
        "no_speech_prob": 0.0025908974930644035,
        "seek": 150436,
        "start": 1514.6399999999999,
        "temperature": 0,
        "text": " All right, so,",
        "tokens": [
          50878,
          1057,
          558,
          11,
          370,
          11,
          50946
        ]
      },
      {
        "avg_logprob": -0.3038509759035977,
        "compression_ratio": 1.446236559139785,
        "end": 1521.36,
        "id": 643,
        "no_speech_prob": 0.0025908974930644035,
        "seek": 150436,
        "start": 1518.28,
        "temperature": 0,
        "text": " and you beautified my coat.",
        "tokens": [
          51060,
          293,
          291,
          1869,
          2587,
          452,
          10690,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.3038509759035977,
        "compression_ratio": 1.446236559139785,
        "end": 1523.9199999999998,
        "id": 644,
        "no_speech_prob": 0.0025908974930644035,
        "seek": 150436,
        "start": 1522.28,
        "temperature": 0,
        "text": " No worries, no worries.",
        "tokens": [
          51260,
          883,
          16340,
          11,
          572,
          16340,
          13,
          51342
        ]
      },
      {
        "avg_logprob": -0.3038509759035977,
        "compression_ratio": 1.446236559139785,
        "end": 1528,
        "id": 645,
        "no_speech_prob": 0.0025908974930644035,
        "seek": 150436,
        "start": 1526.1999999999998,
        "temperature": 0,
        "text": " Beautified and zoomed.",
        "tokens": [
          51456,
          10584,
          2587,
          293,
          8863,
          292,
          13,
          51546
        ]
      },
      {
        "avg_logprob": -0.3038509759035977,
        "compression_ratio": 1.446236559139785,
        "end": 1531.6399999999999,
        "id": 646,
        "no_speech_prob": 0.0025908974930644035,
        "seek": 150436,
        "start": 1528,
        "temperature": 0,
        "text": " Okay, so we first need to define",
        "tokens": [
          51546,
          1033,
          11,
          370,
          321,
          700,
          643,
          281,
          6964,
          51728
        ]
      },
      {
        "avg_logprob": -0.3038509759035977,
        "compression_ratio": 1.446236559139785,
        "end": 1533.76,
        "id": 647,
        "no_speech_prob": 0.0025908974930644035,
        "seek": 150436,
        "start": 1531.6399999999999,
        "temperature": 0,
        "text": " all of our variables at the top.",
        "tokens": [
          51728,
          439,
          295,
          527,
          9102,
          412,
          264,
          1192,
          13,
          51834
        ]
      },
      {
        "avg_logprob": -0.30167990671077244,
        "compression_ratio": 1.4171779141104295,
        "end": 1536.6,
        "id": 648,
        "no_speech_prob": 0.00015356075891759247,
        "seek": 153436,
        "start": 1534.76,
        "temperature": 0,
        "text": " So RGB is our input.",
        "tokens": [
          50384,
          407,
          31231,
          307,
          527,
          4846,
          13,
          50476
        ]
      },
      {
        "avg_logprob": -0.30167990671077244,
        "compression_ratio": 1.4171779141104295,
        "end": 1540.8799999999999,
        "id": 649,
        "no_speech_prob": 0.00015356075891759247,
        "seek": 153436,
        "start": 1537.6399999999999,
        "temperature": 0,
        "text": " And then we have the amount of choices,",
        "tokens": [
          50528,
          400,
          550,
          321,
          362,
          264,
          2372,
          295,
          7994,
          11,
          50690
        ]
      },
      {
        "avg_logprob": -0.30167990671077244,
        "compression_ratio": 1.4171779141104295,
        "end": 1545.8799999999999,
        "id": 650,
        "no_speech_prob": 0.00015356075891759247,
        "seek": 153436,
        "start": 1540.8799999999999,
        "temperature": 0,
        "text": " which is a variable that we use for our output.",
        "tokens": [
          50690,
          597,
          307,
          257,
          7006,
          300,
          321,
          764,
          337,
          527,
          5598,
          13,
          50940
        ]
      },
      {
        "avg_logprob": -0.30167990671077244,
        "compression_ratio": 1.4171779141104295,
        "end": 1552.1999999999998,
        "id": 651,
        "no_speech_prob": 0.00015356075891759247,
        "seek": 153436,
        "start": 1550.32,
        "temperature": 0,
        "text": " Skim one second, just skim this,",
        "tokens": [
          51162,
          7324,
          332,
          472,
          1150,
          11,
          445,
          1110,
          332,
          341,
          11,
          51256
        ]
      },
      {
        "avg_logprob": -0.30167990671077244,
        "compression_ratio": 1.4171779141104295,
        "end": 1555.52,
        "id": 652,
        "no_speech_prob": 0.00015356075891759247,
        "seek": 153436,
        "start": 1552.1999999999998,
        "temperature": 0,
        "text": " make sure I don't give you the wrong information here.",
        "tokens": [
          51256,
          652,
          988,
          286,
          500,
          380,
          976,
          291,
          264,
          2085,
          1589,
          510,
          13,
          51422
        ]
      },
      {
        "avg_logprob": -0.30167990671077244,
        "compression_ratio": 1.4171779141104295,
        "end": 1563.1599999999999,
        "id": 653,
        "no_speech_prob": 0.00015356075891759247,
        "seek": 153436,
        "start": 1561.3999999999999,
        "temperature": 0,
        "text": " Sweet, so we set up our variables.",
        "tokens": [
          51716,
          14653,
          11,
          370,
          321,
          992,
          493,
          527,
          9102,
          13,
          51804
        ]
      },
      {
        "avg_logprob": -0.2533110963537338,
        "compression_ratio": 1.5678391959798994,
        "end": 1564.8400000000001,
        "id": 654,
        "no_speech_prob": 0.0001334190455963835,
        "seek": 156316,
        "start": 1563.2,
        "temperature": 0,
        "text": " RGB is our input data.",
        "tokens": [
          50366,
          31231,
          307,
          527,
          4846,
          1412,
          13,
          50448
        ]
      },
      {
        "avg_logprob": -0.2533110963537338,
        "compression_ratio": 1.5678391959798994,
        "end": 1568.92,
        "id": 655,
        "no_speech_prob": 0.0001334190455963835,
        "seek": 156316,
        "start": 1566.3600000000001,
        "temperature": 0,
        "text": " And then so, one thing that's really important",
        "tokens": [
          50524,
          400,
          550,
          370,
          11,
          472,
          551,
          300,
          311,
          534,
          1021,
          50652
        ]
      },
      {
        "avg_logprob": -0.2533110963537338,
        "compression_ratio": 1.5678391959798994,
        "end": 1572.92,
        "id": 656,
        "no_speech_prob": 0.0001334190455963835,
        "seek": 156316,
        "start": 1568.92,
        "temperature": 0,
        "text": " that I should go over just to make sense",
        "tokens": [
          50652,
          300,
          286,
          820,
          352,
          670,
          445,
          281,
          652,
          2020,
          50852
        ]
      },
      {
        "avg_logprob": -0.2533110963537338,
        "compression_ratio": 1.5678391959798994,
        "end": 1576.3600000000001,
        "id": 657,
        "no_speech_prob": 0.0001334190455963835,
        "seek": 156316,
        "start": 1572.92,
        "temperature": 0,
        "text": " of what's going on here is,",
        "tokens": [
          50852,
          295,
          437,
          311,
          516,
          322,
          510,
          307,
          11,
          51024
        ]
      },
      {
        "avg_logprob": -0.2533110963537338,
        "compression_ratio": 1.5678391959798994,
        "end": 1579,
        "id": 658,
        "no_speech_prob": 0.0001334190455963835,
        "seek": 156316,
        "start": 1576.3600000000001,
        "temperature": 0,
        "text": " too wrong computer on this one.",
        "tokens": [
          51024,
          886,
          2085,
          3820,
          322,
          341,
          472,
          13,
          51156
        ]
      },
      {
        "avg_logprob": -0.2533110963537338,
        "compression_ratio": 1.5678391959798994,
        "end": 1579.8400000000001,
        "id": 659,
        "no_speech_prob": 0.0001334190455963835,
        "seek": 156316,
        "start": 1579,
        "temperature": 0,
        "text": " Delete that.",
        "tokens": [
          51156,
          49452,
          300,
          13,
          51198
        ]
      },
      {
        "avg_logprob": -0.2533110963537338,
        "compression_ratio": 1.5678391959798994,
        "end": 1582.24,
        "id": 660,
        "no_speech_prob": 0.0001334190455963835,
        "seek": 156316,
        "start": 1579.8400000000001,
        "temperature": 0,
        "text": " So it's really important,",
        "tokens": [
          51198,
          407,
          309,
          311,
          534,
          1021,
          11,
          51318
        ]
      },
      {
        "avg_logprob": -0.2533110963537338,
        "compression_ratio": 1.5678391959798994,
        "end": 1583.96,
        "id": 661,
        "no_speech_prob": 0.0001334190455963835,
        "seek": 156316,
        "start": 1582.24,
        "temperature": 0,
        "text": " in order for you to write your algorithm,",
        "tokens": [
          51318,
          294,
          1668,
          337,
          291,
          281,
          2464,
          428,
          9284,
          11,
          51404
        ]
      },
      {
        "avg_logprob": -0.2533110963537338,
        "compression_ratio": 1.5678391959798994,
        "end": 1587.5600000000002,
        "id": 662,
        "no_speech_prob": 0.0001334190455963835,
        "seek": 156316,
        "start": 1583.96,
        "temperature": 0,
        "text": " you need to know how to compute this,",
        "tokens": [
          51404,
          291,
          643,
          281,
          458,
          577,
          281,
          14722,
          341,
          11,
          51584
        ]
      },
      {
        "avg_logprob": -0.2533110963537338,
        "compression_ratio": 1.5678391959798994,
        "end": 1588.8000000000002,
        "id": 663,
        "no_speech_prob": 0.0001334190455963835,
        "seek": 156316,
        "start": 1587.5600000000002,
        "temperature": 0,
        "text": " compute both of these.",
        "tokens": [
          51584,
          14722,
          1293,
          295,
          613,
          13,
          51646
        ]
      },
      {
        "avg_logprob": -0.18385468423366547,
        "compression_ratio": 1.7623318385650224,
        "end": 1593.8,
        "id": 664,
        "no_speech_prob": 0.00029595562955364585,
        "seek": 158880,
        "start": 1588.8,
        "temperature": 0,
        "text": " So this is really just an array of values.",
        "tokens": [
          50364,
          407,
          341,
          307,
          534,
          445,
          364,
          10225,
          295,
          4190,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18385468423366547,
        "compression_ratio": 1.7623318385650224,
        "end": 1598.04,
        "id": 665,
        "no_speech_prob": 0.00029595562955364585,
        "seek": 158880,
        "start": 1594,
        "temperature": 0,
        "text": " So we can call this array G of I, right?",
        "tokens": [
          50624,
          407,
          321,
          393,
          818,
          341,
          10225,
          460,
          295,
          286,
          11,
          558,
          30,
          50826
        ]
      },
      {
        "avg_logprob": -0.18385468423366547,
        "compression_ratio": 1.7623318385650224,
        "end": 1601.52,
        "id": 666,
        "no_speech_prob": 0.00029595562955364585,
        "seek": 158880,
        "start": 1598.04,
        "temperature": 0,
        "text": " So this is G of zero, and this is G of one.",
        "tokens": [
          50826,
          407,
          341,
          307,
          460,
          295,
          4018,
          11,
          293,
          341,
          307,
          460,
          295,
          472,
          13,
          51000
        ]
      },
      {
        "avg_logprob": -0.18385468423366547,
        "compression_ratio": 1.7623318385650224,
        "end": 1603.04,
        "id": 667,
        "no_speech_prob": 0.00029595562955364585,
        "seek": 158880,
        "start": 1601.52,
        "temperature": 0,
        "text": " And G just stands for a guess.",
        "tokens": [
          51000,
          400,
          460,
          445,
          7382,
          337,
          257,
          2041,
          13,
          51076
        ]
      },
      {
        "avg_logprob": -0.18385468423366547,
        "compression_ratio": 1.7623318385650224,
        "end": 1606.04,
        "id": 668,
        "no_speech_prob": 0.00029595562955364585,
        "seek": 158880,
        "start": 1603.04,
        "temperature": 0,
        "text": " I put zero, G of one, right?",
        "tokens": [
          51076,
          286,
          829,
          4018,
          11,
          460,
          295,
          472,
          11,
          558,
          30,
          51226
        ]
      },
      {
        "avg_logprob": -0.18385468423366547,
        "compression_ratio": 1.7623318385650224,
        "end": 1609.24,
        "id": 669,
        "no_speech_prob": 0.00029595562955364585,
        "seek": 158880,
        "start": 1606.04,
        "temperature": 0,
        "text": " And so we wanna know what does G of I,",
        "tokens": [
          51226,
          400,
          370,
          321,
          1948,
          458,
          437,
          775,
          460,
          295,
          286,
          11,
          51386
        ]
      },
      {
        "avg_logprob": -0.18385468423366547,
        "compression_ratio": 1.7623318385650224,
        "end": 1612.1599999999999,
        "id": 670,
        "no_speech_prob": 0.00029595562955364585,
        "seek": 158880,
        "start": 1609.24,
        "temperature": 0,
        "text": " or what does G of zero, or what does G of one equal?",
        "tokens": [
          51386,
          420,
          437,
          775,
          460,
          295,
          4018,
          11,
          420,
          437,
          775,
          460,
          295,
          472,
          2681,
          30,
          51532
        ]
      },
      {
        "avg_logprob": -0.18385468423366547,
        "compression_ratio": 1.7623318385650224,
        "end": 1614.6,
        "id": 671,
        "no_speech_prob": 0.00029595562955364585,
        "seek": 158880,
        "start": 1612.1599999999999,
        "temperature": 0,
        "text": " How can we get that equation?",
        "tokens": [
          51532,
          1012,
          393,
          321,
          483,
          300,
          5367,
          30,
          51654
        ]
      },
      {
        "avg_logprob": -0.18385468423366547,
        "compression_ratio": 1.7623318385650224,
        "end": 1616.84,
        "id": 672,
        "no_speech_prob": 0.00029595562955364585,
        "seek": 158880,
        "start": 1614.6,
        "temperature": 0,
        "text": " Well, if we look at our diagram for our neural network,",
        "tokens": [
          51654,
          1042,
          11,
          498,
          321,
          574,
          412,
          527,
          10686,
          337,
          527,
          18161,
          3209,
          11,
          51766
        ]
      },
      {
        "avg_logprob": -0.18385468423366547,
        "compression_ratio": 1.7623318385650224,
        "end": 1618.04,
        "id": 673,
        "no_speech_prob": 0.00029595562955364585,
        "seek": 158880,
        "start": 1616.84,
        "temperature": 0,
        "text": " it's actually quite simple.",
        "tokens": [
          51766,
          309,
          311,
          767,
          1596,
          2199,
          13,
          51826
        ]
      },
      {
        "avg_logprob": -0.2674228366058652,
        "compression_ratio": 1.5678391959798994,
        "end": 1621.48,
        "id": 674,
        "no_speech_prob": 0.0022517938632518053,
        "seek": 161804,
        "start": 1618.08,
        "temperature": 0,
        "text": " So this is in frame right here.",
        "tokens": [
          50366,
          407,
          341,
          307,
          294,
          3920,
          558,
          510,
          13,
          50536
        ]
      },
      {
        "avg_logprob": -0.2674228366058652,
        "compression_ratio": 1.5678391959798994,
        "end": 1626.48,
        "id": 675,
        "no_speech_prob": 0.0022517938632518053,
        "seek": 161804,
        "start": 1621.48,
        "temperature": 0,
        "text": " So we can do G, oh my goodness, can I write?",
        "tokens": [
          50536,
          407,
          321,
          393,
          360,
          460,
          11,
          1954,
          452,
          8387,
          11,
          393,
          286,
          2464,
          30,
          50786
        ]
      },
      {
        "avg_logprob": -0.2674228366058652,
        "compression_ratio": 1.5678391959798994,
        "end": 1628.84,
        "id": 676,
        "no_speech_prob": 0.0022517938632518053,
        "seek": 161804,
        "start": 1626.48,
        "temperature": 0,
        "text": " You actually have a lot of room to like this way too.",
        "tokens": [
          50786,
          509,
          767,
          362,
          257,
          688,
          295,
          1808,
          281,
          411,
          341,
          636,
          886,
          13,
          50904
        ]
      },
      {
        "avg_logprob": -0.2674228366058652,
        "compression_ratio": 1.5678391959798994,
        "end": 1631.36,
        "id": 677,
        "no_speech_prob": 0.0022517938632518053,
        "seek": 161804,
        "start": 1628.84,
        "temperature": 0,
        "text": " Oh, oh, okay, so let's do it over here.",
        "tokens": [
          50904,
          876,
          11,
          1954,
          11,
          1392,
          11,
          370,
          718,
          311,
          360,
          309,
          670,
          510,
          13,
          51030
        ]
      },
      {
        "avg_logprob": -0.2674228366058652,
        "compression_ratio": 1.5678391959798994,
        "end": 1635.96,
        "id": 678,
        "no_speech_prob": 0.0022517938632518053,
        "seek": 161804,
        "start": 1631.36,
        "temperature": 0,
        "text": " So G of I, which again is this array, this output layer,",
        "tokens": [
          51030,
          407,
          460,
          295,
          286,
          11,
          597,
          797,
          307,
          341,
          10225,
          11,
          341,
          5598,
          4583,
          11,
          51260
        ]
      },
      {
        "avg_logprob": -0.2674228366058652,
        "compression_ratio": 1.5678391959798994,
        "end": 1640.96,
        "id": 679,
        "no_speech_prob": 0.0022517938632518053,
        "seek": 161804,
        "start": 1635.96,
        "temperature": 0,
        "text": " G of I equals the summation of a hidden layer.",
        "tokens": [
          51260,
          460,
          295,
          286,
          6915,
          264,
          28811,
          295,
          257,
          7633,
          4583,
          13,
          51510
        ]
      },
      {
        "avg_logprob": -0.2674228366058652,
        "compression_ratio": 1.5678391959798994,
        "end": 1646.52,
        "id": 680,
        "no_speech_prob": 0.0022517938632518053,
        "seek": 161804,
        "start": 1644.76,
        "temperature": 0,
        "text": " This is gonna be a hidden layer of I,",
        "tokens": [
          51700,
          639,
          307,
          799,
          312,
          257,
          7633,
          4583,
          295,
          286,
          11,
          51788
        ]
      },
      {
        "avg_logprob": -0.24250110314816845,
        "compression_ratio": 1.5406698564593302,
        "end": 1649.08,
        "id": 681,
        "no_speech_prob": 0.00003647819175967015,
        "seek": 164652,
        "start": 1646.52,
        "temperature": 0,
        "text": " and this is gonna be inputs of I.",
        "tokens": [
          50364,
          293,
          341,
          307,
          799,
          312,
          15743,
          295,
          286,
          13,
          50492
        ]
      },
      {
        "avg_logprob": -0.24250110314816845,
        "compression_ratio": 1.5406698564593302,
        "end": 1652.8799999999999,
        "id": 682,
        "no_speech_prob": 0.00003647819175967015,
        "seek": 164652,
        "start": 1650.36,
        "temperature": 0,
        "text": " That's how we define each of these vectors.",
        "tokens": [
          50556,
          663,
          311,
          577,
          321,
          6964,
          1184,
          295,
          613,
          18875,
          13,
          50682
        ]
      },
      {
        "avg_logprob": -0.24250110314816845,
        "compression_ratio": 1.5406698564593302,
        "end": 1657.8799999999999,
        "id": 683,
        "no_speech_prob": 0.00003647819175967015,
        "seek": 164652,
        "start": 1652.8799999999999,
        "temperature": 0,
        "text": " So G of I equals a summation of HL, hidden layer,",
        "tokens": [
          50682,
          407,
          460,
          295,
          286,
          6915,
          257,
          28811,
          295,
          389,
          43,
          11,
          7633,
          4583,
          11,
          50932
        ]
      },
      {
        "avg_logprob": -0.24250110314816845,
        "compression_ratio": 1.5406698564593302,
        "end": 1663.08,
        "id": 684,
        "no_speech_prob": 0.00003647819175967015,
        "seek": 164652,
        "start": 1659.28,
        "temperature": 0,
        "text": " and then we have to go into another loop",
        "tokens": [
          51002,
          293,
          550,
          321,
          362,
          281,
          352,
          666,
          1071,
          6367,
          51192
        ]
      },
      {
        "avg_logprob": -0.24250110314816845,
        "compression_ratio": 1.5406698564593302,
        "end": 1665.72,
        "id": 685,
        "no_speech_prob": 0.00003647819175967015,
        "seek": 164652,
        "start": 1663.08,
        "temperature": 0,
        "text": " because we can't use the same in this C of I and J",
        "tokens": [
          51192,
          570,
          321,
          393,
          380,
          764,
          264,
          912,
          294,
          341,
          383,
          295,
          286,
          293,
          508,
          51324
        ]
      },
      {
        "avg_logprob": -0.24250110314816845,
        "compression_ratio": 1.5406698564593302,
        "end": 1669.48,
        "id": 686,
        "no_speech_prob": 0.00003647819175967015,
        "seek": 164652,
        "start": 1665.72,
        "temperature": 0,
        "text": " because it won't return the right value.",
        "tokens": [
          51324,
          570,
          309,
          1582,
          380,
          2736,
          264,
          558,
          2158,
          13,
          51512
        ]
      },
      {
        "avg_logprob": -0.24250110314816845,
        "compression_ratio": 1.5406698564593302,
        "end": 1674.48,
        "id": 687,
        "no_speech_prob": 0.00003647819175967015,
        "seek": 164652,
        "start": 1669.48,
        "temperature": 0,
        "text": " So a hidden layer of J, which is just gonna be zero, one, two",
        "tokens": [
          51512,
          407,
          257,
          7633,
          4583,
          295,
          508,
          11,
          597,
          307,
          445,
          799,
          312,
          4018,
          11,
          472,
          11,
          732,
          51762
        ]
      },
      {
        "avg_logprob": -0.2085953950881958,
        "compression_ratio": 1.5569620253164558,
        "end": 1679.96,
        "id": 688,
        "no_speech_prob": 0.0000031381393910123734,
        "seek": 167448,
        "start": 1674.96,
        "temperature": 0,
        "text": " times the weight of G of I.",
        "tokens": [
          50388,
          1413,
          264,
          3364,
          295,
          460,
          295,
          286,
          13,
          50638
        ]
      },
      {
        "avg_logprob": -0.2085953950881958,
        "compression_ratio": 1.5569620253164558,
        "end": 1687.44,
        "id": 689,
        "no_speech_prob": 0.0000031381393910123734,
        "seek": 167448,
        "start": 1684.24,
        "temperature": 0,
        "text": " And then we simply just add our bias of G of I.",
        "tokens": [
          50852,
          400,
          550,
          321,
          2935,
          445,
          909,
          527,
          12577,
          295,
          460,
          295,
          286,
          13,
          51012
        ]
      },
      {
        "avg_logprob": -0.2085953950881958,
        "compression_ratio": 1.5569620253164558,
        "end": 1692.3600000000001,
        "id": 690,
        "no_speech_prob": 0.0000031381393910123734,
        "seek": 167448,
        "start": 1689.88,
        "temperature": 0,
        "text": " And so this is the equation that we can use",
        "tokens": [
          51134,
          400,
          370,
          341,
          307,
          264,
          5367,
          300,
          321,
          393,
          764,
          51258
        ]
      },
      {
        "avg_logprob": -0.2085953950881958,
        "compression_ratio": 1.5569620253164558,
        "end": 1696.48,
        "id": 691,
        "no_speech_prob": 0.0000031381393910123734,
        "seek": 167448,
        "start": 1692.3600000000001,
        "temperature": 0,
        "text": " to compute each of our output nodes.",
        "tokens": [
          51258,
          281,
          14722,
          1184,
          295,
          527,
          5598,
          13891,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2085953950881958,
        "compression_ratio": 1.5569620253164558,
        "end": 1698.3600000000001,
        "id": 692,
        "no_speech_prob": 0.0000031381393910123734,
        "seek": 167448,
        "start": 1696.48,
        "temperature": 0,
        "text": " And so just to clarify what's going on here,",
        "tokens": [
          51464,
          400,
          370,
          445,
          281,
          17594,
          437,
          311,
          516,
          322,
          510,
          11,
          51558
        ]
      },
      {
        "avg_logprob": -0.2085953950881958,
        "compression_ratio": 1.5569620253164558,
        "end": 1701,
        "id": 693,
        "no_speech_prob": 0.0000031381393910123734,
        "seek": 167448,
        "start": 1698.3600000000001,
        "temperature": 0,
        "text": " this is summation symbol, which simply means",
        "tokens": [
          51558,
          341,
          307,
          28811,
          5986,
          11,
          597,
          2935,
          1355,
          51690
        ]
      },
      {
        "avg_logprob": -0.21474605602222485,
        "compression_ratio": 1.609375,
        "end": 1705,
        "id": 694,
        "no_speech_prob": 0.000045397675421554595,
        "seek": 170100,
        "start": 1701,
        "temperature": 0,
        "text": " to add up all within the array.",
        "tokens": [
          50364,
          281,
          909,
          493,
          439,
          1951,
          264,
          10225,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.21474605602222485,
        "compression_ratio": 1.609375,
        "end": 1708.32,
        "id": 695,
        "no_speech_prob": 0.000045397675421554595,
        "seek": 170100,
        "start": 1705,
        "temperature": 0,
        "text": " So hidden layer of J times the weight.",
        "tokens": [
          50564,
          407,
          7633,
          4583,
          295,
          508,
          1413,
          264,
          3364,
          13,
          50730
        ]
      },
      {
        "avg_logprob": -0.21474605602222485,
        "compression_ratio": 1.609375,
        "end": 1710.96,
        "id": 696,
        "no_speech_prob": 0.000045397675421554595,
        "seek": 170100,
        "start": 1708.32,
        "temperature": 0,
        "text": " This is a function which simply just grabs the weight",
        "tokens": [
          50730,
          639,
          307,
          257,
          2445,
          597,
          2935,
          445,
          30028,
          264,
          3364,
          50862
        ]
      },
      {
        "avg_logprob": -0.21474605602222485,
        "compression_ratio": 1.609375,
        "end": 1715.6,
        "id": 697,
        "no_speech_prob": 0.000045397675421554595,
        "seek": 170100,
        "start": 1710.96,
        "temperature": 0,
        "text": " of whatever output node you're on.",
        "tokens": [
          50862,
          295,
          2035,
          5598,
          9984,
          291,
          434,
          322,
          13,
          51094
        ]
      },
      {
        "avg_logprob": -0.21474605602222485,
        "compression_ratio": 1.609375,
        "end": 1718.92,
        "id": 698,
        "no_speech_prob": 0.000045397675421554595,
        "seek": 170100,
        "start": 1715.6,
        "temperature": 0,
        "text": " So if you pass G of zero, for example,",
        "tokens": [
          51094,
          407,
          498,
          291,
          1320,
          460,
          295,
          4018,
          11,
          337,
          1365,
          11,
          51260
        ]
      },
      {
        "avg_logprob": -0.21474605602222485,
        "compression_ratio": 1.609375,
        "end": 1720.76,
        "id": 699,
        "no_speech_prob": 0.000045397675421554595,
        "seek": 170100,
        "start": 1718.92,
        "temperature": 0,
        "text": " to do this weight function, it will just grab",
        "tokens": [
          51260,
          281,
          360,
          341,
          3364,
          2445,
          11,
          309,
          486,
          445,
          4444,
          51352
        ]
      },
      {
        "avg_logprob": -0.21474605602222485,
        "compression_ratio": 1.609375,
        "end": 1722.64,
        "id": 700,
        "no_speech_prob": 0.000045397675421554595,
        "seek": 170100,
        "start": 1720.76,
        "temperature": 0,
        "text": " whatever bias, or I'm sorry,",
        "tokens": [
          51352,
          2035,
          12577,
          11,
          420,
          286,
          478,
          2597,
          11,
          51446
        ]
      },
      {
        "avg_logprob": -0.21474605602222485,
        "compression_ratio": 1.609375,
        "end": 1725.28,
        "id": 701,
        "no_speech_prob": 0.000045397675421554595,
        "seek": 170100,
        "start": 1722.64,
        "temperature": 0,
        "text": " whatever weight of G of I is there.",
        "tokens": [
          51446,
          2035,
          3364,
          295,
          460,
          295,
          286,
          307,
          456,
          13,
          51578
        ]
      },
      {
        "avg_logprob": -0.2330781338261623,
        "compression_ratio": 1.7005347593582887,
        "end": 1731.28,
        "id": 702,
        "no_speech_prob": 0.00003647839912446216,
        "seek": 172528,
        "start": 1726.28,
        "temperature": 0,
        "text": " So that's actually G of I of J, actually.",
        "tokens": [
          50414,
          407,
          300,
          311,
          767,
          460,
          295,
          286,
          295,
          508,
          11,
          767,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2330781338261623,
        "compression_ratio": 1.7005347593582887,
        "end": 1733.92,
        "id": 703,
        "no_speech_prob": 0.00003647839912446216,
        "seek": 172528,
        "start": 1732.04,
        "temperature": 0,
        "text": " Oops, G of I of J.",
        "tokens": [
          50702,
          21726,
          11,
          460,
          295,
          286,
          295,
          508,
          13,
          50796
        ]
      },
      {
        "avg_logprob": -0.2330781338261623,
        "compression_ratio": 1.7005347593582887,
        "end": 1738,
        "id": 704,
        "no_speech_prob": 0.00003647839912446216,
        "seek": 172528,
        "start": 1735.8799999999999,
        "temperature": 0,
        "text": " So now we have this equation that tells us",
        "tokens": [
          50894,
          407,
          586,
          321,
          362,
          341,
          5367,
          300,
          5112,
          505,
          51000
        ]
      },
      {
        "avg_logprob": -0.2330781338261623,
        "compression_ratio": 1.7005347593582887,
        "end": 1740.28,
        "id": 705,
        "no_speech_prob": 0.00003647839912446216,
        "seek": 172528,
        "start": 1738,
        "temperature": 0,
        "text": " exactly what these values equal.",
        "tokens": [
          51000,
          2293,
          437,
          613,
          4190,
          2681,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2330781338261623,
        "compression_ratio": 1.7005347593582887,
        "end": 1744,
        "id": 706,
        "no_speech_prob": 0.00003647839912446216,
        "seek": 172528,
        "start": 1740.28,
        "temperature": 0,
        "text": " So now we don't know what HL of J equals.",
        "tokens": [
          51114,
          407,
          586,
          321,
          500,
          380,
          458,
          437,
          389,
          43,
          295,
          508,
          6915,
          13,
          51300
        ]
      },
      {
        "avg_logprob": -0.2330781338261623,
        "compression_ratio": 1.7005347593582887,
        "end": 1746.52,
        "id": 707,
        "no_speech_prob": 0.00003647839912446216,
        "seek": 172528,
        "start": 1744,
        "temperature": 0,
        "text": " So we also have to define HL of J.",
        "tokens": [
          51300,
          407,
          321,
          611,
          362,
          281,
          6964,
          389,
          43,
          295,
          508,
          13,
          51426
        ]
      },
      {
        "avg_logprob": -0.2330781338261623,
        "compression_ratio": 1.7005347593582887,
        "end": 1751,
        "id": 708,
        "no_speech_prob": 0.00003647839912446216,
        "seek": 172528,
        "start": 1746.52,
        "temperature": 0,
        "text": " And we go about doing that by doing the same exact process.",
        "tokens": [
          51426,
          400,
          321,
          352,
          466,
          884,
          300,
          538,
          884,
          264,
          912,
          1900,
          1399,
          13,
          51650
        ]
      },
      {
        "avg_logprob": -0.2330781338261623,
        "compression_ratio": 1.7005347593582887,
        "end": 1754.52,
        "id": 709,
        "no_speech_prob": 0.00003647839912446216,
        "seek": 172528,
        "start": 1751,
        "temperature": 0,
        "text": " Actually, this would be HL of I for indices.",
        "tokens": [
          51650,
          5135,
          11,
          341,
          576,
          312,
          389,
          43,
          295,
          286,
          337,
          43840,
          13,
          51826
        ]
      },
      {
        "avg_logprob": -0.2854457303702113,
        "compression_ratio": 1.50625,
        "end": 1759.56,
        "id": 710,
        "no_speech_prob": 0.0000224739433178911,
        "seek": 175452,
        "start": 1754.56,
        "temperature": 0,
        "text": " Same exact process, summation of our inputs, right?",
        "tokens": [
          50366,
          10635,
          1900,
          1399,
          11,
          28811,
          295,
          527,
          15743,
          11,
          558,
          30,
          50616
        ]
      },
      {
        "avg_logprob": -0.2854457303702113,
        "compression_ratio": 1.50625,
        "end": 1762.6,
        "id": 711,
        "no_speech_prob": 0.0000224739433178911,
        "seek": 175452,
        "start": 1760.28,
        "temperature": 0,
        "text": " Inputs, what do I use, I and P.",
        "tokens": [
          50652,
          682,
          2582,
          82,
          11,
          437,
          360,
          286,
          764,
          11,
          286,
          293,
          430,
          13,
          50768
        ]
      },
      {
        "avg_logprob": -0.2854457303702113,
        "compression_ratio": 1.50625,
        "end": 1768.84,
        "id": 712,
        "no_speech_prob": 0.0000224739433178911,
        "seek": 175452,
        "start": 1763.84,
        "temperature": 0,
        "text": " Inputs, J times weight of HL of I.",
        "tokens": [
          50830,
          682,
          2582,
          82,
          11,
          508,
          1413,
          3364,
          295,
          389,
          43,
          295,
          286,
          13,
          51080
        ]
      },
      {
        "avg_logprob": -0.2854457303702113,
        "compression_ratio": 1.50625,
        "end": 1775.08,
        "id": 713,
        "no_speech_prob": 0.0000224739433178911,
        "seek": 175452,
        "start": 1771.84,
        "temperature": 0,
        "text": " So the same exact input, we need HL of I.",
        "tokens": [
          51230,
          407,
          264,
          912,
          1900,
          4846,
          11,
          321,
          643,
          389,
          43,
          295,
          286,
          13,
          51392
        ]
      },
      {
        "avg_logprob": -0.2854457303702113,
        "compression_ratio": 1.50625,
        "end": 1780.16,
        "id": 714,
        "no_speech_prob": 0.0000224739433178911,
        "seek": 175452,
        "start": 1778.28,
        "temperature": 0,
        "text": " And then we simply just pass our bias.",
        "tokens": [
          51552,
          400,
          550,
          321,
          2935,
          445,
          1320,
          527,
          12577,
          13,
          51646
        ]
      },
      {
        "avg_logprob": -0.2854457303702113,
        "compression_ratio": 1.50625,
        "end": 1782.92,
        "id": 715,
        "no_speech_prob": 0.0000224739433178911,
        "seek": 175452,
        "start": 1780.16,
        "temperature": 0,
        "text": " And again, this right here is a function.",
        "tokens": [
          51646,
          400,
          797,
          11,
          341,
          558,
          510,
          307,
          257,
          2445,
          13,
          51784
        ]
      },
      {
        "avg_logprob": -0.19762487764711734,
        "compression_ratio": 1.5244444444444445,
        "end": 1785.24,
        "id": 716,
        "no_speech_prob": 0.00002796917215164285,
        "seek": 178292,
        "start": 1782.92,
        "temperature": 0,
        "text": " All it does is it grabs the bias",
        "tokens": [
          50364,
          1057,
          309,
          775,
          307,
          309,
          30028,
          264,
          12577,
          50480
        ]
      },
      {
        "avg_logprob": -0.19762487764711734,
        "compression_ratio": 1.5244444444444445,
        "end": 1788.16,
        "id": 717,
        "no_speech_prob": 0.00002796917215164285,
        "seek": 178292,
        "start": 1785.24,
        "temperature": 0,
        "text": " for whatever node that we pass through it.",
        "tokens": [
          50480,
          337,
          2035,
          9984,
          300,
          321,
          1320,
          807,
          309,
          13,
          50626
        ]
      },
      {
        "avg_logprob": -0.19762487764711734,
        "compression_ratio": 1.5244444444444445,
        "end": 1790.1200000000001,
        "id": 718,
        "no_speech_prob": 0.00002796917215164285,
        "seek": 178292,
        "start": 1788.16,
        "temperature": 0,
        "text": " So bias of HL of I.",
        "tokens": [
          50626,
          407,
          12577,
          295,
          389,
          43,
          295,
          286,
          13,
          50724
        ]
      },
      {
        "avg_logprob": -0.19762487764711734,
        "compression_ratio": 1.5244444444444445,
        "end": 1793.04,
        "id": 719,
        "no_speech_prob": 0.00002796917215164285,
        "seek": 178292,
        "start": 1792.2,
        "temperature": 0,
        "text": " And there we have it.",
        "tokens": [
          50828,
          400,
          456,
          321,
          362,
          309,
          13,
          50870
        ]
      },
      {
        "avg_logprob": -0.19762487764711734,
        "compression_ratio": 1.5244444444444445,
        "end": 1794.24,
        "id": 720,
        "no_speech_prob": 0.00002796917215164285,
        "seek": 178292,
        "start": 1793.04,
        "temperature": 0,
        "text": " We have our entire equation,",
        "tokens": [
          50870,
          492,
          362,
          527,
          2302,
          5367,
          11,
          50930
        ]
      },
      {
        "avg_logprob": -0.19762487764711734,
        "compression_ratio": 1.5244444444444445,
        "end": 1797.44,
        "id": 721,
        "no_speech_prob": 0.00002796917215164285,
        "seek": 178292,
        "start": 1794.24,
        "temperature": 0,
        "text": " because we know exactly what input of J equals.",
        "tokens": [
          50930,
          570,
          321,
          458,
          2293,
          437,
          4846,
          295,
          508,
          6915,
          13,
          51090
        ]
      },
      {
        "avg_logprob": -0.19762487764711734,
        "compression_ratio": 1.5244444444444445,
        "end": 1800.5600000000002,
        "id": 722,
        "no_speech_prob": 0.00002796917215164285,
        "seek": 178292,
        "start": 1797.44,
        "temperature": 0,
        "text": " It's gonna be simply the random value of our color.",
        "tokens": [
          51090,
          467,
          311,
          799,
          312,
          2935,
          264,
          4974,
          2158,
          295,
          527,
          2017,
          13,
          51246
        ]
      },
      {
        "avg_logprob": -0.19762487764711734,
        "compression_ratio": 1.5244444444444445,
        "end": 1807.2,
        "id": 723,
        "no_speech_prob": 0.00002796917215164285,
        "seek": 178292,
        "start": 1802.2,
        "temperature": 0,
        "text": " And so this is what we need to write in our software.",
        "tokens": [
          51328,
          400,
          370,
          341,
          307,
          437,
          321,
          643,
          281,
          2464,
          294,
          527,
          4722,
          13,
          51578
        ]
      },
      {
        "avg_logprob": -0.19762487764711734,
        "compression_ratio": 1.5244444444444445,
        "end": 1810.6000000000001,
        "id": 724,
        "no_speech_prob": 0.00002796917215164285,
        "seek": 178292,
        "start": 1809.3600000000001,
        "temperature": 0,
        "text": " How are we on time, Dan?",
        "tokens": [
          51686,
          1012,
          366,
          321,
          322,
          565,
          11,
          3394,
          30,
          51748
        ]
      },
      {
        "avg_logprob": -0.19762487764711734,
        "compression_ratio": 1.5244444444444445,
        "end": 1812.4,
        "id": 725,
        "no_speech_prob": 0.00002796917215164285,
        "seek": 178292,
        "start": 1810.6000000000001,
        "temperature": 0,
        "text": " We're good. Cool.",
        "tokens": [
          51748,
          492,
          434,
          665,
          13,
          8561,
          13,
          51838
        ]
      },
      {
        "avg_logprob": -0.2205352298283981,
        "compression_ratio": 1.7623318385650224,
        "end": 1815.0400000000002,
        "id": 726,
        "no_speech_prob": 0.004538315813988447,
        "seek": 181240,
        "start": 1812.92,
        "temperature": 0,
        "text": " I keep forgetting up is down.",
        "tokens": [
          50390,
          286,
          1066,
          25428,
          493,
          307,
          760,
          13,
          50496
        ]
      },
      {
        "avg_logprob": -0.2205352298283981,
        "compression_ratio": 1.7623318385650224,
        "end": 1819.0400000000002,
        "id": 727,
        "no_speech_prob": 0.004538315813988447,
        "seek": 181240,
        "start": 1815.0400000000002,
        "temperature": 0,
        "text": " Okay, so same exact thing that you see on the board",
        "tokens": [
          50496,
          1033,
          11,
          370,
          912,
          1900,
          551,
          300,
          291,
          536,
          322,
          264,
          3150,
          50696
        ]
      },
      {
        "avg_logprob": -0.2205352298283981,
        "compression_ratio": 1.7623318385650224,
        "end": 1821.52,
        "id": 728,
        "no_speech_prob": 0.004538315813988447,
        "seek": 181240,
        "start": 1819.0400000000002,
        "temperature": 0,
        "text": " is what we write here in our code.",
        "tokens": [
          50696,
          307,
          437,
          321,
          2464,
          510,
          294,
          527,
          3089,
          13,
          50820
        ]
      },
      {
        "avg_logprob": -0.2205352298283981,
        "compression_ratio": 1.7623318385650224,
        "end": 1825.72,
        "id": 729,
        "no_speech_prob": 0.004538315813988447,
        "seek": 181240,
        "start": 1821.52,
        "temperature": 0,
        "text": " So first, before we can get what the guess nodes equal,",
        "tokens": [
          50820,
          407,
          700,
          11,
          949,
          321,
          393,
          483,
          437,
          264,
          2041,
          13891,
          2681,
          11,
          51030
        ]
      },
      {
        "avg_logprob": -0.2205352298283981,
        "compression_ratio": 1.7623318385650224,
        "end": 1828.4,
        "id": 730,
        "no_speech_prob": 0.004538315813988447,
        "seek": 181240,
        "start": 1825.72,
        "temperature": 0,
        "text": " we have to first get what the hidden layer nodes equal.",
        "tokens": [
          51030,
          321,
          362,
          281,
          700,
          483,
          437,
          264,
          7633,
          4583,
          13891,
          2681,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2205352298283981,
        "compression_ratio": 1.7623318385650224,
        "end": 1832.8400000000001,
        "id": 731,
        "no_speech_prob": 0.004538315813988447,
        "seek": 181240,
        "start": 1828.4,
        "temperature": 0,
        "text": " So simply put, as we did on the whiteboard,",
        "tokens": [
          51164,
          407,
          2935,
          829,
          11,
          382,
          321,
          630,
          322,
          264,
          2418,
          3787,
          11,
          51386
        ]
      },
      {
        "avg_logprob": -0.2205352298283981,
        "compression_ratio": 1.7623318385650224,
        "end": 1834.6000000000001,
        "id": 732,
        "no_speech_prob": 0.004538315813988447,
        "seek": 181240,
        "start": 1832.8400000000001,
        "temperature": 0,
        "text": " hidden layer zero equals,",
        "tokens": [
          51386,
          7633,
          4583,
          4018,
          6915,
          11,
          51474
        ]
      },
      {
        "avg_logprob": -0.2205352298283981,
        "compression_ratio": 1.7623318385650224,
        "end": 1836.72,
        "id": 733,
        "no_speech_prob": 0.004538315813988447,
        "seek": 181240,
        "start": 1834.6000000000001,
        "temperature": 0,
        "text": " we'll get to what ReLU is in a second,",
        "tokens": [
          51474,
          321,
          603,
          483,
          281,
          437,
          1300,
          43,
          52,
          307,
          294,
          257,
          1150,
          11,
          51580
        ]
      },
      {
        "avg_logprob": -0.2205352298283981,
        "compression_ratio": 1.7623318385650224,
        "end": 1839.3200000000002,
        "id": 734,
        "no_speech_prob": 0.004538315813988447,
        "seek": 181240,
        "start": 1836.72,
        "temperature": 0,
        "text": " but hidden layer zero equals,",
        "tokens": [
          51580,
          457,
          7633,
          4583,
          4018,
          6915,
          11,
          51710
        ]
      },
      {
        "avg_logprob": -0.2205352298283981,
        "compression_ratio": 1.7623318385650224,
        "end": 1841.2,
        "id": 735,
        "no_speech_prob": 0.004538315813988447,
        "seek": 181240,
        "start": 1839.3200000000002,
        "temperature": 0,
        "text": " we did our input encoder,",
        "tokens": [
          51710,
          321,
          630,
          527,
          4846,
          2058,
          19866,
          11,
          51804
        ]
      },
      {
        "avg_logprob": -0.182261413998074,
        "compression_ratio": 1.5113636363636365,
        "end": 1843.3600000000001,
        "id": 736,
        "no_speech_prob": 0.003027792554348707,
        "seek": 184120,
        "start": 1841.2,
        "temperature": 0,
        "text": " which was a question that was asked earlier",
        "tokens": [
          50364,
          597,
          390,
          257,
          1168,
          300,
          390,
          2351,
          3071,
          50472
        ]
      },
      {
        "avg_logprob": -0.182261413998074,
        "compression_ratio": 1.5113636363636365,
        "end": 1846.8,
        "id": 737,
        "no_speech_prob": 0.003027792554348707,
        "seek": 184120,
        "start": 1843.3600000000001,
        "temperature": 0,
        "text": " about normalizing our input data.",
        "tokens": [
          50472,
          466,
          2710,
          3319,
          527,
          4846,
          1412,
          13,
          50644
        ]
      },
      {
        "avg_logprob": -0.182261413998074,
        "compression_ratio": 1.5113636363636365,
        "end": 1849.56,
        "id": 738,
        "no_speech_prob": 0.003027792554348707,
        "seek": 184120,
        "start": 1846.8,
        "temperature": 0,
        "text": " So this function simply just divides our input,",
        "tokens": [
          50644,
          407,
          341,
          2445,
          2935,
          445,
          41347,
          527,
          4846,
          11,
          50782
        ]
      },
      {
        "avg_logprob": -0.182261413998074,
        "compression_ratio": 1.5113636363636365,
        "end": 1852.52,
        "id": 739,
        "no_speech_prob": 0.003027792554348707,
        "seek": 184120,
        "start": 1849.56,
        "temperature": 0,
        "text": " divided by 255, and then we'll times that",
        "tokens": [
          50782,
          6666,
          538,
          3552,
          20,
          11,
          293,
          550,
          321,
          603,
          1413,
          300,
          50930
        ]
      },
      {
        "avg_logprob": -0.182261413998074,
        "compression_ratio": 1.5113636363636365,
        "end": 1857.52,
        "id": 740,
        "no_speech_prob": 0.003027792554348707,
        "seek": 184120,
        "start": 1852.52,
        "temperature": 0,
        "text": " by the weight of our hidden layer.",
        "tokens": [
          50930,
          538,
          264,
          3364,
          295,
          527,
          7633,
          4583,
          13,
          51180
        ]
      },
      {
        "avg_logprob": -0.182261413998074,
        "compression_ratio": 1.5113636363636365,
        "end": 1863.3600000000001,
        "id": 741,
        "no_speech_prob": 0.003027792554348707,
        "seek": 184120,
        "start": 1860.4,
        "temperature": 0,
        "text": " So this is an array function",
        "tokens": [
          51324,
          407,
          341,
          307,
          364,
          10225,
          2445,
          51472
        ]
      },
      {
        "avg_logprob": -0.182261413998074,
        "compression_ratio": 1.5113636363636365,
        "end": 1866.96,
        "id": 742,
        "no_speech_prob": 0.003027792554348707,
        "seek": 184120,
        "start": 1863.3600000000001,
        "temperature": 0,
        "text": " that I will go over really quickly",
        "tokens": [
          51472,
          300,
          286,
          486,
          352,
          670,
          534,
          2661,
          51652
        ]
      },
      {
        "avg_logprob": -0.29743699232737225,
        "compression_ratio": 1.4791666666666667,
        "end": 1872,
        "id": 743,
        "no_speech_prob": 0.0021826664451509714,
        "seek": 186696,
        "start": 1867,
        "temperature": 0,
        "text": " that we instantiate to hold all of our weights.",
        "tokens": [
          50366,
          300,
          321,
          9836,
          13024,
          281,
          1797,
          439,
          295,
          527,
          17443,
          13,
          50616
        ]
      },
      {
        "avg_logprob": -0.29743699232737225,
        "compression_ratio": 1.4791666666666667,
        "end": 1880.1200000000001,
        "id": 744,
        "no_speech_prob": 0.0021826664451509714,
        "seek": 186696,
        "start": 1876.28,
        "temperature": 0,
        "text": " So color predictor zero, zero, zero.",
        "tokens": [
          50830,
          407,
          2017,
          6069,
          284,
          4018,
          11,
          4018,
          11,
          4018,
          13,
          51022
        ]
      },
      {
        "avg_logprob": -0.29743699232737225,
        "compression_ratio": 1.4791666666666667,
        "end": 1881.4,
        "id": 745,
        "no_speech_prob": 0.0021826664451509714,
        "seek": 186696,
        "start": 1880.1200000000001,
        "temperature": 0,
        "text": " I'll go over this.",
        "tokens": [
          51022,
          286,
          603,
          352,
          670,
          341,
          13,
          51086
        ]
      },
      {
        "avg_logprob": -0.29743699232737225,
        "compression_ratio": 1.4791666666666667,
        "end": 1882.56,
        "id": 746,
        "no_speech_prob": 0.0021826664451509714,
        "seek": 186696,
        "start": 1881.4,
        "temperature": 0,
        "text": " I think it's important.",
        "tokens": [
          51086,
          286,
          519,
          309,
          311,
          1021,
          13,
          51144
        ]
      },
      {
        "avg_logprob": -0.29743699232737225,
        "compression_ratio": 1.4791666666666667,
        "end": 1888.8,
        "id": 747,
        "no_speech_prob": 0.0021826664451509714,
        "seek": 186696,
        "start": 1883.8,
        "temperature": 0,
        "text": " So the function color, can you see this?",
        "tokens": [
          51206,
          407,
          264,
          2445,
          2017,
          11,
          393,
          291,
          536,
          341,
          30,
          51456
        ]
      },
      {
        "avg_logprob": -0.29743699232737225,
        "compression_ratio": 1.4791666666666667,
        "end": 1890.3600000000001,
        "id": 748,
        "no_speech_prob": 0.0021826664451509714,
        "seek": 186696,
        "start": 1889.52,
        "temperature": 0,
        "text": " I think so.",
        "tokens": [
          51492,
          286,
          519,
          370,
          13,
          51534
        ]
      },
      {
        "avg_logprob": -0.29743699232737225,
        "compression_ratio": 1.4791666666666667,
        "end": 1891.2,
        "id": 749,
        "no_speech_prob": 0.0021826664451509714,
        "seek": 186696,
        "start": 1890.3600000000001,
        "temperature": 0,
        "text": " Color.",
        "tokens": [
          51534,
          10458,
          13,
          51576
        ]
      },
      {
        "avg_logprob": -0.29743699232737225,
        "compression_ratio": 1.4791666666666667,
        "end": 1892.24,
        "id": 750,
        "no_speech_prob": 0.0021826664451509714,
        "seek": 186696,
        "start": 1891.2,
        "temperature": 0,
        "text": " You're close to the top of the range.",
        "tokens": [
          51576,
          509,
          434,
          1998,
          281,
          264,
          1192,
          295,
          264,
          3613,
          13,
          51628
        ]
      },
      {
        "avg_logprob": -0.29743699232737225,
        "compression_ratio": 1.4791666666666667,
        "end": 1893.08,
        "id": 751,
        "no_speech_prob": 0.0021826664451509714,
        "seek": 186696,
        "start": 1892.24,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51628,
          1033,
          13,
          51670
        ]
      },
      {
        "avg_logprob": -0.29743699232737225,
        "compression_ratio": 1.4791666666666667,
        "end": 1895.1200000000001,
        "id": 752,
        "no_speech_prob": 0.0021826664451509714,
        "seek": 186696,
        "start": 1893.08,
        "temperature": 0,
        "text": " And there's a lot of data that you have to remember.",
        "tokens": [
          51670,
          400,
          456,
          311,
          257,
          688,
          295,
          1412,
          300,
          291,
          362,
          281,
          1604,
          13,
          51772
        ]
      },
      {
        "avg_logprob": -0.24549021304232402,
        "compression_ratio": 1.6868686868686869,
        "end": 1896.08,
        "id": 753,
        "no_speech_prob": 0.005819580052047968,
        "seek": 189512,
        "start": 1895.12,
        "temperature": 0,
        "text": " This is interesting.",
        "tokens": [
          50364,
          639,
          307,
          1880,
          13,
          50412
        ]
      },
      {
        "avg_logprob": -0.24549021304232402,
        "compression_ratio": 1.6868686868686869,
        "end": 1899.9199999999998,
        "id": 754,
        "no_speech_prob": 0.005819580052047968,
        "seek": 189512,
        "start": 1896.08,
        "temperature": 0,
        "text": " Color predictor variable.",
        "tokens": [
          50412,
          10458,
          6069,
          284,
          7006,
          13,
          50604
        ]
      },
      {
        "avg_logprob": -0.24549021304232402,
        "compression_ratio": 1.6868686868686869,
        "end": 1906.6,
        "id": 755,
        "no_speech_prob": 0.005819580052047968,
        "seek": 189512,
        "start": 1902.1599999999999,
        "temperature": 0,
        "text": " So there's all these different dimensions to it.",
        "tokens": [
          50716,
          407,
          456,
          311,
          439,
          613,
          819,
          12819,
          281,
          309,
          13,
          50938
        ]
      },
      {
        "avg_logprob": -0.24549021304232402,
        "compression_ratio": 1.6868686868686869,
        "end": 1908.36,
        "id": 756,
        "no_speech_prob": 0.005819580052047968,
        "seek": 189512,
        "start": 1906.6,
        "temperature": 0,
        "text": " And I think it's interesting,",
        "tokens": [
          50938,
          400,
          286,
          519,
          309,
          311,
          1880,
          11,
          51026
        ]
      },
      {
        "avg_logprob": -0.24549021304232402,
        "compression_ratio": 1.6868686868686869,
        "end": 1911.4799999999998,
        "id": 757,
        "no_speech_prob": 0.005819580052047968,
        "seek": 189512,
        "start": 1908.36,
        "temperature": 0,
        "text": " or it's important to go over what the dimensions mean.",
        "tokens": [
          51026,
          420,
          309,
          311,
          1021,
          281,
          352,
          670,
          437,
          264,
          12819,
          914,
          13,
          51182
        ]
      },
      {
        "avg_logprob": -0.24549021304232402,
        "compression_ratio": 1.6868686868686869,
        "end": 1914.1599999999999,
        "id": 758,
        "no_speech_prob": 0.005819580052047968,
        "seek": 189512,
        "start": 1911.4799999999998,
        "temperature": 0,
        "text": " So let's just get two, and then let's just do,",
        "tokens": [
          51182,
          407,
          718,
          311,
          445,
          483,
          732,
          11,
          293,
          550,
          718,
          311,
          445,
          360,
          11,
          51316
        ]
      },
      {
        "avg_logprob": -0.24549021304232402,
        "compression_ratio": 1.6868686868686869,
        "end": 1915.56,
        "id": 759,
        "no_speech_prob": 0.005819580052047968,
        "seek": 189512,
        "start": 1914.1599999999999,
        "temperature": 0,
        "text": " I don't know, one.",
        "tokens": [
          51316,
          286,
          500,
          380,
          458,
          11,
          472,
          13,
          51386
        ]
      },
      {
        "avg_logprob": -0.24549021304232402,
        "compression_ratio": 1.6868686868686869,
        "end": 1917,
        "id": 760,
        "no_speech_prob": 0.005819580052047968,
        "seek": 189512,
        "start": 1915.56,
        "temperature": 0,
        "text": " So what does this mean?",
        "tokens": [
          51386,
          407,
          437,
          775,
          341,
          914,
          30,
          51458
        ]
      },
      {
        "avg_logprob": -0.24549021304232402,
        "compression_ratio": 1.6868686868686869,
        "end": 1920.84,
        "id": 761,
        "no_speech_prob": 0.005819580052047968,
        "seek": 189512,
        "start": 1917,
        "temperature": 0,
        "text": " If you have color predictor I zero to one,",
        "tokens": [
          51458,
          759,
          291,
          362,
          2017,
          6069,
          284,
          286,
          4018,
          281,
          472,
          11,
          51650
        ]
      },
      {
        "avg_logprob": -0.24549021304232402,
        "compression_ratio": 1.6868686868686869,
        "end": 1922.4399999999998,
        "id": 762,
        "no_speech_prob": 0.005819580052047968,
        "seek": 189512,
        "start": 1920.84,
        "temperature": 0,
        "text": " what does that mean?",
        "tokens": [
          51650,
          437,
          775,
          300,
          914,
          30,
          51730
        ]
      },
      {
        "avg_logprob": -0.2659565477955098,
        "compression_ratio": 1.6581632653061225,
        "end": 1927.44,
        "id": 763,
        "no_speech_prob": 0.00019110244465991855,
        "seek": 192244,
        "start": 1922.44,
        "temperature": 0,
        "text": " Well, so we want to store these arrays",
        "tokens": [
          50364,
          1042,
          11,
          370,
          321,
          528,
          281,
          3531,
          613,
          41011,
          50614
        ]
      },
      {
        "avg_logprob": -0.2659565477955098,
        "compression_ratio": 1.6581632653061225,
        "end": 1931,
        "id": 764,
        "no_speech_prob": 0.00019110244465991855,
        "seek": 192244,
        "start": 1928.52,
        "temperature": 0,
        "text": " into our color predictor variable.",
        "tokens": [
          50668,
          666,
          527,
          2017,
          6069,
          284,
          7006,
          13,
          50792
        ]
      },
      {
        "avg_logprob": -0.2659565477955098,
        "compression_ratio": 1.6581632653061225,
        "end": 1932.04,
        "id": 765,
        "no_speech_prob": 0.00019110244465991855,
        "seek": 192244,
        "start": 1931,
        "temperature": 0,
        "text": " And we go about doing that",
        "tokens": [
          50792,
          400,
          321,
          352,
          466,
          884,
          300,
          50844
        ]
      },
      {
        "avg_logprob": -0.2659565477955098,
        "compression_ratio": 1.6581632653061225,
        "end": 1935.8,
        "id": 766,
        "no_speech_prob": 0.00019110244465991855,
        "seek": 192244,
        "start": 1932.04,
        "temperature": 0,
        "text": " by defining the location of all of these.",
        "tokens": [
          50844,
          538,
          17827,
          264,
          4914,
          295,
          439,
          295,
          613,
          13,
          51032
        ]
      },
      {
        "avg_logprob": -0.2659565477955098,
        "compression_ratio": 1.6581632653061225,
        "end": 1938.8400000000001,
        "id": 767,
        "no_speech_prob": 0.00019110244465991855,
        "seek": 192244,
        "start": 1935.8,
        "temperature": 0,
        "text": " So the hidden layer is going to be zero,",
        "tokens": [
          51032,
          407,
          264,
          7633,
          4583,
          307,
          516,
          281,
          312,
          4018,
          11,
          51184
        ]
      },
      {
        "avg_logprob": -0.2659565477955098,
        "compression_ratio": 1.6581632653061225,
        "end": 1941.52,
        "id": 768,
        "no_speech_prob": 0.00019110244465991855,
        "seek": 192244,
        "start": 1938.8400000000001,
        "temperature": 0,
        "text": " and then the guess is going to be one.",
        "tokens": [
          51184,
          293,
          550,
          264,
          2041,
          307,
          516,
          281,
          312,
          472,
          13,
          51318
        ]
      },
      {
        "avg_logprob": -0.2659565477955098,
        "compression_ratio": 1.6581632653061225,
        "end": 1944.64,
        "id": 769,
        "no_speech_prob": 0.00019110244465991855,
        "seek": 192244,
        "start": 1942.48,
        "temperature": 0,
        "text": " And so all the nodes",
        "tokens": [
          51366,
          400,
          370,
          439,
          264,
          13891,
          51474
        ]
      },
      {
        "avg_logprob": -0.2659565477955098,
        "compression_ratio": 1.6581632653061225,
        "end": 1946.3600000000001,
        "id": 770,
        "no_speech_prob": 0.00019110244465991855,
        "seek": 192244,
        "start": 1944.64,
        "temperature": 0,
        "text": " are then gonna have their own assignments.",
        "tokens": [
          51474,
          366,
          550,
          799,
          362,
          641,
          1065,
          22546,
          13,
          51560
        ]
      },
      {
        "avg_logprob": -0.2659565477955098,
        "compression_ratio": 1.6581632653061225,
        "end": 1950.3600000000001,
        "id": 771,
        "no_speech_prob": 0.00019110244465991855,
        "seek": 192244,
        "start": 1946.3600000000001,
        "temperature": 0,
        "text": " So zero, one, and then two.",
        "tokens": [
          51560,
          407,
          4018,
          11,
          472,
          11,
          293,
          550,
          732,
          13,
          51760
        ]
      },
      {
        "avg_logprob": -0.2659565477955098,
        "compression_ratio": 1.6581632653061225,
        "end": 1951.8400000000001,
        "id": 772,
        "no_speech_prob": 0.00019110244465991855,
        "seek": 192244,
        "start": 1950.3600000000001,
        "temperature": 0,
        "text": " Same here.",
        "tokens": [
          51760,
          10635,
          510,
          13,
          51834
        ]
      },
      {
        "avg_logprob": -0.23378383136186442,
        "compression_ratio": 1.7521739130434784,
        "end": 1955,
        "id": 773,
        "no_speech_prob": 0.0004305539187043905,
        "seek": 195184,
        "start": 1951.84,
        "temperature": 0,
        "text": " This is gonna be zero and one.",
        "tokens": [
          50364,
          639,
          307,
          799,
          312,
          4018,
          293,
          472,
          13,
          50522
        ]
      },
      {
        "avg_logprob": -0.23378383136186442,
        "compression_ratio": 1.7521739130434784,
        "end": 1956.9599999999998,
        "id": 774,
        "no_speech_prob": 0.0004305539187043905,
        "seek": 195184,
        "start": 1955.8799999999999,
        "temperature": 0,
        "text": " And then the weights",
        "tokens": [
          50566,
          400,
          550,
          264,
          17443,
          50620
        ]
      },
      {
        "avg_logprob": -0.23378383136186442,
        "compression_ratio": 1.7521739130434784,
        "end": 1958.8,
        "id": 775,
        "no_speech_prob": 0.0004305539187043905,
        "seek": 195184,
        "start": 1956.9599999999998,
        "temperature": 0,
        "text": " are also gonna have their own assignment as well.",
        "tokens": [
          50620,
          366,
          611,
          799,
          362,
          641,
          1065,
          15187,
          382,
          731,
          13,
          50712
        ]
      },
      {
        "avg_logprob": -0.23378383136186442,
        "compression_ratio": 1.7521739130434784,
        "end": 1962.48,
        "id": 776,
        "no_speech_prob": 0.0004305539187043905,
        "seek": 195184,
        "start": 1958.8,
        "temperature": 0,
        "text": " So zero, one, two, three, and the same deal.",
        "tokens": [
          50712,
          407,
          4018,
          11,
          472,
          11,
          732,
          11,
          1045,
          11,
          293,
          264,
          912,
          2028,
          13,
          50896
        ]
      },
      {
        "avg_logprob": -0.23378383136186442,
        "compression_ratio": 1.7521739130434784,
        "end": 1964.6799999999998,
        "id": 777,
        "no_speech_prob": 0.0004305539187043905,
        "seek": 195184,
        "start": 1962.48,
        "temperature": 0,
        "text": " Zero, one, two, three.",
        "tokens": [
          50896,
          17182,
          11,
          472,
          11,
          732,
          11,
          1045,
          13,
          51006
        ]
      },
      {
        "avg_logprob": -0.23378383136186442,
        "compression_ratio": 1.7521739130434784,
        "end": 1967.4399999999998,
        "id": 778,
        "no_speech_prob": 0.0004305539187043905,
        "seek": 195184,
        "start": 1964.6799999999998,
        "temperature": 0,
        "text": " And we repeat that for every single weight",
        "tokens": [
          51006,
          400,
          321,
          7149,
          300,
          337,
          633,
          2167,
          3364,
          51144
        ]
      },
      {
        "avg_logprob": -0.23378383136186442,
        "compression_ratio": 1.7521739130434784,
        "end": 1968.8799999999999,
        "id": 779,
        "no_speech_prob": 0.0004305539187043905,
        "seek": 195184,
        "start": 1967.4399999999998,
        "temperature": 0,
        "text": " inside of the nodes, right?",
        "tokens": [
          51144,
          1854,
          295,
          264,
          13891,
          11,
          558,
          30,
          51216
        ]
      },
      {
        "avg_logprob": -0.23378383136186442,
        "compression_ratio": 1.7521739130434784,
        "end": 1972.1999999999998,
        "id": 780,
        "no_speech_prob": 0.0004305539187043905,
        "seek": 195184,
        "start": 1968.8799999999999,
        "temperature": 0,
        "text": " And so how this works is our color predictor",
        "tokens": [
          51216,
          400,
          370,
          577,
          341,
          1985,
          307,
          527,
          2017,
          6069,
          284,
          51382
        ]
      },
      {
        "avg_logprob": -0.23378383136186442,
        "compression_ratio": 1.7521739130434784,
        "end": 1975.1599999999999,
        "id": 781,
        "no_speech_prob": 0.0004305539187043905,
        "seek": 195184,
        "start": 1972.1999999999998,
        "temperature": 0,
        "text": " is if we want to grab reference to zero,",
        "tokens": [
          51382,
          307,
          498,
          321,
          528,
          281,
          4444,
          6408,
          281,
          4018,
          11,
          51530
        ]
      },
      {
        "avg_logprob": -0.23378383136186442,
        "compression_ratio": 1.7521739130434784,
        "end": 1977.36,
        "id": 782,
        "no_speech_prob": 0.0004305539187043905,
        "seek": 195184,
        "start": 1975.1599999999999,
        "temperature": 0,
        "text": " that is going to be hidden layer.",
        "tokens": [
          51530,
          300,
          307,
          516,
          281,
          312,
          7633,
          4583,
          13,
          51640
        ]
      },
      {
        "avg_logprob": -0.23378383136186442,
        "compression_ratio": 1.7521739130434784,
        "end": 1980.28,
        "id": 783,
        "no_speech_prob": 0.0004305539187043905,
        "seek": 195184,
        "start": 1977.36,
        "temperature": 0,
        "text": " And then two is going to be the last node.",
        "tokens": [
          51640,
          400,
          550,
          732,
          307,
          516,
          281,
          312,
          264,
          1036,
          9984,
          13,
          51786
        ]
      },
      {
        "avg_logprob": -0.22430442197479472,
        "compression_ratio": 1.7807692307692307,
        "end": 1983.48,
        "id": 784,
        "no_speech_prob": 0.008315491490066051,
        "seek": 198028,
        "start": 1980.28,
        "temperature": 0,
        "text": " And then one is going to be the second weight",
        "tokens": [
          50364,
          400,
          550,
          472,
          307,
          516,
          281,
          312,
          264,
          1150,
          3364,
          50524
        ]
      },
      {
        "avg_logprob": -0.22430442197479472,
        "compression_ratio": 1.7807692307692307,
        "end": 1985.52,
        "id": 785,
        "no_speech_prob": 0.008315491490066051,
        "seek": 198028,
        "start": 1983.48,
        "temperature": 0,
        "text": " because start zero, one, second weight.",
        "tokens": [
          50524,
          570,
          722,
          4018,
          11,
          472,
          11,
          1150,
          3364,
          13,
          50626
        ]
      },
      {
        "avg_logprob": -0.22430442197479472,
        "compression_ratio": 1.7807692307692307,
        "end": 1989.44,
        "id": 786,
        "no_speech_prob": 0.008315491490066051,
        "seek": 198028,
        "start": 1985.52,
        "temperature": 0,
        "text": " So this variable is grabbing a reference to this weight.",
        "tokens": [
          50626,
          407,
          341,
          7006,
          307,
          23771,
          257,
          6408,
          281,
          341,
          3364,
          13,
          50822
        ]
      },
      {
        "avg_logprob": -0.22430442197479472,
        "compression_ratio": 1.7807692307692307,
        "end": 1993.8799999999999,
        "id": 787,
        "no_speech_prob": 0.008315491490066051,
        "seek": 198028,
        "start": 1989.44,
        "temperature": 0,
        "text": " That's exactly what color predictor zero, two, one is doing.",
        "tokens": [
          50822,
          663,
          311,
          2293,
          437,
          2017,
          6069,
          284,
          4018,
          11,
          732,
          11,
          472,
          307,
          884,
          13,
          51044
        ]
      },
      {
        "avg_logprob": -0.22430442197479472,
        "compression_ratio": 1.7807692307692307,
        "end": 1995,
        "id": 788,
        "no_speech_prob": 0.008315491490066051,
        "seek": 198028,
        "start": 1993.8799999999999,
        "temperature": 0,
        "text": " And so you see this I,",
        "tokens": [
          51044,
          400,
          370,
          291,
          536,
          341,
          286,
          11,
          51100
        ]
      },
      {
        "avg_logprob": -0.22430442197479472,
        "compression_ratio": 1.7807692307692307,
        "end": 1996.28,
        "id": 789,
        "no_speech_prob": 0.008315491490066051,
        "seek": 198028,
        "start": 1995,
        "temperature": 0,
        "text": " that's an extra dimension",
        "tokens": [
          51100,
          300,
          311,
          364,
          2857,
          10139,
          51164
        ]
      },
      {
        "avg_logprob": -0.22430442197479472,
        "compression_ratio": 1.7807692307692307,
        "end": 1997.84,
        "id": 790,
        "no_speech_prob": 0.008315491490066051,
        "seek": 198028,
        "start": 1996.28,
        "temperature": 0,
        "text": " that you might be confused about.",
        "tokens": [
          51164,
          300,
          291,
          1062,
          312,
          9019,
          466,
          13,
          51242
        ]
      },
      {
        "avg_logprob": -0.22430442197479472,
        "compression_ratio": 1.7807692307692307,
        "end": 2000.04,
        "id": 791,
        "no_speech_prob": 0.008315491490066051,
        "seek": 198028,
        "start": 1997.84,
        "temperature": 0,
        "text": " So let's talk about that real briefly.",
        "tokens": [
          51242,
          407,
          718,
          311,
          751,
          466,
          300,
          957,
          10515,
          13,
          51352
        ]
      },
      {
        "avg_logprob": -0.22430442197479472,
        "compression_ratio": 1.7807692307692307,
        "end": 2002.6,
        "id": 792,
        "no_speech_prob": 0.008315491490066051,
        "seek": 198028,
        "start": 2000.04,
        "temperature": 0,
        "text": " So a lot of information.",
        "tokens": [
          51352,
          407,
          257,
          688,
          295,
          1589,
          13,
          51480
        ]
      },
      {
        "avg_logprob": -0.22430442197479472,
        "compression_ratio": 1.7807692307692307,
        "end": 2005.6,
        "id": 793,
        "no_speech_prob": 0.008315491490066051,
        "seek": 198028,
        "start": 2002.6,
        "temperature": 0,
        "text": " There's a lot of information, but bear with me here.",
        "tokens": [
          51480,
          821,
          311,
          257,
          688,
          295,
          1589,
          11,
          457,
          6155,
          365,
          385,
          510,
          13,
          51630
        ]
      },
      {
        "avg_logprob": -0.22430442197479472,
        "compression_ratio": 1.7807692307692307,
        "end": 2007.6399999999999,
        "id": 794,
        "no_speech_prob": 0.008315491490066051,
        "seek": 198028,
        "start": 2005.6,
        "temperature": 0,
        "text": " Oh, switch camera.",
        "tokens": [
          51630,
          876,
          11,
          3679,
          2799,
          13,
          51732
        ]
      },
      {
        "avg_logprob": -0.22430442197479472,
        "compression_ratio": 1.7807692307692307,
        "end": 2008.96,
        "id": 795,
        "no_speech_prob": 0.008315491490066051,
        "seek": 198028,
        "start": 2007.6399999999999,
        "temperature": 0,
        "text": " Okay, all right, I knew that.",
        "tokens": [
          51732,
          1033,
          11,
          439,
          558,
          11,
          286,
          2586,
          300,
          13,
          51798
        ]
      },
      {
        "avg_logprob": -0.22430442197479472,
        "compression_ratio": 1.7807692307692307,
        "end": 2010.24,
        "id": 796,
        "no_speech_prob": 0.008315491490066051,
        "seek": 198028,
        "start": 2008.96,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51798,
          1057,
          558,
          13,
          51862
        ]
      },
      {
        "avg_logprob": -0.26357930249506883,
        "compression_ratio": 1.6134453781512605,
        "end": 2013.48,
        "id": 797,
        "no_speech_prob": 0.002251704689115286,
        "seek": 201024,
        "start": 2011.04,
        "temperature": 0,
        "text": " So you see this extra I, and what does that mean?",
        "tokens": [
          50404,
          407,
          291,
          536,
          341,
          2857,
          286,
          11,
          293,
          437,
          775,
          300,
          914,
          30,
          50526
        ]
      },
      {
        "avg_logprob": -0.26357930249506883,
        "compression_ratio": 1.6134453781512605,
        "end": 2018.6,
        "id": 798,
        "no_speech_prob": 0.002251704689115286,
        "seek": 201024,
        "start": 2014.32,
        "temperature": 0,
        "text": " So traditionally, with such an example,",
        "tokens": [
          50568,
          407,
          19067,
          11,
          365,
          1270,
          364,
          1365,
          11,
          50782
        ]
      },
      {
        "avg_logprob": -0.26357930249506883,
        "compression_ratio": 1.6134453781512605,
        "end": 2023.16,
        "id": 799,
        "no_speech_prob": 0.002251704689115286,
        "seek": 201024,
        "start": 2018.6,
        "temperature": 0,
        "text": " you would use back propagation to train this neural network.",
        "tokens": [
          50782,
          291,
          576,
          764,
          646,
          38377,
          281,
          3847,
          341,
          18161,
          3209,
          13,
          51010
        ]
      },
      {
        "avg_logprob": -0.26357930249506883,
        "compression_ratio": 1.6134453781512605,
        "end": 2024.92,
        "id": 800,
        "no_speech_prob": 0.002251704689115286,
        "seek": 201024,
        "start": 2023.16,
        "temperature": 0,
        "text": " However, time was a factor,",
        "tokens": [
          51010,
          2908,
          11,
          565,
          390,
          257,
          5952,
          11,
          51098
        ]
      },
      {
        "avg_logprob": -0.26357930249506883,
        "compression_ratio": 1.6134453781512605,
        "end": 2029.1200000000001,
        "id": 801,
        "no_speech_prob": 0.002251704689115286,
        "seek": 201024,
        "start": 2024.92,
        "temperature": 0,
        "text": " and as well as we wanted to go over a lesson",
        "tokens": [
          51098,
          293,
          382,
          731,
          382,
          321,
          1415,
          281,
          352,
          670,
          257,
          6898,
          51308
        ]
      },
      {
        "avg_logprob": -0.26357930249506883,
        "compression_ratio": 1.6134453781512605,
        "end": 2032.16,
        "id": 802,
        "no_speech_prob": 0.002251704689115286,
        "seek": 201024,
        "start": 2029.1200000000001,
        "temperature": 0,
        "text": " of both neural networks and genetic algorithms.",
        "tokens": [
          51308,
          295,
          1293,
          18161,
          9590,
          293,
          12462,
          14642,
          13,
          51460
        ]
      },
      {
        "avg_logprob": -0.26357930249506883,
        "compression_ratio": 1.6134453781512605,
        "end": 2034.76,
        "id": 803,
        "no_speech_prob": 0.002251704689115286,
        "seek": 201024,
        "start": 2032.16,
        "temperature": 0,
        "text": " So why not combine them together",
        "tokens": [
          51460,
          407,
          983,
          406,
          10432,
          552,
          1214,
          51590
        ]
      },
      {
        "avg_logprob": -0.26357930249506883,
        "compression_ratio": 1.6134453781512605,
        "end": 2035.92,
        "id": 804,
        "no_speech_prob": 0.002251704689115286,
        "seek": 201024,
        "start": 2034.76,
        "temperature": 0,
        "text": " is what we did for this example.",
        "tokens": [
          51590,
          307,
          437,
          321,
          630,
          337,
          341,
          1365,
          13,
          51648
        ]
      },
      {
        "avg_logprob": -0.26357930249506883,
        "compression_ratio": 1.6134453781512605,
        "end": 2039.56,
        "id": 805,
        "no_speech_prob": 0.002251704689115286,
        "seek": 201024,
        "start": 2035.92,
        "temperature": 0,
        "text": " So the I is actually just grabbing a reference",
        "tokens": [
          51648,
          407,
          264,
          286,
          307,
          767,
          445,
          23771,
          257,
          6408,
          51830
        ]
      },
      {
        "avg_logprob": -0.26186158259709674,
        "compression_ratio": 1.6682926829268292,
        "end": 2043.76,
        "id": 806,
        "no_speech_prob": 0.0017274157144129276,
        "seek": 203956,
        "start": 2039.8799999999999,
        "temperature": 0,
        "text": " to what predictor we are currently using.",
        "tokens": [
          50380,
          281,
          437,
          6069,
          284,
          321,
          366,
          4362,
          1228,
          13,
          50574
        ]
      },
      {
        "avg_logprob": -0.26186158259709674,
        "compression_ratio": 1.6682926829268292,
        "end": 2046.84,
        "id": 807,
        "no_speech_prob": 0.0017274157144129276,
        "seek": 203956,
        "start": 2043.76,
        "temperature": 0,
        "text": " So genetic algorithms real quick,",
        "tokens": [
          50574,
          407,
          12462,
          14642,
          957,
          1702,
          11,
          50728
        ]
      },
      {
        "avg_logprob": -0.26186158259709674,
        "compression_ratio": 1.6682926829268292,
        "end": 2048.32,
        "id": 808,
        "no_speech_prob": 0.0017274157144129276,
        "seek": 203956,
        "start": 2046.84,
        "temperature": 0,
        "text": " you have to have a population,",
        "tokens": [
          50728,
          291,
          362,
          281,
          362,
          257,
          4415,
          11,
          50802
        ]
      },
      {
        "avg_logprob": -0.26186158259709674,
        "compression_ratio": 1.6682926829268292,
        "end": 2051.7999999999997,
        "id": 809,
        "no_speech_prob": 0.0017274157144129276,
        "seek": 203956,
        "start": 2048.32,
        "temperature": 0,
        "text": " you have to assign fitness scores to every single,",
        "tokens": [
          50802,
          291,
          362,
          281,
          6269,
          15303,
          13444,
          281,
          633,
          2167,
          11,
          50976
        ]
      },
      {
        "avg_logprob": -0.26186158259709674,
        "compression_ratio": 1.6682926829268292,
        "end": 2055.68,
        "id": 810,
        "no_speech_prob": 0.0017274157144129276,
        "seek": 203956,
        "start": 2054.68,
        "temperature": 0,
        "text": " what's the word I'm looking for,",
        "tokens": [
          51120,
          437,
          311,
          264,
          1349,
          286,
          478,
          1237,
          337,
          11,
          51170
        ]
      },
      {
        "avg_logprob": -0.26186158259709674,
        "compression_ratio": 1.6682926829268292,
        "end": 2058.08,
        "id": 811,
        "no_speech_prob": 0.0017274157144129276,
        "seek": 203956,
        "start": 2055.68,
        "temperature": 0,
        "text": " the creature within the population,",
        "tokens": [
          51170,
          264,
          12797,
          1951,
          264,
          4415,
          11,
          51290
        ]
      },
      {
        "avg_logprob": -0.26186158259709674,
        "compression_ratio": 1.6682926829268292,
        "end": 2061.2,
        "id": 812,
        "no_speech_prob": 0.0017274157144129276,
        "seek": 203956,
        "start": 2058.08,
        "temperature": 0,
        "text": " and then you have to mutate them and breed them in X, Y, and Z.",
        "tokens": [
          51290,
          293,
          550,
          291,
          362,
          281,
          5839,
          473,
          552,
          293,
          18971,
          552,
          294,
          1783,
          11,
          398,
          11,
          293,
          1176,
          13,
          51446
        ]
      },
      {
        "avg_logprob": -0.26186158259709674,
        "compression_ratio": 1.6682926829268292,
        "end": 2065.56,
        "id": 813,
        "no_speech_prob": 0.0017274157144129276,
        "seek": 203956,
        "start": 2061.2,
        "temperature": 0,
        "text": " So we have a population of 100 predictors at start,",
        "tokens": [
          51446,
          407,
          321,
          362,
          257,
          4415,
          295,
          2319,
          6069,
          830,
          412,
          722,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.2246606057150322,
        "compression_ratio": 2,
        "end": 2069.48,
        "id": 814,
        "no_speech_prob": 0.0009547104709781706,
        "seek": 206556,
        "start": 2065.72,
        "temperature": 0,
        "text": " and then they all have randomly initialized weights",
        "tokens": [
          50372,
          293,
          550,
          436,
          439,
          362,
          16979,
          5883,
          1602,
          17443,
          50560
        ]
      },
      {
        "avg_logprob": -0.2246606057150322,
        "compression_ratio": 2,
        "end": 2072.2799999999997,
        "id": 815,
        "no_speech_prob": 0.0009547104709781706,
        "seek": 206556,
        "start": 2069.48,
        "temperature": 0,
        "text": " and biases, which again, just to make sure we're clear,",
        "tokens": [
          50560,
          293,
          32152,
          11,
          597,
          797,
          11,
          445,
          281,
          652,
          988,
          321,
          434,
          1850,
          11,
          50700
        ]
      },
      {
        "avg_logprob": -0.2246606057150322,
        "compression_ratio": 2,
        "end": 2075.24,
        "id": 816,
        "no_speech_prob": 0.0009547104709781706,
        "seek": 206556,
        "start": 2072.2799999999997,
        "temperature": 0,
        "text": " are all of these values, weight, weight, weight, bias,",
        "tokens": [
          50700,
          366,
          439,
          295,
          613,
          4190,
          11,
          3364,
          11,
          3364,
          11,
          3364,
          11,
          12577,
          11,
          50848
        ]
      },
      {
        "avg_logprob": -0.2246606057150322,
        "compression_ratio": 2,
        "end": 2076.08,
        "id": 817,
        "no_speech_prob": 0.0009547104709781706,
        "seek": 206556,
        "start": 2075.24,
        "temperature": 0,
        "text": " weight, weight, weight, bias.",
        "tokens": [
          50848,
          3364,
          11,
          3364,
          11,
          3364,
          11,
          12577,
          13,
          50890
        ]
      },
      {
        "avg_logprob": -0.2246606057150322,
        "compression_ratio": 2,
        "end": 2077.96,
        "id": 818,
        "no_speech_prob": 0.0009547104709781706,
        "seek": 206556,
        "start": 2076.08,
        "temperature": 0,
        "text": " These are all randomly initialized.",
        "tokens": [
          50890,
          1981,
          366,
          439,
          16979,
          5883,
          1602,
          13,
          50984
        ]
      },
      {
        "avg_logprob": -0.2246606057150322,
        "compression_ratio": 2,
        "end": 2080.88,
        "id": 819,
        "no_speech_prob": 0.0009547104709781706,
        "seek": 206556,
        "start": 2077.96,
        "temperature": 0,
        "text": " The function that we use for this program",
        "tokens": [
          50984,
          440,
          2445,
          300,
          321,
          764,
          337,
          341,
          1461,
          51130
        ]
      },
      {
        "avg_logprob": -0.2246606057150322,
        "compression_ratio": 2,
        "end": 2084.48,
        "id": 820,
        "no_speech_prob": 0.0009547104709781706,
        "seek": 206556,
        "start": 2080.88,
        "temperature": 0,
        "text": " is randomized between zero and one,",
        "tokens": [
          51130,
          307,
          38513,
          1296,
          4018,
          293,
          472,
          11,
          51310
        ]
      },
      {
        "avg_logprob": -0.2246606057150322,
        "compression_ratio": 2,
        "end": 2086.7599999999998,
        "id": 821,
        "no_speech_prob": 0.0009547104709781706,
        "seek": 206556,
        "start": 2084.48,
        "temperature": 0,
        "text": " and then they all,",
        "tokens": [
          51310,
          293,
          550,
          436,
          439,
          11,
          51424
        ]
      },
      {
        "avg_logprob": -0.2246606057150322,
        "compression_ratio": 2,
        "end": 2088.68,
        "id": 822,
        "no_speech_prob": 0.0009547104709781706,
        "seek": 206556,
        "start": 2086.7599999999998,
        "temperature": 0,
        "text": " based on their randomly initialized weights,",
        "tokens": [
          51424,
          2361,
          322,
          641,
          16979,
          5883,
          1602,
          17443,
          11,
          51520
        ]
      },
      {
        "avg_logprob": -0.2246606057150322,
        "compression_ratio": 2,
        "end": 2092.04,
        "id": 823,
        "no_speech_prob": 0.0009547104709781706,
        "seek": 206556,
        "start": 2088.68,
        "temperature": 0,
        "text": " will make a guess on which one they think is correct.",
        "tokens": [
          51520,
          486,
          652,
          257,
          2041,
          322,
          597,
          472,
          436,
          519,
          307,
          3006,
          13,
          51688
        ]
      },
      {
        "avg_logprob": -0.2899448981651893,
        "compression_ratio": 1.5460122699386503,
        "end": 2097.2799999999997,
        "id": 824,
        "no_speech_prob": 0.000022474012439488433,
        "seek": 209204,
        "start": 2092.2799999999997,
        "temperature": 0,
        "text": " And so most of them said that black is the correct color",
        "tokens": [
          50376,
          400,
          370,
          881,
          295,
          552,
          848,
          300,
          2211,
          307,
          264,
          3006,
          2017,
          50626
        ]
      },
      {
        "avg_logprob": -0.2899448981651893,
        "compression_ratio": 1.5460122699386503,
        "end": 2101.8,
        "id": 825,
        "no_speech_prob": 0.000022474012439488433,
        "seek": 209204,
        "start": 2097.68,
        "temperature": 0,
        "text": " that looks best over this randomized color.",
        "tokens": [
          50646,
          300,
          1542,
          1151,
          670,
          341,
          38513,
          2017,
          13,
          50852
        ]
      },
      {
        "avg_logprob": -0.2899448981651893,
        "compression_ratio": 1.5460122699386503,
        "end": 2106.8,
        "id": 826,
        "no_speech_prob": 0.000022474012439488433,
        "seek": 209204,
        "start": 2101.8,
        "temperature": 0,
        "text": " And then we simply just use a genetic algorithm",
        "tokens": [
          50852,
          400,
          550,
          321,
          2935,
          445,
          764,
          257,
          12462,
          9284,
          51102
        ]
      },
      {
        "avg_logprob": -0.2899448981651893,
        "compression_ratio": 1.5460122699386503,
        "end": 2112.72,
        "id": 827,
        "no_speech_prob": 0.000022474012439488433,
        "seek": 209204,
        "start": 2108.72,
        "temperature": 0,
        "text": " to train this predictor to converge",
        "tokens": [
          51198,
          281,
          3847,
          341,
          6069,
          284,
          281,
          41881,
          51398
        ]
      },
      {
        "avg_logprob": -0.2899448981651893,
        "compression_ratio": 1.5460122699386503,
        "end": 2115.2,
        "id": 828,
        "no_speech_prob": 0.000022474012439488433,
        "seek": 209204,
        "start": 2112.72,
        "temperature": 0,
        "text": " on the best possible predictor.",
        "tokens": [
          51398,
          322,
          264,
          1151,
          1944,
          6069,
          284,
          13,
          51522
        ]
      },
      {
        "avg_logprob": -0.2899448981651893,
        "compression_ratio": 1.5460122699386503,
        "end": 2121.68,
        "id": 829,
        "no_speech_prob": 0.000022474012439488433,
        "seek": 209204,
        "start": 2118.38,
        "temperature": 0,
        "text": " And yeah, that's a general overview",
        "tokens": [
          51681,
          400,
          1338,
          11,
          300,
          311,
          257,
          2674,
          12492,
          51846
        ]
      },
      {
        "avg_logprob": -0.22940802342683367,
        "compression_ratio": 1.570281124497992,
        "end": 2122.96,
        "id": 830,
        "no_speech_prob": 0.0007096538320183754,
        "seek": 212168,
        "start": 2122.12,
        "temperature": 0,
        "text": " on this.",
        "tokens": [
          50386,
          322,
          341,
          13,
          50428
        ]
      },
      {
        "avg_logprob": -0.22940802342683367,
        "compression_ratio": 1.570281124497992,
        "end": 2127.2,
        "id": 831,
        "no_speech_prob": 0.0007096538320183754,
        "seek": 212168,
        "start": 2122.96,
        "temperature": 0,
        "text": " The code is available on GitHub,",
        "tokens": [
          50428,
          440,
          3089,
          307,
          2435,
          322,
          23331,
          11,
          50640
        ]
      },
      {
        "avg_logprob": -0.22940802342683367,
        "compression_ratio": 1.570281124497992,
        "end": 2130.08,
        "id": 832,
        "no_speech_prob": 0.0007096538320183754,
        "seek": 212168,
        "start": 2127.2,
        "temperature": 0,
        "text": " and I left a lot of comments.",
        "tokens": [
          50640,
          293,
          286,
          1411,
          257,
          688,
          295,
          3053,
          13,
          50784
        ]
      },
      {
        "avg_logprob": -0.22940802342683367,
        "compression_ratio": 1.570281124497992,
        "end": 2134.64,
        "id": 833,
        "no_speech_prob": 0.0007096538320183754,
        "seek": 212168,
        "start": 2130.08,
        "temperature": 0,
        "text": " However, it will require a bit more in-depth",
        "tokens": [
          50784,
          2908,
          11,
          309,
          486,
          3651,
          257,
          857,
          544,
          294,
          12,
          25478,
          51012
        ]
      },
      {
        "avg_logprob": -0.22940802342683367,
        "compression_ratio": 1.570281124497992,
        "end": 2138.3199999999997,
        "id": 834,
        "no_speech_prob": 0.0007096538320183754,
        "seek": 212168,
        "start": 2134.64,
        "temperature": 0,
        "text": " if you really want to get a full grasp on this",
        "tokens": [
          51012,
          498,
          291,
          534,
          528,
          281,
          483,
          257,
          1577,
          21743,
          322,
          341,
          51196
        ]
      },
      {
        "avg_logprob": -0.22940802342683367,
        "compression_ratio": 1.570281124497992,
        "end": 2140.6,
        "id": 835,
        "no_speech_prob": 0.0007096538320183754,
        "seek": 212168,
        "start": 2138.3199999999997,
        "temperature": 0,
        "text": " from knowing absolutely nothing.",
        "tokens": [
          51196,
          490,
          5276,
          3122,
          1825,
          13,
          51310
        ]
      },
      {
        "avg_logprob": -0.22940802342683367,
        "compression_ratio": 1.570281124497992,
        "end": 2141.68,
        "id": 836,
        "no_speech_prob": 0.0007096538320183754,
        "seek": 212168,
        "start": 2140.6,
        "temperature": 0,
        "text": " If you already know some stuff",
        "tokens": [
          51310,
          759,
          291,
          1217,
          458,
          512,
          1507,
          51364
        ]
      },
      {
        "avg_logprob": -0.22940802342683367,
        "compression_ratio": 1.570281124497992,
        "end": 2143.3599999999997,
        "id": 837,
        "no_speech_prob": 0.0007096538320183754,
        "seek": 212168,
        "start": 2141.68,
        "temperature": 0,
        "text": " about neural networks and machine learning,",
        "tokens": [
          51364,
          466,
          18161,
          9590,
          293,
          3479,
          2539,
          11,
          51448
        ]
      },
      {
        "avg_logprob": -0.22940802342683367,
        "compression_ratio": 1.570281124497992,
        "end": 2144.48,
        "id": 838,
        "no_speech_prob": 0.0007096538320183754,
        "seek": 212168,
        "start": 2143.3599999999997,
        "temperature": 0,
        "text": " I'm pretty sure this example",
        "tokens": [
          51448,
          286,
          478,
          1238,
          988,
          341,
          1365,
          51504
        ]
      },
      {
        "avg_logprob": -0.22940802342683367,
        "compression_ratio": 1.570281124497992,
        "end": 2145.7999999999997,
        "id": 839,
        "no_speech_prob": 0.0007096538320183754,
        "seek": 212168,
        "start": 2144.48,
        "temperature": 0,
        "text": " is pretty straightforward for you.",
        "tokens": [
          51504,
          307,
          1238,
          15325,
          337,
          291,
          13,
          51570
        ]
      },
      {
        "avg_logprob": -0.22940802342683367,
        "compression_ratio": 1.570281124497992,
        "end": 2150.06,
        "id": 840,
        "no_speech_prob": 0.0007096538320183754,
        "seek": 212168,
        "start": 2145.7999999999997,
        "temperature": 0,
        "text": " But the benefit of writing neural networks from scratch",
        "tokens": [
          51570,
          583,
          264,
          5121,
          295,
          3579,
          18161,
          9590,
          490,
          8459,
          51783
        ]
      },
      {
        "avg_logprob": -0.23158702653707916,
        "compression_ratio": 1.5822222222222222,
        "end": 2151.82,
        "id": 841,
        "no_speech_prob": 0.0006361720152199268,
        "seek": 215006,
        "start": 2150.06,
        "temperature": 0,
        "text": " is that you really have a good grasp",
        "tokens": [
          50364,
          307,
          300,
          291,
          534,
          362,
          257,
          665,
          21743,
          50452
        ]
      },
      {
        "avg_logprob": -0.23158702653707916,
        "compression_ratio": 1.5822222222222222,
        "end": 2153.54,
        "id": 842,
        "no_speech_prob": 0.0006361720152199268,
        "seek": 215006,
        "start": 2151.82,
        "temperature": 0,
        "text": " on what's going on behind the scenes",
        "tokens": [
          50452,
          322,
          437,
          311,
          516,
          322,
          2261,
          264,
          8026,
          50538
        ]
      },
      {
        "avg_logprob": -0.23158702653707916,
        "compression_ratio": 1.5822222222222222,
        "end": 2155.36,
        "id": 843,
        "no_speech_prob": 0.0006361720152199268,
        "seek": 215006,
        "start": 2153.54,
        "temperature": 0,
        "text": " versus using libraries.",
        "tokens": [
          50538,
          5717,
          1228,
          15148,
          13,
          50629
        ]
      },
      {
        "avg_logprob": -0.23158702653707916,
        "compression_ratio": 1.5822222222222222,
        "end": 2160.34,
        "id": 844,
        "no_speech_prob": 0.0006361720152199268,
        "seek": 215006,
        "start": 2156.7,
        "temperature": 0,
        "text": " And you're able to debug different problems",
        "tokens": [
          50696,
          400,
          291,
          434,
          1075,
          281,
          24083,
          819,
          2740,
          50878
        ]
      },
      {
        "avg_logprob": -0.23158702653707916,
        "compression_ratio": 1.5822222222222222,
        "end": 2162.5,
        "id": 845,
        "no_speech_prob": 0.0006361720152199268,
        "seek": 215006,
        "start": 2160.34,
        "temperature": 0,
        "text": " that might arise when you are writing",
        "tokens": [
          50878,
          300,
          1062,
          20288,
          562,
          291,
          366,
          3579,
          50986
        ]
      },
      {
        "avg_logprob": -0.23158702653707916,
        "compression_ratio": 1.5822222222222222,
        "end": 2164.5,
        "id": 846,
        "no_speech_prob": 0.0006361720152199268,
        "seek": 215006,
        "start": 2162.5,
        "temperature": 0,
        "text": " your neural networks,",
        "tokens": [
          50986,
          428,
          18161,
          9590,
          11,
          51086
        ]
      },
      {
        "avg_logprob": -0.23158702653707916,
        "compression_ratio": 1.5822222222222222,
        "end": 2167.1,
        "id": 847,
        "no_speech_prob": 0.0006361720152199268,
        "seek": 215006,
        "start": 2164.5,
        "temperature": 0,
        "text": " be it from scratch or using libraries.",
        "tokens": [
          51086,
          312,
          309,
          490,
          8459,
          420,
          1228,
          15148,
          13,
          51216
        ]
      },
      {
        "avg_logprob": -0.23158702653707916,
        "compression_ratio": 1.5822222222222222,
        "end": 2173.66,
        "id": 848,
        "no_speech_prob": 0.0006361720152199268,
        "seek": 215006,
        "start": 2170.02,
        "temperature": 0,
        "text": " Yeah, and that is pretty much it.",
        "tokens": [
          51362,
          865,
          11,
          293,
          300,
          307,
          1238,
          709,
          309,
          13,
          51544
        ]
      },
      {
        "avg_logprob": -0.23158702653707916,
        "compression_ratio": 1.5822222222222222,
        "end": 2175.38,
        "id": 849,
        "no_speech_prob": 0.0006361720152199268,
        "seek": 215006,
        "start": 2173.66,
        "temperature": 0,
        "text": " We do have plans to update it",
        "tokens": [
          51544,
          492,
          360,
          362,
          5482,
          281,
          5623,
          309,
          51630
        ]
      },
      {
        "avg_logprob": -0.23158702653707916,
        "compression_ratio": 1.5822222222222222,
        "end": 2179.86,
        "id": 850,
        "no_speech_prob": 0.0006361720152199268,
        "seek": 215006,
        "start": 2175.38,
        "temperature": 0,
        "text": " with the actual backpropagation algorithm in there.",
        "tokens": [
          51630,
          365,
          264,
          3539,
          646,
          79,
          1513,
          559,
          399,
          9284,
          294,
          456,
          13,
          51854
        ]
      },
      {
        "avg_logprob": -0.3762624787121284,
        "compression_ratio": 1.5311004784688995,
        "end": 2183.02,
        "id": 851,
        "no_speech_prob": 0.0000960990073508583,
        "seek": 217986,
        "start": 2180.6200000000003,
        "temperature": 0,
        "text": " So that you can learn from that as well.",
        "tokens": [
          50402,
          407,
          300,
          291,
          393,
          1466,
          490,
          300,
          382,
          731,
          13,
          50522
        ]
      },
      {
        "avg_logprob": -0.3762624787121284,
        "compression_ratio": 1.5311004784688995,
        "end": 2185.94,
        "id": 852,
        "no_speech_prob": 0.0000960990073508583,
        "seek": 217986,
        "start": 2185.1,
        "temperature": 0,
        "text": " And yeah.",
        "tokens": [
          50626,
          400,
          1338,
          13,
          50668
        ]
      },
      {
        "avg_logprob": -0.3762624787121284,
        "compression_ratio": 1.5311004784688995,
        "end": 2188.98,
        "id": 853,
        "no_speech_prob": 0.0000960990073508583,
        "seek": 217986,
        "start": 2185.94,
        "temperature": 0,
        "text": " Yeah, I mean, so let me turn my mic back on.",
        "tokens": [
          50668,
          865,
          11,
          286,
          914,
          11,
          370,
          718,
          385,
          1261,
          452,
          3123,
          646,
          322,
          13,
          50820
        ]
      },
      {
        "avg_logprob": -0.3762624787121284,
        "compression_ratio": 1.5311004784688995,
        "end": 2190.1,
        "id": 854,
        "no_speech_prob": 0.0000960990073508583,
        "seek": 217986,
        "start": 2188.98,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50820,
          1033,
          13,
          50876
        ]
      },
      {
        "avg_logprob": -0.3762624787121284,
        "compression_ratio": 1.5311004784688995,
        "end": 2191.78,
        "id": 855,
        "no_speech_prob": 0.0000960990073508583,
        "seek": 217986,
        "start": 2190.1,
        "temperature": 0,
        "text": " Where did that cap go?",
        "tokens": [
          50876,
          2305,
          630,
          300,
          1410,
          352,
          30,
          50960
        ]
      },
      {
        "avg_logprob": -0.3762624787121284,
        "compression_ratio": 1.5311004784688995,
        "end": 2192.9,
        "id": 856,
        "no_speech_prob": 0.0000960990073508583,
        "seek": 217986,
        "start": 2191.78,
        "temperature": 0,
        "text": " Oh, the cap.",
        "tokens": [
          50960,
          876,
          11,
          264,
          1410,
          13,
          51016
        ]
      },
      {
        "avg_logprob": -0.3762624787121284,
        "compression_ratio": 1.5311004784688995,
        "end": 2196.1,
        "id": 857,
        "no_speech_prob": 0.0000960990073508583,
        "seek": 217986,
        "start": 2193.82,
        "temperature": 0,
        "text": " I picked it up, I held it in my hand,",
        "tokens": [
          51062,
          286,
          6183,
          309,
          493,
          11,
          286,
          5167,
          309,
          294,
          452,
          1011,
          11,
          51176
        ]
      },
      {
        "avg_logprob": -0.3762624787121284,
        "compression_ratio": 1.5311004784688995,
        "end": 2196.98,
        "id": 858,
        "no_speech_prob": 0.0000960990073508583,
        "seek": 217986,
        "start": 2196.1,
        "temperature": 0,
        "text": " I put it in my pocket.",
        "tokens": [
          51176,
          286,
          829,
          309,
          294,
          452,
          8963,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.3762624787121284,
        "compression_ratio": 1.5311004784688995,
        "end": 2198.6200000000003,
        "id": 859,
        "no_speech_prob": 0.0000960990073508583,
        "seek": 217986,
        "start": 2196.98,
        "temperature": 0,
        "text": " Ah, that's very cool.",
        "tokens": [
          51220,
          2438,
          11,
          300,
          311,
          588,
          1627,
          13,
          51302
        ]
      },
      {
        "avg_logprob": -0.3762624787121284,
        "compression_ratio": 1.5311004784688995,
        "end": 2200.2200000000003,
        "id": 860,
        "no_speech_prob": 0.0000960990073508583,
        "seek": 217986,
        "start": 2198.6200000000003,
        "temperature": 0,
        "text": " So let me come over here.",
        "tokens": [
          51302,
          407,
          718,
          385,
          808,
          670,
          510,
          13,
          51382
        ]
      },
      {
        "avg_logprob": -0.3762624787121284,
        "compression_ratio": 1.5311004784688995,
        "end": 2201.9,
        "id": 861,
        "no_speech_prob": 0.0000960990073508583,
        "seek": 217986,
        "start": 2200.2200000000003,
        "temperature": 0,
        "text": " There are a few more questions.",
        "tokens": [
          51382,
          821,
          366,
          257,
          1326,
          544,
          1651,
          13,
          51466
        ]
      },
      {
        "avg_logprob": -0.3762624787121284,
        "compression_ratio": 1.5311004784688995,
        "end": 2202.7400000000002,
        "id": 862,
        "no_speech_prob": 0.0000960990073508583,
        "seek": 217986,
        "start": 2201.9,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51466,
          1033,
          13,
          51508
        ]
      },
      {
        "avg_logprob": -0.3762624787121284,
        "compression_ratio": 1.5311004784688995,
        "end": 2205.46,
        "id": 863,
        "no_speech_prob": 0.0000960990073508583,
        "seek": 217986,
        "start": 2203.6200000000003,
        "temperature": 0,
        "text": " Let's see what I can find here.",
        "tokens": [
          51552,
          961,
          311,
          536,
          437,
          286,
          393,
          915,
          510,
          13,
          51644
        ]
      },
      {
        "avg_logprob": -0.3762624787121284,
        "compression_ratio": 1.5311004784688995,
        "end": 2206.3,
        "id": 864,
        "no_speech_prob": 0.0000960990073508583,
        "seek": 217986,
        "start": 2205.46,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          51644,
          876,
          13,
          51686
        ]
      },
      {
        "avg_logprob": -0.3583956705012792,
        "compression_ratio": 1.5940959409594095,
        "end": 2207.86,
        "id": 865,
        "no_speech_prob": 0.0010816657450050116,
        "seek": 220630,
        "start": 2207.02,
        "temperature": 0,
        "text": " Um.",
        "tokens": [
          50400,
          3301,
          13,
          50442
        ]
      },
      {
        "avg_logprob": -0.3583956705012792,
        "compression_ratio": 1.5940959409594095,
        "end": 2211.42,
        "id": 866,
        "no_speech_prob": 0.0010816657450050116,
        "seek": 220630,
        "start": 2209.1800000000003,
        "temperature": 0,
        "text": " So first, people had asked,",
        "tokens": [
          50508,
          407,
          700,
          11,
          561,
          632,
          2351,
          11,
          50620
        ]
      },
      {
        "avg_logprob": -0.3583956705012792,
        "compression_ratio": 1.5940959409594095,
        "end": 2212.9,
        "id": 867,
        "no_speech_prob": 0.0010816657450050116,
        "seek": 220630,
        "start": 2211.42,
        "temperature": 0,
        "text": " is the code already at GitHub,",
        "tokens": [
          50620,
          307,
          264,
          3089,
          1217,
          412,
          23331,
          11,
          50694
        ]
      },
      {
        "avg_logprob": -0.3583956705012792,
        "compression_ratio": 1.5940959409594095,
        "end": 2214.6600000000003,
        "id": 868,
        "no_speech_prob": 0.0010816657450050116,
        "seek": 220630,
        "start": 2212.9,
        "temperature": 0,
        "text": " or are you gonna update it on GitHub later?",
        "tokens": [
          50694,
          420,
          366,
          291,
          799,
          5623,
          309,
          322,
          23331,
          1780,
          30,
          50782
        ]
      },
      {
        "avg_logprob": -0.3583956705012792,
        "compression_ratio": 1.5940959409594095,
        "end": 2216.86,
        "id": 869,
        "no_speech_prob": 0.0010816657450050116,
        "seek": 220630,
        "start": 2214.6600000000003,
        "temperature": 0,
        "text": " Yeah, I still have to upload it to GitHub.",
        "tokens": [
          50782,
          865,
          11,
          286,
          920,
          362,
          281,
          6580,
          309,
          281,
          23331,
          13,
          50892
        ]
      },
      {
        "avg_logprob": -0.3583956705012792,
        "compression_ratio": 1.5940959409594095,
        "end": 2218.82,
        "id": 870,
        "no_speech_prob": 0.0010816657450050116,
        "seek": 220630,
        "start": 2216.86,
        "temperature": 0,
        "text": " So stay tuned.",
        "tokens": [
          50892,
          407,
          1754,
          10870,
          13,
          50990
        ]
      },
      {
        "avg_logprob": -0.3583956705012792,
        "compression_ratio": 1.5940959409594095,
        "end": 2221.26,
        "id": 871,
        "no_speech_prob": 0.0010816657450050116,
        "seek": 220630,
        "start": 2218.82,
        "temperature": 0,
        "text": " Whenever it's on GitHub,",
        "tokens": [
          50990,
          14159,
          309,
          311,
          322,
          23331,
          11,
          51112
        ]
      },
      {
        "avg_logprob": -0.3583956705012792,
        "compression_ratio": 1.5940959409594095,
        "end": 2223.34,
        "id": 872,
        "no_speech_prob": 0.0010816657450050116,
        "seek": 220630,
        "start": 2221.26,
        "temperature": 0,
        "text": " I will come back and edit the description",
        "tokens": [
          51112,
          286,
          486,
          808,
          646,
          293,
          8129,
          264,
          3855,
          51216
        ]
      },
      {
        "avg_logprob": -0.3583956705012792,
        "compression_ratio": 1.5940959409594095,
        "end": 2225.46,
        "id": 873,
        "no_speech_prob": 0.0010816657450050116,
        "seek": 220630,
        "start": 2223.34,
        "temperature": 0,
        "text": " for this live stream and put a link to the code there.",
        "tokens": [
          51216,
          337,
          341,
          1621,
          4309,
          293,
          829,
          257,
          2113,
          281,
          264,
          3089,
          456,
          13,
          51322
        ]
      },
      {
        "avg_logprob": -0.3583956705012792,
        "compression_ratio": 1.5940959409594095,
        "end": 2227.1000000000004,
        "id": 874,
        "no_speech_prob": 0.0010816657450050116,
        "seek": 220630,
        "start": 2225.46,
        "temperature": 0,
        "text": " But they can currently go to",
        "tokens": [
          51322,
          583,
          436,
          393,
          4362,
          352,
          281,
          51404
        ]
      },
      {
        "avg_logprob": -0.3583956705012792,
        "compression_ratio": 1.5940959409594095,
        "end": 2230.78,
        "id": 875,
        "no_speech_prob": 0.0010816657450050116,
        "seek": 220630,
        "start": 2227.1000000000004,
        "temperature": 0,
        "text": " stephsup.com slash color.",
        "tokens": [
          51404,
          1823,
          71,
          82,
          1010,
          13,
          1112,
          17330,
          2017,
          13,
          51588
        ]
      },
      {
        "avg_logprob": -0.3583956705012792,
        "compression_ratio": 1.5940959409594095,
        "end": 2232.0600000000004,
        "id": 876,
        "no_speech_prob": 0.0010816657450050116,
        "seek": 220630,
        "start": 2230.78,
        "temperature": 0,
        "text": " Oh, that link that I use.",
        "tokens": [
          51588,
          876,
          11,
          300,
          2113,
          300,
          286,
          764,
          13,
          51652
        ]
      },
      {
        "avg_logprob": -0.3583956705012792,
        "compression_ratio": 1.5940959409594095,
        "end": 2232.9,
        "id": 877,
        "no_speech_prob": 0.0010816657450050116,
        "seek": 220630,
        "start": 2232.0600000000004,
        "temperature": 0,
        "text": " Right.",
        "tokens": [
          51652,
          1779,
          13,
          51694
        ]
      },
      {
        "avg_logprob": -0.3583956705012792,
        "compression_ratio": 1.5940959409594095,
        "end": 2234.1000000000004,
        "id": 878,
        "no_speech_prob": 0.0010816657450050116,
        "seek": 220630,
        "start": 2232.9,
        "temperature": 0,
        "text": " Yeah, so you can go to,",
        "tokens": [
          51694,
          865,
          11,
          370,
          291,
          393,
          352,
          281,
          11,
          51754
        ]
      },
      {
        "avg_logprob": -0.3583956705012792,
        "compression_ratio": 1.5940959409594095,
        "end": 2235.94,
        "id": 879,
        "no_speech_prob": 0.0010816657450050116,
        "seek": 220630,
        "start": 2234.1000000000004,
        "temperature": 0,
        "text": " let me zoom in here and show you.",
        "tokens": [
          51754,
          718,
          385,
          8863,
          294,
          510,
          293,
          855,
          291,
          13,
          51846
        ]
      },
      {
        "avg_logprob": -0.27976551762333624,
        "compression_ratio": 1.6374501992031874,
        "end": 2239.5,
        "id": 880,
        "no_speech_prob": 0.00007141764217521995,
        "seek": 223594,
        "start": 2236.58,
        "temperature": 0,
        "text": " So stephsup.com, this one.",
        "tokens": [
          50396,
          407,
          1823,
          71,
          82,
          1010,
          13,
          1112,
          11,
          341,
          472,
          13,
          50542
        ]
      },
      {
        "avg_logprob": -0.27976551762333624,
        "compression_ratio": 1.6374501992031874,
        "end": 2240.34,
        "id": 881,
        "no_speech_prob": 0.00007141764217521995,
        "seek": 223594,
        "start": 2239.5,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          50542,
          1079,
          13,
          50584
        ]
      },
      {
        "avg_logprob": -0.27976551762333624,
        "compression_ratio": 1.6374501992031874,
        "end": 2243.5,
        "id": 882,
        "no_speech_prob": 0.00007141764217521995,
        "seek": 223594,
        "start": 2240.34,
        "temperature": 0,
        "text": " So if you wanna grab the code right now,",
        "tokens": [
          50584,
          407,
          498,
          291,
          1948,
          4444,
          264,
          3089,
          558,
          586,
          11,
          50742
        ]
      },
      {
        "avg_logprob": -0.27976551762333624,
        "compression_ratio": 1.6374501992031874,
        "end": 2245.02,
        "id": 883,
        "no_speech_prob": 0.00007141764217521995,
        "seek": 223594,
        "start": 2243.5,
        "temperature": 0,
        "text": " and I don't know why,",
        "tokens": [
          50742,
          293,
          286,
          500,
          380,
          458,
          983,
          11,
          50818
        ]
      },
      {
        "avg_logprob": -0.27976551762333624,
        "compression_ratio": 1.6374501992031874,
        "end": 2247.54,
        "id": 884,
        "no_speech_prob": 0.00007141764217521995,
        "seek": 223594,
        "start": 2245.02,
        "temperature": 0,
        "text": " whenever I paste links into the YouTube chat,",
        "tokens": [
          50818,
          5699,
          286,
          9163,
          6123,
          666,
          264,
          3088,
          5081,
          11,
          50944
        ]
      },
      {
        "avg_logprob": -0.27976551762333624,
        "compression_ratio": 1.6374501992031874,
        "end": 2249.46,
        "id": 885,
        "no_speech_prob": 0.00007141764217521995,
        "seek": 223594,
        "start": 2247.54,
        "temperature": 0,
        "text": " they don't seem to work for people.",
        "tokens": [
          50944,
          436,
          500,
          380,
          1643,
          281,
          589,
          337,
          561,
          13,
          51040
        ]
      },
      {
        "avg_logprob": -0.27976551762333624,
        "compression_ratio": 1.6374501992031874,
        "end": 2250.3,
        "id": 886,
        "no_speech_prob": 0.00007141764217521995,
        "seek": 223594,
        "start": 2249.46,
        "temperature": 0,
        "text": " So but anyway,",
        "tokens": [
          51040,
          407,
          457,
          4033,
          11,
          51082
        ]
      },
      {
        "avg_logprob": -0.27976551762333624,
        "compression_ratio": 1.6374501992031874,
        "end": 2251.3,
        "id": 887,
        "no_speech_prob": 0.00007141764217521995,
        "seek": 223594,
        "start": 2250.3,
        "temperature": 0,
        "text": " so I would paste this into the chat,",
        "tokens": [
          51082,
          370,
          286,
          576,
          9163,
          341,
          666,
          264,
          5081,
          11,
          51132
        ]
      },
      {
        "avg_logprob": -0.27976551762333624,
        "compression_ratio": 1.6374501992031874,
        "end": 2252.34,
        "id": 888,
        "no_speech_prob": 0.00007141764217521995,
        "seek": 223594,
        "start": 2251.3,
        "temperature": 0,
        "text": " but that wouldn't even work.",
        "tokens": [
          51132,
          457,
          300,
          2759,
          380,
          754,
          589,
          13,
          51184
        ]
      },
      {
        "avg_logprob": -0.27976551762333624,
        "compression_ratio": 1.6374501992031874,
        "end": 2256.02,
        "id": 889,
        "no_speech_prob": 0.00007141764217521995,
        "seek": 223594,
        "start": 2252.34,
        "temperature": 0,
        "text": " So you can see it up there.",
        "tokens": [
          51184,
          407,
          291,
          393,
          536,
          309,
          493,
          456,
          13,
          51368
        ]
      },
      {
        "avg_logprob": -0.27976551762333624,
        "compression_ratio": 1.6374501992031874,
        "end": 2257.1,
        "id": 890,
        "no_speech_prob": 0.00007141764217521995,
        "seek": 223594,
        "start": 2256.02,
        "temperature": 0,
        "text": " That you can grab the code now.",
        "tokens": [
          51368,
          663,
          291,
          393,
          4444,
          264,
          3089,
          586,
          13,
          51422
        ]
      },
      {
        "avg_logprob": -0.27976551762333624,
        "compression_ratio": 1.6374501992031874,
        "end": 2260.34,
        "id": 891,
        "no_speech_prob": 0.00007141764217521995,
        "seek": 223594,
        "start": 2257.1,
        "temperature": 0,
        "text": " But I will also include a link",
        "tokens": [
          51422,
          583,
          286,
          486,
          611,
          4090,
          257,
          2113,
          51584
        ]
      },
      {
        "avg_logprob": -0.27976551762333624,
        "compression_ratio": 1.6374501992031874,
        "end": 2262.42,
        "id": 892,
        "no_speech_prob": 0.00007141764217521995,
        "seek": 223594,
        "start": 2260.34,
        "temperature": 0,
        "text": " to GitHub repository, whatever that's.",
        "tokens": [
          51584,
          281,
          23331,
          25841,
          11,
          2035,
          300,
          311,
          13,
          51688
        ]
      },
      {
        "avg_logprob": -0.27976551762333624,
        "compression_ratio": 1.6374501992031874,
        "end": 2263.94,
        "id": 893,
        "no_speech_prob": 0.00007141764217521995,
        "seek": 223594,
        "start": 2262.42,
        "temperature": 0,
        "text": " And it is my intention,",
        "tokens": [
          51688,
          400,
          309,
          307,
          452,
          7789,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.24438570722748962,
        "compression_ratio": 1.767515923566879,
        "end": 2266.98,
        "id": 894,
        "no_speech_prob": 0.0021826429292559624,
        "seek": 226394,
        "start": 2263.94,
        "temperature": 0,
        "text": " I think one of the reasons why I love this demo,",
        "tokens": [
          50364,
          286,
          519,
          472,
          295,
          264,
          4112,
          983,
          286,
          959,
          341,
          10723,
          11,
          50516
        ]
      },
      {
        "avg_logprob": -0.24438570722748962,
        "compression_ratio": 1.767515923566879,
        "end": 2268.98,
        "id": 895,
        "no_speech_prob": 0.0021826429292559624,
        "seek": 226394,
        "start": 2266.98,
        "temperature": 0,
        "text": " and people were kind of asking this a bit in the chat,",
        "tokens": [
          50516,
          293,
          561,
          645,
          733,
          295,
          3365,
          341,
          257,
          857,
          294,
          264,
          5081,
          11,
          50616
        ]
      },
      {
        "avg_logprob": -0.24438570722748962,
        "compression_ratio": 1.767515923566879,
        "end": 2269.94,
        "id": 896,
        "no_speech_prob": 0.0021826429292559624,
        "seek": 226394,
        "start": 2268.98,
        "temperature": 0,
        "text": " was like, oh, like,",
        "tokens": [
          50616,
          390,
          411,
          11,
          1954,
          11,
          411,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.24438570722748962,
        "compression_ratio": 1.767515923566879,
        "end": 2271.7000000000003,
        "id": 897,
        "no_speech_prob": 0.0021826429292559624,
        "seek": 226394,
        "start": 2269.94,
        "temperature": 0,
        "text": " do you really need a neural network for this?",
        "tokens": [
          50664,
          360,
          291,
          534,
          643,
          257,
          18161,
          3209,
          337,
          341,
          30,
          50752
        ]
      },
      {
        "avg_logprob": -0.24438570722748962,
        "compression_ratio": 1.767515923566879,
        "end": 2272.54,
        "id": 898,
        "no_speech_prob": 0.0021826429292559624,
        "seek": 226394,
        "start": 2271.7000000000003,
        "temperature": 0,
        "text": " Right.",
        "tokens": [
          50752,
          1779,
          13,
          50794
        ]
      },
      {
        "avg_logprob": -0.24438570722748962,
        "compression_ratio": 1.767515923566879,
        "end": 2273.54,
        "id": 899,
        "no_speech_prob": 0.0021826429292559624,
        "seek": 226394,
        "start": 2272.54,
        "temperature": 0,
        "text": " And I think to me,",
        "tokens": [
          50794,
          400,
          286,
          519,
          281,
          385,
          11,
          50844
        ]
      },
      {
        "avg_logprob": -0.24438570722748962,
        "compression_ratio": 1.767515923566879,
        "end": 2275.78,
        "id": 900,
        "no_speech_prob": 0.0021826429292559624,
        "seek": 226394,
        "start": 2273.54,
        "temperature": 0,
        "text": " I mean, that's a perfectly valid and interesting question.",
        "tokens": [
          50844,
          286,
          914,
          11,
          300,
          311,
          257,
          6239,
          7363,
          293,
          1880,
          1168,
          13,
          50956
        ]
      },
      {
        "avg_logprob": -0.24438570722748962,
        "compression_ratio": 1.767515923566879,
        "end": 2277.06,
        "id": 901,
        "no_speech_prob": 0.0021826429292559624,
        "seek": 226394,
        "start": 2275.78,
        "temperature": 0,
        "text": " And probably the answer is no,",
        "tokens": [
          50956,
          400,
          1391,
          264,
          1867,
          307,
          572,
          11,
          51020
        ]
      },
      {
        "avg_logprob": -0.24438570722748962,
        "compression_ratio": 1.767515923566879,
        "end": 2279.18,
        "id": 902,
        "no_speech_prob": 0.0021826429292559624,
        "seek": 226394,
        "start": 2277.06,
        "temperature": 0,
        "text": " you don't need a neural network for this.",
        "tokens": [
          51020,
          291,
          500,
          380,
          643,
          257,
          18161,
          3209,
          337,
          341,
          13,
          51126
        ]
      },
      {
        "avg_logprob": -0.24438570722748962,
        "compression_ratio": 1.767515923566879,
        "end": 2281.18,
        "id": 903,
        "no_speech_prob": 0.0021826429292559624,
        "seek": 226394,
        "start": 2279.18,
        "temperature": 0,
        "text": " But when learning about neural networks,",
        "tokens": [
          51126,
          583,
          562,
          2539,
          466,
          18161,
          9590,
          11,
          51226
        ]
      },
      {
        "avg_logprob": -0.24438570722748962,
        "compression_ratio": 1.767515923566879,
        "end": 2283.46,
        "id": 904,
        "no_speech_prob": 0.0021826429292559624,
        "seek": 226394,
        "start": 2281.18,
        "temperature": 0,
        "text": " when trying to build your own machine learning project,",
        "tokens": [
          51226,
          562,
          1382,
          281,
          1322,
          428,
          1065,
          3479,
          2539,
          1716,
          11,
          51340
        ]
      },
      {
        "avg_logprob": -0.24438570722748962,
        "compression_ratio": 1.767515923566879,
        "end": 2286.26,
        "id": 905,
        "no_speech_prob": 0.0021826429292559624,
        "seek": 226394,
        "start": 2283.46,
        "temperature": 0,
        "text": " if you can start with a well-defined,",
        "tokens": [
          51340,
          498,
          291,
          393,
          722,
          365,
          257,
          731,
          12,
          37716,
          11,
          51480
        ]
      },
      {
        "avg_logprob": -0.24438570722748962,
        "compression_ratio": 1.767515923566879,
        "end": 2288.34,
        "id": 906,
        "no_speech_prob": 0.0021826429292559624,
        "seek": 226394,
        "start": 2286.26,
        "temperature": 0,
        "text": " small in scope problem,",
        "tokens": [
          51480,
          1359,
          294,
          11923,
          1154,
          11,
          51584
        ]
      },
      {
        "avg_logprob": -0.24438570722748962,
        "compression_ratio": 1.767515923566879,
        "end": 2289.78,
        "id": 907,
        "no_speech_prob": 0.0021826429292559624,
        "seek": 226394,
        "start": 2288.34,
        "temperature": 0,
        "text": " then you can really figure out,",
        "tokens": [
          51584,
          550,
          291,
          393,
          534,
          2573,
          484,
          11,
          51656
        ]
      },
      {
        "avg_logprob": -0.24438570722748962,
        "compression_ratio": 1.767515923566879,
        "end": 2292.9,
        "id": 908,
        "no_speech_prob": 0.0021826429292559624,
        "seek": 226394,
        "start": 2289.78,
        "temperature": 0,
        "text": " and in some ways I do this similarly",
        "tokens": [
          51656,
          293,
          294,
          512,
          2098,
          286,
          360,
          341,
          14138,
          51812
        ]
      },
      {
        "avg_logprob": -0.23273981730143228,
        "compression_ratio": 1.8154362416107384,
        "end": 2296.2200000000003,
        "id": 909,
        "no_speech_prob": 0.00003219127393094823,
        "seek": 229290,
        "start": 2292.9,
        "temperature": 0,
        "text": " with some of my genetic algorithm projects.",
        "tokens": [
          50364,
          365,
          512,
          295,
          452,
          12462,
          9284,
          4455,
          13,
          50530
        ]
      },
      {
        "avg_logprob": -0.23273981730143228,
        "compression_ratio": 1.8154362416107384,
        "end": 2300.54,
        "id": 910,
        "no_speech_prob": 0.00003219127393094823,
        "seek": 229290,
        "start": 2296.2200000000003,
        "temperature": 0,
        "text": " I take an example where I know the answer.",
        "tokens": [
          50530,
          286,
          747,
          364,
          1365,
          689,
          286,
          458,
          264,
          1867,
          13,
          50746
        ]
      },
      {
        "avg_logprob": -0.23273981730143228,
        "compression_ratio": 1.8154362416107384,
        "end": 2301.38,
        "id": 911,
        "no_speech_prob": 0.00003219127393094823,
        "seek": 229290,
        "start": 2300.54,
        "temperature": 0,
        "text": " Right.",
        "tokens": [
          50746,
          1779,
          13,
          50788
        ]
      },
      {
        "avg_logprob": -0.23273981730143228,
        "compression_ratio": 1.8154362416107384,
        "end": 2303.14,
        "id": 912,
        "no_speech_prob": 0.00003219127393094823,
        "seek": 229290,
        "start": 2301.38,
        "temperature": 0,
        "text": " So I can see if the genetic algorithm worked.",
        "tokens": [
          50788,
          407,
          286,
          393,
          536,
          498,
          264,
          12462,
          9284,
          2732,
          13,
          50876
        ]
      },
      {
        "avg_logprob": -0.23273981730143228,
        "compression_ratio": 1.8154362416107384,
        "end": 2304.5,
        "id": 913,
        "no_speech_prob": 0.00003219127393094823,
        "seek": 229290,
        "start": 2303.14,
        "temperature": 0,
        "text": " Because ultimately what I want to do",
        "tokens": [
          50876,
          1436,
          6284,
          437,
          286,
          528,
          281,
          360,
          50944
        ]
      },
      {
        "avg_logprob": -0.23273981730143228,
        "compression_ratio": 1.8154362416107384,
        "end": 2306.62,
        "id": 914,
        "no_speech_prob": 0.00003219127393094823,
        "seek": 229290,
        "start": 2304.5,
        "temperature": 0,
        "text": " is use a neural network or a genetic algorithm",
        "tokens": [
          50944,
          307,
          764,
          257,
          18161,
          3209,
          420,
          257,
          12462,
          9284,
          51050
        ]
      },
      {
        "avg_logprob": -0.23273981730143228,
        "compression_ratio": 1.8154362416107384,
        "end": 2308.94,
        "id": 915,
        "no_speech_prob": 0.00003219127393094823,
        "seek": 229290,
        "start": 2306.62,
        "temperature": 0,
        "text": " in some domain where maybe I don't know the answer,",
        "tokens": [
          51050,
          294,
          512,
          9274,
          689,
          1310,
          286,
          500,
          380,
          458,
          264,
          1867,
          11,
          51166
        ]
      },
      {
        "avg_logprob": -0.23273981730143228,
        "compression_ratio": 1.8154362416107384,
        "end": 2310.6800000000003,
        "id": 916,
        "no_speech_prob": 0.00003219127393094823,
        "seek": 229290,
        "start": 2308.94,
        "temperature": 0,
        "text": " I couldn't solve the answer easily,",
        "tokens": [
          51166,
          286,
          2809,
          380,
          5039,
          264,
          1867,
          3612,
          11,
          51253
        ]
      },
      {
        "avg_logprob": -0.23273981730143228,
        "compression_ratio": 1.8154362416107384,
        "end": 2312.14,
        "id": 917,
        "no_speech_prob": 0.00003219127393094823,
        "seek": 229290,
        "start": 2310.6800000000003,
        "temperature": 0,
        "text": " but to figure out how those things work,",
        "tokens": [
          51253,
          457,
          281,
          2573,
          484,
          577,
          729,
          721,
          589,
          11,
          51326
        ]
      },
      {
        "avg_logprob": -0.23273981730143228,
        "compression_ratio": 1.8154362416107384,
        "end": 2313.14,
        "id": 918,
        "no_speech_prob": 0.00003219127393094823,
        "seek": 229290,
        "start": 2312.14,
        "temperature": 0,
        "text": " I've got to come up with,",
        "tokens": [
          51326,
          286,
          600,
          658,
          281,
          808,
          493,
          365,
          11,
          51376
        ]
      },
      {
        "avg_logprob": -0.23273981730143228,
        "compression_ratio": 1.8154362416107384,
        "end": 2315.46,
        "id": 919,
        "no_speech_prob": 0.00003219127393094823,
        "seek": 229290,
        "start": 2313.14,
        "temperature": 0,
        "text": " and so this is a really nice problem for that,",
        "tokens": [
          51376,
          293,
          370,
          341,
          307,
          257,
          534,
          1481,
          1154,
          337,
          300,
          11,
          51492
        ]
      },
      {
        "avg_logprob": -0.23273981730143228,
        "compression_ratio": 1.8154362416107384,
        "end": 2316.98,
        "id": 920,
        "no_speech_prob": 0.00003219127393094823,
        "seek": 229290,
        "start": 2315.46,
        "temperature": 0,
        "text": " because it's simple, small in scope,",
        "tokens": [
          51492,
          570,
          309,
          311,
          2199,
          11,
          1359,
          294,
          11923,
          11,
          51568
        ]
      },
      {
        "avg_logprob": -0.23273981730143228,
        "compression_ratio": 1.8154362416107384,
        "end": 2319.62,
        "id": 921,
        "no_speech_prob": 0.00003219127393094823,
        "seek": 229290,
        "start": 2316.98,
        "temperature": 0,
        "text": " and for people who want to do creative coding,",
        "tokens": [
          51568,
          293,
          337,
          561,
          567,
          528,
          281,
          360,
          5880,
          17720,
          11,
          51700
        ]
      },
      {
        "avg_logprob": -0.23273981730143228,
        "compression_ratio": 1.8154362416107384,
        "end": 2320.86,
        "id": 922,
        "no_speech_prob": 0.00003219127393094823,
        "seek": 229290,
        "start": 2319.62,
        "temperature": 0,
        "text": " and graphics, and design stuff,",
        "tokens": [
          51700,
          293,
          11837,
          11,
          293,
          1715,
          1507,
          11,
          51762
        ]
      },
      {
        "avg_logprob": -0.26995043073381697,
        "compression_ratio": 1.7411347517730495,
        "end": 2323.06,
        "id": 923,
        "no_speech_prob": 0.0031718439422547817,
        "seek": 232086,
        "start": 2320.86,
        "temperature": 0,
        "text": " it's got color, and graphics.",
        "tokens": [
          50364,
          309,
          311,
          658,
          2017,
          11,
          293,
          11837,
          13,
          50474
        ]
      },
      {
        "avg_logprob": -0.26995043073381697,
        "compression_ratio": 1.7411347517730495,
        "end": 2324.02,
        "id": 924,
        "no_speech_prob": 0.0031718439422547817,
        "seek": 232086,
        "start": 2323.06,
        "temperature": 0,
        "text": " And not to mention,",
        "tokens": [
          50474,
          400,
          406,
          281,
          2152,
          11,
          50522
        ]
      },
      {
        "avg_logprob": -0.26995043073381697,
        "compression_ratio": 1.7411347517730495,
        "end": 2326.6600000000003,
        "id": 925,
        "no_speech_prob": 0.0031718439422547817,
        "seek": 232086,
        "start": 2324.02,
        "temperature": 0,
        "text": " once you learn how to do this stuff from scratch,",
        "tokens": [
          50522,
          1564,
          291,
          1466,
          577,
          281,
          360,
          341,
          1507,
          490,
          8459,
          11,
          50654
        ]
      },
      {
        "avg_logprob": -0.26995043073381697,
        "compression_ratio": 1.7411347517730495,
        "end": 2330.1,
        "id": 926,
        "no_speech_prob": 0.0031718439422547817,
        "seek": 232086,
        "start": 2326.6600000000003,
        "temperature": 0,
        "text": " this is easily scalable for the most part.",
        "tokens": [
          50654,
          341,
          307,
          3612,
          38481,
          337,
          264,
          881,
          644,
          13,
          50826
        ]
      },
      {
        "avg_logprob": -0.26995043073381697,
        "compression_ratio": 1.7411347517730495,
        "end": 2331.46,
        "id": 927,
        "no_speech_prob": 0.0031718439422547817,
        "seek": 232086,
        "start": 2330.1,
        "temperature": 0,
        "text": " You still have to worry about some other stuff",
        "tokens": [
          50826,
          509,
          920,
          362,
          281,
          3292,
          466,
          512,
          661,
          1507,
          50894
        ]
      },
      {
        "avg_logprob": -0.26995043073381697,
        "compression_ratio": 1.7411347517730495,
        "end": 2333.06,
        "id": 928,
        "no_speech_prob": 0.0031718439422547817,
        "seek": 232086,
        "start": 2331.46,
        "temperature": 0,
        "text": " like vanishing gradients and stuff like that,",
        "tokens": [
          50894,
          411,
          3161,
          3807,
          2771,
          2448,
          293,
          1507,
          411,
          300,
          11,
          50974
        ]
      },
      {
        "avg_logprob": -0.26995043073381697,
        "compression_ratio": 1.7411347517730495,
        "end": 2333.94,
        "id": 929,
        "no_speech_prob": 0.0031718439422547817,
        "seek": 232086,
        "start": 2333.06,
        "temperature": 0,
        "text": " but for the most part,",
        "tokens": [
          50974,
          457,
          337,
          264,
          881,
          644,
          11,
          51018
        ]
      },
      {
        "avg_logprob": -0.26995043073381697,
        "compression_ratio": 1.7411347517730495,
        "end": 2335.2200000000003,
        "id": 930,
        "no_speech_prob": 0.0031718439422547817,
        "seek": 232086,
        "start": 2333.94,
        "temperature": 0,
        "text": " you can take this and scale this up,",
        "tokens": [
          51018,
          291,
          393,
          747,
          341,
          293,
          4373,
          341,
          493,
          11,
          51082
        ]
      },
      {
        "avg_logprob": -0.26995043073381697,
        "compression_ratio": 1.7411347517730495,
        "end": 2337.08,
        "id": 931,
        "no_speech_prob": 0.0031718439422547817,
        "seek": 232086,
        "start": 2335.2200000000003,
        "temperature": 0,
        "text": " and it'll work just about the same.",
        "tokens": [
          51082,
          293,
          309,
          603,
          589,
          445,
          466,
          264,
          912,
          13,
          51175
        ]
      },
      {
        "avg_logprob": -0.26995043073381697,
        "compression_ratio": 1.7411347517730495,
        "end": 2339.78,
        "id": 932,
        "no_speech_prob": 0.0031718439422547817,
        "seek": 232086,
        "start": 2337.08,
        "temperature": 0,
        "text": " So there's also that benefit as well.",
        "tokens": [
          51175,
          407,
          456,
          311,
          611,
          300,
          5121,
          382,
          731,
          13,
          51310
        ]
      },
      {
        "avg_logprob": -0.26995043073381697,
        "compression_ratio": 1.7411347517730495,
        "end": 2344.02,
        "id": 933,
        "no_speech_prob": 0.0031718439422547817,
        "seek": 232086,
        "start": 2339.78,
        "temperature": 0,
        "text": " So there were a couple questions that came in on Twitter,",
        "tokens": [
          51310,
          407,
          456,
          645,
          257,
          1916,
          1651,
          300,
          1361,
          294,
          322,
          5794,
          11,
          51522
        ]
      },
      {
        "avg_logprob": -0.26995043073381697,
        "compression_ratio": 1.7411347517730495,
        "end": 2347.5,
        "id": 934,
        "no_speech_prob": 0.0031718439422547817,
        "seek": 232086,
        "start": 2344.02,
        "temperature": 0,
        "text": " ask Jabril hashtag,",
        "tokens": [
          51522,
          1029,
          40319,
          24216,
          20379,
          11,
          51696
        ]
      },
      {
        "avg_logprob": -0.26995043073381697,
        "compression_ratio": 1.7411347517730495,
        "end": 2349.1800000000003,
        "id": 935,
        "no_speech_prob": 0.0031718439422547817,
        "seek": 232086,
        "start": 2347.5,
        "temperature": 0,
        "text": " people, there were a lot of questions like,",
        "tokens": [
          51696,
          561,
          11,
          456,
          645,
          257,
          688,
          295,
          1651,
          411,
          11,
          51780
        ]
      },
      {
        "avg_logprob": -0.2511385300580193,
        "compression_ratio": 1.8105263157894738,
        "end": 2350.8599999999997,
        "id": 936,
        "no_speech_prob": 0.0002866408322006464,
        "seek": 234918,
        "start": 2349.18,
        "temperature": 0,
        "text": " how are you speaking with your mouth?",
        "tokens": [
          50364,
          577,
          366,
          291,
          4124,
          365,
          428,
          4525,
          30,
          50448
        ]
      },
      {
        "avg_logprob": -0.2511385300580193,
        "compression_ratio": 1.8105263157894738,
        "end": 2353.02,
        "id": 937,
        "no_speech_prob": 0.0002866408322006464,
        "seek": 234918,
        "start": 2350.8599999999997,
        "temperature": 0,
        "text": " There was a lot of moving, there was a lot of that.",
        "tokens": [
          50448,
          821,
          390,
          257,
          688,
          295,
          2684,
          11,
          456,
          390,
          257,
          688,
          295,
          300,
          13,
          50556
        ]
      },
      {
        "avg_logprob": -0.2511385300580193,
        "compression_ratio": 1.8105263157894738,
        "end": 2354.4199999999996,
        "id": 938,
        "no_speech_prob": 0.0002866408322006464,
        "seek": 234918,
        "start": 2353.02,
        "temperature": 0,
        "text": " I am a bot.",
        "tokens": [
          50556,
          286,
          669,
          257,
          10592,
          13,
          50626
        ]
      },
      {
        "avg_logprob": -0.2511385300580193,
        "compression_ratio": 1.8105263157894738,
        "end": 2355.58,
        "id": 939,
        "no_speech_prob": 0.0002866408322006464,
        "seek": 234918,
        "start": 2354.4199999999996,
        "temperature": 0,
        "text": " How can I become like you?",
        "tokens": [
          50626,
          1012,
          393,
          286,
          1813,
          411,
          291,
          30,
          50684
        ]
      },
      {
        "avg_logprob": -0.2511385300580193,
        "compression_ratio": 1.8105263157894738,
        "end": 2357.2599999999998,
        "id": 940,
        "no_speech_prob": 0.0002866408322006464,
        "seek": 234918,
        "start": 2355.58,
        "temperature": 0,
        "text": " I don't know if that's an answerable question,",
        "tokens": [
          50684,
          286,
          500,
          380,
          458,
          498,
          300,
          311,
          364,
          1867,
          712,
          1168,
          11,
          50768
        ]
      },
      {
        "avg_logprob": -0.2511385300580193,
        "compression_ratio": 1.8105263157894738,
        "end": 2359.62,
        "id": 941,
        "no_speech_prob": 0.0002866408322006464,
        "seek": 234918,
        "start": 2357.2599999999998,
        "temperature": 0,
        "text": " but that was a question that came in",
        "tokens": [
          50768,
          457,
          300,
          390,
          257,
          1168,
          300,
          1361,
          294,
          50886
        ]
      },
      {
        "avg_logprob": -0.2511385300580193,
        "compression_ratio": 1.8105263157894738,
        "end": 2362.2599999999998,
        "id": 942,
        "no_speech_prob": 0.0002866408322006464,
        "seek": 234918,
        "start": 2359.62,
        "temperature": 0,
        "text": " from ideaxiso on Twitter.",
        "tokens": [
          50886,
          490,
          741,
          1479,
          2797,
          19227,
          322,
          5794,
          13,
          51018
        ]
      },
      {
        "avg_logprob": -0.2511385300580193,
        "compression_ratio": 1.8105263157894738,
        "end": 2365.7,
        "id": 943,
        "no_speech_prob": 0.0002866408322006464,
        "seek": 234918,
        "start": 2362.2599999999998,
        "temperature": 0,
        "text": " So here's a question from IamRoshan on Twitter.",
        "tokens": [
          51018,
          407,
          510,
          311,
          257,
          1168,
          490,
          286,
          335,
          49,
          3019,
          282,
          322,
          5794,
          13,
          51190
        ]
      },
      {
        "avg_logprob": -0.2511385300580193,
        "compression_ratio": 1.8105263157894738,
        "end": 2366.74,
        "id": 944,
        "no_speech_prob": 0.0002866408322006464,
        "seek": 234918,
        "start": 2365.7,
        "temperature": 0,
        "text": " This is a big question.",
        "tokens": [
          51190,
          639,
          307,
          257,
          955,
          1168,
          13,
          51242
        ]
      },
      {
        "avg_logprob": -0.2511385300580193,
        "compression_ratio": 1.8105263157894738,
        "end": 2367.58,
        "id": 945,
        "no_speech_prob": 0.0002866408322006464,
        "seek": 234918,
        "start": 2366.74,
        "temperature": 0,
        "text": " Okay, let's do it.",
        "tokens": [
          51242,
          1033,
          11,
          718,
          311,
          360,
          309,
          13,
          51284
        ]
      },
      {
        "avg_logprob": -0.2511385300580193,
        "compression_ratio": 1.8105263157894738,
        "end": 2368.66,
        "id": 946,
        "no_speech_prob": 0.0002866408322006464,
        "seek": 234918,
        "start": 2367.58,
        "temperature": 0,
        "text": " I don't know if,",
        "tokens": [
          51284,
          286,
          500,
          380,
          458,
          498,
          11,
          51338
        ]
      },
      {
        "avg_logprob": -0.2511385300580193,
        "compression_ratio": 1.8105263157894738,
        "end": 2369.62,
        "id": 947,
        "no_speech_prob": 0.0002866408322006464,
        "seek": 234918,
        "start": 2368.66,
        "temperature": 0,
        "text": " and I think this is a question",
        "tokens": [
          51338,
          293,
          286,
          519,
          341,
          307,
          257,
          1168,
          51386
        ]
      },
      {
        "avg_logprob": -0.2511385300580193,
        "compression_ratio": 1.8105263157894738,
        "end": 2371.46,
        "id": 948,
        "no_speech_prob": 0.0002866408322006464,
        "seek": 234918,
        "start": 2369.62,
        "temperature": 0,
        "text": " I've certainly touched on,",
        "tokens": [
          51386,
          286,
          600,
          3297,
          9828,
          322,
          11,
          51478
        ]
      },
      {
        "avg_logprob": -0.2511385300580193,
        "compression_ratio": 1.8105263157894738,
        "end": 2374.14,
        "id": 949,
        "no_speech_prob": 0.0002866408322006464,
        "seek": 234918,
        "start": 2371.46,
        "temperature": 0,
        "text": " but how is AI,",
        "tokens": [
          51478,
          457,
          577,
          307,
          7318,
          11,
          51612
        ]
      },
      {
        "avg_logprob": -0.2511385300580193,
        "compression_ratio": 1.8105263157894738,
        "end": 2376.02,
        "id": 950,
        "no_speech_prob": 0.0002866408322006464,
        "seek": 234918,
        "start": 2374.14,
        "temperature": 0,
        "text": " let me read the question,",
        "tokens": [
          51612,
          718,
          385,
          1401,
          264,
          1168,
          11,
          51706
        ]
      },
      {
        "avg_logprob": -0.2511385300580193,
        "compression_ratio": 1.8105263157894738,
        "end": 2376.98,
        "id": 951,
        "no_speech_prob": 0.0002866408322006464,
        "seek": 234918,
        "start": 2376.02,
        "temperature": 0,
        "text": " how it actually is written.",
        "tokens": [
          51706,
          577,
          309,
          767,
          307,
          3720,
          13,
          51754
        ]
      },
      {
        "avg_logprob": -0.2511385300580193,
        "compression_ratio": 1.8105263157894738,
        "end": 2379.06,
        "id": 952,
        "no_speech_prob": 0.0002866408322006464,
        "seek": 234918,
        "start": 2376.98,
        "temperature": 0,
        "text": " How is AI different from a neural network,",
        "tokens": [
          51754,
          1012,
          307,
          7318,
          819,
          490,
          257,
          18161,
          3209,
          11,
          51858
        ]
      },
      {
        "avg_logprob": -0.276318359375,
        "compression_ratio": 1.7863777089783281,
        "end": 2381.02,
        "id": 953,
        "no_speech_prob": 0.00022337197151500732,
        "seek": 237906,
        "start": 2379.9,
        "temperature": 0,
        "text": " or deep learning, or machine learning?",
        "tokens": [
          50406,
          420,
          2452,
          2539,
          11,
          420,
          3479,
          2539,
          30,
          50462
        ]
      },
      {
        "avg_logprob": -0.276318359375,
        "compression_ratio": 1.7863777089783281,
        "end": 2382.74,
        "id": 954,
        "no_speech_prob": 0.00022337197151500732,
        "seek": 237906,
        "start": 2381.02,
        "temperature": 0,
        "text": " They often seem to be used interchangeably",
        "tokens": [
          50462,
          814,
          2049,
          1643,
          281,
          312,
          1143,
          30358,
          1188,
          50548
        ]
      },
      {
        "avg_logprob": -0.276318359375,
        "compression_ratio": 1.7863777089783281,
        "end": 2383.62,
        "id": 955,
        "no_speech_prob": 0.00022337197151500732,
        "seek": 237906,
        "start": 2382.74,
        "temperature": 0,
        "text": " and cause confusion.",
        "tokens": [
          50548,
          293,
          3082,
          15075,
          13,
          50592
        ]
      },
      {
        "avg_logprob": -0.276318359375,
        "compression_ratio": 1.7863777089783281,
        "end": 2384.58,
        "id": 956,
        "no_speech_prob": 0.00022337197151500732,
        "seek": 237906,
        "start": 2383.62,
        "temperature": 0,
        "text": " So first of all, I want to say,",
        "tokens": [
          50592,
          407,
          700,
          295,
          439,
          11,
          286,
          528,
          281,
          584,
          11,
          50640
        ]
      },
      {
        "avg_logprob": -0.276318359375,
        "compression_ratio": 1.7863777089783281,
        "end": 2386.58,
        "id": 957,
        "no_speech_prob": 0.00022337197151500732,
        "seek": 237906,
        "start": 2384.58,
        "temperature": 0,
        "text": " like, this is a really good question.",
        "tokens": [
          50640,
          411,
          11,
          341,
          307,
          257,
          534,
          665,
          1168,
          13,
          50740
        ]
      },
      {
        "avg_logprob": -0.276318359375,
        "compression_ratio": 1.7863777089783281,
        "end": 2388.18,
        "id": 958,
        "no_speech_prob": 0.00022337197151500732,
        "seek": 237906,
        "start": 2386.58,
        "temperature": 0,
        "text": " And I struggle with this question all the time",
        "tokens": [
          50740,
          400,
          286,
          7799,
          365,
          341,
          1168,
          439,
          264,
          565,
          50820
        ]
      },
      {
        "avg_logprob": -0.276318359375,
        "compression_ratio": 1.7863777089783281,
        "end": 2389.9,
        "id": 959,
        "no_speech_prob": 0.00022337197151500732,
        "seek": 237906,
        "start": 2388.18,
        "temperature": 0,
        "text": " because there's all these different terms.",
        "tokens": [
          50820,
          570,
          456,
          311,
          439,
          613,
          819,
          2115,
          13,
          50906
        ]
      },
      {
        "avg_logprob": -0.276318359375,
        "compression_ratio": 1.7863777089783281,
        "end": 2391.86,
        "id": 960,
        "no_speech_prob": 0.00022337197151500732,
        "seek": 237906,
        "start": 2389.9,
        "temperature": 0,
        "text": " So let me list those terms.",
        "tokens": [
          50906,
          407,
          718,
          385,
          1329,
          729,
          2115,
          13,
          51004
        ]
      },
      {
        "avg_logprob": -0.276318359375,
        "compression_ratio": 1.7863777089783281,
        "end": 2395.14,
        "id": 961,
        "no_speech_prob": 0.00022337197151500732,
        "seek": 237906,
        "start": 2391.86,
        "temperature": 0,
        "text": " Artificial intelligence, deep learning, machine learning.",
        "tokens": [
          51004,
          5735,
          10371,
          7599,
          11,
          2452,
          2539,
          11,
          3479,
          2539,
          13,
          51168
        ]
      },
      {
        "avg_logprob": -0.276318359375,
        "compression_ratio": 1.7863777089783281,
        "end": 2396.66,
        "id": 962,
        "no_speech_prob": 0.00022337197151500732,
        "seek": 237906,
        "start": 2395.14,
        "temperature": 0,
        "text": " And then I might put neural network",
        "tokens": [
          51168,
          400,
          550,
          286,
          1062,
          829,
          18161,
          3209,
          51244
        ]
      },
      {
        "avg_logprob": -0.276318359375,
        "compression_ratio": 1.7863777089783281,
        "end": 2398.38,
        "id": 963,
        "no_speech_prob": 0.00022337197151500732,
        "seek": 237906,
        "start": 2396.66,
        "temperature": 0,
        "text": " in a different category.",
        "tokens": [
          51244,
          294,
          257,
          819,
          7719,
          13,
          51330
        ]
      },
      {
        "avg_logprob": -0.276318359375,
        "compression_ratio": 1.7863777089783281,
        "end": 2399.98,
        "id": 964,
        "no_speech_prob": 0.00022337197151500732,
        "seek": 237906,
        "start": 2398.38,
        "temperature": 0,
        "text": " But that's another term as well.",
        "tokens": [
          51330,
          583,
          300,
          311,
          1071,
          1433,
          382,
          731,
          13,
          51410
        ]
      },
      {
        "avg_logprob": -0.276318359375,
        "compression_ratio": 1.7863777089783281,
        "end": 2402.14,
        "id": 965,
        "no_speech_prob": 0.00022337197151500732,
        "seek": 237906,
        "start": 2399.98,
        "temperature": 0,
        "text": " I don't know if you have a kind of like,",
        "tokens": [
          51410,
          286,
          500,
          380,
          458,
          498,
          291,
          362,
          257,
          733,
          295,
          411,
          11,
          51518
        ]
      },
      {
        "avg_logprob": -0.276318359375,
        "compression_ratio": 1.7863777089783281,
        "end": 2404.06,
        "id": 966,
        "no_speech_prob": 0.00022337197151500732,
        "seek": 237906,
        "start": 2402.14,
        "temperature": 0,
        "text": " way that you describe these,",
        "tokens": [
          51518,
          636,
          300,
          291,
          6786,
          613,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.276318359375,
        "compression_ratio": 1.7863777089783281,
        "end": 2405.82,
        "id": 967,
        "no_speech_prob": 0.00022337197151500732,
        "seek": 237906,
        "start": 2404.06,
        "temperature": 0,
        "text": " the terminology of people when they ask those kind of questions.",
        "tokens": [
          51614,
          264,
          27575,
          295,
          561,
          562,
          436,
          1029,
          729,
          733,
          295,
          1651,
          13,
          51702
        ]
      },
      {
        "avg_logprob": -0.2468642388190423,
        "compression_ratio": 1.779467680608365,
        "end": 2409.1000000000004,
        "id": 968,
        "no_speech_prob": 0.06952948868274689,
        "seek": 240582,
        "start": 2405.82,
        "temperature": 0,
        "text": " Yeah, I like to start with English is difficult.",
        "tokens": [
          50364,
          865,
          11,
          286,
          411,
          281,
          722,
          365,
          3669,
          307,
          2252,
          13,
          50528
        ]
      },
      {
        "avg_logprob": -0.2468642388190423,
        "compression_ratio": 1.779467680608365,
        "end": 2410.94,
        "id": 969,
        "no_speech_prob": 0.06952948868274689,
        "seek": 240582,
        "start": 2409.1000000000004,
        "temperature": 0,
        "text": " I like to start there.",
        "tokens": [
          50528,
          286,
          411,
          281,
          722,
          456,
          13,
          50620
        ]
      },
      {
        "avg_logprob": -0.2468642388190423,
        "compression_ratio": 1.779467680608365,
        "end": 2411.82,
        "id": 970,
        "no_speech_prob": 0.06952948868274689,
        "seek": 240582,
        "start": 2410.94,
        "temperature": 0,
        "text": " But for the most part,",
        "tokens": [
          50620,
          583,
          337,
          264,
          881,
          644,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.2468642388190423,
        "compression_ratio": 1.779467680608365,
        "end": 2414.98,
        "id": 971,
        "no_speech_prob": 0.06952948868274689,
        "seek": 240582,
        "start": 2411.82,
        "temperature": 0,
        "text": " AI is like a grab all for everything AI.",
        "tokens": [
          50664,
          7318,
          307,
          411,
          257,
          4444,
          439,
          337,
          1203,
          7318,
          13,
          50822
        ]
      },
      {
        "avg_logprob": -0.2468642388190423,
        "compression_ratio": 1.779467680608365,
        "end": 2417.1800000000003,
        "id": 972,
        "no_speech_prob": 0.06952948868274689,
        "seek": 240582,
        "start": 2414.98,
        "temperature": 0,
        "text": " Like, you can hard code AI.",
        "tokens": [
          50822,
          1743,
          11,
          291,
          393,
          1152,
          3089,
          7318,
          13,
          50932
        ]
      },
      {
        "avg_logprob": -0.2468642388190423,
        "compression_ratio": 1.779467680608365,
        "end": 2419.42,
        "id": 973,
        "no_speech_prob": 0.06952948868274689,
        "seek": 240582,
        "start": 2417.1800000000003,
        "temperature": 0,
        "text": " You don't have to use machine learning.",
        "tokens": [
          50932,
          509,
          500,
          380,
          362,
          281,
          764,
          3479,
          2539,
          13,
          51044
        ]
      },
      {
        "avg_logprob": -0.2468642388190423,
        "compression_ratio": 1.779467680608365,
        "end": 2421.86,
        "id": 974,
        "no_speech_prob": 0.06952948868274689,
        "seek": 240582,
        "start": 2419.42,
        "temperature": 0,
        "text": " So that's kind of like the grab all for it all.",
        "tokens": [
          51044,
          407,
          300,
          311,
          733,
          295,
          411,
          264,
          4444,
          439,
          337,
          309,
          439,
          13,
          51166
        ]
      },
      {
        "avg_logprob": -0.2468642388190423,
        "compression_ratio": 1.779467680608365,
        "end": 2422.86,
        "id": 975,
        "no_speech_prob": 0.06952948868274689,
        "seek": 240582,
        "start": 2421.86,
        "temperature": 0,
        "text": " And then what was the other,",
        "tokens": [
          51166,
          400,
          550,
          437,
          390,
          264,
          661,
          11,
          51216
        ]
      },
      {
        "avg_logprob": -0.2468642388190423,
        "compression_ratio": 1.779467680608365,
        "end": 2423.98,
        "id": 976,
        "no_speech_prob": 0.06952948868274689,
        "seek": 240582,
        "start": 2422.86,
        "temperature": 0,
        "text": " the code words for it?",
        "tokens": [
          51216,
          264,
          3089,
          2283,
          337,
          309,
          30,
          51272
        ]
      },
      {
        "avg_logprob": -0.2468642388190423,
        "compression_ratio": 1.779467680608365,
        "end": 2425.9,
        "id": 977,
        "no_speech_prob": 0.06952948868274689,
        "seek": 240582,
        "start": 2423.98,
        "temperature": 0,
        "text": " So, oh boy, all these things are coming in.",
        "tokens": [
          51272,
          407,
          11,
          1954,
          3237,
          11,
          439,
          613,
          721,
          366,
          1348,
          294,
          13,
          51368
        ]
      },
      {
        "avg_logprob": -0.2468642388190423,
        "compression_ratio": 1.779467680608365,
        "end": 2429.3,
        "id": 978,
        "no_speech_prob": 0.06952948868274689,
        "seek": 240582,
        "start": 2425.9,
        "temperature": 0,
        "text": " AI, machine learning, deep learning, neural network.",
        "tokens": [
          51368,
          7318,
          11,
          3479,
          2539,
          11,
          2452,
          2539,
          11,
          18161,
          3209,
          13,
          51538
        ]
      },
      {
        "avg_logprob": -0.2468642388190423,
        "compression_ratio": 1.779467680608365,
        "end": 2430.86,
        "id": 979,
        "no_speech_prob": 0.06952948868274689,
        "seek": 240582,
        "start": 2429.3,
        "temperature": 0,
        "text": " Yeah, and so machine learning,",
        "tokens": [
          51538,
          865,
          11,
          293,
          370,
          3479,
          2539,
          11,
          51616
        ]
      },
      {
        "avg_logprob": -0.2468642388190423,
        "compression_ratio": 1.779467680608365,
        "end": 2433.5,
        "id": 980,
        "no_speech_prob": 0.06952948868274689,
        "seek": 240582,
        "start": 2430.86,
        "temperature": 0,
        "text": " I think is like the next level down.",
        "tokens": [
          51616,
          286,
          519,
          307,
          411,
          264,
          958,
          1496,
          760,
          13,
          51748
        ]
      },
      {
        "avg_logprob": -0.20277154907699704,
        "compression_ratio": 1.8686131386861313,
        "end": 2436.38,
        "id": 981,
        "no_speech_prob": 0.004536098800599575,
        "seek": 243350,
        "start": 2433.5,
        "temperature": 0,
        "text": " So you don't need to use a neural network",
        "tokens": [
          50364,
          407,
          291,
          500,
          380,
          643,
          281,
          764,
          257,
          18161,
          3209,
          50508
        ]
      },
      {
        "avg_logprob": -0.20277154907699704,
        "compression_ratio": 1.8686131386861313,
        "end": 2437.42,
        "id": 982,
        "no_speech_prob": 0.004536098800599575,
        "seek": 243350,
        "start": 2436.38,
        "temperature": 0,
        "text": " to do machine learning.",
        "tokens": [
          50508,
          281,
          360,
          3479,
          2539,
          13,
          50560
        ]
      },
      {
        "avg_logprob": -0.20277154907699704,
        "compression_ratio": 1.8686131386861313,
        "end": 2439.78,
        "id": 983,
        "no_speech_prob": 0.004536098800599575,
        "seek": 243350,
        "start": 2437.42,
        "temperature": 0,
        "text": " There are different ways that you can go about",
        "tokens": [
          50560,
          821,
          366,
          819,
          2098,
          300,
          291,
          393,
          352,
          466,
          50678
        ]
      },
      {
        "avg_logprob": -0.20277154907699704,
        "compression_ratio": 1.8686131386861313,
        "end": 2441.22,
        "id": 984,
        "no_speech_prob": 0.004536098800599575,
        "seek": 243350,
        "start": 2439.78,
        "temperature": 0,
        "text": " teaching a machine how to learn.",
        "tokens": [
          50678,
          4571,
          257,
          3479,
          577,
          281,
          1466,
          13,
          50750
        ]
      },
      {
        "avg_logprob": -0.20277154907699704,
        "compression_ratio": 1.8686131386861313,
        "end": 2444.18,
        "id": 985,
        "no_speech_prob": 0.004536098800599575,
        "seek": 243350,
        "start": 2441.22,
        "temperature": 0,
        "text": " One really good example is decision trees.",
        "tokens": [
          50750,
          1485,
          534,
          665,
          1365,
          307,
          3537,
          5852,
          13,
          50898
        ]
      },
      {
        "avg_logprob": -0.20277154907699704,
        "compression_ratio": 1.8686131386861313,
        "end": 2446.42,
        "id": 986,
        "no_speech_prob": 0.004536098800599575,
        "seek": 243350,
        "start": 2444.18,
        "temperature": 0,
        "text": " People have developed really complex decision trees",
        "tokens": [
          50898,
          3432,
          362,
          4743,
          534,
          3997,
          3537,
          5852,
          51010
        ]
      },
      {
        "avg_logprob": -0.20277154907699704,
        "compression_ratio": 1.8686131386861313,
        "end": 2449.22,
        "id": 987,
        "no_speech_prob": 0.004536098800599575,
        "seek": 243350,
        "start": 2446.42,
        "temperature": 0,
        "text": " and the machine just kind of explores the space",
        "tokens": [
          51010,
          293,
          264,
          3479,
          445,
          733,
          295,
          45473,
          264,
          1901,
          51150
        ]
      },
      {
        "avg_logprob": -0.20277154907699704,
        "compression_ratio": 1.8686131386861313,
        "end": 2452.22,
        "id": 988,
        "no_speech_prob": 0.004536098800599575,
        "seek": 243350,
        "start": 2449.22,
        "temperature": 0,
        "text": " and learns the best way to use this decision tree.",
        "tokens": [
          51150,
          293,
          27152,
          264,
          1151,
          636,
          281,
          764,
          341,
          3537,
          4230,
          13,
          51300
        ]
      },
      {
        "avg_logprob": -0.20277154907699704,
        "compression_ratio": 1.8686131386861313,
        "end": 2454.5,
        "id": 989,
        "no_speech_prob": 0.004536098800599575,
        "seek": 243350,
        "start": 2452.22,
        "temperature": 0,
        "text": " So that's another way of applying machine learning.",
        "tokens": [
          51300,
          407,
          300,
          311,
          1071,
          636,
          295,
          9275,
          3479,
          2539,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20277154907699704,
        "compression_ratio": 1.8686131386861313,
        "end": 2457.46,
        "id": 990,
        "no_speech_prob": 0.004536098800599575,
        "seek": 243350,
        "start": 2454.5,
        "temperature": 0,
        "text": " And then, what'd you say, neural network and deep learning?",
        "tokens": [
          51414,
          400,
          550,
          11,
          437,
          1116,
          291,
          584,
          11,
          18161,
          3209,
          293,
          2452,
          2539,
          30,
          51562
        ]
      },
      {
        "avg_logprob": -0.20277154907699704,
        "compression_ratio": 1.8686131386861313,
        "end": 2458.3,
        "id": 991,
        "no_speech_prob": 0.004536098800599575,
        "seek": 243350,
        "start": 2457.46,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          51562,
          1079,
          13,
          51604
        ]
      },
      {
        "avg_logprob": -0.20277154907699704,
        "compression_ratio": 1.8686131386861313,
        "end": 2460.9,
        "id": 992,
        "no_speech_prob": 0.004536098800599575,
        "seek": 243350,
        "start": 2458.3,
        "temperature": 0,
        "text": " Yeah, so neural networks is essentially what we showed.",
        "tokens": [
          51604,
          865,
          11,
          370,
          18161,
          9590,
          307,
          4476,
          437,
          321,
          4712,
          13,
          51734
        ]
      },
      {
        "avg_logprob": -0.2803066716049657,
        "compression_ratio": 1.745019920318725,
        "end": 2465.2200000000003,
        "id": 993,
        "no_speech_prob": 0.00009761429828358814,
        "seek": 246090,
        "start": 2460.9,
        "temperature": 0,
        "text": " And even that's kind of up to debate",
        "tokens": [
          50364,
          400,
          754,
          300,
          311,
          733,
          295,
          493,
          281,
          7958,
          50580
        ]
      },
      {
        "avg_logprob": -0.2803066716049657,
        "compression_ratio": 1.745019920318725,
        "end": 2468.14,
        "id": 994,
        "no_speech_prob": 0.00009761429828358814,
        "seek": 246090,
        "start": 2465.2200000000003,
        "temperature": 0,
        "text": " because recurrent neural networks are neural networks,",
        "tokens": [
          50580,
          570,
          18680,
          1753,
          18161,
          9590,
          366,
          18161,
          9590,
          11,
          50726
        ]
      },
      {
        "avg_logprob": -0.2803066716049657,
        "compression_ratio": 1.745019920318725,
        "end": 2473.14,
        "id": 995,
        "no_speech_prob": 0.00009761429828358814,
        "seek": 246090,
        "start": 2468.14,
        "temperature": 0,
        "text": " but they're not really neural networked,",
        "tokens": [
          50726,
          457,
          436,
          434,
          406,
          534,
          18161,
          3209,
          292,
          11,
          50976
        ]
      },
      {
        "avg_logprob": -0.2803066716049657,
        "compression_ratio": 1.745019920318725,
        "end": 2474.46,
        "id": 996,
        "no_speech_prob": 0.00009761429828358814,
        "seek": 246090,
        "start": 2473.26,
        "temperature": 0,
        "text": " you know, if that makes sense.",
        "tokens": [
          50982,
          291,
          458,
          11,
          498,
          300,
          1669,
          2020,
          13,
          51042
        ]
      },
      {
        "avg_logprob": -0.2803066716049657,
        "compression_ratio": 1.745019920318725,
        "end": 2475.9,
        "id": 997,
        "no_speech_prob": 0.00009761429828358814,
        "seek": 246090,
        "start": 2474.46,
        "temperature": 0,
        "text": " So I don't know.",
        "tokens": [
          51042,
          407,
          286,
          500,
          380,
          458,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2803066716049657,
        "compression_ratio": 1.745019920318725,
        "end": 2478.46,
        "id": 998,
        "no_speech_prob": 0.00009761429828358814,
        "seek": 246090,
        "start": 2477.26,
        "temperature": 0,
        "text": " If you say neural network,",
        "tokens": [
          51182,
          759,
          291,
          584,
          18161,
          3209,
          11,
          51242
        ]
      },
      {
        "avg_logprob": -0.2803066716049657,
        "compression_ratio": 1.745019920318725,
        "end": 2480.82,
        "id": 999,
        "no_speech_prob": 0.00009761429828358814,
        "seek": 246090,
        "start": 2478.46,
        "temperature": 0,
        "text": " people will know what you're talking about for the most part.",
        "tokens": [
          51242,
          561,
          486,
          458,
          437,
          291,
          434,
          1417,
          466,
          337,
          264,
          881,
          644,
          13,
          51360
        ]
      },
      {
        "avg_logprob": -0.2803066716049657,
        "compression_ratio": 1.745019920318725,
        "end": 2483.5,
        "id": 1000,
        "no_speech_prob": 0.00009761429828358814,
        "seek": 246090,
        "start": 2480.82,
        "temperature": 0,
        "text": " All right, I'm gonna try to give my take on this.",
        "tokens": [
          51360,
          1057,
          558,
          11,
          286,
          478,
          799,
          853,
          281,
          976,
          452,
          747,
          322,
          341,
          13,
          51494
        ]
      },
      {
        "avg_logprob": -0.2803066716049657,
        "compression_ratio": 1.745019920318725,
        "end": 2484.34,
        "id": 1001,
        "no_speech_prob": 0.00009761429828358814,
        "seek": 246090,
        "start": 2483.5,
        "temperature": 0,
        "text": " Let's see if I can do it.",
        "tokens": [
          51494,
          961,
          311,
          536,
          498,
          286,
          393,
          360,
          309,
          13,
          51536
        ]
      },
      {
        "avg_logprob": -0.2803066716049657,
        "compression_ratio": 1.745019920318725,
        "end": 2485.1800000000003,
        "id": 1002,
        "no_speech_prob": 0.00009761429828358814,
        "seek": 246090,
        "start": 2484.34,
        "temperature": 0,
        "text": " Let's do it.",
        "tokens": [
          51536,
          961,
          311,
          360,
          309,
          13,
          51578
        ]
      },
      {
        "avg_logprob": -0.2803066716049657,
        "compression_ratio": 1.745019920318725,
        "end": 2487.7400000000002,
        "id": 1003,
        "no_speech_prob": 0.00009761429828358814,
        "seek": 246090,
        "start": 2486.3,
        "temperature": 0,
        "text": " I forgot already what I was gonna say.",
        "tokens": [
          51634,
          286,
          5298,
          1217,
          437,
          286,
          390,
          799,
          584,
          13,
          51706
        ]
      },
      {
        "avg_logprob": -0.2803066716049657,
        "compression_ratio": 1.745019920318725,
        "end": 2489.1,
        "id": 1004,
        "no_speech_prob": 0.00009761429828358814,
        "seek": 246090,
        "start": 2487.7400000000002,
        "temperature": 0,
        "text": " Well, I think I would put neural network",
        "tokens": [
          51706,
          1042,
          11,
          286,
          519,
          286,
          576,
          829,
          18161,
          3209,
          51774
        ]
      },
      {
        "avg_logprob": -0.2544912099838257,
        "compression_ratio": 1.7877094972067038,
        "end": 2491.2599999999998,
        "id": 1005,
        "no_speech_prob": 0.06186797842383385,
        "seek": 248910,
        "start": 2489.14,
        "temperature": 0,
        "text": " in a different category than those other terms.",
        "tokens": [
          50366,
          294,
          257,
          819,
          7719,
          813,
          729,
          661,
          2115,
          13,
          50472
        ]
      },
      {
        "avg_logprob": -0.2544912099838257,
        "compression_ratio": 1.7877094972067038,
        "end": 2492.46,
        "id": 1006,
        "no_speech_prob": 0.06186797842383385,
        "seek": 248910,
        "start": 2491.2599999999998,
        "temperature": 0,
        "text": " Because to me, neural network-",
        "tokens": [
          50472,
          1436,
          281,
          385,
          11,
          18161,
          3209,
          12,
          50532
        ]
      },
      {
        "avg_logprob": -0.2544912099838257,
        "compression_ratio": 1.7877094972067038,
        "end": 2493.2999999999997,
        "id": 1007,
        "no_speech_prob": 0.06186797842383385,
        "seek": 248910,
        "start": 2492.46,
        "temperature": 0,
        "text": " I need to look at the camera.",
        "tokens": [
          50532,
          286,
          643,
          281,
          574,
          412,
          264,
          2799,
          13,
          50574
        ]
      },
      {
        "avg_logprob": -0.2544912099838257,
        "compression_ratio": 1.7877094972067038,
        "end": 2494.14,
        "id": 1008,
        "no_speech_prob": 0.06186797842383385,
        "seek": 248910,
        "start": 2493.2999999999997,
        "temperature": 0,
        "text": " I know, I don't know.",
        "tokens": [
          50574,
          286,
          458,
          11,
          286,
          500,
          380,
          458,
          13,
          50616
        ]
      },
      {
        "avg_logprob": -0.2544912099838257,
        "compression_ratio": 1.7877094972067038,
        "end": 2495.02,
        "id": 1009,
        "no_speech_prob": 0.06186797842383385,
        "seek": 248910,
        "start": 2494.14,
        "temperature": 0,
        "text": " I'm so bad.",
        "tokens": [
          50616,
          286,
          478,
          370,
          1578,
          13,
          50660
        ]
      },
      {
        "avg_logprob": -0.2544912099838257,
        "compression_ratio": 1.7877094972067038,
        "end": 2497.42,
        "id": 1010,
        "no_speech_prob": 0.06186797842383385,
        "seek": 248910,
        "start": 2495.02,
        "temperature": 0,
        "text": " I don't have a good, I wanted to get like",
        "tokens": [
          50660,
          286,
          500,
          380,
          362,
          257,
          665,
          11,
          286,
          1415,
          281,
          483,
          411,
          50780
        ]
      },
      {
        "avg_logprob": -0.2544912099838257,
        "compression_ratio": 1.7877094972067038,
        "end": 2500.06,
        "id": 1011,
        "no_speech_prob": 0.06186797842383385,
        "seek": 248910,
        "start": 2497.42,
        "temperature": 0,
        "text": " between the ferns like set up in here.",
        "tokens": [
          50780,
          1296,
          264,
          283,
          1248,
          82,
          411,
          992,
          493,
          294,
          510,
          13,
          50912
        ]
      },
      {
        "avg_logprob": -0.2544912099838257,
        "compression_ratio": 1.7877094972067038,
        "end": 2501.74,
        "id": 1012,
        "no_speech_prob": 0.06186797842383385,
        "seek": 248910,
        "start": 2500.06,
        "temperature": 0,
        "text": " Or I could get like a camera and some chairs,",
        "tokens": [
          50912,
          1610,
          286,
          727,
          483,
          411,
          257,
          2799,
          293,
          512,
          18299,
          11,
          50996
        ]
      },
      {
        "avg_logprob": -0.2544912099838257,
        "compression_ratio": 1.7877094972067038,
        "end": 2504.1,
        "id": 1013,
        "no_speech_prob": 0.06186797842383385,
        "seek": 248910,
        "start": 2501.74,
        "temperature": 0,
        "text": " a little coffee table and could have like a conversation.",
        "tokens": [
          50996,
          257,
          707,
          4982,
          3199,
          293,
          727,
          362,
          411,
          257,
          3761,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2544912099838257,
        "compression_ratio": 1.7877094972067038,
        "end": 2506.06,
        "id": 1014,
        "no_speech_prob": 0.06186797842383385,
        "seek": 248910,
        "start": 2504.1,
        "temperature": 0,
        "text": " But instead, it's just the awkward standing thing.",
        "tokens": [
          51114,
          583,
          2602,
          11,
          309,
          311,
          445,
          264,
          11411,
          4877,
          551,
          13,
          51212
        ]
      },
      {
        "avg_logprob": -0.2544912099838257,
        "compression_ratio": 1.7877094972067038,
        "end": 2508.7799999999997,
        "id": 1015,
        "no_speech_prob": 0.06186797842383385,
        "seek": 248910,
        "start": 2506.06,
        "temperature": 0,
        "text": " Somebody in the chat told me to put a mirror",
        "tokens": [
          51212,
          13463,
          294,
          264,
          5081,
          1907,
          385,
          281,
          829,
          257,
          8013,
          51348
        ]
      },
      {
        "avg_logprob": -0.2544912099838257,
        "compression_ratio": 1.7877094972067038,
        "end": 2509.7799999999997,
        "id": 1016,
        "no_speech_prob": 0.06186797842383385,
        "seek": 248910,
        "start": 2508.7799999999997,
        "temperature": 0,
        "text": " behind the camera.",
        "tokens": [
          51348,
          2261,
          264,
          2799,
          13,
          51398
        ]
      },
      {
        "avg_logprob": -0.2544912099838257,
        "compression_ratio": 1.7877094972067038,
        "end": 2511.14,
        "id": 1017,
        "no_speech_prob": 0.06186797842383385,
        "seek": 248910,
        "start": 2509.7799999999997,
        "temperature": 0,
        "text": " And then we're like talking to each other",
        "tokens": [
          51398,
          400,
          550,
          321,
          434,
          411,
          1417,
          281,
          1184,
          661,
          51466
        ]
      },
      {
        "avg_logprob": -0.2544912099838257,
        "compression_ratio": 1.7877094972067038,
        "end": 2511.98,
        "id": 1018,
        "no_speech_prob": 0.06186797842383385,
        "seek": 248910,
        "start": 2511.14,
        "temperature": 0,
        "text": " but looking at the mirror.",
        "tokens": [
          51466,
          457,
          1237,
          412,
          264,
          8013,
          13,
          51508
        ]
      },
      {
        "avg_logprob": -0.2544912099838257,
        "compression_ratio": 1.7877094972067038,
        "end": 2512.8199999999997,
        "id": 1019,
        "no_speech_prob": 0.06186797842383385,
        "seek": 248910,
        "start": 2511.98,
        "temperature": 0,
        "text": " I like that.",
        "tokens": [
          51508,
          286,
          411,
          300,
          13,
          51550
        ]
      },
      {
        "avg_logprob": -0.2544912099838257,
        "compression_ratio": 1.7877094972067038,
        "end": 2514.58,
        "id": 1020,
        "no_speech_prob": 0.06186797842383385,
        "seek": 248910,
        "start": 2512.8199999999997,
        "temperature": 0,
        "text": " That might be weird though if there's nobody else here.",
        "tokens": [
          51550,
          663,
          1062,
          312,
          3657,
          1673,
          498,
          456,
          311,
          5079,
          1646,
          510,
          13,
          51638
        ]
      },
      {
        "avg_logprob": -0.2544912099838257,
        "compression_ratio": 1.7877094972067038,
        "end": 2516.74,
        "id": 1021,
        "no_speech_prob": 0.06186797842383385,
        "seek": 248910,
        "start": 2514.58,
        "temperature": 0,
        "text": " I'm kind of egotistical.",
        "tokens": [
          51638,
          286,
          478,
          733,
          295,
          308,
          13178,
          42686,
          13,
          51746
        ]
      },
      {
        "avg_logprob": -0.2544912099838257,
        "compression_ratio": 1.7877094972067038,
        "end": 2518.7799999999997,
        "id": 1022,
        "no_speech_prob": 0.06186797842383385,
        "seek": 248910,
        "start": 2516.74,
        "temperature": 0,
        "text": " I used to have a screen over there",
        "tokens": [
          51746,
          286,
          1143,
          281,
          362,
          257,
          2568,
          670,
          456,
          51848
        ]
      },
      {
        "avg_logprob": -0.2727087631966304,
        "compression_ratio": 1.8081632653061224,
        "end": 2520.3,
        "id": 1023,
        "no_speech_prob": 0.0000017879618781080353,
        "seek": 251878,
        "start": 2519.46,
        "temperature": 0,
        "text": " and I would always stare at that.",
        "tokens": [
          50398,
          293,
          286,
          576,
          1009,
          22432,
          412,
          300,
          13,
          50440
        ]
      },
      {
        "avg_logprob": -0.2727087631966304,
        "compression_ratio": 1.8081632653061224,
        "end": 2523.9,
        "id": 1024,
        "no_speech_prob": 0.0000017879618781080353,
        "seek": 251878,
        "start": 2520.3,
        "temperature": 0,
        "text": " But anyway, so the reason, so neural network to me",
        "tokens": [
          50440,
          583,
          4033,
          11,
          370,
          264,
          1778,
          11,
          370,
          18161,
          3209,
          281,
          385,
          50620
        ]
      },
      {
        "avg_logprob": -0.2727087631966304,
        "compression_ratio": 1.8081632653061224,
        "end": 2528.9,
        "id": 1025,
        "no_speech_prob": 0.0000017879618781080353,
        "seek": 251878,
        "start": 2523.9,
        "temperature": 0,
        "text": " is a particular algorithm that involves connected nodes",
        "tokens": [
          50620,
          307,
          257,
          1729,
          9284,
          300,
          11626,
          4582,
          13891,
          50870
        ]
      },
      {
        "avg_logprob": -0.2727087631966304,
        "compression_ratio": 1.8081632653061224,
        "end": 2533.6200000000003,
        "id": 1026,
        "no_speech_prob": 0.0000017879618781080353,
        "seek": 251878,
        "start": 2531.2200000000003,
        "temperature": 0,
        "text": " and data flows from one node to the other.",
        "tokens": [
          50986,
          293,
          1412,
          12867,
          490,
          472,
          9984,
          281,
          264,
          661,
          13,
          51106
        ]
      },
      {
        "avg_logprob": -0.2727087631966304,
        "compression_ratio": 1.8081632653061224,
        "end": 2535.38,
        "id": 1027,
        "no_speech_prob": 0.0000017879618781080353,
        "seek": 251878,
        "start": 2533.6200000000003,
        "temperature": 0,
        "text": " And there could be different architectures and styles.",
        "tokens": [
          51106,
          400,
          456,
          727,
          312,
          819,
          6331,
          1303,
          293,
          13273,
          13,
          51194
        ]
      },
      {
        "avg_logprob": -0.2727087631966304,
        "compression_ratio": 1.8081632653061224,
        "end": 2539.3,
        "id": 1028,
        "no_speech_prob": 0.0000017879618781080353,
        "seek": 251878,
        "start": 2535.38,
        "temperature": 0,
        "text": " And so that neural network data structure algorithm",
        "tokens": [
          51194,
          400,
          370,
          300,
          18161,
          3209,
          1412,
          3877,
          9284,
          51390
        ]
      },
      {
        "avg_logprob": -0.2727087631966304,
        "compression_ratio": 1.8081632653061224,
        "end": 2543.5,
        "id": 1029,
        "no_speech_prob": 0.0000017879618781080353,
        "seek": 251878,
        "start": 2539.3,
        "temperature": 0,
        "text": " can be applied in the fields of artificial intelligence,",
        "tokens": [
          51390,
          393,
          312,
          6456,
          294,
          264,
          7909,
          295,
          11677,
          7599,
          11,
          51600
        ]
      },
      {
        "avg_logprob": -0.2727087631966304,
        "compression_ratio": 1.8081632653061224,
        "end": 2544.5400000000004,
        "id": 1030,
        "no_speech_prob": 0.0000017879618781080353,
        "seek": 251878,
        "start": 2543.5,
        "temperature": 0,
        "text": " machine learning and deep learning.",
        "tokens": [
          51600,
          3479,
          2539,
          293,
          2452,
          2539,
          13,
          51652
        ]
      },
      {
        "avg_logprob": -0.2727087631966304,
        "compression_ratio": 1.8081632653061224,
        "end": 2548.38,
        "id": 1031,
        "no_speech_prob": 0.0000017879618781080353,
        "seek": 251878,
        "start": 2544.5400000000004,
        "temperature": 0,
        "text": " But neural network is an example of a particular algorithm,",
        "tokens": [
          51652,
          583,
          18161,
          3209,
          307,
          364,
          1365,
          295,
          257,
          1729,
          9284,
          11,
          51844
        ]
      },
      {
        "avg_logprob": -0.26702574466137174,
        "compression_ratio": 1.6605504587155964,
        "end": 2551.1400000000003,
        "id": 1032,
        "no_speech_prob": 0.000005862237685505534,
        "seek": 254838,
        "start": 2549.02,
        "temperature": 0,
        "text": " you could sort of think of it also as a data structure,",
        "tokens": [
          50396,
          291,
          727,
          1333,
          295,
          519,
          295,
          309,
          611,
          382,
          257,
          1412,
          3877,
          11,
          50502
        ]
      },
      {
        "avg_logprob": -0.26702574466137174,
        "compression_ratio": 1.6605504587155964,
        "end": 2552.86,
        "id": 1033,
        "no_speech_prob": 0.000005862237685505534,
        "seek": 254838,
        "start": 2551.1400000000003,
        "temperature": 0,
        "text": " but there's an algorithm there in terms of",
        "tokens": [
          50502,
          457,
          456,
          311,
          364,
          9284,
          456,
          294,
          2115,
          295,
          50588
        ]
      },
      {
        "avg_logprob": -0.26702574466137174,
        "compression_ratio": 1.6605504587155964,
        "end": 2555.58,
        "id": 1034,
        "no_speech_prob": 0.000005862237685505534,
        "seek": 254838,
        "start": 2552.86,
        "temperature": 0,
        "text": " how the data flows through the structure.",
        "tokens": [
          50588,
          577,
          264,
          1412,
          12867,
          807,
          264,
          3877,
          13,
          50724
        ]
      },
      {
        "avg_logprob": -0.26702574466137174,
        "compression_ratio": 1.6605504587155964,
        "end": 2557.1800000000003,
        "id": 1035,
        "no_speech_prob": 0.000005862237685505534,
        "seek": 254838,
        "start": 2555.58,
        "temperature": 0,
        "text": " So that's what I think.",
        "tokens": [
          50724,
          407,
          300,
          311,
          437,
          286,
          519,
          13,
          50804
        ]
      },
      {
        "avg_logprob": -0.26702574466137174,
        "compression_ratio": 1.6605504587155964,
        "end": 2561.26,
        "id": 1036,
        "no_speech_prob": 0.000005862237685505534,
        "seek": 254838,
        "start": 2557.1800000000003,
        "temperature": 0,
        "text": " And then I think that, to me, artificial intelligence",
        "tokens": [
          50804,
          400,
          550,
          286,
          519,
          300,
          11,
          281,
          385,
          11,
          11677,
          7599,
          51008
        ]
      },
      {
        "avg_logprob": -0.26702574466137174,
        "compression_ratio": 1.6605504587155964,
        "end": 2564.62,
        "id": 1037,
        "no_speech_prob": 0.000005862237685505534,
        "seek": 254838,
        "start": 2561.26,
        "temperature": 0,
        "text": " is this umbrella term that is really just like,",
        "tokens": [
          51008,
          307,
          341,
          21925,
          1433,
          300,
          307,
          534,
          445,
          411,
          11,
          51176
        ]
      },
      {
        "avg_logprob": -0.26702574466137174,
        "compression_ratio": 1.6605504587155964,
        "end": 2569.62,
        "id": 1038,
        "no_speech_prob": 0.000005862237685505534,
        "seek": 254838,
        "start": 2564.62,
        "temperature": 0,
        "text": " hey, can computers and can technology have intelligence",
        "tokens": [
          51176,
          4177,
          11,
          393,
          10807,
          293,
          393,
          2899,
          362,
          7599,
          51426
        ]
      },
      {
        "avg_logprob": -0.26702574466137174,
        "compression_ratio": 1.6605504587155964,
        "end": 2572.2000000000003,
        "id": 1039,
        "no_speech_prob": 0.000005862237685505534,
        "seek": 254838,
        "start": 2569.86,
        "temperature": 0,
        "text": " like humans do and what does that mean?",
        "tokens": [
          51438,
          411,
          6255,
          360,
          293,
          437,
          775,
          300,
          914,
          30,
          51555
        ]
      },
      {
        "avg_logprob": -0.2844161655591882,
        "compression_ratio": 1.7106227106227105,
        "end": 2577.48,
        "id": 1040,
        "no_speech_prob": 0.000005858087206433993,
        "seek": 257220,
        "start": 2572.48,
        "temperature": 0,
        "text": " And apparently my technology is not intelligent enough",
        "tokens": [
          50378,
          400,
          7970,
          452,
          2899,
          307,
          406,
          13232,
          1547,
          50628
        ]
      },
      {
        "avg_logprob": -0.2844161655591882,
        "compression_ratio": 1.7106227106227105,
        "end": 2581.2799999999997,
        "id": 1041,
        "no_speech_prob": 0.000005858087206433993,
        "seek": 257220,
        "start": 2578.4399999999996,
        "temperature": 0,
        "text": " to record a video for more than 30 minutes at a time.",
        "tokens": [
          50676,
          281,
          2136,
          257,
          960,
          337,
          544,
          813,
          2217,
          2077,
          412,
          257,
          565,
          13,
          50818
        ]
      },
      {
        "avg_logprob": -0.2844161655591882,
        "compression_ratio": 1.7106227106227105,
        "end": 2584.96,
        "id": 1042,
        "no_speech_prob": 0.000005858087206433993,
        "seek": 257220,
        "start": 2582.7999999999997,
        "temperature": 0,
        "text": " So I think of that as a very broad umbrella term",
        "tokens": [
          50894,
          407,
          286,
          519,
          295,
          300,
          382,
          257,
          588,
          4152,
          21925,
          1433,
          51002
        ]
      },
      {
        "avg_logprob": -0.2844161655591882,
        "compression_ratio": 1.7106227106227105,
        "end": 2587.72,
        "id": 1043,
        "no_speech_prob": 0.000005858087206433993,
        "seek": 257220,
        "start": 2584.96,
        "temperature": 0,
        "text": " to just the big field of like simulated intelligence.",
        "tokens": [
          51002,
          281,
          445,
          264,
          955,
          2519,
          295,
          411,
          41713,
          7599,
          13,
          51140
        ]
      },
      {
        "avg_logprob": -0.2844161655591882,
        "compression_ratio": 1.7106227106227105,
        "end": 2589.68,
        "id": 1044,
        "no_speech_prob": 0.000005858087206433993,
        "seek": 257220,
        "start": 2587.72,
        "temperature": 0,
        "text": " Whether is that, is it real intelligence?",
        "tokens": [
          51140,
          8503,
          307,
          300,
          11,
          307,
          309,
          957,
          7599,
          30,
          51238
        ]
      },
      {
        "avg_logprob": -0.2844161655591882,
        "compression_ratio": 1.7106227106227105,
        "end": 2590.8799999999997,
        "id": 1045,
        "no_speech_prob": 0.000005858087206433993,
        "seek": 257220,
        "start": 2589.68,
        "temperature": 0,
        "text": " Is it the illusion of intelligence?",
        "tokens": [
          51238,
          1119,
          309,
          264,
          18854,
          295,
          7599,
          30,
          51298
        ]
      },
      {
        "avg_logprob": -0.2844161655591882,
        "compression_ratio": 1.7106227106227105,
        "end": 2591.72,
        "id": 1046,
        "no_speech_prob": 0.000005858087206433993,
        "seek": 257220,
        "start": 2590.8799999999997,
        "temperature": 0,
        "text": " Is that the same thing?",
        "tokens": [
          51298,
          1119,
          300,
          264,
          912,
          551,
          30,
          51340
        ]
      },
      {
        "avg_logprob": -0.2844161655591882,
        "compression_ratio": 1.7106227106227105,
        "end": 2594.7599999999998,
        "id": 1047,
        "no_speech_prob": 0.000005858087206433993,
        "seek": 257220,
        "start": 2591.72,
        "temperature": 0,
        "text": " It's like kind of a deep philosophical question.",
        "tokens": [
          51340,
          467,
          311,
          411,
          733,
          295,
          257,
          2452,
          25066,
          1168,
          13,
          51492
        ]
      },
      {
        "avg_logprob": -0.2844161655591882,
        "compression_ratio": 1.7106227106227105,
        "end": 2598.2,
        "id": 1048,
        "no_speech_prob": 0.000005858087206433993,
        "seek": 257220,
        "start": 2594.7599999999998,
        "temperature": 0,
        "text": " And then machine learning to me is a subfield",
        "tokens": [
          51492,
          400,
          550,
          3479,
          2539,
          281,
          385,
          307,
          257,
          1422,
          7610,
          51664
        ]
      },
      {
        "avg_logprob": -0.2844161655591882,
        "compression_ratio": 1.7106227106227105,
        "end": 2602.1,
        "id": 1049,
        "no_speech_prob": 0.000005858087206433993,
        "seek": 257220,
        "start": 2598.2,
        "temperature": 0,
        "text": " of artificial intelligence involving making sense of data.",
        "tokens": [
          51664,
          295,
          11677,
          7599,
          17030,
          1455,
          2020,
          295,
          1412,
          13,
          51859
        ]
      },
      {
        "avg_logprob": -0.25355073567983266,
        "compression_ratio": 1.7914110429447854,
        "end": 2605.1,
        "id": 1050,
        "no_speech_prob": 0.000013210589713708032,
        "seek": 260210,
        "start": 2603,
        "temperature": 0,
        "text": " So you have data and that's input to a system",
        "tokens": [
          50409,
          407,
          291,
          362,
          1412,
          293,
          300,
          311,
          4846,
          281,
          257,
          1185,
          50514
        ]
      },
      {
        "avg_logprob": -0.25355073567983266,
        "compression_ratio": 1.7914110429447854,
        "end": 2607.3399999999997,
        "id": 1051,
        "no_speech_prob": 0.000013210589713708032,
        "seek": 260210,
        "start": 2605.1,
        "temperature": 0,
        "text": " and you have some output which might be making sense",
        "tokens": [
          50514,
          293,
          291,
          362,
          512,
          5598,
          597,
          1062,
          312,
          1455,
          2020,
          50626
        ]
      },
      {
        "avg_logprob": -0.25355073567983266,
        "compression_ratio": 1.7914110429447854,
        "end": 2608.98,
        "id": 1052,
        "no_speech_prob": 0.000013210589713708032,
        "seek": 260210,
        "start": 2607.3399999999997,
        "temperature": 0,
        "text": " of that data whether it's a prediction",
        "tokens": [
          50626,
          295,
          300,
          1412,
          1968,
          309,
          311,
          257,
          17630,
          50708
        ]
      },
      {
        "avg_logprob": -0.25355073567983266,
        "compression_ratio": 1.7914110429447854,
        "end": 2610.46,
        "id": 1053,
        "no_speech_prob": 0.000013210589713708032,
        "seek": 260210,
        "start": 2608.98,
        "temperature": 0,
        "text": " for something that's gonna happen in the future",
        "tokens": [
          50708,
          337,
          746,
          300,
          311,
          799,
          1051,
          294,
          264,
          2027,
          50782
        ]
      },
      {
        "avg_logprob": -0.25355073567983266,
        "compression_ratio": 1.7914110429447854,
        "end": 2612.3399999999997,
        "id": 1054,
        "no_speech_prob": 0.000013210589713708032,
        "seek": 260210,
        "start": 2610.46,
        "temperature": 0,
        "text": " or a classification of something.",
        "tokens": [
          50782,
          420,
          257,
          21538,
          295,
          746,
          13,
          50876
        ]
      },
      {
        "avg_logprob": -0.25355073567983266,
        "compression_ratio": 1.7914110429447854,
        "end": 2617.3399999999997,
        "id": 1055,
        "no_speech_prob": 0.000013210589713708032,
        "seek": 260210,
        "start": 2612.3399999999997,
        "temperature": 0,
        "text": " And then I think of deep learning as a kind of,",
        "tokens": [
          50876,
          400,
          550,
          286,
          519,
          295,
          2452,
          2539,
          382,
          257,
          733,
          295,
          11,
          51126
        ]
      },
      {
        "avg_logprob": -0.25355073567983266,
        "compression_ratio": 1.7914110429447854,
        "end": 2619.66,
        "id": 1056,
        "no_speech_prob": 0.000013210589713708032,
        "seek": 260210,
        "start": 2617.8199999999997,
        "temperature": 0,
        "text": " almost like a modern rebranding",
        "tokens": [
          51150,
          1920,
          411,
          257,
          4363,
          12970,
          3699,
          278,
          51242
        ]
      },
      {
        "avg_logprob": -0.25355073567983266,
        "compression_ratio": 1.7914110429447854,
        "end": 2621.62,
        "id": 1057,
        "no_speech_prob": 0.000013210589713708032,
        "seek": 260210,
        "start": 2619.66,
        "temperature": 0,
        "text": " of machine learning with neural networks.",
        "tokens": [
          51242,
          295,
          3479,
          2539,
          365,
          18161,
          9590,
          13,
          51340
        ]
      },
      {
        "avg_logprob": -0.25355073567983266,
        "compression_ratio": 1.7914110429447854,
        "end": 2623.9,
        "id": 1058,
        "no_speech_prob": 0.000013210589713708032,
        "seek": 260210,
        "start": 2621.62,
        "temperature": 0,
        "text": " That's like, hey, we have bigger data sets now",
        "tokens": [
          51340,
          663,
          311,
          411,
          11,
          4177,
          11,
          321,
          362,
          3801,
          1412,
          6352,
          586,
          51454
        ]
      },
      {
        "avg_logprob": -0.25355073567983266,
        "compression_ratio": 1.7914110429447854,
        "end": 2625.42,
        "id": 1059,
        "no_speech_prob": 0.000013210589713708032,
        "seek": 260210,
        "start": 2623.9,
        "temperature": 0,
        "text": " and faster computers now.",
        "tokens": [
          51454,
          293,
          4663,
          10807,
          586,
          13,
          51530
        ]
      },
      {
        "avg_logprob": -0.25355073567983266,
        "compression_ratio": 1.7914110429447854,
        "end": 2627.54,
        "id": 1060,
        "no_speech_prob": 0.000013210589713708032,
        "seek": 260210,
        "start": 2625.42,
        "temperature": 0,
        "text": " All of a sudden, the things that people researched",
        "tokens": [
          51530,
          1057,
          295,
          257,
          3990,
          11,
          264,
          721,
          300,
          561,
          37098,
          51636
        ]
      },
      {
        "avg_logprob": -0.25355073567983266,
        "compression_ratio": 1.7914110429447854,
        "end": 2629.2,
        "id": 1061,
        "no_speech_prob": 0.000013210589713708032,
        "seek": 260210,
        "start": 2627.54,
        "temperature": 0,
        "text": " many years ago called neural networks",
        "tokens": [
          51636,
          867,
          924,
          2057,
          1219,
          18161,
          9590,
          51719
        ]
      },
      {
        "avg_logprob": -0.25355073567983266,
        "compression_ratio": 1.7914110429447854,
        "end": 2630.58,
        "id": 1062,
        "no_speech_prob": 0.000013210589713708032,
        "seek": 260210,
        "start": 2629.2,
        "temperature": 0,
        "text": " that nobody thought could really do anything",
        "tokens": [
          51719,
          300,
          5079,
          1194,
          727,
          534,
          360,
          1340,
          51788
        ]
      },
      {
        "avg_logprob": -0.25355073567983266,
        "compression_ratio": 1.7914110429447854,
        "end": 2632.04,
        "id": 1063,
        "no_speech_prob": 0.000013210589713708032,
        "seek": 260210,
        "start": 2630.58,
        "temperature": 0,
        "text": " or they thought could but couldn't,",
        "tokens": [
          51788,
          420,
          436,
          1194,
          727,
          457,
          2809,
          380,
          11,
          51861
        ]
      },
      {
        "avg_logprob": -0.28292449848763895,
        "compression_ratio": 1.7762237762237763,
        "end": 2634.84,
        "id": 1064,
        "no_speech_prob": 0.000056494667660444975,
        "seek": 263204,
        "start": 2632.98,
        "temperature": 0,
        "text": " now all of a sudden, we can do more of them with.",
        "tokens": [
          50411,
          586,
          439,
          295,
          257,
          3990,
          11,
          321,
          393,
          360,
          544,
          295,
          552,
          365,
          13,
          50504
        ]
      },
      {
        "avg_logprob": -0.28292449848763895,
        "compression_ratio": 1.7762237762237763,
        "end": 2637.08,
        "id": 1065,
        "no_speech_prob": 0.000056494667660444975,
        "seek": 263204,
        "start": 2634.84,
        "temperature": 0,
        "text": " And so it's really just like,",
        "tokens": [
          50504,
          400,
          370,
          309,
          311,
          534,
          445,
          411,
          11,
          50616
        ]
      },
      {
        "avg_logprob": -0.28292449848763895,
        "compression_ratio": 1.7762237762237763,
        "end": 2638.56,
        "id": 1066,
        "no_speech_prob": 0.000056494667660444975,
        "seek": 263204,
        "start": 2637.08,
        "temperature": 0,
        "text": " I mean it's not meant to be marketing",
        "tokens": [
          50616,
          286,
          914,
          309,
          311,
          406,
          4140,
          281,
          312,
          6370,
          50690
        ]
      },
      {
        "avg_logprob": -0.28292449848763895,
        "compression_ratio": 1.7762237762237763,
        "end": 2640.4,
        "id": 1067,
        "no_speech_prob": 0.000056494667660444975,
        "seek": 263204,
        "start": 2638.56,
        "temperature": 0,
        "text": " but it's kind of like marketing this idea",
        "tokens": [
          50690,
          457,
          309,
          311,
          733,
          295,
          411,
          6370,
          341,
          1558,
          50782
        ]
      },
      {
        "avg_logprob": -0.28292449848763895,
        "compression_ratio": 1.7762237762237763,
        "end": 2642.92,
        "id": 1068,
        "no_speech_prob": 0.000056494667660444975,
        "seek": 263204,
        "start": 2640.4,
        "temperature": 0,
        "text": " of big data, neural networks.",
        "tokens": [
          50782,
          295,
          955,
          1412,
          11,
          18161,
          9590,
          13,
          50908
        ]
      },
      {
        "avg_logprob": -0.28292449848763895,
        "compression_ratio": 1.7762237762237763,
        "end": 2644.16,
        "id": 1069,
        "no_speech_prob": 0.000056494667660444975,
        "seek": 263204,
        "start": 2642.92,
        "temperature": 0,
        "text": " Yeah, I agree.",
        "tokens": [
          50908,
          865,
          11,
          286,
          3986,
          13,
          50970
        ]
      },
      {
        "avg_logprob": -0.28292449848763895,
        "compression_ratio": 1.7762237762237763,
        "end": 2646.72,
        "id": 1070,
        "no_speech_prob": 0.000056494667660444975,
        "seek": 263204,
        "start": 2644.16,
        "temperature": 0,
        "text": " I think it's a lot of the marketing side of things",
        "tokens": [
          50970,
          286,
          519,
          309,
          311,
          257,
          688,
          295,
          264,
          6370,
          1252,
          295,
          721,
          51098
        ]
      },
      {
        "avg_logprob": -0.28292449848763895,
        "compression_ratio": 1.7762237762237763,
        "end": 2648.44,
        "id": 1071,
        "no_speech_prob": 0.000056494667660444975,
        "seek": 263204,
        "start": 2646.72,
        "temperature": 0,
        "text": " because you'll read so many different posts",
        "tokens": [
          51098,
          570,
          291,
          603,
          1401,
          370,
          867,
          819,
          12300,
          51184
        ]
      },
      {
        "avg_logprob": -0.28292449848763895,
        "compression_ratio": 1.7762237762237763,
        "end": 2649.88,
        "id": 1072,
        "no_speech_prob": 0.000056494667660444975,
        "seek": 263204,
        "start": 2648.44,
        "temperature": 0,
        "text": " like what's the difference between deep learning",
        "tokens": [
          51184,
          411,
          437,
          311,
          264,
          2649,
          1296,
          2452,
          2539,
          51256
        ]
      },
      {
        "avg_logprob": -0.28292449848763895,
        "compression_ratio": 1.7762237762237763,
        "end": 2651.12,
        "id": 1073,
        "no_speech_prob": 0.000056494667660444975,
        "seek": 263204,
        "start": 2649.88,
        "temperature": 0,
        "text": " and machine learning?",
        "tokens": [
          51256,
          293,
          3479,
          2539,
          30,
          51318
        ]
      },
      {
        "avg_logprob": -0.28292449848763895,
        "compression_ratio": 1.7762237762237763,
        "end": 2652.82,
        "id": 1074,
        "no_speech_prob": 0.000056494667660444975,
        "seek": 263204,
        "start": 2651.12,
        "temperature": 0,
        "text": " It has two hidden layers.",
        "tokens": [
          51318,
          467,
          575,
          732,
          7633,
          7914,
          13,
          51403
        ]
      },
      {
        "avg_logprob": -0.28292449848763895,
        "compression_ratio": 1.7762237762237763,
        "end": 2653.72,
        "id": 1075,
        "no_speech_prob": 0.000056494667660444975,
        "seek": 263204,
        "start": 2652.82,
        "temperature": 0,
        "text": " That's it?",
        "tokens": [
          51403,
          663,
          311,
          309,
          30,
          51448
        ]
      },
      {
        "avg_logprob": -0.28292449848763895,
        "compression_ratio": 1.7762237762237763,
        "end": 2655.16,
        "id": 1076,
        "no_speech_prob": 0.000056494667660444975,
        "seek": 263204,
        "start": 2653.72,
        "temperature": 0,
        "text": " Yeah, like literally.",
        "tokens": [
          51448,
          865,
          11,
          411,
          3736,
          13,
          51520
        ]
      },
      {
        "avg_logprob": -0.28292449848763895,
        "compression_ratio": 1.7762237762237763,
        "end": 2657.32,
        "id": 1077,
        "no_speech_prob": 0.000056494667660444975,
        "seek": 263204,
        "start": 2655.16,
        "temperature": 0,
        "text": " I think it's more the marketing side, my personal opinion.",
        "tokens": [
          51520,
          286,
          519,
          309,
          311,
          544,
          264,
          6370,
          1252,
          11,
          452,
          2973,
          4800,
          13,
          51628
        ]
      },
      {
        "avg_logprob": -0.28292449848763895,
        "compression_ratio": 1.7762237762237763,
        "end": 2659.12,
        "id": 1078,
        "no_speech_prob": 0.000056494667660444975,
        "seek": 263204,
        "start": 2657.32,
        "temperature": 0,
        "text": " But that's awesome.",
        "tokens": [
          51628,
          583,
          300,
          311,
          3476,
          13,
          51718
        ]
      },
      {
        "avg_logprob": -0.2487192594088041,
        "compression_ratio": 1.7470355731225296,
        "end": 2660.12,
        "id": 1079,
        "no_speech_prob": 0.0000809270131867379,
        "seek": 265912,
        "start": 2659.12,
        "temperature": 0,
        "text": " Cool.",
        "tokens": [
          50364,
          8561,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.2487192594088041,
        "compression_ratio": 1.7470355731225296,
        "end": 2662.12,
        "id": 1080,
        "no_speech_prob": 0.0000809270131867379,
        "seek": 265912,
        "start": 2660.12,
        "temperature": 0,
        "text": " Let me see if we have any other.",
        "tokens": [
          50414,
          961,
          385,
          536,
          498,
          321,
          362,
          604,
          661,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2487192594088041,
        "compression_ratio": 1.7470355731225296,
        "end": 2664.52,
        "id": 1081,
        "no_speech_prob": 0.0000809270131867379,
        "seek": 265912,
        "start": 2662.12,
        "temperature": 0,
        "text": " Oh yeah, neural network, I like this definition.",
        "tokens": [
          50514,
          876,
          1338,
          11,
          18161,
          3209,
          11,
          286,
          411,
          341,
          7123,
          13,
          50634
        ]
      },
      {
        "avg_logprob": -0.2487192594088041,
        "compression_ratio": 1.7470355731225296,
        "end": 2668.16,
        "id": 1082,
        "no_speech_prob": 0.0000809270131867379,
        "seek": 265912,
        "start": 2664.52,
        "temperature": 0,
        "text": " Neural network is a universal function approximator.",
        "tokens": [
          50634,
          1734,
          1807,
          3209,
          307,
          257,
          11455,
          2445,
          8542,
          1639,
          13,
          50816
        ]
      },
      {
        "avg_logprob": -0.2487192594088041,
        "compression_ratio": 1.7470355731225296,
        "end": 2671.72,
        "id": 1083,
        "no_speech_prob": 0.0000809270131867379,
        "seek": 265912,
        "start": 2668.16,
        "temperature": 0,
        "text": " I actually, this is actually like a really,",
        "tokens": [
          50816,
          286,
          767,
          11,
          341,
          307,
          767,
          411,
          257,
          534,
          11,
          50994
        ]
      },
      {
        "avg_logprob": -0.2487192594088041,
        "compression_ratio": 1.7470355731225296,
        "end": 2674.16,
        "id": 1084,
        "no_speech_prob": 0.0000809270131867379,
        "seek": 265912,
        "start": 2671.72,
        "temperature": 0,
        "text": " this is Robin, I'm gonna, hello, let's try this.",
        "tokens": [
          50994,
          341,
          307,
          16533,
          11,
          286,
          478,
          799,
          11,
          7751,
          11,
          718,
          311,
          853,
          341,
          13,
          51116
        ]
      },
      {
        "avg_logprob": -0.2487192594088041,
        "compression_ratio": 1.7470355731225296,
        "end": 2675.16,
        "id": 1085,
        "no_speech_prob": 0.0000809270131867379,
        "seek": 265912,
        "start": 2674.16,
        "temperature": 0,
        "text": " Oh, this is crazy talk.",
        "tokens": [
          51116,
          876,
          11,
          341,
          307,
          3219,
          751,
          13,
          51166
        ]
      },
      {
        "avg_logprob": -0.2487192594088041,
        "compression_ratio": 1.7470355731225296,
        "end": 2676.56,
        "id": 1086,
        "no_speech_prob": 0.0000809270131867379,
        "seek": 265912,
        "start": 2675.16,
        "temperature": 0,
        "text": " Now I'm coming over here.",
        "tokens": [
          51166,
          823,
          286,
          478,
          1348,
          670,
          510,
          13,
          51236
        ]
      },
      {
        "avg_logprob": -0.2487192594088041,
        "compression_ratio": 1.7470355731225296,
        "end": 2678.4,
        "id": 1087,
        "no_speech_prob": 0.0000809270131867379,
        "seek": 265912,
        "start": 2676.56,
        "temperature": 0,
        "text": " I actually think this is really kind of a good way",
        "tokens": [
          51236,
          286,
          767,
          519,
          341,
          307,
          534,
          733,
          295,
          257,
          665,
          636,
          51328
        ]
      },
      {
        "avg_logprob": -0.2487192594088041,
        "compression_ratio": 1.7470355731225296,
        "end": 2679.24,
        "id": 1088,
        "no_speech_prob": 0.0000809270131867379,
        "seek": 265912,
        "start": 2678.4,
        "temperature": 0,
        "text": " to think about it.",
        "tokens": [
          51328,
          281,
          519,
          466,
          309,
          13,
          51370
        ]
      },
      {
        "avg_logprob": -0.2487192594088041,
        "compression_ratio": 1.7470355731225296,
        "end": 2680.44,
        "id": 1089,
        "no_speech_prob": 0.0000809270131867379,
        "seek": 265912,
        "start": 2679.24,
        "temperature": 0,
        "text": " I was thinking about this the other day",
        "tokens": [
          51370,
          286,
          390,
          1953,
          466,
          341,
          264,
          661,
          786,
          51430
        ]
      },
      {
        "avg_logprob": -0.2487192594088041,
        "compression_ratio": 1.7470355731225296,
        "end": 2685.44,
        "id": 1090,
        "no_speech_prob": 0.0000809270131867379,
        "seek": 265912,
        "start": 2680.44,
        "temperature": 0,
        "text": " because what if we made function color predictor",
        "tokens": [
          51430,
          570,
          437,
          498,
          321,
          1027,
          2445,
          2017,
          6069,
          284,
          51680
        ]
      },
      {
        "avg_logprob": -0.2715267302497985,
        "compression_ratio": 1.796812749003984,
        "end": 2690,
        "id": 1091,
        "no_speech_prob": 0.000009971893632609863,
        "seek": 268544,
        "start": 2686,
        "temperature": 0,
        "text": " and we just had like an if statement in there",
        "tokens": [
          50392,
          293,
          321,
          445,
          632,
          411,
          364,
          498,
          5629,
          294,
          456,
          50592
        ]
      },
      {
        "avg_logprob": -0.2715267302497985,
        "compression_ratio": 1.796812749003984,
        "end": 2692.16,
        "id": 1092,
        "no_speech_prob": 0.000009971893632609863,
        "seek": 268544,
        "start": 2690,
        "temperature": 0,
        "text": " and you give it a color.",
        "tokens": [
          50592,
          293,
          291,
          976,
          309,
          257,
          2017,
          13,
          50700
        ]
      },
      {
        "avg_logprob": -0.2715267302497985,
        "compression_ratio": 1.796812749003984,
        "end": 2695.08,
        "id": 1093,
        "no_speech_prob": 0.000009971893632609863,
        "seek": 268544,
        "start": 2692.16,
        "temperature": 0,
        "text": " So if the brightness, blah, blah, blah,",
        "tokens": [
          50700,
          407,
          498,
          264,
          21367,
          11,
          12288,
          11,
          12288,
          11,
          12288,
          11,
          50846
        ]
      },
      {
        "avg_logprob": -0.2715267302497985,
        "compression_ratio": 1.796812749003984,
        "end": 2698.04,
        "id": 1094,
        "no_speech_prob": 0.000009971893632609863,
        "seek": 268544,
        "start": 2695.08,
        "temperature": 0,
        "text": " of that color is greater than some value,",
        "tokens": [
          50846,
          295,
          300,
          2017,
          307,
          5044,
          813,
          512,
          2158,
          11,
          50994
        ]
      },
      {
        "avg_logprob": -0.2715267302497985,
        "compression_ratio": 1.796812749003984,
        "end": 2699.96,
        "id": 1095,
        "no_speech_prob": 0.000009971893632609863,
        "seek": 268544,
        "start": 2698.04,
        "temperature": 0,
        "text": " then you should put black on that color",
        "tokens": [
          50994,
          550,
          291,
          820,
          829,
          2211,
          322,
          300,
          2017,
          51090
        ]
      },
      {
        "avg_logprob": -0.2715267302497985,
        "compression_ratio": 1.796812749003984,
        "end": 2701.8,
        "id": 1096,
        "no_speech_prob": 0.000009971893632609863,
        "seek": 268544,
        "start": 2699.96,
        "temperature": 0,
        "text": " or white on that color otherwise.",
        "tokens": [
          51090,
          420,
          2418,
          322,
          300,
          2017,
          5911,
          13,
          51182
        ]
      },
      {
        "avg_logprob": -0.2715267302497985,
        "compression_ratio": 1.796812749003984,
        "end": 2704.92,
        "id": 1097,
        "no_speech_prob": 0.000009971893632609863,
        "seek": 268544,
        "start": 2701.8,
        "temperature": 0,
        "text": " So this is like a hard coded function",
        "tokens": [
          51182,
          407,
          341,
          307,
          411,
          257,
          1152,
          34874,
          2445,
          51338
        ]
      },
      {
        "avg_logprob": -0.2715267302497985,
        "compression_ratio": 1.796812749003984,
        "end": 2707,
        "id": 1098,
        "no_speech_prob": 0.000009971893632609863,
        "seek": 268544,
        "start": 2704.92,
        "temperature": 0,
        "text": " that takes inputs and returns an output.",
        "tokens": [
          51338,
          300,
          2516,
          15743,
          293,
          11247,
          364,
          5598,
          13,
          51442
        ]
      },
      {
        "avg_logprob": -0.2715267302497985,
        "compression_ratio": 1.796812749003984,
        "end": 2707.92,
        "id": 1099,
        "no_speech_prob": 0.000009971893632609863,
        "seek": 268544,
        "start": 2707,
        "temperature": 0,
        "text": " Right.",
        "tokens": [
          51442,
          1779,
          13,
          51488
        ]
      },
      {
        "avg_logprob": -0.2715267302497985,
        "compression_ratio": 1.796812749003984,
        "end": 2710.2400000000002,
        "id": 1100,
        "no_speech_prob": 0.000009971893632609863,
        "seek": 268544,
        "start": 2707.92,
        "temperature": 0,
        "text": " And so we could write a lot of if statements.",
        "tokens": [
          51488,
          400,
          370,
          321,
          727,
          2464,
          257,
          688,
          295,
          498,
          12363,
          13,
          51604
        ]
      },
      {
        "avg_logprob": -0.2715267302497985,
        "compression_ratio": 1.796812749003984,
        "end": 2711.96,
        "id": 1101,
        "no_speech_prob": 0.000009971893632609863,
        "seek": 268544,
        "start": 2710.2400000000002,
        "temperature": 0,
        "text": " We could get really crazy complicated about this.",
        "tokens": [
          51604,
          492,
          727,
          483,
          534,
          3219,
          6179,
          466,
          341,
          13,
          51690
        ]
      },
      {
        "avg_logprob": -0.2715267302497985,
        "compression_ratio": 1.796812749003984,
        "end": 2713.84,
        "id": 1102,
        "no_speech_prob": 0.000009971893632609863,
        "seek": 268544,
        "start": 2711.96,
        "temperature": 0,
        "text": " We could come up with a whole set of rules",
        "tokens": [
          51690,
          492,
          727,
          808,
          493,
          365,
          257,
          1379,
          992,
          295,
          4474,
          51784
        ]
      },
      {
        "avg_logprob": -0.27995100366063863,
        "compression_ratio": 1.9364548494983278,
        "end": 2715.6400000000003,
        "id": 1103,
        "no_speech_prob": 0.000002058026211670949,
        "seek": 271384,
        "start": 2713.88,
        "temperature": 0,
        "text": " and a neural network in a way is a thing",
        "tokens": [
          50366,
          293,
          257,
          18161,
          3209,
          294,
          257,
          636,
          307,
          257,
          551,
          50454
        ]
      },
      {
        "avg_logprob": -0.27995100366063863,
        "compression_ratio": 1.9364548494983278,
        "end": 2718.1200000000003,
        "id": 1104,
        "no_speech_prob": 0.000002058026211670949,
        "seek": 271384,
        "start": 2715.6400000000003,
        "temperature": 0,
        "text": " that you could put in here to kind of learn",
        "tokens": [
          50454,
          300,
          291,
          727,
          829,
          294,
          510,
          281,
          733,
          295,
          1466,
          50578
        ]
      },
      {
        "avg_logprob": -0.27995100366063863,
        "compression_ratio": 1.9364548494983278,
        "end": 2720.52,
        "id": 1105,
        "no_speech_prob": 0.000002058026211670949,
        "seek": 271384,
        "start": 2718.1200000000003,
        "temperature": 0,
        "text": " to return the value according to,",
        "tokens": [
          50578,
          281,
          2736,
          264,
          2158,
          4650,
          281,
          11,
          50698
        ]
      },
      {
        "avg_logprob": -0.27995100366063863,
        "compression_ratio": 1.9364548494983278,
        "end": 2722.2400000000002,
        "id": 1106,
        "no_speech_prob": 0.000002058026211670949,
        "seek": 271384,
        "start": 2720.52,
        "temperature": 0,
        "text": " in a more mysterious way in a way,",
        "tokens": [
          50698,
          294,
          257,
          544,
          13831,
          636,
          294,
          257,
          636,
          11,
          50784
        ]
      },
      {
        "avg_logprob": -0.27995100366063863,
        "compression_ratio": 1.9364548494983278,
        "end": 2723.48,
        "id": 1107,
        "no_speech_prob": 0.000002058026211670949,
        "seek": 271384,
        "start": 2722.2400000000002,
        "temperature": 0,
        "text": " like in a sense.",
        "tokens": [
          50784,
          411,
          294,
          257,
          2020,
          13,
          50846
        ]
      },
      {
        "avg_logprob": -0.27995100366063863,
        "compression_ratio": 1.9364548494983278,
        "end": 2726.28,
        "id": 1108,
        "no_speech_prob": 0.000002058026211670949,
        "seek": 271384,
        "start": 2723.48,
        "temperature": 0,
        "text": " It can learn, it acts, so in a way like does,",
        "tokens": [
          50846,
          467,
          393,
          1466,
          11,
          309,
          10672,
          11,
          370,
          294,
          257,
          636,
          411,
          775,
          11,
          50986
        ]
      },
      {
        "avg_logprob": -0.27995100366063863,
        "compression_ratio": 1.9364548494983278,
        "end": 2730.04,
        "id": 1109,
        "no_speech_prob": 0.000002058026211670949,
        "seek": 271384,
        "start": 2726.28,
        "temperature": 0,
        "text": " do neural networks and machine learning replace coding?",
        "tokens": [
          50986,
          360,
          18161,
          9590,
          293,
          3479,
          2539,
          7406,
          17720,
          30,
          51174
        ]
      },
      {
        "avg_logprob": -0.27995100366063863,
        "compression_ratio": 1.9364548494983278,
        "end": 2730.88,
        "id": 1110,
        "no_speech_prob": 0.000002058026211670949,
        "seek": 271384,
        "start": 2730.04,
        "temperature": 0,
        "text": " Right.",
        "tokens": [
          51174,
          1779,
          13,
          51216
        ]
      },
      {
        "avg_logprob": -0.27995100366063863,
        "compression_ratio": 1.9364548494983278,
        "end": 2732.84,
        "id": 1111,
        "no_speech_prob": 0.000002058026211670949,
        "seek": 271384,
        "start": 2730.88,
        "temperature": 0,
        "text": " I don't think of them as, maybe someday they will",
        "tokens": [
          51216,
          286,
          500,
          380,
          519,
          295,
          552,
          382,
          11,
          1310,
          19412,
          436,
          486,
          51314
        ]
      },
      {
        "avg_logprob": -0.27995100366063863,
        "compression_ratio": 1.9364548494983278,
        "end": 2734.4,
        "id": 1112,
        "no_speech_prob": 0.000002058026211670949,
        "seek": 271384,
        "start": 2732.84,
        "temperature": 0,
        "text": " in some weird way, but I think of it as like",
        "tokens": [
          51314,
          294,
          512,
          3657,
          636,
          11,
          457,
          286,
          519,
          295,
          309,
          382,
          411,
          51392
        ]
      },
      {
        "avg_logprob": -0.27995100366063863,
        "compression_ratio": 1.9364548494983278,
        "end": 2736.48,
        "id": 1113,
        "no_speech_prob": 0.000002058026211670949,
        "seek": 271384,
        "start": 2734.4,
        "temperature": 0,
        "text": " they don't replace coding, but they can replace",
        "tokens": [
          51392,
          436,
          500,
          380,
          7406,
          17720,
          11,
          457,
          436,
          393,
          7406,
          51496
        ]
      },
      {
        "avg_logprob": -0.27995100366063863,
        "compression_ratio": 1.9364548494983278,
        "end": 2739.08,
        "id": 1114,
        "no_speech_prob": 0.000002058026211670949,
        "seek": 271384,
        "start": 2736.48,
        "temperature": 0,
        "text": " or act as a function in your code.",
        "tokens": [
          51496,
          420,
          605,
          382,
          257,
          2445,
          294,
          428,
          3089,
          13,
          51626
        ]
      },
      {
        "avg_logprob": -0.27995100366063863,
        "compression_ratio": 1.9364548494983278,
        "end": 2740.6400000000003,
        "id": 1115,
        "no_speech_prob": 0.000002058026211670949,
        "seek": 271384,
        "start": 2739.08,
        "temperature": 0,
        "text": " So that function that you might have hard coded",
        "tokens": [
          51626,
          407,
          300,
          2445,
          300,
          291,
          1062,
          362,
          1152,
          34874,
          51704
        ]
      },
      {
        "avg_logprob": -0.27995100366063863,
        "compression_ratio": 1.9364548494983278,
        "end": 2742.08,
        "id": 1116,
        "no_speech_prob": 0.000002058026211670949,
        "seek": 271384,
        "start": 2740.6400000000003,
        "temperature": 0,
        "text": " with a lot of if statements can now have",
        "tokens": [
          51704,
          365,
          257,
          688,
          295,
          498,
          12363,
          393,
          586,
          362,
          51776
        ]
      },
      {
        "avg_logprob": -0.27995100366063863,
        "compression_ratio": 1.9364548494983278,
        "end": 2743.54,
        "id": 1117,
        "no_speech_prob": 0.000002058026211670949,
        "seek": 271384,
        "start": 2742.08,
        "temperature": 0,
        "text": " a machine learning system in it,",
        "tokens": [
          51776,
          257,
          3479,
          2539,
          1185,
          294,
          309,
          11,
          51849
        ]
      },
      {
        "avg_logprob": -0.29422912129595236,
        "compression_ratio": 1.7415384615384615,
        "end": 2745.7,
        "id": 1118,
        "no_speech_prob": 0.000869323848746717,
        "seek": 274354,
        "start": 2744.24,
        "temperature": 0,
        "text": " and take some inputs and generate an output.",
        "tokens": [
          50399,
          293,
          747,
          512,
          15743,
          293,
          8460,
          364,
          5598,
          13,
          50472
        ]
      },
      {
        "avg_logprob": -0.29422912129595236,
        "compression_ratio": 1.7415384615384615,
        "end": 2746.9,
        "id": 1119,
        "no_speech_prob": 0.000869323848746717,
        "seek": 274354,
        "start": 2745.7,
        "temperature": 0,
        "text": " Yeah, I agree.",
        "tokens": [
          50472,
          865,
          11,
          286,
          3986,
          13,
          50532
        ]
      },
      {
        "avg_logprob": -0.29422912129595236,
        "compression_ratio": 1.7415384615384615,
        "end": 2748.58,
        "id": 1120,
        "no_speech_prob": 0.000869323848746717,
        "seek": 274354,
        "start": 2746.9,
        "temperature": 0,
        "text": " I mean, when it's all said and done,",
        "tokens": [
          50532,
          286,
          914,
          11,
          562,
          309,
          311,
          439,
          848,
          293,
          1096,
          11,
          50616
        ]
      },
      {
        "avg_logprob": -0.29422912129595236,
        "compression_ratio": 1.7415384615384615,
        "end": 2752.18,
        "id": 1121,
        "no_speech_prob": 0.000869323848746717,
        "seek": 274354,
        "start": 2748.58,
        "temperature": 0,
        "text": " algorithms are input, instructions, output.",
        "tokens": [
          50616,
          14642,
          366,
          4846,
          11,
          9415,
          11,
          5598,
          13,
          50796
        ]
      },
      {
        "avg_logprob": -0.29422912129595236,
        "compression_ratio": 1.7415384615384615,
        "end": 2753.02,
        "id": 1122,
        "no_speech_prob": 0.000869323848746717,
        "seek": 274354,
        "start": 2752.18,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          50796,
          865,
          13,
          50838
        ]
      },
      {
        "avg_logprob": -0.29422912129595236,
        "compression_ratio": 1.7415384615384615,
        "end": 2754.5,
        "id": 1123,
        "no_speech_prob": 0.000869323848746717,
        "seek": 274354,
        "start": 2753.02,
        "temperature": 0,
        "text": " And you're just replacing the instruction part.",
        "tokens": [
          50838,
          400,
          291,
          434,
          445,
          19139,
          264,
          10951,
          644,
          13,
          50912
        ]
      },
      {
        "avg_logprob": -0.29422912129595236,
        "compression_ratio": 1.7415384615384615,
        "end": 2755.34,
        "id": 1124,
        "no_speech_prob": 0.000869323848746717,
        "seek": 274354,
        "start": 2754.5,
        "temperature": 0,
        "text": " Totally.",
        "tokens": [
          50912,
          22837,
          13,
          50954
        ]
      },
      {
        "avg_logprob": -0.29422912129595236,
        "compression_ratio": 1.7415384615384615,
        "end": 2758.38,
        "id": 1125,
        "no_speech_prob": 0.000869323848746717,
        "seek": 274354,
        "start": 2756.34,
        "temperature": 0,
        "text": " I believe Siraj already did a video on that.",
        "tokens": [
          51004,
          286,
          1697,
          6144,
          1805,
          1217,
          630,
          257,
          960,
          322,
          300,
          13,
          51106
        ]
      },
      {
        "avg_logprob": -0.29422912129595236,
        "compression_ratio": 1.7415384615384615,
        "end": 2760.9,
        "id": 1126,
        "no_speech_prob": 0.000869323848746717,
        "seek": 274354,
        "start": 2758.38,
        "temperature": 0,
        "text": " I think Siraj having already done a video on that",
        "tokens": [
          51106,
          286,
          519,
          6144,
          1805,
          1419,
          1217,
          1096,
          257,
          960,
          322,
          300,
          51232
        ]
      },
      {
        "avg_logprob": -0.29422912129595236,
        "compression_ratio": 1.7415384615384615,
        "end": 2762.34,
        "id": 1127,
        "no_speech_prob": 0.000869323848746717,
        "seek": 274354,
        "start": 2760.9,
        "temperature": 0,
        "text": " is probably the answer for everything",
        "tokens": [
          51232,
          307,
          1391,
          264,
          1867,
          337,
          1203,
          51304
        ]
      },
      {
        "avg_logprob": -0.29422912129595236,
        "compression_ratio": 1.7415384615384615,
        "end": 2764.5,
        "id": 1128,
        "no_speech_prob": 0.000869323848746717,
        "seek": 274354,
        "start": 2762.34,
        "temperature": 0,
        "text": " we might ever talk about in this.",
        "tokens": [
          51304,
          321,
          1062,
          1562,
          751,
          466,
          294,
          341,
          13,
          51412
        ]
      },
      {
        "avg_logprob": -0.29422912129595236,
        "compression_ratio": 1.7415384615384615,
        "end": 2765.7799999999997,
        "id": 1129,
        "no_speech_prob": 0.000869323848746717,
        "seek": 274354,
        "start": 2764.5,
        "temperature": 0,
        "text": " Because he definitely has a video on everything.",
        "tokens": [
          51412,
          1436,
          415,
          2138,
          575,
          257,
          960,
          322,
          1203,
          13,
          51476
        ]
      },
      {
        "avg_logprob": -0.29422912129595236,
        "compression_ratio": 1.7415384615384615,
        "end": 2767.82,
        "id": 1130,
        "no_speech_prob": 0.000869323848746717,
        "seek": 274354,
        "start": 2765.7799999999997,
        "temperature": 0,
        "text": " That's the new Simpsons edit.",
        "tokens": [
          51476,
          663,
          311,
          264,
          777,
          3998,
          1878,
          892,
          8129,
          13,
          51578
        ]
      },
      {
        "avg_logprob": -0.29422912129595236,
        "compression_ratio": 1.7415384615384615,
        "end": 2769.96,
        "id": 1131,
        "no_speech_prob": 0.000869323848746717,
        "seek": 274354,
        "start": 2767.82,
        "temperature": 0,
        "text": " Coding, train, are you gonna show us the working code",
        "tokens": [
          51578,
          383,
          8616,
          11,
          3847,
          11,
          366,
          291,
          799,
          855,
          505,
          264,
          1364,
          3089,
          51685
        ]
      },
      {
        "avg_logprob": -0.29422912129595236,
        "compression_ratio": 1.7415384615384615,
        "end": 2770.86,
        "id": 1132,
        "no_speech_prob": 0.000869323848746717,
        "seek": 274354,
        "start": 2769.96,
        "temperature": 0,
        "text": " or is it just a discussion?",
        "tokens": [
          51685,
          420,
          307,
          309,
          445,
          257,
          5017,
          30,
          51730
        ]
      },
      {
        "avg_logprob": -0.29422912129595236,
        "compression_ratio": 1.7415384615384615,
        "end": 2772.1,
        "id": 1133,
        "no_speech_prob": 0.000869323848746717,
        "seek": 274354,
        "start": 2770.86,
        "temperature": 0,
        "text": " So I think we're wrapping up here.",
        "tokens": [
          51730,
          407,
          286,
          519,
          321,
          434,
          21993,
          493,
          510,
          13,
          51792
        ]
      },
      {
        "avg_logprob": -0.24092906885753476,
        "compression_ratio": 1.7023121387283238,
        "end": 2773.42,
        "id": 1134,
        "no_speech_prob": 0.0015010403003543615,
        "seek": 277210,
        "start": 2772.1,
        "temperature": 0,
        "text": " This was really just a discussion.",
        "tokens": [
          50364,
          639,
          390,
          534,
          445,
          257,
          5017,
          13,
          50430
        ]
      },
      {
        "avg_logprob": -0.24092906885753476,
        "compression_ratio": 1.7023121387283238,
        "end": 2775.2599999999998,
        "id": 1135,
        "no_speech_prob": 0.0015010403003543615,
        "seek": 277210,
        "start": 2773.42,
        "temperature": 0,
        "text": " The code is here.",
        "tokens": [
          50430,
          440,
          3089,
          307,
          510,
          13,
          50522
        ]
      },
      {
        "avg_logprob": -0.24092906885753476,
        "compression_ratio": 1.7023121387283238,
        "end": 2777.18,
        "id": 1136,
        "no_speech_prob": 0.0015010403003543615,
        "seek": 277210,
        "start": 2775.2599999999998,
        "temperature": 0,
        "text": " Some people had asked just to scroll to the top.",
        "tokens": [
          50522,
          2188,
          561,
          632,
          2351,
          445,
          281,
          11369,
          281,
          264,
          1192,
          13,
          50618
        ]
      },
      {
        "avg_logprob": -0.24092906885753476,
        "compression_ratio": 1.7023121387283238,
        "end": 2778.02,
        "id": 1137,
        "no_speech_prob": 0.0015010403003543615,
        "seek": 277210,
        "start": 2777.18,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50618,
          1033,
          13,
          50660
        ]
      },
      {
        "avg_logprob": -0.24092906885753476,
        "compression_ratio": 1.7023121387283238,
        "end": 2779.38,
        "id": 1138,
        "no_speech_prob": 0.0015010403003543615,
        "seek": 277210,
        "start": 2778.02,
        "temperature": 0,
        "text": " Maybe you hadn't seen what was at the top.",
        "tokens": [
          50660,
          2704,
          291,
          8782,
          380,
          1612,
          437,
          390,
          412,
          264,
          1192,
          13,
          50728
        ]
      },
      {
        "avg_logprob": -0.24092906885753476,
        "compression_ratio": 1.7023121387283238,
        "end": 2781.8199999999997,
        "id": 1139,
        "no_speech_prob": 0.0015010403003543615,
        "seek": 277210,
        "start": 2779.38,
        "temperature": 0,
        "text": " But I don't know if that really matters.",
        "tokens": [
          50728,
          583,
          286,
          500,
          380,
          458,
          498,
          300,
          534,
          7001,
          13,
          50850
        ]
      },
      {
        "avg_logprob": -0.24092906885753476,
        "compression_ratio": 1.7023121387283238,
        "end": 2783.38,
        "id": 1140,
        "no_speech_prob": 0.0015010403003543615,
        "seek": 277210,
        "start": 2781.8199999999997,
        "temperature": 0,
        "text": " But I'm standing in front of the code anyway.",
        "tokens": [
          50850,
          583,
          286,
          478,
          4877,
          294,
          1868,
          295,
          264,
          3089,
          4033,
          13,
          50928
        ]
      },
      {
        "avg_logprob": -0.24092906885753476,
        "compression_ratio": 1.7023121387283238,
        "end": 2785.42,
        "id": 1141,
        "no_speech_prob": 0.0015010403003543615,
        "seek": 277210,
        "start": 2783.38,
        "temperature": 0,
        "text": " But this code is available at that URL.",
        "tokens": [
          50928,
          583,
          341,
          3089,
          307,
          2435,
          412,
          300,
          12905,
          13,
          51030
        ]
      },
      {
        "avg_logprob": -0.24092906885753476,
        "compression_ratio": 1.7023121387283238,
        "end": 2786.98,
        "id": 1142,
        "no_speech_prob": 0.0015010403003543615,
        "seek": 277210,
        "start": 2785.42,
        "temperature": 0,
        "text": " There'll be a link in this video's description.",
        "tokens": [
          51030,
          821,
          603,
          312,
          257,
          2113,
          294,
          341,
          960,
          311,
          3855,
          13,
          51108
        ]
      },
      {
        "avg_logprob": -0.24092906885753476,
        "compression_ratio": 1.7023121387283238,
        "end": 2790.22,
        "id": 1143,
        "no_speech_prob": 0.0015010403003543615,
        "seek": 277210,
        "start": 2786.98,
        "temperature": 0,
        "text": " And I think, I mean, I don't wanna like,",
        "tokens": [
          51108,
          400,
          286,
          519,
          11,
          286,
          914,
          11,
          286,
          500,
          380,
          1948,
          411,
          11,
          51270
        ]
      },
      {
        "avg_logprob": -0.24092906885753476,
        "compression_ratio": 1.7023121387283238,
        "end": 2791.58,
        "id": 1144,
        "no_speech_prob": 0.0015010403003543615,
        "seek": 277210,
        "start": 2790.22,
        "temperature": 0,
        "text": " I mean, I feel committed to doing this.",
        "tokens": [
          51270,
          286,
          914,
          11,
          286,
          841,
          7784,
          281,
          884,
          341,
          13,
          51338
        ]
      },
      {
        "avg_logprob": -0.24092906885753476,
        "compression_ratio": 1.7023121387283238,
        "end": 2793.54,
        "id": 1145,
        "no_speech_prob": 0.0015010403003543615,
        "seek": 277210,
        "start": 2791.58,
        "temperature": 0,
        "text": " I just don't know when exactly it'll happen.",
        "tokens": [
          51338,
          286,
          445,
          500,
          380,
          458,
          562,
          2293,
          309,
          603,
          1051,
          13,
          51436
        ]
      },
      {
        "avg_logprob": -0.24092906885753476,
        "compression_ratio": 1.7023121387283238,
        "end": 2795.54,
        "id": 1146,
        "no_speech_prob": 0.0015010403003543615,
        "seek": 277210,
        "start": 2793.54,
        "temperature": 0,
        "text": " But hopefully sometime next week.",
        "tokens": [
          51436,
          583,
          4696,
          15053,
          958,
          1243,
          13,
          51536
        ]
      },
      {
        "avg_logprob": -0.24092906885753476,
        "compression_ratio": 1.7023121387283238,
        "end": 2797.74,
        "id": 1147,
        "no_speech_prob": 0.0015010403003543615,
        "seek": 277210,
        "start": 2795.54,
        "temperature": 0,
        "text": " I'd like to make my own version of this project,",
        "tokens": [
          51536,
          286,
          1116,
          411,
          281,
          652,
          452,
          1065,
          3037,
          295,
          341,
          1716,
          11,
          51646
        ]
      },
      {
        "avg_logprob": -0.24092906885753476,
        "compression_ratio": 1.7023121387283238,
        "end": 2800.02,
        "id": 1148,
        "no_speech_prob": 0.0015010403003543615,
        "seek": 277210,
        "start": 2797.74,
        "temperature": 0,
        "text": " which I'll do like in a coding challenge from scratch.",
        "tokens": [
          51646,
          597,
          286,
          603,
          360,
          411,
          294,
          257,
          17720,
          3430,
          490,
          8459,
          13,
          51760
        ]
      },
      {
        "avg_logprob": -0.3074354229551373,
        "compression_ratio": 1.9014084507042253,
        "end": 2802.5,
        "id": 1149,
        "no_speech_prob": 0.0010161529062315822,
        "seek": 280002,
        "start": 2800.7,
        "temperature": 0,
        "text": " And then we can kinda compare and contrast that.",
        "tokens": [
          50398,
          400,
          550,
          321,
          393,
          4144,
          6794,
          293,
          8712,
          300,
          13,
          50488
        ]
      },
      {
        "avg_logprob": -0.3074354229551373,
        "compression_ratio": 1.9014084507042253,
        "end": 2804.62,
        "id": 1150,
        "no_speech_prob": 0.0010161529062315822,
        "seek": 280002,
        "start": 2802.5,
        "temperature": 0,
        "text": " And I have a feeling that you're probably",
        "tokens": [
          50488,
          400,
          286,
          362,
          257,
          2633,
          300,
          291,
          434,
          1391,
          50594
        ]
      },
      {
        "avg_logprob": -0.3074354229551373,
        "compression_ratio": 1.9014084507042253,
        "end": 2806.02,
        "id": 1151,
        "no_speech_prob": 0.0010161529062315822,
        "seek": 280002,
        "start": 2804.62,
        "temperature": 0,
        "text": " gonna have some other video content",
        "tokens": [
          50594,
          799,
          362,
          512,
          661,
          960,
          2701,
          50664
        ]
      },
      {
        "avg_logprob": -0.3074354229551373,
        "compression_ratio": 1.9014084507042253,
        "end": 2807.62,
        "id": 1152,
        "no_speech_prob": 0.0010161529062315822,
        "seek": 280002,
        "start": 2806.02,
        "temperature": 0,
        "text": " about this project at some point.",
        "tokens": [
          50664,
          466,
          341,
          1716,
          412,
          512,
          935,
          13,
          50744
        ]
      },
      {
        "avg_logprob": -0.3074354229551373,
        "compression_ratio": 1.9014084507042253,
        "end": 2809.34,
        "id": 1153,
        "no_speech_prob": 0.0010161529062315822,
        "seek": 280002,
        "start": 2807.62,
        "temperature": 0,
        "text": " Did I mention that you should subscribe?",
        "tokens": [
          50744,
          2589,
          286,
          2152,
          300,
          291,
          820,
          3022,
          30,
          50830
        ]
      },
      {
        "avg_logprob": -0.3074354229551373,
        "compression_ratio": 1.9014084507042253,
        "end": 2811.74,
        "id": 1154,
        "no_speech_prob": 0.0010161529062315822,
        "seek": 280002,
        "start": 2809.34,
        "temperature": 0,
        "text": " There's gonna be a special guest.",
        "tokens": [
          50830,
          821,
          311,
          799,
          312,
          257,
          2121,
          8341,
          13,
          50950
        ]
      },
      {
        "avg_logprob": -0.3074354229551373,
        "compression_ratio": 1.9014084507042253,
        "end": 2814.9,
        "id": 1155,
        "no_speech_prob": 0.0010161529062315822,
        "seek": 280002,
        "start": 2811.74,
        "temperature": 0,
        "text": " Did I mention that you should subscribe?",
        "tokens": [
          50950,
          2589,
          286,
          2152,
          300,
          291,
          820,
          3022,
          30,
          51108
        ]
      },
      {
        "avg_logprob": -0.3074354229551373,
        "compression_ratio": 1.9014084507042253,
        "end": 2815.94,
        "id": 1156,
        "no_speech_prob": 0.0010161529062315822,
        "seek": 280002,
        "start": 2814.9,
        "temperature": 0,
        "text": " There's gonna be a special guest.",
        "tokens": [
          51108,
          821,
          311,
          799,
          312,
          257,
          2121,
          8341,
          13,
          51160
        ]
      },
      {
        "avg_logprob": -0.3074354229551373,
        "compression_ratio": 1.9014084507042253,
        "end": 2817.02,
        "id": 1157,
        "no_speech_prob": 0.0010161529062315822,
        "seek": 280002,
        "start": 2815.94,
        "temperature": 0,
        "text": " I don't know who.",
        "tokens": [
          51160,
          286,
          500,
          380,
          458,
          567,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.3074354229551373,
        "compression_ratio": 1.9014084507042253,
        "end": 2818.2599999999998,
        "id": 1158,
        "no_speech_prob": 0.0010161529062315822,
        "seek": 280002,
        "start": 2817.02,
        "temperature": 0,
        "text": " I have no idea who.",
        "tokens": [
          51214,
          286,
          362,
          572,
          1558,
          567,
          13,
          51276
        ]
      },
      {
        "avg_logprob": -0.3074354229551373,
        "compression_ratio": 1.9014084507042253,
        "end": 2819.18,
        "id": 1159,
        "no_speech_prob": 0.0010161529062315822,
        "seek": 280002,
        "start": 2818.2599999999998,
        "temperature": 0,
        "text": " Wait, how do I?",
        "tokens": [
          51276,
          3802,
          11,
          577,
          360,
          286,
          30,
          51322
        ]
      },
      {
        "avg_logprob": -0.3074354229551373,
        "compression_ratio": 1.9014084507042253,
        "end": 2822.14,
        "id": 1160,
        "no_speech_prob": 0.0010161529062315822,
        "seek": 280002,
        "start": 2819.18,
        "temperature": 0,
        "text": " YouTube, you need, do you know you can get",
        "tokens": [
          51322,
          3088,
          11,
          291,
          643,
          11,
          360,
          291,
          458,
          291,
          393,
          483,
          51470
        ]
      },
      {
        "avg_logprob": -0.3074354229551373,
        "compression_ratio": 1.9014084507042253,
        "end": 2824.1,
        "id": 1161,
        "no_speech_prob": 0.0010161529062315822,
        "seek": 280002,
        "start": 2822.14,
        "temperature": 0,
        "text": " one of these vanity URL things now?",
        "tokens": [
          51470,
          472,
          295,
          613,
          44622,
          12905,
          721,
          586,
          30,
          51568
        ]
      },
      {
        "avg_logprob": -0.3074354229551373,
        "compression_ratio": 1.9014084507042253,
        "end": 2826.18,
        "id": 1162,
        "no_speech_prob": 0.0010161529062315822,
        "seek": 280002,
        "start": 2824.1,
        "temperature": 0,
        "text": " So you can get like this?",
        "tokens": [
          51568,
          407,
          291,
          393,
          483,
          411,
          341,
          30,
          51672
        ]
      },
      {
        "avg_logprob": -0.3074354229551373,
        "compression_ratio": 1.9014084507042253,
        "end": 2827.02,
        "id": 1163,
        "no_speech_prob": 0.0010161529062315822,
        "seek": 280002,
        "start": 2826.18,
        "temperature": 0,
        "text": " Ah.",
        "tokens": [
          51672,
          2438,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.3074354229551373,
        "compression_ratio": 1.9014084507042253,
        "end": 2828.86,
        "id": 1164,
        "no_speech_prob": 0.0010161529062315822,
        "seek": 280002,
        "start": 2827.02,
        "temperature": 0,
        "text": " I don't know, because I have one now.",
        "tokens": [
          51714,
          286,
          500,
          380,
          458,
          11,
          570,
          286,
          362,
          472,
          586,
          13,
          51806
        ]
      },
      {
        "avg_logprob": -0.3074354229551373,
        "compression_ratio": 1.9014084507042253,
        "end": 2829.7,
        "id": 1165,
        "no_speech_prob": 0.0010161529062315822,
        "seek": 280002,
        "start": 2828.86,
        "temperature": 0,
        "text": " I need a little bit of time.",
        "tokens": [
          51806,
          286,
          643,
          257,
          707,
          857,
          295,
          565,
          13,
          51848
        ]
      },
      {
        "avg_logprob": -0.4056830256240173,
        "compression_ratio": 1.7961538461538462,
        "end": 2831.66,
        "id": 1166,
        "no_speech_prob": 0.013221592642366886,
        "seek": 282970,
        "start": 2830.4199999999996,
        "temperature": 0,
        "text": " Maybe you have to be like very special on YouTube",
        "tokens": [
          50400,
          2704,
          291,
          362,
          281,
          312,
          411,
          588,
          2121,
          322,
          3088,
          50462
        ]
      },
      {
        "avg_logprob": -0.4056830256240173,
        "compression_ratio": 1.7961538461538462,
        "end": 2832.7,
        "id": 1167,
        "no_speech_prob": 0.013221592642366886,
        "seek": 282970,
        "start": 2831.66,
        "temperature": 0,
        "text": " to get that unlocked for you.",
        "tokens": [
          50462,
          281,
          483,
          300,
          30180,
          337,
          291,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.4056830256240173,
        "compression_ratio": 1.7961538461538462,
        "end": 2833.7799999999997,
        "id": 1168,
        "no_speech_prob": 0.013221592642366886,
        "seek": 282970,
        "start": 2832.7,
        "temperature": 0,
        "text": " I think you're special.",
        "tokens": [
          50514,
          286,
          519,
          291,
          434,
          2121,
          13,
          50568
        ]
      },
      {
        "avg_logprob": -0.4056830256240173,
        "compression_ratio": 1.7961538461538462,
        "end": 2834.62,
        "id": 1169,
        "no_speech_prob": 0.013221592642366886,
        "seek": 282970,
        "start": 2833.7799999999997,
        "temperature": 0,
        "text": " Oh, excuse me.",
        "tokens": [
          50568,
          876,
          11,
          8960,
          385,
          13,
          50610
        ]
      },
      {
        "avg_logprob": -0.4056830256240173,
        "compression_ratio": 1.7961538461538462,
        "end": 2838.46,
        "id": 1170,
        "no_speech_prob": 0.013221592642366886,
        "seek": 282970,
        "start": 2834.62,
        "temperature": 0,
        "text": " But, so I'm just gonna search for you again.",
        "tokens": [
          50610,
          583,
          11,
          370,
          286,
          478,
          445,
          799,
          3164,
          337,
          291,
          797,
          13,
          50802
        ]
      },
      {
        "avg_logprob": -0.4056830256240173,
        "compression_ratio": 1.7961538461538462,
        "end": 2840.06,
        "id": 1171,
        "no_speech_prob": 0.013221592642366886,
        "seek": 282970,
        "start": 2838.46,
        "temperature": 0,
        "text": " If you just do Jabril's, it comes up.",
        "tokens": [
          50802,
          759,
          291,
          445,
          360,
          40319,
          24216,
          311,
          11,
          309,
          1487,
          493,
          13,
          50882
        ]
      },
      {
        "avg_logprob": -0.4056830256240173,
        "compression_ratio": 1.7961538461538462,
        "end": 2842.22,
        "id": 1172,
        "no_speech_prob": 0.013221592642366886,
        "seek": 282970,
        "start": 2840.06,
        "temperature": 0,
        "text": " Oh, well then you have that.",
        "tokens": [
          50882,
          876,
          11,
          731,
          550,
          291,
          362,
          300,
          13,
          50990
        ]
      },
      {
        "avg_logprob": -0.4056830256240173,
        "compression_ratio": 1.7961538461538462,
        "end": 2844.22,
        "id": 1173,
        "no_speech_prob": 0.013221592642366886,
        "seek": 282970,
        "start": 2842.22,
        "temperature": 0,
        "text": " I don't think URL though.",
        "tokens": [
          50990,
          286,
          500,
          380,
          519,
          12905,
          1673,
          13,
          51090
        ]
      },
      {
        "avg_logprob": -0.4056830256240173,
        "compression_ratio": 1.7961538461538462,
        "end": 2845.8599999999997,
        "id": 1174,
        "no_speech_prob": 0.013221592642366886,
        "seek": 282970,
        "start": 2844.22,
        "temperature": 0,
        "text": " You just have to search it and it comes up.",
        "tokens": [
          51090,
          509,
          445,
          362,
          281,
          3164,
          309,
          293,
          309,
          1487,
          493,
          13,
          51172
        ]
      },
      {
        "avg_logprob": -0.4056830256240173,
        "compression_ratio": 1.7961538461538462,
        "end": 2846.8999999999996,
        "id": 1175,
        "no_speech_prob": 0.013221592642366886,
        "seek": 282970,
        "start": 2845.8599999999997,
        "temperature": 0,
        "text": " Oh, yeah, you have to search it.",
        "tokens": [
          51172,
          876,
          11,
          1338,
          11,
          291,
          362,
          281,
          3164,
          309,
          13,
          51224
        ]
      },
      {
        "avg_logprob": -0.4056830256240173,
        "compression_ratio": 1.7961538461538462,
        "end": 2848.1,
        "id": 1176,
        "no_speech_prob": 0.013221592642366886,
        "seek": 282970,
        "start": 2846.8999999999996,
        "temperature": 0,
        "text": " Yeah, yeah, yeah, I see.",
        "tokens": [
          51224,
          865,
          11,
          1338,
          11,
          1338,
          11,
          286,
          536,
          13,
          51284
        ]
      },
      {
        "avg_logprob": -0.4056830256240173,
        "compression_ratio": 1.7961538461538462,
        "end": 2851.62,
        "id": 1177,
        "no_speech_prob": 0.013221592642366886,
        "seek": 282970,
        "start": 2850.5,
        "temperature": 0,
        "text": " Captain Meshut.",
        "tokens": [
          51404,
          10873,
          376,
          14935,
          325,
          13,
          51460
        ]
      },
      {
        "avg_logprob": -0.4056830256240173,
        "compression_ratio": 1.7961538461538462,
        "end": 2856.06,
        "id": 1178,
        "no_speech_prob": 0.013221592642366886,
        "seek": 282970,
        "start": 2851.62,
        "temperature": 0,
        "text": " Yes, okay, so here once again, subscribe.",
        "tokens": [
          51460,
          1079,
          11,
          1392,
          11,
          370,
          510,
          1564,
          797,
          11,
          3022,
          13,
          51682
        ]
      },
      {
        "avg_logprob": -0.4056830256240173,
        "compression_ratio": 1.7961538461538462,
        "end": 2857.62,
        "id": 1179,
        "no_speech_prob": 0.013221592642366886,
        "seek": 282970,
        "start": 2856.06,
        "temperature": 0,
        "text": " So I'm gonna just show you.",
        "tokens": [
          51682,
          407,
          286,
          478,
          799,
          445,
          855,
          291,
          13,
          51760
        ]
      },
      {
        "avg_logprob": -0.4056830256240173,
        "compression_ratio": 1.7961538461538462,
        "end": 2859.18,
        "id": 1180,
        "no_speech_prob": 0.013221592642366886,
        "seek": 282970,
        "start": 2857.62,
        "temperature": 0,
        "text": " I'm gonna unsubscribe.",
        "tokens": [
          51760,
          286,
          478,
          799,
          2693,
          9493,
          13,
          51838
        ]
      },
      {
        "avg_logprob": -0.2897098510245967,
        "compression_ratio": 1.5923076923076922,
        "end": 2860.74,
        "id": 1181,
        "no_speech_prob": 0.000027108442736789584,
        "seek": 285918,
        "start": 2859.66,
        "temperature": 0,
        "text": " This is terrible, unsubscribe.",
        "tokens": [
          50388,
          639,
          307,
          6237,
          11,
          2693,
          9493,
          13,
          50442
        ]
      },
      {
        "avg_logprob": -0.2897098510245967,
        "compression_ratio": 1.5923076923076922,
        "end": 2862.74,
        "id": 1182,
        "no_speech_prob": 0.000027108442736789584,
        "seek": 285918,
        "start": 2860.74,
        "temperature": 0,
        "text": " Now I'm gonna show you how you do this.",
        "tokens": [
          50442,
          823,
          286,
          478,
          799,
          855,
          291,
          577,
          291,
          360,
          341,
          13,
          50542
        ]
      },
      {
        "avg_logprob": -0.2897098510245967,
        "compression_ratio": 1.5923076923076922,
        "end": 2865.5,
        "id": 1183,
        "no_speech_prob": 0.000027108442736789584,
        "seek": 285918,
        "start": 2862.74,
        "temperature": 0,
        "text": " You go, you search Jabril's in the search bar.",
        "tokens": [
          50542,
          509,
          352,
          11,
          291,
          3164,
          40319,
          24216,
          311,
          294,
          264,
          3164,
          2159,
          13,
          50680
        ]
      },
      {
        "avg_logprob": -0.2897098510245967,
        "compression_ratio": 1.5923076923076922,
        "end": 2866.74,
        "id": 1184,
        "no_speech_prob": 0.000027108442736789584,
        "seek": 285918,
        "start": 2865.5,
        "temperature": 0,
        "text": " Then you click subscribe.",
        "tokens": [
          50680,
          1396,
          291,
          2052,
          3022,
          13,
          50742
        ]
      },
      {
        "avg_logprob": -0.2897098510245967,
        "compression_ratio": 1.5923076923076922,
        "end": 2869.54,
        "id": 1185,
        "no_speech_prob": 0.000027108442736789584,
        "seek": 285918,
        "start": 2866.74,
        "temperature": 0,
        "text": " Then you click the alarm bell,",
        "tokens": [
          50742,
          1396,
          291,
          2052,
          264,
          14183,
          4549,
          11,
          50882
        ]
      },
      {
        "avg_logprob": -0.2897098510245967,
        "compression_ratio": 1.5923076923076922,
        "end": 2873.66,
        "id": 1186,
        "no_speech_prob": 0.000027108442736789584,
        "seek": 285918,
        "start": 2869.54,
        "temperature": 0,
        "text": " because if you want this special surprise video",
        "tokens": [
          50882,
          570,
          498,
          291,
          528,
          341,
          2121,
          6365,
          960,
          51088
        ]
      },
      {
        "avg_logprob": -0.2897098510245967,
        "compression_ratio": 1.5923076923076922,
        "end": 2876.8599999999997,
        "id": 1187,
        "no_speech_prob": 0.000027108442736789584,
        "seek": 285918,
        "start": 2873.66,
        "temperature": 0,
        "text": " that might come out very soon, you'll get a notification.",
        "tokens": [
          51088,
          300,
          1062,
          808,
          484,
          588,
          2321,
          11,
          291,
          603,
          483,
          257,
          11554,
          13,
          51248
        ]
      },
      {
        "avg_logprob": -0.2897098510245967,
        "compression_ratio": 1.5923076923076922,
        "end": 2881.8199999999997,
        "id": 1188,
        "no_speech_prob": 0.000027108442736789584,
        "seek": 285918,
        "start": 2876.8599999999997,
        "temperature": 0,
        "text": " Okay, you need 100 subscribers to get the vanity URL.",
        "tokens": [
          51248,
          1033,
          11,
          291,
          643,
          2319,
          11092,
          281,
          483,
          264,
          44622,
          12905,
          13,
          51496
        ]
      },
      {
        "avg_logprob": -0.2897098510245967,
        "compression_ratio": 1.5923076923076922,
        "end": 2883.02,
        "id": 1189,
        "no_speech_prob": 0.000027108442736789584,
        "seek": 285918,
        "start": 2881.8199999999997,
        "temperature": 0,
        "text": " I got some work to do.",
        "tokens": [
          51496,
          286,
          658,
          512,
          589,
          281,
          360,
          13,
          51556
        ]
      },
      {
        "avg_logprob": -0.2897098510245967,
        "compression_ratio": 1.5923076923076922,
        "end": 2883.8599999999997,
        "id": 1190,
        "no_speech_prob": 0.000027108442736789584,
        "seek": 285918,
        "start": 2883.02,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51556,
          865,
          13,
          51598
        ]
      },
      {
        "avg_logprob": -0.2897098510245967,
        "compression_ratio": 1.5923076923076922,
        "end": 2887.3399999999997,
        "id": 1191,
        "no_speech_prob": 0.000027108442736789584,
        "seek": 285918,
        "start": 2884.7,
        "temperature": 0,
        "text": " All right, so let me just check to see if there's,",
        "tokens": [
          51640,
          1057,
          558,
          11,
          370,
          718,
          385,
          445,
          1520,
          281,
          536,
          498,
          456,
          311,
          11,
          51772
        ]
      },
      {
        "avg_logprob": -0.31443360794422237,
        "compression_ratio": 1.6847457627118645,
        "end": 2890.9,
        "id": 1192,
        "no_speech_prob": 0.00032499272492714226,
        "seek": 288734,
        "start": 2887.34,
        "temperature": 0,
        "text": " oh yes, people are asking your Twitch.",
        "tokens": [
          50364,
          1954,
          2086,
          11,
          561,
          366,
          3365,
          428,
          22222,
          13,
          50542
        ]
      },
      {
        "avg_logprob": -0.31443360794422237,
        "compression_ratio": 1.6847457627118645,
        "end": 2893.26,
        "id": 1193,
        "no_speech_prob": 0.00032499272492714226,
        "seek": 288734,
        "start": 2890.9,
        "temperature": 0,
        "text": " So let's see if we can, let me just say,",
        "tokens": [
          50542,
          407,
          718,
          311,
          536,
          498,
          321,
          393,
          11,
          718,
          385,
          445,
          584,
          11,
          50660
        ]
      },
      {
        "avg_logprob": -0.31443360794422237,
        "compression_ratio": 1.6847457627118645,
        "end": 2896.6600000000003,
        "id": 1194,
        "no_speech_prob": 0.00032499272492714226,
        "seek": 288734,
        "start": 2893.26,
        "temperature": 0,
        "text": " if I do this, what do you think the chance that'll come up?",
        "tokens": [
          50660,
          498,
          286,
          360,
          341,
          11,
          437,
          360,
          291,
          519,
          264,
          2931,
          300,
          603,
          808,
          493,
          30,
          50830
        ]
      },
      {
        "avg_logprob": -0.31443360794422237,
        "compression_ratio": 1.6847457627118645,
        "end": 2898.34,
        "id": 1195,
        "no_speech_prob": 0.00032499272492714226,
        "seek": 288734,
        "start": 2896.6600000000003,
        "temperature": 0,
        "text": " It's just Jabril's CPU.",
        "tokens": [
          50830,
          467,
          311,
          445,
          40319,
          24216,
          311,
          13199,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.31443360794422237,
        "compression_ratio": 1.6847457627118645,
        "end": 2899.1800000000003,
        "id": 1196,
        "no_speech_prob": 0.00032499272492714226,
        "seek": 288734,
        "start": 2898.34,
        "temperature": 0,
        "text": " Yeah, it's right there.",
        "tokens": [
          50914,
          865,
          11,
          309,
          311,
          558,
          456,
          13,
          50956
        ]
      },
      {
        "avg_logprob": -0.31443360794422237,
        "compression_ratio": 1.6847457627118645,
        "end": 2900.02,
        "id": 1197,
        "no_speech_prob": 0.00032499272492714226,
        "seek": 288734,
        "start": 2899.1800000000003,
        "temperature": 0,
        "text": " Oh, wow.",
        "tokens": [
          50956,
          876,
          11,
          6076,
          13,
          50998
        ]
      },
      {
        "avg_logprob": -0.31443360794422237,
        "compression_ratio": 1.6847457627118645,
        "end": 2904.46,
        "id": 1198,
        "no_speech_prob": 0.00032499272492714226,
        "seek": 288734,
        "start": 2900.02,
        "temperature": 0,
        "text": " So if you go to twitch.tv, Jabril's CPU,",
        "tokens": [
          50998,
          407,
          498,
          291,
          352,
          281,
          34167,
          13,
          24641,
          11,
          40319,
          24216,
          311,
          13199,
          11,
          51220
        ]
      },
      {
        "avg_logprob": -0.31443360794422237,
        "compression_ratio": 1.6847457627118645,
        "end": 2906.1800000000003,
        "id": 1199,
        "no_speech_prob": 0.00032499272492714226,
        "seek": 288734,
        "start": 2904.46,
        "temperature": 0,
        "text": " that's Jabril's Twitch.",
        "tokens": [
          51220,
          300,
          311,
          40319,
          24216,
          311,
          22222,
          13,
          51306
        ]
      },
      {
        "avg_logprob": -0.31443360794422237,
        "compression_ratio": 1.6847457627118645,
        "end": 2908.34,
        "id": 1200,
        "no_speech_prob": 0.00032499272492714226,
        "seek": 288734,
        "start": 2906.1800000000003,
        "temperature": 0,
        "text": " And actually, so I was gonna say this for you, but.",
        "tokens": [
          51306,
          400,
          767,
          11,
          370,
          286,
          390,
          799,
          584,
          341,
          337,
          291,
          11,
          457,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.31443360794422237,
        "compression_ratio": 1.6847457627118645,
        "end": 2909.38,
        "id": 1201,
        "no_speech_prob": 0.00032499272492714226,
        "seek": 288734,
        "start": 2908.34,
        "temperature": 0,
        "text": " Whoa, whoa.",
        "tokens": [
          51414,
          7521,
          11,
          13310,
          13,
          51466
        ]
      },
      {
        "avg_logprob": -0.31443360794422237,
        "compression_ratio": 1.6847457627118645,
        "end": 2911.54,
        "id": 1202,
        "no_speech_prob": 0.00032499272492714226,
        "seek": 288734,
        "start": 2909.38,
        "temperature": 0,
        "text": " All right, they can't hear this by the way.",
        "tokens": [
          51466,
          1057,
          558,
          11,
          436,
          393,
          380,
          1568,
          341,
          538,
          264,
          636,
          13,
          51574
        ]
      },
      {
        "avg_logprob": -0.31443360794422237,
        "compression_ratio": 1.6847457627118645,
        "end": 2912.38,
        "id": 1203,
        "no_speech_prob": 0.00032499272492714226,
        "seek": 288734,
        "start": 2911.54,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          51574,
          876,
          13,
          51616
        ]
      },
      {
        "avg_logprob": -0.31443360794422237,
        "compression_ratio": 1.6847457627118645,
        "end": 2914.1800000000003,
        "id": 1204,
        "no_speech_prob": 0.00032499272492714226,
        "seek": 288734,
        "start": 2912.38,
        "temperature": 0,
        "text": " I mean, they can if it comes through our mics,",
        "tokens": [
          51616,
          286,
          914,
          11,
          436,
          393,
          498,
          309,
          1487,
          807,
          527,
          45481,
          11,
          51706
        ]
      },
      {
        "avg_logprob": -0.31443360794422237,
        "compression_ratio": 1.6847457627118645,
        "end": 2915.26,
        "id": 1205,
        "no_speech_prob": 0.00032499272492714226,
        "seek": 288734,
        "start": 2914.1800000000003,
        "temperature": 0,
        "text": " but the audio from this laptop.",
        "tokens": [
          51706,
          457,
          264,
          6278,
          490,
          341,
          10732,
          13,
          51760
        ]
      },
      {
        "avg_logprob": -0.31443360794422237,
        "compression_ratio": 1.6847457627118645,
        "end": 2916.6600000000003,
        "id": 1206,
        "no_speech_prob": 0.00032499272492714226,
        "seek": 288734,
        "start": 2915.26,
        "temperature": 0,
        "text": " So he's just seeing us freaking out over it.",
        "tokens": [
          51760,
          407,
          415,
          311,
          445,
          2577,
          505,
          14612,
          484,
          670,
          309,
          13,
          51830
        ]
      },
      {
        "avg_logprob": -0.26943206787109375,
        "compression_ratio": 1.8166666666666667,
        "end": 2918.2599999999998,
        "id": 1207,
        "no_speech_prob": 0.0033761058002710342,
        "seek": 291666,
        "start": 2916.66,
        "temperature": 0,
        "text": " Yeah, he is something to resolve.",
        "tokens": [
          50364,
          865,
          11,
          415,
          307,
          746,
          281,
          367,
          279,
          37361,
          13,
          50444
        ]
      },
      {
        "avg_logprob": -0.26943206787109375,
        "compression_ratio": 1.8166666666666667,
        "end": 2919.5,
        "id": 1208,
        "no_speech_prob": 0.0033761058002710342,
        "seek": 291666,
        "start": 2918.2599999999998,
        "temperature": 0,
        "text": " But actually, I'm curious.",
        "tokens": [
          50444,
          583,
          767,
          11,
          286,
          478,
          6369,
          13,
          50506
        ]
      },
      {
        "avg_logprob": -0.26943206787109375,
        "compression_ratio": 1.8166666666666667,
        "end": 2922.18,
        "id": 1209,
        "no_speech_prob": 0.0033761058002710342,
        "seek": 291666,
        "start": 2919.5,
        "temperature": 0,
        "text": " So tell me about your,",
        "tokens": [
          50506,
          407,
          980,
          385,
          466,
          428,
          11,
          50640
        ]
      },
      {
        "avg_logprob": -0.26943206787109375,
        "compression_ratio": 1.8166666666666667,
        "end": 2925.42,
        "id": 1210,
        "no_speech_prob": 0.0033761058002710342,
        "seek": 291666,
        "start": 2922.18,
        "temperature": 0,
        "text": " because I'm always, I always feel like I have no idea",
        "tokens": [
          50640,
          570,
          286,
          478,
          1009,
          11,
          286,
          1009,
          841,
          411,
          286,
          362,
          572,
          1558,
          50802
        ]
      },
      {
        "avg_logprob": -0.26943206787109375,
        "compression_ratio": 1.8166666666666667,
        "end": 2927.7,
        "id": 1211,
        "no_speech_prob": 0.0033761058002710342,
        "seek": 291666,
        "start": 2925.42,
        "temperature": 0,
        "text": " if I'm doing, I don't think there is an answer to this.",
        "tokens": [
          50802,
          498,
          286,
          478,
          884,
          11,
          286,
          500,
          380,
          519,
          456,
          307,
          364,
          1867,
          281,
          341,
          13,
          50916
        ]
      },
      {
        "avg_logprob": -0.26943206787109375,
        "compression_ratio": 1.8166666666666667,
        "end": 2929.3799999999997,
        "id": 1212,
        "no_speech_prob": 0.0033761058002710342,
        "seek": 291666,
        "start": 2927.7,
        "temperature": 0,
        "text": " Like my process, I have this weird process.",
        "tokens": [
          50916,
          1743,
          452,
          1399,
          11,
          286,
          362,
          341,
          3657,
          1399,
          13,
          51000
        ]
      },
      {
        "avg_logprob": -0.26943206787109375,
        "compression_ratio": 1.8166666666666667,
        "end": 2931.22,
        "id": 1213,
        "no_speech_prob": 0.0033761058002710342,
        "seek": 291666,
        "start": 2929.3799999999997,
        "temperature": 0,
        "text": " Like I do live streams that are on YouTube,",
        "tokens": [
          51000,
          1743,
          286,
          360,
          1621,
          15842,
          300,
          366,
          322,
          3088,
          11,
          51092
        ]
      },
      {
        "avg_logprob": -0.26943206787109375,
        "compression_ratio": 1.8166666666666667,
        "end": 2932.74,
        "id": 1214,
        "no_speech_prob": 0.0033761058002710342,
        "seek": 291666,
        "start": 2931.22,
        "temperature": 0,
        "text": " then I cut up and edit the live streams",
        "tokens": [
          51092,
          550,
          286,
          1723,
          493,
          293,
          8129,
          264,
          1621,
          15842,
          51168
        ]
      },
      {
        "avg_logprob": -0.26943206787109375,
        "compression_ratio": 1.8166666666666667,
        "end": 2934.42,
        "id": 1215,
        "no_speech_prob": 0.0033761058002710342,
        "seek": 291666,
        "start": 2932.74,
        "temperature": 0,
        "text": " as separate videos also on YouTube.",
        "tokens": [
          51168,
          382,
          4994,
          2145,
          611,
          322,
          3088,
          13,
          51252
        ]
      },
      {
        "avg_logprob": -0.26943206787109375,
        "compression_ratio": 1.8166666666666667,
        "end": 2935.2599999999998,
        "id": 1216,
        "no_speech_prob": 0.0033761058002710342,
        "seek": 291666,
        "start": 2934.42,
        "temperature": 0,
        "text": " And sometimes I think, oh,",
        "tokens": [
          51252,
          400,
          2171,
          286,
          519,
          11,
          1954,
          11,
          51294
        ]
      },
      {
        "avg_logprob": -0.26943206787109375,
        "compression_ratio": 1.8166666666666667,
        "end": 2936.94,
        "id": 1217,
        "no_speech_prob": 0.0033761058002710342,
        "seek": 291666,
        "start": 2935.2599999999998,
        "temperature": 0,
        "text": " I should be live streaming on Twitch.",
        "tokens": [
          51294,
          286,
          820,
          312,
          1621,
          11791,
          322,
          22222,
          13,
          51378
        ]
      },
      {
        "avg_logprob": -0.26943206787109375,
        "compression_ratio": 1.8166666666666667,
        "end": 2938.02,
        "id": 1218,
        "no_speech_prob": 0.0033761058002710342,
        "seek": 291666,
        "start": 2936.94,
        "temperature": 0,
        "text": " Should I not be posting redundant?",
        "tokens": [
          51378,
          6454,
          286,
          406,
          312,
          15978,
          40997,
          30,
          51432
        ]
      },
      {
        "avg_logprob": -0.26943206787109375,
        "compression_ratio": 1.8166666666666667,
        "end": 2940.46,
        "id": 1219,
        "no_speech_prob": 0.0033761058002710342,
        "seek": 291666,
        "start": 2938.02,
        "temperature": 0,
        "text": " Anyway, so what's your, how do you separate those?",
        "tokens": [
          51432,
          5684,
          11,
          370,
          437,
          311,
          428,
          11,
          577,
          360,
          291,
          4994,
          729,
          30,
          51554
        ]
      },
      {
        "avg_logprob": -0.26943206787109375,
        "compression_ratio": 1.8166666666666667,
        "end": 2941.98,
        "id": 1220,
        "no_speech_prob": 0.0033761058002710342,
        "seek": 291666,
        "start": 2940.46,
        "temperature": 0,
        "text": " You have the YouTube channel, you have Twitch,",
        "tokens": [
          51554,
          509,
          362,
          264,
          3088,
          2269,
          11,
          291,
          362,
          22222,
          11,
          51630
        ]
      },
      {
        "avg_logprob": -0.26943206787109375,
        "compression_ratio": 1.8166666666666667,
        "end": 2943.1,
        "id": 1221,
        "no_speech_prob": 0.0033761058002710342,
        "seek": 291666,
        "start": 2941.98,
        "temperature": 0,
        "text": " and then you have a second YouTube channel.",
        "tokens": [
          51630,
          293,
          550,
          291,
          362,
          257,
          1150,
          3088,
          2269,
          13,
          51686
        ]
      },
      {
        "avg_logprob": -0.26943206787109375,
        "compression_ratio": 1.8166666666666667,
        "end": 2943.94,
        "id": 1222,
        "no_speech_prob": 0.0033761058002710342,
        "seek": 291666,
        "start": 2943.1,
        "temperature": 0,
        "text": " Correct.",
        "tokens": [
          51686,
          12753,
          13,
          51728
        ]
      },
      {
        "avg_logprob": -0.26943206787109375,
        "compression_ratio": 1.8166666666666667,
        "end": 2944.7799999999997,
        "id": 1223,
        "no_speech_prob": 0.0033761058002710342,
        "seek": 291666,
        "start": 2943.94,
        "temperature": 0,
        "text": " Jabril's CPU.",
        "tokens": [
          51728,
          40319,
          24216,
          311,
          13199,
          13,
          51770
        ]
      },
      {
        "avg_logprob": -0.26943206787109375,
        "compression_ratio": 1.8166666666666667,
        "end": 2945.62,
        "id": 1224,
        "no_speech_prob": 0.0033761058002710342,
        "seek": 291666,
        "start": 2944.7799999999997,
        "temperature": 0,
        "text": " Correct.",
        "tokens": [
          51770,
          12753,
          13,
          51812
        ]
      },
      {
        "avg_logprob": -0.26943206787109375,
        "compression_ratio": 1.8166666666666667,
        "end": 2946.46,
        "id": 1225,
        "no_speech_prob": 0.0033761058002710342,
        "seek": 291666,
        "start": 2945.62,
        "temperature": 0,
        "text": " What are those pieces?",
        "tokens": [
          51812,
          708,
          366,
          729,
          3755,
          30,
          51854
        ]
      },
      {
        "avg_logprob": -0.3235153594574371,
        "compression_ratio": 1.949820788530466,
        "end": 2949.18,
        "id": 1226,
        "no_speech_prob": 0.0030274158343672752,
        "seek": 294646,
        "start": 2947.26,
        "temperature": 0,
        "text": " I focus on the Jabril's channel, like the main one.",
        "tokens": [
          50404,
          286,
          1879,
          322,
          264,
          40319,
          24216,
          311,
          2269,
          11,
          411,
          264,
          2135,
          472,
          13,
          50500
        ]
      },
      {
        "avg_logprob": -0.3235153594574371,
        "compression_ratio": 1.949820788530466,
        "end": 2950.78,
        "id": 1227,
        "no_speech_prob": 0.0030274158343672752,
        "seek": 294646,
        "start": 2949.18,
        "temperature": 0,
        "text": " So I'm literally live streaming,",
        "tokens": [
          50500,
          407,
          286,
          478,
          3736,
          1621,
          11791,
          11,
          50580
        ]
      },
      {
        "avg_logprob": -0.3235153594574371,
        "compression_ratio": 1.949820788530466,
        "end": 2952.06,
        "id": 1228,
        "no_speech_prob": 0.0030274158343672752,
        "seek": 294646,
        "start": 2950.78,
        "temperature": 0,
        "text": " and then whatever comes out of that",
        "tokens": [
          50580,
          293,
          550,
          2035,
          1487,
          484,
          295,
          300,
          50644
        ]
      },
      {
        "avg_logprob": -0.3235153594574371,
        "compression_ratio": 1.949820788530466,
        "end": 2954.9,
        "id": 1229,
        "no_speech_prob": 0.0030274158343672752,
        "seek": 294646,
        "start": 2952.06,
        "temperature": 0,
        "text": " is being straight uploaded to YouTube.",
        "tokens": [
          50644,
          307,
          885,
          2997,
          493,
          752,
          12777,
          281,
          3088,
          13,
          50786
        ]
      },
      {
        "avg_logprob": -0.3235153594574371,
        "compression_ratio": 1.949820788530466,
        "end": 2956.5,
        "id": 1230,
        "no_speech_prob": 0.0030274158343672752,
        "seek": 294646,
        "start": 2954.9,
        "temperature": 0,
        "text": " But it's a separate YouTube channel.",
        "tokens": [
          50786,
          583,
          309,
          311,
          257,
          4994,
          3088,
          2269,
          13,
          50866
        ]
      },
      {
        "avg_logprob": -0.3235153594574371,
        "compression_ratio": 1.949820788530466,
        "end": 2959.3,
        "id": 1231,
        "no_speech_prob": 0.0030274158343672752,
        "seek": 294646,
        "start": 2956.5,
        "temperature": 0,
        "text": " Like these, the live streams on Twitch",
        "tokens": [
          50866,
          1743,
          613,
          11,
          264,
          1621,
          15842,
          322,
          22222,
          51006
        ]
      },
      {
        "avg_logprob": -0.3235153594574371,
        "compression_ratio": 1.949820788530466,
        "end": 2962.7,
        "id": 1232,
        "no_speech_prob": 0.0030274158343672752,
        "seek": 294646,
        "start": 2959.3,
        "temperature": 0,
        "text": " don't show up in the Jabril's YouTube channel.",
        "tokens": [
          51006,
          500,
          380,
          855,
          493,
          294,
          264,
          40319,
          24216,
          311,
          3088,
          2269,
          13,
          51176
        ]
      },
      {
        "avg_logprob": -0.3235153594574371,
        "compression_ratio": 1.949820788530466,
        "end": 2964.62,
        "id": 1233,
        "no_speech_prob": 0.0030274158343672752,
        "seek": 294646,
        "start": 2962.7,
        "temperature": 0,
        "text": " They show up in the Jabril's CPU YouTube channel.",
        "tokens": [
          51176,
          814,
          855,
          493,
          294,
          264,
          40319,
          24216,
          311,
          13199,
          3088,
          2269,
          13,
          51272
        ]
      },
      {
        "avg_logprob": -0.3235153594574371,
        "compression_ratio": 1.949820788530466,
        "end": 2966.7400000000002,
        "id": 1234,
        "no_speech_prob": 0.0030274158343672752,
        "seek": 294646,
        "start": 2964.62,
        "temperature": 0,
        "text": " Correct, unless I do like really special live streams.",
        "tokens": [
          51272,
          12753,
          11,
          5969,
          286,
          360,
          411,
          534,
          2121,
          1621,
          15842,
          13,
          51378
        ]
      },
      {
        "avg_logprob": -0.3235153594574371,
        "compression_ratio": 1.949820788530466,
        "end": 2967.58,
        "id": 1235,
        "no_speech_prob": 0.0030274158343672752,
        "seek": 294646,
        "start": 2966.7400000000002,
        "temperature": 0,
        "text": " Then they go on.",
        "tokens": [
          51378,
          1396,
          436,
          352,
          322,
          13,
          51420
        ]
      },
      {
        "avg_logprob": -0.3235153594574371,
        "compression_ratio": 1.949820788530466,
        "end": 2968.42,
        "id": 1236,
        "no_speech_prob": 0.0030274158343672752,
        "seek": 294646,
        "start": 2967.58,
        "temperature": 0,
        "text": " Then they go there.",
        "tokens": [
          51420,
          1396,
          436,
          352,
          456,
          13,
          51462
        ]
      },
      {
        "avg_logprob": -0.3235153594574371,
        "compression_ratio": 1.949820788530466,
        "end": 2971.62,
        "id": 1237,
        "no_speech_prob": 0.0030274158343672752,
        "seek": 294646,
        "start": 2968.42,
        "temperature": 0,
        "text": " Yeah, so you have three things to subscribe to.",
        "tokens": [
          51462,
          865,
          11,
          370,
          291,
          362,
          1045,
          721,
          281,
          3022,
          281,
          13,
          51622
        ]
      },
      {
        "avg_logprob": -0.3235153594574371,
        "compression_ratio": 1.949820788530466,
        "end": 2973.42,
        "id": 1238,
        "no_speech_prob": 0.0030274158343672752,
        "seek": 294646,
        "start": 2971.62,
        "temperature": 0,
        "text": " Twitch live stream, YouTube live stream,",
        "tokens": [
          51622,
          22222,
          1621,
          4309,
          11,
          3088,
          1621,
          4309,
          11,
          51712
        ]
      },
      {
        "avg_logprob": -0.3235153594574371,
        "compression_ratio": 1.949820788530466,
        "end": 2976.3,
        "id": 1239,
        "no_speech_prob": 0.0030274158343672752,
        "seek": 294646,
        "start": 2973.42,
        "temperature": 0,
        "text": " archive, and the main channel.",
        "tokens": [
          51712,
          23507,
          11,
          293,
          264,
          2135,
          2269,
          13,
          51856
        ]
      },
      {
        "avg_logprob": -0.40540650639220743,
        "compression_ratio": 1.599264705882353,
        "end": 2977.98,
        "id": 1240,
        "no_speech_prob": 0.01495156530290842,
        "seek": 297630,
        "start": 2977.1400000000003,
        "temperature": 0,
        "text": " Oh wow, thank you.",
        "tokens": [
          50406,
          876,
          6076,
          11,
          1309,
          291,
          13,
          50448
        ]
      },
      {
        "avg_logprob": -0.40540650639220743,
        "compression_ratio": 1.599264705882353,
        "end": 2980.26,
        "id": 1241,
        "no_speech_prob": 0.01495156530290842,
        "seek": 297630,
        "start": 2977.98,
        "temperature": 0,
        "text": " You know, at least subscribe to the main channel.",
        "tokens": [
          50448,
          509,
          458,
          11,
          412,
          1935,
          3022,
          281,
          264,
          2135,
          2269,
          13,
          50562
        ]
      },
      {
        "avg_logprob": -0.40540650639220743,
        "compression_ratio": 1.599264705882353,
        "end": 2981.5800000000004,
        "id": 1242,
        "no_speech_prob": 0.01495156530290842,
        "seek": 297630,
        "start": 2980.26,
        "temperature": 0,
        "text": " Definitely the main channel.",
        "tokens": [
          50562,
          12151,
          264,
          2135,
          2269,
          13,
          50628
        ]
      },
      {
        "avg_logprob": -0.40540650639220743,
        "compression_ratio": 1.599264705882353,
        "end": 2984.78,
        "id": 1243,
        "no_speech_prob": 0.01495156530290842,
        "seek": 297630,
        "start": 2981.5800000000004,
        "temperature": 0,
        "text": " Yes, Bruno clarifies you don't need 100K subscribers,",
        "tokens": [
          50628,
          1079,
          11,
          23046,
          6093,
          11221,
          291,
          500,
          380,
          643,
          2319,
          42,
          11092,
          11,
          50788
        ]
      },
      {
        "avg_logprob": -0.40540650639220743,
        "compression_ratio": 1.599264705882353,
        "end": 2987.1400000000003,
        "id": 1244,
        "no_speech_prob": 0.01495156530290842,
        "seek": 297630,
        "start": 2984.78,
        "temperature": 0,
        "text": " only 100, and then you can do the channel name thing.",
        "tokens": [
          50788,
          787,
          2319,
          11,
          293,
          550,
          291,
          393,
          360,
          264,
          2269,
          1315,
          551,
          13,
          50906
        ]
      },
      {
        "avg_logprob": -0.40540650639220743,
        "compression_ratio": 1.599264705882353,
        "end": 2989.98,
        "id": 1245,
        "no_speech_prob": 0.01495156530290842,
        "seek": 297630,
        "start": 2987.1400000000003,
        "temperature": 0,
        "text": " So you could get YouTube.com slash Jabril's or.",
        "tokens": [
          50906,
          407,
          291,
          727,
          483,
          3088,
          13,
          1112,
          17330,
          40319,
          24216,
          311,
          420,
          13,
          51048
        ]
      },
      {
        "avg_logprob": -0.40540650639220743,
        "compression_ratio": 1.599264705882353,
        "end": 2990.86,
        "id": 1246,
        "no_speech_prob": 0.01495156530290842,
        "seek": 297630,
        "start": 2989.98,
        "temperature": 0,
        "text": " Ah, ah.",
        "tokens": [
          51048,
          2438,
          11,
          3716,
          13,
          51092
        ]
      },
      {
        "avg_logprob": -0.40540650639220743,
        "compression_ratio": 1.599264705882353,
        "end": 2993.26,
        "id": 1247,
        "no_speech_prob": 0.01495156530290842,
        "seek": 297630,
        "start": 2990.86,
        "temperature": 0,
        "text": " I can't say that, stuff stuff.",
        "tokens": [
          51092,
          286,
          393,
          380,
          584,
          300,
          11,
          1507,
          1507,
          13,
          51212
        ]
      },
      {
        "avg_logprob": -0.40540650639220743,
        "compression_ratio": 1.599264705882353,
        "end": 2996.82,
        "id": 1248,
        "no_speech_prob": 0.01495156530290842,
        "seek": 297630,
        "start": 2994.6200000000003,
        "temperature": 0,
        "text": " All right, so let me see.",
        "tokens": [
          51280,
          1057,
          558,
          11,
          370,
          718,
          385,
          536,
          13,
          51390
        ]
      },
      {
        "avg_logprob": -0.40540650639220743,
        "compression_ratio": 1.599264705882353,
        "end": 3000.6200000000003,
        "id": 1249,
        "no_speech_prob": 0.01495156530290842,
        "seek": 297630,
        "start": 2996.82,
        "temperature": 0,
        "text": " Let me just check the ask Jabril hashtag on Twitter.",
        "tokens": [
          51390,
          961,
          385,
          445,
          1520,
          264,
          1029,
          40319,
          24216,
          20379,
          322,
          5794,
          13,
          51580
        ]
      },
      {
        "avg_logprob": -0.40540650639220743,
        "compression_ratio": 1.599264705882353,
        "end": 3002.7400000000002,
        "id": 1250,
        "no_speech_prob": 0.01495156530290842,
        "seek": 297630,
        "start": 3000.6200000000003,
        "temperature": 0,
        "text": " Maybe that's, see if there's anything.",
        "tokens": [
          51580,
          2704,
          300,
          311,
          11,
          536,
          498,
          456,
          311,
          1340,
          13,
          51686
        ]
      },
      {
        "avg_logprob": -0.40540650639220743,
        "compression_ratio": 1.599264705882353,
        "end": 3004.98,
        "id": 1251,
        "no_speech_prob": 0.01495156530290842,
        "seek": 297630,
        "start": 3002.7400000000002,
        "temperature": 0,
        "text": " No, okay, anything else?",
        "tokens": [
          51686,
          883,
          11,
          1392,
          11,
          1340,
          1646,
          30,
          51798
        ]
      },
      {
        "avg_logprob": -0.24637884177908992,
        "compression_ratio": 1.5794701986754967,
        "end": 3007.62,
        "id": 1252,
        "no_speech_prob": 0.00012930856610182673,
        "seek": 300498,
        "start": 3005.02,
        "temperature": 0,
        "text": " There actually, somebody used this earlier in 2012.",
        "tokens": [
          50366,
          821,
          767,
          11,
          2618,
          1143,
          341,
          3071,
          294,
          9125,
          13,
          50496
        ]
      },
      {
        "avg_logprob": -0.24637884177908992,
        "compression_ratio": 1.5794701986754967,
        "end": 3008.7400000000002,
        "id": 1253,
        "no_speech_prob": 0.00012930856610182673,
        "seek": 300498,
        "start": 3007.62,
        "temperature": 0,
        "text": " There's some weird.",
        "tokens": [
          50496,
          821,
          311,
          512,
          3657,
          13,
          50552
        ]
      },
      {
        "avg_logprob": -0.24637884177908992,
        "compression_ratio": 1.5794701986754967,
        "end": 3009.58,
        "id": 1254,
        "no_speech_prob": 0.00012930856610182673,
        "seek": 300498,
        "start": 3008.7400000000002,
        "temperature": 0,
        "text": " Oh interesting.",
        "tokens": [
          50552,
          876,
          1880,
          13,
          50594
        ]
      },
      {
        "avg_logprob": -0.24637884177908992,
        "compression_ratio": 1.5794701986754967,
        "end": 3010.86,
        "id": 1255,
        "no_speech_prob": 0.00012930856610182673,
        "seek": 300498,
        "start": 3009.58,
        "temperature": 0,
        "text": " So I should have made this ask,",
        "tokens": [
          50594,
          407,
          286,
          820,
          362,
          1027,
          341,
          1029,
          11,
          50658
        ]
      },
      {
        "avg_logprob": -0.24637884177908992,
        "compression_ratio": 1.5794701986754967,
        "end": 3013.34,
        "id": 1256,
        "no_speech_prob": 0.00012930856610182673,
        "seek": 300498,
        "start": 3010.86,
        "temperature": 0,
        "text": " let's see Jabril's with the S.",
        "tokens": [
          50658,
          718,
          311,
          536,
          40319,
          24216,
          311,
          365,
          264,
          318,
          13,
          50782
        ]
      },
      {
        "avg_logprob": -0.24637884177908992,
        "compression_ratio": 1.5794701986754967,
        "end": 3014.34,
        "id": 1257,
        "no_speech_prob": 0.00012930856610182673,
        "seek": 300498,
        "start": 3013.34,
        "temperature": 0,
        "text": " Let's see if that shows up.",
        "tokens": [
          50782,
          961,
          311,
          536,
          498,
          300,
          3110,
          493,
          13,
          50832
        ]
      },
      {
        "avg_logprob": -0.24637884177908992,
        "compression_ratio": 1.5794701986754967,
        "end": 3016.18,
        "id": 1258,
        "no_speech_prob": 0.00012930856610182673,
        "seek": 300498,
        "start": 3014.34,
        "temperature": 0,
        "text": " Ah yeah, so next time, you're not seeing this,",
        "tokens": [
          50832,
          2438,
          1338,
          11,
          370,
          958,
          565,
          11,
          291,
          434,
          406,
          2577,
          341,
          11,
          50924
        ]
      },
      {
        "avg_logprob": -0.24637884177908992,
        "compression_ratio": 1.5794701986754967,
        "end": 3019.14,
        "id": 1259,
        "no_speech_prob": 0.00012930856610182673,
        "seek": 300498,
        "start": 3016.18,
        "temperature": 0,
        "text": " but next time we'll do a different hashtag.",
        "tokens": [
          50924,
          457,
          958,
          565,
          321,
          603,
          360,
          257,
          819,
          20379,
          13,
          51072
        ]
      },
      {
        "avg_logprob": -0.24637884177908992,
        "compression_ratio": 1.5794701986754967,
        "end": 3019.98,
        "id": 1260,
        "no_speech_prob": 0.00012930856610182673,
        "seek": 300498,
        "start": 3019.14,
        "temperature": 0,
        "text": " Anyway.",
        "tokens": [
          51072,
          5684,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.24637884177908992,
        "compression_ratio": 1.5794701986754967,
        "end": 3020.82,
        "id": 1261,
        "no_speech_prob": 0.00012930856610182673,
        "seek": 300498,
        "start": 3019.98,
        "temperature": 0,
        "text": " Very cool.",
        "tokens": [
          51114,
          4372,
          1627,
          13,
          51156
        ]
      },
      {
        "avg_logprob": -0.24637884177908992,
        "compression_ratio": 1.5794701986754967,
        "end": 3021.64,
        "id": 1262,
        "no_speech_prob": 0.00012930856610182673,
        "seek": 300498,
        "start": 3020.82,
        "temperature": 0,
        "text": " So what time is it?",
        "tokens": [
          51156,
          407,
          437,
          565,
          307,
          309,
          30,
          51197
        ]
      },
      {
        "avg_logprob": -0.24637884177908992,
        "compression_ratio": 1.5794701986754967,
        "end": 3022.7400000000002,
        "id": 1263,
        "no_speech_prob": 0.00012930856610182673,
        "seek": 300498,
        "start": 3021.64,
        "temperature": 0,
        "text": " It is four o'clock.",
        "tokens": [
          51197,
          467,
          307,
          1451,
          277,
          6,
          9023,
          13,
          51252
        ]
      },
      {
        "avg_logprob": -0.24637884177908992,
        "compression_ratio": 1.5794701986754967,
        "end": 3026.86,
        "id": 1264,
        "no_speech_prob": 0.00012930856610182673,
        "seek": 300498,
        "start": 3022.7400000000002,
        "temperature": 0,
        "text": " That means I have to leave and go catch my coding train.",
        "tokens": [
          51252,
          663,
          1355,
          286,
          362,
          281,
          1856,
          293,
          352,
          3745,
          452,
          17720,
          3847,
          13,
          51458
        ]
      },
      {
        "avg_logprob": -0.24637884177908992,
        "compression_ratio": 1.5794701986754967,
        "end": 3031.94,
        "id": 1265,
        "no_speech_prob": 0.00012930856610182673,
        "seek": 300498,
        "start": 3027.94,
        "temperature": 0,
        "text": " So I will be back for sure next Friday.",
        "tokens": [
          51512,
          407,
          286,
          486,
          312,
          646,
          337,
          988,
          958,
          6984,
          13,
          51712
        ]
      },
      {
        "avg_logprob": -0.24637884177908992,
        "compression_ratio": 1.5794701986754967,
        "end": 3034.42,
        "id": 1266,
        "no_speech_prob": 0.00012930856610182673,
        "seek": 300498,
        "start": 3031.94,
        "temperature": 0,
        "text": " I hope that we'll be able to do more collaborations",
        "tokens": [
          51712,
          286,
          1454,
          300,
          321,
          603,
          312,
          1075,
          281,
          360,
          544,
          36908,
          51836
        ]
      },
      {
        "avg_logprob": -0.2851269780373087,
        "compression_ratio": 1.6327868852459015,
        "end": 3035.7000000000003,
        "id": 1267,
        "no_speech_prob": 0.01115624513477087,
        "seek": 303442,
        "start": 3034.86,
        "temperature": 0,
        "text": " like this.",
        "tokens": [
          50386,
          411,
          341,
          13,
          50428
        ]
      },
      {
        "avg_logprob": -0.2851269780373087,
        "compression_ratio": 1.6327868852459015,
        "end": 3037.9,
        "id": 1268,
        "no_speech_prob": 0.01115624513477087,
        "seek": 303442,
        "start": 3035.7000000000003,
        "temperature": 0,
        "text": " Jabril's based in San Diego, right?",
        "tokens": [
          50428,
          40319,
          24216,
          311,
          2361,
          294,
          5271,
          16377,
          11,
          558,
          30,
          50538
        ]
      },
      {
        "avg_logprob": -0.2851269780373087,
        "compression_ratio": 1.6327868852459015,
        "end": 3040.38,
        "id": 1269,
        "no_speech_prob": 0.01115624513477087,
        "seek": 303442,
        "start": 3037.9,
        "temperature": 0,
        "text": " So we do not, even though San Diego sounds dreamy to me,",
        "tokens": [
          50538,
          407,
          321,
          360,
          406,
          11,
          754,
          1673,
          5271,
          16377,
          3263,
          3055,
          88,
          281,
          385,
          11,
          50662
        ]
      },
      {
        "avg_logprob": -0.2851269780373087,
        "compression_ratio": 1.6327868852459015,
        "end": 3042.54,
        "id": 1270,
        "no_speech_prob": 0.01115624513477087,
        "seek": 303442,
        "start": 3040.38,
        "temperature": 0,
        "text": " so I'm not gonna have to go on a trip there sometime.",
        "tokens": [
          50662,
          370,
          286,
          478,
          406,
          799,
          362,
          281,
          352,
          322,
          257,
          4931,
          456,
          15053,
          13,
          50770
        ]
      },
      {
        "avg_logprob": -0.2851269780373087,
        "compression_ratio": 1.6327868852459015,
        "end": 3046.38,
        "id": 1271,
        "no_speech_prob": 0.01115624513477087,
        "seek": 303442,
        "start": 3042.54,
        "temperature": 0,
        "text": " But AwakeMe asks, when is the next coding challenge?",
        "tokens": [
          50770,
          583,
          6381,
          619,
          12671,
          8962,
          11,
          562,
          307,
          264,
          958,
          17720,
          3430,
          30,
          50962
        ]
      },
      {
        "avg_logprob": -0.2851269780373087,
        "compression_ratio": 1.6327868852459015,
        "end": 3050.06,
        "id": 1272,
        "no_speech_prob": 0.01115624513477087,
        "seek": 303442,
        "start": 3046.38,
        "temperature": 0,
        "text": " So I'll probably do coding challenges again next Friday.",
        "tokens": [
          50962,
          407,
          286,
          603,
          1391,
          360,
          17720,
          4759,
          797,
          958,
          6984,
          13,
          51146
        ]
      },
      {
        "avg_logprob": -0.2851269780373087,
        "compression_ratio": 1.6327868852459015,
        "end": 3052.78,
        "id": 1273,
        "no_speech_prob": 0.01115624513477087,
        "seek": 303442,
        "start": 3050.06,
        "temperature": 0,
        "text": " If I can get it together, I'd like to try to at least",
        "tokens": [
          51146,
          759,
          286,
          393,
          483,
          309,
          1214,
          11,
          286,
          1116,
          411,
          281,
          853,
          281,
          412,
          1935,
          51282
        ]
      },
      {
        "avg_logprob": -0.2851269780373087,
        "compression_ratio": 1.6327868852459015,
        "end": 3056.26,
        "id": 1274,
        "no_speech_prob": 0.01115624513477087,
        "seek": 303442,
        "start": 3052.78,
        "temperature": 0,
        "text": " tackle this color predictor idea before next Friday.",
        "tokens": [
          51282,
          14896,
          341,
          2017,
          6069,
          284,
          1558,
          949,
          958,
          6984,
          13,
          51456
        ]
      },
      {
        "avg_logprob": -0.2851269780373087,
        "compression_ratio": 1.6327868852459015,
        "end": 3057.94,
        "id": 1275,
        "no_speech_prob": 0.01115624513477087,
        "seek": 303442,
        "start": 3056.26,
        "temperature": 0,
        "text": " Oh, let me show one thing.",
        "tokens": [
          51456,
          876,
          11,
          718,
          385,
          855,
          472,
          551,
          13,
          51540
        ]
      },
      {
        "avg_logprob": -0.2851269780373087,
        "compression_ratio": 1.6327868852459015,
        "end": 3059.1800000000003,
        "id": 1276,
        "no_speech_prob": 0.01115624513477087,
        "seek": 303442,
        "start": 3057.94,
        "temperature": 0,
        "text": " You can, I don't know where you want it,",
        "tokens": [
          51540,
          509,
          393,
          11,
          286,
          500,
          380,
          458,
          689,
          291,
          528,
          309,
          11,
          51602
        ]
      },
      {
        "avg_logprob": -0.2851269780373087,
        "compression_ratio": 1.6327868852459015,
        "end": 3062.38,
        "id": 1277,
        "no_speech_prob": 0.01115624513477087,
        "seek": 303442,
        "start": 3059.1800000000003,
        "temperature": 0,
        "text": " you can stand here, because I wanted to mention people,",
        "tokens": [
          51602,
          291,
          393,
          1463,
          510,
          11,
          570,
          286,
          1415,
          281,
          2152,
          561,
          11,
          51762
        ]
      },
      {
        "avg_logprob": -0.2529976908365885,
        "compression_ratio": 1.4437869822485208,
        "end": 3065.76,
        "id": 1278,
        "no_speech_prob": 0.00011235279816901311,
        "seek": 306238,
        "start": 3062.38,
        "temperature": 0,
        "text": " most recently I did a coding challenge about quadtrees.",
        "tokens": [
          50364,
          881,
          3938,
          286,
          630,
          257,
          17720,
          3430,
          466,
          10787,
          3599,
          279,
          13,
          50533
        ]
      },
      {
        "avg_logprob": -0.2529976908365885,
        "compression_ratio": 1.4437869822485208,
        "end": 3067.86,
        "id": 1279,
        "no_speech_prob": 0.00011235279816901311,
        "seek": 306238,
        "start": 3067.02,
        "temperature": 0,
        "text": " No, okay.",
        "tokens": [
          50596,
          883,
          11,
          1392,
          13,
          50638
        ]
      },
      {
        "avg_logprob": -0.2529976908365885,
        "compression_ratio": 1.4437869822485208,
        "end": 3072.6,
        "id": 1280,
        "no_speech_prob": 0.00011235279816901311,
        "seek": 306238,
        "start": 3067.86,
        "temperature": 0,
        "text": " So github.com slash coding train slash quadtree.",
        "tokens": [
          50638,
          407,
          290,
          355,
          836,
          13,
          1112,
          17330,
          17720,
          3847,
          17330,
          10787,
          83,
          701,
          13,
          50875
        ]
      },
      {
        "avg_logprob": -0.2529976908365885,
        "compression_ratio": 1.4437869822485208,
        "end": 3079.54,
        "id": 1281,
        "no_speech_prob": 0.00011235279816901311,
        "seek": 306238,
        "start": 3074.54,
        "temperature": 0,
        "text": " And so if you remember the code demo,",
        "tokens": [
          50972,
          400,
          370,
          498,
          291,
          1604,
          264,
          3089,
          10723,
          11,
          51222
        ]
      },
      {
        "avg_logprob": -0.2529976908365885,
        "compression_ratio": 1.4437869822485208,
        "end": 3086.04,
        "id": 1282,
        "no_speech_prob": 0.00011235279816901311,
        "seek": 306238,
        "start": 3081.04,
        "temperature": 0,
        "text": " this was what I did in my tutorial.",
        "tokens": [
          51297,
          341,
          390,
          437,
          286,
          630,
          294,
          452,
          7073,
          13,
          51547
        ]
      },
      {
        "avg_logprob": -0.2529976908365885,
        "compression_ratio": 1.4437869822485208,
        "end": 3091.6600000000003,
        "id": 1283,
        "no_speech_prob": 0.00011235279816901311,
        "seek": 306238,
        "start": 3087.3,
        "temperature": 0,
        "text": " So I just made a whole bunch of random points in space,",
        "tokens": [
          51610,
          407,
          286,
          445,
          1027,
          257,
          1379,
          3840,
          295,
          4974,
          2793,
          294,
          1901,
          11,
          51828
        ]
      },
      {
        "avg_logprob": -0.24908745125548482,
        "compression_ratio": 1.7028753993610224,
        "end": 3094.5,
        "id": 1284,
        "no_speech_prob": 0.000018925074982689694,
        "seek": 309166,
        "start": 3091.94,
        "temperature": 0,
        "text": " 2D space, then I registered them in this quadtree",
        "tokens": [
          50378,
          568,
          35,
          1901,
          11,
          550,
          286,
          13968,
          552,
          294,
          341,
          10787,
          83,
          701,
          50506
        ]
      },
      {
        "avg_logprob": -0.24908745125548482,
        "compression_ratio": 1.7028753993610224,
        "end": 3096.1,
        "id": 1285,
        "no_speech_prob": 0.000018925074982689694,
        "seek": 309166,
        "start": 3094.5,
        "temperature": 0,
        "text": " data structure, which you'd have to go back and watch",
        "tokens": [
          50506,
          1412,
          3877,
          11,
          597,
          291,
          1116,
          362,
          281,
          352,
          646,
          293,
          1159,
          50586
        ]
      },
      {
        "avg_logprob": -0.24908745125548482,
        "compression_ratio": 1.7028753993610224,
        "end": 3097.62,
        "id": 1286,
        "no_speech_prob": 0.000018925074982689694,
        "seek": 309166,
        "start": 3096.1,
        "temperature": 0,
        "text": " the videos to find out what that is.",
        "tokens": [
          50586,
          264,
          2145,
          281,
          915,
          484,
          437,
          300,
          307,
          13,
          50662
        ]
      },
      {
        "avg_logprob": -0.24908745125548482,
        "compression_ratio": 1.7028753993610224,
        "end": 3101.22,
        "id": 1287,
        "no_speech_prob": 0.000018925074982689694,
        "seek": 309166,
        "start": 3097.62,
        "temperature": 0,
        "text": " And then I had an algorithm that, in a hopefully faster way",
        "tokens": [
          50662,
          400,
          550,
          286,
          632,
          364,
          9284,
          300,
          11,
          294,
          257,
          4696,
          4663,
          636,
          50842
        ]
      },
      {
        "avg_logprob": -0.24908745125548482,
        "compression_ratio": 1.7028753993610224,
        "end": 3103.06,
        "id": 1288,
        "no_speech_prob": 0.000018925074982689694,
        "seek": 309166,
        "start": 3101.22,
        "temperature": 0,
        "text": " than iterating over all the points,",
        "tokens": [
          50842,
          813,
          17138,
          990,
          670,
          439,
          264,
          2793,
          11,
          50934
        ]
      },
      {
        "avg_logprob": -0.24908745125548482,
        "compression_ratio": 1.7028753993610224,
        "end": 3106.66,
        "id": 1289,
        "no_speech_prob": 0.000018925074982689694,
        "seek": 309166,
        "start": 3103.06,
        "temperature": 0,
        "text": " pulls out a selection of points within a certain radius.",
        "tokens": [
          50934,
          16982,
          484,
          257,
          9450,
          295,
          2793,
          1951,
          257,
          1629,
          15845,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.24908745125548482,
        "compression_ratio": 1.7028753993610224,
        "end": 3109.18,
        "id": 1290,
        "no_speech_prob": 0.000018925074982689694,
        "seek": 309166,
        "start": 3106.66,
        "temperature": 0,
        "text": " And actually, I didn't do the circular region",
        "tokens": [
          51114,
          400,
          767,
          11,
          286,
          994,
          380,
          360,
          264,
          16476,
          4458,
          51240
        ]
      },
      {
        "avg_logprob": -0.24908745125548482,
        "compression_ratio": 1.7028753993610224,
        "end": 3112.62,
        "id": 1291,
        "no_speech_prob": 0.000018925074982689694,
        "seek": 309166,
        "start": 3109.18,
        "temperature": 0,
        "text": " in the tutorials, somebody sent a pull request in",
        "tokens": [
          51240,
          294,
          264,
          17616,
          11,
          2618,
          2279,
          257,
          2235,
          5308,
          294,
          51412
        ]
      },
      {
        "avg_logprob": -0.24908745125548482,
        "compression_ratio": 1.7028753993610224,
        "end": 3115.14,
        "id": 1292,
        "no_speech_prob": 0.000018925074982689694,
        "seek": 309166,
        "start": 3112.62,
        "temperature": 0,
        "text": " after I uploaded the code for the circular region.",
        "tokens": [
          51412,
          934,
          286,
          17135,
          264,
          3089,
          337,
          264,
          16476,
          4458,
          13,
          51538
        ]
      },
      {
        "avg_logprob": -0.24908745125548482,
        "compression_ratio": 1.7028753993610224,
        "end": 3118.42,
        "id": 1293,
        "no_speech_prob": 0.000018925074982689694,
        "seek": 309166,
        "start": 3115.14,
        "temperature": 0,
        "text": " So then what I did, not, and I want to do this",
        "tokens": [
          51538,
          407,
          550,
          437,
          286,
          630,
          11,
          406,
          11,
          293,
          286,
          528,
          281,
          360,
          341,
          51702
        ]
      },
      {
        "avg_logprob": -0.24908745125548482,
        "compression_ratio": 1.7028753993610224,
        "end": 3121.2999999999997,
        "id": 1294,
        "no_speech_prob": 0.000018925074982689694,
        "seek": 309166,
        "start": 3118.42,
        "temperature": 0,
        "text": " as a coding challenge, but I did it in class,",
        "tokens": [
          51702,
          382,
          257,
          17720,
          3430,
          11,
          457,
          286,
          630,
          309,
          294,
          1508,
          11,
          51846
        ]
      },
      {
        "avg_logprob": -0.24272526093643076,
        "compression_ratio": 1.788888888888889,
        "end": 3123.6200000000003,
        "id": 1295,
        "no_speech_prob": 0.0000021568073407252086,
        "seek": 312130,
        "start": 3122.1400000000003,
        "temperature": 0,
        "text": " my NYU class earlier this week.",
        "tokens": [
          50406,
          452,
          42682,
          1508,
          3071,
          341,
          1243,
          13,
          50480
        ]
      },
      {
        "avg_logprob": -0.24272526093643076,
        "compression_ratio": 1.788888888888889,
        "end": 3127.6200000000003,
        "id": 1296,
        "no_speech_prob": 0.0000021568073407252086,
        "seek": 312130,
        "start": 3123.6200000000003,
        "temperature": 0,
        "text": " I did a collision detection test, so let's look at this.",
        "tokens": [
          50480,
          286,
          630,
          257,
          24644,
          17784,
          1500,
          11,
          370,
          718,
          311,
          574,
          412,
          341,
          13,
          50680
        ]
      },
      {
        "avg_logprob": -0.24272526093643076,
        "compression_ratio": 1.788888888888889,
        "end": 3131.02,
        "id": 1297,
        "no_speech_prob": 0.0000021568073407252086,
        "seek": 312130,
        "start": 3127.6200000000003,
        "temperature": 0,
        "text": " So this is just a simple example that has,",
        "tokens": [
          50680,
          407,
          341,
          307,
          445,
          257,
          2199,
          1365,
          300,
          575,
          11,
          50850
        ]
      },
      {
        "avg_logprob": -0.24272526093643076,
        "compression_ratio": 1.788888888888889,
        "end": 3133.5,
        "id": 1298,
        "no_speech_prob": 0.0000021568073407252086,
        "seek": 312130,
        "start": 3131.02,
        "temperature": 0,
        "text": " I believe there are one, oh yeah, it's down here.",
        "tokens": [
          50850,
          286,
          1697,
          456,
          366,
          472,
          11,
          1954,
          1338,
          11,
          309,
          311,
          760,
          510,
          13,
          50974
        ]
      },
      {
        "avg_logprob": -0.24272526093643076,
        "compression_ratio": 1.788888888888889,
        "end": 3135.92,
        "id": 1299,
        "no_speech_prob": 0.0000021568073407252086,
        "seek": 312130,
        "start": 3133.5,
        "temperature": 0,
        "text": " There are 1,000 particles.",
        "tokens": [
          50974,
          821,
          366,
          502,
          11,
          1360,
          10007,
          13,
          51095
        ]
      },
      {
        "avg_logprob": -0.24272526093643076,
        "compression_ratio": 1.788888888888889,
        "end": 3138.7000000000003,
        "id": 1300,
        "no_speech_prob": 0.0000021568073407252086,
        "seek": 312130,
        "start": 3137.1000000000004,
        "temperature": 0,
        "text": " You have such a nice smile on your face.",
        "tokens": [
          51154,
          509,
          362,
          1270,
          257,
          1481,
          7563,
          322,
          428,
          1851,
          13,
          51234
        ]
      },
      {
        "avg_logprob": -0.24272526093643076,
        "compression_ratio": 1.788888888888889,
        "end": 3141.7000000000003,
        "id": 1301,
        "no_speech_prob": 0.0000021568073407252086,
        "seek": 312130,
        "start": 3138.7000000000003,
        "temperature": 0,
        "text": " There are 1,000 particles and I'm testing",
        "tokens": [
          51234,
          821,
          366,
          502,
          11,
          1360,
          10007,
          293,
          286,
          478,
          4997,
          51384
        ]
      },
      {
        "avg_logprob": -0.24272526093643076,
        "compression_ratio": 1.788888888888889,
        "end": 3144.1400000000003,
        "id": 1302,
        "no_speech_prob": 0.0000021568073407252086,
        "seek": 312130,
        "start": 3141.7000000000003,
        "temperature": 0,
        "text": " if they are intersecting, and when they're intersecting",
        "tokens": [
          51384,
          498,
          436,
          366,
          27815,
          278,
          11,
          293,
          562,
          436,
          434,
          27815,
          278,
          51506
        ]
      },
      {
        "avg_logprob": -0.24272526093643076,
        "compression_ratio": 1.788888888888889,
        "end": 3146.34,
        "id": 1303,
        "no_speech_prob": 0.0000021568073407252086,
        "seek": 312130,
        "start": 3144.1400000000003,
        "temperature": 0,
        "text": " they're highlighted white, when they're not intersecting",
        "tokens": [
          51506,
          436,
          434,
          17173,
          2418,
          11,
          562,
          436,
          434,
          406,
          27815,
          278,
          51616
        ]
      },
      {
        "avg_logprob": -0.24272526093643076,
        "compression_ratio": 1.788888888888889,
        "end": 3147.98,
        "id": 1304,
        "no_speech_prob": 0.0000021568073407252086,
        "seek": 312130,
        "start": 3146.34,
        "temperature": 0,
        "text": " they're just gray.",
        "tokens": [
          51616,
          436,
          434,
          445,
          10855,
          13,
          51698
        ]
      },
      {
        "avg_logprob": -0.24272526093643076,
        "compression_ratio": 1.788888888888889,
        "end": 3150.98,
        "id": 1305,
        "no_speech_prob": 0.0000021568073407252086,
        "seek": 312130,
        "start": 3147.98,
        "temperature": 0,
        "text": " And you can see I'm getting a pretty reasonable frame rate.",
        "tokens": [
          51698,
          400,
          291,
          393,
          536,
          286,
          478,
          1242,
          257,
          1238,
          10585,
          3920,
          3314,
          13,
          51848
        ]
      },
      {
        "avg_logprob": -0.1960377950926085,
        "compression_ratio": 1.7602739726027397,
        "end": 3153.14,
        "id": 1306,
        "no_speech_prob": 0.00000936867218115367,
        "seek": 315098,
        "start": 3151.7,
        "temperature": 0,
        "text": " I bet you I'm getting kind of a lower,",
        "tokens": [
          50400,
          286,
          778,
          291,
          286,
          478,
          1242,
          733,
          295,
          257,
          3126,
          11,
          50472
        ]
      },
      {
        "avg_logprob": -0.1960377950926085,
        "compression_ratio": 1.7602739726027397,
        "end": 3155.46,
        "id": 1307,
        "no_speech_prob": 0.00000936867218115367,
        "seek": 315098,
        "start": 3153.14,
        "temperature": 0,
        "text": " I was getting 60 frames per second, no problem,",
        "tokens": [
          50472,
          286,
          390,
          1242,
          4060,
          12083,
          680,
          1150,
          11,
          572,
          1154,
          11,
          50588
        ]
      },
      {
        "avg_logprob": -0.1960377950926085,
        "compression_ratio": 1.7602739726027397,
        "end": 3158.14,
        "id": 1308,
        "no_speech_prob": 0.00000936867218115367,
        "seek": 315098,
        "start": 3155.46,
        "temperature": 0,
        "text": " when I tried this, so maybe it's just this computer",
        "tokens": [
          50588,
          562,
          286,
          3031,
          341,
          11,
          370,
          1310,
          309,
          311,
          445,
          341,
          3820,
          50722
        ]
      },
      {
        "avg_logprob": -0.1960377950926085,
        "compression_ratio": 1.7602739726027397,
        "end": 3161.94,
        "id": 1309,
        "no_speech_prob": 0.00000936867218115367,
        "seek": 315098,
        "start": 3158.14,
        "temperature": 0,
        "text": " because it's hooked up to the streaming system",
        "tokens": [
          50722,
          570,
          309,
          311,
          20410,
          493,
          281,
          264,
          11791,
          1185,
          50912
        ]
      },
      {
        "avg_logprob": -0.1960377950926085,
        "compression_ratio": 1.7602739726027397,
        "end": 3163.88,
        "id": 1310,
        "no_speech_prob": 0.00000936867218115367,
        "seek": 315098,
        "start": 3161.94,
        "temperature": 0,
        "text": " or there's other things in the browser",
        "tokens": [
          50912,
          420,
          456,
          311,
          661,
          721,
          294,
          264,
          11185,
          51009
        ]
      },
      {
        "avg_logprob": -0.1960377950926085,
        "compression_ratio": 1.7602739726027397,
        "end": 3166.54,
        "id": 1311,
        "no_speech_prob": 0.00000936867218115367,
        "seek": 315098,
        "start": 3163.88,
        "temperature": 0,
        "text": " like the Twitch channel going, but anyway.",
        "tokens": [
          51009,
          411,
          264,
          22222,
          2269,
          516,
          11,
          457,
          4033,
          13,
          51142
        ]
      },
      {
        "avg_logprob": -0.1960377950926085,
        "compression_ratio": 1.7602739726027397,
        "end": 3169.7,
        "id": 1312,
        "no_speech_prob": 0.00000936867218115367,
        "seek": 315098,
        "start": 3166.54,
        "temperature": 0,
        "text": " The point is, I'm going to uncheck this using quadtree.",
        "tokens": [
          51142,
          440,
          935,
          307,
          11,
          286,
          478,
          516,
          281,
          46672,
          341,
          1228,
          10787,
          83,
          701,
          13,
          51300
        ]
      },
      {
        "avg_logprob": -0.1960377950926085,
        "compression_ratio": 1.7602739726027397,
        "end": 3171.98,
        "id": 1313,
        "no_speech_prob": 0.00000936867218115367,
        "seek": 315098,
        "start": 3169.7,
        "temperature": 0,
        "text": " So as soon as I uncheck this using quadtree,",
        "tokens": [
          51300,
          407,
          382,
          2321,
          382,
          286,
          46672,
          341,
          1228,
          10787,
          83,
          701,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.1960377950926085,
        "compression_ratio": 1.7602739726027397,
        "end": 3176.18,
        "id": 1314,
        "no_speech_prob": 0.00000936867218115367,
        "seek": 315098,
        "start": 3171.98,
        "temperature": 0,
        "text": " it's going to, for every dot, iterate over all the dots",
        "tokens": [
          51414,
          309,
          311,
          516,
          281,
          11,
          337,
          633,
          5893,
          11,
          44497,
          670,
          439,
          264,
          15026,
          51624
        ]
      },
      {
        "avg_logprob": -0.1960377950926085,
        "compression_ratio": 1.7602739726027397,
        "end": 3178.3,
        "id": 1315,
        "no_speech_prob": 0.00000936867218115367,
        "seek": 315098,
        "start": 3176.18,
        "temperature": 0,
        "text": " instead of using the quadtree.",
        "tokens": [
          51624,
          2602,
          295,
          1228,
          264,
          10787,
          83,
          701,
          13,
          51730
        ]
      },
      {
        "avg_logprob": -0.1960377950926085,
        "compression_ratio": 1.7602739726027397,
        "end": 3180.54,
        "id": 1316,
        "no_speech_prob": 0.00000936867218115367,
        "seek": 315098,
        "start": 3178.3,
        "temperature": 0,
        "text": " And you can see now I'm at four or five frames per second.",
        "tokens": [
          51730,
          400,
          291,
          393,
          536,
          586,
          286,
          478,
          412,
          1451,
          420,
          1732,
          12083,
          680,
          1150,
          13,
          51842
        ]
      },
      {
        "avg_logprob": -0.22633122726225516,
        "compression_ratio": 1.6889632107023411,
        "end": 3182.94,
        "id": 1317,
        "no_speech_prob": 0.0000030414475986617617,
        "seek": 318054,
        "start": 3181.3,
        "temperature": 0,
        "text": " So we can see how the quadtree, at least,",
        "tokens": [
          50402,
          407,
          321,
          393,
          536,
          577,
          264,
          10787,
          83,
          701,
          11,
          412,
          1935,
          11,
          50484
        ]
      },
      {
        "avg_logprob": -0.22633122726225516,
        "compression_ratio": 1.6889632107023411,
        "end": 3185.1,
        "id": 1318,
        "no_speech_prob": 0.0000030414475986617617,
        "seek": 318054,
        "start": 3182.94,
        "temperature": 0,
        "text": " even though I did get a lot of comments",
        "tokens": [
          50484,
          754,
          1673,
          286,
          630,
          483,
          257,
          688,
          295,
          3053,
          50592
        ]
      },
      {
        "avg_logprob": -0.22633122726225516,
        "compression_ratio": 1.6889632107023411,
        "end": 3188.06,
        "id": 1319,
        "no_speech_prob": 0.0000030414475986617617,
        "seek": 318054,
        "start": 3185.1,
        "temperature": 0,
        "text": " along the lines of, you're doing your quadtree incorrectly,",
        "tokens": [
          50592,
          2051,
          264,
          3876,
          295,
          11,
          291,
          434,
          884,
          428,
          10787,
          83,
          701,
          42892,
          11,
          50740
        ]
      },
      {
        "avg_logprob": -0.22633122726225516,
        "compression_ratio": 1.6889632107023411,
        "end": 3190.54,
        "id": 1320,
        "no_speech_prob": 0.0000030414475986617617,
        "seek": 318054,
        "start": 3188.06,
        "temperature": 0,
        "text": " there's ways of making it better and more efficient.",
        "tokens": [
          50740,
          456,
          311,
          2098,
          295,
          1455,
          309,
          1101,
          293,
          544,
          7148,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.22633122726225516,
        "compression_ratio": 1.6889632107023411,
        "end": 3193.42,
        "id": 1321,
        "no_speech_prob": 0.0000030414475986617617,
        "seek": 318054,
        "start": 3190.54,
        "temperature": 0,
        "text": " And two is, why are you doing a quadtree in JavaScript?",
        "tokens": [
          50864,
          400,
          732,
          307,
          11,
          983,
          366,
          291,
          884,
          257,
          10787,
          83,
          701,
          294,
          15778,
          30,
          51008
        ]
      },
      {
        "avg_logprob": -0.22633122726225516,
        "compression_ratio": 1.6889632107023411,
        "end": 3195.7799999999997,
        "id": 1322,
        "no_speech_prob": 0.0000030414475986617617,
        "seek": 318054,
        "start": 3193.42,
        "temperature": 0,
        "text": " That's sort of silly, it's not going to be very fast.",
        "tokens": [
          51008,
          663,
          311,
          1333,
          295,
          11774,
          11,
          309,
          311,
          406,
          516,
          281,
          312,
          588,
          2370,
          13,
          51126
        ]
      },
      {
        "avg_logprob": -0.22633122726225516,
        "compression_ratio": 1.6889632107023411,
        "end": 3198.22,
        "id": 1323,
        "no_speech_prob": 0.0000030414475986617617,
        "seek": 318054,
        "start": 3195.7799999999997,
        "temperature": 0,
        "text": " And so while all of those points are valid and true,",
        "tokens": [
          51126,
          400,
          370,
          1339,
          439,
          295,
          729,
          2793,
          366,
          7363,
          293,
          2074,
          11,
          51248
        ]
      },
      {
        "avg_logprob": -0.22633122726225516,
        "compression_ratio": 1.6889632107023411,
        "end": 3201.82,
        "id": 1324,
        "no_speech_prob": 0.0000030414475986617617,
        "seek": 318054,
        "start": 3198.22,
        "temperature": 0,
        "text": " I would say, you can see that even with all of my failings",
        "tokens": [
          51248,
          286,
          576,
          584,
          11,
          291,
          393,
          536,
          300,
          754,
          365,
          439,
          295,
          452,
          3061,
          1109,
          51428
        ]
      },
      {
        "avg_logprob": -0.22633122726225516,
        "compression_ratio": 1.6889632107023411,
        "end": 3204.3,
        "id": 1325,
        "no_speech_prob": 0.0000030414475986617617,
        "seek": 318054,
        "start": 3201.82,
        "temperature": 0,
        "text": " as a programmer and using JavaScript,",
        "tokens": [
          51428,
          382,
          257,
          32116,
          293,
          1228,
          15778,
          11,
          51552
        ]
      },
      {
        "avg_logprob": -0.22633122726225516,
        "compression_ratio": 1.6889632107023411,
        "end": 3207.4,
        "id": 1326,
        "no_speech_prob": 0.0000030414475986617617,
        "seek": 318054,
        "start": 3204.3,
        "temperature": 0,
        "text": " I'm still getting an incredible speed performance.",
        "tokens": [
          51552,
          286,
          478,
          920,
          1242,
          364,
          4651,
          3073,
          3389,
          13,
          51707
        ]
      },
      {
        "avg_logprob": -0.25776704775741677,
        "compression_ratio": 1.6725352112676057,
        "end": 3210.88,
        "id": 1327,
        "no_speech_prob": 0.000008530172635801136,
        "seek": 320740,
        "start": 3207.4,
        "temperature": 0,
        "text": " And if I go down to, if I, you know,",
        "tokens": [
          50364,
          400,
          498,
          286,
          352,
          760,
          281,
          11,
          498,
          286,
          11,
          291,
          458,
          11,
          50538
        ]
      },
      {
        "avg_logprob": -0.25776704775741677,
        "compression_ratio": 1.6725352112676057,
        "end": 3213.7000000000003,
        "id": 1328,
        "no_speech_prob": 0.000008530172635801136,
        "seek": 320740,
        "start": 3210.88,
        "temperature": 0,
        "text": " I can see even with 3,000 particles,",
        "tokens": [
          50538,
          286,
          393,
          536,
          754,
          365,
          805,
          11,
          1360,
          10007,
          11,
          50679
        ]
      },
      {
        "avg_logprob": -0.25776704775741677,
        "compression_ratio": 1.6725352112676057,
        "end": 3215.82,
        "id": 1329,
        "no_speech_prob": 0.000008530172635801136,
        "seek": 320740,
        "start": 3213.7000000000003,
        "temperature": 0,
        "text": " I'm still getting 15 frames per second.",
        "tokens": [
          50679,
          286,
          478,
          920,
          1242,
          2119,
          12083,
          680,
          1150,
          13,
          50785
        ]
      },
      {
        "avg_logprob": -0.25776704775741677,
        "compression_ratio": 1.6725352112676057,
        "end": 3218.56,
        "id": 1330,
        "no_speech_prob": 0.000008530172635801136,
        "seek": 320740,
        "start": 3215.82,
        "temperature": 0,
        "text": " And if I uncheck this, I mean, just forget about it.",
        "tokens": [
          50785,
          400,
          498,
          286,
          46672,
          341,
          11,
          286,
          914,
          11,
          445,
          2870,
          466,
          309,
          13,
          50922
        ]
      },
      {
        "avg_logprob": -0.25776704775741677,
        "compression_ratio": 1.6725352112676057,
        "end": 3221.56,
        "id": 1331,
        "no_speech_prob": 0.000008530172635801136,
        "seek": 320740,
        "start": 3218.56,
        "temperature": 0,
        "text": " I don't even, you know, oops, it didn't even,",
        "tokens": [
          50922,
          286,
          500,
          380,
          754,
          11,
          291,
          458,
          11,
          34166,
          11,
          309,
          994,
          380,
          754,
          11,
          51072
        ]
      },
      {
        "avg_logprob": -0.25776704775741677,
        "compression_ratio": 1.6725352112676057,
        "end": 3224.1,
        "id": 1332,
        "no_speech_prob": 0.000008530172635801136,
        "seek": 320740,
        "start": 3221.56,
        "temperature": 0,
        "text": " it couldn't even, like, oh, you can't see",
        "tokens": [
          51072,
          309,
          2809,
          380,
          754,
          11,
          411,
          11,
          1954,
          11,
          291,
          393,
          380,
          536,
          51199
        ]
      },
      {
        "avg_logprob": -0.25776704775741677,
        "compression_ratio": 1.6725352112676057,
        "end": 3226.36,
        "id": 1333,
        "no_speech_prob": 0.000008530172635801136,
        "seek": 320740,
        "start": 3224.1,
        "temperature": 0,
        "text": " what just happened, it checked itself.",
        "tokens": [
          51199,
          437,
          445,
          2011,
          11,
          309,
          10033,
          2564,
          13,
          51312
        ]
      },
      {
        "avg_logprob": -0.25776704775741677,
        "compression_ratio": 1.6725352112676057,
        "end": 3227.52,
        "id": 1334,
        "no_speech_prob": 0.000008530172635801136,
        "seek": 320740,
        "start": 3226.36,
        "temperature": 0,
        "text": " No, no, it's okay.",
        "tokens": [
          51312,
          883,
          11,
          572,
          11,
          309,
          311,
          1392,
          13,
          51370
        ]
      },
      {
        "avg_logprob": -0.25776704775741677,
        "compression_ratio": 1.6725352112676057,
        "end": 3230.52,
        "id": 1335,
        "no_speech_prob": 0.000008530172635801136,
        "seek": 320740,
        "start": 3227.52,
        "temperature": 0,
        "text": " So you can see the frame rate is officially zero right now.",
        "tokens": [
          51370,
          407,
          291,
          393,
          536,
          264,
          3920,
          3314,
          307,
          12053,
          4018,
          558,
          586,
          13,
          51520
        ]
      },
      {
        "avg_logprob": -0.25776704775741677,
        "compression_ratio": 1.6725352112676057,
        "end": 3232.8,
        "id": 1336,
        "no_speech_prob": 0.000008530172635801136,
        "seek": 320740,
        "start": 3230.52,
        "temperature": 0,
        "text": " So if I can manage to check that again, we'll see.",
        "tokens": [
          51520,
          407,
          498,
          286,
          393,
          3067,
          281,
          1520,
          300,
          797,
          11,
          321,
          603,
          536,
          13,
          51634
        ]
      },
      {
        "avg_logprob": -0.25776704775741677,
        "compression_ratio": 1.6725352112676057,
        "end": 3235.76,
        "id": 1337,
        "no_speech_prob": 0.000008530172635801136,
        "seek": 320740,
        "start": 3232.8,
        "temperature": 0,
        "text": " So there is certainly, I'm sure, more optimizations",
        "tokens": [
          51634,
          407,
          456,
          307,
          3297,
          11,
          286,
          478,
          988,
          11,
          544,
          5028,
          14455,
          51782
        ]
      },
      {
        "avg_logprob": -0.25347475572065875,
        "compression_ratio": 1.5258964143426295,
        "end": 3239.36,
        "id": 1338,
        "no_speech_prob": 0.000026683108444558457,
        "seek": 323576,
        "start": 3235.76,
        "temperature": 0,
        "text": " that I could do, but there is a benefit.",
        "tokens": [
          50364,
          300,
          286,
          727,
          360,
          11,
          457,
          456,
          307,
          257,
          5121,
          13,
          50544
        ]
      },
      {
        "avg_logprob": -0.25347475572065875,
        "compression_ratio": 1.5258964143426295,
        "end": 3243.6400000000003,
        "id": 1339,
        "no_speech_prob": 0.000026683108444558457,
        "seek": 323576,
        "start": 3240.4,
        "temperature": 0,
        "text": " So I have a challenge for everybody watching.",
        "tokens": [
          50596,
          407,
          286,
          362,
          257,
          3430,
          337,
          2201,
          1976,
          13,
          50758
        ]
      },
      {
        "avg_logprob": -0.25347475572065875,
        "compression_ratio": 1.5258964143426295,
        "end": 3248.0400000000004,
        "id": 1340,
        "no_speech_prob": 0.000026683108444558457,
        "seek": 323576,
        "start": 3243.6400000000003,
        "temperature": 0,
        "text": " If anybody, right now everything is in this GitHub repo,",
        "tokens": [
          50758,
          759,
          4472,
          11,
          558,
          586,
          1203,
          307,
          294,
          341,
          23331,
          49040,
          11,
          50978
        ]
      },
      {
        "avg_logprob": -0.25347475572065875,
        "compression_ratio": 1.5258964143426295,
        "end": 3251.5600000000004,
        "id": 1341,
        "no_speech_prob": 0.000026683108444558457,
        "seek": 323576,
        "start": 3248.0400000000004,
        "temperature": 0,
        "text": " CodingTrain slash Quadtree, and you can see links",
        "tokens": [
          50978,
          383,
          8616,
          51,
          7146,
          17330,
          29619,
          83,
          701,
          11,
          293,
          291,
          393,
          536,
          6123,
          51154
        ]
      },
      {
        "avg_logprob": -0.25347475572065875,
        "compression_ratio": 1.5258964143426295,
        "end": 3255.7200000000003,
        "id": 1342,
        "no_speech_prob": 0.000026683108444558457,
        "seek": 323576,
        "start": 3251.5600000000004,
        "temperature": 0,
        "text": " to the video tutorials, the pseudocode Wikipedia page,",
        "tokens": [
          51154,
          281,
          264,
          960,
          17616,
          11,
          264,
          25505,
          532,
          905,
          1429,
          28999,
          3028,
          11,
          51362
        ]
      },
      {
        "avg_logprob": -0.25347475572065875,
        "compression_ratio": 1.5258964143426295,
        "end": 3257.1600000000003,
        "id": 1343,
        "no_speech_prob": 0.000026683108444558457,
        "seek": 323576,
        "start": 3255.7200000000003,
        "temperature": 0,
        "text": " and then these are the two examples.",
        "tokens": [
          51362,
          293,
          550,
          613,
          366,
          264,
          732,
          5110,
          13,
          51434
        ]
      },
      {
        "avg_logprob": -0.25347475572065875,
        "compression_ratio": 1.5258964143426295,
        "end": 3258.76,
        "id": 1344,
        "no_speech_prob": 0.000026683108444558457,
        "seek": 323576,
        "start": 3257.1600000000003,
        "temperature": 0,
        "text": " You're fine, you're fine.",
        "tokens": [
          51434,
          509,
          434,
          2489,
          11,
          291,
          434,
          2489,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.25347475572065875,
        "compression_ratio": 1.5258964143426295,
        "end": 3260.76,
        "id": 1345,
        "no_speech_prob": 0.000026683108444558457,
        "seek": 323576,
        "start": 3258.76,
        "temperature": 0,
        "text": " There's some other Quadtree libraries in JavaScript",
        "tokens": [
          51514,
          821,
          311,
          512,
          661,
          29619,
          83,
          701,
          15148,
          294,
          15778,
          51614
        ]
      },
      {
        "avg_logprob": -0.25347475572065875,
        "compression_ratio": 1.5258964143426295,
        "end": 3261.76,
        "id": 1346,
        "no_speech_prob": 0.000026683108444558457,
        "seek": 323576,
        "start": 3260.76,
        "temperature": 0,
        "text": " that are down here.",
        "tokens": [
          51614,
          300,
          366,
          760,
          510,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21891529376690205,
        "compression_ratio": 1.662962962962963,
        "end": 3265.8,
        "id": 1347,
        "no_speech_prob": 0.0000028572885639732704,
        "seek": 326176,
        "start": 3262.76,
        "temperature": 0,
        "text": " But I have a challenge for anyone,",
        "tokens": [
          50414,
          583,
          286,
          362,
          257,
          3430,
          337,
          2878,
          11,
          50566
        ]
      },
      {
        "avg_logprob": -0.21891529376690205,
        "compression_ratio": 1.662962962962963,
        "end": 3268.34,
        "id": 1348,
        "no_speech_prob": 0.0000028572885639732704,
        "seek": 326176,
        "start": 3265.8,
        "temperature": 0,
        "text": " which is that I would love to have another example here",
        "tokens": [
          50566,
          597,
          307,
          300,
          286,
          576,
          959,
          281,
          362,
          1071,
          1365,
          510,
          50693
        ]
      },
      {
        "avg_logprob": -0.21891529376690205,
        "compression_ratio": 1.662962962962963,
        "end": 3270.78,
        "id": 1349,
        "no_speech_prob": 0.0000028572885639732704,
        "seek": 326176,
        "start": 3268.34,
        "temperature": 0,
        "text": " that is a flocking with Quadtree.",
        "tokens": [
          50693,
          300,
          307,
          257,
          2591,
          25723,
          365,
          29619,
          83,
          701,
          13,
          50815
        ]
      },
      {
        "avg_logprob": -0.21891529376690205,
        "compression_ratio": 1.662962962962963,
        "end": 3272.6800000000003,
        "id": 1350,
        "no_speech_prob": 0.0000028572885639732704,
        "seek": 326176,
        "start": 3270.78,
        "temperature": 0,
        "text": " So I will be accepting pull requests",
        "tokens": [
          50815,
          407,
          286,
          486,
          312,
          17391,
          2235,
          12475,
          50910
        ]
      },
      {
        "avg_logprob": -0.21891529376690205,
        "compression_ratio": 1.662962962962963,
        "end": 3274.92,
        "id": 1351,
        "no_speech_prob": 0.0000028572885639732704,
        "seek": 326176,
        "start": 3272.6800000000003,
        "temperature": 0,
        "text": " if you want to make a flocking demo",
        "tokens": [
          50910,
          498,
          291,
          528,
          281,
          652,
          257,
          2591,
          25723,
          10723,
          51022
        ]
      },
      {
        "avg_logprob": -0.21891529376690205,
        "compression_ratio": 1.662962962962963,
        "end": 3276.48,
        "id": 1352,
        "no_speech_prob": 0.0000028572885639732704,
        "seek": 326176,
        "start": 3274.92,
        "temperature": 0,
        "text": " with this Quadtree code.",
        "tokens": [
          51022,
          365,
          341,
          29619,
          83,
          701,
          3089,
          13,
          51100
        ]
      },
      {
        "avg_logprob": -0.21891529376690205,
        "compression_ratio": 1.662962962962963,
        "end": 3278.1600000000003,
        "id": 1353,
        "no_speech_prob": 0.0000028572885639732704,
        "seek": 326176,
        "start": 3276.48,
        "temperature": 0,
        "text": " And I mean, I'll make this myself at some point,",
        "tokens": [
          51100,
          400,
          286,
          914,
          11,
          286,
          603,
          652,
          341,
          2059,
          412,
          512,
          935,
          11,
          51184
        ]
      },
      {
        "avg_logprob": -0.21891529376690205,
        "compression_ratio": 1.662962962962963,
        "end": 3280,
        "id": 1354,
        "no_speech_prob": 0.0000028572885639732704,
        "seek": 326176,
        "start": 3278.1600000000003,
        "temperature": 0,
        "text": " but I love to have people contribute.",
        "tokens": [
          51184,
          457,
          286,
          959,
          281,
          362,
          561,
          10586,
          13,
          51276
        ]
      },
      {
        "avg_logprob": -0.21891529376690205,
        "compression_ratio": 1.662962962962963,
        "end": 3282.32,
        "id": 1355,
        "no_speech_prob": 0.0000028572885639732704,
        "seek": 326176,
        "start": 3280,
        "temperature": 0,
        "text": " So that's one thing to see, like,",
        "tokens": [
          51276,
          407,
          300,
          311,
          472,
          551,
          281,
          536,
          11,
          411,
          11,
          51392
        ]
      },
      {
        "avg_logprob": -0.21891529376690205,
        "compression_ratio": 1.662962962962963,
        "end": 3285.0400000000004,
        "id": 1356,
        "no_speech_prob": 0.0000028572885639732704,
        "seek": 326176,
        "start": 3282.32,
        "temperature": 0,
        "text": " can I get a flocking simulation in JavaScript",
        "tokens": [
          51392,
          393,
          286,
          483,
          257,
          2591,
          25723,
          16575,
          294,
          15778,
          51528
        ]
      },
      {
        "avg_logprob": -0.21891529376690205,
        "compression_ratio": 1.662962962962963,
        "end": 3288.28,
        "id": 1357,
        "no_speech_prob": 0.0000028572885639732704,
        "seek": 326176,
        "start": 3285.0400000000004,
        "temperature": 0,
        "text": " with, like, 600 agents that's going to run reasonably well.",
        "tokens": [
          51528,
          365,
          11,
          411,
          11,
          11849,
          12554,
          300,
          311,
          516,
          281,
          1190,
          23551,
          731,
          13,
          51690
        ]
      },
      {
        "avg_logprob": -0.28518603515625,
        "compression_ratio": 1.58984375,
        "end": 3293.92,
        "id": 1358,
        "no_speech_prob": 0.0001355131098534912,
        "seek": 328828,
        "start": 3288.92,
        "temperature": 0,
        "text": " Um, okay, whoops, I'm getting a notification here.",
        "tokens": [
          50396,
          3301,
          11,
          1392,
          11,
          567,
          3370,
          11,
          286,
          478,
          1242,
          257,
          11554,
          510,
          13,
          50646
        ]
      },
      {
        "avg_logprob": -0.28518603515625,
        "compression_ratio": 1.58984375,
        "end": 3296.44,
        "id": 1359,
        "no_speech_prob": 0.0001355131098534912,
        "seek": 328828,
        "start": 3294.36,
        "temperature": 0,
        "text": " Oh, thank you, Sixy.",
        "tokens": [
          50668,
          876,
          11,
          1309,
          291,
          11,
          11678,
          88,
          13,
          50772
        ]
      },
      {
        "avg_logprob": -0.28518603515625,
        "compression_ratio": 1.58984375,
        "end": 3299.32,
        "id": 1360,
        "no_speech_prob": 0.0001355131098534912,
        "seek": 328828,
        "start": 3296.44,
        "temperature": 0,
        "text": " Sixy in the chat says, don't forget,",
        "tokens": [
          50772,
          11678,
          88,
          294,
          264,
          5081,
          1619,
          11,
          500,
          380,
          2870,
          11,
          50916
        ]
      },
      {
        "avg_logprob": -0.28518603515625,
        "compression_ratio": 1.58984375,
        "end": 3301.26,
        "id": 1361,
        "no_speech_prob": 0.0001355131098534912,
        "seek": 328828,
        "start": 3299.32,
        "temperature": 0,
        "text": " you have to do this before you leave.",
        "tokens": [
          50916,
          291,
          362,
          281,
          360,
          341,
          949,
          291,
          1856,
          13,
          51013
        ]
      },
      {
        "avg_logprob": -0.28518603515625,
        "compression_ratio": 1.58984375,
        "end": 3304.28,
        "id": 1362,
        "no_speech_prob": 0.0001355131098534912,
        "seek": 328828,
        "start": 3302.52,
        "temperature": 0,
        "text": " This means we're wrapping up here.",
        "tokens": [
          51076,
          639,
          1355,
          321,
          434,
          21993,
          493,
          510,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.28518603515625,
        "compression_ratio": 1.58984375,
        "end": 3306.7200000000003,
        "id": 1363,
        "no_speech_prob": 0.0001355131098534912,
        "seek": 328828,
        "start": 3304.28,
        "temperature": 0,
        "text": " You have to read some random numbers.",
        "tokens": [
          51164,
          509,
          362,
          281,
          1401,
          512,
          4974,
          3547,
          13,
          51286
        ]
      },
      {
        "avg_logprob": -0.28518603515625,
        "compression_ratio": 1.58984375,
        "end": 3308.28,
        "id": 1364,
        "no_speech_prob": 0.0001355131098534912,
        "seek": 328828,
        "start": 3306.7200000000003,
        "temperature": 0,
        "text": " Unfortunately, I don't have the soundboard",
        "tokens": [
          51286,
          8590,
          11,
          286,
          500,
          380,
          362,
          264,
          1626,
          3787,
          51364
        ]
      },
      {
        "avg_logprob": -0.28518603515625,
        "compression_ratio": 1.58984375,
        "end": 3309.28,
        "id": 1365,
        "no_speech_prob": 0.0001355131098534912,
        "seek": 328828,
        "start": 3308.28,
        "temperature": 0,
        "text": " for any lullaby music.",
        "tokens": [
          51364,
          337,
          604,
          287,
          858,
          2509,
          1318,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.28518603515625,
        "compression_ratio": 1.58984375,
        "end": 3311.6800000000003,
        "id": 1366,
        "no_speech_prob": 0.0001355131098534912,
        "seek": 328828,
        "start": 3309.28,
        "temperature": 0,
        "text": " You can pick a page, read whatever you like.",
        "tokens": [
          51414,
          509,
          393,
          1888,
          257,
          3028,
          11,
          1401,
          2035,
          291,
          411,
          13,
          51534
        ]
      },
      {
        "avg_logprob": -0.28518603515625,
        "compression_ratio": 1.58984375,
        "end": 3314,
        "id": 1367,
        "no_speech_prob": 0.0001355131098534912,
        "seek": 328828,
        "start": 3311.6800000000003,
        "temperature": 0,
        "text": " Take your time, enjoy.",
        "tokens": [
          51534,
          3664,
          428,
          565,
          11,
          2103,
          13,
          51650
        ]
      },
      {
        "avg_logprob": -0.28518603515625,
        "compression_ratio": 1.58984375,
        "end": 3316.6000000000004,
        "id": 1368,
        "no_speech_prob": 0.0001355131098534912,
        "seek": 328828,
        "start": 3314,
        "temperature": 0,
        "text": " I'll check the chat for any last important questions.",
        "tokens": [
          51650,
          286,
          603,
          1520,
          264,
          5081,
          337,
          604,
          1036,
          1021,
          1651,
          13,
          51780
        ]
      },
      {
        "avg_logprob": -0.31666412869015254,
        "compression_ratio": 1.6386861313868613,
        "end": 3321.6400000000003,
        "id": 1369,
        "no_speech_prob": 0.00004611208714777604,
        "seek": 331828,
        "start": 3319.1200000000003,
        "temperature": 0,
        "text": " You know what, this is silly to have",
        "tokens": [
          50406,
          509,
          458,
          437,
          11,
          341,
          307,
          11774,
          281,
          362,
          50532
        ]
      },
      {
        "avg_logprob": -0.31666412869015254,
        "compression_ratio": 1.6386861313868613,
        "end": 3323.6400000000003,
        "id": 1370,
        "no_speech_prob": 0.00004611208714777604,
        "seek": 331828,
        "start": 3321.6400000000003,
        "temperature": 0,
        "text": " the Quadtrees thing behind you.",
        "tokens": [
          50532,
          264,
          29619,
          3599,
          279,
          551,
          2261,
          291,
          13,
          50632
        ]
      },
      {
        "avg_logprob": -0.31666412869015254,
        "compression_ratio": 1.6386861313868613,
        "end": 3326.1600000000003,
        "id": 1371,
        "no_speech_prob": 0.00004611208714777604,
        "seek": 331828,
        "start": 3323.6400000000003,
        "temperature": 0,
        "text": " So let's, so I guess what probably makes,",
        "tokens": [
          50632,
          407,
          718,
          311,
          11,
          370,
          286,
          2041,
          437,
          1391,
          1669,
          11,
          50758
        ]
      },
      {
        "avg_logprob": -0.31666412869015254,
        "compression_ratio": 1.6386861313868613,
        "end": 3329.0400000000004,
        "id": 1372,
        "no_speech_prob": 0.00004611208714777604,
        "seek": 331828,
        "start": 3326.1600000000003,
        "temperature": 0,
        "text": " options are your own website, or just like the full,",
        "tokens": [
          50758,
          3956,
          366,
          428,
          1065,
          3144,
          11,
          420,
          445,
          411,
          264,
          1577,
          11,
          50902
        ]
      },
      {
        "avg_logprob": -0.31666412869015254,
        "compression_ratio": 1.6386861313868613,
        "end": 3330.36,
        "id": 1373,
        "no_speech_prob": 0.00004611208714777604,
        "seek": 331828,
        "start": 3329.0400000000004,
        "temperature": 0,
        "text": " let's just give you the full code.",
        "tokens": [
          50902,
          718,
          311,
          445,
          976,
          291,
          264,
          1577,
          3089,
          13,
          50968
        ]
      },
      {
        "avg_logprob": -0.31666412869015254,
        "compression_ratio": 1.6386861313868613,
        "end": 3332.1200000000003,
        "id": 1374,
        "no_speech_prob": 0.00004611208714777604,
        "seek": 331828,
        "start": 3330.36,
        "temperature": 0,
        "text": " Do I get the soundtrack?",
        "tokens": [
          50968,
          1144,
          286,
          483,
          264,
          27029,
          30,
          51056
        ]
      },
      {
        "avg_logprob": -0.31666412869015254,
        "compression_ratio": 1.6386861313868613,
        "end": 3333.8,
        "id": 1375,
        "no_speech_prob": 0.00004611208714777604,
        "seek": 331828,
        "start": 3332.1200000000003,
        "temperature": 0,
        "text": " I don't have it hooked up right now.",
        "tokens": [
          51056,
          286,
          500,
          380,
          362,
          309,
          20410,
          493,
          558,
          586,
          13,
          51140
        ]
      },
      {
        "avg_logprob": -0.31666412869015254,
        "compression_ratio": 1.6386861313868613,
        "end": 3334.6200000000003,
        "id": 1376,
        "no_speech_prob": 0.00004611208714777604,
        "seek": 331828,
        "start": 3333.8,
        "temperature": 0,
        "text": " Dang it.",
        "tokens": [
          51140,
          29580,
          309,
          13,
          51181
        ]
      },
      {
        "avg_logprob": -0.31666412869015254,
        "compression_ratio": 1.6386861313868613,
        "end": 3335.46,
        "id": 1377,
        "no_speech_prob": 0.00004611208714777604,
        "seek": 331828,
        "start": 3334.6200000000003,
        "temperature": 0,
        "text": " I can.",
        "tokens": [
          51181,
          286,
          393,
          13,
          51223
        ]
      },
      {
        "avg_logprob": -0.31666412869015254,
        "compression_ratio": 1.6386861313868613,
        "end": 3336.28,
        "id": 1378,
        "no_speech_prob": 0.00004611208714777604,
        "seek": 331828,
        "start": 3335.46,
        "temperature": 0,
        "text": " Dang it.",
        "tokens": [
          51223,
          29580,
          309,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.31666412869015254,
        "compression_ratio": 1.6386861313868613,
        "end": 3338.6000000000004,
        "id": 1379,
        "no_speech_prob": 0.00004611208714777604,
        "seek": 331828,
        "start": 3336.28,
        "temperature": 0,
        "text": " We can edit and overlay it later.",
        "tokens": [
          51264,
          492,
          393,
          8129,
          293,
          31741,
          309,
          1780,
          13,
          51380
        ]
      },
      {
        "avg_logprob": -0.31666412869015254,
        "compression_ratio": 1.6386861313868613,
        "end": 3339.44,
        "id": 1380,
        "no_speech_prob": 0.00004611208714777604,
        "seek": 331828,
        "start": 3338.6000000000004,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51380,
          1033,
          13,
          51422
        ]
      },
      {
        "avg_logprob": -0.31666412869015254,
        "compression_ratio": 1.6386861313868613,
        "end": 3342.1200000000003,
        "id": 1381,
        "no_speech_prob": 0.00004611208714777604,
        "seek": 331828,
        "start": 3339.44,
        "temperature": 0,
        "text": " That's why people can, the other thing I could do is,",
        "tokens": [
          51422,
          663,
          311,
          983,
          561,
          393,
          11,
          264,
          661,
          551,
          286,
          727,
          360,
          307,
          11,
          51556
        ]
      },
      {
        "avg_logprob": -0.31666412869015254,
        "compression_ratio": 1.6386861313868613,
        "end": 3345.7200000000003,
        "id": 1382,
        "no_speech_prob": 0.00004611208714777604,
        "seek": 331828,
        "start": 3342.1200000000003,
        "temperature": 0,
        "text": " this is fun sometimes, people want to make their own.",
        "tokens": [
          51556,
          341,
          307,
          1019,
          2171,
          11,
          561,
          528,
          281,
          652,
          641,
          1065,
          13,
          51736
        ]
      },
      {
        "avg_logprob": -0.31666412869015254,
        "compression_ratio": 1.6386861313868613,
        "end": 3347.2400000000002,
        "id": 1383,
        "no_speech_prob": 0.00004611208714777604,
        "seek": 331828,
        "start": 3345.7200000000003,
        "temperature": 0,
        "text": " Oh, nice, okay.",
        "tokens": [
          51736,
          876,
          11,
          1481,
          11,
          1392,
          13,
          51812
        ]
      },
      {
        "avg_logprob": -0.41295961900190875,
        "compression_ratio": 1.5308641975308641,
        "end": 3348.3399999999997,
        "id": 1384,
        "no_speech_prob": 0.0008692280389368534,
        "seek": 334724,
        "start": 3347.24,
        "temperature": 0,
        "text": " Remixes of this.",
        "tokens": [
          50364,
          4080,
          36005,
          295,
          341,
          13,
          50419
        ]
      },
      {
        "avg_logprob": -0.41295961900190875,
        "compression_ratio": 1.5308641975308641,
        "end": 3349.18,
        "id": 1385,
        "no_speech_prob": 0.0008692280389368534,
        "seek": 334724,
        "start": 3348.3399999999997,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50419,
          1033,
          13,
          50461
        ]
      },
      {
        "avg_logprob": -0.41295961900190875,
        "compression_ratio": 1.5308641975308641,
        "end": 3353.12,
        "id": 1386,
        "no_speech_prob": 0.0008692280389368534,
        "seek": 334724,
        "start": 3349.18,
        "temperature": 0,
        "text": " And then they can overlay music, and whatever.",
        "tokens": [
          50461,
          400,
          550,
          436,
          393,
          31741,
          1318,
          11,
          293,
          2035,
          13,
          50658
        ]
      },
      {
        "avg_logprob": -0.41295961900190875,
        "compression_ratio": 1.5308641975308641,
        "end": 3355.02,
        "id": 1387,
        "no_speech_prob": 0.0008692280389368534,
        "seek": 334724,
        "start": 3353.12,
        "temperature": 0,
        "text": " There we go, I'll see how you step out.",
        "tokens": [
          50658,
          821,
          321,
          352,
          11,
          286,
          603,
          536,
          577,
          291,
          1823,
          484,
          13,
          50753
        ]
      },
      {
        "avg_logprob": -0.41295961900190875,
        "compression_ratio": 1.5308641975308641,
        "end": 3360.04,
        "id": 1388,
        "no_speech_prob": 0.0008692280389368534,
        "seek": 334724,
        "start": 3357.68,
        "temperature": 0,
        "text": " Seven, nine, five, zero.",
        "tokens": [
          50886,
          14868,
          11,
          4949,
          11,
          1732,
          11,
          4018,
          13,
          51004
        ]
      },
      {
        "avg_logprob": -0.41295961900190875,
        "compression_ratio": 1.5308641975308641,
        "end": 3364,
        "id": 1389,
        "no_speech_prob": 0.0008692280389368534,
        "seek": 334724,
        "start": 3361.18,
        "temperature": 0,
        "text": " Point three, three, one.",
        "tokens": [
          51061,
          12387,
          1045,
          11,
          1045,
          11,
          472,
          13,
          51202
        ]
      },
      {
        "avg_logprob": -0.41295961900190875,
        "compression_ratio": 1.5308641975308641,
        "end": 3367.7599999999998,
        "id": 1390,
        "no_speech_prob": 0.0008692280389368534,
        "seek": 334724,
        "start": 3364,
        "temperature": 0,
        "text": " One point seven, one, four.",
        "tokens": [
          51202,
          1485,
          935,
          3407,
          11,
          472,
          11,
          1451,
          13,
          51390
        ]
      },
      {
        "avg_logprob": -0.41295961900190875,
        "compression_ratio": 1.5308641975308641,
        "end": 3370.64,
        "id": 1391,
        "no_speech_prob": 0.0008692280389368534,
        "seek": 334724,
        "start": 3367.7599999999998,
        "temperature": 0,
        "text": " One point eight, eight, nine.",
        "tokens": [
          51390,
          1485,
          935,
          3180,
          11,
          3180,
          11,
          4949,
          13,
          51534
        ]
      },
      {
        "avg_logprob": -0.41295961900190875,
        "compression_ratio": 1.5308641975308641,
        "end": 3373.8799999999997,
        "id": 1392,
        "no_speech_prob": 0.0008692280389368534,
        "seek": 334724,
        "start": 3370.64,
        "temperature": 0,
        "text": " Dash point eight, five, eight.",
        "tokens": [
          51534,
          23453,
          935,
          3180,
          11,
          1732,
          11,
          3180,
          13,
          51696
        ]
      },
      {
        "avg_logprob": -0.25636051495869955,
        "compression_ratio": 1.6041666666666667,
        "end": 3379.1600000000003,
        "id": 1393,
        "no_speech_prob": 0.00818366277962923,
        "seek": 337388,
        "start": 3374.88,
        "temperature": 0,
        "text": " Dash point four, zero, one.",
        "tokens": [
          50414,
          23453,
          935,
          1451,
          11,
          4018,
          11,
          472,
          13,
          50628
        ]
      },
      {
        "avg_logprob": -0.25636051495869955,
        "compression_ratio": 1.6041666666666667,
        "end": 3381.1600000000003,
        "id": 1394,
        "no_speech_prob": 0.00818366277962923,
        "seek": 337388,
        "start": 3379.1600000000003,
        "temperature": 0,
        "text": " One point two, one, five.",
        "tokens": [
          50628,
          1485,
          935,
          732,
          11,
          472,
          11,
          1732,
          13,
          50728
        ]
      },
      {
        "avg_logprob": -0.25636051495869955,
        "compression_ratio": 1.6041666666666667,
        "end": 3385.48,
        "id": 1395,
        "no_speech_prob": 0.00818366277962923,
        "seek": 337388,
        "start": 3382.84,
        "temperature": 0,
        "text": " One point five, two, six.",
        "tokens": [
          50812,
          1485,
          935,
          1732,
          11,
          732,
          11,
          2309,
          13,
          50944
        ]
      },
      {
        "avg_logprob": -0.25636051495869955,
        "compression_ratio": 1.6041666666666667,
        "end": 3389.6400000000003,
        "id": 1396,
        "no_speech_prob": 0.00818366277962923,
        "seek": 337388,
        "start": 3386.76,
        "temperature": 0,
        "text": " Point six, nine, two, dash.",
        "tokens": [
          51008,
          12387,
          2309,
          11,
          4949,
          11,
          732,
          11,
          8240,
          13,
          51152
        ]
      },
      {
        "avg_logprob": -0.25636051495869955,
        "compression_ratio": 1.6041666666666667,
        "end": 3392.6,
        "id": 1397,
        "no_speech_prob": 0.00818366277962923,
        "seek": 337388,
        "start": 3390.76,
        "temperature": 0,
        "text": " Point five, six, seven.",
        "tokens": [
          51208,
          12387,
          1732,
          11,
          2309,
          11,
          3407,
          13,
          51300
        ]
      },
      {
        "avg_logprob": -0.25636051495869955,
        "compression_ratio": 1.6041666666666667,
        "end": 3399,
        "id": 1398,
        "no_speech_prob": 0.00818366277962923,
        "seek": 337388,
        "start": 3394,
        "temperature": 0,
        "text": " Point four, one, zero.",
        "tokens": [
          51370,
          12387,
          1451,
          11,
          472,
          11,
          4018,
          13,
          51620
        ]
      },
      {
        "avg_logprob": -0.3126130561306052,
        "compression_ratio": 1.6770833333333333,
        "end": 3406.1600000000003,
        "id": 1399,
        "no_speech_prob": 0.00021651093265973032,
        "seek": 340388,
        "start": 3404.88,
        "temperature": 0,
        "text": " Beautiful, that was beautiful.",
        "tokens": [
          50414,
          14724,
          11,
          300,
          390,
          2238,
          13,
          50478
        ]
      },
      {
        "avg_logprob": -0.3126130561306052,
        "compression_ratio": 1.6770833333333333,
        "end": 3407.92,
        "id": 1400,
        "no_speech_prob": 0.00021651093265973032,
        "seek": 340388,
        "start": 3406.1600000000003,
        "temperature": 0,
        "text": " It brought tears to my eyes.",
        "tokens": [
          50478,
          467,
          3038,
          10462,
          281,
          452,
          2575,
          13,
          50566
        ]
      },
      {
        "avg_logprob": -0.3126130561306052,
        "compression_ratio": 1.6770833333333333,
        "end": 3410.6800000000003,
        "id": 1401,
        "no_speech_prob": 0.00021651093265973032,
        "seek": 340388,
        "start": 3407.92,
        "temperature": 0,
        "text": " People were telling me that it's very dangerous",
        "tokens": [
          50566,
          3432,
          645,
          3585,
          385,
          300,
          309,
          311,
          588,
          5795,
          50704
        ]
      },
      {
        "avg_logprob": -0.3126130561306052,
        "compression_ratio": 1.6770833333333333,
        "end": 3412.88,
        "id": 1402,
        "no_speech_prob": 0.00021651093265973032,
        "seek": 340388,
        "start": 3410.6800000000003,
        "temperature": 0,
        "text": " to stand in front of a green screen on the internet.",
        "tokens": [
          50704,
          281,
          1463,
          294,
          1868,
          295,
          257,
          3092,
          2568,
          322,
          264,
          4705,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.3126130561306052,
        "compression_ratio": 1.6770833333333333,
        "end": 3414.48,
        "id": 1403,
        "no_speech_prob": 0.00021651093265973032,
        "seek": 340388,
        "start": 3412.88,
        "temperature": 0,
        "text": " But I do that all the time, and nobody ever,",
        "tokens": [
          50814,
          583,
          286,
          360,
          300,
          439,
          264,
          565,
          11,
          293,
          5079,
          1562,
          11,
          50894
        ]
      },
      {
        "avg_logprob": -0.3126130561306052,
        "compression_ratio": 1.6770833333333333,
        "end": 3416.96,
        "id": 1404,
        "no_speech_prob": 0.00021651093265973032,
        "seek": 340388,
        "start": 3414.48,
        "temperature": 0,
        "text": " I made a whole, I danced in front of the green screen",
        "tokens": [
          50894,
          286,
          1027,
          257,
          1379,
          11,
          286,
          32909,
          294,
          1868,
          295,
          264,
          3092,
          2568,
          51018
        ]
      },
      {
        "avg_logprob": -0.3126130561306052,
        "compression_ratio": 1.6770833333333333,
        "end": 3419.4,
        "id": 1405,
        "no_speech_prob": 0.00021651093265973032,
        "seek": 340388,
        "start": 3416.96,
        "temperature": 0,
        "text": " for 45 minutes straight, and nobody ever did it.",
        "tokens": [
          51018,
          337,
          6905,
          2077,
          2997,
          11,
          293,
          5079,
          1562,
          630,
          309,
          13,
          51140
        ]
      },
      {
        "avg_logprob": -0.3126130561306052,
        "compression_ratio": 1.6770833333333333,
        "end": 3422.2000000000003,
        "id": 1406,
        "no_speech_prob": 0.00021651093265973032,
        "seek": 340388,
        "start": 3420.96,
        "temperature": 0,
        "text": " Okay, there was some applause.",
        "tokens": [
          51218,
          1033,
          11,
          456,
          390,
          512,
          9969,
          13,
          51280
        ]
      },
      {
        "avg_logprob": -0.3126130561306052,
        "compression_ratio": 1.6770833333333333,
        "end": 3424.8,
        "id": 1407,
        "no_speech_prob": 0.00021651093265973032,
        "seek": 340388,
        "start": 3422.2000000000003,
        "temperature": 0,
        "text": " All right, so Quadrenion.",
        "tokens": [
          51280,
          1057,
          558,
          11,
          370,
          29619,
          1095,
          313,
          13,
          51410
        ]
      },
      {
        "avg_logprob": -0.3126130561306052,
        "compression_ratio": 1.6770833333333333,
        "end": 3426.6,
        "id": 1408,
        "no_speech_prob": 0.00021651093265973032,
        "seek": 340388,
        "start": 3424.8,
        "temperature": 0,
        "text": " So I think we can wrap up.",
        "tokens": [
          51410,
          407,
          286,
          519,
          321,
          393,
          7019,
          493,
          13,
          51500
        ]
      },
      {
        "avg_logprob": -0.3126130561306052,
        "compression_ratio": 1.6770833333333333,
        "end": 3430.36,
        "id": 1409,
        "no_speech_prob": 0.00021651093265973032,
        "seek": 340388,
        "start": 3428.56,
        "temperature": 0,
        "text": " Thank you so much, Jabril, for being here",
        "tokens": [
          51598,
          1044,
          291,
          370,
          709,
          11,
          508,
          455,
          24216,
          11,
          337,
          885,
          510,
          51688
        ]
      },
      {
        "avg_logprob": -0.3126130561306052,
        "compression_ratio": 1.6770833333333333,
        "end": 3431.88,
        "id": 1410,
        "no_speech_prob": 0.00021651093265973032,
        "seek": 340388,
        "start": 3430.36,
        "temperature": 0,
        "text": " at ITP this whole week.",
        "tokens": [
          51688,
          412,
          6783,
          47,
          341,
          1379,
          1243,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.3126130561306052,
        "compression_ratio": 1.6770833333333333,
        "end": 3432.7200000000003,
        "id": 1411,
        "no_speech_prob": 0.00021651093265973032,
        "seek": 340388,
        "start": 3431.88,
        "temperature": 0,
        "text": " Thank you for having me.",
        "tokens": [
          51764,
          1044,
          291,
          337,
          1419,
          385,
          13,
          51806
        ]
      },
      {
        "avg_logprob": -0.2667892507258678,
        "compression_ratio": 1.6928104575163399,
        "end": 3433.72,
        "id": 1412,
        "no_speech_prob": 0.00394392991438508,
        "seek": 343272,
        "start": 3432.72,
        "temperature": 0,
        "text": " Thank you for coming and being a guest",
        "tokens": [
          50364,
          1044,
          291,
          337,
          1348,
          293,
          885,
          257,
          8341,
          50414
        ]
      },
      {
        "avg_logprob": -0.2667892507258678,
        "compression_ratio": 1.6928104575163399,
        "end": 3434.6,
        "id": 1413,
        "no_speech_prob": 0.00394392991438508,
        "seek": 343272,
        "start": 3433.72,
        "temperature": 0,
        "text": " on the Coding Train.",
        "tokens": [
          50414,
          322,
          264,
          383,
          8616,
          28029,
          13,
          50458
        ]
      },
      {
        "avg_logprob": -0.2667892507258678,
        "compression_ratio": 1.6928104575163399,
        "end": 3436.2799999999997,
        "id": 1414,
        "no_speech_prob": 0.00394392991438508,
        "seek": 343272,
        "start": 3434.6,
        "temperature": 0,
        "text": " Thank you for having me.",
        "tokens": [
          50458,
          1044,
          291,
          337,
          1419,
          385,
          13,
          50542
        ]
      },
      {
        "avg_logprob": -0.2667892507258678,
        "compression_ratio": 1.6928104575163399,
        "end": 3439.9599999999996,
        "id": 1415,
        "no_speech_prob": 0.00394392991438508,
        "seek": 343272,
        "start": 3436.2799999999997,
        "temperature": 0,
        "text": " And to many more future collaborations",
        "tokens": [
          50542,
          400,
          281,
          867,
          544,
          2027,
          36908,
          50726
        ]
      },
      {
        "avg_logprob": -0.2667892507258678,
        "compression_ratio": 1.6928104575163399,
        "end": 3441.9199999999996,
        "id": 1416,
        "no_speech_prob": 0.00394392991438508,
        "seek": 343272,
        "start": 3439.9599999999996,
        "temperature": 0,
        "text": " and things like that in the future.",
        "tokens": [
          50726,
          293,
          721,
          411,
          300,
          294,
          264,
          2027,
          13,
          50824
        ]
      },
      {
        "avg_logprob": -0.2667892507258678,
        "compression_ratio": 1.6928104575163399,
        "end": 3442.7599999999998,
        "id": 1417,
        "no_speech_prob": 0.00394392991438508,
        "seek": 343272,
        "start": 3441.9199999999996,
        "temperature": 0,
        "text": " Awesome.",
        "tokens": [
          50824,
          10391,
          13,
          50866
        ]
      },
      {
        "avg_logprob": -0.2667892507258678,
        "compression_ratio": 1.6928104575163399,
        "end": 3443.6,
        "id": 1418,
        "no_speech_prob": 0.00394392991438508,
        "seek": 343272,
        "start": 3442.7599999999998,
        "temperature": 0,
        "text": " You gotta free stream that.",
        "tokens": [
          50866,
          509,
          3428,
          1737,
          4309,
          300,
          13,
          50908
        ]
      },
      {
        "avg_logprob": -0.2667892507258678,
        "compression_ratio": 1.6928104575163399,
        "end": 3444.4399999999996,
        "id": 1419,
        "no_speech_prob": 0.00394392991438508,
        "seek": 343272,
        "start": 3443.6,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          50908,
          1079,
          13,
          50950
        ]
      },
      {
        "avg_logprob": -0.2667892507258678,
        "compression_ratio": 1.6928104575163399,
        "end": 3447.8399999999997,
        "id": 1420,
        "no_speech_prob": 0.00394392991438508,
        "seek": 343272,
        "start": 3445.4399999999996,
        "temperature": 0,
        "text": " I was just glad I didn't mess that up",
        "tokens": [
          51000,
          286,
          390,
          445,
          5404,
          286,
          994,
          380,
          2082,
          300,
          493,
          51120
        ]
      },
      {
        "avg_logprob": -0.2667892507258678,
        "compression_ratio": 1.6928104575163399,
        "end": 3450.7999999999997,
        "id": 1421,
        "no_speech_prob": 0.00394392991438508,
        "seek": 343272,
        "start": 3447.8399999999997,
        "temperature": 0,
        "text": " and do it like this, or hit my face by accident",
        "tokens": [
          51120,
          293,
          360,
          309,
          411,
          341,
          11,
          420,
          2045,
          452,
          1851,
          538,
          6398,
          51268
        ]
      },
      {
        "avg_logprob": -0.2667892507258678,
        "compression_ratio": 1.6928104575163399,
        "end": 3452.68,
        "id": 1422,
        "no_speech_prob": 0.00394392991438508,
        "seek": 343272,
        "start": 3450.7999999999997,
        "temperature": 0,
        "text": " or something, because that's typically what I would do.",
        "tokens": [
          51268,
          420,
          746,
          11,
          570,
          300,
          311,
          5850,
          437,
          286,
          576,
          360,
          13,
          51362
        ]
      },
      {
        "avg_logprob": -0.2667892507258678,
        "compression_ratio": 1.6928104575163399,
        "end": 3454.52,
        "id": 1423,
        "no_speech_prob": 0.00394392991438508,
        "seek": 343272,
        "start": 3452.68,
        "temperature": 0,
        "text": " All right, so we're gonna say goodbye.",
        "tokens": [
          51362,
          1057,
          558,
          11,
          370,
          321,
          434,
          799,
          584,
          12084,
          13,
          51454
        ]
      },
      {
        "avg_logprob": -0.2667892507258678,
        "compression_ratio": 1.6928104575163399,
        "end": 3455.72,
        "id": 1424,
        "no_speech_prob": 0.00394392991438508,
        "seek": 343272,
        "start": 3454.52,
        "temperature": 0,
        "text": " Thank you, internet, for watching.",
        "tokens": [
          51454,
          1044,
          291,
          11,
          4705,
          11,
          337,
          1976,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2667892507258678,
        "compression_ratio": 1.6928104575163399,
        "end": 3458.6,
        "id": 1425,
        "no_speech_prob": 0.00394392991438508,
        "seek": 343272,
        "start": 3455.72,
        "temperature": 0,
        "text": " Now go, if Glitch Project is still live streaming,",
        "tokens": [
          51514,
          823,
          352,
          11,
          498,
          5209,
          1549,
          9849,
          307,
          920,
          1621,
          11791,
          11,
          51658
        ]
      },
      {
        "avg_logprob": -0.2667892507258678,
        "compression_ratio": 1.6928104575163399,
        "end": 3461.16,
        "id": 1426,
        "no_speech_prob": 0.00394392991438508,
        "seek": 343272,
        "start": 3458.6,
        "temperature": 0,
        "text": " or TensorFlow Dev Summit is still live streaming,",
        "tokens": [
          51658,
          420,
          37624,
          9096,
          28726,
          307,
          920,
          1621,
          11791,
          11,
          51786
        ]
      },
      {
        "avg_logprob": -0.2691215232566551,
        "compression_ratio": 1.7371794871794872,
        "end": 3463.24,
        "id": 1427,
        "no_speech_prob": 0.0014778000768274069,
        "seek": 346116,
        "start": 3461.2,
        "temperature": 0,
        "text": " or I don't know, go watch somebody play",
        "tokens": [
          50366,
          420,
          286,
          500,
          380,
          458,
          11,
          352,
          1159,
          2618,
          862,
          50468
        ]
      },
      {
        "avg_logprob": -0.2691215232566551,
        "compression_ratio": 1.7371794871794872,
        "end": 3464.64,
        "id": 1428,
        "no_speech_prob": 0.0014778000768274069,
        "seek": 346116,
        "start": 3463.24,
        "temperature": 0,
        "text": " some beautiful music or something,",
        "tokens": [
          50468,
          512,
          2238,
          1318,
          420,
          746,
          11,
          50538
        ]
      },
      {
        "avg_logprob": -0.2691215232566551,
        "compression_ratio": 1.7371794871794872,
        "end": 3466.7999999999997,
        "id": 1429,
        "no_speech_prob": 0.0014778000768274069,
        "seek": 346116,
        "start": 3464.64,
        "temperature": 0,
        "text": " something non-coding related.",
        "tokens": [
          50538,
          746,
          2107,
          12,
          66,
          8616,
          4077,
          13,
          50646
        ]
      },
      {
        "avg_logprob": -0.2691215232566551,
        "compression_ratio": 1.7371794871794872,
        "end": 3469.16,
        "id": 1430,
        "no_speech_prob": 0.0014778000768274069,
        "seek": 346116,
        "start": 3466.7999999999997,
        "temperature": 0,
        "text": " Turn off YouTube, go outside.",
        "tokens": [
          50646,
          7956,
          766,
          3088,
          11,
          352,
          2380,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2691215232566551,
        "compression_ratio": 1.7371794871794872,
        "end": 3470.68,
        "id": 1431,
        "no_speech_prob": 0.0014778000768274069,
        "seek": 346116,
        "start": 3469.16,
        "temperature": 0,
        "text": " Be with friends and family.",
        "tokens": [
          50764,
          879,
          365,
          1855,
          293,
          1605,
          13,
          50840
        ]
      },
      {
        "avg_logprob": -0.2691215232566551,
        "compression_ratio": 1.7371794871794872,
        "end": 3472.64,
        "id": 1432,
        "no_speech_prob": 0.0014778000768274069,
        "seek": 346116,
        "start": 3470.68,
        "temperature": 0,
        "text": " So anyway, anyway, you choose what to do.",
        "tokens": [
          50840,
          407,
          4033,
          11,
          4033,
          11,
          291,
          2826,
          437,
          281,
          360,
          13,
          50938
        ]
      },
      {
        "avg_logprob": -0.2691215232566551,
        "compression_ratio": 1.7371794871794872,
        "end": 3473.92,
        "id": 1433,
        "no_speech_prob": 0.0014778000768274069,
        "seek": 346116,
        "start": 3472.64,
        "temperature": 0,
        "text": " Don't listen to me.",
        "tokens": [
          50938,
          1468,
          380,
          2140,
          281,
          385,
          13,
          51002
        ]
      },
      {
        "avg_logprob": -0.2691215232566551,
        "compression_ratio": 1.7371794871794872,
        "end": 3475.64,
        "id": 1434,
        "no_speech_prob": 0.0014778000768274069,
        "seek": 346116,
        "start": 3473.92,
        "temperature": 0,
        "text": " We're gonna leave.",
        "tokens": [
          51002,
          492,
          434,
          799,
          1856,
          13,
          51088
        ]
      },
      {
        "avg_logprob": -0.2691215232566551,
        "compression_ratio": 1.7371794871794872,
        "end": 3476.92,
        "id": 1435,
        "no_speech_prob": 0.0014778000768274069,
        "seek": 346116,
        "start": 3475.64,
        "temperature": 0,
        "text": " I don't have a good system for this.",
        "tokens": [
          51088,
          286,
          500,
          380,
          362,
          257,
          665,
          1185,
          337,
          341,
          13,
          51152
        ]
      },
      {
        "avg_logprob": -0.2691215232566551,
        "compression_ratio": 1.7371794871794872,
        "end": 3479.08,
        "id": 1436,
        "no_speech_prob": 0.0014778000768274069,
        "seek": 346116,
        "start": 3476.92,
        "temperature": 0,
        "text": " I just have to, only thing I can do is I use this mouse,",
        "tokens": [
          51152,
          286,
          445,
          362,
          281,
          11,
          787,
          551,
          286,
          393,
          360,
          307,
          286,
          764,
          341,
          9719,
          11,
          51260
        ]
      },
      {
        "avg_logprob": -0.2691215232566551,
        "compression_ratio": 1.7371794871794872,
        "end": 3481.2,
        "id": 1437,
        "no_speech_prob": 0.0014778000768274069,
        "seek": 346116,
        "start": 3479.08,
        "temperature": 0,
        "text": " and I go over here and I click this stop streaming button,",
        "tokens": [
          51260,
          293,
          286,
          352,
          670,
          510,
          293,
          286,
          2052,
          341,
          1590,
          11791,
          2960,
          11,
          51366
        ]
      },
      {
        "avg_logprob": -0.2691215232566551,
        "compression_ratio": 1.7371794871794872,
        "end": 3482.52,
        "id": 1438,
        "no_speech_prob": 0.0014778000768274069,
        "seek": 346116,
        "start": 3481.2,
        "temperature": 0,
        "text": " and then we disappear.",
        "tokens": [
          51366,
          293,
          550,
          321,
          11596,
          13,
          51432
        ]
      },
      {
        "avg_logprob": -0.2691215232566551,
        "compression_ratio": 1.7371794871794872,
        "end": 3485.56,
        "id": 1439,
        "no_speech_prob": 0.0014778000768274069,
        "seek": 346116,
        "start": 3482.52,
        "temperature": 0,
        "text": " So I need a little outro video or something.",
        "tokens": [
          51432,
          407,
          286,
          643,
          257,
          707,
          13170,
          960,
          420,
          746,
          13,
          51584
        ]
      },
      {
        "avg_logprob": -0.2691215232566551,
        "compression_ratio": 1.7371794871794872,
        "end": 3488.3199999999997,
        "id": 1440,
        "no_speech_prob": 0.0014778000768274069,
        "seek": 346116,
        "start": 3485.56,
        "temperature": 0,
        "text": " I do have an intro video.",
        "tokens": [
          51584,
          286,
          360,
          362,
          364,
          12897,
          960,
          13,
          51722
        ]
      },
      {
        "avg_logprob": -0.2691215232566551,
        "compression_ratio": 1.7371794871794872,
        "end": 3490.16,
        "id": 1441,
        "no_speech_prob": 0.0014778000768274069,
        "seek": 346116,
        "start": 3488.3199999999997,
        "temperature": 0,
        "text": " I can actually just go straight to the intro video.",
        "tokens": [
          51722,
          286,
          393,
          767,
          445,
          352,
          2997,
          281,
          264,
          12897,
          960,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.48724678235176283,
        "compression_ratio": 1.1204819277108433,
        "end": 3491.44,
        "id": 1442,
        "no_speech_prob": 0.03066946566104889,
        "seek": 349016,
        "start": 3490.16,
        "temperature": 0,
        "text": " I don't have to do it over,",
        "tokens": [
          50364,
          286,
          500,
          380,
          362,
          281,
          360,
          309,
          670,
          11,
          50428
        ]
      },
      {
        "avg_logprob": -0.48724678235176283,
        "compression_ratio": 1.1204819277108433,
        "end": 3493.08,
        "id": 1443,
        "no_speech_prob": 0.03066946566104889,
        "seek": 349016,
        "start": 3491.44,
        "temperature": 0,
        "text": " but I don't have an outro one.",
        "tokens": [
          50428,
          457,
          286,
          500,
          380,
          362,
          364,
          13170,
          472,
          13,
          50510
        ]
      },
      {
        "avg_logprob": -0.48724678235176283,
        "compression_ratio": 1.1204819277108433,
        "end": 3493.92,
        "id": 1444,
        "no_speech_prob": 0.03066946566104889,
        "seek": 349016,
        "start": 3493.08,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50510,
          1033,
          13,
          50552
        ]
      },
      {
        "avg_logprob": -0.48724678235176283,
        "compression_ratio": 1.1204819277108433,
        "end": 3496.6,
        "id": 1445,
        "no_speech_prob": 0.03066946566104889,
        "seek": 349016,
        "start": 3495.52,
        "temperature": 0,
        "text": " Here we go, goodbye.",
        "tokens": [
          50632,
          1692,
          321,
          352,
          11,
          12084,
          13,
          50686
        ]
      },
      {
        "avg_logprob": -0.48724678235176283,
        "compression_ratio": 1.1204819277108433,
        "end": 3497.44,
        "id": 1446,
        "no_speech_prob": 0.03066946566104889,
        "seek": 349016,
        "start": 3496.6,
        "temperature": 0,
        "text": " Cookie.",
        "tokens": [
          50686,
          42011,
          13,
          50728
        ]
      }
    ],
    "transcription": " Yes. My event is starting. Oh wait, maybe I shouldn't be showing this yet. That's fine, it could be back here. Hello! I think I've started streaming. Welcome to... The Coding Train, live on a Friday. So this is a special Friday Coding Train episode. I have a very special guest, and this is my special guest's project that this approximately one hour livestream will be about. You should, oh, audio is low. This is good. So I have a two mic setup going, and so let me debug that a little bit here before I get started. I'm opening up the Slack channel, which is for patrons. So make it louder. So hold on, special guest. I don't know why I'm making this like some sort of surprise reveal. But special guest, just say a couple sentences, and let's test your audio. Hello, testing, testing. Can you do a cut to me while I'm testing audio? I can, actually. Hello. Wrong, wrong, cut to special guest. Oh, hello, testing. Ding, ding, ding, ding, ding, ding, ding, ding. All right. So is it just my mic that's low? I can hear him, but I can't see him. No, that, you know, that's, you will in a second. Is it, is my mic lower than my special guest's mic? Because you don't know who it is. That's gonna take a minute. The one issue with live streaming is the chat is about 20 seconds behind us in real time. So that question, they won't actually hear it for about 20 seconds. I love it, it's awesome. My mic is fine. Hi, mine is low. Shiftman mic is low only. Is my mic low? Is my mic tested? No, yours was fine. And I can actually turn. So first of all, I'm kind of okay with my mic being low. First of all, is it actually registering my mic? If I'm tapping on here, are you hearing like a tapping? Both mics are fine. I'm gonna up mine. I'm tapping mine now. I have to tap on mine. Because it could be I'm low just because they're only hearing it through your mic. That'd be interesting. No, no, it's mine's here. I turned mine up a little bit. Okay. I hear tapping on both. I can hear you both fine. Okay, hello, welcome. I have a very special guest here in the Coding Train studio. I'm gonna cut to a special guest. Welcome to Jabril. If you're not familiar with Jabril's YouTube channel, I probably just Googled J-A-B-R-I-L-S on YouTube. It's also, I learned how to say it now. F stuff, Seth stuff. You're wrong. No, I'm joking. Seth stuff, S-E-F-D stuff. On YouTube, Jabril has been teaching himself machine learning for the last, around nine months. And has discovered and made all sorts of exciting and interesting projects. Has made a bunch of videos about those projects. Happened to be in New York this week. Is actually doing a short term residency at ITP, which is a program where I teach. And has taught a workshop here this week and gave a presentation on his work. So it's Friday afternoon, coding train time. And so, I thought I would bring him here to talk about a new project that he's making. So before I get to that, let me just do some housekeeping. Today is going to be a shorter livestream than usual. There won't be any coding challenges or tutorials from me. I hope to make that up with a bonus livestream next week or the week after. But happy whatever holidays that are happening today and this weekend that you might be celebrating. I have to catch a train in a couple hours. So, it's funny how I have to catch an actual real life train in a couple hours to head out of town. So, this is just gonna be a guest session. I will say though that if you don't subscribe, I don't know why I'm pretending I don't have a computer here. YouTube, let's search for Seth Stuff. So this is, hey you have two YouTube channels. I have a million channels to be honest. I kind of knew that but I forgot about that. Do you work on all of them still? So this is the one you're actively maintaining still. Just this one. So this is Jabril's YouTube channel. And you can see, just memorize this channel ID, I'll read it to you. Capital U, capital C, getting this down, capital Q. Oh, you're cheating on your numbers book today. Oh yeah, we're gonna have you read some random numbers. So, what was I saying? So you should definitely subscribe. You should click, look, oh I'm gonna subscribe. So the reason why I'm not subscribed is not because I'm not subscribed. It's because this is a fake account that I set up just, that I bought YouTube Red with so that if I look at stuff on YouTube on my live stream, the ads don't show up. It's also a YouTube channel, an account that my kids use when they watch YouTube because I don't want them to have to watch the ads either so you can see what kind of videos they like to watch. And look, Jabril's visits the coding train. Now let me go back and I'm gonna give you a clue here. You're gonna, what you're gonna wanna do is you're gonna go to his channel, you're gonna wanna click subscribe, then you're gonna wanna click this alarm bell. I learned about this today. Actually, I already knew about this. But the alarm bell's gonna, you could do this with my channel too if you want. I guess you're probably already subscribed if you're watching. But it'll give you a, it will give you a notification as soon as there's a new video and the reason why you might wanna do this is there's, Jabril will be publishing a new video on Sunday that I think you're gonna wanna watch. That's all I'm gonna say about it. Okay, so if you wanna get that notification, it's gonna be on his channel so you're gonna have to subscribe. There. Okay. I'm looking at the chat. So, I think that, oh, these are, look at this. These are some great, let's look at these. Oh, look at your friends. Oh, that, okay, so also, by the way, this I learned about recently too. Jabril is doing live streams. I guess I could let you talk about your own stuff. I don't know why I'm doing, I can't stop talking. This is my channel, I guess I'm in charge here. This channel is where Jabril does his live stream archives and he does his live streams. So, I'm not sure if you're gonna be able to see it published here, but your live streams are actually on Twitch. Correct, yes. Okay, and then also, some nice, the Physics Girl is an awesome channel. Coding Train is, it's kind of okay. And I don't know some of these other channels, but I'm definitely gonna have to check them out. They look cool. All right, so, and here you can see here, you can see YouTube, Jabril, Real Life, Jabril, YouTube, Jabril, Real Life, Jabril. Oh, oh, oh. If you're reading this. You've been hacked. He's like a real life YouTuber in person. I don't think of myself as that because I'm like an old person, but he's like a full of, I don't know, youthful energy. Okay, I have, all right, so I think, okay, let me mention two other things. Number one is there's a lot of live streams going on right now. I saw that, just in case, normally I would tell you to watch something else if it's just me, but since it's Jabril, you should stay here. But there is, oh no, there's the Glitch channel. This is totally giving me the wrong stuff. Ugh, Glitch, a code editor, YouTube. I don't know why. I saw that they were live streaming. I can't find it. Nevermind, Glitch. Glitch, I don't know why I'm plugging Glitch, but I love Glitch. It's a code editor. Not an official sponsor or anything, but they have a live stream going on today. And then there's also the TensorFlow Dev Summit. This, in particular, I wanted to mention. Let's see if we can tune in to the live stream really briefly. What are we learning about now? All right. All right. All right. All of you may want to distribute. You're tuning to multiple devices. See, now you don't hear the audio from this except through my mic, so maybe I should just do a voiceover. Saying these workers, servers, and there's very little going on, saying, to estimate, I can't do it. So, the TensorFlow Dev Summit is going on live right now. I don't know what this is about. And I think earlier already today, there was a very exciting announcement. If I go to js.tensorflow.org, I think. Yes. So, you might have heard me talk about a project called Deep Learn JS on this channel. What happens if I go to deeplearnjs.org? It's still there, but it now says, exactly what I wanted to tell you, is that deeplearn.js has become tensorflow.js. So, that's pretty exciting. Like, it graduated. It grew up, it graduated. It's a teenager now, maybe, in whatever, computing years, open source years. I don't know how that translates to dog year. But, a member asked in the chat, can we get to the point? Very unlikely that's gonna happen anytime soon. I do not get to the point. And so, it's really exciting how this project is growing to be able to unlock and make possible more types of machine learning algorithms and possibilities in the browser. And I have been working on a project at ITP with a bunch of researchers. I know Jibril has been experimenting with it for maybe an upcoming project. If I go to github.com slash ml5js, I'm gonna go here. So, this is a machine learning library, kind of like a higher level, simple, basic library to do some machine learning stuff that is built on top of deeplearn.js, wherever that went away. And now that deeplearn.js has become tensorflow.js, this means we're going to do a lot more work on this to support all the new possibilities that are unlocked from tensorflow.js. In particular, most of our examples in this library involve using pre-trained models. And if you wanna train your own model, you've gotta go and set up your Python environment. We have some tutorials for that. But now, we're gonna start to be able to make some examples and things where you can actually do the training in the browser. So, I'm slowly getting to it, but this is, I hope, gonna be a big focus of my channel April, May, June, however long I have the energy to do this over the summer. So, that's coming. Let me see if there are any questions in the chat. Is it efficient to learn in the web? I don't have an answer to that question. It definitely does not. What the researchers at Google have done in making tensorflow.js is nothing short of heroic in getting all of the matrix operations that need to happen in WebGL using the GPU of the computer in the browser. But its performance is still not going to be as fast as native C++ tensorflow, but it's remarkable how fast it is, and the ease of not having to set up an environment and just go to a web page to execute a task, to program something, to make an animation. I think there's a lot of exciting possibilities there. Okay. So, let's transition now to our guest. And so, I'm gonna, let me see. So, I don't remember, I'm trying to remember. Oops, I'm like. You can step into the frame. Welcome, Jabril. So, I'm looking over here because I have a monitor over here. So, one thing, by the way, is that I have to practice is that the people we are speaking to are there, but you'll notice I do this a lot, like blah, blah, blah, blah, blah, because I'm staring at the monitor I have over here. You're very pro. Okay, so, I'm trying to think when I first discovered Jabril's channel, and I wish I had a good memory of this or story of this, but I definitely remember when I first saw his video on the Run Forest project. So, I'll let Jabril introduce himself and say more about his background and how he got into this machine learning stuff, if you like, rather than try to do it myself. But what I loved about that, I have a book that some of you might be familiar with called Nature of Code, where I have a kind of a chapter on neural networks and a chapter on genetic algorithm, and they're kind of old and out of date, and I've kind of been wanting to expand that and do more with it. This is my camera, it goes off every 30 minutes. Now you know you're experiencing this live. And so, when I saw that project, the Run Forest project, which if you haven't seen, it's a Unity-based simulation that trains a simulation forest gum, basically, character to run around a maze using both neural networks and genetic algorithms, and it was really like I looked at it like, oh, this is the perfect kind of demonstration example in the kind of creative coding or game making or art making context of how to apply machine learning to a simple, I mean, it's not that simple, but to a graphics motion-based simulation. So I was super excited to see that, inspired me to think about some new stuff and where I wanted to take some of my tutorials in JavaScript, I don't know. The internet puts people in touch. I've been watching his videos, I think he's watching some of mine, we'll see. And so, welcome to the coding train. So what I'm gonna do, awkwardly, is I'm going to take my coffee and my laptop and I'm gonna slide out of the way and go sit, there's a chair over there, and then I'm gonna turn it over to you. I might mute my microphone and you can talk about your project and code and I'll watch the chat to see if there are questions. So after a little bit of time, I'll come back and ask you some of the questions that people have asked. Sweet. Make sense? Very cool. Okay, shuffle, awkward, shuffle, awkward, okay. All right, howdy, everyone, how is it going? So yeah, I'm gonna give a little brief overview about who I am for those of you that do not know, which I'm sure is all of you. So my name is Jabril, I run a little YouTube channel called Jabril's here on YouTube. And recently I converted my channel to focus on computer science, that happened in September, and that was probably one of the best things I've ever done because I learned that, you know, I had a great passion for writing code and making products and projects that were based on computer science. And so, yeah, I mean, obviously, if I had a passion for that it was easy to show that in video projects as well. And fast forward, so one of the biggest projects that I've produced to date is the Run Forest project that got a lot of eyes. I'm really grateful for, and that really harnessed the power of machine learning, which is a really big buzzword these days. And yeah, that's pretty much overview. I spent nine months learning on how to write neural networks from scratch, which I- Sorry, I'm gonna pause you for a second. People are telling me the audio is low. Oh, okay. So let's do a little, I'm sorry to interrupt you in the middle. Let's do a little- No, no worries, no worries. Is my placing good? Oh, you know what? It's because it's going through, it's fine. You're good, you're good. Okay. I got it. I have an idea. Okay. I got a little time, so I'll dance. I actually muted myself. Tap your mic for a second. Okay. All right. Let's see if this is better for people. All right, just let us know if this mic is still too low. But yeah, that's pretty much overview. I spent about nine months learning how to write machine learning algorithms from scratch because it was something, AI is really cool to me, I think. And so yeah, the Runforest was released. And today, today, what we're gonna do is we're going to examine this really simple JavaScript machine learning application, kind of how it was done. It's another machine learning application written from scratch. So we're gonna take a look at the code and all that good stuff. So let's get into this. So here we have this example. It's what I call a color predictor neural network demo. And it asks you a simple question. Does white or black look better over this color? And so the color is within the circle and it's randomly generated. So, so, we use a, can I use the whiteboard? Okay. So what you have to do is press two. Two. That's it. Okay. Sweet. And then you come over here. And I just walk, that's it? If I'm sitting here, am I in the shot? No. Okay, so what's important for us to start before we can get into the application, we have to understand the main computational part of this application. So we have a color. And as you know, colors are, they're represented as a vector of three, or sometimes four if you include the alpha. But we're not including the alpha. We're only gonna use the RGB values. So we have our inputs, which is three. Is that all in the frame? Yes. All right. So we have red, green, and blue. And these are values between zero and 255 for each input. So, we need to build a neural network that will be able to take these inputs and then do a computation on them and then pass them to an output to predict if it looks better over black or white. So let's first draw our outputs. Just make sure it's all in frame. Yes, that's good. And this is gonna be, it predicts black and this predicts white. So now we need a hidden layer, is what we call a hidden layer, with artificial neural networks in the middle that does the computation part. And this is our guess. And so we are just gonna arbitrarily just duplicate the same size of our inputs for our hidden layer nodes. We're just gonna say three. It's a good place to start. If we're really serious about this, we could expand it, try five, try seven, and just log the results for all of them and see which one works the best. But we're just gonna say three for this example, make it nice and simple. And so, we have our RGB, and if we go back to press one, yeah. Our example. What's happening here is there's a computation that happens within our network. Two, three, one, two, three, one, two, three. And Dan, feel free to interrupt if you think that I'm a little off base with anything. Uh-huh. Uh-huh. Uh-huh. Okay, so this, what did I just do? That looks really confusing, but it's actually really simple. So, we need to somehow get our inputs, computation, and then to our outputs. And the way that we do that is we use what I'm using, bubbles, to represent what are called weights within our neural network. And so, every single node within our hidden layer has the same amount of weights as there are inputs. So, what that means is there's one weight for this input, there's one weight for this input, and there's one weight for this input. And the same for the rest of them. One weight for this input, one weight for this input, one weight for that input, and repeat. I didn't do that right. Boom, boom. And so, what then happens is that we pass this through, we do our input times the weight, and then plus our bias, and we can repeat the process. This will give us a value. After we compute all these, sum them up, add a bias, it will give us, let's just say, 0.5. And then we'll pass that to our outputs, which is three. Boom. Pass this to our output, and then that will give us a value for each of these. Let's say this is 0.3, and then this is 0.7. And then it's just as simple as we'll just say that this is higher, 0.7. And so it's guessing why. So, that's a quick overview on what's going on here. Daniel's gonna post a more in-depth tutorial on this, or you already have. Well, so I have tutorials on neural network stuff like this that people could go back. So this is the same kind of structure that I've used in my neural network library videos. And I was thinking at some point, maybe next week, hopefully, I might try to recreate your project as a coding challenge. In which case, I'll revisit this. So we can put a link to your, okay. So we'll put a link to Daniel's Shipman series in which he goes in-depth with this. So if you wanna learn more about what's going on here. But that's a quick overview on the math, on the computation. So our inputs, it gets times by weight and biases, then we get a value, and then we pass that to our output, same computation, and then gives us a prediction. So. Oh, and actually, there's a bunch of questions. Oh. I might as well ask, may I interrupt you and ask a question? Yeah, let's do it. All right. People are asking, are you using libraries? Let me just give you a bunch of questions just because the chat's gonna scroll too fast. Okay. Or actually, no, it's fine. I've stopped it from scrolling. So question number one. Are you using any libraries, or are you building this from scratch? Okay, so yeah. So this is a from scratch computation. We're doing this completely from scratch. And it's not necessarily important that you do from scratch neural networks. But if you wanna get a good understanding on how to debug networks, this is a really good, it's a really good way to go about ensuring that you can do that. Yeah. Okay, next question is, does the input have to be from zero to 255? Okay. Should inputs have to be normalized? What's the, from zero to one? Yes, great question, great question. So again, I just glossed over this, but so normalizing inputs for colors is actually really simple. And it is always best to normalize your input data. So because we know that the domain for a color value is always gonna be one to 256, or in computer language, we shift that by one, zero to 255, we can simply just divide whatever this value is over 255. And that will remap this between zero and one. And so essentially, when you're writing your program, you would just pass the input through a function that would just divide it by 255. So yes, great question. All right, one more question. So I'm kind of curious about this too. I sort of think it's probably, I feel like I answered the question before I ask it. But is there a benefit to having two output nodes rather than just have one, since there's only like this like a range between negative one and one or something like that? Yeah, so there's a lot of debate on this. And I agree with the side that it's easier when you have like classifiers versus like, if you have just one output node that is mapped between negative one and one, right? And then if it's above zero, then it's gonna be white. If it's below zero, then it's gonna be black. Yeah, based on the research that I've read, it's always best to go on a classifier. And it seems to me like maybe this would be fine in the case of there's only two labels or two classes, but once you have more than two, it's gonna be problematic. And so as a like demonstration and learning, even though this might be a very like basic scenario, it's useful to demonstrate the multiple outputs because you're gonna need to do that if you were to expand this further. Correct, and the whole reason for that is because what happens when you separate them is you get probabilities versus like you get a map of between zero and one, which again, if it's one output, you can get away with that. But if you try and encode your outputs using this for like 30 different, the neural network might not make good sense of that. Cool, all right. Cool, so let's continue on because we need to get into the code part. So let's look at some of the code as to how we went about writing that part of our neural network. Right, down is up, I keep forgetting. I'm new to Mac, so please forgive me here. All right, so, and you beautified my coat. No worries, no worries. Beautified and zoomed. Okay, so we first need to define all of our variables at the top. So RGB is our input. And then we have the amount of choices, which is a variable that we use for our output. Skim one second, just skim this, make sure I don't give you the wrong information here. Sweet, so we set up our variables. RGB is our input data. And then so, one thing that's really important that I should go over just to make sense of what's going on here is, too wrong computer on this one. Delete that. So it's really important, in order for you to write your algorithm, you need to know how to compute this, compute both of these. So this is really just an array of values. So we can call this array G of I, right? So this is G of zero, and this is G of one. And G just stands for a guess. I put zero, G of one, right? And so we wanna know what does G of I, or what does G of zero, or what does G of one equal? How can we get that equation? Well, if we look at our diagram for our neural network, it's actually quite simple. So this is in frame right here. So we can do G, oh my goodness, can I write? You actually have a lot of room to like this way too. Oh, oh, okay, so let's do it over here. So G of I, which again is this array, this output layer, G of I equals the summation of a hidden layer. This is gonna be a hidden layer of I, and this is gonna be inputs of I. That's how we define each of these vectors. So G of I equals a summation of HL, hidden layer, and then we have to go into another loop because we can't use the same in this C of I and J because it won't return the right value. So a hidden layer of J, which is just gonna be zero, one, two times the weight of G of I. And then we simply just add our bias of G of I. And so this is the equation that we can use to compute each of our output nodes. And so just to clarify what's going on here, this is summation symbol, which simply means to add up all within the array. So hidden layer of J times the weight. This is a function which simply just grabs the weight of whatever output node you're on. So if you pass G of zero, for example, to do this weight function, it will just grab whatever bias, or I'm sorry, whatever weight of G of I is there. So that's actually G of I of J, actually. Oops, G of I of J. So now we have this equation that tells us exactly what these values equal. So now we don't know what HL of J equals. So we also have to define HL of J. And we go about doing that by doing the same exact process. Actually, this would be HL of I for indices. Same exact process, summation of our inputs, right? Inputs, what do I use, I and P. Inputs, J times weight of HL of I. So the same exact input, we need HL of I. And then we simply just pass our bias. And again, this right here is a function. All it does is it grabs the bias for whatever node that we pass through it. So bias of HL of I. And there we have it. We have our entire equation, because we know exactly what input of J equals. It's gonna be simply the random value of our color. And so this is what we need to write in our software. How are we on time, Dan? We're good. Cool. I keep forgetting up is down. Okay, so same exact thing that you see on the board is what we write here in our code. So first, before we can get what the guess nodes equal, we have to first get what the hidden layer nodes equal. So simply put, as we did on the whiteboard, hidden layer zero equals, we'll get to what ReLU is in a second, but hidden layer zero equals, we did our input encoder, which was a question that was asked earlier about normalizing our input data. So this function simply just divides our input, divided by 255, and then we'll times that by the weight of our hidden layer. So this is an array function that I will go over really quickly that we instantiate to hold all of our weights. So color predictor zero, zero, zero. I'll go over this. I think it's important. So the function color, can you see this? I think so. Color. You're close to the top of the range. Okay. And there's a lot of data that you have to remember. This is interesting. Color predictor variable. So there's all these different dimensions to it. And I think it's interesting, or it's important to go over what the dimensions mean. So let's just get two, and then let's just do, I don't know, one. So what does this mean? If you have color predictor I zero to one, what does that mean? Well, so we want to store these arrays into our color predictor variable. And we go about doing that by defining the location of all of these. So the hidden layer is going to be zero, and then the guess is going to be one. And so all the nodes are then gonna have their own assignments. So zero, one, and then two. Same here. This is gonna be zero and one. And then the weights are also gonna have their own assignment as well. So zero, one, two, three, and the same deal. Zero, one, two, three. And we repeat that for every single weight inside of the nodes, right? And so how this works is our color predictor is if we want to grab reference to zero, that is going to be hidden layer. And then two is going to be the last node. And then one is going to be the second weight because start zero, one, second weight. So this variable is grabbing a reference to this weight. That's exactly what color predictor zero, two, one is doing. And so you see this I, that's an extra dimension that you might be confused about. So let's talk about that real briefly. So a lot of information. There's a lot of information, but bear with me here. Oh, switch camera. Okay, all right, I knew that. All right. So you see this extra I, and what does that mean? So traditionally, with such an example, you would use back propagation to train this neural network. However, time was a factor, and as well as we wanted to go over a lesson of both neural networks and genetic algorithms. So why not combine them together is what we did for this example. So the I is actually just grabbing a reference to what predictor we are currently using. So genetic algorithms real quick, you have to have a population, you have to assign fitness scores to every single, what's the word I'm looking for, the creature within the population, and then you have to mutate them and breed them in X, Y, and Z. So we have a population of 100 predictors at start, and then they all have randomly initialized weights and biases, which again, just to make sure we're clear, are all of these values, weight, weight, weight, bias, weight, weight, weight, bias. These are all randomly initialized. The function that we use for this program is randomized between zero and one, and then they all, based on their randomly initialized weights, will make a guess on which one they think is correct. And so most of them said that black is the correct color that looks best over this randomized color. And then we simply just use a genetic algorithm to train this predictor to converge on the best possible predictor. And yeah, that's a general overview on this. The code is available on GitHub, and I left a lot of comments. However, it will require a bit more in-depth if you really want to get a full grasp on this from knowing absolutely nothing. If you already know some stuff about neural networks and machine learning, I'm pretty sure this example is pretty straightforward for you. But the benefit of writing neural networks from scratch is that you really have a good grasp on what's going on behind the scenes versus using libraries. And you're able to debug different problems that might arise when you are writing your neural networks, be it from scratch or using libraries. Yeah, and that is pretty much it. We do have plans to update it with the actual backpropagation algorithm in there. So that you can learn from that as well. And yeah. Yeah, I mean, so let me turn my mic back on. Okay. Where did that cap go? Oh, the cap. I picked it up, I held it in my hand, I put it in my pocket. Ah, that's very cool. So let me come over here. There are a few more questions. Okay. Let's see what I can find here. Oh. Um. So first, people had asked, is the code already at GitHub, or are you gonna update it on GitHub later? Yeah, I still have to upload it to GitHub. So stay tuned. Whenever it's on GitHub, I will come back and edit the description for this live stream and put a link to the code there. But they can currently go to stephsup.com slash color. Oh, that link that I use. Right. Yeah, so you can go to, let me zoom in here and show you. So stephsup.com, this one. Yes. So if you wanna grab the code right now, and I don't know why, whenever I paste links into the YouTube chat, they don't seem to work for people. So but anyway, so I would paste this into the chat, but that wouldn't even work. So you can see it up there. That you can grab the code now. But I will also include a link to GitHub repository, whatever that's. And it is my intention, I think one of the reasons why I love this demo, and people were kind of asking this a bit in the chat, was like, oh, like, do you really need a neural network for this? Right. And I think to me, I mean, that's a perfectly valid and interesting question. And probably the answer is no, you don't need a neural network for this. But when learning about neural networks, when trying to build your own machine learning project, if you can start with a well-defined, small in scope problem, then you can really figure out, and in some ways I do this similarly with some of my genetic algorithm projects. I take an example where I know the answer. Right. So I can see if the genetic algorithm worked. Because ultimately what I want to do is use a neural network or a genetic algorithm in some domain where maybe I don't know the answer, I couldn't solve the answer easily, but to figure out how those things work, I've got to come up with, and so this is a really nice problem for that, because it's simple, small in scope, and for people who want to do creative coding, and graphics, and design stuff, it's got color, and graphics. And not to mention, once you learn how to do this stuff from scratch, this is easily scalable for the most part. You still have to worry about some other stuff like vanishing gradients and stuff like that, but for the most part, you can take this and scale this up, and it'll work just about the same. So there's also that benefit as well. So there were a couple questions that came in on Twitter, ask Jabril hashtag, people, there were a lot of questions like, how are you speaking with your mouth? There was a lot of moving, there was a lot of that. I am a bot. How can I become like you? I don't know if that's an answerable question, but that was a question that came in from ideaxiso on Twitter. So here's a question from IamRoshan on Twitter. This is a big question. Okay, let's do it. I don't know if, and I think this is a question I've certainly touched on, but how is AI, let me read the question, how it actually is written. How is AI different from a neural network, or deep learning, or machine learning? They often seem to be used interchangeably and cause confusion. So first of all, I want to say, like, this is a really good question. And I struggle with this question all the time because there's all these different terms. So let me list those terms. Artificial intelligence, deep learning, machine learning. And then I might put neural network in a different category. But that's another term as well. I don't know if you have a kind of like, way that you describe these, the terminology of people when they ask those kind of questions. Yeah, I like to start with English is difficult. I like to start there. But for the most part, AI is like a grab all for everything AI. Like, you can hard code AI. You don't have to use machine learning. So that's kind of like the grab all for it all. And then what was the other, the code words for it? So, oh boy, all these things are coming in. AI, machine learning, deep learning, neural network. Yeah, and so machine learning, I think is like the next level down. So you don't need to use a neural network to do machine learning. There are different ways that you can go about teaching a machine how to learn. One really good example is decision trees. People have developed really complex decision trees and the machine just kind of explores the space and learns the best way to use this decision tree. So that's another way of applying machine learning. And then, what'd you say, neural network and deep learning? Yes. Yeah, so neural networks is essentially what we showed. And even that's kind of up to debate because recurrent neural networks are neural networks, but they're not really neural networked, you know, if that makes sense. So I don't know. If you say neural network, people will know what you're talking about for the most part. All right, I'm gonna try to give my take on this. Let's see if I can do it. Let's do it. I forgot already what I was gonna say. Well, I think I would put neural network in a different category than those other terms. Because to me, neural network- I need to look at the camera. I know, I don't know. I'm so bad. I don't have a good, I wanted to get like between the ferns like set up in here. Or I could get like a camera and some chairs, a little coffee table and could have like a conversation. But instead, it's just the awkward standing thing. Somebody in the chat told me to put a mirror behind the camera. And then we're like talking to each other but looking at the mirror. I like that. That might be weird though if there's nobody else here. I'm kind of egotistical. I used to have a screen over there and I would always stare at that. But anyway, so the reason, so neural network to me is a particular algorithm that involves connected nodes and data flows from one node to the other. And there could be different architectures and styles. And so that neural network data structure algorithm can be applied in the fields of artificial intelligence, machine learning and deep learning. But neural network is an example of a particular algorithm, you could sort of think of it also as a data structure, but there's an algorithm there in terms of how the data flows through the structure. So that's what I think. And then I think that, to me, artificial intelligence is this umbrella term that is really just like, hey, can computers and can technology have intelligence like humans do and what does that mean? And apparently my technology is not intelligent enough to record a video for more than 30 minutes at a time. So I think of that as a very broad umbrella term to just the big field of like simulated intelligence. Whether is that, is it real intelligence? Is it the illusion of intelligence? Is that the same thing? It's like kind of a deep philosophical question. And then machine learning to me is a subfield of artificial intelligence involving making sense of data. So you have data and that's input to a system and you have some output which might be making sense of that data whether it's a prediction for something that's gonna happen in the future or a classification of something. And then I think of deep learning as a kind of, almost like a modern rebranding of machine learning with neural networks. That's like, hey, we have bigger data sets now and faster computers now. All of a sudden, the things that people researched many years ago called neural networks that nobody thought could really do anything or they thought could but couldn't, now all of a sudden, we can do more of them with. And so it's really just like, I mean it's not meant to be marketing but it's kind of like marketing this idea of big data, neural networks. Yeah, I agree. I think it's a lot of the marketing side of things because you'll read so many different posts like what's the difference between deep learning and machine learning? It has two hidden layers. That's it? Yeah, like literally. I think it's more the marketing side, my personal opinion. But that's awesome. Cool. Let me see if we have any other. Oh yeah, neural network, I like this definition. Neural network is a universal function approximator. I actually, this is actually like a really, this is Robin, I'm gonna, hello, let's try this. Oh, this is crazy talk. Now I'm coming over here. I actually think this is really kind of a good way to think about it. I was thinking about this the other day because what if we made function color predictor and we just had like an if statement in there and you give it a color. So if the brightness, blah, blah, blah, of that color is greater than some value, then you should put black on that color or white on that color otherwise. So this is like a hard coded function that takes inputs and returns an output. Right. And so we could write a lot of if statements. We could get really crazy complicated about this. We could come up with a whole set of rules and a neural network in a way is a thing that you could put in here to kind of learn to return the value according to, in a more mysterious way in a way, like in a sense. It can learn, it acts, so in a way like does, do neural networks and machine learning replace coding? Right. I don't think of them as, maybe someday they will in some weird way, but I think of it as like they don't replace coding, but they can replace or act as a function in your code. So that function that you might have hard coded with a lot of if statements can now have a machine learning system in it, and take some inputs and generate an output. Yeah, I agree. I mean, when it's all said and done, algorithms are input, instructions, output. Yeah. And you're just replacing the instruction part. Totally. I believe Siraj already did a video on that. I think Siraj having already done a video on that is probably the answer for everything we might ever talk about in this. Because he definitely has a video on everything. That's the new Simpsons edit. Coding, train, are you gonna show us the working code or is it just a discussion? So I think we're wrapping up here. This was really just a discussion. The code is here. Some people had asked just to scroll to the top. Okay. Maybe you hadn't seen what was at the top. But I don't know if that really matters. But I'm standing in front of the code anyway. But this code is available at that URL. There'll be a link in this video's description. And I think, I mean, I don't wanna like, I mean, I feel committed to doing this. I just don't know when exactly it'll happen. But hopefully sometime next week. I'd like to make my own version of this project, which I'll do like in a coding challenge from scratch. And then we can kinda compare and contrast that. And I have a feeling that you're probably gonna have some other video content about this project at some point. Did I mention that you should subscribe? There's gonna be a special guest. Did I mention that you should subscribe? There's gonna be a special guest. I don't know who. I have no idea who. Wait, how do I? YouTube, you need, do you know you can get one of these vanity URL things now? So you can get like this? Ah. I don't know, because I have one now. I need a little bit of time. Maybe you have to be like very special on YouTube to get that unlocked for you. I think you're special. Oh, excuse me. But, so I'm just gonna search for you again. If you just do Jabril's, it comes up. Oh, well then you have that. I don't think URL though. You just have to search it and it comes up. Oh, yeah, you have to search it. Yeah, yeah, yeah, I see. Captain Meshut. Yes, okay, so here once again, subscribe. So I'm gonna just show you. I'm gonna unsubscribe. This is terrible, unsubscribe. Now I'm gonna show you how you do this. You go, you search Jabril's in the search bar. Then you click subscribe. Then you click the alarm bell, because if you want this special surprise video that might come out very soon, you'll get a notification. Okay, you need 100 subscribers to get the vanity URL. I got some work to do. Yeah. All right, so let me just check to see if there's, oh yes, people are asking your Twitch. So let's see if we can, let me just say, if I do this, what do you think the chance that'll come up? It's just Jabril's CPU. Yeah, it's right there. Oh, wow. So if you go to twitch.tv, Jabril's CPU, that's Jabril's Twitch. And actually, so I was gonna say this for you, but. Whoa, whoa. All right, they can't hear this by the way. Oh. I mean, they can if it comes through our mics, but the audio from this laptop. So he's just seeing us freaking out over it. Yeah, he is something to resolve. But actually, I'm curious. So tell me about your, because I'm always, I always feel like I have no idea if I'm doing, I don't think there is an answer to this. Like my process, I have this weird process. Like I do live streams that are on YouTube, then I cut up and edit the live streams as separate videos also on YouTube. And sometimes I think, oh, I should be live streaming on Twitch. Should I not be posting redundant? Anyway, so what's your, how do you separate those? You have the YouTube channel, you have Twitch, and then you have a second YouTube channel. Correct. Jabril's CPU. Correct. What are those pieces? I focus on the Jabril's channel, like the main one. So I'm literally live streaming, and then whatever comes out of that is being straight uploaded to YouTube. But it's a separate YouTube channel. Like these, the live streams on Twitch don't show up in the Jabril's YouTube channel. They show up in the Jabril's CPU YouTube channel. Correct, unless I do like really special live streams. Then they go on. Then they go there. Yeah, so you have three things to subscribe to. Twitch live stream, YouTube live stream, archive, and the main channel. Oh wow, thank you. You know, at least subscribe to the main channel. Definitely the main channel. Yes, Bruno clarifies you don't need 100K subscribers, only 100, and then you can do the channel name thing. So you could get YouTube.com slash Jabril's or. Ah, ah. I can't say that, stuff stuff. All right, so let me see. Let me just check the ask Jabril hashtag on Twitter. Maybe that's, see if there's anything. No, okay, anything else? There actually, somebody used this earlier in 2012. There's some weird. Oh interesting. So I should have made this ask, let's see Jabril's with the S. Let's see if that shows up. Ah yeah, so next time, you're not seeing this, but next time we'll do a different hashtag. Anyway. Very cool. So what time is it? It is four o'clock. That means I have to leave and go catch my coding train. So I will be back for sure next Friday. I hope that we'll be able to do more collaborations like this. Jabril's based in San Diego, right? So we do not, even though San Diego sounds dreamy to me, so I'm not gonna have to go on a trip there sometime. But AwakeMe asks, when is the next coding challenge? So I'll probably do coding challenges again next Friday. If I can get it together, I'd like to try to at least tackle this color predictor idea before next Friday. Oh, let me show one thing. You can, I don't know where you want it, you can stand here, because I wanted to mention people, most recently I did a coding challenge about quadtrees. No, okay. So github.com slash coding train slash quadtree. And so if you remember the code demo, this was what I did in my tutorial. So I just made a whole bunch of random points in space, 2D space, then I registered them in this quadtree data structure, which you'd have to go back and watch the videos to find out what that is. And then I had an algorithm that, in a hopefully faster way than iterating over all the points, pulls out a selection of points within a certain radius. And actually, I didn't do the circular region in the tutorials, somebody sent a pull request in after I uploaded the code for the circular region. So then what I did, not, and I want to do this as a coding challenge, but I did it in class, my NYU class earlier this week. I did a collision detection test, so let's look at this. So this is just a simple example that has, I believe there are one, oh yeah, it's down here. There are 1,000 particles. You have such a nice smile on your face. There are 1,000 particles and I'm testing if they are intersecting, and when they're intersecting they're highlighted white, when they're not intersecting they're just gray. And you can see I'm getting a pretty reasonable frame rate. I bet you I'm getting kind of a lower, I was getting 60 frames per second, no problem, when I tried this, so maybe it's just this computer because it's hooked up to the streaming system or there's other things in the browser like the Twitch channel going, but anyway. The point is, I'm going to uncheck this using quadtree. So as soon as I uncheck this using quadtree, it's going to, for every dot, iterate over all the dots instead of using the quadtree. And you can see now I'm at four or five frames per second. So we can see how the quadtree, at least, even though I did get a lot of comments along the lines of, you're doing your quadtree incorrectly, there's ways of making it better and more efficient. And two is, why are you doing a quadtree in JavaScript? That's sort of silly, it's not going to be very fast. And so while all of those points are valid and true, I would say, you can see that even with all of my failings as a programmer and using JavaScript, I'm still getting an incredible speed performance. And if I go down to, if I, you know, I can see even with 3,000 particles, I'm still getting 15 frames per second. And if I uncheck this, I mean, just forget about it. I don't even, you know, oops, it didn't even, it couldn't even, like, oh, you can't see what just happened, it checked itself. No, no, it's okay. So you can see the frame rate is officially zero right now. So if I can manage to check that again, we'll see. So there is certainly, I'm sure, more optimizations that I could do, but there is a benefit. So I have a challenge for everybody watching. If anybody, right now everything is in this GitHub repo, CodingTrain slash Quadtree, and you can see links to the video tutorials, the pseudocode Wikipedia page, and then these are the two examples. You're fine, you're fine. There's some other Quadtree libraries in JavaScript that are down here. But I have a challenge for anyone, which is that I would love to have another example here that is a flocking with Quadtree. So I will be accepting pull requests if you want to make a flocking demo with this Quadtree code. And I mean, I'll make this myself at some point, but I love to have people contribute. So that's one thing to see, like, can I get a flocking simulation in JavaScript with, like, 600 agents that's going to run reasonably well. Um, okay, whoops, I'm getting a notification here. Oh, thank you, Sixy. Sixy in the chat says, don't forget, you have to do this before you leave. This means we're wrapping up here. You have to read some random numbers. Unfortunately, I don't have the soundboard for any lullaby music. You can pick a page, read whatever you like. Take your time, enjoy. I'll check the chat for any last important questions. You know what, this is silly to have the Quadtrees thing behind you. So let's, so I guess what probably makes, options are your own website, or just like the full, let's just give you the full code. Do I get the soundtrack? I don't have it hooked up right now. Dang it. I can. Dang it. We can edit and overlay it later. Okay. That's why people can, the other thing I could do is, this is fun sometimes, people want to make their own. Oh, nice, okay. Remixes of this. Okay. And then they can overlay music, and whatever. There we go, I'll see how you step out. Seven, nine, five, zero. Point three, three, one. One point seven, one, four. One point eight, eight, nine. Dash point eight, five, eight. Dash point four, zero, one. One point two, one, five. One point five, two, six. Point six, nine, two, dash. Point five, six, seven. Point four, one, zero. Beautiful, that was beautiful. It brought tears to my eyes. People were telling me that it's very dangerous to stand in front of a green screen on the internet. But I do that all the time, and nobody ever, I made a whole, I danced in front of the green screen for 45 minutes straight, and nobody ever did it. Okay, there was some applause. All right, so Quadrenion. So I think we can wrap up. Thank you so much, Jabril, for being here at ITP this whole week. Thank you for having me. Thank you for coming and being a guest on the Coding Train. Thank you for having me. And to many more future collaborations and things like that in the future. Awesome. You gotta free stream that. Yes. I was just glad I didn't mess that up and do it like this, or hit my face by accident or something, because that's typically what I would do. All right, so we're gonna say goodbye. Thank you, internet, for watching. Now go, if Glitch Project is still live streaming, or TensorFlow Dev Summit is still live streaming, or I don't know, go watch somebody play some beautiful music or something, something non-coding related. Turn off YouTube, go outside. Be with friends and family. So anyway, anyway, you choose what to do. Don't listen to me. We're gonna leave. I don't have a good system for this. I just have to, only thing I can do is I use this mouse, and I go over here and I click this stop streaming button, and then we disappear. So I need a little outro video or something. I do have an intro video. I can actually just go straight to the intro video. I don't have to do it over, but I don't have an outro one. Okay. Here we go, goodbye. Cookie.",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:03:52.691907Z",
  "started_at": "2023-09-26T21:20:11.376611Z",
  "completed_at": "2023-09-26T21:36:48.180749Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=L9InSe46jkw",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 996.804138
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/h4rujpjbl7wmon5mzrz4imhwma/cancel",
    "get": "https://api.replicate.com/v1/predictions/h4rujpjbl7wmon5mzrz4imhwma"
  }
}