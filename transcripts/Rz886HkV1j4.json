{
  "id": "5zq2qxrbqwhvsaldzvthmu7z4q",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/Rz886HkV1j4.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/114924 [00:00<?, ?frames/s]\n  2%|▏         | 2860/114924 [00:08<05:17, 352.81frames/s]\n  5%|▌         | 5768/114924 [00:16<05:21, 339.98frames/s]\n  7%|▋         | 8564/114924 [00:26<05:39, 313.34frames/s]\n 10%|▉         | 11442/114924 [00:35<05:31, 312.36frames/s]\n 12%|█▏        | 14330/114924 [00:47<05:47, 289.62frames/s]\n 15%|█▌        | 17302/114924 [00:56<05:27, 298.30frames/s]\n 18%|█▊        | 20278/114924 [01:04<04:54, 321.05frames/s]\n 20%|██        | 23174/114924 [01:10<04:17, 356.69frames/s]\n 23%|██▎       | 25926/114924 [01:21<04:40, 317.58frames/s]\n 25%|██▌       | 28914/114924 [01:31<04:35, 312.41frames/s]\n 28%|██▊       | 31666/114924 [01:40<04:30, 307.24frames/s]\n 30%|███       | 34570/114924 [01:50<04:22, 306.58frames/s]\n 33%|███▎      | 37376/114924 [01:59<04:17, 300.86frames/s]\n 35%|███▍      | 40200/114924 [02:08<04:02, 307.97frames/s]\n 37%|███▋      | 43060/114924 [02:17<03:47, 316.57frames/s]\n 40%|███▉      | 45732/114924 [02:25<03:37, 318.54frames/s]\n 42%|████▏     | 48628/114924 [02:35<03:32, 311.51frames/s]\n 45%|████▍     | 51476/114924 [02:45<03:29, 302.67frames/s]\n 47%|████▋     | 54328/114924 [02:55<03:25, 295.42frames/s]\n 50%|████▉     | 57132/114924 [03:04<03:14, 296.39frames/s]\n 52%|█████▏    | 59992/114924 [03:14<03:06, 294.92frames/s]\n 55%|█████▍    | 62924/114924 [03:23<02:51, 303.40frames/s]\n 57%|█████▋    | 65896/114924 [03:32<02:36, 313.22frames/s]\n 60%|█████▉    | 68816/114924 [03:40<02:24, 319.92frames/s]\n 62%|██████▏   | 71776/114924 [03:49<02:12, 325.81frames/s]\n 65%|██████▌   | 74760/114924 [03:58<02:00, 333.75frames/s]\n 68%|██████▊   | 77600/114924 [04:05<01:47, 346.07frames/s]\n 70%|███████   | 80588/114924 [04:12<01:32, 372.83frames/s]\n 73%|███████▎  | 83436/114924 [04:18<01:20, 388.91frames/s]\n 75%|███████▍  | 86164/114924 [04:26<01:15, 378.60frames/s]\n 78%|███████▊  | 89072/114924 [04:34<01:10, 368.07frames/s]\n 80%|████████  | 92052/114924 [04:40<00:56, 405.47frames/s]\n 83%|████████▎ | 94908/114924 [04:48<00:51, 385.60frames/s]\n 85%|████████▌ | 97902/114924 [04:58<00:46, 364.00frames/s]\n 88%|████████▊ | 100710/114924 [05:06<00:39, 358.58frames/s]\n 90%|█████████ | 103706/114924 [05:12<00:29, 382.63frames/s]\n 93%|█████████▎| 106550/114924 [05:20<00:22, 379.12frames/s]\n 95%|█████████▌| 109346/114924 [05:26<00:14, 396.80frames/s]\n 98%|█████████▊| 112308/114924 [05:33<00:06, 401.55frames/s]\n 99%|█████████▉| 113960/114924 [05:38<00:02, 389.22frames/s]\n100%|██████████| 114924/114924 [05:39<00:00, 433.06frames/s]\n100%|██████████| 114924/114924 [05:39<00:00, 338.62frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.2524431266036688,
        "compression_ratio": 1.770392749244713,
        "end": 3.92,
        "id": 0,
        "no_speech_prob": 0.02367629110813141,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " Welcome to another Working With Data and APIs video.",
        "tokens": [
          50364,
          4027,
          281,
          1071,
          18337,
          2022,
          11888,
          293,
          21445,
          960,
          13,
          50560
        ]
      },
      {
        "avg_logprob": -0.2524431266036688,
        "compression_ratio": 1.770392749244713,
        "end": 6.28,
        "id": 1,
        "no_speech_prob": 0.02367629110813141,
        "seek": 0,
        "start": 3.92,
        "temperature": 0,
        "text": " I have one more thing to demonstrate to you.",
        "tokens": [
          50560,
          286,
          362,
          472,
          544,
          551,
          281,
          11698,
          281,
          291,
          13,
          50678
        ]
      },
      {
        "avg_logprob": -0.2524431266036688,
        "compression_ratio": 1.770392749244713,
        "end": 8.8,
        "id": 2,
        "no_speech_prob": 0.02367629110813141,
        "seek": 0,
        "start": 6.28,
        "temperature": 0,
        "text": " I mean, the truth of the matter is there's probably",
        "tokens": [
          50678,
          286,
          914,
          11,
          264,
          3494,
          295,
          264,
          1871,
          307,
          456,
          311,
          1391,
          50804
        ]
      },
      {
        "avg_logprob": -0.2524431266036688,
        "compression_ratio": 1.770392749244713,
        "end": 10.92,
        "id": 3,
        "no_speech_prob": 0.02367629110813141,
        "seek": 0,
        "start": 8.8,
        "temperature": 0,
        "text": " hundreds, thousands, tens of thousands,",
        "tokens": [
          50804,
          6779,
          11,
          5383,
          11,
          10688,
          295,
          5383,
          11,
          50910
        ]
      },
      {
        "avg_logprob": -0.2524431266036688,
        "compression_ratio": 1.770392749244713,
        "end": 13.56,
        "id": 4,
        "no_speech_prob": 0.02367629110813141,
        "seek": 0,
        "start": 10.92,
        "temperature": 0,
        "text": " millions of things that I've missed that I should cover,",
        "tokens": [
          50910,
          6803,
          295,
          721,
          300,
          286,
          600,
          6721,
          300,
          286,
          820,
          2060,
          11,
          51042
        ]
      },
      {
        "avg_logprob": -0.2524431266036688,
        "compression_ratio": 1.770392749244713,
        "end": 15.6,
        "id": 5,
        "no_speech_prob": 0.02367629110813141,
        "seek": 0,
        "start": 13.56,
        "temperature": 0,
        "text": " that I could get to, that I don't even know about,",
        "tokens": [
          51042,
          300,
          286,
          727,
          483,
          281,
          11,
          300,
          286,
          500,
          380,
          754,
          458,
          466,
          11,
          51144
        ]
      },
      {
        "avg_logprob": -0.2524431266036688,
        "compression_ratio": 1.770392749244713,
        "end": 16.6,
        "id": 6,
        "no_speech_prob": 0.02367629110813141,
        "seek": 0,
        "start": 15.6,
        "temperature": 0,
        "text": " that I will hear from you.",
        "tokens": [
          51144,
          300,
          286,
          486,
          1568,
          490,
          291,
          13,
          51194
        ]
      },
      {
        "avg_logprob": -0.2524431266036688,
        "compression_ratio": 1.770392749244713,
        "end": 18.56,
        "id": 7,
        "no_speech_prob": 0.02367629110813141,
        "seek": 0,
        "start": 16.6,
        "temperature": 0,
        "text": " And so I look forward to hearing all about in the comments",
        "tokens": [
          51194,
          400,
          370,
          286,
          574,
          2128,
          281,
          4763,
          439,
          466,
          294,
          264,
          3053,
          51292
        ]
      },
      {
        "avg_logprob": -0.2524431266036688,
        "compression_ratio": 1.770392749244713,
        "end": 19.98,
        "id": 8,
        "no_speech_prob": 0.02367629110813141,
        "seek": 0,
        "start": 18.56,
        "temperature": 0,
        "text": " and hopefully returning and making",
        "tokens": [
          51292,
          293,
          4696,
          12678,
          293,
          1455,
          51363
        ]
      },
      {
        "avg_logprob": -0.2524431266036688,
        "compression_ratio": 1.770392749244713,
        "end": 23.52,
        "id": 9,
        "no_speech_prob": 0.02367629110813141,
        "seek": 0,
        "start": 19.98,
        "temperature": 0,
        "text": " more videos that continue these projects and this discussion.",
        "tokens": [
          51363,
          544,
          2145,
          300,
          2354,
          613,
          4455,
          293,
          341,
          5017,
          13,
          51540
        ]
      },
      {
        "avg_logprob": -0.2524431266036688,
        "compression_ratio": 1.770392749244713,
        "end": 26.52,
        "id": 10,
        "no_speech_prob": 0.02367629110813141,
        "seek": 0,
        "start": 23.52,
        "temperature": 0,
        "text": " But before I go, at least in this first round of what",
        "tokens": [
          51540,
          583,
          949,
          286,
          352,
          11,
          412,
          1935,
          294,
          341,
          700,
          3098,
          295,
          437,
          51690
        ]
      },
      {
        "avg_logprob": -0.2524431266036688,
        "compression_ratio": 1.770392749244713,
        "end": 28.6,
        "id": 11,
        "no_speech_prob": 0.02367629110813141,
        "seek": 0,
        "start": 26.52,
        "temperature": 0,
        "text": " I'm making right now, I want to show you one thing,",
        "tokens": [
          51690,
          286,
          478,
          1455,
          558,
          586,
          11,
          286,
          528,
          281,
          855,
          291,
          472,
          551,
          11,
          51794
        ]
      },
      {
        "avg_logprob": -0.26742904663085937,
        "compression_ratio": 1.7916666666666667,
        "end": 30.560000000000002,
        "id": 12,
        "no_speech_prob": 0.0021156123839318752,
        "seek": 2860,
        "start": 28.6,
        "temperature": 0,
        "text": " how to deploy your project to a server,",
        "tokens": [
          50364,
          577,
          281,
          7274,
          428,
          1716,
          281,
          257,
          7154,
          11,
          50462
        ]
      },
      {
        "avg_logprob": -0.26742904663085937,
        "compression_ratio": 1.7916666666666667,
        "end": 33.36,
        "id": 13,
        "no_speech_prob": 0.0021156123839318752,
        "seek": 2860,
        "start": 30.560000000000002,
        "temperature": 0,
        "text": " put it out in the world so that people could access and use it.",
        "tokens": [
          50462,
          829,
          309,
          484,
          294,
          264,
          1002,
          370,
          300,
          561,
          727,
          2105,
          293,
          764,
          309,
          13,
          50602
        ]
      },
      {
        "avg_logprob": -0.26742904663085937,
        "compression_ratio": 1.7916666666666667,
        "end": 35.88,
        "id": 14,
        "no_speech_prob": 0.0021156123839318752,
        "seek": 2860,
        "start": 33.36,
        "temperature": 0,
        "text": " There's an inherent problem with me even making this video,",
        "tokens": [
          50602,
          821,
          311,
          364,
          26387,
          1154,
          365,
          385,
          754,
          1455,
          341,
          960,
          11,
          50728
        ]
      },
      {
        "avg_logprob": -0.26742904663085937,
        "compression_ratio": 1.7916666666666667,
        "end": 37.480000000000004,
        "id": 15,
        "no_speech_prob": 0.0021156123839318752,
        "seek": 2860,
        "start": 35.88,
        "temperature": 0,
        "text": " because there's no one way to do this.",
        "tokens": [
          50728,
          570,
          456,
          311,
          572,
          472,
          636,
          281,
          360,
          341,
          13,
          50808
        ]
      },
      {
        "avg_logprob": -0.26742904663085937,
        "compression_ratio": 1.7916666666666667,
        "end": 39.46,
        "id": 16,
        "no_speech_prob": 0.0021156123839318752,
        "seek": 2860,
        "start": 37.480000000000004,
        "temperature": 0,
        "text": " I mean, you could build your own server,",
        "tokens": [
          50808,
          286,
          914,
          11,
          291,
          727,
          1322,
          428,
          1065,
          7154,
          11,
          50907
        ]
      },
      {
        "avg_logprob": -0.26742904663085937,
        "compression_ratio": 1.7916666666666667,
        "end": 42.36,
        "id": 17,
        "no_speech_prob": 0.0021156123839318752,
        "seek": 2860,
        "start": 39.46,
        "temperature": 0,
        "text": " get your own internet connection, get an IP address,",
        "tokens": [
          50907,
          483,
          428,
          1065,
          4705,
          4984,
          11,
          483,
          364,
          8671,
          2985,
          11,
          51052
        ]
      },
      {
        "avg_logprob": -0.26742904663085937,
        "compression_ratio": 1.7916666666666667,
        "end": 45.08,
        "id": 18,
        "no_speech_prob": 0.0021156123839318752,
        "seek": 2860,
        "start": 42.36,
        "temperature": 0,
        "text": " create your own web server on a Raspberry Pi even,",
        "tokens": [
          51052,
          1884,
          428,
          1065,
          3670,
          7154,
          322,
          257,
          41154,
          17741,
          754,
          11,
          51188
        ]
      },
      {
        "avg_logprob": -0.26742904663085937,
        "compression_ratio": 1.7916666666666667,
        "end": 48.040000000000006,
        "id": 19,
        "no_speech_prob": 0.0021156123839318752,
        "seek": 2860,
        "start": 45.08,
        "temperature": 0,
        "text": " put it somewhere out in the forest wirelessly, who knows,",
        "tokens": [
          51188,
          829,
          309,
          4079,
          484,
          294,
          264,
          6719,
          6234,
          12048,
          11,
          567,
          3255,
          11,
          51336
        ]
      },
      {
        "avg_logprob": -0.26742904663085937,
        "compression_ratio": 1.7916666666666667,
        "end": 49.96,
        "id": 20,
        "no_speech_prob": 0.0021156123839318752,
        "seek": 2860,
        "start": 48.040000000000006,
        "temperature": 0,
        "text": " attach it to a space station.",
        "tokens": [
          51336,
          5085,
          309,
          281,
          257,
          1901,
          5214,
          13,
          51432
        ]
      },
      {
        "avg_logprob": -0.26742904663085937,
        "compression_ratio": 1.7916666666666667,
        "end": 51.92,
        "id": 21,
        "no_speech_prob": 0.0021156123839318752,
        "seek": 2860,
        "start": 49.96,
        "temperature": 0,
        "text": " But what I want to look for here,",
        "tokens": [
          51432,
          583,
          437,
          286,
          528,
          281,
          574,
          337,
          510,
          11,
          51530
        ]
      },
      {
        "avg_logprob": -0.26742904663085937,
        "compression_ratio": 1.7916666666666667,
        "end": 55.08,
        "id": 22,
        "no_speech_prob": 0.0021156123839318752,
        "seek": 2860,
        "start": 51.92,
        "temperature": 0,
        "text": " at least I want to look at least two scenarios of using",
        "tokens": [
          51530,
          412,
          1935,
          286,
          528,
          281,
          574,
          412,
          1935,
          732,
          15077,
          295,
          1228,
          51688
        ]
      },
      {
        "avg_logprob": -0.26742904663085937,
        "compression_ratio": 1.7916666666666667,
        "end": 57.68000000000001,
        "id": 23,
        "no_speech_prob": 0.0021156123839318752,
        "seek": 2860,
        "start": 55.08,
        "temperature": 0,
        "text": " a commercial hosting service that",
        "tokens": [
          51688,
          257,
          6841,
          16058,
          2643,
          300,
          51818
        ]
      },
      {
        "avg_logprob": -0.22100145676556757,
        "compression_ratio": 1.8083067092651757,
        "end": 59.84,
        "id": 24,
        "no_speech_prob": 0.020330971106886864,
        "seek": 5768,
        "start": 57.68,
        "temperature": 0,
        "text": " allows you to deploy your node code",
        "tokens": [
          50364,
          4045,
          291,
          281,
          7274,
          428,
          9984,
          3089,
          50472
        ]
      },
      {
        "avg_logprob": -0.22100145676556757,
        "compression_ratio": 1.8083067092651757,
        "end": 61.64,
        "id": 25,
        "no_speech_prob": 0.020330971106886864,
        "seek": 5768,
        "start": 59.84,
        "temperature": 0,
        "text": " and have it run somewhere and will give you",
        "tokens": [
          50472,
          293,
          362,
          309,
          1190,
          4079,
          293,
          486,
          976,
          291,
          50562
        ]
      },
      {
        "avg_logprob": -0.22100145676556757,
        "compression_ratio": 1.8083067092651757,
        "end": 63.96,
        "id": 26,
        "no_speech_prob": 0.020330971106886864,
        "seek": 5768,
        "start": 61.64,
        "temperature": 0,
        "text": " a URL so that you can actually see it in the browser.",
        "tokens": [
          50562,
          257,
          12905,
          370,
          300,
          291,
          393,
          767,
          536,
          309,
          294,
          264,
          11185,
          13,
          50678
        ]
      },
      {
        "avg_logprob": -0.22100145676556757,
        "compression_ratio": 1.8083067092651757,
        "end": 67.6,
        "id": 27,
        "no_speech_prob": 0.020330971106886864,
        "seek": 5768,
        "start": 63.96,
        "temperature": 0,
        "text": " And the two services I want to show you are Glitch and Heroku.",
        "tokens": [
          50678,
          400,
          264,
          732,
          3328,
          286,
          528,
          281,
          855,
          291,
          366,
          5209,
          1549,
          293,
          3204,
          13275,
          13,
          50860
        ]
      },
      {
        "avg_logprob": -0.22100145676556757,
        "compression_ratio": 1.8083067092651757,
        "end": 69.1,
        "id": 28,
        "no_speech_prob": 0.020330971106886864,
        "seek": 5768,
        "start": 67.6,
        "temperature": 0,
        "text": " Glitch, as it says on their website,",
        "tokens": [
          50860,
          5209,
          1549,
          11,
          382,
          309,
          1619,
          322,
          641,
          3144,
          11,
          50935
        ]
      },
      {
        "avg_logprob": -0.22100145676556757,
        "compression_ratio": 1.8083067092651757,
        "end": 70.68,
        "id": 29,
        "no_speech_prob": 0.020330971106886864,
        "seek": 5768,
        "start": 69.1,
        "temperature": 0,
        "text": " is the friendly community where you'll",
        "tokens": [
          50935,
          307,
          264,
          9208,
          1768,
          689,
          291,
          603,
          51014
        ]
      },
      {
        "avg_logprob": -0.22100145676556757,
        "compression_ratio": 1.8083067092651757,
        "end": 72.08,
        "id": 30,
        "no_speech_prob": 0.020330971106886864,
        "seek": 5768,
        "start": 70.68,
        "temperature": 0,
        "text": " find the app of your dreams.",
        "tokens": [
          51014,
          915,
          264,
          724,
          295,
          428,
          7505,
          13,
          51084
        ]
      },
      {
        "avg_logprob": -0.22100145676556757,
        "compression_ratio": 1.8083067092651757,
        "end": 73.28,
        "id": 31,
        "no_speech_prob": 0.020330971106886864,
        "seek": 5768,
        "start": 72.08,
        "temperature": 0,
        "text": " I love Glitch.",
        "tokens": [
          51084,
          286,
          959,
          5209,
          1549,
          13,
          51144
        ]
      },
      {
        "avg_logprob": -0.22100145676556757,
        "compression_ratio": 1.8083067092651757,
        "end": 76.68,
        "id": 32,
        "no_speech_prob": 0.020330971106886864,
        "seek": 5768,
        "start": 73.28,
        "temperature": 0,
        "text": " It's an amazing code editor in the browser",
        "tokens": [
          51144,
          467,
          311,
          364,
          2243,
          3089,
          9839,
          294,
          264,
          11185,
          51314
        ]
      },
      {
        "avg_logprob": -0.22100145676556757,
        "compression_ratio": 1.8083067092651757,
        "end": 79.12,
        "id": 33,
        "no_speech_prob": 0.020330971106886864,
        "seek": 5768,
        "start": 76.68,
        "temperature": 0,
        "text": " that you can write node code, client JavaScript.",
        "tokens": [
          51314,
          300,
          291,
          393,
          2464,
          9984,
          3089,
          11,
          6423,
          15778,
          13,
          51436
        ]
      },
      {
        "avg_logprob": -0.22100145676556757,
        "compression_ratio": 1.8083067092651757,
        "end": 80.48,
        "id": 34,
        "no_speech_prob": 0.020330971106886864,
        "seek": 5768,
        "start": 79.12,
        "temperature": 0,
        "text": " You can build all sorts of apps.",
        "tokens": [
          51436,
          509,
          393,
          1322,
          439,
          7527,
          295,
          7733,
          13,
          51504
        ]
      },
      {
        "avg_logprob": -0.22100145676556757,
        "compression_ratio": 1.8083067092651757,
        "end": 81.28,
        "id": 35,
        "no_speech_prob": 0.020330971106886864,
        "seek": 5768,
        "start": 80.48,
        "temperature": 0,
        "text": " You can share them.",
        "tokens": [
          51504,
          509,
          393,
          2073,
          552,
          13,
          51544
        ]
      },
      {
        "avg_logprob": -0.22100145676556757,
        "compression_ratio": 1.8083067092651757,
        "end": 82.24000000000001,
        "id": 36,
        "no_speech_prob": 0.020330971106886864,
        "seek": 5768,
        "start": 81.28,
        "temperature": 0,
        "text": " You can remix them.",
        "tokens": [
          51544,
          509,
          393,
          47788,
          552,
          13,
          51592
        ]
      },
      {
        "avg_logprob": -0.22100145676556757,
        "compression_ratio": 1.8083067092651757,
        "end": 82.78,
        "id": 37,
        "no_speech_prob": 0.020330971106886864,
        "seek": 5768,
        "start": 82.24000000000001,
        "temperature": 0,
        "text": " It's colorful.",
        "tokens": [
          51592,
          467,
          311,
          18506,
          13,
          51619
        ]
      },
      {
        "avg_logprob": -0.22100145676556757,
        "compression_ratio": 1.8083067092651757,
        "end": 83.24000000000001,
        "id": 38,
        "no_speech_prob": 0.020330971106886864,
        "seek": 5768,
        "start": 82.78,
        "temperature": 0,
        "text": " It's friendly.",
        "tokens": [
          51619,
          467,
          311,
          9208,
          13,
          51642
        ]
      },
      {
        "avg_logprob": -0.22100145676556757,
        "compression_ratio": 1.8083067092651757,
        "end": 84.12,
        "id": 39,
        "no_speech_prob": 0.020330971106886864,
        "seek": 5768,
        "start": 83.24000000000001,
        "temperature": 0,
        "text": " You can ask for help.",
        "tokens": [
          51642,
          509,
          393,
          1029,
          337,
          854,
          13,
          51686
        ]
      },
      {
        "avg_logprob": -0.22100145676556757,
        "compression_ratio": 1.8083067092651757,
        "end": 85.64,
        "id": 40,
        "no_speech_prob": 0.020330971106886864,
        "seek": 5768,
        "start": 84.12,
        "temperature": 0,
        "text": " There's so much there in Glitch.",
        "tokens": [
          51686,
          821,
          311,
          370,
          709,
          456,
          294,
          5209,
          1549,
          13,
          51762
        ]
      },
      {
        "avg_logprob": -0.19889309790826612,
        "compression_ratio": 1.7113702623906706,
        "end": 88.68,
        "id": 41,
        "no_speech_prob": 0.00021995148563291878,
        "seek": 8564,
        "start": 85.64,
        "temperature": 0,
        "text": " And honestly, I could imagine a version of these tutorials",
        "tokens": [
          50364,
          400,
          6095,
          11,
          286,
          727,
          3811,
          257,
          3037,
          295,
          613,
          17616,
          50516
        ]
      },
      {
        "avg_logprob": -0.19889309790826612,
        "compression_ratio": 1.7113702623906706,
        "end": 91.24,
        "id": 42,
        "no_speech_prob": 0.00021995148563291878,
        "seek": 8564,
        "start": 88.68,
        "temperature": 0,
        "text": " where I just started with the first day opening up Glitch",
        "tokens": [
          50516,
          689,
          286,
          445,
          1409,
          365,
          264,
          700,
          786,
          5193,
          493,
          5209,
          1549,
          50644
        ]
      },
      {
        "avg_logprob": -0.19889309790826612,
        "compression_ratio": 1.7113702623906706,
        "end": 92.68,
        "id": 43,
        "no_speech_prob": 0.00021995148563291878,
        "seek": 8564,
        "start": 91.24,
        "temperature": 0,
        "text": " and building the project there.",
        "tokens": [
          50644,
          293,
          2390,
          264,
          1716,
          456,
          13,
          50716
        ]
      },
      {
        "avg_logprob": -0.19889309790826612,
        "compression_ratio": 1.7113702623906706,
        "end": 94.4,
        "id": 44,
        "no_speech_prob": 0.00021995148563291878,
        "seek": 8564,
        "start": 92.68,
        "temperature": 0,
        "text": " But since I've already built the project,",
        "tokens": [
          50716,
          583,
          1670,
          286,
          600,
          1217,
          3094,
          264,
          1716,
          11,
          50802
        ]
      },
      {
        "avg_logprob": -0.19889309790826612,
        "compression_ratio": 1.7113702623906706,
        "end": 96.78,
        "id": 45,
        "no_speech_prob": 0.00021995148563291878,
        "seek": 8564,
        "start": 94.4,
        "temperature": 0,
        "text": " I'm going to show you how to import it right into Glitch",
        "tokens": [
          50802,
          286,
          478,
          516,
          281,
          855,
          291,
          577,
          281,
          974,
          309,
          558,
          666,
          5209,
          1549,
          50921
        ]
      },
      {
        "avg_logprob": -0.19889309790826612,
        "compression_ratio": 1.7113702623906706,
        "end": 97.8,
        "id": 46,
        "no_speech_prob": 0.00021995148563291878,
        "seek": 8564,
        "start": 96.78,
        "temperature": 0,
        "text": " and run it there.",
        "tokens": [
          50921,
          293,
          1190,
          309,
          456,
          13,
          50972
        ]
      },
      {
        "avg_logprob": -0.19889309790826612,
        "compression_ratio": 1.7113702623906706,
        "end": 99.96000000000001,
        "id": 47,
        "no_speech_prob": 0.00021995148563291878,
        "seek": 8564,
        "start": 97.8,
        "temperature": 0,
        "text": " After that, I'm going to show you",
        "tokens": [
          50972,
          2381,
          300,
          11,
          286,
          478,
          516,
          281,
          855,
          291,
          51080
        ]
      },
      {
        "avg_logprob": -0.19889309790826612,
        "compression_ratio": 1.7113702623906706,
        "end": 101.64,
        "id": 48,
        "no_speech_prob": 0.00021995148563291878,
        "seek": 8564,
        "start": 99.96000000000001,
        "temperature": 0,
        "text": " another service called Heroku.",
        "tokens": [
          51080,
          1071,
          2643,
          1219,
          3204,
          13275,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19889309790826612,
        "compression_ratio": 1.7113702623906706,
        "end": 104.16,
        "id": 49,
        "no_speech_prob": 0.00021995148563291878,
        "seek": 8564,
        "start": 101.64,
        "temperature": 0,
        "text": " It's a cloud platform that lets you deploy web applications.",
        "tokens": [
          51164,
          467,
          311,
          257,
          4588,
          3663,
          300,
          6653,
          291,
          7274,
          3670,
          5821,
          13,
          51290
        ]
      },
      {
        "avg_logprob": -0.19889309790826612,
        "compression_ratio": 1.7113702623906706,
        "end": 105.8,
        "id": 50,
        "no_speech_prob": 0.00021995148563291878,
        "seek": 8564,
        "start": 104.16,
        "temperature": 0,
        "text": " It has a pretty reasonable free tier",
        "tokens": [
          51290,
          467,
          575,
          257,
          1238,
          10585,
          1737,
          12362,
          51372
        ]
      },
      {
        "avg_logprob": -0.19889309790826612,
        "compression_ratio": 1.7113702623906706,
        "end": 108.38,
        "id": 51,
        "no_speech_prob": 0.00021995148563291878,
        "seek": 8564,
        "start": 105.8,
        "temperature": 0,
        "text": " that I can get up and running with easily.",
        "tokens": [
          51372,
          300,
          286,
          393,
          483,
          493,
          293,
          2614,
          365,
          3612,
          13,
          51501
        ]
      },
      {
        "avg_logprob": -0.19889309790826612,
        "compression_ratio": 1.7113702623906706,
        "end": 110.16,
        "id": 52,
        "no_speech_prob": 0.00021995148563291878,
        "seek": 8564,
        "start": 108.38,
        "temperature": 0,
        "text": " This is not sponsored content.",
        "tokens": [
          51501,
          639,
          307,
          406,
          16621,
          2701,
          13,
          51590
        ]
      },
      {
        "avg_logprob": -0.19889309790826612,
        "compression_ratio": 1.7113702623906706,
        "end": 112.28,
        "id": 53,
        "no_speech_prob": 0.00021995148563291878,
        "seek": 8564,
        "start": 110.16,
        "temperature": 0,
        "text": " There are lots of other services that I've used.",
        "tokens": [
          51590,
          821,
          366,
          3195,
          295,
          661,
          3328,
          300,
          286,
          600,
          1143,
          13,
          51696
        ]
      },
      {
        "avg_logprob": -0.19889309790826612,
        "compression_ratio": 1.7113702623906706,
        "end": 114.42,
        "id": 54,
        "no_speech_prob": 0.00021995148563291878,
        "seek": 8564,
        "start": 112.28,
        "temperature": 0,
        "text": " Amazon Web Services, Digital Ocean,",
        "tokens": [
          51696,
          6795,
          9573,
          12124,
          11,
          15522,
          18101,
          11,
          51803
        ]
      },
      {
        "avg_logprob": -0.2535717806076621,
        "compression_ratio": 1.7763157894736843,
        "end": 115.86,
        "id": 55,
        "no_speech_prob": 0.03021278604865074,
        "seek": 11442,
        "start": 114.42,
        "temperature": 0,
        "text": " are just a couple to name a few.",
        "tokens": [
          50364,
          366,
          445,
          257,
          1916,
          281,
          1315,
          257,
          1326,
          13,
          50436
        ]
      },
      {
        "avg_logprob": -0.2535717806076621,
        "compression_ratio": 1.7763157894736843,
        "end": 117.54,
        "id": 56,
        "no_speech_prob": 0.03021278604865074,
        "seek": 11442,
        "start": 115.86,
        "temperature": 0,
        "text": " And I'm happy to come back and show",
        "tokens": [
          50436,
          400,
          286,
          478,
          2055,
          281,
          808,
          646,
          293,
          855,
          50520
        ]
      },
      {
        "avg_logprob": -0.2535717806076621,
        "compression_ratio": 1.7763157894736843,
        "end": 119.14,
        "id": 57,
        "no_speech_prob": 0.03021278604865074,
        "seek": 11442,
        "start": 117.54,
        "temperature": 0,
        "text": " some other ones in a video as well",
        "tokens": [
          50520,
          512,
          661,
          2306,
          294,
          257,
          960,
          382,
          731,
          50600
        ]
      },
      {
        "avg_logprob": -0.2535717806076621,
        "compression_ratio": 1.7763157894736843,
        "end": 120.5,
        "id": 58,
        "no_speech_prob": 0.03021278604865074,
        "seek": 11442,
        "start": 119.14,
        "temperature": 0,
        "text": " if that might be something useful.",
        "tokens": [
          50600,
          498,
          300,
          1062,
          312,
          746,
          4420,
          13,
          50668
        ]
      },
      {
        "avg_logprob": -0.2535717806076621,
        "compression_ratio": 1.7763157894736843,
        "end": 123.14,
        "id": 59,
        "no_speech_prob": 0.03021278604865074,
        "seek": 11442,
        "start": 120.5,
        "temperature": 0,
        "text": " Or leave in the comments what type of cloud server",
        "tokens": [
          50668,
          1610,
          1856,
          294,
          264,
          3053,
          437,
          2010,
          295,
          4588,
          7154,
          50800
        ]
      },
      {
        "avg_logprob": -0.2535717806076621,
        "compression_ratio": 1.7763157894736843,
        "end": 124.82000000000001,
        "id": 60,
        "no_speech_prob": 0.03021278604865074,
        "seek": 11442,
        "start": 123.14,
        "temperature": 0,
        "text": " you like to deploy your applications on.",
        "tokens": [
          50800,
          291,
          411,
          281,
          7274,
          428,
          5821,
          322,
          13,
          50884
        ]
      },
      {
        "avg_logprob": -0.2535717806076621,
        "compression_ratio": 1.7763157894736843,
        "end": 127.06,
        "id": 61,
        "no_speech_prob": 0.03021278604865074,
        "seek": 11442,
        "start": 124.82000000000001,
        "temperature": 0,
        "text": " There's also this thing called serverless programming.",
        "tokens": [
          50884,
          821,
          311,
          611,
          341,
          551,
          1219,
          7154,
          1832,
          9410,
          13,
          50996
        ]
      },
      {
        "avg_logprob": -0.2535717806076621,
        "compression_ratio": 1.7763157894736843,
        "end": 129.02,
        "id": 62,
        "no_speech_prob": 0.03021278604865074,
        "seek": 11442,
        "start": 127.06,
        "temperature": 0,
        "text": " Oh, we'll come back to that another time.",
        "tokens": [
          50996,
          876,
          11,
          321,
          603,
          808,
          646,
          281,
          300,
          1071,
          565,
          13,
          51094
        ]
      },
      {
        "avg_logprob": -0.2535717806076621,
        "compression_ratio": 1.7763157894736843,
        "end": 130.4,
        "id": 63,
        "no_speech_prob": 0.03021278604865074,
        "seek": 11442,
        "start": 129.02,
        "temperature": 0,
        "text": " Let's start off here with Glitch.",
        "tokens": [
          51094,
          961,
          311,
          722,
          766,
          510,
          365,
          5209,
          1549,
          13,
          51163
        ]
      },
      {
        "avg_logprob": -0.2535717806076621,
        "compression_ratio": 1.7763157894736843,
        "end": 132.54,
        "id": 64,
        "no_speech_prob": 0.03021278604865074,
        "seek": 11442,
        "start": 130.4,
        "temperature": 0,
        "text": " So here I am logged into my Glitch account.",
        "tokens": [
          51163,
          407,
          510,
          286,
          669,
          27231,
          666,
          452,
          5209,
          1549,
          2696,
          13,
          51270
        ]
      },
      {
        "avg_logprob": -0.2535717806076621,
        "compression_ratio": 1.7763157894736843,
        "end": 134.7,
        "id": 65,
        "no_speech_prob": 0.03021278604865074,
        "seek": 11442,
        "start": 132.54,
        "temperature": 0,
        "text": " My Glitch account is actually linked to my GitHub account,",
        "tokens": [
          51270,
          1222,
          5209,
          1549,
          2696,
          307,
          767,
          9408,
          281,
          452,
          23331,
          2696,
          11,
          51378
        ]
      },
      {
        "avg_logprob": -0.2535717806076621,
        "compression_ratio": 1.7763157894736843,
        "end": 136.42000000000002,
        "id": 66,
        "no_speech_prob": 0.03021278604865074,
        "seek": 11442,
        "start": 134.7,
        "temperature": 0,
        "text": " although you don't need a GitHub account to sign up",
        "tokens": [
          51378,
          4878,
          291,
          500,
          380,
          643,
          257,
          23331,
          2696,
          281,
          1465,
          493,
          51464
        ]
      },
      {
        "avg_logprob": -0.2535717806076621,
        "compression_ratio": 1.7763157894736843,
        "end": 137.7,
        "id": 67,
        "no_speech_prob": 0.03021278604865074,
        "seek": 11442,
        "start": 136.42000000000002,
        "temperature": 0,
        "text": " and start working with Glitch.",
        "tokens": [
          51464,
          293,
          722,
          1364,
          365,
          5209,
          1549,
          13,
          51528
        ]
      },
      {
        "avg_logprob": -0.2535717806076621,
        "compression_ratio": 1.7763157894736843,
        "end": 139.38,
        "id": 68,
        "no_speech_prob": 0.03021278604865074,
        "seek": 11442,
        "start": 137.7,
        "temperature": 0,
        "text": " I could make a new project.",
        "tokens": [
          51528,
          286,
          727,
          652,
          257,
          777,
          1716,
          13,
          51612
        ]
      },
      {
        "avg_logprob": -0.2535717806076621,
        "compression_ratio": 1.7763157894736843,
        "end": 141.14,
        "id": 69,
        "no_speech_prob": 0.03021278604865074,
        "seek": 11442,
        "start": 139.38,
        "temperature": 0,
        "text": " And I could actually make a blank project.",
        "tokens": [
          51612,
          400,
          286,
          727,
          767,
          652,
          257,
          8247,
          1716,
          13,
          51700
        ]
      },
      {
        "avg_logprob": -0.2535717806076621,
        "compression_ratio": 1.7763157894736843,
        "end": 142.18,
        "id": 70,
        "no_speech_prob": 0.03021278604865074,
        "seek": 11442,
        "start": 141.14,
        "temperature": 0,
        "text": " Hello, Express.",
        "tokens": [
          51700,
          2425,
          11,
          20212,
          13,
          51752
        ]
      },
      {
        "avg_logprob": -0.2535717806076621,
        "compression_ratio": 1.7763157894736843,
        "end": 143.3,
        "id": 71,
        "no_speech_prob": 0.03021278604865074,
        "seek": 11442,
        "start": 142.18,
        "temperature": 0,
        "text": " This would have been a good place for me",
        "tokens": [
          51752,
          639,
          576,
          362,
          668,
          257,
          665,
          1081,
          337,
          385,
          51808
        ]
      },
      {
        "avg_logprob": -0.22275535829605594,
        "compression_ratio": 1.721362229102167,
        "end": 144.78,
        "id": 72,
        "no_speech_prob": 0.014727938920259476,
        "seek": 14330,
        "start": 143.3,
        "temperature": 0,
        "text": " to start when I was back in the day.",
        "tokens": [
          50364,
          281,
          722,
          562,
          286,
          390,
          646,
          294,
          264,
          786,
          13,
          50438
        ]
      },
      {
        "avg_logprob": -0.22275535829605594,
        "compression_ratio": 1.721362229102167,
        "end": 145.94,
        "id": 73,
        "no_speech_prob": 0.014727938920259476,
        "seek": 14330,
        "start": 144.78,
        "temperature": 0,
        "text": " I didn't have anything yet.",
        "tokens": [
          50438,
          286,
          994,
          380,
          362,
          1340,
          1939,
          13,
          50496
        ]
      },
      {
        "avg_logprob": -0.22275535829605594,
        "compression_ratio": 1.721362229102167,
        "end": 147.74,
        "id": 74,
        "no_speech_prob": 0.014727938920259476,
        "seek": 14330,
        "start": 145.94,
        "temperature": 0,
        "text": " I could just make a new simple Express app",
        "tokens": [
          50496,
          286,
          727,
          445,
          652,
          257,
          777,
          2199,
          20212,
          724,
          50586
        ]
      },
      {
        "avg_logprob": -0.22275535829605594,
        "compression_ratio": 1.721362229102167,
        "end": 148.9,
        "id": 75,
        "no_speech_prob": 0.014727938920259476,
        "seek": 14330,
        "start": 147.74,
        "temperature": 0,
        "text": " and build on top of that.",
        "tokens": [
          50586,
          293,
          1322,
          322,
          1192,
          295,
          300,
          13,
          50644
        ]
      },
      {
        "avg_logprob": -0.22275535829605594,
        "compression_ratio": 1.721362229102167,
        "end": 151.16000000000003,
        "id": 76,
        "no_speech_prob": 0.014727938920259476,
        "seek": 14330,
        "start": 148.9,
        "temperature": 0,
        "text": " But I'm going to do something a little bit different.",
        "tokens": [
          50644,
          583,
          286,
          478,
          516,
          281,
          360,
          746,
          257,
          707,
          857,
          819,
          13,
          50757
        ]
      },
      {
        "avg_logprob": -0.22275535829605594,
        "compression_ratio": 1.721362229102167,
        "end": 153.54000000000002,
        "id": 77,
        "no_speech_prob": 0.014727938920259476,
        "seek": 14330,
        "start": 151.16000000000003,
        "temperature": 0,
        "text": " I'm going to use this clone from Git repo.",
        "tokens": [
          50757,
          286,
          478,
          516,
          281,
          764,
          341,
          26506,
          490,
          16939,
          49040,
          13,
          50876
        ]
      },
      {
        "avg_logprob": -0.22275535829605594,
        "compression_ratio": 1.721362229102167,
        "end": 156.02,
        "id": 78,
        "no_speech_prob": 0.014727938920259476,
        "seek": 14330,
        "start": 153.54000000000002,
        "temperature": 0,
        "text": " Since I've already gone through all the motions of writing",
        "tokens": [
          50876,
          4162,
          286,
          600,
          1217,
          2780,
          807,
          439,
          264,
          27500,
          295,
          3579,
          51000
        ]
      },
      {
        "avg_logprob": -0.22275535829605594,
        "compression_ratio": 1.721362229102167,
        "end": 158.66000000000003,
        "id": 79,
        "no_speech_prob": 0.014727938920259476,
        "seek": 14330,
        "start": 156.02,
        "temperature": 0,
        "text": " my code locally on the computer and then pushing it to GitHub,",
        "tokens": [
          51000,
          452,
          3089,
          16143,
          322,
          264,
          3820,
          293,
          550,
          7380,
          309,
          281,
          23331,
          11,
          51132
        ]
      },
      {
        "avg_logprob": -0.22275535829605594,
        "compression_ratio": 1.721362229102167,
        "end": 161.42000000000002,
        "id": 80,
        "no_speech_prob": 0.014727938920259476,
        "seek": 14330,
        "start": 158.66000000000003,
        "temperature": 0,
        "text": " I could just grab it and put it here.",
        "tokens": [
          51132,
          286,
          727,
          445,
          4444,
          309,
          293,
          829,
          309,
          510,
          13,
          51270
        ]
      },
      {
        "avg_logprob": -0.22275535829605594,
        "compression_ratio": 1.721362229102167,
        "end": 164.02,
        "id": 81,
        "no_speech_prob": 0.014727938920259476,
        "seek": 14330,
        "start": 161.42000000000002,
        "temperature": 0,
        "text": " But before I do that, I better make one more change.",
        "tokens": [
          51270,
          583,
          949,
          286,
          360,
          300,
          11,
          286,
          1101,
          652,
          472,
          544,
          1319,
          13,
          51400
        ]
      },
      {
        "avg_logprob": -0.22275535829605594,
        "compression_ratio": 1.721362229102167,
        "end": 167.02,
        "id": 82,
        "no_speech_prob": 0.014727938920259476,
        "seek": 14330,
        "start": 164.02,
        "temperature": 0,
        "text": " There's something that I missed that's rather important.",
        "tokens": [
          51400,
          821,
          311,
          746,
          300,
          286,
          6721,
          300,
          311,
          2831,
          1021,
          13,
          51550
        ]
      },
      {
        "avg_logprob": -0.22275535829605594,
        "compression_ratio": 1.721362229102167,
        "end": 173.02,
        "id": 83,
        "no_speech_prob": 0.014727938920259476,
        "seek": 14330,
        "start": 167.02,
        "temperature": 0,
        "text": " So in my code, I have hard coded in here the port 3000.",
        "tokens": [
          51550,
          407,
          294,
          452,
          3089,
          11,
          286,
          362,
          1152,
          34874,
          294,
          510,
          264,
          2436,
          20984,
          13,
          51850
        ]
      },
      {
        "avg_logprob": -0.22609119278063877,
        "compression_ratio": 1.8235294117647058,
        "end": 174.94,
        "id": 84,
        "no_speech_prob": 0.00035142895649187267,
        "seek": 17302,
        "start": 173.02,
        "temperature": 0,
        "text": " That's the port that I'm arbitrarily",
        "tokens": [
          50364,
          663,
          311,
          264,
          2436,
          300,
          286,
          478,
          19071,
          3289,
          50460
        ]
      },
      {
        "avg_logprob": -0.22609119278063877,
        "compression_ratio": 1.8235294117647058,
        "end": 178.26000000000002,
        "id": 85,
        "no_speech_prob": 0.00035142895649187267,
        "seek": 17302,
        "start": 174.94,
        "temperature": 0,
        "text": " choosing to run and test the stuff locally on this computer.",
        "tokens": [
          50460,
          10875,
          281,
          1190,
          293,
          1500,
          264,
          1507,
          16143,
          322,
          341,
          3820,
          13,
          50626
        ]
      },
      {
        "avg_logprob": -0.22609119278063877,
        "compression_ratio": 1.8235294117647058,
        "end": 180.74,
        "id": 86,
        "no_speech_prob": 0.00035142895649187267,
        "seek": 17302,
        "start": 178.26000000000002,
        "temperature": 0,
        "text": " But any type of web hosting platform",
        "tokens": [
          50626,
          583,
          604,
          2010,
          295,
          3670,
          16058,
          3663,
          50750
        ]
      },
      {
        "avg_logprob": -0.22609119278063877,
        "compression_ratio": 1.8235294117647058,
        "end": 183.78,
        "id": 87,
        "no_speech_prob": 0.00035142895649187267,
        "seek": 17302,
        "start": 180.74,
        "temperature": 0,
        "text": " is probably going to generate a port automatically.",
        "tokens": [
          50750,
          307,
          1391,
          516,
          281,
          8460,
          257,
          2436,
          6772,
          13,
          50902
        ]
      },
      {
        "avg_logprob": -0.22609119278063877,
        "compression_ratio": 1.8235294117647058,
        "end": 185.9,
        "id": 88,
        "no_speech_prob": 0.00035142895649187267,
        "seek": 17302,
        "start": 183.78,
        "temperature": 0,
        "text": " And there are some standard ports",
        "tokens": [
          50902,
          400,
          456,
          366,
          512,
          3832,
          18160,
          51008
        ]
      },
      {
        "avg_logprob": -0.22609119278063877,
        "compression_ratio": 1.8235294117647058,
        "end": 187.78,
        "id": 89,
        "no_speech_prob": 0.00035142895649187267,
        "seek": 17302,
        "start": 185.9,
        "temperature": 0,
        "text": " for hosting up a website.",
        "tokens": [
          51008,
          337,
          16058,
          493,
          257,
          3144,
          13,
          51102
        ]
      },
      {
        "avg_logprob": -0.22609119278063877,
        "compression_ratio": 1.8235294117647058,
        "end": 190.58,
        "id": 90,
        "no_speech_prob": 0.00035142895649187267,
        "seek": 17302,
        "start": 187.78,
        "temperature": 0,
        "text": " So I actually want to pull that from the environment variable.",
        "tokens": [
          51102,
          407,
          286,
          767,
          528,
          281,
          2235,
          300,
          490,
          264,
          2823,
          7006,
          13,
          51242
        ]
      },
      {
        "avg_logprob": -0.22609119278063877,
        "compression_ratio": 1.8235294117647058,
        "end": 192.54000000000002,
        "id": 91,
        "no_speech_prob": 0.00035142895649187267,
        "seek": 17302,
        "start": 190.58,
        "temperature": 0,
        "text": " And this will be maybe an environment variable",
        "tokens": [
          51242,
          400,
          341,
          486,
          312,
          1310,
          364,
          2823,
          7006,
          51340
        ]
      },
      {
        "avg_logprob": -0.22609119278063877,
        "compression_ratio": 1.8235294117647058,
        "end": 194.70000000000002,
        "id": 92,
        "no_speech_prob": 0.00035142895649187267,
        "seek": 17302,
        "start": 192.54000000000002,
        "temperature": 0,
        "text": " that I don't actually set, but that already",
        "tokens": [
          51340,
          300,
          286,
          500,
          380,
          767,
          992,
          11,
          457,
          300,
          1217,
          51448
        ]
      },
      {
        "avg_logprob": -0.22609119278063877,
        "compression_ratio": 1.8235294117647058,
        "end": 196.22,
        "id": 93,
        "no_speech_prob": 0.00035142895649187267,
        "seek": 17302,
        "start": 194.70000000000002,
        "temperature": 0,
        "text": " comes with the platform.",
        "tokens": [
          51448,
          1487,
          365,
          264,
          3663,
          13,
          51524
        ]
      },
      {
        "avg_logprob": -0.22609119278063877,
        "compression_ratio": 1.8235294117647058,
        "end": 198.58,
        "id": 94,
        "no_speech_prob": 0.00035142895649187267,
        "seek": 17302,
        "start": 196.22,
        "temperature": 0,
        "text": " So not necessarily something that I put in here,",
        "tokens": [
          51524,
          407,
          406,
          4725,
          746,
          300,
          286,
          829,
          294,
          510,
          11,
          51642
        ]
      },
      {
        "avg_logprob": -0.22609119278063877,
        "compression_ratio": 1.8235294117647058,
        "end": 201.3,
        "id": 95,
        "no_speech_prob": 0.00035142895649187267,
        "seek": 17302,
        "start": 198.58,
        "temperature": 0,
        "text": " but something that's just going to be present whenever I'm",
        "tokens": [
          51642,
          457,
          746,
          300,
          311,
          445,
          516,
          281,
          312,
          1974,
          5699,
          286,
          478,
          51778
        ]
      },
      {
        "avg_logprob": -0.22609119278063877,
        "compression_ratio": 1.8235294117647058,
        "end": 202.78,
        "id": 96,
        "no_speech_prob": 0.00035142895649187267,
        "seek": 17302,
        "start": 201.3,
        "temperature": 0,
        "text": " on that platform itself.",
        "tokens": [
          51778,
          322,
          300,
          3663,
          2564,
          13,
          51852
        ]
      },
      {
        "avg_logprob": -0.310944087921627,
        "compression_ratio": 1.7579908675799087,
        "end": 204.9,
        "id": 97,
        "no_speech_prob": 0.0007207964663393795,
        "seek": 20278,
        "start": 203.54,
        "temperature": 0,
        "text": " So let me go back to the code.",
        "tokens": [
          50402,
          407,
          718,
          385,
          352,
          646,
          281,
          264,
          3089,
          13,
          50470
        ]
      },
      {
        "avg_logprob": -0.310944087921627,
        "compression_ratio": 1.7579908675799087,
        "end": 210.62,
        "id": 98,
        "no_speech_prob": 0.0007207964663393795,
        "seek": 20278,
        "start": 204.9,
        "temperature": 0,
        "text": " And let me add a const port equals process.env.port.",
        "tokens": [
          50470,
          400,
          718,
          385,
          909,
          257,
          1817,
          2436,
          6915,
          1399,
          13,
          268,
          85,
          13,
          2707,
          13,
          50756
        ]
      },
      {
        "avg_logprob": -0.310944087921627,
        "compression_ratio": 1.7579908675799087,
        "end": 211.42000000000002,
        "id": 99,
        "no_speech_prob": 0.0007207964663393795,
        "seek": 20278,
        "start": 210.62,
        "temperature": 0,
        "text": " Now here's the thing.",
        "tokens": [
          50756,
          823,
          510,
          311,
          264,
          551,
          13,
          50796
        ]
      },
      {
        "avg_logprob": -0.310944087921627,
        "compression_ratio": 1.7579908675799087,
        "end": 214.02,
        "id": 100,
        "no_speech_prob": 0.0007207964663393795,
        "seek": 20278,
        "start": 211.42000000000002,
        "temperature": 0,
        "text": " Now when I run this, and I'm going to put this port here.",
        "tokens": [
          50796,
          823,
          562,
          286,
          1190,
          341,
          11,
          293,
          286,
          478,
          516,
          281,
          829,
          341,
          2436,
          510,
          13,
          50926
        ]
      },
      {
        "avg_logprob": -0.310944087921627,
        "compression_ratio": 1.7579908675799087,
        "end": 217.86,
        "id": 101,
        "no_speech_prob": 0.0007207964663393795,
        "seek": 20278,
        "start": 214.02,
        "temperature": 0,
        "text": " And I'm going to just change the string to starting server at,",
        "tokens": [
          50926,
          400,
          286,
          478,
          516,
          281,
          445,
          1319,
          264,
          6798,
          281,
          2891,
          7154,
          412,
          11,
          51118
        ]
      },
      {
        "avg_logprob": -0.310944087921627,
        "compression_ratio": 1.7579908675799087,
        "end": 221.06,
        "id": 102,
        "no_speech_prob": 0.0007207964663393795,
        "seek": 20278,
        "start": 217.86,
        "temperature": 0,
        "text": " and then I'm just going to say port.",
        "tokens": [
          51118,
          293,
          550,
          286,
          478,
          445,
          516,
          281,
          584,
          2436,
          13,
          51278
        ]
      },
      {
        "avg_logprob": -0.310944087921627,
        "compression_ratio": 1.7579908675799087,
        "end": 223.42000000000002,
        "id": 103,
        "no_speech_prob": 0.0007207964663393795,
        "seek": 20278,
        "start": 221.06,
        "temperature": 0,
        "text": " So this is some changes I made to the code.",
        "tokens": [
          51278,
          407,
          341,
          307,
          512,
          2962,
          286,
          1027,
          281,
          264,
          3089,
          13,
          51396
        ]
      },
      {
        "avg_logprob": -0.310944087921627,
        "compression_ratio": 1.7579908675799087,
        "end": 224.1,
        "id": 104,
        "no_speech_prob": 0.0007207964663393795,
        "seek": 20278,
        "start": 223.42000000000002,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51396,
          2264,
          13,
          51430
        ]
      },
      {
        "avg_logprob": -0.310944087921627,
        "compression_ratio": 1.7579908675799087,
        "end": 225.06,
        "id": 105,
        "no_speech_prob": 0.0007207964663393795,
        "seek": 20278,
        "start": 224.1,
        "temperature": 0,
        "text": " So here's the thing.",
        "tokens": [
          51430,
          407,
          510,
          311,
          264,
          551,
          13,
          51478
        ]
      },
      {
        "avg_logprob": -0.310944087921627,
        "compression_ratio": 1.7579908675799087,
        "end": 231.74,
        "id": 106,
        "no_speech_prob": 0.0007207964663393795,
        "seek": 20278,
        "start": 225.06,
        "temperature": 0,
        "text": " This now, if I go and try to run this locally, boom.",
        "tokens": [
          51478,
          639,
          586,
          11,
          498,
          286,
          352,
          293,
          853,
          281,
          1190,
          341,
          16143,
          11,
          9351,
          13,
          51812
        ]
      },
      {
        "avg_logprob": -0.25596570420539244,
        "compression_ratio": 1.7152317880794703,
        "end": 232.82000000000002,
        "id": 107,
        "no_speech_prob": 0.0009110409300774336,
        "seek": 23174,
        "start": 231.82000000000002,
        "temperature": 0,
        "text": " A port number.",
        "tokens": [
          50368,
          316,
          2436,
          1230,
          13,
          50418
        ]
      },
      {
        "avg_logprob": -0.25596570420539244,
        "compression_ratio": 1.7152317880794703,
        "end": 234.62,
        "id": 108,
        "no_speech_prob": 0.0009110409300774336,
        "seek": 23174,
        "start": 232.82000000000002,
        "temperature": 0,
        "text": " Or do I actually have another error?",
        "tokens": [
          50418,
          1610,
          360,
          286,
          767,
          362,
          1071,
          6713,
          30,
          50508
        ]
      },
      {
        "avg_logprob": -0.25596570420539244,
        "compression_ratio": 1.7152317880794703,
        "end": 235.82000000000002,
        "id": 109,
        "no_speech_prob": 0.0009110409300774336,
        "seek": 23174,
        "start": 234.62,
        "temperature": 0,
        "text": " Oh, that's a different error.",
        "tokens": [
          50508,
          876,
          11,
          300,
          311,
          257,
          819,
          6713,
          13,
          50568
        ]
      },
      {
        "avg_logprob": -0.25596570420539244,
        "compression_ratio": 1.7152317880794703,
        "end": 236.94,
        "id": 110,
        "no_speech_prob": 0.0009110409300774336,
        "seek": 23174,
        "start": 235.82000000000002,
        "temperature": 0,
        "text": " I've got some syntax error.",
        "tokens": [
          50568,
          286,
          600,
          658,
          512,
          28431,
          6713,
          13,
          50624
        ]
      },
      {
        "avg_logprob": -0.25596570420539244,
        "compression_ratio": 1.7152317880794703,
        "end": 237.9,
        "id": 111,
        "no_speech_prob": 0.0009110409300774336,
        "seek": 23174,
        "start": 236.94,
        "temperature": 0,
        "text": " Let me fix that.",
        "tokens": [
          50624,
          961,
          385,
          3191,
          300,
          13,
          50672
        ]
      },
      {
        "avg_logprob": -0.25596570420539244,
        "compression_ratio": 1.7152317880794703,
        "end": 239.10000000000002,
        "id": 112,
        "no_speech_prob": 0.0009110409300774336,
        "seek": 23174,
        "start": 237.9,
        "temperature": 0,
        "text": " Always getting syntax errors.",
        "tokens": [
          50672,
          11270,
          1242,
          28431,
          13603,
          13,
          50732
        ]
      },
      {
        "avg_logprob": -0.25596570420539244,
        "compression_ratio": 1.7152317880794703,
        "end": 239.70000000000002,
        "id": 113,
        "no_speech_prob": 0.0009110409300774336,
        "seek": 23174,
        "start": 239.10000000000002,
        "temperature": 0,
        "text": " Oh, I don't know.",
        "tokens": [
          50732,
          876,
          11,
          286,
          500,
          380,
          458,
          13,
          50762
        ]
      },
      {
        "avg_logprob": -0.25596570420539244,
        "compression_ratio": 1.7152317880794703,
        "end": 240.86,
        "id": 114,
        "no_speech_prob": 0.0009110409300774336,
        "seek": 23174,
        "start": 239.70000000000002,
        "temperature": 0,
        "text": " I lost my curly brackets.",
        "tokens": [
          50762,
          286,
          2731,
          452,
          32066,
          26179,
          13,
          50820
        ]
      },
      {
        "avg_logprob": -0.25596570420539244,
        "compression_ratio": 1.7152317880794703,
        "end": 242.10000000000002,
        "id": 115,
        "no_speech_prob": 0.0009110409300774336,
        "seek": 23174,
        "start": 240.86,
        "temperature": 0,
        "text": " I'm not sure what I did here.",
        "tokens": [
          50820,
          286,
          478,
          406,
          988,
          437,
          286,
          630,
          510,
          13,
          50882
        ]
      },
      {
        "avg_logprob": -0.25596570420539244,
        "compression_ratio": 1.7152317880794703,
        "end": 242.62,
        "id": 116,
        "no_speech_prob": 0.0009110409300774336,
        "seek": 23174,
        "start": 242.10000000000002,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50882,
          821,
          321,
          352,
          13,
          50908
        ]
      },
      {
        "avg_logprob": -0.25596570420539244,
        "compression_ratio": 1.7152317880794703,
        "end": 243.18,
        "id": 117,
        "no_speech_prob": 0.0009110409300774336,
        "seek": 23174,
        "start": 242.62,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          50908,
          1079,
          13,
          50936
        ]
      },
      {
        "avg_logprob": -0.25596570420539244,
        "compression_ratio": 1.7152317880794703,
        "end": 246.02,
        "id": 118,
        "no_speech_prob": 0.0009110409300774336,
        "seek": 23174,
        "start": 243.18,
        "temperature": 0,
        "text": " Listen at that port, and then I log",
        "tokens": [
          50936,
          7501,
          412,
          300,
          2436,
          11,
          293,
          550,
          286,
          3565,
          51078
        ]
      },
      {
        "avg_logprob": -0.25596570420539244,
        "compression_ratio": 1.7152317880794703,
        "end": 247.38,
        "id": 119,
        "no_speech_prob": 0.0009110409300774336,
        "seek": 23174,
        "start": 246.02,
        "temperature": 0,
        "text": " starting the server at that port.",
        "tokens": [
          51078,
          2891,
          264,
          7154,
          412,
          300,
          2436,
          13,
          51146
        ]
      },
      {
        "avg_logprob": -0.25596570420539244,
        "compression_ratio": 1.7152317880794703,
        "end": 248.06,
        "id": 120,
        "no_speech_prob": 0.0009110409300774336,
        "seek": 23174,
        "start": 247.38,
        "temperature": 0,
        "text": " Sorry about that.",
        "tokens": [
          51146,
          4919,
          466,
          300,
          13,
          51180
        ]
      },
      {
        "avg_logprob": -0.25596570420539244,
        "compression_ratio": 1.7152317880794703,
        "end": 250.70000000000002,
        "id": 121,
        "no_speech_prob": 0.0009110409300774336,
        "seek": 23174,
        "start": 248.06,
        "temperature": 0,
        "text": " Let's try that again.",
        "tokens": [
          51180,
          961,
          311,
          853,
          300,
          797,
          13,
          51312
        ]
      },
      {
        "avg_logprob": -0.25596570420539244,
        "compression_ratio": 1.7152317880794703,
        "end": 252.58,
        "id": 122,
        "no_speech_prob": 0.0009110409300774336,
        "seek": 23174,
        "start": 250.70000000000002,
        "temperature": 0,
        "text": " Starting server at undefined.",
        "tokens": [
          51312,
          16217,
          7154,
          412,
          674,
          5666,
          2001,
          13,
          51406
        ]
      },
      {
        "avg_logprob": -0.25596570420539244,
        "compression_ratio": 1.7152317880794703,
        "end": 254.38,
        "id": 123,
        "no_speech_prob": 0.0009110409300774336,
        "seek": 23174,
        "start": 252.58,
        "temperature": 0,
        "text": " So I don't even know, how would I possibly,",
        "tokens": [
          51406,
          407,
          286,
          500,
          380,
          754,
          458,
          11,
          577,
          576,
          286,
          6264,
          11,
          51496
        ]
      },
      {
        "avg_logprob": -0.25596570420539244,
        "compression_ratio": 1.7152317880794703,
        "end": 255.42000000000002,
        "id": 124,
        "no_speech_prob": 0.0009110409300774336,
        "seek": 23174,
        "start": 254.38,
        "temperature": 0,
        "text": " there's no port.",
        "tokens": [
          51496,
          456,
          311,
          572,
          2436,
          13,
          51548
        ]
      },
      {
        "avg_logprob": -0.25596570420539244,
        "compression_ratio": 1.7152317880794703,
        "end": 257.58,
        "id": 125,
        "no_speech_prob": 0.0009110409300774336,
        "seek": 23174,
        "start": 255.42000000000002,
        "temperature": 0,
        "text": " I can't access the server.",
        "tokens": [
          51548,
          286,
          393,
          380,
          2105,
          264,
          7154,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.25596570420539244,
        "compression_ratio": 1.7152317880794703,
        "end": 259.26,
        "id": 126,
        "no_speech_prob": 0.0009110409300774336,
        "seek": 23174,
        "start": 257.58,
        "temperature": 0,
        "text": " So this is where I can do something nice.",
        "tokens": [
          51656,
          407,
          341,
          307,
          689,
          286,
          393,
          360,
          746,
          1481,
          13,
          51740
        ]
      },
      {
        "avg_logprob": -0.2417201727208957,
        "compression_ratio": 1.6555555555555554,
        "end": 264.02,
        "id": 127,
        "no_speech_prob": 0.008577308617532253,
        "seek": 25926,
        "start": 259.82,
        "temperature": 0,
        "text": " If there is no port in an environment variable or 3,000.",
        "tokens": [
          50392,
          759,
          456,
          307,
          572,
          2436,
          294,
          364,
          2823,
          7006,
          420,
          805,
          11,
          1360,
          13,
          50602
        ]
      },
      {
        "avg_logprob": -0.2417201727208957,
        "compression_ratio": 1.6555555555555554,
        "end": 267.74,
        "id": 128,
        "no_speech_prob": 0.008577308617532253,
        "seek": 25926,
        "start": 264.02,
        "temperature": 0,
        "text": " So now, if I run the server again, it's starting at 3,000.",
        "tokens": [
          50602,
          407,
          586,
          11,
          498,
          286,
          1190,
          264,
          7154,
          797,
          11,
          309,
          311,
          2891,
          412,
          805,
          11,
          1360,
          13,
          50788
        ]
      },
      {
        "avg_logprob": -0.2417201727208957,
        "compression_ratio": 1.6555555555555554,
        "end": 271.65999999999997,
        "id": 129,
        "no_speech_prob": 0.008577308617532253,
        "seek": 25926,
        "start": 267.74,
        "temperature": 0,
        "text": " I can go back and look at the project running locally",
        "tokens": [
          50788,
          286,
          393,
          352,
          646,
          293,
          574,
          412,
          264,
          1716,
          2614,
          16143,
          50984
        ]
      },
      {
        "avg_logprob": -0.2417201727208957,
        "compression_ratio": 1.6555555555555554,
        "end": 274.02,
        "id": 130,
        "no_speech_prob": 0.008577308617532253,
        "seek": 25926,
        "start": 271.65999999999997,
        "temperature": 0,
        "text": " at port 3,000.",
        "tokens": [
          50984,
          412,
          2436,
          805,
          11,
          1360,
          13,
          51102
        ]
      },
      {
        "avg_logprob": -0.2417201727208957,
        "compression_ratio": 1.6555555555555554,
        "end": 274.94,
        "id": 131,
        "no_speech_prob": 0.008577308617532253,
        "seek": 25926,
        "start": 274.02,
        "temperature": 0,
        "text": " And here it is.",
        "tokens": [
          51102,
          400,
          510,
          309,
          307,
          13,
          51148
        ]
      },
      {
        "avg_logprob": -0.2417201727208957,
        "compression_ratio": 1.6555555555555554,
        "end": 277.42,
        "id": 132,
        "no_speech_prob": 0.008577308617532253,
        "seek": 25926,
        "start": 274.94,
        "temperature": 0,
        "text": " OK, but that's not, I needed to do this,",
        "tokens": [
          51148,
          2264,
          11,
          457,
          300,
          311,
          406,
          11,
          286,
          2978,
          281,
          360,
          341,
          11,
          51272
        ]
      },
      {
        "avg_logprob": -0.2417201727208957,
        "compression_ratio": 1.6555555555555554,
        "end": 282.26,
        "id": 133,
        "no_speech_prob": 0.008577308617532253,
        "seek": 25926,
        "start": 277.42,
        "temperature": 0,
        "text": " because I now want Glitch to take care of the port for me.",
        "tokens": [
          51272,
          570,
          286,
          586,
          528,
          5209,
          1549,
          281,
          747,
          1127,
          295,
          264,
          2436,
          337,
          385,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2417201727208957,
        "compression_ratio": 1.6555555555555554,
        "end": 283.78,
        "id": 134,
        "no_speech_prob": 0.008577308617532253,
        "seek": 25926,
        "start": 282.26,
        "temperature": 0,
        "text": " I don't want to be in charge of that.",
        "tokens": [
          51514,
          286,
          500,
          380,
          528,
          281,
          312,
          294,
          4602,
          295,
          300,
          13,
          51590
        ]
      },
      {
        "avg_logprob": -0.2417201727208957,
        "compression_ratio": 1.6555555555555554,
        "end": 286.65999999999997,
        "id": 135,
        "no_speech_prob": 0.008577308617532253,
        "seek": 25926,
        "start": 283.78,
        "temperature": 0,
        "text": " Now, since I'm going to be getting the code from GitHub",
        "tokens": [
          51590,
          823,
          11,
          1670,
          286,
          478,
          516,
          281,
          312,
          1242,
          264,
          3089,
          490,
          23331,
          51734
        ]
      },
      {
        "avg_logprob": -0.2417201727208957,
        "compression_ratio": 1.6555555555555554,
        "end": 289.14,
        "id": 136,
        "no_speech_prob": 0.008577308617532253,
        "seek": 25926,
        "start": 286.65999999999997,
        "temperature": 0,
        "text": " onto Glitch, I need to make sure I take that change.",
        "tokens": [
          51734,
          3911,
          5209,
          1549,
          11,
          286,
          643,
          281,
          652,
          988,
          286,
          747,
          300,
          1319,
          13,
          51858
        ]
      },
      {
        "avg_logprob": -0.3118960165208386,
        "compression_ratio": 1.6384615384615384,
        "end": 291.53999999999996,
        "id": 137,
        "no_speech_prob": 0.00032502601970918477,
        "seek": 28914,
        "start": 289.14,
        "temperature": 0,
        "text": " I thought I just made it locally, and push it onto GitHub.",
        "tokens": [
          50364,
          286,
          1194,
          286,
          445,
          1027,
          309,
          16143,
          11,
          293,
          2944,
          309,
          3911,
          23331,
          13,
          50484
        ]
      },
      {
        "avg_logprob": -0.3118960165208386,
        "compression_ratio": 1.6384615384615384,
        "end": 292.03999999999996,
        "id": 138,
        "no_speech_prob": 0.00032502601970918477,
        "seek": 28914,
        "start": 291.53999999999996,
        "temperature": 0,
        "text": " Woo!",
        "tokens": [
          50484,
          10468,
          0,
          50509
        ]
      },
      {
        "avg_logprob": -0.3118960165208386,
        "compression_ratio": 1.6384615384615384,
        "end": 297.18,
        "id": 139,
        "no_speech_prob": 0.00032502601970918477,
        "seek": 28914,
        "start": 294.34,
        "temperature": 0,
        "text": " So I'm going to add, and I'm going to commit port",
        "tokens": [
          50624,
          407,
          286,
          478,
          516,
          281,
          909,
          11,
          293,
          286,
          478,
          516,
          281,
          5599,
          2436,
          50766
        ]
      },
      {
        "avg_logprob": -0.3118960165208386,
        "compression_ratio": 1.6384615384615384,
        "end": 301.5,
        "id": 140,
        "no_speech_prob": 0.00032502601970918477,
        "seek": 28914,
        "start": 297.18,
        "temperature": 0,
        "text": " from environment variable.",
        "tokens": [
          50766,
          490,
          2823,
          7006,
          13,
          50982
        ]
      },
      {
        "avg_logprob": -0.3118960165208386,
        "compression_ratio": 1.6384615384615384,
        "end": 304.94,
        "id": 141,
        "no_speech_prob": 0.00032502601970918477,
        "seek": 28914,
        "start": 301.5,
        "temperature": 0,
        "text": " And then I'm going to say git push origin master, which",
        "tokens": [
          50982,
          400,
          550,
          286,
          478,
          516,
          281,
          584,
          18331,
          2944,
          4957,
          4505,
          11,
          597,
          51154
        ]
      },
      {
        "avg_logprob": -0.3118960165208386,
        "compression_ratio": 1.6384615384615384,
        "end": 306.94,
        "id": 142,
        "no_speech_prob": 0.00032502601970918477,
        "seek": 28914,
        "start": 304.94,
        "temperature": 0,
        "text": " sends it up to GitHub itself.",
        "tokens": [
          51154,
          14790,
          309,
          493,
          281,
          23331,
          2564,
          13,
          51254
        ]
      },
      {
        "avg_logprob": -0.3118960165208386,
        "compression_ratio": 1.6384615384615384,
        "end": 308.53999999999996,
        "id": 143,
        "no_speech_prob": 0.00032502601970918477,
        "seek": 28914,
        "start": 306.94,
        "temperature": 0,
        "text": " This is getting a little bit confusing,",
        "tokens": [
          51254,
          639,
          307,
          1242,
          257,
          707,
          857,
          13181,
          11,
          51334
        ]
      },
      {
        "avg_logprob": -0.3118960165208386,
        "compression_ratio": 1.6384615384615384,
        "end": 311.03999999999996,
        "id": 144,
        "no_speech_prob": 0.00032502601970918477,
        "seek": 28914,
        "start": 308.53999999999996,
        "temperature": 0,
        "text": " so let's make a quick diagram just to understand the pieces.",
        "tokens": [
          51334,
          370,
          718,
          311,
          652,
          257,
          1702,
          10686,
          445,
          281,
          1223,
          264,
          3755,
          13,
          51459
        ]
      },
      {
        "avg_logprob": -0.3118960165208386,
        "compression_ratio": 1.6384615384615384,
        "end": 313.46,
        "id": 145,
        "no_speech_prob": 0.00032502601970918477,
        "seek": 28914,
        "start": 311.03999999999996,
        "temperature": 0,
        "text": " So I've got my laptop here.",
        "tokens": [
          51459,
          407,
          286,
          600,
          658,
          452,
          10732,
          510,
          13,
          51580
        ]
      },
      {
        "avg_logprob": -0.3118960165208386,
        "compression_ratio": 1.6384615384615384,
        "end": 315.74,
        "id": 146,
        "no_speech_prob": 0.00032502601970918477,
        "seek": 28914,
        "start": 313.46,
        "temperature": 0,
        "text": " And so I've been writing all the code here, the server",
        "tokens": [
          51580,
          400,
          370,
          286,
          600,
          668,
          3579,
          439,
          264,
          3089,
          510,
          11,
          264,
          7154,
          51694
        ]
      },
      {
        "avg_logprob": -0.3118960165208386,
        "compression_ratio": 1.6384615384615384,
        "end": 316.65999999999997,
        "id": 147,
        "no_speech_prob": 0.00032502601970918477,
        "seek": 28914,
        "start": 315.74,
        "temperature": 0,
        "text": " and the client.",
        "tokens": [
          51694,
          293,
          264,
          6423,
          13,
          51740
        ]
      },
      {
        "avg_logprob": -0.18414721690433125,
        "compression_ratio": 1.8611111111111112,
        "end": 320.22,
        "id": 148,
        "no_speech_prob": 0.000031201838282868266,
        "seek": 31666,
        "start": 316.66,
        "temperature": 0,
        "text": " Now what I've done is I have now taken all that code,",
        "tokens": [
          50364,
          823,
          437,
          286,
          600,
          1096,
          307,
          286,
          362,
          586,
          2726,
          439,
          300,
          3089,
          11,
          50542
        ]
      },
      {
        "avg_logprob": -0.18414721690433125,
        "compression_ratio": 1.8611111111111112,
        "end": 323.34000000000003,
        "id": 149,
        "no_speech_prob": 0.000031201838282868266,
        "seek": 31666,
        "start": 320.22,
        "temperature": 0,
        "text": " and I have put it onto GitHub.",
        "tokens": [
          50542,
          293,
          286,
          362,
          829,
          309,
          3911,
          23331,
          13,
          50698
        ]
      },
      {
        "avg_logprob": -0.18414721690433125,
        "compression_ratio": 1.8611111111111112,
        "end": 324.82000000000005,
        "id": 150,
        "no_speech_prob": 0.000031201838282868266,
        "seek": 31666,
        "start": 323.34000000000003,
        "temperature": 0,
        "text": " And these are now linked.",
        "tokens": [
          50698,
          400,
          613,
          366,
          586,
          9408,
          13,
          50772
        ]
      },
      {
        "avg_logprob": -0.18414721690433125,
        "compression_ratio": 1.8611111111111112,
        "end": 328.90000000000003,
        "id": 151,
        "no_speech_prob": 0.000031201838282868266,
        "seek": 31666,
        "start": 324.82000000000005,
        "temperature": 0,
        "text": " I can always push, which is sending code this way,",
        "tokens": [
          50772,
          286,
          393,
          1009,
          2944,
          11,
          597,
          307,
          7750,
          3089,
          341,
          636,
          11,
          50976
        ]
      },
      {
        "avg_logprob": -0.18414721690433125,
        "compression_ratio": 1.8611111111111112,
        "end": 331.46000000000004,
        "id": 152,
        "no_speech_prob": 0.000031201838282868266,
        "seek": 31666,
        "start": 328.90000000000003,
        "temperature": 0,
        "text": " or I can pull, which is sending code this way.",
        "tokens": [
          50976,
          420,
          286,
          393,
          2235,
          11,
          597,
          307,
          7750,
          3089,
          341,
          636,
          13,
          51104
        ]
      },
      {
        "avg_logprob": -0.18414721690433125,
        "compression_ratio": 1.8611111111111112,
        "end": 333.78000000000003,
        "id": 153,
        "no_speech_prob": 0.000031201838282868266,
        "seek": 31666,
        "start": 331.46000000000004,
        "temperature": 0,
        "text": " So this is really the thing that I've set up.",
        "tokens": [
          51104,
          407,
          341,
          307,
          534,
          264,
          551,
          300,
          286,
          600,
          992,
          493,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.18414721690433125,
        "compression_ratio": 1.8611111111111112,
        "end": 336.62,
        "id": 154,
        "no_speech_prob": 0.000031201838282868266,
        "seek": 31666,
        "start": 333.78000000000003,
        "temperature": 0,
        "text": " But I want to add a third component here.",
        "tokens": [
          51220,
          583,
          286,
          528,
          281,
          909,
          257,
          2636,
          6542,
          510,
          13,
          51362
        ]
      },
      {
        "avg_logprob": -0.18414721690433125,
        "compression_ratio": 1.8611111111111112,
        "end": 340.18,
        "id": 155,
        "no_speech_prob": 0.000031201838282868266,
        "seek": 31666,
        "start": 336.62,
        "temperature": 0,
        "text": " So that third component, I'm going to add Glitch as one.",
        "tokens": [
          51362,
          407,
          300,
          2636,
          6542,
          11,
          286,
          478,
          516,
          281,
          909,
          5209,
          1549,
          382,
          472,
          13,
          51540
        ]
      },
      {
        "avg_logprob": -0.18414721690433125,
        "compression_ratio": 1.8611111111111112,
        "end": 341.84000000000003,
        "id": 156,
        "no_speech_prob": 0.000031201838282868266,
        "seek": 31666,
        "start": 340.18,
        "temperature": 0,
        "text": " And I'm also going to show you, I'm also",
        "tokens": [
          51540,
          400,
          286,
          478,
          611,
          516,
          281,
          855,
          291,
          11,
          286,
          478,
          611,
          51623
        ]
      },
      {
        "avg_logprob": -0.18414721690433125,
        "compression_ratio": 1.8611111111111112,
        "end": 343.58000000000004,
        "id": 157,
        "no_speech_prob": 0.000031201838282868266,
        "seek": 31666,
        "start": 341.84000000000003,
        "temperature": 0,
        "text": " eventually going to add Heroku.",
        "tokens": [
          51623,
          4728,
          516,
          281,
          909,
          3204,
          13275,
          13,
          51710
        ]
      },
      {
        "avg_logprob": -0.18414721690433125,
        "compression_ratio": 1.8611111111111112,
        "end": 345.70000000000005,
        "id": 158,
        "no_speech_prob": 0.000031201838282868266,
        "seek": 31666,
        "start": 343.58000000000004,
        "temperature": 0,
        "text": " Now, the difference with Glitch and Heroku",
        "tokens": [
          51710,
          823,
          11,
          264,
          2649,
          365,
          5209,
          1549,
          293,
          3204,
          13275,
          51816
        ]
      },
      {
        "avg_logprob": -0.2698842148107985,
        "compression_ratio": 1.7057057057057057,
        "end": 347.53999999999996,
        "id": 159,
        "no_speech_prob": 0.0008426348795183003,
        "seek": 34570,
        "start": 345.7,
        "temperature": 0,
        "text": " is this is actually a code editor.",
        "tokens": [
          50364,
          307,
          341,
          307,
          767,
          257,
          3089,
          9839,
          13,
          50456
        ]
      },
      {
        "avg_logprob": -0.2698842148107985,
        "compression_ratio": 1.7057057057057057,
        "end": 350.3,
        "id": 160,
        "no_speech_prob": 0.0008426348795183003,
        "seek": 34570,
        "start": 347.53999999999996,
        "temperature": 0,
        "text": " So once I get the code from GitHub",
        "tokens": [
          50456,
          407,
          1564,
          286,
          483,
          264,
          3089,
          490,
          23331,
          50594
        ]
      },
      {
        "avg_logprob": -0.2698842148107985,
        "compression_ratio": 1.7057057057057057,
        "end": 352.58,
        "id": 161,
        "no_speech_prob": 0.0008426348795183003,
        "seek": 34570,
        "start": 350.3,
        "temperature": 0,
        "text": " and place it onto Glitch, this is",
        "tokens": [
          50594,
          293,
          1081,
          309,
          3911,
          5209,
          1549,
          11,
          341,
          307,
          50708
        ]
      },
      {
        "avg_logprob": -0.2698842148107985,
        "compression_ratio": 1.7057057057057057,
        "end": 355.21999999999997,
        "id": 162,
        "no_speech_prob": 0.0008426348795183003,
        "seek": 34570,
        "start": 352.58,
        "temperature": 0,
        "text": " kind of a connection that doesn't need to persist.",
        "tokens": [
          50708,
          733,
          295,
          257,
          4984,
          300,
          1177,
          380,
          643,
          281,
          13233,
          13,
          50840
        ]
      },
      {
        "avg_logprob": -0.2698842148107985,
        "compression_ratio": 1.7057057057057057,
        "end": 356.3,
        "id": 163,
        "no_speech_prob": 0.0008426348795183003,
        "seek": 34570,
        "start": 355.21999999999997,
        "temperature": 0,
        "text": " Then I could just, it's just there.",
        "tokens": [
          50840,
          1396,
          286,
          727,
          445,
          11,
          309,
          311,
          445,
          456,
          13,
          50894
        ]
      },
      {
        "avg_logprob": -0.2698842148107985,
        "compression_ratio": 1.7057057057057057,
        "end": 357.09999999999997,
        "id": 164,
        "no_speech_prob": 0.0008426348795183003,
        "seek": 34570,
        "start": 356.3,
        "temperature": 0,
        "text": " I can work on it.",
        "tokens": [
          50894,
          286,
          393,
          589,
          322,
          309,
          13,
          50934
        ]
      },
      {
        "avg_logprob": -0.2698842148107985,
        "compression_ratio": 1.7057057057057057,
        "end": 359.65999999999997,
        "id": 165,
        "no_speech_prob": 0.0008426348795183003,
        "seek": 34570,
        "start": 357.09999999999997,
        "temperature": 0,
        "text": " I just want a quick way of getting the stuff on Glitch.",
        "tokens": [
          50934,
          286,
          445,
          528,
          257,
          1702,
          636,
          295,
          1242,
          264,
          1507,
          322,
          5209,
          1549,
          13,
          51062
        ]
      },
      {
        "avg_logprob": -0.2698842148107985,
        "compression_ratio": 1.7057057057057057,
        "end": 361.34,
        "id": 166,
        "no_speech_prob": 0.0008426348795183003,
        "seek": 34570,
        "start": 359.65999999999997,
        "temperature": 0,
        "text": " I could have uploaded my files or copy-paste",
        "tokens": [
          51062,
          286,
          727,
          362,
          17135,
          452,
          7098,
          420,
          5055,
          12,
          79,
          9079,
          51146
        ]
      },
      {
        "avg_logprob": -0.2698842148107985,
        "compression_ratio": 1.7057057057057057,
        "end": 362.82,
        "id": 167,
        "no_speech_prob": 0.0008426348795183003,
        "seek": 34570,
        "start": 361.34,
        "temperature": 0,
        "text": " or been working there all along.",
        "tokens": [
          51146,
          420,
          668,
          1364,
          456,
          439,
          2051,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.2698842148107985,
        "compression_ratio": 1.7057057057057057,
        "end": 364.3,
        "id": 168,
        "no_speech_prob": 0.0008426348795183003,
        "seek": 34570,
        "start": 362.82,
        "temperature": 0,
        "text": " But something different will happen",
        "tokens": [
          51220,
          583,
          746,
          819,
          486,
          1051,
          51294
        ]
      },
      {
        "avg_logprob": -0.2698842148107985,
        "compression_ratio": 1.7057057057057057,
        "end": 366.98,
        "id": 169,
        "no_speech_prob": 0.0008426348795183003,
        "seek": 34570,
        "start": 364.3,
        "temperature": 0,
        "text": " once I put it on Heroku, which I will keep all of these things",
        "tokens": [
          51294,
          1564,
          286,
          829,
          309,
          322,
          3204,
          13275,
          11,
          597,
          286,
          486,
          1066,
          439,
          295,
          613,
          721,
          51428
        ]
      },
      {
        "avg_logprob": -0.2698842148107985,
        "compression_ratio": 1.7057057057057057,
        "end": 369.3,
        "id": 170,
        "no_speech_prob": 0.0008426348795183003,
        "seek": 34570,
        "start": 366.98,
        "temperature": 0,
        "text": " linked so I can continue to do the development here",
        "tokens": [
          51428,
          9408,
          370,
          286,
          393,
          2354,
          281,
          360,
          264,
          3250,
          510,
          51544
        ]
      },
      {
        "avg_logprob": -0.2698842148107985,
        "compression_ratio": 1.7057057057057057,
        "end": 372.3,
        "id": 171,
        "no_speech_prob": 0.0008426348795183003,
        "seek": 34570,
        "start": 369.3,
        "temperature": 0,
        "text": " on my laptop and push those changes through.",
        "tokens": [
          51544,
          322,
          452,
          10732,
          293,
          2944,
          729,
          2962,
          807,
          13,
          51694
        ]
      },
      {
        "avg_logprob": -0.2698842148107985,
        "compression_ratio": 1.7057057057057057,
        "end": 373.76,
        "id": 172,
        "no_speech_prob": 0.0008426348795183003,
        "seek": 34570,
        "start": 372.3,
        "temperature": 0,
        "text": " So let's come back to Glitch.",
        "tokens": [
          51694,
          407,
          718,
          311,
          808,
          646,
          281,
          5209,
          1549,
          13,
          51767
        ]
      },
      {
        "avg_logprob": -0.2321886914841672,
        "compression_ratio": 1.8716814159292035,
        "end": 376.96,
        "id": 173,
        "no_speech_prob": 0.00005225191489444114,
        "seek": 37376,
        "start": 373.76,
        "temperature": 0,
        "text": " And let's click on this button, Clone from a Git Repo.",
        "tokens": [
          50364,
          400,
          718,
          311,
          2052,
          322,
          341,
          2960,
          11,
          45536,
          490,
          257,
          16939,
          3696,
          78,
          13,
          50524
        ]
      },
      {
        "avg_logprob": -0.2321886914841672,
        "compression_ratio": 1.8716814159292035,
        "end": 379.32,
        "id": 174,
        "no_speech_prob": 0.00005225191489444114,
        "seek": 37376,
        "start": 376.96,
        "temperature": 0,
        "text": " And then I'm going to go over to my repo.",
        "tokens": [
          50524,
          400,
          550,
          286,
          478,
          516,
          281,
          352,
          670,
          281,
          452,
          49040,
          13,
          50642
        ]
      },
      {
        "avg_logprob": -0.2321886914841672,
        "compression_ratio": 1.8716814159292035,
        "end": 380.84,
        "id": 175,
        "no_speech_prob": 0.00005225191489444114,
        "seek": 37376,
        "start": 379.32,
        "temperature": 0,
        "text": " I'm going to copy the URL.",
        "tokens": [
          50642,
          286,
          478,
          516,
          281,
          5055,
          264,
          12905,
          13,
          50718
        ]
      },
      {
        "avg_logprob": -0.2321886914841672,
        "compression_ratio": 1.8716814159292035,
        "end": 382.64,
        "id": 176,
        "no_speech_prob": 0.00005225191489444114,
        "seek": 37376,
        "start": 380.84,
        "temperature": 0,
        "text": " And I'm going to, whoop, I'm going to press that button",
        "tokens": [
          50718,
          400,
          286,
          478,
          516,
          281,
          11,
          567,
          404,
          11,
          286,
          478,
          516,
          281,
          1886,
          300,
          2960,
          50808
        ]
      },
      {
        "avg_logprob": -0.2321886914841672,
        "compression_ratio": 1.8716814159292035,
        "end": 383.32,
        "id": 177,
        "no_speech_prob": 0.00005225191489444114,
        "seek": 37376,
        "start": 382.64,
        "temperature": 0,
        "text": " again.",
        "tokens": [
          50808,
          797,
          13,
          50842
        ]
      },
      {
        "avg_logprob": -0.2321886914841672,
        "compression_ratio": 1.8716814159292035,
        "end": 385.24,
        "id": 178,
        "no_speech_prob": 0.00005225191489444114,
        "seek": 37376,
        "start": 383.32,
        "temperature": 0,
        "text": " And I'm going to go over here and paste it in.",
        "tokens": [
          50842,
          400,
          286,
          478,
          516,
          281,
          352,
          670,
          510,
          293,
          9163,
          309,
          294,
          13,
          50938
        ]
      },
      {
        "avg_logprob": -0.2321886914841672,
        "compression_ratio": 1.8716814159292035,
        "end": 388.4,
        "id": 179,
        "no_speech_prob": 0.00005225191489444114,
        "seek": 37376,
        "start": 385.24,
        "temperature": 0,
        "text": " So I am grabbing all the code from coding",
        "tokens": [
          50938,
          407,
          286,
          669,
          23771,
          439,
          264,
          3089,
          490,
          17720,
          51096
        ]
      },
      {
        "avg_logprob": -0.2321886914841672,
        "compression_ratio": 1.8716814159292035,
        "end": 390.56,
        "id": 180,
        "no_speech_prob": 0.00005225191489444114,
        "seek": 37376,
        "start": 388.4,
        "temperature": 0,
        "text": " train slash the weather here.",
        "tokens": [
          51096,
          3847,
          17330,
          264,
          5503,
          510,
          13,
          51204
        ]
      },
      {
        "avg_logprob": -0.2321886914841672,
        "compression_ratio": 1.8716814159292035,
        "end": 392.03999999999996,
        "id": 181,
        "no_speech_prob": 0.00005225191489444114,
        "seek": 37376,
        "start": 390.56,
        "temperature": 0,
        "text": " And I'm going to hit OK.",
        "tokens": [
          51204,
          400,
          286,
          478,
          516,
          281,
          2045,
          2264,
          13,
          51278
        ]
      },
      {
        "avg_logprob": -0.2321886914841672,
        "compression_ratio": 1.8716814159292035,
        "end": 393.7,
        "id": 182,
        "no_speech_prob": 0.00005225191489444114,
        "seek": 37376,
        "start": 392.03999999999996,
        "temperature": 0,
        "text": " And I'm going to wait for a little bit.",
        "tokens": [
          51278,
          400,
          286,
          478,
          516,
          281,
          1699,
          337,
          257,
          707,
          857,
          13,
          51361
        ]
      },
      {
        "avg_logprob": -0.2321886914841672,
        "compression_ratio": 1.8716814159292035,
        "end": 399.32,
        "id": 183,
        "no_speech_prob": 0.00005225191489444114,
        "seek": 37376,
        "start": 397.71999999999997,
        "temperature": 0,
        "text": " And look at that.",
        "tokens": [
          51562,
          400,
          574,
          412,
          300,
          13,
          51642
        ]
      },
      {
        "avg_logprob": -0.2321886914841672,
        "compression_ratio": 1.8716814159292035,
        "end": 400.48,
        "id": 184,
        "no_speech_prob": 0.00005225191489444114,
        "seek": 37376,
        "start": 399.32,
        "temperature": 0,
        "text": " Look at this.",
        "tokens": [
          51642,
          2053,
          412,
          341,
          13,
          51700
        ]
      },
      {
        "avg_logprob": -0.2321886914841672,
        "compression_ratio": 1.8716814159292035,
        "end": 402,
        "id": 185,
        "no_speech_prob": 0.00005225191489444114,
        "seek": 37376,
        "start": 400.48,
        "temperature": 0,
        "text": " Everything is there.",
        "tokens": [
          51700,
          5471,
          307,
          456,
          13,
          51776
        ]
      },
      {
        "avg_logprob": -0.23515462550987193,
        "compression_ratio": 1.7174721189591078,
        "end": 405.52,
        "id": 186,
        "no_speech_prob": 0.0006166198290884495,
        "seek": 40200,
        "start": 402,
        "temperature": 0,
        "text": " Public check-ins, public logs, public index, public sketch,",
        "tokens": [
          50364,
          9489,
          1520,
          12,
          1292,
          11,
          1908,
          20820,
          11,
          1908,
          8186,
          11,
          1908,
          12325,
          11,
          50540
        ]
      },
      {
        "avg_logprob": -0.23515462550987193,
        "compression_ratio": 1.7174721189591078,
        "end": 407.8,
        "id": 187,
        "no_speech_prob": 0.0006166198290884495,
        "seek": 40200,
        "start": 405.52,
        "temperature": 0,
        "text": " public style, git ignore index, pack it up.",
        "tokens": [
          50540,
          1908,
          3758,
          11,
          18331,
          11200,
          8186,
          11,
          2844,
          309,
          493,
          13,
          50654
        ]
      },
      {
        "avg_logprob": -0.23515462550987193,
        "compression_ratio": 1.7174721189591078,
        "end": 410,
        "id": 188,
        "no_speech_prob": 0.0006166198290884495,
        "seek": 40200,
        "start": 407.8,
        "temperature": 0,
        "text": " Ooh, environment sample.",
        "tokens": [
          50654,
          7951,
          11,
          2823,
          6889,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.23515462550987193,
        "compression_ratio": 1.7174721189591078,
        "end": 410.68,
        "id": 189,
        "no_speech_prob": 0.0006166198290884495,
        "seek": 40200,
        "start": 410,
        "temperature": 0,
        "text": " Aha.",
        "tokens": [
          50764,
          27448,
          13,
          50798
        ]
      },
      {
        "avg_logprob": -0.23515462550987193,
        "compression_ratio": 1.7174721189591078,
        "end": 412.74,
        "id": 190,
        "no_speech_prob": 0.0006166198290884495,
        "seek": 40200,
        "start": 410.68,
        "temperature": 0,
        "text": " So remember, I need my API key.",
        "tokens": [
          50798,
          407,
          1604,
          11,
          286,
          643,
          452,
          9362,
          2141,
          13,
          50901
        ]
      },
      {
        "avg_logprob": -0.23515462550987193,
        "compression_ratio": 1.7174721189591078,
        "end": 416,
        "id": 191,
        "no_speech_prob": 0.0006166198290884495,
        "seek": 40200,
        "start": 412.74,
        "temperature": 0,
        "text": " So before I even try to run this, what I'm going to do now",
        "tokens": [
          50901,
          407,
          949,
          286,
          754,
          853,
          281,
          1190,
          341,
          11,
          437,
          286,
          478,
          516,
          281,
          360,
          586,
          51064
        ]
      },
      {
        "avg_logprob": -0.23515462550987193,
        "compression_ratio": 1.7174721189591078,
        "end": 418.76,
        "id": 192,
        "no_speech_prob": 0.0006166198290884495,
        "seek": 40200,
        "start": 416,
        "temperature": 0,
        "text": " is I'm going to hit Rename.",
        "tokens": [
          51064,
          307,
          286,
          478,
          516,
          281,
          2045,
          12883,
          529,
          13,
          51202
        ]
      },
      {
        "avg_logprob": -0.23515462550987193,
        "compression_ratio": 1.7174721189591078,
        "end": 420.98,
        "id": 193,
        "no_speech_prob": 0.0006166198290884495,
        "seek": 40200,
        "start": 418.76,
        "temperature": 0,
        "text": " And I'm going to change this to just.env.",
        "tokens": [
          51202,
          400,
          286,
          478,
          516,
          281,
          1319,
          341,
          281,
          445,
          2411,
          268,
          85,
          13,
          51313
        ]
      },
      {
        "avg_logprob": -0.23515462550987193,
        "compression_ratio": 1.7174721189591078,
        "end": 423.08,
        "id": 194,
        "no_speech_prob": 0.0006166198290884495,
        "seek": 40200,
        "start": 420.98,
        "temperature": 0,
        "text": " So now you can see it's got a key there.",
        "tokens": [
          51313,
          407,
          586,
          291,
          393,
          536,
          309,
          311,
          658,
          257,
          2141,
          456,
          13,
          51418
        ]
      },
      {
        "avg_logprob": -0.23515462550987193,
        "compression_ratio": 1.7174721189591078,
        "end": 424.04,
        "id": 195,
        "no_speech_prob": 0.0006166198290884495,
        "seek": 40200,
        "start": 423.08,
        "temperature": 0,
        "text": " Glitch knows.",
        "tokens": [
          51418,
          5209,
          1549,
          3255,
          13,
          51466
        ]
      },
      {
        "avg_logprob": -0.23515462550987193,
        "compression_ratio": 1.7174721189591078,
        "end": 427.72,
        "id": 196,
        "no_speech_prob": 0.0006166198290884495,
        "seek": 40200,
        "start": 424.04,
        "temperature": 0,
        "text": " Glitch really knows that.env files are secret files.",
        "tokens": [
          51466,
          5209,
          1549,
          534,
          3255,
          300,
          2411,
          268,
          85,
          7098,
          366,
          4054,
          7098,
          13,
          51650
        ]
      },
      {
        "avg_logprob": -0.23515462550987193,
        "compression_ratio": 1.7174721189591078,
        "end": 430.6,
        "id": 197,
        "no_speech_prob": 0.0006166198290884495,
        "seek": 40200,
        "start": 427.72,
        "temperature": 0,
        "text": " So if someone chooses to remix this project or based on it,",
        "tokens": [
          51650,
          407,
          498,
          1580,
          25963,
          281,
          47788,
          341,
          1716,
          420,
          2361,
          322,
          309,
          11,
          51794
        ]
      },
      {
        "avg_logprob": -0.21582225629478502,
        "compression_ratio": 1.848605577689243,
        "end": 433.16,
        "id": 198,
        "no_speech_prob": 0.00007254295633174479,
        "seek": 43060,
        "start": 430.6,
        "temperature": 0,
        "text": " if I'm sharing this, no one will be able to see the API key",
        "tokens": [
          50364,
          498,
          286,
          478,
          5414,
          341,
          11,
          572,
          472,
          486,
          312,
          1075,
          281,
          536,
          264,
          9362,
          2141,
          50492
        ]
      },
      {
        "avg_logprob": -0.21582225629478502,
        "compression_ratio": 1.848605577689243,
        "end": 433.96000000000004,
        "id": 199,
        "no_speech_prob": 0.00007254295633174479,
        "seek": 43060,
        "start": 433.16,
        "temperature": 0,
        "text": " in there.",
        "tokens": [
          50492,
          294,
          456,
          13,
          50532
        ]
      },
      {
        "avg_logprob": -0.21582225629478502,
        "compression_ratio": 1.848605577689243,
        "end": 435.24,
        "id": 200,
        "no_speech_prob": 0.00007254295633174479,
        "seek": 43060,
        "start": 433.96000000000004,
        "temperature": 0,
        "text": " I'm going to go.",
        "tokens": [
          50532,
          286,
          478,
          516,
          281,
          352,
          13,
          50596
        ]
      },
      {
        "avg_logprob": -0.21582225629478502,
        "compression_ratio": 1.848605577689243,
        "end": 436.88,
        "id": 201,
        "no_speech_prob": 0.00007254295633174479,
        "seek": 43060,
        "start": 435.24,
        "temperature": 0,
        "text": " And I'm going to go back to my code",
        "tokens": [
          50596,
          400,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          452,
          3089,
          50678
        ]
      },
      {
        "avg_logprob": -0.21582225629478502,
        "compression_ratio": 1.848605577689243,
        "end": 441.12,
        "id": 202,
        "no_speech_prob": 0.00007254295633174479,
        "seek": 43060,
        "start": 436.88,
        "temperature": 0,
        "text": " where I have my.env file, grab this API key, paste it in here,",
        "tokens": [
          50678,
          689,
          286,
          362,
          452,
          2411,
          268,
          85,
          3991,
          11,
          4444,
          341,
          9362,
          2141,
          11,
          9163,
          309,
          294,
          510,
          11,
          50890
        ]
      },
      {
        "avg_logprob": -0.21582225629478502,
        "compression_ratio": 1.848605577689243,
        "end": 442.20000000000005,
        "id": 203,
        "no_speech_prob": 0.00007254295633174479,
        "seek": 43060,
        "start": 441.12,
        "temperature": 0,
        "text": " hit Save.",
        "tokens": [
          50890,
          2045,
          15541,
          13,
          50944
        ]
      },
      {
        "avg_logprob": -0.21582225629478502,
        "compression_ratio": 1.848605577689243,
        "end": 445.16,
        "id": 204,
        "no_speech_prob": 0.00007254295633174479,
        "seek": 43060,
        "start": 442.20000000000005,
        "temperature": 0,
        "text": " And then I'm going to click on this Show button.",
        "tokens": [
          50944,
          400,
          550,
          286,
          478,
          516,
          281,
          2052,
          322,
          341,
          6895,
          2960,
          13,
          51092
        ]
      },
      {
        "avg_logprob": -0.21582225629478502,
        "compression_ratio": 1.848605577689243,
        "end": 447.24,
        "id": 205,
        "no_speech_prob": 0.00007254295633174479,
        "seek": 43060,
        "start": 445.16,
        "temperature": 0,
        "text": " And so now I can choose to show in a new window",
        "tokens": [
          51092,
          400,
          370,
          586,
          286,
          393,
          2826,
          281,
          855,
          294,
          257,
          777,
          4910,
          51196
        ]
      },
      {
        "avg_logprob": -0.21582225629478502,
        "compression_ratio": 1.848605577689243,
        "end": 448.12,
        "id": 206,
        "no_speech_prob": 0.00007254295633174479,
        "seek": 43060,
        "start": 447.24,
        "temperature": 0,
        "text": " or right next to the code.",
        "tokens": [
          51196,
          420,
          558,
          958,
          281,
          264,
          3089,
          13,
          51240
        ]
      },
      {
        "avg_logprob": -0.21582225629478502,
        "compression_ratio": 1.848605577689243,
        "end": 450.52000000000004,
        "id": 207,
        "no_speech_prob": 0.00007254295633174479,
        "seek": 43060,
        "start": 448.12,
        "temperature": 0,
        "text": " Let's just look at it right next to the code.",
        "tokens": [
          51240,
          961,
          311,
          445,
          574,
          412,
          309,
          558,
          958,
          281,
          264,
          3089,
          13,
          51360
        ]
      },
      {
        "avg_logprob": -0.21582225629478502,
        "compression_ratio": 1.848605577689243,
        "end": 451.12,
        "id": 208,
        "no_speech_prob": 0.00007254295633174479,
        "seek": 43060,
        "start": 450.52000000000004,
        "temperature": 0,
        "text": " There it is.",
        "tokens": [
          51360,
          821,
          309,
          307,
          13,
          51390
        ]
      },
      {
        "avg_logprob": -0.21582225629478502,
        "compression_ratio": 1.848605577689243,
        "end": 453.40000000000003,
        "id": 209,
        "no_speech_prob": 0.00007254295633174479,
        "seek": 43060,
        "start": 451.12,
        "temperature": 0,
        "text": " There's my project.",
        "tokens": [
          51390,
          821,
          311,
          452,
          1716,
          13,
          51504
        ]
      },
      {
        "avg_logprob": -0.21582225629478502,
        "compression_ratio": 1.848605577689243,
        "end": 456,
        "id": 210,
        "no_speech_prob": 0.00007254295633174479,
        "seek": 43060,
        "start": 453.40000000000003,
        "temperature": 0,
        "text": " Now let's click on Show and go in a new window.",
        "tokens": [
          51504,
          823,
          718,
          311,
          2052,
          322,
          6895,
          293,
          352,
          294,
          257,
          777,
          4910,
          13,
          51634
        ]
      },
      {
        "avg_logprob": -0.21582225629478502,
        "compression_ratio": 1.848605577689243,
        "end": 457.32000000000005,
        "id": 211,
        "no_speech_prob": 0.00007254295633174479,
        "seek": 43060,
        "start": 456,
        "temperature": 0,
        "text": " And look at this.",
        "tokens": [
          51634,
          400,
          574,
          412,
          341,
          13,
          51700
        ]
      },
      {
        "avg_logprob": -0.20753935363395082,
        "compression_ratio": 1.88715953307393,
        "end": 461.92,
        "id": 212,
        "no_speech_prob": 0.006487955339252949,
        "seek": 45732,
        "start": 457.32,
        "temperature": 0,
        "text": " If you go to coding-the-weather-here.glitch.me,",
        "tokens": [
          50364,
          759,
          291,
          352,
          281,
          17720,
          12,
          3322,
          12,
          826,
          1172,
          12,
          6703,
          13,
          7191,
          1549,
          13,
          1398,
          11,
          50594
        ]
      },
      {
        "avg_logprob": -0.20753935363395082,
        "compression_ratio": 1.88715953307393,
        "end": 463.32,
        "id": 213,
        "no_speech_prob": 0.006487955339252949,
        "seek": 45732,
        "start": 461.92,
        "temperature": 0,
        "text": " you have the project.",
        "tokens": [
          50594,
          291,
          362,
          264,
          1716,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20753935363395082,
        "compression_ratio": 1.88715953307393,
        "end": 465.44,
        "id": 214,
        "no_speech_prob": 0.006487955339252949,
        "seek": 45732,
        "start": 463.32,
        "temperature": 0,
        "text": " And I can go back here.",
        "tokens": [
          50664,
          400,
          286,
          393,
          352,
          646,
          510,
          13,
          50770
        ]
      },
      {
        "avg_logprob": -0.20753935363395082,
        "compression_ratio": 1.88715953307393,
        "end": 468.44,
        "id": 215,
        "no_speech_prob": 0.006487955339252949,
        "seek": 45732,
        "start": 465.44,
        "temperature": 0,
        "text": " And I can start saying, hey, let's go to Berlin and check",
        "tokens": [
          50770,
          400,
          286,
          393,
          722,
          1566,
          11,
          4177,
          11,
          718,
          311,
          352,
          281,
          13848,
          293,
          1520,
          50920
        ]
      },
      {
        "avg_logprob": -0.20753935363395082,
        "compression_ratio": 1.88715953307393,
        "end": 469.08,
        "id": 216,
        "no_speech_prob": 0.006487955339252949,
        "seek": 45732,
        "start": 468.44,
        "temperature": 0,
        "text": " in.",
        "tokens": [
          50920,
          294,
          13,
          50952
        ]
      },
      {
        "avg_logprob": -0.20753935363395082,
        "compression_ratio": 1.88715953307393,
        "end": 471.6,
        "id": 217,
        "no_speech_prob": 0.006487955339252949,
        "seek": 45732,
        "start": 469.08,
        "temperature": 0,
        "text": " And let's go to London and check in.",
        "tokens": [
          50952,
          400,
          718,
          311,
          352,
          281,
          7042,
          293,
          1520,
          294,
          13,
          51078
        ]
      },
      {
        "avg_logprob": -0.20753935363395082,
        "compression_ratio": 1.88715953307393,
        "end": 474.32,
        "id": 218,
        "no_speech_prob": 0.006487955339252949,
        "seek": 45732,
        "start": 471.6,
        "temperature": 0,
        "text": " Let's go to San Francisco and check in.",
        "tokens": [
          51078,
          961,
          311,
          352,
          281,
          5271,
          12279,
          293,
          1520,
          294,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20753935363395082,
        "compression_ratio": 1.88715953307393,
        "end": 475.52,
        "id": 219,
        "no_speech_prob": 0.006487955339252949,
        "seek": 45732,
        "start": 474.32,
        "temperature": 0,
        "text": " Let's view check-ins.",
        "tokens": [
          51214,
          961,
          311,
          1910,
          1520,
          12,
          1292,
          13,
          51274
        ]
      },
      {
        "avg_logprob": -0.20753935363395082,
        "compression_ratio": 1.88715953307393,
        "end": 477.68,
        "id": 220,
        "no_speech_prob": 0.006487955339252949,
        "seek": 45732,
        "start": 475.52,
        "temperature": 0,
        "text": " And all of those check-ins are here.",
        "tokens": [
          51274,
          400,
          439,
          295,
          729,
          1520,
          12,
          1292,
          366,
          510,
          13,
          51382
        ]
      },
      {
        "avg_logprob": -0.20753935363395082,
        "compression_ratio": 1.88715953307393,
        "end": 479.8,
        "id": 221,
        "no_speech_prob": 0.006487955339252949,
        "seek": 45732,
        "start": 477.68,
        "temperature": 0,
        "text": " And in fact, I don't know what this",
        "tokens": [
          51382,
          400,
          294,
          1186,
          11,
          286,
          500,
          380,
          458,
          437,
          341,
          51488
        ]
      },
      {
        "avg_logprob": -0.20753935363395082,
        "compression_ratio": 1.88715953307393,
        "end": 481.6,
        "id": 222,
        "no_speech_prob": 0.006487955339252949,
        "seek": 45732,
        "start": 479.8,
        "temperature": 0,
        "text": " is going to look like now when you go to it.",
        "tokens": [
          51488,
          307,
          516,
          281,
          574,
          411,
          586,
          562,
          291,
          352,
          281,
          309,
          13,
          51578
        ]
      },
      {
        "avg_logprob": -0.20753935363395082,
        "compression_ratio": 1.88715953307393,
        "end": 483.42,
        "id": 223,
        "no_speech_prob": 0.006487955339252949,
        "seek": 45732,
        "start": 481.6,
        "temperature": 0,
        "text": " I assume I'm going to leave this here as is.",
        "tokens": [
          51578,
          286,
          6552,
          286,
          478,
          516,
          281,
          1856,
          341,
          510,
          382,
          307,
          13,
          51669
        ]
      },
      {
        "avg_logprob": -0.20753935363395082,
        "compression_ratio": 1.88715953307393,
        "end": 485.08,
        "id": 224,
        "no_speech_prob": 0.006487955339252949,
        "seek": 45732,
        "start": 483.42,
        "temperature": 0,
        "text": " And lots of other people have gone there",
        "tokens": [
          51669,
          400,
          3195,
          295,
          661,
          561,
          362,
          2780,
          456,
          51752
        ]
      },
      {
        "avg_logprob": -0.20753935363395082,
        "compression_ratio": 1.88715953307393,
        "end": 486.28,
        "id": 225,
        "no_speech_prob": 0.006487955339252949,
        "seek": 45732,
        "start": 485.08,
        "temperature": 0,
        "text": " and added their check-ins.",
        "tokens": [
          51752,
          293,
          3869,
          641,
          1520,
          12,
          1292,
          13,
          51812
        ]
      },
      {
        "avg_logprob": -0.21971636642644435,
        "compression_ratio": 1.9,
        "end": 487.76,
        "id": 226,
        "no_speech_prob": 0.0006666927365586162,
        "seek": 48628,
        "start": 486.28,
        "temperature": 0,
        "text": " So we can see all of that.",
        "tokens": [
          50364,
          407,
          321,
          393,
          536,
          439,
          295,
          300,
          13,
          50438
        ]
      },
      {
        "avg_logprob": -0.21971636642644435,
        "compression_ratio": 1.9,
        "end": 490.15999999999997,
        "id": 227,
        "no_speech_prob": 0.0006666927365586162,
        "seek": 48628,
        "start": 487.76,
        "temperature": 0,
        "text": " And you'll see that if you go to that URL right now.",
        "tokens": [
          50438,
          400,
          291,
          603,
          536,
          300,
          498,
          291,
          352,
          281,
          300,
          12905,
          558,
          586,
          13,
          50558
        ]
      },
      {
        "avg_logprob": -0.21971636642644435,
        "compression_ratio": 1.9,
        "end": 493.52,
        "id": 228,
        "no_speech_prob": 0.0006666927365586162,
        "seek": 48628,
        "start": 490.15999999999997,
        "temperature": 0,
        "text": " And to be clear, remember, this is a code editor.",
        "tokens": [
          50558,
          400,
          281,
          312,
          1850,
          11,
          1604,
          11,
          341,
          307,
          257,
          3089,
          9839,
          13,
          50726
        ]
      },
      {
        "avg_logprob": -0.21971636642644435,
        "compression_ratio": 1.9,
        "end": 495.23999999999995,
        "id": 229,
        "no_speech_prob": 0.0006666927365586162,
        "seek": 48628,
        "start": 493.52,
        "temperature": 0,
        "text": " So I can start changing stuff.",
        "tokens": [
          50726,
          407,
          286,
          393,
          722,
          4473,
          1507,
          13,
          50812
        ]
      },
      {
        "avg_logprob": -0.21971636642644435,
        "compression_ratio": 1.9,
        "end": 497.4,
        "id": 230,
        "no_speech_prob": 0.0006666927365586162,
        "seek": 48628,
        "start": 495.23999999999995,
        "temperature": 0,
        "text": " I can go to this index.html page.",
        "tokens": [
          50812,
          286,
          393,
          352,
          281,
          341,
          8186,
          13,
          357,
          15480,
          3028,
          13,
          50920
        ]
      },
      {
        "avg_logprob": -0.21971636642644435,
        "compression_ratio": 1.9,
        "end": 500.55999999999995,
        "id": 231,
        "no_speech_prob": 0.0006666927365586162,
        "seek": 48628,
        "start": 497.4,
        "temperature": 0,
        "text": " And I can say the weather is here.",
        "tokens": [
          50920,
          400,
          286,
          393,
          584,
          264,
          5503,
          307,
          510,
          13,
          51078
        ]
      },
      {
        "avg_logprob": -0.21971636642644435,
        "compression_ratio": 1.9,
        "end": 502.67999999999995,
        "id": 232,
        "no_speech_prob": 0.0006666927365586162,
        "seek": 48628,
        "start": 500.55999999999995,
        "temperature": 0,
        "text": " And you can see that immediately updated.",
        "tokens": [
          51078,
          400,
          291,
          393,
          536,
          300,
          4258,
          10588,
          13,
          51184
        ]
      },
      {
        "avg_logprob": -0.21971636642644435,
        "compression_ratio": 1.9,
        "end": 504.35999999999996,
        "id": 233,
        "no_speech_prob": 0.0006666927365586162,
        "seek": 48628,
        "start": 502.67999999999995,
        "temperature": 0,
        "text": " I can change something in the server.",
        "tokens": [
          51184,
          286,
          393,
          1319,
          746,
          294,
          264,
          7154,
          13,
          51268
        ]
      },
      {
        "avg_logprob": -0.21971636642644435,
        "compression_ratio": 1.9,
        "end": 505.67999999999995,
        "id": 234,
        "no_speech_prob": 0.0006666927365586162,
        "seek": 48628,
        "start": 504.35999999999996,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          51268,
          286,
          500,
          380,
          458,
          13,
          51334
        ]
      },
      {
        "avg_logprob": -0.21971636642644435,
        "compression_ratio": 1.9,
        "end": 507.08,
        "id": 235,
        "no_speech_prob": 0.0006666927365586162,
        "seek": 48628,
        "start": 505.67999999999995,
        "temperature": 0,
        "text": " I'm afraid to change things in the server.",
        "tokens": [
          51334,
          286,
          478,
          4638,
          281,
          1319,
          721,
          294,
          264,
          7154,
          13,
          51404
        ]
      },
      {
        "avg_logprob": -0.21971636642644435,
        "compression_ratio": 1.9,
        "end": 508.59999999999997,
        "id": 236,
        "no_speech_prob": 0.0006666927365586162,
        "seek": 48628,
        "start": 507.08,
        "temperature": 0,
        "text": " But I can start working on the server code.",
        "tokens": [
          51404,
          583,
          286,
          393,
          722,
          1364,
          322,
          264,
          7154,
          3089,
          13,
          51480
        ]
      },
      {
        "avg_logprob": -0.21971636642644435,
        "compression_ratio": 1.9,
        "end": 510,
        "id": 237,
        "no_speech_prob": 0.0006666927365586162,
        "seek": 48628,
        "start": 508.59999999999997,
        "temperature": 0,
        "text": " It's all very, very small here.",
        "tokens": [
          51480,
          467,
          311,
          439,
          588,
          11,
          588,
          1359,
          510,
          13,
          51550
        ]
      },
      {
        "avg_logprob": -0.21971636642644435,
        "compression_ratio": 1.9,
        "end": 511.52,
        "id": 238,
        "no_speech_prob": 0.0006666927365586162,
        "seek": 48628,
        "start": 510,
        "temperature": 0,
        "text": " I could change that.",
        "tokens": [
          51550,
          286,
          727,
          1319,
          300,
          13,
          51626
        ]
      },
      {
        "avg_logprob": -0.21971636642644435,
        "compression_ratio": 1.9,
        "end": 512.88,
        "id": 239,
        "no_speech_prob": 0.0006666927365586162,
        "seek": 48628,
        "start": 511.52,
        "temperature": 0,
        "text": " And stuff would change.",
        "tokens": [
          51626,
          400,
          1507,
          576,
          1319,
          13,
          51694
        ]
      },
      {
        "avg_logprob": -0.21971636642644435,
        "compression_ratio": 1.9,
        "end": 514.76,
        "id": 240,
        "no_speech_prob": 0.0006666927365586162,
        "seek": 48628,
        "start": 512.88,
        "temperature": 0,
        "text": " The server would rerun itself automatically.",
        "tokens": [
          51694,
          440,
          7154,
          576,
          43819,
          409,
          2564,
          6772,
          13,
          51788
        ]
      },
      {
        "avg_logprob": -0.2447322153905679,
        "compression_ratio": 1.6788732394366197,
        "end": 517.2,
        "id": 241,
        "no_speech_prob": 0.004331331234425306,
        "seek": 51476,
        "start": 514.76,
        "temperature": 0,
        "text": " So again, I would love to come back and revisit more videos",
        "tokens": [
          50364,
          407,
          797,
          11,
          286,
          576,
          959,
          281,
          808,
          646,
          293,
          32676,
          544,
          2145,
          50486
        ]
      },
      {
        "avg_logprob": -0.2447322153905679,
        "compression_ratio": 1.6788732394366197,
        "end": 518.92,
        "id": 242,
        "no_speech_prob": 0.004331331234425306,
        "seek": 51476,
        "start": 517.2,
        "temperature": 0,
        "text": " about how Glitch works itself.",
        "tokens": [
          50486,
          466,
          577,
          5209,
          1549,
          1985,
          2564,
          13,
          50572
        ]
      },
      {
        "avg_logprob": -0.2447322153905679,
        "compression_ratio": 1.6788732394366197,
        "end": 521.36,
        "id": 243,
        "no_speech_prob": 0.004331331234425306,
        "seek": 51476,
        "start": 518.92,
        "temperature": 0,
        "text": " Now that this project is there, I",
        "tokens": [
          50572,
          823,
          300,
          341,
          1716,
          307,
          456,
          11,
          286,
          50694
        ]
      },
      {
        "avg_logprob": -0.2447322153905679,
        "compression_ratio": 1.6788732394366197,
        "end": 522.88,
        "id": 244,
        "no_speech_prob": 0.004331331234425306,
        "seek": 51476,
        "start": 521.36,
        "temperature": 0,
        "text": " would encourage you to go to the URL.",
        "tokens": [
          50694,
          576,
          5373,
          291,
          281,
          352,
          281,
          264,
          12905,
          13,
          50770
        ]
      },
      {
        "avg_logprob": -0.2447322153905679,
        "compression_ratio": 1.6788732394366197,
        "end": 524.34,
        "id": 245,
        "no_speech_prob": 0.004331331234425306,
        "seek": 51476,
        "start": 522.88,
        "temperature": 0,
        "text": " It'll be in the video's description",
        "tokens": [
          50770,
          467,
          603,
          312,
          294,
          264,
          960,
          311,
          3855,
          50843
        ]
      },
      {
        "avg_logprob": -0.2447322153905679,
        "compression_ratio": 1.6788732394366197,
        "end": 525.68,
        "id": 246,
        "no_speech_prob": 0.004331331234425306,
        "seek": 51476,
        "start": 524.34,
        "temperature": 0,
        "text": " and click Remix Project.",
        "tokens": [
          50843,
          293,
          2052,
          4080,
          970,
          9849,
          13,
          50910
        ]
      },
      {
        "avg_logprob": -0.2447322153905679,
        "compression_ratio": 1.6788732394366197,
        "end": 527.4399999999999,
        "id": 247,
        "no_speech_prob": 0.004331331234425306,
        "seek": 51476,
        "start": 525.68,
        "temperature": 0,
        "text": " You don't even have to do any of this stuff",
        "tokens": [
          50910,
          509,
          500,
          380,
          754,
          362,
          281,
          360,
          604,
          295,
          341,
          1507,
          50998
        ]
      },
      {
        "avg_logprob": -0.2447322153905679,
        "compression_ratio": 1.6788732394366197,
        "end": 529.4399999999999,
        "id": 248,
        "no_speech_prob": 0.004331331234425306,
        "seek": 51476,
        "start": 527.4399999999999,
        "temperature": 0,
        "text": " because once I have it deployed on Glitch,",
        "tokens": [
          50998,
          570,
          1564,
          286,
          362,
          309,
          17826,
          322,
          5209,
          1549,
          11,
          51098
        ]
      },
      {
        "avg_logprob": -0.2447322153905679,
        "compression_ratio": 1.6788732394366197,
        "end": 531.3199999999999,
        "id": 249,
        "no_speech_prob": 0.004331331234425306,
        "seek": 51476,
        "start": 529.4399999999999,
        "temperature": 0,
        "text": " other people can get the code and make",
        "tokens": [
          51098,
          661,
          561,
          393,
          483,
          264,
          3089,
          293,
          652,
          51192
        ]
      },
      {
        "avg_logprob": -0.2447322153905679,
        "compression_ratio": 1.6788732394366197,
        "end": 532.36,
        "id": 250,
        "no_speech_prob": 0.004331331234425306,
        "seek": 51476,
        "start": 531.3199999999999,
        "temperature": 0,
        "text": " their own version of it.",
        "tokens": [
          51192,
          641,
          1065,
          3037,
          295,
          309,
          13,
          51244
        ]
      },
      {
        "avg_logprob": -0.2447322153905679,
        "compression_ratio": 1.6788732394366197,
        "end": 534.84,
        "id": 251,
        "no_speech_prob": 0.004331331234425306,
        "seek": 51476,
        "start": 532.36,
        "temperature": 0,
        "text": " So I'll include this as an example",
        "tokens": [
          51244,
          407,
          286,
          603,
          4090,
          341,
          382,
          364,
          1365,
          51368
        ]
      },
      {
        "avg_logprob": -0.2447322153905679,
        "compression_ratio": 1.6788732394366197,
        "end": 535.84,
        "id": 252,
        "no_speech_prob": 0.004331331234425306,
        "seek": 51476,
        "start": 534.84,
        "temperature": 0,
        "text": " that you can start with.",
        "tokens": [
          51368,
          300,
          291,
          393,
          722,
          365,
          13,
          51418
        ]
      },
      {
        "avg_logprob": -0.2447322153905679,
        "compression_ratio": 1.6788732394366197,
        "end": 537.4399999999999,
        "id": 253,
        "no_speech_prob": 0.004331331234425306,
        "seek": 51476,
        "start": 535.84,
        "temperature": 0,
        "text": " And I probably shouldn't mention that.",
        "tokens": [
          51418,
          400,
          286,
          1391,
          4659,
          380,
          2152,
          300,
          13,
          51498
        ]
      },
      {
        "avg_logprob": -0.2447322153905679,
        "compression_ratio": 1.6788732394366197,
        "end": 538.96,
        "id": 254,
        "no_speech_prob": 0.004331331234425306,
        "seek": 51476,
        "start": 537.4399999999999,
        "temperature": 0,
        "text": " I should have mentioned that earlier.",
        "tokens": [
          51498,
          286,
          820,
          362,
          2835,
          300,
          3071,
          13,
          51574
        ]
      },
      {
        "avg_logprob": -0.2447322153905679,
        "compression_ratio": 1.6788732394366197,
        "end": 539.48,
        "id": 255,
        "no_speech_prob": 0.004331331234425306,
        "seek": 51476,
        "start": 538.96,
        "temperature": 0,
        "text": " Oh, well.",
        "tokens": [
          51574,
          876,
          11,
          731,
          13,
          51600
        ]
      },
      {
        "avg_logprob": -0.2447322153905679,
        "compression_ratio": 1.6788732394366197,
        "end": 541.12,
        "id": 256,
        "no_speech_prob": 0.004331331234425306,
        "seek": 51476,
        "start": 539.48,
        "temperature": 0,
        "text": " Let's try one more deployment just",
        "tokens": [
          51600,
          961,
          311,
          853,
          472,
          544,
          19317,
          445,
          51682
        ]
      },
      {
        "avg_logprob": -0.2447322153905679,
        "compression_ratio": 1.6788732394366197,
        "end": 543.28,
        "id": 257,
        "no_speech_prob": 0.004331331234425306,
        "seek": 51476,
        "start": 541.12,
        "temperature": 0,
        "text": " so we can see how another system works.",
        "tokens": [
          51682,
          370,
          321,
          393,
          536,
          577,
          1071,
          1185,
          1985,
          13,
          51790
        ]
      },
      {
        "avg_logprob": -0.220605960969002,
        "compression_ratio": 1.7603833865814698,
        "end": 545.0799999999999,
        "id": 258,
        "no_speech_prob": 0.0023594913072884083,
        "seek": 54328,
        "start": 543.28,
        "temperature": 0,
        "text": " So now I'm going to show you Heroku.",
        "tokens": [
          50364,
          407,
          586,
          286,
          478,
          516,
          281,
          855,
          291,
          3204,
          13275,
          13,
          50454
        ]
      },
      {
        "avg_logprob": -0.220605960969002,
        "compression_ratio": 1.7603833865814698,
        "end": 548.56,
        "id": 259,
        "no_speech_prob": 0.0023594913072884083,
        "seek": 54328,
        "start": 545.0799999999999,
        "temperature": 0,
        "text": " Heroku has its own CLI, which stands for Command Line",
        "tokens": [
          50454,
          3204,
          13275,
          575,
          1080,
          1065,
          12855,
          40,
          11,
          597,
          7382,
          337,
          17901,
          14670,
          50628
        ]
      },
      {
        "avg_logprob": -0.220605960969002,
        "compression_ratio": 1.7603833865814698,
        "end": 549.36,
        "id": 260,
        "no_speech_prob": 0.0023594913072884083,
        "seek": 54328,
        "start": 548.56,
        "temperature": 0,
        "text": " Interface.",
        "tokens": [
          50628,
          5751,
          2868,
          13,
          50668
        ]
      },
      {
        "avg_logprob": -0.220605960969002,
        "compression_ratio": 1.7603833865814698,
        "end": 552.48,
        "id": 261,
        "no_speech_prob": 0.0023594913072884083,
        "seek": 54328,
        "start": 549.36,
        "temperature": 0,
        "text": " So you can actually do things and deploy projects just",
        "tokens": [
          50668,
          407,
          291,
          393,
          767,
          360,
          721,
          293,
          7274,
          4455,
          445,
          50824
        ]
      },
      {
        "avg_logprob": -0.220605960969002,
        "compression_ratio": 1.7603833865814698,
        "end": 555.1999999999999,
        "id": 262,
        "no_speech_prob": 0.0023594913072884083,
        "seek": 54328,
        "start": 552.48,
        "temperature": 0,
        "text": " from your terminal application itself.",
        "tokens": [
          50824,
          490,
          428,
          14709,
          3861,
          2564,
          13,
          50960
        ]
      },
      {
        "avg_logprob": -0.220605960969002,
        "compression_ratio": 1.7603833865814698,
        "end": 558.92,
        "id": 263,
        "no_speech_prob": 0.0023594913072884083,
        "seek": 54328,
        "start": 555.1999999999999,
        "temperature": 0,
        "text": " So you're going to need to first install the Heroku CLI.",
        "tokens": [
          50960,
          407,
          291,
          434,
          516,
          281,
          643,
          281,
          700,
          3625,
          264,
          3204,
          13275,
          12855,
          40,
          13,
          51146
        ]
      },
      {
        "avg_logprob": -0.220605960969002,
        "compression_ratio": 1.7603833865814698,
        "end": 559.92,
        "id": 264,
        "no_speech_prob": 0.0023594913072884083,
        "seek": 54328,
        "start": 558.92,
        "temperature": 0,
        "text": " I've done that already.",
        "tokens": [
          51146,
          286,
          600,
          1096,
          300,
          1217,
          13,
          51196
        ]
      },
      {
        "avg_logprob": -0.220605960969002,
        "compression_ratio": 1.7603833865814698,
        "end": 561.72,
        "id": 265,
        "no_speech_prob": 0.0023594913072884083,
        "seek": 54328,
        "start": 559.92,
        "temperature": 0,
        "text": " But you can download and install for Mac OS.",
        "tokens": [
          51196,
          583,
          291,
          393,
          5484,
          293,
          3625,
          337,
          5707,
          12731,
          13,
          51286
        ]
      },
      {
        "avg_logprob": -0.220605960969002,
        "compression_ratio": 1.7603833865814698,
        "end": 563.64,
        "id": 266,
        "no_speech_prob": 0.0023594913072884083,
        "seek": 54328,
        "start": 561.72,
        "temperature": 0,
        "text": " Or you can download and install for Windows or Ubuntu,",
        "tokens": [
          51286,
          1610,
          291,
          393,
          5484,
          293,
          3625,
          337,
          8591,
          420,
          30230,
          45605,
          11,
          51382
        ]
      },
      {
        "avg_logprob": -0.220605960969002,
        "compression_ratio": 1.7603833865814698,
        "end": 565.3199999999999,
        "id": 267,
        "no_speech_prob": 0.0023594913072884083,
        "seek": 54328,
        "start": 563.64,
        "temperature": 0,
        "text": " whatever your operating system is.",
        "tokens": [
          51382,
          2035,
          428,
          7447,
          1185,
          307,
          13,
          51466
        ]
      },
      {
        "avg_logprob": -0.220605960969002,
        "compression_ratio": 1.7603833865814698,
        "end": 567.36,
        "id": 268,
        "no_speech_prob": 0.0023594913072884083,
        "seek": 54328,
        "start": 565.3199999999999,
        "temperature": 0,
        "text": " You'll know that you have the CLI installed",
        "tokens": [
          51466,
          509,
          603,
          458,
          300,
          291,
          362,
          264,
          12855,
          40,
          8899,
          51568
        ]
      },
      {
        "avg_logprob": -0.220605960969002,
        "compression_ratio": 1.7603833865814698,
        "end": 569.1999999999999,
        "id": 269,
        "no_speech_prob": 0.0023594913072884083,
        "seek": 54328,
        "start": 567.36,
        "temperature": 0,
        "text": " if you can type Heroku into the command line",
        "tokens": [
          51568,
          498,
          291,
          393,
          2010,
          3204,
          13275,
          666,
          264,
          5622,
          1622,
          51660
        ]
      },
      {
        "avg_logprob": -0.220605960969002,
        "compression_ratio": 1.7603833865814698,
        "end": 571.3199999999999,
        "id": 270,
        "no_speech_prob": 0.0023594913072884083,
        "seek": 54328,
        "start": 569.1999999999999,
        "temperature": 0,
        "text": " and see it doesn't say, I don't know what that is.",
        "tokens": [
          51660,
          293,
          536,
          309,
          1177,
          380,
          584,
          11,
          286,
          500,
          380,
          458,
          437,
          300,
          307,
          13,
          51766
        ]
      },
      {
        "avg_logprob": -0.20917596528024385,
        "compression_ratio": 1.8373702422145328,
        "end": 574.1600000000001,
        "id": 271,
        "no_speech_prob": 0.00000268416192739096,
        "seek": 57132,
        "start": 571.32,
        "temperature": 0,
        "text": " So one of the things I want to do is type in Heroku login.",
        "tokens": [
          50364,
          407,
          472,
          295,
          264,
          721,
          286,
          528,
          281,
          360,
          307,
          2010,
          294,
          3204,
          13275,
          24276,
          13,
          50506
        ]
      },
      {
        "avg_logprob": -0.20917596528024385,
        "compression_ratio": 1.8373702422145328,
        "end": 577,
        "id": 272,
        "no_speech_prob": 0.00000268416192739096,
        "seek": 57132,
        "start": 574.1600000000001,
        "temperature": 0,
        "text": " So I've already signed up for a Heroku account.",
        "tokens": [
          50506,
          407,
          286,
          600,
          1217,
          8175,
          493,
          337,
          257,
          3204,
          13275,
          2696,
          13,
          50648
        ]
      },
      {
        "avg_logprob": -0.20917596528024385,
        "compression_ratio": 1.8373702422145328,
        "end": 579.7,
        "id": 273,
        "no_speech_prob": 0.00000268416192739096,
        "seek": 57132,
        "start": 577,
        "temperature": 0,
        "text": " So you'll have to have done that if you're going to follow along",
        "tokens": [
          50648,
          407,
          291,
          603,
          362,
          281,
          362,
          1096,
          300,
          498,
          291,
          434,
          516,
          281,
          1524,
          2051,
          50783
        ]
      },
      {
        "avg_logprob": -0.20917596528024385,
        "compression_ratio": 1.8373702422145328,
        "end": 581.32,
        "id": 274,
        "no_speech_prob": 0.00000268416192739096,
        "seek": 57132,
        "start": 579.7,
        "temperature": 0,
        "text": " with these instructions.",
        "tokens": [
          50783,
          365,
          613,
          9415,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20917596528024385,
        "compression_ratio": 1.8373702422145328,
        "end": 583.9200000000001,
        "id": 275,
        "no_speech_prob": 0.00000268416192739096,
        "seek": 57132,
        "start": 581.32,
        "temperature": 0,
        "text": " It's going to ask me to press any key.",
        "tokens": [
          50864,
          467,
          311,
          516,
          281,
          1029,
          385,
          281,
          1886,
          604,
          2141,
          13,
          50994
        ]
      },
      {
        "avg_logprob": -0.20917596528024385,
        "compression_ratio": 1.8373702422145328,
        "end": 585.36,
        "id": 276,
        "no_speech_prob": 0.00000268416192739096,
        "seek": 57132,
        "start": 583.9200000000001,
        "temperature": 0,
        "text": " It's going to open up the browser.",
        "tokens": [
          50994,
          467,
          311,
          516,
          281,
          1269,
          493,
          264,
          11185,
          13,
          51066
        ]
      },
      {
        "avg_logprob": -0.20917596528024385,
        "compression_ratio": 1.8373702422145328,
        "end": 587.08,
        "id": 277,
        "no_speech_prob": 0.00000268416192739096,
        "seek": 57132,
        "start": 585.36,
        "temperature": 0,
        "text": " It's going to ask me to log in.",
        "tokens": [
          51066,
          467,
          311,
          516,
          281,
          1029,
          385,
          281,
          3565,
          294,
          13,
          51152
        ]
      },
      {
        "avg_logprob": -0.20917596528024385,
        "compression_ratio": 1.8373702422145328,
        "end": 588,
        "id": 278,
        "no_speech_prob": 0.00000268416192739096,
        "seek": 57132,
        "start": 587.08,
        "temperature": 0,
        "text": " I'm already logged in.",
        "tokens": [
          51152,
          286,
          478,
          1217,
          27231,
          294,
          13,
          51198
        ]
      },
      {
        "avg_logprob": -0.20917596528024385,
        "compression_ratio": 1.8373702422145328,
        "end": 589.48,
        "id": 279,
        "no_speech_prob": 0.00000268416192739096,
        "seek": 57132,
        "start": 588,
        "temperature": 0,
        "text": " I've already logged in.",
        "tokens": [
          51198,
          286,
          600,
          1217,
          27231,
          294,
          13,
          51272
        ]
      },
      {
        "avg_logprob": -0.20917596528024385,
        "compression_ratio": 1.8373702422145328,
        "end": 591.0400000000001,
        "id": 280,
        "no_speech_prob": 0.00000268416192739096,
        "seek": 57132,
        "start": 589.48,
        "temperature": 0,
        "text": " We can go back to the terminal.",
        "tokens": [
          51272,
          492,
          393,
          352,
          646,
          281,
          264,
          14709,
          13,
          51350
        ]
      },
      {
        "avg_logprob": -0.20917596528024385,
        "compression_ratio": 1.8373702422145328,
        "end": 593.1600000000001,
        "id": 281,
        "no_speech_prob": 0.00000268416192739096,
        "seek": 57132,
        "start": 591.0400000000001,
        "temperature": 0,
        "text": " And we can see that I've logged in now.",
        "tokens": [
          51350,
          400,
          321,
          393,
          536,
          300,
          286,
          600,
          27231,
          294,
          586,
          13,
          51456
        ]
      },
      {
        "avg_logprob": -0.20917596528024385,
        "compression_ratio": 1.8373702422145328,
        "end": 596.8800000000001,
        "id": 282,
        "no_speech_prob": 0.00000268416192739096,
        "seek": 57132,
        "start": 593.1600000000001,
        "temperature": 0,
        "text": " Once I'm logged in in terminal, I need to create a new app.",
        "tokens": [
          51456,
          3443,
          286,
          478,
          27231,
          294,
          294,
          14709,
          11,
          286,
          643,
          281,
          1884,
          257,
          777,
          724,
          13,
          51642
        ]
      },
      {
        "avg_logprob": -0.20917596528024385,
        "compression_ratio": 1.8373702422145328,
        "end": 599.9200000000001,
        "id": 283,
        "no_speech_prob": 0.00000268416192739096,
        "seek": 57132,
        "start": 596.8800000000001,
        "temperature": 0,
        "text": " So I could go to my Heroku dashboard at this URL.",
        "tokens": [
          51642,
          407,
          286,
          727,
          352,
          281,
          452,
          3204,
          13275,
          18342,
          412,
          341,
          12905,
          13,
          51794
        ]
      },
      {
        "avg_logprob": -0.21537895970696572,
        "compression_ratio": 1.8141263940520447,
        "end": 603.4799999999999,
        "id": 284,
        "no_speech_prob": 0.00005391045124270022,
        "seek": 59992,
        "start": 599.92,
        "temperature": 0,
        "text": " And then I can just click here and say new, create new app.",
        "tokens": [
          50364,
          400,
          550,
          286,
          393,
          445,
          2052,
          510,
          293,
          584,
          777,
          11,
          1884,
          777,
          724,
          13,
          50542
        ]
      },
      {
        "avg_logprob": -0.21537895970696572,
        "compression_ratio": 1.8141263940520447,
        "end": 607.7199999999999,
        "id": 285,
        "no_speech_prob": 0.00005391045124270022,
        "seek": 59992,
        "start": 603.4799999999999,
        "temperature": 0,
        "text": " So I'm going to create an app called the weather here.",
        "tokens": [
          50542,
          407,
          286,
          478,
          516,
          281,
          1884,
          364,
          724,
          1219,
          264,
          5503,
          510,
          13,
          50754
        ]
      },
      {
        "avg_logprob": -0.21537895970696572,
        "compression_ratio": 1.8141263940520447,
        "end": 609.3199999999999,
        "id": 286,
        "no_speech_prob": 0.00005391045124270022,
        "seek": 59992,
        "start": 607.7199999999999,
        "temperature": 0,
        "text": " The weather here is available.",
        "tokens": [
          50754,
          440,
          5503,
          510,
          307,
          2435,
          13,
          50834
        ]
      },
      {
        "avg_logprob": -0.21537895970696572,
        "compression_ratio": 1.8141263940520447,
        "end": 612.28,
        "id": 287,
        "no_speech_prob": 0.00005391045124270022,
        "seek": 59992,
        "start": 609.3199999999999,
        "temperature": 0,
        "text": " I'm going to hit create app.",
        "tokens": [
          50834,
          286,
          478,
          516,
          281,
          2045,
          1884,
          724,
          13,
          50982
        ]
      },
      {
        "avg_logprob": -0.21537895970696572,
        "compression_ratio": 1.8141263940520447,
        "end": 613.28,
        "id": 288,
        "no_speech_prob": 0.00005391045124270022,
        "seek": 59992,
        "start": 612.28,
        "temperature": 0,
        "text": " And then look at this.",
        "tokens": [
          50982,
          400,
          550,
          574,
          412,
          341,
          13,
          51032
        ]
      },
      {
        "avg_logprob": -0.21537895970696572,
        "compression_ratio": 1.8141263940520447,
        "end": 614.4399999999999,
        "id": 289,
        "no_speech_prob": 0.00005391045124270022,
        "seek": 59992,
        "start": 613.28,
        "temperature": 0,
        "text": " This is so perfect.",
        "tokens": [
          51032,
          639,
          307,
          370,
          2176,
          13,
          51090
        ]
      },
      {
        "avg_logprob": -0.21537895970696572,
        "compression_ratio": 1.8141263940520447,
        "end": 616.4799999999999,
        "id": 290,
        "no_speech_prob": 0.00005391045124270022,
        "seek": 59992,
        "start": 614.4399999999999,
        "temperature": 0,
        "text": " It's kind of given me everything I need to do.",
        "tokens": [
          51090,
          467,
          311,
          733,
          295,
          2212,
          385,
          1203,
          286,
          643,
          281,
          360,
          13,
          51192
        ]
      },
      {
        "avg_logprob": -0.21537895970696572,
        "compression_ratio": 1.8141263940520447,
        "end": 619.1999999999999,
        "id": 291,
        "no_speech_prob": 0.00005391045124270022,
        "seek": 59992,
        "start": 616.4799999999999,
        "temperature": 0,
        "text": " I need to do Heroku login, which I've already done.",
        "tokens": [
          51192,
          286,
          643,
          281,
          360,
          3204,
          13275,
          24276,
          11,
          597,
          286,
          600,
          1217,
          1096,
          13,
          51328
        ]
      },
      {
        "avg_logprob": -0.21537895970696572,
        "compression_ratio": 1.8141263940520447,
        "end": 621,
        "id": 292,
        "no_speech_prob": 0.00005391045124270022,
        "seek": 59992,
        "start": 619.1999999999999,
        "temperature": 0,
        "text": " I've already created a Git repository,",
        "tokens": [
          51328,
          286,
          600,
          1217,
          2942,
          257,
          16939,
          25841,
          11,
          51418
        ]
      },
      {
        "avg_logprob": -0.21537895970696572,
        "compression_ratio": 1.8141263940520447,
        "end": 622.9599999999999,
        "id": 293,
        "no_speech_prob": 0.00005391045124270022,
        "seek": 59992,
        "start": 621,
        "temperature": 0,
        "text": " so I don't need to worry about any of this.",
        "tokens": [
          51418,
          370,
          286,
          500,
          380,
          643,
          281,
          3292,
          466,
          604,
          295,
          341,
          13,
          51516
        ]
      },
      {
        "avg_logprob": -0.21537895970696572,
        "compression_ratio": 1.8141263940520447,
        "end": 627.56,
        "id": 294,
        "no_speech_prob": 0.00005391045124270022,
        "seek": 59992,
        "start": 622.9599999999999,
        "temperature": 0,
        "text": " But now I just need to add Heroku as a remote.",
        "tokens": [
          51516,
          583,
          586,
          286,
          445,
          643,
          281,
          909,
          3204,
          13275,
          382,
          257,
          8607,
          13,
          51746
        ]
      },
      {
        "avg_logprob": -0.21537895970696572,
        "compression_ratio": 1.8141263940520447,
        "end": 629.24,
        "id": 295,
        "no_speech_prob": 0.00005391045124270022,
        "seek": 59992,
        "start": 627.56,
        "temperature": 0,
        "text": " So I'm going to go back to terminal here.",
        "tokens": [
          51746,
          407,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          14709,
          510,
          13,
          51830
        ]
      },
      {
        "avg_logprob": -0.24985133131889448,
        "compression_ratio": 1.9273504273504274,
        "end": 631.2,
        "id": 296,
        "no_speech_prob": 0.0006878343410789967,
        "seek": 62924,
        "start": 629.28,
        "temperature": 0,
        "text": " I'm going to say git remote.",
        "tokens": [
          50366,
          286,
          478,
          516,
          281,
          584,
          18331,
          8607,
          13,
          50462
        ]
      },
      {
        "avg_logprob": -0.24985133131889448,
        "compression_ratio": 1.9273504273504274,
        "end": 632.84,
        "id": 297,
        "no_speech_prob": 0.0006878343410789967,
        "seek": 62924,
        "start": 631.2,
        "temperature": 0,
        "text": " I'm going to say git remote dash v.",
        "tokens": [
          50462,
          286,
          478,
          516,
          281,
          584,
          18331,
          8607,
          8240,
          371,
          13,
          50544
        ]
      },
      {
        "avg_logprob": -0.24985133131889448,
        "compression_ratio": 1.9273504273504274,
        "end": 635.36,
        "id": 298,
        "no_speech_prob": 0.0006878343410789967,
        "seek": 62924,
        "start": 632.84,
        "temperature": 0,
        "text": " So this is listing me the current remotes.",
        "tokens": [
          50544,
          407,
          341,
          307,
          22161,
          385,
          264,
          2190,
          890,
          17251,
          13,
          50670
        ]
      },
      {
        "avg_logprob": -0.24985133131889448,
        "compression_ratio": 1.9273504273504274,
        "end": 637.6800000000001,
        "id": 299,
        "no_speech_prob": 0.0006878343410789967,
        "seek": 62924,
        "start": 635.36,
        "temperature": 0,
        "text": " And the only current remote is called origin.",
        "tokens": [
          50670,
          400,
          264,
          787,
          2190,
          8607,
          307,
          1219,
          4957,
          13,
          50786
        ]
      },
      {
        "avg_logprob": -0.24985133131889448,
        "compression_ratio": 1.9273504273504274,
        "end": 639.44,
        "id": 300,
        "no_speech_prob": 0.0006878343410789967,
        "seek": 62924,
        "start": 637.6800000000001,
        "temperature": 0,
        "text": " And it's at github.com.",
        "tokens": [
          50786,
          400,
          309,
          311,
          412,
          290,
          355,
          836,
          13,
          1112,
          13,
          50874
        ]
      },
      {
        "avg_logprob": -0.24985133131889448,
        "compression_ratio": 1.9273504273504274,
        "end": 642.32,
        "id": 301,
        "no_speech_prob": 0.0006878343410789967,
        "seek": 62924,
        "start": 639.44,
        "temperature": 0,
        "text": " I want to add another remote by copying and pasting",
        "tokens": [
          50874,
          286,
          528,
          281,
          909,
          1071,
          8607,
          538,
          27976,
          293,
          1791,
          278,
          51018
        ]
      },
      {
        "avg_logprob": -0.24985133131889448,
        "compression_ratio": 1.9273504273504274,
        "end": 644.24,
        "id": 302,
        "no_speech_prob": 0.0006878343410789967,
        "seek": 62924,
        "start": 642.32,
        "temperature": 0,
        "text": " this command right here.",
        "tokens": [
          51018,
          341,
          5622,
          558,
          510,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.24985133131889448,
        "compression_ratio": 1.9273504273504274,
        "end": 646.84,
        "id": 303,
        "no_speech_prob": 0.0006878343410789967,
        "seek": 62924,
        "start": 644.24,
        "temperature": 0,
        "text": " I'm going to paste that in.",
        "tokens": [
          51114,
          286,
          478,
          516,
          281,
          9163,
          300,
          294,
          13,
          51244
        ]
      },
      {
        "avg_logprob": -0.24985133131889448,
        "compression_ratio": 1.9273504273504274,
        "end": 648,
        "id": 304,
        "no_speech_prob": 0.0006878343410789967,
        "seek": 62924,
        "start": 646.84,
        "temperature": 0,
        "text": " OK, I've got another remote.",
        "tokens": [
          51244,
          2264,
          11,
          286,
          600,
          658,
          1071,
          8607,
          13,
          51302
        ]
      },
      {
        "avg_logprob": -0.24985133131889448,
        "compression_ratio": 1.9273504273504274,
        "end": 650.88,
        "id": 305,
        "no_speech_prob": 0.0006878343410789967,
        "seek": 62924,
        "start": 648,
        "temperature": 0,
        "text": " If I say git remote dash v, we can see, aha,",
        "tokens": [
          51302,
          759,
          286,
          584,
          18331,
          8607,
          8240,
          371,
          11,
          321,
          393,
          536,
          11,
          47340,
          11,
          51446
        ]
      },
      {
        "avg_logprob": -0.24985133131889448,
        "compression_ratio": 1.9273504273504274,
        "end": 653.6,
        "id": 306,
        "no_speech_prob": 0.0006878343410789967,
        "seek": 62924,
        "start": 650.88,
        "temperature": 0,
        "text": " I have the Heroku remote and the origin remote.",
        "tokens": [
          51446,
          286,
          362,
          264,
          3204,
          13275,
          8607,
          293,
          264,
          4957,
          8607,
          13,
          51582
        ]
      },
      {
        "avg_logprob": -0.24985133131889448,
        "compression_ratio": 1.9273504273504274,
        "end": 655.08,
        "id": 307,
        "no_speech_prob": 0.0006878343410789967,
        "seek": 62924,
        "start": 653.6,
        "temperature": 0,
        "text": " What's next?",
        "tokens": [
          51582,
          708,
          311,
          958,
          30,
          51656
        ]
      },
      {
        "avg_logprob": -0.24985133131889448,
        "compression_ratio": 1.9273504273504274,
        "end": 658.96,
        "id": 308,
        "no_speech_prob": 0.0006878343410789967,
        "seek": 62924,
        "start": 655.08,
        "temperature": 0,
        "text": " Now I'm going to say, actually, I",
        "tokens": [
          51656,
          823,
          286,
          478,
          516,
          281,
          584,
          11,
          767,
          11,
          286,
          51850
        ]
      },
      {
        "avg_logprob": -0.2467921574910482,
        "compression_ratio": 1.6728624535315986,
        "end": 661.2,
        "id": 309,
        "no_speech_prob": 0.0001852241693995893,
        "seek": 65896,
        "start": 659.6800000000001,
        "temperature": 0,
        "text": " If I made any changes to the code,",
        "tokens": [
          50400,
          759,
          286,
          1027,
          604,
          2962,
          281,
          264,
          3089,
          11,
          50476
        ]
      },
      {
        "avg_logprob": -0.2467921574910482,
        "compression_ratio": 1.6728624535315986,
        "end": 663.32,
        "id": 310,
        "no_speech_prob": 0.0001852241693995893,
        "seek": 65896,
        "start": 661.2,
        "temperature": 0,
        "text": " I would need to do git add and git commit.",
        "tokens": [
          50476,
          286,
          576,
          643,
          281,
          360,
          18331,
          909,
          293,
          18331,
          5599,
          13,
          50582
        ]
      },
      {
        "avg_logprob": -0.2467921574910482,
        "compression_ratio": 1.6728624535315986,
        "end": 665.4000000000001,
        "id": 311,
        "no_speech_prob": 0.0001852241693995893,
        "seek": 65896,
        "start": 663.32,
        "temperature": 0,
        "text": " But all I need to do is now deploy it.",
        "tokens": [
          50582,
          583,
          439,
          286,
          643,
          281,
          360,
          307,
          586,
          7274,
          309,
          13,
          50686
        ]
      },
      {
        "avg_logprob": -0.2467921574910482,
        "compression_ratio": 1.6728624535315986,
        "end": 668.4000000000001,
        "id": 312,
        "no_speech_prob": 0.0001852241693995893,
        "seek": 65896,
        "start": 665.4000000000001,
        "temperature": 0,
        "text": " To deploy it to Heroku, I say git push Heroku master.",
        "tokens": [
          50686,
          1407,
          7274,
          309,
          281,
          3204,
          13275,
          11,
          286,
          584,
          18331,
          2944,
          3204,
          13275,
          4505,
          13,
          50836
        ]
      },
      {
        "avg_logprob": -0.2467921574910482,
        "compression_ratio": 1.6728624535315986,
        "end": 669.84,
        "id": 313,
        "no_speech_prob": 0.0001852241693995893,
        "seek": 65896,
        "start": 668.4000000000001,
        "temperature": 0,
        "text": " I'm sure I've forgotten something.",
        "tokens": [
          50836,
          286,
          478,
          988,
          286,
          600,
          11832,
          746,
          13,
          50908
        ]
      },
      {
        "avg_logprob": -0.2467921574910482,
        "compression_ratio": 1.6728624535315986,
        "end": 672.64,
        "id": 314,
        "no_speech_prob": 0.0001852241693995893,
        "seek": 65896,
        "start": 669.84,
        "temperature": 0,
        "text": " Let's see what happens.",
        "tokens": [
          50908,
          961,
          311,
          536,
          437,
          2314,
          13,
          51048
        ]
      },
      {
        "avg_logprob": -0.2467921574910482,
        "compression_ratio": 1.6728624535315986,
        "end": 674.72,
        "id": 315,
        "no_speech_prob": 0.0001852241693995893,
        "seek": 65896,
        "start": 672.64,
        "temperature": 0,
        "text": " It's going to run through a bunch of things,",
        "tokens": [
          51048,
          467,
          311,
          516,
          281,
          1190,
          807,
          257,
          3840,
          295,
          721,
          11,
          51152
        ]
      },
      {
        "avg_logprob": -0.2467921574910482,
        "compression_ratio": 1.6728624535315986,
        "end": 676.44,
        "id": 316,
        "no_speech_prob": 0.0001852241693995893,
        "seek": 65896,
        "start": 674.72,
        "temperature": 0,
        "text": " building the project.",
        "tokens": [
          51152,
          2390,
          264,
          1716,
          13,
          51238
        ]
      },
      {
        "avg_logprob": -0.2467921574910482,
        "compression_ratio": 1.6728624535315986,
        "end": 677.64,
        "id": 317,
        "no_speech_prob": 0.0001852241693995893,
        "seek": 65896,
        "start": 676.44,
        "temperature": 0,
        "text": " And it's deployed.",
        "tokens": [
          51238,
          400,
          309,
          311,
          17826,
          13,
          51298
        ]
      },
      {
        "avg_logprob": -0.2467921574910482,
        "compression_ratio": 1.6728624535315986,
        "end": 681,
        "id": 318,
        "no_speech_prob": 0.0001852241693995893,
        "seek": 65896,
        "start": 677.64,
        "temperature": 0,
        "text": " So I can click on this and open it in the browser.",
        "tokens": [
          51298,
          407,
          286,
          393,
          2052,
          322,
          341,
          293,
          1269,
          309,
          294,
          264,
          11185,
          13,
          51466
        ]
      },
      {
        "avg_logprob": -0.2467921574910482,
        "compression_ratio": 1.6728624535315986,
        "end": 684.88,
        "id": 319,
        "no_speech_prob": 0.0001852241693995893,
        "seek": 65896,
        "start": 681,
        "temperature": 0,
        "text": " And look, there it is.",
        "tokens": [
          51466,
          400,
          574,
          11,
          456,
          309,
          307,
          13,
          51660
        ]
      },
      {
        "avg_logprob": -0.2467921574910482,
        "compression_ratio": 1.6728624535315986,
        "end": 685.72,
        "id": 320,
        "no_speech_prob": 0.0001852241693995893,
        "seek": 65896,
        "start": 684.88,
        "temperature": 0,
        "text": " So it's working.",
        "tokens": [
          51660,
          407,
          309,
          311,
          1364,
          13,
          51702
        ]
      },
      {
        "avg_logprob": -0.2467921574910482,
        "compression_ratio": 1.6728624535315986,
        "end": 688.1600000000001,
        "id": 321,
        "no_speech_prob": 0.0001852241693995893,
        "seek": 65896,
        "start": 685.72,
        "temperature": 0,
        "text": " It's deployed, but I don't see temperature.",
        "tokens": [
          51702,
          467,
          311,
          17826,
          11,
          457,
          286,
          500,
          380,
          536,
          4292,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.2232231044169492,
        "compression_ratio": 1.712837837837838,
        "end": 690.12,
        "id": 322,
        "no_speech_prob": 0.00017130639753304422,
        "seek": 68816,
        "start": 688.16,
        "temperature": 0,
        "text": " If I go to view check-ins, there's",
        "tokens": [
          50364,
          759,
          286,
          352,
          281,
          1910,
          1520,
          12,
          1292,
          11,
          456,
          311,
          50462
        ]
      },
      {
        "avg_logprob": -0.2232231044169492,
        "compression_ratio": 1.712837837837838,
        "end": 692,
        "id": 323,
        "no_speech_prob": 0.00017130639753304422,
        "seek": 68816,
        "start": 690.12,
        "temperature": 0,
        "text": " nothing added to the database.",
        "tokens": [
          50462,
          1825,
          3869,
          281,
          264,
          8149,
          13,
          50556
        ]
      },
      {
        "avg_logprob": -0.2232231044169492,
        "compression_ratio": 1.712837837837838,
        "end": 693.4,
        "id": 324,
        "no_speech_prob": 0.00017130639753304422,
        "seek": 68816,
        "start": 692,
        "temperature": 0,
        "text": " So something's not working.",
        "tokens": [
          50556,
          407,
          746,
          311,
          406,
          1364,
          13,
          50626
        ]
      },
      {
        "avg_logprob": -0.2232231044169492,
        "compression_ratio": 1.712837837837838,
        "end": 695.4,
        "id": 325,
        "no_speech_prob": 0.00017130639753304422,
        "seek": 68816,
        "start": 693.4,
        "temperature": 0,
        "text": " It's deployed, but it's not working.",
        "tokens": [
          50626,
          467,
          311,
          17826,
          11,
          457,
          309,
          311,
          406,
          1364,
          13,
          50726
        ]
      },
      {
        "avg_logprob": -0.2232231044169492,
        "compression_ratio": 1.712837837837838,
        "end": 696.68,
        "id": 326,
        "no_speech_prob": 0.00017130639753304422,
        "seek": 68816,
        "start": 695.4,
        "temperature": 0,
        "text": " Aha.",
        "tokens": [
          50726,
          27448,
          13,
          50790
        ]
      },
      {
        "avg_logprob": -0.2232231044169492,
        "compression_ratio": 1.712837837837838,
        "end": 697.7199999999999,
        "id": 327,
        "no_speech_prob": 0.00017130639753304422,
        "seek": 68816,
        "start": 696.68,
        "temperature": 0,
        "text": " Do you remember?",
        "tokens": [
          50790,
          1144,
          291,
          1604,
          30,
          50842
        ]
      },
      {
        "avg_logprob": -0.2232231044169492,
        "compression_ratio": 1.712837837837838,
        "end": 698.56,
        "id": 328,
        "no_speech_prob": 0.00017130639753304422,
        "seek": 68816,
        "start": 697.7199999999999,
        "temperature": 0,
        "text": " I remember.",
        "tokens": [
          50842,
          286,
          1604,
          13,
          50884
        ]
      },
      {
        "avg_logprob": -0.2232231044169492,
        "compression_ratio": 1.712837837837838,
        "end": 701.36,
        "id": 329,
        "no_speech_prob": 0.00017130639753304422,
        "seek": 68816,
        "start": 698.56,
        "temperature": 0,
        "text": " So the thing that I missed is, once again, the API key.",
        "tokens": [
          50884,
          407,
          264,
          551,
          300,
          286,
          6721,
          307,
          11,
          1564,
          797,
          11,
          264,
          9362,
          2141,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.2232231044169492,
        "compression_ratio": 1.712837837837838,
        "end": 705.0799999999999,
        "id": 330,
        "no_speech_prob": 0.00017130639753304422,
        "seek": 68816,
        "start": 701.36,
        "temperature": 0,
        "text": " So this environment file did not make it to Heroku.",
        "tokens": [
          51024,
          407,
          341,
          2823,
          3991,
          630,
          406,
          652,
          309,
          281,
          3204,
          13275,
          13,
          51210
        ]
      },
      {
        "avg_logprob": -0.2232231044169492,
        "compression_ratio": 1.712837837837838,
        "end": 706.88,
        "id": 331,
        "no_speech_prob": 0.00017130639753304422,
        "seek": 68816,
        "start": 705.0799999999999,
        "temperature": 0,
        "text": " And actually, in this case, with Heroku,",
        "tokens": [
          51210,
          400,
          767,
          11,
          294,
          341,
          1389,
          11,
          365,
          3204,
          13275,
          11,
          51300
        ]
      },
      {
        "avg_logprob": -0.2232231044169492,
        "compression_ratio": 1.712837837837838,
        "end": 708.8,
        "id": 332,
        "no_speech_prob": 0.00017130639753304422,
        "seek": 68816,
        "start": 706.88,
        "temperature": 0,
        "text": " I don't need a.env file.",
        "tokens": [
          51300,
          286,
          500,
          380,
          643,
          257,
          2411,
          268,
          85,
          3991,
          13,
          51396
        ]
      },
      {
        "avg_logprob": -0.2232231044169492,
        "compression_ratio": 1.712837837837838,
        "end": 711.36,
        "id": 333,
        "no_speech_prob": 0.00017130639753304422,
        "seek": 68816,
        "start": 708.8,
        "temperature": 0,
        "text": " I don't actually even need that npm package.env,",
        "tokens": [
          51396,
          286,
          500,
          380,
          767,
          754,
          643,
          300,
          297,
          14395,
          7372,
          2411,
          268,
          85,
          11,
          51524
        ]
      },
      {
        "avg_logprob": -0.2232231044169492,
        "compression_ratio": 1.712837837837838,
        "end": 713.56,
        "id": 334,
        "no_speech_prob": 0.00017130639753304422,
        "seek": 68816,
        "start": 711.36,
        "temperature": 0,
        "text": " because the Heroku command line interface",
        "tokens": [
          51524,
          570,
          264,
          3204,
          13275,
          5622,
          1622,
          9226,
          51634
        ]
      },
      {
        "avg_logprob": -0.2232231044169492,
        "compression_ratio": 1.712837837837838,
        "end": 716.1999999999999,
        "id": 335,
        "no_speech_prob": 0.00017130639753304422,
        "seek": 68816,
        "start": 713.56,
        "temperature": 0,
        "text": " lets me set environment variables directly.",
        "tokens": [
          51634,
          6653,
          385,
          992,
          2823,
          9102,
          3838,
          13,
          51766
        ]
      },
      {
        "avg_logprob": -0.2232231044169492,
        "compression_ratio": 1.712837837837838,
        "end": 717.76,
        "id": 336,
        "no_speech_prob": 0.00017130639753304422,
        "seek": 68816,
        "start": 716.1999999999999,
        "temperature": 0,
        "text": " So I can go back to the terminal.",
        "tokens": [
          51766,
          407,
          286,
          393,
          352,
          646,
          281,
          264,
          14709,
          13,
          51844
        ]
      },
      {
        "avg_logprob": -0.2344819146233636,
        "compression_ratio": 1.7564575645756457,
        "end": 719.8,
        "id": 337,
        "no_speech_prob": 0.0004878465551882982,
        "seek": 71776,
        "start": 717.84,
        "temperature": 0,
        "text": " And I can type to Heroku config.",
        "tokens": [
          50368,
          400,
          286,
          393,
          2010,
          281,
          3204,
          13275,
          6662,
          13,
          50466
        ]
      },
      {
        "avg_logprob": -0.2344819146233636,
        "compression_ratio": 1.7564575645756457,
        "end": 722.56,
        "id": 338,
        "no_speech_prob": 0.0004878465551882982,
        "seek": 71776,
        "start": 719.8,
        "temperature": 0,
        "text": " And Heroku config is going to show me all of my environment",
        "tokens": [
          50466,
          400,
          3204,
          13275,
          6662,
          307,
          516,
          281,
          855,
          385,
          439,
          295,
          452,
          2823,
          50604
        ]
      },
      {
        "avg_logprob": -0.2344819146233636,
        "compression_ratio": 1.7564575645756457,
        "end": 724.24,
        "id": 339,
        "no_speech_prob": 0.0004878465551882982,
        "seek": 71776,
        "start": 722.56,
        "temperature": 0,
        "text": " variables, of which there are none.",
        "tokens": [
          50604,
          9102,
          11,
          295,
          597,
          456,
          366,
          6022,
          13,
          50688
        ]
      },
      {
        "avg_logprob": -0.2344819146233636,
        "compression_ratio": 1.7564575645756457,
        "end": 728.96,
        "id": 340,
        "no_speech_prob": 0.0004878465551882982,
        "seek": 71776,
        "start": 724.24,
        "temperature": 0,
        "text": " So I can now say Heroku config colon set API underscore key",
        "tokens": [
          50688,
          407,
          286,
          393,
          586,
          584,
          3204,
          13275,
          6662,
          8255,
          992,
          9362,
          37556,
          2141,
          50924
        ]
      },
      {
        "avg_logprob": -0.2344819146233636,
        "compression_ratio": 1.7564575645756457,
        "end": 729.56,
        "id": 341,
        "no_speech_prob": 0.0004878465551882982,
        "seek": 71776,
        "start": 728.96,
        "temperature": 0,
        "text": " equals.",
        "tokens": [
          50924,
          6915,
          13,
          50954
        ]
      },
      {
        "avg_logprob": -0.2344819146233636,
        "compression_ratio": 1.7564575645756457,
        "end": 730.8,
        "id": 342,
        "no_speech_prob": 0.0004878465551882982,
        "seek": 71776,
        "start": 729.56,
        "temperature": 0,
        "text": " Go back to my code.",
        "tokens": [
          50954,
          1037,
          646,
          281,
          452,
          3089,
          13,
          51016
        ]
      },
      {
        "avg_logprob": -0.2344819146233636,
        "compression_ratio": 1.7564575645756457,
        "end": 731.76,
        "id": 343,
        "no_speech_prob": 0.0004878465551882982,
        "seek": 71776,
        "start": 730.8,
        "temperature": 0,
        "text": " Grab this.",
        "tokens": [
          51016,
          20357,
          341,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2344819146233636,
        "compression_ratio": 1.7564575645756457,
        "end": 732.76,
        "id": 344,
        "no_speech_prob": 0.0004878465551882982,
        "seek": 71776,
        "start": 731.76,
        "temperature": 0,
        "text": " Paste that in.",
        "tokens": [
          51064,
          43827,
          300,
          294,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2344819146233636,
        "compression_ratio": 1.7564575645756457,
        "end": 734.84,
        "id": 345,
        "no_speech_prob": 0.0004878465551882982,
        "seek": 71776,
        "start": 732.76,
        "temperature": 0,
        "text": " Hit Enter.",
        "tokens": [
          51114,
          9217,
          10399,
          13,
          51218
        ]
      },
      {
        "avg_logprob": -0.2344819146233636,
        "compression_ratio": 1.7564575645756457,
        "end": 736.12,
        "id": 346,
        "no_speech_prob": 0.0004878465551882982,
        "seek": 71776,
        "start": 734.84,
        "temperature": 0,
        "text": " It's setting the API key.",
        "tokens": [
          51218,
          467,
          311,
          3287,
          264,
          9362,
          2141,
          13,
          51282
        ]
      },
      {
        "avg_logprob": -0.2344819146233636,
        "compression_ratio": 1.7564575645756457,
        "end": 738.84,
        "id": 347,
        "no_speech_prob": 0.0004878465551882982,
        "seek": 71776,
        "start": 736.12,
        "temperature": 0,
        "text": " And it's even restarting the app for me.",
        "tokens": [
          51282,
          400,
          309,
          311,
          754,
          21022,
          278,
          264,
          724,
          337,
          385,
          13,
          51418
        ]
      },
      {
        "avg_logprob": -0.2344819146233636,
        "compression_ratio": 1.7564575645756457,
        "end": 741.04,
        "id": 348,
        "no_speech_prob": 0.0004878465551882982,
        "seek": 71776,
        "start": 738.84,
        "temperature": 0,
        "text": " So nice of it to do that for me.",
        "tokens": [
          51418,
          407,
          1481,
          295,
          309,
          281,
          360,
          300,
          337,
          385,
          13,
          51528
        ]
      },
      {
        "avg_logprob": -0.2344819146233636,
        "compression_ratio": 1.7564575645756457,
        "end": 742.96,
        "id": 349,
        "no_speech_prob": 0.0004878465551882982,
        "seek": 71776,
        "start": 741.04,
        "temperature": 0,
        "text": " Let's just check Heroku config again.",
        "tokens": [
          51528,
          961,
          311,
          445,
          1520,
          3204,
          13275,
          6662,
          797,
          13,
          51624
        ]
      },
      {
        "avg_logprob": -0.2344819146233636,
        "compression_ratio": 1.7564575645756457,
        "end": 745.08,
        "id": 350,
        "no_speech_prob": 0.0004878465551882982,
        "seek": 71776,
        "start": 742.96,
        "temperature": 0,
        "text": " You can see that's my environment variable.",
        "tokens": [
          51624,
          509,
          393,
          536,
          300,
          311,
          452,
          2823,
          7006,
          13,
          51730
        ]
      },
      {
        "avg_logprob": -0.2344819146233636,
        "compression_ratio": 1.7564575645756457,
        "end": 747.6,
        "id": 351,
        "no_speech_prob": 0.0004878465551882982,
        "seek": 71776,
        "start": 745.08,
        "temperature": 0,
        "text": " It's not found anywhere other than here.",
        "tokens": [
          51730,
          467,
          311,
          406,
          1352,
          4992,
          661,
          813,
          510,
          13,
          51856
        ]
      },
      {
        "avg_logprob": -0.2383529410874548,
        "compression_ratio": 1.772972972972973,
        "end": 749.76,
        "id": 352,
        "no_speech_prob": 0.0005527632310986519,
        "seek": 74760,
        "start": 747.96,
        "temperature": 0,
        "text": " It's saved secretly.",
        "tokens": [
          50382,
          467,
          311,
          6624,
          22611,
          13,
          50472
        ]
      },
      {
        "avg_logprob": -0.2383529410874548,
        "compression_ratio": 1.772972972972973,
        "end": 750.76,
        "id": 353,
        "no_speech_prob": 0.0005527632310986519,
        "seek": 74760,
        "start": 749.76,
        "temperature": 0,
        "text": " And I can hit Refresh.",
        "tokens": [
          50472,
          400,
          286,
          393,
          2045,
          16957,
          3644,
          13,
          50522
        ]
      },
      {
        "avg_logprob": -0.2383529410874548,
        "compression_ratio": 1.772972972972973,
        "end": 757.84,
        "id": 354,
        "no_speech_prob": 0.0005527632310986519,
        "seek": 74760,
        "start": 754.44,
        "temperature": 0,
        "text": " And there we go.",
        "tokens": [
          50706,
          400,
          456,
          321,
          352,
          13,
          50876
        ]
      },
      {
        "avg_logprob": -0.2383529410874548,
        "compression_ratio": 1.772972972972973,
        "end": 759.32,
        "id": 355,
        "no_speech_prob": 0.0005527632310986519,
        "seek": 74760,
        "start": 757.84,
        "temperature": 0,
        "text": " Now I've got the temperature.",
        "tokens": [
          50876,
          823,
          286,
          600,
          658,
          264,
          4292,
          13,
          50950
        ]
      },
      {
        "avg_logprob": -0.2383529410874548,
        "compression_ratio": 1.772972972972973,
        "end": 761.44,
        "id": 356,
        "no_speech_prob": 0.0005527632310986519,
        "seek": 74760,
        "start": 759.32,
        "temperature": 0,
        "text": " Once again, I can go to Mountain View.",
        "tokens": [
          50950,
          3443,
          797,
          11,
          286,
          393,
          352,
          281,
          15586,
          13909,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.2383529410874548,
        "compression_ratio": 1.772972972972973,
        "end": 763.2,
        "id": 357,
        "no_speech_prob": 0.0005527632310986519,
        "seek": 74760,
        "start": 761.44,
        "temperature": 0,
        "text": " I can hit Refresh to check in.",
        "tokens": [
          51056,
          286,
          393,
          2045,
          16957,
          3644,
          281,
          1520,
          294,
          13,
          51144
        ]
      },
      {
        "avg_logprob": -0.2383529410874548,
        "compression_ratio": 1.772972972972973,
        "end": 765.4,
        "id": 358,
        "no_speech_prob": 0.0005527632310986519,
        "seek": 74760,
        "start": 763.2,
        "temperature": 0,
        "text": " I can go to San Francisco.",
        "tokens": [
          51144,
          286,
          393,
          352,
          281,
          5271,
          12279,
          13,
          51254
        ]
      },
      {
        "avg_logprob": -0.2383529410874548,
        "compression_ratio": 1.772972972972973,
        "end": 766.4,
        "id": 359,
        "no_speech_prob": 0.0005527632310986519,
        "seek": 74760,
        "start": 765.4,
        "temperature": 0,
        "text": " I can check in again.",
        "tokens": [
          51254,
          286,
          393,
          1520,
          294,
          797,
          13,
          51304
        ]
      },
      {
        "avg_logprob": -0.2383529410874548,
        "compression_ratio": 1.772972972972973,
        "end": 767.6800000000001,
        "id": 360,
        "no_speech_prob": 0.0005527632310986519,
        "seek": 74760,
        "start": 766.4,
        "temperature": 0,
        "text": " Ooh.",
        "tokens": [
          51304,
          7951,
          13,
          51368
        ]
      },
      {
        "avg_logprob": -0.2383529410874548,
        "compression_ratio": 1.772972972972973,
        "end": 769.32,
        "id": 361,
        "no_speech_prob": 0.0005527632310986519,
        "seek": 74760,
        "start": 767.6800000000001,
        "temperature": 0,
        "text": " I can go to Sao Paolo.",
        "tokens": [
          51368,
          286,
          393,
          352,
          281,
          6299,
          78,
          3426,
          7902,
          13,
          51450
        ]
      },
      {
        "avg_logprob": -0.2383529410874548,
        "compression_ratio": 1.772972972972973,
        "end": 770.5600000000001,
        "id": 362,
        "no_speech_prob": 0.0005527632310986519,
        "seek": 74760,
        "start": 769.32,
        "temperature": 0,
        "text": " I can check in again.",
        "tokens": [
          51450,
          286,
          393,
          1520,
          294,
          797,
          13,
          51512
        ]
      },
      {
        "avg_logprob": -0.2383529410874548,
        "compression_ratio": 1.772972972972973,
        "end": 772.1600000000001,
        "id": 363,
        "no_speech_prob": 0.0005527632310986519,
        "seek": 74760,
        "start": 770.5600000000001,
        "temperature": 0,
        "text": " I can view all my check-ins.",
        "tokens": [
          51512,
          286,
          393,
          1910,
          439,
          452,
          1520,
          12,
          1292,
          13,
          51592
        ]
      },
      {
        "avg_logprob": -0.2383529410874548,
        "compression_ratio": 1.772972972972973,
        "end": 774.1600000000001,
        "id": 364,
        "no_speech_prob": 0.0005527632310986519,
        "seek": 74760,
        "start": 772.1600000000001,
        "temperature": 0,
        "text": " And there they are.",
        "tokens": [
          51592,
          400,
          456,
          436,
          366,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.2383529410874548,
        "compression_ratio": 1.772972972972973,
        "end": 776,
        "id": 365,
        "no_speech_prob": 0.0005527632310986519,
        "seek": 74760,
        "start": 774.1600000000001,
        "temperature": 0,
        "text": " Everything is here.",
        "tokens": [
          51692,
          5471,
          307,
          510,
          13,
          51784
        ]
      },
      {
        "avg_logprob": -0.24121577497841656,
        "compression_ratio": 1.6363636363636365,
        "end": 777.6,
        "id": 366,
        "no_speech_prob": 0.005220050457865,
        "seek": 77600,
        "start": 776,
        "temperature": 0,
        "text": " And the app is working.",
        "tokens": [
          50364,
          400,
          264,
          724,
          307,
          1364,
          13,
          50444
        ]
      },
      {
        "avg_logprob": -0.24121577497841656,
        "compression_ratio": 1.6363636363636365,
        "end": 780.28,
        "id": 367,
        "no_speech_prob": 0.005220050457865,
        "seek": 77600,
        "start": 777.6,
        "temperature": 0,
        "text": " Kind of can't believe this actually worked.",
        "tokens": [
          50444,
          9242,
          295,
          393,
          380,
          1697,
          341,
          767,
          2732,
          13,
          50578
        ]
      },
      {
        "avg_logprob": -0.24121577497841656,
        "compression_ratio": 1.6363636363636365,
        "end": 782.12,
        "id": 368,
        "no_speech_prob": 0.005220050457865,
        "seek": 77600,
        "start": 780.28,
        "temperature": 0,
        "text": " And in many ways, I'm done with this series.",
        "tokens": [
          50578,
          400,
          294,
          867,
          2098,
          11,
          286,
          478,
          1096,
          365,
          341,
          2638,
          13,
          50670
        ]
      },
      {
        "avg_logprob": -0.24121577497841656,
        "compression_ratio": 1.6363636363636365,
        "end": 783.28,
        "id": 369,
        "no_speech_prob": 0.005220050457865,
        "seek": 77600,
        "start": 782.12,
        "temperature": 0,
        "text": " I'm not done.",
        "tokens": [
          50670,
          286,
          478,
          406,
          1096,
          13,
          50728
        ]
      },
      {
        "avg_logprob": -0.24121577497841656,
        "compression_ratio": 1.6363636363636365,
        "end": 784.72,
        "id": 370,
        "no_speech_prob": 0.005220050457865,
        "seek": 77600,
        "start": 783.28,
        "temperature": 0,
        "text": " That's the thing I already discussed.",
        "tokens": [
          50728,
          663,
          311,
          264,
          551,
          286,
          1217,
          7152,
          13,
          50800
        ]
      },
      {
        "avg_logprob": -0.24121577497841656,
        "compression_ratio": 1.6363636363636365,
        "end": 788.04,
        "id": 371,
        "no_speech_prob": 0.005220050457865,
        "seek": 77600,
        "start": 784.72,
        "temperature": 0,
        "text": " But there is some important stuff I need to talk about.",
        "tokens": [
          50800,
          583,
          456,
          307,
          512,
          1021,
          1507,
          286,
          643,
          281,
          751,
          466,
          13,
          50966
        ]
      },
      {
        "avg_logprob": -0.24121577497841656,
        "compression_ratio": 1.6363636363636365,
        "end": 791.44,
        "id": 372,
        "no_speech_prob": 0.005220050457865,
        "seek": 77600,
        "start": 788.04,
        "temperature": 0,
        "text": " Number one, where's the database again?",
        "tokens": [
          50966,
          5118,
          472,
          11,
          689,
          311,
          264,
          8149,
          797,
          30,
          51136
        ]
      },
      {
        "avg_logprob": -0.24121577497841656,
        "compression_ratio": 1.6363636363636365,
        "end": 793.24,
        "id": 373,
        "no_speech_prob": 0.005220050457865,
        "seek": 77600,
        "start": 791.44,
        "temperature": 0,
        "text": " Look at these three check-ins here.",
        "tokens": [
          51136,
          2053,
          412,
          613,
          1045,
          1520,
          12,
          1292,
          510,
          13,
          51226
        ]
      },
      {
        "avg_logprob": -0.24121577497841656,
        "compression_ratio": 1.6363636363636365,
        "end": 796.72,
        "id": 374,
        "no_speech_prob": 0.005220050457865,
        "seek": 77600,
        "start": 793.24,
        "temperature": 0,
        "text": " And I'm at theweatherhere.herokuapp.com.",
        "tokens": [
          51226,
          400,
          286,
          478,
          412,
          264,
          826,
          1172,
          6703,
          13,
          511,
          13275,
          1746,
          13,
          1112,
          13,
          51400
        ]
      },
      {
        "avg_logprob": -0.24121577497841656,
        "compression_ratio": 1.6363636363636365,
        "end": 803.88,
        "id": 375,
        "no_speech_prob": 0.005220050457865,
        "seek": 77600,
        "start": 796.72,
        "temperature": 0,
        "text": " Let me now go to codingtrain dash theweatherhere.glitch.me.",
        "tokens": [
          51400,
          961,
          385,
          586,
          352,
          281,
          17720,
          83,
          7146,
          8240,
          264,
          826,
          1172,
          6703,
          13,
          7191,
          1549,
          13,
          1398,
          13,
          51758
        ]
      },
      {
        "avg_logprob": -0.24121577497841656,
        "compression_ratio": 1.6363636363636365,
        "end": 805.88,
        "id": 376,
        "no_speech_prob": 0.005220050457865,
        "seek": 77600,
        "start": 803.88,
        "temperature": 0,
        "text": " And let's look at those check-ins.",
        "tokens": [
          51758,
          400,
          718,
          311,
          574,
          412,
          729,
          1520,
          12,
          1292,
          13,
          51858
        ]
      },
      {
        "avg_logprob": -0.2222317208489068,
        "compression_ratio": 1.7301038062283738,
        "end": 808.4399999999999,
        "id": 377,
        "no_speech_prob": 0.000048325520765502006,
        "seek": 80588,
        "start": 806.76,
        "temperature": 0,
        "text": " There's like seven of them.",
        "tokens": [
          50408,
          821,
          311,
          411,
          3407,
          295,
          552,
          13,
          50492
        ]
      },
      {
        "avg_logprob": -0.2222317208489068,
        "compression_ratio": 1.7301038062283738,
        "end": 811.56,
        "id": 378,
        "no_speech_prob": 0.000048325520765502006,
        "seek": 80588,
        "start": 808.4399999999999,
        "temperature": 0,
        "text": " Over here on the Heroku one, there's four of them.",
        "tokens": [
          50492,
          4886,
          510,
          322,
          264,
          3204,
          13275,
          472,
          11,
          456,
          311,
          1451,
          295,
          552,
          13,
          50648
        ]
      },
      {
        "avg_logprob": -0.2222317208489068,
        "compression_ratio": 1.7301038062283738,
        "end": 813.32,
        "id": 379,
        "no_speech_prob": 0.000048325520765502006,
        "seek": 80588,
        "start": 811.56,
        "temperature": 0,
        "text": " They're not sharing a database.",
        "tokens": [
          50648,
          814,
          434,
          406,
          5414,
          257,
          8149,
          13,
          50736
        ]
      },
      {
        "avg_logprob": -0.2222317208489068,
        "compression_ratio": 1.7301038062283738,
        "end": 814.8,
        "id": 380,
        "no_speech_prob": 0.000048325520765502006,
        "seek": 80588,
        "start": 813.32,
        "temperature": 0,
        "text": " This is very important.",
        "tokens": [
          50736,
          639,
          307,
          588,
          1021,
          13,
          50810
        ]
      },
      {
        "avg_logprob": -0.2222317208489068,
        "compression_ratio": 1.7301038062283738,
        "end": 819.12,
        "id": 381,
        "no_speech_prob": 0.000048325520765502006,
        "seek": 80588,
        "start": 814.8,
        "temperature": 0,
        "text": " Remember, the server is the holder of the database.",
        "tokens": [
          50810,
          5459,
          11,
          264,
          7154,
          307,
          264,
          20349,
          295,
          264,
          8149,
          13,
          51026
        ]
      },
      {
        "avg_logprob": -0.2222317208489068,
        "compression_ratio": 1.7301038062283738,
        "end": 821.6,
        "id": 382,
        "no_speech_prob": 0.000048325520765502006,
        "seek": 80588,
        "start": 819.12,
        "temperature": 0,
        "text": " So you wouldn't want to deploy this to multiple places.",
        "tokens": [
          51026,
          407,
          291,
          2759,
          380,
          528,
          281,
          7274,
          341,
          281,
          3866,
          3190,
          13,
          51150
        ]
      },
      {
        "avg_logprob": -0.2222317208489068,
        "compression_ratio": 1.7301038062283738,
        "end": 823.4399999999999,
        "id": 383,
        "no_speech_prob": 0.000048325520765502006,
        "seek": 80588,
        "start": 821.6,
        "temperature": 0,
        "text": " I'm just kind of showing you how that works.",
        "tokens": [
          51150,
          286,
          478,
          445,
          733,
          295,
          4099,
          291,
          577,
          300,
          1985,
          13,
          51242
        ]
      },
      {
        "avg_logprob": -0.2222317208489068,
        "compression_ratio": 1.7301038062283738,
        "end": 826.68,
        "id": 384,
        "no_speech_prob": 0.000048325520765502006,
        "seek": 80588,
        "start": 823.4399999999999,
        "temperature": 0,
        "text": " But that database is something that is created",
        "tokens": [
          51242,
          583,
          300,
          8149,
          307,
          746,
          300,
          307,
          2942,
          51404
        ]
      },
      {
        "avg_logprob": -0.2222317208489068,
        "compression_ratio": 1.7301038062283738,
        "end": 828.32,
        "id": 385,
        "no_speech_prob": 0.000048325520765502006,
        "seek": 80588,
        "start": 826.68,
        "temperature": 0,
        "text": " from the server side itself.",
        "tokens": [
          51404,
          490,
          264,
          7154,
          1252,
          2564,
          13,
          51486
        ]
      },
      {
        "avg_logprob": -0.2222317208489068,
        "compression_ratio": 1.7301038062283738,
        "end": 830.48,
        "id": 386,
        "no_speech_prob": 0.000048325520765502006,
        "seek": 80588,
        "start": 828.32,
        "temperature": 0,
        "text": " And it's different than I could be running this locally here.",
        "tokens": [
          51486,
          400,
          309,
          311,
          819,
          813,
          286,
          727,
          312,
          2614,
          341,
          16143,
          510,
          13,
          51594
        ]
      },
      {
        "avg_logprob": -0.2222317208489068,
        "compression_ratio": 1.7301038062283738,
        "end": 832.04,
        "id": 387,
        "no_speech_prob": 0.000048325520765502006,
        "seek": 80588,
        "start": 830.48,
        "temperature": 0,
        "text": " I'm not running the server right now.",
        "tokens": [
          51594,
          286,
          478,
          406,
          2614,
          264,
          7154,
          558,
          586,
          13,
          51672
        ]
      },
      {
        "avg_logprob": -0.2222317208489068,
        "compression_ratio": 1.7301038062283738,
        "end": 834.36,
        "id": 388,
        "no_speech_prob": 0.000048325520765502006,
        "seek": 80588,
        "start": 832.04,
        "temperature": 0,
        "text": " But I could still say node index.js.",
        "tokens": [
          51672,
          583,
          286,
          727,
          920,
          584,
          9984,
          8186,
          13,
          25530,
          13,
          51788
        ]
      },
      {
        "avg_logprob": -0.2038275620033001,
        "compression_ratio": 1.7331081081081081,
        "end": 837.76,
        "id": 389,
        "no_speech_prob": 0.00023781995696481317,
        "seek": 83436,
        "start": 834.36,
        "temperature": 0,
        "text": " And I've got whatever data I happen to have here locally.",
        "tokens": [
          50364,
          400,
          286,
          600,
          658,
          2035,
          1412,
          286,
          1051,
          281,
          362,
          510,
          16143,
          13,
          50534
        ]
      },
      {
        "avg_logprob": -0.2038275620033001,
        "compression_ratio": 1.7331081081081081,
        "end": 841.44,
        "id": 390,
        "no_speech_prob": 0.00023781995696481317,
        "seek": 83436,
        "start": 837.76,
        "temperature": 0,
        "text": " So I could take that database.db file and pass it around.",
        "tokens": [
          50534,
          407,
          286,
          727,
          747,
          300,
          8149,
          13,
          67,
          65,
          3991,
          293,
          1320,
          309,
          926,
          13,
          50718
        ]
      },
      {
        "avg_logprob": -0.2038275620033001,
        "compression_ratio": 1.7331081081081081,
        "end": 843.04,
        "id": 391,
        "no_speech_prob": 0.00023781995696481317,
        "seek": 83436,
        "start": 841.44,
        "temperature": 0,
        "text": " But that's not what I'm doing here.",
        "tokens": [
          50718,
          583,
          300,
          311,
          406,
          437,
          286,
          478,
          884,
          510,
          13,
          50798
        ]
      },
      {
        "avg_logprob": -0.2038275620033001,
        "compression_ratio": 1.7331081081081081,
        "end": 846.48,
        "id": 392,
        "no_speech_prob": 0.00023781995696481317,
        "seek": 83436,
        "start": 843.04,
        "temperature": 0,
        "text": " So ultimately, what I think of is",
        "tokens": [
          50798,
          407,
          6284,
          11,
          437,
          286,
          519,
          295,
          307,
          50970
        ]
      },
      {
        "avg_logprob": -0.2038275620033001,
        "compression_ratio": 1.7331081081081081,
        "end": 849.32,
        "id": 393,
        "no_speech_prob": 0.00023781995696481317,
        "seek": 83436,
        "start": 846.48,
        "temperature": 0,
        "text": " I would have a local database for testing purposes.",
        "tokens": [
          50970,
          286,
          576,
          362,
          257,
          2654,
          8149,
          337,
          4997,
          9932,
          13,
          51112
        ]
      },
      {
        "avg_logprob": -0.2038275620033001,
        "compression_ratio": 1.7331081081081081,
        "end": 851.08,
        "id": 394,
        "no_speech_prob": 0.00023781995696481317,
        "seek": 83436,
        "start": 849.32,
        "temperature": 0,
        "text": " And once I've deployed it, that database",
        "tokens": [
          51112,
          400,
          1564,
          286,
          600,
          17826,
          309,
          11,
          300,
          8149,
          51200
        ]
      },
      {
        "avg_logprob": -0.2038275620033001,
        "compression_ratio": 1.7331081081081081,
        "end": 852.08,
        "id": 395,
        "no_speech_prob": 0.00023781995696481317,
        "seek": 83436,
        "start": 851.08,
        "temperature": 0,
        "text": " will persist forever.",
        "tokens": [
          51200,
          486,
          13233,
          5680,
          13,
          51250
        ]
      },
      {
        "avg_logprob": -0.2038275620033001,
        "compression_ratio": 1.7331081081081081,
        "end": 854.28,
        "id": 396,
        "no_speech_prob": 0.00023781995696481317,
        "seek": 83436,
        "start": 852.08,
        "temperature": 0,
        "text": " Of course, I might want to wipe it for every reason.",
        "tokens": [
          51250,
          2720,
          1164,
          11,
          286,
          1062,
          528,
          281,
          14082,
          309,
          337,
          633,
          1778,
          13,
          51360
        ]
      },
      {
        "avg_logprob": -0.2038275620033001,
        "compression_ratio": 1.7331081081081081,
        "end": 856.36,
        "id": 397,
        "no_speech_prob": 0.00023781995696481317,
        "seek": 83436,
        "start": 854.28,
        "temperature": 0,
        "text": " And again, I'm just sort of tinkering around here.",
        "tokens": [
          51360,
          400,
          797,
          11,
          286,
          478,
          445,
          1333,
          295,
          256,
          475,
          1794,
          926,
          510,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2038275620033001,
        "compression_ratio": 1.7331081081081081,
        "end": 858.72,
        "id": 398,
        "no_speech_prob": 0.00023781995696481317,
        "seek": 83436,
        "start": 856.36,
        "temperature": 0,
        "text": " But where the database lives, where the app lives",
        "tokens": [
          51464,
          583,
          689,
          264,
          8149,
          2909,
          11,
          689,
          264,
          724,
          2909,
          51582
        ]
      },
      {
        "avg_logprob": -0.2038275620033001,
        "compression_ratio": 1.7331081081081081,
        "end": 859.96,
        "id": 399,
        "no_speech_prob": 0.00023781995696481317,
        "seek": 83436,
        "start": 858.72,
        "temperature": 0,
        "text": " is quite important.",
        "tokens": [
          51582,
          307,
          1596,
          1021,
          13,
          51644
        ]
      },
      {
        "avg_logprob": -0.2038275620033001,
        "compression_ratio": 1.7331081081081081,
        "end": 861.64,
        "id": 400,
        "no_speech_prob": 0.00023781995696481317,
        "seek": 83436,
        "start": 859.96,
        "temperature": 0,
        "text": " There's also the question, if I wanted",
        "tokens": [
          51644,
          821,
          311,
          611,
          264,
          1168,
          11,
          498,
          286,
          1415,
          51728
        ]
      },
      {
        "avg_logprob": -0.19919864396403605,
        "compression_ratio": 1.6926070038910506,
        "end": 864.48,
        "id": 401,
        "no_speech_prob": 0.007345592603087425,
        "seek": 86164,
        "start": 861.64,
        "temperature": 0,
        "text": " to continue to work on this, if I'm on Glitch,",
        "tokens": [
          50364,
          281,
          2354,
          281,
          589,
          322,
          341,
          11,
          498,
          286,
          478,
          322,
          5209,
          1549,
          11,
          50506
        ]
      },
      {
        "avg_logprob": -0.19919864396403605,
        "compression_ratio": 1.6926070038910506,
        "end": 866.6,
        "id": 402,
        "no_speech_prob": 0.007345592603087425,
        "seek": 86164,
        "start": 864.48,
        "temperature": 0,
        "text": " Glitch is a whole code editor itself.",
        "tokens": [
          50506,
          5209,
          1549,
          307,
          257,
          1379,
          3089,
          9839,
          2564,
          13,
          50612
        ]
      },
      {
        "avg_logprob": -0.19919864396403605,
        "compression_ratio": 1.6926070038910506,
        "end": 869.16,
        "id": 403,
        "no_speech_prob": 0.007345592603087425,
        "seek": 86164,
        "start": 866.6,
        "temperature": 0,
        "text": " So I can kind of continue and play and work there.",
        "tokens": [
          50612,
          407,
          286,
          393,
          733,
          295,
          2354,
          293,
          862,
          293,
          589,
          456,
          13,
          50740
        ]
      },
      {
        "avg_logprob": -0.19919864396403605,
        "compression_ratio": 1.6926070038910506,
        "end": 872.12,
        "id": 404,
        "no_speech_prob": 0.007345592603087425,
        "seek": 86164,
        "start": 869.16,
        "temperature": 0,
        "text": " But if I wanted to make a change on Heroku,",
        "tokens": [
          50740,
          583,
          498,
          286,
          1415,
          281,
          652,
          257,
          1319,
          322,
          3204,
          13275,
          11,
          50888
        ]
      },
      {
        "avg_logprob": -0.19919864396403605,
        "compression_ratio": 1.6926070038910506,
        "end": 873.52,
        "id": 405,
        "no_speech_prob": 0.007345592603087425,
        "seek": 86164,
        "start": 872.12,
        "temperature": 0,
        "text": " how would I do that?",
        "tokens": [
          50888,
          577,
          576,
          286,
          360,
          300,
          30,
          50958
        ]
      },
      {
        "avg_logprob": -0.19919864396403605,
        "compression_ratio": 1.6926070038910506,
        "end": 877.16,
        "id": 406,
        "no_speech_prob": 0.007345592603087425,
        "seek": 86164,
        "start": 873.52,
        "temperature": 0,
        "text": " So to do that, I've got to now go through multiple steps.",
        "tokens": [
          50958,
          407,
          281,
          360,
          300,
          11,
          286,
          600,
          658,
          281,
          586,
          352,
          807,
          3866,
          4439,
          13,
          51140
        ]
      },
      {
        "avg_logprob": -0.19919864396403605,
        "compression_ratio": 1.6926070038910506,
        "end": 881.1999999999999,
        "id": 407,
        "no_speech_prob": 0.007345592603087425,
        "seek": 86164,
        "start": 877.16,
        "temperature": 0,
        "text": " I first would come here to my local code.",
        "tokens": [
          51140,
          286,
          700,
          576,
          808,
          510,
          281,
          452,
          2654,
          3089,
          13,
          51342
        ]
      },
      {
        "avg_logprob": -0.19919864396403605,
        "compression_ratio": 1.6926070038910506,
        "end": 883.64,
        "id": 408,
        "no_speech_prob": 0.007345592603087425,
        "seek": 86164,
        "start": 881.1999999999999,
        "temperature": 0,
        "text": " And just to make the simplest change possible,",
        "tokens": [
          51342,
          400,
          445,
          281,
          652,
          264,
          22811,
          1319,
          1944,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.19919864396403605,
        "compression_ratio": 1.6926070038910506,
        "end": 888.92,
        "id": 409,
        "no_speech_prob": 0.007345592603087425,
        "seek": 86164,
        "start": 883.64,
        "temperature": 0,
        "text": " I'm just going to change and say, like, the weather is here,",
        "tokens": [
          51464,
          286,
          478,
          445,
          516,
          281,
          1319,
          293,
          584,
          11,
          411,
          11,
          264,
          5503,
          307,
          510,
          11,
          51728
        ]
      },
      {
        "avg_logprob": -0.19919864396403605,
        "compression_ratio": 1.6926070038910506,
        "end": 890.72,
        "id": 410,
        "no_speech_prob": 0.007345592603087425,
        "seek": 86164,
        "start": 888.92,
        "temperature": 0,
        "text": " just as, like, the header.",
        "tokens": [
          51728,
          445,
          382,
          11,
          411,
          11,
          264,
          23117,
          13,
          51818
        ]
      },
      {
        "avg_logprob": -0.20274314474552235,
        "compression_ratio": 1.6310679611650485,
        "end": 893.12,
        "id": 411,
        "no_speech_prob": 0.0000030894736937625566,
        "seek": 89072,
        "start": 890.72,
        "temperature": 0,
        "text": " Then I would have to go back to my terminal.",
        "tokens": [
          50364,
          1396,
          286,
          576,
          362,
          281,
          352,
          646,
          281,
          452,
          14709,
          13,
          50484
        ]
      },
      {
        "avg_logprob": -0.20274314474552235,
        "compression_ratio": 1.6310679611650485,
        "end": 902.0400000000001,
        "id": 412,
        "no_speech_prob": 0.0000030894736937625566,
        "seek": 89072,
        "start": 893.12,
        "temperature": 0,
        "text": " I've got to commit that, making a change to demonstrate",
        "tokens": [
          50484,
          286,
          600,
          658,
          281,
          5599,
          300,
          11,
          1455,
          257,
          1319,
          281,
          11698,
          50930
        ]
      },
      {
        "avg_logprob": -0.20274314474552235,
        "compression_ratio": 1.6310679611650485,
        "end": 905.9200000000001,
        "id": 413,
        "no_speech_prob": 0.0000030894736937625566,
        "seek": 89072,
        "start": 902.0400000000001,
        "temperature": 0,
        "text": " deploy to Heroku.",
        "tokens": [
          50930,
          7274,
          281,
          3204,
          13275,
          13,
          51124
        ]
      },
      {
        "avg_logprob": -0.20274314474552235,
        "compression_ratio": 1.6310679611650485,
        "end": 907.2,
        "id": 414,
        "no_speech_prob": 0.0000030894736937625566,
        "seek": 89072,
        "start": 905.9200000000001,
        "temperature": 0,
        "text": " I'm going to make that change.",
        "tokens": [
          51124,
          286,
          478,
          516,
          281,
          652,
          300,
          1319,
          13,
          51188
        ]
      },
      {
        "avg_logprob": -0.20274314474552235,
        "compression_ratio": 1.6310679611650485,
        "end": 911.88,
        "id": 415,
        "no_speech_prob": 0.0000030894736937625566,
        "seek": 89072,
        "start": 907.2,
        "temperature": 0,
        "text": " And then I'm going to say git push Heroku master.",
        "tokens": [
          51188,
          400,
          550,
          286,
          478,
          516,
          281,
          584,
          18331,
          2944,
          3204,
          13275,
          4505,
          13,
          51422
        ]
      },
      {
        "avg_logprob": -0.20274314474552235,
        "compression_ratio": 1.6310679611650485,
        "end": 916.64,
        "id": 416,
        "no_speech_prob": 0.0000030894736937625566,
        "seek": 89072,
        "start": 911.88,
        "temperature": 0,
        "text": " And this will now automatically rebuild and restart the app.",
        "tokens": [
          51422,
          400,
          341,
          486,
          586,
          6772,
          16877,
          293,
          21022,
          264,
          724,
          13,
          51660
        ]
      },
      {
        "avg_logprob": -0.20274314474552235,
        "compression_ratio": 1.6310679611650485,
        "end": 918.76,
        "id": 417,
        "no_speech_prob": 0.0000030894736937625566,
        "seek": 89072,
        "start": 916.64,
        "temperature": 0,
        "text": " Heroku knows to do that automatically when you",
        "tokens": [
          51660,
          3204,
          13275,
          3255,
          281,
          360,
          300,
          6772,
          562,
          291,
          51766
        ]
      },
      {
        "avg_logprob": -0.20274314474552235,
        "compression_ratio": 1.6310679611650485,
        "end": 920.52,
        "id": 418,
        "no_speech_prob": 0.0000030894736937625566,
        "seek": 89072,
        "start": 918.76,
        "temperature": 0,
        "text": " try to send it revised code.",
        "tokens": [
          51766,
          853,
          281,
          2845,
          309,
          35228,
          3089,
          13,
          51854
        ]
      },
      {
        "avg_logprob": -0.2262026658698694,
        "compression_ratio": 1.5747126436781609,
        "end": 922.56,
        "id": 419,
        "no_speech_prob": 0.0000337368473992683,
        "seek": 92052,
        "start": 921.3199999999999,
        "temperature": 0,
        "text": " But it only can send it revised code",
        "tokens": [
          50404,
          583,
          309,
          787,
          393,
          2845,
          309,
          35228,
          3089,
          50466
        ]
      },
      {
        "avg_logprob": -0.2262026658698694,
        "compression_ratio": 1.5747126436781609,
        "end": 924.6,
        "id": 420,
        "no_speech_prob": 0.0000337368473992683,
        "seek": 92052,
        "start": 922.56,
        "temperature": 0,
        "text": " if it's been committed to Git.",
        "tokens": [
          50466,
          498,
          309,
          311,
          668,
          7784,
          281,
          16939,
          13,
          50568
        ]
      },
      {
        "avg_logprob": -0.2262026658698694,
        "compression_ratio": 1.5747126436781609,
        "end": 926.52,
        "id": 421,
        "no_speech_prob": 0.0000337368473992683,
        "seek": 92052,
        "start": 924.6,
        "temperature": 0,
        "text": " I can go back to the browser.",
        "tokens": [
          50568,
          286,
          393,
          352,
          646,
          281,
          264,
          11185,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2262026658698694,
        "compression_ratio": 1.5747126436781609,
        "end": 927.36,
        "id": 422,
        "no_speech_prob": 0.0000337368473992683,
        "seek": 92052,
        "start": 926.52,
        "temperature": 0,
        "text": " I'm on Heroku.",
        "tokens": [
          50664,
          286,
          478,
          322,
          3204,
          13275,
          13,
          50706
        ]
      },
      {
        "avg_logprob": -0.2262026658698694,
        "compression_ratio": 1.5747126436781609,
        "end": 928.4,
        "id": 423,
        "no_speech_prob": 0.0000337368473992683,
        "seek": 92052,
        "start": 927.36,
        "temperature": 0,
        "text": " I can click on Check In.",
        "tokens": [
          50706,
          286,
          393,
          2052,
          322,
          6881,
          682,
          13,
          50758
        ]
      },
      {
        "avg_logprob": -0.2262026658698694,
        "compression_ratio": 1.5747126436781609,
        "end": 930.3199999999999,
        "id": 424,
        "no_speech_prob": 0.0000337368473992683,
        "seek": 92052,
        "start": 928.4,
        "temperature": 0,
        "text": " And you can see, aha, is is there now.",
        "tokens": [
          50758,
          400,
          291,
          393,
          536,
          11,
          47340,
          11,
          307,
          307,
          456,
          586,
          13,
          50854
        ]
      },
      {
        "avg_logprob": -0.2262026658698694,
        "compression_ratio": 1.5747126436781609,
        "end": 931.3199999999999,
        "id": 425,
        "no_speech_prob": 0.0000337368473992683,
        "seek": 92052,
        "start": 930.3199999999999,
        "temperature": 0,
        "text": " I've added is.",
        "tokens": [
          50854,
          286,
          600,
          3869,
          307,
          13,
          50904
        ]
      },
      {
        "avg_logprob": -0.2262026658698694,
        "compression_ratio": 1.5747126436781609,
        "end": 935.1999999999999,
        "id": 426,
        "no_speech_prob": 0.0000337368473992683,
        "seek": 92052,
        "start": 931.3199999999999,
        "temperature": 0,
        "text": " Now, interestingly enough, if I go here onto GitHub",
        "tokens": [
          50904,
          823,
          11,
          25873,
          1547,
          11,
          498,
          286,
          352,
          510,
          3911,
          23331,
          51098
        ]
      },
      {
        "avg_logprob": -0.2262026658698694,
        "compression_ratio": 1.5747126436781609,
        "end": 942.12,
        "id": 427,
        "no_speech_prob": 0.0000337368473992683,
        "seek": 92052,
        "start": 935.1999999999999,
        "temperature": 0,
        "text": " and I go into public index.html, it still",
        "tokens": [
          51098,
          293,
          286,
          352,
          666,
          1908,
          8186,
          13,
          357,
          15480,
          11,
          309,
          920,
          51444
        ]
      },
      {
        "avg_logprob": -0.2262026658698694,
        "compression_ratio": 1.5747126436781609,
        "end": 944.4,
        "id": 428,
        "no_speech_prob": 0.0000337368473992683,
        "seek": 92052,
        "start": 942.12,
        "temperature": 0,
        "text": " just says the weather here.",
        "tokens": [
          51444,
          445,
          1619,
          264,
          5503,
          510,
          13,
          51558
        ]
      },
      {
        "avg_logprob": -0.2262026658698694,
        "compression_ratio": 1.5747126436781609,
        "end": 946.4,
        "id": 429,
        "no_speech_prob": 0.0000337368473992683,
        "seek": 92052,
        "start": 944.4,
        "temperature": 0,
        "text": " Let's return to this simple diagram",
        "tokens": [
          51558,
          961,
          311,
          2736,
          281,
          341,
          2199,
          10686,
          51658
        ]
      },
      {
        "avg_logprob": -0.2262026658698694,
        "compression_ratio": 1.5747126436781609,
        "end": 947.88,
        "id": 430,
        "no_speech_prob": 0.0000337368473992683,
        "seek": 92052,
        "start": 946.4,
        "temperature": 0,
        "text": " for a second to think about this.",
        "tokens": [
          51658,
          337,
          257,
          1150,
          281,
          519,
          466,
          341,
          13,
          51732
        ]
      },
      {
        "avg_logprob": -0.2262026658698694,
        "compression_ratio": 1.5747126436781609,
        "end": 949.0799999999999,
        "id": 431,
        "no_speech_prob": 0.0000337368473992683,
        "seek": 92052,
        "start": 947.88,
        "temperature": 0,
        "text": " So I'm working on the code.",
        "tokens": [
          51732,
          407,
          286,
          478,
          1364,
          322,
          264,
          3089,
          13,
          51792
        ]
      },
      {
        "avg_logprob": -0.236026175070129,
        "compression_ratio": 1.7556270096463023,
        "end": 951.5600000000001,
        "id": 432,
        "no_speech_prob": 0.00015356183575931937,
        "seek": 94908,
        "start": 949.08,
        "temperature": 0,
        "text": " This is my local dev environment.",
        "tokens": [
          50364,
          639,
          307,
          452,
          2654,
          1905,
          2823,
          13,
          50488
        ]
      },
      {
        "avg_logprob": -0.236026175070129,
        "compression_ratio": 1.7556270096463023,
        "end": 954.96,
        "id": 433,
        "no_speech_prob": 0.00015356183575931937,
        "seek": 94908,
        "start": 951.5600000000001,
        "temperature": 0,
        "text": " Then I can push my code up to GitHub,",
        "tokens": [
          50488,
          1396,
          286,
          393,
          2944,
          452,
          3089,
          493,
          281,
          23331,
          11,
          50658
        ]
      },
      {
        "avg_logprob": -0.236026175070129,
        "compression_ratio": 1.7556270096463023,
        "end": 957.24,
        "id": 434,
        "no_speech_prob": 0.00015356183575931937,
        "seek": 94908,
        "start": 954.96,
        "temperature": 0,
        "text": " really just as a way of backing it up or releasing it",
        "tokens": [
          50658,
          534,
          445,
          382,
          257,
          636,
          295,
          19373,
          309,
          493,
          420,
          16327,
          309,
          50772
        ]
      },
      {
        "avg_logprob": -0.236026175070129,
        "compression_ratio": 1.7556270096463023,
        "end": 959.2800000000001,
        "id": 435,
        "no_speech_prob": 0.00015356183575931937,
        "seek": 94908,
        "start": 957.24,
        "temperature": 0,
        "text": " to open source or collaborating with other people",
        "tokens": [
          50772,
          281,
          1269,
          4009,
          420,
          30188,
          365,
          661,
          561,
          50874
        ]
      },
      {
        "avg_logprob": -0.236026175070129,
        "compression_ratio": 1.7556270096463023,
        "end": 960.7800000000001,
        "id": 436,
        "no_speech_prob": 0.00015356183575931937,
        "seek": 94908,
        "start": 959.2800000000001,
        "temperature": 0,
        "text": " who might want to work on it as well.",
        "tokens": [
          50874,
          567,
          1062,
          528,
          281,
          589,
          322,
          309,
          382,
          731,
          13,
          50949
        ]
      },
      {
        "avg_logprob": -0.236026175070129,
        "compression_ratio": 1.7556270096463023,
        "end": 963.6,
        "id": 437,
        "no_speech_prob": 0.00015356183575931937,
        "seek": 94908,
        "start": 960.7800000000001,
        "temperature": 0,
        "text": " I can pull changes from GitHub if other people are sharing",
        "tokens": [
          50949,
          286,
          393,
          2235,
          2962,
          490,
          23331,
          498,
          661,
          561,
          366,
          5414,
          51090
        ]
      },
      {
        "avg_logprob": -0.236026175070129,
        "compression_ratio": 1.7556270096463023,
        "end": 964.6800000000001,
        "id": 438,
        "no_speech_prob": 0.00015356183575931937,
        "seek": 94908,
        "start": 963.6,
        "temperature": 0,
        "text": " and implementing things.",
        "tokens": [
          51090,
          293,
          18114,
          721,
          13,
          51144
        ]
      },
      {
        "avg_logprob": -0.236026175070129,
        "compression_ratio": 1.7556270096463023,
        "end": 967.1,
        "id": 439,
        "no_speech_prob": 0.00015356183575931937,
        "seek": 94908,
        "start": 964.6800000000001,
        "temperature": 0,
        "text": " But that's kind of beyond the scope of what I'm doing here.",
        "tokens": [
          51144,
          583,
          300,
          311,
          733,
          295,
          4399,
          264,
          11923,
          295,
          437,
          286,
          478,
          884,
          510,
          13,
          51265
        ]
      },
      {
        "avg_logprob": -0.236026175070129,
        "compression_ratio": 1.7556270096463023,
        "end": 969.6,
        "id": 440,
        "no_speech_prob": 0.00015356183575931937,
        "seek": 94908,
        "start": 967.1,
        "temperature": 0,
        "text": " But now I've added Heroku.",
        "tokens": [
          51265,
          583,
          586,
          286,
          600,
          3869,
          3204,
          13275,
          13,
          51390
        ]
      },
      {
        "avg_logprob": -0.236026175070129,
        "compression_ratio": 1.7556270096463023,
        "end": 971.84,
        "id": 441,
        "no_speech_prob": 0.00015356183575931937,
        "seek": 94908,
        "start": 969.6,
        "temperature": 0,
        "text": " So what's important to realize, unlike with Glitch,",
        "tokens": [
          51390,
          407,
          437,
          311,
          1021,
          281,
          4325,
          11,
          8343,
          365,
          5209,
          1549,
          11,
          51502
        ]
      },
      {
        "avg_logprob": -0.236026175070129,
        "compression_ratio": 1.7556270096463023,
        "end": 975.44,
        "id": 442,
        "no_speech_prob": 0.00015356183575931937,
        "seek": 94908,
        "start": 971.84,
        "temperature": 0,
        "text": " when I kind of like from Glitch grab the code from GitHub,",
        "tokens": [
          51502,
          562,
          286,
          733,
          295,
          411,
          490,
          5209,
          1549,
          4444,
          264,
          3089,
          490,
          23331,
          11,
          51682
        ]
      },
      {
        "avg_logprob": -0.236026175070129,
        "compression_ratio": 1.7556270096463023,
        "end": 979.0200000000001,
        "id": 443,
        "no_speech_prob": 0.00015356183575931937,
        "seek": 94908,
        "start": 975.44,
        "temperature": 0,
        "text": " I'm actually also pushing the code here to Heroku.",
        "tokens": [
          51682,
          286,
          478,
          767,
          611,
          7380,
          264,
          3089,
          510,
          281,
          3204,
          13275,
          13,
          51861
        ]
      },
      {
        "avg_logprob": -0.24429798126220703,
        "compression_ratio": 1.7676767676767677,
        "end": 980.8199999999999,
        "id": 444,
        "no_speech_prob": 0.00017674383707344532,
        "seek": 97902,
        "start": 979.46,
        "temperature": 0,
        "text": " So this is where I'm working on it.",
        "tokens": [
          50386,
          407,
          341,
          307,
          689,
          286,
          478,
          1364,
          322,
          309,
          13,
          50454
        ]
      },
      {
        "avg_logprob": -0.24429798126220703,
        "compression_ratio": 1.7676767676767677,
        "end": 984.06,
        "id": 445,
        "no_speech_prob": 0.00017674383707344532,
        "seek": 97902,
        "start": 980.8199999999999,
        "temperature": 0,
        "text": " When I push it to Heroku, it rebuilds the server.",
        "tokens": [
          50454,
          1133,
          286,
          2944,
          309,
          281,
          3204,
          13275,
          11,
          309,
          16877,
          82,
          264,
          7154,
          13,
          50616
        ]
      },
      {
        "avg_logprob": -0.24429798126220703,
        "compression_ratio": 1.7676767676767677,
        "end": 984.9399999999999,
        "id": 446,
        "no_speech_prob": 0.00017674383707344532,
        "seek": 97902,
        "start": 984.06,
        "temperature": 0,
        "text": " So this is important.",
        "tokens": [
          50616,
          407,
          341,
          307,
          1021,
          13,
          50660
        ]
      },
      {
        "avg_logprob": -0.24429798126220703,
        "compression_ratio": 1.7676767676767677,
        "end": 986.26,
        "id": 447,
        "no_speech_prob": 0.00017674383707344532,
        "seek": 97902,
        "start": 984.9399999999999,
        "temperature": 0,
        "text": " That's like a deployment thing.",
        "tokens": [
          50660,
          663,
          311,
          411,
          257,
          19317,
          551,
          13,
          50726
        ]
      },
      {
        "avg_logprob": -0.24429798126220703,
        "compression_ratio": 1.7676767676767677,
        "end": 989.86,
        "id": 448,
        "no_speech_prob": 0.00017674383707344532,
        "seek": 97902,
        "start": 986.26,
        "temperature": 0,
        "text": " So as I'm developing it, I might just test it locally,",
        "tokens": [
          50726,
          407,
          382,
          286,
          478,
          6416,
          309,
          11,
          286,
          1062,
          445,
          1500,
          309,
          16143,
          11,
          50906
        ]
      },
      {
        "avg_logprob": -0.24429798126220703,
        "compression_ratio": 1.7676767676767677,
        "end": 992.5,
        "id": 449,
        "no_speech_prob": 0.00017674383707344532,
        "seek": 97902,
        "start": 989.86,
        "temperature": 0,
        "text": " push to GitHub to publish the code.",
        "tokens": [
          50906,
          2944,
          281,
          23331,
          281,
          11374,
          264,
          3089,
          13,
          51038
        ]
      },
      {
        "avg_logprob": -0.24429798126220703,
        "compression_ratio": 1.7676767676767677,
        "end": 994.88,
        "id": 450,
        "no_speech_prob": 0.00017674383707344532,
        "seek": 97902,
        "start": 992.5,
        "temperature": 0,
        "text": " And then when I'm ready, actually push it to Heroku.",
        "tokens": [
          51038,
          400,
          550,
          562,
          286,
          478,
          1919,
          11,
          767,
          2944,
          309,
          281,
          3204,
          13275,
          13,
          51157
        ]
      },
      {
        "avg_logprob": -0.24429798126220703,
        "compression_ratio": 1.7676767676767677,
        "end": 997.6999999999999,
        "id": 451,
        "no_speech_prob": 0.00017674383707344532,
        "seek": 97902,
        "start": 994.88,
        "temperature": 0,
        "text": " And I can have a development server and a deployment server.",
        "tokens": [
          51157,
          400,
          286,
          393,
          362,
          257,
          3250,
          7154,
          293,
          257,
          19317,
          7154,
          13,
          51298
        ]
      },
      {
        "avg_logprob": -0.24429798126220703,
        "compression_ratio": 1.7676767676767677,
        "end": 999.74,
        "id": 452,
        "no_speech_prob": 0.00017674383707344532,
        "seek": 97902,
        "start": 997.6999999999999,
        "temperature": 0,
        "text": " And I can go grab a lot of rabbit holes",
        "tokens": [
          51298,
          400,
          286,
          393,
          352,
          4444,
          257,
          688,
          295,
          19509,
          8118,
          51400
        ]
      },
      {
        "avg_logprob": -0.24429798126220703,
        "compression_ratio": 1.7676767676767677,
        "end": 1001.98,
        "id": 453,
        "no_speech_prob": 0.00017674383707344532,
        "seek": 97902,
        "start": 999.74,
        "temperature": 0,
        "text": " there to have a much more complex workflow.",
        "tokens": [
          51400,
          456,
          281,
          362,
          257,
          709,
          544,
          3997,
          20993,
          13,
          51512
        ]
      },
      {
        "avg_logprob": -0.24429798126220703,
        "compression_ratio": 1.7676767676767677,
        "end": 1004.34,
        "id": 454,
        "no_speech_prob": 0.00017674383707344532,
        "seek": 97902,
        "start": 1001.98,
        "temperature": 0,
        "text": " But it's important to realize that GitHub and Heroku are",
        "tokens": [
          51512,
          583,
          309,
          311,
          1021,
          281,
          4325,
          300,
          23331,
          293,
          3204,
          13275,
          366,
          51630
        ]
      },
      {
        "avg_logprob": -0.24429798126220703,
        "compression_ratio": 1.7676767676767677,
        "end": 1007.1,
        "id": 455,
        "no_speech_prob": 0.00017674383707344532,
        "seek": 97902,
        "start": 1004.34,
        "temperature": 0,
        "text": " never talking to each other themselves.",
        "tokens": [
          51630,
          1128,
          1417,
          281,
          1184,
          661,
          2969,
          13,
          51768
        ]
      },
      {
        "avg_logprob": -0.20396384028078035,
        "compression_ratio": 1.7736625514403292,
        "end": 1010.3000000000001,
        "id": 456,
        "no_speech_prob": 0.0012448130873963237,
        "seek": 100710,
        "start": 1007.1,
        "temperature": 0,
        "text": " I am just working on my code here, sending it to GitHub,",
        "tokens": [
          50364,
          286,
          669,
          445,
          1364,
          322,
          452,
          3089,
          510,
          11,
          7750,
          309,
          281,
          23331,
          11,
          50524
        ]
      },
      {
        "avg_logprob": -0.20396384028078035,
        "compression_ratio": 1.7736625514403292,
        "end": 1011.66,
        "id": 457,
        "no_speech_prob": 0.0012448130873963237,
        "seek": 100710,
        "start": 1010.3000000000001,
        "temperature": 0,
        "text": " sending it to Heroku.",
        "tokens": [
          50524,
          7750,
          309,
          281,
          3204,
          13275,
          13,
          50592
        ]
      },
      {
        "avg_logprob": -0.20396384028078035,
        "compression_ratio": 1.7736625514403292,
        "end": 1016.26,
        "id": 458,
        "no_speech_prob": 0.0012448130873963237,
        "seek": 100710,
        "start": 1011.66,
        "temperature": 0,
        "text": " So to finish this off, I'm going to say git push origin master.",
        "tokens": [
          50592,
          407,
          281,
          2413,
          341,
          766,
          11,
          286,
          478,
          516,
          281,
          584,
          18331,
          2944,
          4957,
          4505,
          13,
          50822
        ]
      },
      {
        "avg_logprob": -0.20396384028078035,
        "compression_ratio": 1.7736625514403292,
        "end": 1019.36,
        "id": 459,
        "no_speech_prob": 0.0012448130873963237,
        "seek": 100710,
        "start": 1016.26,
        "temperature": 0,
        "text": " And that's sending it to GitHub.",
        "tokens": [
          50822,
          400,
          300,
          311,
          7750,
          309,
          281,
          23331,
          13,
          50977
        ]
      },
      {
        "avg_logprob": -0.20396384028078035,
        "compression_ratio": 1.7736625514403292,
        "end": 1022.3000000000001,
        "id": 460,
        "no_speech_prob": 0.0012448130873963237,
        "seek": 100710,
        "start": 1019.36,
        "temperature": 0,
        "text": " And if I go here, we can see that it now",
        "tokens": [
          50977,
          400,
          498,
          286,
          352,
          510,
          11,
          321,
          393,
          536,
          300,
          309,
          586,
          51124
        ]
      },
      {
        "avg_logprob": -0.20396384028078035,
        "compression_ratio": 1.7736625514403292,
        "end": 1024.38,
        "id": 461,
        "no_speech_prob": 0.0012448130873963237,
        "seek": 100710,
        "start": 1022.3000000000001,
        "temperature": 0,
        "text": " has the weather is here also.",
        "tokens": [
          51124,
          575,
          264,
          5503,
          307,
          510,
          611,
          13,
          51228
        ]
      },
      {
        "avg_logprob": -0.20396384028078035,
        "compression_ratio": 1.7736625514403292,
        "end": 1025.58,
        "id": 462,
        "no_speech_prob": 0.0012448130873963237,
        "seek": 100710,
        "start": 1024.38,
        "temperature": 0,
        "text": " Everything is in sync.",
        "tokens": [
          51228,
          5471,
          307,
          294,
          20271,
          13,
          51288
        ]
      },
      {
        "avg_logprob": -0.20396384028078035,
        "compression_ratio": 1.7736625514403292,
        "end": 1030.7,
        "id": 463,
        "no_speech_prob": 0.0012448130873963237,
        "seek": 100710,
        "start": 1025.58,
        "temperature": 0,
        "text": " And I have my project deployed to the weather",
        "tokens": [
          51288,
          400,
          286,
          362,
          452,
          1716,
          17826,
          281,
          264,
          5503,
          51544
        ]
      },
      {
        "avg_logprob": -0.20396384028078035,
        "compression_ratio": 1.7736625514403292,
        "end": 1032.54,
        "id": 464,
        "no_speech_prob": 0.0012448130873963237,
        "seek": 100710,
        "start": 1030.7,
        "temperature": 0,
        "text": " here dot Heroku dot app.",
        "tokens": [
          51544,
          510,
          5893,
          3204,
          13275,
          5893,
          724,
          13,
          51636
        ]
      },
      {
        "avg_logprob": -0.20396384028078035,
        "compression_ratio": 1.7736625514403292,
        "end": 1034.88,
        "id": 465,
        "no_speech_prob": 0.0012448130873963237,
        "seek": 100710,
        "start": 1032.54,
        "temperature": 0,
        "text": " And I'll remind you that if you want to go here,",
        "tokens": [
          51636,
          400,
          286,
          603,
          4160,
          291,
          300,
          498,
          291,
          528,
          281,
          352,
          510,
          11,
          51753
        ]
      },
      {
        "avg_logprob": -0.20396384028078035,
        "compression_ratio": 1.7736625514403292,
        "end": 1037.06,
        "id": 466,
        "no_speech_prob": 0.0012448130873963237,
        "seek": 100710,
        "start": 1034.88,
        "temperature": 0,
        "text": " you can base project for the git cloning.",
        "tokens": [
          51753,
          291,
          393,
          3096,
          1716,
          337,
          264,
          18331,
          596,
          16638,
          13,
          51862
        ]
      },
      {
        "avg_logprob": -0.23574147421932784,
        "compression_ratio": 1.7183098591549295,
        "end": 1039.62,
        "id": 467,
        "no_speech_prob": 0.0000047849675866018515,
        "seek": 103706,
        "start": 1037.06,
        "temperature": 0,
        "text": " So I got to clean this up and edit this description.",
        "tokens": [
          50364,
          407,
          286,
          658,
          281,
          2541,
          341,
          493,
          293,
          8129,
          341,
          3855,
          13,
          50492
        ]
      },
      {
        "avg_logprob": -0.23574147421932784,
        "compression_ratio": 1.7183098591549295,
        "end": 1043.26,
        "id": 468,
        "no_speech_prob": 0.0000047849675866018515,
        "seek": 103706,
        "start": 1039.62,
        "temperature": 0,
        "text": " But you can go here to this particular URL.",
        "tokens": [
          50492,
          583,
          291,
          393,
          352,
          510,
          281,
          341,
          1729,
          12905,
          13,
          50674
        ]
      },
      {
        "avg_logprob": -0.23574147421932784,
        "compression_ratio": 1.7183098591549295,
        "end": 1045.86,
        "id": 469,
        "no_speech_prob": 0.0000047849675866018515,
        "seek": 103706,
        "start": 1043.26,
        "temperature": 0,
        "text": " And this is where now you can also find the project,",
        "tokens": [
          50674,
          400,
          341,
          307,
          689,
          586,
          291,
          393,
          611,
          915,
          264,
          1716,
          11,
          50804
        ]
      },
      {
        "avg_logprob": -0.23574147421932784,
        "compression_ratio": 1.7183098591549295,
        "end": 1047.7,
        "id": 470,
        "no_speech_prob": 0.0000047849675866018515,
        "seek": 103706,
        "start": 1045.86,
        "temperature": 0,
        "text": " remix it, take a look at the code,",
        "tokens": [
          50804,
          47788,
          309,
          11,
          747,
          257,
          574,
          412,
          264,
          3089,
          11,
          50896
        ]
      },
      {
        "avg_logprob": -0.23574147421932784,
        "compression_ratio": 1.7183098591549295,
        "end": 1050.74,
        "id": 471,
        "no_speech_prob": 0.0000047849675866018515,
        "seek": 103706,
        "start": 1047.7,
        "temperature": 0,
        "text": " and have it already running online in the browser itself",
        "tokens": [
          50896,
          293,
          362,
          309,
          1217,
          2614,
          2950,
          294,
          264,
          11185,
          2564,
          51048
        ]
      },
      {
        "avg_logprob": -0.23574147421932784,
        "compression_ratio": 1.7183098591549295,
        "end": 1051.8999999999999,
        "id": 472,
        "no_speech_prob": 0.0000047849675866018515,
        "seek": 103706,
        "start": 1050.74,
        "temperature": 0,
        "text": " just through a glitch.",
        "tokens": [
          51048,
          445,
          807,
          257,
          23552,
          13,
          51106
        ]
      },
      {
        "avg_logprob": -0.23574147421932784,
        "compression_ratio": 1.7183098591549295,
        "end": 1053.6599999999999,
        "id": 473,
        "no_speech_prob": 0.0000047849675866018515,
        "seek": 103706,
        "start": 1051.8999999999999,
        "temperature": 0,
        "text": " Thank you so much for watching this whole course.",
        "tokens": [
          51106,
          1044,
          291,
          370,
          709,
          337,
          1976,
          341,
          1379,
          1164,
          13,
          51194
        ]
      },
      {
        "avg_logprob": -0.23574147421932784,
        "compression_ratio": 1.7183098591549295,
        "end": 1055.24,
        "id": 474,
        "no_speech_prob": 0.0000047849675866018515,
        "seek": 103706,
        "start": 1053.6599999999999,
        "temperature": 0,
        "text": " Did you really watch the whole course?",
        "tokens": [
          51194,
          2589,
          291,
          534,
          1159,
          264,
          1379,
          1164,
          30,
          51273
        ]
      },
      {
        "avg_logprob": -0.23574147421932784,
        "compression_ratio": 1.7183098591549295,
        "end": 1056.3,
        "id": 475,
        "no_speech_prob": 0.0000047849675866018515,
        "seek": 103706,
        "start": 1055.24,
        "temperature": 0,
        "text": " If so, I'm quite amazed.",
        "tokens": [
          51273,
          759,
          370,
          11,
          286,
          478,
          1596,
          20507,
          13,
          51326
        ]
      },
      {
        "avg_logprob": -0.23574147421932784,
        "compression_ratio": 1.7183098591549295,
        "end": 1057.62,
        "id": 476,
        "no_speech_prob": 0.0000047849675866018515,
        "seek": 103706,
        "start": 1056.3,
        "temperature": 0,
        "text": " I mean, maybe this isn't the end.",
        "tokens": [
          51326,
          286,
          914,
          11,
          1310,
          341,
          1943,
          380,
          264,
          917,
          13,
          51392
        ]
      },
      {
        "avg_logprob": -0.23574147421932784,
        "compression_ratio": 1.7183098591549295,
        "end": 1058.78,
        "id": 477,
        "no_speech_prob": 0.0000047849675866018515,
        "seek": 103706,
        "start": 1057.62,
        "temperature": 0,
        "text": " Maybe in the future, there'll actually",
        "tokens": [
          51392,
          2704,
          294,
          264,
          2027,
          11,
          456,
          603,
          767,
          51450
        ]
      },
      {
        "avg_logprob": -0.23574147421932784,
        "compression_ratio": 1.7183098591549295,
        "end": 1060.12,
        "id": 478,
        "no_speech_prob": 0.0000047849675866018515,
        "seek": 103706,
        "start": 1058.78,
        "temperature": 0,
        "text": " be some videos that follow this.",
        "tokens": [
          51450,
          312,
          512,
          2145,
          300,
          1524,
          341,
          13,
          51517
        ]
      },
      {
        "avg_logprob": -0.23574147421932784,
        "compression_ratio": 1.7183098591549295,
        "end": 1062.22,
        "id": 479,
        "no_speech_prob": 0.0000047849675866018515,
        "seek": 103706,
        "start": 1060.12,
        "temperature": 0,
        "text": " But right now, this is where I'm finishing up.",
        "tokens": [
          51517,
          583,
          558,
          586,
          11,
          341,
          307,
          689,
          286,
          478,
          12693,
          493,
          13,
          51622
        ]
      },
      {
        "avg_logprob": -0.23574147421932784,
        "compression_ratio": 1.7183098591549295,
        "end": 1063.94,
        "id": 480,
        "no_speech_prob": 0.0000047849675866018515,
        "seek": 103706,
        "start": 1062.22,
        "temperature": 0,
        "text": " By watching this course, you've hopefully",
        "tokens": [
          51622,
          3146,
          1976,
          341,
          1164,
          11,
          291,
          600,
          4696,
          51708
        ]
      },
      {
        "avg_logprob": -0.23574147421932784,
        "compression_ratio": 1.7183098591549295,
        "end": 1065.5,
        "id": 481,
        "no_speech_prob": 0.0000047849675866018515,
        "seek": 103706,
        "start": 1063.94,
        "temperature": 0,
        "text": " added something new to your toolbox.",
        "tokens": [
          51708,
          3869,
          746,
          777,
          281,
          428,
          44593,
          13,
          51786
        ]
      },
      {
        "avg_logprob": -0.23219050917514536,
        "compression_ratio": 1.6815068493150684,
        "end": 1067.14,
        "id": 482,
        "no_speech_prob": 0.005468917544931173,
        "seek": 106550,
        "start": 1065.5,
        "temperature": 0,
        "text": " Even just from the client side, you've",
        "tokens": [
          50364,
          2754,
          445,
          490,
          264,
          6423,
          1252,
          11,
          291,
          600,
          50446
        ]
      },
      {
        "avg_logprob": -0.23219050917514536,
        "compression_ratio": 1.6815068493150684,
        "end": 1069.1,
        "id": 483,
        "no_speech_prob": 0.005468917544931173,
        "seek": 106550,
        "start": 1067.14,
        "temperature": 0,
        "text": " learned how to work with the Fetch Wipe API,",
        "tokens": [
          50446,
          3264,
          577,
          281,
          589,
          365,
          264,
          479,
          7858,
          343,
          6527,
          9362,
          11,
          50544
        ]
      },
      {
        "avg_logprob": -0.23219050917514536,
        "compression_ratio": 1.6815068493150684,
        "end": 1071.42,
        "id": 484,
        "no_speech_prob": 0.005468917544931173,
        "seek": 106550,
        "start": 1069.1,
        "temperature": 0,
        "text": " loading a CSV file, graphing it.",
        "tokens": [
          50544,
          15114,
          257,
          48814,
          3991,
          11,
          1295,
          79,
          571,
          309,
          13,
          50660
        ]
      },
      {
        "avg_logprob": -0.23219050917514536,
        "compression_ratio": 1.6815068493150684,
        "end": 1073.98,
        "id": 485,
        "no_speech_prob": 0.005468917544931173,
        "seek": 106550,
        "start": 1071.42,
        "temperature": 0,
        "text": " Hopefully, you've also learned something about how",
        "tokens": [
          50660,
          10429,
          11,
          291,
          600,
          611,
          3264,
          746,
          466,
          577,
          50788
        ]
      },
      {
        "avg_logprob": -0.23219050917514536,
        "compression_ratio": 1.6815068493150684,
        "end": 1076.5,
        "id": 486,
        "no_speech_prob": 0.005468917544931173,
        "seek": 106550,
        "start": 1073.98,
        "temperature": 0,
        "text": " the basics of JavaScript, knowing how JavaScript objects",
        "tokens": [
          50788,
          264,
          14688,
          295,
          15778,
          11,
          5276,
          577,
          15778,
          6565,
          50914
        ]
      },
      {
        "avg_logprob": -0.23219050917514536,
        "compression_ratio": 1.6815068493150684,
        "end": 1080.18,
        "id": 487,
        "no_speech_prob": 0.005468917544931173,
        "seek": 106550,
        "start": 1076.5,
        "temperature": 0,
        "text": " works, leads you to understand how JSON data, data",
        "tokens": [
          50914,
          1985,
          11,
          6689,
          291,
          281,
          1223,
          577,
          31828,
          1412,
          11,
          1412,
          51098
        ]
      },
      {
        "avg_logprob": -0.23219050917514536,
        "compression_ratio": 1.6815068493150684,
        "end": 1082.82,
        "id": 488,
        "no_speech_prob": 0.005468917544931173,
        "seek": 106550,
        "start": 1080.18,
        "temperature": 0,
        "text": " in JSON format, JavaScript object notation works.",
        "tokens": [
          51098,
          294,
          31828,
          7877,
          11,
          15778,
          2657,
          24657,
          1985,
          13,
          51230
        ]
      },
      {
        "avg_logprob": -0.23219050917514536,
        "compression_ratio": 1.6815068493150684,
        "end": 1087.02,
        "id": 489,
        "no_speech_prob": 0.005468917544931173,
        "seek": 106550,
        "start": 1082.82,
        "temperature": 0,
        "text": " And you can make a call to an external API, get information,",
        "tokens": [
          51230,
          400,
          291,
          393,
          652,
          257,
          818,
          281,
          364,
          8320,
          9362,
          11,
          483,
          1589,
          11,
          51440
        ]
      },
      {
        "avg_logprob": -0.23219050917514536,
        "compression_ratio": 1.6815068493150684,
        "end": 1089.06,
        "id": 490,
        "no_speech_prob": 0.005468917544931173,
        "seek": 106550,
        "start": 1087.02,
        "temperature": 0,
        "text": " and use that information, repurpose it",
        "tokens": [
          51440,
          293,
          764,
          300,
          1589,
          11,
          1085,
          31345,
          309,
          51542
        ]
      },
      {
        "avg_logprob": -0.23219050917514536,
        "compression_ratio": 1.6815068493150684,
        "end": 1090.74,
        "id": 491,
        "no_speech_prob": 0.005468917544931173,
        "seek": 106550,
        "start": 1089.06,
        "temperature": 0,
        "text": " in a web page itself.",
        "tokens": [
          51542,
          294,
          257,
          3670,
          3028,
          2564,
          13,
          51626
        ]
      },
      {
        "avg_logprob": -0.23219050917514536,
        "compression_ratio": 1.6815068493150684,
        "end": 1093.46,
        "id": 492,
        "no_speech_prob": 0.005468917544931173,
        "seek": 106550,
        "start": 1090.74,
        "temperature": 0,
        "text": " Then more importantly, hopefully now you've",
        "tokens": [
          51626,
          1396,
          544,
          8906,
          11,
          4696,
          586,
          291,
          600,
          51762
        ]
      },
      {
        "avg_logprob": -0.22774716743133352,
        "compression_ratio": 1.7678018575851393,
        "end": 1096.26,
        "id": 493,
        "no_speech_prob": 0.06278456002473831,
        "seek": 109346,
        "start": 1093.46,
        "temperature": 0,
        "text": " realized that server-side programming is something",
        "tokens": [
          50364,
          5334,
          300,
          7154,
          12,
          1812,
          9410,
          307,
          746,
          50504
        ]
      },
      {
        "avg_logprob": -0.22774716743133352,
        "compression_ratio": 1.7678018575851393,
        "end": 1097.66,
        "id": 494,
        "no_speech_prob": 0.06278456002473831,
        "seek": 109346,
        "start": 1096.26,
        "temperature": 0,
        "text": " that you can add to your toolbox.",
        "tokens": [
          50504,
          300,
          291,
          393,
          909,
          281,
          428,
          44593,
          13,
          50574
        ]
      },
      {
        "avg_logprob": -0.22774716743133352,
        "compression_ratio": 1.7678018575851393,
        "end": 1100.1000000000001,
        "id": 495,
        "no_speech_prob": 0.06278456002473831,
        "seek": 109346,
        "start": 1097.66,
        "temperature": 0,
        "text": " You can use it to save data to a database.",
        "tokens": [
          50574,
          509,
          393,
          764,
          309,
          281,
          3155,
          1412,
          281,
          257,
          8149,
          13,
          50696
        ]
      },
      {
        "avg_logprob": -0.22774716743133352,
        "compression_ratio": 1.7678018575851393,
        "end": 1102.1000000000001,
        "id": 496,
        "no_speech_prob": 0.06278456002473831,
        "seek": 109346,
        "start": 1100.1000000000001,
        "temperature": 0,
        "text": " You can use it to hide API keys.",
        "tokens": [
          50696,
          509,
          393,
          764,
          309,
          281,
          6479,
          9362,
          9317,
          13,
          50796
        ]
      },
      {
        "avg_logprob": -0.22774716743133352,
        "compression_ratio": 1.7678018575851393,
        "end": 1103.5,
        "id": 497,
        "no_speech_prob": 0.06278456002473831,
        "seek": 109346,
        "start": 1102.1000000000001,
        "temperature": 0,
        "text": " There's so much more that you can",
        "tokens": [
          50796,
          821,
          311,
          370,
          709,
          544,
          300,
          291,
          393,
          50866
        ]
      },
      {
        "avg_logprob": -0.22774716743133352,
        "compression_ratio": 1.7678018575851393,
        "end": 1105.38,
        "id": 498,
        "no_speech_prob": 0.06278456002473831,
        "seek": 109346,
        "start": 1103.5,
        "temperature": 0,
        "text": " do with server-side programming in terms",
        "tokens": [
          50866,
          360,
          365,
          7154,
          12,
          1812,
          9410,
          294,
          2115,
          50960
        ]
      },
      {
        "avg_logprob": -0.22774716743133352,
        "compression_ratio": 1.7678018575851393,
        "end": 1108.54,
        "id": 499,
        "no_speech_prob": 0.06278456002473831,
        "seek": 109346,
        "start": 1105.38,
        "temperature": 0,
        "text": " of being able to have multiple applications communicate",
        "tokens": [
          50960,
          295,
          885,
          1075,
          281,
          362,
          3866,
          5821,
          7890,
          51118
        ]
      },
      {
        "avg_logprob": -0.22774716743133352,
        "compression_ratio": 1.7678018575851393,
        "end": 1110.38,
        "id": 500,
        "no_speech_prob": 0.06278456002473831,
        "seek": 109346,
        "start": 1108.54,
        "temperature": 0,
        "text": " to each other across the network.",
        "tokens": [
          51118,
          281,
          1184,
          661,
          2108,
          264,
          3209,
          13,
          51210
        ]
      },
      {
        "avg_logprob": -0.22774716743133352,
        "compression_ratio": 1.7678018575851393,
        "end": 1112.8600000000001,
        "id": 501,
        "no_speech_prob": 0.06278456002473831,
        "seek": 109346,
        "start": 1110.38,
        "temperature": 0,
        "text": " So I hope this is just the beginning for you.",
        "tokens": [
          51210,
          407,
          286,
          1454,
          341,
          307,
          445,
          264,
          2863,
          337,
          291,
          13,
          51334
        ]
      },
      {
        "avg_logprob": -0.22774716743133352,
        "compression_ratio": 1.7678018575851393,
        "end": 1114.3,
        "id": 502,
        "no_speech_prob": 0.06278456002473831,
        "seek": 109346,
        "start": 1112.8600000000001,
        "temperature": 0,
        "text": " Let me know what kind of questions",
        "tokens": [
          51334,
          961,
          385,
          458,
          437,
          733,
          295,
          1651,
          51406
        ]
      },
      {
        "avg_logprob": -0.22774716743133352,
        "compression_ratio": 1.7678018575851393,
        "end": 1115.94,
        "id": 503,
        "no_speech_prob": 0.06278456002473831,
        "seek": 109346,
        "start": 1114.3,
        "temperature": 0,
        "text": " you have in the comments.",
        "tokens": [
          51406,
          291,
          362,
          294,
          264,
          3053,
          13,
          51488
        ]
      },
      {
        "avg_logprob": -0.22774716743133352,
        "compression_ratio": 1.7678018575851393,
        "end": 1117.8600000000001,
        "id": 504,
        "no_speech_prob": 0.06278456002473831,
        "seek": 109346,
        "start": 1115.94,
        "temperature": 0,
        "text": " If you make a project, if you've made one",
        "tokens": [
          51488,
          759,
          291,
          652,
          257,
          1716,
          11,
          498,
          291,
          600,
          1027,
          472,
          51584
        ]
      },
      {
        "avg_logprob": -0.22774716743133352,
        "compression_ratio": 1.7678018575851393,
        "end": 1120.66,
        "id": 505,
        "no_speech_prob": 0.06278456002473831,
        "seek": 109346,
        "start": 1117.8600000000001,
        "temperature": 0,
        "text": " and you've deployed it, go to thecodingtrain.com,",
        "tokens": [
          51584,
          293,
          291,
          600,
          17826,
          309,
          11,
          352,
          281,
          264,
          66,
          8616,
          83,
          7146,
          13,
          1112,
          11,
          51724
        ]
      },
      {
        "avg_logprob": -0.22774716743133352,
        "compression_ratio": 1.7678018575851393,
        "end": 1123.08,
        "id": 506,
        "no_speech_prob": 0.06278456002473831,
        "seek": 109346,
        "start": 1120.66,
        "temperature": 0,
        "text": " where I'll have a page that you can share URLs",
        "tokens": [
          51724,
          689,
          286,
          603,
          362,
          257,
          3028,
          300,
          291,
          393,
          2073,
          43267,
          51845
        ]
      },
      {
        "avg_logprob": -0.2983749906222026,
        "compression_ratio": 1.5471698113207548,
        "end": 1125.56,
        "id": 507,
        "no_speech_prob": 0.001098628737963736,
        "seek": 112308,
        "start": 1123.1999999999998,
        "temperature": 0,
        "text": " to projects that you've made and deployed.",
        "tokens": [
          50370,
          281,
          4455,
          300,
          291,
          600,
          1027,
          293,
          17826,
          13,
          50488
        ]
      },
      {
        "avg_logprob": -0.2983749906222026,
        "compression_ratio": 1.5471698113207548,
        "end": 1128.32,
        "id": 508,
        "no_speech_prob": 0.001098628737963736,
        "seek": 112308,
        "start": 1125.56,
        "temperature": 0,
        "text": " And in particular, if you found a web service, a web hosting",
        "tokens": [
          50488,
          400,
          294,
          1729,
          11,
          498,
          291,
          1352,
          257,
          3670,
          2643,
          11,
          257,
          3670,
          16058,
          50626
        ]
      },
      {
        "avg_logprob": -0.2983749906222026,
        "compression_ratio": 1.5471698113207548,
        "end": 1130.52,
        "id": 509,
        "no_speech_prob": 0.001098628737963736,
        "seek": 112308,
        "start": 1128.32,
        "temperature": 0,
        "text": " service that you like to deploy your project,",
        "tokens": [
          50626,
          2643,
          300,
          291,
          411,
          281,
          7274,
          428,
          1716,
          11,
          50736
        ]
      },
      {
        "avg_logprob": -0.2983749906222026,
        "compression_ratio": 1.5471698113207548,
        "end": 1132.08,
        "id": 510,
        "no_speech_prob": 0.001098628737963736,
        "seek": 112308,
        "start": 1130.52,
        "temperature": 0,
        "text": " I would love to hear about it as well.",
        "tokens": [
          50736,
          286,
          576,
          959,
          281,
          1568,
          466,
          309,
          382,
          731,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2983749906222026,
        "compression_ratio": 1.5471698113207548,
        "end": 1133.36,
        "id": 511,
        "no_speech_prob": 0.001098628737963736,
        "seek": 112308,
        "start": 1132.08,
        "temperature": 0,
        "text": " So thanks so much for watching.",
        "tokens": [
          50814,
          407,
          3231,
          370,
          709,
          337,
          1976,
          13,
          50878
        ]
      },
      {
        "avg_logprob": -0.2983749906222026,
        "compression_ratio": 1.5471698113207548,
        "end": 1135.52,
        "id": 512,
        "no_speech_prob": 0.001098628737963736,
        "seek": 112308,
        "start": 1133.36,
        "temperature": 0,
        "text": " Hope you enjoyed this whole set of videos.",
        "tokens": [
          50878,
          6483,
          291,
          4626,
          341,
          1379,
          992,
          295,
          2145,
          13,
          50986
        ]
      },
      {
        "avg_logprob": -0.2983749906222026,
        "compression_ratio": 1.5471698113207548,
        "end": 1138.3999999999999,
        "id": 513,
        "no_speech_prob": 0.001098628737963736,
        "seek": 112308,
        "start": 1135.52,
        "temperature": 0,
        "text": " And I'll see you in future Coding Train stuff.",
        "tokens": [
          50986,
          400,
          286,
          603,
          536,
          291,
          294,
          2027,
          383,
          8616,
          28029,
          1507,
          13,
          51130
        ]
      },
      {
        "avg_logprob": -0.2983749906222026,
        "compression_ratio": 1.5471698113207548,
        "end": 1139,
        "id": 514,
        "no_speech_prob": 0.001098628737963736,
        "seek": 112308,
        "start": 1138.3999999999999,
        "temperature": 0,
        "text": " Goodbye.",
        "tokens": [
          51130,
          15528,
          13,
          51160
        ]
      },
      {
        "avg_logprob": -0.2983749906222026,
        "compression_ratio": 1.5471698113207548,
        "end": 1139.6,
        "id": 515,
        "no_speech_prob": 0.001098628737963736,
        "seek": 112308,
        "start": 1139,
        "temperature": 0,
        "text": " Bye-bye.",
        "tokens": [
          51160,
          4621,
          12,
          6650,
          13,
          51190
        ]
      },
      {
        "avg_logprob": -0.9921564261118571,
        "compression_ratio": 0.5555555555555556,
        "end": 1141.28,
        "id": 516,
        "no_speech_prob": 0.8570675849914551,
        "seek": 113960,
        "start": 1139.6,
        "temperature": 0,
        "text": " Thank you.",
        "tokens": [
          50370,
          1044,
          291,
          13,
          50448
        ]
      }
    ],
    "transcription": " Welcome to another Working With Data and APIs video. I have one more thing to demonstrate to you. I mean, the truth of the matter is there's probably hundreds, thousands, tens of thousands, millions of things that I've missed that I should cover, that I could get to, that I don't even know about, that I will hear from you. And so I look forward to hearing all about in the comments and hopefully returning and making more videos that continue these projects and this discussion. But before I go, at least in this first round of what I'm making right now, I want to show you one thing, how to deploy your project to a server, put it out in the world so that people could access and use it. There's an inherent problem with me even making this video, because there's no one way to do this. I mean, you could build your own server, get your own internet connection, get an IP address, create your own web server on a Raspberry Pi even, put it somewhere out in the forest wirelessly, who knows, attach it to a space station. But what I want to look for here, at least I want to look at least two scenarios of using a commercial hosting service that allows you to deploy your node code and have it run somewhere and will give you a URL so that you can actually see it in the browser. And the two services I want to show you are Glitch and Heroku. Glitch, as it says on their website, is the friendly community where you'll find the app of your dreams. I love Glitch. It's an amazing code editor in the browser that you can write node code, client JavaScript. You can build all sorts of apps. You can share them. You can remix them. It's colorful. It's friendly. You can ask for help. There's so much there in Glitch. And honestly, I could imagine a version of these tutorials where I just started with the first day opening up Glitch and building the project there. But since I've already built the project, I'm going to show you how to import it right into Glitch and run it there. After that, I'm going to show you another service called Heroku. It's a cloud platform that lets you deploy web applications. It has a pretty reasonable free tier that I can get up and running with easily. This is not sponsored content. There are lots of other services that I've used. Amazon Web Services, Digital Ocean, are just a couple to name a few. And I'm happy to come back and show some other ones in a video as well if that might be something useful. Or leave in the comments what type of cloud server you like to deploy your applications on. There's also this thing called serverless programming. Oh, we'll come back to that another time. Let's start off here with Glitch. So here I am logged into my Glitch account. My Glitch account is actually linked to my GitHub account, although you don't need a GitHub account to sign up and start working with Glitch. I could make a new project. And I could actually make a blank project. Hello, Express. This would have been a good place for me to start when I was back in the day. I didn't have anything yet. I could just make a new simple Express app and build on top of that. But I'm going to do something a little bit different. I'm going to use this clone from Git repo. Since I've already gone through all the motions of writing my code locally on the computer and then pushing it to GitHub, I could just grab it and put it here. But before I do that, I better make one more change. There's something that I missed that's rather important. So in my code, I have hard coded in here the port 3000. That's the port that I'm arbitrarily choosing to run and test the stuff locally on this computer. But any type of web hosting platform is probably going to generate a port automatically. And there are some standard ports for hosting up a website. So I actually want to pull that from the environment variable. And this will be maybe an environment variable that I don't actually set, but that already comes with the platform. So not necessarily something that I put in here, but something that's just going to be present whenever I'm on that platform itself. So let me go back to the code. And let me add a const port equals process.env.port. Now here's the thing. Now when I run this, and I'm going to put this port here. And I'm going to just change the string to starting server at, and then I'm just going to say port. So this is some changes I made to the code. OK. So here's the thing. This now, if I go and try to run this locally, boom. A port number. Or do I actually have another error? Oh, that's a different error. I've got some syntax error. Let me fix that. Always getting syntax errors. Oh, I don't know. I lost my curly brackets. I'm not sure what I did here. There we go. Yes. Listen at that port, and then I log starting the server at that port. Sorry about that. Let's try that again. Starting server at undefined. So I don't even know, how would I possibly, there's no port. I can't access the server. So this is where I can do something nice. If there is no port in an environment variable or 3,000. So now, if I run the server again, it's starting at 3,000. I can go back and look at the project running locally at port 3,000. And here it is. OK, but that's not, I needed to do this, because I now want Glitch to take care of the port for me. I don't want to be in charge of that. Now, since I'm going to be getting the code from GitHub onto Glitch, I need to make sure I take that change. I thought I just made it locally, and push it onto GitHub. Woo! So I'm going to add, and I'm going to commit port from environment variable. And then I'm going to say git push origin master, which sends it up to GitHub itself. This is getting a little bit confusing, so let's make a quick diagram just to understand the pieces. So I've got my laptop here. And so I've been writing all the code here, the server and the client. Now what I've done is I have now taken all that code, and I have put it onto GitHub. And these are now linked. I can always push, which is sending code this way, or I can pull, which is sending code this way. So this is really the thing that I've set up. But I want to add a third component here. So that third component, I'm going to add Glitch as one. And I'm also going to show you, I'm also eventually going to add Heroku. Now, the difference with Glitch and Heroku is this is actually a code editor. So once I get the code from GitHub and place it onto Glitch, this is kind of a connection that doesn't need to persist. Then I could just, it's just there. I can work on it. I just want a quick way of getting the stuff on Glitch. I could have uploaded my files or copy-paste or been working there all along. But something different will happen once I put it on Heroku, which I will keep all of these things linked so I can continue to do the development here on my laptop and push those changes through. So let's come back to Glitch. And let's click on this button, Clone from a Git Repo. And then I'm going to go over to my repo. I'm going to copy the URL. And I'm going to, whoop, I'm going to press that button again. And I'm going to go over here and paste it in. So I am grabbing all the code from coding train slash the weather here. And I'm going to hit OK. And I'm going to wait for a little bit. And look at that. Look at this. Everything is there. Public check-ins, public logs, public index, public sketch, public style, git ignore index, pack it up. Ooh, environment sample. Aha. So remember, I need my API key. So before I even try to run this, what I'm going to do now is I'm going to hit Rename. And I'm going to change this to just.env. So now you can see it's got a key there. Glitch knows. Glitch really knows that.env files are secret files. So if someone chooses to remix this project or based on it, if I'm sharing this, no one will be able to see the API key in there. I'm going to go. And I'm going to go back to my code where I have my.env file, grab this API key, paste it in here, hit Save. And then I'm going to click on this Show button. And so now I can choose to show in a new window or right next to the code. Let's just look at it right next to the code. There it is. There's my project. Now let's click on Show and go in a new window. And look at this. If you go to coding-the-weather-here.glitch.me, you have the project. And I can go back here. And I can start saying, hey, let's go to Berlin and check in. And let's go to London and check in. Let's go to San Francisco and check in. Let's view check-ins. And all of those check-ins are here. And in fact, I don't know what this is going to look like now when you go to it. I assume I'm going to leave this here as is. And lots of other people have gone there and added their check-ins. So we can see all of that. And you'll see that if you go to that URL right now. And to be clear, remember, this is a code editor. So I can start changing stuff. I can go to this index.html page. And I can say the weather is here. And you can see that immediately updated. I can change something in the server. I don't know. I'm afraid to change things in the server. But I can start working on the server code. It's all very, very small here. I could change that. And stuff would change. The server would rerun itself automatically. So again, I would love to come back and revisit more videos about how Glitch works itself. Now that this project is there, I would encourage you to go to the URL. It'll be in the video's description and click Remix Project. You don't even have to do any of this stuff because once I have it deployed on Glitch, other people can get the code and make their own version of it. So I'll include this as an example that you can start with. And I probably shouldn't mention that. I should have mentioned that earlier. Oh, well. Let's try one more deployment just so we can see how another system works. So now I'm going to show you Heroku. Heroku has its own CLI, which stands for Command Line Interface. So you can actually do things and deploy projects just from your terminal application itself. So you're going to need to first install the Heroku CLI. I've done that already. But you can download and install for Mac OS. Or you can download and install for Windows or Ubuntu, whatever your operating system is. You'll know that you have the CLI installed if you can type Heroku into the command line and see it doesn't say, I don't know what that is. So one of the things I want to do is type in Heroku login. So I've already signed up for a Heroku account. So you'll have to have done that if you're going to follow along with these instructions. It's going to ask me to press any key. It's going to open up the browser. It's going to ask me to log in. I'm already logged in. I've already logged in. We can go back to the terminal. And we can see that I've logged in now. Once I'm logged in in terminal, I need to create a new app. So I could go to my Heroku dashboard at this URL. And then I can just click here and say new, create new app. So I'm going to create an app called the weather here. The weather here is available. I'm going to hit create app. And then look at this. This is so perfect. It's kind of given me everything I need to do. I need to do Heroku login, which I've already done. I've already created a Git repository, so I don't need to worry about any of this. But now I just need to add Heroku as a remote. So I'm going to go back to terminal here. I'm going to say git remote. I'm going to say git remote dash v. So this is listing me the current remotes. And the only current remote is called origin. And it's at github.com. I want to add another remote by copying and pasting this command right here. I'm going to paste that in. OK, I've got another remote. If I say git remote dash v, we can see, aha, I have the Heroku remote and the origin remote. What's next? Now I'm going to say, actually, I If I made any changes to the code, I would need to do git add and git commit. But all I need to do is now deploy it. To deploy it to Heroku, I say git push Heroku master. I'm sure I've forgotten something. Let's see what happens. It's going to run through a bunch of things, building the project. And it's deployed. So I can click on this and open it in the browser. And look, there it is. So it's working. It's deployed, but I don't see temperature. If I go to view check-ins, there's nothing added to the database. So something's not working. It's deployed, but it's not working. Aha. Do you remember? I remember. So the thing that I missed is, once again, the API key. So this environment file did not make it to Heroku. And actually, in this case, with Heroku, I don't need a.env file. I don't actually even need that npm package.env, because the Heroku command line interface lets me set environment variables directly. So I can go back to the terminal. And I can type to Heroku config. And Heroku config is going to show me all of my environment variables, of which there are none. So I can now say Heroku config colon set API underscore key equals. Go back to my code. Grab this. Paste that in. Hit Enter. It's setting the API key. And it's even restarting the app for me. So nice of it to do that for me. Let's just check Heroku config again. You can see that's my environment variable. It's not found anywhere other than here. It's saved secretly. And I can hit Refresh. And there we go. Now I've got the temperature. Once again, I can go to Mountain View. I can hit Refresh to check in. I can go to San Francisco. I can check in again. Ooh. I can go to Sao Paolo. I can check in again. I can view all my check-ins. And there they are. Everything is here. And the app is working. Kind of can't believe this actually worked. And in many ways, I'm done with this series. I'm not done. That's the thing I already discussed. But there is some important stuff I need to talk about. Number one, where's the database again? Look at these three check-ins here. And I'm at theweatherhere.herokuapp.com. Let me now go to codingtrain dash theweatherhere.glitch.me. And let's look at those check-ins. There's like seven of them. Over here on the Heroku one, there's four of them. They're not sharing a database. This is very important. Remember, the server is the holder of the database. So you wouldn't want to deploy this to multiple places. I'm just kind of showing you how that works. But that database is something that is created from the server side itself. And it's different than I could be running this locally here. I'm not running the server right now. But I could still say node index.js. And I've got whatever data I happen to have here locally. So I could take that database.db file and pass it around. But that's not what I'm doing here. So ultimately, what I think of is I would have a local database for testing purposes. And once I've deployed it, that database will persist forever. Of course, I might want to wipe it for every reason. And again, I'm just sort of tinkering around here. But where the database lives, where the app lives is quite important. There's also the question, if I wanted to continue to work on this, if I'm on Glitch, Glitch is a whole code editor itself. So I can kind of continue and play and work there. But if I wanted to make a change on Heroku, how would I do that? So to do that, I've got to now go through multiple steps. I first would come here to my local code. And just to make the simplest change possible, I'm just going to change and say, like, the weather is here, just as, like, the header. Then I would have to go back to my terminal. I've got to commit that, making a change to demonstrate deploy to Heroku. I'm going to make that change. And then I'm going to say git push Heroku master. And this will now automatically rebuild and restart the app. Heroku knows to do that automatically when you try to send it revised code. But it only can send it revised code if it's been committed to Git. I can go back to the browser. I'm on Heroku. I can click on Check In. And you can see, aha, is is there now. I've added is. Now, interestingly enough, if I go here onto GitHub and I go into public index.html, it still just says the weather here. Let's return to this simple diagram for a second to think about this. So I'm working on the code. This is my local dev environment. Then I can push my code up to GitHub, really just as a way of backing it up or releasing it to open source or collaborating with other people who might want to work on it as well. I can pull changes from GitHub if other people are sharing and implementing things. But that's kind of beyond the scope of what I'm doing here. But now I've added Heroku. So what's important to realize, unlike with Glitch, when I kind of like from Glitch grab the code from GitHub, I'm actually also pushing the code here to Heroku. So this is where I'm working on it. When I push it to Heroku, it rebuilds the server. So this is important. That's like a deployment thing. So as I'm developing it, I might just test it locally, push to GitHub to publish the code. And then when I'm ready, actually push it to Heroku. And I can have a development server and a deployment server. And I can go grab a lot of rabbit holes there to have a much more complex workflow. But it's important to realize that GitHub and Heroku are never talking to each other themselves. I am just working on my code here, sending it to GitHub, sending it to Heroku. So to finish this off, I'm going to say git push origin master. And that's sending it to GitHub. And if I go here, we can see that it now has the weather is here also. Everything is in sync. And I have my project deployed to the weather here dot Heroku dot app. And I'll remind you that if you want to go here, you can base project for the git cloning. So I got to clean this up and edit this description. But you can go here to this particular URL. And this is where now you can also find the project, remix it, take a look at the code, and have it already running online in the browser itself just through a glitch. Thank you so much for watching this whole course. Did you really watch the whole course? If so, I'm quite amazed. I mean, maybe this isn't the end. Maybe in the future, there'll actually be some videos that follow this. But right now, this is where I'm finishing up. By watching this course, you've hopefully added something new to your toolbox. Even just from the client side, you've learned how to work with the Fetch Wipe API, loading a CSV file, graphing it. Hopefully, you've also learned something about how the basics of JavaScript, knowing how JavaScript objects works, leads you to understand how JSON data, data in JSON format, JavaScript object notation works. And you can make a call to an external API, get information, and use that information, repurpose it in a web page itself. Then more importantly, hopefully now you've realized that server-side programming is something that you can add to your toolbox. You can use it to save data to a database. You can use it to hide API keys. There's so much more that you can do with server-side programming in terms of being able to have multiple applications communicate to each other across the network. So I hope this is just the beginning for you. Let me know what kind of questions you have in the comments. If you make a project, if you've made one and you've deployed it, go to thecodingtrain.com, where I'll have a page that you can share URLs to projects that you've made and deployed. And in particular, if you found a web service, a web hosting service that you like to deploy your project, I would love to hear about it as well. So thanks so much for watching. Hope you enjoyed this whole set of videos. And I'll see you in future Coding Train stuff. Goodbye. Bye-bye. Thank you.",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:03:35.313413Z",
  "started_at": "2023-09-26T21:15:30.848089Z",
  "completed_at": "2023-09-26T21:21:15.487658Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=Rz886HkV1j4",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 344.639569
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/5zq2qxrbqwhvsaldzvthmu7z4q/cancel",
    "get": "https://api.replicate.com/v1/predictions/5zq2qxrbqwhvsaldzvthmu7z4q"
  }
}