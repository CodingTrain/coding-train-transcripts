{
  "id": "jasiy2bbpyhwtnuse2du3ody4m",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/lCzB9V9L8d0.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/776131 [00:00<?, ?frames/s]\n  0%|          | 2268/776131 [00:02<15:01, 858.55frames/s]\n  1%|          | 5172/776131 [00:07<18:23, 698.38frames/s]\n  1%|          | 7396/776131 [00:14<27:21, 468.18frames/s]\n  1%|▏         | 10236/776131 [00:16<20:41, 617.04frames/s]\n  2%|▏         | 12836/776131 [00:22<22:53, 555.81frames/s]\n  2%|▏         | 15700/776131 [00:30<27:25, 462.06frames/s]\n  2%|▏         | 18468/776131 [00:39<32:34, 387.63frames/s]\n  3%|▎         | 21228/776131 [00:45<30:24, 413.86frames/s]\n  3%|▎         | 24004/776131 [00:52<31:07, 402.81frames/s]\n  3%|▎         | 26612/776131 [00:59<31:51, 392.17frames/s]\n  4%|▍         | 29588/776131 [01:08<32:29, 382.96frames/s]\n  4%|▍         | 32412/776131 [01:14<30:56, 400.58frames/s]\n  5%|▍         | 35332/776131 [01:23<32:41, 377.63frames/s]\n  5%|▍         | 38252/776131 [01:31<33:27, 367.58frames/s]\n  5%|▌         | 40636/776131 [01:38<33:31, 365.60frames/s]\n  6%|▌         | 43212/776131 [01:44<32:16, 378.40frames/s]\n  6%|▌         | 45980/776131 [01:51<31:53, 381.60frames/s]\n  6%|▋         | 48780/776131 [01:59<32:28, 373.21frames/s]\n  7%|▋         | 51652/776131 [02:07<32:46, 368.37frames/s]\n  7%|▋         | 54652/776131 [02:12<28:25, 423.05frames/s]\n  7%|▋         | 57596/776131 [02:22<32:52, 364.34frames/s]\n  8%|▊         | 60548/776131 [02:28<29:43, 401.19frames/s]\n  8%|▊         | 63516/776131 [02:35<29:14, 406.22frames/s]\n  9%|▊         | 66516/776131 [02:44<31:22, 376.92frames/s]\n  9%|▉         | 69380/776131 [02:52<31:20, 375.79frames/s]\n  9%|▉         | 72220/776131 [02:57<28:04, 417.91frames/s]\n 10%|▉         | 75132/776131 [03:04<27:44, 421.06frames/s]\n 10%|█         | 77940/776131 [03:14<31:51, 365.27frames/s]\n 10%|█         | 80924/776131 [03:23<32:38, 355.00frames/s]\n 11%|█         | 83420/776131 [03:33<35:49, 322.33frames/s]\n 11%|█         | 86340/776131 [03:41<34:37, 331.97frames/s]\n 12%|█▏        | 89340/776131 [03:46<30:32, 374.83frames/s]\n 12%|█▏        | 89340/776131 [03:58<30:32, 374.83frames/s]\n 12%|█▏        | 92244/776131 [04:19<59:17, 192.22frames/s]\n 12%|█▏        | 95188/776131 [04:25<48:55, 231.97frames/s]\n 13%|█▎        | 97876/776131 [04:30<40:00, 282.52frames/s]\n 13%|█▎        | 99156/776131 [04:32<37:34, 300.27frames/s]\n 13%|█▎        | 101668/776131 [04:41<37:36, 298.94frames/s]\n 13%|█▎        | 103876/776131 [04:44<31:12, 358.95frames/s]\n 14%|█▎        | 106620/776131 [04:49<27:04, 412.17frames/s]\n 14%|█▍        | 109356/776131 [04:54<25:33, 434.88frames/s]\n 14%|█▍        | 112316/776131 [04:59<22:40, 487.87frames/s]\n 15%|█▍        | 115316/776131 [05:04<21:59, 500.68frames/s]\n 15%|█▌        | 118244/776131 [05:10<21:21, 513.47frames/s]\n 15%|█▌        | 118244/776131 [05:28<21:21, 513.47frames/s]\n 16%|█▌        | 121188/776131 [05:33<40:50, 267.30frames/s]\n 16%|█▌        | 121188/776131 [05:48<40:50, 267.30frames/s]\n 16%|█▌        | 124108/776131 [05:59<58:39, 185.28frames/s]\n 16%|█▋        | 126772/776131 [06:04<47:02, 230.05frames/s]\n 17%|█▋        | 129404/776131 [06:07<37:08, 290.19frames/s]\n 17%|█▋        | 132124/776131 [06:09<28:45, 373.20frames/s]\n 17%|█▋        | 134108/776131 [06:12<24:49, 431.15frames/s]\n 18%|█▊        | 136964/776131 [06:25<32:43, 325.53frames/s]\n 18%|█▊        | 139892/776131 [06:31<28:52, 367.32frames/s]\n 18%|█▊        | 142860/776131 [06:36<25:03, 421.06frames/s]\n 19%|█▉        | 145828/776131 [06:41<22:43, 462.14frames/s]\n 19%|█▉        | 148508/776131 [06:46<22:31, 464.36frames/s]\n 20%|█▉        | 151508/776131 [06:53<22:10, 469.54frames/s]\n 20%|█▉        | 154428/776131 [06:57<19:41, 526.09frames/s]\n 20%|██        | 157084/776131 [07:02<19:32, 528.05frames/s]\n 21%|██        | 159620/776131 [07:06<19:06, 537.72frames/s]\n 21%|██        | 162604/776131 [07:12<19:33, 522.61frames/s]\n 21%|██▏       | 165252/776131 [07:17<19:09, 531.59frames/s]\n 22%|██▏       | 168148/776131 [07:22<18:11, 557.26frames/s]\n 22%|██▏       | 170836/776131 [07:25<16:42, 603.98frames/s]\n 22%|██▏       | 173628/776131 [07:32<18:39, 537.96frames/s]\n 23%|██▎       | 176340/776131 [07:35<17:17, 577.94frames/s]\n 23%|██▎       | 178964/776131 [07:40<17:06, 581.82frames/s]\n 23%|██▎       | 181204/776131 [07:43<16:30, 600.35frames/s]\n 24%|██▎       | 184148/776131 [07:49<16:51, 584.97frames/s]\n 24%|██▍       | 186996/776131 [07:54<17:21, 565.65frames/s]\n 24%|██▍       | 189868/776131 [08:00<18:17, 534.33frames/s]\n 25%|██▍       | 192708/776131 [08:06<19:05, 509.22frames/s]\n 25%|██▌       | 195516/776131 [08:12<18:53, 512.38frames/s]\n 25%|██▌       | 197836/776131 [08:16<18:32, 519.88frames/s]\n 26%|██▌       | 200796/776131 [08:21<18:18, 523.60frames/s]\n 26%|██▌       | 200796/776131 [08:38<18:18, 523.60frames/s]\n 26%|██▌       | 203644/776131 [08:57<48:49, 195.40frames/s]\n 27%|██▋       | 205732/776131 [08:59<39:51, 238.47frames/s]\n 27%|██▋       | 208676/776131 [09:03<30:03, 314.68frames/s]\n 27%|██▋       | 211580/776131 [09:08<25:56, 362.71frames/s]\n 28%|██▊       | 214324/776131 [09:14<24:12, 386.74frames/s]\n 28%|██▊       | 217020/776131 [09:19<22:14, 418.99frames/s]\n 28%|██▊       | 220020/776131 [09:24<19:29, 475.35frames/s]\n 29%|██▊       | 223020/776131 [09:30<19:23, 475.53frames/s]\n 29%|██▉       | 225476/776131 [09:34<18:30, 495.76frames/s]\n 29%|██▉       | 228364/776131 [09:38<16:46, 544.17frames/s]\n 30%|██▉       | 231316/776131 [09:45<17:43, 512.46frames/s]\n 30%|███       | 234316/776131 [09:52<18:33, 486.65frames/s]\n 31%|███       | 237316/776131 [09:56<16:39, 539.20frames/s]\n 31%|███       | 240204/776131 [10:01<16:22, 545.65frames/s]\n 31%|███▏      | 242948/776131 [10:06<15:47, 562.88frames/s]\n 32%|███▏      | 245948/776131 [10:13<17:08, 515.45frames/s]\n 32%|███▏      | 248804/776131 [10:20<18:31, 474.32frames/s]\n 32%|███▏      | 251484/776131 [10:26<18:32, 471.46frames/s]\n 33%|███▎      | 254092/776131 [10:31<18:15, 476.63frames/s]\n 33%|███▎      | 257012/776131 [10:36<17:38, 490.63frames/s]\n 33%|███▎      | 259660/776131 [10:41<16:25, 524.09frames/s]\n 34%|███▍      | 262260/776131 [10:45<15:50, 540.56frames/s]\n 34%|███▍      | 264924/776131 [10:51<16:25, 518.67frames/s]\n 34%|███▍      | 267236/776131 [10:55<16:04, 527.45frames/s]\n 35%|███▍      | 270108/776131 [11:00<15:34, 541.37frames/s]\n 35%|███▌      | 272892/776131 [11:04<14:06, 594.35frames/s]\n 35%|███▌      | 275476/776131 [11:09<15:16, 545.99frames/s]\n 36%|███▌      | 278148/776131 [11:15<15:50, 523.90frames/s]\n 36%|███▌      | 280916/776131 [11:20<15:43, 524.90frames/s]\n 37%|███▋      | 283732/776131 [11:26<16:34, 494.95frames/s]\n 37%|███▋      | 286468/776131 [11:32<16:36, 491.62frames/s]\n 37%|███▋      | 289052/776131 [11:37<16:10, 501.92frames/s]\n 38%|███▊      | 291996/776131 [11:43<16:02, 502.77frames/s]\n 38%|███▊      | 294868/776131 [11:49<16:12, 495.04frames/s]\n 38%|███▊      | 297652/776131 [11:54<15:22, 518.81frames/s]\n 39%|███▊      | 300644/776131 [11:59<15:09, 522.97frames/s]\n 39%|███▉      | 303300/776131 [12:04<14:31, 542.67frames/s]\n 39%|███▉      | 306188/776131 [12:09<14:04, 556.24frames/s]\n 40%|███▉      | 308948/776131 [12:13<13:54, 559.61frames/s]\n 40%|████      | 311580/776131 [12:17<12:38, 612.77frames/s]\n 41%|████      | 314580/776131 [12:20<11:09, 688.92frames/s]\n 41%|████      | 317580/776131 [12:26<12:09, 628.68frames/s]\n 41%|████▏     | 320396/776131 [12:31<12:58, 585.21frames/s]\n 42%|████▏     | 323292/776131 [12:37<13:12, 571.41frames/s]\n 42%|████▏     | 325956/776131 [12:42<13:24, 559.69frames/s]\n 42%|████▏     | 328884/776131 [12:47<13:49, 539.15frames/s]\n 43%|████▎     | 331700/776131 [12:53<14:07, 524.48frames/s]\n 43%|████▎     | 334356/776131 [12:58<14:11, 518.55frames/s]\n 43%|████▎     | 337316/776131 [13:04<13:40, 534.82frames/s]\n 44%|████▍     | 340124/776131 [13:08<13:07, 553.40frames/s]\n 44%|████▍     | 342708/776131 [13:13<12:51, 561.72frames/s]\n 44%|████▍     | 345180/776131 [13:16<12:13, 587.64frames/s]\n 45%|████▍     | 347892/776131 [13:22<12:36, 566.34frames/s]\n 45%|████▌     | 350812/776131 [13:27<13:02, 543.49frames/s]\n 46%|████▌     | 353764/776131 [13:32<12:27, 564.94frames/s]\n 46%|████▌     | 356420/776131 [13:35<11:22, 615.34frames/s]\n 46%|████▋     | 359420/776131 [13:39<10:33, 657.64frames/s]\n 47%|████▋     | 362316/776131 [13:43<09:36, 718.01frames/s]\n 47%|████▋     | 365316/776131 [13:47<09:32, 717.84frames/s]\n 47%|████▋     | 368060/776131 [13:51<09:42, 700.83frames/s]\n 48%|████▊     | 370436/776131 [13:54<09:36, 703.61frames/s]\n 48%|████▊     | 373436/776131 [13:59<09:52, 679.30frames/s]\n 48%|████▊     | 376308/776131 [14:03<09:20, 713.57frames/s]\n 49%|████▉     | 379180/776131 [14:08<10:00, 661.00frames/s]\n 49%|████▉     | 382180/776131 [14:13<10:26, 628.44frames/s]\n 50%|████▉     | 385180/776131 [14:17<10:02, 648.52frames/s]\n 50%|█████     | 388180/776131 [14:21<09:20, 691.68frames/s]\n 50%|█████     | 390980/776131 [14:24<08:40, 739.86frames/s]\n 51%|█████     | 393732/776131 [14:29<09:45, 653.50frames/s]\n 51%|█████     | 396244/776131 [14:33<09:36, 659.27frames/s]\n 51%|█████▏    | 398804/776131 [14:37<09:27, 665.29frames/s]\n 52%|█████▏    | 400844/776131 [14:41<09:52, 633.24frames/s]\n 52%|█████▏    | 403844/776131 [14:44<08:45, 708.78frames/s]\n 52%|█████▏    | 406316/776131 [14:48<09:02, 681.75frames/s]\n 53%|█████▎    | 409316/776131 [14:53<09:09, 668.06frames/s]\n 53%|█████▎    | 411988/776131 [14:57<09:14, 656.31frames/s]\n 53%|█████▎    | 414668/776131 [15:02<09:46, 616.48frames/s]\n 54%|█████▍    | 417532/776131 [15:07<10:07, 589.81frames/s]\n 54%|█████▍    | 420060/776131 [15:12<10:12, 581.17frames/s]\n 54%|█████▍    | 422700/776131 [15:15<09:40, 609.18frames/s]\n 55%|█████▍    | 425228/776131 [15:18<08:54, 657.05frames/s]\n 55%|█████▌    | 428036/776131 [15:22<08:09, 711.61frames/s]\n 55%|█████▌    | 430612/776131 [15:25<08:06, 710.91frames/s]\n 56%|█████▌    | 432174/776131 [15:27<07:57, 720.07frames/s]\n 56%|█████▌    | 434174/776131 [15:29<06:59, 814.69frames/s]\n 56%|█████▋    | 436654/776131 [15:33<07:36, 743.64frames/s]\n 57%|█████▋    | 439542/776131 [15:37<07:52, 712.25frames/s]\n 57%|█████▋    | 442320/776131 [15:40<07:12, 772.43frames/s]\n 57%|█████▋    | 445152/776131 [15:46<08:13, 671.14frames/s]\n 57%|█████▋    | 445152/776131 [15:58<08:13, 671.14frames/s]\n 58%|█████▊    | 448064/776131 [16:01<15:00, 364.33frames/s]\n 58%|█████▊    | 450184/776131 [16:04<13:02, 416.69frames/s]\n 58%|█████▊    | 453184/776131 [16:07<10:03, 535.05frames/s]\n 59%|█████▉    | 456184/776131 [16:12<09:45, 546.29frames/s]\n 59%|█████▉    | 458912/776131 [16:17<09:37, 549.29frames/s]\n 59%|█████▉    | 461704/776131 [16:22<09:20, 560.72frames/s]\n 60%|█████▉    | 464512/776131 [16:28<09:51, 527.14frames/s]\n 60%|██████    | 467392/776131 [16:34<10:01, 513.52frames/s]\n 61%|██████    | 470248/776131 [16:38<09:09, 557.09frames/s]\n 61%|██████    | 473096/776131 [16:42<08:45, 576.28frames/s]\n 61%|██████▏   | 476008/776131 [16:47<08:25, 594.09frames/s]\n 62%|██████▏   | 478528/776131 [16:52<08:52, 559.17frames/s]\n 62%|██████▏   | 481208/776131 [16:56<08:08, 603.89frames/s]\n 62%|██████▏   | 484120/776131 [17:00<08:01, 606.30frames/s]\n 63%|██████▎   | 486952/776131 [17:06<08:13, 585.81frames/s]\n 63%|██████▎   | 489624/776131 [17:10<08:17, 575.33frames/s]\n 63%|██████▎   | 492152/776131 [17:15<08:15, 573.66frames/s]\n 64%|██████▍   | 494896/776131 [17:19<07:51, 596.28frames/s]\n 64%|██████▍   | 497408/776131 [17:24<08:03, 576.64frames/s]\n 64%|██████▍   | 500240/776131 [17:28<07:45, 592.21frames/s]\n 65%|██████▍   | 502936/776131 [17:34<08:19, 546.86frames/s]\n 65%|██████▌   | 505736/776131 [17:39<07:58, 564.73frames/s]\n 66%|██████▌   | 508400/776131 [17:45<08:31, 523.75frames/s]\n 66%|██████▌   | 511400/776131 [17:50<08:08, 542.26frames/s]\n 66%|██████▋   | 514224/776131 [17:55<07:58, 547.63frames/s]\n 67%|██████▋   | 517224/776131 [18:01<08:22, 515.52frames/s]\n 67%|██████▋   | 520048/776131 [18:07<08:25, 506.23frames/s]\n 67%|██████▋   | 522824/776131 [18:12<08:10, 516.95frames/s]\n 68%|██████▊   | 525376/776131 [18:18<08:23, 498.00frames/s]\n 68%|██████▊   | 527824/776131 [18:21<07:17, 567.37frames/s]\n 68%|██████▊   | 530656/776131 [18:26<07:08, 572.59frames/s]\n 69%|██████▊   | 533424/776131 [18:29<06:26, 627.86frames/s]\n 69%|██████▉   | 536424/776131 [18:33<06:05, 656.57frames/s]\n 69%|██████▉   | 539200/776131 [18:36<05:34, 708.25frames/s]\n 70%|██████▉   | 541800/776131 [18:40<05:44, 681.03frames/s]\n 70%|███████   | 544568/776131 [18:46<06:07, 630.88frames/s]\n 71%|███████   | 547328/776131 [18:52<06:44, 565.74frames/s]\n 71%|███████   | 550264/776131 [18:56<06:30, 578.60frames/s]\n 71%|███████▏  | 553264/776131 [19:01<06:11, 599.66frames/s]\n 72%|███████▏  | 555880/776131 [19:05<05:53, 622.41frames/s]\n 72%|███████▏  | 558816/776131 [19:08<05:23, 672.29frames/s]\n 72%|███████▏  | 561488/776131 [19:14<05:49, 613.90frames/s]\n 73%|███████▎  | 564416/776131 [19:20<06:24, 550.31frames/s]\n 73%|███████▎  | 567256/776131 [19:26<06:21, 547.46frames/s]\n 73%|███████▎  | 570032/776131 [19:29<05:42, 601.61frames/s]\n 74%|███████▍  | 572784/776131 [19:34<05:41, 595.44frames/s]\n 74%|███████▍  | 575082/776131 [19:38<05:36, 597.56frames/s]\n 74%|███████▍  | 577826/776131 [19:42<05:27, 604.62frames/s]\n 75%|███████▍  | 580690/776131 [19:48<05:42, 571.37frames/s]\n 75%|███████▌  | 583578/776131 [19:54<05:56, 540.14frames/s]\n 76%|███████▌  | 586458/776131 [19:59<05:58, 528.57frames/s]\n 76%|███████▌  | 589402/776131 [20:05<05:45, 540.70frames/s]\n 76%|███████▋  | 592282/776131 [20:10<05:42, 537.11frames/s]\n 77%|███████▋  | 595282/776131 [20:14<05:16, 571.93frames/s]\n 77%|███████▋  | 597810/776131 [20:20<05:28, 543.48frames/s]\n 77%|███████▋  | 600514/776131 [20:23<04:44, 618.15frames/s]\n 78%|███████▊  | 603514/776131 [20:27<04:28, 642.86frames/s]\n 78%|███████▊  | 606218/776131 [20:30<03:59, 710.51frames/s]\n 78%|███████▊  | 609218/776131 [20:34<04:01, 690.82frames/s]\n 78%|███████▊  | 609218/776131 [20:48<04:01, 690.82frames/s]\n 79%|███████▉  | 612090/776131 [20:49<06:52, 397.74frames/s]\n 79%|███████▉  | 614930/776131 [20:54<06:12, 432.21frames/s]\n 80%|███████▉  | 617682/776131 [21:00<05:55, 445.66frames/s]\n 80%|███████▉  | 620538/776131 [21:04<05:15, 493.86frames/s]\n 80%|████████  | 623458/776131 [21:08<04:38, 548.15frames/s]\n 81%|████████  | 626362/776131 [21:11<03:51, 647.53frames/s]\n 81%|████████  | 629210/776131 [21:14<03:31, 693.40frames/s]\n 81%|████████▏ | 631362/776131 [21:17<03:25, 705.70frames/s]\n 82%|████████▏ | 634362/776131 [21:21<03:17, 718.29frames/s]\n 82%|████████▏ | 636930/776131 [21:25<03:16, 708.76frames/s]\n 82%|████████▏ | 639714/776131 [21:28<03:03, 741.77frames/s]\n 83%|████████▎ | 642474/776131 [21:31<02:48, 793.08frames/s]\n 83%|████████▎ | 645154/776131 [21:36<03:05, 704.56frames/s]\n 83%|████████▎ | 647954/776131 [21:40<03:00, 709.10frames/s]\n 84%|████████▍ | 650642/776131 [21:44<03:06, 671.57frames/s]\n 84%|████████▍ | 653394/776131 [21:49<03:13, 634.91frames/s]\n 85%|████████▍ | 656138/776131 [21:53<03:04, 648.69frames/s]\n 85%|████████▍ | 658818/776131 [21:59<03:18, 590.82frames/s]\n 85%|████████▌ | 661058/776131 [22:02<03:09, 605.73frames/s]\n 86%|████████▌ | 663874/776131 [22:06<03:03, 613.20frames/s]\n 86%|████████▌ | 666858/776131 [22:12<03:09, 577.29frames/s]\n 86%|████████▋ | 669698/776131 [22:18<03:17, 537.94frames/s]\n 87%|████████▋ | 672634/776131 [22:24<03:12, 536.61frames/s]\n 87%|████████▋ | 675626/776131 [22:30<03:16, 511.99frames/s]\n 87%|████████▋ | 678554/776131 [22:38<03:35, 453.19frames/s]\n 88%|████████▊ | 681530/776131 [22:47<03:43, 422.89frames/s]\n 88%|████████▊ | 684530/776131 [22:51<03:10, 480.91frames/s]\n 89%|████████▊ | 687410/776131 [22:59<03:25, 430.84frames/s]\n 89%|████████▉ | 690410/776131 [23:08<03:33, 401.12frames/s]\n 89%|████████▉ | 693410/776131 [23:14<03:15, 422.76frames/s]\n 90%|████████▉ | 696170/776131 [23:19<02:58, 447.99frames/s]\n 90%|█████████ | 698810/776131 [23:24<02:44, 470.06frames/s]\n 90%|█████████ | 701754/776131 [23:30<02:37, 473.69frames/s]\n 91%|█████████ | 704178/776131 [23:36<02:37, 457.92frames/s]\n 91%|█████████ | 706962/776131 [23:40<02:11, 525.52frames/s]\n 91%|█████████▏| 709962/776131 [23:46<02:08, 514.97frames/s]\n 92%|█████████▏| 712954/776131 [23:50<01:55, 544.78frames/s]\n 92%|█████████▏| 715914/776131 [23:57<01:55, 519.29frames/s]\n 92%|█████████▏| 715914/776131 [24:08<01:55, 519.29frames/s]\n 93%|█████████▎| 718874/776131 [24:40<05:33, 171.58frames/s]\n 93%|█████████▎| 721746/776131 [24:45<04:10, 217.52frames/s]\n 93%|█████████▎| 724050/776131 [24:48<03:12, 270.38frames/s]\n 94%|█████████▎| 727002/776131 [24:52<02:28, 329.81frames/s]\n 94%|█████████▍| 729914/776131 [24:57<01:59, 385.90frames/s]\n 94%|█████████▍| 732810/776131 [25:03<01:42, 421.33frames/s]\n 95%|█████████▍| 735394/776131 [25:07<01:28, 460.55frames/s]\n 95%|█████████▌| 738274/776131 [25:11<01:15, 498.73frames/s]\n 95%|█████████▌| 741026/776131 [25:16<01:05, 533.55frames/s]\n 96%|█████████▌| 743858/776131 [25:21<01:00, 537.69frames/s]\n 96%|█████████▌| 746298/776131 [25:25<00:54, 545.36frames/s]\n 97%|█████████▋| 749242/776131 [25:30<00:48, 558.06frames/s]\n 97%|█████████▋| 752242/776131 [25:35<00:39, 597.24frames/s]\n 97%|█████████▋| 754898/776131 [25:39<00:36, 589.33frames/s]\n 98%|█████████▊| 757530/776131 [25:44<00:31, 591.39frames/s]\n 98%|█████████▊| 760218/776131 [25:48<00:26, 597.42frames/s]\n 98%|█████████▊| 762954/776131 [25:53<00:22, 580.64frames/s]\n 99%|█████████▊| 765594/776131 [25:58<00:18, 556.98frames/s]\n 99%|█████████▉| 768594/776131 [26:03<00:13, 565.79frames/s]\n 99%|█████████▉| 771354/776131 [26:10<00:09, 523.30frames/s]\n 99%|█████████▉| 771354/776131 [26:28<00:09, 523.30frames/s]\n100%|█████████▉| 774354/776131 [26:43<00:08, 207.41frames/s]\n100%|██████████| 776131/776131 [26:46<00:00, 237.43frames/s]\n100%|██████████| 776131/776131 [26:46<00:00, 483.02frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.48151202823804773,
        "compression_ratio": 1.34375,
        "end": 16.6,
        "id": 0,
        "no_speech_prob": 0.4263022541999817,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " Did you think that learning coding would be really rough?",
        "tokens": [
          50364,
          2589,
          291,
          519,
          300,
          2539,
          17720,
          576,
          312,
          534,
          5903,
          30,
          51194
        ]
      },
      {
        "avg_logprob": -0.48151202823804773,
        "compression_ratio": 1.34375,
        "end": 19.68,
        "id": 1,
        "no_speech_prob": 0.4263022541999817,
        "seek": 0,
        "start": 16.6,
        "temperature": 0,
        "text": " Throw your hands up in the air and say, enough's enough!",
        "tokens": [
          51194,
          22228,
          428,
          2377,
          493,
          294,
          264,
          1988,
          293,
          584,
          11,
          1547,
          311,
          1547,
          0,
          51348
        ]
      },
      {
        "avg_logprob": -0.48151202823804773,
        "compression_ratio": 1.34375,
        "end": 22.68,
        "id": 2,
        "no_speech_prob": 0.4263022541999817,
        "seek": 0,
        "start": 19.68,
        "temperature": 0,
        "text": " Do you want to learn to code and make some awesome stuff?",
        "tokens": [
          51348,
          1144,
          291,
          528,
          281,
          1466,
          281,
          3089,
          293,
          652,
          512,
          3476,
          1507,
          30,
          51498
        ]
      },
      {
        "avg_logprob": -0.36253324236188617,
        "compression_ratio": 1.48,
        "end": 26.44,
        "id": 3,
        "no_speech_prob": 0.03409254178404808,
        "seek": 2268,
        "start": 22.919999999999998,
        "temperature": 0,
        "text": " Learn that anyone can when you're coding with Dan on!",
        "tokens": [
          50376,
          17216,
          300,
          2878,
          393,
          562,
          291,
          434,
          17720,
          365,
          3394,
          322,
          0,
          50552
        ]
      },
      {
        "avg_logprob": -0.36253324236188617,
        "compression_ratio": 1.48,
        "end": 35.4,
        "id": 4,
        "no_speech_prob": 0.03409254178404808,
        "seek": 2268,
        "start": 32.92,
        "temperature": 0,
        "text": " Whether you're a pro or this is all brand new,",
        "tokens": [
          50876,
          8503,
          291,
          434,
          257,
          447,
          420,
          341,
          307,
          439,
          3360,
          777,
          11,
          51000
        ]
      },
      {
        "avg_logprob": -0.36253324236188617,
        "compression_ratio": 1.48,
        "end": 42.120000000000005,
        "id": 5,
        "no_speech_prob": 0.03409254178404808,
        "seek": 2268,
        "start": 38.92,
        "temperature": 0,
        "text": " learn the overarching concepts and some fun stuff too!",
        "tokens": [
          51176,
          1466,
          264,
          45501,
          10392,
          293,
          512,
          1019,
          1507,
          886,
          0,
          51336
        ]
      },
      {
        "avg_logprob": -0.36253324236188617,
        "compression_ratio": 1.48,
        "end": 45.480000000000004,
        "id": 6,
        "no_speech_prob": 0.03409254178404808,
        "seek": 2268,
        "start": 42.120000000000005,
        "temperature": 0,
        "text": " And with Dan as your guide, come along for the ride on!",
        "tokens": [
          51336,
          400,
          365,
          3394,
          382,
          428,
          5934,
          11,
          808,
          2051,
          337,
          264,
          5077,
          322,
          0,
          51504
        ]
      },
      {
        "avg_logprob": -0.36253324236188617,
        "compression_ratio": 1.48,
        "end": 51.72,
        "id": 7,
        "no_speech_prob": 0.03409254178404808,
        "seek": 2268,
        "start": 48.519999999999996,
        "temperature": 0,
        "text": " Make a crazy pixel mirror to reflect your face,",
        "tokens": [
          51656,
          4387,
          257,
          3219,
          19261,
          8013,
          281,
          5031,
          428,
          1851,
          11,
          51816
        ]
      },
      {
        "avg_logprob": -0.23342019608877237,
        "compression_ratio": 1.7714285714285714,
        "end": 54.92,
        "id": 8,
        "no_speech_prob": 0.0002694572613108903,
        "seek": 5172,
        "start": 51.72,
        "temperature": 0,
        "text": " you can make a jump to light speed into outer space,",
        "tokens": [
          50364,
          291,
          393,
          652,
          257,
          3012,
          281,
          1442,
          3073,
          666,
          10847,
          1901,
          11,
          50524
        ]
      },
      {
        "avg_logprob": -0.23342019608877237,
        "compression_ratio": 1.7714285714285714,
        "end": 58.12,
        "id": 9,
        "no_speech_prob": 0.0002694572613108903,
        "seek": 5172,
        "start": 54.92,
        "temperature": 0,
        "text": " you can generate a maze that can go on for days,",
        "tokens": [
          50524,
          291,
          393,
          8460,
          257,
          33032,
          300,
          393,
          352,
          322,
          337,
          1708,
          11,
          50684
        ]
      },
      {
        "avg_logprob": -0.23342019608877237,
        "compression_ratio": 1.7714285714285714,
        "end": 61.32,
        "id": 10,
        "no_speech_prob": 0.0002694572613108903,
        "seek": 5172,
        "start": 58.12,
        "temperature": 0,
        "text": " you can make your own terrain and some purple rain,",
        "tokens": [
          50684,
          291,
          393,
          652,
          428,
          1065,
          17674,
          293,
          512,
          9656,
          4830,
          11,
          50844
        ]
      },
      {
        "avg_logprob": -0.23342019608877237,
        "compression_ratio": 1.7714285714285714,
        "end": 64.52,
        "id": 11,
        "no_speech_prob": 0.0002694572613108903,
        "seek": 5172,
        "start": 61.32,
        "temperature": 0,
        "text": " you can make a retro game to see how it's done,",
        "tokens": [
          50844,
          291,
          393,
          652,
          257,
          18820,
          1216,
          281,
          536,
          577,
          309,
          311,
          1096,
          11,
          51004
        ]
      },
      {
        "avg_logprob": -0.23342019608877237,
        "compression_ratio": 1.7714285714285714,
        "end": 67.72,
        "id": 12,
        "no_speech_prob": 0.0002694572613108903,
        "seek": 5172,
        "start": 64.52,
        "temperature": 0,
        "text": " and then tweak a piece to make it yours for everyone!",
        "tokens": [
          51004,
          293,
          550,
          29879,
          257,
          2522,
          281,
          652,
          309,
          6342,
          337,
          1518,
          0,
          51164
        ]
      },
      {
        "avg_logprob": -0.23342019608877237,
        "compression_ratio": 1.7714285714285714,
        "end": 70.75999999999999,
        "id": 13,
        "no_speech_prob": 0.0002694572613108903,
        "seek": 5172,
        "start": 67.72,
        "temperature": 0,
        "text": " Make some fractally trees or twitter bots if you please,",
        "tokens": [
          51164,
          4387,
          512,
          17948,
          379,
          5852,
          420,
          21439,
          35410,
          498,
          291,
          1767,
          11,
          51316
        ]
      },
      {
        "avg_logprob": -0.23342019608877237,
        "compression_ratio": 1.7714285714285714,
        "end": 73.96000000000001,
        "id": 14,
        "no_speech_prob": 0.0002694572613108903,
        "seek": 5172,
        "start": 70.75999999999999,
        "temperature": 0,
        "text": " and when the seeds are a stone, you can make them your own!",
        "tokens": [
          51316,
          293,
          562,
          264,
          9203,
          366,
          257,
          7581,
          11,
          291,
          393,
          652,
          552,
          428,
          1065,
          0,
          51476
        ]
      },
      {
        "avg_logprob": -0.4472346950221706,
        "compression_ratio": 1.17,
        "end": 83.8,
        "id": 15,
        "no_speech_prob": 0.03258010372519493,
        "seek": 7396,
        "start": 73.96,
        "temperature": 0,
        "text": " Run the colors of code, you can follow the road too!",
        "tokens": [
          50364,
          8950,
          264,
          4577,
          295,
          3089,
          11,
          291,
          393,
          1524,
          264,
          3060,
          886,
          0,
          50856
        ]
      },
      {
        "avg_logprob": -0.4472346950221706,
        "compression_ratio": 1.17,
        "end": 95.32,
        "id": 16,
        "no_speech_prob": 0.03258010372519493,
        "seek": 7396,
        "start": 91.96,
        "temperature": 0,
        "text": " Hello, welcome to another episode of...",
        "tokens": [
          51264,
          2425,
          11,
          2928,
          281,
          1071,
          3500,
          295,
          485,
          51432
        ]
      },
      {
        "avg_logprob": -0.4472346950221706,
        "compression_ratio": 1.17,
        "end": 102.36,
        "id": 17,
        "no_speech_prob": 0.03258010372519493,
        "seek": 7396,
        "start": 101.47999999999999,
        "temperature": 0,
        "text": " I don't know what it is.",
        "tokens": [
          51740,
          286,
          500,
          380,
          458,
          437,
          309,
          307,
          13,
          51784
        ]
      },
      {
        "avg_logprob": -0.29084238895150116,
        "compression_ratio": 1.5279187817258884,
        "end": 104.6,
        "id": 18,
        "no_speech_prob": 0.00364901265129447,
        "seek": 10236,
        "start": 102.36,
        "temperature": 0,
        "text": " Okay, so hopefully you're there and watching.",
        "tokens": [
          50364,
          1033,
          11,
          370,
          4696,
          291,
          434,
          456,
          293,
          1976,
          13,
          50476
        ]
      },
      {
        "avg_logprob": -0.29084238895150116,
        "compression_ratio": 1.5279187817258884,
        "end": 105.24,
        "id": 19,
        "no_speech_prob": 0.00364901265129447,
        "seek": 10236,
        "start": 104.6,
        "temperature": 0,
        "text": " I am here.",
        "tokens": [
          50476,
          286,
          669,
          510,
          13,
          50508
        ]
      },
      {
        "avg_logprob": -0.29084238895150116,
        "compression_ratio": 1.5279187817258884,
        "end": 110.76,
        "id": 20,
        "no_speech_prob": 0.00364901265129447,
        "seek": 10236,
        "start": 105.24,
        "temperature": 0,
        "text": " It's been two weeks since I've been here on the YouTube.",
        "tokens": [
          50508,
          467,
          311,
          668,
          732,
          3259,
          1670,
          286,
          600,
          668,
          510,
          322,
          264,
          3088,
          13,
          50784
        ]
      },
      {
        "avg_logprob": -0.29084238895150116,
        "compression_ratio": 1.5279187817258884,
        "end": 116.12,
        "id": 21,
        "no_speech_prob": 0.00364901265129447,
        "seek": 10236,
        "start": 113.32,
        "temperature": 0,
        "text": " And I'm very excited and glad to be back.",
        "tokens": [
          50912,
          400,
          286,
          478,
          588,
          2919,
          293,
          5404,
          281,
          312,
          646,
          13,
          51052
        ]
      },
      {
        "avg_logprob": -0.29084238895150116,
        "compression_ratio": 1.5279187817258884,
        "end": 121.16,
        "id": 22,
        "no_speech_prob": 0.00364901265129447,
        "seek": 10236,
        "start": 116.68,
        "temperature": 0,
        "text": " And this has been a very tricky month with busy end of semester for me,",
        "tokens": [
          51080,
          400,
          341,
          575,
          668,
          257,
          588,
          12414,
          1618,
          365,
          5856,
          917,
          295,
          11894,
          337,
          385,
          11,
          51304
        ]
      },
      {
        "avg_logprob": -0.29084238895150116,
        "compression_ratio": 1.5279187817258884,
        "end": 128.36,
        "id": 23,
        "no_speech_prob": 0.00364901265129447,
        "seek": 10236,
        "start": 121.16,
        "temperature": 0,
        "text": " with my other job, and with the holidays that have been here in New York,",
        "tokens": [
          51304,
          365,
          452,
          661,
          1691,
          11,
          293,
          365,
          264,
          15734,
          300,
          362,
          668,
          510,
          294,
          1873,
          3609,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.22946876703306687,
        "compression_ratio": 1.5340501792114696,
        "end": 130.76000000000002,
        "id": 24,
        "no_speech_prob": 0.06654844433069229,
        "seek": 12836,
        "start": 128.36,
        "temperature": 0,
        "text": " this crazy election thing that happened,",
        "tokens": [
          50364,
          341,
          3219,
          6618,
          551,
          300,
          2011,
          11,
          50484
        ]
      },
      {
        "avg_logprob": -0.22946876703306687,
        "compression_ratio": 1.5340501792114696,
        "end": 134.84,
        "id": 25,
        "no_speech_prob": 0.06654844433069229,
        "seek": 12836,
        "start": 130.76000000000002,
        "temperature": 0,
        "text": " which I am upsetting on so many different kinds of levels.",
        "tokens": [
          50484,
          597,
          286,
          669,
          44109,
          322,
          370,
          867,
          819,
          3685,
          295,
          4358,
          13,
          50688
        ]
      },
      {
        "avg_logprob": -0.22946876703306687,
        "compression_ratio": 1.5340501792114696,
        "end": 140.68,
        "id": 26,
        "no_speech_prob": 0.06654844433069229,
        "seek": 12836,
        "start": 134.84,
        "temperature": 0,
        "text": " But here I am anyway, alive in this room here at the School for Poetic Computation",
        "tokens": [
          50688,
          583,
          510,
          286,
          669,
          4033,
          11,
          5465,
          294,
          341,
          1808,
          510,
          412,
          264,
          5070,
          337,
          6165,
          3532,
          37804,
          399,
          50980
        ]
      },
      {
        "avg_logprob": -0.22946876703306687,
        "compression_ratio": 1.5340501792114696,
        "end": 145.08,
        "id": 27,
        "no_speech_prob": 0.06654844433069229,
        "seek": 12836,
        "start": 141.8,
        "temperature": 0,
        "text": " in the West Village of New York City.",
        "tokens": [
          51036,
          294,
          264,
          4055,
          22651,
          295,
          1873,
          3609,
          4392,
          13,
          51200
        ]
      },
      {
        "avg_logprob": -0.22946876703306687,
        "compression_ratio": 1.5340501792114696,
        "end": 147.48000000000002,
        "id": 28,
        "no_speech_prob": 0.06654844433069229,
        "seek": 12836,
        "start": 145.08,
        "temperature": 0,
        "text": " And it's around 3.20 p.m.",
        "tokens": [
          51200,
          400,
          309,
          311,
          926,
          805,
          13,
          2009,
          280,
          13,
          76,
          13,
          51320
        ]
      },
      {
        "avg_logprob": -0.22946876703306687,
        "compression_ratio": 1.5340501792114696,
        "end": 149.08,
        "id": 29,
        "no_speech_prob": 0.06654844433069229,
        "seek": 12836,
        "start": 147.48000000000002,
        "temperature": 0,
        "text": " I don't think it's December yet.",
        "tokens": [
          51320,
          286,
          500,
          380,
          519,
          309,
          311,
          7687,
          1939,
          13,
          51400
        ]
      },
      {
        "avg_logprob": -0.22946876703306687,
        "compression_ratio": 1.5340501792114696,
        "end": 151.8,
        "id": 30,
        "no_speech_prob": 0.06654844433069229,
        "seek": 12836,
        "start": 149.08,
        "temperature": 0,
        "text": " I'm pretty sure it's still just November.",
        "tokens": [
          51400,
          286,
          478,
          1238,
          988,
          309,
          311,
          920,
          445,
          7674,
          13,
          51536
        ]
      },
      {
        "avg_logprob": -0.22946876703306687,
        "compression_ratio": 1.5340501792114696,
        "end": 153.08,
        "id": 31,
        "no_speech_prob": 0.06654844433069229,
        "seek": 12836,
        "start": 151.8,
        "temperature": 0,
        "text": " Please don't be November.",
        "tokens": [
          51536,
          2555,
          500,
          380,
          312,
          7674,
          13,
          51600
        ]
      },
      {
        "avg_logprob": -0.22946876703306687,
        "compression_ratio": 1.5340501792114696,
        "end": 153.8,
        "id": 32,
        "no_speech_prob": 0.06654844433069229,
        "seek": 12836,
        "start": 153.08,
        "temperature": 0,
        "text": " Actually, you know what?",
        "tokens": [
          51600,
          5135,
          11,
          291,
          458,
          437,
          30,
          51636
        ]
      },
      {
        "avg_logprob": -0.22946876703306687,
        "compression_ratio": 1.5340501792114696,
        "end": 154.36,
        "id": 33,
        "no_speech_prob": 0.06654844433069229,
        "seek": 12836,
        "start": 153.8,
        "temperature": 0,
        "text": " December.",
        "tokens": [
          51636,
          7687,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.22946876703306687,
        "compression_ratio": 1.5340501792114696,
        "end": 155.96,
        "id": 34,
        "no_speech_prob": 0.06654844433069229,
        "seek": 12836,
        "start": 154.36,
        "temperature": 0,
        "text": " Fine, let's bring on December.",
        "tokens": [
          51664,
          12024,
          11,
          718,
          311,
          1565,
          322,
          7687,
          13,
          51744
        ]
      },
      {
        "avg_logprob": -0.22946876703306687,
        "compression_ratio": 1.5340501792114696,
        "end": 157,
        "id": 35,
        "no_speech_prob": 0.06654844433069229,
        "seek": 12836,
        "start": 155.96,
        "temperature": 0,
        "text": " Bring on 2000.",
        "tokens": [
          51744,
          12842,
          322,
          8132,
          13,
          51796
        ]
      },
      {
        "avg_logprob": -0.1902641605686497,
        "compression_ratio": 1.7681159420289856,
        "end": 160.04,
        "id": 36,
        "no_speech_prob": 0.0020829064305871725,
        "seek": 15700,
        "start": 157.32,
        "temperature": 0,
        "text": " Some jump, let's jump a bunch of years into the future.",
        "tokens": [
          50380,
          2188,
          3012,
          11,
          718,
          311,
          3012,
          257,
          3840,
          295,
          924,
          666,
          264,
          2027,
          13,
          50516
        ]
      },
      {
        "avg_logprob": -0.1902641605686497,
        "compression_ratio": 1.7681159420289856,
        "end": 161.88,
        "id": 37,
        "no_speech_prob": 0.0020829064305871725,
        "seek": 15700,
        "start": 160.68,
        "temperature": 0,
        "text": " And maybe that'll be a good thing.",
        "tokens": [
          50548,
          400,
          1310,
          300,
          603,
          312,
          257,
          665,
          551,
          13,
          50608
        ]
      },
      {
        "avg_logprob": -0.1902641605686497,
        "compression_ratio": 1.7681159420289856,
        "end": 164.36,
        "id": 38,
        "no_speech_prob": 0.0020829064305871725,
        "seek": 15700,
        "start": 161.88,
        "temperature": 0,
        "text": " Anyway, what's up with the colors?",
        "tokens": [
          50608,
          5684,
          11,
          437,
          311,
          493,
          365,
          264,
          4577,
          30,
          50732
        ]
      },
      {
        "avg_logprob": -0.1902641605686497,
        "compression_ratio": 1.7681159420289856,
        "end": 166.84,
        "id": 39,
        "no_speech_prob": 0.0020829064305871725,
        "seek": 15700,
        "start": 165.88,
        "temperature": 0,
        "text": " Is anything looking weird?",
        "tokens": [
          50808,
          1119,
          1340,
          1237,
          3657,
          30,
          50856
        ]
      },
      {
        "avg_logprob": -0.1902641605686497,
        "compression_ratio": 1.7681159420289856,
        "end": 170.44,
        "id": 40,
        "no_speech_prob": 0.0020829064305871725,
        "seek": 15700,
        "start": 166.84,
        "temperature": 0,
        "text": " Am I, you know, I have a little, I have some, I'm sort of lighting challenged.",
        "tokens": [
          50856,
          2012,
          286,
          11,
          291,
          458,
          11,
          286,
          362,
          257,
          707,
          11,
          286,
          362,
          512,
          11,
          286,
          478,
          1333,
          295,
          9577,
          17737,
          13,
          51036
        ]
      },
      {
        "avg_logprob": -0.1902641605686497,
        "compression_ratio": 1.7681159420289856,
        "end": 173.4,
        "id": 41,
        "no_speech_prob": 0.0020829064305871725,
        "seek": 15700,
        "start": 170.44,
        "temperature": 0,
        "text": " So I don't know if there's some weird colored things going on.",
        "tokens": [
          51036,
          407,
          286,
          500,
          380,
          458,
          498,
          456,
          311,
          512,
          3657,
          14332,
          721,
          516,
          322,
          13,
          51184
        ]
      },
      {
        "avg_logprob": -0.1902641605686497,
        "compression_ratio": 1.7681159420289856,
        "end": 177.96,
        "id": 42,
        "no_speech_prob": 0.0020829064305871725,
        "seek": 15700,
        "start": 175.32,
        "temperature": 0,
        "text": " And, but yes, I did have a haircut.",
        "tokens": [
          51280,
          400,
          11,
          457,
          2086,
          11,
          286,
          630,
          362,
          257,
          30328,
          13,
          51412
        ]
      },
      {
        "avg_logprob": -0.1902641605686497,
        "compression_ratio": 1.7681159420289856,
        "end": 179.16,
        "id": 43,
        "no_speech_prob": 0.0020829064305871725,
        "seek": 15700,
        "start": 177.96,
        "temperature": 0,
        "text": " Thank you for noticing.",
        "tokens": [
          51412,
          1044,
          291,
          337,
          21814,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -0.1902641605686497,
        "compression_ratio": 1.7681159420289856,
        "end": 179.8,
        "id": 44,
        "no_speech_prob": 0.0020829064305871725,
        "seek": 15700,
        "start": 179.16,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          51472,
          286,
          500,
          380,
          458,
          13,
          51504
        ]
      },
      {
        "avg_logprob": -0.1902641605686497,
        "compression_ratio": 1.7681159420289856,
        "end": 183.16,
        "id": 45,
        "no_speech_prob": 0.0020829064305871725,
        "seek": 15700,
        "start": 179.8,
        "temperature": 0,
        "text": " This is probably not what you tuned in for, or perhaps it is what you tuned in for.",
        "tokens": [
          51504,
          639,
          307,
          1391,
          406,
          437,
          291,
          10870,
          294,
          337,
          11,
          420,
          4317,
          309,
          307,
          437,
          291,
          10870,
          294,
          337,
          13,
          51672
        ]
      },
      {
        "avg_logprob": -0.1902641605686497,
        "compression_ratio": 1.7681159420289856,
        "end": 184.68,
        "id": 46,
        "no_speech_prob": 0.0020829064305871725,
        "seek": 15700,
        "start": 183.16,
        "temperature": 0,
        "text": " So what's going on with this thing?",
        "tokens": [
          51672,
          407,
          437,
          311,
          516,
          322,
          365,
          341,
          551,
          30,
          51748
        ]
      },
      {
        "avg_logprob": -0.19805191375397063,
        "compression_ratio": 1.5975103734439835,
        "end": 187.32,
        "id": 47,
        "no_speech_prob": 0.0008167171617969871,
        "seek": 18468,
        "start": 184.68,
        "temperature": 0,
        "text": " So my name is Dan.",
        "tokens": [
          50364,
          407,
          452,
          1315,
          307,
          3394,
          13,
          50496
        ]
      },
      {
        "avg_logprob": -0.19805191375397063,
        "compression_ratio": 1.5975103734439835,
        "end": 194.76000000000002,
        "id": 48,
        "no_speech_prob": 0.0008167171617969871,
        "seek": 18468,
        "start": 188.12,
        "temperature": 0,
        "text": " I do live streams on YouTube weekly, except for the weeks where that I miss, like last week,",
        "tokens": [
          50536,
          286,
          360,
          1621,
          15842,
          322,
          3088,
          12460,
          11,
          3993,
          337,
          264,
          3259,
          689,
          300,
          286,
          1713,
          11,
          411,
          1036,
          1243,
          11,
          50868
        ]
      },
      {
        "avg_logprob": -0.19805191375397063,
        "compression_ratio": 1.5975103734439835,
        "end": 199.32,
        "id": 49,
        "no_speech_prob": 0.0008167171617969871,
        "seek": 18468,
        "start": 194.76000000000002,
        "temperature": 0,
        "text": " where I demonstrate a variety of different programming, coding techniques,",
        "tokens": [
          50868,
          689,
          286,
          11698,
          257,
          5673,
          295,
          819,
          9410,
          11,
          17720,
          7512,
          11,
          51096
        ]
      },
      {
        "avg_logprob": -0.19805191375397063,
        "compression_ratio": 1.5975103734439835,
        "end": 203.4,
        "id": 50,
        "no_speech_prob": 0.0008167171617969871,
        "seek": 18468,
        "start": 199.32,
        "temperature": 0,
        "text": " generally in the creative sphere of applications.",
        "tokens": [
          51096,
          5101,
          294,
          264,
          5880,
          16687,
          295,
          5821,
          13,
          51300
        ]
      },
      {
        "avg_logprob": -0.19805191375397063,
        "compression_ratio": 1.5975103734439835,
        "end": 205.8,
        "id": 51,
        "no_speech_prob": 0.0008167171617969871,
        "seek": 18468,
        "start": 203.4,
        "temperature": 0,
        "text": " So look at generative algorithms for visual art,",
        "tokens": [
          51300,
          407,
          574,
          412,
          1337,
          1166,
          14642,
          337,
          5056,
          1523,
          11,
          51420
        ]
      },
      {
        "avg_logprob": -0.19805191375397063,
        "compression_ratio": 1.5975103734439835,
        "end": 210.52,
        "id": 52,
        "no_speech_prob": 0.0008167171617969871,
        "seek": 18468,
        "start": 206.84,
        "temperature": 0,
        "text": " different kinds of algorithms for generating and analyzing text,",
        "tokens": [
          51472,
          819,
          3685,
          295,
          14642,
          337,
          17746,
          293,
          23663,
          2487,
          11,
          51656
        ]
      },
      {
        "avg_logprob": -0.19805191375397063,
        "compression_ratio": 1.5975103734439835,
        "end": 212.28,
        "id": 53,
        "no_speech_prob": 0.0008167171617969871,
        "seek": 18468,
        "start": 210.52,
        "temperature": 0,
        "text": " which has been my focus this fall.",
        "tokens": [
          51656,
          597,
          575,
          668,
          452,
          1879,
          341,
          2100,
          13,
          51744
        ]
      },
      {
        "avg_logprob": -0.26129512626583834,
        "compression_ratio": 1.742537313432836,
        "end": 215.24,
        "id": 54,
        "no_speech_prob": 0.00013341403973754495,
        "seek": 21228,
        "start": 212.28,
        "temperature": 0,
        "text": " I noticed somebody in the chat mentioned,",
        "tokens": [
          50364,
          286,
          5694,
          2618,
          294,
          264,
          5081,
          2835,
          11,
          50512
        ]
      },
      {
        "avg_logprob": -0.26129512626583834,
        "compression_ratio": 1.742537313432836,
        "end": 222.28,
        "id": 55,
        "no_speech_prob": 0.00013341403973754495,
        "seek": 21228,
        "start": 217.4,
        "temperature": 0,
        "text": " mentioned, somebody in the chat mentioned machine learning.",
        "tokens": [
          50620,
          2835,
          11,
          2618,
          294,
          264,
          5081,
          2835,
          3479,
          2539,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.26129512626583834,
        "compression_ratio": 1.742537313432836,
        "end": 224.28,
        "id": 56,
        "no_speech_prob": 0.00013341403973754495,
        "seek": 21228,
        "start": 222.28,
        "temperature": 0,
        "text": " And that's actually on my list of topics.",
        "tokens": [
          50864,
          400,
          300,
          311,
          767,
          322,
          452,
          1329,
          295,
          8378,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.26129512626583834,
        "compression_ratio": 1.742537313432836,
        "end": 228.6,
        "id": 57,
        "no_speech_prob": 0.00013341403973754495,
        "seek": 21228,
        "start": 224.28,
        "temperature": 0,
        "text": " That's going to be one of my main focuses this spring in the new year in 2017.",
        "tokens": [
          50964,
          663,
          311,
          516,
          281,
          312,
          472,
          295,
          452,
          2135,
          16109,
          341,
          5587,
          294,
          264,
          777,
          1064,
          294,
          6591,
          13,
          51180
        ]
      },
      {
        "avg_logprob": -0.26129512626583834,
        "compression_ratio": 1.742537313432836,
        "end": 232.84,
        "id": 58,
        "no_speech_prob": 0.00013341403973754495,
        "seek": 21228,
        "start": 229.56,
        "temperature": 0,
        "text": " But so today, what I wanted to do, I want to do a couple things.",
        "tokens": [
          51228,
          583,
          370,
          965,
          11,
          437,
          286,
          1415,
          281,
          360,
          11,
          286,
          528,
          281,
          360,
          257,
          1916,
          721,
          13,
          51392
        ]
      },
      {
        "avg_logprob": -0.26129512626583834,
        "compression_ratio": 1.742537313432836,
        "end": 235.08,
        "id": 59,
        "no_speech_prob": 0.00013341403973754495,
        "seek": 21228,
        "start": 232.84,
        "temperature": 0,
        "text": " One is I want to talk about the processing fellowships,",
        "tokens": [
          51392,
          1485,
          307,
          286,
          528,
          281,
          751,
          466,
          264,
          9007,
          24989,
          82,
          11,
          51504
        ]
      },
      {
        "avg_logprob": -0.26129512626583834,
        "compression_ratio": 1.742537313432836,
        "end": 237.16,
        "id": 60,
        "no_speech_prob": 0.00013341403973754495,
        "seek": 21228,
        "start": 235.08,
        "temperature": 0,
        "text": " which might be something that you aren't aware of.",
        "tokens": [
          51504,
          597,
          1062,
          312,
          746,
          300,
          291,
          3212,
          380,
          3650,
          295,
          13,
          51608
        ]
      },
      {
        "avg_logprob": -0.26129512626583834,
        "compression_ratio": 1.742537313432836,
        "end": 240.04,
        "id": 61,
        "no_speech_prob": 0.00013341403973754495,
        "seek": 21228,
        "start": 237.16,
        "temperature": 0,
        "text": " So I'm gonna spend a little time talking about the processing foundation",
        "tokens": [
          51608,
          407,
          286,
          478,
          799,
          3496,
          257,
          707,
          565,
          1417,
          466,
          264,
          9007,
          7030,
          51752
        ]
      },
      {
        "avg_logprob": -0.19313219038106627,
        "compression_ratio": 1.6398467432950192,
        "end": 244.12,
        "id": 62,
        "no_speech_prob": 0.007011260837316513,
        "seek": 24004,
        "start": 240.04,
        "temperature": 0,
        "text": " and the fellowship program that's out now that any of you might be interested in,",
        "tokens": [
          50364,
          293,
          264,
          24989,
          1461,
          300,
          311,
          484,
          586,
          300,
          604,
          295,
          291,
          1062,
          312,
          3102,
          294,
          11,
          50568
        ]
      },
      {
        "avg_logprob": -0.19313219038106627,
        "compression_ratio": 1.6398467432950192,
        "end": 248.28,
        "id": 63,
        "no_speech_prob": 0.007011260837316513,
        "seek": 24004,
        "start": 246.76,
        "temperature": 0,
        "text": " interested in applying to.",
        "tokens": [
          50700,
          3102,
          294,
          9275,
          281,
          13,
          50776
        ]
      },
      {
        "avg_logprob": -0.19313219038106627,
        "compression_ratio": 1.6398467432950192,
        "end": 251.64,
        "id": 64,
        "no_speech_prob": 0.007011260837316513,
        "seek": 24004,
        "start": 248.28,
        "temperature": 0,
        "text": " Sorry, I'm trying to keep an eye on the chat, which it's very difficult to have this,",
        "tokens": [
          50776,
          4919,
          11,
          286,
          478,
          1382,
          281,
          1066,
          364,
          3313,
          322,
          264,
          5081,
          11,
          597,
          309,
          311,
          588,
          2252,
          281,
          362,
          341,
          11,
          50944
        ]
      },
      {
        "avg_logprob": -0.19313219038106627,
        "compression_ratio": 1.6398467432950192,
        "end": 256.2,
        "id": 65,
        "no_speech_prob": 0.007011260837316513,
        "seek": 24004,
        "start": 252.44,
        "temperature": 0,
        "text": " to speak and have a continuous thought and read a chat at the same time.",
        "tokens": [
          50984,
          281,
          1710,
          293,
          362,
          257,
          10957,
          1194,
          293,
          1401,
          257,
          5081,
          412,
          264,
          912,
          565,
          13,
          51172
        ]
      },
      {
        "avg_logprob": -0.19313219038106627,
        "compression_ratio": 1.6398467432950192,
        "end": 257.8,
        "id": 66,
        "no_speech_prob": 0.007011260837316513,
        "seek": 24004,
        "start": 257.08,
        "temperature": 0,
        "text": " Hi, Arson.",
        "tokens": [
          51216,
          2421,
          11,
          1587,
          3015,
          13,
          51252
        ]
      },
      {
        "avg_logprob": -0.19313219038106627,
        "compression_ratio": 1.6398467432950192,
        "end": 259.24,
        "id": 67,
        "no_speech_prob": 0.007011260837316513,
        "seek": 24004,
        "start": 257.8,
        "temperature": 0,
        "text": " Arson, yes, I do remember.",
        "tokens": [
          51252,
          1587,
          3015,
          11,
          2086,
          11,
          286,
          360,
          1604,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.19313219038106627,
        "compression_ratio": 1.6398467432950192,
        "end": 262.59999999999997,
        "id": 68,
        "no_speech_prob": 0.007011260837316513,
        "seek": 24004,
        "start": 260.68,
        "temperature": 0,
        "text": " And yes, there will be JavaScript stuff today.",
        "tokens": [
          51396,
          400,
          2086,
          11,
          456,
          486,
          312,
          15778,
          1507,
          965,
          13,
          51492
        ]
      },
      {
        "avg_logprob": -0.19313219038106627,
        "compression_ratio": 1.6398467432950192,
        "end": 266.12,
        "id": 69,
        "no_speech_prob": 0.007011260837316513,
        "seek": 24004,
        "start": 262.59999999999997,
        "temperature": 0,
        "text": " So the coding that I will do after I talk about the processing fellowships,",
        "tokens": [
          51492,
          407,
          264,
          17720,
          300,
          286,
          486,
          360,
          934,
          286,
          751,
          466,
          264,
          9007,
          24989,
          82,
          11,
          51668
        ]
      },
      {
        "avg_logprob": -0.2300543818913453,
        "compression_ratio": 1.6857142857142857,
        "end": 271.88,
        "id": 70,
        "no_speech_prob": 0.010012932121753693,
        "seek": 26612,
        "start": 267,
        "temperature": 0,
        "text": " I'm going to look at sentiment analysis with a word list known as the AFIN111.",
        "tokens": [
          50408,
          286,
          478,
          516,
          281,
          574,
          412,
          16149,
          5215,
          365,
          257,
          1349,
          1329,
          2570,
          382,
          264,
          20389,
          1464,
          5348,
          16,
          13,
          50652
        ]
      },
      {
        "avg_logprob": -0.2300543818913453,
        "compression_ratio": 1.6857142857142857,
        "end": 273.88,
        "id": 71,
        "no_speech_prob": 0.010012932121753693,
        "seek": 26612,
        "start": 273.08,
        "temperature": 0,
        "text": " Is that what you woke?",
        "tokens": [
          50712,
          1119,
          300,
          437,
          291,
          12852,
          30,
          50752
        ]
      },
      {
        "avg_logprob": -0.2300543818913453,
        "compression_ratio": 1.6857142857142857,
        "end": 275.16,
        "id": 72,
        "no_speech_prob": 0.010012932121753693,
        "seek": 26612,
        "start": 273.88,
        "temperature": 0,
        "text": " You were like, you're lying in bed.",
        "tokens": [
          50752,
          509,
          645,
          411,
          11,
          291,
          434,
          8493,
          294,
          2901,
          13,
          50816
        ]
      },
      {
        "avg_logprob": -0.2300543818913453,
        "compression_ratio": 1.6857142857142857,
        "end": 277.8,
        "id": 73,
        "no_speech_prob": 0.010012932121753693,
        "seek": 26612,
        "start": 277,
        "temperature": 0,
        "text": " Your alarm went off.",
        "tokens": [
          50908,
          2260,
          14183,
          1437,
          766,
          13,
          50948
        ]
      },
      {
        "avg_logprob": -0.2300543818913453,
        "compression_ratio": 1.6857142857142857,
        "end": 283.16,
        "id": 74,
        "no_speech_prob": 0.010012932121753693,
        "seek": 26612,
        "start": 279.96,
        "temperature": 0,
        "text": " And you woke up and you thought, I know what I'm going to do today.",
        "tokens": [
          51056,
          400,
          291,
          12852,
          493,
          293,
          291,
          1194,
          11,
          286,
          458,
          437,
          286,
          478,
          516,
          281,
          360,
          965,
          13,
          51216
        ]
      },
      {
        "avg_logprob": -0.2300543818913453,
        "compression_ratio": 1.6857142857142857,
        "end": 284.36,
        "id": 75,
        "no_speech_prob": 0.010012932121753693,
        "seek": 26612,
        "start": 283.16,
        "temperature": 0,
        "text": " I'm going to turn off my computer.",
        "tokens": [
          51216,
          286,
          478,
          516,
          281,
          1261,
          766,
          452,
          3820,
          13,
          51276
        ]
      },
      {
        "avg_logprob": -0.2300543818913453,
        "compression_ratio": 1.6857142857142857,
        "end": 287.8,
        "id": 76,
        "no_speech_prob": 0.010012932121753693,
        "seek": 26612,
        "start": 284.36,
        "temperature": 0,
        "text": " I'm going to watch somebody talk about AFIN111 sentiment analysis on YouTube.",
        "tokens": [
          51276,
          286,
          478,
          516,
          281,
          1159,
          2618,
          751,
          466,
          20389,
          1464,
          5348,
          16,
          16149,
          5215,
          322,
          3088,
          13,
          51448
        ]
      },
      {
        "avg_logprob": -0.2300543818913453,
        "compression_ratio": 1.6857142857142857,
        "end": 289.16,
        "id": 77,
        "no_speech_prob": 0.010012932121753693,
        "seek": 26612,
        "start": 287.8,
        "temperature": 0,
        "text": " Well, that's what's happening.",
        "tokens": [
          51448,
          1042,
          11,
          300,
          311,
          437,
          311,
          2737,
          13,
          51516
        ]
      },
      {
        "avg_logprob": -0.2300543818913453,
        "compression_ratio": 1.6857142857142857,
        "end": 290.6,
        "id": 78,
        "no_speech_prob": 0.010012932121753693,
        "seek": 26612,
        "start": 289.8,
        "temperature": 0,
        "text": " Oh, yeah.",
        "tokens": [
          51548,
          876,
          11,
          1338,
          13,
          51588
        ]
      },
      {
        "avg_logprob": -0.2300543818913453,
        "compression_ratio": 1.6857142857142857,
        "end": 295.88,
        "id": 79,
        "no_speech_prob": 0.010012932121753693,
        "seek": 26612,
        "start": 290.6,
        "temperature": 0,
        "text": " By the way, I noticed that Lourdes in the chat mentions everyone check out Siraj's channel.",
        "tokens": [
          51588,
          3146,
          264,
          636,
          11,
          286,
          5694,
          300,
          441,
          396,
          14792,
          294,
          264,
          5081,
          23844,
          1518,
          1520,
          484,
          6144,
          1805,
          311,
          2269,
          13,
          51852
        ]
      },
      {
        "avg_logprob": -0.1973790734764037,
        "compression_ratio": 1.6195121951219513,
        "end": 299.64,
        "id": 80,
        "no_speech_prob": 0.0002611799573060125,
        "seek": 29588,
        "start": 296.2,
        "temperature": 0,
        "text": " I noticed, actually, I got a notification that Siraj was also doing a live stream.",
        "tokens": [
          50380,
          286,
          5694,
          11,
          767,
          11,
          286,
          658,
          257,
          11554,
          300,
          6144,
          1805,
          390,
          611,
          884,
          257,
          1621,
          4309,
          13,
          50552
        ]
      },
      {
        "avg_logprob": -0.1973790734764037,
        "compression_ratio": 1.6195121951219513,
        "end": 301.32,
        "id": 81,
        "no_speech_prob": 0.0002611799573060125,
        "seek": 29588,
        "start": 299.64,
        "temperature": 0,
        "text": " Does anyone know if that's still going on?",
        "tokens": [
          50552,
          4402,
          2878,
          458,
          498,
          300,
          311,
          920,
          516,
          322,
          30,
          50636
        ]
      },
      {
        "avg_logprob": -0.1973790734764037,
        "compression_ratio": 1.6195121951219513,
        "end": 302.12,
        "id": 82,
        "no_speech_prob": 0.0002611799573060125,
        "seek": 29588,
        "start": 301.32,
        "temperature": 0,
        "text": " Let's pull it up.",
        "tokens": [
          50636,
          961,
          311,
          2235,
          309,
          493,
          13,
          50676
        ]
      },
      {
        "avg_logprob": -0.1973790734764037,
        "compression_ratio": 1.6195121951219513,
        "end": 305.15999999999997,
        "id": 83,
        "no_speech_prob": 0.0002611799573060125,
        "seek": 29588,
        "start": 302.76,
        "temperature": 0,
        "text": " Let's see if we can embed a live stream.",
        "tokens": [
          50708,
          961,
          311,
          536,
          498,
          321,
          393,
          12240,
          257,
          1621,
          4309,
          13,
          50828
        ]
      },
      {
        "avg_logprob": -0.1973790734764037,
        "compression_ratio": 1.6195121951219513,
        "end": 307.56,
        "id": 84,
        "no_speech_prob": 0.0002611799573060125,
        "seek": 29588,
        "start": 306.28,
        "temperature": 0,
        "text": " Siraj YouTube.",
        "tokens": [
          50884,
          6144,
          1805,
          3088,
          13,
          50948
        ]
      },
      {
        "avg_logprob": -0.1973790734764037,
        "compression_ratio": 1.6195121951219513,
        "end": 311.56,
        "id": 85,
        "no_speech_prob": 0.0002611799573060125,
        "seek": 29588,
        "start": 310.2,
        "temperature": 0,
        "text": " No, that's not right.",
        "tokens": [
          51080,
          883,
          11,
          300,
          311,
          406,
          558,
          13,
          51148
        ]
      },
      {
        "avg_logprob": -0.1973790734764037,
        "compression_ratio": 1.6195121951219513,
        "end": 313.56,
        "id": 86,
        "no_speech_prob": 0.0002611799573060125,
        "seek": 29588,
        "start": 311.56,
        "temperature": 0,
        "text": " Sirajology.",
        "tokens": [
          51148,
          6144,
          1805,
          1793,
          13,
          51248
        ]
      },
      {
        "avg_logprob": -0.1973790734764037,
        "compression_ratio": 1.6195121951219513,
        "end": 315.08,
        "id": 87,
        "no_speech_prob": 0.0002611799573060125,
        "seek": 29588,
        "start": 314.2,
        "temperature": 0,
        "text": " Sirajology?",
        "tokens": [
          51280,
          6144,
          1805,
          1793,
          30,
          51324
        ]
      },
      {
        "avg_logprob": -0.1973790734764037,
        "compression_ratio": 1.6195121951219513,
        "end": 316.84,
        "id": 88,
        "no_speech_prob": 0.0002611799573060125,
        "seek": 29588,
        "start": 315.8,
        "temperature": 0,
        "text": " Sirajology.",
        "tokens": [
          51360,
          6144,
          1805,
          1793,
          13,
          51412
        ]
      },
      {
        "avg_logprob": -0.1973790734764037,
        "compression_ratio": 1.6195121951219513,
        "end": 319.48,
        "id": 89,
        "no_speech_prob": 0.0002611799573060125,
        "seek": 29588,
        "start": 318.2,
        "temperature": 0,
        "text": " Is he live right now?",
        "tokens": [
          51480,
          1119,
          415,
          1621,
          558,
          586,
          30,
          51544
        ]
      },
      {
        "avg_logprob": -0.1973790734764037,
        "compression_ratio": 1.6195121951219513,
        "end": 319.96,
        "id": 90,
        "no_speech_prob": 0.0002611799573060125,
        "seek": 29588,
        "start": 319.48,
        "temperature": 0,
        "text": " Live.",
        "tokens": [
          51544,
          10385,
          13,
          51568
        ]
      },
      {
        "avg_logprob": -0.1973790734764037,
        "compression_ratio": 1.6195121951219513,
        "end": 321.96,
        "id": 91,
        "no_speech_prob": 0.0002611799573060125,
        "seek": 29588,
        "start": 320.84,
        "temperature": 0,
        "text": " Oh, but this is finished.",
        "tokens": [
          51612,
          876,
          11,
          457,
          341,
          307,
          4335,
          13,
          51668
        ]
      },
      {
        "avg_logprob": -0.1973790734764037,
        "compression_ratio": 1.6195121951219513,
        "end": 323.24,
        "id": 92,
        "no_speech_prob": 0.0002611799573060125,
        "seek": 29588,
        "start": 322.68,
        "temperature": 0,
        "text": " So I won't.",
        "tokens": [
          51704,
          407,
          286,
          1582,
          380,
          13,
          51732
        ]
      },
      {
        "avg_logprob": -0.1973790734764037,
        "compression_ratio": 1.6195121951219513,
        "end": 324.12,
        "id": 93,
        "no_speech_prob": 0.0002611799573060125,
        "seek": 29588,
        "start": 323.24,
        "temperature": 0,
        "text": " I won't.",
        "tokens": [
          51732,
          286,
          1582,
          380,
          13,
          51776
        ]
      },
      {
        "avg_logprob": -0.18596929158919898,
        "compression_ratio": 1.6511627906976745,
        "end": 326.6,
        "id": 94,
        "no_speech_prob": 0.006289617158472538,
        "seek": 32412,
        "start": 324.2,
        "temperature": 0,
        "text": " So anyway, I'm sure this was a great live stream.",
        "tokens": [
          50368,
          407,
          4033,
          11,
          286,
          478,
          988,
          341,
          390,
          257,
          869,
          1621,
          4309,
          13,
          50488
        ]
      },
      {
        "avg_logprob": -0.18596929158919898,
        "compression_ratio": 1.6511627906976745,
        "end": 328.68,
        "id": 95,
        "no_speech_prob": 0.006289617158472538,
        "seek": 32412,
        "start": 327.48,
        "temperature": 0,
        "text": " Oh, by the way, am I in focus?",
        "tokens": [
          50532,
          876,
          11,
          538,
          264,
          636,
          11,
          669,
          286,
          294,
          1879,
          30,
          50592
        ]
      },
      {
        "avg_logprob": -0.18596929158919898,
        "compression_ratio": 1.6511627906976745,
        "end": 329.88,
        "id": 96,
        "no_speech_prob": 0.006289617158472538,
        "seek": 32412,
        "start": 328.68,
        "temperature": 0,
        "text": " The camera was all out of focus.",
        "tokens": [
          50592,
          440,
          2799,
          390,
          439,
          484,
          295,
          1879,
          13,
          50652
        ]
      },
      {
        "avg_logprob": -0.18596929158919898,
        "compression_ratio": 1.6511627906976745,
        "end": 331.56,
        "id": 97,
        "no_speech_prob": 0.006289617158472538,
        "seek": 32412,
        "start": 329.88,
        "temperature": 0,
        "text": " I just randomly focused it.",
        "tokens": [
          50652,
          286,
          445,
          16979,
          5178,
          309,
          13,
          50736
        ]
      },
      {
        "avg_logprob": -0.18596929158919898,
        "compression_ratio": 1.6511627906976745,
        "end": 337.48,
        "id": 98,
        "no_speech_prob": 0.006289617158472538,
        "seek": 32412,
        "start": 332.28000000000003,
        "temperature": 0,
        "text": " So I don't know if I got myself in focus.",
        "tokens": [
          50772,
          407,
          286,
          500,
          380,
          458,
          498,
          286,
          658,
          2059,
          294,
          1879,
          13,
          51032
        ]
      },
      {
        "avg_logprob": -0.18596929158919898,
        "compression_ratio": 1.6511627906976745,
        "end": 341.48,
        "id": 99,
        "no_speech_prob": 0.006289617158472538,
        "seek": 32412,
        "start": 338.6,
        "temperature": 0,
        "text": " Siraj, I've been talking about Siraj doing a collaboration with him.",
        "tokens": [
          51088,
          6144,
          1805,
          11,
          286,
          600,
          668,
          1417,
          466,
          6144,
          1805,
          884,
          257,
          9363,
          365,
          796,
          13,
          51232
        ]
      },
      {
        "avg_logprob": -0.18596929158919898,
        "compression_ratio": 1.6511627906976745,
        "end": 344.04,
        "id": 100,
        "no_speech_prob": 0.006289617158472538,
        "seek": 32412,
        "start": 341.48,
        "temperature": 0,
        "text": " So I hope hopefully that will come at some point soon.",
        "tokens": [
          51232,
          407,
          286,
          1454,
          4696,
          300,
          486,
          808,
          412,
          512,
          935,
          2321,
          13,
          51360
        ]
      },
      {
        "avg_logprob": -0.18596929158919898,
        "compression_ratio": 1.6511627906976745,
        "end": 345.88,
        "id": 101,
        "no_speech_prob": 0.006289617158472538,
        "seek": 32412,
        "start": 344.04,
        "temperature": 0,
        "text": " I'm hoping to do some videos about machine learning.",
        "tokens": [
          51360,
          286,
          478,
          7159,
          281,
          360,
          512,
          2145,
          466,
          3479,
          2539,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.18596929158919898,
        "compression_ratio": 1.6511627906976745,
        "end": 346.68,
        "id": 102,
        "no_speech_prob": 0.006289617158472538,
        "seek": 32412,
        "start": 345.88,
        "temperature": 0,
        "text": " He does a ton of them.",
        "tokens": [
          51452,
          634,
          775,
          257,
          2952,
          295,
          552,
          13,
          51492
        ]
      },
      {
        "avg_logprob": -0.18596929158919898,
        "compression_ratio": 1.6511627906976745,
        "end": 347.48,
        "id": 103,
        "no_speech_prob": 0.006289617158472538,
        "seek": 32412,
        "start": 346.68,
        "temperature": 0,
        "text": " They're really terrific.",
        "tokens": [
          51492,
          814,
          434,
          534,
          20899,
          13,
          51532
        ]
      },
      {
        "avg_logprob": -0.18596929158919898,
        "compression_ratio": 1.6511627906976745,
        "end": 349.32,
        "id": 104,
        "no_speech_prob": 0.006289617158472538,
        "seek": 32412,
        "start": 348.76,
        "temperature": 0,
        "text": " I love them.",
        "tokens": [
          51596,
          286,
          959,
          552,
          13,
          51624
        ]
      },
      {
        "avg_logprob": -0.18596929158919898,
        "compression_ratio": 1.6511627906976745,
        "end": 349.96,
        "id": 105,
        "no_speech_prob": 0.006289617158472538,
        "seek": 32412,
        "start": 349.32,
        "temperature": 0,
        "text": " I watch them.",
        "tokens": [
          51624,
          286,
          1159,
          552,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.18596929158919898,
        "compression_ratio": 1.6511627906976745,
        "end": 352.04,
        "id": 106,
        "no_speech_prob": 0.006289617158472538,
        "seek": 32412,
        "start": 349.96,
        "temperature": 0,
        "text": " And then I think, oh, maybe I could learn this stuff too.",
        "tokens": [
          51656,
          400,
          550,
          286,
          519,
          11,
          1954,
          11,
          1310,
          286,
          727,
          1466,
          341,
          1507,
          886,
          13,
          51760
        ]
      },
      {
        "avg_logprob": -0.18596929158919898,
        "compression_ratio": 1.6511627906976745,
        "end": 353.32,
        "id": 107,
        "no_speech_prob": 0.006289617158472538,
        "seek": 32412,
        "start": 352.92,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51804,
          2264,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.2139051547948865,
        "compression_ratio": 1.6490066225165563,
        "end": 354.59999999999997,
        "id": 108,
        "no_speech_prob": 0.0003301390679553151,
        "seek": 35332,
        "start": 353.64,
        "temperature": 0,
        "text": " Sorry, I got sidetracked.",
        "tokens": [
          50380,
          4919,
          11,
          286,
          658,
          20822,
          27965,
          25949,
          13,
          50428
        ]
      },
      {
        "avg_logprob": -0.2139051547948865,
        "compression_ratio": 1.6490066225165563,
        "end": 355.48,
        "id": 109,
        "no_speech_prob": 0.0003301390679553151,
        "seek": 35332,
        "start": 354.59999999999997,
        "temperature": 0,
        "text": " What was I talking about?",
        "tokens": [
          50428,
          708,
          390,
          286,
          1417,
          466,
          30,
          50472
        ]
      },
      {
        "avg_logprob": -0.2139051547948865,
        "compression_ratio": 1.6490066225165563,
        "end": 359.08,
        "id": 110,
        "no_speech_prob": 0.0003301390679553151,
        "seek": 35332,
        "start": 356.12,
        "temperature": 0,
        "text": " OK, so the AFIN111 text stuff, I'm going to finish off.",
        "tokens": [
          50504,
          2264,
          11,
          370,
          264,
          20389,
          1464,
          5348,
          16,
          2487,
          1507,
          11,
          286,
          478,
          516,
          281,
          2413,
          766,
          13,
          50652
        ]
      },
      {
        "avg_logprob": -0.2139051547948865,
        "compression_ratio": 1.6490066225165563,
        "end": 364.04,
        "id": 111,
        "no_speech_prob": 0.0003301390679553151,
        "seek": 35332,
        "start": 359.08,
        "temperature": 0,
        "text": " So I want to do a coding challenge of just AFIN111 in the browser just to look at, hey,",
        "tokens": [
          50652,
          407,
          286,
          528,
          281,
          360,
          257,
          17720,
          3430,
          295,
          445,
          20389,
          1464,
          5348,
          16,
          294,
          264,
          11185,
          445,
          281,
          574,
          412,
          11,
          4177,
          11,
          50900
        ]
      },
      {
        "avg_logprob": -0.2139051547948865,
        "compression_ratio": 1.6490066225165563,
        "end": 368.52,
        "id": 112,
        "no_speech_prob": 0.0003301390679553151,
        "seek": 35332,
        "start": 364.04,
        "temperature": 0,
        "text": " I typed some text into a text field, and it gives me a sentiment score at the bottom.",
        "tokens": [
          50900,
          286,
          33941,
          512,
          2487,
          666,
          257,
          2487,
          2519,
          11,
          293,
          309,
          2709,
          385,
          257,
          16149,
          6175,
          412,
          264,
          2767,
          13,
          51124
        ]
      },
      {
        "avg_logprob": -0.2139051547948865,
        "compression_ratio": 1.6490066225165563,
        "end": 373.71999999999997,
        "id": 113,
        "no_speech_prob": 0.0003301390679553151,
        "seek": 35332,
        "start": 369.24,
        "temperature": 0,
        "text": " And then I'll also talk about other kinds of sentiment analysis beyond just this one",
        "tokens": [
          51160,
          400,
          550,
          286,
          603,
          611,
          751,
          466,
          661,
          3685,
          295,
          16149,
          5215,
          4399,
          445,
          341,
          472,
          51384
        ]
      },
      {
        "avg_logprob": -0.2139051547948865,
        "compression_ratio": 1.6490066225165563,
        "end": 375.88,
        "id": 114,
        "no_speech_prob": 0.0003301390679553151,
        "seek": 35332,
        "start": 373.71999999999997,
        "temperature": 0,
        "text": " technique, which is a very simple approach.",
        "tokens": [
          51384,
          6532,
          11,
          597,
          307,
          257,
          588,
          2199,
          3109,
          13,
          51492
        ]
      },
      {
        "avg_logprob": -0.2139051547948865,
        "compression_ratio": 1.6490066225165563,
        "end": 382.52,
        "id": 115,
        "no_speech_prob": 0.0003301390679553151,
        "seek": 35332,
        "start": 377.08,
        "temperature": 0,
        "text": " And then if there's, and then I want to also finish off my examples about building your",
        "tokens": [
          51552,
          400,
          550,
          498,
          456,
          311,
          11,
          293,
          550,
          286,
          528,
          281,
          611,
          2413,
          766,
          452,
          5110,
          466,
          2390,
          428,
          51824
        ]
      },
      {
        "avg_logprob": -0.14808928749778055,
        "compression_ratio": 1.6131687242798354,
        "end": 384.03999999999996,
        "id": 116,
        "no_speech_prob": 0.00024536674027331173,
        "seek": 38252,
        "start": 382.52,
        "temperature": 0,
        "text": " own API in Node.",
        "tokens": [
          50364,
          1065,
          9362,
          294,
          38640,
          13,
          50440
        ]
      },
      {
        "avg_logprob": -0.14808928749778055,
        "compression_ratio": 1.6131687242798354,
        "end": 390.35999999999996,
        "id": 117,
        "no_speech_prob": 0.00024536674027331173,
        "seek": 38252,
        "start": 384.03999999999996,
        "temperature": 0,
        "text": " So once we do the sentiment analysis in the browser, we'll transfer that into Node and",
        "tokens": [
          50440,
          407,
          1564,
          321,
          360,
          264,
          16149,
          5215,
          294,
          264,
          11185,
          11,
          321,
          603,
          5003,
          300,
          666,
          38640,
          293,
          50756
        ]
      },
      {
        "avg_logprob": -0.14808928749778055,
        "compression_ratio": 1.6131687242798354,
        "end": 395.56,
        "id": 118,
        "no_speech_prob": 0.00024536674027331173,
        "seek": 38252,
        "start": 390.35999999999996,
        "temperature": 0,
        "text": " make a sentiment analysis API and look at what it means to make a POST request versus",
        "tokens": [
          50756,
          652,
          257,
          16149,
          5215,
          9362,
          293,
          574,
          412,
          437,
          309,
          1355,
          281,
          652,
          257,
          430,
          28067,
          5308,
          5717,
          51016
        ]
      },
      {
        "avg_logprob": -0.14808928749778055,
        "compression_ratio": 1.6131687242798354,
        "end": 396.35999999999996,
        "id": 119,
        "no_speech_prob": 0.00024536674027331173,
        "seek": 38252,
        "start": 395.56,
        "temperature": 0,
        "text": " a GET request.",
        "tokens": [
          51016,
          257,
          28091,
          5308,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.14808928749778055,
        "compression_ratio": 1.6131687242798354,
        "end": 398.59999999999997,
        "id": 120,
        "no_speech_prob": 0.00024536674027331173,
        "seek": 38252,
        "start": 396.35999999999996,
        "temperature": 0,
        "text": " So that's on my list for today.",
        "tokens": [
          51056,
          407,
          300,
          311,
          322,
          452,
          1329,
          337,
          965,
          13,
          51168
        ]
      },
      {
        "avg_logprob": -0.14808928749778055,
        "compression_ratio": 1.6131687242798354,
        "end": 403.4,
        "id": 121,
        "no_speech_prob": 0.00024536674027331173,
        "seek": 38252,
        "start": 400.12,
        "temperature": 0,
        "text": " And then if there's extra time, I got some other things I would love to do.",
        "tokens": [
          51244,
          400,
          550,
          498,
          456,
          311,
          2857,
          565,
          11,
          286,
          658,
          512,
          661,
          721,
          286,
          576,
          959,
          281,
          360,
          13,
          51408
        ]
      },
      {
        "avg_logprob": -0.14808928749778055,
        "compression_ratio": 1.6131687242798354,
        "end": 404.59999999999997,
        "id": 122,
        "no_speech_prob": 0.00024536674027331173,
        "seek": 38252,
        "start": 403.4,
        "temperature": 0,
        "text": " I keep whacking the microphone.",
        "tokens": [
          51408,
          286,
          1066,
          315,
          14134,
          264,
          10952,
          13,
          51468
        ]
      },
      {
        "avg_logprob": -0.14808928749778055,
        "compression_ratio": 1.6131687242798354,
        "end": 406.35999999999996,
        "id": 123,
        "no_speech_prob": 0.00024536674027331173,
        "seek": 38252,
        "start": 404.59999999999997,
        "temperature": 0,
        "text": " I hope that's not making a weird sound for you.",
        "tokens": [
          51468,
          286,
          1454,
          300,
          311,
          406,
          1455,
          257,
          3657,
          1626,
          337,
          291,
          13,
          51556
        ]
      },
      {
        "avg_logprob": -0.1797651216095569,
        "compression_ratio": 1.548936170212766,
        "end": 412.92,
        "id": 124,
        "no_speech_prob": 0.29090404510498047,
        "seek": 40636,
        "start": 407.16,
        "temperature": 0,
        "text": " So let me say just a few quick words of where to find out more.",
        "tokens": [
          50404,
          407,
          718,
          385,
          584,
          445,
          257,
          1326,
          1702,
          2283,
          295,
          689,
          281,
          915,
          484,
          544,
          13,
          50692
        ]
      },
      {
        "avg_logprob": -0.1797651216095569,
        "compression_ratio": 1.548936170212766,
        "end": 420.44,
        "id": 125,
        "no_speech_prob": 0.29090404510498047,
        "seek": 40636,
        "start": 412.92,
        "temperature": 0,
        "text": " So at this website, which is hmmhmm.com, if you go there, you can subscribe.",
        "tokens": [
          50692,
          407,
          412,
          341,
          3144,
          11,
          597,
          307,
          16478,
          10250,
          13,
          1112,
          11,
          498,
          291,
          352,
          456,
          11,
          291,
          393,
          3022,
          13,
          51068
        ]
      },
      {
        "avg_logprob": -0.1797651216095569,
        "compression_ratio": 1.548936170212766,
        "end": 423.72,
        "id": 126,
        "no_speech_prob": 0.29090404510498047,
        "seek": 40636,
        "start": 420.44,
        "temperature": 0,
        "text": " You can become a patron if you are so inclined.",
        "tokens": [
          51068,
          509,
          393,
          1813,
          257,
          21843,
          498,
          291,
          366,
          370,
          28173,
          13,
          51232
        ]
      },
      {
        "avg_logprob": -0.1797651216095569,
        "compression_ratio": 1.548936170212766,
        "end": 427.48,
        "id": 127,
        "no_speech_prob": 0.29090404510498047,
        "seek": 40636,
        "start": 423.72,
        "temperature": 0,
        "text": " And there's a Slack channel that comes as a benefit of being a patron on this service",
        "tokens": [
          51232,
          400,
          456,
          311,
          257,
          37211,
          2269,
          300,
          1487,
          382,
          257,
          5121,
          295,
          885,
          257,
          21843,
          322,
          341,
          2643,
          51420
        ]
      },
      {
        "avg_logprob": -0.1797651216095569,
        "compression_ratio": 1.548936170212766,
        "end": 428.2,
        "id": 128,
        "no_speech_prob": 0.29090404510498047,
        "seek": 40636,
        "start": 427.48,
        "temperature": 0,
        "text": " called Patreon.",
        "tokens": [
          51420,
          1219,
          15692,
          13,
          51456
        ]
      },
      {
        "avg_logprob": -0.1797651216095569,
        "compression_ratio": 1.548936170212766,
        "end": 432.12,
        "id": 129,
        "no_speech_prob": 0.29090404510498047,
        "seek": 40636,
        "start": 428.84000000000003,
        "temperature": 0,
        "text": " One thing I just want to point out, though, is I get this question a lot.",
        "tokens": [
          51488,
          1485,
          551,
          286,
          445,
          528,
          281,
          935,
          484,
          11,
          1673,
          11,
          307,
          286,
          483,
          341,
          1168,
          257,
          688,
          13,
          51652
        ]
      },
      {
        "avg_logprob": -0.16500513670874423,
        "compression_ratio": 1.6241610738255035,
        "end": 438.92,
        "id": 130,
        "no_speech_prob": 0.001432520803064108,
        "seek": 43212,
        "start": 433,
        "temperature": 0,
        "text": " So these days with my live streams, I'm kind of off into the weeds of doing examples and",
        "tokens": [
          50408,
          407,
          613,
          1708,
          365,
          452,
          1621,
          15842,
          11,
          286,
          478,
          733,
          295,
          766,
          666,
          264,
          26370,
          295,
          884,
          5110,
          293,
          50704
        ]
      },
      {
        "avg_logprob": -0.16500513670874423,
        "compression_ratio": 1.6241610738255035,
        "end": 443.56,
        "id": 131,
        "no_speech_prob": 0.001432520803064108,
        "seek": 43212,
        "start": 438.92,
        "temperature": 0,
        "text": " coding ideas, assuming that the people watching have done some programming before.",
        "tokens": [
          50704,
          17720,
          3487,
          11,
          11926,
          300,
          264,
          561,
          1976,
          362,
          1096,
          512,
          9410,
          949,
          13,
          50936
        ]
      },
      {
        "avg_logprob": -0.16500513670874423,
        "compression_ratio": 1.6241610738255035,
        "end": 447.4,
        "id": 132,
        "no_speech_prob": 0.001432520803064108,
        "seek": 43212,
        "start": 443.56,
        "temperature": 0,
        "text": " And obviously, everybody watching, I'm sure, has a variety of different levels of experience.",
        "tokens": [
          50936,
          400,
          2745,
          11,
          2201,
          1976,
          11,
          286,
          478,
          988,
          11,
          575,
          257,
          5673,
          295,
          819,
          4358,
          295,
          1752,
          13,
          51128
        ]
      },
      {
        "avg_logprob": -0.16500513670874423,
        "compression_ratio": 1.6241610738255035,
        "end": 452.36,
        "id": 133,
        "no_speech_prob": 0.001432520803064108,
        "seek": 43212,
        "start": 448.2,
        "temperature": 0,
        "text": " But I always get the question, oh, what should I do if I don't know anything, if I want to",
        "tokens": [
          51168,
          583,
          286,
          1009,
          483,
          264,
          1168,
          11,
          1954,
          11,
          437,
          820,
          286,
          360,
          498,
          286,
          500,
          380,
          458,
          1340,
          11,
          498,
          286,
          528,
          281,
          51376
        ]
      },
      {
        "avg_logprob": -0.16500513670874423,
        "compression_ratio": 1.6241610738255035,
        "end": 454.28000000000003,
        "id": 134,
        "no_speech_prob": 0.001432520803064108,
        "seek": 43212,
        "start": 452.36,
        "temperature": 0,
        "text": " start learning to program from scratch?",
        "tokens": [
          51376,
          722,
          2539,
          281,
          1461,
          490,
          8459,
          30,
          51472
        ]
      },
      {
        "avg_logprob": -0.16500513670874423,
        "compression_ratio": 1.6241610738255035,
        "end": 459.8,
        "id": 135,
        "no_speech_prob": 0.001432520803064108,
        "seek": 43212,
        "start": 454.28000000000003,
        "temperature": 0,
        "text": " And so this playlist that's at the CodingRainbow.com website, you can look at that one,",
        "tokens": [
          51472,
          400,
          370,
          341,
          16788,
          300,
          311,
          412,
          264,
          383,
          8616,
          49,
          491,
          8202,
          13,
          1112,
          3144,
          11,
          291,
          393,
          574,
          412,
          300,
          472,
          11,
          51748
        ]
      },
      {
        "avg_logprob": -0.20706744492053986,
        "compression_ratio": 1.6645367412140575,
        "end": 464.36,
        "id": 136,
        "no_speech_prob": 0.04813374578952789,
        "seek": 45980,
        "start": 460.44,
        "temperature": 0,
        "text": " this will assume no knowledge of programming whatsoever and get you started using JavaScript.",
        "tokens": [
          50396,
          341,
          486,
          6552,
          572,
          3601,
          295,
          9410,
          17076,
          293,
          483,
          291,
          1409,
          1228,
          15778,
          13,
          50592
        ]
      },
      {
        "avg_logprob": -0.20706744492053986,
        "compression_ratio": 1.6645367412140575,
        "end": 467.72,
        "id": 137,
        "no_speech_prob": 0.04813374578952789,
        "seek": 45980,
        "start": 464.36,
        "temperature": 0,
        "text": " Of course, there are many other languages and other videos and books and things you",
        "tokens": [
          50592,
          2720,
          1164,
          11,
          456,
          366,
          867,
          661,
          8650,
          293,
          661,
          2145,
          293,
          3642,
          293,
          721,
          291,
          50760
        ]
      },
      {
        "avg_logprob": -0.20706744492053986,
        "compression_ratio": 1.6645367412140575,
        "end": 468.84000000000003,
        "id": 138,
        "no_speech_prob": 0.04813374578952789,
        "seek": 45980,
        "start": 467.72,
        "temperature": 0,
        "text": " can use to get started.",
        "tokens": [
          50760,
          393,
          764,
          281,
          483,
          1409,
          13,
          50816
        ]
      },
      {
        "avg_logprob": -0.20706744492053986,
        "compression_ratio": 1.6645367412140575,
        "end": 472.12,
        "id": 139,
        "no_speech_prob": 0.04813374578952789,
        "seek": 45980,
        "start": 468.84000000000003,
        "temperature": 0,
        "text": " But if you're looking for my stuff, this is what I would recommend right here.",
        "tokens": [
          50816,
          583,
          498,
          291,
          434,
          1237,
          337,
          452,
          1507,
          11,
          341,
          307,
          437,
          286,
          576,
          2748,
          558,
          510,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.20706744492053986,
        "compression_ratio": 1.6645367412140575,
        "end": 477.88,
        "id": 140,
        "no_speech_prob": 0.04813374578952789,
        "seek": 45980,
        "start": 472.76,
        "temperature": 0,
        "text": " I also have another playlist for processing, which is a Java-based environment, which is",
        "tokens": [
          51012,
          286,
          611,
          362,
          1071,
          16788,
          337,
          9007,
          11,
          597,
          307,
          257,
          10745,
          12,
          6032,
          2823,
          11,
          597,
          307,
          51268
        ]
      },
      {
        "avg_logprob": -0.20706744492053986,
        "compression_ratio": 1.6645367412140575,
        "end": 480.44,
        "id": 141,
        "no_speech_prob": 0.04813374578952789,
        "seek": 45980,
        "start": 477.88,
        "temperature": 0,
        "text": " beginner, for complete beginners that you can look at.",
        "tokens": [
          51268,
          22080,
          11,
          337,
          3566,
          26992,
          300,
          291,
          393,
          574,
          412,
          13,
          51396
        ]
      },
      {
        "avg_logprob": -0.20706744492053986,
        "compression_ratio": 1.6645367412140575,
        "end": 482.52,
        "id": 142,
        "no_speech_prob": 0.04813374578952789,
        "seek": 45980,
        "start": 480.44,
        "temperature": 0,
        "text": " And there's a textbook that goes along with that as well.",
        "tokens": [
          51396,
          400,
          456,
          311,
          257,
          25591,
          300,
          1709,
          2051,
          365,
          300,
          382,
          731,
          13,
          51500
        ]
      },
      {
        "avg_logprob": -0.20706744492053986,
        "compression_ratio": 1.6645367412140575,
        "end": 483.48,
        "id": 143,
        "no_speech_prob": 0.04813374578952789,
        "seek": 45980,
        "start": 483.16,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51532,
          2264,
          13,
          51548
        ]
      },
      {
        "avg_logprob": -0.20706744492053986,
        "compression_ratio": 1.6645367412140575,
        "end": 487.8,
        "id": 144,
        "no_speech_prob": 0.04813374578952789,
        "seek": 45980,
        "start": 486.12,
        "temperature": 0,
        "text": " So what else do I need to mention?",
        "tokens": [
          51680,
          407,
          437,
          1646,
          360,
          286,
          643,
          281,
          2152,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.1822723732855087,
        "compression_ratio": 1.61003861003861,
        "end": 492.68,
        "id": 145,
        "no_speech_prob": 0.013427871279418468,
        "seek": 48780,
        "start": 487.8,
        "temperature": 0,
        "text": " So I mentioned that I do send out emails periodically when I have a schedule for my",
        "tokens": [
          50364,
          407,
          286,
          2835,
          300,
          286,
          360,
          2845,
          484,
          12524,
          38916,
          562,
          286,
          362,
          257,
          7567,
          337,
          452,
          50608
        ]
      },
      {
        "avg_logprob": -0.1822723732855087,
        "compression_ratio": 1.61003861003861,
        "end": 493.24,
        "id": 146,
        "no_speech_prob": 0.013427871279418468,
        "seek": 48780,
        "start": 492.68,
        "temperature": 0,
        "text": " live stream.",
        "tokens": [
          50608,
          1621,
          4309,
          13,
          50636
        ]
      },
      {
        "avg_logprob": -0.1822723732855087,
        "compression_ratio": 1.61003861003861,
        "end": 494.92,
        "id": 147,
        "no_speech_prob": 0.013427871279418468,
        "seek": 48780,
        "start": 493.24,
        "temperature": 0,
        "text": " And you can also sign up for that here.",
        "tokens": [
          50636,
          400,
          291,
          393,
          611,
          1465,
          493,
          337,
          300,
          510,
          13,
          50720
        ]
      },
      {
        "avg_logprob": -0.1822723732855087,
        "compression_ratio": 1.61003861003861,
        "end": 497.08,
        "id": 148,
        "no_speech_prob": 0.013427871279418468,
        "seek": 48780,
        "start": 496.6,
        "temperature": 0,
        "text": " Let's see.",
        "tokens": [
          50804,
          961,
          311,
          536,
          13,
          50828
        ]
      },
      {
        "avg_logprob": -0.1822723732855087,
        "compression_ratio": 1.61003861003861,
        "end": 497.72,
        "id": 149,
        "no_speech_prob": 0.013427871279418468,
        "seek": 48780,
        "start": 497.08,
        "temperature": 0,
        "text": " Anything else?",
        "tokens": [
          50828,
          11998,
          1646,
          30,
          50860
        ]
      },
      {
        "avg_logprob": -0.1822723732855087,
        "compression_ratio": 1.61003861003861,
        "end": 503.16,
        "id": 150,
        "no_speech_prob": 0.013427871279418468,
        "seek": 48780,
        "start": 500.04,
        "temperature": 0,
        "text": " I do have my little soundboard, if you guys want to indulge me for a second.",
        "tokens": [
          50976,
          286,
          360,
          362,
          452,
          707,
          1626,
          3787,
          11,
          498,
          291,
          1074,
          528,
          281,
          28626,
          432,
          385,
          337,
          257,
          1150,
          13,
          51132
        ]
      },
      {
        "avg_logprob": -0.1822723732855087,
        "compression_ratio": 1.61003861003861,
        "end": 504.92,
        "id": 151,
        "no_speech_prob": 0.013427871279418468,
        "seek": 48780,
        "start": 503.8,
        "temperature": 0,
        "text": " I can try to get that hooked up.",
        "tokens": [
          51164,
          286,
          393,
          853,
          281,
          483,
          300,
          20410,
          493,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.1822723732855087,
        "compression_ratio": 1.61003861003861,
        "end": 506.44,
        "id": 152,
        "no_speech_prob": 0.013427871279418468,
        "seek": 48780,
        "start": 504.92,
        "temperature": 0,
        "text": " Let me see something here.",
        "tokens": [
          51220,
          961,
          385,
          536,
          746,
          510,
          13,
          51296
        ]
      },
      {
        "avg_logprob": -0.1822723732855087,
        "compression_ratio": 1.61003861003861,
        "end": 513.64,
        "id": 153,
        "no_speech_prob": 0.013427871279418468,
        "seek": 48780,
        "start": 506.44,
        "temperature": 0,
        "text": " Let's go back to Siraj and see if, because I want to see if sound is working.",
        "tokens": [
          51296,
          961,
          311,
          352,
          646,
          281,
          6144,
          1805,
          293,
          536,
          498,
          11,
          570,
          286,
          528,
          281,
          536,
          498,
          1626,
          307,
          1364,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.1822723732855087,
        "compression_ratio": 1.61003861003861,
        "end": 515.4,
        "id": 154,
        "no_speech_prob": 0.013427871279418468,
        "seek": 48780,
        "start": 514.76,
        "temperature": 0,
        "text": " We're going to play.",
        "tokens": [
          51712,
          492,
          434,
          516,
          281,
          862,
          13,
          51744
        ]
      },
      {
        "avg_logprob": -0.1822723732855087,
        "compression_ratio": 1.61003861003861,
        "end": 515.8,
        "id": 155,
        "no_speech_prob": 0.013427871279418468,
        "seek": 48780,
        "start": 515.4,
        "temperature": 0,
        "text": " Oops.",
        "tokens": [
          51744,
          21726,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1822723732855087,
        "compression_ratio": 1.61003861003861,
        "end": 516.52,
        "id": 156,
        "no_speech_prob": 0.013427871279418468,
        "seek": 48780,
        "start": 515.8,
        "temperature": 0,
        "text": " Oh, no, add.",
        "tokens": [
          51764,
          876,
          11,
          572,
          11,
          909,
          13,
          51800
        ]
      },
      {
        "avg_logprob": -0.20342847898408964,
        "compression_ratio": 1.3875,
        "end": 519.48,
        "id": 157,
        "no_speech_prob": 0.0007553720497526228,
        "seek": 51652,
        "start": 517.24,
        "temperature": 0,
        "text": " I'm not being paid to play this ad.",
        "tokens": [
          50400,
          286,
          478,
          406,
          885,
          4835,
          281,
          862,
          341,
          614,
          13,
          50512
        ]
      },
      {
        "avg_logprob": -0.20342847898408964,
        "compression_ratio": 1.3875,
        "end": 519.8,
        "id": 158,
        "no_speech_prob": 0.0007553720497526228,
        "seek": 51652,
        "start": 519.48,
        "temperature": 0,
        "text": " Skip.",
        "tokens": [
          50512,
          46405,
          13,
          50528
        ]
      },
      {
        "avg_logprob": -0.20342847898408964,
        "compression_ratio": 1.3875,
        "end": 527.3199999999999,
        "id": 159,
        "no_speech_prob": 0.0007553720497526228,
        "seek": 51652,
        "start": 524.92,
        "temperature": 0,
        "text": " I don't think you guys can hear Siraj.",
        "tokens": [
          50784,
          286,
          500,
          380,
          519,
          291,
          1074,
          393,
          1568,
          6144,
          1805,
          13,
          50904
        ]
      },
      {
        "avg_logprob": -0.20342847898408964,
        "compression_ratio": 1.3875,
        "end": 528.28,
        "id": 160,
        "no_speech_prob": 0.0007553720497526228,
        "seek": 51652,
        "start": 527.3199999999999,
        "temperature": 0,
        "text": " So I need to fix this.",
        "tokens": [
          50904,
          407,
          286,
          643,
          281,
          3191,
          341,
          13,
          50952
        ]
      },
      {
        "avg_logprob": -0.20342847898408964,
        "compression_ratio": 1.3875,
        "end": 533.72,
        "id": 161,
        "no_speech_prob": 0.0007553720497526228,
        "seek": 51652,
        "start": 529,
        "temperature": 0,
        "text": " System preferences, sound, multi-output device.",
        "tokens": [
          50988,
          8910,
          21910,
          11,
          1626,
          11,
          4825,
          12,
          346,
          2582,
          4302,
          13,
          51224
        ]
      },
      {
        "avg_logprob": -0.20342847898408964,
        "compression_ratio": 1.3875,
        "end": 535.4,
        "id": 162,
        "no_speech_prob": 0.0007553720497526228,
        "seek": 51652,
        "start": 533.72,
        "temperature": 0,
        "text": " This might change the sound in a second.",
        "tokens": [
          51224,
          639,
          1062,
          1319,
          264,
          1626,
          294,
          257,
          1150,
          13,
          51308
        ]
      },
      {
        "avg_logprob": -0.20342847898408964,
        "compression_ratio": 1.3875,
        "end": 539.96,
        "id": 163,
        "no_speech_prob": 0.0007553720497526228,
        "seek": 51652,
        "start": 539.0799999999999,
        "temperature": 0,
        "text": " Speak, Siraj.",
        "tokens": [
          51492,
          27868,
          11,
          6144,
          1805,
          13,
          51536
        ]
      },
      {
        "avg_logprob": -0.20342847898408964,
        "compression_ratio": 1.3875,
        "end": 545.56,
        "id": 164,
        "no_speech_prob": 0.0007553720497526228,
        "seek": 51652,
        "start": 544.6,
        "temperature": 0,
        "text": " See who we got.",
        "tokens": [
          51768,
          3008,
          567,
          321,
          658,
          13,
          51816
        ]
      },
      {
        "avg_logprob": -0.19958693330938165,
        "compression_ratio": 1.6899696048632218,
        "end": 547.24,
        "id": 165,
        "no_speech_prob": 0.00036257406463846564,
        "seek": 54652,
        "start": 546.52,
        "temperature": 0,
        "text": " What is that sound?",
        "tokens": [
          50364,
          708,
          307,
          300,
          1626,
          30,
          50400
        ]
      },
      {
        "avg_logprob": -0.19958693330938165,
        "compression_ratio": 1.6899696048632218,
        "end": 548.04,
        "id": 166,
        "no_speech_prob": 0.00036257406463846564,
        "seek": 54652,
        "start": 547.8,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50428,
          2264,
          13,
          50440
        ]
      },
      {
        "avg_logprob": -0.19958693330938165,
        "compression_ratio": 1.6899696048632218,
        "end": 548.76,
        "id": 167,
        "no_speech_prob": 0.00036257406463846564,
        "seek": 54652,
        "start": 548.04,
        "temperature": 0,
        "text": " I heard some music.",
        "tokens": [
          50440,
          286,
          2198,
          512,
          1318,
          13,
          50476
        ]
      },
      {
        "avg_logprob": -0.19958693330938165,
        "compression_ratio": 1.6899696048632218,
        "end": 550.52,
        "id": 168,
        "no_speech_prob": 0.00036257406463846564,
        "seek": 54652,
        "start": 549.8,
        "temperature": 0,
        "text": " Oh, what is that?",
        "tokens": [
          50528,
          876,
          11,
          437,
          307,
          300,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.19958693330938165,
        "compression_ratio": 1.6899696048632218,
        "end": 551,
        "id": 169,
        "no_speech_prob": 0.00036257406463846564,
        "seek": 54652,
        "start": 550.52,
        "temperature": 0,
        "text": " What is that?",
        "tokens": [
          50564,
          708,
          307,
          300,
          30,
          50588
        ]
      },
      {
        "avg_logprob": -0.19958693330938165,
        "compression_ratio": 1.6899696048632218,
        "end": 552.04,
        "id": 170,
        "no_speech_prob": 0.00036257406463846564,
        "seek": 54652,
        "start": 551,
        "temperature": 0,
        "text": " Hi, Siraj.",
        "tokens": [
          50588,
          2421,
          11,
          6144,
          1805,
          13,
          50640
        ]
      },
      {
        "avg_logprob": -0.19958693330938165,
        "compression_ratio": 1.6899696048632218,
        "end": 557.0799999999999,
        "id": 171,
        "no_speech_prob": 0.00036257406463846564,
        "seek": 54652,
        "start": 552.04,
        "temperature": 0,
        "text": " This is like some sort of weird meta performance thing where I'm speaking to you as if.",
        "tokens": [
          50640,
          639,
          307,
          411,
          512,
          1333,
          295,
          3657,
          19616,
          3389,
          551,
          689,
          286,
          478,
          4124,
          281,
          291,
          382,
          498,
          13,
          50892
        ]
      },
      {
        "avg_logprob": -0.19958693330938165,
        "compression_ratio": 1.6899696048632218,
        "end": 557.4,
        "id": 172,
        "no_speech_prob": 0.00036257406463846564,
        "seek": 54652,
        "start": 557.0799999999999,
        "temperature": 0,
        "text": " Come on.",
        "tokens": [
          50892,
          2492,
          322,
          13,
          50908
        ]
      },
      {
        "avg_logprob": -0.19958693330938165,
        "compression_ratio": 1.6899696048632218,
        "end": 557.8,
        "id": 173,
        "no_speech_prob": 0.00036257406463846564,
        "seek": 54652,
        "start": 557.4,
        "temperature": 0,
        "text": " It's OK.",
        "tokens": [
          50908,
          467,
          311,
          2264,
          13,
          50928
        ]
      },
      {
        "avg_logprob": -0.19958693330938165,
        "compression_ratio": 1.6899696048632218,
        "end": 558.68,
        "id": 174,
        "no_speech_prob": 0.00036257406463846564,
        "seek": 54652,
        "start": 557.8,
        "temperature": 0,
        "text": " The sound is working.",
        "tokens": [
          50928,
          440,
          1626,
          307,
          1364,
          13,
          50972
        ]
      },
      {
        "avg_logprob": -0.19958693330938165,
        "compression_ratio": 1.6899696048632218,
        "end": 559.72,
        "id": 175,
        "no_speech_prob": 0.00036257406463846564,
        "seek": 54652,
        "start": 558.68,
        "temperature": 0,
        "text": " You're live, except you're not.",
        "tokens": [
          50972,
          509,
          434,
          1621,
          11,
          3993,
          291,
          434,
          406,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.19958693330938165,
        "compression_ratio": 1.6899696048632218,
        "end": 560.68,
        "id": 176,
        "no_speech_prob": 0.00036257406463846564,
        "seek": 54652,
        "start": 559.72,
        "temperature": 0,
        "text": " This is recorded.",
        "tokens": [
          51024,
          639,
          307,
          8287,
          13,
          51072
        ]
      },
      {
        "avg_logprob": -0.19958693330938165,
        "compression_ratio": 1.6899696048632218,
        "end": 561.4,
        "id": 177,
        "no_speech_prob": 0.00036257406463846564,
        "seek": 54652,
        "start": 560.68,
        "temperature": 0,
        "text": " Hearing something.",
        "tokens": [
          51072,
          37875,
          746,
          13,
          51108
        ]
      },
      {
        "avg_logprob": -0.19958693330938165,
        "compression_ratio": 1.6899696048632218,
        "end": 563.3199999999999,
        "id": 178,
        "no_speech_prob": 0.00036257406463846564,
        "seek": 54652,
        "start": 561.4,
        "temperature": 0,
        "text": " See, look, we're doing a collaboration already.",
        "tokens": [
          51108,
          3008,
          11,
          574,
          11,
          321,
          434,
          884,
          257,
          9363,
          1217,
          13,
          51204
        ]
      },
      {
        "avg_logprob": -0.19958693330938165,
        "compression_ratio": 1.6899696048632218,
        "end": 564.28,
        "id": 179,
        "no_speech_prob": 0.00036257406463846564,
        "seek": 54652,
        "start": 563.3199999999999,
        "temperature": 0,
        "text": " I didn't realize it.",
        "tokens": [
          51204,
          286,
          994,
          380,
          4325,
          309,
          13,
          51252
        ]
      },
      {
        "avg_logprob": -0.19958693330938165,
        "compression_ratio": 1.6899696048632218,
        "end": 566.36,
        "id": 180,
        "no_speech_prob": 0.00036257406463846564,
        "seek": 54652,
        "start": 564.28,
        "temperature": 0,
        "text": " Somebody snapshot this and tweet it to Siraj.",
        "tokens": [
          51252,
          13463,
          30163,
          341,
          293,
          15258,
          309,
          281,
          6144,
          1805,
          13,
          51356
        ]
      },
      {
        "avg_logprob": -0.19958693330938165,
        "compression_ratio": 1.6899696048632218,
        "end": 569.24,
        "id": 181,
        "no_speech_prob": 0.00036257406463846564,
        "seek": 54652,
        "start": 566.36,
        "temperature": 0,
        "text": " I'm sure he would appreciate this weird thing that's happening right here.",
        "tokens": [
          51356,
          286,
          478,
          988,
          415,
          576,
          4449,
          341,
          3657,
          551,
          300,
          311,
          2737,
          558,
          510,
          13,
          51500
        ]
      },
      {
        "avg_logprob": -0.19958693330938165,
        "compression_ratio": 1.6899696048632218,
        "end": 571.24,
        "id": 182,
        "no_speech_prob": 0.00036257406463846564,
        "seek": 54652,
        "start": 569.24,
        "temperature": 0,
        "text": " But I think you're hearing the sound.",
        "tokens": [
          51500,
          583,
          286,
          519,
          291,
          434,
          4763,
          264,
          1626,
          13,
          51600
        ]
      },
      {
        "avg_logprob": -0.19958693330938165,
        "compression_ratio": 1.6899696048632218,
        "end": 575.96,
        "id": 183,
        "no_speech_prob": 0.00036257406463846564,
        "seek": 54652,
        "start": 573.3199999999999,
        "temperature": 0,
        "text": " And I could also do this and talk to myself.",
        "tokens": [
          51704,
          400,
          286,
          727,
          611,
          360,
          341,
          293,
          751,
          281,
          2059,
          13,
          51836
        ]
      },
      {
        "avg_logprob": -0.2158651806059338,
        "compression_ratio": 1.5728643216080402,
        "end": 577.08,
        "id": 184,
        "no_speech_prob": 0.0007096478366293013,
        "seek": 57596,
        "start": 575.96,
        "temperature": 0,
        "text": " And that would be a little bit weird.",
        "tokens": [
          50364,
          400,
          300,
          576,
          312,
          257,
          707,
          857,
          3657,
          13,
          50420
        ]
      },
      {
        "avg_logprob": -0.2158651806059338,
        "compression_ratio": 1.5728643216080402,
        "end": 577.32,
        "id": 185,
        "no_speech_prob": 0.0007096478366293013,
        "seek": 57596,
        "start": 577.08,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50420,
          2264,
          13,
          50432
        ]
      },
      {
        "avg_logprob": -0.2158651806059338,
        "compression_ratio": 1.5728643216080402,
        "end": 583.5600000000001,
        "id": 186,
        "no_speech_prob": 0.0007096478366293013,
        "seek": 57596,
        "start": 577.88,
        "temperature": 0,
        "text": " Now what I want to do here is go to soundboard.",
        "tokens": [
          50460,
          823,
          437,
          286,
          528,
          281,
          360,
          510,
          307,
          352,
          281,
          1626,
          3787,
          13,
          50744
        ]
      },
      {
        "avg_logprob": -0.2158651806059338,
        "compression_ratio": 1.5728643216080402,
        "end": 585,
        "id": 187,
        "no_speech_prob": 0.0007096478366293013,
        "seek": 57596,
        "start": 583.5600000000001,
        "temperature": 0,
        "text": " I have this soundboard app.",
        "tokens": [
          50744,
          286,
          362,
          341,
          1626,
          3787,
          724,
          13,
          50816
        ]
      },
      {
        "avg_logprob": -0.2158651806059338,
        "compression_ratio": 1.5728643216080402,
        "end": 592.2800000000001,
        "id": 188,
        "no_speech_prob": 0.0007096478366293013,
        "seek": 57596,
        "start": 586.2800000000001,
        "temperature": 0,
        "text": " And I can airplay it to this laptop.",
        "tokens": [
          50880,
          400,
          286,
          393,
          1988,
          2858,
          309,
          281,
          341,
          10732,
          13,
          51180
        ]
      },
      {
        "avg_logprob": -0.2158651806059338,
        "compression_ratio": 1.5728643216080402,
        "end": 593.32,
        "id": 189,
        "no_speech_prob": 0.0007096478366293013,
        "seek": 57596,
        "start": 592.2800000000001,
        "temperature": 0,
        "text": " You're going to see it in a second.",
        "tokens": [
          51180,
          509,
          434,
          516,
          281,
          536,
          309,
          294,
          257,
          1150,
          13,
          51232
        ]
      },
      {
        "avg_logprob": -0.2158651806059338,
        "compression_ratio": 1.5728643216080402,
        "end": 596.84,
        "id": 190,
        "no_speech_prob": 0.0007096478366293013,
        "seek": 57596,
        "start": 595.32,
        "temperature": 0,
        "text": " Oh, mirroring on.",
        "tokens": [
          51332,
          876,
          11,
          8013,
          278,
          322,
          13,
          51408
        ]
      },
      {
        "avg_logprob": -0.2158651806059338,
        "compression_ratio": 1.5728643216080402,
        "end": 599,
        "id": 191,
        "no_speech_prob": 0.0007096478366293013,
        "seek": 57596,
        "start": 598.2800000000001,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51480,
          821,
          321,
          352,
          13,
          51516
        ]
      },
      {
        "avg_logprob": -0.2158651806059338,
        "compression_ratio": 1.5728643216080402,
        "end": 602.84,
        "id": 192,
        "no_speech_prob": 0.0007096478366293013,
        "seek": 57596,
        "start": 600.12,
        "temperature": 0,
        "text": " And now you're seeing my soundboard, by the way.",
        "tokens": [
          51572,
          400,
          586,
          291,
          434,
          2577,
          452,
          1626,
          3787,
          11,
          538,
          264,
          636,
          13,
          51708
        ]
      },
      {
        "avg_logprob": -0.2158651806059338,
        "compression_ratio": 1.5728643216080402,
        "end": 605.48,
        "id": 193,
        "no_speech_prob": 0.0007096478366293013,
        "seek": 57596,
        "start": 602.84,
        "temperature": 0,
        "text": " This is how this little behind the scenes.",
        "tokens": [
          51708,
          639,
          307,
          577,
          341,
          707,
          2261,
          264,
          8026,
          13,
          51840
        ]
      },
      {
        "avg_logprob": -0.17951665224728885,
        "compression_ratio": 1.9535864978902953,
        "end": 606.36,
        "id": 194,
        "no_speech_prob": 0.0005702982889488339,
        "seek": 60548,
        "start": 605.48,
        "temperature": 0,
        "text": " Behind the music.",
        "tokens": [
          50364,
          20475,
          264,
          1318,
          13,
          50408
        ]
      },
      {
        "avg_logprob": -0.17951665224728885,
        "compression_ratio": 1.9535864978902953,
        "end": 608.2,
        "id": 195,
        "no_speech_prob": 0.0005702982889488339,
        "seek": 60548,
        "start": 607.08,
        "temperature": 0,
        "text": " So let's see if this works.",
        "tokens": [
          50444,
          407,
          718,
          311,
          536,
          498,
          341,
          1985,
          13,
          50500
        ]
      },
      {
        "avg_logprob": -0.17951665224728885,
        "compression_ratio": 1.9535864978902953,
        "end": 614.6,
        "id": 196,
        "no_speech_prob": 0.0005702982889488339,
        "seek": 60548,
        "start": 612.44,
        "temperature": 0,
        "text": " Does that sound horribly loud?",
        "tokens": [
          50712,
          4402,
          300,
          1626,
          45028,
          6588,
          30,
          50820
        ]
      },
      {
        "avg_logprob": -0.17951665224728885,
        "compression_ratio": 1.9535864978902953,
        "end": 619.16,
        "id": 197,
        "no_speech_prob": 0.0005702982889488339,
        "seek": 60548,
        "start": 615.64,
        "temperature": 0,
        "text": " As always, I always forget the this dot, this dot, this dot, this dot.",
        "tokens": [
          50872,
          1018,
          1009,
          11,
          286,
          1009,
          2870,
          264,
          341,
          5893,
          11,
          341,
          5893,
          11,
          341,
          5893,
          11,
          341,
          5893,
          13,
          51048
        ]
      },
      {
        "avg_logprob": -0.17951665224728885,
        "compression_ratio": 1.9535864978902953,
        "end": 620.84,
        "id": 198,
        "no_speech_prob": 0.0005702982889488339,
        "seek": 60548,
        "start": 619.16,
        "temperature": 0,
        "text": " I'm going to do this dot, this dot.",
        "tokens": [
          51048,
          286,
          478,
          516,
          281,
          360,
          341,
          5893,
          11,
          341,
          5893,
          13,
          51132
        ]
      },
      {
        "avg_logprob": -0.17951665224728885,
        "compression_ratio": 1.9535864978902953,
        "end": 623.32,
        "id": 199,
        "no_speech_prob": 0.0005702982889488339,
        "seek": 60548,
        "start": 620.84,
        "temperature": 0,
        "text": " I'm going to do this, this dot, this dot, this dot.",
        "tokens": [
          51132,
          286,
          478,
          516,
          281,
          360,
          341,
          11,
          341,
          5893,
          11,
          341,
          5893,
          11,
          341,
          5893,
          13,
          51256
        ]
      },
      {
        "avg_logprob": -0.17951665224728885,
        "compression_ratio": 1.9535864978902953,
        "end": 624.44,
        "id": 200,
        "no_speech_prob": 0.0005702982889488339,
        "seek": 60548,
        "start": 623.32,
        "temperature": 0,
        "text": " I'm going to do this.",
        "tokens": [
          51256,
          286,
          478,
          516,
          281,
          360,
          341,
          13,
          51312
        ]
      },
      {
        "avg_logprob": -0.17951665224728885,
        "compression_ratio": 1.9535864978902953,
        "end": 626.36,
        "id": 201,
        "no_speech_prob": 0.0005702982889488339,
        "seek": 60548,
        "start": 624.44,
        "temperature": 0,
        "text": " So it looks like I have a soundboard working.",
        "tokens": [
          51312,
          407,
          309,
          1542,
          411,
          286,
          362,
          257,
          1626,
          3787,
          1364,
          13,
          51408
        ]
      },
      {
        "avg_logprob": -0.17951665224728885,
        "compression_ratio": 1.9535864978902953,
        "end": 629.5600000000001,
        "id": 202,
        "no_speech_prob": 0.0005702982889488339,
        "seek": 60548,
        "start": 626.36,
        "temperature": 0,
        "text": " In case I need to play some music or things, I can minimize this.",
        "tokens": [
          51408,
          682,
          1389,
          286,
          643,
          281,
          862,
          512,
          1318,
          420,
          721,
          11,
          286,
          393,
          17522,
          341,
          13,
          51568
        ]
      },
      {
        "avg_logprob": -0.17951665224728885,
        "compression_ratio": 1.9535864978902953,
        "end": 631.8000000000001,
        "id": 203,
        "no_speech_prob": 0.0005702982889488339,
        "seek": 60548,
        "start": 629.5600000000001,
        "temperature": 0,
        "text": " You guys can let me know if the audio is a problem.",
        "tokens": [
          51568,
          509,
          1074,
          393,
          718,
          385,
          458,
          498,
          264,
          6278,
          307,
          257,
          1154,
          13,
          51680
        ]
      },
      {
        "avg_logprob": -0.17951665224728885,
        "compression_ratio": 1.9535864978902953,
        "end": 635.16,
        "id": 204,
        "no_speech_prob": 0.0005702982889488339,
        "seek": 60548,
        "start": 633.32,
        "temperature": 0,
        "text": " Nobody could get that screenshot in time.",
        "tokens": [
          51756,
          9297,
          727,
          483,
          300,
          27712,
          294,
          565,
          13,
          51848
        ]
      },
      {
        "avg_logprob": -0.1813608335968632,
        "compression_ratio": 1.750915750915751,
        "end": 637.24,
        "id": 205,
        "no_speech_prob": 0.00039820739766582847,
        "seek": 63516,
        "start": 635.56,
        "temperature": 0,
        "text": " You can reverse back in time.",
        "tokens": [
          50384,
          509,
          393,
          9943,
          646,
          294,
          565,
          13,
          50468
        ]
      },
      {
        "avg_logprob": -0.1813608335968632,
        "compression_ratio": 1.750915750915751,
        "end": 639.88,
        "id": 206,
        "no_speech_prob": 0.00039820739766582847,
        "seek": 63516,
        "start": 638.6,
        "temperature": 0,
        "text": " Maybe somebody else got it.",
        "tokens": [
          50536,
          2704,
          2618,
          1646,
          658,
          309,
          13,
          50600
        ]
      },
      {
        "avg_logprob": -0.1813608335968632,
        "compression_ratio": 1.750915750915751,
        "end": 640.68,
        "id": 207,
        "no_speech_prob": 0.00039820739766582847,
        "seek": 63516,
        "start": 639.88,
        "temperature": 0,
        "text": " It doesn't really matter.",
        "tokens": [
          50600,
          467,
          1177,
          380,
          534,
          1871,
          13,
          50640
        ]
      },
      {
        "avg_logprob": -0.1813608335968632,
        "compression_ratio": 1.750915750915751,
        "end": 641.3199999999999,
        "id": 208,
        "no_speech_prob": 0.00039820739766582847,
        "seek": 63516,
        "start": 640.68,
        "temperature": 0,
        "text": " This will be there.",
        "tokens": [
          50640,
          639,
          486,
          312,
          456,
          13,
          50672
        ]
      },
      {
        "avg_logprob": -0.1813608335968632,
        "compression_ratio": 1.750915750915751,
        "end": 644.4399999999999,
        "id": 209,
        "no_speech_prob": 0.00039820739766582847,
        "seek": 63516,
        "start": 641.3199999999999,
        "temperature": 0,
        "text": " Somebody will watch this later and then screenshot it then,",
        "tokens": [
          50672,
          13463,
          486,
          1159,
          341,
          1780,
          293,
          550,
          27712,
          309,
          550,
          11,
          50828
        ]
      },
      {
        "avg_logprob": -0.1813608335968632,
        "compression_ratio": 1.750915750915751,
        "end": 645.64,
        "id": 210,
        "no_speech_prob": 0.00039820739766582847,
        "seek": 63516,
        "start": 644.4399999999999,
        "temperature": 0,
        "text": " thinking they're watching it live.",
        "tokens": [
          50828,
          1953,
          436,
          434,
          1976,
          309,
          1621,
          13,
          50888
        ]
      },
      {
        "avg_logprob": -0.1813608335968632,
        "compression_ratio": 1.750915750915751,
        "end": 646.14,
        "id": 211,
        "no_speech_prob": 0.00039820739766582847,
        "seek": 63516,
        "start": 645.64,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50888,
          2264,
          13,
          50913
        ]
      },
      {
        "avg_logprob": -0.1813608335968632,
        "compression_ratio": 1.750915750915751,
        "end": 649.8,
        "id": 212,
        "no_speech_prob": 0.00039820739766582847,
        "seek": 63516,
        "start": 649.24,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51068,
          1057,
          558,
          13,
          51096
        ]
      },
      {
        "avg_logprob": -0.1813608335968632,
        "compression_ratio": 1.750915750915751,
        "end": 651,
        "id": 213,
        "no_speech_prob": 0.00039820739766582847,
        "seek": 63516,
        "start": 649.8,
        "temperature": 0,
        "text": " You guys love that song.",
        "tokens": [
          51096,
          509,
          1074,
          959,
          300,
          2153,
          13,
          51156
        ]
      },
      {
        "avg_logprob": -0.1813608335968632,
        "compression_ratio": 1.750915750915751,
        "end": 652.28,
        "id": 214,
        "no_speech_prob": 0.00039820739766582847,
        "seek": 63516,
        "start": 651,
        "temperature": 0,
        "text": " Somebody sent me a new song.",
        "tokens": [
          51156,
          13463,
          2279,
          385,
          257,
          777,
          2153,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.1813608335968632,
        "compression_ratio": 1.750915750915751,
        "end": 656.92,
        "id": 215,
        "no_speech_prob": 0.00039820739766582847,
        "seek": 63516,
        "start": 653.3199999999999,
        "temperature": 0,
        "text": " Lost G Bear on Slack sent me a new song that I don't have loaded yet.",
        "tokens": [
          51272,
          23422,
          460,
          19836,
          322,
          37211,
          2279,
          385,
          257,
          777,
          2153,
          300,
          286,
          500,
          380,
          362,
          13210,
          1939,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.1813608335968632,
        "compression_ratio": 1.750915750915751,
        "end": 659.3199999999999,
        "id": 216,
        "no_speech_prob": 0.00039820739766582847,
        "seek": 63516,
        "start": 656.92,
        "temperature": 0,
        "text": " If you're watching, I don't know if I got the name right.",
        "tokens": [
          51452,
          759,
          291,
          434,
          1976,
          11,
          286,
          500,
          380,
          458,
          498,
          286,
          658,
          264,
          1315,
          558,
          13,
          51572
        ]
      },
      {
        "avg_logprob": -0.1813608335968632,
        "compression_ratio": 1.750915750915751,
        "end": 659.8,
        "id": 217,
        "no_speech_prob": 0.00039820739766582847,
        "seek": 63516,
        "start": 659.3199999999999,
        "temperature": 0,
        "text": " Let me know.",
        "tokens": [
          51572,
          961,
          385,
          458,
          13,
          51596
        ]
      },
      {
        "avg_logprob": -0.1813608335968632,
        "compression_ratio": 1.750915750915751,
        "end": 661,
        "id": 218,
        "no_speech_prob": 0.00039820739766582847,
        "seek": 63516,
        "start": 659.8,
        "temperature": 0,
        "text": " Maybe I'll play that song.",
        "tokens": [
          51596,
          2704,
          286,
          603,
          862,
          300,
          2153,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.1813608335968632,
        "compression_ratio": 1.750915750915751,
        "end": 664.28,
        "id": 219,
        "no_speech_prob": 0.00039820739766582847,
        "seek": 63516,
        "start": 661.56,
        "temperature": 0,
        "text": " I'm hoping to have a new logo, a new name.",
        "tokens": [
          51684,
          286,
          478,
          7159,
          281,
          362,
          257,
          777,
          9699,
          11,
          257,
          777,
          1315,
          13,
          51820
        ]
      },
      {
        "avg_logprob": -0.19575868334089006,
        "compression_ratio": 1.797945205479452,
        "end": 667.4,
        "id": 220,
        "no_speech_prob": 0.0005112240905873477,
        "seek": 66516,
        "start": 665.16,
        "temperature": 0,
        "text": " A new song, a new video, all of these things.",
        "tokens": [
          50364,
          316,
          777,
          2153,
          11,
          257,
          777,
          960,
          11,
          439,
          295,
          613,
          721,
          13,
          50476
        ]
      },
      {
        "avg_logprob": -0.19575868334089006,
        "compression_ratio": 1.797945205479452,
        "end": 672.28,
        "id": 221,
        "no_speech_prob": 0.0005112240905873477,
        "seek": 66516,
        "start": 667.4,
        "temperature": 0,
        "text": " It's really unfortunate that I have this name and logo and video and song.",
        "tokens": [
          50476,
          467,
          311,
          534,
          17843,
          300,
          286,
          362,
          341,
          1315,
          293,
          9699,
          293,
          960,
          293,
          2153,
          13,
          50720
        ]
      },
      {
        "avg_logprob": -0.19575868334089006,
        "compression_ratio": 1.797945205479452,
        "end": 674.28,
        "id": 222,
        "no_speech_prob": 0.0005112240905873477,
        "seek": 66516,
        "start": 672.28,
        "temperature": 0,
        "text": " And unfortunately, I can't use the name anymore.",
        "tokens": [
          50720,
          400,
          7015,
          11,
          286,
          393,
          380,
          764,
          264,
          1315,
          3602,
          13,
          50820
        ]
      },
      {
        "avg_logprob": -0.19575868334089006,
        "compression_ratio": 1.797945205479452,
        "end": 677.0799999999999,
        "id": 223,
        "no_speech_prob": 0.0005112240905873477,
        "seek": 66516,
        "start": 674.28,
        "temperature": 0,
        "text": " So there was a lot of time and effort went into that.",
        "tokens": [
          50820,
          407,
          456,
          390,
          257,
          688,
          295,
          565,
          293,
          4630,
          1437,
          666,
          300,
          13,
          50960
        ]
      },
      {
        "avg_logprob": -0.19575868334089006,
        "compression_ratio": 1.797945205479452,
        "end": 679.0799999999999,
        "id": 224,
        "no_speech_prob": 0.0005112240905873477,
        "seek": 66516,
        "start": 677.0799999999999,
        "temperature": 0,
        "text": " And there just hasn't been a lot of time to do anything new.",
        "tokens": [
          50960,
          400,
          456,
          445,
          6132,
          380,
          668,
          257,
          688,
          295,
          565,
          281,
          360,
          1340,
          777,
          13,
          51060
        ]
      },
      {
        "avg_logprob": -0.19575868334089006,
        "compression_ratio": 1.797945205479452,
        "end": 680.4399999999999,
        "id": 225,
        "no_speech_prob": 0.0005112240905873477,
        "seek": 66516,
        "start": 679.0799999999999,
        "temperature": 0,
        "text": " But I will get started on that.",
        "tokens": [
          51060,
          583,
          286,
          486,
          483,
          1409,
          322,
          300,
          13,
          51128
        ]
      },
      {
        "avg_logprob": -0.19575868334089006,
        "compression_ratio": 1.797945205479452,
        "end": 680.9399999999999,
        "id": 226,
        "no_speech_prob": 0.0005112240905873477,
        "seek": 66516,
        "start": 680.4399999999999,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51128,
          2264,
          13,
          51153
        ]
      },
      {
        "avg_logprob": -0.19575868334089006,
        "compression_ratio": 1.797945205479452,
        "end": 682.36,
        "id": 227,
        "no_speech_prob": 0.0005112240905873477,
        "seek": 66516,
        "start": 681.24,
        "temperature": 0,
        "text": " Hello to Brazil.",
        "tokens": [
          51168,
          2425,
          281,
          9435,
          13,
          51224
        ]
      },
      {
        "avg_logprob": -0.19575868334089006,
        "compression_ratio": 1.797945205479452,
        "end": 683.64,
        "id": 228,
        "no_speech_prob": 0.0005112240905873477,
        "seek": 66516,
        "start": 683,
        "temperature": 0,
        "text": " Oh, yes.",
        "tokens": [
          51256,
          876,
          11,
          2086,
          13,
          51288
        ]
      },
      {
        "avg_logprob": -0.19575868334089006,
        "compression_ratio": 1.797945205479452,
        "end": 686.68,
        "id": 229,
        "no_speech_prob": 0.0005112240905873477,
        "seek": 66516,
        "start": 683.64,
        "temperature": 0,
        "text": " So if you're looking for the this dot song, there are actually two this dot songs.",
        "tokens": [
          51288,
          407,
          498,
          291,
          434,
          1237,
          337,
          264,
          341,
          5893,
          2153,
          11,
          456,
          366,
          767,
          732,
          341,
          5893,
          5781,
          13,
          51440
        ]
      },
      {
        "avg_logprob": -0.19575868334089006,
        "compression_ratio": 1.797945205479452,
        "end": 690.36,
        "id": 230,
        "no_speech_prob": 0.0005112240905873477,
        "seek": 66516,
        "start": 686.68,
        "temperature": 0,
        "text": " One by F Looper and one by Christian Peterson.",
        "tokens": [
          51440,
          1485,
          538,
          479,
          6130,
          7192,
          293,
          472,
          538,
          5778,
          36943,
          13,
          51624
        ]
      },
      {
        "avg_logprob": -0.19575868334089006,
        "compression_ratio": 1.797945205479452,
        "end": 693.8,
        "id": 231,
        "no_speech_prob": 0.0005112240905873477,
        "seek": 66516,
        "start": 691,
        "temperature": 0,
        "text": " If you're looking for those, since it was asked.",
        "tokens": [
          51656,
          759,
          291,
          434,
          1237,
          337,
          729,
          11,
          1670,
          309,
          390,
          2351,
          13,
          51796
        ]
      },
      {
        "avg_logprob": -0.299670174008324,
        "compression_ratio": 1.658878504672897,
        "end": 700.8399999999999,
        "id": 232,
        "no_speech_prob": 0.0062885829247534275,
        "seek": 69380,
        "start": 693.8,
        "temperature": 0,
        "text": " If you go to SoundCloud, I think if I just look Daniel Shiffman playlist,",
        "tokens": [
          50364,
          759,
          291,
          352,
          281,
          14673,
          32787,
          11,
          286,
          519,
          498,
          286,
          445,
          574,
          8033,
          1160,
          3661,
          1601,
          16788,
          11,
          50716
        ]
      },
      {
        "avg_logprob": -0.299670174008324,
        "compression_ratio": 1.658878504672897,
        "end": 704.3599999999999,
        "id": 233,
        "no_speech_prob": 0.0062885829247534275,
        "seek": 69380,
        "start": 702.8399999999999,
        "temperature": 0,
        "text": " this dot, well, this comes up.",
        "tokens": [
          50816,
          341,
          5893,
          11,
          731,
          11,
          341,
          1487,
          493,
          13,
          50892
        ]
      },
      {
        "avg_logprob": -0.299670174008324,
        "compression_ratio": 1.658878504672897,
        "end": 712.04,
        "id": 234,
        "no_speech_prob": 0.0062885829247534275,
        "seek": 69380,
        "start": 704.3599999999999,
        "temperature": 0,
        "text": " But yeah, Daniel Shiffman's Coding Rainbow, the remixes is a few different remixes.",
        "tokens": [
          50892,
          583,
          1338,
          11,
          8033,
          1160,
          3661,
          1601,
          311,
          383,
          8616,
          29477,
          11,
          264,
          890,
          36005,
          307,
          257,
          1326,
          819,
          890,
          36005,
          13,
          51276
        ]
      },
      {
        "avg_logprob": -0.299670174008324,
        "compression_ratio": 1.658878504672897,
        "end": 713,
        "id": 235,
        "no_speech_prob": 0.0062885829247534275,
        "seek": 69380,
        "start": 712.04,
        "temperature": 0,
        "text": " So this is random.",
        "tokens": [
          51276,
          407,
          341,
          307,
          4974,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.299670174008324,
        "compression_ratio": 1.658878504672897,
        "end": 713.8,
        "id": 236,
        "no_speech_prob": 0.0062885829247534275,
        "seek": 69380,
        "start": 713,
        "temperature": 0,
        "text": " This is noise.",
        "tokens": [
          51324,
          639,
          307,
          5658,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.299670174008324,
        "compression_ratio": 1.658878504672897,
        "end": 714.76,
        "id": 237,
        "no_speech_prob": 0.0062885829247534275,
        "seek": 69380,
        "start": 713.8,
        "temperature": 0,
        "text": " This is Perlin noise.",
        "tokens": [
          51364,
          639,
          307,
          3026,
          5045,
          5658,
          13,
          51412
        ]
      },
      {
        "avg_logprob": -0.299670174008324,
        "compression_ratio": 1.658878504672897,
        "end": 719.56,
        "id": 238,
        "no_speech_prob": 0.0062885829247534275,
        "seek": 69380,
        "start": 714.76,
        "temperature": 0,
        "text": " That is in the core random algorithm, the actual random algorithm itself.",
        "tokens": [
          51412,
          663,
          307,
          294,
          264,
          4965,
          4974,
          9284,
          11,
          264,
          3539,
          4974,
          9284,
          2564,
          13,
          51652
        ]
      },
      {
        "avg_logprob": -0.299670174008324,
        "compression_ratio": 1.658878504672897,
        "end": 722.1999999999999,
        "id": 239,
        "no_speech_prob": 0.0062885829247534275,
        "seek": 69380,
        "start": 719.56,
        "temperature": 0,
        "text": " Those numbers aren't related at all.",
        "tokens": [
          51652,
          3950,
          3547,
          3212,
          380,
          4077,
          412,
          439,
          13,
          51784
        ]
      },
      {
        "avg_logprob": -0.21632301330566406,
        "compression_ratio": 1.5714285714285714,
        "end": 725,
        "id": 240,
        "no_speech_prob": 0.008059809915721416,
        "seek": 72220,
        "start": 722.9200000000001,
        "temperature": 0,
        "text": " I'm picking random numbers between 0 and 10.",
        "tokens": [
          50400,
          286,
          478,
          8867,
          4974,
          3547,
          1296,
          1958,
          293,
          1266,
          13,
          50504
        ]
      },
      {
        "avg_logprob": -0.21632301330566406,
        "compression_ratio": 1.5714285714285714,
        "end": 729.8000000000001,
        "id": 241,
        "no_speech_prob": 0.008059809915721416,
        "seek": 72220,
        "start": 725,
        "temperature": 0,
        "text": " 9, 2, 7, 6, 1, 9, 4, 8, 9, 2, 1, 3.",
        "tokens": [
          50504,
          1722,
          11,
          568,
          11,
          1614,
          11,
          1386,
          11,
          502,
          11,
          1722,
          11,
          1017,
          11,
          1649,
          11,
          1722,
          11,
          568,
          11,
          502,
          11,
          805,
          13,
          50744
        ]
      },
      {
        "avg_logprob": -0.21632301330566406,
        "compression_ratio": 1.5714285714285714,
        "end": 731.8000000000001,
        "id": 242,
        "no_speech_prob": 0.008059809915721416,
        "seek": 72220,
        "start": 729.8000000000001,
        "temperature": 0,
        "text": " So you guys can download and enjoy these songs.",
        "tokens": [
          50744,
          407,
          291,
          1074,
          393,
          5484,
          293,
          2103,
          613,
          5781,
          13,
          50844
        ]
      },
      {
        "avg_logprob": -0.21632301330566406,
        "compression_ratio": 1.5714285714285714,
        "end": 735,
        "id": 243,
        "no_speech_prob": 0.008059809915721416,
        "seek": 72220,
        "start": 731.8000000000001,
        "temperature": 0,
        "text": " If anybody wants to make more songs, I love it.",
        "tokens": [
          50844,
          759,
          4472,
          2738,
          281,
          652,
          544,
          5781,
          11,
          286,
          959,
          309,
          13,
          51004
        ]
      },
      {
        "avg_logprob": -0.21632301330566406,
        "compression_ratio": 1.5714285714285714,
        "end": 737,
        "id": 244,
        "no_speech_prob": 0.008059809915721416,
        "seek": 72220,
        "start": 735,
        "temperature": 0,
        "text": " Nothing thrills me more than music.",
        "tokens": [
          51004,
          6693,
          739,
          2565,
          385,
          544,
          813,
          1318,
          13,
          51104
        ]
      },
      {
        "avg_logprob": -0.21632301330566406,
        "compression_ratio": 1.5714285714285714,
        "end": 741.48,
        "id": 245,
        "no_speech_prob": 0.008059809915721416,
        "seek": 72220,
        "start": 737,
        "temperature": 0,
        "text": " I'm just like a failed musical theater wannabe person.",
        "tokens": [
          51104,
          286,
          478,
          445,
          411,
          257,
          7612,
          9165,
          10612,
          38064,
          4488,
          954,
          13,
          51328
        ]
      },
      {
        "avg_logprob": -0.21632301330566406,
        "compression_ratio": 1.5714285714285714,
        "end": 744.0400000000001,
        "id": 246,
        "no_speech_prob": 0.008059809915721416,
        "seek": 72220,
        "start": 741.48,
        "temperature": 0,
        "text": " And then I just make programming videos on YouTube.",
        "tokens": [
          51328,
          400,
          550,
          286,
          445,
          652,
          9410,
          2145,
          322,
          3088,
          13,
          51456
        ]
      },
      {
        "avg_logprob": -0.21632301330566406,
        "compression_ratio": 1.5714285714285714,
        "end": 747.8000000000001,
        "id": 247,
        "no_speech_prob": 0.008059809915721416,
        "seek": 72220,
        "start": 744.0400000000001,
        "temperature": 0,
        "text": " So if I could somehow, you know, I forgot to enter the Hamilton lottery today.",
        "tokens": [
          51456,
          407,
          498,
          286,
          727,
          6063,
          11,
          291,
          458,
          11,
          286,
          5298,
          281,
          3242,
          264,
          18484,
          27391,
          965,
          13,
          51644
        ]
      },
      {
        "avg_logprob": -0.21632301330566406,
        "compression_ratio": 1.5714285714285714,
        "end": 748.6,
        "id": 248,
        "no_speech_prob": 0.008059809915721416,
        "seek": 72220,
        "start": 747.8000000000001,
        "temperature": 0,
        "text": " Maybe there's still time.",
        "tokens": [
          51644,
          2704,
          456,
          311,
          920,
          565,
          13,
          51684
        ]
      },
      {
        "avg_logprob": -0.21632301330566406,
        "compression_ratio": 1.5714285714285714,
        "end": 749.72,
        "id": 249,
        "no_speech_prob": 0.008059809915721416,
        "seek": 72220,
        "start": 748.6,
        "temperature": 0,
        "text": " Maybe I should enter it live.",
        "tokens": [
          51684,
          2704,
          286,
          820,
          3242,
          309,
          1621,
          13,
          51740
        ]
      },
      {
        "avg_logprob": -0.21632301330566406,
        "compression_ratio": 1.5714285714285714,
        "end": 751.32,
        "id": 250,
        "no_speech_prob": 0.008059809915721416,
        "seek": 72220,
        "start": 749.72,
        "temperature": 0,
        "text": " Because usually you can enter it till 4.",
        "tokens": [
          51740,
          1436,
          2673,
          291,
          393,
          3242,
          309,
          4288,
          1017,
          13,
          51820
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 752.6,
        "id": 251,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 751.48,
        "temperature": 0,
        "text": " You guys don't mind, do you?",
        "tokens": [
          50372,
          509,
          1074,
          500,
          380,
          1575,
          11,
          360,
          291,
          30,
          50428
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 754.12,
        "id": 252,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 753.24,
        "temperature": 0,
        "text": " I have an app.",
        "tokens": [
          50460,
          286,
          362,
          364,
          724,
          13,
          50504
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 755.32,
        "id": 253,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 754.12,
        "temperature": 0,
        "text": " It's really fast, I swear.",
        "tokens": [
          50504,
          467,
          311,
          534,
          2370,
          11,
          286,
          11902,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 758.9200000000001,
        "id": 254,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 757.08,
        "temperature": 0,
        "text": " I'll put on the This Dot song for you guys.",
        "tokens": [
          50652,
          286,
          603,
          829,
          322,
          264,
          639,
          38753,
          2153,
          337,
          291,
          1074,
          13,
          50744
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 760.6800000000001,
        "id": 255,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 758.9200000000001,
        "temperature": 0,
        "text": " As always, I always forget the This Dot.",
        "tokens": [
          50744,
          1018,
          1009,
          11,
          286,
          1009,
          2870,
          264,
          639,
          38753,
          13,
          50832
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 762.36,
        "id": 256,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 760.6800000000001,
        "temperature": 0,
        "text": " This Dot, This Dot, This Dot.",
        "tokens": [
          50832,
          639,
          38753,
          11,
          639,
          38753,
          11,
          639,
          38753,
          13,
          50916
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 763.48,
        "id": 257,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 762.36,
        "temperature": 0,
        "text": " I'm going to do This Dot, This Dot.",
        "tokens": [
          50916,
          286,
          478,
          516,
          281,
          360,
          639,
          38753,
          11,
          639,
          38753,
          13,
          50972
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 766.6,
        "id": 258,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 763.48,
        "temperature": 0,
        "text": " I'm going to do This Dot, This Dot, This Dot.",
        "tokens": [
          50972,
          286,
          478,
          516,
          281,
          360,
          639,
          38753,
          11,
          639,
          38753,
          11,
          639,
          38753,
          13,
          51128
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 767.24,
        "id": 259,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 766.6,
        "temperature": 0,
        "text": " I'm going to do This Dot, This Dot, This Dot.",
        "tokens": [
          51128,
          286,
          478,
          516,
          281,
          360,
          639,
          38753,
          11,
          639,
          38753,
          11,
          639,
          38753,
          13,
          51160
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 767.8000000000001,
        "id": 260,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 767.24,
        "temperature": 0,
        "text": " What's today?",
        "tokens": [
          51160,
          708,
          311,
          965,
          30,
          51188
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 768.2800000000001,
        "id": 261,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 767.8000000000001,
        "temperature": 0,
        "text": " This Dot.",
        "tokens": [
          51188,
          639,
          38753,
          13,
          51212
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 769.6400000000001,
        "id": 262,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 768.2800000000001,
        "temperature": 0,
        "text": " I'm going to do Wednesday.",
        "tokens": [
          51212,
          286,
          478,
          516,
          281,
          360,
          10579,
          13,
          51280
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 770.2800000000001,
        "id": 263,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 769.6400000000001,
        "temperature": 0,
        "text": " Yes, Wednesday.",
        "tokens": [
          51280,
          1079,
          11,
          10579,
          13,
          51312
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 770.6800000000001,
        "id": 264,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 770.2800000000001,
        "temperature": 0,
        "text": " This Dot.",
        "tokens": [
          51312,
          639,
          38753,
          13,
          51332
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 772.7600000000001,
        "id": 265,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 771.6400000000001,
        "temperature": 0,
        "text": " This Dot, This Dot, This Dot.",
        "tokens": [
          51380,
          639,
          38753,
          11,
          639,
          38753,
          11,
          639,
          38753,
          13,
          51436
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 773.24,
        "id": 266,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 772.7600000000001,
        "temperature": 0,
        "text": " Enter.",
        "tokens": [
          51436,
          10399,
          13,
          51460
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 774.0400000000001,
        "id": 267,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 773.24,
        "temperature": 0,
        "text": " This Dot.",
        "tokens": [
          51460,
          639,
          38753,
          13,
          51500
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 775.1600000000001,
        "id": 268,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 774.0400000000001,
        "temperature": 0,
        "text": " Closes at 4 PM.",
        "tokens": [
          51500,
          2033,
          4201,
          412,
          1017,
          12499,
          13,
          51556
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 776.0400000000001,
        "id": 269,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 775.1600000000001,
        "temperature": 0,
        "text": " Live on the air.",
        "tokens": [
          51556,
          10385,
          322,
          264,
          1988,
          13,
          51600
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 778.0400000000001,
        "id": 270,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 776.0400000000001,
        "temperature": 0,
        "text": " I can't check at 4 o'clock.",
        "tokens": [
          51600,
          286,
          393,
          380,
          1520,
          412,
          1017,
          277,
          6,
          9023,
          13,
          51700
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 779.4000000000001,
        "id": 271,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 778.0400000000001,
        "temperature": 0,
        "text": " Somebody can remind me.",
        "tokens": [
          51700,
          13463,
          393,
          4160,
          385,
          13,
          51768
        ]
      },
      {
        "avg_logprob": -0.33754515167850774,
        "compression_ratio": 2.0721153846153846,
        "end": 780.4399999999999,
        "id": 272,
        "no_speech_prob": 0.0726078525185585,
        "seek": 77940,
        "start": 779.4,
        "temperature": 0,
        "text": " I have to make sure I'm a pro.",
        "tokens": [
          50364,
          286,
          362,
          281,
          652,
          988,
          286,
          478,
          257,
          447,
          13,
          50416
        ]
      },
      {
        "avg_logprob": -0.33754515167850774,
        "compression_ratio": 2.0721153846153846,
        "end": 782.12,
        "id": 273,
        "no_speech_prob": 0.0726078525185585,
        "seek": 77940,
        "start": 780.4399999999999,
        "temperature": 0,
        "text": " I have to select all the images with graphs.",
        "tokens": [
          50416,
          286,
          362,
          281,
          3048,
          439,
          264,
          5267,
          365,
          24877,
          13,
          50500
        ]
      },
      {
        "avg_logprob": -0.33754515167850774,
        "compression_ratio": 2.0721153846153846,
        "end": 785,
        "id": 274,
        "no_speech_prob": 0.0726078525185585,
        "seek": 77940,
        "start": 783.16,
        "temperature": 0,
        "text": " I'm selecting all the images with graphs.",
        "tokens": [
          50552,
          286,
          478,
          18182,
          439,
          264,
          5267,
          365,
          24877,
          13,
          50644
        ]
      },
      {
        "avg_logprob": -0.33754515167850774,
        "compression_ratio": 2.0721153846153846,
        "end": 786.84,
        "id": 275,
        "no_speech_prob": 0.0726078525185585,
        "seek": 77940,
        "start": 785.64,
        "temperature": 0,
        "text": " I'm entering the lottery.",
        "tokens": [
          50676,
          286,
          478,
          11104,
          264,
          27391,
          13,
          50736
        ]
      },
      {
        "avg_logprob": -0.33754515167850774,
        "compression_ratio": 2.0721153846153846,
        "end": 788.92,
        "id": 276,
        "no_speech_prob": 0.0726078525185585,
        "seek": 77940,
        "start": 787.48,
        "temperature": 0,
        "text": " Oh, the cameras are going off.",
        "tokens": [
          50768,
          876,
          11,
          264,
          8622,
          366,
          516,
          766,
          13,
          50840
        ]
      },
      {
        "avg_logprob": -0.33754515167850774,
        "compression_ratio": 2.0721153846153846,
        "end": 790.1999999999999,
        "id": 277,
        "no_speech_prob": 0.0726078525185585,
        "seek": 77940,
        "start": 789.48,
        "temperature": 0,
        "text": " I'm going to enter it.",
        "tokens": [
          50868,
          286,
          478,
          516,
          281,
          3242,
          309,
          13,
          50904
        ]
      },
      {
        "avg_logprob": -0.33754515167850774,
        "compression_ratio": 2.0721153846153846,
        "end": 791.9599999999999,
        "id": 278,
        "no_speech_prob": 0.0726078525185585,
        "seek": 77940,
        "start": 791.56,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          50972,
          6962,
          322,
          13,
          50992
        ]
      },
      {
        "avg_logprob": -0.33754515167850774,
        "compression_ratio": 2.0721153846153846,
        "end": 798.12,
        "id": 279,
        "no_speech_prob": 0.0726078525185585,
        "seek": 77940,
        "start": 793.8,
        "temperature": 0,
        "text": " At 4 o'clock, I can check to see if I won the Hamilton lottery.",
        "tokens": [
          51084,
          1711,
          1017,
          277,
          6,
          9023,
          11,
          286,
          393,
          1520,
          281,
          536,
          498,
          286,
          1582,
          264,
          18484,
          27391,
          13,
          51300
        ]
      },
      {
        "avg_logprob": -0.33754515167850774,
        "compression_ratio": 2.0721153846153846,
        "end": 799.4,
        "id": 280,
        "no_speech_prob": 0.0726078525185585,
        "seek": 77940,
        "start": 798.12,
        "temperature": 0,
        "text": " $10 front row ticket.",
        "tokens": [
          51300,
          1848,
          3279,
          1868,
          5386,
          10550,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.33754515167850774,
        "compression_ratio": 2.0721153846153846,
        "end": 799.9599999999999,
        "id": 281,
        "no_speech_prob": 0.0726078525185585,
        "seek": 77940,
        "start": 799.4,
        "temperature": 0,
        "text": " This Dot.",
        "tokens": [
          51364,
          639,
          38753,
          13,
          51392
        ]
      },
      {
        "avg_logprob": -0.33754515167850774,
        "compression_ratio": 2.0721153846153846,
        "end": 801.9599999999999,
        "id": 282,
        "no_speech_prob": 0.0726078525185585,
        "seek": 77940,
        "start": 799.9599999999999,
        "temperature": 0,
        "text": " I'm going to do This Dot, This Dot.",
        "tokens": [
          51392,
          286,
          478,
          516,
          281,
          360,
          639,
          38753,
          11,
          639,
          38753,
          13,
          51492
        ]
      },
      {
        "avg_logprob": -0.33754515167850774,
        "compression_ratio": 2.0721153846153846,
        "end": 804.04,
        "id": 283,
        "no_speech_prob": 0.0726078525185585,
        "seek": 77940,
        "start": 801.9599999999999,
        "temperature": 0,
        "text": " I'm going to do This Dot, This Dot.",
        "tokens": [
          51492,
          286,
          478,
          516,
          281,
          360,
          639,
          38753,
          11,
          639,
          38753,
          13,
          51596
        ]
      },
      {
        "avg_logprob": -0.33754515167850774,
        "compression_ratio": 2.0721153846153846,
        "end": 806.68,
        "id": 284,
        "no_speech_prob": 0.0726078525185585,
        "seek": 77940,
        "start": 805.0799999999999,
        "temperature": 0,
        "text": " This Dot, This Dot, Sorry.",
        "tokens": [
          51648,
          639,
          38753,
          11,
          639,
          38753,
          11,
          4919,
          13,
          51728
        ]
      },
      {
        "avg_logprob": -0.33754515167850774,
        "compression_ratio": 2.0721153846153846,
        "end": 809.24,
        "id": 285,
        "no_speech_prob": 0.0726078525185585,
        "seek": 77940,
        "start": 806.68,
        "temperature": 0,
        "text": " This Dot, This Dot, This Dot.",
        "tokens": [
          51728,
          639,
          38753,
          11,
          639,
          38753,
          11,
          639,
          38753,
          13,
          51856
        ]
      },
      {
        "avg_logprob": -0.2510536857273268,
        "compression_ratio": 1.7644927536231885,
        "end": 811.24,
        "id": 286,
        "no_speech_prob": 0.00004133514084969647,
        "seek": 80924,
        "start": 809.32,
        "temperature": 0,
        "text": " Select all the images with trees.",
        "tokens": [
          50368,
          13638,
          439,
          264,
          5267,
          365,
          5852,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2510536857273268,
        "compression_ratio": 1.7644927536231885,
        "end": 811.96,
        "id": 287,
        "no_speech_prob": 0.00004133514084969647,
        "seek": 80924,
        "start": 811.24,
        "temperature": 0,
        "text": " Oh my god.",
        "tokens": [
          50464,
          876,
          452,
          3044,
          13,
          50500
        ]
      },
      {
        "avg_logprob": -0.2510536857273268,
        "compression_ratio": 1.7644927536231885,
        "end": 813.5600000000001,
        "id": 288,
        "no_speech_prob": 0.00004133514084969647,
        "seek": 80924,
        "start": 811.96,
        "temperature": 0,
        "text": " Watermelon is not a tree, is it?",
        "tokens": [
          50500,
          8772,
          22710,
          307,
          406,
          257,
          4230,
          11,
          307,
          309,
          30,
          50580
        ]
      },
      {
        "avg_logprob": -0.2510536857273268,
        "compression_ratio": 1.7644927536231885,
        "end": 814.92,
        "id": 289,
        "no_speech_prob": 0.00004133514084969647,
        "seek": 80924,
        "start": 813.5600000000001,
        "temperature": 0,
        "text": " It's a little stressful.",
        "tokens": [
          50580,
          467,
          311,
          257,
          707,
          19108,
          13,
          50648
        ]
      },
      {
        "avg_logprob": -0.2510536857273268,
        "compression_ratio": 1.7644927536231885,
        "end": 815.5600000000001,
        "id": 290,
        "no_speech_prob": 0.00004133514084969647,
        "seek": 80924,
        "start": 814.92,
        "temperature": 0,
        "text": " This Dot, This Dot, This Dot.",
        "tokens": [
          50648,
          639,
          38753,
          11,
          639,
          38753,
          11,
          639,
          38753,
          13,
          50680
        ]
      },
      {
        "avg_logprob": -0.2510536857273268,
        "compression_ratio": 1.7644927536231885,
        "end": 816.6,
        "id": 291,
        "no_speech_prob": 0.00004133514084969647,
        "seek": 80924,
        "start": 815.5600000000001,
        "temperature": 0,
        "text": " I always feel so stressed out.",
        "tokens": [
          50680,
          286,
          1009,
          841,
          370,
          14471,
          484,
          13,
          50732
        ]
      },
      {
        "avg_logprob": -0.2510536857273268,
        "compression_ratio": 1.7644927536231885,
        "end": 819.48,
        "id": 292,
        "no_speech_prob": 0.00004133514084969647,
        "seek": 80924,
        "start": 817.32,
        "temperature": 0,
        "text": " I'm going to get in trouble if I don't answer the right one.",
        "tokens": [
          50768,
          286,
          478,
          516,
          281,
          483,
          294,
          5253,
          498,
          286,
          500,
          380,
          1867,
          264,
          558,
          472,
          13,
          50876
        ]
      },
      {
        "avg_logprob": -0.2510536857273268,
        "compression_ratio": 1.7644927536231885,
        "end": 820.52,
        "id": 293,
        "no_speech_prob": 0.00004133514084969647,
        "seek": 80924,
        "start": 819.48,
        "temperature": 0,
        "text": " There's trees on this one.",
        "tokens": [
          50876,
          821,
          311,
          5852,
          322,
          341,
          472,
          13,
          50928
        ]
      },
      {
        "avg_logprob": -0.2510536857273268,
        "compression_ratio": 1.7644927536231885,
        "end": 820.76,
        "id": 294,
        "no_speech_prob": 0.00004133514084969647,
        "seek": 80924,
        "start": 820.52,
        "temperature": 0,
        "text": " OK, fine.",
        "tokens": [
          50928,
          2264,
          11,
          2489,
          13,
          50940
        ]
      },
      {
        "avg_logprob": -0.2510536857273268,
        "compression_ratio": 1.7644927536231885,
        "end": 822.44,
        "id": 295,
        "no_speech_prob": 0.00004133514084969647,
        "seek": 80924,
        "start": 820.76,
        "temperature": 0,
        "text": " This Dot, This Dot, This Dot.",
        "tokens": [
          50940,
          639,
          38753,
          11,
          639,
          38753,
          11,
          639,
          38753,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.2510536857273268,
        "compression_ratio": 1.7644927536231885,
        "end": 823.32,
        "id": 296,
        "no_speech_prob": 0.00004133514084969647,
        "seek": 80924,
        "start": 822.44,
        "temperature": 0,
        "text": " The This Dot song.",
        "tokens": [
          51024,
          440,
          639,
          38753,
          2153,
          13,
          51068
        ]
      },
      {
        "avg_logprob": -0.2510536857273268,
        "compression_ratio": 1.7644927536231885,
        "end": 824.44,
        "id": 297,
        "no_speech_prob": 0.00004133514084969647,
        "seek": 80924,
        "start": 823.32,
        "temperature": 0,
        "text": " Never forget the This Dot.",
        "tokens": [
          51068,
          7344,
          2870,
          264,
          639,
          38753,
          13,
          51124
        ]
      },
      {
        "avg_logprob": -0.2510536857273268,
        "compression_ratio": 1.7644927536231885,
        "end": 826.2,
        "id": 298,
        "no_speech_prob": 0.00004133514084969647,
        "seek": 80924,
        "start": 825.48,
        "temperature": 0,
        "text": " Somebody composed that song for me.",
        "tokens": [
          51176,
          13463,
          18204,
          300,
          2153,
          337,
          385,
          13,
          51212
        ]
      },
      {
        "avg_logprob": -0.2510536857273268,
        "compression_ratio": 1.7644927536231885,
        "end": 828.28,
        "id": 299,
        "no_speech_prob": 0.00004133514084969647,
        "seek": 80924,
        "start": 826.2,
        "temperature": 0,
        "text": " OK, I've now entered the Hamilton lottery.",
        "tokens": [
          51212,
          2264,
          11,
          286,
          600,
          586,
          9065,
          264,
          18484,
          27391,
          13,
          51316
        ]
      },
      {
        "avg_logprob": -0.2510536857273268,
        "compression_ratio": 1.7644927536231885,
        "end": 830.2,
        "id": 300,
        "no_speech_prob": 0.00004133514084969647,
        "seek": 80924,
        "start": 828.84,
        "temperature": 0,
        "text": " And this camera went off.",
        "tokens": [
          51344,
          400,
          341,
          2799,
          1437,
          766,
          13,
          51412
        ]
      },
      {
        "avg_logprob": -0.2510536857273268,
        "compression_ratio": 1.7644927536231885,
        "end": 831.4,
        "id": 301,
        "no_speech_prob": 0.00004133514084969647,
        "seek": 80924,
        "start": 830.2,
        "temperature": 0,
        "text": " Let me just fix that.",
        "tokens": [
          51412,
          961,
          385,
          445,
          3191,
          300,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -0.2510536857273268,
        "compression_ratio": 1.7644927536231885,
        "end": 834.2,
        "id": 302,
        "no_speech_prob": 0.00004133514084969647,
        "seek": 80924,
        "start": 832.92,
        "temperature": 0,
        "text": " Let me cycle this one.",
        "tokens": [
          51548,
          961,
          385,
          6586,
          341,
          472,
          13,
          51612
        ]
      },
      {
        "avg_logprob": -0.5364498500406307,
        "compression_ratio": 2.0844155844155843,
        "end": 837,
        "id": 303,
        "no_speech_prob": 0.0024725785478949547,
        "seek": 83420,
        "start": 834.36,
        "temperature": 0,
        "text": " I need to erase the whiteboard.",
        "tokens": [
          50372,
          286,
          643,
          281,
          23525,
          264,
          2418,
          3787,
          13,
          50504
        ]
      },
      {
        "avg_logprob": -0.5364498500406307,
        "compression_ratio": 2.0844155844155843,
        "end": 839.32,
        "id": 304,
        "no_speech_prob": 0.0024725785478949547,
        "seek": 83420,
        "start": 837.5600000000001,
        "temperature": 0,
        "text": " I don't know where the eraser is.",
        "tokens": [
          50532,
          286,
          500,
          380,
          458,
          689,
          264,
          46018,
          307,
          13,
          50620
        ]
      },
      {
        "avg_logprob": -0.5364498500406307,
        "compression_ratio": 2.0844155844155843,
        "end": 839.82,
        "id": 305,
        "no_speech_prob": 0.0024725785478949547,
        "seek": 83420,
        "start": 839.32,
        "temperature": 0,
        "text": " Hmm.",
        "tokens": [
          50620,
          8239,
          13,
          50645
        ]
      },
      {
        "avg_logprob": -0.5364498500406307,
        "compression_ratio": 2.0844155844155843,
        "end": 843.08,
        "id": 306,
        "no_speech_prob": 0.0024725785478949547,
        "seek": 83420,
        "start": 841.08,
        "temperature": 0,
        "text": " Where is the eraser?",
        "tokens": [
          50708,
          2305,
          307,
          264,
          46018,
          30,
          50808
        ]
      },
      {
        "avg_logprob": -0.5364498500406307,
        "compression_ratio": 2.0844155844155843,
        "end": 850.2800000000001,
        "id": 307,
        "no_speech_prob": 0.0024725785478949547,
        "seek": 83420,
        "start": 848.6,
        "temperature": 0,
        "text": " Where is that eraser?",
        "tokens": [
          51084,
          2305,
          307,
          300,
          46018,
          30,
          51168
        ]
      },
      {
        "avg_logprob": -0.5364498500406307,
        "compression_ratio": 2.0844155844155843,
        "end": 851.6400000000001,
        "id": 308,
        "no_speech_prob": 0.0024725785478949547,
        "seek": 83420,
        "start": 851,
        "temperature": 0,
        "text": " Erasure.",
        "tokens": [
          51204,
          3300,
          2508,
          13,
          51236
        ]
      },
      {
        "avg_logprob": -0.5364498500406307,
        "compression_ratio": 2.0844155844155843,
        "end": 852.2,
        "id": 309,
        "no_speech_prob": 0.0024725785478949547,
        "seek": 83420,
        "start": 851.6400000000001,
        "temperature": 0,
        "text": " Eraser.",
        "tokens": [
          51236,
          3300,
          17756,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.5364498500406307,
        "compression_ratio": 2.0844155844155843,
        "end": 852.6800000000001,
        "id": 310,
        "no_speech_prob": 0.0024725785478949547,
        "seek": 83420,
        "start": 852.2,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          51264,
          876,
          13,
          51288
        ]
      },
      {
        "avg_logprob": -0.5364498500406307,
        "compression_ratio": 2.0844155844155843,
        "end": 854.6800000000001,
        "id": 311,
        "no_speech_prob": 0.0024725785478949547,
        "seek": 83420,
        "start": 853.6400000000001,
        "temperature": 0,
        "text": " OK, hold on, everyone.",
        "tokens": [
          51336,
          2264,
          11,
          1797,
          322,
          11,
          1518,
          13,
          51388
        ]
      },
      {
        "avg_logprob": -0.5364498500406307,
        "compression_ratio": 2.0844155844155843,
        "end": 857.48,
        "id": 312,
        "no_speech_prob": 0.0024725785478949547,
        "seek": 83420,
        "start": 856.9200000000001,
        "temperature": 0,
        "text": " Oh, here it is.",
        "tokens": [
          51500,
          876,
          11,
          510,
          309,
          307,
          13,
          51528
        ]
      },
      {
        "avg_logprob": -0.5364498500406307,
        "compression_ratio": 2.0844155844155843,
        "end": 857.72,
        "id": 313,
        "no_speech_prob": 0.0024725785478949547,
        "seek": 83420,
        "start": 857.48,
        "temperature": 0,
        "text": " I found it.",
        "tokens": [
          51528,
          286,
          1352,
          309,
          13,
          51540
        ]
      },
      {
        "avg_logprob": -0.5364498500406307,
        "compression_ratio": 2.0844155844155843,
        "end": 858.0400000000001,
        "id": 314,
        "no_speech_prob": 0.0024725785478949547,
        "seek": 83420,
        "start": 857.72,
        "temperature": 0,
        "text": " I found it.",
        "tokens": [
          51540,
          286,
          1352,
          309,
          13,
          51556
        ]
      },
      {
        "avg_logprob": -0.5364498500406307,
        "compression_ratio": 2.0844155844155843,
        "end": 858.6800000000001,
        "id": 315,
        "no_speech_prob": 0.0024725785478949547,
        "seek": 83420,
        "start": 858.0400000000001,
        "temperature": 0,
        "text": " I found it.",
        "tokens": [
          51556,
          286,
          1352,
          309,
          13,
          51588
        ]
      },
      {
        "avg_logprob": -0.5364498500406307,
        "compression_ratio": 2.0844155844155843,
        "end": 860.12,
        "id": 316,
        "no_speech_prob": 0.0024725785478949547,
        "seek": 83420,
        "start": 858.6800000000001,
        "temperature": 0,
        "text": " Everything's going to be OK, everybody.",
        "tokens": [
          51588,
          5471,
          311,
          516,
          281,
          312,
          2264,
          11,
          2201,
          13,
          51660
        ]
      },
      {
        "avg_logprob": -0.5364498500406307,
        "compression_ratio": 2.0844155844155843,
        "end": 860.6800000000001,
        "id": 317,
        "no_speech_prob": 0.0024725785478949547,
        "seek": 83420,
        "start": 860.12,
        "temperature": 0,
        "text": " I found it.",
        "tokens": [
          51660,
          286,
          1352,
          309,
          13,
          51688
        ]
      },
      {
        "avg_logprob": -0.5364498500406307,
        "compression_ratio": 2.0844155844155843,
        "end": 861.24,
        "id": 318,
        "no_speech_prob": 0.0024725785478949547,
        "seek": 83420,
        "start": 860.6800000000001,
        "temperature": 0,
        "text": " I found it.",
        "tokens": [
          51688,
          286,
          1352,
          309,
          13,
          51716
        ]
      },
      {
        "avg_logprob": -0.5364498500406307,
        "compression_ratio": 2.0844155844155843,
        "end": 861.72,
        "id": 319,
        "no_speech_prob": 0.0024725785478949547,
        "seek": 83420,
        "start": 861.24,
        "temperature": 0,
        "text": " I found it.",
        "tokens": [
          51716,
          286,
          1352,
          309,
          13,
          51740
        ]
      },
      {
        "avg_logprob": -0.5364498500406307,
        "compression_ratio": 2.0844155844155843,
        "end": 862.2800000000001,
        "id": 320,
        "no_speech_prob": 0.0024725785478949547,
        "seek": 83420,
        "start": 861.72,
        "temperature": 0,
        "text": " I found it.",
        "tokens": [
          51740,
          286,
          1352,
          309,
          13,
          51768
        ]
      },
      {
        "avg_logprob": -0.5364498500406307,
        "compression_ratio": 2.0844155844155843,
        "end": 862.84,
        "id": 321,
        "no_speech_prob": 0.0024725785478949547,
        "seek": 83420,
        "start": 862.2800000000001,
        "temperature": 0,
        "text": " I found it.",
        "tokens": [
          51768,
          286,
          1352,
          309,
          13,
          51796
        ]
      },
      {
        "avg_logprob": -0.5364498500406307,
        "compression_ratio": 2.0844155844155843,
        "end": 863.4000000000001,
        "id": 322,
        "no_speech_prob": 0.0024725785478949547,
        "seek": 83420,
        "start": 862.84,
        "temperature": 0,
        "text": " I found it.",
        "tokens": [
          51796,
          286,
          1352,
          309,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.34784033863814834,
        "compression_ratio": 1.6209150326797386,
        "end": 864.04,
        "id": 323,
        "no_speech_prob": 0.016652381047606468,
        "seek": 86340,
        "start": 863.4,
        "temperature": 0,
        "text": " Everything's going to be OK, everybody.",
        "tokens": [
          50364,
          5471,
          311,
          516,
          281,
          312,
          2264,
          11,
          2201,
          13,
          50396
        ]
      },
      {
        "avg_logprob": -0.34784033863814834,
        "compression_ratio": 1.6209150326797386,
        "end": 866.68,
        "id": 324,
        "no_speech_prob": 0.016652381047606468,
        "seek": 86340,
        "start": 865,
        "temperature": 0,
        "text": " I'm going to, this is what I had.",
        "tokens": [
          50444,
          286,
          478,
          516,
          281,
          11,
          341,
          307,
          437,
          286,
          632,
          13,
          50528
        ]
      },
      {
        "avg_logprob": -0.34784033863814834,
        "compression_ratio": 1.6209150326797386,
        "end": 867.24,
        "id": 325,
        "no_speech_prob": 0.016652381047606468,
        "seek": 86340,
        "start": 866.68,
        "temperature": 0,
        "text": " Oh, look.",
        "tokens": [
          50528,
          876,
          11,
          574,
          13,
          50556
        ]
      },
      {
        "avg_logprob": -0.34784033863814834,
        "compression_ratio": 1.6209150326797386,
        "end": 870.06,
        "id": 326,
        "no_speech_prob": 0.016652381047606468,
        "seek": 86340,
        "start": 869.56,
        "temperature": 0,
        "text": " Uh.",
        "tokens": [
          50672,
          4019,
          13,
          50697
        ]
      },
      {
        "avg_logprob": -0.34784033863814834,
        "compression_ratio": 1.6209150326797386,
        "end": 872.04,
        "id": 327,
        "no_speech_prob": 0.016652381047606468,
        "seek": 86340,
        "start": 871,
        "temperature": 0,
        "text": " Let me erase all this.",
        "tokens": [
          50744,
          961,
          385,
          23525,
          439,
          341,
          13,
          50796
        ]
      },
      {
        "avg_logprob": -0.34784033863814834,
        "compression_ratio": 1.6209150326797386,
        "end": 878.4399999999999,
        "id": 328,
        "no_speech_prob": 0.016652381047606468,
        "seek": 86340,
        "start": 876.36,
        "temperature": 0,
        "text": " This is such a nice eraser.",
        "tokens": [
          51012,
          639,
          307,
          1270,
          257,
          1481,
          46018,
          13,
          51116
        ]
      },
      {
        "avg_logprob": -0.34784033863814834,
        "compression_ratio": 1.6209150326797386,
        "end": 879.72,
        "id": 329,
        "no_speech_prob": 0.016652381047606468,
        "seek": 86340,
        "start": 878.4399999999999,
        "temperature": 0,
        "text": " Makes such a nice sound, too.",
        "tokens": [
          51116,
          25245,
          1270,
          257,
          1481,
          1626,
          11,
          886,
          13,
          51180
        ]
      },
      {
        "avg_logprob": -0.34784033863814834,
        "compression_ratio": 1.6209150326797386,
        "end": 882.6,
        "id": 330,
        "no_speech_prob": 0.016652381047606468,
        "seek": 86340,
        "start": 881.56,
        "temperature": 0,
        "text": " Go to sleep.",
        "tokens": [
          51272,
          1037,
          281,
          2817,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.34784033863814834,
        "compression_ratio": 1.6209150326797386,
        "end": 884.84,
        "id": 331,
        "no_speech_prob": 0.016652381047606468,
        "seek": 86340,
        "start": 883.8,
        "temperature": 0,
        "text": " Go to sleep.",
        "tokens": [
          51384,
          1037,
          281,
          2817,
          13,
          51436
        ]
      },
      {
        "avg_logprob": -0.34784033863814834,
        "compression_ratio": 1.6209150326797386,
        "end": 889.72,
        "id": 332,
        "no_speech_prob": 0.016652381047606468,
        "seek": 86340,
        "start": 886.04,
        "temperature": 0,
        "text": " Go to sleep, little eyes.",
        "tokens": [
          51496,
          1037,
          281,
          2817,
          11,
          707,
          2575,
          13,
          51680
        ]
      },
      {
        "avg_logprob": -0.34784033863814834,
        "compression_ratio": 1.6209150326797386,
        "end": 891.8,
        "id": 333,
        "no_speech_prob": 0.016652381047606468,
        "seek": 86340,
        "start": 890.76,
        "temperature": 0,
        "text": " Go to sleep.",
        "tokens": [
          51732,
          1037,
          281,
          2817,
          13,
          51784
        ]
      },
      {
        "avg_logprob": -0.34784033863814834,
        "compression_ratio": 1.6209150326797386,
        "end": 892.68,
        "id": 334,
        "no_speech_prob": 0.016652381047606468,
        "seek": 86340,
        "start": 891.8,
        "temperature": 0,
        "text": " OK, I'm wrong.",
        "tokens": [
          51784,
          2264,
          11,
          286,
          478,
          2085,
          13,
          51828
        ]
      },
      {
        "avg_logprob": -0.3625325920168033,
        "compression_ratio": 1.5913461538461537,
        "end": 896.28,
        "id": 335,
        "no_speech_prob": 0.00030061163124628365,
        "seek": 89340,
        "start": 893.88,
        "temperature": 0.4,
        "text": " Oh, it's been a weird few weeks.",
        "tokens": [
          50388,
          876,
          11,
          309,
          311,
          668,
          257,
          3657,
          1326,
          3259,
          13,
          50508
        ]
      },
      {
        "avg_logprob": -0.3625325920168033,
        "compression_ratio": 1.5913461538461537,
        "end": 896.78,
        "id": 336,
        "no_speech_prob": 0.00030061163124628365,
        "seek": 89340,
        "start": 896.28,
        "temperature": 0.4,
        "text": " OK.",
        "tokens": [
          50508,
          2264,
          13,
          50533
        ]
      },
      {
        "avg_logprob": -0.3625325920168033,
        "compression_ratio": 1.5913461538461537,
        "end": 900.6999999999999,
        "id": 337,
        "no_speech_prob": 0.00030061163124628365,
        "seek": 89340,
        "start": 900.1999999999999,
        "temperature": 0.4,
        "text": " OK.",
        "tokens": [
          50704,
          220,
          9443,
          13,
          50729
        ]
      },
      {
        "avg_logprob": -0.3625325920168033,
        "compression_ratio": 1.5913461538461537,
        "end": 901.72,
        "id": 338,
        "no_speech_prob": 0.00030061163124628365,
        "seek": 89340,
        "start": 901.4,
        "temperature": 0.4,
        "text": " All right.",
        "tokens": [
          50764,
          1057,
          558,
          13,
          50780
        ]
      },
      {
        "avg_logprob": -0.3625325920168033,
        "compression_ratio": 1.5913461538461537,
        "end": 906.1999999999999,
        "id": 339,
        "no_speech_prob": 0.00030061163124628365,
        "seek": 89340,
        "start": 901.72,
        "temperature": 0.4,
        "text": " So the first thing I want to do, I'm actually going to start, weirdly, with a coding challenge.",
        "tokens": [
          50780,
          407,
          264,
          700,
          551,
          286,
          528,
          281,
          360,
          11,
          286,
          478,
          767,
          516,
          281,
          722,
          11,
          321,
          347,
          67,
          356,
          11,
          365,
          257,
          17720,
          3430,
          13,
          51004
        ]
      },
      {
        "avg_logprob": -0.3625325920168033,
        "compression_ratio": 1.5913461538461537,
        "end": 914.12,
        "id": 340,
        "no_speech_prob": 0.00030061163124628365,
        "seek": 89340,
        "start": 907.24,
        "temperature": 0.4,
        "text": " And that coding challenge, you should be confused, is to ch-ch-ch-ch-ch-ch-ch-ch-afin",
        "tokens": [
          51056,
          400,
          300,
          598,
          3584,
          3430,
          11,
          291,
          820,
          312,
          9019,
          11,
          307,
          220,
          1353,
          417,
          12,
          339,
          12,
          339,
          12,
          339,
          12,
          339,
          12,
          339,
          12,
          339,
          12,
          339,
          12,
          2792,
          259,
          51400
        ]
      },
      {
        "avg_logprob": -0.3625325920168033,
        "compression_ratio": 1.5913461538461537,
        "end": 916.12,
        "id": 341,
        "no_speech_prob": 0.00030061163124628365,
        "seek": 89340,
        "start": 915.0799999999999,
        "temperature": 0.4,
        "text": " 111.",
        "tokens": [
          51448,
          2975,
          16,
          13,
          51500
        ]
      },
      {
        "avg_logprob": -0.3625325920168033,
        "compression_ratio": 1.5913461538461537,
        "end": 922.4399999999999,
        "id": 342,
        "no_speech_prob": 0.00030061163124628365,
        "seek": 89340,
        "start": 916.12,
        "temperature": 0.4,
        "text": " So what I'm going to do, a lot of you might have watched these before, but the live streams,",
        "tokens": [
          51500,
          407,
          437,
          286,
          478,
          516,
          281,
          360,
          11,
          257,
          688,
          295,
          291,
          1062,
          362,
          6858,
          19318,
          613,
          949,
          11,
          457,
          264,
          1621,
          15842,
          11,
          51816
        ]
      },
      {
        "avg_logprob": -0.20056218172596618,
        "compression_ratio": 1.6015325670498084,
        "end": 927,
        "id": 343,
        "no_speech_prob": 0.0013885014923289418,
        "seek": 92244,
        "start": 922.44,
        "temperature": 0,
        "text": " typically, I do a lot of talking and researching and clicking and getting set up.",
        "tokens": [
          50364,
          5850,
          11,
          286,
          360,
          257,
          688,
          295,
          1417,
          293,
          24176,
          293,
          9697,
          293,
          1242,
          992,
          493,
          13,
          50592
        ]
      },
      {
        "avg_logprob": -0.20056218172596618,
        "compression_ratio": 1.6015325670498084,
        "end": 931.8800000000001,
        "id": 344,
        "no_speech_prob": 0.0013885014923289418,
        "seek": 92244,
        "start": 927,
        "temperature": 0,
        "text": " And at a certain point, I start an actual tutorial or coding challenge, where I pretend",
        "tokens": [
          50592,
          400,
          412,
          257,
          1629,
          935,
          11,
          286,
          722,
          364,
          3539,
          7073,
          420,
          17720,
          3430,
          11,
          689,
          286,
          11865,
          50836
        ]
      },
      {
        "avg_logprob": -0.20056218172596618,
        "compression_ratio": 1.6015325670498084,
        "end": 935.24,
        "id": 345,
        "no_speech_prob": 0.0013885014923289418,
        "seek": 92244,
        "start": 931.8800000000001,
        "temperature": 0,
        "text": " as if I'm recording a video, even though that's what I'm doing all this time.",
        "tokens": [
          50836,
          382,
          498,
          286,
          478,
          6613,
          257,
          960,
          11,
          754,
          1673,
          300,
          311,
          437,
          286,
          478,
          884,
          439,
          341,
          565,
          13,
          51004
        ]
      },
      {
        "avg_logprob": -0.20056218172596618,
        "compression_ratio": 1.6015325670498084,
        "end": 937.96,
        "id": 346,
        "no_speech_prob": 0.0013885014923289418,
        "seek": 92244,
        "start": 935.24,
        "temperature": 0,
        "text": " So let me first get set up here.",
        "tokens": [
          51004,
          407,
          718,
          385,
          700,
          483,
          992,
          493,
          510,
          13,
          51140
        ]
      },
      {
        "avg_logprob": -0.20056218172596618,
        "compression_ratio": 1.6015325670498084,
        "end": 942.84,
        "id": 347,
        "no_speech_prob": 0.0013885014923289418,
        "seek": 92244,
        "start": 937.96,
        "temperature": 0,
        "text": " Let's get some links that are relevant and talk to you a little bit about afin 111.",
        "tokens": [
          51140,
          961,
          311,
          483,
          512,
          6123,
          300,
          366,
          7340,
          293,
          751,
          281,
          291,
          257,
          707,
          857,
          466,
          3238,
          259,
          2975,
          16,
          13,
          51384
        ]
      },
      {
        "avg_logprob": -0.20056218172596618,
        "compression_ratio": 1.6015325670498084,
        "end": 951.8800000000001,
        "id": 348,
        "no_speech_prob": 0.0013885014923289418,
        "seek": 92244,
        "start": 942.84,
        "temperature": 0,
        "text": " So afin is a list of English words rated for valence,",
        "tokens": [
          51384,
          407,
          3238,
          259,
          307,
          257,
          1329,
          295,
          3669,
          2283,
          22103,
          337,
          1323,
          655,
          11,
          51836
        ]
      },
      {
        "avg_logprob": -0.20406039730533138,
        "compression_ratio": 1.5203619909502262,
        "end": 957.96,
        "id": 349,
        "no_speech_prob": 0.00020026999118272215,
        "seek": 95188,
        "start": 951.88,
        "temperature": 0,
        "text": " meaning positivity or negativity, with an integer between minus 5 and plus 5.",
        "tokens": [
          50364,
          3620,
          35198,
          420,
          39297,
          11,
          365,
          364,
          24922,
          1296,
          3175,
          1025,
          293,
          1804,
          1025,
          13,
          50668
        ]
      },
      {
        "avg_logprob": -0.20406039730533138,
        "compression_ratio": 1.5203619909502262,
        "end": 965.8,
        "id": 350,
        "no_speech_prob": 0.00020026999118272215,
        "seek": 95188,
        "start": 958.6,
        "temperature": 0,
        "text": " And so these words were manually labeled by Fin Arup Nielsen, which is why it's called the afin.",
        "tokens": [
          50700,
          400,
          370,
          613,
          2283,
          645,
          16945,
          21335,
          538,
          3773,
          316,
          11976,
          426,
          1187,
          6748,
          11,
          597,
          307,
          983,
          309,
          311,
          1219,
          264,
          3238,
          259,
          13,
          51060
        ]
      },
      {
        "avg_logprob": -0.20406039730533138,
        "compression_ratio": 1.5203619909502262,
        "end": 972.52,
        "id": 351,
        "no_speech_prob": 0.00020026999118272215,
        "seek": 95188,
        "start": 967,
        "temperature": 0,
        "text": " And afin 111 is the newest version that has 2,477 words and phrases.",
        "tokens": [
          51120,
          400,
          3238,
          259,
          2975,
          16,
          307,
          264,
          17569,
          3037,
          300,
          575,
          568,
          11,
          14060,
          22,
          2283,
          293,
          20312,
          13,
          51396
        ]
      },
      {
        "avg_logprob": -0.20406039730533138,
        "compression_ratio": 1.5203619909502262,
        "end": 978.76,
        "id": 352,
        "no_speech_prob": 0.00020026999118272215,
        "seek": 95188,
        "start": 973.96,
        "temperature": 0,
        "text": " So if you are a scientist, I am not a scientist, I hope you would reference the above paper.",
        "tokens": [
          51468,
          407,
          498,
          291,
          366,
          257,
          12662,
          11,
          286,
          669,
          406,
          257,
          12662,
          11,
          286,
          1454,
          291,
          576,
          6408,
          264,
          3673,
          3035,
          13,
          51708
        ]
      },
      {
        "avg_logprob": -0.22517929077148438,
        "compression_ratio": 1.4666666666666666,
        "end": 982.68,
        "id": 353,
        "no_speech_prob": 0.08631249517202377,
        "seek": 97876,
        "start": 978.76,
        "temperature": 0,
        "text": " I will reference the above paper and this link in this video's description.",
        "tokens": [
          50364,
          286,
          486,
          6408,
          264,
          3673,
          3035,
          293,
          341,
          2113,
          294,
          341,
          960,
          311,
          3855,
          13,
          50560
        ]
      },
      {
        "avg_logprob": -0.22517929077148438,
        "compression_ratio": 1.4666666666666666,
        "end": 988.52,
        "id": 354,
        "no_speech_prob": 0.08631249517202377,
        "seek": 97876,
        "start": 984.12,
        "temperature": 0,
        "text": " This database is copyright protected and distributed under the Open Database license.",
        "tokens": [
          50632,
          639,
          8149,
          307,
          17996,
          10594,
          293,
          12631,
          833,
          264,
          7238,
          40461,
          651,
          10476,
          13,
          50852
        ]
      },
      {
        "avg_logprob": -0.22517929077148438,
        "compression_ratio": 1.4666666666666666,
        "end": 991.56,
        "id": 355,
        "no_speech_prob": 0.08631249517202377,
        "seek": 97876,
        "start": 988.52,
        "temperature": 0,
        "text": " So what I'm going to do is I'm going to download it so we can take a look at it.",
        "tokens": [
          50852,
          407,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          5484,
          309,
          370,
          321,
          393,
          747,
          257,
          574,
          412,
          309,
          13,
          51004
        ]
      },
      {
        "avg_logprob": -0.4282178333827427,
        "compression_ratio": 1.3909774436090225,
        "end": 992.6199999999999,
        "id": 356,
        "no_speech_prob": 0.4377190172672272,
        "seek": 99156,
        "start": 992.1199999999999,
        "temperature": 0.2,
        "text": " OK.",
        "tokens": [
          50392,
          2264,
          13,
          50417
        ]
      },
      {
        "avg_logprob": -0.4282178333827427,
        "compression_ratio": 1.3909774436090225,
        "end": 1003.8199999999999,
        "id": 357,
        "no_speech_prob": 0.4377190172672272,
        "seek": 99156,
        "start": 1003.3199999999999,
        "temperature": 0.2,
        "text": " Afin.",
        "tokens": [
          50952,
          3325,
          259,
          13,
          50977
        ]
      },
      {
        "avg_logprob": -0.4282178333827427,
        "compression_ratio": 1.3909774436090225,
        "end": 1008.8399999999999,
        "id": 358,
        "no_speech_prob": 0.4377190172672272,
        "seek": 99156,
        "start": 1003.8199999999999,
        "temperature": 0.2,
        "text": " Oh, look, I downloaded it last week or two weeks ago.",
        "tokens": [
          50977,
          876,
          11,
          574,
          11,
          286,
          21748,
          309,
          1036,
          1243,
          420,
          732,
          3259,
          2057,
          13,
          51228
        ]
      },
      {
        "avg_logprob": -0.4282178333827427,
        "compression_ratio": 1.3909774436090225,
        "end": 1009.9599999999999,
        "id": 359,
        "no_speech_prob": 0.4377190172672272,
        "seek": 99156,
        "start": 1008.8399999999999,
        "temperature": 0.2,
        "text": " So let's look at the readme.",
        "tokens": [
          51228,
          407,
          718,
          311,
          574,
          412,
          264,
          1401,
          1398,
          13,
          51284
        ]
      },
      {
        "avg_logprob": -0.4282178333827427,
        "compression_ratio": 1.3909774436090225,
        "end": 1013.7199999999999,
        "id": 360,
        "no_speech_prob": 0.4377190172672272,
        "seek": 99156,
        "start": 1010.5999999999999,
        "temperature": 0.2,
        "text": " This is what it says already on the site.",
        "tokens": [
          51316,
          639,
          307,
          437,
          309,
          1619,
          1217,
          322,
          264,
          3621,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -0.4282178333827427,
        "compression_ratio": 1.3909774436090225,
        "end": 1015.64,
        "id": 361,
        "no_speech_prob": 0.4377190172672272,
        "seek": 99156,
        "start": 1014.28,
        "temperature": 0.2,
        "text": " OK, now let's look at this.",
        "tokens": [
          51500,
          2264,
          11,
          586,
          718,
          311,
          574,
          412,
          341,
          13,
          51568
        ]
      },
      {
        "avg_logprob": -0.4282178333827427,
        "compression_ratio": 1.3909774436090225,
        "end": 1016.68,
        "id": 362,
        "no_speech_prob": 0.4377190172672272,
        "seek": 99156,
        "start": 1015.64,
        "temperature": 0.2,
        "text": " Now, here's the thing.",
        "tokens": [
          51568,
          823,
          11,
          510,
          311,
          264,
          551,
          13,
          51620
        ]
      },
      {
        "avg_logprob": -0.404370134527033,
        "compression_ratio": 1.828358208955224,
        "end": 1022.4399999999999,
        "id": 363,
        "no_speech_prob": 0.022975703701376915,
        "seek": 101668,
        "start": 1017.4,
        "temperature": 0,
        "text": " I really, really, really, really, really, really, really, really, really, really,",
        "tokens": [
          50400,
          286,
          534,
          11,
          534,
          11,
          534,
          11,
          534,
          11,
          534,
          11,
          534,
          11,
          534,
          11,
          534,
          11,
          534,
          11,
          534,
          11,
          50652
        ]
      },
      {
        "avg_logprob": -0.404370134527033,
        "compression_ratio": 1.828358208955224,
        "end": 1026.28,
        "id": 364,
        "no_speech_prob": 0.022975703701376915,
        "seek": 101668,
        "start": 1022.4399999999999,
        "temperature": 0,
        "text": " really would like to have this list in JSON format.",
        "tokens": [
          50652,
          534,
          576,
          411,
          281,
          362,
          341,
          1329,
          294,
          31828,
          7877,
          13,
          50844
        ]
      },
      {
        "avg_logprob": -0.404370134527033,
        "compression_ratio": 1.828358208955224,
        "end": 1033.72,
        "id": 365,
        "no_speech_prob": 0.022975703701376915,
        "seek": 101668,
        "start": 1027.24,
        "temperature": 0,
        "text": " So the question I have for myself is do I make the coding challenge itself,",
        "tokens": [
          50892,
          407,
          264,
          1168,
          286,
          362,
          337,
          2059,
          307,
          360,
          286,
          652,
          264,
          17720,
          3430,
          2564,
          11,
          51216
        ]
      },
      {
        "avg_logprob": -0.404370134527033,
        "compression_ratio": 1.828358208955224,
        "end": 1038.76,
        "id": 366,
        "no_speech_prob": 0.022975703701376915,
        "seek": 101668,
        "start": 1034.76,
        "temperature": 0,
        "text": " part of it converting this to JSON?",
        "tokens": [
          51268,
          644,
          295,
          309,
          29942,
          341,
          281,
          31828,
          30,
          51468
        ]
      },
      {
        "avg_logprob": -0.4606565671546437,
        "compression_ratio": 1.6702127659574468,
        "end": 1042.12,
        "id": 367,
        "no_speech_prob": 0.12939266860485077,
        "seek": 103876,
        "start": 1038.76,
        "temperature": 0,
        "text": " And also, what's up with this?",
        "tokens": [
          50364,
          400,
          611,
          11,
          437,
          311,
          493,
          365,
          341,
          30,
          50532
        ]
      },
      {
        "avg_logprob": -0.4606565671546437,
        "compression_ratio": 1.6702127659574468,
        "end": 1044.52,
        "id": 368,
        "no_speech_prob": 0.12939266860485077,
        "seek": 103876,
        "start": 1043.32,
        "temperature": 0,
        "text": " What's up with this list?",
        "tokens": [
          50592,
          708,
          311,
          493,
          365,
          341,
          1329,
          30,
          50652
        ]
      },
      {
        "avg_logprob": -0.4606565671546437,
        "compression_ratio": 1.6702127659574468,
        "end": 1049.72,
        "id": 369,
        "no_speech_prob": 0.12939266860485077,
        "seek": 103876,
        "start": 1044.52,
        "temperature": 0,
        "text": " Like, wow, wow, wow, wow, with two Ws, I guess.",
        "tokens": [
          50652,
          1743,
          11,
          6076,
          11,
          6076,
          11,
          6076,
          11,
          6076,
          11,
          365,
          732,
          343,
          82,
          11,
          286,
          2041,
          13,
          50912
        ]
      },
      {
        "avg_logprob": -0.4606565671546437,
        "compression_ratio": 1.6702127659574468,
        "end": 1057.08,
        "id": 370,
        "no_speech_prob": 0.12939266860485077,
        "seek": 103876,
        "start": 1052.76,
        "temperature": 0,
        "text": " Yes, there's a lot of words, but why is there no space there between the number?",
        "tokens": [
          51064,
          1079,
          11,
          456,
          311,
          257,
          688,
          295,
          2283,
          11,
          457,
          983,
          307,
          456,
          572,
          1901,
          456,
          1296,
          264,
          1230,
          30,
          51280
        ]
      },
      {
        "avg_logprob": -0.4606565671546437,
        "compression_ratio": 1.6702127659574468,
        "end": 1057.58,
        "id": 371,
        "no_speech_prob": 0.12939266860485077,
        "seek": 103876,
        "start": 1057.08,
        "temperature": 0,
        "text": " Huh.",
        "tokens": [
          51280,
          8063,
          13,
          51305
        ]
      },
      {
        "avg_logprob": -0.4606565671546437,
        "compression_ratio": 1.6702127659574468,
        "end": 1060.6,
        "id": 372,
        "no_speech_prob": 0.12939266860485077,
        "seek": 103876,
        "start": 1058.36,
        "temperature": 0,
        "text": " So I feel like, oh, there's probably a tab.",
        "tokens": [
          51344,
          407,
          286,
          841,
          411,
          11,
          1954,
          11,
          456,
          311,
          1391,
          257,
          4421,
          13,
          51456
        ]
      },
      {
        "avg_logprob": -0.4606565671546437,
        "compression_ratio": 1.6702127659574468,
        "end": 1063,
        "id": 373,
        "no_speech_prob": 0.12939266860485077,
        "seek": 103876,
        "start": 1060.6,
        "temperature": 0,
        "text": " This is probably tab delimited, right?",
        "tokens": [
          51456,
          639,
          307,
          1391,
          4421,
          1103,
          332,
          1226,
          11,
          558,
          30,
          51576
        ]
      },
      {
        "avg_logprob": -0.4606565671546437,
        "compression_ratio": 1.6702127659574468,
        "end": 1066.2,
        "id": 374,
        "no_speech_prob": 0.12939266860485077,
        "seek": 103876,
        "start": 1064.6,
        "temperature": 0,
        "text": " Yeah, so there's actually a space there.",
        "tokens": [
          51656,
          865,
          11,
          370,
          456,
          311,
          767,
          257,
          1901,
          456,
          13,
          51736
        ]
      },
      {
        "avg_logprob": -0.42165476675251967,
        "compression_ratio": 1.6525096525096525,
        "end": 1068.8400000000001,
        "id": 375,
        "no_speech_prob": 0.00011591900693019852,
        "seek": 106620,
        "start": 1066.44,
        "temperature": 0,
        "text": " It's just, yeah, it's just there's a tab there.",
        "tokens": [
          50376,
          467,
          311,
          445,
          11,
          1338,
          11,
          309,
          311,
          445,
          456,
          311,
          257,
          4421,
          456,
          13,
          50496
        ]
      },
      {
        "avg_logprob": -0.42165476675251967,
        "compression_ratio": 1.6525096525096525,
        "end": 1073.0800000000002,
        "id": 376,
        "no_speech_prob": 0.00011591900693019852,
        "seek": 106620,
        "start": 1068.8400000000001,
        "temperature": 0,
        "text": " OK, so what I want to do is I'm going to do,",
        "tokens": [
          50496,
          2264,
          11,
          370,
          437,
          286,
          528,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          360,
          11,
          50708
        ]
      },
      {
        "avg_logprob": -0.42165476675251967,
        "compression_ratio": 1.6525096525096525,
        "end": 1076.6000000000001,
        "id": 377,
        "no_speech_prob": 0.00011591900693019852,
        "seek": 106620,
        "start": 1073.0800000000002,
        "temperature": 0,
        "text": " I can't decide if I should do this as two separate coding challenges",
        "tokens": [
          50708,
          286,
          393,
          380,
          4536,
          498,
          286,
          820,
          360,
          341,
          382,
          732,
          4994,
          17720,
          4759,
          50884
        ]
      },
      {
        "avg_logprob": -0.42165476675251967,
        "compression_ratio": 1.6525096525096525,
        "end": 1085.16,
        "id": 378,
        "no_speech_prob": 0.00011591900693019852,
        "seek": 106620,
        "start": 1078.52,
        "temperature": 0,
        "text": " or I'm seeing in the chat that a note that the video quality is not good.",
        "tokens": [
          50980,
          420,
          286,
          478,
          2577,
          294,
          264,
          5081,
          300,
          257,
          3637,
          300,
          264,
          960,
          3125,
          307,
          406,
          665,
          13,
          51312
        ]
      },
      {
        "avg_logprob": -0.42165476675251967,
        "compression_ratio": 1.6525096525096525,
        "end": 1087.16,
        "id": 379,
        "no_speech_prob": 0.00011591900693019852,
        "seek": 106620,
        "start": 1085.16,
        "temperature": 0,
        "text": " So I don't know if sometimes with the stream,",
        "tokens": [
          51312,
          407,
          286,
          500,
          380,
          458,
          498,
          2171,
          365,
          264,
          4309,
          11,
          51412
        ]
      },
      {
        "avg_logprob": -0.42165476675251967,
        "compression_ratio": 1.6525096525096525,
        "end": 1089.32,
        "id": 380,
        "no_speech_prob": 0.00011591900693019852,
        "seek": 106620,
        "start": 1087.16,
        "temperature": 0,
        "text": " depending on your connection, you can get low quality.",
        "tokens": [
          51412,
          5413,
          322,
          428,
          4984,
          11,
          291,
          393,
          483,
          2295,
          3125,
          13,
          51520
        ]
      },
      {
        "avg_logprob": -0.42165476675251967,
        "compression_ratio": 1.6525096525096525,
        "end": 1090.04,
        "id": 381,
        "no_speech_prob": 0.00011591900693019852,
        "seek": 106620,
        "start": 1089.32,
        "temperature": 0,
        "text": " It is only seven.",
        "tokens": [
          51520,
          467,
          307,
          787,
          3407,
          13,
          51556
        ]
      },
      {
        "avg_logprob": -0.42165476675251967,
        "compression_ratio": 1.6525096525096525,
        "end": 1091.56,
        "id": 382,
        "no_speech_prob": 0.00011591900693019852,
        "seek": 106620,
        "start": 1090.04,
        "temperature": 0,
        "text": " I am only broadcasting at 720p.",
        "tokens": [
          51556,
          286,
          669,
          787,
          30024,
          412,
          40881,
          79,
          13,
          51632
        ]
      },
      {
        "avg_logprob": -0.42165476675251967,
        "compression_ratio": 1.6525096525096525,
        "end": 1093.56,
        "id": 383,
        "no_speech_prob": 0.00011591900693019852,
        "seek": 106620,
        "start": 1091.56,
        "temperature": 0,
        "text": " So I'm not sure if I'm going to get 720p.",
        "tokens": [
          51632,
          407,
          286,
          478,
          406,
          988,
          498,
          286,
          478,
          516,
          281,
          483,
          40881,
          79,
          13,
          51732
        ]
      },
      {
        "avg_logprob": -0.2040511903308687,
        "compression_ratio": 1.5210084033613445,
        "end": 1094.6,
        "id": 384,
        "no_speech_prob": 0.014727959409356117,
        "seek": 109356,
        "start": 1093.96,
        "temperature": 0,
        "text": " It is only seven.",
        "tokens": [
          50384,
          467,
          307,
          787,
          3407,
          13,
          50416
        ]
      },
      {
        "avg_logprob": -0.2040511903308687,
        "compression_ratio": 1.5210084033613445,
        "end": 1098.6799999999998,
        "id": 385,
        "no_speech_prob": 0.014727959409356117,
        "seek": 109356,
        "start": 1094.6,
        "temperature": 0,
        "text": " I am only broadcasting at 720p because I don't have a good enough connection here,",
        "tokens": [
          50416,
          286,
          669,
          787,
          30024,
          412,
          40881,
          79,
          570,
          286,
          500,
          380,
          362,
          257,
          665,
          1547,
          4984,
          510,
          11,
          50620
        ]
      },
      {
        "avg_logprob": -0.2040511903308687,
        "compression_ratio": 1.5210084033613445,
        "end": 1101.3999999999999,
        "id": 386,
        "no_speech_prob": 0.014727959409356117,
        "seek": 109356,
        "start": 1098.6799999999998,
        "temperature": 0,
        "text": " I think, to support 108 broadcasting at 1080p.",
        "tokens": [
          50620,
          286,
          519,
          11,
          281,
          1406,
          1266,
          23,
          30024,
          412,
          24547,
          79,
          13,
          50756
        ]
      },
      {
        "avg_logprob": -0.2040511903308687,
        "compression_ratio": 1.5210084033613445,
        "end": 1109.48,
        "id": 387,
        "no_speech_prob": 0.014727959409356117,
        "seek": 109356,
        "start": 1102.84,
        "temperature": 0,
        "text": " But so let me know if anybody else is experiencing issues with quality.",
        "tokens": [
          50828,
          583,
          370,
          718,
          385,
          458,
          498,
          4472,
          1646,
          307,
          11139,
          2663,
          365,
          3125,
          13,
          51160
        ]
      },
      {
        "avg_logprob": -0.2040511903308687,
        "compression_ratio": 1.5210084033613445,
        "end": 1115.08,
        "id": 388,
        "no_speech_prob": 0.014727959409356117,
        "seek": 109356,
        "start": 1110.6,
        "temperature": 0,
        "text": " OK, so what I want to do, let's do, hmm.",
        "tokens": [
          51216,
          2264,
          11,
          370,
          437,
          286,
          528,
          281,
          360,
          11,
          718,
          311,
          360,
          11,
          16478,
          13,
          51440
        ]
      },
      {
        "avg_logprob": -0.2040511903308687,
        "compression_ratio": 1.5210084033613445,
        "end": 1119.24,
        "id": 389,
        "no_speech_prob": 0.014727959409356117,
        "seek": 109356,
        "start": 1116.9199999999998,
        "temperature": 0,
        "text": " I mean, this is not a complicated problem.",
        "tokens": [
          51532,
          286,
          914,
          11,
          341,
          307,
          406,
          257,
          6179,
          1154,
          13,
          51648
        ]
      },
      {
        "avg_logprob": -0.2040511903308687,
        "compression_ratio": 1.5210084033613445,
        "end": 1123.1599999999999,
        "id": 390,
        "no_speech_prob": 0.014727959409356117,
        "seek": 109356,
        "start": 1119.24,
        "temperature": 0,
        "text": " I'm just trying to decide if I want to do it all together.",
        "tokens": [
          51648,
          286,
          478,
          445,
          1382,
          281,
          4536,
          498,
          286,
          528,
          281,
          360,
          309,
          439,
          1214,
          13,
          51844
        ]
      },
      {
        "avg_logprob": -0.1618015582744892,
        "compression_ratio": 1.7017543859649122,
        "end": 1125.16,
        "id": 391,
        "no_speech_prob": 0.000018058466594084166,
        "seek": 112316,
        "start": 1123.16,
        "temperature": 0,
        "text": " Let's do it all together as one video.",
        "tokens": [
          50364,
          961,
          311,
          360,
          309,
          439,
          1214,
          382,
          472,
          960,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1618015582744892,
        "compression_ratio": 1.7017543859649122,
        "end": 1125.72,
        "id": 392,
        "no_speech_prob": 0.000018058466594084166,
        "seek": 112316,
        "start": 1125.16,
        "temperature": 0,
        "text": " Why not?",
        "tokens": [
          50464,
          1545,
          406,
          30,
          50492
        ]
      },
      {
        "avg_logprob": -0.1618015582744892,
        "compression_ratio": 1.7017543859649122,
        "end": 1127.24,
        "id": 393,
        "no_speech_prob": 0.000018058466594084166,
        "seek": 112316,
        "start": 1126.44,
        "temperature": 0,
        "text": " You know, who cares?",
        "tokens": [
          50528,
          509,
          458,
          11,
          567,
          12310,
          30,
          50568
        ]
      },
      {
        "avg_logprob": -0.1618015582744892,
        "compression_ratio": 1.7017543859649122,
        "end": 1133.48,
        "id": 394,
        "no_speech_prob": 0.000018058466594084166,
        "seek": 112316,
        "start": 1128.52,
        "temperature": 0,
        "text": " So this video, what I'm going to do is I'm going to talk about what AFIN111 is.",
        "tokens": [
          50632,
          407,
          341,
          960,
          11,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          751,
          466,
          437,
          20389,
          1464,
          5348,
          16,
          307,
          13,
          50880
        ]
      },
      {
        "avg_logprob": -0.1618015582744892,
        "compression_ratio": 1.7017543859649122,
        "end": 1135.16,
        "id": 395,
        "no_speech_prob": 0.000018058466594084166,
        "seek": 112316,
        "start": 1133.48,
        "temperature": 0,
        "text": " I'm going to grab this file.",
        "tokens": [
          50880,
          286,
          478,
          516,
          281,
          4444,
          341,
          3991,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1618015582744892,
        "compression_ratio": 1.7017543859649122,
        "end": 1137.48,
        "id": 396,
        "no_speech_prob": 0.000018058466594084166,
        "seek": 112316,
        "start": 1135.16,
        "temperature": 0,
        "text": " I'm going to open it in p5.",
        "tokens": [
          50964,
          286,
          478,
          516,
          281,
          1269,
          309,
          294,
          280,
          20,
          13,
          51080
        ]
      },
      {
        "avg_logprob": -0.1618015582744892,
        "compression_ratio": 1.7017543859649122,
        "end": 1139.16,
        "id": 397,
        "no_speech_prob": 0.000018058466594084166,
        "seek": 112316,
        "start": 1137.48,
        "temperature": 0,
        "text": " I'm going to convert it to JSON.",
        "tokens": [
          51080,
          286,
          478,
          516,
          281,
          7620,
          309,
          281,
          31828,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1618015582744892,
        "compression_ratio": 1.7017543859649122,
        "end": 1143.96,
        "id": 398,
        "no_speech_prob": 0.000018058466594084166,
        "seek": 112316,
        "start": 1140.3600000000001,
        "temperature": 0,
        "text": " Then I am going to save it as JSON.",
        "tokens": [
          51224,
          1396,
          286,
          669,
          516,
          281,
          3155,
          309,
          382,
          31828,
          13,
          51404
        ]
      },
      {
        "avg_logprob": -0.1618015582744892,
        "compression_ratio": 1.7017543859649122,
        "end": 1147,
        "id": 399,
        "no_speech_prob": 0.000018058466594084166,
        "seek": 112316,
        "start": 1143.96,
        "temperature": 0,
        "text": " And then I'm going to make a new sketch that loads it as JSON",
        "tokens": [
          51404,
          400,
          550,
          286,
          478,
          516,
          281,
          652,
          257,
          777,
          12325,
          300,
          12668,
          309,
          382,
          31828,
          51556
        ]
      },
      {
        "avg_logprob": -0.1618015582744892,
        "compression_ratio": 1.7017543859649122,
        "end": 1150.1200000000001,
        "id": 400,
        "no_speech_prob": 0.000018058466594084166,
        "seek": 112316,
        "start": 1147,
        "temperature": 0,
        "text": " and does the sentiment analysis part.",
        "tokens": [
          51556,
          293,
          775,
          264,
          16149,
          5215,
          644,
          13,
          51712
        ]
      },
      {
        "avg_logprob": -0.1618015582744892,
        "compression_ratio": 1.7017543859649122,
        "end": 1152.3600000000001,
        "id": 401,
        "no_speech_prob": 0.000018058466594084166,
        "seek": 112316,
        "start": 1150.1200000000001,
        "temperature": 0,
        "text": " OK, so great.",
        "tokens": [
          51712,
          2264,
          11,
          370,
          869,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.41774512875464653,
        "compression_ratio": 1.6989795918367347,
        "end": 1156.1200000000001,
        "id": 402,
        "no_speech_prob": 0.00009610014967620373,
        "seek": 115316,
        "start": 1153.16,
        "temperature": 0,
        "text": " Um, here we go.",
        "tokens": [
          50364,
          3301,
          11,
          510,
          321,
          352,
          13,
          50512
        ]
      },
      {
        "avg_logprob": -0.41774512875464653,
        "compression_ratio": 1.6989795918367347,
        "end": 1158.1200000000001,
        "id": 403,
        "no_speech_prob": 0.00009610014967620373,
        "seek": 115316,
        "start": 1156.92,
        "temperature": 0,
        "text": " So I think I'm ready for this.",
        "tokens": [
          50552,
          407,
          286,
          519,
          286,
          478,
          1919,
          337,
          341,
          13,
          50612
        ]
      },
      {
        "avg_logprob": -0.41774512875464653,
        "compression_ratio": 1.6989795918367347,
        "end": 1160.8400000000001,
        "id": 404,
        "no_speech_prob": 0.00009610014967620373,
        "seek": 115316,
        "start": 1159.16,
        "temperature": 0,
        "text": " Let me check here.",
        "tokens": [
          50664,
          961,
          385,
          1520,
          510,
          13,
          50748
        ]
      },
      {
        "avg_logprob": -0.41774512875464653,
        "compression_ratio": 1.6989795918367347,
        "end": 1162.1200000000001,
        "id": 405,
        "no_speech_prob": 0.00009610014967620373,
        "seek": 115316,
        "start": 1160.8400000000001,
        "temperature": 0,
        "text": " Let me get a little more set up.",
        "tokens": [
          50748,
          961,
          385,
          483,
          257,
          707,
          544,
          992,
          493,
          13,
          50812
        ]
      },
      {
        "avg_logprob": -0.41774512875464653,
        "compression_ratio": 1.6989795918367347,
        "end": 1163.5600000000002,
        "id": 406,
        "no_speech_prob": 0.00009610014967620373,
        "seek": 115316,
        "start": 1162.1200000000001,
        "temperature": 0,
        "text": " I'll play you another song.",
        "tokens": [
          50812,
          286,
          603,
          862,
          291,
          1071,
          2153,
          13,
          50884
        ]
      },
      {
        "avg_logprob": -0.41774512875464653,
        "compression_ratio": 1.6989795918367347,
        "end": 1164.8400000000001,
        "id": 407,
        "no_speech_prob": 0.00009610014967620373,
        "seek": 115316,
        "start": 1163.5600000000002,
        "temperature": 0,
        "text": " You can have the Perlin Noise one now.",
        "tokens": [
          50884,
          509,
          393,
          362,
          264,
          3026,
          5045,
          44821,
          472,
          586,
          13,
          50948
        ]
      },
      {
        "avg_logprob": -0.41774512875464653,
        "compression_ratio": 1.6989795918367347,
        "end": 1167.4,
        "id": 408,
        "no_speech_prob": 0.00009610014967620373,
        "seek": 115316,
        "start": 1164.8400000000001,
        "temperature": 0,
        "text": " Oh, that's just a clip.",
        "tokens": [
          50948,
          876,
          11,
          300,
          311,
          445,
          257,
          7353,
          13,
          51076
        ]
      },
      {
        "avg_logprob": -0.41774512875464653,
        "compression_ratio": 1.6989795918367347,
        "end": 1171.4,
        "id": 409,
        "no_speech_prob": 0.00009610014967620373,
        "seek": 115316,
        "start": 1167.4,
        "temperature": 0,
        "text": " Who knows?",
        "tokens": [
          51076,
          2102,
          3255,
          30,
          51276
        ]
      },
      {
        "avg_logprob": -0.41774512875464653,
        "compression_ratio": 1.6989795918367347,
        "end": 1176.28,
        "id": 410,
        "no_speech_prob": 0.00009610014967620373,
        "seek": 115316,
        "start": 1171.4,
        "temperature": 0,
        "text": " Uh, yeah, that was just a clip.",
        "tokens": [
          51276,
          4019,
          11,
          1338,
          11,
          300,
          390,
          445,
          257,
          7353,
          13,
          51520
        ]
      },
      {
        "avg_logprob": -0.41774512875464653,
        "compression_ratio": 1.6989795918367347,
        "end": 1178.76,
        "id": 411,
        "no_speech_prob": 0.00009610014967620373,
        "seek": 115316,
        "start": 1177.16,
        "temperature": 0,
        "text": " As always, I always forget the this stop.",
        "tokens": [
          51564,
          1018,
          1009,
          11,
          286,
          1009,
          2870,
          264,
          341,
          1590,
          13,
          51644
        ]
      },
      {
        "avg_logprob": -0.41774512875464653,
        "compression_ratio": 1.6989795918367347,
        "end": 1179.48,
        "id": 412,
        "no_speech_prob": 0.00009610014967620373,
        "seek": 115316,
        "start": 1178.76,
        "temperature": 0,
        "text": " Oh, that's the this stop.",
        "tokens": [
          51644,
          876,
          11,
          300,
          311,
          264,
          341,
          1590,
          13,
          51680
        ]
      },
      {
        "avg_logprob": -0.41774512875464653,
        "compression_ratio": 1.6989795918367347,
        "end": 1179.96,
        "id": 413,
        "no_speech_prob": 0.00009610014967620373,
        "seek": 115316,
        "start": 1179.48,
        "temperature": 0,
        "text": " This stop.",
        "tokens": [
          51680,
          639,
          1590,
          13,
          51704
        ]
      },
      {
        "avg_logprob": -0.41774512875464653,
        "compression_ratio": 1.6989795918367347,
        "end": 1180.44,
        "id": 414,
        "no_speech_prob": 0.00009610014967620373,
        "seek": 115316,
        "start": 1179.96,
        "temperature": 0,
        "text": " This stop.",
        "tokens": [
          51704,
          639,
          1590,
          13,
          51728
        ]
      },
      {
        "avg_logprob": -0.41774512875464653,
        "compression_ratio": 1.6989795918367347,
        "end": 1182.44,
        "id": 415,
        "no_speech_prob": 0.00009610014967620373,
        "seek": 115316,
        "start": 1180.44,
        "temperature": 0,
        "text": " This stop.",
        "tokens": [
          51728,
          639,
          1590,
          13,
          51828
        ]
      },
      {
        "avg_logprob": -0.4761797421938413,
        "compression_ratio": 2.116022099447514,
        "end": 1183.72,
        "id": 416,
        "no_speech_prob": 0.09805931895971298,
        "seek": 118244,
        "start": 1183.3200000000002,
        "temperature": 0.4,
        "text": " This stop.",
        "tokens": [
          50408,
          639,
          1590,
          13,
          50428
        ]
      },
      {
        "avg_logprob": -0.4761797421938413,
        "compression_ratio": 2.116022099447514,
        "end": 1184.1200000000001,
        "id": 417,
        "no_speech_prob": 0.09805931895971298,
        "seek": 118244,
        "start": 1183.72,
        "temperature": 0.4,
        "text": " This stop.",
        "tokens": [
          50428,
          639,
          1590,
          13,
          50448
        ]
      },
      {
        "avg_logprob": -0.4761797421938413,
        "compression_ratio": 2.116022099447514,
        "end": 1184.68,
        "id": 418,
        "no_speech_prob": 0.09805931895971298,
        "seek": 118244,
        "start": 1184.1200000000001,
        "temperature": 0.4,
        "text": " This stop.",
        "tokens": [
          50448,
          639,
          1590,
          13,
          50476
        ]
      },
      {
        "avg_logprob": -0.4761797421938413,
        "compression_ratio": 2.116022099447514,
        "end": 1186.3600000000001,
        "id": 419,
        "no_speech_prob": 0.09805931895971298,
        "seek": 118244,
        "start": 1184.68,
        "temperature": 0.4,
        "text": " Empty examples should be good.",
        "tokens": [
          50476,
          3968,
          39420,
          5110,
          820,
          312,
          665,
          13,
          50560
        ]
      },
      {
        "avg_logprob": -0.4761797421938413,
        "compression_ratio": 2.116022099447514,
        "end": 1187.24,
        "id": 420,
        "no_speech_prob": 0.09805931895971298,
        "seek": 118244,
        "start": 1186.3600000000001,
        "temperature": 0.4,
        "text": " This stop.",
        "tokens": [
          50560,
          639,
          1590,
          13,
          50604
        ]
      },
      {
        "avg_logprob": -0.4761797421938413,
        "compression_ratio": 2.116022099447514,
        "end": 1188.2,
        "id": 421,
        "no_speech_prob": 0.09805931895971298,
        "seek": 118244,
        "start": 1187.24,
        "temperature": 0.4,
        "text": " This stop.",
        "tokens": [
          50604,
          639,
          1590,
          13,
          50652
        ]
      },
      {
        "avg_logprob": -0.4761797421938413,
        "compression_ratio": 2.116022099447514,
        "end": 1189.48,
        "id": 422,
        "no_speech_prob": 0.09805931895971298,
        "seek": 118244,
        "start": 1188.2,
        "temperature": 0.4,
        "text": " This stop.",
        "tokens": [
          50652,
          639,
          1590,
          13,
          50716
        ]
      },
      {
        "avg_logprob": -0.4761797421938413,
        "compression_ratio": 2.116022099447514,
        "end": 1191.96,
        "id": 423,
        "no_speech_prob": 0.09805931895971298,
        "seek": 118244,
        "start": 1189.48,
        "temperature": 0.4,
        "text": " 0.5, 0.4 is a good version of p5.",
        "tokens": [
          50716,
          1958,
          13,
          20,
          11,
          1958,
          13,
          19,
          307,
          257,
          665,
          3037,
          295,
          280,
          20,
          13,
          50840
        ]
      },
      {
        "avg_logprob": -0.4761797421938413,
        "compression_ratio": 2.116022099447514,
        "end": 1192.52,
        "id": 424,
        "no_speech_prob": 0.09805931895971298,
        "seek": 118244,
        "start": 1191.96,
        "temperature": 0.4,
        "text": " This stop.",
        "tokens": [
          50840,
          639,
          1590,
          13,
          50868
        ]
      },
      {
        "avg_logprob": -0.4761797421938413,
        "compression_ratio": 2.116022099447514,
        "end": 1193.56,
        "id": 425,
        "no_speech_prob": 0.09805931895971298,
        "seek": 118244,
        "start": 1192.52,
        "temperature": 0.4,
        "text": " This stop.",
        "tokens": [
          50868,
          639,
          1590,
          13,
          50920
        ]
      },
      {
        "avg_logprob": -0.4761797421938413,
        "compression_ratio": 2.116022099447514,
        "end": 1194.3600000000001,
        "id": 426,
        "no_speech_prob": 0.09805931895971298,
        "seek": 118244,
        "start": 1193.56,
        "temperature": 0.4,
        "text": " This stop.",
        "tokens": [
          50920,
          639,
          1590,
          13,
          50960
        ]
      },
      {
        "avg_logprob": -0.4761797421938413,
        "compression_ratio": 2.116022099447514,
        "end": 1195.64,
        "id": 427,
        "no_speech_prob": 0.09805931895971298,
        "seek": 118244,
        "start": 1194.3600000000001,
        "temperature": 0.4,
        "text": " Never forget this stop.",
        "tokens": [
          50960,
          7344,
          2870,
          341,
          1590,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.4761797421938413,
        "compression_ratio": 2.116022099447514,
        "end": 1196.68,
        "id": 428,
        "no_speech_prob": 0.09805931895971298,
        "seek": 118244,
        "start": 1195.64,
        "temperature": 0.4,
        "text": " This stop.",
        "tokens": [
          51024,
          639,
          1590,
          13,
          51076
        ]
      },
      {
        "avg_logprob": -0.4761797421938413,
        "compression_ratio": 2.116022099447514,
        "end": 1197.24,
        "id": 429,
        "no_speech_prob": 0.09805931895971298,
        "seek": 118244,
        "start": 1196.68,
        "temperature": 0.4,
        "text": " This stop.",
        "tokens": [
          51076,
          639,
          1590,
          13,
          51104
        ]
      },
      {
        "avg_logprob": -0.4761797421938413,
        "compression_ratio": 2.116022099447514,
        "end": 1198.8400000000001,
        "id": 430,
        "no_speech_prob": 0.09805931895971298,
        "seek": 118244,
        "start": 1197.24,
        "temperature": 0.4,
        "text": " This stop.",
        "tokens": [
          51104,
          639,
          1590,
          13,
          51184
        ]
      },
      {
        "avg_logprob": -0.4761797421938413,
        "compression_ratio": 2.116022099447514,
        "end": 1203.4,
        "id": 431,
        "no_speech_prob": 0.09805931895971298,
        "seek": 118244,
        "start": 1198.8400000000001,
        "temperature": 0.4,
        "text": " Let's make this A to Z.",
        "tokens": [
          51184,
          961,
          311,
          652,
          341,
          316,
          281,
          1176,
          13,
          51412
        ]
      },
      {
        "avg_logprob": -0.4761797421938413,
        "compression_ratio": 2.116022099447514,
        "end": 1205.24,
        "id": 432,
        "no_speech_prob": 0.09805931895971298,
        "seek": 118244,
        "start": 1204.52,
        "temperature": 0.4,
        "text": " Session.",
        "tokens": [
          51468,
          318,
          4311,
          13,
          51504
        ]
      },
      {
        "avg_logprob": -0.4761797421938413,
        "compression_ratio": 2.116022099447514,
        "end": 1207.72,
        "id": 433,
        "no_speech_prob": 0.09805931895971298,
        "seek": 118244,
        "start": 1205.24,
        "temperature": 0.4,
        "text": " This is still session eight, if you can believe that.",
        "tokens": [
          51504,
          639,
          307,
          920,
          5481,
          3180,
          11,
          498,
          291,
          393,
          1697,
          300,
          13,
          51628
        ]
      },
      {
        "avg_logprob": -0.4761797421938413,
        "compression_ratio": 2.116022099447514,
        "end": 1208.68,
        "id": 434,
        "no_speech_prob": 0.09805931895971298,
        "seek": 118244,
        "start": 1207.72,
        "temperature": 0.4,
        "text": " Always a good one.",
        "tokens": [
          51628,
          11270,
          257,
          665,
          472,
          13,
          51676
        ]
      },
      {
        "avg_logprob": -0.4761797421938413,
        "compression_ratio": 2.116022099447514,
        "end": 1209.24,
        "id": 435,
        "no_speech_prob": 0.09805931895971298,
        "seek": 118244,
        "start": 1208.68,
        "temperature": 0.4,
        "text": " This stop.",
        "tokens": [
          51676,
          639,
          1590,
          13,
          51704
        ]
      },
      {
        "avg_logprob": -0.4761797421938413,
        "compression_ratio": 2.116022099447514,
        "end": 1210.28,
        "id": 436,
        "no_speech_prob": 0.09805931895971298,
        "seek": 118244,
        "start": 1209.24,
        "temperature": 0.4,
        "text": " This stop.",
        "tokens": [
          51704,
          639,
          1590,
          13,
          51756
        ]
      },
      {
        "avg_logprob": -0.4761797421938413,
        "compression_ratio": 2.116022099447514,
        "end": 1211.88,
        "id": 437,
        "no_speech_prob": 0.09805931895971298,
        "seek": 118244,
        "start": 1210.28,
        "temperature": 0.4,
        "text": " I mean, in a way, this example is.",
        "tokens": [
          51756,
          286,
          914,
          11,
          294,
          257,
          636,
          11,
          341,
          1365,
          307,
          13,
          51836
        ]
      },
      {
        "avg_logprob": -0.9909916893910553,
        "compression_ratio": 1.5858585858585859,
        "end": 1212.8400000000001,
        "id": 438,
        "no_speech_prob": 0.21425142884254456,
        "seek": 121188,
        "start": 1212.44,
        "temperature": 0.6000000000000001,
        "text": " This stop.",
        "tokens": [
          50392,
          639,
          1590,
          13,
          50412
        ]
      },
      {
        "avg_logprob": -0.9909916893910553,
        "compression_ratio": 1.5858585858585859,
        "end": 1213,
        "id": 439,
        "no_speech_prob": 0.21425142884254456,
        "seek": 121188,
        "start": 1212.8400000000001,
        "temperature": 0.6000000000000001,
        "text": " This stop.",
        "tokens": [
          50412,
          639,
          1590,
          13,
          50420
        ]
      },
      {
        "avg_logprob": -0.9909916893910553,
        "compression_ratio": 1.5858585858585859,
        "end": 1222.6000000000001,
        "id": 440,
        "no_speech_prob": 0.21425142884254456,
        "seek": 121188,
        "start": 1213,
        "temperature": 0.6000000000000001,
        "text": " From that earlier session.",
        "tokens": [
          50420,
          479,
          4397,
          300,
          3071,
          5481,
          13,
          50900
        ]
      },
      {
        "avg_logprob": -0.9909916893910553,
        "compression_ratio": 1.5858585858585859,
        "end": 1236.6000000000001,
        "id": 441,
        "no_speech_prob": 0.21425142884254456,
        "seek": 121188,
        "start": 1229.8000000000002,
        "temperature": 0.6000000000000001,
        "text": " When you say sublime or Adam, these days.",
        "tokens": [
          51260,
          1133,
          291,
          584,
          1422,
          40941,
          420,
          316,
          10170,
          11,
          613,
          1708,
          13,
          51600
        ]
      },
      {
        "avg_logprob": -0.9909916893910553,
        "compression_ratio": 1.5858585858585859,
        "end": 1241.0800000000002,
        "id": 442,
        "no_speech_prob": 0.21425142884254456,
        "seek": 121188,
        "start": 1237.96,
        "temperature": 0.6000000000000001,
        "text": " I'm gonna do this, this, this, this, this, this, this, this, this.",
        "tokens": [
          51668,
          286,
          478,
          799,
          220,
          2595,
          341,
          11,
          341,
          11,
          341,
          11,
          341,
          11,
          341,
          11,
          341,
          11,
          341,
          11,
          341,
          11,
          341,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.3325635669300857,
        "compression_ratio": 1.5077720207253886,
        "end": 1241.56,
        "id": 443,
        "no_speech_prob": 0.004823004826903343,
        "seek": 124108,
        "start": 1241.08,
        "temperature": 0,
        "text": " Stop song.",
        "tokens": [
          50364,
          5535,
          2153,
          13,
          50388
        ]
      },
      {
        "avg_logprob": -0.3325635669300857,
        "compression_ratio": 1.5077720207253886,
        "end": 1242.76,
        "id": 444,
        "no_speech_prob": 0.004823004826903343,
        "seek": 124108,
        "start": 1241.56,
        "temperature": 0,
        "text": " Never forget the this dot.",
        "tokens": [
          50388,
          7344,
          2870,
          264,
          341,
          5893,
          13,
          50448
        ]
      },
      {
        "avg_logprob": -0.3325635669300857,
        "compression_ratio": 1.5077720207253886,
        "end": 1245.1599999999999,
        "id": 445,
        "no_speech_prob": 0.004823004826903343,
        "seek": 124108,
        "start": 1243.8,
        "temperature": 0,
        "text": " Somebody composed that song for me.",
        "tokens": [
          50500,
          13463,
          18204,
          300,
          2153,
          337,
          385,
          13,
          50568
        ]
      },
      {
        "avg_logprob": -0.3325635669300857,
        "compression_ratio": 1.5077720207253886,
        "end": 1246.28,
        "id": 446,
        "no_speech_prob": 0.004823004826903343,
        "seek": 124108,
        "start": 1245.96,
        "temperature": 0,
        "text": " Oops.",
        "tokens": [
          50608,
          21726,
          13,
          50624
        ]
      },
      {
        "avg_logprob": -0.3325635669300857,
        "compression_ratio": 1.5077720207253886,
        "end": 1249.72,
        "id": 447,
        "no_speech_prob": 0.004823004826903343,
        "seek": 124108,
        "start": 1248.84,
        "temperature": 0,
        "text": " Well, here we go.",
        "tokens": [
          50752,
          1042,
          11,
          510,
          321,
          352,
          13,
          50796
        ]
      },
      {
        "avg_logprob": -0.3325635669300857,
        "compression_ratio": 1.5077720207253886,
        "end": 1249.96,
        "id": 448,
        "no_speech_prob": 0.004823004826903343,
        "seek": 124108,
        "start": 1249.72,
        "temperature": 0,
        "text": " This.",
        "tokens": [
          50796,
          639,
          13,
          50808
        ]
      },
      {
        "avg_logprob": -0.3325635669300857,
        "compression_ratio": 1.5077720207253886,
        "end": 1251.56,
        "id": 449,
        "no_speech_prob": 0.004823004826903343,
        "seek": 124108,
        "start": 1251.24,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50872,
          1033,
          13,
          50888
        ]
      },
      {
        "avg_logprob": -0.3325635669300857,
        "compression_ratio": 1.5077720207253886,
        "end": 1253.3999999999999,
        "id": 450,
        "no_speech_prob": 0.004823004826903343,
        "seek": 124108,
        "start": 1251.56,
        "temperature": 0,
        "text": " I'm just opening up this project.",
        "tokens": [
          50888,
          286,
          478,
          445,
          5193,
          493,
          341,
          1716,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.3325635669300857,
        "compression_ratio": 1.5077720207253886,
        "end": 1256.12,
        "id": 451,
        "no_speech_prob": 0.004823004826903343,
        "seek": 124108,
        "start": 1255.1599999999999,
        "temperature": 0,
        "text": " Getting the code.",
        "tokens": [
          51068,
          13674,
          264,
          3089,
          13,
          51116
        ]
      },
      {
        "avg_logprob": -0.3325635669300857,
        "compression_ratio": 1.5077720207253886,
        "end": 1256.76,
        "id": 452,
        "no_speech_prob": 0.004823004826903343,
        "seek": 124108,
        "start": 1256.12,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51116,
          821,
          321,
          352,
          13,
          51148
        ]
      },
      {
        "avg_logprob": -0.3325635669300857,
        "compression_ratio": 1.5077720207253886,
        "end": 1262.04,
        "id": 453,
        "no_speech_prob": 0.004823004826903343,
        "seek": 124108,
        "start": 1258.4399999999998,
        "temperature": 0,
        "text": " I'm gonna clean this up for a second.",
        "tokens": [
          51232,
          286,
          478,
          799,
          2541,
          341,
          493,
          337,
          257,
          1150,
          13,
          51412
        ]
      },
      {
        "avg_logprob": -0.3325635669300857,
        "compression_ratio": 1.5077720207253886,
        "end": 1264.36,
        "id": 454,
        "no_speech_prob": 0.004823004826903343,
        "seek": 124108,
        "start": 1262.04,
        "temperature": 0,
        "text": " I want to have, I don't need the sound library.",
        "tokens": [
          51412,
          286,
          528,
          281,
          362,
          11,
          286,
          500,
          380,
          643,
          264,
          1626,
          6405,
          13,
          51528
        ]
      },
      {
        "avg_logprob": -0.3325635669300857,
        "compression_ratio": 1.5077720207253886,
        "end": 1267.72,
        "id": 455,
        "no_speech_prob": 0.004823004826903343,
        "seek": 124108,
        "start": 1265.8799999999999,
        "temperature": 0,
        "text": " But I do need the dom library.",
        "tokens": [
          51604,
          583,
          286,
          360,
          643,
          264,
          3285,
          6405,
          13,
          51696
        ]
      },
      {
        "avg_logprob": -0.35057291777237604,
        "compression_ratio": 1.2941176470588236,
        "end": 1271,
        "id": 456,
        "no_speech_prob": 0.09944014996290207,
        "seek": 126772,
        "start": 1268.44,
        "temperature": 0,
        "text": " And sketch dot JS.",
        "tokens": [
          50400,
          400,
          12325,
          5893,
          33063,
          13,
          50528
        ]
      },
      {
        "avg_logprob": -0.35057291777237604,
        "compression_ratio": 1.2941176470588236,
        "end": 1274.44,
        "id": 457,
        "no_speech_prob": 0.09944014996290207,
        "seek": 126772,
        "start": 1272.6000000000001,
        "temperature": 0,
        "text": " And index dot HTML.",
        "tokens": [
          50608,
          400,
          8186,
          5893,
          17995,
          13,
          50700
        ]
      },
      {
        "avg_logprob": -0.35057291777237604,
        "compression_ratio": 1.2941176470588236,
        "end": 1276.28,
        "id": 458,
        "no_speech_prob": 0.09944014996290207,
        "seek": 126772,
        "start": 1274.44,
        "temperature": 0,
        "text": " And I'm gonna say title.",
        "tokens": [
          50700,
          400,
          286,
          478,
          799,
          584,
          4876,
          13,
          50792
        ]
      },
      {
        "avg_logprob": -0.35057291777237604,
        "compression_ratio": 1.2941176470588236,
        "end": 1279.72,
        "id": 459,
        "no_speech_prob": 0.09944014996290207,
        "seek": 126772,
        "start": 1279.24,
        "temperature": 0,
        "text": " Title.",
        "tokens": [
          50940,
          26768,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.35057291777237604,
        "compression_ratio": 1.2941176470588236,
        "end": 1282.52,
        "id": 460,
        "no_speech_prob": 0.09944014996290207,
        "seek": 126772,
        "start": 1280.3600000000001,
        "temperature": 0,
        "text": " A fin one eleven demo.",
        "tokens": [
          50996,
          316,
          962,
          472,
          21090,
          10723,
          13,
          51104
        ]
      },
      {
        "avg_logprob": -0.35057291777237604,
        "compression_ratio": 1.2941176470588236,
        "end": 1285.88,
        "id": 461,
        "no_speech_prob": 0.09944014996290207,
        "seek": 126772,
        "start": 1283.96,
        "temperature": 0,
        "text": " Just get a few things set up here.",
        "tokens": [
          51176,
          1449,
          483,
          257,
          1326,
          721,
          992,
          493,
          510,
          13,
          51272
        ]
      },
      {
        "avg_logprob": -0.35057291777237604,
        "compression_ratio": 1.2941176470588236,
        "end": 1289.64,
        "id": 462,
        "no_speech_prob": 0.09944014996290207,
        "seek": 126772,
        "start": 1287.48,
        "temperature": 0,
        "text": " And then I want to run a server.",
        "tokens": [
          51352,
          400,
          550,
          286,
          528,
          281,
          1190,
          257,
          7154,
          13,
          51460
        ]
      },
      {
        "avg_logprob": -0.35057291777237604,
        "compression_ratio": 1.2941176470588236,
        "end": 1293.8,
        "id": 463,
        "no_speech_prob": 0.09944014996290207,
        "seek": 126772,
        "start": 1292.92,
        "temperature": 0,
        "text": " Tempted.",
        "tokens": [
          51624,
          314,
          4543,
          292,
          13,
          51668
        ]
      },
      {
        "avg_logprob": -0.35057291777237604,
        "compression_ratio": 1.2941176470588236,
        "end": 1294.04,
        "id": 464,
        "no_speech_prob": 0.09944014996290207,
        "seek": 126772,
        "start": 1293.8,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51668,
          1033,
          13,
          51680
        ]
      },
      {
        "avg_logprob": -0.7626950010961416,
        "compression_ratio": 1.2285714285714286,
        "end": 1295.3999999999999,
        "id": 465,
        "no_speech_prob": 0.006487752310931683,
        "seek": 129404,
        "start": 1294.92,
        "temperature": 0,
        "text": " Oops.",
        "tokens": [
          50408,
          21726,
          13,
          50432
        ]
      },
      {
        "avg_logprob": -0.7626950010961416,
        "compression_ratio": 1.2285714285714286,
        "end": 1300.6,
        "id": 466,
        "no_speech_prob": 0.006487752310931683,
        "seek": 129404,
        "start": 1299.32,
        "temperature": 0,
        "text": " Let's run a server.",
        "tokens": [
          50628,
          961,
          311,
          1190,
          257,
          7154,
          13,
          50692
        ]
      },
      {
        "avg_logprob": -0.7626950010961416,
        "compression_ratio": 1.2285714285714286,
        "end": 1305.08,
        "id": 467,
        "no_speech_prob": 0.006487752310931683,
        "seek": 129404,
        "start": 1304.12,
        "temperature": 0,
        "text": " Session eight.",
        "tokens": [
          50868,
          318,
          4311,
          3180,
          13,
          50916
        ]
      },
      {
        "avg_logprob": -0.7626950010961416,
        "compression_ratio": 1.2285714285714286,
        "end": 1313.1599999999999,
        "id": 468,
        "no_speech_prob": 0.006487752310931683,
        "seek": 129404,
        "start": 1309.96,
        "temperature": 0,
        "text": " And let's take a look at everything in the browser.",
        "tokens": [
          51160,
          400,
          718,
          311,
          747,
          257,
          574,
          412,
          1203,
          294,
          264,
          11185,
          13,
          51320
        ]
      },
      {
        "avg_logprob": -0.7626950010961416,
        "compression_ratio": 1.2285714285714286,
        "end": 1320.12,
        "id": 469,
        "no_speech_prob": 0.006487752310931683,
        "seek": 129404,
        "start": 1315.96,
        "temperature": 0,
        "text": " And let's get a console open.",
        "tokens": [
          51460,
          400,
          718,
          311,
          483,
          257,
          11076,
          1269,
          13,
          51668
        ]
      },
      {
        "avg_logprob": -0.7626950010961416,
        "compression_ratio": 1.2285714285714286,
        "end": 1321.24,
        "id": 470,
        "no_speech_prob": 0.006487752310931683,
        "seek": 129404,
        "start": 1320.92,
        "temperature": 0,
        "text": " Let's.",
        "tokens": [
          51708,
          961,
          311,
          13,
          51724
        ]
      },
      {
        "avg_logprob": -0.6386990547180176,
        "compression_ratio": 1.2252252252252251,
        "end": 1326.6,
        "id": 471,
        "no_speech_prob": 0.0009697200148366392,
        "seek": 132124,
        "start": 1321.24,
        "temperature": 0,
        "text": " Do no canvas.",
        "tokens": [
          50364,
          1144,
          572,
          16267,
          13,
          50632
        ]
      },
      {
        "avg_logprob": -0.6386990547180176,
        "compression_ratio": 1.2252252252252251,
        "end": 1330.6,
        "id": 472,
        "no_speech_prob": 0.0009697200148366392,
        "seek": 132124,
        "start": 1328.1200000000001,
        "temperature": 0,
        "text": " Console dot log sentiment.",
        "tokens": [
          50708,
          44152,
          5893,
          3565,
          16149,
          13,
          50832
        ]
      },
      {
        "avg_logprob": -0.6386990547180176,
        "compression_ratio": 1.2252252252252251,
        "end": 1333.4,
        "id": 473,
        "no_speech_prob": 0.0009697200148366392,
        "seek": 132124,
        "start": 1332.92,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50948,
          1033,
          13,
          50972
        ]
      },
      {
        "avg_logprob": -0.6386990547180176,
        "compression_ratio": 1.2252252252252251,
        "end": 1336.04,
        "id": 474,
        "no_speech_prob": 0.0009697200148366392,
        "seek": 132124,
        "start": 1333.4,
        "temperature": 0,
        "text": " So it looks like we are up and running.",
        "tokens": [
          50972,
          407,
          309,
          1542,
          411,
          321,
          366,
          493,
          293,
          2614,
          13,
          51104
        ]
      },
      {
        "avg_logprob": -0.6386990547180176,
        "compression_ratio": 1.2252252252252251,
        "end": 1338.84,
        "id": 475,
        "no_speech_prob": 0.0009697200148366392,
        "seek": 132124,
        "start": 1336.92,
        "temperature": 0,
        "text": " I need to have the website.",
        "tokens": [
          51148,
          286,
          643,
          281,
          362,
          264,
          3144,
          13,
          51244
        ]
      },
      {
        "avg_logprob": -0.6386990547180176,
        "compression_ratio": 1.2252252252252251,
        "end": 1341.08,
        "id": 476,
        "no_speech_prob": 0.0009697200148366392,
        "seek": 132124,
        "start": 1339.48,
        "temperature": 0,
        "text": " I need also this URL.",
        "tokens": [
          51276,
          286,
          643,
          611,
          341,
          12905,
          13,
          51356
        ]
      },
      {
        "avg_logprob": -0.5787181592967412,
        "compression_ratio": 2.2131147540983607,
        "end": 1343.3999999999999,
        "id": 477,
        "no_speech_prob": 0.013020152226090431,
        "seek": 134108,
        "start": 1341.8799999999999,
        "temperature": 0.2,
        "text": " I will have open here.",
        "tokens": [
          50404,
          286,
          486,
          362,
          1269,
          510,
          13,
          50480
        ]
      },
      {
        "avg_logprob": -0.5787181592967412,
        "compression_ratio": 2.2131147540983607,
        "end": 1343.8999999999999,
        "id": 478,
        "no_speech_prob": 0.013020152226090431,
        "seek": 134108,
        "start": 1343.3999999999999,
        "temperature": 0.2,
        "text": " Okay.",
        "tokens": [
          50480,
          1033,
          13,
          50505
        ]
      },
      {
        "avg_logprob": -0.5787181592967412,
        "compression_ratio": 2.2131147540983607,
        "end": 1347.8,
        "id": 479,
        "no_speech_prob": 0.013020152226090431,
        "seek": 134108,
        "start": 1344.52,
        "temperature": 0.2,
        "text": " Just checking the chat.",
        "tokens": [
          50536,
          1449,
          8568,
          264,
          5081,
          13,
          50700
        ]
      },
      {
        "avg_logprob": -0.5787181592967412,
        "compression_ratio": 2.2131147540983607,
        "end": 1349.8799999999999,
        "id": 480,
        "no_speech_prob": 0.013020152226090431,
        "seek": 134108,
        "start": 1347.8,
        "temperature": 0.2,
        "text": " Are you supposed to hear the audio from the computer?",
        "tokens": [
          50700,
          2014,
          291,
          3442,
          281,
          1568,
          264,
          6278,
          490,
          264,
          3820,
          30,
          50804
        ]
      },
      {
        "avg_logprob": -0.5787181592967412,
        "compression_ratio": 2.2131147540983607,
        "end": 1351.08,
        "id": 481,
        "no_speech_prob": 0.013020152226090431,
        "seek": 134108,
        "start": 1350.4399999999998,
        "temperature": 0.2,
        "text": " You are.",
        "tokens": [
          50832,
          509,
          366,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.5787181592967412,
        "compression_ratio": 2.2131147540983607,
        "end": 1352.6799999999998,
        "id": 482,
        "no_speech_prob": 0.013020152226090431,
        "seek": 134108,
        "start": 1352.04,
        "temperature": 0.2,
        "text": " Did you not?",
        "tokens": [
          50912,
          2589,
          291,
          406,
          30,
          50944
        ]
      },
      {
        "avg_logprob": -0.5787181592967412,
        "compression_ratio": 2.2131147540983607,
        "end": 1353.8,
        "id": 483,
        "no_speech_prob": 0.013020152226090431,
        "seek": 134108,
        "start": 1353.24,
        "temperature": 0.2,
        "text": " Hold on.",
        "tokens": [
          50972,
          6962,
          322,
          13,
          51000
        ]
      },
      {
        "avg_logprob": -0.5787181592967412,
        "compression_ratio": 2.2131147540983607,
        "end": 1358.6799999999998,
        "id": 484,
        "no_speech_prob": 0.013020152226090431,
        "seek": 134108,
        "start": 1355,
        "temperature": 0.2,
        "text": " Oh, you can't hear my voice when I'm playing the music at the same time.",
        "tokens": [
          51060,
          876,
          11,
          291,
          393,
          380,
          1568,
          452,
          3177,
          562,
          286,
          478,
          2433,
          264,
          1318,
          412,
          264,
          912,
          565,
          13,
          51244
        ]
      },
      {
        "avg_logprob": -0.5787181592967412,
        "compression_ratio": 2.2131147540983607,
        "end": 1359.1599999999999,
        "id": 485,
        "no_speech_prob": 0.013020152226090431,
        "seek": 134108,
        "start": 1358.6799999999998,
        "temperature": 0.2,
        "text": " Okay.",
        "tokens": [
          51244,
          1033,
          13,
          51268
        ]
      },
      {
        "avg_logprob": -0.5787181592967412,
        "compression_ratio": 2.2131147540983607,
        "end": 1359.8,
        "id": 486,
        "no_speech_prob": 0.013020152226090431,
        "seek": 134108,
        "start": 1359.1599999999999,
        "temperature": 0.2,
        "text": " That's good to know.",
        "tokens": [
          51268,
          663,
          311,
          665,
          281,
          458,
          13,
          51300
        ]
      },
      {
        "avg_logprob": -0.5787181592967412,
        "compression_ratio": 2.2131147540983607,
        "end": 1362.4399999999998,
        "id": 487,
        "no_speech_prob": 0.013020152226090431,
        "seek": 134108,
        "start": 1360.76,
        "temperature": 0.2,
        "text": " I can turn on my music.",
        "tokens": [
          51348,
          286,
          393,
          1261,
          322,
          452,
          1318,
          13,
          51432
        ]
      },
      {
        "avg_logprob": -0.5787181592967412,
        "compression_ratio": 2.2131147540983607,
        "end": 1364.12,
        "id": 488,
        "no_speech_prob": 0.013020152226090431,
        "seek": 134108,
        "start": 1362.4399999999998,
        "temperature": 0.2,
        "text": " I can turn on my music.",
        "tokens": [
          51432,
          286,
          393,
          1261,
          322,
          452,
          1318,
          13,
          51516
        ]
      },
      {
        "avg_logprob": -0.5787181592967412,
        "compression_ratio": 2.2131147540983607,
        "end": 1365.1599999999999,
        "id": 489,
        "no_speech_prob": 0.013020152226090431,
        "seek": 134108,
        "start": 1364.12,
        "temperature": 0.2,
        "text": " I can turn on my music.",
        "tokens": [
          51516,
          286,
          393,
          1261,
          322,
          452,
          1318,
          13,
          51568
        ]
      },
      {
        "avg_logprob": -0.5787181592967412,
        "compression_ratio": 2.2131147540983607,
        "end": 1366.12,
        "id": 490,
        "no_speech_prob": 0.013020152226090431,
        "seek": 134108,
        "start": 1365.1599999999999,
        "temperature": 0.2,
        "text": " I can turn on my music.",
        "tokens": [
          51568,
          286,
          393,
          1261,
          322,
          452,
          1318,
          13,
          51616
        ]
      },
      {
        "avg_logprob": -0.5787181592967412,
        "compression_ratio": 2.2131147540983607,
        "end": 1367.24,
        "id": 491,
        "no_speech_prob": 0.013020152226090431,
        "seek": 134108,
        "start": 1366.12,
        "temperature": 0.2,
        "text": " I can turn on my music.",
        "tokens": [
          51616,
          286,
          393,
          1261,
          322,
          452,
          1318,
          13,
          51672
        ]
      },
      {
        "avg_logprob": -0.5787181592967412,
        "compression_ratio": 2.2131147540983607,
        "end": 1368.28,
        "id": 492,
        "no_speech_prob": 0.013020152226090431,
        "seek": 134108,
        "start": 1367.24,
        "temperature": 0.2,
        "text": " I can turn on my music.",
        "tokens": [
          51672,
          286,
          393,
          1261,
          322,
          452,
          1318,
          13,
          51724
        ]
      },
      {
        "avg_logprob": -0.5787181592967412,
        "compression_ratio": 2.2131147540983607,
        "end": 1369.6399999999999,
        "id": 493,
        "no_speech_prob": 0.013020152226090431,
        "seek": 134108,
        "start": 1368.28,
        "temperature": 0.2,
        "text": " I can turn on my music.",
        "tokens": [
          51724,
          286,
          393,
          1261,
          322,
          452,
          1318,
          13,
          51792
        ]
      },
      {
        "avg_logprob": -0.2065848880343967,
        "compression_ratio": 1.789090909090909,
        "end": 1373.64,
        "id": 494,
        "no_speech_prob": 0.0005703010829165578,
        "seek": 136964,
        "start": 1370.3600000000001,
        "temperature": 0,
        "text": " I can turn I can also turn down the music and all that stuff.",
        "tokens": [
          50400,
          286,
          393,
          1261,
          286,
          393,
          611,
          1261,
          760,
          264,
          1318,
          293,
          439,
          300,
          1507,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2065848880343967,
        "compression_ratio": 1.789090909090909,
        "end": 1375,
        "id": 495,
        "no_speech_prob": 0.0005703010829165578,
        "seek": 136964,
        "start": 1373.64,
        "temperature": 0,
        "text": " But I'm not going to worry about it right now.",
        "tokens": [
          50564,
          583,
          286,
          478,
          406,
          516,
          281,
          3292,
          466,
          309,
          558,
          586,
          13,
          50632
        ]
      },
      {
        "avg_logprob": -0.2065848880343967,
        "compression_ratio": 1.789090909090909,
        "end": 1378.2800000000002,
        "id": 496,
        "no_speech_prob": 0.0005703010829165578,
        "seek": 136964,
        "start": 1377.88,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50776,
          1057,
          558,
          13,
          50796
        ]
      },
      {
        "avg_logprob": -0.2065848880343967,
        "compression_ratio": 1.789090909090909,
        "end": 1379.16,
        "id": 497,
        "no_speech_prob": 0.0005703010829165578,
        "seek": 136964,
        "start": 1378.92,
        "temperature": 0,
        "text": " Wow.",
        "tokens": [
          50828,
          3153,
          13,
          50840
        ]
      },
      {
        "avg_logprob": -0.2065848880343967,
        "compression_ratio": 1.789090909090909,
        "end": 1380.8400000000001,
        "id": 498,
        "no_speech_prob": 0.0005703010829165578,
        "seek": 136964,
        "start": 1379.16,
        "temperature": 0,
        "text": " This has been the least amount I shouldn't say.",
        "tokens": [
          50840,
          639,
          575,
          668,
          264,
          1935,
          2372,
          286,
          4659,
          380,
          584,
          13,
          50924
        ]
      },
      {
        "avg_logprob": -0.2065848880343967,
        "compression_ratio": 1.789090909090909,
        "end": 1385.0800000000002,
        "id": 499,
        "no_speech_prob": 0.0005703010829165578,
        "seek": 136964,
        "start": 1380.8400000000001,
        "temperature": 0,
        "text": " I was going to say the least amount of technical difficulties I've had doing this in a while.",
        "tokens": [
          50924,
          286,
          390,
          516,
          281,
          584,
          264,
          1935,
          2372,
          295,
          6191,
          14399,
          286,
          600,
          632,
          884,
          341,
          294,
          257,
          1339,
          13,
          51136
        ]
      },
      {
        "avg_logprob": -0.2065848880343967,
        "compression_ratio": 1.789090909090909,
        "end": 1387.96,
        "id": 500,
        "no_speech_prob": 0.0005703010829165578,
        "seek": 136964,
        "start": 1385.0800000000002,
        "temperature": 0,
        "text": " But I shouldn't say anything because now everything's going to start crashing and burning.",
        "tokens": [
          51136,
          583,
          286,
          4659,
          380,
          584,
          1340,
          570,
          586,
          1203,
          311,
          516,
          281,
          722,
          26900,
          293,
          9488,
          13,
          51280
        ]
      },
      {
        "avg_logprob": -0.2065848880343967,
        "compression_ratio": 1.789090909090909,
        "end": 1388.68,
        "id": 501,
        "no_speech_prob": 0.0005703010829165578,
        "seek": 136964,
        "start": 1387.96,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51280,
          1033,
          13,
          51316
        ]
      },
      {
        "avg_logprob": -0.2065848880343967,
        "compression_ratio": 1.789090909090909,
        "end": 1396.8400000000001,
        "id": 502,
        "no_speech_prob": 0.0005703010829165578,
        "seek": 136964,
        "start": 1388.68,
        "temperature": 0,
        "text": " So I'm checking at the in the chat to see if anyone is saying anything important.",
        "tokens": [
          51316,
          407,
          286,
          478,
          8568,
          412,
          264,
          294,
          264,
          5081,
          281,
          536,
          498,
          2878,
          307,
          1566,
          1340,
          1021,
          13,
          51724
        ]
      },
      {
        "avg_logprob": -0.2065848880343967,
        "compression_ratio": 1.789090909090909,
        "end": 1398.2,
        "id": 503,
        "no_speech_prob": 0.0005703010829165578,
        "seek": 136964,
        "start": 1396.8400000000001,
        "temperature": 0,
        "text": " Like nothing is working.",
        "tokens": [
          51724,
          1743,
          1825,
          307,
          1364,
          13,
          51792
        ]
      },
      {
        "avg_logprob": -0.2065848880343967,
        "compression_ratio": 1.789090909090909,
        "end": 1398.92,
        "id": 504,
        "no_speech_prob": 0.0005703010829165578,
        "seek": 136964,
        "start": 1398.2,
        "temperature": 0,
        "text": " I can't see anything.",
        "tokens": [
          51792,
          286,
          393,
          380,
          536,
          1340,
          13,
          51828
        ]
      },
      {
        "avg_logprob": -0.22821394034794398,
        "compression_ratio": 1.5384615384615385,
        "end": 1399.64,
        "id": 505,
        "no_speech_prob": 0.00018813961651176214,
        "seek": 139892,
        "start": 1398.92,
        "temperature": 0,
        "text": " It looks okay.",
        "tokens": [
          50364,
          467,
          1542,
          1392,
          13,
          50400
        ]
      },
      {
        "avg_logprob": -0.22821394034794398,
        "compression_ratio": 1.5384615384615385,
        "end": 1401.8000000000002,
        "id": 506,
        "no_speech_prob": 0.00018813961651176214,
        "seek": 139892,
        "start": 1400.2,
        "temperature": 0,
        "text": " So I am now going to get started.",
        "tokens": [
          50428,
          407,
          286,
          669,
          586,
          516,
          281,
          483,
          1409,
          13,
          50508
        ]
      },
      {
        "avg_logprob": -0.22821394034794398,
        "compression_ratio": 1.5384615384615385,
        "end": 1402.6000000000001,
        "id": 507,
        "no_speech_prob": 0.00018813961651176214,
        "seek": 139892,
        "start": 1401.8000000000002,
        "temperature": 0,
        "text": " Oh, hold on.",
        "tokens": [
          50508,
          876,
          11,
          1797,
          322,
          13,
          50548
        ]
      },
      {
        "avg_logprob": -0.22821394034794398,
        "compression_ratio": 1.5384615384615385,
        "end": 1405.72,
        "id": 508,
        "no_speech_prob": 0.00018813961651176214,
        "seek": 139892,
        "start": 1402.6000000000001,
        "temperature": 0,
        "text": " This microphone is awkwardly positioned.",
        "tokens": [
          50548,
          639,
          10952,
          307,
          11411,
          356,
          24889,
          13,
          50704
        ]
      },
      {
        "avg_logprob": -0.22821394034794398,
        "compression_ratio": 1.5384615384615385,
        "end": 1407,
        "id": 509,
        "no_speech_prob": 0.00018813961651176214,
        "seek": 139892,
        "start": 1405.72,
        "temperature": 0,
        "text": " That's a little bit better.",
        "tokens": [
          50704,
          663,
          311,
          257,
          707,
          857,
          1101,
          13,
          50768
        ]
      },
      {
        "avg_logprob": -0.22821394034794398,
        "compression_ratio": 1.5384615384615385,
        "end": 1413.16,
        "id": 510,
        "no_speech_prob": 0.00018813961651176214,
        "seek": 139892,
        "start": 1407,
        "temperature": 0,
        "text": " So this first video that I'm going to do, first of all, the reason why I'm doing this is because",
        "tokens": [
          50768,
          407,
          341,
          700,
          960,
          300,
          286,
          478,
          516,
          281,
          360,
          11,
          700,
          295,
          439,
          11,
          264,
          1778,
          983,
          286,
          478,
          884,
          341,
          307,
          570,
          51076
        ]
      },
      {
        "avg_logprob": -0.22821394034794398,
        "compression_ratio": 1.5384615384615385,
        "end": 1414.6000000000001,
        "id": 511,
        "no_speech_prob": 0.00018813961651176214,
        "seek": 139892,
        "start": 1414.2,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          51128,
          286,
          500,
          380,
          458,
          13,
          51148
        ]
      },
      {
        "avg_logprob": -0.22821394034794398,
        "compression_ratio": 1.5384615384615385,
        "end": 1415.8000000000002,
        "id": 512,
        "no_speech_prob": 0.00018813961651176214,
        "seek": 139892,
        "start": 1415.3200000000002,
        "temperature": 0,
        "text": " Why not?",
        "tokens": [
          51184,
          1545,
          406,
          30,
          51208
        ]
      },
      {
        "avg_logprob": -0.22821394034794398,
        "compression_ratio": 1.5384615384615385,
        "end": 1426.52,
        "id": 513,
        "no_speech_prob": 0.00018813961651176214,
        "seek": 139892,
        "start": 1417.3200000000002,
        "temperature": 0,
        "text": " But what I want to do is have the node API that I'm making do be an example just be a",
        "tokens": [
          51284,
          583,
          437,
          286,
          528,
          281,
          360,
          307,
          362,
          264,
          9984,
          9362,
          300,
          286,
          478,
          1455,
          360,
          312,
          364,
          1365,
          445,
          312,
          257,
          51744
        ]
      },
      {
        "avg_logprob": -0.22821394034794398,
        "compression_ratio": 1.5384615384615385,
        "end": 1428.6000000000001,
        "id": 514,
        "no_speech_prob": 0.00018813961651176214,
        "seek": 139892,
        "start": 1426.52,
        "temperature": 0,
        "text": " sentiment analysis API.",
        "tokens": [
          51744,
          16149,
          5215,
          9362,
          13,
          51848
        ]
      },
      {
        "avg_logprob": -0.2093562416408373,
        "compression_ratio": 1.6513409961685823,
        "end": 1433.3999999999999,
        "id": 515,
        "no_speech_prob": 0.00003705273411469534,
        "seek": 142860,
        "start": 1428.84,
        "temperature": 0,
        "text": " So I thought it would be worth before going and adding all that code to node to just sort",
        "tokens": [
          50376,
          407,
          286,
          1194,
          309,
          576,
          312,
          3163,
          949,
          516,
          293,
          5127,
          439,
          300,
          3089,
          281,
          9984,
          281,
          445,
          1333,
          50604
        ]
      },
      {
        "avg_logprob": -0.2093562416408373,
        "compression_ratio": 1.6513409961685823,
        "end": 1440.6,
        "id": 516,
        "no_speech_prob": 0.00003705273411469534,
        "seek": 142860,
        "start": 1433.3999999999999,
        "temperature": 0,
        "text": " of show one simple technique for doing sentiment analysis and do that in a coding challenge.",
        "tokens": [
          50604,
          295,
          855,
          472,
          2199,
          6532,
          337,
          884,
          16149,
          5215,
          293,
          360,
          300,
          294,
          257,
          17720,
          3430,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2093562416408373,
        "compression_ratio": 1.6513409961685823,
        "end": 1447.3999999999999,
        "id": 517,
        "no_speech_prob": 0.00003705273411469534,
        "seek": 142860,
        "start": 1440.6,
        "temperature": 0,
        "text": " Also, just kind of like there's a lot of stuff I think that's interesting to explore here.",
        "tokens": [
          50964,
          2743,
          11,
          445,
          733,
          295,
          411,
          456,
          311,
          257,
          688,
          295,
          1507,
          286,
          519,
          300,
          311,
          1880,
          281,
          6839,
          510,
          13,
          51304
        ]
      },
      {
        "avg_logprob": -0.2093562416408373,
        "compression_ratio": 1.6513409961685823,
        "end": 1448.9199999999998,
        "id": 518,
        "no_speech_prob": 0.00003705273411469534,
        "seek": 142860,
        "start": 1447.3999999999999,
        "temperature": 0,
        "text": " So here we go.",
        "tokens": [
          51304,
          407,
          510,
          321,
          352,
          13,
          51380
        ]
      },
      {
        "avg_logprob": -0.2093562416408373,
        "compression_ratio": 1.6513409961685823,
        "end": 1451.24,
        "id": 519,
        "no_speech_prob": 0.00003705273411469534,
        "seek": 142860,
        "start": 1449.56,
        "temperature": 0,
        "text": " The little shadow on the green screen.",
        "tokens": [
          51412,
          440,
          707,
          8576,
          322,
          264,
          3092,
          2568,
          13,
          51496
        ]
      },
      {
        "avg_logprob": -0.2093562416408373,
        "compression_ratio": 1.6513409961685823,
        "end": 1452.1999999999998,
        "id": 520,
        "no_speech_prob": 0.00003705273411469534,
        "seek": 142860,
        "start": 1451.24,
        "temperature": 0,
        "text": " I know.",
        "tokens": [
          51496,
          286,
          458,
          13,
          51544
        ]
      },
      {
        "avg_logprob": -0.2093562416408373,
        "compression_ratio": 1.6513409961685823,
        "end": 1454.12,
        "id": 521,
        "no_speech_prob": 0.00003705273411469534,
        "seek": 142860,
        "start": 1452.1999999999998,
        "temperature": 0,
        "text": " It's because one of my lights is broken.",
        "tokens": [
          51544,
          467,
          311,
          570,
          472,
          295,
          452,
          5811,
          307,
          5463,
          13,
          51640
        ]
      },
      {
        "avg_logprob": -0.2093562416408373,
        "compression_ratio": 1.6513409961685823,
        "end": 1458.28,
        "id": 522,
        "no_speech_prob": 0.00003705273411469534,
        "seek": 142860,
        "start": 1454.12,
        "temperature": 0,
        "text": " Let's see if I might be able to do something about it.",
        "tokens": [
          51640,
          961,
          311,
          536,
          498,
          286,
          1062,
          312,
          1075,
          281,
          360,
          746,
          466,
          309,
          13,
          51848
        ]
      },
      {
        "avg_logprob": -0.22105077487319263,
        "compression_ratio": 1.6322869955156951,
        "end": 1458.92,
        "id": 523,
        "no_speech_prob": 0.00014883642143104225,
        "seek": 145828,
        "start": 1458.52,
        "temperature": 0,
        "text": " I shouldn't.",
        "tokens": [
          50376,
          286,
          4659,
          380,
          13,
          50396
        ]
      },
      {
        "avg_logprob": -0.22105077487319263,
        "compression_ratio": 1.6322869955156951,
        "end": 1461.16,
        "id": 524,
        "no_speech_prob": 0.00014883642143104225,
        "seek": 145828,
        "start": 1459.72,
        "temperature": 0,
        "text": " I'm a little bit afraid to do this.",
        "tokens": [
          50436,
          286,
          478,
          257,
          707,
          857,
          4638,
          281,
          360,
          341,
          13,
          50508
        ]
      },
      {
        "avg_logprob": -0.22105077487319263,
        "compression_ratio": 1.6322869955156951,
        "end": 1461.66,
        "id": 525,
        "no_speech_prob": 0.00014883642143104225,
        "seek": 145828,
        "start": 1461.16,
        "temperature": 0,
        "text": " Whoa.",
        "tokens": [
          50508,
          7521,
          13,
          50533
        ]
      },
      {
        "avg_logprob": -0.22105077487319263,
        "compression_ratio": 1.6322869955156951,
        "end": 1464.2,
        "id": 526,
        "no_speech_prob": 0.00014883642143104225,
        "seek": 145828,
        "start": 1462.84,
        "temperature": 0,
        "text": " Hey, that shadow is gone now.",
        "tokens": [
          50592,
          1911,
          11,
          300,
          8576,
          307,
          2780,
          586,
          13,
          50660
        ]
      },
      {
        "avg_logprob": -0.22105077487319263,
        "compression_ratio": 1.6322869955156951,
        "end": 1465.24,
        "id": 527,
        "no_speech_prob": 0.00014883642143104225,
        "seek": 145828,
        "start": 1464.2,
        "temperature": 0,
        "text": " Oh, no, it's worse.",
        "tokens": [
          50660,
          876,
          11,
          572,
          11,
          309,
          311,
          5324,
          13,
          50712
        ]
      },
      {
        "avg_logprob": -0.22105077487319263,
        "compression_ratio": 1.6322869955156951,
        "end": 1466.2,
        "id": 528,
        "no_speech_prob": 0.00014883642143104225,
        "seek": 145828,
        "start": 1465.24,
        "temperature": 0,
        "text": " Okay, better not do that.",
        "tokens": [
          50712,
          1033,
          11,
          1101,
          406,
          360,
          300,
          13,
          50760
        ]
      },
      {
        "avg_logprob": -0.22105077487319263,
        "compression_ratio": 1.6322869955156951,
        "end": 1470.28,
        "id": 529,
        "no_speech_prob": 0.00014883642143104225,
        "seek": 145828,
        "start": 1468.36,
        "temperature": 0,
        "text": " Okay, we're just gonna have to live with it.",
        "tokens": [
          50868,
          1033,
          11,
          321,
          434,
          445,
          799,
          362,
          281,
          1621,
          365,
          309,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.22105077487319263,
        "compression_ratio": 1.6322869955156951,
        "end": 1472.84,
        "id": 530,
        "no_speech_prob": 0.00014883642143104225,
        "seek": 145828,
        "start": 1470.28,
        "temperature": 0,
        "text": " It's if I step over here, it gets worse.",
        "tokens": [
          50964,
          467,
          311,
          498,
          286,
          1823,
          670,
          510,
          11,
          309,
          2170,
          5324,
          13,
          51092
        ]
      },
      {
        "avg_logprob": -0.22105077487319263,
        "compression_ratio": 1.6322869955156951,
        "end": 1474.76,
        "id": 531,
        "no_speech_prob": 0.00014883642143104225,
        "seek": 145828,
        "start": 1472.84,
        "temperature": 0,
        "text": " If I stay over here, it's better.",
        "tokens": [
          51092,
          759,
          286,
          1754,
          670,
          510,
          11,
          309,
          311,
          1101,
          13,
          51188
        ]
      },
      {
        "avg_logprob": -0.22105077487319263,
        "compression_ratio": 1.6322869955156951,
        "end": 1476.84,
        "id": 532,
        "no_speech_prob": 0.00014883642143104225,
        "seek": 145828,
        "start": 1474.76,
        "temperature": 0,
        "text": " So that's just how it's going to be for now.",
        "tokens": [
          51188,
          407,
          300,
          311,
          445,
          577,
          309,
          311,
          516,
          281,
          312,
          337,
          586,
          13,
          51292
        ]
      },
      {
        "avg_logprob": -0.22105077487319263,
        "compression_ratio": 1.6322869955156951,
        "end": 1478.3799999999999,
        "id": 533,
        "no_speech_prob": 0.00014883642143104225,
        "seek": 145828,
        "start": 1477.8799999999999,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51344,
          1033,
          13,
          51369
        ]
      },
      {
        "avg_logprob": -0.22105077487319263,
        "compression_ratio": 1.6322869955156951,
        "end": 1481.8799999999999,
        "id": 534,
        "no_speech_prob": 0.00014883642143104225,
        "seek": 145828,
        "start": 1480.76,
        "temperature": 0,
        "text": " Audio is awesome.",
        "tokens": [
          51488,
          25706,
          307,
          3476,
          13,
          51544
        ]
      },
      {
        "avg_logprob": -0.22105077487319263,
        "compression_ratio": 1.6322869955156951,
        "end": 1482.3799999999999,
        "id": 535,
        "no_speech_prob": 0.00014883642143104225,
        "seek": 145828,
        "start": 1481.8799999999999,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51544,
          1057,
          558,
          13,
          51569
        ]
      },
      {
        "avg_logprob": -0.22105077487319263,
        "compression_ratio": 1.6322869955156951,
        "end": 1485.08,
        "id": 536,
        "no_speech_prob": 0.00014883642143104225,
        "seek": 145828,
        "start": 1483.72,
        "temperature": 0,
        "text": " All right, here we go, everybody.",
        "tokens": [
          51636,
          1057,
          558,
          11,
          510,
          321,
          352,
          11,
          2201,
          13,
          51704
        ]
      },
      {
        "avg_logprob": -0.25776033072636045,
        "compression_ratio": 1.7007575757575757,
        "end": 1488.1999999999998,
        "id": 537,
        "no_speech_prob": 0.00010720844147726893,
        "seek": 148508,
        "start": 1486.04,
        "temperature": 0,
        "text": " This is a tutorial.",
        "tokens": [
          50412,
          639,
          307,
          257,
          7073,
          13,
          50520
        ]
      },
      {
        "avg_logprob": -0.25776033072636045,
        "compression_ratio": 1.7007575757575757,
        "end": 1489,
        "id": 538,
        "no_speech_prob": 0.00010720844147726893,
        "seek": 148508,
        "start": 1488.1999999999998,
        "temperature": 0,
        "text": " It is 3.",
        "tokens": [
          50520,
          467,
          307,
          805,
          13,
          50560
        ]
      },
      {
        "avg_logprob": -0.25776033072636045,
        "compression_ratio": 1.7007575757575757,
        "end": 1490.76,
        "id": 539,
        "no_speech_prob": 0.00010720844147726893,
        "seek": 148508,
        "start": 1489,
        "temperature": 0,
        "text": " Oh, my God, it's 3.45 already.",
        "tokens": [
          50560,
          876,
          11,
          452,
          1265,
          11,
          309,
          311,
          805,
          13,
          8465,
          1217,
          13,
          50648
        ]
      },
      {
        "avg_logprob": -0.25776033072636045,
        "compression_ratio": 1.7007575757575757,
        "end": 1491.3999999999999,
        "id": 540,
        "no_speech_prob": 0.00010720844147726893,
        "seek": 148508,
        "start": 1490.76,
        "temperature": 0,
        "text": " That's not good.",
        "tokens": [
          50648,
          663,
          311,
          406,
          665,
          13,
          50680
        ]
      },
      {
        "avg_logprob": -0.25776033072636045,
        "compression_ratio": 1.7007575757575757,
        "end": 1491.8999999999999,
        "id": 541,
        "no_speech_prob": 0.00010720844147726893,
        "seek": 148508,
        "start": 1491.3999999999999,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50680,
          1033,
          13,
          50705
        ]
      },
      {
        "avg_logprob": -0.25776033072636045,
        "compression_ratio": 1.7007575757575757,
        "end": 1495.02,
        "id": 542,
        "no_speech_prob": 0.00010720844147726893,
        "seek": 148508,
        "start": 1494.52,
        "temperature": 0,
        "text": " 25.",
        "tokens": [
          50836,
          3552,
          13,
          50861
        ]
      },
      {
        "avg_logprob": -0.25776033072636045,
        "compression_ratio": 1.7007575757575757,
        "end": 1495.8,
        "id": 543,
        "no_speech_prob": 0.00010720844147726893,
        "seek": 148508,
        "start": 1495.02,
        "temperature": 0,
        "text": " Oh, I forgot.",
        "tokens": [
          50861,
          876,
          11,
          286,
          5298,
          13,
          50900
        ]
      },
      {
        "avg_logprob": -0.25776033072636045,
        "compression_ratio": 1.7007575757575757,
        "end": 1497.8799999999999,
        "id": 544,
        "no_speech_prob": 0.00010720844147726893,
        "seek": 148508,
        "start": 1495.8,
        "temperature": 0,
        "text": " I was going to talk about the processing fellowships.",
        "tokens": [
          50900,
          286,
          390,
          516,
          281,
          751,
          466,
          264,
          9007,
          24989,
          82,
          13,
          51004
        ]
      },
      {
        "avg_logprob": -0.25776033072636045,
        "compression_ratio": 1.7007575757575757,
        "end": 1499.6399999999999,
        "id": 545,
        "no_speech_prob": 0.00010720844147726893,
        "seek": 148508,
        "start": 1497.8799999999999,
        "temperature": 0,
        "text": " So that was my first thing that I was going to talk about.",
        "tokens": [
          51004,
          407,
          300,
          390,
          452,
          700,
          551,
          300,
          286,
          390,
          516,
          281,
          751,
          466,
          13,
          51092
        ]
      },
      {
        "avg_logprob": -0.25776033072636045,
        "compression_ratio": 1.7007575757575757,
        "end": 1500.36,
        "id": 546,
        "no_speech_prob": 0.00010720844147726893,
        "seek": 148508,
        "start": 1499.6399999999999,
        "temperature": 0,
        "text": " Let's do that now.",
        "tokens": [
          51092,
          961,
          311,
          360,
          300,
          586,
          13,
          51128
        ]
      },
      {
        "avg_logprob": -0.25776033072636045,
        "compression_ratio": 1.7007575757575757,
        "end": 1501.24,
        "id": 547,
        "no_speech_prob": 0.00010720844147726893,
        "seek": 148508,
        "start": 1500.36,
        "temperature": 0,
        "text": " So, oh, boy.",
        "tokens": [
          51128,
          407,
          11,
          1954,
          11,
          3237,
          13,
          51172
        ]
      },
      {
        "avg_logprob": -0.25776033072636045,
        "compression_ratio": 1.7007575757575757,
        "end": 1504.28,
        "id": 548,
        "no_speech_prob": 0.00010720844147726893,
        "seek": 148508,
        "start": 1502.6799999999998,
        "temperature": 0,
        "text": " Okay, I'm going to do this.",
        "tokens": [
          51244,
          1033,
          11,
          286,
          478,
          516,
          281,
          360,
          341,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.25776033072636045,
        "compression_ratio": 1.7007575757575757,
        "end": 1511.56,
        "id": 549,
        "no_speech_prob": 0.00010720844147726893,
        "seek": 148508,
        "start": 1505.8,
        "temperature": 0,
        "text": " So I just want to mention this because I think it's worth mentioning to kind of let the broadest",
        "tokens": [
          51400,
          407,
          286,
          445,
          528,
          281,
          2152,
          341,
          570,
          286,
          519,
          309,
          311,
          3163,
          18315,
          281,
          733,
          295,
          718,
          264,
          4152,
          377,
          51688
        ]
      },
      {
        "avg_logprob": -0.25776033072636045,
        "compression_ratio": 1.7007575757575757,
        "end": 1514.84,
        "id": 550,
        "no_speech_prob": 0.00010720844147726893,
        "seek": 148508,
        "start": 1511.56,
        "temperature": 0,
        "text": " audience know about this opportunity for those of you who might be interested.",
        "tokens": [
          51688,
          4034,
          458,
          466,
          341,
          2650,
          337,
          729,
          295,
          291,
          567,
          1062,
          312,
          3102,
          13,
          51852
        ]
      },
      {
        "avg_logprob": -0.18884419870900584,
        "compression_ratio": 1.6692607003891051,
        "end": 1519.6399999999999,
        "id": 551,
        "no_speech_prob": 0.000049070709792431444,
        "seek": 151508,
        "start": 1515.3999999999999,
        "temperature": 0,
        "text": " Processing Foundation, I've talked about before on live streams, is a non-for-profit",
        "tokens": [
          50380,
          31093,
          278,
          10335,
          11,
          286,
          600,
          2825,
          466,
          949,
          322,
          1621,
          15842,
          11,
          307,
          257,
          2107,
          12,
          2994,
          12,
          14583,
          50592
        ]
      },
      {
        "avg_logprob": -0.18884419870900584,
        "compression_ratio": 1.6692607003891051,
        "end": 1529.08,
        "id": 552,
        "no_speech_prob": 0.000049070709792431444,
        "seek": 151508,
        "start": 1521.32,
        "temperature": 0,
        "text": " foundation whose primary mission is to promote software literacy and make code and creative",
        "tokens": [
          50676,
          7030,
          6104,
          6194,
          4447,
          307,
          281,
          9773,
          4722,
          23166,
          293,
          652,
          3089,
          293,
          5880,
          51064
        ]
      },
      {
        "avg_logprob": -0.18884419870900584,
        "compression_ratio": 1.6692607003891051,
        "end": 1533.56,
        "id": 553,
        "no_speech_prob": 0.000049070709792431444,
        "seek": 151508,
        "start": 1529.08,
        "temperature": 0,
        "text": " work with code accessible and available to diverse communities.",
        "tokens": [
          51064,
          589,
          365,
          3089,
          9515,
          293,
          2435,
          281,
          9521,
          4456,
          13,
          51288
        ]
      },
      {
        "avg_logprob": -0.18884419870900584,
        "compression_ratio": 1.6692607003891051,
        "end": 1539.6399999999999,
        "id": 554,
        "no_speech_prob": 0.000049070709792431444,
        "seek": 151508,
        "start": 1533.56,
        "temperature": 0,
        "text": " And so in addition to education and diversity initiatives that we sponsor, which you can",
        "tokens": [
          51288,
          400,
          370,
          294,
          4500,
          281,
          3309,
          293,
          8811,
          16194,
          300,
          321,
          16198,
          11,
          597,
          291,
          393,
          51592
        ]
      },
      {
        "avg_logprob": -0.18884419870900584,
        "compression_ratio": 1.6692607003891051,
        "end": 1544.28,
        "id": 555,
        "no_speech_prob": 0.000049070709792431444,
        "seek": 151508,
        "start": 1539.6399999999999,
        "temperature": 0,
        "text": " find out on the Processing Foundation's initiative page, we maintain that what you're probably more",
        "tokens": [
          51592,
          915,
          484,
          322,
          264,
          31093,
          278,
          10335,
          311,
          11552,
          3028,
          11,
          321,
          6909,
          300,
          437,
          291,
          434,
          1391,
          544,
          51824
        ]
      },
      {
        "avg_logprob": -0.2135896515427974,
        "compression_ratio": 1.6173285198555956,
        "end": 1550.12,
        "id": 556,
        "no_speech_prob": 0.00030060444260016084,
        "seek": 154428,
        "start": 1544.28,
        "temperature": 0,
        "text": " familiar with, the platform's processing, which is a Java-based creative coding platform,",
        "tokens": [
          50364,
          4963,
          365,
          11,
          264,
          3663,
          311,
          9007,
          11,
          597,
          307,
          257,
          10745,
          12,
          6032,
          5880,
          17720,
          3663,
          11,
          50656
        ]
      },
      {
        "avg_logprob": -0.2135896515427974,
        "compression_ratio": 1.6173285198555956,
        "end": 1554.2,
        "id": 557,
        "no_speech_prob": 0.00030060444260016084,
        "seek": 154428,
        "start": 1550.12,
        "temperature": 0,
        "text": " p5.js, which is the JavaScript library that I'm using in a lot of my examples, at least",
        "tokens": [
          50656,
          280,
          20,
          13,
          25530,
          11,
          597,
          307,
          264,
          15778,
          6405,
          300,
          286,
          478,
          1228,
          294,
          257,
          688,
          295,
          452,
          5110,
          11,
          412,
          1935,
          50860
        ]
      },
      {
        "avg_logprob": -0.2135896515427974,
        "compression_ratio": 1.6173285198555956,
        "end": 1555.32,
        "id": 558,
        "no_speech_prob": 0.00030060444260016084,
        "seek": 154428,
        "start": 1554.2,
        "temperature": 0,
        "text": " the ones that I'll do today.",
        "tokens": [
          50860,
          264,
          2306,
          300,
          286,
          603,
          360,
          965,
          13,
          50916
        ]
      },
      {
        "avg_logprob": -0.2135896515427974,
        "compression_ratio": 1.6173285198555956,
        "end": 1557.32,
        "id": 559,
        "no_speech_prob": 0.00030060444260016084,
        "seek": 154428,
        "start": 1555.32,
        "temperature": 0,
        "text": " There's also a Python version of processing.",
        "tokens": [
          50916,
          821,
          311,
          611,
          257,
          15329,
          3037,
          295,
          9007,
          13,
          51016
        ]
      },
      {
        "avg_logprob": -0.2135896515427974,
        "compression_ratio": 1.6173285198555956,
        "end": 1561.08,
        "id": 560,
        "no_speech_prob": 0.00030060444260016084,
        "seek": 154428,
        "start": 1557.32,
        "temperature": 0,
        "text": " You can't see I'm like hovering with this like tiny little pointer on these links.",
        "tokens": [
          51016,
          509,
          393,
          380,
          536,
          286,
          478,
          411,
          44923,
          365,
          341,
          411,
          5870,
          707,
          23918,
          322,
          613,
          6123,
          13,
          51204
        ]
      },
      {
        "avg_logprob": -0.2135896515427974,
        "compression_ratio": 1.6173285198555956,
        "end": 1566.68,
        "id": 561,
        "no_speech_prob": 0.00030060444260016084,
        "seek": 154428,
        "start": 1561.08,
        "temperature": 0,
        "text": " So you might be familiar with all of these different projects.",
        "tokens": [
          51204,
          407,
          291,
          1062,
          312,
          4963,
          365,
          439,
          295,
          613,
          819,
          4455,
          13,
          51484
        ]
      },
      {
        "avg_logprob": -0.2135896515427974,
        "compression_ratio": 1.6173285198555956,
        "end": 1570.84,
        "id": 562,
        "no_speech_prob": 0.00030060444260016084,
        "seek": 154428,
        "start": 1567.48,
        "temperature": 0,
        "text": " What we started last year is a fellowship program.",
        "tokens": [
          51524,
          708,
          321,
          1409,
          1036,
          1064,
          307,
          257,
          24989,
          1461,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.22258494882022634,
        "compression_ratio": 1.5588235294117647,
        "end": 1574.52,
        "id": 563,
        "no_speech_prob": 0.07580222934484482,
        "seek": 157084,
        "start": 1570.84,
        "temperature": 0,
        "text": " And the fellowship program currently has its open call right now.",
        "tokens": [
          50364,
          400,
          264,
          24989,
          1461,
          4362,
          575,
          1080,
          1269,
          818,
          558,
          586,
          13,
          50548
        ]
      },
      {
        "avg_logprob": -0.22258494882022634,
        "compression_ratio": 1.5588235294117647,
        "end": 1580.1999999999998,
        "id": 564,
        "no_speech_prob": 0.07580222934484482,
        "seek": 157084,
        "start": 1574.52,
        "temperature": 0,
        "text": " So just to let you know briefly, let me scroll down here and get, these are the fellows from",
        "tokens": [
          50548,
          407,
          445,
          281,
          718,
          291,
          458,
          10515,
          11,
          718,
          385,
          11369,
          760,
          510,
          293,
          483,
          11,
          613,
          366,
          264,
          35595,
          490,
          50832
        ]
      },
      {
        "avg_logprob": -0.22258494882022634,
        "compression_ratio": 1.5588235294117647,
        "end": 1585.6399999999999,
        "id": 565,
        "no_speech_prob": 0.07580222934484482,
        "seek": 157084,
        "start": 1580.1999999999998,
        "temperature": 0,
        "text": " last year, Alison Parrish, who worked on advocacy documentation and tutorials for processing",
        "tokens": [
          50832,
          1036,
          1064,
          11,
          41001,
          47890,
          742,
          11,
          567,
          2732,
          322,
          22011,
          14333,
          293,
          17616,
          337,
          9007,
          51104
        ]
      },
      {
        "avg_logprob": -0.22258494882022634,
        "compression_ratio": 1.5588235294117647,
        "end": 1586.36,
        "id": 566,
        "no_speech_prob": 0.07580222934484482,
        "seek": 157084,
        "start": 1585.6399999999999,
        "temperature": 0,
        "text": " Python mode.",
        "tokens": [
          51104,
          15329,
          4391,
          13,
          51140
        ]
      },
      {
        "avg_logprob": -0.22258494882022634,
        "compression_ratio": 1.5588235294117647,
        "end": 1591.72,
        "id": 567,
        "no_speech_prob": 0.07580222934484482,
        "seek": 157084,
        "start": 1587,
        "temperature": 0,
        "text": " Claire Kearney-Volpe, who was a guest here on this YouTube channel to talk about her",
        "tokens": [
          51172,
          22605,
          3189,
          289,
          2397,
          12,
          53,
          401,
          494,
          11,
          567,
          390,
          257,
          8341,
          510,
          322,
          341,
          3088,
          2269,
          281,
          751,
          466,
          720,
          51408
        ]
      },
      {
        "avg_logprob": -0.22258494882022634,
        "compression_ratio": 1.5588235294117647,
        "end": 1596.1999999999998,
        "id": 568,
        "no_speech_prob": 0.07580222934484482,
        "seek": 157084,
        "start": 1591.72,
        "temperature": 0,
        "text": " work with accessibility, working with low vision and blind people in code.",
        "tokens": [
          51408,
          589,
          365,
          15002,
          11,
          1364,
          365,
          2295,
          5201,
          293,
          6865,
          561,
          294,
          3089,
          13,
          51632
        ]
      },
      {
        "avg_logprob": -0.23421553152578847,
        "compression_ratio": 1.6292834890965733,
        "end": 1601.88,
        "id": 569,
        "no_speech_prob": 0.03160376846790314,
        "seek": 159620,
        "start": 1596.92,
        "temperature": 0,
        "text": " Digital Citizens Lab created a learning platform about code using comics, worked with an after",
        "tokens": [
          50400,
          15522,
          44120,
          10137,
          2942,
          257,
          2539,
          3663,
          466,
          3089,
          1228,
          18756,
          11,
          2732,
          365,
          364,
          934,
          50648
        ]
      },
      {
        "avg_logprob": -0.23421553152578847,
        "compression_ratio": 1.6292834890965733,
        "end": 1603.96,
        "id": 570,
        "no_speech_prob": 0.03160376846790314,
        "seek": 159620,
        "start": 1601.88,
        "temperature": 0,
        "text": " school program here in the Bronx in New York City.",
        "tokens": [
          50648,
          1395,
          1461,
          510,
          294,
          264,
          41862,
          294,
          1873,
          3609,
          4392,
          13,
          50752
        ]
      },
      {
        "avg_logprob": -0.23421553152578847,
        "compression_ratio": 1.6292834890965733,
        "end": 1609.72,
        "id": 571,
        "no_speech_prob": 0.03160376846790314,
        "seek": 159620,
        "start": 1604.52,
        "temperature": 0,
        "text": " Jessica Klein and Atul Varma worked on a bunch of different features to make p5 more friendly",
        "tokens": [
          50780,
          15570,
          33327,
          293,
          1711,
          425,
          14662,
          1696,
          2732,
          322,
          257,
          3840,
          295,
          819,
          4122,
          281,
          652,
          280,
          20,
          544,
          9208,
          51040
        ]
      },
      {
        "avg_logprob": -0.23421553152578847,
        "compression_ratio": 1.6292834890965733,
        "end": 1610.44,
        "id": 572,
        "no_speech_prob": 0.03160376846790314,
        "seek": 159620,
        "start": 1609.72,
        "temperature": 0,
        "text": " and accessible.",
        "tokens": [
          51040,
          293,
          9515,
          13,
          51076
        ]
      },
      {
        "avg_logprob": -0.23421553152578847,
        "compression_ratio": 1.6292834890965733,
        "end": 1615.16,
        "id": 573,
        "no_speech_prob": 0.03160376846790314,
        "seek": 159620,
        "start": 1611.16,
        "temperature": 0,
        "text": " So these are some of the, oh, and sorry, I didn't scroll all the way down.",
        "tokens": [
          51112,
          407,
          613,
          366,
          512,
          295,
          264,
          11,
          1954,
          11,
          293,
          2597,
          11,
          286,
          994,
          380,
          11369,
          439,
          264,
          636,
          760,
          13,
          51312
        ]
      },
      {
        "avg_logprob": -0.23421553152578847,
        "compression_ratio": 1.6292834890965733,
        "end": 1618.8400000000001,
        "id": 574,
        "no_speech_prob": 0.03160376846790314,
        "seek": 159620,
        "start": 1615.16,
        "temperature": 0,
        "text": " Tiga Brain and Luisa Pereira, who worked on tutorials for p5.",
        "tokens": [
          51312,
          314,
          9900,
          29783,
          293,
          5047,
          3837,
          49349,
          4271,
          11,
          567,
          2732,
          322,
          17616,
          337,
          280,
          20,
          13,
          51496
        ]
      },
      {
        "avg_logprob": -0.23421553152578847,
        "compression_ratio": 1.6292834890965733,
        "end": 1620.6000000000001,
        "id": 575,
        "no_speech_prob": 0.03160376846790314,
        "seek": 159620,
        "start": 1618.8400000000001,
        "temperature": 0,
        "text": " Tiga also did a tutorial for this channel.",
        "tokens": [
          51496,
          314,
          9900,
          611,
          630,
          257,
          7073,
          337,
          341,
          2269,
          13,
          51584
        ]
      },
      {
        "avg_logprob": -0.23421553152578847,
        "compression_ratio": 1.6292834890965733,
        "end": 1626.04,
        "id": 576,
        "no_speech_prob": 0.03160376846790314,
        "seek": 159620,
        "start": 1621.4,
        "temperature": 0,
        "text": " And these are some previous fellowships, Vilm Tobin, who worked on the processing sound",
        "tokens": [
          51624,
          400,
          613,
          366,
          512,
          3894,
          24989,
          82,
          11,
          35653,
          76,
          26350,
          259,
          11,
          567,
          2732,
          322,
          264,
          9007,
          1626,
          51856
        ]
      },
      {
        "avg_logprob": -0.20184044444232907,
        "compression_ratio": 1.5471698113207548,
        "end": 1626.76,
        "id": 577,
        "no_speech_prob": 0.0006878144340589643,
        "seek": 162604,
        "start": 1626.12,
        "temperature": 0,
        "text": " library.",
        "tokens": [
          50368,
          6405,
          13,
          50400
        ]
      },
      {
        "avg_logprob": -0.20184044444232907,
        "compression_ratio": 1.5471698113207548,
        "end": 1631.8,
        "id": 578,
        "no_speech_prob": 0.0006878144340589643,
        "seek": 162604,
        "start": 1626.76,
        "temperature": 0,
        "text": " Lauren McCarthy, who now is a core director of the Processing Foundation, the inventor",
        "tokens": [
          50400,
          18915,
          44085,
          11,
          567,
          586,
          307,
          257,
          4965,
          5391,
          295,
          264,
          31093,
          278,
          10335,
          11,
          264,
          41593,
          50652
        ]
      },
      {
        "avg_logprob": -0.20184044444232907,
        "compression_ratio": 1.5471698113207548,
        "end": 1634.36,
        "id": 579,
        "no_speech_prob": 0.0006878144340589643,
        "seek": 162604,
        "start": 1631.8,
        "temperature": 0,
        "text": " of p5.js, what originally started as a fellowship.",
        "tokens": [
          50652,
          295,
          280,
          20,
          13,
          25530,
          11,
          437,
          7993,
          1409,
          382,
          257,
          24989,
          13,
          50780
        ]
      },
      {
        "avg_logprob": -0.20184044444232907,
        "compression_ratio": 1.5471698113207548,
        "end": 1638.44,
        "id": 580,
        "no_speech_prob": 0.0006878144340589643,
        "seek": 162604,
        "start": 1634.92,
        "temperature": 0,
        "text": " Greg Bornstein, who did a fellowship on OpenCV with processing.",
        "tokens": [
          50808,
          11490,
          29808,
          9089,
          11,
          567,
          630,
          257,
          24989,
          322,
          7238,
          34,
          53,
          365,
          9007,
          13,
          50984
        ]
      },
      {
        "avg_logprob": -0.20184044444232907,
        "compression_ratio": 1.5471698113207548,
        "end": 1643.72,
        "id": 581,
        "no_speech_prob": 0.0006878144340589643,
        "seek": 162604,
        "start": 1638.44,
        "temperature": 0,
        "text": " So these are fellowships that we've sponsored, and we now have an open call.",
        "tokens": [
          50984,
          407,
          613,
          366,
          24989,
          82,
          300,
          321,
          600,
          16621,
          11,
          293,
          321,
          586,
          362,
          364,
          1269,
          818,
          13,
          51248
        ]
      },
      {
        "avg_logprob": -0.20184044444232907,
        "compression_ratio": 1.5471698113207548,
        "end": 1650.52,
        "id": 582,
        "no_speech_prob": 0.0006878144340589643,
        "seek": 162604,
        "start": 1643.72,
        "temperature": 0,
        "text": " The idea is that for you to propose a project that you want to spend about 100 hours on",
        "tokens": [
          51248,
          440,
          1558,
          307,
          300,
          337,
          291,
          281,
          17421,
          257,
          1716,
          300,
          291,
          528,
          281,
          3496,
          466,
          2319,
          2496,
          322,
          51588
        ]
      },
      {
        "avg_logprob": -0.20184044444232907,
        "compression_ratio": 1.5471698113207548,
        "end": 1652.52,
        "id": 583,
        "no_speech_prob": 0.0006878144340589643,
        "seek": 162604,
        "start": 1650.52,
        "temperature": 0,
        "text": " between February 1st and May 31st.",
        "tokens": [
          51588,
          1296,
          8711,
          502,
          372,
          293,
          1891,
          10353,
          372,
          13,
          51688
        ]
      },
      {
        "avg_logprob": -0.16920601981026787,
        "compression_ratio": 1.5524193548387097,
        "end": 1660.52,
        "id": 584,
        "no_speech_prob": 0.00243421271443367,
        "seek": 165252,
        "start": 1653.48,
        "temperature": 0,
        "text": " And there is a $3,000 stipend, US dollars, but you don't have to be a US citizen.",
        "tokens": [
          50412,
          400,
          456,
          307,
          257,
          1848,
          18,
          11,
          1360,
          37001,
          521,
          11,
          2546,
          3808,
          11,
          457,
          291,
          500,
          380,
          362,
          281,
          312,
          257,
          2546,
          13326,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.16920601981026787,
        "compression_ratio": 1.5524193548387097,
        "end": 1664.12,
        "id": 585,
        "no_speech_prob": 0.00243421271443367,
        "seek": 165252,
        "start": 1660.52,
        "temperature": 0,
        "text": " You don't have to live in New York or the United States or anywhere to apply for the",
        "tokens": [
          50764,
          509,
          500,
          380,
          362,
          281,
          1621,
          294,
          1873,
          3609,
          420,
          264,
          2824,
          3040,
          420,
          4992,
          281,
          3079,
          337,
          264,
          50944
        ]
      },
      {
        "avg_logprob": -0.16920601981026787,
        "compression_ratio": 1.5524193548387097,
        "end": 1664.68,
        "id": 586,
        "no_speech_prob": 0.00243421271443367,
        "seek": 165252,
        "start": 1664.12,
        "temperature": 0,
        "text": " fellowship.",
        "tokens": [
          50944,
          24989,
          13,
          50972
        ]
      },
      {
        "avg_logprob": -0.16920601981026787,
        "compression_ratio": 1.5524193548387097,
        "end": 1671.6399999999999,
        "id": 587,
        "no_speech_prob": 0.00243421271443367,
        "seek": 165252,
        "start": 1665.8799999999999,
        "temperature": 0,
        "text": " And if you are selected for the fellowship, you're assigned a mentor to work and develop",
        "tokens": [
          51032,
          400,
          498,
          291,
          366,
          8209,
          337,
          264,
          24989,
          11,
          291,
          434,
          13279,
          257,
          14478,
          281,
          589,
          293,
          1499,
          51320
        ]
      },
      {
        "avg_logprob": -0.16920601981026787,
        "compression_ratio": 1.5524193548387097,
        "end": 1672.52,
        "id": 588,
        "no_speech_prob": 0.00243421271443367,
        "seek": 165252,
        "start": 1671.6399999999999,
        "temperature": 0,
        "text": " this project.",
        "tokens": [
          51320,
          341,
          1716,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.16920601981026787,
        "compression_ratio": 1.5524193548387097,
        "end": 1677.4,
        "id": 589,
        "no_speech_prob": 0.00243421271443367,
        "seek": 165252,
        "start": 1672.52,
        "temperature": 0,
        "text": " This is very similar to Google Summer of Code, which is a program that some of you might",
        "tokens": [
          51364,
          639,
          307,
          588,
          2531,
          281,
          3329,
          16161,
          295,
          15549,
          11,
          597,
          307,
          257,
          1461,
          300,
          512,
          295,
          291,
          1062,
          51608
        ]
      },
      {
        "avg_logprob": -0.16920601981026787,
        "compression_ratio": 1.5524193548387097,
        "end": 1681.48,
        "id": 590,
        "no_speech_prob": 0.00243421271443367,
        "seek": 165252,
        "start": 1680.84,
        "temperature": 0,
        "text": " familiar with.",
        "tokens": [
          51780,
          4963,
          365,
          13,
          51812
        ]
      },
      {
        "avg_logprob": -0.2542692086635492,
        "compression_ratio": 1.759433962264151,
        "end": 1685.88,
        "id": 591,
        "no_speech_prob": 0.00008887966396287084,
        "seek": 168148,
        "start": 1682.04,
        "temperature": 0,
        "text": " The key difference between the Processing Fellowship and Google Summer of Code, however,",
        "tokens": [
          50392,
          440,
          2141,
          2649,
          1296,
          264,
          31093,
          278,
          40011,
          1210,
          293,
          3329,
          16161,
          295,
          15549,
          11,
          4461,
          11,
          50584
        ]
      },
      {
        "avg_logprob": -0.2542692086635492,
        "compression_ratio": 1.759433962264151,
        "end": 1695.24,
        "id": 592,
        "no_speech_prob": 0.00008887966396287084,
        "seek": 168148,
        "start": 1685.88,
        "temperature": 0,
        "text": " is that community-based education, diversity, projects about bringing processing to different",
        "tokens": [
          50584,
          307,
          300,
          1768,
          12,
          6032,
          3309,
          11,
          8811,
          11,
          4455,
          466,
          5062,
          9007,
          281,
          819,
          51052
        ]
      },
      {
        "avg_logprob": -0.2542692086635492,
        "compression_ratio": 1.759433962264151,
        "end": 1701.8,
        "id": 593,
        "no_speech_prob": 0.00008887966396287084,
        "seek": 168148,
        "start": 1695.24,
        "temperature": 0,
        "text": " and diverse communities, or documentation, tutorials, these are valid processing fellowships,",
        "tokens": [
          51052,
          293,
          9521,
          4456,
          11,
          420,
          14333,
          11,
          17616,
          11,
          613,
          366,
          7363,
          9007,
          24989,
          82,
          11,
          51380
        ]
      },
      {
        "avg_logprob": -0.2542692086635492,
        "compression_ratio": 1.759433962264151,
        "end": 1707.96,
        "id": 594,
        "no_speech_prob": 0.00008887966396287084,
        "seek": 168148,
        "start": 1702.44,
        "temperature": 0,
        "text": " which is different than Google Summer of Code, which requires projects to be about writing",
        "tokens": [
          51412,
          597,
          307,
          819,
          813,
          3329,
          16161,
          295,
          15549,
          11,
          597,
          7029,
          4455,
          281,
          312,
          466,
          3579,
          51688
        ]
      },
      {
        "avg_logprob": -0.2542692086635492,
        "compression_ratio": 1.759433962264151,
        "end": 1708.3600000000001,
        "id": 595,
        "no_speech_prob": 0.00008887966396287084,
        "seek": 168148,
        "start": 1707.96,
        "temperature": 0,
        "text": " code.",
        "tokens": [
          51688,
          3089,
          13,
          51708
        ]
      },
      {
        "avg_logprob": -0.18295692292270282,
        "compression_ratio": 1.9531772575250836,
        "end": 1710.6799999999998,
        "id": 596,
        "no_speech_prob": 0.012052780948579311,
        "seek": 170836,
        "start": 1708.36,
        "temperature": 0,
        "text": " So you don't have to be a professional programmer.",
        "tokens": [
          50364,
          407,
          291,
          500,
          380,
          362,
          281,
          312,
          257,
          4843,
          32116,
          13,
          50480
        ]
      },
      {
        "avg_logprob": -0.18295692292270282,
        "compression_ratio": 1.9531772575250836,
        "end": 1712.12,
        "id": 597,
        "no_speech_prob": 0.012052780948579311,
        "seek": 170836,
        "start": 1710.6799999999998,
        "temperature": 0,
        "text": " You don't have to be an advanced programmer.",
        "tokens": [
          50480,
          509,
          500,
          380,
          362,
          281,
          312,
          364,
          7339,
          32116,
          13,
          50552
        ]
      },
      {
        "avg_logprob": -0.18295692292270282,
        "compression_ratio": 1.9531772575250836,
        "end": 1713.08,
        "id": 598,
        "no_speech_prob": 0.012052780948579311,
        "seek": 170836,
        "start": 1712.12,
        "temperature": 0,
        "text": " You can be a beginner.",
        "tokens": [
          50552,
          509,
          393,
          312,
          257,
          22080,
          13,
          50600
        ]
      },
      {
        "avg_logprob": -0.18295692292270282,
        "compression_ratio": 1.9531772575250836,
        "end": 1714.4399999999998,
        "id": 599,
        "no_speech_prob": 0.012052780948579311,
        "seek": 170836,
        "start": 1713.08,
        "temperature": 0,
        "text": " You can be a teacher.",
        "tokens": [
          50600,
          509,
          393,
          312,
          257,
          5027,
          13,
          50668
        ]
      },
      {
        "avg_logprob": -0.18295692292270282,
        "compression_ratio": 1.9531772575250836,
        "end": 1717.8,
        "id": 600,
        "no_speech_prob": 0.012052780948579311,
        "seek": 170836,
        "start": 1714.4399999999998,
        "temperature": 0,
        "text": " If you want to write curriculum, these are types of things that are possible for the",
        "tokens": [
          50668,
          759,
          291,
          528,
          281,
          2464,
          14302,
          11,
          613,
          366,
          3467,
          295,
          721,
          300,
          366,
          1944,
          337,
          264,
          50836
        ]
      },
      {
        "avg_logprob": -0.18295692292270282,
        "compression_ratio": 1.9531772575250836,
        "end": 1718.9199999999998,
        "id": 601,
        "no_speech_prob": 0.012052780948579311,
        "seek": 170836,
        "start": 1717.8,
        "temperature": 0,
        "text": " Processing Fellowship.",
        "tokens": [
          50836,
          31093,
          278,
          40011,
          1210,
          13,
          50892
        ]
      },
      {
        "avg_logprob": -0.18295692292270282,
        "compression_ratio": 1.9531772575250836,
        "end": 1724.1999999999998,
        "id": 602,
        "no_speech_prob": 0.012052780948579311,
        "seek": 170836,
        "start": 1718.9199999999998,
        "temperature": 0,
        "text": " So I just wanted to mention that if you are interested in the fellowship and have questions",
        "tokens": [
          50892,
          407,
          286,
          445,
          1415,
          281,
          2152,
          300,
          498,
          291,
          366,
          3102,
          294,
          264,
          24989,
          293,
          362,
          1651,
          51156
        ]
      },
      {
        "avg_logprob": -0.18295692292270282,
        "compression_ratio": 1.9531772575250836,
        "end": 1728.76,
        "id": 603,
        "no_speech_prob": 0.012052780948579311,
        "seek": 170836,
        "start": 1724.1999999999998,
        "temperature": 0,
        "text": " about it, on Twitter is twitter.com slash processing org.",
        "tokens": [
          51156,
          466,
          309,
          11,
          322,
          5794,
          307,
          21439,
          13,
          1112,
          17330,
          9007,
          14045,
          13,
          51384
        ]
      },
      {
        "avg_logprob": -0.18295692292270282,
        "compression_ratio": 1.9531772575250836,
        "end": 1730.36,
        "id": 604,
        "no_speech_prob": 0.012052780948579311,
        "seek": 170836,
        "start": 1728.76,
        "temperature": 0,
        "text": " You can tweet at processing org.",
        "tokens": [
          51384,
          509,
          393,
          15258,
          412,
          9007,
          14045,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18295692292270282,
        "compression_ratio": 1.9531772575250836,
        "end": 1733.8,
        "id": 605,
        "no_speech_prob": 0.012052780948579311,
        "seek": 170836,
        "start": 1730.36,
        "temperature": 0,
        "text": " You can ask questions on the processing forum, which is forum.processing.org.",
        "tokens": [
          51464,
          509,
          393,
          1029,
          1651,
          322,
          264,
          9007,
          17542,
          11,
          597,
          307,
          17542,
          13,
          41075,
          278,
          13,
          4646,
          13,
          51636
        ]
      },
      {
        "avg_logprob": -0.18295692292270282,
        "compression_ratio": 1.9531772575250836,
        "end": 1736.28,
        "id": 606,
        "no_speech_prob": 0.012052780948579311,
        "seek": 170836,
        "start": 1733.8,
        "temperature": 0,
        "text": " And certainly, you can get in touch with me in the comments of this video.",
        "tokens": [
          51636,
          400,
          3297,
          11,
          291,
          393,
          483,
          294,
          2557,
          365,
          385,
          294,
          264,
          3053,
          295,
          341,
          960,
          13,
          51760
        ]
      },
      {
        "avg_logprob": -0.22641995895740596,
        "compression_ratio": 1.4977578475336324,
        "end": 1739.16,
        "id": 607,
        "no_speech_prob": 0.0018386451993137598,
        "seek": 173628,
        "start": 1736.28,
        "temperature": 0,
        "text": " I'm having trouble keeping up with YouTube comments, but I do read them.",
        "tokens": [
          50364,
          286,
          478,
          1419,
          5253,
          5145,
          493,
          365,
          3088,
          3053,
          11,
          457,
          286,
          360,
          1401,
          552,
          13,
          50508
        ]
      },
      {
        "avg_logprob": -0.22641995895740596,
        "compression_ratio": 1.4977578475336324,
        "end": 1747.6399999999999,
        "id": 608,
        "no_speech_prob": 0.0018386451993137598,
        "seek": 173628,
        "start": 1740.12,
        "temperature": 0,
        "text": " And so that's what I just wanted to make an announcement about and plug a little bit",
        "tokens": [
          50556,
          400,
          370,
          300,
          311,
          437,
          286,
          445,
          1415,
          281,
          652,
          364,
          12847,
          466,
          293,
          5452,
          257,
          707,
          857,
          50932
        ]
      },
      {
        "avg_logprob": -0.22641995895740596,
        "compression_ratio": 1.4977578475336324,
        "end": 1749.16,
        "id": 609,
        "no_speech_prob": 0.0018386451993137598,
        "seek": 173628,
        "start": 1747.6399999999999,
        "temperature": 0,
        "text": " about this fellowship program.",
        "tokens": [
          50932,
          466,
          341,
          24989,
          1461,
          13,
          51008
        ]
      },
      {
        "avg_logprob": -0.22641995895740596,
        "compression_ratio": 1.4977578475336324,
        "end": 1758.28,
        "id": 610,
        "no_speech_prob": 0.0018386451993137598,
        "seek": 173628,
        "start": 1750.12,
        "temperature": 0,
        "text": " OK, so the other thing I'll mention very briefly also, if I go to twitter.com processing org.",
        "tokens": [
          51056,
          2264,
          11,
          370,
          264,
          661,
          551,
          286,
          603,
          2152,
          588,
          10515,
          611,
          11,
          498,
          286,
          352,
          281,
          21439,
          13,
          1112,
          9007,
          14045,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.22641995895740596,
        "compression_ratio": 1.4977578475336324,
        "end": 1763.3999999999999,
        "id": 611,
        "no_speech_prob": 0.0018386451993137598,
        "seek": 173628,
        "start": 1760.12,
        "temperature": 0,
        "text": " So this is the link for the Processing Fellowships.",
        "tokens": [
          51556,
          407,
          341,
          307,
          264,
          2113,
          337,
          264,
          31093,
          278,
          40011,
          7640,
          13,
          51720
        ]
      },
      {
        "avg_logprob": -0.19778608071683634,
        "compression_ratio": 1.610091743119266,
        "end": 1769.4,
        "id": 612,
        "no_speech_prob": 0.0029348640237003565,
        "seek": 176340,
        "start": 1764.3600000000001,
        "temperature": 0,
        "text": " And then also, if we do here, yes.",
        "tokens": [
          50412,
          400,
          550,
          611,
          11,
          498,
          321,
          360,
          510,
          11,
          2086,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19778608071683634,
        "compression_ratio": 1.610091743119266,
        "end": 1773.16,
        "id": 613,
        "no_speech_prob": 0.0029348640237003565,
        "seek": 176340,
        "start": 1769.96,
        "temperature": 0,
        "text": " So we have a community survey.",
        "tokens": [
          50692,
          407,
          321,
          362,
          257,
          1768,
          8984,
          13,
          50852
        ]
      },
      {
        "avg_logprob": -0.19778608071683634,
        "compression_ratio": 1.610091743119266,
        "end": 1778.3600000000001,
        "id": 614,
        "no_speech_prob": 0.0029348640237003565,
        "seek": 176340,
        "start": 1773.16,
        "temperature": 0,
        "text": " So I would also encourage you, if you are a user or a teacher or if you're a student,",
        "tokens": [
          50852,
          407,
          286,
          576,
          611,
          5373,
          291,
          11,
          498,
          291,
          366,
          257,
          4195,
          420,
          257,
          5027,
          420,
          498,
          291,
          434,
          257,
          3107,
          11,
          51112
        ]
      },
      {
        "avg_logprob": -0.19778608071683634,
        "compression_ratio": 1.610091743119266,
        "end": 1784.2800000000002,
        "id": 615,
        "no_speech_prob": 0.0029348640237003565,
        "seek": 176340,
        "start": 1778.3600000000001,
        "temperature": 0,
        "text": " a teacher, a professional, a hobbyist, if you use processing p5.js, processing.py, please",
        "tokens": [
          51112,
          257,
          5027,
          11,
          257,
          4843,
          11,
          257,
          18240,
          468,
          11,
          498,
          291,
          764,
          9007,
          280,
          20,
          13,
          25530,
          11,
          9007,
          13,
          8200,
          11,
          1767,
          51408
        ]
      },
      {
        "avg_logprob": -0.19778608071683634,
        "compression_ratio": 1.610091743119266,
        "end": 1788.2,
        "id": 616,
        "no_speech_prob": 0.0029348640237003565,
        "seek": 176340,
        "start": 1784.2800000000002,
        "temperature": 0,
        "text": " fill out this survey to help us understand how people use the software and make priorities",
        "tokens": [
          51408,
          2836,
          484,
          341,
          8984,
          281,
          854,
          505,
          1223,
          577,
          561,
          764,
          264,
          4722,
          293,
          652,
          15503,
          51604
        ]
      },
      {
        "avg_logprob": -0.19778608071683634,
        "compression_ratio": 1.610091743119266,
        "end": 1789.64,
        "id": 617,
        "no_speech_prob": 0.0029348640237003565,
        "seek": 176340,
        "start": 1788.2,
        "temperature": 0,
        "text": " for the next year.",
        "tokens": [
          51604,
          337,
          264,
          958,
          1064,
          13,
          51676
        ]
      },
      {
        "avg_logprob": -0.5362614949544271,
        "compression_ratio": 1.4529411764705882,
        "end": 1790.44,
        "id": 618,
        "no_speech_prob": 0.001477921148762107,
        "seek": 178964,
        "start": 1789.88,
        "temperature": 0,
        "text": " Good question.",
        "tokens": [
          50376,
          2205,
          1168,
          13,
          50404
        ]
      },
      {
        "avg_logprob": -0.5362614949544271,
        "compression_ratio": 1.4529411764705882,
        "end": 1792.44,
        "id": 619,
        "no_speech_prob": 0.001477921148762107,
        "seek": 178964,
        "start": 1790.44,
        "temperature": 0,
        "text": " Is I came here lately.",
        "tokens": [
          50404,
          1119,
          286,
          1361,
          510,
          12881,
          13,
          50504
        ]
      },
      {
        "avg_logprob": -0.5362614949544271,
        "compression_ratio": 1.4529411764705882,
        "end": 1794.76,
        "id": 620,
        "no_speech_prob": 0.001477921148762107,
        "seek": 178964,
        "start": 1792.44,
        "temperature": 0,
        "text": " Is it available outside the USA?",
        "tokens": [
          50504,
          1119,
          309,
          2435,
          2380,
          264,
          10827,
          30,
          50620
        ]
      },
      {
        "avg_logprob": -0.5362614949544271,
        "compression_ratio": 1.4529411764705882,
        "end": 1802.3600000000001,
        "id": 621,
        "no_speech_prob": 0.001477921148762107,
        "seek": 178964,
        "start": 1797.0800000000002,
        "temperature": 0,
        "text": " So yes, the you can apply for the fellowship outside of the United States.",
        "tokens": [
          50736,
          407,
          2086,
          11,
          264,
          291,
          393,
          3079,
          337,
          264,
          24989,
          2380,
          295,
          264,
          2824,
          3040,
          13,
          51000
        ]
      },
      {
        "avg_logprob": -0.5362614949544271,
        "compression_ratio": 1.4529411764705882,
        "end": 1802.92,
        "id": 622,
        "no_speech_prob": 0.001477921148762107,
        "seek": 178964,
        "start": 1802.3600000000001,
        "temperature": 0,
        "text": " Absolutely.",
        "tokens": [
          51000,
          7021,
          13,
          51028
        ]
      },
      {
        "avg_logprob": -0.5362614949544271,
        "compression_ratio": 1.4529411764705882,
        "end": 1808.92,
        "id": 623,
        "no_speech_prob": 0.001477921148762107,
        "seek": 178964,
        "start": 1803.96,
        "temperature": 0,
        "text": " There is, you know, there are no restrictions on who can apply.",
        "tokens": [
          51080,
          821,
          307,
          11,
          291,
          458,
          11,
          456,
          366,
          572,
          14191,
          322,
          567,
          393,
          3079,
          13,
          51328
        ]
      },
      {
        "avg_logprob": -0.5362614949544271,
        "compression_ratio": 1.4529411764705882,
        "end": 1810.3600000000001,
        "id": 624,
        "no_speech_prob": 0.001477921148762107,
        "seek": 178964,
        "start": 1808.92,
        "temperature": 0,
        "text": " It is open to anyone.",
        "tokens": [
          51328,
          467,
          307,
          1269,
          281,
          2878,
          13,
          51400
        ]
      },
      {
        "avg_logprob": -0.5362614949544271,
        "compression_ratio": 1.4529411764705882,
        "end": 1812.0400000000002,
        "id": 625,
        "no_speech_prob": 0.001477921148762107,
        "seek": 178964,
        "start": 1811.5600000000002,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51460,
          2264,
          13,
          51484
        ]
      },
      {
        "avg_logprob": -0.27317306643626726,
        "compression_ratio": 1.6297872340425532,
        "end": 1813,
        "id": 626,
        "no_speech_prob": 0.015421215444803238,
        "seek": 181204,
        "start": 1812.76,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50400,
          2264,
          13,
          50412
        ]
      },
      {
        "avg_logprob": -0.27317306643626726,
        "compression_ratio": 1.6297872340425532,
        "end": 1820.28,
        "id": 627,
        "no_speech_prob": 0.015421215444803238,
        "seek": 181204,
        "start": 1816.84,
        "temperature": 0,
        "text": " OK, so that is I wanted to mention and talk about.",
        "tokens": [
          50604,
          2264,
          11,
          370,
          300,
          307,
          286,
          1415,
          281,
          2152,
          293,
          751,
          466,
          13,
          50776
        ]
      },
      {
        "avg_logprob": -0.27317306643626726,
        "compression_ratio": 1.6297872340425532,
        "end": 1821.72,
        "id": 628,
        "no_speech_prob": 0.015421215444803238,
        "seek": 181204,
        "start": 1820.28,
        "temperature": 0,
        "text": " Can you kind of link the survey?",
        "tokens": [
          50776,
          1664,
          291,
          733,
          295,
          2113,
          264,
          8984,
          30,
          50848
        ]
      },
      {
        "avg_logprob": -0.27317306643626726,
        "compression_ratio": 1.6297872340425532,
        "end": 1822.92,
        "id": 629,
        "no_speech_prob": 0.015421215444803238,
        "seek": 181204,
        "start": 1821.72,
        "temperature": 0,
        "text": " So I'll link this.",
        "tokens": [
          50848,
          407,
          286,
          603,
          2113,
          341,
          13,
          50908
        ]
      },
      {
        "avg_logprob": -0.27317306643626726,
        "compression_ratio": 1.6297872340425532,
        "end": 1824.84,
        "id": 630,
        "no_speech_prob": 0.015421215444803238,
        "seek": 181204,
        "start": 1822.92,
        "temperature": 0,
        "text": " If someone in the chat is a moderator.",
        "tokens": [
          50908,
          759,
          1580,
          294,
          264,
          5081,
          307,
          257,
          37778,
          13,
          51004
        ]
      },
      {
        "avg_logprob": -0.27317306643626726,
        "compression_ratio": 1.6297872340425532,
        "end": 1825.48,
        "id": 631,
        "no_speech_prob": 0.015421215444803238,
        "seek": 181204,
        "start": 1824.84,
        "temperature": 0,
        "text": " Oh, thank you.",
        "tokens": [
          51004,
          876,
          11,
          1309,
          291,
          13,
          51036
        ]
      },
      {
        "avg_logprob": -0.27317306643626726,
        "compression_ratio": 1.6297872340425532,
        "end": 1827.56,
        "id": 632,
        "no_speech_prob": 0.015421215444803238,
        "seek": 181204,
        "start": 1825.48,
        "temperature": 0,
        "text": " I think Alvaro in the chat link the survey.",
        "tokens": [
          51036,
          286,
          519,
          967,
          8517,
          78,
          294,
          264,
          5081,
          2113,
          264,
          8984,
          13,
          51140
        ]
      },
      {
        "avg_logprob": -0.27317306643626726,
        "compression_ratio": 1.6297872340425532,
        "end": 1831.32,
        "id": 633,
        "no_speech_prob": 0.015421215444803238,
        "seek": 181204,
        "start": 1827.56,
        "temperature": 0,
        "text": " I will try and Matiu who helps me with this, of course, will try to remember to put a link",
        "tokens": [
          51140,
          286,
          486,
          853,
          293,
          6789,
          5951,
          567,
          3665,
          385,
          365,
          341,
          11,
          295,
          1164,
          11,
          486,
          853,
          281,
          1604,
          281,
          829,
          257,
          2113,
          51328
        ]
      },
      {
        "avg_logprob": -0.27317306643626726,
        "compression_ratio": 1.6297872340425532,
        "end": 1833.1599999999999,
        "id": 634,
        "no_speech_prob": 0.015421215444803238,
        "seek": 181204,
        "start": 1831.32,
        "temperature": 0,
        "text": " to the survey also in this video's description.",
        "tokens": [
          51328,
          281,
          264,
          8984,
          611,
          294,
          341,
          960,
          311,
          3855,
          13,
          51420
        ]
      },
      {
        "avg_logprob": -0.27317306643626726,
        "compression_ratio": 1.6297872340425532,
        "end": 1836.04,
        "id": 635,
        "no_speech_prob": 0.015421215444803238,
        "seek": 181204,
        "start": 1835.8,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51552,
          2264,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.27317306643626726,
        "compression_ratio": 1.6297872340425532,
        "end": 1841.48,
        "id": 636,
        "no_speech_prob": 0.015421215444803238,
        "seek": 181204,
        "start": 1837.32,
        "temperature": 0,
        "text": " Thank you, everyone, for listening.",
        "tokens": [
          51628,
          1044,
          291,
          11,
          1518,
          11,
          337,
          4764,
          13,
          51836
        ]
      },
      {
        "avg_logprob": -0.2113976170939784,
        "compression_ratio": 1.80859375,
        "end": 1844.2,
        "id": 637,
        "no_speech_prob": 0.0008967086323536932,
        "seek": 184148,
        "start": 1841.48,
        "temperature": 0,
        "text": " And being supportive of the Processing Foundation.",
        "tokens": [
          50364,
          400,
          885,
          14435,
          295,
          264,
          31093,
          278,
          10335,
          13,
          50500
        ]
      },
      {
        "avg_logprob": -0.2113976170939784,
        "compression_ratio": 1.80859375,
        "end": 1846.1200000000001,
        "id": 638,
        "no_speech_prob": 0.0008967086323536932,
        "seek": 184148,
        "start": 1844.76,
        "temperature": 0,
        "text": " By the way, I have this weird idea.",
        "tokens": [
          50528,
          3146,
          264,
          636,
          11,
          286,
          362,
          341,
          3657,
          1558,
          13,
          50596
        ]
      },
      {
        "avg_logprob": -0.2113976170939784,
        "compression_ratio": 1.80859375,
        "end": 1848.2,
        "id": 639,
        "no_speech_prob": 0.0008967086323536932,
        "seek": 184148,
        "start": 1846.68,
        "temperature": 0,
        "text": " I shouldn't mention it.",
        "tokens": [
          50624,
          286,
          4659,
          380,
          2152,
          309,
          13,
          50700
        ]
      },
      {
        "avg_logprob": -0.2113976170939784,
        "compression_ratio": 1.80859375,
        "end": 1852.6,
        "id": 640,
        "no_speech_prob": 0.0008967086323536932,
        "seek": 184148,
        "start": 1848.2,
        "temperature": 0,
        "text": " But the last week of not the last week of December, but the last week before the winter",
        "tokens": [
          50700,
          583,
          264,
          1036,
          1243,
          295,
          406,
          264,
          1036,
          1243,
          295,
          7687,
          11,
          457,
          264,
          1036,
          1243,
          949,
          264,
          6355,
          50920
        ]
      },
      {
        "avg_logprob": -0.2113976170939784,
        "compression_ratio": 1.80859375,
        "end": 1859.32,
        "id": 641,
        "no_speech_prob": 0.0008967086323536932,
        "seek": 184148,
        "start": 1852.6,
        "temperature": 0,
        "text": " holiday, I think, which ends December 23rd, I have a fairly free week that week, not the",
        "tokens": [
          50920,
          9960,
          11,
          286,
          519,
          11,
          597,
          5314,
          7687,
          6673,
          7800,
          11,
          286,
          362,
          257,
          6457,
          1737,
          1243,
          300,
          1243,
          11,
          406,
          264,
          51256
        ]
      },
      {
        "avg_logprob": -0.2113976170939784,
        "compression_ratio": 1.80859375,
        "end": 1861.16,
        "id": 642,
        "no_speech_prob": 0.0008967086323536932,
        "seek": 184148,
        "start": 1859.32,
        "temperature": 0,
        "text": " beginning of the week, but towards the end of the week.",
        "tokens": [
          51256,
          2863,
          295,
          264,
          1243,
          11,
          457,
          3030,
          264,
          917,
          295,
          264,
          1243,
          13,
          51348
        ]
      },
      {
        "avg_logprob": -0.2113976170939784,
        "compression_ratio": 1.80859375,
        "end": 1868.68,
        "id": 643,
        "no_speech_prob": 0.0008967086323536932,
        "seek": 184148,
        "start": 1861.16,
        "temperature": 0,
        "text": " And I had this idea that that I see that people are getting banned in the chat, but I should",
        "tokens": [
          51348,
          400,
          286,
          632,
          341,
          1558,
          300,
          300,
          286,
          536,
          300,
          561,
          366,
          1242,
          19564,
          294,
          264,
          5081,
          11,
          457,
          286,
          820,
          51724
        ]
      },
      {
        "avg_logprob": -0.2113976170939784,
        "compression_ratio": 1.80859375,
        "end": 1869.96,
        "id": 644,
        "no_speech_prob": 0.0008967086323536932,
        "seek": 184148,
        "start": 1868.68,
        "temperature": 0,
        "text": " just like let that happen.",
        "tokens": [
          51724,
          445,
          411,
          718,
          300,
          1051,
          13,
          51788
        ]
      },
      {
        "avg_logprob": -0.23693757738385882,
        "compression_ratio": 1.70446735395189,
        "end": 1873.4,
        "id": 645,
        "no_speech_prob": 0.014280887320637703,
        "seek": 186996,
        "start": 1869.96,
        "temperature": 0,
        "text": " I'm sure it distracts me a little bit too much.",
        "tokens": [
          50364,
          286,
          478,
          988,
          309,
          9945,
          82,
          385,
          257,
          707,
          857,
          886,
          709,
          13,
          50536
        ]
      },
      {
        "avg_logprob": -0.23693757738385882,
        "compression_ratio": 1.70446735395189,
        "end": 1877.88,
        "id": 646,
        "no_speech_prob": 0.014280887320637703,
        "seek": 186996,
        "start": 1874.76,
        "temperature": 0,
        "text": " I had this idea of kind of doing an all day live stream.",
        "tokens": [
          50604,
          286,
          632,
          341,
          1558,
          295,
          733,
          295,
          884,
          364,
          439,
          786,
          1621,
          4309,
          13,
          50760
        ]
      },
      {
        "avg_logprob": -0.23693757738385882,
        "compression_ratio": 1.70446735395189,
        "end": 1882.04,
        "id": 647,
        "no_speech_prob": 0.014280887320637703,
        "seek": 186996,
        "start": 1877.88,
        "temperature": 0,
        "text": " And by all day, I don't mean I mean something like starting at 10 or 11 and finishing at",
        "tokens": [
          50760,
          400,
          538,
          439,
          786,
          11,
          286,
          500,
          380,
          914,
          286,
          914,
          746,
          411,
          2891,
          412,
          1266,
          420,
          2975,
          293,
          12693,
          412,
          50968
        ]
      },
      {
        "avg_logprob": -0.23693757738385882,
        "compression_ratio": 1.70446735395189,
        "end": 1884.52,
        "id": 648,
        "no_speech_prob": 0.014280887320637703,
        "seek": 186996,
        "start": 1882.04,
        "temperature": 0,
        "text": " four or five, maybe with a little lunch break in the middle.",
        "tokens": [
          50968,
          1451,
          420,
          1732,
          11,
          1310,
          365,
          257,
          707,
          6349,
          1821,
          294,
          264,
          2808,
          13,
          51092
        ]
      },
      {
        "avg_logprob": -0.23693757738385882,
        "compression_ratio": 1.70446735395189,
        "end": 1886.28,
        "id": 649,
        "no_speech_prob": 0.014280887320637703,
        "seek": 186996,
        "start": 1884.52,
        "temperature": 0,
        "text": " Maybe a guest would come in and do something.",
        "tokens": [
          51092,
          2704,
          257,
          8341,
          576,
          808,
          294,
          293,
          360,
          746,
          13,
          51180
        ]
      },
      {
        "avg_logprob": -0.23693757738385882,
        "compression_ratio": 1.70446735395189,
        "end": 1887.64,
        "id": 650,
        "no_speech_prob": 0.014280887320637703,
        "seek": 186996,
        "start": 1886.28,
        "temperature": 0,
        "text": " I would go have some lunch.",
        "tokens": [
          51180,
          286,
          576,
          352,
          362,
          512,
          6349,
          13,
          51248
        ]
      },
      {
        "avg_logprob": -0.23693757738385882,
        "compression_ratio": 1.70446735395189,
        "end": 1889.56,
        "id": 651,
        "no_speech_prob": 0.014280887320637703,
        "seek": 186996,
        "start": 1887.64,
        "temperature": 0,
        "text": " I almost think of it as like a telethon.",
        "tokens": [
          51248,
          286,
          1920,
          519,
          295,
          309,
          382,
          411,
          257,
          15284,
          3293,
          266,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.23693757738385882,
        "compression_ratio": 1.70446735395189,
        "end": 1893.24,
        "id": 652,
        "no_speech_prob": 0.014280887320637703,
        "seek": 186996,
        "start": 1891,
        "temperature": 0,
        "text": " Just like catch up on a lot of tutorials, have some fun.",
        "tokens": [
          51416,
          1449,
          411,
          3745,
          493,
          322,
          257,
          688,
          295,
          17616,
          11,
          362,
          512,
          1019,
          13,
          51528
        ]
      },
      {
        "avg_logprob": -0.23693757738385882,
        "compression_ratio": 1.70446735395189,
        "end": 1898.68,
        "id": 653,
        "no_speech_prob": 0.014280887320637703,
        "seek": 186996,
        "start": 1893.24,
        "temperature": 0,
        "text": " It's sort of like end of the year celebration of creative code stuff.",
        "tokens": [
          51528,
          467,
          311,
          1333,
          295,
          411,
          917,
          295,
          264,
          1064,
          14184,
          295,
          5880,
          3089,
          1507,
          13,
          51800
        ]
      },
      {
        "avg_logprob": -0.21406430668301052,
        "compression_ratio": 1.710801393728223,
        "end": 1902.52,
        "id": 654,
        "no_speech_prob": 0.03258833661675453,
        "seek": 189868,
        "start": 1899.16,
        "temperature": 0,
        "text": " And I thought it could be kind of like a telethon to raise money for the Processing Foundation,",
        "tokens": [
          50388,
          400,
          286,
          1194,
          309,
          727,
          312,
          733,
          295,
          411,
          257,
          15284,
          3293,
          266,
          281,
          5300,
          1460,
          337,
          264,
          31093,
          278,
          10335,
          11,
          50556
        ]
      },
      {
        "avg_logprob": -0.21406430668301052,
        "compression_ratio": 1.710801393728223,
        "end": 1905.3200000000002,
        "id": 655,
        "no_speech_prob": 0.03258833661675453,
        "seek": 189868,
        "start": 1902.52,
        "temperature": 0,
        "text": " or maybe there's another cause you should consider raising money for.",
        "tokens": [
          50556,
          420,
          1310,
          456,
          311,
          1071,
          3082,
          291,
          820,
          1949,
          11225,
          1460,
          337,
          13,
          50696
        ]
      },
      {
        "avg_logprob": -0.21406430668301052,
        "compression_ratio": 1.710801393728223,
        "end": 1908.2,
        "id": 656,
        "no_speech_prob": 0.03258833661675453,
        "seek": 189868,
        "start": 1905.88,
        "temperature": 0,
        "text": " So anyway, I'm thinking about that.",
        "tokens": [
          50724,
          407,
          4033,
          11,
          286,
          478,
          1953,
          466,
          300,
          13,
          50840
        ]
      },
      {
        "avg_logprob": -0.21406430668301052,
        "compression_ratio": 1.710801393728223,
        "end": 1909.88,
        "id": 657,
        "no_speech_prob": 0.03258833661675453,
        "seek": 189868,
        "start": 1908.2,
        "temperature": 0,
        "text": " You could encourage or discourage me.",
        "tokens": [
          50840,
          509,
          727,
          5373,
          420,
          21497,
          609,
          385,
          13,
          50924
        ]
      },
      {
        "avg_logprob": -0.21406430668301052,
        "compression_ratio": 1.710801393728223,
        "end": 1910.92,
        "id": 658,
        "no_speech_prob": 0.03258833661675453,
        "seek": 189868,
        "start": 1909.88,
        "temperature": 0,
        "text": " I'm sure you all would.",
        "tokens": [
          50924,
          286,
          478,
          988,
          291,
          439,
          576,
          13,
          50976
        ]
      },
      {
        "avg_logprob": -0.21406430668301052,
        "compression_ratio": 1.710801393728223,
        "end": 1914.1200000000001,
        "id": 659,
        "no_speech_prob": 0.03258833661675453,
        "seek": 189868,
        "start": 1910.92,
        "temperature": 0,
        "text": " But if that happens, it would be on the 22nd or the 23rd.",
        "tokens": [
          50976,
          583,
          498,
          300,
          2314,
          11,
          309,
          576,
          312,
          322,
          264,
          5853,
          273,
          420,
          264,
          6673,
          7800,
          13,
          51136
        ]
      },
      {
        "avg_logprob": -0.21406430668301052,
        "compression_ratio": 1.710801393728223,
        "end": 1915.24,
        "id": 660,
        "no_speech_prob": 0.03258833661675453,
        "seek": 189868,
        "start": 1914.1200000000001,
        "temperature": 0,
        "text": " So keep that in mind.",
        "tokens": [
          51136,
          407,
          1066,
          300,
          294,
          1575,
          13,
          51192
        ]
      },
      {
        "avg_logprob": -0.21406430668301052,
        "compression_ratio": 1.710801393728223,
        "end": 1921.8,
        "id": 661,
        "no_speech_prob": 0.03258833661675453,
        "seek": 189868,
        "start": 1916.76,
        "temperature": 0,
        "text": " I would love to if you're in the Slack channel, if you're a patron in the Slack channel, you",
        "tokens": [
          51268,
          286,
          576,
          959,
          281,
          498,
          291,
          434,
          294,
          264,
          37211,
          2269,
          11,
          498,
          291,
          434,
          257,
          21843,
          294,
          264,
          37211,
          2269,
          11,
          291,
          51520
        ]
      },
      {
        "avg_logprob": -0.21406430668301052,
        "compression_ratio": 1.710801393728223,
        "end": 1923.88,
        "id": 662,
        "no_speech_prob": 0.03258833661675453,
        "seek": 189868,
        "start": 1921.8,
        "temperature": 0,
        "text": " can tell me your ideas about this there.",
        "tokens": [
          51520,
          393,
          980,
          385,
          428,
          3487,
          466,
          341,
          456,
          13,
          51624
        ]
      },
      {
        "avg_logprob": -0.21406430668301052,
        "compression_ratio": 1.710801393728223,
        "end": 1925.02,
        "id": 663,
        "no_speech_prob": 0.03258833661675453,
        "seek": 189868,
        "start": 1924.52,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51656,
          2264,
          13,
          51681
        ]
      },
      {
        "avg_logprob": -0.21406430668301052,
        "compression_ratio": 1.710801393728223,
        "end": 1927.0800000000002,
        "id": 664,
        "no_speech_prob": 0.03258833661675453,
        "seek": 189868,
        "start": 1926.44,
        "temperature": 0,
        "text": " OK, cool.",
        "tokens": [
          51752,
          2264,
          11,
          1627,
          13,
          51784
        ]
      },
      {
        "avg_logprob": -0.22016384887695312,
        "compression_ratio": 1.5798611111111112,
        "end": 1929.1599999999999,
        "id": 665,
        "no_speech_prob": 0.00007368563092313707,
        "seek": 192708,
        "start": 1928.04,
        "temperature": 0,
        "text": " What's Nerdfighters?",
        "tokens": [
          50412,
          708,
          311,
          38367,
          14919,
          433,
          30,
          50468
        ]
      },
      {
        "avg_logprob": -0.22016384887695312,
        "compression_ratio": 1.5798611111111112,
        "end": 1930.04,
        "id": 666,
        "no_speech_prob": 0.00007368563092313707,
        "seek": 192708,
        "start": 1929.1599999999999,
        "temperature": 0,
        "text": " I don't know what that is.",
        "tokens": [
          50468,
          286,
          500,
          380,
          458,
          437,
          300,
          307,
          13,
          50512
        ]
      },
      {
        "avg_logprob": -0.22016384887695312,
        "compression_ratio": 1.5798611111111112,
        "end": 1936.6799999999998,
        "id": 667,
        "no_speech_prob": 0.00007368563092313707,
        "seek": 192708,
        "start": 1930.04,
        "temperature": 0,
        "text": " But I'm definitely looking to do more collaborations and things with other folks on YouTube, especially",
        "tokens": [
          50512,
          583,
          286,
          478,
          2138,
          1237,
          281,
          360,
          544,
          36908,
          293,
          721,
          365,
          661,
          4024,
          322,
          3088,
          11,
          2318,
          50844
        ]
      },
      {
        "avg_logprob": -0.22016384887695312,
        "compression_ratio": 1.5798611111111112,
        "end": 1941.48,
        "id": 668,
        "no_speech_prob": 0.00007368563092313707,
        "seek": 192708,
        "start": 1936.6799999999998,
        "temperature": 0,
        "text": " if they don't look like me, or have different ideas and come from a different background.",
        "tokens": [
          50844,
          498,
          436,
          500,
          380,
          574,
          411,
          385,
          11,
          420,
          362,
          819,
          3487,
          293,
          808,
          490,
          257,
          819,
          3678,
          13,
          51084
        ]
      },
      {
        "avg_logprob": -0.22016384887695312,
        "compression_ratio": 1.5798611111111112,
        "end": 1946.84,
        "id": 669,
        "no_speech_prob": 0.00007368563092313707,
        "seek": 192708,
        "start": 1942.6799999999998,
        "temperature": 0,
        "text": " OK, so let's get back to that AFIN111 thing.",
        "tokens": [
          51144,
          2264,
          11,
          370,
          718,
          311,
          483,
          646,
          281,
          300,
          20389,
          1464,
          5348,
          16,
          551,
          13,
          51352
        ]
      },
      {
        "avg_logprob": -0.22016384887695312,
        "compression_ratio": 1.5798611111111112,
        "end": 1949,
        "id": 670,
        "no_speech_prob": 0.00007368563092313707,
        "seek": 192708,
        "start": 1946.84,
        "temperature": 0,
        "text": " I've got to do something programming-wise today.",
        "tokens": [
          51352,
          286,
          600,
          658,
          281,
          360,
          746,
          9410,
          12,
          3711,
          965,
          13,
          51460
        ]
      },
      {
        "avg_logprob": -0.22016384887695312,
        "compression_ratio": 1.5798611111111112,
        "end": 1952.1999999999998,
        "id": 671,
        "no_speech_prob": 0.00007368563092313707,
        "seek": 192708,
        "start": 1949,
        "temperature": 0,
        "text": " I want to just apologize that things have been a little light this month.",
        "tokens": [
          51460,
          286,
          528,
          281,
          445,
          12328,
          300,
          721,
          362,
          668,
          257,
          707,
          1442,
          341,
          1618,
          13,
          51620
        ]
      },
      {
        "avg_logprob": -0.22016384887695312,
        "compression_ratio": 1.5798611111111112,
        "end": 1952.9199999999998,
        "id": 672,
        "no_speech_prob": 0.00007368563092313707,
        "seek": 192708,
        "start": 1952.1999999999998,
        "temperature": 0,
        "text": " I missed a week.",
        "tokens": [
          51620,
          286,
          6721,
          257,
          1243,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.22016384887695312,
        "compression_ratio": 1.5798611111111112,
        "end": 1955.1599999999999,
        "id": 673,
        "no_speech_prob": 0.00007368563092313707,
        "seek": 192708,
        "start": 1954.04,
        "temperature": 0,
        "text": " I missed two weeks, I think.",
        "tokens": [
          51712,
          286,
          6721,
          732,
          3259,
          11,
          286,
          519,
          13,
          51768
        ]
      },
      {
        "avg_logprob": -0.21106017263312088,
        "compression_ratio": 1.4863636363636363,
        "end": 1958.52,
        "id": 674,
        "no_speech_prob": 0.00021654243755619973,
        "seek": 195516,
        "start": 1955.88,
        "temperature": 0,
        "text": " There's some of the when I didn't miss a week, I had shorter streams.",
        "tokens": [
          50400,
          821,
          311,
          512,
          295,
          264,
          562,
          286,
          994,
          380,
          1713,
          257,
          1243,
          11,
          286,
          632,
          11639,
          15842,
          13,
          50532
        ]
      },
      {
        "avg_logprob": -0.21106017263312088,
        "compression_ratio": 1.4863636363636363,
        "end": 1959.48,
        "id": 675,
        "no_speech_prob": 0.00021654243755619973,
        "seek": 195516,
        "start": 1958.52,
        "temperature": 0,
        "text": " And today is no exception.",
        "tokens": [
          50532,
          400,
          965,
          307,
          572,
          11183,
          13,
          50580
        ]
      },
      {
        "avg_logprob": -0.21106017263312088,
        "compression_ratio": 1.4863636363636363,
        "end": 1965.5600000000002,
        "id": 676,
        "no_speech_prob": 0.00021654243755619973,
        "seek": 195516,
        "start": 1959.48,
        "temperature": 0,
        "text": " I hope that December and January will bring back more of a regular routine of content.",
        "tokens": [
          50580,
          286,
          1454,
          300,
          7687,
          293,
          7061,
          486,
          1565,
          646,
          544,
          295,
          257,
          3890,
          9927,
          295,
          2701,
          13,
          50884
        ]
      },
      {
        "avg_logprob": -0.21106017263312088,
        "compression_ratio": 1.4863636363636363,
        "end": 1968.2,
        "id": 677,
        "no_speech_prob": 0.00021654243755619973,
        "seek": 195516,
        "start": 1965.5600000000002,
        "temperature": 0,
        "text": " And I have more ideas about that in the future.",
        "tokens": [
          50884,
          400,
          286,
          362,
          544,
          3487,
          466,
          300,
          294,
          264,
          2027,
          13,
          51016
        ]
      },
      {
        "avg_logprob": -0.21106017263312088,
        "compression_ratio": 1.4863636363636363,
        "end": 1968.7,
        "id": 678,
        "no_speech_prob": 0.00021654243755619973,
        "seek": 195516,
        "start": 1968.2,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51016,
          2264,
          13,
          51041
        ]
      },
      {
        "avg_logprob": -0.21106017263312088,
        "compression_ratio": 1.4863636363636363,
        "end": 1973.8000000000002,
        "id": 679,
        "no_speech_prob": 0.00021654243755619973,
        "seek": 195516,
        "start": 1971.8000000000002,
        "temperature": 0,
        "text": " OK, so let's see.",
        "tokens": [
          51196,
          2264,
          11,
          370,
          718,
          311,
          536,
          13,
          51296
        ]
      },
      {
        "avg_logprob": -0.21106017263312088,
        "compression_ratio": 1.4863636363636363,
        "end": 1978.3600000000001,
        "id": 680,
        "no_speech_prob": 0.00021654243755619973,
        "seek": 195516,
        "start": 1975.4,
        "temperature": 0,
        "text": " I'm going to cycle the cameras again since I babbled on for way too long.",
        "tokens": [
          51376,
          286,
          478,
          516,
          281,
          6586,
          264,
          8622,
          797,
          1670,
          286,
          7564,
          18320,
          322,
          337,
          636,
          886,
          938,
          13,
          51524
        ]
      },
      {
        "avg_logprob": -0.590570782858228,
        "compression_ratio": 1.7960526315789473,
        "end": 1981.4799999999998,
        "id": 681,
        "no_speech_prob": 0.005730148870497942,
        "seek": 197836,
        "start": 1978.52,
        "temperature": 0,
        "text": " And it's so quiet today here.",
        "tokens": [
          50372,
          400,
          309,
          311,
          370,
          5677,
          965,
          510,
          13,
          50520
        ]
      },
      {
        "avg_logprob": -0.590570782858228,
        "compression_ratio": 1.7960526315789473,
        "end": 1983.74,
        "id": 682,
        "no_speech_prob": 0.005730148870497942,
        "seek": 197836,
        "start": 1983.24,
        "temperature": 0,
        "text": " Eerie.",
        "tokens": [
          50608,
          462,
          17487,
          13,
          50633
        ]
      },
      {
        "avg_logprob": -0.590570782858228,
        "compression_ratio": 1.7960526315789473,
        "end": 1987.8,
        "id": 683,
        "no_speech_prob": 0.005730148870497942,
        "seek": 197836,
        "start": 1983.8,
        "temperature": 0,
        "text": " OK, let's do AFIN111.",
        "tokens": [
          50636,
          2264,
          11,
          718,
          311,
          360,
          20389,
          1464,
          5348,
          16,
          13,
          50836
        ]
      },
      {
        "avg_logprob": -0.590570782858228,
        "compression_ratio": 1.7960526315789473,
        "end": 1995.82,
        "id": 684,
        "no_speech_prob": 0.005730148870497942,
        "seek": 197836,
        "start": 1995.32,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          51212,
          6962,
          322,
          13,
          51237
        ]
      },
      {
        "avg_logprob": -0.590570782858228,
        "compression_ratio": 1.7960526315789473,
        "end": 1996.6799999999998,
        "id": 685,
        "no_speech_prob": 0.005730148870497942,
        "seek": 197836,
        "start": 1995.8799999999999,
        "temperature": 0,
        "text": " Sorry, everybody.",
        "tokens": [
          51240,
          4919,
          11,
          2201,
          13,
          51280
        ]
      },
      {
        "avg_logprob": -0.590570782858228,
        "compression_ratio": 1.7960526315789473,
        "end": 1998.36,
        "id": 686,
        "no_speech_prob": 0.005730148870497942,
        "seek": 197836,
        "start": 1996.6799999999998,
        "temperature": 0,
        "text": " I just want to like try to, ah!",
        "tokens": [
          51280,
          286,
          445,
          528,
          281,
          411,
          853,
          281,
          11,
          3716,
          0,
          51364
        ]
      },
      {
        "avg_logprob": -0.590570782858228,
        "compression_ratio": 1.7960526315789473,
        "end": 2004.1999999999998,
        "id": 687,
        "no_speech_prob": 0.005730148870497942,
        "seek": 197836,
        "start": 1999.08,
        "temperature": 0,
        "text": " I'm like so overly, neurotically, anal retentive in this.",
        "tokens": [
          51400,
          286,
          478,
          411,
          370,
          24324,
          11,
          43286,
          984,
          11,
          2624,
          1533,
          317,
          488,
          294,
          341,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.590570782858228,
        "compression_ratio": 1.7960526315789473,
        "end": 2004.6799999999998,
        "id": 688,
        "no_speech_prob": 0.005730148870497942,
        "seek": 197836,
        "start": 2004.1999999999998,
        "temperature": 0,
        "text": " I'm like, ah!",
        "tokens": [
          51656,
          286,
          478,
          411,
          11,
          3716,
          0,
          51680
        ]
      },
      {
        "avg_logprob": -0.590570782858228,
        "compression_ratio": 1.7960526315789473,
        "end": 2005.24,
        "id": 689,
        "no_speech_prob": 0.005730148870497942,
        "seek": 197836,
        "start": 2004.6799999999998,
        "temperature": 0,
        "text": " I'm like, ah!",
        "tokens": [
          51680,
          286,
          478,
          411,
          11,
          3716,
          0,
          51708
        ]
      },
      {
        "avg_logprob": -0.590570782858228,
        "compression_ratio": 1.7960526315789473,
        "end": 2005.8,
        "id": 690,
        "no_speech_prob": 0.005730148870497942,
        "seek": 197836,
        "start": 2005.24,
        "temperature": 0,
        "text": " I'm like, ah!",
        "tokens": [
          51708,
          286,
          478,
          411,
          11,
          3716,
          0,
          51736
        ]
      },
      {
        "avg_logprob": -0.590570782858228,
        "compression_ratio": 1.7960526315789473,
        "end": 2006.36,
        "id": 691,
        "no_speech_prob": 0.005730148870497942,
        "seek": 197836,
        "start": 2005.8,
        "temperature": 0,
        "text": " I'm like, ah!",
        "tokens": [
          51736,
          286,
          478,
          411,
          11,
          3716,
          0,
          51764
        ]
      },
      {
        "avg_logprob": -0.590570782858228,
        "compression_ratio": 1.7960526315789473,
        "end": 2006.9199999999998,
        "id": 692,
        "no_speech_prob": 0.005730148870497942,
        "seek": 197836,
        "start": 2006.36,
        "temperature": 0,
        "text": " I'm like, ah!",
        "tokens": [
          51764,
          286,
          478,
          411,
          11,
          3716,
          0,
          51792
        ]
      },
      {
        "avg_logprob": -0.590570782858228,
        "compression_ratio": 1.7960526315789473,
        "end": 2007.3999999999999,
        "id": 693,
        "no_speech_prob": 0.005730148870497942,
        "seek": 197836,
        "start": 2006.9199999999998,
        "temperature": 0,
        "text": " I'm like, ah!",
        "tokens": [
          51792,
          286,
          478,
          411,
          11,
          3716,
          0,
          51816
        ]
      },
      {
        "avg_logprob": -0.590570782858228,
        "compression_ratio": 1.7960526315789473,
        "end": 2007.9599999999998,
        "id": 694,
        "no_speech_prob": 0.005730148870497942,
        "seek": 197836,
        "start": 2007.3999999999999,
        "temperature": 0,
        "text": " I'm like, ah!",
        "tokens": [
          51816,
          286,
          478,
          411,
          11,
          3716,
          0,
          51844
        ]
      },
      {
        "avg_logprob": -0.5718402982507862,
        "compression_ratio": 1.8766519823788546,
        "end": 2008.76,
        "id": 695,
        "no_speech_prob": 0.012820527888834476,
        "seek": 200796,
        "start": 2008.1200000000001,
        "temperature": 0.6000000000000001,
        "text": " I'm like, ah!",
        "tokens": [
          50372,
          286,
          478,
          411,
          11,
          3716,
          0,
          50404
        ]
      },
      {
        "avg_logprob": -0.5718402982507862,
        "compression_ratio": 1.8766519823788546,
        "end": 2009.32,
        "id": 696,
        "no_speech_prob": 0.012820527888834476,
        "seek": 200796,
        "start": 2008.76,
        "temperature": 0.6000000000000001,
        "text": " I'm like, ah!",
        "tokens": [
          50404,
          286,
          478,
          411,
          11,
          3716,
          0,
          50432
        ]
      },
      {
        "avg_logprob": -0.5718402982507862,
        "compression_ratio": 1.8766519823788546,
        "end": 2009.88,
        "id": 697,
        "no_speech_prob": 0.012820527888834476,
        "seek": 200796,
        "start": 2009.32,
        "temperature": 0.6000000000000001,
        "text": " I'm like, ah!",
        "tokens": [
          50432,
          286,
          478,
          411,
          11,
          3716,
          0,
          50460
        ]
      },
      {
        "avg_logprob": -0.5718402982507862,
        "compression_ratio": 1.8766519823788546,
        "end": 2010.44,
        "id": 698,
        "no_speech_prob": 0.012820527888834476,
        "seek": 200796,
        "start": 2009.88,
        "temperature": 0.6000000000000001,
        "text": " I'm like, ah!",
        "tokens": [
          50460,
          286,
          478,
          411,
          11,
          3716,
          0,
          50488
        ]
      },
      {
        "avg_logprob": -0.5718402982507862,
        "compression_ratio": 1.8766519823788546,
        "end": 2011,
        "id": 699,
        "no_speech_prob": 0.012820527888834476,
        "seek": 200796,
        "start": 2010.44,
        "temperature": 0.6000000000000001,
        "text": " OK, let's see.",
        "tokens": [
          50488,
          2264,
          11,
          718,
          311,
          536,
          13,
          50516
        ]
      },
      {
        "avg_logprob": -0.5718402982507862,
        "compression_ratio": 1.8766519823788546,
        "end": 2011.4,
        "id": 700,
        "no_speech_prob": 0.012820527888834476,
        "seek": 200796,
        "start": 2011,
        "temperature": 0.6000000000000001,
        "text": " I think we're good.",
        "tokens": [
          50516,
          286,
          519,
          321,
          434,
          665,
          13,
          50536
        ]
      },
      {
        "avg_logprob": -0.5718402982507862,
        "compression_ratio": 1.8766519823788546,
        "end": 2012.1200000000001,
        "id": 701,
        "no_speech_prob": 0.012820527888834476,
        "seek": 200796,
        "start": 2011.4,
        "temperature": 0.6000000000000001,
        "text": " I think we're good.",
        "tokens": [
          50536,
          286,
          519,
          321,
          434,
          665,
          13,
          50572
        ]
      },
      {
        "avg_logprob": -0.5718402982507862,
        "compression_ratio": 1.8766519823788546,
        "end": 2014.04,
        "id": 702,
        "no_speech_prob": 0.012820527888834476,
        "seek": 200796,
        "start": 2012.1200000000001,
        "temperature": 0.6000000000000001,
        "text": " OK, so now we're good.",
        "tokens": [
          50572,
          220,
          9443,
          11,
          370,
          586,
          321,
          434,
          665,
          13,
          50668
        ]
      },
      {
        "avg_logprob": -0.5718402982507862,
        "compression_ratio": 1.8766519823788546,
        "end": 2014.92,
        "id": 703,
        "no_speech_prob": 0.012820527888834476,
        "seek": 200796,
        "start": 2014.04,
        "temperature": 0.6000000000000001,
        "text": " OK, so now we're good.",
        "tokens": [
          50668,
          2264,
          11,
          370,
          586,
          321,
          434,
          665,
          13,
          50712
        ]
      },
      {
        "avg_logprob": -0.5718402982507862,
        "compression_ratio": 1.8766519823788546,
        "end": 2017.56,
        "id": 704,
        "no_speech_prob": 0.012820527888834476,
        "seek": 200796,
        "start": 2015.48,
        "temperature": 0.6000000000000001,
        "text": " I wish this had like a little bit of a prettier image.",
        "tokens": [
          50740,
          286,
          3172,
          341,
          632,
          411,
          257,
          707,
          857,
          295,
          257,
          36825,
          3256,
          13,
          50844
        ]
      },
      {
        "avg_logprob": -0.5718402982507862,
        "compression_ratio": 1.8766519823788546,
        "end": 2018.8400000000001,
        "id": 705,
        "no_speech_prob": 0.012820527888834476,
        "seek": 200796,
        "start": 2017.56,
        "temperature": 0.6000000000000001,
        "text": " But what can you help?",
        "tokens": [
          50844,
          583,
          437,
          393,
          291,
          854,
          30,
          50908
        ]
      },
      {
        "avg_logprob": -0.5718402982507862,
        "compression_ratio": 1.8766519823788546,
        "end": 2024.28,
        "id": 706,
        "no_speech_prob": 0.012820527888834476,
        "seek": 200796,
        "start": 2018.8400000000001,
        "temperature": 0.6000000000000001,
        "text": " What if I do sentiment analysis images?",
        "tokens": [
          50908,
          708,
          498,
          286,
          360,
          16149,
          5215,
          5267,
          30,
          51180
        ]
      },
      {
        "avg_logprob": -0.5718402982507862,
        "compression_ratio": 1.8766519823788546,
        "end": 2028.52,
        "id": 707,
        "no_speech_prob": 0.012820527888834476,
        "seek": 200796,
        "start": 2027.64,
        "temperature": 0.6000000000000001,
        "text": " This works for me.",
        "tokens": [
          51348,
          639,
          1985,
          337,
          385,
          13,
          51392
        ]
      },
      {
        "avg_logprob": -0.5718402982507862,
        "compression_ratio": 1.8766519823788546,
        "end": 2031.8,
        "id": 708,
        "no_speech_prob": 0.012820527888834476,
        "seek": 200796,
        "start": 2029.64,
        "temperature": 0.6000000000000001,
        "text": " OK, I want to do a whole.",
        "tokens": [
          51448,
          2264,
          11,
          286,
          528,
          281,
          360,
          257,
          1379,
          13,
          51556
        ]
      },
      {
        "avg_logprob": -0.5718402982507862,
        "compression_ratio": 1.8766519823788546,
        "end": 2035.24,
        "id": 709,
        "no_speech_prob": 0.012820527888834476,
        "seek": 200796,
        "start": 2031.8,
        "temperature": 0.6000000000000001,
        "text": " I also want to do like a whole live stream only about emojis, which I find to be sort",
        "tokens": [
          51556,
          286,
          611,
          528,
          281,
          360,
          411,
          257,
          1379,
          1621,
          4309,
          787,
          466,
          19611,
          40371,
          11,
          597,
          286,
          915,
          281,
          312,
          1333,
          51728
        ]
      },
      {
        "avg_logprob": -0.5718402982507862,
        "compression_ratio": 1.8766519823788546,
        "end": 2036.44,
        "id": 710,
        "no_speech_prob": 0.012820527888834476,
        "seek": 200796,
        "start": 2035.24,
        "temperature": 0.6000000000000001,
        "text": " of like fascinating.",
        "tokens": [
          51728,
          295,
          411,
          10343,
          13,
          51788
        ]
      },
      {
        "avg_logprob": -0.2517486572265625,
        "compression_ratio": 1.1951219512195121,
        "end": 2038.3600000000001,
        "id": 711,
        "no_speech_prob": 0.0019877038430422544,
        "seek": 203644,
        "start": 2036.92,
        "temperature": 0,
        "text": " OK, where are the barking dogs?",
        "tokens": [
          50388,
          2264,
          11,
          689,
          366,
          264,
          32995,
          7197,
          30,
          50460
        ]
      },
      {
        "avg_logprob": -0.2517486572265625,
        "compression_ratio": 1.1951219512195121,
        "end": 2039.16,
        "id": 712,
        "no_speech_prob": 0.0019877038430422544,
        "seek": 203644,
        "start": 2038.3600000000001,
        "temperature": 0,
        "text": " Not today, I guess.",
        "tokens": [
          50460,
          1726,
          965,
          11,
          286,
          2041,
          13,
          50500
        ]
      },
      {
        "avg_logprob": -0.2517486572265625,
        "compression_ratio": 1.1951219512195121,
        "end": 2047.24,
        "id": 713,
        "no_speech_prob": 0.0019877038430422544,
        "seek": 203644,
        "start": 2045.96,
        "temperature": 0,
        "text": " Where's my bumper music?",
        "tokens": [
          50840,
          2305,
          311,
          452,
          23992,
          1318,
          30,
          50904
        ]
      },
      {
        "avg_logprob": -0.2517486572265625,
        "compression_ratio": 1.1951219512195121,
        "end": 2053.8,
        "id": 714,
        "no_speech_prob": 0.0019877038430422544,
        "seek": 203644,
        "start": 2052.68,
        "temperature": 0,
        "text": " Can you hear that?",
        "tokens": [
          51176,
          1664,
          291,
          1568,
          300,
          30,
          51232
        ]
      },
      {
        "avg_logprob": -0.2517486572265625,
        "compression_ratio": 1.1951219512195121,
        "end": 2054.52,
        "id": 715,
        "no_speech_prob": 0.0019877038430422544,
        "seek": 203644,
        "start": 2053.8,
        "temperature": 0,
        "text": " Is it loud?",
        "tokens": [
          51232,
          1119,
          309,
          6588,
          30,
          51268
        ]
      },
      {
        "avg_logprob": -0.2517486572265625,
        "compression_ratio": 1.1951219512195121,
        "end": 2055.08,
        "id": 716,
        "no_speech_prob": 0.0019877038430422544,
        "seek": 203644,
        "start": 2054.52,
        "temperature": 0,
        "text": " Is that loud?",
        "tokens": [
          51268,
          1119,
          300,
          6588,
          30,
          51296
        ]
      },
      {
        "avg_logprob": -0.2517486572265625,
        "compression_ratio": 1.1951219512195121,
        "end": 2057,
        "id": 717,
        "no_speech_prob": 0.0019877038430422544,
        "seek": 203644,
        "start": 2055.88,
        "temperature": 0,
        "text": " It's so quiet for me.",
        "tokens": [
          51336,
          467,
          311,
          370,
          5677,
          337,
          385,
          13,
          51392
        ]
      },
      {
        "avg_logprob": -0.2517486572265625,
        "compression_ratio": 1.1951219512195121,
        "end": 2057.32,
        "id": 718,
        "no_speech_prob": 0.0019877038430422544,
        "seek": 203644,
        "start": 2057,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51392,
          2264,
          13,
          51408
        ]
      },
      {
        "avg_logprob": -0.26340553495619035,
        "compression_ratio": 1.3641975308641976,
        "end": 2067.7200000000003,
        "id": 719,
        "no_speech_prob": 0.012430688366293907,
        "seek": 205732,
        "start": 2058.2000000000003,
        "temperature": 0,
        "text": " OK, sorry, I'm paying too much attention to the chat.",
        "tokens": [
          50408,
          2264,
          11,
          2597,
          11,
          286,
          478,
          6229,
          886,
          709,
          3202,
          281,
          264,
          5081,
          13,
          50884
        ]
      },
      {
        "avg_logprob": -0.26340553495619035,
        "compression_ratio": 1.3641975308641976,
        "end": 2069.56,
        "id": 720,
        "no_speech_prob": 0.012430688366293907,
        "seek": 205732,
        "start": 2067.7200000000003,
        "temperature": 0,
        "text": " Wow, there are really 160 people watching?",
        "tokens": [
          50884,
          3153,
          11,
          456,
          366,
          534,
          21243,
          561,
          1976,
          30,
          50976
        ]
      },
      {
        "avg_logprob": -0.26340553495619035,
        "compression_ratio": 1.3641975308641976,
        "end": 2071.56,
        "id": 721,
        "no_speech_prob": 0.012430688366293907,
        "seek": 205732,
        "start": 2070.36,
        "temperature": 0,
        "text": " That is insane.",
        "tokens": [
          51016,
          663,
          307,
          10838,
          13,
          51076
        ]
      },
      {
        "avg_logprob": -0.26340553495619035,
        "compression_ratio": 1.3641975308641976,
        "end": 2072.28,
        "id": 722,
        "no_speech_prob": 0.012430688366293907,
        "seek": 205732,
        "start": 2071.56,
        "temperature": 0,
        "text": " Oh my goodness.",
        "tokens": [
          51076,
          876,
          452,
          8387,
          13,
          51112
        ]
      },
      {
        "avg_logprob": -0.26340553495619035,
        "compression_ratio": 1.3641975308641976,
        "end": 2075.32,
        "id": 723,
        "no_speech_prob": 0.012430688366293907,
        "seek": 205732,
        "start": 2073.32,
        "temperature": 0,
        "text": " OK, OK, here we go.",
        "tokens": [
          51164,
          2264,
          11,
          2264,
          11,
          510,
          321,
          352,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.26340553495619035,
        "compression_ratio": 1.3641975308641976,
        "end": 2081.32,
        "id": 724,
        "no_speech_prob": 0.012430688366293907,
        "seek": 205732,
        "start": 2080.36,
        "temperature": 0,
        "text": " I'm going to try that again.",
        "tokens": [
          51516,
          286,
          478,
          516,
          281,
          853,
          300,
          797,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.26340553495619035,
        "compression_ratio": 1.3641975308641976,
        "end": 2086.76,
        "id": 725,
        "no_speech_prob": 0.012430688366293907,
        "seek": 205732,
        "start": 2084.52,
        "temperature": 0,
        "text": " Hello, welcome to a coding challenge again.",
        "tokens": [
          51724,
          2425,
          11,
          2928,
          281,
          257,
          17720,
          3430,
          797,
          13,
          51836
        ]
      },
      {
        "avg_logprob": -0.17450004327492635,
        "compression_ratio": 1.7709923664122138,
        "end": 2092.92,
        "id": 726,
        "no_speech_prob": 0.0007096632616594434,
        "seek": 208676,
        "start": 2086.76,
        "temperature": 0,
        "text": " In this coding challenge, I am going to build from scratch a web application that does sentiment",
        "tokens": [
          50364,
          682,
          341,
          17720,
          3430,
          11,
          286,
          669,
          516,
          281,
          1322,
          490,
          8459,
          257,
          3670,
          3861,
          300,
          775,
          16149,
          50672
        ]
      },
      {
        "avg_logprob": -0.17450004327492635,
        "compression_ratio": 1.7709923664122138,
        "end": 2093.48,
        "id": 727,
        "no_speech_prob": 0.0007096632616594434,
        "seek": 208676,
        "start": 2092.92,
        "temperature": 0,
        "text": " analysis.",
        "tokens": [
          50672,
          5215,
          13,
          50700
        ]
      },
      {
        "avg_logprob": -0.17450004327492635,
        "compression_ratio": 1.7709923664122138,
        "end": 2095.96,
        "id": 728,
        "no_speech_prob": 0.0007096632616594434,
        "seek": 208676,
        "start": 2094.76,
        "temperature": 0,
        "text": " What is sentiment analysis?",
        "tokens": [
          50764,
          708,
          307,
          16149,
          5215,
          30,
          50824
        ]
      },
      {
        "avg_logprob": -0.17450004327492635,
        "compression_ratio": 1.7709923664122138,
        "end": 2099.32,
        "id": 729,
        "no_speech_prob": 0.0007096632616594434,
        "seek": 208676,
        "start": 2095.96,
        "temperature": 0,
        "text": " So first of all, I want to mention that the actual, oops, I'm in the wrong page.",
        "tokens": [
          50824,
          407,
          700,
          295,
          439,
          11,
          286,
          528,
          281,
          2152,
          300,
          264,
          3539,
          11,
          34166,
          11,
          286,
          478,
          294,
          264,
          2085,
          3028,
          13,
          50992
        ]
      },
      {
        "avg_logprob": -0.17450004327492635,
        "compression_ratio": 1.7709923664122138,
        "end": 2107,
        "id": 730,
        "no_speech_prob": 0.0007096632616594434,
        "seek": 208676,
        "start": 2099.32,
        "temperature": 0,
        "text": " The particular technique I'm going to use is a score-based system using a list of words",
        "tokens": [
          50992,
          440,
          1729,
          6532,
          286,
          478,
          516,
          281,
          764,
          307,
          257,
          6175,
          12,
          6032,
          1185,
          1228,
          257,
          1329,
          295,
          2283,
          51376
        ]
      },
      {
        "avg_logprob": -0.17450004327492635,
        "compression_ratio": 1.7709923664122138,
        "end": 2108.76,
        "id": 731,
        "no_speech_prob": 0.0007096632616594434,
        "seek": 208676,
        "start": 2107,
        "temperature": 0,
        "text": " known as the AFIN111.",
        "tokens": [
          51376,
          2570,
          382,
          264,
          20389,
          1464,
          5348,
          16,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.17450004327492635,
        "compression_ratio": 1.7709923664122138,
        "end": 2111,
        "id": 732,
        "no_speech_prob": 0.0007096632616594434,
        "seek": 208676,
        "start": 2108.76,
        "temperature": 0,
        "text": " So there are a lot of ways to do sentiment analysis.",
        "tokens": [
          51464,
          407,
          456,
          366,
          257,
          688,
          295,
          2098,
          281,
          360,
          16149,
          5215,
          13,
          51576
        ]
      },
      {
        "avg_logprob": -0.17450004327492635,
        "compression_ratio": 1.7709923664122138,
        "end": 2115.8,
        "id": 733,
        "no_speech_prob": 0.0007096632616594434,
        "seek": 208676,
        "start": 2111,
        "temperature": 0,
        "text": " What I mean by sentiment analysis is here's some text, here's some information I want",
        "tokens": [
          51576,
          708,
          286,
          914,
          538,
          16149,
          5215,
          307,
          510,
          311,
          512,
          2487,
          11,
          510,
          311,
          512,
          1589,
          286,
          528,
          51816
        ]
      },
      {
        "avg_logprob": -0.15224213295794548,
        "compression_ratio": 1.9798387096774193,
        "end": 2116.28,
        "id": 734,
        "no_speech_prob": 0.0011513563804328442,
        "seek": 211580,
        "start": 2115.8,
        "temperature": 0,
        "text": " to determine.",
        "tokens": [
          50364,
          281,
          6997,
          13,
          50388
        ]
      },
      {
        "avg_logprob": -0.15224213295794548,
        "compression_ratio": 1.9798387096774193,
        "end": 2117.32,
        "id": 735,
        "no_speech_prob": 0.0011513563804328442,
        "seek": 211580,
        "start": 2116.28,
        "temperature": 0,
        "text": " Is it positive?",
        "tokens": [
          50388,
          1119,
          309,
          3353,
          30,
          50440
        ]
      },
      {
        "avg_logprob": -0.15224213295794548,
        "compression_ratio": 1.9798387096774193,
        "end": 2118.04,
        "id": 736,
        "no_speech_prob": 0.0011513563804328442,
        "seek": 211580,
        "start": 2117.32,
        "temperature": 0,
        "text": " Is it negative?",
        "tokens": [
          50440,
          1119,
          309,
          3671,
          30,
          50476
        ]
      },
      {
        "avg_logprob": -0.15224213295794548,
        "compression_ratio": 1.9798387096774193,
        "end": 2120.2000000000003,
        "id": 737,
        "no_speech_prob": 0.0011513563804328442,
        "seek": 211580,
        "start": 2118.76,
        "temperature": 0,
        "text": " And I want to assign it a score.",
        "tokens": [
          50512,
          400,
          286,
          528,
          281,
          6269,
          309,
          257,
          6175,
          13,
          50584
        ]
      },
      {
        "avg_logprob": -0.15224213295794548,
        "compression_ratio": 1.9798387096774193,
        "end": 2122.36,
        "id": 738,
        "no_speech_prob": 0.0011513563804328442,
        "seek": 211580,
        "start": 2120.2000000000003,
        "temperature": 0,
        "text": " Is it a high number, meaning very positive?",
        "tokens": [
          50584,
          1119,
          309,
          257,
          1090,
          1230,
          11,
          3620,
          588,
          3353,
          30,
          50692
        ]
      },
      {
        "avg_logprob": -0.15224213295794548,
        "compression_ratio": 1.9798387096774193,
        "end": 2124.2000000000003,
        "id": 739,
        "no_speech_prob": 0.0011513563804328442,
        "seek": 211580,
        "start": 2122.36,
        "temperature": 0,
        "text": " Is it 0, meaning completely neutral?",
        "tokens": [
          50692,
          1119,
          309,
          1958,
          11,
          3620,
          2584,
          10598,
          30,
          50784
        ]
      },
      {
        "avg_logprob": -0.15224213295794548,
        "compression_ratio": 1.9798387096774193,
        "end": 2127.32,
        "id": 740,
        "no_speech_prob": 0.0011513563804328442,
        "seek": 211580,
        "start": 2124.2000000000003,
        "temperature": 0,
        "text": " Is it a low negative number, meaning very negative?",
        "tokens": [
          50784,
          1119,
          309,
          257,
          2295,
          3671,
          1230,
          11,
          3620,
          588,
          3671,
          30,
          50940
        ]
      },
      {
        "avg_logprob": -0.15224213295794548,
        "compression_ratio": 1.9798387096774193,
        "end": 2128.52,
        "id": 741,
        "no_speech_prob": 0.0011513563804328442,
        "seek": 211580,
        "start": 2127.32,
        "temperature": 0,
        "text": " And there are different ways you can do this.",
        "tokens": [
          50940,
          400,
          456,
          366,
          819,
          2098,
          291,
          393,
          360,
          341,
          13,
          51000
        ]
      },
      {
        "avg_logprob": -0.15224213295794548,
        "compression_ratio": 1.9798387096774193,
        "end": 2132.92,
        "id": 742,
        "no_speech_prob": 0.0011513563804328442,
        "seek": 211580,
        "start": 2128.52,
        "temperature": 0,
        "text": " There are machine learning systems that can be trained.",
        "tokens": [
          51000,
          821,
          366,
          3479,
          2539,
          3652,
          300,
          393,
          312,
          8895,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.15224213295794548,
        "compression_ratio": 1.9798387096774193,
        "end": 2137.96,
        "id": 743,
        "no_speech_prob": 0.0011513563804328442,
        "seek": 211580,
        "start": 2132.92,
        "temperature": 0,
        "text": " Here's a lot of very positive essays, and here's a lot of really negative essays.",
        "tokens": [
          51220,
          1692,
          311,
          257,
          688,
          295,
          588,
          3353,
          35123,
          11,
          293,
          510,
          311,
          257,
          688,
          295,
          534,
          3671,
          35123,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -0.15224213295794548,
        "compression_ratio": 1.9798387096774193,
        "end": 2138.6800000000003,
        "id": 744,
        "no_speech_prob": 0.0011513563804328442,
        "seek": 211580,
        "start": 2137.96,
        "temperature": 0,
        "text": " Learn about them.",
        "tokens": [
          51472,
          17216,
          466,
          552,
          13,
          51508
        ]
      },
      {
        "avg_logprob": -0.15224213295794548,
        "compression_ratio": 1.9798387096774193,
        "end": 2139.4,
        "id": 745,
        "no_speech_prob": 0.0011513563804328442,
        "seek": 211580,
        "start": 2138.6800000000003,
        "temperature": 0,
        "text": " Here's an essay.",
        "tokens": [
          51508,
          1692,
          311,
          364,
          16238,
          13,
          51544
        ]
      },
      {
        "avg_logprob": -0.15224213295794548,
        "compression_ratio": 1.9798387096774193,
        "end": 2140.92,
        "id": 746,
        "no_speech_prob": 0.0011513563804328442,
        "seek": 211580,
        "start": 2139.4,
        "temperature": 0,
        "text": " Please give it a score.",
        "tokens": [
          51544,
          2555,
          976,
          309,
          257,
          6175,
          13,
          51620
        ]
      },
      {
        "avg_logprob": -0.15224213295794548,
        "compression_ratio": 1.9798387096774193,
        "end": 2143.2400000000002,
        "id": 747,
        "no_speech_prob": 0.0011513563804328442,
        "seek": 211580,
        "start": 2140.92,
        "temperature": 0,
        "text": " There's neural networks can do this.",
        "tokens": [
          51620,
          821,
          311,
          18161,
          9590,
          393,
          360,
          341,
          13,
          51736
        ]
      },
      {
        "avg_logprob": -0.17404300331050515,
        "compression_ratio": 1.673003802281369,
        "end": 2149.08,
        "id": 748,
        "no_speech_prob": 0.013636068440973759,
        "seek": 214324,
        "start": 2143.24,
        "temperature": 0,
        "text": " There's a technique known as Bayesian classification that can be trained to look, also be trained",
        "tokens": [
          50364,
          821,
          311,
          257,
          6532,
          2570,
          382,
          7840,
          42434,
          21538,
          300,
          393,
          312,
          8895,
          281,
          574,
          11,
          611,
          312,
          8895,
          50656
        ]
      },
      {
        "avg_logprob": -0.17404300331050515,
        "compression_ratio": 1.673003802281369,
        "end": 2150.6,
        "id": 749,
        "no_speech_prob": 0.013636068440973759,
        "seek": 214324,
        "start": 2149.08,
        "temperature": 0,
        "text": " based on positive and negative text.",
        "tokens": [
          50656,
          2361,
          322,
          3353,
          293,
          3671,
          2487,
          13,
          50732
        ]
      },
      {
        "avg_logprob": -0.17404300331050515,
        "compression_ratio": 1.673003802281369,
        "end": 2154.3599999999997,
        "id": 750,
        "no_speech_prob": 0.013636068440973759,
        "seek": 214324,
        "start": 2151.24,
        "temperature": 0,
        "text": " And there's, I'm sure, a list of many other techniques here.",
        "tokens": [
          50764,
          400,
          456,
          311,
          11,
          286,
          478,
          988,
          11,
          257,
          1329,
          295,
          867,
          661,
          7512,
          510,
          13,
          50920
        ]
      },
      {
        "avg_logprob": -0.17404300331050515,
        "compression_ratio": 1.673003802281369,
        "end": 2158.52,
        "id": 751,
        "no_speech_prob": 0.013636068440973759,
        "seek": 214324,
        "start": 2154.3599999999997,
        "temperature": 0,
        "text": " But the technique that I want to look at in this particular video is quite a simple one,",
        "tokens": [
          50920,
          583,
          264,
          6532,
          300,
          286,
          528,
          281,
          574,
          412,
          294,
          341,
          1729,
          960,
          307,
          1596,
          257,
          2199,
          472,
          11,
          51128
        ]
      },
      {
        "avg_logprob": -0.17404300331050515,
        "compression_ratio": 1.673003802281369,
        "end": 2165.9599999999996,
        "id": 752,
        "no_speech_prob": 0.013636068440973759,
        "seek": 214324,
        "start": 2158.52,
        "temperature": 0,
        "text": " and it involves a pre-made list of words that are assigned a valence, a positivity or negativity",
        "tokens": [
          51128,
          293,
          309,
          11626,
          257,
          659,
          12,
          10341,
          1329,
          295,
          2283,
          300,
          366,
          13279,
          257,
          1323,
          655,
          11,
          257,
          35198,
          420,
          39297,
          51500
        ]
      },
      {
        "avg_logprob": -0.17404300331050515,
        "compression_ratio": 1.673003802281369,
        "end": 2166.6,
        "id": 753,
        "no_speech_prob": 0.013636068440973759,
        "seek": 214324,
        "start": 2165.9599999999996,
        "temperature": 0,
        "text": " score.",
        "tokens": [
          51500,
          6175,
          13,
          51532
        ]
      },
      {
        "avg_logprob": -0.17404300331050515,
        "compression_ratio": 1.673003802281369,
        "end": 2170.2,
        "id": 754,
        "no_speech_prob": 0.013636068440973759,
        "seek": 214324,
        "start": 2166.6,
        "temperature": 0,
        "text": " And so this list is a well-known list, the AFIN111.",
        "tokens": [
          51532,
          400,
          370,
          341,
          1329,
          307,
          257,
          731,
          12,
          6861,
          1329,
          11,
          264,
          20389,
          1464,
          5348,
          16,
          13,
          51712
        ]
      },
      {
        "avg_logprob": -0.20963716969906704,
        "compression_ratio": 1.6053811659192825,
        "end": 2178.12,
        "id": 755,
        "no_speech_prob": 0.0003199963248334825,
        "seek": 217020,
        "start": 2171.16,
        "temperature": 0,
        "text": " It is the newest version with 2,477 words and phrases, and these were labeled by Fin",
        "tokens": [
          50412,
          467,
          307,
          264,
          17569,
          3037,
          365,
          568,
          11,
          14060,
          22,
          2283,
          293,
          20312,
          11,
          293,
          613,
          645,
          21335,
          538,
          3773,
          50760
        ]
      },
      {
        "avg_logprob": -0.20963716969906704,
        "compression_ratio": 1.6053811659192825,
        "end": 2181.08,
        "id": 756,
        "no_speech_prob": 0.0003199963248334825,
        "seek": 217020,
        "start": 2178.12,
        "temperature": 0,
        "text": " Arup-Nielsen in 2009, 2011.",
        "tokens": [
          50760,
          316,
          11976,
          12,
          45,
          1187,
          6748,
          294,
          11453,
          11,
          10154,
          13,
          50908
        ]
      },
      {
        "avg_logprob": -0.20963716969906704,
        "compression_ratio": 1.6053811659192825,
        "end": 2187.24,
        "id": 757,
        "no_speech_prob": 0.0003199963248334825,
        "seek": 217020,
        "start": 2181.08,
        "temperature": 0,
        "text": " So the way this works is you take a body of text, you read through it, you look for any",
        "tokens": [
          50908,
          407,
          264,
          636,
          341,
          1985,
          307,
          291,
          747,
          257,
          1772,
          295,
          2487,
          11,
          291,
          1401,
          807,
          309,
          11,
          291,
          574,
          337,
          604,
          51216
        ]
      },
      {
        "avg_logprob": -0.20963716969906704,
        "compression_ratio": 1.6053811659192825,
        "end": 2193.48,
        "id": 758,
        "no_speech_prob": 0.0003199963248334825,
        "seek": 217020,
        "start": 2187.24,
        "temperature": 0,
        "text": " time a word that appears on the AFIN111 list is, you look for any words that appear on",
        "tokens": [
          51216,
          565,
          257,
          1349,
          300,
          7038,
          322,
          264,
          20389,
          1464,
          5348,
          16,
          1329,
          307,
          11,
          291,
          574,
          337,
          604,
          2283,
          300,
          4204,
          322,
          51528
        ]
      },
      {
        "avg_logprob": -0.20963716969906704,
        "compression_ratio": 1.6053811659192825,
        "end": 2196.7599999999998,
        "id": 759,
        "no_speech_prob": 0.0003199963248334825,
        "seek": 217020,
        "start": 2193.48,
        "temperature": 0,
        "text": " that list, you look up its score, and you add all the scores together.",
        "tokens": [
          51528,
          300,
          1329,
          11,
          291,
          574,
          493,
          1080,
          6175,
          11,
          293,
          291,
          909,
          439,
          264,
          13444,
          1214,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.20768596363716385,
        "compression_ratio": 1.802325581395349,
        "end": 2204.8399999999997,
        "id": 760,
        "no_speech_prob": 0.02033115178346634,
        "seek": 220020,
        "start": 2200.8399999999997,
        "temperature": 0,
        "text": " I don't know why I felt like this video is going fine, but I just realized I don't have",
        "tokens": [
          50396,
          286,
          500,
          380,
          458,
          983,
          286,
          2762,
          411,
          341,
          960,
          307,
          516,
          2489,
          11,
          457,
          286,
          445,
          5334,
          286,
          500,
          380,
          362,
          50596
        ]
      },
      {
        "avg_logprob": -0.20768596363716385,
        "compression_ratio": 1.802325581395349,
        "end": 2205.3999999999996,
        "id": 761,
        "no_speech_prob": 0.02033115178346634,
        "seek": 220020,
        "start": 2204.8399999999997,
        "temperature": 0,
        "text": " a marker.",
        "tokens": [
          50596,
          257,
          15247,
          13,
          50624
        ]
      },
      {
        "avg_logprob": -0.20768596363716385,
        "compression_ratio": 1.802325581395349,
        "end": 2210.2,
        "id": 762,
        "no_speech_prob": 0.02033115178346634,
        "seek": 220020,
        "start": 2207.3199999999997,
        "temperature": 0,
        "text": " And I was going to, I was like, kept thinking, oh, I should just like do this on the white",
        "tokens": [
          50720,
          400,
          286,
          390,
          516,
          281,
          11,
          286,
          390,
          411,
          11,
          4305,
          1953,
          11,
          1954,
          11,
          286,
          820,
          445,
          411,
          360,
          341,
          322,
          264,
          2418,
          50864
        ]
      },
      {
        "avg_logprob": -0.20768596363716385,
        "compression_ratio": 1.802325581395349,
        "end": 2210.52,
        "id": 763,
        "no_speech_prob": 0.02033115178346634,
        "seek": 220020,
        "start": 2210.2,
        "temperature": 0,
        "text": " board.",
        "tokens": [
          50864,
          3150,
          13,
          50880
        ]
      },
      {
        "avg_logprob": -0.20768596363716385,
        "compression_ratio": 1.802325581395349,
        "end": 2217.08,
        "id": 764,
        "no_speech_prob": 0.02033115178346634,
        "seek": 220020,
        "start": 2211.16,
        "temperature": 0,
        "text": " And then I realized I don't have a marker, and then I lost my train of thought.",
        "tokens": [
          50912,
          400,
          550,
          286,
          5334,
          286,
          500,
          380,
          362,
          257,
          15247,
          11,
          293,
          550,
          286,
          2731,
          452,
          3847,
          295,
          1194,
          13,
          51208
        ]
      },
      {
        "avg_logprob": -0.20768596363716385,
        "compression_ratio": 1.802325581395349,
        "end": 2219.24,
        "id": 765,
        "no_speech_prob": 0.02033115178346634,
        "seek": 220020,
        "start": 2217.64,
        "temperature": 0,
        "text": " And Denmark.",
        "tokens": [
          51236,
          400,
          28065,
          13,
          51316
        ]
      },
      {
        "avg_logprob": -0.20768596363716385,
        "compression_ratio": 1.802325581395349,
        "end": 2220.04,
        "id": 766,
        "no_speech_prob": 0.02033115178346634,
        "seek": 220020,
        "start": 2219.24,
        "temperature": 0,
        "text": " Oh, OK.",
        "tokens": [
          51316,
          876,
          11,
          2264,
          13,
          51356
        ]
      },
      {
        "avg_logprob": -0.20768596363716385,
        "compression_ratio": 1.802325581395349,
        "end": 2221.56,
        "id": 767,
        "no_speech_prob": 0.02033115178346634,
        "seek": 220020,
        "start": 2220.04,
        "temperature": 0,
        "text": " So I'm going to do something a little weird.",
        "tokens": [
          51356,
          407,
          286,
          478,
          516,
          281,
          360,
          746,
          257,
          707,
          3657,
          13,
          51432
        ]
      },
      {
        "avg_logprob": -0.20768596363716385,
        "compression_ratio": 1.802325581395349,
        "end": 2223.24,
        "id": 768,
        "no_speech_prob": 0.02033115178346634,
        "seek": 220020,
        "start": 2221.56,
        "temperature": 0,
        "text": " Mathias seems to be in the chat.",
        "tokens": [
          51432,
          15776,
          4609,
          2544,
          281,
          312,
          294,
          264,
          5081,
          13,
          51516
        ]
      },
      {
        "avg_logprob": -0.20768596363716385,
        "compression_ratio": 1.802325581395349,
        "end": 2229.8799999999997,
        "id": 769,
        "no_speech_prob": 0.02033115178346634,
        "seek": 220020,
        "start": 2223.24,
        "temperature": 0,
        "text": " I'm going to re-explain the AFIN111 thing, but I'm going to do it over by the white board.",
        "tokens": [
          51516,
          286,
          478,
          516,
          281,
          319,
          12,
          23040,
          491,
          264,
          20389,
          1464,
          5348,
          16,
          551,
          11,
          457,
          286,
          478,
          516,
          281,
          360,
          309,
          670,
          538,
          264,
          2418,
          3150,
          13,
          51848
        ]
      },
      {
        "avg_logprob": -0.19503579680452643,
        "compression_ratio": 1.509090909090909,
        "end": 2233.48,
        "id": 770,
        "no_speech_prob": 0.00003883098179358058,
        "seek": 223020,
        "start": 2230.6,
        "temperature": 0,
        "text": " And so you're just going to have to, I think you can just cut out that quick explanation",
        "tokens": [
          50384,
          400,
          370,
          291,
          434,
          445,
          516,
          281,
          362,
          281,
          11,
          286,
          519,
          291,
          393,
          445,
          1723,
          484,
          300,
          1702,
          10835,
          50528
        ]
      },
      {
        "avg_logprob": -0.19503579680452643,
        "compression_ratio": 1.509090909090909,
        "end": 2239,
        "id": 771,
        "no_speech_prob": 0.00003883098179358058,
        "seek": 223020,
        "start": 2234.68,
        "temperature": 0,
        "text": " and splice in this new, better explanation with the white board, and then I'll keep going.",
        "tokens": [
          50588,
          293,
          4732,
          573,
          294,
          341,
          777,
          11,
          1101,
          10835,
          365,
          264,
          2418,
          3150,
          11,
          293,
          550,
          286,
          603,
          1066,
          516,
          13,
          50804
        ]
      },
      {
        "avg_logprob": -0.19503579680452643,
        "compression_ratio": 1.509090909090909,
        "end": 2240.2,
        "id": 772,
        "no_speech_prob": 0.00003883098179358058,
        "seek": 223020,
        "start": 2239.8799999999997,
        "temperature": 0,
        "text": " Sorry.",
        "tokens": [
          50848,
          4919,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19503579680452643,
        "compression_ratio": 1.509090909090909,
        "end": 2242.52,
        "id": 773,
        "no_speech_prob": 0.00003883098179358058,
        "seek": 223020,
        "start": 2240.8399999999997,
        "temperature": 0,
        "text": " If it doesn't work, whatever, we'll figure it out.",
        "tokens": [
          50896,
          759,
          309,
          1177,
          380,
          589,
          11,
          2035,
          11,
          321,
          603,
          2573,
          309,
          484,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.19503579680452643,
        "compression_ratio": 1.509090909090909,
        "end": 2249.48,
        "id": 774,
        "no_speech_prob": 0.00003883098179358058,
        "seek": 223020,
        "start": 2245.56,
        "temperature": 0,
        "text": " So what is the AFIN111 technique?",
        "tokens": [
          51132,
          407,
          437,
          307,
          264,
          20389,
          1464,
          5348,
          16,
          6532,
          30,
          51328
        ]
      },
      {
        "avg_logprob": -0.19503579680452643,
        "compression_ratio": 1.509090909090909,
        "end": 2254.7599999999998,
        "id": 775,
        "no_speech_prob": 0.00003883098179358058,
        "seek": 223020,
        "start": 2249.48,
        "temperature": 0,
        "text": " The AFIN111 technique involves a pre-assigned list of words.",
        "tokens": [
          51328,
          440,
          20389,
          1464,
          5348,
          16,
          6532,
          11626,
          257,
          659,
          12,
          640,
          16690,
          1329,
          295,
          2283,
          13,
          51592
        ]
      },
      {
        "avg_logprob": -0.2913219287831296,
        "compression_ratio": 1.5638297872340425,
        "end": 2259.88,
        "id": 776,
        "no_speech_prob": 0.0039453571662306786,
        "seek": 225476,
        "start": 2255.5600000000004,
        "temperature": 0,
        "text": " So if I were to say like happy, this has a score of 5.",
        "tokens": [
          50404,
          407,
          498,
          286,
          645,
          281,
          584,
          411,
          2055,
          11,
          341,
          575,
          257,
          6175,
          295,
          1025,
          13,
          50620
        ]
      },
      {
        "avg_logprob": -0.2913219287831296,
        "compression_ratio": 1.5638297872340425,
        "end": 2268.1200000000003,
        "id": 777,
        "no_speech_prob": 0.0039453571662306786,
        "seek": 225476,
        "start": 2260.6000000000004,
        "temperature": 0,
        "text": " Each word gets a positive or negative valence score, 5 being very positive.",
        "tokens": [
          50656,
          6947,
          1349,
          2170,
          257,
          3353,
          420,
          3671,
          1323,
          655,
          6175,
          11,
          1025,
          885,
          588,
          3353,
          13,
          51032
        ]
      },
      {
        "avg_logprob": -0.2913219287831296,
        "compression_ratio": 1.5638297872340425,
        "end": 2271.5600000000004,
        "id": 778,
        "no_speech_prob": 0.0039453571662306786,
        "seek": 225476,
        "start": 2268.6800000000003,
        "temperature": 0,
        "text": " Sad, very negative.",
        "tokens": [
          51060,
          12269,
          11,
          588,
          3671,
          13,
          51204
        ]
      },
      {
        "avg_logprob": -0.2913219287831296,
        "compression_ratio": 1.5638297872340425,
        "end": 2273.0800000000004,
        "id": 779,
        "no_speech_prob": 0.0039453571662306786,
        "seek": 225476,
        "start": 2272.2000000000003,
        "temperature": 0,
        "text": " No rainbow.",
        "tokens": [
          51236,
          883,
          18526,
          13,
          51280
        ]
      },
      {
        "avg_logprob": -0.2913219287831296,
        "compression_ratio": 1.5638297872340425,
        "end": 2275.32,
        "id": 780,
        "no_speech_prob": 0.0039453571662306786,
        "seek": 225476,
        "start": 2274.1200000000003,
        "temperature": 0,
        "text": " Also very positive.",
        "tokens": [
          51332,
          2743,
          588,
          3353,
          13,
          51392
        ]
      },
      {
        "avg_logprob": -0.2913219287831296,
        "compression_ratio": 1.5638297872340425,
        "end": 2276.44,
        "id": 781,
        "no_speech_prob": 0.0039453571662306786,
        "seek": 225476,
        "start": 2275.88,
        "temperature": 0,
        "text": " 5.",
        "tokens": [
          51420,
          1025,
          13,
          51448
        ]
      },
      {
        "avg_logprob": -0.2913219287831296,
        "compression_ratio": 1.5638297872340425,
        "end": 2278.92,
        "id": 782,
        "no_speech_prob": 0.0039453571662306786,
        "seek": 225476,
        "start": 2276.44,
        "temperature": 0,
        "text": " I don't want to give rainbow the score of 4 and happy 5.",
        "tokens": [
          51448,
          286,
          500,
          380,
          528,
          281,
          976,
          18526,
          264,
          6175,
          295,
          1017,
          293,
          2055,
          1025,
          13,
          51572
        ]
      },
      {
        "avg_logprob": -0.2913219287831296,
        "compression_ratio": 1.5638297872340425,
        "end": 2283.6400000000003,
        "id": 783,
        "no_speech_prob": 0.0039453571662306786,
        "seek": 225476,
        "start": 2279.7200000000003,
        "temperature": 0,
        "text": " And I could think of what's like, you know, turtle.",
        "tokens": [
          51612,
          400,
          286,
          727,
          519,
          295,
          437,
          311,
          411,
          11,
          291,
          458,
          11,
          22866,
          13,
          51808
        ]
      },
      {
        "avg_logprob": -0.18904897901746961,
        "compression_ratio": 1.8020134228187918,
        "end": 2285.4,
        "id": 784,
        "no_speech_prob": 0.00004198601527605206,
        "seek": 228364,
        "start": 2283.64,
        "temperature": 0,
        "text": " Turtles are like a little bit sad.",
        "tokens": [
          50364,
          5712,
          23995,
          366,
          411,
          257,
          707,
          857,
          4227,
          13,
          50452
        ]
      },
      {
        "avg_logprob": -0.18904897901746961,
        "compression_ratio": 1.8020134228187918,
        "end": 2287.3199999999997,
        "id": 785,
        "no_speech_prob": 0.00004198601527605206,
        "seek": 228364,
        "start": 2285.4,
        "temperature": 0,
        "text": " I don't know, turtles are happy.",
        "tokens": [
          50452,
          286,
          500,
          380,
          458,
          11,
          32422,
          366,
          2055,
          13,
          50548
        ]
      },
      {
        "avg_logprob": -0.18904897901746961,
        "compression_ratio": 1.8020134228187918,
        "end": 2288.12,
        "id": 786,
        "no_speech_prob": 0.00004198601527605206,
        "seek": 228364,
        "start": 2287.3199999999997,
        "temperature": 0,
        "text": " Turtle 2, right?",
        "tokens": [
          50548,
          48406,
          568,
          11,
          558,
          30,
          50588
        ]
      },
      {
        "avg_logprob": -0.18904897901746961,
        "compression_ratio": 1.8020134228187918,
        "end": 2289.24,
        "id": 787,
        "no_speech_prob": 0.00004198601527605206,
        "seek": 228364,
        "start": 2288.12,
        "temperature": 0,
        "text": " Okay, so you get the idea.",
        "tokens": [
          50588,
          1033,
          11,
          370,
          291,
          483,
          264,
          1558,
          13,
          50644
        ]
      },
      {
        "avg_logprob": -0.18904897901746961,
        "compression_ratio": 1.8020134228187918,
        "end": 2293.3199999999997,
        "id": 788,
        "no_speech_prob": 0.00004198601527605206,
        "seek": 228364,
        "start": 2289.24,
        "temperature": 0,
        "text": " I'm not going to try to make, clearly I'm not qualified to make up a list of words and scores.",
        "tokens": [
          50644,
          286,
          478,
          406,
          516,
          281,
          853,
          281,
          652,
          11,
          4448,
          286,
          478,
          406,
          15904,
          281,
          652,
          493,
          257,
          1329,
          295,
          2283,
          293,
          13444,
          13,
          50848
        ]
      },
      {
        "avg_logprob": -0.18904897901746961,
        "compression_ratio": 1.8020134228187918,
        "end": 2297.16,
        "id": 789,
        "no_speech_prob": 0.00004198601527605206,
        "seek": 228364,
        "start": 2293.3199999999997,
        "temperature": 0,
        "text": " So if you have this pre-made list of words, and these could be in any language,",
        "tokens": [
          50848,
          407,
          498,
          291,
          362,
          341,
          659,
          12,
          10341,
          1329,
          295,
          2283,
          11,
          293,
          613,
          727,
          312,
          294,
          604,
          2856,
          11,
          51040
        ]
      },
      {
        "avg_logprob": -0.18904897901746961,
        "compression_ratio": 1.8020134228187918,
        "end": 2299.48,
        "id": 790,
        "no_speech_prob": 0.00004198601527605206,
        "seek": 228364,
        "start": 2297.16,
        "temperature": 0,
        "text": " this is a particular list in the English language.",
        "tokens": [
          51040,
          341,
          307,
          257,
          1729,
          1329,
          294,
          264,
          3669,
          2856,
          13,
          51156
        ]
      },
      {
        "avg_logprob": -0.18904897901746961,
        "compression_ratio": 1.8020134228187918,
        "end": 2304.8399999999997,
        "id": 791,
        "no_speech_prob": 0.00004198601527605206,
        "seek": 228364,
        "start": 2300.44,
        "temperature": 0,
        "text": " And if you have thousands and thousands of them, then if you have a particular text",
        "tokens": [
          51204,
          400,
          498,
          291,
          362,
          5383,
          293,
          5383,
          295,
          552,
          11,
          550,
          498,
          291,
          362,
          257,
          1729,
          2487,
          51424
        ]
      },
      {
        "avg_logprob": -0.18904897901746961,
        "compression_ratio": 1.8020134228187918,
        "end": 2311.16,
        "id": 792,
        "no_speech_prob": 0.00004198601527605206,
        "seek": 228364,
        "start": 2305.96,
        "temperature": 0,
        "text": " with a lot of words in it, you could write a computer program to just look at each word",
        "tokens": [
          51480,
          365,
          257,
          688,
          295,
          2283,
          294,
          309,
          11,
          291,
          727,
          2464,
          257,
          3820,
          1461,
          281,
          445,
          574,
          412,
          1184,
          1349,
          51740
        ]
      },
      {
        "avg_logprob": -0.18904897901746961,
        "compression_ratio": 1.8020134228187918,
        "end": 2313.16,
        "id": 793,
        "no_speech_prob": 0.00004198601527605206,
        "seek": 228364,
        "start": 2311.16,
        "temperature": 0,
        "text": " and ask, is it in the list?",
        "tokens": [
          51740,
          293,
          1029,
          11,
          307,
          309,
          294,
          264,
          1329,
          30,
          51840
        ]
      },
      {
        "avg_logprob": -0.1765647207855419,
        "compression_ratio": 1.9541984732824427,
        "end": 2316.7599999999998,
        "id": 794,
        "no_speech_prob": 0.000047576333599863574,
        "seek": 231316,
        "start": 2313.16,
        "temperature": 0,
        "text": " If it's in the list, look up its score and add it to a running total.",
        "tokens": [
          50364,
          759,
          309,
          311,
          294,
          264,
          1329,
          11,
          574,
          493,
          1080,
          6175,
          293,
          909,
          309,
          281,
          257,
          2614,
          3217,
          13,
          50544
        ]
      },
      {
        "avg_logprob": -0.1765647207855419,
        "compression_ratio": 1.9541984732824427,
        "end": 2320.2,
        "id": 795,
        "no_speech_prob": 0.000047576333599863574,
        "seek": 231316,
        "start": 2316.7599999999998,
        "temperature": 0,
        "text": " And at the end, you're going to get some value, like you might get 27.",
        "tokens": [
          50544,
          400,
          412,
          264,
          917,
          11,
          291,
          434,
          516,
          281,
          483,
          512,
          2158,
          11,
          411,
          291,
          1062,
          483,
          7634,
          13,
          50716
        ]
      },
      {
        "avg_logprob": -0.1765647207855419,
        "compression_ratio": 1.9541984732824427,
        "end": 2322.44,
        "id": 796,
        "no_speech_prob": 0.000047576333599863574,
        "seek": 231316,
        "start": 2320.2,
        "temperature": 0,
        "text": " And it's going to be, that's going to be a positive.",
        "tokens": [
          50716,
          400,
          309,
          311,
          516,
          281,
          312,
          11,
          300,
          311,
          516,
          281,
          312,
          257,
          3353,
          13,
          50828
        ]
      },
      {
        "avg_logprob": -0.1765647207855419,
        "compression_ratio": 1.9541984732824427,
        "end": 2325.64,
        "id": 797,
        "no_speech_prob": 0.000047576333599863574,
        "seek": 231316,
        "start": 2322.44,
        "temperature": 0,
        "text": " This is a positive email, a positive tweet, positive essay.",
        "tokens": [
          50828,
          639,
          307,
          257,
          3353,
          3796,
          11,
          257,
          3353,
          15258,
          11,
          3353,
          16238,
          13,
          50988
        ]
      },
      {
        "avg_logprob": -0.1765647207855419,
        "compression_ratio": 1.9541984732824427,
        "end": 2327.48,
        "id": 798,
        "no_speech_prob": 0.000047576333599863574,
        "seek": 231316,
        "start": 2325.64,
        "temperature": 0,
        "text": " Or you might get negative 31.",
        "tokens": [
          50988,
          1610,
          291,
          1062,
          483,
          3671,
          10353,
          13,
          51080
        ]
      },
      {
        "avg_logprob": -0.1765647207855419,
        "compression_ratio": 1.9541984732824427,
        "end": 2329.16,
        "id": 799,
        "no_speech_prob": 0.000047576333599863574,
        "seek": 231316,
        "start": 2327.48,
        "temperature": 0,
        "text": " And this is very, very negative.",
        "tokens": [
          51080,
          400,
          341,
          307,
          588,
          11,
          588,
          3671,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1765647207855419,
        "compression_ratio": 1.9541984732824427,
        "end": 2331.3199999999997,
        "id": 800,
        "no_speech_prob": 0.000047576333599863574,
        "seek": 231316,
        "start": 2329.16,
        "temperature": 0,
        "text": " So you can get the total score.",
        "tokens": [
          51164,
          407,
          291,
          393,
          483,
          264,
          3217,
          6175,
          13,
          51272
        ]
      },
      {
        "avg_logprob": -0.1765647207855419,
        "compression_ratio": 1.9541984732824427,
        "end": 2333.96,
        "id": 801,
        "no_speech_prob": 0.000047576333599863574,
        "seek": 231316,
        "start": 2331.3199999999997,
        "temperature": 0,
        "text": " And you can also get what's known as the comparable score.",
        "tokens": [
          51272,
          400,
          291,
          393,
          611,
          483,
          437,
          311,
          2570,
          382,
          264,
          25323,
          6175,
          13,
          51404
        ]
      },
      {
        "avg_logprob": -0.1765647207855419,
        "compression_ratio": 1.9541984732824427,
        "end": 2334.68,
        "id": 802,
        "no_speech_prob": 0.000047576333599863574,
        "seek": 231316,
        "start": 2333.96,
        "temperature": 0,
        "text": " I think that's right.",
        "tokens": [
          51404,
          286,
          519,
          300,
          311,
          558,
          13,
          51440
        ]
      },
      {
        "avg_logprob": -0.1765647207855419,
        "compression_ratio": 1.9541984732824427,
        "end": 2335.64,
        "id": 803,
        "no_speech_prob": 0.000047576333599863574,
        "seek": 231316,
        "start": 2334.68,
        "temperature": 0,
        "text": " Comparable score.",
        "tokens": [
          51440,
          2432,
          42012,
          6175,
          13,
          51488
        ]
      },
      {
        "avg_logprob": -0.1765647207855419,
        "compression_ratio": 1.9541984732824427,
        "end": 2336.44,
        "id": 804,
        "no_speech_prob": 0.000047576333599863574,
        "seek": 231316,
        "start": 2335.64,
        "temperature": 0,
        "text": " What is that called?",
        "tokens": [
          51488,
          708,
          307,
          300,
          1219,
          30,
          51528
        ]
      },
      {
        "avg_logprob": -0.1765647207855419,
        "compression_ratio": 1.9541984732824427,
        "end": 2340.92,
        "id": 805,
        "no_speech_prob": 0.000047576333599863574,
        "seek": 231316,
        "start": 2340.2,
        "temperature": 0,
        "text": " Okay, wait, wait, wait.",
        "tokens": [
          51716,
          1033,
          11,
          1699,
          11,
          1699,
          11,
          1699,
          13,
          51752
        ]
      },
      {
        "avg_logprob": -0.1765647207855419,
        "compression_ratio": 1.9541984732824427,
        "end": 2341.72,
        "id": 806,
        "no_speech_prob": 0.000047576333599863574,
        "seek": 231316,
        "start": 2340.92,
        "temperature": 0,
        "text": " What's that called?",
        "tokens": [
          51752,
          708,
          311,
          300,
          1219,
          30,
          51792
        ]
      },
      {
        "avg_logprob": -0.25772934771598655,
        "compression_ratio": 1.532544378698225,
        "end": 2345,
        "id": 807,
        "no_speech_prob": 0.0005274739814922214,
        "seek": 234316,
        "start": 2343.96,
        "temperature": 0,
        "text": " I don't want to get it wrong.",
        "tokens": [
          50404,
          286,
          500,
          380,
          528,
          281,
          483,
          309,
          2085,
          13,
          50456
        ]
      },
      {
        "avg_logprob": -0.25772934771598655,
        "compression_ratio": 1.532544378698225,
        "end": 2346.92,
        "id": 808,
        "no_speech_prob": 0.0005274739814922214,
        "seek": 234316,
        "start": 2346.12,
        "temperature": 0,
        "text": " Comparable.",
        "tokens": [
          50512,
          2432,
          42012,
          13,
          50552
        ]
      },
      {
        "avg_logprob": -0.25772934771598655,
        "compression_ratio": 1.532544378698225,
        "end": 2348.92,
        "id": 809,
        "no_speech_prob": 0.0005274739814922214,
        "seek": 234316,
        "start": 2348.2,
        "temperature": 0,
        "text": " Comparable.",
        "tokens": [
          50616,
          2432,
          42012,
          13,
          50652
        ]
      },
      {
        "avg_logprob": -0.25772934771598655,
        "compression_ratio": 1.532544378698225,
        "end": 2354.68,
        "id": 810,
        "no_speech_prob": 0.0005274739814922214,
        "seek": 234316,
        "start": 2353.56,
        "temperature": 0,
        "text": " Oh, look, I'm going to look at this.",
        "tokens": [
          50884,
          876,
          11,
          574,
          11,
          286,
          478,
          516,
          281,
          574,
          412,
          341,
          13,
          50940
        ]
      },
      {
        "avg_logprob": -0.25772934771598655,
        "compression_ratio": 1.532544378698225,
        "end": 2356.6,
        "id": 811,
        "no_speech_prob": 0.0005274739814922214,
        "seek": 234316,
        "start": 2354.68,
        "temperature": 0,
        "text": " This is exactly, by the way, I've seen this web page before.",
        "tokens": [
          50940,
          639,
          307,
          2293,
          11,
          538,
          264,
          636,
          11,
          286,
          600,
          1612,
          341,
          3670,
          3028,
          949,
          13,
          51036
        ]
      },
      {
        "avg_logprob": -0.25772934771598655,
        "compression_ratio": 1.532544378698225,
        "end": 2357.7999999999997,
        "id": 812,
        "no_speech_prob": 0.0005274739814922214,
        "seek": 234316,
        "start": 2356.6,
        "temperature": 0,
        "text": " This is exactly what I'm going to build.",
        "tokens": [
          51036,
          639,
          307,
          2293,
          437,
          286,
          478,
          516,
          281,
          1322,
          13,
          51096
        ]
      },
      {
        "avg_logprob": -0.25772934771598655,
        "compression_ratio": 1.532544378698225,
        "end": 2360.7599999999998,
        "id": 813,
        "no_speech_prob": 0.0005274739814922214,
        "seek": 234316,
        "start": 2359.48,
        "temperature": 0,
        "text": " I am happy.",
        "tokens": [
          51180,
          286,
          669,
          2055,
          13,
          51244
        ]
      },
      {
        "avg_logprob": -0.25772934771598655,
        "compression_ratio": 1.532544378698225,
        "end": 2362.68,
        "id": 814,
        "no_speech_prob": 0.0005274739814922214,
        "seek": 234316,
        "start": 2361.8799999999997,
        "temperature": 0,
        "text": " Comparative.",
        "tokens": [
          51300,
          2432,
          2181,
          1166,
          13,
          51340
        ]
      },
      {
        "avg_logprob": -0.25772934771598655,
        "compression_ratio": 1.532544378698225,
        "end": 2363.3999999999996,
        "id": 815,
        "no_speech_prob": 0.0005274739814922214,
        "seek": 234316,
        "start": 2362.68,
        "temperature": 0,
        "text": " Why did I say?",
        "tokens": [
          51340,
          1545,
          630,
          286,
          584,
          30,
          51376
        ]
      },
      {
        "avg_logprob": -0.25772934771598655,
        "compression_ratio": 1.532544378698225,
        "end": 2371.16,
        "id": 816,
        "no_speech_prob": 0.0005274739814922214,
        "seek": 234316,
        "start": 2367.08,
        "temperature": 0,
        "text": " Okay, coming back to here.",
        "tokens": [
          51560,
          1033,
          11,
          1348,
          646,
          281,
          510,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2261227903694942,
        "compression_ratio": 1.5726141078838174,
        "end": 2376.04,
        "id": 817,
        "no_speech_prob": 0.00002046287409029901,
        "seek": 237316,
        "start": 2373.48,
        "temperature": 0,
        "text": " Okay, oh, camera's still on the whiteboard.",
        "tokens": [
          50380,
          1033,
          11,
          1954,
          11,
          2799,
          311,
          920,
          322,
          264,
          2418,
          3787,
          13,
          50508
        ]
      },
      {
        "avg_logprob": -0.2261227903694942,
        "compression_ratio": 1.5726141078838174,
        "end": 2377.56,
        "id": 818,
        "no_speech_prob": 0.00002046287409029901,
        "seek": 237316,
        "start": 2376.04,
        "temperature": 0,
        "text": " Sorry, everybody, but that's fine.",
        "tokens": [
          50508,
          4919,
          11,
          2201,
          11,
          457,
          300,
          311,
          2489,
          13,
          50584
        ]
      },
      {
        "avg_logprob": -0.2261227903694942,
        "compression_ratio": 1.5726141078838174,
        "end": 2379,
        "id": 819,
        "no_speech_prob": 0.00002046287409029901,
        "seek": 237316,
        "start": 2377.56,
        "temperature": 0,
        "text": " I was just looking something up.",
        "tokens": [
          50584,
          286,
          390,
          445,
          1237,
          746,
          493,
          13,
          50656
        ]
      },
      {
        "avg_logprob": -0.2261227903694942,
        "compression_ratio": 1.5726141078838174,
        "end": 2379.96,
        "id": 820,
        "no_speech_prob": 0.00002046287409029901,
        "seek": 237316,
        "start": 2379,
        "temperature": 0,
        "text": " Comparative.",
        "tokens": [
          50656,
          2432,
          2181,
          1166,
          13,
          50704
        ]
      },
      {
        "avg_logprob": -0.2261227903694942,
        "compression_ratio": 1.5726141078838174,
        "end": 2381.48,
        "id": 821,
        "no_speech_prob": 0.00002046287409029901,
        "seek": 237316,
        "start": 2379.96,
        "temperature": 0,
        "text": " I don't know why I said comparable.",
        "tokens": [
          50704,
          286,
          500,
          380,
          458,
          983,
          286,
          848,
          25323,
          13,
          50780
        ]
      },
      {
        "avg_logprob": -0.2261227903694942,
        "compression_ratio": 1.5726141078838174,
        "end": 2385.8799999999997,
        "id": 822,
        "no_speech_prob": 0.00002046287409029901,
        "seek": 237316,
        "start": 2382.44,
        "temperature": 0,
        "text": " So thank you, Mattheo, for being a master editor.",
        "tokens": [
          50828,
          407,
          1309,
          291,
          11,
          6789,
          3322,
          78,
          11,
          337,
          885,
          257,
          4505,
          9839,
          13,
          51000
        ]
      },
      {
        "avg_logprob": -0.2261227903694942,
        "compression_ratio": 1.5726141078838174,
        "end": 2389.7999999999997,
        "id": 823,
        "no_speech_prob": 0.00002046287409029901,
        "seek": 237316,
        "start": 2387.24,
        "temperature": 0,
        "text": " I would basically have to quit doing this if it wasn't for you.",
        "tokens": [
          51068,
          286,
          576,
          1936,
          362,
          281,
          10366,
          884,
          341,
          498,
          309,
          2067,
          380,
          337,
          291,
          13,
          51196
        ]
      },
      {
        "avg_logprob": -0.2261227903694942,
        "compression_ratio": 1.5726141078838174,
        "end": 2390.04,
        "id": 824,
        "no_speech_prob": 0.00002046287409029901,
        "seek": 237316,
        "start": 2389.7999999999997,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51196,
          1033,
          13,
          51208
        ]
      },
      {
        "avg_logprob": -0.2261227903694942,
        "compression_ratio": 1.5726141078838174,
        "end": 2400.04,
        "id": 825,
        "no_speech_prob": 0.00002046287409029901,
        "seek": 237316,
        "start": 2397.7999999999997,
        "temperature": 0,
        "text": " So this is what would be known as the total score.",
        "tokens": [
          51596,
          407,
          341,
          307,
          437,
          576,
          312,
          2570,
          382,
          264,
          3217,
          6175,
          13,
          51708
        ]
      },
      {
        "avg_logprob": -0.2261227903694942,
        "compression_ratio": 1.5726141078838174,
        "end": 2402.04,
        "id": 826,
        "no_speech_prob": 0.00002046287409029901,
        "seek": 237316,
        "start": 2400.04,
        "temperature": 0,
        "text": " But you can also look at the comparative score.",
        "tokens": [
          51708,
          583,
          291,
          393,
          611,
          574,
          412,
          264,
          39292,
          6175,
          13,
          51808
        ]
      },
      {
        "avg_logprob": -0.20327399540873406,
        "compression_ratio": 1.6566523605150214,
        "end": 2406.92,
        "id": 827,
        "no_speech_prob": 0.0001420229091309011,
        "seek": 240204,
        "start": 2403,
        "temperature": 0,
        "text": " Just because you have a really long document with the word happy in it a lot of times,",
        "tokens": [
          50412,
          1449,
          570,
          291,
          362,
          257,
          534,
          938,
          4166,
          365,
          264,
          1349,
          2055,
          294,
          309,
          257,
          688,
          295,
          1413,
          11,
          50608
        ]
      },
      {
        "avg_logprob": -0.20327399540873406,
        "compression_ratio": 1.6566523605150214,
        "end": 2411.56,
        "id": 828,
        "no_speech_prob": 0.0001420229091309011,
        "seek": 240204,
        "start": 2406.92,
        "temperature": 0,
        "text": " is that more positive than a short document with the word happy in it fewer times?",
        "tokens": [
          50608,
          307,
          300,
          544,
          3353,
          813,
          257,
          2099,
          4166,
          365,
          264,
          1349,
          2055,
          294,
          309,
          13366,
          1413,
          30,
          50840
        ]
      },
      {
        "avg_logprob": -0.20327399540873406,
        "compression_ratio": 1.6566523605150214,
        "end": 2419.32,
        "id": 829,
        "no_speech_prob": 0.0001420229091309011,
        "seek": 240204,
        "start": 2411.56,
        "temperature": 0,
        "text": " So the comparative score would be the total score divided by the total number of words.",
        "tokens": [
          50840,
          407,
          264,
          39292,
          6175,
          576,
          312,
          264,
          3217,
          6175,
          6666,
          538,
          264,
          3217,
          1230,
          295,
          2283,
          13,
          51228
        ]
      },
      {
        "avg_logprob": -0.20327399540873406,
        "compression_ratio": 1.6566523605150214,
        "end": 2423.48,
        "id": 830,
        "no_speech_prob": 0.0001420229091309011,
        "seek": 240204,
        "start": 2420.92,
        "temperature": 0,
        "text": " Okay, so this is exactly what I want to implement.",
        "tokens": [
          51308,
          1033,
          11,
          370,
          341,
          307,
          2293,
          437,
          286,
          528,
          281,
          4445,
          13,
          51436
        ]
      },
      {
        "avg_logprob": -0.20327399540873406,
        "compression_ratio": 1.6566523605150214,
        "end": 2425.08,
        "id": 831,
        "no_speech_prob": 0.0001420229091309011,
        "seek": 240204,
        "start": 2423.48,
        "temperature": 0,
        "text": " So let's look back here.",
        "tokens": [
          51436,
          407,
          718,
          311,
          574,
          646,
          510,
          13,
          51516
        ]
      },
      {
        "avg_logprob": -0.20327399540873406,
        "compression_ratio": 1.6566523605150214,
        "end": 2425.56,
        "id": 832,
        "no_speech_prob": 0.0001420229091309011,
        "seek": 240204,
        "start": 2425.08,
        "temperature": 0,
        "text": " Sorry.",
        "tokens": [
          51516,
          4919,
          13,
          51540
        ]
      },
      {
        "avg_logprob": -0.20327399540873406,
        "compression_ratio": 1.6566523605150214,
        "end": 2429.48,
        "id": 833,
        "no_speech_prob": 0.0001420229091309011,
        "seek": 240204,
        "start": 2425.56,
        "temperature": 0,
        "text": " So the AFIN111 is a particular list of words.",
        "tokens": [
          51540,
          407,
          264,
          20389,
          1464,
          5348,
          16,
          307,
          257,
          1729,
          1329,
          295,
          2283,
          13,
          51736
        ]
      },
      {
        "avg_logprob": -0.18187445402145386,
        "compression_ratio": 1.654867256637168,
        "end": 2433,
        "id": 834,
        "no_speech_prob": 0.0340975783765316,
        "seek": 242948,
        "start": 2430.44,
        "temperature": 0,
        "text": " This was manually made by Finn Arup-Nielsen.",
        "tokens": [
          50412,
          639,
          390,
          16945,
          1027,
          538,
          21066,
          316,
          11976,
          12,
          45,
          1187,
          6748,
          13,
          50540
        ]
      },
      {
        "avg_logprob": -0.18187445402145386,
        "compression_ratio": 1.654867256637168,
        "end": 2436.44,
        "id": 835,
        "no_speech_prob": 0.0340975783765316,
        "seek": 242948,
        "start": 2433.56,
        "temperature": 0,
        "text": " You can imagine what kind of research and thought went into this.",
        "tokens": [
          50568,
          509,
          393,
          3811,
          437,
          733,
          295,
          2132,
          293,
          1194,
          1437,
          666,
          341,
          13,
          50712
        ]
      },
      {
        "avg_logprob": -0.18187445402145386,
        "compression_ratio": 1.654867256637168,
        "end": 2439.16,
        "id": 836,
        "no_speech_prob": 0.0340975783765316,
        "seek": 242948,
        "start": 2437.08,
        "temperature": 0,
        "text": " And I encourage you to read the paper.",
        "tokens": [
          50744,
          400,
          286,
          5373,
          291,
          281,
          1401,
          264,
          3035,
          13,
          50848
        ]
      },
      {
        "avg_logprob": -0.18187445402145386,
        "compression_ratio": 1.654867256637168,
        "end": 2442.76,
        "id": 837,
        "no_speech_prob": 0.0340975783765316,
        "seek": 242948,
        "start": 2439.16,
        "temperature": 0,
        "text": " And also, if you use this list, you should also reference the paper.",
        "tokens": [
          50848,
          400,
          611,
          11,
          498,
          291,
          764,
          341,
          1329,
          11,
          291,
          820,
          611,
          6408,
          264,
          3035,
          13,
          51028
        ]
      },
      {
        "avg_logprob": -0.18187445402145386,
        "compression_ratio": 1.654867256637168,
        "end": 2446.84,
        "id": 838,
        "no_speech_prob": 0.0340975783765316,
        "seek": 242948,
        "start": 2442.76,
        "temperature": 0,
        "text": " And everything is on this website, which is linked in this video's description.",
        "tokens": [
          51028,
          400,
          1203,
          307,
          322,
          341,
          3144,
          11,
          597,
          307,
          9408,
          294,
          341,
          960,
          311,
          3855,
          13,
          51232
        ]
      },
      {
        "avg_logprob": -0.18187445402145386,
        "compression_ratio": 1.654867256637168,
        "end": 2448.92,
        "id": 839,
        "no_speech_prob": 0.0340975783765316,
        "seek": 242948,
        "start": 2446.84,
        "temperature": 0,
        "text": " Okay, so what I'm going to actually do is just download it.",
        "tokens": [
          51232,
          1033,
          11,
          370,
          437,
          286,
          478,
          516,
          281,
          767,
          360,
          307,
          445,
          5484,
          309,
          13,
          51336
        ]
      },
      {
        "avg_logprob": -0.18187445402145386,
        "compression_ratio": 1.654867256637168,
        "end": 2450.52,
        "id": 840,
        "no_speech_prob": 0.0340975783765316,
        "seek": 242948,
        "start": 2448.92,
        "temperature": 0,
        "text": " Oh, I've already downloaded it.",
        "tokens": [
          51336,
          876,
          11,
          286,
          600,
          1217,
          21748,
          309,
          13,
          51416
        ]
      },
      {
        "avg_logprob": -0.18187445402145386,
        "compression_ratio": 1.654867256637168,
        "end": 2452.28,
        "id": 841,
        "no_speech_prob": 0.0340975783765316,
        "seek": 242948,
        "start": 2450.52,
        "temperature": 0,
        "text": " I did that before it started.",
        "tokens": [
          51416,
          286,
          630,
          300,
          949,
          309,
          1409,
          13,
          51504
        ]
      },
      {
        "avg_logprob": -0.18187445402145386,
        "compression_ratio": 1.654867256637168,
        "end": 2453.08,
        "id": 842,
        "no_speech_prob": 0.0340975783765316,
        "seek": 242948,
        "start": 2452.28,
        "temperature": 0,
        "text": " It's like a cooking show.",
        "tokens": [
          51504,
          467,
          311,
          411,
          257,
          6361,
          855,
          13,
          51544
        ]
      },
      {
        "avg_logprob": -0.18187445402145386,
        "compression_ratio": 1.654867256637168,
        "end": 2456.68,
        "id": 843,
        "no_speech_prob": 0.0340975783765316,
        "seek": 242948,
        "start": 2453.8,
        "temperature": 0,
        "text": " Here's my AFIN111 list, except this is a fan.",
        "tokens": [
          51580,
          1692,
          311,
          452,
          20389,
          1464,
          5348,
          16,
          1329,
          11,
          3993,
          341,
          307,
          257,
          3429,
          13,
          51724
        ]
      },
      {
        "avg_logprob": -0.18187445402145386,
        "compression_ratio": 1.654867256637168,
        "end": 2459.32,
        "id": 844,
        "no_speech_prob": 0.0340975783765316,
        "seek": 242948,
        "start": 2456.68,
        "temperature": 0,
        "text": " By the way, isn't it random that I just, like, underneath this desk,",
        "tokens": [
          51724,
          3146,
          264,
          636,
          11,
          1943,
          380,
          309,
          4974,
          300,
          286,
          445,
          11,
          411,
          11,
          7223,
          341,
          10026,
          11,
          51856
        ]
      },
      {
        "avg_logprob": -0.23214747266071598,
        "compression_ratio": 1.7473309608540926,
        "end": 2460.6,
        "id": 845,
        "no_speech_prob": 0.00001644245821807999,
        "seek": 245948,
        "start": 2460.44,
        "temperature": 0,
        "text": " I have a monitor?",
        "tokens": [
          50412,
          286,
          362,
          257,
          6002,
          30,
          50420
        ]
      },
      {
        "avg_logprob": -0.23214747266071598,
        "compression_ratio": 1.7473309608540926,
        "end": 2461.48,
        "id": 846,
        "no_speech_prob": 0.00001644245821807999,
        "seek": 245948,
        "start": 2460.6,
        "temperature": 0,
        "text": " What else do I have?",
        "tokens": [
          50420,
          708,
          1646,
          360,
          286,
          362,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.23214747266071598,
        "compression_ratio": 1.7473309608540926,
        "end": 2463.08,
        "id": 847,
        "no_speech_prob": 0.00001644245821807999,
        "seek": 245948,
        "start": 2462.12,
        "temperature": 0,
        "text": " Nothing is the sad thing.",
        "tokens": [
          50496,
          6693,
          307,
          264,
          4227,
          551,
          13,
          50544
        ]
      },
      {
        "avg_logprob": -0.23214747266071598,
        "compression_ratio": 1.7473309608540926,
        "end": 2463.88,
        "id": 848,
        "no_speech_prob": 0.00001644245821807999,
        "seek": 245948,
        "start": 2463.08,
        "temperature": 0,
        "text": " Oh, watch this, though.",
        "tokens": [
          50544,
          876,
          11,
          1159,
          341,
          11,
          1673,
          13,
          50584
        ]
      },
      {
        "avg_logprob": -0.23214747266071598,
        "compression_ratio": 1.7473309608540926,
        "end": 2466.04,
        "id": 849,
        "no_speech_prob": 0.00001644245821807999,
        "seek": 245948,
        "start": 2464.52,
        "temperature": 0,
        "text": " I have another fan.",
        "tokens": [
          50616,
          286,
          362,
          1071,
          3429,
          13,
          50692
        ]
      },
      {
        "avg_logprob": -0.23214747266071598,
        "compression_ratio": 1.7473309608540926,
        "end": 2468.92,
        "id": 850,
        "no_speech_prob": 0.00001644245821807999,
        "seek": 245948,
        "start": 2466.04,
        "temperature": 0,
        "text": " It's just like, in here, I have a magical, oh, look at this.",
        "tokens": [
          50692,
          467,
          311,
          445,
          411,
          11,
          294,
          510,
          11,
          286,
          362,
          257,
          12066,
          11,
          1954,
          11,
          574,
          412,
          341,
          13,
          50836
        ]
      },
      {
        "avg_logprob": -0.23214747266071598,
        "compression_ratio": 1.7473309608540926,
        "end": 2469.56,
        "id": 851,
        "no_speech_prob": 0.00001644245821807999,
        "seek": 245948,
        "start": 2468.92,
        "temperature": 0,
        "text": " Look at this.",
        "tokens": [
          50836,
          2053,
          412,
          341,
          13,
          50868
        ]
      },
      {
        "avg_logprob": -0.23214747266071598,
        "compression_ratio": 1.7473309608540926,
        "end": 2471.16,
        "id": 852,
        "no_speech_prob": 0.00001644245821807999,
        "seek": 245948,
        "start": 2469.56,
        "temperature": 0,
        "text": " Over here, I have a monitor.",
        "tokens": [
          50868,
          4886,
          510,
          11,
          286,
          362,
          257,
          6002,
          13,
          50948
        ]
      },
      {
        "avg_logprob": -0.23214747266071598,
        "compression_ratio": 1.7473309608540926,
        "end": 2473.08,
        "id": 853,
        "no_speech_prob": 0.00001644245821807999,
        "seek": 245948,
        "start": 2472.2,
        "temperature": 0,
        "text": " There's lots of stuff.",
        "tokens": [
          51000,
          821,
          311,
          3195,
          295,
          1507,
          13,
          51044
        ]
      },
      {
        "avg_logprob": -0.23214747266071598,
        "compression_ratio": 1.7473309608540926,
        "end": 2478.12,
        "id": 854,
        "no_speech_prob": 0.00001644245821807999,
        "seek": 245948,
        "start": 2473.08,
        "temperature": 0,
        "text": " It's like a magical bag of things that people are telling me to concentrate.",
        "tokens": [
          51044,
          467,
          311,
          411,
          257,
          12066,
          3411,
          295,
          721,
          300,
          561,
          366,
          3585,
          385,
          281,
          18089,
          13,
          51296
        ]
      },
      {
        "avg_logprob": -0.23214747266071598,
        "compression_ratio": 1.7473309608540926,
        "end": 2479.4,
        "id": 855,
        "no_speech_prob": 0.00001644245821807999,
        "seek": 245948,
        "start": 2478.12,
        "temperature": 0,
        "text": " I don't do a good job of that.",
        "tokens": [
          51296,
          286,
          500,
          380,
          360,
          257,
          665,
          1691,
          295,
          300,
          13,
          51360
        ]
      },
      {
        "avg_logprob": -0.23214747266071598,
        "compression_ratio": 1.7473309608540926,
        "end": 2481.72,
        "id": 856,
        "no_speech_prob": 0.00001644245821807999,
        "seek": 245948,
        "start": 2479.4,
        "temperature": 0,
        "text": " Okay, so I've already downloaded this list.",
        "tokens": [
          51360,
          1033,
          11,
          370,
          286,
          600,
          1217,
          21748,
          341,
          1329,
          13,
          51476
        ]
      },
      {
        "avg_logprob": -0.23214747266071598,
        "compression_ratio": 1.7473309608540926,
        "end": 2484.44,
        "id": 857,
        "no_speech_prob": 0.00001644245821807999,
        "seek": 245948,
        "start": 2481.72,
        "temperature": 0,
        "text": " I can't pull it out, and let's go take a look at it.",
        "tokens": [
          51476,
          286,
          393,
          380,
          2235,
          309,
          484,
          11,
          293,
          718,
          311,
          352,
          747,
          257,
          574,
          412,
          309,
          13,
          51612
        ]
      },
      {
        "avg_logprob": -0.23214747266071598,
        "compression_ratio": 1.7473309608540926,
        "end": 2486.2,
        "id": 858,
        "no_speech_prob": 0.00001644245821807999,
        "seek": 245948,
        "start": 2484.44,
        "temperature": 0,
        "text": " So where would it be?",
        "tokens": [
          51612,
          407,
          689,
          576,
          309,
          312,
          30,
          51700
        ]
      },
      {
        "avg_logprob": -0.23214747266071598,
        "compression_ratio": 1.7473309608540926,
        "end": 2488.04,
        "id": 859,
        "no_speech_prob": 0.00001644245821807999,
        "seek": 245948,
        "start": 2486.2,
        "temperature": 0,
        "text": " It would be in my downloads.",
        "tokens": [
          51700,
          467,
          576,
          312,
          294,
          452,
          36553,
          13,
          51792
        ]
      },
      {
        "avg_logprob": -0.2158168156941732,
        "compression_ratio": 1.8482490272373542,
        "end": 2489.8,
        "id": 860,
        "no_speech_prob": 0.00005391055310610682,
        "seek": 248804,
        "start": 2488.04,
        "temperature": 0,
        "text": " And here it is under AFIN111.",
        "tokens": [
          50364,
          400,
          510,
          309,
          307,
          833,
          20389,
          1464,
          5348,
          16,
          13,
          50452
        ]
      },
      {
        "avg_logprob": -0.2158168156941732,
        "compression_ratio": 1.8482490272373542,
        "end": 2494.04,
        "id": 861,
        "no_speech_prob": 0.00005391055310610682,
        "seek": 248804,
        "start": 2489.8,
        "temperature": 0,
        "text": " So here, I'm going to open this up, and we can take a look at this list.",
        "tokens": [
          50452,
          407,
          510,
          11,
          286,
          478,
          516,
          281,
          1269,
          341,
          493,
          11,
          293,
          321,
          393,
          747,
          257,
          574,
          412,
          341,
          1329,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2158168156941732,
        "compression_ratio": 1.8482490272373542,
        "end": 2501.24,
        "id": 862,
        "no_speech_prob": 0.00005391055310610682,
        "seek": 248804,
        "start": 2496.92,
        "temperature": 0,
        "text": " So you can see this has several thousand words, and you can see abandon being negative two,",
        "tokens": [
          50808,
          407,
          291,
          393,
          536,
          341,
          575,
          2940,
          4714,
          2283,
          11,
          293,
          291,
          393,
          536,
          9072,
          885,
          3671,
          732,
          11,
          51024
        ]
      },
      {
        "avg_logprob": -0.2158168156941732,
        "compression_ratio": 1.8482490272373542,
        "end": 2507.72,
        "id": 863,
        "no_speech_prob": 0.00005391055310610682,
        "seek": 248804,
        "start": 2501.24,
        "temperature": 0,
        "text": " abandon negative two, et cetera, et cetera, et cetera, compelled one, congratulations two,",
        "tokens": [
          51024,
          9072,
          3671,
          732,
          11,
          1030,
          11458,
          11,
          1030,
          11458,
          11,
          1030,
          11458,
          11,
          40021,
          472,
          11,
          13568,
          732,
          11,
          51348
        ]
      },
      {
        "avg_logprob": -0.2158168156941732,
        "compression_ratio": 1.8482490272373542,
        "end": 2508.04,
        "id": 864,
        "no_speech_prob": 0.00005391055310610682,
        "seek": 248804,
        "start": 2507.72,
        "temperature": 0,
        "text": " et cetera.",
        "tokens": [
          51348,
          1030,
          11458,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2158168156941732,
        "compression_ratio": 1.8482490272373542,
        "end": 2510.04,
        "id": 865,
        "no_speech_prob": 0.00005391055310610682,
        "seek": 248804,
        "start": 2508.04,
        "temperature": 0,
        "text": " You can see here all the words and all their scores.",
        "tokens": [
          51364,
          509,
          393,
          536,
          510,
          439,
          264,
          2283,
          293,
          439,
          641,
          13444,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2158168156941732,
        "compression_ratio": 1.8482490272373542,
        "end": 2511.56,
        "id": 866,
        "no_speech_prob": 0.00005391055310610682,
        "seek": 248804,
        "start": 2510.04,
        "temperature": 0,
        "text": " I can scroll through the whole thing.",
        "tokens": [
          51464,
          286,
          393,
          11369,
          807,
          264,
          1379,
          551,
          13,
          51540
        ]
      },
      {
        "avg_logprob": -0.2158168156941732,
        "compression_ratio": 1.8482490272373542,
        "end": 2514.84,
        "id": 867,
        "no_speech_prob": 0.00005391055310610682,
        "seek": 248804,
        "start": 2511.56,
        "temperature": 0,
        "text": " So the first thing that I want to do in this challenge, I think, is it would be so much",
        "tokens": [
          51540,
          407,
          264,
          700,
          551,
          300,
          286,
          528,
          281,
          360,
          294,
          341,
          3430,
          11,
          286,
          519,
          11,
          307,
          309,
          576,
          312,
          370,
          709,
          51704
        ]
      },
      {
        "avg_logprob": -0.14271779920234054,
        "compression_ratio": 1.6627906976744187,
        "end": 2520.52,
        "id": 868,
        "no_speech_prob": 0.07585230469703674,
        "seek": 251484,
        "start": 2514.84,
        "temperature": 0,
        "text": " more convenient if this text file was actually a JSON file.",
        "tokens": [
          50364,
          544,
          10851,
          498,
          341,
          2487,
          3991,
          390,
          767,
          257,
          31828,
          3991,
          13,
          50648
        ]
      },
      {
        "avg_logprob": -0.14271779920234054,
        "compression_ratio": 1.6627906976744187,
        "end": 2523.2400000000002,
        "id": 869,
        "no_speech_prob": 0.07585230469703674,
        "seek": 251484,
        "start": 2520.52,
        "temperature": 0,
        "text": " So let's write a little quick program to convert it to JSON.",
        "tokens": [
          50648,
          407,
          718,
          311,
          2464,
          257,
          707,
          1702,
          1461,
          281,
          7620,
          309,
          281,
          31828,
          13,
          50784
        ]
      },
      {
        "avg_logprob": -0.14271779920234054,
        "compression_ratio": 1.6627906976744187,
        "end": 2527,
        "id": 870,
        "no_speech_prob": 0.07585230469703674,
        "seek": 251484,
        "start": 2523.2400000000002,
        "temperature": 0,
        "text": " I could do that in like Node or Python or something, but I'm going to somewhat absurdly",
        "tokens": [
          50784,
          286,
          727,
          360,
          300,
          294,
          411,
          38640,
          420,
          15329,
          420,
          746,
          11,
          457,
          286,
          478,
          516,
          281,
          8344,
          19774,
          356,
          50972
        ]
      },
      {
        "avg_logprob": -0.14271779920234054,
        "compression_ratio": 1.6627906976744187,
        "end": 2529.32,
        "id": 871,
        "no_speech_prob": 0.07585230469703674,
        "seek": 251484,
        "start": 2527.88,
        "temperature": 0,
        "text": " just do this in the browser.",
        "tokens": [
          51016,
          445,
          360,
          341,
          294,
          264,
          11185,
          13,
          51088
        ]
      },
      {
        "avg_logprob": -0.14271779920234054,
        "compression_ratio": 1.6627906976744187,
        "end": 2533.88,
        "id": 872,
        "no_speech_prob": 0.07585230469703674,
        "seek": 251484,
        "start": 2529.32,
        "temperature": 0,
        "text": " So first, what I want to do is I need to get this list, and I need to go to my folder that",
        "tokens": [
          51088,
          407,
          700,
          11,
          437,
          286,
          528,
          281,
          360,
          307,
          286,
          643,
          281,
          483,
          341,
          1329,
          11,
          293,
          286,
          643,
          281,
          352,
          281,
          452,
          10820,
          300,
          51316
        ]
      },
      {
        "avg_logprob": -0.14271779920234054,
        "compression_ratio": 1.6627906976744187,
        "end": 2538.1200000000003,
        "id": 873,
        "no_speech_prob": 0.07585230469703674,
        "seek": 251484,
        "start": 2533.88,
        "temperature": 0,
        "text": " has my code, and I'm going to paste it in here.",
        "tokens": [
          51316,
          575,
          452,
          3089,
          11,
          293,
          286,
          478,
          516,
          281,
          9163,
          309,
          294,
          510,
          13,
          51528
        ]
      },
      {
        "avg_logprob": -0.14271779920234054,
        "compression_ratio": 1.6627906976744187,
        "end": 2540.92,
        "id": 874,
        "no_speech_prob": 0.07585230469703674,
        "seek": 251484,
        "start": 2538.1200000000003,
        "temperature": 0,
        "text": " So right now, I have a folder that has an HTML file.",
        "tokens": [
          51528,
          407,
          558,
          586,
          11,
          286,
          362,
          257,
          10820,
          300,
          575,
          364,
          17995,
          3991,
          13,
          51668
        ]
      },
      {
        "avg_logprob": -0.19743642880935078,
        "compression_ratio": 1.6692015209125475,
        "end": 2546.76,
        "id": 875,
        "no_speech_prob": 0.0006986688822507858,
        "seek": 254092,
        "start": 2540.92,
        "temperature": 0,
        "text": " I have a libraries folder because I'm using the p5.js and the p5.dom library, and sketch.js",
        "tokens": [
          50364,
          286,
          362,
          257,
          15148,
          10820,
          570,
          286,
          478,
          1228,
          264,
          280,
          20,
          13,
          25530,
          293,
          264,
          280,
          20,
          13,
          4121,
          6405,
          11,
          293,
          12325,
          13,
          25530,
          50656
        ]
      },
      {
        "avg_logprob": -0.19743642880935078,
        "compression_ratio": 1.6692015209125475,
        "end": 2548.84,
        "id": 876,
        "no_speech_prob": 0.0006986688822507858,
        "seek": 254092,
        "start": 2546.76,
        "temperature": 0,
        "text": " is where I'm going to have my JavaScript code.",
        "tokens": [
          50656,
          307,
          689,
          286,
          478,
          516,
          281,
          362,
          452,
          15778,
          3089,
          13,
          50760
        ]
      },
      {
        "avg_logprob": -0.19743642880935078,
        "compression_ratio": 1.6692015209125475,
        "end": 2552.52,
        "id": 877,
        "no_speech_prob": 0.0006986688822507858,
        "seek": 254092,
        "start": 2549.4,
        "temperature": 0,
        "text": " OK, so now what I want to do is, so here's the thing.",
        "tokens": [
          50788,
          2264,
          11,
          370,
          586,
          437,
          286,
          528,
          281,
          360,
          307,
          11,
          370,
          510,
          311,
          264,
          551,
          13,
          50944
        ]
      },
      {
        "avg_logprob": -0.19743642880935078,
        "compression_ratio": 1.6692015209125475,
        "end": 2558.52,
        "id": 878,
        "no_speech_prob": 0.0006986688822507858,
        "seek": 254092,
        "start": 2553.2400000000002,
        "temperature": 0,
        "text": " This file, which I can load up here, this is actually, I'm almost certain, is a tab",
        "tokens": [
          50980,
          639,
          3991,
          11,
          597,
          286,
          393,
          3677,
          493,
          510,
          11,
          341,
          307,
          767,
          11,
          286,
          478,
          1920,
          1629,
          11,
          307,
          257,
          4421,
          51244
        ]
      },
      {
        "avg_logprob": -0.19743642880935078,
        "compression_ratio": 1.6692015209125475,
        "end": 2565.2400000000002,
        "id": 879,
        "no_speech_prob": 0.0006986688822507858,
        "seek": 254092,
        "start": 2558.52,
        "temperature": 0,
        "text": " delimited file, meaning each word, the format of this file is word tab score.",
        "tokens": [
          51244,
          1103,
          332,
          1226,
          3991,
          11,
          3620,
          1184,
          1349,
          11,
          264,
          7877,
          295,
          341,
          3991,
          307,
          1349,
          4421,
          6175,
          13,
          51580
        ]
      },
      {
        "avg_logprob": -0.19743642880935078,
        "compression_ratio": 1.6692015209125475,
        "end": 2570.12,
        "id": 880,
        "no_speech_prob": 0.0006986688822507858,
        "seek": 254092,
        "start": 2565.2400000000002,
        "temperature": 0,
        "text": " So there's a variety of ways I could parse this, and this may not actually work, but",
        "tokens": [
          51580,
          407,
          456,
          311,
          257,
          5673,
          295,
          2098,
          286,
          727,
          48377,
          341,
          11,
          293,
          341,
          815,
          406,
          767,
          589,
          11,
          457,
          51824
        ]
      },
      {
        "avg_logprob": -0.18517747132674509,
        "compression_ratio": 1.6206896551724137,
        "end": 2576.92,
        "id": 881,
        "no_speech_prob": 0.0016229457687586546,
        "seek": 257012,
        "start": 2570.12,
        "temperature": 0,
        "text": " let's test the p5.js library and see if load table works with this file.",
        "tokens": [
          50364,
          718,
          311,
          1500,
          264,
          280,
          20,
          13,
          25530,
          6405,
          293,
          536,
          498,
          3677,
          3199,
          1985,
          365,
          341,
          3991,
          13,
          50704
        ]
      },
      {
        "avg_logprob": -0.18517747132674509,
        "compression_ratio": 1.6206896551724137,
        "end": 2583.24,
        "id": 882,
        "no_speech_prob": 0.0016229457687586546,
        "seek": 257012,
        "start": 2577.48,
        "temperature": 0,
        "text": " So what I'm going to do is go back to my code, and I'm going to say var table,",
        "tokens": [
          50732,
          407,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          352,
          646,
          281,
          452,
          3089,
          11,
          293,
          286,
          478,
          516,
          281,
          584,
          1374,
          3199,
          11,
          51020
        ]
      },
      {
        "avg_logprob": -0.18517747132674509,
        "compression_ratio": 1.6206896551724137,
        "end": 2590.2,
        "id": 883,
        "no_speech_prob": 0.0016229457687586546,
        "seek": 257012,
        "start": 2584.52,
        "temperature": 0,
        "text": " function pre, I'm going to use preload, which is a function that I can use to make sure",
        "tokens": [
          51084,
          2445,
          659,
          11,
          286,
          478,
          516,
          281,
          764,
          659,
          2907,
          11,
          597,
          307,
          257,
          2445,
          300,
          286,
          393,
          764,
          281,
          652,
          988,
          51368
        ]
      },
      {
        "avg_logprob": -0.18517747132674509,
        "compression_ratio": 1.6206896551724137,
        "end": 2596.6,
        "id": 884,
        "no_speech_prob": 0.0016229457687586546,
        "seek": 257012,
        "start": 2590.2,
        "temperature": 0,
        "text": " certain images or media or data files are loaded before the page, the sketch even begins.",
        "tokens": [
          51368,
          1629,
          5267,
          420,
          3021,
          420,
          1412,
          7098,
          366,
          13210,
          949,
          264,
          3028,
          11,
          264,
          12325,
          754,
          7338,
          13,
          51688
        ]
      },
      {
        "avg_logprob": -0.21007553411989796,
        "compression_ratio": 1.5,
        "end": 2604.68,
        "id": 885,
        "no_speech_prob": 0.0029809593688696623,
        "seek": 259660,
        "start": 2597.3199999999997,
        "temperature": 0,
        "text": " Load table, and then I need to give it the file name, afin111.txt, and then I'm just",
        "tokens": [
          50400,
          48408,
          3199,
          11,
          293,
          550,
          286,
          643,
          281,
          976,
          309,
          264,
          3991,
          1315,
          11,
          3238,
          259,
          5348,
          16,
          13,
          83,
          734,
          11,
          293,
          550,
          286,
          478,
          445,
          50768
        ]
      },
      {
        "avg_logprob": -0.21007553411989796,
        "compression_ratio": 1.5,
        "end": 2609.3199999999997,
        "id": 886,
        "no_speech_prob": 0.0029809593688696623,
        "seek": 259660,
        "start": 2604.68,
        "temperature": 0,
        "text": " going to say console.log table, and let's see what happens.",
        "tokens": [
          50768,
          516,
          281,
          584,
          11076,
          13,
          4987,
          3199,
          11,
          293,
          718,
          311,
          536,
          437,
          2314,
          13,
          51000
        ]
      },
      {
        "avg_logprob": -0.21007553411989796,
        "compression_ratio": 1.5,
        "end": 2613.4,
        "id": 887,
        "no_speech_prob": 0.0029809593688696623,
        "seek": 259660,
        "start": 2610.44,
        "temperature": 0,
        "text": " And this is my, so that's good.",
        "tokens": [
          51056,
          400,
          341,
          307,
          452,
          11,
          370,
          300,
          311,
          665,
          13,
          51204
        ]
      },
      {
        "avg_logprob": -0.21007553411989796,
        "compression_ratio": 1.5,
        "end": 2613.96,
        "id": 888,
        "no_speech_prob": 0.0029809593688696623,
        "seek": 259660,
        "start": 2613.4,
        "temperature": 0,
        "text": " Look at this.",
        "tokens": [
          51204,
          2053,
          412,
          341,
          13,
          51232
        ]
      },
      {
        "avg_logprob": -0.21007553411989796,
        "compression_ratio": 1.5,
        "end": 2615.4,
        "id": 889,
        "no_speech_prob": 0.0029809593688696623,
        "seek": 259660,
        "start": 2613.96,
        "temperature": 0,
        "text": " This is very promising.",
        "tokens": [
          51232,
          639,
          307,
          588,
          20257,
          13,
          51304
        ]
      },
      {
        "avg_logprob": -0.21007553411989796,
        "compression_ratio": 1.5,
        "end": 2622.6,
        "id": 890,
        "no_speech_prob": 0.0029809593688696623,
        "seek": 259660,
        "start": 2615.4,
        "temperature": 0,
        "text": " You can see that a table object got loaded, and it includes an array of rows with 2,477.",
        "tokens": [
          51304,
          509,
          393,
          536,
          300,
          257,
          3199,
          2657,
          658,
          13210,
          11,
          293,
          309,
          5974,
          364,
          10225,
          295,
          13241,
          365,
          568,
          11,
          14060,
          22,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19918775928112886,
        "compression_ratio": 1.5588235294117647,
        "end": 2627.4,
        "id": 891,
        "no_speech_prob": 0.0000490865386382211,
        "seek": 262260,
        "start": 2622.6,
        "temperature": 0,
        "text": " So frankly, there's not really a huge need to turn this into JSON, because I have it",
        "tokens": [
          50364,
          407,
          11939,
          11,
          456,
          311,
          406,
          534,
          257,
          2603,
          643,
          281,
          1261,
          341,
          666,
          31828,
          11,
          570,
          286,
          362,
          309,
          50604
        ]
      },
      {
        "avg_logprob": -0.19918775928112886,
        "compression_ratio": 1.5588235294117647,
        "end": 2631.64,
        "id": 892,
        "no_speech_prob": 0.0000490865386382211,
        "seek": 262260,
        "start": 2627.4,
        "temperature": 0,
        "text": " in this nice table object, which makes it very easy to parse, but let's, for lookup,",
        "tokens": [
          50604,
          294,
          341,
          1481,
          3199,
          2657,
          11,
          597,
          1669,
          309,
          588,
          1858,
          281,
          48377,
          11,
          457,
          718,
          311,
          11,
          337,
          574,
          1010,
          11,
          50816
        ]
      },
      {
        "avg_logprob": -0.19918775928112886,
        "compression_ratio": 1.5588235294117647,
        "end": 2634.2799999999997,
        "id": 893,
        "no_speech_prob": 0.0000490865386382211,
        "seek": 262260,
        "start": 2631.64,
        "temperature": 0,
        "text": " when I want to look up the scores, I'm going to want it as a JavaScript object.",
        "tokens": [
          50816,
          562,
          286,
          528,
          281,
          574,
          493,
          264,
          13444,
          11,
          286,
          478,
          516,
          281,
          528,
          309,
          382,
          257,
          15778,
          2657,
          13,
          50948
        ]
      },
      {
        "avg_logprob": -0.19918775928112886,
        "compression_ratio": 1.5588235294117647,
        "end": 2638.36,
        "id": 894,
        "no_speech_prob": 0.0000490865386382211,
        "seek": 262260,
        "start": 2634.2799999999997,
        "temperature": 0,
        "text": " So let's see, how do we iterate over this table?",
        "tokens": [
          50948,
          407,
          718,
          311,
          536,
          11,
          577,
          360,
          321,
          44497,
          670,
          341,
          3199,
          30,
          51152
        ]
      },
      {
        "avg_logprob": -0.19918775928112886,
        "compression_ratio": 1.5588235294117647,
        "end": 2644.36,
        "id": 895,
        "no_speech_prob": 0.0000490865386382211,
        "seek": 262260,
        "start": 2638.36,
        "temperature": 0,
        "text": " So for var i equals 0, i is less than table.getRowCount.",
        "tokens": [
          51152,
          407,
          337,
          1374,
          741,
          6915,
          1958,
          11,
          741,
          307,
          1570,
          813,
          3199,
          13,
          847,
          49,
          305,
          34,
          792,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.19918775928112886,
        "compression_ratio": 1.5588235294117647,
        "end": 2646.04,
        "id": 896,
        "no_speech_prob": 0.0000490865386382211,
        "seek": 262260,
        "start": 2645.08,
        "temperature": 0,
        "text": " Here's the thing.",
        "tokens": [
          51488,
          1692,
          311,
          264,
          551,
          13,
          51536
        ]
      },
      {
        "avg_logprob": -0.19918775928112886,
        "compression_ratio": 1.5588235294117647,
        "end": 2649.24,
        "id": 897,
        "no_speech_prob": 0.0000490865386382211,
        "seek": 262260,
        "start": 2646.04,
        "temperature": 0,
        "text": " I don't know the table API off the top of my head.",
        "tokens": [
          51536,
          286,
          500,
          380,
          458,
          264,
          3199,
          9362,
          766,
          264,
          1192,
          295,
          452,
          1378,
          13,
          51696
        ]
      },
      {
        "avg_logprob": -0.15612624002539593,
        "compression_ratio": 1.5792349726775956,
        "end": 2656.8399999999997,
        "id": 898,
        "no_speech_prob": 0.0008040797547437251,
        "seek": 264924,
        "start": 2649.24,
        "temperature": 0,
        "text": " So let's go to p5js.org, reference, and then what I'm going to do is look for table,",
        "tokens": [
          50364,
          407,
          718,
          311,
          352,
          281,
          280,
          20,
          25530,
          13,
          4646,
          11,
          6408,
          11,
          293,
          550,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          574,
          337,
          3199,
          11,
          50744
        ]
      },
      {
        "avg_logprob": -0.15612624002539593,
        "compression_ratio": 1.5792349726775956,
        "end": 2660.04,
        "id": 899,
        "no_speech_prob": 0.0008040797547437251,
        "seek": 264924,
        "start": 2657.3999999999996,
        "temperature": 0,
        "text": " and we can see load table, p5 table.",
        "tokens": [
          50772,
          293,
          321,
          393,
          536,
          3677,
          3199,
          11,
          280,
          20,
          3199,
          13,
          50904
        ]
      },
      {
        "avg_logprob": -0.15612624002539593,
        "compression_ratio": 1.5792349726775956,
        "end": 2668.2,
        "id": 900,
        "no_speech_prob": 0.0008040797547437251,
        "seek": 264924,
        "start": 2660.04,
        "temperature": 0,
        "text": " So let's go to p5 table, and we can see a bunch of the functions, like getRowCount.",
        "tokens": [
          50904,
          407,
          718,
          311,
          352,
          281,
          280,
          20,
          3199,
          11,
          293,
          321,
          393,
          536,
          257,
          3840,
          295,
          264,
          6828,
          11,
          411,
          483,
          49,
          305,
          34,
          792,
          13,
          51312
        ]
      },
      {
        "avg_logprob": -0.15612624002539593,
        "compression_ratio": 1.5792349726775956,
        "end": 2672.3599999999997,
        "id": 901,
        "no_speech_prob": 0.0008040797547437251,
        "seek": 264924,
        "start": 2668.2,
        "temperature": 0,
        "text": " So this is something I certainly need to, that I want to iterate over all the rows.",
        "tokens": [
          51312,
          407,
          341,
          307,
          746,
          286,
          3297,
          643,
          281,
          11,
          300,
          286,
          528,
          281,
          44497,
          670,
          439,
          264,
          13241,
          13,
          51520
        ]
      },
      {
        "avg_logprob": -0.2072498589231257,
        "compression_ratio": 1.5221238938053097,
        "end": 2681.32,
        "id": 902,
        "no_speech_prob": 0.007011683192104101,
        "seek": 267236,
        "start": 2672.36,
        "temperature": 0,
        "text": " So I can say for var i equals 0, i is less than table.getRowCount, i plus plus.",
        "tokens": [
          50364,
          407,
          286,
          393,
          584,
          337,
          1374,
          741,
          6915,
          1958,
          11,
          741,
          307,
          1570,
          813,
          3199,
          13,
          847,
          49,
          305,
          34,
          792,
          11,
          741,
          1804,
          1804,
          13,
          50812
        ]
      },
      {
        "avg_logprob": -0.2072498589231257,
        "compression_ratio": 1.5221238938053097,
        "end": 2686.92,
        "id": 903,
        "no_speech_prob": 0.007011683192104101,
        "seek": 267236,
        "start": 2682.2000000000003,
        "temperature": 0,
        "text": " And then I can get each row, probably by saying, getRow i.",
        "tokens": [
          50856,
          400,
          550,
          286,
          393,
          483,
          1184,
          5386,
          11,
          1391,
          538,
          1566,
          11,
          483,
          49,
          305,
          741,
          13,
          51092
        ]
      },
      {
        "avg_logprob": -0.2072498589231257,
        "compression_ratio": 1.5221238938053097,
        "end": 2689.32,
        "id": 904,
        "no_speech_prob": 0.007011683192104101,
        "seek": 267236,
        "start": 2687.48,
        "temperature": 0,
        "text": " That seems probably like it's the case.",
        "tokens": [
          51120,
          663,
          2544,
          1391,
          411,
          309,
          311,
          264,
          1389,
          13,
          51212
        ]
      },
      {
        "avg_logprob": -0.2072498589231257,
        "compression_ratio": 1.5221238938053097,
        "end": 2691.48,
        "id": 905,
        "no_speech_prob": 0.007011683192104101,
        "seek": 267236,
        "start": 2689.32,
        "temperature": 0,
        "text": " Let's say console.log row.",
        "tokens": [
          51212,
          961,
          311,
          584,
          11076,
          13,
          4987,
          5386,
          13,
          51320
        ]
      },
      {
        "avg_logprob": -0.2072498589231257,
        "compression_ratio": 1.5221238938053097,
        "end": 2692.6,
        "id": 906,
        "no_speech_prob": 0.007011683192104101,
        "seek": 267236,
        "start": 2691.48,
        "temperature": 0,
        "text": " Let's see if that works.",
        "tokens": [
          51320,
          961,
          311,
          536,
          498,
          300,
          1985,
          13,
          51376
        ]
      },
      {
        "avg_logprob": -0.2072498589231257,
        "compression_ratio": 1.5221238938053097,
        "end": 2695.4,
        "id": 907,
        "no_speech_prob": 0.007011683192104101,
        "seek": 267236,
        "start": 2693.6400000000003,
        "temperature": 0,
        "text": " Whoops, let me go back over here.",
        "tokens": [
          51428,
          45263,
          11,
          718,
          385,
          352,
          646,
          670,
          510,
          13,
          51516
        ]
      },
      {
        "avg_logprob": -0.2072498589231257,
        "compression_ratio": 1.5221238938053097,
        "end": 2696.92,
        "id": 908,
        "no_speech_prob": 0.007011683192104101,
        "seek": 267236,
        "start": 2696.04,
        "temperature": 0,
        "text": " So this looks good.",
        "tokens": [
          51548,
          407,
          341,
          1542,
          665,
          13,
          51592
        ]
      },
      {
        "avg_logprob": -0.2072498589231257,
        "compression_ratio": 1.5221238938053097,
        "end": 2701.08,
        "id": 909,
        "no_speech_prob": 0.007011683192104101,
        "seek": 267236,
        "start": 2696.92,
        "temperature": 0,
        "text": " Like, I'm getting a row object for every row in that table,",
        "tokens": [
          51592,
          1743,
          11,
          286,
          478,
          1242,
          257,
          5386,
          2657,
          337,
          633,
          5386,
          294,
          300,
          3199,
          11,
          51800
        ]
      },
      {
        "avg_logprob": -0.15156426007234597,
        "compression_ratio": 1.5914634146341464,
        "end": 2711.7999999999997,
        "id": 910,
        "no_speech_prob": 0.00004611272015608847,
        "seek": 270108,
        "start": 2701.08,
        "temperature": 0,
        "text": " and I probably can say var word equals table.get 0, and var score equals table.get 1.",
        "tokens": [
          50364,
          293,
          286,
          1391,
          393,
          584,
          1374,
          1349,
          6915,
          3199,
          13,
          847,
          1958,
          11,
          293,
          1374,
          6175,
          6915,
          3199,
          13,
          847,
          502,
          13,
          50900
        ]
      },
      {
        "avg_logprob": -0.15156426007234597,
        "compression_ratio": 1.5914634146341464,
        "end": 2713.7999999999997,
        "id": 911,
        "no_speech_prob": 0.00004611272015608847,
        "seek": 270108,
        "start": 2711.7999999999997,
        "temperature": 0,
        "text": " And why am I saying that?",
        "tokens": [
          50900,
          400,
          983,
          669,
          286,
          1566,
          300,
          30,
          51000
        ]
      },
      {
        "avg_logprob": -0.15156426007234597,
        "compression_ratio": 1.5914634146341464,
        "end": 2721.88,
        "id": 912,
        "no_speech_prob": 0.00004611272015608847,
        "seek": 270108,
        "start": 2713.7999999999997,
        "temperature": 0,
        "text": " Because if this file is in a table, and each line of this text file is a row,",
        "tokens": [
          51000,
          1436,
          498,
          341,
          3991,
          307,
          294,
          257,
          3199,
          11,
          293,
          1184,
          1622,
          295,
          341,
          2487,
          3991,
          307,
          257,
          5386,
          11,
          51404
        ]
      },
      {
        "avg_logprob": -0.15156426007234597,
        "compression_ratio": 1.5914634146341464,
        "end": 2728.92,
        "id": 913,
        "no_speech_prob": 0.00004611272015608847,
        "seek": 270108,
        "start": 2721.88,
        "temperature": 0,
        "text": " think of it as a spreadsheet, a board is in column 0, 1 is in column 1.",
        "tokens": [
          51404,
          519,
          295,
          309,
          382,
          257,
          27733,
          11,
          257,
          3150,
          307,
          294,
          7738,
          1958,
          11,
          502,
          307,
          294,
          7738,
          502,
          13,
          51756
        ]
      },
      {
        "avg_logprob": -0.15201690253310315,
        "compression_ratio": 1.7732793522267207,
        "end": 2735.7200000000003,
        "id": 914,
        "no_speech_prob": 0.00005649789090966806,
        "seek": 272892,
        "start": 2728.92,
        "temperature": 0,
        "text": " So this is me saying, load that text file into a table, look at every single row,",
        "tokens": [
          50364,
          407,
          341,
          307,
          385,
          1566,
          11,
          3677,
          300,
          2487,
          3991,
          666,
          257,
          3199,
          11,
          574,
          412,
          633,
          2167,
          5386,
          11,
          50704
        ]
      },
      {
        "avg_logprob": -0.15201690253310315,
        "compression_ratio": 1.7732793522267207,
        "end": 2740.76,
        "id": 915,
        "no_speech_prob": 0.00005649789090966806,
        "seek": 272892,
        "start": 2735.7200000000003,
        "temperature": 0,
        "text": " get every row, and then get the stuff that's in column 0, and get the stuff that's in column 1.",
        "tokens": [
          50704,
          483,
          633,
          5386,
          11,
          293,
          550,
          483,
          264,
          1507,
          300,
          311,
          294,
          7738,
          1958,
          11,
          293,
          483,
          264,
          1507,
          300,
          311,
          294,
          7738,
          502,
          13,
          50956
        ]
      },
      {
        "avg_logprob": -0.15201690253310315,
        "compression_ratio": 1.7732793522267207,
        "end": 2744.2000000000003,
        "id": 916,
        "no_speech_prob": 0.00005649789090966806,
        "seek": 272892,
        "start": 2740.76,
        "temperature": 0,
        "text": " And by the way, I could actually label the columns with headers and use that.",
        "tokens": [
          50956,
          400,
          538,
          264,
          636,
          11,
          286,
          727,
          767,
          7645,
          264,
          13766,
          365,
          45101,
          293,
          764,
          300,
          13,
          51128
        ]
      },
      {
        "avg_logprob": -0.15201690253310315,
        "compression_ratio": 1.7732793522267207,
        "end": 2748.28,
        "id": 917,
        "no_speech_prob": 0.00005649789090966806,
        "seek": 272892,
        "start": 2744.2000000000003,
        "temperature": 0,
        "text": " There's lots of fancier things you can do with tables in p5n processing, but this should do.",
        "tokens": [
          51128,
          821,
          311,
          3195,
          295,
          3429,
          27674,
          721,
          291,
          393,
          360,
          365,
          8020,
          294,
          280,
          20,
          77,
          9007,
          11,
          457,
          341,
          820,
          360,
          13,
          51332
        ]
      },
      {
        "avg_logprob": -0.15201690253310315,
        "compression_ratio": 1.7732793522267207,
        "end": 2751.8,
        "id": 918,
        "no_speech_prob": 0.00005649789090966806,
        "seek": 272892,
        "start": 2748.28,
        "temperature": 0,
        "text": " So let's say console.log word score, and let's run this.",
        "tokens": [
          51332,
          407,
          718,
          311,
          584,
          11076,
          13,
          4987,
          1349,
          6175,
          11,
          293,
          718,
          311,
          1190,
          341,
          13,
          51508
        ]
      },
      {
        "avg_logprob": -0.15201690253310315,
        "compression_ratio": 1.7732793522267207,
        "end": 2754.76,
        "id": 919,
        "no_speech_prob": 0.00005649789090966806,
        "seek": 272892,
        "start": 2752.52,
        "temperature": 0,
        "text": " Undefined, undefined, undefined.",
        "tokens": [
          51544,
          2719,
          5666,
          2001,
          11,
          674,
          5666,
          2001,
          11,
          674,
          5666,
          2001,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.17041774058905174,
        "compression_ratio": 1.6162790697674418,
        "end": 2759.32,
        "id": 920,
        "no_speech_prob": 0.006903759203851223,
        "seek": 275476,
        "start": 2754.76,
        "temperature": 0,
        "text": " So get, I suppose, is not the actual function.",
        "tokens": [
          50364,
          407,
          483,
          11,
          286,
          7297,
          11,
          307,
          406,
          264,
          3539,
          2445,
          13,
          50592
        ]
      },
      {
        "avg_logprob": -0.17041774058905174,
        "compression_ratio": 1.6162790697674418,
        "end": 2763,
        "id": 921,
        "no_speech_prob": 0.006903759203851223,
        "seek": 275476,
        "start": 2760.1200000000003,
        "temperature": 0,
        "text": " Oh, and I said table, because I need to say row.",
        "tokens": [
          50632,
          876,
          11,
          293,
          286,
          848,
          3199,
          11,
          570,
          286,
          643,
          281,
          584,
          5386,
          13,
          50776
        ]
      },
      {
        "avg_logprob": -0.17041774058905174,
        "compression_ratio": 1.6162790697674418,
        "end": 2764.6800000000003,
        "id": 922,
        "no_speech_prob": 0.006903759203851223,
        "seek": 275476,
        "start": 2763,
        "temperature": 0,
        "text": " Probably all of you are noticing this.",
        "tokens": [
          50776,
          9210,
          439,
          295,
          291,
          366,
          21814,
          341,
          13,
          50860
        ]
      },
      {
        "avg_logprob": -0.17041774058905174,
        "compression_ratio": 1.6162790697674418,
        "end": 2767.32,
        "id": 923,
        "no_speech_prob": 0.006903759203851223,
        "seek": 275476,
        "start": 2764.6800000000003,
        "temperature": 0,
        "text": " I see in the chat that everyone noticed this like five minutes ago.",
        "tokens": [
          50860,
          286,
          536,
          294,
          264,
          5081,
          300,
          1518,
          5694,
          341,
          411,
          1732,
          2077,
          2057,
          13,
          50992
        ]
      },
      {
        "avg_logprob": -0.17041774058905174,
        "compression_ratio": 1.6162790697674418,
        "end": 2773.6400000000003,
        "id": 924,
        "no_speech_prob": 0.006903759203851223,
        "seek": 275476,
        "start": 2767.96,
        "temperature": 0,
        "text": " So row.get, because of course what I want to do is get column 0 from that row, not from the table.",
        "tokens": [
          51024,
          407,
          5386,
          13,
          847,
          11,
          570,
          295,
          1164,
          437,
          286,
          528,
          281,
          360,
          307,
          483,
          7738,
          1958,
          490,
          300,
          5386,
          11,
          406,
          490,
          264,
          3199,
          13,
          51308
        ]
      },
      {
        "avg_logprob": -0.17041774058905174,
        "compression_ratio": 1.6162790697674418,
        "end": 2774.28,
        "id": 925,
        "no_speech_prob": 0.006903759203851223,
        "seek": 275476,
        "start": 2773.6400000000003,
        "temperature": 0,
        "text": " Sorry about that.",
        "tokens": [
          51308,
          4919,
          466,
          300,
          13,
          51340
        ]
      },
      {
        "avg_logprob": -0.17041774058905174,
        "compression_ratio": 1.6162790697674418,
        "end": 2779.0800000000004,
        "id": 926,
        "no_speech_prob": 0.006903759203851223,
        "seek": 275476,
        "start": 2775.0800000000004,
        "temperature": 0,
        "text": " And then we can see, now why do I still see some undefines?",
        "tokens": [
          51380,
          400,
          550,
          321,
          393,
          536,
          11,
          586,
          983,
          360,
          286,
          920,
          536,
          512,
          674,
          5666,
          1652,
          30,
          51580
        ]
      },
      {
        "avg_logprob": -0.17041774058905174,
        "compression_ratio": 1.6162790697674418,
        "end": 2780.1200000000003,
        "id": 927,
        "no_speech_prob": 0.006903759203851223,
        "seek": 275476,
        "start": 2779.0800000000004,
        "temperature": 0,
        "text": " Oh, look at this.",
        "tokens": [
          51580,
          876,
          11,
          574,
          412,
          341,
          13,
          51632
        ]
      },
      {
        "avg_logprob": -0.17041774058905174,
        "compression_ratio": 1.6162790697674418,
        "end": 2781.48,
        "id": 928,
        "no_speech_prob": 0.006903759203851223,
        "seek": 275476,
        "start": 2780.1200000000003,
        "temperature": 0,
        "text": " It didn't split it.",
        "tokens": [
          51632,
          467,
          994,
          380,
          7472,
          309,
          13,
          51700
        ]
      },
      {
        "avg_logprob": -0.15969406763712565,
        "compression_ratio": 1.5576036866359446,
        "end": 2785.2400000000002,
        "id": 929,
        "no_speech_prob": 0.009559337981045246,
        "seek": 278148,
        "start": 2782.28,
        "temperature": 0,
        "text": " It wasn't able to do it by tabs.",
        "tokens": [
          50404,
          467,
          2067,
          380,
          1075,
          281,
          360,
          309,
          538,
          20743,
          13,
          50552
        ]
      },
      {
        "avg_logprob": -0.15969406763712565,
        "compression_ratio": 1.5576036866359446,
        "end": 2786.28,
        "id": 930,
        "no_speech_prob": 0.009559337981045246,
        "seek": 278148,
        "start": 2785.2400000000002,
        "temperature": 0,
        "text": " That's so sad.",
        "tokens": [
          50552,
          663,
          311,
          370,
          4227,
          13,
          50604
        ]
      },
      {
        "avg_logprob": -0.15969406763712565,
        "compression_ratio": 1.5576036866359446,
        "end": 2787.56,
        "id": 931,
        "no_speech_prob": 0.009559337981045246,
        "seek": 278148,
        "start": 2787.08,
        "temperature": 0,
        "text": " Load table.",
        "tokens": [
          50644,
          48408,
          3199,
          13,
          50668
        ]
      },
      {
        "avg_logprob": -0.15969406763712565,
        "compression_ratio": 1.5576036866359446,
        "end": 2793.88,
        "id": 932,
        "no_speech_prob": 0.009559337981045246,
        "seek": 278148,
        "start": 2787.56,
        "temperature": 0,
        "text": " So this might be a p5.js bug, or I might just be wrong about how this table is formatted,",
        "tokens": [
          50668,
          407,
          341,
          1062,
          312,
          257,
          280,
          20,
          13,
          25530,
          7426,
          11,
          420,
          286,
          1062,
          445,
          312,
          2085,
          466,
          577,
          341,
          3199,
          307,
          1254,
          32509,
          11,
          50984
        ]
      },
      {
        "avg_logprob": -0.15969406763712565,
        "compression_ratio": 1.5576036866359446,
        "end": 2799.32,
        "id": 933,
        "no_speech_prob": 0.009559337981045246,
        "seek": 278148,
        "start": 2793.88,
        "temperature": 0,
        "text": " or I might need to give it a file extension.",
        "tokens": [
          50984,
          420,
          286,
          1062,
          643,
          281,
          976,
          309,
          257,
          3991,
          10320,
          13,
          51256
        ]
      },
      {
        "avg_logprob": -0.15969406763712565,
        "compression_ratio": 1.5576036866359446,
        "end": 2799.96,
        "id": 934,
        "no_speech_prob": 0.009559337981045246,
        "seek": 278148,
        "start": 2799.32,
        "temperature": 0,
        "text": " Let's try that.",
        "tokens": [
          51256,
          961,
          311,
          853,
          300,
          13,
          51288
        ]
      },
      {
        "avg_logprob": -0.15969406763712565,
        "compression_ratio": 1.5576036866359446,
        "end": 2801,
        "id": 935,
        "no_speech_prob": 0.009559337981045246,
        "seek": 278148,
        "start": 2799.96,
        "temperature": 0,
        "text": " Oh, look at that.",
        "tokens": [
          51288,
          876,
          11,
          574,
          412,
          300,
          13,
          51340
        ]
      },
      {
        "avg_logprob": -0.15969406763712565,
        "compression_ratio": 1.5576036866359446,
        "end": 2801.8,
        "id": 936,
        "no_speech_prob": 0.009559337981045246,
        "seek": 278148,
        "start": 2801,
        "temperature": 0,
        "text": " That worked.",
        "tokens": [
          51340,
          663,
          2732,
          13,
          51380
        ]
      },
      {
        "avg_logprob": -0.15969406763712565,
        "compression_ratio": 1.5576036866359446,
        "end": 2809.16,
        "id": 937,
        "no_speech_prob": 0.009559337981045246,
        "seek": 278148,
        "start": 2801.8,
        "temperature": 0,
        "text": " So what I needed to do is, because it's.txt, p5 couldn't auto-detect that it was a tab-delimited",
        "tokens": [
          51380,
          407,
          437,
          286,
          2978,
          281,
          360,
          307,
          11,
          570,
          309,
          311,
          2411,
          83,
          734,
          11,
          280,
          20,
          2809,
          380,
          8399,
          12,
          17863,
          557,
          300,
          309,
          390,
          257,
          4421,
          12,
          18105,
          332,
          1226,
          51748
        ]
      },
      {
        "avg_logprob": -0.17855861637142154,
        "compression_ratio": 1.7045454545454546,
        "end": 2815.3199999999997,
        "id": 938,
        "no_speech_prob": 0.0009253822499886155,
        "seek": 280916,
        "start": 2809.16,
        "temperature": 0,
        "text": " file, so I'm able to give it a second argument and give it an extension, tsv, to tell it that",
        "tokens": [
          50364,
          3991,
          11,
          370,
          286,
          478,
          1075,
          281,
          976,
          309,
          257,
          1150,
          6770,
          293,
          976,
          309,
          364,
          10320,
          11,
          35492,
          85,
          11,
          281,
          980,
          309,
          300,
          50672
        ]
      },
      {
        "avg_logprob": -0.17855861637142154,
        "compression_ratio": 1.7045454545454546,
        "end": 2816.92,
        "id": 939,
        "no_speech_prob": 0.0009253822499886155,
        "seek": 280916,
        "start": 2815.3199999999997,
        "temperature": 0,
        "text": " it is a tab-separated file.",
        "tokens": [
          50672,
          309,
          307,
          257,
          4421,
          12,
          405,
          2181,
          770,
          3991,
          13,
          50752
        ]
      },
      {
        "avg_logprob": -0.17855861637142154,
        "compression_ratio": 1.7045454545454546,
        "end": 2823.08,
        "id": 940,
        "no_speech_prob": 0.0009253822499886155,
        "seek": 280916,
        "start": 2816.92,
        "temperature": 0,
        "text": " If it were a comma-separated file, meaning commas in between instead of tabs, then that's",
        "tokens": [
          50752,
          759,
          309,
          645,
          257,
          22117,
          12,
          405,
          2181,
          770,
          3991,
          11,
          3620,
          800,
          296,
          294,
          1296,
          2602,
          295,
          20743,
          11,
          550,
          300,
          311,
          51060
        ]
      },
      {
        "avg_logprob": -0.17855861637142154,
        "compression_ratio": 1.7045454545454546,
        "end": 2823.8799999999997,
        "id": 941,
        "no_speech_prob": 0.0009253822499886155,
        "seek": 280916,
        "start": 2823.08,
        "temperature": 0,
        "text": " what I had before.",
        "tokens": [
          51060,
          437,
          286,
          632,
          949,
          13,
          51100
        ]
      },
      {
        "avg_logprob": -0.17855861637142154,
        "compression_ratio": 1.7045454545454546,
        "end": 2826.44,
        "id": 942,
        "no_speech_prob": 0.0009253822499886155,
        "seek": 280916,
        "start": 2823.8799999999997,
        "temperature": 0,
        "text": " It was getting the whole thing, and then there's no second column.",
        "tokens": [
          51100,
          467,
          390,
          1242,
          264,
          1379,
          551,
          11,
          293,
          550,
          456,
          311,
          572,
          1150,
          7738,
          13,
          51228
        ]
      },
      {
        "avg_logprob": -0.17855861637142154,
        "compression_ratio": 1.7045454545454546,
        "end": 2827.96,
        "id": 943,
        "no_speech_prob": 0.0009253822499886155,
        "seek": 280916,
        "start": 2826.44,
        "temperature": 0,
        "text": " OK, so that fixed that.",
        "tokens": [
          51228,
          2264,
          11,
          370,
          300,
          6806,
          300,
          13,
          51304
        ]
      },
      {
        "avg_logprob": -0.17855861637142154,
        "compression_ratio": 1.7045454545454546,
        "end": 2829.48,
        "id": 944,
        "no_speech_prob": 0.0009253822499886155,
        "seek": 280916,
        "start": 2827.96,
        "temperature": 0,
        "text": " OK, so tsv.",
        "tokens": [
          51304,
          2264,
          11,
          370,
          35492,
          85,
          13,
          51380
        ]
      },
      {
        "avg_logprob": -0.17855861637142154,
        "compression_ratio": 1.7045454545454546,
        "end": 2829.7999999999997,
        "id": 945,
        "no_speech_prob": 0.0009253822499886155,
        "seek": 280916,
        "start": 2829.48,
        "temperature": 0,
        "text": " Great.",
        "tokens": [
          51380,
          3769,
          13,
          51396
        ]
      },
      {
        "avg_logprob": -0.17855861637142154,
        "compression_ratio": 1.7045454545454546,
        "end": 2835.7999999999997,
        "id": 946,
        "no_speech_prob": 0.0009253822499886155,
        "seek": 280916,
        "start": 2829.7999999999997,
        "temperature": 0,
        "text": " So now what I want to do is I'm going to make an object called the afin, and it's an empty",
        "tokens": [
          51396,
          407,
          586,
          437,
          286,
          528,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          652,
          364,
          2657,
          1219,
          264,
          257,
          5194,
          11,
          293,
          309,
          311,
          364,
          6707,
          51696
        ]
      },
      {
        "avg_logprob": -0.17855861637142154,
        "compression_ratio": 1.7045454545454546,
        "end": 2837.3199999999997,
        "id": 947,
        "no_speech_prob": 0.0009253822499886155,
        "seek": 280916,
        "start": 2835.7999999999997,
        "temperature": 0,
        "text": " JavaScript object.",
        "tokens": [
          51696,
          15778,
          2657,
          13,
          51772
        ]
      },
      {
        "avg_logprob": -0.18383008241653442,
        "compression_ratio": 1.8847926267281105,
        "end": 2842.28,
        "id": 948,
        "no_speech_prob": 0.0011878996156156063,
        "seek": 283732,
        "start": 2837.32,
        "temperature": 0,
        "text": " And what I want to do is I want to say I want to put in that object the word as the key,",
        "tokens": [
          50364,
          400,
          437,
          286,
          528,
          281,
          360,
          307,
          286,
          528,
          281,
          584,
          286,
          528,
          281,
          829,
          294,
          300,
          2657,
          264,
          1349,
          382,
          264,
          2141,
          11,
          50612
        ]
      },
      {
        "avg_logprob": -0.18383008241653442,
        "compression_ratio": 1.8847926267281105,
        "end": 2843.96,
        "id": 949,
        "no_speech_prob": 0.0011878996156156063,
        "seek": 283732,
        "start": 2843,
        "temperature": 0,
        "text": " the number as the value.",
        "tokens": [
          50648,
          264,
          1230,
          382,
          264,
          2158,
          13,
          50696
        ]
      },
      {
        "avg_logprob": -0.18383008241653442,
        "compression_ratio": 1.8847926267281105,
        "end": 2845.7200000000003,
        "id": 950,
        "no_speech_prob": 0.0011878996156156063,
        "seek": 283732,
        "start": 2843.96,
        "temperature": 0,
        "text": " Word is the key, number is the value.",
        "tokens": [
          50696,
          8725,
          307,
          264,
          2141,
          11,
          1230,
          307,
          264,
          2158,
          13,
          50784
        ]
      },
      {
        "avg_logprob": -0.18383008241653442,
        "compression_ratio": 1.8847926267281105,
        "end": 2849.6400000000003,
        "id": 951,
        "no_speech_prob": 0.0011878996156156063,
        "seek": 283732,
        "start": 2845.7200000000003,
        "temperature": 0,
        "text": " So I'm going to say afin word equals score.",
        "tokens": [
          50784,
          407,
          286,
          478,
          516,
          281,
          584,
          3238,
          259,
          1349,
          6915,
          6175,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.18383008241653442,
        "compression_ratio": 1.8847926267281105,
        "end": 2855.0800000000004,
        "id": 952,
        "no_speech_prob": 0.0011878996156156063,
        "seek": 283732,
        "start": 2850.2000000000003,
        "temperature": 0,
        "text": " And then at the very end, I'm going to say console.log afin, and we're going to look",
        "tokens": [
          51008,
          400,
          550,
          412,
          264,
          588,
          917,
          11,
          286,
          478,
          516,
          281,
          584,
          11076,
          13,
          4987,
          3238,
          259,
          11,
          293,
          321,
          434,
          516,
          281,
          574,
          51252
        ]
      },
      {
        "avg_logprob": -0.18383008241653442,
        "compression_ratio": 1.8847926267281105,
        "end": 2856.6800000000003,
        "id": 953,
        "no_speech_prob": 0.0011878996156156063,
        "seek": 283732,
        "start": 2855.0800000000004,
        "temperature": 0,
        "text": " at this, and we can see, look at that.",
        "tokens": [
          51252,
          412,
          341,
          11,
          293,
          321,
          393,
          536,
          11,
          574,
          412,
          300,
          13,
          51332
        ]
      },
      {
        "avg_logprob": -0.18383008241653442,
        "compression_ratio": 1.8847926267281105,
        "end": 2858.28,
        "id": 954,
        "no_speech_prob": 0.0011878996156156063,
        "seek": 283732,
        "start": 2857.4,
        "temperature": 0,
        "text": " There it is.",
        "tokens": [
          51368,
          821,
          309,
          307,
          13,
          51412
        ]
      },
      {
        "avg_logprob": -0.18383008241653442,
        "compression_ratio": 1.8847926267281105,
        "end": 2864.6800000000003,
        "id": 955,
        "no_speech_prob": 0.0011878996156156063,
        "seek": 283732,
        "start": 2858.28,
        "temperature": 0,
        "text": " There now is that afin list in a JavaScript object, every word with a score.",
        "tokens": [
          51412,
          821,
          586,
          307,
          300,
          3238,
          259,
          1329,
          294,
          257,
          15778,
          2657,
          11,
          633,
          1349,
          365,
          257,
          6175,
          13,
          51732
        ]
      },
      {
        "avg_logprob": -0.19799902632429794,
        "compression_ratio": 1.5968992248062015,
        "end": 2867.64,
        "id": 956,
        "no_speech_prob": 0.09534618258476257,
        "seek": 286468,
        "start": 2864.68,
        "temperature": 0,
        "text": " And I'm kind of scrolling through it just to see if anything broke, like if there was",
        "tokens": [
          50364,
          400,
          286,
          478,
          733,
          295,
          29053,
          807,
          309,
          445,
          281,
          536,
          498,
          1340,
          6902,
          11,
          411,
          498,
          456,
          390,
          50512
        ]
      },
      {
        "avg_logprob": -0.19799902632429794,
        "compression_ratio": 1.5968992248062015,
        "end": 2871.64,
        "id": 957,
        "no_speech_prob": 0.09534618258476257,
        "seek": 286468,
        "start": 2867.64,
        "temperature": 0,
        "text": " a weird apostrophe or something that broke it, but it doesn't look like it did.",
        "tokens": [
          50512,
          257,
          3657,
          19484,
          27194,
          420,
          746,
          300,
          6902,
          309,
          11,
          457,
          309,
          1177,
          380,
          574,
          411,
          309,
          630,
          13,
          50712
        ]
      },
      {
        "avg_logprob": -0.19799902632429794,
        "compression_ratio": 1.5968992248062015,
        "end": 2877.7999999999997,
        "id": 958,
        "no_speech_prob": 0.09534618258476257,
        "seek": 286468,
        "start": 2872.3599999999997,
        "temperature": 0,
        "text": " And just to remind you, remember, if I have an object and I say object something.x equals",
        "tokens": [
          50748,
          400,
          445,
          281,
          4160,
          291,
          11,
          1604,
          11,
          498,
          286,
          362,
          364,
          2657,
          293,
          286,
          584,
          2657,
          746,
          13,
          87,
          6915,
          51020
        ]
      },
      {
        "avg_logprob": -0.19799902632429794,
        "compression_ratio": 1.5968992248062015,
        "end": 2879.72,
        "id": 959,
        "no_speech_prob": 0.09534618258476257,
        "seek": 286468,
        "start": 2877.7999999999997,
        "temperature": 0,
        "text": " 100, this is the same.",
        "tokens": [
          51020,
          2319,
          11,
          341,
          307,
          264,
          912,
          13,
          51116
        ]
      },
      {
        "avg_logprob": -0.19799902632429794,
        "compression_ratio": 1.5968992248062015,
        "end": 2882.7599999999998,
        "id": 960,
        "no_speech_prob": 0.09534618258476257,
        "seek": 286468,
        "start": 2879.72,
        "temperature": 0,
        "text": " My laptop's about to fall over, as saying this.",
        "tokens": [
          51116,
          1222,
          10732,
          311,
          466,
          281,
          2100,
          670,
          11,
          382,
          1566,
          341,
          13,
          51268
        ]
      },
      {
        "avg_logprob": -0.19799902632429794,
        "compression_ratio": 1.5968992248062015,
        "end": 2890.52,
        "id": 961,
        "no_speech_prob": 0.09534618258476257,
        "seek": 286468,
        "start": 2884.9199999999996,
        "temperature": 0,
        "text": " So since these words are all strings, and I want those to be the keys, the properties",
        "tokens": [
          51376,
          407,
          1670,
          613,
          2283,
          366,
          439,
          13985,
          11,
          293,
          286,
          528,
          729,
          281,
          312,
          264,
          9317,
          11,
          264,
          7221,
          51656
        ]
      },
      {
        "avg_logprob": -0.18760373699131297,
        "compression_ratio": 1.5895522388059702,
        "end": 2894.04,
        "id": 962,
        "no_speech_prob": 0.04401756823062897,
        "seek": 289052,
        "start": 2890.52,
        "temperature": 0,
        "text": " of the objects, I need to pass them in using this bracket syntax.",
        "tokens": [
          50364,
          295,
          264,
          6565,
          11,
          286,
          643,
          281,
          1320,
          552,
          294,
          1228,
          341,
          16904,
          28431,
          13,
          50540
        ]
      },
      {
        "avg_logprob": -0.18760373699131297,
        "compression_ratio": 1.5895522388059702,
        "end": 2897,
        "id": 963,
        "no_speech_prob": 0.04401756823062897,
        "seek": 289052,
        "start": 2894.04,
        "temperature": 0,
        "text": " I can't do it like this, because it's not a variable name at this point.",
        "tokens": [
          50540,
          286,
          393,
          380,
          360,
          309,
          411,
          341,
          11,
          570,
          309,
          311,
          406,
          257,
          7006,
          1315,
          412,
          341,
          935,
          13,
          50688
        ]
      },
      {
        "avg_logprob": -0.18760373699131297,
        "compression_ratio": 1.5895522388059702,
        "end": 2898.36,
        "id": 964,
        "no_speech_prob": 0.04401756823062897,
        "seek": 289052,
        "start": 2897,
        "temperature": 0,
        "text": " It's coming in as a string.",
        "tokens": [
          50688,
          467,
          311,
          1348,
          294,
          382,
          257,
          6798,
          13,
          50756
        ]
      },
      {
        "avg_logprob": -0.18760373699131297,
        "compression_ratio": 1.5895522388059702,
        "end": 2903.24,
        "id": 965,
        "no_speech_prob": 0.04401756823062897,
        "seek": 289052,
        "start": 2898.36,
        "temperature": 0,
        "text": " OK, so now that that's done, one of the lovely things about using p5 is I can just say save",
        "tokens": [
          50756,
          2264,
          11,
          370,
          586,
          300,
          300,
          311,
          1096,
          11,
          472,
          295,
          264,
          7496,
          721,
          466,
          1228,
          280,
          20,
          307,
          286,
          393,
          445,
          584,
          3155,
          51000
        ]
      },
      {
        "avg_logprob": -0.18760373699131297,
        "compression_ratio": 1.5895522388059702,
        "end": 2909.72,
        "id": 966,
        "no_speech_prob": 0.04401756823062897,
        "seek": 289052,
        "start": 2904.68,
        "temperature": 0,
        "text": " afin111.json afin.",
        "tokens": [
          51072,
          3238,
          259,
          5348,
          16,
          13,
          73,
          3015,
          3238,
          259,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.18760373699131297,
        "compression_ratio": 1.5895522388059702,
        "end": 2913.24,
        "id": 967,
        "no_speech_prob": 0.04401756823062897,
        "seek": 289052,
        "start": 2910.7599999999998,
        "temperature": 0,
        "text": " And I'm saying it's with two n's, I think, right?",
        "tokens": [
          51376,
          400,
          286,
          478,
          1566,
          309,
          311,
          365,
          732,
          297,
          311,
          11,
          286,
          519,
          11,
          558,
          30,
          51500
        ]
      },
      {
        "avg_logprob": -0.18760373699131297,
        "compression_ratio": 1.5895522388059702,
        "end": 2913.48,
        "id": 968,
        "no_speech_prob": 0.04401756823062897,
        "seek": 289052,
        "start": 2913.24,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51500,
          865,
          13,
          51512
        ]
      },
      {
        "avg_logprob": -0.18760373699131297,
        "compression_ratio": 1.5895522388059702,
        "end": 2919.96,
        "id": 969,
        "no_speech_prob": 0.04401756823062897,
        "seek": 289052,
        "start": 2914.12,
        "temperature": 0,
        "text": " So now I can just save that file, save that data as a JSON file, and it should auto download",
        "tokens": [
          51544,
          407,
          586,
          286,
          393,
          445,
          3155,
          300,
          3991,
          11,
          3155,
          300,
          1412,
          382,
          257,
          31828,
          3991,
          11,
          293,
          309,
          820,
          8399,
          5484,
          51836
        ]
      },
      {
        "avg_logprob": -0.20170291955920233,
        "compression_ratio": 1.5916030534351144,
        "end": 2921.2400000000002,
        "id": 970,
        "no_speech_prob": 0.01472836546599865,
        "seek": 291996,
        "start": 2919.96,
        "temperature": 0,
        "text": " that to me in the browser.",
        "tokens": [
          50364,
          300,
          281,
          385,
          294,
          264,
          11185,
          13,
          50428
        ]
      },
      {
        "avg_logprob": -0.20170291955920233,
        "compression_ratio": 1.5916030534351144,
        "end": 2922.84,
        "id": 971,
        "no_speech_prob": 0.01472836546599865,
        "seek": 291996,
        "start": 2921.2400000000002,
        "temperature": 0,
        "text": " So let's run it again.",
        "tokens": [
          50428,
          407,
          718,
          311,
          1190,
          309,
          797,
          13,
          50508
        ]
      },
      {
        "avg_logprob": -0.20170291955920233,
        "compression_ratio": 1.5916030534351144,
        "end": 2925,
        "id": 972,
        "no_speech_prob": 0.01472836546599865,
        "seek": 291996,
        "start": 2922.84,
        "temperature": 0,
        "text": " Ooh, file name index of.",
        "tokens": [
          50508,
          7951,
          11,
          3991,
          1315,
          8186,
          295,
          13,
          50616
        ]
      },
      {
        "avg_logprob": -0.20170291955920233,
        "compression_ratio": 1.5916030534351144,
        "end": 2925.8,
        "id": 973,
        "no_speech_prob": 0.01472836546599865,
        "seek": 291996,
        "start": 2925,
        "temperature": 0,
        "text": " Ooh, OK.",
        "tokens": [
          50616,
          7951,
          11,
          2264,
          13,
          50656
        ]
      },
      {
        "avg_logprob": -0.20170291955920233,
        "compression_ratio": 1.5916030534351144,
        "end": 2929.16,
        "id": 974,
        "no_speech_prob": 0.01472836546599865,
        "seek": 291996,
        "start": 2925.8,
        "temperature": 0,
        "text": " So I think maybe I'm supposed to say it the other way around.",
        "tokens": [
          50656,
          407,
          286,
          519,
          1310,
          286,
          478,
          3442,
          281,
          584,
          309,
          264,
          661,
          636,
          926,
          13,
          50824
        ]
      },
      {
        "avg_logprob": -0.20170291955920233,
        "compression_ratio": 1.5916030534351144,
        "end": 2930.92,
        "id": 975,
        "no_speech_prob": 0.01472836546599865,
        "seek": 291996,
        "start": 2929.16,
        "temperature": 0,
        "text": " First, the data, and then the file name.",
        "tokens": [
          50824,
          2386,
          11,
          264,
          1412,
          11,
          293,
          550,
          264,
          3991,
          1315,
          13,
          50912
        ]
      },
      {
        "avg_logprob": -0.20170291955920233,
        "compression_ratio": 1.5916030534351144,
        "end": 2933.16,
        "id": 976,
        "no_speech_prob": 0.01472836546599865,
        "seek": 291996,
        "start": 2931.88,
        "temperature": 0,
        "text": " That seems right.",
        "tokens": [
          50960,
          663,
          2544,
          558,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.20170291955920233,
        "compression_ratio": 1.5916030534351144,
        "end": 2933.96,
        "id": 977,
        "no_speech_prob": 0.01472836546599865,
        "seek": 291996,
        "start": 2933.16,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51024,
          821,
          321,
          352,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.20170291955920233,
        "compression_ratio": 1.5916030534351144,
        "end": 2935.2400000000002,
        "id": 978,
        "no_speech_prob": 0.01472836546599865,
        "seek": 291996,
        "start": 2933.96,
        "temperature": 0,
        "text": " And you can see my browser.",
        "tokens": [
          51064,
          400,
          291,
          393,
          536,
          452,
          11185,
          13,
          51128
        ]
      },
      {
        "avg_logprob": -0.20170291955920233,
        "compression_ratio": 1.5916030534351144,
        "end": 2943.32,
        "id": 979,
        "no_speech_prob": 0.01472836546599865,
        "seek": 291996,
        "start": 2935.2400000000002,
        "temperature": 0,
        "text": " I'm standing in front of it, but my browser auto downloaded this file called afinb, because",
        "tokens": [
          51128,
          286,
          478,
          4877,
          294,
          1868,
          295,
          309,
          11,
          457,
          452,
          11185,
          8399,
          21748,
          341,
          3991,
          1219,
          3238,
          259,
          65,
          11,
          570,
          51532
        ]
      },
      {
        "avg_logprob": -0.20170291955920233,
        "compression_ratio": 1.5916030534351144,
        "end": 2945.64,
        "id": 980,
        "no_speech_prob": 0.01472836546599865,
        "seek": 291996,
        "start": 2943.32,
        "temperature": 0,
        "text": " I must have put that in my code by accident.",
        "tokens": [
          51532,
          286,
          1633,
          362,
          829,
          300,
          294,
          452,
          3089,
          538,
          6398,
          13,
          51648
        ]
      },
      {
        "avg_logprob": -0.20170291955920233,
        "compression_ratio": 1.5916030534351144,
        "end": 2947.56,
        "id": 981,
        "no_speech_prob": 0.01472836546599865,
        "seek": 291996,
        "start": 2946.68,
        "temperature": 0,
        "text": " Oh, where's my code?",
        "tokens": [
          51700,
          876,
          11,
          689,
          311,
          452,
          3089,
          30,
          51744
        ]
      },
      {
        "avg_logprob": -0.20170291955920233,
        "compression_ratio": 1.5916030534351144,
        "end": 2948.68,
        "id": 982,
        "no_speech_prob": 0.01472836546599865,
        "seek": 291996,
        "start": 2948.12,
        "temperature": 0,
        "text": " Yeah, whoops.",
        "tokens": [
          51772,
          865,
          11,
          567,
          3370,
          13,
          51800
        ]
      },
      {
        "avg_logprob": -0.2040280158366632,
        "compression_ratio": 1.5868544600938967,
        "end": 2951,
        "id": 983,
        "no_speech_prob": 0.0021826939191669226,
        "seek": 294868,
        "start": 2949.24,
        "temperature": 0,
        "text": " Two n's there, but that doesn't really matter.",
        "tokens": [
          50392,
          4453,
          297,
          311,
          456,
          11,
          457,
          300,
          1177,
          380,
          534,
          1871,
          13,
          50480
        ]
      },
      {
        "avg_logprob": -0.2040280158366632,
        "compression_ratio": 1.5868544600938967,
        "end": 2962.3599999999997,
        "id": 984,
        "no_speech_prob": 0.0021826939191669226,
        "seek": 294868,
        "start": 2951,
        "temperature": 0,
        "text": " The point is, now I have this file, afin, and I can put that here instead of the text",
        "tokens": [
          50480,
          440,
          935,
          307,
          11,
          586,
          286,
          362,
          341,
          3991,
          11,
          3238,
          259,
          11,
          293,
          286,
          393,
          829,
          300,
          510,
          2602,
          295,
          264,
          2487,
          51048
        ]
      },
      {
        "avg_logprob": -0.2040280158366632,
        "compression_ratio": 1.5868544600938967,
        "end": 2962.52,
        "id": 985,
        "no_speech_prob": 0.0021826939191669226,
        "seek": 294868,
        "start": 2962.3599999999997,
        "temperature": 0,
        "text": " file.",
        "tokens": [
          51048,
          3991,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.2040280158366632,
        "compression_ratio": 1.5868544600938967,
        "end": 2964.04,
        "id": 986,
        "no_speech_prob": 0.0021826939191669226,
        "seek": 294868,
        "start": 2962.52,
        "temperature": 0,
        "text": " So let me rename it to fix it.",
        "tokens": [
          51056,
          407,
          718,
          385,
          36741,
          309,
          281,
          3191,
          309,
          13,
          51132
        ]
      },
      {
        "avg_logprob": -0.2040280158366632,
        "compression_ratio": 1.5868544600938967,
        "end": 2971.56,
        "id": 987,
        "no_speech_prob": 0.0021826939191669226,
        "seek": 294868,
        "start": 2965.16,
        "temperature": 0,
        "text": " So what I did just is now instead of this text file, I now converted that to a JSON",
        "tokens": [
          51188,
          407,
          437,
          286,
          630,
          445,
          307,
          586,
          2602,
          295,
          341,
          2487,
          3991,
          11,
          286,
          586,
          16424,
          300,
          281,
          257,
          31828,
          51508
        ]
      },
      {
        "avg_logprob": -0.2040280158366632,
        "compression_ratio": 1.5868544600938967,
        "end": 2971.8799999999997,
        "id": 988,
        "no_speech_prob": 0.0021826939191669226,
        "seek": 294868,
        "start": 2971.56,
        "temperature": 0,
        "text": " file.",
        "tokens": [
          51508,
          3991,
          13,
          51524
        ]
      },
      {
        "avg_logprob": -0.2040280158366632,
        "compression_ratio": 1.5868544600938967,
        "end": 2973.24,
        "id": 989,
        "no_speech_prob": 0.0021826939191669226,
        "seek": 294868,
        "start": 2971.8799999999997,
        "temperature": 0,
        "text": " And of course, it won't.",
        "tokens": [
          51524,
          400,
          295,
          1164,
          11,
          309,
          1582,
          380,
          13,
          51592
        ]
      },
      {
        "avg_logprob": -0.2040280158366632,
        "compression_ratio": 1.5868544600938967,
        "end": 2976.52,
        "id": 990,
        "no_speech_prob": 0.0021826939191669226,
        "seek": 294868,
        "start": 2973.8799999999997,
        "temperature": 0,
        "text": " Oh, but this is my, I can open it right through here.",
        "tokens": [
          51624,
          876,
          11,
          457,
          341,
          307,
          452,
          11,
          286,
          393,
          1269,
          309,
          558,
          807,
          510,
          13,
          51756
        ]
      },
      {
        "avg_logprob": -0.19767752427321214,
        "compression_ratio": 1.5813953488372092,
        "end": 2978.7599999999998,
        "id": 991,
        "no_speech_prob": 0.00014653110702056438,
        "seek": 297652,
        "start": 2977.48,
        "temperature": 0,
        "text": " And we can see there it is.",
        "tokens": [
          50412,
          400,
          321,
          393,
          536,
          456,
          309,
          307,
          13,
          50476
        ]
      },
      {
        "avg_logprob": -0.19767752427321214,
        "compression_ratio": 1.5813953488372092,
        "end": 2984.2,
        "id": 992,
        "no_speech_prob": 0.00014653110702056438,
        "seek": 297652,
        "start": 2978.7599999999998,
        "temperature": 0,
        "text": " So this is great, because now to do the text analysis, the sentiment analysis, it's going",
        "tokens": [
          50476,
          407,
          341,
          307,
          869,
          11,
          570,
          586,
          281,
          360,
          264,
          2487,
          5215,
          11,
          264,
          16149,
          5215,
          11,
          309,
          311,
          516,
          50748
        ]
      },
      {
        "avg_logprob": -0.19767752427321214,
        "compression_ratio": 1.5813953488372092,
        "end": 2987.4,
        "id": 993,
        "no_speech_prob": 0.00014653110702056438,
        "seek": 297652,
        "start": 2984.2,
        "temperature": 0,
        "text": " to be so much easier if I already have this data in a JSON file.",
        "tokens": [
          50748,
          281,
          312,
          370,
          709,
          3571,
          498,
          286,
          1217,
          362,
          341,
          1412,
          294,
          257,
          31828,
          3991,
          13,
          50908
        ]
      },
      {
        "avg_logprob": -0.19767752427321214,
        "compression_ratio": 1.5813953488372092,
        "end": 2991.24,
        "id": 994,
        "no_speech_prob": 0.00014653110702056438,
        "seek": 297652,
        "start": 2987.4,
        "temperature": 0,
        "text": " And by the way, you could probably Google afin111 JSON.",
        "tokens": [
          50908,
          400,
          538,
          264,
          636,
          11,
          291,
          727,
          1391,
          3329,
          3238,
          259,
          5348,
          16,
          31828,
          13,
          51100
        ]
      },
      {
        "avg_logprob": -0.19767752427321214,
        "compression_ratio": 1.5813953488372092,
        "end": 2995.24,
        "id": 995,
        "no_speech_prob": 0.00014653110702056438,
        "seek": 297652,
        "start": 2992.44,
        "temperature": 0,
        "text": " Countless people all over the world and internet have done this already.",
        "tokens": [
          51160,
          5247,
          1832,
          561,
          439,
          670,
          264,
          1002,
          293,
          4705,
          362,
          1096,
          341,
          1217,
          13,
          51300
        ]
      },
      {
        "avg_logprob": -0.19767752427321214,
        "compression_ratio": 1.5813953488372092,
        "end": 3001.88,
        "id": 996,
        "no_speech_prob": 0.00014653110702056438,
        "seek": 297652,
        "start": 2995.24,
        "temperature": 0,
        "text": " But I thought it was a useful demonstration to show in p5 how to convert between one format",
        "tokens": [
          51300,
          583,
          286,
          1194,
          309,
          390,
          257,
          4420,
          16520,
          281,
          855,
          294,
          280,
          20,
          577,
          281,
          7620,
          1296,
          472,
          7877,
          51632
        ]
      },
      {
        "avg_logprob": -0.19767752427321214,
        "compression_ratio": 1.5813953488372092,
        "end": 3002.36,
        "id": 997,
        "no_speech_prob": 0.00014653110702056438,
        "seek": 297652,
        "start": 3001.88,
        "temperature": 0,
        "text": " to another.",
        "tokens": [
          51632,
          281,
          1071,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.19767752427321214,
        "compression_ratio": 1.5813953488372092,
        "end": 3006.44,
        "id": 998,
        "no_speech_prob": 0.00014653110702056438,
        "seek": 297652,
        "start": 3003.96,
        "temperature": 0,
        "text": " Let's do the, so all of you who were like, I wanted to watch",
        "tokens": [
          51736,
          961,
          311,
          360,
          264,
          11,
          370,
          439,
          295,
          291,
          567,
          645,
          411,
          11,
          286,
          1415,
          281,
          1159,
          51860
        ]
      },
      {
        "avg_logprob": -0.17608444289405747,
        "compression_ratio": 1.784688995215311,
        "end": 3007.96,
        "id": 999,
        "no_speech_prob": 0.00022341514704748988,
        "seek": 300644,
        "start": 3006.44,
        "temperature": 0,
        "text": " the video about sentiment analysis.",
        "tokens": [
          50364,
          264,
          960,
          466,
          16149,
          5215,
          13,
          50440
        ]
      },
      {
        "avg_logprob": -0.17608444289405747,
        "compression_ratio": 1.784688995215311,
        "end": 3013.48,
        "id": 1000,
        "no_speech_prob": 0.00022341514704748988,
        "seek": 300644,
        "start": 3009.56,
        "temperature": 0,
        "text": " Maybe I can put a little time code in this challenge of skip ahead to the sentiment",
        "tokens": [
          50520,
          2704,
          286,
          393,
          829,
          257,
          707,
          565,
          3089,
          294,
          341,
          3430,
          295,
          10023,
          2286,
          281,
          264,
          16149,
          50716
        ]
      },
      {
        "avg_logprob": -0.17608444289405747,
        "compression_ratio": 1.784688995215311,
        "end": 3014.04,
        "id": 1001,
        "no_speech_prob": 0.00022341514704748988,
        "seek": 300644,
        "start": 3013.48,
        "temperature": 0,
        "text": " analysis part.",
        "tokens": [
          50716,
          5215,
          644,
          13,
          50744
        ]
      },
      {
        "avg_logprob": -0.17608444289405747,
        "compression_ratio": 1.784688995215311,
        "end": 3017,
        "id": 1002,
        "no_speech_prob": 0.00022341514704748988,
        "seek": 300644,
        "start": 3014.04,
        "temperature": 0,
        "text": " So now we're actually ready to do the sentiment analysis.",
        "tokens": [
          50744,
          407,
          586,
          321,
          434,
          767,
          1919,
          281,
          360,
          264,
          16149,
          5215,
          13,
          50892
        ]
      },
      {
        "avg_logprob": -0.17608444289405747,
        "compression_ratio": 1.784688995215311,
        "end": 3023.2400000000002,
        "id": 1003,
        "no_speech_prob": 0.00022341514704748988,
        "seek": 300644,
        "start": 3018.28,
        "temperature": 0,
        "text": " So what I'm going to do is I'm going to just actually save this as the JavaScript",
        "tokens": [
          50956,
          407,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          445,
          767,
          3155,
          341,
          382,
          264,
          15778,
          51204
        ]
      },
      {
        "avg_logprob": -0.17608444289405747,
        "compression_ratio": 1.784688995215311,
        "end": 3023.4,
        "id": 1004,
        "no_speech_prob": 0.00022341514704748988,
        "seek": 300644,
        "start": 3023.2400000000002,
        "temperature": 0,
        "text": " file.",
        "tokens": [
          51204,
          3991,
          13,
          51212
        ]
      },
      {
        "avg_logprob": -0.17608444289405747,
        "compression_ratio": 1.784688995215311,
        "end": 3025.08,
        "id": 1005,
        "no_speech_prob": 0.00022341514704748988,
        "seek": 300644,
        "start": 3023.4,
        "temperature": 0,
        "text": " I'm going to call it convert.js.",
        "tokens": [
          51212,
          286,
          478,
          516,
          281,
          818,
          309,
          7620,
          13,
          25530,
          13,
          51296
        ]
      },
      {
        "avg_logprob": -0.17608444289405747,
        "compression_ratio": 1.784688995215311,
        "end": 3033,
        "id": 1006,
        "no_speech_prob": 0.00022341514704748988,
        "seek": 300644,
        "start": 3026.92,
        "temperature": 0,
        "text": " And I'm just going to get rid of everything and start over.",
        "tokens": [
          51388,
          400,
          286,
          478,
          445,
          516,
          281,
          483,
          3973,
          295,
          1203,
          293,
          722,
          670,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.19034488781078443,
        "compression_ratio": 1.5069124423963134,
        "end": 3042.12,
        "id": 1007,
        "no_speech_prob": 0.00021318710059858859,
        "seek": 303300,
        "start": 3033.08,
        "temperature": 0,
        "text": " Because I don't, what am I trying to say here?",
        "tokens": [
          50368,
          1436,
          286,
          500,
          380,
          11,
          437,
          669,
          286,
          1382,
          281,
          584,
          510,
          30,
          50820
        ]
      },
      {
        "avg_logprob": -0.19034488781078443,
        "compression_ratio": 1.5069124423963134,
        "end": 3046.12,
        "id": 1008,
        "no_speech_prob": 0.00021318710059858859,
        "seek": 303300,
        "start": 3043.24,
        "temperature": 0,
        "text": " I don't need to ever do that again.",
        "tokens": [
          50876,
          286,
          500,
          380,
          643,
          281,
          1562,
          360,
          300,
          797,
          13,
          51020
        ]
      },
      {
        "avg_logprob": -0.19034488781078443,
        "compression_ratio": 1.5069124423963134,
        "end": 3047.8,
        "id": 1009,
        "no_speech_prob": 0.00021318710059858859,
        "seek": 303300,
        "start": 3046.12,
        "temperature": 0,
        "text": " I've already converted it to JSON.",
        "tokens": [
          51020,
          286,
          600,
          1217,
          16424,
          309,
          281,
          31828,
          13,
          51104
        ]
      },
      {
        "avg_logprob": -0.19034488781078443,
        "compression_ratio": 1.5069124423963134,
        "end": 3050.12,
        "id": 1010,
        "no_speech_prob": 0.00021318710059858859,
        "seek": 303300,
        "start": 3047.8,
        "temperature": 0,
        "text": " But it's good to save that code if you want to take a look at it.",
        "tokens": [
          51104,
          583,
          309,
          311,
          665,
          281,
          3155,
          300,
          3089,
          498,
          291,
          528,
          281,
          747,
          257,
          574,
          412,
          309,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.19034488781078443,
        "compression_ratio": 1.5069124423963134,
        "end": 3051.64,
        "id": 1011,
        "no_speech_prob": 0.00021318710059858859,
        "seek": 303300,
        "start": 3050.12,
        "temperature": 0,
        "text": " OK, so here we go.",
        "tokens": [
          51220,
          2264,
          11,
          370,
          510,
          321,
          352,
          13,
          51296
        ]
      },
      {
        "avg_logprob": -0.19034488781078443,
        "compression_ratio": 1.5069124423963134,
        "end": 3052.28,
        "id": 1012,
        "no_speech_prob": 0.00021318710059858859,
        "seek": 303300,
        "start": 3051.64,
        "temperature": 0,
        "text": " Part two.",
        "tokens": [
          51296,
          4100,
          732,
          13,
          51328
        ]
      },
      {
        "avg_logprob": -0.19034488781078443,
        "compression_ratio": 1.5069124423963134,
        "end": 3053.64,
        "id": 1013,
        "no_speech_prob": 0.00021318710059858859,
        "seek": 303300,
        "start": 3052.28,
        "temperature": 0,
        "text": " I don't know if there should be two videos.",
        "tokens": [
          51328,
          286,
          500,
          380,
          458,
          498,
          456,
          820,
          312,
          732,
          2145,
          13,
          51396
        ]
      },
      {
        "avg_logprob": -0.19034488781078443,
        "compression_ratio": 1.5069124423963134,
        "end": 3054.92,
        "id": 1014,
        "no_speech_prob": 0.00021318710059858859,
        "seek": 303300,
        "start": 3054.28,
        "temperature": 0,
        "text": " Just in case.",
        "tokens": [
          51428,
          1449,
          294,
          1389,
          13,
          51460
        ]
      },
      {
        "avg_logprob": -0.19034488781078443,
        "compression_ratio": 1.5069124423963134,
        "end": 3056.44,
        "id": 1015,
        "no_speech_prob": 0.00021318710059858859,
        "seek": 303300,
        "start": 3055.8,
        "temperature": 0,
        "text": " Where's my bell?",
        "tokens": [
          51504,
          2305,
          311,
          452,
          4549,
          30,
          51536
        ]
      },
      {
        "avg_logprob": -0.19034488781078443,
        "compression_ratio": 1.5069124423963134,
        "end": 3061.88,
        "id": 1016,
        "no_speech_prob": 0.00021318710059858859,
        "seek": 303300,
        "start": 3059.16,
        "temperature": 0,
        "text": " Part two of afin111 sentiment analysis.",
        "tokens": [
          51672,
          4100,
          732,
          295,
          3238,
          259,
          5348,
          16,
          16149,
          5215,
          13,
          51808
        ]
      },
      {
        "avg_logprob": -0.1668569701058524,
        "compression_ratio": 1.5897435897435896,
        "end": 3063.4,
        "id": 1017,
        "no_speech_prob": 0.0000031875572403805563,
        "seek": 306188,
        "start": 3062.6800000000003,
        "temperature": 0,
        "text": " OK, here we go.",
        "tokens": [
          50404,
          2264,
          11,
          510,
          321,
          352,
          13,
          50440
        ]
      },
      {
        "avg_logprob": -0.1668569701058524,
        "compression_ratio": 1.5897435897435896,
        "end": 3070.6800000000003,
        "id": 1018,
        "no_speech_prob": 0.0000031875572403805563,
        "seek": 306188,
        "start": 3063.4,
        "temperature": 0,
        "text": " So the first thing that I need to do is I want to load this file.",
        "tokens": [
          50440,
          407,
          264,
          700,
          551,
          300,
          286,
          643,
          281,
          360,
          307,
          286,
          528,
          281,
          3677,
          341,
          3991,
          13,
          50804
        ]
      },
      {
        "avg_logprob": -0.1668569701058524,
        "compression_ratio": 1.5897435897435896,
        "end": 3075.08,
        "id": 1019,
        "no_speech_prob": 0.0000031875572403805563,
        "seek": 306188,
        "start": 3070.6800000000003,
        "temperature": 0,
        "text": " So let's make a variable.",
        "tokens": [
          50804,
          407,
          718,
          311,
          652,
          257,
          7006,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.1668569701058524,
        "compression_ratio": 1.5897435897435896,
        "end": 3076.28,
        "id": 1020,
        "no_speech_prob": 0.0000031875572403805563,
        "seek": 306188,
        "start": 3075.08,
        "temperature": 0,
        "text": " I'm going to call it afin again.",
        "tokens": [
          51024,
          286,
          478,
          516,
          281,
          818,
          309,
          3238,
          259,
          797,
          13,
          51084
        ]
      },
      {
        "avg_logprob": -0.1668569701058524,
        "compression_ratio": 1.5897435897435896,
        "end": 3082.6,
        "id": 1021,
        "no_speech_prob": 0.0000031875572403805563,
        "seek": 306188,
        "start": 3077,
        "temperature": 0,
        "text": " afin equals load JSON, afin111.json.",
        "tokens": [
          51120,
          3238,
          259,
          6915,
          3677,
          31828,
          11,
          3238,
          259,
          5348,
          16,
          13,
          73,
          3015,
          13,
          51400
        ]
      },
      {
        "avg_logprob": -0.1668569701058524,
        "compression_ratio": 1.5897435897435896,
        "end": 3084.36,
        "id": 1022,
        "no_speech_prob": 0.0000031875572403805563,
        "seek": 306188,
        "start": 3082.6,
        "temperature": 0,
        "text": " And I just want to see that that worked.",
        "tokens": [
          51400,
          400,
          286,
          445,
          528,
          281,
          536,
          300,
          300,
          2732,
          13,
          51488
        ]
      },
      {
        "avg_logprob": -0.1668569701058524,
        "compression_ratio": 1.5897435897435896,
        "end": 3086.36,
        "id": 1023,
        "no_speech_prob": 0.0000031875572403805563,
        "seek": 306188,
        "start": 3084.36,
        "temperature": 0,
        "text": " I'm going to say console.log afin.",
        "tokens": [
          51488,
          286,
          478,
          516,
          281,
          584,
          11076,
          13,
          4987,
          3238,
          259,
          13,
          51588
        ]
      },
      {
        "avg_logprob": -0.1668569701058524,
        "compression_ratio": 1.5897435897435896,
        "end": 3087.96,
        "id": 1024,
        "no_speech_prob": 0.0000031875572403805563,
        "seek": 306188,
        "start": 3086.36,
        "temperature": 0,
        "text": " OK, so we're starting up.",
        "tokens": [
          51588,
          2264,
          11,
          370,
          321,
          434,
          2891,
          493,
          13,
          51668
        ]
      },
      {
        "avg_logprob": -0.1668569701058524,
        "compression_ratio": 1.5897435897435896,
        "end": 3089.48,
        "id": 1025,
        "no_speech_prob": 0.0000031875572403805563,
        "seek": 306188,
        "start": 3087.96,
        "temperature": 0,
        "text": " And I just want to see, great.",
        "tokens": [
          51668,
          400,
          286,
          445,
          528,
          281,
          536,
          11,
          869,
          13,
          51744
        ]
      },
      {
        "avg_logprob": -0.1791146372405576,
        "compression_ratio": 1.39375,
        "end": 3092.2,
        "id": 1026,
        "no_speech_prob": 0.00005391053491621278,
        "seek": 308948,
        "start": 3089.56,
        "temperature": 0,
        "text": " So we can see that that list has been loaded, which is wonderful.",
        "tokens": [
          50368,
          407,
          321,
          393,
          536,
          300,
          300,
          1329,
          575,
          668,
          13210,
          11,
          597,
          307,
          3715,
          13,
          50500
        ]
      },
      {
        "avg_logprob": -0.1791146372405576,
        "compression_ratio": 1.39375,
        "end": 3095.88,
        "id": 1027,
        "no_speech_prob": 0.00005391053491621278,
        "seek": 308948,
        "start": 3092.2,
        "temperature": 0,
        "text": " Now, the next thing I need is I want to have a place.",
        "tokens": [
          50500,
          823,
          11,
          264,
          958,
          551,
          286,
          643,
          307,
          286,
          528,
          281,
          362,
          257,
          1081,
          13,
          50684
        ]
      },
      {
        "avg_logprob": -0.1791146372405576,
        "compression_ratio": 1.39375,
        "end": 3099.8,
        "id": 1028,
        "no_speech_prob": 0.00005391053491621278,
        "seek": 308948,
        "start": 3098.04,
        "temperature": 0,
        "text": " So let's add some stuff here.",
        "tokens": [
          50792,
          407,
          718,
          311,
          909,
          512,
          1507,
          510,
          13,
          50880
        ]
      },
      {
        "avg_logprob": -0.1791146372405576,
        "compression_ratio": 1.39375,
        "end": 3102.52,
        "id": 1029,
        "no_speech_prob": 0.00005391053491621278,
        "seek": 308948,
        "start": 3099.8,
        "temperature": 0,
        "text": " afin sentiment demo.",
        "tokens": [
          50880,
          3238,
          259,
          16149,
          10723,
          13,
          51016
        ]
      },
      {
        "avg_logprob": -0.1791146372405576,
        "compression_ratio": 1.39375,
        "end": 3107.4,
        "id": 1030,
        "no_speech_prob": 0.00005391053491621278,
        "seek": 308948,
        "start": 3105.16,
        "temperature": 0,
        "text": " Let's say type here.",
        "tokens": [
          51148,
          961,
          311,
          584,
          2010,
          510,
          13,
          51260
        ]
      },
      {
        "avg_logprob": -0.1791146372405576,
        "compression_ratio": 1.39375,
        "end": 3115.8,
        "id": 1031,
        "no_speech_prob": 0.00005391053491621278,
        "seek": 308948,
        "start": 3109.8,
        "temperature": 0,
        "text": " And make a text area like this.",
        "tokens": [
          51380,
          400,
          652,
          257,
          2487,
          1859,
          411,
          341,
          13,
          51680
        ]
      },
      {
        "avg_logprob": -0.2875624117643937,
        "compression_ratio": 1.4930555555555556,
        "end": 3124.36,
        "id": 1032,
        "no_speech_prob": 0.0019266968593001366,
        "seek": 311580,
        "start": 3115.8,
        "temperature": 0,
        "text": " textarea id equals text textarea.",
        "tokens": [
          50364,
          2487,
          35425,
          4496,
          6915,
          2487,
          2487,
          35425,
          13,
          50792
        ]
      },
      {
        "avg_logprob": -0.2875624117643937,
        "compression_ratio": 1.4930555555555556,
        "end": 3133.4,
        "id": 1033,
        "no_speech_prob": 0.0019266968593001366,
        "seek": 311580,
        "start": 3127.6400000000003,
        "temperature": 0,
        "text": " OK, so now I should have on the HTML page, we should see, whoops.",
        "tokens": [
          50956,
          2264,
          11,
          370,
          586,
          286,
          820,
          362,
          322,
          264,
          17995,
          3028,
          11,
          321,
          820,
          536,
          11,
          567,
          3370,
          13,
          51244
        ]
      },
      {
        "avg_logprob": -0.2875624117643937,
        "compression_ratio": 1.4930555555555556,
        "end": 3135.4,
        "id": 1034,
        "no_speech_prob": 0.0019266968593001366,
        "seek": 311580,
        "start": 3134.04,
        "temperature": 0,
        "text": " I definitely did something wrong.",
        "tokens": [
          51276,
          286,
          2138,
          630,
          746,
          2085,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.2875624117643937,
        "compression_ratio": 1.4930555555555556,
        "end": 3139.7200000000003,
        "id": 1035,
        "no_speech_prob": 0.0019266968593001366,
        "seek": 311580,
        "start": 3136.36,
        "temperature": 0,
        "text": " textarea textarea.",
        "tokens": [
          51392,
          2487,
          35425,
          2487,
          35425,
          13,
          51560
        ]
      },
      {
        "avg_logprob": -0.2875624117643937,
        "compression_ratio": 1.4930555555555556,
        "end": 3141.4,
        "id": 1036,
        "no_speech_prob": 0.0019266968593001366,
        "seek": 311580,
        "start": 3140.6000000000004,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51604,
          821,
          321,
          352,
          13,
          51644
        ]
      },
      {
        "avg_logprob": -0.2875624117643937,
        "compression_ratio": 1.4930555555555556,
        "end": 3145.48,
        "id": 1037,
        "no_speech_prob": 0.0019266968593001366,
        "seek": 311580,
        "start": 3141.4,
        "temperature": 0,
        "text": " OK, so we should see, oh, a global function text.",
        "tokens": [
          51644,
          2264,
          11,
          370,
          321,
          820,
          536,
          11,
          1954,
          11,
          257,
          4338,
          2445,
          2487,
          13,
          51848
        ]
      },
      {
        "avg_logprob": -0.2024724573121035,
        "compression_ratio": 1.585551330798479,
        "end": 3147,
        "id": 1038,
        "no_speech_prob": 0.00022341572912409902,
        "seek": 314580,
        "start": 3145.8,
        "temperature": 0,
        "text": " Because your code has already used it.",
        "tokens": [
          50364,
          1436,
          428,
          3089,
          575,
          1217,
          1143,
          309,
          13,
          50424
        ]
      },
      {
        "avg_logprob": -0.2024724573121035,
        "compression_ratio": 1.585551330798479,
        "end": 3150.84,
        "id": 1039,
        "no_speech_prob": 0.00022341572912409902,
        "seek": 314580,
        "start": 3147,
        "temperature": 0,
        "text": " So I think it's a bad idea to, so let's call this txt.",
        "tokens": [
          50424,
          407,
          286,
          519,
          309,
          311,
          257,
          1578,
          1558,
          281,
          11,
          370,
          718,
          311,
          818,
          341,
          256,
          734,
          13,
          50616
        ]
      },
      {
        "avg_logprob": -0.2024724573121035,
        "compression_ratio": 1.585551330798479,
        "end": 3156.36,
        "id": 1040,
        "no_speech_prob": 0.00022341572912409902,
        "seek": 314580,
        "start": 3151.96,
        "temperature": 0,
        "text": " OK, so we can see here that, now, how do I, by the way, with textarea,",
        "tokens": [
          50672,
          2264,
          11,
          370,
          321,
          393,
          536,
          510,
          300,
          11,
          586,
          11,
          577,
          360,
          286,
          11,
          538,
          264,
          636,
          11,
          365,
          2487,
          35425,
          11,
          50892
        ]
      },
      {
        "avg_logprob": -0.2024724573121035,
        "compression_ratio": 1.585551330798479,
        "end": 3159.2400000000002,
        "id": 1041,
        "no_speech_prob": 0.00022341572912409902,
        "seek": 314580,
        "start": 3156.36,
        "temperature": 0,
        "text": " I kind of just want it to already start as like a slightly bigger thing,",
        "tokens": [
          50892,
          286,
          733,
          295,
          445,
          528,
          309,
          281,
          1217,
          722,
          382,
          411,
          257,
          4748,
          3801,
          551,
          11,
          51036
        ]
      },
      {
        "avg_logprob": -0.2024724573121035,
        "compression_ratio": 1.585551330798479,
        "end": 3160.2000000000003,
        "id": 1042,
        "no_speech_prob": 0.00022341572912409902,
        "seek": 314580,
        "start": 3159.2400000000002,
        "temperature": 0,
        "text": " which is kind of unnecessary.",
        "tokens": [
          51036,
          597,
          307,
          733,
          295,
          19350,
          13,
          51084
        ]
      },
      {
        "avg_logprob": -0.2024724573121035,
        "compression_ratio": 1.585551330798479,
        "end": 3162.04,
        "id": 1043,
        "no_speech_prob": 0.00022341572912409902,
        "seek": 314580,
        "start": 3160.2000000000003,
        "temperature": 0,
        "text": " I'm going to say columns equals 50.",
        "tokens": [
          51084,
          286,
          478,
          516,
          281,
          584,
          13766,
          6915,
          2625,
          13,
          51176
        ]
      },
      {
        "avg_logprob": -0.2024724573121035,
        "compression_ratio": 1.585551330798479,
        "end": 3163.88,
        "id": 1044,
        "no_speech_prob": 0.00022341572912409902,
        "seek": 314580,
        "start": 3163.1600000000003,
        "temperature": 0,
        "text": " So that's good.",
        "tokens": [
          51232,
          407,
          300,
          311,
          665,
          13,
          51268
        ]
      },
      {
        "avg_logprob": -0.2024724573121035,
        "compression_ratio": 1.585551330798479,
        "end": 3168.1200000000003,
        "id": 1045,
        "no_speech_prob": 0.00022341572912409902,
        "seek": 314580,
        "start": 3164.76,
        "temperature": 0,
        "text": " And rows equals 10.",
        "tokens": [
          51312,
          400,
          13241,
          6915,
          1266,
          13,
          51480
        ]
      },
      {
        "avg_logprob": -0.2024724573121035,
        "compression_ratio": 1.585551330798479,
        "end": 3174.52,
        "id": 1046,
        "no_speech_prob": 0.00022341572912409902,
        "seek": 314580,
        "start": 3168.92,
        "temperature": 0,
        "text": " OK, so now I can, the idea here is that what I want to do is, as I type here,",
        "tokens": [
          51520,
          2264,
          11,
          370,
          586,
          286,
          393,
          11,
          264,
          1558,
          510,
          307,
          300,
          437,
          286,
          528,
          281,
          360,
          307,
          11,
          382,
          286,
          2010,
          510,
          11,
          51800
        ]
      },
      {
        "avg_logprob": -0.20661130547523499,
        "compression_ratio": 1.6591760299625469,
        "end": 3178.84,
        "id": 1047,
        "no_speech_prob": 0.00010889645636780187,
        "seek": 317580,
        "start": 3176.76,
        "temperature": 0,
        "text": " I am happy, how are you?",
        "tokens": [
          50412,
          286,
          669,
          2055,
          11,
          577,
          366,
          291,
          30,
          50516
        ]
      },
      {
        "avg_logprob": -0.20661130547523499,
        "compression_ratio": 1.6591760299625469,
        "end": 3184.28,
        "id": 1048,
        "no_speech_prob": 0.00010889645636780187,
        "seek": 317580,
        "start": 3179.6400000000003,
        "temperature": 0,
        "text": " What I want to do is I want to live calculate the sentiment of this text",
        "tokens": [
          50556,
          708,
          286,
          528,
          281,
          360,
          307,
          286,
          528,
          281,
          1621,
          8873,
          264,
          16149,
          295,
          341,
          2487,
          50788
        ]
      },
      {
        "avg_logprob": -0.20661130547523499,
        "compression_ratio": 1.6591760299625469,
        "end": 3187.1600000000003,
        "id": 1049,
        "no_speech_prob": 0.00010889645636780187,
        "seek": 317580,
        "start": 3184.28,
        "temperature": 0,
        "text": " and have it appear below, as I press every single key.",
        "tokens": [
          50788,
          293,
          362,
          309,
          4204,
          2507,
          11,
          382,
          286,
          1886,
          633,
          2167,
          2141,
          13,
          50932
        ]
      },
      {
        "avg_logprob": -0.20661130547523499,
        "compression_ratio": 1.6591760299625469,
        "end": 3190.76,
        "id": 1050,
        "no_speech_prob": 0.00010889645636780187,
        "seek": 317580,
        "start": 3187.8,
        "temperature": 0,
        "text": " So first, I need to bind some sort of event.",
        "tokens": [
          50964,
          407,
          700,
          11,
          286,
          643,
          281,
          14786,
          512,
          1333,
          295,
          2280,
          13,
          51112
        ]
      },
      {
        "avg_logprob": -0.20661130547523499,
        "compression_ratio": 1.6591760299625469,
        "end": 3194.28,
        "id": 1051,
        "no_speech_prob": 0.00010889645636780187,
        "seek": 317580,
        "start": 3190.76,
        "temperature": 0,
        "text": " So I need an event for every time I type into this text area.",
        "tokens": [
          51112,
          407,
          286,
          643,
          364,
          2280,
          337,
          633,
          565,
          286,
          2010,
          666,
          341,
          2487,
          1859,
          13,
          51288
        ]
      },
      {
        "avg_logprob": -0.20661130547523499,
        "compression_ratio": 1.6591760299625469,
        "end": 3197.5600000000004,
        "id": 1052,
        "no_speech_prob": 0.00010889645636780187,
        "seek": 317580,
        "start": 3194.28,
        "temperature": 0,
        "text": " So first of all, I need access to this text area in JavaScript.",
        "tokens": [
          51288,
          407,
          700,
          295,
          439,
          11,
          286,
          643,
          2105,
          281,
          341,
          2487,
          1859,
          294,
          15778,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.20661130547523499,
        "compression_ratio": 1.6591760299625469,
        "end": 3199.1600000000003,
        "id": 1053,
        "no_speech_prob": 0.00010889645636780187,
        "seek": 317580,
        "start": 3197.5600000000004,
        "temperature": 0,
        "text": " And I can do that with the select function.",
        "tokens": [
          51452,
          400,
          286,
          393,
          360,
          300,
          365,
          264,
          3048,
          2445,
          13,
          51532
        ]
      },
      {
        "avg_logprob": -0.20661130547523499,
        "compression_ratio": 1.6591760299625469,
        "end": 3203.96,
        "id": 1054,
        "no_speech_prob": 0.00010889645636780187,
        "seek": 317580,
        "start": 3199.1600000000003,
        "temperature": 0,
        "text": " If I were jQuery, I'd use that dollar sign thing or document.getElementById",
        "tokens": [
          51532,
          759,
          286,
          645,
          361,
          35550,
          11,
          286,
          1116,
          764,
          300,
          7241,
          1465,
          551,
          420,
          4166,
          13,
          847,
          36,
          3054,
          27690,
          42739,
          51772
        ]
      },
      {
        "avg_logprob": -0.20639765067178695,
        "compression_ratio": 1.751054852320675,
        "end": 3205.32,
        "id": 1055,
        "no_speech_prob": 0.00005562193473451771,
        "seek": 320396,
        "start": 3204.2,
        "temperature": 0,
        "text": " with regular JavaScript.",
        "tokens": [
          50376,
          365,
          3890,
          15778,
          13,
          50432
        ]
      },
      {
        "avg_logprob": -0.20639765067178695,
        "compression_ratio": 1.751054852320675,
        "end": 3207.64,
        "id": 1056,
        "no_speech_prob": 0.00005562193473451771,
        "seek": 320396,
        "start": 3205.88,
        "temperature": 0,
        "text": " So I called id was txt.",
        "tokens": [
          50460,
          407,
          286,
          1219,
          4496,
          390,
          256,
          734,
          13,
          50548
        ]
      },
      {
        "avg_logprob": -0.20639765067178695,
        "compression_ratio": 1.751054852320675,
        "end": 3215.08,
        "id": 1057,
        "no_speech_prob": 0.00005562193473451771,
        "seek": 320396,
        "start": 3208.2,
        "temperature": 0,
        "text": " So what I need to do is say var txt equals select by the id txt.",
        "tokens": [
          50576,
          407,
          437,
          286,
          643,
          281,
          360,
          307,
          584,
          1374,
          256,
          734,
          6915,
          3048,
          538,
          264,
          4496,
          256,
          734,
          13,
          50920
        ]
      },
      {
        "avg_logprob": -0.20639765067178695,
        "compression_ratio": 1.751054852320675,
        "end": 3220.12,
        "id": 1058,
        "no_speech_prob": 0.00005562193473451771,
        "seek": 320396,
        "start": 3215.64,
        "temperature": 0,
        "text": " And then the event that I want to track is called an input event.",
        "tokens": [
          50948,
          400,
          550,
          264,
          2280,
          300,
          286,
          528,
          281,
          2837,
          307,
          1219,
          364,
          4846,
          2280,
          13,
          51172
        ]
      },
      {
        "avg_logprob": -0.20639765067178695,
        "compression_ratio": 1.751054852320675,
        "end": 3221.56,
        "id": 1059,
        "no_speech_prob": 0.00005562193473451771,
        "seek": 320396,
        "start": 3220.12,
        "temperature": 0,
        "text": " There's a changed event.",
        "tokens": [
          51172,
          821,
          311,
          257,
          3105,
          2280,
          13,
          51244
        ]
      },
      {
        "avg_logprob": -0.20639765067178695,
        "compression_ratio": 1.751054852320675,
        "end": 3223.4,
        "id": 1060,
        "no_speech_prob": 0.00005562193473451771,
        "seek": 320396,
        "start": 3221.56,
        "temperature": 0,
        "text": " There's a change event and an input event.",
        "tokens": [
          51244,
          821,
          311,
          257,
          1319,
          2280,
          293,
          364,
          4846,
          2280,
          13,
          51336
        ]
      },
      {
        "avg_logprob": -0.20639765067178695,
        "compression_ratio": 1.751054852320675,
        "end": 3225.4,
        "id": 1061,
        "no_speech_prob": 0.00005562193473451771,
        "seek": 320396,
        "start": 3223.4,
        "temperature": 0,
        "text": " It's a little weird in the browser.",
        "tokens": [
          51336,
          467,
          311,
          257,
          707,
          3657,
          294,
          264,
          11185,
          13,
          51436
        ]
      },
      {
        "avg_logprob": -0.20639765067178695,
        "compression_ratio": 1.751054852320675,
        "end": 3230.44,
        "id": 1062,
        "no_speech_prob": 0.00005562193473451771,
        "seek": 320396,
        "start": 3225.4,
        "temperature": 0,
        "text": " The changed event is only if I hit Enter or Tab, if I finished my action.",
        "tokens": [
          51436,
          440,
          3105,
          2280,
          307,
          787,
          498,
          286,
          2045,
          10399,
          420,
          14106,
          11,
          498,
          286,
          4335,
          452,
          3069,
          13,
          51688
        ]
      },
      {
        "avg_logprob": -0.20639765067178695,
        "compression_ratio": 1.751054852320675,
        "end": 3232.92,
        "id": 1063,
        "no_speech_prob": 0.00005562193473451771,
        "seek": 320396,
        "start": 3230.44,
        "temperature": 0,
        "text": " But the input event happens anytime I press a key at all.",
        "tokens": [
          51688,
          583,
          264,
          4846,
          2280,
          2314,
          13038,
          286,
          1886,
          257,
          2141,
          412,
          439,
          13,
          51812
        ]
      },
      {
        "avg_logprob": -0.16429390823631956,
        "compression_ratio": 1.7198067632850242,
        "end": 3236.84,
        "id": 1064,
        "no_speech_prob": 0.00015356147196143866,
        "seek": 323292,
        "start": 3232.92,
        "temperature": 0,
        "text": " So text.input, I'm going to call this event typing.",
        "tokens": [
          50364,
          407,
          2487,
          13,
          259,
          2582,
          11,
          286,
          478,
          516,
          281,
          818,
          341,
          2280,
          18444,
          13,
          50560
        ]
      },
      {
        "avg_logprob": -0.16429390823631956,
        "compression_ratio": 1.7198067632850242,
        "end": 3240.36,
        "id": 1065,
        "no_speech_prob": 0.00015356147196143866,
        "seek": 323292,
        "start": 3237.56,
        "temperature": 0,
        "text": " And I'm going to say now function typing.",
        "tokens": [
          50596,
          400,
          286,
          478,
          516,
          281,
          584,
          586,
          2445,
          18444,
          13,
          50736
        ]
      },
      {
        "avg_logprob": -0.16429390823631956,
        "compression_ratio": 1.7198067632850242,
        "end": 3245.16,
        "id": 1066,
        "no_speech_prob": 0.00015356147196143866,
        "seek": 323292,
        "start": 3241.4,
        "temperature": 0,
        "text": " And I'm just going to say console.log txt.value.",
        "tokens": [
          50788,
          400,
          286,
          478,
          445,
          516,
          281,
          584,
          11076,
          13,
          4987,
          256,
          734,
          13,
          29155,
          13,
          50976
        ]
      },
      {
        "avg_logprob": -0.16429390823631956,
        "compression_ratio": 1.7198067632850242,
        "end": 3249.64,
        "id": 1067,
        "no_speech_prob": 0.00015356147196143866,
        "seek": 323292,
        "start": 3245.16,
        "temperature": 0,
        "text": " So what I want to see is, as I'm typing, I just want to see that I have access",
        "tokens": [
          50976,
          407,
          437,
          286,
          528,
          281,
          536,
          307,
          11,
          382,
          286,
          478,
          18444,
          11,
          286,
          445,
          528,
          281,
          536,
          300,
          286,
          362,
          2105,
          51200
        ]
      },
      {
        "avg_logprob": -0.16429390823631956,
        "compression_ratio": 1.7198067632850242,
        "end": 3252.28,
        "id": 1068,
        "no_speech_prob": 0.00015356147196143866,
        "seek": 323292,
        "start": 3249.64,
        "temperature": 0,
        "text": " to the words that are in what I'm typing.",
        "tokens": [
          51200,
          281,
          264,
          2283,
          300,
          366,
          294,
          437,
          286,
          478,
          18444,
          13,
          51332
        ]
      },
      {
        "avg_logprob": -0.16429390823631956,
        "compression_ratio": 1.7198067632850242,
        "end": 3257.48,
        "id": 1069,
        "no_speech_prob": 0.00015356147196143866,
        "seek": 323292,
        "start": 3252.28,
        "temperature": 0,
        "text": " OK, so let's refresh this and say, hello, how are you?",
        "tokens": [
          51332,
          2264,
          11,
          370,
          718,
          311,
          15134,
          341,
          293,
          584,
          11,
          7751,
          11,
          577,
          366,
          291,
          30,
          51592
        ]
      },
      {
        "avg_logprob": -0.16429390823631956,
        "compression_ratio": 1.7198067632850242,
        "end": 3259.56,
        "id": 1070,
        "no_speech_prob": 0.00015356147196143866,
        "seek": 323292,
        "start": 3257.48,
        "temperature": 0,
        "text": " And you can see that this is working.",
        "tokens": [
          51592,
          400,
          291,
          393,
          536,
          300,
          341,
          307,
          1364,
          13,
          51696
        ]
      },
      {
        "avg_logprob": -0.15114381734062643,
        "compression_ratio": 1.8571428571428572,
        "end": 3267.16,
        "id": 1071,
        "no_speech_prob": 0.23932795226573944,
        "seek": 325956,
        "start": 3260.12,
        "temperature": 0,
        "text": " That as I type what I'm typing, every time I hit a key, it comes out in the console there.",
        "tokens": [
          50392,
          663,
          382,
          286,
          2010,
          437,
          286,
          478,
          18444,
          11,
          633,
          565,
          286,
          2045,
          257,
          2141,
          11,
          309,
          1487,
          484,
          294,
          264,
          11076,
          456,
          13,
          50744
        ]
      },
      {
        "avg_logprob": -0.15114381734062643,
        "compression_ratio": 1.8571428571428572,
        "end": 3268.44,
        "id": 1072,
        "no_speech_prob": 0.23932795226573944,
        "seek": 325956,
        "start": 3267.16,
        "temperature": 0,
        "text": " OK, so that's perfect.",
        "tokens": [
          50744,
          2264,
          11,
          370,
          300,
          311,
          2176,
          13,
          50808
        ]
      },
      {
        "avg_logprob": -0.15114381734062643,
        "compression_ratio": 1.8571428571428572,
        "end": 3269.64,
        "id": 1073,
        "no_speech_prob": 0.23932795226573944,
        "seek": 325956,
        "start": 3268.44,
        "temperature": 0,
        "text": " That's what I want.",
        "tokens": [
          50808,
          663,
          311,
          437,
          286,
          528,
          13,
          50868
        ]
      },
      {
        "avg_logprob": -0.15114381734062643,
        "compression_ratio": 1.8571428571428572,
        "end": 3272.44,
        "id": 1074,
        "no_speech_prob": 0.23932795226573944,
        "seek": 325956,
        "start": 3269.64,
        "temperature": 0,
        "text": " Now I can start to calculate the sentiment score.",
        "tokens": [
          50868,
          823,
          286,
          393,
          722,
          281,
          8873,
          264,
          16149,
          6175,
          13,
          51008
        ]
      },
      {
        "avg_logprob": -0.15114381734062643,
        "compression_ratio": 1.8571428571428572,
        "end": 3276.44,
        "id": 1075,
        "no_speech_prob": 0.23932795226573944,
        "seek": 325956,
        "start": 3273.08,
        "temperature": 0,
        "text": " So what should I, how should I calculate the sentiment score?",
        "tokens": [
          51040,
          407,
          437,
          820,
          286,
          11,
          577,
          820,
          286,
          8873,
          264,
          16149,
          6175,
          30,
          51208
        ]
      },
      {
        "avg_logprob": -0.15114381734062643,
        "compression_ratio": 1.8571428571428572,
        "end": 3280.36,
        "id": 1076,
        "no_speech_prob": 0.23932795226573944,
        "seek": 325956,
        "start": 3276.44,
        "temperature": 0,
        "text": " The first thing I need to do is split up the text by words.",
        "tokens": [
          51208,
          440,
          700,
          551,
          286,
          643,
          281,
          360,
          307,
          7472,
          493,
          264,
          2487,
          538,
          2283,
          13,
          51404
        ]
      },
      {
        "avg_logprob": -0.15114381734062643,
        "compression_ratio": 1.8571428571428572,
        "end": 3282.2,
        "id": 1077,
        "no_speech_prob": 0.23932795226573944,
        "seek": 325956,
        "start": 3280.36,
        "temperature": 0,
        "text": " And I can use a regular expression.",
        "tokens": [
          51404,
          400,
          286,
          393,
          764,
          257,
          3890,
          6114,
          13,
          51496
        ]
      },
      {
        "avg_logprob": -0.15114381734062643,
        "compression_ratio": 1.8571428571428572,
        "end": 3285.88,
        "id": 1078,
        "no_speech_prob": 0.23932795226573944,
        "seek": 325956,
        "start": 3282.2,
        "temperature": 0,
        "text": " See my videos about regular expressions using the split function.",
        "tokens": [
          51496,
          3008,
          452,
          2145,
          466,
          3890,
          15277,
          1228,
          264,
          7472,
          2445,
          13,
          51680
        ]
      },
      {
        "avg_logprob": -0.15114381734062643,
        "compression_ratio": 1.8571428571428572,
        "end": 3288.84,
        "id": 1079,
        "no_speech_prob": 0.23932795226573944,
        "seek": 325956,
        "start": 3285.88,
        "temperature": 0,
        "text": " So I'm going to say var, I'm going to say tokens, I'm going to say words.",
        "tokens": [
          51680,
          407,
          286,
          478,
          516,
          281,
          584,
          1374,
          11,
          286,
          478,
          516,
          281,
          584,
          22667,
          11,
          286,
          478,
          516,
          281,
          584,
          2283,
          13,
          51828
        ]
      },
      {
        "avg_logprob": -0.15370685403997247,
        "compression_ratio": 1.7205387205387206,
        "end": 3290.6800000000003,
        "id": 1080,
        "no_speech_prob": 0.000014510466826322954,
        "seek": 328884,
        "start": 3288.84,
        "temperature": 0,
        "text": " Words equals txt.split.",
        "tokens": [
          50364,
          32857,
          6915,
          256,
          734,
          13,
          46535,
          270,
          13,
          50456
        ]
      },
      {
        "avg_logprob": -0.15370685403997247,
        "compression_ratio": 1.7205387205387206,
        "end": 3293.7200000000003,
        "id": 1081,
        "no_speech_prob": 0.000014510466826322954,
        "seek": 328884,
        "start": 3291.48,
        "temperature": 0,
        "text": " And then I want to split by a regular expression.",
        "tokens": [
          50496,
          400,
          550,
          286,
          528,
          281,
          7472,
          538,
          257,
          3890,
          6114,
          13,
          50608
        ]
      },
      {
        "avg_logprob": -0.15370685403997247,
        "compression_ratio": 1.7205387205387206,
        "end": 3298.76,
        "id": 1082,
        "no_speech_prob": 0.000014510466826322954,
        "seek": 328884,
        "start": 3293.7200000000003,
        "temperature": 0,
        "text": " And a regular expression in JavaScript is a string, like a sequence of characters",
        "tokens": [
          50608,
          400,
          257,
          3890,
          6114,
          294,
          15778,
          307,
          257,
          6798,
          11,
          411,
          257,
          8310,
          295,
          4342,
          50860
        ]
      },
      {
        "avg_logprob": -0.15370685403997247,
        "compression_ratio": 1.7205387205387206,
        "end": 3301.96,
        "id": 1083,
        "no_speech_prob": 0.000014510466826322954,
        "seek": 328884,
        "start": 3298.76,
        "temperature": 0,
        "text": " that goes between forward slashes rather than between quotes.",
        "tokens": [
          50860,
          300,
          1709,
          1296,
          2128,
          1061,
          12808,
          2831,
          813,
          1296,
          19963,
          13,
          51020
        ]
      },
      {
        "avg_logprob": -0.15370685403997247,
        "compression_ratio": 1.7205387205387206,
        "end": 3303.88,
        "id": 1084,
        "no_speech_prob": 0.000014510466826322954,
        "seek": 328884,
        "start": 3301.96,
        "temperature": 0,
        "text": " And it defines a pattern in the text.",
        "tokens": [
          51020,
          400,
          309,
          23122,
          257,
          5102,
          294,
          264,
          2487,
          13,
          51116
        ]
      },
      {
        "avg_logprob": -0.15370685403997247,
        "compression_ratio": 1.7205387205387206,
        "end": 3305.96,
        "id": 1085,
        "no_speech_prob": 0.000014510466826322954,
        "seek": 328884,
        "start": 3303.88,
        "temperature": 0,
        "text": " And I have a whole set of videos all about regular expressions.",
        "tokens": [
          51116,
          400,
          286,
          362,
          257,
          1379,
          992,
          295,
          2145,
          439,
          466,
          3890,
          15277,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.15370685403997247,
        "compression_ratio": 1.7205387205387206,
        "end": 3309.7200000000003,
        "id": 1086,
        "no_speech_prob": 0.000014510466826322954,
        "seek": 328884,
        "start": 3306.52,
        "temperature": 0,
        "text": " What the pattern is, what separates the words?",
        "tokens": [
          51248,
          708,
          264,
          5102,
          307,
          11,
          437,
          34149,
          264,
          2283,
          30,
          51408
        ]
      },
      {
        "avg_logprob": -0.15370685403997247,
        "compression_ratio": 1.7205387205387206,
        "end": 3314.92,
        "id": 1087,
        "no_speech_prob": 0.000014510466826322954,
        "seek": 328884,
        "start": 3309.7200000000003,
        "temperature": 0,
        "text": " So whitespace, commas, periods, punctuation, whitespace, that sort of thing.",
        "tokens": [
          51408,
          407,
          21909,
          17940,
          11,
          800,
          296,
          11,
          13804,
          11,
          27006,
          16073,
          11,
          21909,
          17940,
          11,
          300,
          1333,
          295,
          551,
          13,
          51668
        ]
      },
      {
        "avg_logprob": -0.15370685403997247,
        "compression_ratio": 1.7205387205387206,
        "end": 3317,
        "id": 1088,
        "no_speech_prob": 0.000014510466826322954,
        "seek": 328884,
        "start": 3314.92,
        "temperature": 0,
        "text": " Basically, I'm going to do something kind of silly and simple here.",
        "tokens": [
          51668,
          8537,
          11,
          286,
          478,
          516,
          281,
          360,
          746,
          733,
          295,
          11774,
          293,
          2199,
          510,
          13,
          51772
        ]
      },
      {
        "avg_logprob": -0.1818114734086834,
        "compression_ratio": 1.7022222222222223,
        "end": 3322.6,
        "id": 1089,
        "no_speech_prob": 0.01243140920996666,
        "seek": 331700,
        "start": 3317,
        "temperature": 0,
        "text": " I'm going to say anything that's not a letter or number.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          584,
          1340,
          300,
          311,
          406,
          257,
          5063,
          420,
          1230,
          13,
          50644
        ]
      },
      {
        "avg_logprob": -0.1818114734086834,
        "compression_ratio": 1.7022222222222223,
        "end": 3327,
        "id": 1090,
        "no_speech_prob": 0.01243140920996666,
        "seek": 331700,
        "start": 3322.6,
        "temperature": 0,
        "text": " And so there's, I can actually just say backslash w.",
        "tokens": [
          50644,
          400,
          370,
          456,
          311,
          11,
          286,
          393,
          767,
          445,
          584,
          646,
          10418,
          1299,
          261,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1818114734086834,
        "compression_ratio": 1.7022222222222223,
        "end": 3331.4,
        "id": 1091,
        "no_speech_prob": 0.01243140920996666,
        "seek": 331700,
        "start": 3327,
        "temperature": 0,
        "text": " So this is slash w is any letter or number.",
        "tokens": [
          50864,
          407,
          341,
          307,
          17330,
          261,
          307,
          604,
          5063,
          420,
          1230,
          13,
          51084
        ]
      },
      {
        "avg_logprob": -0.1818114734086834,
        "compression_ratio": 1.7022222222222223,
        "end": 3335.08,
        "id": 1092,
        "no_speech_prob": 0.01243140920996666,
        "seek": 331700,
        "start": 3331.4,
        "temperature": 0,
        "text": " And backslash capital W is any non-letter, non-number.",
        "tokens": [
          51084,
          400,
          646,
          10418,
          1299,
          4238,
          343,
          307,
          604,
          2107,
          12,
          21248,
          11,
          2107,
          12,
          41261,
          13,
          51268
        ]
      },
      {
        "avg_logprob": -0.1818114734086834,
        "compression_ratio": 1.7022222222222223,
        "end": 3338.12,
        "id": 1093,
        "no_speech_prob": 0.01243140920996666,
        "seek": 331700,
        "start": 3335.08,
        "temperature": 0,
        "text": " And I could also say, maybe I should say or an apostrophe.",
        "tokens": [
          51268,
          400,
          286,
          727,
          611,
          584,
          11,
          1310,
          286,
          820,
          584,
          420,
          364,
          19484,
          27194,
          13,
          51420
        ]
      },
      {
        "avg_logprob": -0.1818114734086834,
        "compression_ratio": 1.7022222222222223,
        "end": 3339.24,
        "id": 1094,
        "no_speech_prob": 0.01243140920996666,
        "seek": 331700,
        "start": 3338.12,
        "temperature": 0,
        "text": " Oh no, but that's included.",
        "tokens": [
          51420,
          876,
          572,
          11,
          457,
          300,
          311,
          5556,
          13,
          51476
        ]
      },
      {
        "avg_logprob": -0.1818114734086834,
        "compression_ratio": 1.7022222222222223,
        "end": 3341,
        "id": 1095,
        "no_speech_prob": 0.01243140920996666,
        "seek": 331700,
        "start": 3339.24,
        "temperature": 0,
        "text": " No, I should have let it be or not.",
        "tokens": [
          51476,
          883,
          11,
          286,
          820,
          362,
          718,
          309,
          312,
          420,
          406,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1818114734086834,
        "compression_ratio": 1.7022222222222223,
        "end": 3341.8,
        "id": 1096,
        "no_speech_prob": 0.01243140920996666,
        "seek": 331700,
        "start": 3341,
        "temperature": 0,
        "text": " Anyway, whatever.",
        "tokens": [
          51564,
          5684,
          11,
          2035,
          13,
          51604
        ]
      },
      {
        "avg_logprob": -0.1818114734086834,
        "compression_ratio": 1.7022222222222223,
        "end": 3343.56,
        "id": 1097,
        "no_speech_prob": 0.01243140920996666,
        "seek": 331700,
        "start": 3342.6,
        "temperature": 0,
        "text": " This will be good enough for now.",
        "tokens": [
          51644,
          639,
          486,
          312,
          665,
          1547,
          337,
          586,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.20059738159179688,
        "compression_ratio": 1.7032520325203253,
        "end": 3349.08,
        "id": 1098,
        "no_speech_prob": 0.09946592897176743,
        "seek": 334356,
        "start": 3344.52,
        "temperature": 0,
        "text": " You could spend your life trying to define the best regular expression for splitting,",
        "tokens": [
          50412,
          509,
          727,
          3496,
          428,
          993,
          1382,
          281,
          6964,
          264,
          1151,
          3890,
          6114,
          337,
          30348,
          11,
          50640
        ]
      },
      {
        "avg_logprob": -0.20059738159179688,
        "compression_ratio": 1.7032520325203253,
        "end": 3354.2,
        "id": 1099,
        "no_speech_prob": 0.09946592897176743,
        "seek": 334356,
        "start": 3349.08,
        "temperature": 0,
        "text": " tokenizing a sentence into words or a paragraph into sentences",
        "tokens": [
          50640,
          14862,
          3319,
          257,
          8174,
          666,
          2283,
          420,
          257,
          18865,
          666,
          16579,
          50896
        ]
      },
      {
        "avg_logprob": -0.20059738159179688,
        "compression_ratio": 1.7032520325203253,
        "end": 3356.2,
        "id": 1100,
        "no_speech_prob": 0.09946592897176743,
        "seek": 334356,
        "start": 3354.2,
        "temperature": 0,
        "text": " or essay into paragraphs, all that sort of thing.",
        "tokens": [
          50896,
          420,
          16238,
          666,
          48910,
          11,
          439,
          300,
          1333,
          295,
          551,
          13,
          50996
        ]
      },
      {
        "avg_logprob": -0.20059738159179688,
        "compression_ratio": 1.7032520325203253,
        "end": 3359.32,
        "id": 1101,
        "no_speech_prob": 0.09946592897176743,
        "seek": 334356,
        "start": 3357.32,
        "temperature": 0,
        "text": " OK, so I'm going to do that.",
        "tokens": [
          51052,
          2264,
          11,
          370,
          286,
          478,
          516,
          281,
          360,
          300,
          13,
          51152
        ]
      },
      {
        "avg_logprob": -0.20059738159179688,
        "compression_ratio": 1.7032520325203253,
        "end": 3361.32,
        "id": 1102,
        "no_speech_prob": 0.09946592897176743,
        "seek": 334356,
        "start": 3359.32,
        "temperature": 0,
        "text": " And then I'm just going to see that this works.",
        "tokens": [
          51152,
          400,
          550,
          286,
          478,
          445,
          516,
          281,
          536,
          300,
          341,
          1985,
          13,
          51252
        ]
      },
      {
        "avg_logprob": -0.20059738159179688,
        "compression_ratio": 1.7032520325203253,
        "end": 3364.84,
        "id": 1103,
        "no_speech_prob": 0.09946592897176743,
        "seek": 334356,
        "start": 3361.32,
        "temperature": 0,
        "text": " I'm going to say console.log words just to check that.",
        "tokens": [
          51252,
          286,
          478,
          516,
          281,
          584,
          11076,
          13,
          4987,
          2283,
          445,
          281,
          1520,
          300,
          13,
          51428
        ]
      },
      {
        "avg_logprob": -0.20059738159179688,
        "compression_ratio": 1.7032520325203253,
        "end": 3365.32,
        "id": 1104,
        "no_speech_prob": 0.09946592897176743,
        "seek": 334356,
        "start": 3364.84,
        "temperature": 0,
        "text": " Hello.",
        "tokens": [
          51428,
          2425,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.20059738159179688,
        "compression_ratio": 1.7032520325203253,
        "end": 3367.88,
        "id": 1105,
        "no_speech_prob": 0.09946592897176743,
        "seek": 334356,
        "start": 3365.32,
        "temperature": 0,
        "text": " Oh, txt.split is not a function.",
        "tokens": [
          51452,
          876,
          11,
          256,
          734,
          13,
          46535,
          270,
          307,
          406,
          257,
          2445,
          13,
          51580
        ]
      },
      {
        "avg_logprob": -0.20059738159179688,
        "compression_ratio": 1.7032520325203253,
        "end": 3373.16,
        "id": 1106,
        "no_speech_prob": 0.09946592897176743,
        "seek": 334356,
        "start": 3367.88,
        "temperature": 0,
        "text": " Well, of course it's not a function because txt,",
        "tokens": [
          51580,
          1042,
          11,
          295,
          1164,
          309,
          311,
          406,
          257,
          2445,
          570,
          256,
          734,
          11,
          51844
        ]
      },
      {
        "avg_logprob": -0.19995767825117736,
        "compression_ratio": 1.5,
        "end": 3375.7999999999997,
        "id": 1107,
        "no_speech_prob": 0.000410847453167662,
        "seek": 337316,
        "start": 3373.96,
        "temperature": 0,
        "text": " I can't come up with variable names.",
        "tokens": [
          50404,
          286,
          393,
          380,
          808,
          493,
          365,
          7006,
          5288,
          13,
          50496
        ]
      },
      {
        "avg_logprob": -0.19995767825117736,
        "compression_ratio": 1.5,
        "end": 3383.96,
        "id": 1108,
        "no_speech_prob": 0.000410847453167662,
        "seek": 337316,
        "start": 3379.7999999999997,
        "temperature": 0,
        "text": " Word, text input, fine, equals txt.value.",
        "tokens": [
          50696,
          8725,
          11,
          2487,
          4846,
          11,
          2489,
          11,
          6915,
          256,
          734,
          13,
          29155,
          13,
          50904
        ]
      },
      {
        "avg_logprob": -0.19995767825117736,
        "compression_ratio": 1.5,
        "end": 3386.68,
        "id": 1109,
        "no_speech_prob": 0.000410847453167662,
        "seek": 337316,
        "start": 3384.8399999999997,
        "temperature": 0,
        "text": " So I want to get the value.",
        "tokens": [
          50948,
          407,
          286,
          528,
          281,
          483,
          264,
          2158,
          13,
          51040
        ]
      },
      {
        "avg_logprob": -0.19995767825117736,
        "compression_ratio": 1.5,
        "end": 3387.8799999999997,
        "id": 1110,
        "no_speech_prob": 0.000410847453167662,
        "seek": 337316,
        "start": 3386.68,
        "temperature": 0,
        "text": " That's the contents.",
        "tokens": [
          51040,
          663,
          311,
          264,
          15768,
          13,
          51100
        ]
      },
      {
        "avg_logprob": -0.19995767825117736,
        "compression_ratio": 1.5,
        "end": 3389.24,
        "id": 1111,
        "no_speech_prob": 0.000410847453167662,
        "seek": 337316,
        "start": 3387.8799999999997,
        "temperature": 0,
        "text": " And then I need to split that.",
        "tokens": [
          51100,
          400,
          550,
          286,
          643,
          281,
          7472,
          300,
          13,
          51168
        ]
      },
      {
        "avg_logprob": -0.19995767825117736,
        "compression_ratio": 1.5,
        "end": 3390.8399999999997,
        "id": 1112,
        "no_speech_prob": 0.000410847453167662,
        "seek": 337316,
        "start": 3389.24,
        "temperature": 0,
        "text": " So it's good that I checked that.",
        "tokens": [
          51168,
          407,
          309,
          311,
          665,
          300,
          286,
          10033,
          300,
          13,
          51248
        ]
      },
      {
        "avg_logprob": -0.19995767825117736,
        "compression_ratio": 1.5,
        "end": 3396.3599999999997,
        "id": 1113,
        "no_speech_prob": 0.000410847453167662,
        "seek": 337316,
        "start": 3391.7999999999997,
        "temperature": 0,
        "text": " And now I'm going to say, hello, this is a test.",
        "tokens": [
          51296,
          400,
          586,
          286,
          478,
          516,
          281,
          584,
          11,
          7751,
          11,
          341,
          307,
          257,
          1500,
          13,
          51524
        ]
      },
      {
        "avg_logprob": -0.19995767825117736,
        "compression_ratio": 1.5,
        "end": 3400.68,
        "id": 1114,
        "no_speech_prob": 0.000410847453167662,
        "seek": 337316,
        "start": 3396.3599999999997,
        "temperature": 0,
        "text": " So you can see as I type, it's splitting up into an array of words.",
        "tokens": [
          51524,
          407,
          291,
          393,
          536,
          382,
          286,
          2010,
          11,
          309,
          311,
          30348,
          493,
          666,
          364,
          10225,
          295,
          2283,
          13,
          51740
        ]
      },
      {
        "avg_logprob": -0.19995767825117736,
        "compression_ratio": 1.5,
        "end": 3401.24,
        "id": 1115,
        "no_speech_prob": 0.000410847453167662,
        "seek": 337316,
        "start": 3400.68,
        "temperature": 0,
        "text": " Perfect.",
        "tokens": [
          51740,
          10246,
          13,
          51768
        ]
      },
      {
        "avg_logprob": -0.1869371223449707,
        "compression_ratio": 1.5339366515837105,
        "end": 3403.3199999999997,
        "id": 1116,
        "no_speech_prob": 1.538172824666617e-7,
        "seek": 340124,
        "start": 3401.24,
        "temperature": 0,
        "text": " So now I need to iterate over that array of words.",
        "tokens": [
          50364,
          407,
          586,
          286,
          643,
          281,
          44497,
          670,
          300,
          10225,
          295,
          2283,
          13,
          50468
        ]
      },
      {
        "avg_logprob": -0.1869371223449707,
        "compression_ratio": 1.5339366515837105,
        "end": 3411.56,
        "id": 1117,
        "no_speech_prob": 1.538172824666617e-7,
        "seek": 340124,
        "start": 3404.3599999999997,
        "temperature": 0,
        "text": " So I need to say for var i equals 0, i is less than words.length, i plus plus.",
        "tokens": [
          50520,
          407,
          286,
          643,
          281,
          584,
          337,
          1374,
          741,
          6915,
          1958,
          11,
          741,
          307,
          1570,
          813,
          2283,
          13,
          45390,
          11,
          741,
          1804,
          1804,
          13,
          50880
        ]
      },
      {
        "avg_logprob": -0.1869371223449707,
        "compression_ratio": 1.5339366515837105,
        "end": 3413,
        "id": 1118,
        "no_speech_prob": 1.538172824666617e-7,
        "seek": 340124,
        "start": 3411.56,
        "temperature": 0,
        "text": " Now, here's something that's important.",
        "tokens": [
          50880,
          823,
          11,
          510,
          311,
          746,
          300,
          311,
          1021,
          13,
          50952
        ]
      },
      {
        "avg_logprob": -0.1869371223449707,
        "compression_ratio": 1.5339366515837105,
        "end": 3415.8799999999997,
        "id": 1119,
        "no_speech_prob": 1.538172824666617e-7,
        "seek": 340124,
        "start": 3413.7999999999997,
        "temperature": 0,
        "text": " Let's go back to our AFIN111 list.",
        "tokens": [
          50992,
          961,
          311,
          352,
          646,
          281,
          527,
          20389,
          1464,
          5348,
          16,
          1329,
          13,
          51096
        ]
      },
      {
        "avg_logprob": -0.1869371223449707,
        "compression_ratio": 1.5339366515837105,
        "end": 3417.8799999999997,
        "id": 1120,
        "no_speech_prob": 1.538172824666617e-7,
        "seek": 340124,
        "start": 3416.9199999999996,
        "temperature": 0,
        "text": " Notice something here.",
        "tokens": [
          51148,
          13428,
          746,
          510,
          13,
          51196
        ]
      },
      {
        "avg_logprob": -0.1869371223449707,
        "compression_ratio": 1.5339366515837105,
        "end": 3421.7999999999997,
        "id": 1121,
        "no_speech_prob": 1.538172824666617e-7,
        "seek": 340124,
        "start": 3418.4399999999996,
        "temperature": 0,
        "text": " All of these words are entirely lowercase.",
        "tokens": [
          51224,
          1057,
          295,
          613,
          2283,
          366,
          7696,
          3126,
          9765,
          13,
          51392
        ]
      },
      {
        "avg_logprob": -0.1869371223449707,
        "compression_ratio": 1.5339366515837105,
        "end": 3427.08,
        "id": 1122,
        "no_speech_prob": 1.538172824666617e-7,
        "seek": 340124,
        "start": 3421.7999999999997,
        "temperature": 0,
        "text": " There is not a single uppercase letter in this particular word list.",
        "tokens": [
          51392,
          821,
          307,
          406,
          257,
          2167,
          11775,
          2869,
          651,
          5063,
          294,
          341,
          1729,
          1349,
          1329,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.19246418504829865,
        "compression_ratio": 1.6136363636363635,
        "end": 3432.12,
        "id": 1123,
        "no_speech_prob": 0.0005033347406424582,
        "seek": 342708,
        "start": 3427.08,
        "temperature": 0,
        "text": " So one thing I definitely want to do is when I'm in my code,",
        "tokens": [
          50364,
          407,
          472,
          551,
          286,
          2138,
          528,
          281,
          360,
          307,
          562,
          286,
          478,
          294,
          452,
          3089,
          11,
          50616
        ]
      },
      {
        "avg_logprob": -0.19246418504829865,
        "compression_ratio": 1.6136363636363635,
        "end": 3438.2799999999997,
        "id": 1124,
        "no_speech_prob": 0.0005033347406424582,
        "seek": 342708,
        "start": 3432.12,
        "temperature": 0,
        "text": " the first thing I want to do is say word equals words index i dot to lowercase.",
        "tokens": [
          50616,
          264,
          700,
          551,
          286,
          528,
          281,
          360,
          307,
          584,
          1349,
          6915,
          2283,
          8186,
          741,
          5893,
          281,
          3126,
          9765,
          13,
          50924
        ]
      },
      {
        "avg_logprob": -0.19246418504829865,
        "compression_ratio": 1.6136363636363635,
        "end": 3443.16,
        "id": 1125,
        "no_speech_prob": 0.0005033347406424582,
        "seek": 342708,
        "start": 3438.2799999999997,
        "temperature": 0,
        "text": " Because when I look up to see what its score is, I need a lowercase word.",
        "tokens": [
          50924,
          1436,
          562,
          286,
          574,
          493,
          281,
          536,
          437,
          1080,
          6175,
          307,
          11,
          286,
          643,
          257,
          3126,
          9765,
          1349,
          13,
          51168
        ]
      },
      {
        "avg_logprob": -0.19246418504829865,
        "compression_ratio": 1.6136363636363635,
        "end": 3451.7999999999997,
        "id": 1126,
        "no_speech_prob": 0.0005033347406424582,
        "seek": 342708,
        "start": 3443.16,
        "temperature": 0,
        "text": " So now that I've done that, then I want to say, does that word exist?",
        "tokens": [
          51168,
          407,
          586,
          300,
          286,
          600,
          1096,
          300,
          11,
          550,
          286,
          528,
          281,
          584,
          11,
          775,
          300,
          1349,
          2514,
          30,
          51600
        ]
      },
      {
        "avg_logprob": -0.182903562273298,
        "compression_ratio": 1.5301724137931034,
        "end": 3459.2400000000002,
        "id": 1127,
        "no_speech_prob": 0.0001293154200538993,
        "seek": 345180,
        "start": 3451.8,
        "temperature": 0,
        "text": " So if AFIN word, does it exist?",
        "tokens": [
          50364,
          407,
          498,
          20389,
          1464,
          1349,
          11,
          775,
          309,
          2514,
          30,
          50736
        ]
      },
      {
        "avg_logprob": -0.182903562273298,
        "compression_ratio": 1.5301724137931034,
        "end": 3460.92,
        "id": 1128,
        "no_speech_prob": 0.0001293154200538993,
        "seek": 345180,
        "start": 3459.2400000000002,
        "temperature": 0,
        "text": " Now, I could use this has.",
        "tokens": [
          50736,
          823,
          11,
          286,
          727,
          764,
          341,
          575,
          13,
          50820
        ]
      },
      {
        "avg_logprob": -0.182903562273298,
        "compression_ratio": 1.5301724137931034,
        "end": 3463.4,
        "id": 1129,
        "no_speech_prob": 0.0001293154200538993,
        "seek": 345180,
        "start": 3460.92,
        "temperature": 0,
        "text": " I should probably use the has own property thing.",
        "tokens": [
          50820,
          286,
          820,
          1391,
          764,
          264,
          575,
          1065,
          4707,
          551,
          13,
          50944
        ]
      },
      {
        "avg_logprob": -0.182903562273298,
        "compression_ratio": 1.5301724137931034,
        "end": 3467.4,
        "id": 1130,
        "no_speech_prob": 0.0001293154200538993,
        "seek": 345180,
        "start": 3463.4,
        "temperature": 0,
        "text": " So this is me asking, let's say the word is cat.",
        "tokens": [
          50944,
          407,
          341,
          307,
          385,
          3365,
          11,
          718,
          311,
          584,
          264,
          1349,
          307,
          3857,
          13,
          51144
        ]
      },
      {
        "avg_logprob": -0.182903562273298,
        "compression_ratio": 1.5301724137931034,
        "end": 3472.52,
        "id": 1131,
        "no_speech_prob": 0.0001293154200538993,
        "seek": 345180,
        "start": 3467.4,
        "temperature": 0,
        "text": " If cat is in the AFIN word list, I'm going to get the score for cat, like 3.",
        "tokens": [
          51144,
          759,
          3857,
          307,
          294,
          264,
          20389,
          1464,
          1349,
          1329,
          11,
          286,
          478,
          516,
          281,
          483,
          264,
          6175,
          337,
          3857,
          11,
          411,
          805,
          13,
          51400
        ]
      },
      {
        "avg_logprob": -0.182903562273298,
        "compression_ratio": 1.5301724137931034,
        "end": 3475,
        "id": 1132,
        "no_speech_prob": 0.0001293154200538993,
        "seek": 345180,
        "start": 3473.32,
        "temperature": 0,
        "text": " Maybe kitten would be like 4.",
        "tokens": [
          51440,
          2704,
          39696,
          576,
          312,
          411,
          1017,
          13,
          51524
        ]
      },
      {
        "avg_logprob": -0.182903562273298,
        "compression_ratio": 1.5301724137931034,
        "end": 3475.32,
        "id": 1133,
        "no_speech_prob": 0.0001293154200538993,
        "seek": 345180,
        "start": 3475,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          51524,
          286,
          500,
          380,
          458,
          13,
          51540
        ]
      },
      {
        "avg_logprob": -0.182903562273298,
        "compression_ratio": 1.5301724137931034,
        "end": 3477.0800000000004,
        "id": 1134,
        "no_speech_prob": 0.0001293154200538993,
        "seek": 345180,
        "start": 3475.96,
        "temperature": 0,
        "text": " Cats and kittens, they're equal.",
        "tokens": [
          51572,
          40902,
          293,
          47363,
          11,
          436,
          434,
          2681,
          13,
          51628
        ]
      },
      {
        "avg_logprob": -0.182903562273298,
        "compression_ratio": 1.5301724137931034,
        "end": 3477.6400000000003,
        "id": 1135,
        "no_speech_prob": 0.0001293154200538993,
        "seek": 345180,
        "start": 3477.0800000000004,
        "temperature": 0,
        "text": " I love it.",
        "tokens": [
          51628,
          286,
          959,
          309,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.182903562273298,
        "compression_ratio": 1.5301724137931034,
        "end": 3478.92,
        "id": 1136,
        "no_speech_prob": 0.0001293154200538993,
        "seek": 345180,
        "start": 3477.6400000000003,
        "temperature": 0,
        "text": " Anyway, what am I talking about?",
        "tokens": [
          51656,
          5684,
          11,
          437,
          669,
          286,
          1417,
          466,
          30,
          51720
        ]
      },
      {
        "avg_logprob": -0.204145261976454,
        "compression_ratio": 1.6493055555555556,
        "end": 3482.76,
        "id": 1137,
        "no_speech_prob": 0.0015247771516442299,
        "seek": 347892,
        "start": 3478.92,
        "temperature": 0,
        "text": " I'm so worried about offending words with their positive negative score.",
        "tokens": [
          50364,
          286,
          478,
          370,
          5804,
          466,
          766,
          2029,
          2283,
          365,
          641,
          3353,
          3671,
          6175,
          13,
          50556
        ]
      },
      {
        "avg_logprob": -0.204145261976454,
        "compression_ratio": 1.6493055555555556,
        "end": 3486.12,
        "id": 1138,
        "no_speech_prob": 0.0015247771516442299,
        "seek": 347892,
        "start": 3483.4,
        "temperature": 0,
        "text": " It's a very strange personality I have.",
        "tokens": [
          50588,
          467,
          311,
          257,
          588,
          5861,
          9033,
          286,
          362,
          13,
          50724
        ]
      },
      {
        "avg_logprob": -0.204145261976454,
        "compression_ratio": 1.6493055555555556,
        "end": 3488.76,
        "id": 1139,
        "no_speech_prob": 0.0015247771516442299,
        "seek": 347892,
        "start": 3486.12,
        "temperature": 0,
        "text": " OK, but there was a point to what I was saying, which is that,",
        "tokens": [
          50724,
          2264,
          11,
          457,
          456,
          390,
          257,
          935,
          281,
          437,
          286,
          390,
          1566,
          11,
          597,
          307,
          300,
          11,
          50856
        ]
      },
      {
        "avg_logprob": -0.204145261976454,
        "compression_ratio": 1.6493055555555556,
        "end": 3494.36,
        "id": 1140,
        "no_speech_prob": 0.0015247771516442299,
        "seek": 347892,
        "start": 3493.16,
        "temperature": 0,
        "text": " that, ah, right.",
        "tokens": [
          51076,
          300,
          11,
          3716,
          11,
          558,
          13,
          51136
        ]
      },
      {
        "avg_logprob": -0.204145261976454,
        "compression_ratio": 1.6493055555555556,
        "end": 3496.6800000000003,
        "id": 1141,
        "no_speech_prob": 0.0015247771516442299,
        "seek": 347892,
        "start": 3494.36,
        "temperature": 0,
        "text": " If cat exists, I'll get the score, like 4.",
        "tokens": [
          51136,
          759,
          3857,
          8198,
          11,
          286,
          603,
          483,
          264,
          6175,
          11,
          411,
          1017,
          13,
          51252
        ]
      },
      {
        "avg_logprob": -0.204145261976454,
        "compression_ratio": 1.6493055555555556,
        "end": 3499.64,
        "id": 1142,
        "no_speech_prob": 0.0015247771516442299,
        "seek": 347892,
        "start": 3496.6800000000003,
        "temperature": 0,
        "text": " If it doesn't, I'll get undefined, which will evaluate to false.",
        "tokens": [
          51252,
          759,
          309,
          1177,
          380,
          11,
          286,
          603,
          483,
          674,
          5666,
          2001,
          11,
          597,
          486,
          13059,
          281,
          7908,
          13,
          51400
        ]
      },
      {
        "avg_logprob": -0.204145261976454,
        "compression_ratio": 1.6493055555555556,
        "end": 3501.32,
        "id": 1143,
        "no_speech_prob": 0.0015247771516442299,
        "seek": 347892,
        "start": 3499.64,
        "temperature": 0,
        "text": " But there's a weird sort of issue here.",
        "tokens": [
          51400,
          583,
          456,
          311,
          257,
          3657,
          1333,
          295,
          2734,
          510,
          13,
          51484
        ]
      },
      {
        "avg_logprob": -0.204145261976454,
        "compression_ratio": 1.6493055555555556,
        "end": 3505,
        "id": 1144,
        "no_speech_prob": 0.0015247771516442299,
        "seek": 347892,
        "start": 3501.32,
        "temperature": 0,
        "text": " Like sometimes, like there might be like some built-in JavaScript properties",
        "tokens": [
          51484,
          1743,
          2171,
          11,
          411,
          456,
          1062,
          312,
          411,
          512,
          3094,
          12,
          259,
          15778,
          7221,
          51668
        ]
      },
      {
        "avg_logprob": -0.204145261976454,
        "compression_ratio": 1.6493055555555556,
        "end": 3508.12,
        "id": 1145,
        "no_speech_prob": 0.0015247771516442299,
        "seek": 347892,
        "start": 3505,
        "temperature": 0,
        "text": " that happen to have the same word as a word in the essay.",
        "tokens": [
          51668,
          300,
          1051,
          281,
          362,
          264,
          912,
          1349,
          382,
          257,
          1349,
          294,
          264,
          16238,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.16388984962745948,
        "compression_ratio": 1.5578512396694215,
        "end": 3513.24,
        "id": 1146,
        "no_speech_prob": 0.00002318747283425182,
        "seek": 350812,
        "start": 3508.12,
        "temperature": 0,
        "text": " So to be 100% sure, I can say has own property.",
        "tokens": [
          50364,
          407,
          281,
          312,
          2319,
          4,
          988,
          11,
          286,
          393,
          584,
          575,
          1065,
          4707,
          13,
          50620
        ]
      },
      {
        "avg_logprob": -0.16388984962745948,
        "compression_ratio": 1.5578512396694215,
        "end": 3519.96,
        "id": 1147,
        "no_speech_prob": 0.00002318747283425182,
        "seek": 350812,
        "start": 3513.7999999999997,
        "temperature": 0,
        "text": " This will evaluate to true or false if word is a particular property of this list",
        "tokens": [
          50648,
          639,
          486,
          13059,
          281,
          2074,
          420,
          7908,
          498,
          1349,
          307,
          257,
          1729,
          4707,
          295,
          341,
          1329,
          50956
        ]
      },
      {
        "avg_logprob": -0.16388984962745948,
        "compression_ratio": 1.5578512396694215,
        "end": 3524.52,
        "id": 1148,
        "no_speech_prob": 0.00002318747283425182,
        "seek": 350812,
        "start": 3519.96,
        "temperature": 0,
        "text": " that I've developed that's not part of the sort of JavaScript object thingy language itself,",
        "tokens": [
          50956,
          300,
          286,
          600,
          4743,
          300,
          311,
          406,
          644,
          295,
          264,
          1333,
          295,
          15778,
          2657,
          551,
          88,
          2856,
          2564,
          11,
          51184
        ]
      },
      {
        "avg_logprob": -0.16388984962745948,
        "compression_ratio": 1.5578512396694215,
        "end": 3525.24,
        "id": 1149,
        "no_speech_prob": 0.00002318747283425182,
        "seek": 350812,
        "start": 3524.52,
        "temperature": 0,
        "text": " whatever.",
        "tokens": [
          51184,
          2035,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.16388984962745948,
        "compression_ratio": 1.5578512396694215,
        "end": 3530.04,
        "id": 1150,
        "no_speech_prob": 0.00002318747283425182,
        "seek": 350812,
        "start": 3525.24,
        "temperature": 0,
        "text": " OK, so if it does, first of all, I need to say score equals 0.",
        "tokens": [
          51220,
          2264,
          11,
          370,
          498,
          309,
          775,
          11,
          700,
          295,
          439,
          11,
          286,
          643,
          281,
          584,
          6175,
          6915,
          1958,
          13,
          51460
        ]
      },
      {
        "avg_logprob": -0.16388984962745948,
        "compression_ratio": 1.5578512396694215,
        "end": 3535.3199999999997,
        "id": 1151,
        "no_speech_prob": 0.00002318747283425182,
        "seek": 350812,
        "start": 3530.04,
        "temperature": 0,
        "text": " I can say score plus equals AFIN word.",
        "tokens": [
          51460,
          286,
          393,
          584,
          6175,
          1804,
          6915,
          20389,
          1464,
          1349,
          13,
          51724
        ]
      },
      {
        "avg_logprob": -0.16388984962745948,
        "compression_ratio": 1.5578512396694215,
        "end": 3537.64,
        "id": 1152,
        "no_speech_prob": 0.00002318747283425182,
        "seek": 350812,
        "start": 3535.3199999999997,
        "temperature": 0,
        "text": " So now I can look up the score and add it.",
        "tokens": [
          51724,
          407,
          586,
          286,
          393,
          574,
          493,
          264,
          6175,
          293,
          909,
          309,
          13,
          51840
        ]
      },
      {
        "avg_logprob": -0.2062123917244576,
        "compression_ratio": 1.4491017964071857,
        "end": 3544.6,
        "id": 1153,
        "no_speech_prob": 0.00006401994323823601,
        "seek": 353764,
        "start": 3537.64,
        "temperature": 0,
        "text": " And then what I'm going to do is let's add a little area for results.",
        "tokens": [
          50364,
          400,
          550,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          718,
          311,
          909,
          257,
          707,
          1859,
          337,
          3542,
          13,
          50712
        ]
      },
      {
        "avg_logprob": -0.2062123917244576,
        "compression_ratio": 1.4491017964071857,
        "end": 3548.92,
        "id": 1154,
        "no_speech_prob": 0.00006401994323823601,
        "seek": 353764,
        "start": 3545.16,
        "temperature": 0,
        "text": " I'm going to say PID equals score.",
        "tokens": [
          50740,
          286,
          478,
          516,
          281,
          584,
          430,
          2777,
          6915,
          6175,
          13,
          50928
        ]
      },
      {
        "avg_logprob": -0.2062123917244576,
        "compression_ratio": 1.4491017964071857,
        "end": 3552.8399999999997,
        "id": 1155,
        "no_speech_prob": 0.00006401994323823601,
        "seek": 353764,
        "start": 3551.16,
        "temperature": 0,
        "text": " And I'm going to add some things.",
        "tokens": [
          51040,
          400,
          286,
          478,
          516,
          281,
          909,
          512,
          721,
          13,
          51124
        ]
      },
      {
        "avg_logprob": -0.2062123917244576,
        "compression_ratio": 1.4491017964071857,
        "end": 3559.48,
        "id": 1156,
        "no_speech_prob": 0.00006401994323823601,
        "seek": 353764,
        "start": 3552.8399999999997,
        "temperature": 0,
        "text": " Score, comparative, and what else?",
        "tokens": [
          51124,
          47901,
          11,
          39292,
          11,
          293,
          437,
          1646,
          30,
          51456
        ]
      },
      {
        "avg_logprob": -0.2062123917244576,
        "compression_ratio": 1.4491017964071857,
        "end": 3564.2,
        "id": 1157,
        "no_speech_prob": 0.00006401994323823601,
        "seek": 353764,
        "start": 3559.48,
        "temperature": 0,
        "text": " Maybe I'll do a word list just so we can see everything on the page.",
        "tokens": [
          51456,
          2704,
          286,
          603,
          360,
          257,
          1349,
          1329,
          445,
          370,
          321,
          393,
          536,
          1203,
          322,
          264,
          3028,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.24853859824695806,
        "compression_ratio": 1.4904761904761905,
        "end": 3569.72,
        "id": 1158,
        "no_speech_prob": 0.01495691854506731,
        "seek": 356420,
        "start": 3564.8399999999997,
        "temperature": 0,
        "text": " So OK, so I added three paragraphs because I want to report some information on the page.",
        "tokens": [
          50396,
          407,
          2264,
          11,
          370,
          286,
          3869,
          1045,
          48910,
          570,
          286,
          528,
          281,
          2275,
          512,
          1589,
          322,
          264,
          3028,
          13,
          50640
        ]
      },
      {
        "avg_logprob": -0.24853859824695806,
        "compression_ratio": 1.4904761904761905,
        "end": 3579.7999999999997,
        "id": 1159,
        "no_speech_prob": 0.01495691854506731,
        "seek": 356420,
        "start": 3569.72,
        "temperature": 0,
        "text": " So the first thing I can do now in JavaScript here is say, I can say var scoreP equals select",
        "tokens": [
          50640,
          407,
          264,
          700,
          551,
          286,
          393,
          360,
          586,
          294,
          15778,
          510,
          307,
          584,
          11,
          286,
          393,
          584,
          1374,
          6175,
          47,
          6915,
          3048,
          51144
        ]
      },
      {
        "avg_logprob": -0.24853859824695806,
        "compression_ratio": 1.4904761904761905,
        "end": 3581.08,
        "id": 1160,
        "no_speech_prob": 0.01495691854506731,
        "seek": 356420,
        "start": 3580.6,
        "temperature": 0,
        "text": " score.",
        "tokens": [
          51184,
          6175,
          13,
          51208
        ]
      },
      {
        "avg_logprob": -0.24853859824695806,
        "compression_ratio": 1.4904761904761905,
        "end": 3584.9199999999996,
        "id": 1161,
        "no_speech_prob": 0.01495691854506731,
        "seek": 356420,
        "start": 3581.8799999999997,
        "temperature": 0,
        "text": " And then say scoreP.html is the score.",
        "tokens": [
          51248,
          400,
          550,
          584,
          6175,
          47,
          13,
          357,
          15480,
          307,
          264,
          6175,
          13,
          51400
        ]
      },
      {
        "avg_logprob": -0.24853859824695806,
        "compression_ratio": 1.4904761904761905,
        "end": 3593.3199999999997,
        "id": 1162,
        "no_speech_prob": 0.01495691854506731,
        "seek": 356420,
        "start": 3589.96,
        "temperature": 0,
        "text": " This is sort of, there's better ways I could do this, but this will work just fine.",
        "tokens": [
          51652,
          639,
          307,
          1333,
          295,
          11,
          456,
          311,
          1101,
          2098,
          286,
          727,
          360,
          341,
          11,
          457,
          341,
          486,
          589,
          445,
          2489,
          13,
          51820
        ]
      },
      {
        "avg_logprob": -0.22499895095825195,
        "compression_ratio": 1.695945945945946,
        "end": 3597.24,
        "id": 1163,
        "no_speech_prob": 0.00026947871083393693,
        "seek": 359420,
        "start": 3594.68,
        "temperature": 0,
        "text": " Comparative, select comparative.",
        "tokens": [
          50388,
          2432,
          2181,
          1166,
          11,
          3048,
          39292,
          13,
          50516
        ]
      },
      {
        "avg_logprob": -0.22499895095825195,
        "compression_ratio": 1.695945945945946,
        "end": 3607.3999999999996,
        "id": 1164,
        "no_speech_prob": 0.00026947871083393693,
        "seek": 359420,
        "start": 3599.56,
        "temperature": 0,
        "text": " And then the comparative is the score divided by words.length.",
        "tokens": [
          50632,
          400,
          550,
          264,
          39292,
          307,
          264,
          6175,
          6666,
          538,
          2283,
          13,
          45390,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.22499895095825195,
        "compression_ratio": 1.695945945945946,
        "end": 3610.2799999999997,
        "id": 1165,
        "no_speech_prob": 0.00026947871083393693,
        "seek": 359420,
        "start": 3607.3999999999996,
        "temperature": 0,
        "text": " So the score divided by the number of words in the file.",
        "tokens": [
          51024,
          407,
          264,
          6175,
          6666,
          538,
          264,
          1230,
          295,
          2283,
          294,
          264,
          3991,
          13,
          51168
        ]
      },
      {
        "avg_logprob": -0.22499895095825195,
        "compression_ratio": 1.695945945945946,
        "end": 3621.48,
        "id": 1166,
        "no_speech_prob": 0.00026947871083393693,
        "seek": 359420,
        "start": 3610.8399999999997,
        "temperature": 0,
        "text": " And then also maybe word list, select word list, and word list HTML.",
        "tokens": [
          51196,
          400,
          550,
          611,
          1310,
          1349,
          1329,
          11,
          3048,
          1349,
          1329,
          11,
          293,
          1349,
          1329,
          17995,
          13,
          51728
        ]
      },
      {
        "avg_logprob": -0.22499895095825195,
        "compression_ratio": 1.695945945945946,
        "end": 3623.16,
        "id": 1167,
        "no_speech_prob": 0.00026947871083393693,
        "seek": 359420,
        "start": 3621.48,
        "temperature": 0,
        "text": " Oh, I'm not saving the words.",
        "tokens": [
          51728,
          876,
          11,
          286,
          478,
          406,
          6816,
          264,
          2283,
          13,
          51812
        ]
      },
      {
        "avg_logprob": -0.18666437838939912,
        "compression_ratio": 1.5906735751295338,
        "end": 3624.2799999999997,
        "id": 1168,
        "no_speech_prob": 0.000022125650502857752,
        "seek": 362316,
        "start": 3623.16,
        "temperature": 0,
        "text": " So let's make a list.",
        "tokens": [
          50364,
          407,
          718,
          311,
          652,
          257,
          1329,
          13,
          50420
        ]
      },
      {
        "avg_logprob": -0.18666437838939912,
        "compression_ratio": 1.5906735751295338,
        "end": 3629.3999999999996,
        "id": 1169,
        "no_speech_prob": 0.000022125650502857752,
        "seek": 362316,
        "start": 3627.24,
        "temperature": 0,
        "text": " So let's make a list.",
        "tokens": [
          50568,
          407,
          718,
          311,
          652,
          257,
          1329,
          13,
          50676
        ]
      },
      {
        "avg_logprob": -0.18666437838939912,
        "compression_ratio": 1.5906735751295338,
        "end": 3632.6,
        "id": 1170,
        "no_speech_prob": 0.000022125650502857752,
        "seek": 362316,
        "start": 3629.3999999999996,
        "temperature": 0,
        "text": " We'll call it scored words.",
        "tokens": [
          50676,
          492,
          603,
          818,
          309,
          18139,
          2283,
          13,
          50836
        ]
      },
      {
        "avg_logprob": -0.18666437838939912,
        "compression_ratio": 1.5906735751295338,
        "end": 3634.12,
        "id": 1171,
        "no_speech_prob": 0.000022125650502857752,
        "seek": 362316,
        "start": 3632.6,
        "temperature": 0,
        "text": " And it's an empty array.",
        "tokens": [
          50836,
          400,
          309,
          311,
          364,
          6707,
          10225,
          13,
          50912
        ]
      },
      {
        "avg_logprob": -0.18666437838939912,
        "compression_ratio": 1.5906735751295338,
        "end": 3639.8799999999997,
        "id": 1172,
        "no_speech_prob": 0.000022125650502857752,
        "seek": 362316,
        "start": 3634.12,
        "temperature": 0,
        "text": " And if I ever find one of those, I'm going to say scored words.push the word.",
        "tokens": [
          50912,
          400,
          498,
          286,
          1562,
          915,
          472,
          295,
          729,
          11,
          286,
          478,
          516,
          281,
          584,
          18139,
          2283,
          13,
          79,
          1498,
          264,
          1349,
          13,
          51200
        ]
      },
      {
        "avg_logprob": -0.18666437838939912,
        "compression_ratio": 1.5906735751295338,
        "end": 3647.7999999999997,
        "id": 1173,
        "no_speech_prob": 0.000022125650502857752,
        "seek": 362316,
        "start": 3640.6,
        "temperature": 0,
        "text": " Oh, and maybe colon its score, something like that.",
        "tokens": [
          51236,
          876,
          11,
          293,
          1310,
          8255,
          1080,
          6175,
          11,
          746,
          411,
          300,
          13,
          51596
        ]
      },
      {
        "avg_logprob": -0.18666437838939912,
        "compression_ratio": 1.5906735751295338,
        "end": 3652.2,
        "id": 1174,
        "no_speech_prob": 0.000022125650502857752,
        "seek": 362316,
        "start": 3647.7999999999997,
        "temperature": 0,
        "text": " So I'm not being very thoughtful about the design of the display of the results.",
        "tokens": [
          51596,
          407,
          286,
          478,
          406,
          885,
          588,
          21566,
          466,
          264,
          1715,
          295,
          264,
          4674,
          295,
          264,
          3542,
          13,
          51816
        ]
      },
      {
        "avg_logprob": -0.22571090941733502,
        "compression_ratio": 1.543859649122807,
        "end": 3655.64,
        "id": 1175,
        "no_speech_prob": 0.000020145667804172263,
        "seek": 365316,
        "start": 3654.04,
        "temperature": 0,
        "text": " But comparative.",
        "tokens": [
          50408,
          583,
          39292,
          13,
          50488
        ]
      },
      {
        "avg_logprob": -0.22571090941733502,
        "compression_ratio": 1.543859649122807,
        "end": 3657.3999999999996,
        "id": 1176,
        "no_speech_prob": 0.000020145667804172263,
        "seek": 365316,
        "start": 3655.64,
        "temperature": 0,
        "text": " OK, but let's see if this works.",
        "tokens": [
          50488,
          2264,
          11,
          457,
          718,
          311,
          536,
          498,
          341,
          1985,
          13,
          50576
        ]
      },
      {
        "avg_logprob": -0.22571090941733502,
        "compression_ratio": 1.543859649122807,
        "end": 3658.92,
        "id": 1177,
        "no_speech_prob": 0.000020145667804172263,
        "seek": 365316,
        "start": 3658.52,
        "temperature": 0,
        "text": " Hello.",
        "tokens": [
          50632,
          2425,
          13,
          50652
        ]
      },
      {
        "avg_logprob": -0.22571090941733502,
        "compression_ratio": 1.543859649122807,
        "end": 3661.24,
        "id": 1178,
        "no_speech_prob": 0.000020145667804172263,
        "seek": 365316,
        "start": 3660.12,
        "temperature": 0,
        "text": " Uncaught reference error.",
        "tokens": [
          50712,
          1156,
          496,
          1599,
          6408,
          6713,
          13,
          50768
        ]
      },
      {
        "avg_logprob": -0.22571090941733502,
        "compression_ratio": 1.543859649122807,
        "end": 3662.92,
        "id": 1179,
        "no_speech_prob": 0.000020145667804172263,
        "seek": 365316,
        "start": 3661.24,
        "temperature": 0,
        "text": " Score words is not defined.",
        "tokens": [
          50768,
          47901,
          2283,
          307,
          406,
          7642,
          13,
          50852
        ]
      },
      {
        "avg_logprob": -0.22571090941733502,
        "compression_ratio": 1.543859649122807,
        "end": 3666.3599999999997,
        "id": 1180,
        "no_speech_prob": 0.000020145667804172263,
        "seek": 365316,
        "start": 3663.96,
        "temperature": 0,
        "text": " Scored words, scored words.",
        "tokens": [
          50904,
          2747,
          2769,
          2283,
          11,
          18139,
          2283,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.22571090941733502,
        "compression_ratio": 1.543859649122807,
        "end": 3670.44,
        "id": 1181,
        "no_speech_prob": 0.000020145667804172263,
        "seek": 365316,
        "start": 3668.8399999999997,
        "temperature": 0,
        "text": " And scored words.",
        "tokens": [
          51148,
          400,
          18139,
          2283,
          13,
          51228
        ]
      },
      {
        "avg_logprob": -0.22571090941733502,
        "compression_ratio": 1.543859649122807,
        "end": 3671.56,
        "id": 1182,
        "no_speech_prob": 0.000020145667804172263,
        "seek": 365316,
        "start": 3670.44,
        "temperature": 0,
        "text": " I don't know what I'm doing here.",
        "tokens": [
          51228,
          286,
          500,
          380,
          458,
          437,
          286,
          478,
          884,
          510,
          13,
          51284
        ]
      },
      {
        "avg_logprob": -0.22571090941733502,
        "compression_ratio": 1.543859649122807,
        "end": 3672.7599999999998,
        "id": 1183,
        "no_speech_prob": 0.000020145667804172263,
        "seek": 365316,
        "start": 3671.56,
        "temperature": 0,
        "text": " OK, let's try this.",
        "tokens": [
          51284,
          2264,
          11,
          718,
          311,
          853,
          341,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.22571090941733502,
        "compression_ratio": 1.543859649122807,
        "end": 3676.52,
        "id": 1184,
        "no_speech_prob": 0.000020145667804172263,
        "seek": 365316,
        "start": 3674.68,
        "temperature": 0,
        "text": " So OK, let's try typing.",
        "tokens": [
          51440,
          407,
          2264,
          11,
          718,
          311,
          853,
          18444,
          13,
          51532
        ]
      },
      {
        "avg_logprob": -0.22571090941733502,
        "compression_ratio": 1.543859649122807,
        "end": 3680.6,
        "id": 1185,
        "no_speech_prob": 0.000020145667804172263,
        "seek": 365316,
        "start": 3677.08,
        "temperature": 0,
        "text": " I love kittens and rainbows.",
        "tokens": [
          51560,
          286,
          959,
          47363,
          293,
          4830,
          21118,
          13,
          51736
        ]
      },
      {
        "avg_logprob": -0.24351389114170857,
        "compression_ratio": 1.4493670886075949,
        "end": 3689,
        "id": 1186,
        "no_speech_prob": 0.0000388310436392203,
        "seek": 368060,
        "start": 3681.56,
        "temperature": 0,
        "text": " Also, unicorns and the color purple and pink and red and green and blue.",
        "tokens": [
          50412,
          2743,
          11,
          28122,
          82,
          293,
          264,
          2017,
          9656,
          293,
          7022,
          293,
          2182,
          293,
          3092,
          293,
          3344,
          13,
          50784
        ]
      },
      {
        "avg_logprob": -0.24351389114170857,
        "compression_ratio": 1.4493670886075949,
        "end": 3690.7599999999998,
        "id": 1187,
        "no_speech_prob": 0.0000388310436392203,
        "seek": 368060,
        "start": 3689,
        "temperature": 0,
        "text": " I am happy.",
        "tokens": [
          50784,
          286,
          669,
          2055,
          13,
          50872
        ]
      },
      {
        "avg_logprob": -0.24351389114170857,
        "compression_ratio": 1.4493670886075949,
        "end": 3693.96,
        "id": 1188,
        "no_speech_prob": 0.0000388310436392203,
        "seek": 368060,
        "start": 3690.7599999999998,
        "temperature": 0,
        "text": " So, so very, very happy and joyful.",
        "tokens": [
          50872,
          407,
          11,
          370,
          588,
          11,
          588,
          2055,
          293,
          33090,
          13,
          51032
        ]
      },
      {
        "avg_logprob": -0.24351389114170857,
        "compression_ratio": 1.4493670886075949,
        "end": 3699.3199999999997,
        "id": 1189,
        "no_speech_prob": 0.0000388310436392203,
        "seek": 368060,
        "start": 3695.88,
        "temperature": 0,
        "text": " So you can see, oh, a couple of things are wrong here.",
        "tokens": [
          51128,
          407,
          291,
          393,
          536,
          11,
          1954,
          11,
          257,
          1916,
          295,
          721,
          366,
          2085,
          510,
          13,
          51300
        ]
      },
      {
        "avg_logprob": -0.24351389114170857,
        "compression_ratio": 1.4493670886075949,
        "end": 3701.4,
        "id": 1190,
        "no_speech_prob": 0.0000388310436392203,
        "seek": 368060,
        "start": 3699.96,
        "temperature": 0,
        "text": " This is not at all correct.",
        "tokens": [
          51332,
          639,
          307,
          406,
          412,
          439,
          3006,
          13,
          51404
        ]
      },
      {
        "avg_logprob": -0.24351389114170857,
        "compression_ratio": 1.4493670886075949,
        "end": 3704.36,
        "id": 1191,
        "no_speech_prob": 0.0000388310436392203,
        "seek": 368060,
        "start": 3702.7599999999998,
        "temperature": 0,
        "text": " So what's happening here?",
        "tokens": [
          51472,
          407,
          437,
          311,
          2737,
          510,
          30,
          51552
        ]
      },
      {
        "avg_logprob": -0.14643789220739295,
        "compression_ratio": 1.6801801801801801,
        "end": 3711.88,
        "id": 1192,
        "no_speech_prob": 0.00015597979654558003,
        "seek": 370436,
        "start": 3704.44,
        "temperature": 0,
        "text": " It's getting the information from the JSON file.",
        "tokens": [
          50368,
          467,
          311,
          1242,
          264,
          1589,
          490,
          264,
          31828,
          3991,
          13,
          50740
        ]
      },
      {
        "avg_logprob": -0.14643789220739295,
        "compression_ratio": 1.6801801801801801,
        "end": 3713.56,
        "id": 1193,
        "no_speech_prob": 0.00015597979654558003,
        "seek": 370436,
        "start": 3711.88,
        "temperature": 0,
        "text": " And it's adding those numbers together.",
        "tokens": [
          50740,
          400,
          309,
          311,
          5127,
          729,
          3547,
          1214,
          13,
          50824
        ]
      },
      {
        "avg_logprob": -0.14643789220739295,
        "compression_ratio": 1.6801801801801801,
        "end": 3718.84,
        "id": 1194,
        "no_speech_prob": 0.00015597979654558003,
        "seek": 370436,
        "start": 3713.56,
        "temperature": 0,
        "text": " It's saying 3 plus 3 plus 3 plus 3 equals 3, 3, 3, 3, 3.",
        "tokens": [
          50824,
          467,
          311,
          1566,
          805,
          1804,
          805,
          1804,
          805,
          1804,
          805,
          6915,
          805,
          11,
          805,
          11,
          805,
          11,
          805,
          11,
          805,
          13,
          51088
        ]
      },
      {
        "avg_logprob": -0.14643789220739295,
        "compression_ratio": 1.6801801801801801,
        "end": 3720.44,
        "id": 1195,
        "no_speech_prob": 0.00015597979654558003,
        "seek": 370436,
        "start": 3718.84,
        "temperature": 0,
        "text": " So it's not adding them as numbers.",
        "tokens": [
          51088,
          407,
          309,
          311,
          406,
          5127,
          552,
          382,
          3547,
          13,
          51168
        ]
      },
      {
        "avg_logprob": -0.14643789220739295,
        "compression_ratio": 1.6801801801801801,
        "end": 3724.04,
        "id": 1196,
        "no_speech_prob": 0.00015597979654558003,
        "seek": 370436,
        "start": 3720.44,
        "temperature": 0,
        "text": " It thinks everything is a string, which is also why I'm getting some goofy results here.",
        "tokens": [
          51168,
          467,
          7309,
          1203,
          307,
          257,
          6798,
          11,
          597,
          307,
          611,
          983,
          286,
          478,
          1242,
          512,
          42995,
          3542,
          510,
          13,
          51348
        ]
      },
      {
        "avg_logprob": -0.14643789220739295,
        "compression_ratio": 1.6801801801801801,
        "end": 3731.96,
        "id": 1197,
        "no_speech_prob": 0.00015597979654558003,
        "seek": 370436,
        "start": 3725,
        "temperature": 0,
        "text": " So one thing that I need to do here is make sure that when I get that score,",
        "tokens": [
          51396,
          407,
          472,
          551,
          300,
          286,
          643,
          281,
          360,
          510,
          307,
          652,
          988,
          300,
          562,
          286,
          483,
          300,
          6175,
          11,
          51744
        ]
      },
      {
        "avg_logprob": -0.14643789220739295,
        "compression_ratio": 1.6801801801801801,
        "end": 3733.48,
        "id": 1198,
        "no_speech_prob": 0.00015597979654558003,
        "seek": 370436,
        "start": 3731.96,
        "temperature": 0,
        "text": " I convert it to a number.",
        "tokens": [
          51744,
          286,
          7620,
          309,
          281,
          257,
          1230,
          13,
          51820
        ]
      },
      {
        "avg_logprob": -0.2205343246459961,
        "compression_ratio": 1.4896907216494846,
        "end": 3735.4,
        "id": 1199,
        "no_speech_prob": 0.00015118159353733063,
        "seek": 373436,
        "start": 3734.36,
        "temperature": 0,
        "text": " So let's fix that.",
        "tokens": [
          50364,
          407,
          718,
          311,
          3191,
          300,
          13,
          50416
        ]
      },
      {
        "avg_logprob": -0.2205343246459961,
        "compression_ratio": 1.4896907216494846,
        "end": 3738.84,
        "id": 1200,
        "no_speech_prob": 0.00015118159353733063,
        "seek": 373436,
        "start": 3735.96,
        "temperature": 0,
        "text": " That score that's coming out of the word list, I need to convert it to a number.",
        "tokens": [
          50444,
          663,
          6175,
          300,
          311,
          1348,
          484,
          295,
          264,
          1349,
          1329,
          11,
          286,
          643,
          281,
          7620,
          309,
          281,
          257,
          1230,
          13,
          50588
        ]
      },
      {
        "avg_logprob": -0.2205343246459961,
        "compression_ratio": 1.4896907216494846,
        "end": 3747.32,
        "id": 1201,
        "no_speech_prob": 0.00015118159353733063,
        "seek": 373436,
        "start": 3739.96,
        "temperature": 0,
        "text": " I should have just happy, sad, not so sad, but not so happy.",
        "tokens": [
          50644,
          286,
          820,
          362,
          445,
          2055,
          11,
          4227,
          11,
          406,
          370,
          4227,
          11,
          457,
          406,
          370,
          2055,
          13,
          51012
        ]
      },
      {
        "avg_logprob": -0.2205343246459961,
        "compression_ratio": 1.4896907216494846,
        "end": 3758.28,
        "id": 1202,
        "no_speech_prob": 0.00015118159353733063,
        "seek": 373436,
        "start": 3748.1200000000003,
        "temperature": 0,
        "text": " Happy and joyful and full of scared fear for things that scream and monsters.",
        "tokens": [
          51052,
          8277,
          293,
          33090,
          293,
          1577,
          295,
          5338,
          4240,
          337,
          721,
          300,
          7291,
          293,
          15785,
          13,
          51560
        ]
      },
      {
        "avg_logprob": -0.2205343246459961,
        "compression_ratio": 1.4896907216494846,
        "end": 3763.08,
        "id": 1203,
        "no_speech_prob": 0.00015118159353733063,
        "seek": 373436,
        "start": 3759,
        "temperature": 0,
        "text": " But I like, am I still recording a video tutorial?",
        "tokens": [
          51596,
          583,
          286,
          411,
          11,
          669,
          286,
          920,
          6613,
          257,
          960,
          7073,
          30,
          51800
        ]
      },
      {
        "avg_logprob": -0.20982276068793404,
        "compression_ratio": 1.562992125984252,
        "end": 3766.36,
        "id": 1204,
        "no_speech_prob": 0.0001233942311955616,
        "seek": 376308,
        "start": 3763.16,
        "temperature": 0,
        "text": " Or did I just become hypnotized by my weird nonsensical typing?",
        "tokens": [
          50368,
          1610,
          630,
          286,
          445,
          1813,
          42944,
          1602,
          538,
          452,
          3657,
          297,
          892,
          694,
          804,
          18444,
          30,
          50528
        ]
      },
      {
        "avg_logprob": -0.20982276068793404,
        "compression_ratio": 1.562992125984252,
        "end": 3771.7999999999997,
        "id": 1205,
        "no_speech_prob": 0.0001233942311955616,
        "seek": 376308,
        "start": 3766.36,
        "temperature": 0,
        "text": " So you can see, I'm now getting, now, I'm seeing some weird stuff going on here,",
        "tokens": [
          50528,
          407,
          291,
          393,
          536,
          11,
          286,
          478,
          586,
          1242,
          11,
          586,
          11,
          286,
          478,
          2577,
          512,
          3657,
          1507,
          516,
          322,
          510,
          11,
          50800
        ]
      },
      {
        "avg_logprob": -0.20982276068793404,
        "compression_ratio": 1.562992125984252,
        "end": 3776.68,
        "id": 1206,
        "no_speech_prob": 0.0001233942311955616,
        "seek": 376308,
        "start": 3771.7999999999997,
        "temperature": 0,
        "text": " which might just be the fact that I'm not being very thoughtful about how I display the information.",
        "tokens": [
          50800,
          597,
          1062,
          445,
          312,
          264,
          1186,
          300,
          286,
          478,
          406,
          885,
          588,
          21566,
          466,
          577,
          286,
          4674,
          264,
          1589,
          13,
          51044
        ]
      },
      {
        "avg_logprob": -0.20982276068793404,
        "compression_ratio": 1.562992125984252,
        "end": 3779.64,
        "id": 1207,
        "no_speech_prob": 0.0001233942311955616,
        "seek": 376308,
        "start": 3777.64,
        "temperature": 0,
        "text": " But let's do some more tests here.",
        "tokens": [
          51092,
          583,
          718,
          311,
          360,
          512,
          544,
          6921,
          510,
          13,
          51192
        ]
      },
      {
        "avg_logprob": -0.20982276068793404,
        "compression_ratio": 1.562992125984252,
        "end": 3782.44,
        "id": 1208,
        "no_speech_prob": 0.0001233942311955616,
        "seek": 376308,
        "start": 3780.2,
        "temperature": 0,
        "text": " If I say sad, OK, that works.",
        "tokens": [
          51220,
          759,
          286,
          584,
          4227,
          11,
          2264,
          11,
          300,
          1985,
          13,
          51332
        ]
      },
      {
        "avg_logprob": -0.20982276068793404,
        "compression_ratio": 1.562992125984252,
        "end": 3783.4,
        "id": 1209,
        "no_speech_prob": 0.0001233942311955616,
        "seek": 376308,
        "start": 3782.44,
        "temperature": 0,
        "text": " Score is negative 2.",
        "tokens": [
          51332,
          47901,
          307,
          3671,
          568,
          13,
          51380
        ]
      },
      {
        "avg_logprob": -0.20982276068793404,
        "compression_ratio": 1.562992125984252,
        "end": 3784.52,
        "id": 1210,
        "no_speech_prob": 0.0001233942311955616,
        "seek": 376308,
        "start": 3783.4,
        "temperature": 0,
        "text": " Oops, camera went off.",
        "tokens": [
          51380,
          21726,
          11,
          2799,
          1437,
          766,
          13,
          51436
        ]
      },
      {
        "avg_logprob": -0.20982276068793404,
        "compression_ratio": 1.562992125984252,
        "end": 3791.7999999999997,
        "id": 1211,
        "no_speech_prob": 0.0001233942311955616,
        "seek": 376308,
        "start": 3788.84,
        "temperature": 0,
        "text": " If I say sad, exactly what I would expect.",
        "tokens": [
          51652,
          759,
          286,
          584,
          4227,
          11,
          2293,
          437,
          286,
          576,
          2066,
          13,
          51800
        ]
      },
      {
        "avg_logprob": -0.20219441878894143,
        "compression_ratio": 1.6007905138339922,
        "end": 3793.0800000000004,
        "id": 1212,
        "no_speech_prob": 0.0036499605048447847,
        "seek": 379180,
        "start": 3791.8,
        "temperature": 0,
        "text": " Let me move this over here.",
        "tokens": [
          50364,
          961,
          385,
          1286,
          341,
          670,
          510,
          13,
          50428
        ]
      },
      {
        "avg_logprob": -0.20219441878894143,
        "compression_ratio": 1.6007905138339922,
        "end": 3795.8,
        "id": 1213,
        "no_speech_prob": 0.0036499605048447847,
        "seek": 379180,
        "start": 3793.96,
        "temperature": 0,
        "text": " I got a total score of negative 2.",
        "tokens": [
          50472,
          286,
          658,
          257,
          3217,
          6175,
          295,
          3671,
          568,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.20219441878894143,
        "compression_ratio": 1.6007905138339922,
        "end": 3799.2400000000002,
        "id": 1214,
        "no_speech_prob": 0.0036499605048447847,
        "seek": 379180,
        "start": 3795.8,
        "temperature": 0,
        "text": " Comparative is negative 2 because it's negative 2 divided by one word total.",
        "tokens": [
          50564,
          2432,
          2181,
          1166,
          307,
          3671,
          568,
          570,
          309,
          311,
          3671,
          568,
          6666,
          538,
          472,
          1349,
          3217,
          13,
          50736
        ]
      },
      {
        "avg_logprob": -0.20219441878894143,
        "compression_ratio": 1.6007905138339922,
        "end": 3802.6800000000003,
        "id": 1215,
        "no_speech_prob": 0.0036499605048447847,
        "seek": 379180,
        "start": 3799.2400000000002,
        "temperature": 0,
        "text": " If I say happy, OK, so this is working.",
        "tokens": [
          50736,
          759,
          286,
          584,
          2055,
          11,
          2264,
          11,
          370,
          341,
          307,
          1364,
          13,
          50908
        ]
      },
      {
        "avg_logprob": -0.20219441878894143,
        "compression_ratio": 1.6007905138339922,
        "end": 3807.0800000000004,
        "id": 1216,
        "no_speech_prob": 0.0036499605048447847,
        "seek": 379180,
        "start": 3803.48,
        "temperature": 0,
        "text": " And abandoned, I remember, was in there, is negative 1.",
        "tokens": [
          50948,
          400,
          13732,
          11,
          286,
          1604,
          11,
          390,
          294,
          456,
          11,
          307,
          3671,
          502,
          13,
          51128
        ]
      },
      {
        "avg_logprob": -0.20219441878894143,
        "compression_ratio": 1.6007905138339922,
        "end": 3808.44,
        "id": 1217,
        "no_speech_prob": 0.0036499605048447847,
        "seek": 379180,
        "start": 3807.0800000000004,
        "temperature": 0,
        "text": " So it's just the formatting.",
        "tokens": [
          51128,
          407,
          309,
          311,
          445,
          264,
          39366,
          13,
          51196
        ]
      },
      {
        "avg_logprob": -0.20219441878894143,
        "compression_ratio": 1.6007905138339922,
        "end": 3809.7200000000003,
        "id": 1218,
        "no_speech_prob": 0.0036499605048447847,
        "seek": 379180,
        "start": 3808.44,
        "temperature": 0,
        "text": " So we're really done.",
        "tokens": [
          51196,
          407,
          321,
          434,
          534,
          1096,
          13,
          51260
        ]
      },
      {
        "avg_logprob": -0.20219441878894143,
        "compression_ratio": 1.6007905138339922,
        "end": 3811.4,
        "id": 1219,
        "no_speech_prob": 0.0036499605048447847,
        "seek": 379180,
        "start": 3809.7200000000003,
        "temperature": 0,
        "text": " I could copy and paste some text.",
        "tokens": [
          51260,
          286,
          727,
          5055,
          293,
          9163,
          512,
          2487,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.20219441878894143,
        "compression_ratio": 1.6007905138339922,
        "end": 3820.76,
        "id": 1220,
        "no_speech_prob": 0.0036499605048447847,
        "seek": 379180,
        "start": 3811.4,
        "temperature": 0,
        "text": " Like, I don't know, if I go to kittens Wikipedia, let's get some text about kittens.",
        "tokens": [
          51344,
          1743,
          11,
          286,
          500,
          380,
          458,
          11,
          498,
          286,
          352,
          281,
          47363,
          28999,
          11,
          718,
          311,
          483,
          512,
          2487,
          466,
          47363,
          13,
          51812
        ]
      },
      {
        "avg_logprob": -0.18706661892920426,
        "compression_ratio": 1.4461538461538461,
        "end": 3827.5600000000004,
        "id": 1221,
        "no_speech_prob": 0.000046838700654916465,
        "seek": 382180,
        "start": 3821.96,
        "temperature": 0,
        "text": " And see what happens if I paste it in here.",
        "tokens": [
          50372,
          400,
          536,
          437,
          2314,
          498,
          286,
          9163,
          309,
          294,
          510,
          13,
          50652
        ]
      },
      {
        "avg_logprob": -0.18706661892920426,
        "compression_ratio": 1.4461538461538461,
        "end": 3831.5600000000004,
        "id": 1222,
        "no_speech_prob": 0.000046838700654916465,
        "seek": 382180,
        "start": 3828.6000000000004,
        "temperature": 0,
        "text": " And we can see I got a score of 4.",
        "tokens": [
          50704,
          400,
          321,
          393,
          536,
          286,
          658,
          257,
          6175,
          295,
          1017,
          13,
          50852
        ]
      },
      {
        "avg_logprob": -0.18706661892920426,
        "compression_ratio": 1.4461538461538461,
        "end": 3833.32,
        "id": 1223,
        "no_speech_prob": 0.000046838700654916465,
        "seek": 382180,
        "start": 3831.5600000000004,
        "temperature": 0,
        "text": " Comparative of 0.04.",
        "tokens": [
          50852,
          2432,
          2181,
          1166,
          295,
          1958,
          13,
          14565,
          13,
          50940
        ]
      },
      {
        "avg_logprob": -0.18706661892920426,
        "compression_ratio": 1.4461538461538461,
        "end": 3834.6000000000004,
        "id": 1224,
        "no_speech_prob": 0.000046838700654916465,
        "seek": 382180,
        "start": 3833.32,
        "temperature": 0,
        "text": " This is positive text.",
        "tokens": [
          50940,
          639,
          307,
          3353,
          2487,
          13,
          51004
        ]
      },
      {
        "avg_logprob": -0.18706661892920426,
        "compression_ratio": 1.4461538461538461,
        "end": 3840.04,
        "id": 1225,
        "no_speech_prob": 0.000046838700654916465,
        "seek": 382180,
        "start": 3835.6400000000003,
        "temperature": 0,
        "text": " The words that I got were solid and enjoy.",
        "tokens": [
          51056,
          440,
          2283,
          300,
          286,
          658,
          645,
          5100,
          293,
          2103,
          13,
          51276
        ]
      },
      {
        "avg_logprob": -0.18706661892920426,
        "compression_ratio": 1.4461538461538461,
        "end": 3841.7200000000003,
        "id": 1226,
        "no_speech_prob": 0.000046838700654916465,
        "seek": 382180,
        "start": 3840.04,
        "temperature": 0,
        "text": " I should get a score of 6.",
        "tokens": [
          51276,
          286,
          820,
          483,
          257,
          6175,
          295,
          1386,
          13,
          51360
        ]
      },
      {
        "avg_logprob": -0.18706661892920426,
        "compression_ratio": 1.4461538461538461,
        "end": 3848.84,
        "id": 1227,
        "no_speech_prob": 0.000046838700654916465,
        "seek": 382180,
        "start": 3847.32,
        "temperature": 0,
        "text": " So something is wrong here, right?",
        "tokens": [
          51640,
          407,
          746,
          307,
          2085,
          510,
          11,
          558,
          30,
          51716
        ]
      },
      {
        "avg_logprob": -0.18706661892920426,
        "compression_ratio": 1.4461538461538461,
        "end": 3849.5600000000004,
        "id": 1228,
        "no_speech_prob": 0.000046838700654916465,
        "seek": 382180,
        "start": 3848.84,
        "temperature": 0,
        "text": " What did I forget?",
        "tokens": [
          51716,
          708,
          630,
          286,
          2870,
          30,
          51752
        ]
      },
      {
        "avg_logprob": -0.18706661892920426,
        "compression_ratio": 1.4461538461538461,
        "end": 3851.4,
        "id": 1229,
        "no_speech_prob": 0.000046838700654916465,
        "seek": 382180,
        "start": 3849.5600000000004,
        "temperature": 0,
        "text": " I made a, there's a bug in my code.",
        "tokens": [
          51752,
          286,
          1027,
          257,
          11,
          456,
          311,
          257,
          7426,
          294,
          452,
          3089,
          13,
          51844
        ]
      },
      {
        "avg_logprob": -0.2713041423279562,
        "compression_ratio": 1.3935483870967742,
        "end": 3853.5600000000004,
        "id": 1230,
        "no_speech_prob": 0.00005829120345879346,
        "seek": 385180,
        "start": 3852.04,
        "temperature": 0,
        "text": " Score plus equals.",
        "tokens": [
          50376,
          47901,
          1804,
          6915,
          13,
          50452
        ]
      },
      {
        "avg_logprob": -0.2713041423279562,
        "compression_ratio": 1.3935483870967742,
        "end": 3860.52,
        "id": 1231,
        "no_speech_prob": 0.00005829120345879346,
        "seek": 385180,
        "start": 3855.6400000000003,
        "temperature": 0,
        "text": " Let's say, let's just do console.log word and score.",
        "tokens": [
          50556,
          961,
          311,
          584,
          11,
          718,
          311,
          445,
          360,
          11076,
          13,
          4987,
          1349,
          293,
          6175,
          13,
          50800
        ]
      },
      {
        "avg_logprob": -0.2713041423279562,
        "compression_ratio": 1.3935483870967742,
        "end": 3863.6400000000003,
        "id": 1232,
        "no_speech_prob": 0.00005829120345879346,
        "seek": 385180,
        "start": 3862.2000000000003,
        "temperature": 0,
        "text": " Yeah, something's wrong with the math.",
        "tokens": [
          50884,
          865,
          11,
          746,
          311,
          2085,
          365,
          264,
          5221,
          13,
          50956
        ]
      },
      {
        "avg_logprob": -0.2713041423279562,
        "compression_ratio": 1.3935483870967742,
        "end": 3865.7200000000003,
        "id": 1233,
        "no_speech_prob": 0.00005829120345879346,
        "seek": 385180,
        "start": 3865.1600000000003,
        "temperature": 0,
        "text": " What did I say?",
        "tokens": [
          51032,
          708,
          630,
          286,
          584,
          30,
          51060
        ]
      },
      {
        "avg_logprob": -0.2713041423279562,
        "compression_ratio": 1.3935483870967742,
        "end": 3866.92,
        "id": 1234,
        "no_speech_prob": 0.00005829120345879346,
        "seek": 385180,
        "start": 3865.7200000000003,
        "temperature": 0,
        "text": " Solid 2.",
        "tokens": [
          51060,
          26664,
          568,
          13,
          51120
        ]
      },
      {
        "avg_logprob": -0.2713041423279562,
        "compression_ratio": 1.3935483870967742,
        "end": 3870.36,
        "id": 1235,
        "no_speech_prob": 0.00005829120345879346,
        "seek": 385180,
        "start": 3869.32,
        "temperature": 0,
        "text": " What was the other word?",
        "tokens": [
          51240,
          708,
          390,
          264,
          661,
          1349,
          30,
          51292
        ]
      },
      {
        "avg_logprob": -0.2713041423279562,
        "compression_ratio": 1.3935483870967742,
        "end": 3871.96,
        "id": 1236,
        "no_speech_prob": 0.00005829120345879346,
        "seek": 385180,
        "start": 3871.0800000000004,
        "temperature": 0,
        "text": " Whatever, happy.",
        "tokens": [
          51328,
          8541,
          11,
          2055,
          13,
          51372
        ]
      },
      {
        "avg_logprob": -0.2713041423279562,
        "compression_ratio": 1.3935483870967742,
        "end": 3876.28,
        "id": 1237,
        "no_speech_prob": 0.00005829120345879346,
        "seek": 385180,
        "start": 3875.5600000000004,
        "temperature": 0,
        "text": " 5.",
        "tokens": [
          51552,
          1025,
          13,
          51588
        ]
      },
      {
        "avg_logprob": -0.2713041423279562,
        "compression_ratio": 1.3935483870967742,
        "end": 3877.96,
        "id": 1238,
        "no_speech_prob": 0.00005829120345879346,
        "seek": 385180,
        "start": 3876.28,
        "temperature": 0,
        "text": " Solid, ooh, wait.",
        "tokens": [
          51588,
          26664,
          11,
          17024,
          11,
          1699,
          13,
          51672
        ]
      },
      {
        "avg_logprob": -0.2713041423279562,
        "compression_ratio": 1.3935483870967742,
        "end": 3880.84,
        "id": 1239,
        "no_speech_prob": 0.00005829120345879346,
        "seek": 385180,
        "start": 3879,
        "temperature": 0,
        "text": " Solid 0, happy 2.",
        "tokens": [
          51724,
          26664,
          1958,
          11,
          2055,
          568,
          13,
          51816
        ]
      },
      {
        "avg_logprob": -0.3007029104923856,
        "compression_ratio": 1.2440944881889764,
        "end": 3883.1600000000003,
        "id": 1240,
        "no_speech_prob": 0.00021654377633240074,
        "seek": 388180,
        "start": 3882.6800000000003,
        "temperature": 0,
        "text": " Huh?",
        "tokens": [
          50408,
          8063,
          30,
          50432
        ]
      },
      {
        "avg_logprob": -0.3007029104923856,
        "compression_ratio": 1.2440944881889764,
        "end": 3886.28,
        "id": 1241,
        "no_speech_prob": 0.00021654377633240074,
        "seek": 388180,
        "start": 3884.84,
        "temperature": 0,
        "text": " Debugging time, hold on, hold on.",
        "tokens": [
          50516,
          27347,
          697,
          3249,
          565,
          11,
          1797,
          322,
          11,
          1797,
          322,
          13,
          50588
        ]
      },
      {
        "avg_logprob": -0.3007029104923856,
        "compression_ratio": 1.2440944881889764,
        "end": 3891.48,
        "id": 1242,
        "no_speech_prob": 0.00021654377633240074,
        "seek": 388180,
        "start": 3890.2000000000003,
        "temperature": 0,
        "text": " Solid has a score of 2.",
        "tokens": [
          50784,
          26664,
          575,
          257,
          6175,
          295,
          568,
          13,
          50848
        ]
      },
      {
        "avg_logprob": -0.3007029104923856,
        "compression_ratio": 1.2440944881889764,
        "end": 3894.76,
        "id": 1243,
        "no_speech_prob": 0.00021654377633240074,
        "seek": 388180,
        "start": 3892.76,
        "temperature": 0,
        "text": " But why is that coming out as 0?",
        "tokens": [
          50912,
          583,
          983,
          307,
          300,
          1348,
          484,
          382,
          1958,
          30,
          51012
        ]
      },
      {
        "avg_logprob": -0.3007029104923856,
        "compression_ratio": 1.2440944881889764,
        "end": 3901.4,
        "id": 1244,
        "no_speech_prob": 0.00021654377633240074,
        "seek": 388180,
        "start": 3899.7200000000003,
        "temperature": 0,
        "text": " Oh, I don't have a variable.",
        "tokens": [
          51260,
          876,
          11,
          286,
          500,
          380,
          362,
          257,
          7006,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.3007029104923856,
        "compression_ratio": 1.2440944881889764,
        "end": 3902.1200000000003,
        "id": 1245,
        "no_speech_prob": 0.00021654377633240074,
        "seek": 388180,
        "start": 3901.4,
        "temperature": 0,
        "text": " Oh, sorry.",
        "tokens": [
          51344,
          876,
          11,
          2597,
          13,
          51380
        ]
      },
      {
        "avg_logprob": -0.3007029104923856,
        "compression_ratio": 1.2440944881889764,
        "end": 3908.84,
        "id": 1246,
        "no_speech_prob": 0.00021654377633240074,
        "seek": 388180,
        "start": 3908.1200000000003,
        "temperature": 0,
        "text": " Okay, hold on.",
        "tokens": [
          51680,
          1033,
          11,
          1797,
          322,
          13,
          51716
        ]
      },
      {
        "avg_logprob": -0.3007029104923856,
        "compression_ratio": 1.2440944881889764,
        "end": 3909.8,
        "id": 1247,
        "no_speech_prob": 0.00021654377633240074,
        "seek": 388180,
        "start": 3908.84,
        "temperature": 0,
        "text": " Oh, no.",
        "tokens": [
          51716,
          876,
          11,
          572,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.3129295654296875,
        "compression_ratio": 1.7153846153846153,
        "end": 3914.6000000000004,
        "id": 1248,
        "no_speech_prob": 0.00004198627721052617,
        "seek": 390980,
        "start": 3910.36,
        "temperature": 0,
        "text": " Did something, you know, sometimes if I have an element named with an, oh, whoops.",
        "tokens": [
          50392,
          2589,
          746,
          11,
          291,
          458,
          11,
          2171,
          498,
          286,
          362,
          364,
          4478,
          4926,
          365,
          364,
          11,
          1954,
          11,
          567,
          3370,
          13,
          50604
        ]
      },
      {
        "avg_logprob": -0.3129295654296875,
        "compression_ratio": 1.7153846153846153,
        "end": 3917.32,
        "id": 1249,
        "no_speech_prob": 0.00004198627721052617,
        "seek": 390980,
        "start": 3915.48,
        "temperature": 0,
        "text": " Sorry, this is, remind me later.",
        "tokens": [
          50648,
          4919,
          11,
          341,
          307,
          11,
          4160,
          385,
          1780,
          13,
          50740
        ]
      },
      {
        "avg_logprob": -0.3129295654296875,
        "compression_ratio": 1.7153846153846153,
        "end": 3918.52,
        "id": 1250,
        "no_speech_prob": 0.00004198627721052617,
        "seek": 390980,
        "start": 3917.32,
        "temperature": 0,
        "text": " I don't need a software update.",
        "tokens": [
          50740,
          286,
          500,
          380,
          643,
          257,
          4722,
          5623,
          13,
          50800
        ]
      },
      {
        "avg_logprob": -0.3129295654296875,
        "compression_ratio": 1.7153846153846153,
        "end": 3922.84,
        "id": 1251,
        "no_speech_prob": 0.00004198627721052617,
        "seek": 390980,
        "start": 3918.52,
        "temperature": 0,
        "text": " Sometimes if I have an element, things in JavaScript can be, happen in weird things.",
        "tokens": [
          50800,
          4803,
          498,
          286,
          362,
          364,
          4478,
          11,
          721,
          294,
          15778,
          393,
          312,
          11,
          1051,
          294,
          3657,
          721,
          13,
          51016
        ]
      },
      {
        "avg_logprob": -0.3129295654296875,
        "compression_ratio": 1.7153846153846153,
        "end": 3927.48,
        "id": 1252,
        "no_speech_prob": 0.00004198627721052617,
        "seek": 390980,
        "start": 3922.84,
        "temperature": 0,
        "text": " Like I named this variable score, and I happen to have a DOM element with an ID of score.",
        "tokens": [
          51016,
          1743,
          286,
          4926,
          341,
          7006,
          6175,
          11,
          293,
          286,
          1051,
          281,
          362,
          257,
          35727,
          4478,
          365,
          364,
          7348,
          295,
          6175,
          13,
          51248
        ]
      },
      {
        "avg_logprob": -0.3129295654296875,
        "compression_ratio": 1.7153846153846153,
        "end": 3930.1200000000003,
        "id": 1253,
        "no_speech_prob": 0.00004198627721052617,
        "seek": 390980,
        "start": 3927.48,
        "temperature": 0,
        "text": " I wonder if that's causing me a weird sort of problem.",
        "tokens": [
          51248,
          286,
          2441,
          498,
          300,
          311,
          9853,
          385,
          257,
          3657,
          1333,
          295,
          1154,
          13,
          51380
        ]
      },
      {
        "avg_logprob": -0.3129295654296875,
        "compression_ratio": 1.7153846153846153,
        "end": 3937.32,
        "id": 1254,
        "no_speech_prob": 0.00004198627721052617,
        "seek": 390980,
        "start": 3930.1200000000003,
        "temperature": 0,
        "text": " So I'm going to go here and say score p, comparative p, word list p.",
        "tokens": [
          51380,
          407,
          286,
          478,
          516,
          281,
          352,
          510,
          293,
          584,
          6175,
          280,
          11,
          39292,
          280,
          11,
          1349,
          1329,
          280,
          13,
          51740
        ]
      },
      {
        "avg_logprob": -0.20749121976185994,
        "compression_ratio": 1.4864864864864864,
        "end": 3938.44,
        "id": 1255,
        "no_speech_prob": 0.00035696991835720837,
        "seek": 393732,
        "start": 3937.6400000000003,
        "temperature": 0,
        "text": " Word list p.",
        "tokens": [
          50380,
          8725,
          1329,
          280,
          13,
          50420
        ]
      },
      {
        "avg_logprob": -0.20749121976185994,
        "compression_ratio": 1.4864864864864864,
        "end": 3941.6400000000003,
        "id": 1256,
        "no_speech_prob": 0.00035696991835720837,
        "seek": 393732,
        "start": 3939.6400000000003,
        "temperature": 0,
        "text": " And I'm going to go back to my sketch.",
        "tokens": [
          50480,
          400,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          452,
          12325,
          13,
          50580
        ]
      },
      {
        "avg_logprob": -0.20749121976185994,
        "compression_ratio": 1.4864864864864864,
        "end": 3946.6800000000003,
        "id": 1257,
        "no_speech_prob": 0.00035696991835720837,
        "seek": 393732,
        "start": 3942.2000000000003,
        "temperature": 0,
        "text": " I'm just going to see if that's an issue.",
        "tokens": [
          50608,
          286,
          478,
          445,
          516,
          281,
          536,
          498,
          300,
          311,
          364,
          2734,
          13,
          50832
        ]
      },
      {
        "avg_logprob": -0.20749121976185994,
        "compression_ratio": 1.4864864864864864,
        "end": 3955.56,
        "id": 1258,
        "no_speech_prob": 0.00035696991835720837,
        "seek": 393732,
        "start": 3948.76,
        "temperature": 0,
        "text": " Oh, I also just not, oh, I'm being score p dot, oh, no, no, score.",
        "tokens": [
          50936,
          876,
          11,
          286,
          611,
          445,
          406,
          11,
          1954,
          11,
          286,
          478,
          885,
          6175,
          280,
          5893,
          11,
          1954,
          11,
          572,
          11,
          572,
          11,
          6175,
          13,
          51276
        ]
      },
      {
        "avg_logprob": -0.20749121976185994,
        "compression_ratio": 1.4864864864864864,
        "end": 3956.2000000000003,
        "id": 1259,
        "no_speech_prob": 0.00035696991835720837,
        "seek": 393732,
        "start": 3955.56,
        "temperature": 0,
        "text": " Yeah, that's right.",
        "tokens": [
          51276,
          865,
          11,
          300,
          311,
          558,
          13,
          51308
        ]
      },
      {
        "avg_logprob": -0.20749121976185994,
        "compression_ratio": 1.4864864864864864,
        "end": 3960.92,
        "id": 1260,
        "no_speech_prob": 0.00035696991835720837,
        "seek": 393732,
        "start": 3958.1200000000003,
        "temperature": 0,
        "text": " And comparative word list p.",
        "tokens": [
          51404,
          400,
          39292,
          1349,
          1329,
          280,
          13,
          51544
        ]
      },
      {
        "avg_logprob": -0.20749121976185994,
        "compression_ratio": 1.4864864864864864,
        "end": 3962.44,
        "id": 1261,
        "no_speech_prob": 0.00035696991835720837,
        "seek": 393732,
        "start": 3961.88,
        "temperature": 0,
        "text": " Let's see.",
        "tokens": [
          51592,
          961,
          311,
          536,
          13,
          51620
        ]
      },
      {
        "avg_logprob": -0.40428506322653895,
        "compression_ratio": 1.4797687861271676,
        "end": 3965.8,
        "id": 1262,
        "no_speech_prob": 0.0002611899108160287,
        "seek": 396244,
        "start": 3962.92,
        "temperature": 0,
        "text": " Let me just make all the variables name different to overdo it.",
        "tokens": [
          50388,
          961,
          385,
          445,
          652,
          439,
          264,
          9102,
          1315,
          819,
          281,
          670,
          2595,
          309,
          13,
          50532
        ]
      },
      {
        "avg_logprob": -0.40428506322653895,
        "compression_ratio": 1.4797687861271676,
        "end": 3969.56,
        "id": 1263,
        "no_speech_prob": 0.0002611899108160287,
        "seek": 396244,
        "start": 3967.56,
        "temperature": 0,
        "text": " Solid, happy.",
        "tokens": [
          50620,
          26664,
          11,
          2055,
          13,
          50720
        ]
      },
      {
        "avg_logprob": -0.40428506322653895,
        "compression_ratio": 1.4797687861271676,
        "end": 3973.96,
        "id": 1264,
        "no_speech_prob": 0.0002611899108160287,
        "seek": 396244,
        "start": 3971.96,
        "temperature": 0,
        "text": " Solid is two, happy is three.",
        "tokens": [
          50840,
          26664,
          307,
          732,
          11,
          2055,
          307,
          1045,
          13,
          50940
        ]
      },
      {
        "avg_logprob": -0.40428506322653895,
        "compression_ratio": 1.4797687861271676,
        "end": 3976.76,
        "id": 1265,
        "no_speech_prob": 0.0002611899108160287,
        "seek": 396244,
        "start": 3973.96,
        "temperature": 0,
        "text": " Why am I seeing happy five here?",
        "tokens": [
          50940,
          1545,
          669,
          286,
          2577,
          2055,
          1732,
          510,
          30,
          51080
        ]
      },
      {
        "avg_logprob": -0.40428506322653895,
        "compression_ratio": 1.4797687861271676,
        "end": 3977.88,
        "id": 1266,
        "no_speech_prob": 0.0002611899108160287,
        "seek": 396244,
        "start": 3976.76,
        "temperature": 0,
        "text": " So this is correct.",
        "tokens": [
          51080,
          407,
          341,
          307,
          3006,
          13,
          51136
        ]
      },
      {
        "avg_logprob": -0.40428506322653895,
        "compression_ratio": 1.4797687861271676,
        "end": 3978.44,
        "id": 1267,
        "no_speech_prob": 0.0002611899108160287,
        "seek": 396244,
        "start": 3977.88,
        "temperature": 0,
        "text": " This is correct.",
        "tokens": [
          51136,
          639,
          307,
          3006,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.40428506322653895,
        "compression_ratio": 1.4797687861271676,
        "end": 3979.56,
        "id": 1268,
        "no_speech_prob": 0.0002611899108160287,
        "seek": 396244,
        "start": 3978.44,
        "temperature": 0,
        "text": " And this is wrong.",
        "tokens": [
          51164,
          400,
          341,
          307,
          2085,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.40428506322653895,
        "compression_ratio": 1.4797687861271676,
        "end": 3988.04,
        "id": 1269,
        "no_speech_prob": 0.0002611899108160287,
        "seek": 396244,
        "start": 3981.48,
        "temperature": 0,
        "text": " I'm a little skeptical of, oh, I put the score, once again.",
        "tokens": [
          51316,
          286,
          478,
          257,
          707,
          28601,
          295,
          11,
          1954,
          11,
          286,
          829,
          264,
          6175,
          11,
          1564,
          797,
          13,
          51644
        ]
      },
      {
        "avg_logprob": -0.20392178326118282,
        "compression_ratio": 1.5783783783783785,
        "end": 3995.32,
        "id": 1270,
        "no_speech_prob": 0.007011739071458578,
        "seek": 398804,
        "start": 3988.6,
        "temperature": 0,
        "text": " Once again, I'm conflating the total score and the individual word score.",
        "tokens": [
          50392,
          3443,
          797,
          11,
          286,
          478,
          1497,
          75,
          990,
          264,
          3217,
          6175,
          293,
          264,
          2609,
          1349,
          6175,
          13,
          50728
        ]
      },
      {
        "avg_logprob": -0.20392178326118282,
        "compression_ratio": 1.5783783783783785,
        "end": 3999.56,
        "id": 1271,
        "no_speech_prob": 0.007011739071458578,
        "seek": 398804,
        "start": 3995.32,
        "temperature": 0,
        "text": " So I should really, if I want to be thoughtful about this, boy, I'm terrible at this sort of stuff.",
        "tokens": [
          50728,
          407,
          286,
          820,
          534,
          11,
          498,
          286,
          528,
          281,
          312,
          21566,
          466,
          341,
          11,
          3237,
          11,
          286,
          478,
          6237,
          412,
          341,
          1333,
          295,
          1507,
          13,
          50940
        ]
      },
      {
        "avg_logprob": -0.20392178326118282,
        "compression_ratio": 1.5783783783783785,
        "end": 4005.08,
        "id": 1272,
        "no_speech_prob": 0.007011739071458578,
        "seek": 398804,
        "start": 4000.6,
        "temperature": 0,
        "text": " I should really say var score equals, I don't think it was that at all.",
        "tokens": [
          50992,
          286,
          820,
          534,
          584,
          1374,
          6175,
          6915,
          11,
          286,
          500,
          380,
          519,
          309,
          390,
          300,
          412,
          439,
          13,
          51216
        ]
      },
      {
        "avg_logprob": -0.20392178326118282,
        "compression_ratio": 1.5783783783783785,
        "end": 4008.44,
        "id": 1273,
        "no_speech_prob": 0.007011739071458578,
        "seek": 398804,
        "start": 4006.2799999999997,
        "temperature": 0,
        "text": " I think it was, this was my problem all along.",
        "tokens": [
          51276,
          286,
          519,
          309,
          390,
          11,
          341,
          390,
          452,
          1154,
          439,
          2051,
          13,
          51384
        ]
      },
      {
        "avg_logprob": -0.2782429171280122,
        "compression_ratio": 1.7125,
        "end": 4019.16,
        "id": 1274,
        "no_speech_prob": 0.0005884079146198928,
        "seek": 400844,
        "start": 4009.32,
        "temperature": 0,
        "text": " So I want to make sure I have a difference between the individual word score and the actual",
        "tokens": [
          50408,
          407,
          286,
          528,
          281,
          652,
          988,
          286,
          362,
          257,
          2649,
          1296,
          264,
          2609,
          1349,
          6175,
          293,
          264,
          3539,
          50900
        ]
      },
      {
        "avg_logprob": -0.2782429171280122,
        "compression_ratio": 1.7125,
        "end": 4021.4,
        "id": 1275,
        "no_speech_prob": 0.0005884079146198928,
        "seek": 400844,
        "start": 4019.16,
        "temperature": 0,
        "text": " total score that I'm adding up.",
        "tokens": [
          50900,
          3217,
          6175,
          300,
          286,
          478,
          5127,
          493,
          13,
          51012
        ]
      },
      {
        "avg_logprob": -0.2782429171280122,
        "compression_ratio": 1.7125,
        "end": 4023.4,
        "id": 1276,
        "no_speech_prob": 0.0005884079146198928,
        "seek": 400844,
        "start": 4021.4,
        "temperature": 0,
        "text": " And so this is the total score.",
        "tokens": [
          51012,
          400,
          370,
          341,
          307,
          264,
          3217,
          6175,
          13,
          51112
        ]
      },
      {
        "avg_logprob": -0.2782429171280122,
        "compression_ratio": 1.7125,
        "end": 4025.7200000000003,
        "id": 1277,
        "no_speech_prob": 0.0005884079146198928,
        "seek": 400844,
        "start": 4023.96,
        "temperature": 0,
        "text": " And this is the total score.",
        "tokens": [
          51140,
          400,
          341,
          307,
          264,
          3217,
          6175,
          13,
          51228
        ]
      },
      {
        "avg_logprob": -0.2782429171280122,
        "compression_ratio": 1.7125,
        "end": 4037.2400000000002,
        "id": 1278,
        "no_speech_prob": 0.0005884079146198928,
        "seek": 400844,
        "start": 4025.7200000000003,
        "temperature": 0,
        "text": " And the things that I'm putting into the list, just add some padding here for formatting.",
        "tokens": [
          51228,
          400,
          264,
          721,
          300,
          286,
          478,
          3372,
          666,
          264,
          1329,
          11,
          445,
          909,
          512,
          39562,
          510,
          337,
          39366,
          13,
          51804
        ]
      },
      {
        "avg_logprob": -0.19538243611653647,
        "compression_ratio": 1.6848484848484848,
        "end": 4050.36,
        "id": 1279,
        "no_speech_prob": 0.0004173128691036254,
        "seek": 403844,
        "start": 4038.84,
        "temperature": 0,
        "text": " Now, happy, sad, this is better, yes, no, no, no, no, no, no, no, no, no, no, no.",
        "tokens": [
          50384,
          823,
          11,
          2055,
          11,
          4227,
          11,
          341,
          307,
          1101,
          11,
          2086,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          13,
          50960
        ]
      },
      {
        "avg_logprob": -0.19538243611653647,
        "compression_ratio": 1.6848484848484848,
        "end": 4053.88,
        "id": 1280,
        "no_speech_prob": 0.0004173128691036254,
        "seek": 403844,
        "start": 4052.2000000000003,
        "temperature": 0,
        "text": " OK, so there we go.",
        "tokens": [
          51052,
          2264,
          11,
          370,
          456,
          321,
          352,
          13,
          51136
        ]
      },
      {
        "avg_logprob": -0.19538243611653647,
        "compression_ratio": 1.6848484848484848,
        "end": 4059.64,
        "id": 1281,
        "no_speech_prob": 0.0004173128691036254,
        "seek": 403844,
        "start": 4053.88,
        "temperature": 0,
        "text": " You can see now I have real time sentiment analysis where I could be much, if you're",
        "tokens": [
          51136,
          509,
          393,
          536,
          586,
          286,
          362,
          957,
          565,
          16149,
          5215,
          689,
          286,
          727,
          312,
          709,
          11,
          498,
          291,
          434,
          51424
        ]
      },
      {
        "avg_logprob": -0.19538243611653647,
        "compression_ratio": 1.6848484848484848,
        "end": 4063.16,
        "id": 1282,
        "no_speech_prob": 0.0004173128691036254,
        "seek": 403844,
        "start": 4059.64,
        "temperature": 0,
        "text": " watching this video, if you're going to make something with this, you could be so much more",
        "tokens": [
          51424,
          1976,
          341,
          960,
          11,
          498,
          291,
          434,
          516,
          281,
          652,
          746,
          365,
          341,
          11,
          291,
          727,
          312,
          370,
          709,
          544,
          51600
        ]
      },
      {
        "avg_logprob": -0.15308968226114908,
        "compression_ratio": 1.6388888888888888,
        "end": 4068.2799999999997,
        "id": 1283,
        "no_speech_prob": 0.04467877373099327,
        "seek": 406316,
        "start": 4063.16,
        "temperature": 0,
        "text": " thoughtful in terms of how you display the results, whether it's color or visualization,",
        "tokens": [
          50364,
          21566,
          294,
          2115,
          295,
          577,
          291,
          4674,
          264,
          3542,
          11,
          1968,
          309,
          311,
          2017,
          420,
          25801,
          11,
          50620
        ]
      },
      {
        "avg_logprob": -0.15308968226114908,
        "compression_ratio": 1.6388888888888888,
        "end": 4072.44,
        "id": 1284,
        "no_speech_prob": 0.04467877373099327,
        "seek": 406316,
        "start": 4068.2799999999997,
        "temperature": 0,
        "text": " formatting the numbers nicely, formatting the list of words in a different way.",
        "tokens": [
          50620,
          39366,
          264,
          3547,
          9594,
          11,
          39366,
          264,
          1329,
          295,
          2283,
          294,
          257,
          819,
          636,
          13,
          50828
        ]
      },
      {
        "avg_logprob": -0.15308968226114908,
        "compression_ratio": 1.6388888888888888,
        "end": 4074.8399999999997,
        "id": 1285,
        "no_speech_prob": 0.04467877373099327,
        "seek": 406316,
        "start": 4072.44,
        "temperature": 0,
        "text": " But you have the basic framework for it here.",
        "tokens": [
          50828,
          583,
          291,
          362,
          264,
          3875,
          8388,
          337,
          309,
          510,
          13,
          50948
        ]
      },
      {
        "avg_logprob": -0.15308968226114908,
        "compression_ratio": 1.6388888888888888,
        "end": 4079,
        "id": 1286,
        "no_speech_prob": 0.04467877373099327,
        "seek": 406316,
        "start": 4074.8399999999997,
        "temperature": 0,
        "text": " I will show you that there is a major issue with this particular approach.",
        "tokens": [
          50948,
          286,
          486,
          855,
          291,
          300,
          456,
          307,
          257,
          2563,
          2734,
          365,
          341,
          1729,
          3109,
          13,
          51156
        ]
      },
      {
        "avg_logprob": -0.15308968226114908,
        "compression_ratio": 1.6388888888888888,
        "end": 4083.72,
        "id": 1287,
        "no_speech_prob": 0.04467877373099327,
        "seek": 406316,
        "start": 4081.24,
        "temperature": 0,
        "text": " OK, so here's a particular issue.",
        "tokens": [
          51268,
          2264,
          11,
          370,
          510,
          311,
          257,
          1729,
          2734,
          13,
          51392
        ]
      },
      {
        "avg_logprob": -0.15308968226114908,
        "compression_ratio": 1.6388888888888888,
        "end": 4086.8399999999997,
        "id": 1288,
        "no_speech_prob": 0.04467877373099327,
        "seek": 406316,
        "start": 4083.72,
        "temperature": 0,
        "text": " Here is my text that I am going to type right now.",
        "tokens": [
          51392,
          1692,
          307,
          452,
          2487,
          300,
          286,
          669,
          516,
          281,
          2010,
          558,
          586,
          13,
          51548
        ]
      },
      {
        "avg_logprob": -0.15308968226114908,
        "compression_ratio": 1.6388888888888888,
        "end": 4090.2,
        "id": 1289,
        "no_speech_prob": 0.04467877373099327,
        "seek": 406316,
        "start": 4088.68,
        "temperature": 0,
        "text": " I am not sad.",
        "tokens": [
          51640,
          286,
          669,
          406,
          4227,
          13,
          51716
        ]
      },
      {
        "avg_logprob": -0.15308968226114908,
        "compression_ratio": 1.6388888888888888,
        "end": 4092.2799999999997,
        "id": 1290,
        "no_speech_prob": 0.04467877373099327,
        "seek": 406316,
        "start": 4090.2,
        "temperature": 0,
        "text": " I am not at all unhappy.",
        "tokens": [
          51716,
          286,
          669,
          406,
          412,
          439,
          22172,
          13,
          51820
        ]
      },
      {
        "avg_logprob": -0.22638356685638428,
        "compression_ratio": 1.669683257918552,
        "end": 4098.36,
        "id": 1291,
        "no_speech_prob": 0.00013135152403265238,
        "seek": 409316,
        "start": 4093.56,
        "temperature": 0,
        "text": " I am not feeling worse today.",
        "tokens": [
          50384,
          286,
          669,
          406,
          2633,
          5324,
          965,
          13,
          50624
        ]
      },
      {
        "avg_logprob": -0.22638356685638428,
        "compression_ratio": 1.669683257918552,
        "end": 4104.36,
        "id": 1292,
        "no_speech_prob": 0.00013135152403265238,
        "seek": 409316,
        "start": 4099,
        "temperature": 0,
        "text": " So you can see I've got a really, really negative score of negative 6, even though I said I'm not",
        "tokens": [
          50656,
          407,
          291,
          393,
          536,
          286,
          600,
          658,
          257,
          534,
          11,
          534,
          3671,
          6175,
          295,
          3671,
          1386,
          11,
          754,
          1673,
          286,
          848,
          286,
          478,
          406,
          50924
        ]
      },
      {
        "avg_logprob": -0.22638356685638428,
        "compression_ratio": 1.669683257918552,
        "end": 4107.5599999999995,
        "id": 1293,
        "no_speech_prob": 0.00013135152403265238,
        "seek": 409316,
        "start": 4104.36,
        "temperature": 0,
        "text": " sad, I am not at all unhappy, I am not feeling worse today.",
        "tokens": [
          50924,
          4227,
          11,
          286,
          669,
          406,
          412,
          439,
          22172,
          11,
          286,
          669,
          406,
          2633,
          5324,
          965,
          13,
          51084
        ]
      },
      {
        "avg_logprob": -0.22638356685638428,
        "compression_ratio": 1.669683257918552,
        "end": 4114.76,
        "id": 1294,
        "no_speech_prob": 0.00013135152403265238,
        "seek": 409316,
        "start": 4107.5599999999995,
        "temperature": 0,
        "text": " Because this particular technique is only looking at the raw counts of words and those scores.",
        "tokens": [
          51084,
          1436,
          341,
          1729,
          6532,
          307,
          787,
          1237,
          412,
          264,
          8936,
          14893,
          295,
          2283,
          293,
          729,
          13444,
          13,
          51444
        ]
      },
      {
        "avg_logprob": -0.22638356685638428,
        "compression_ratio": 1.669683257918552,
        "end": 4119.88,
        "id": 1295,
        "no_speech_prob": 0.00013135152403265238,
        "seek": 409316,
        "start": 4115.639999999999,
        "temperature": 0,
        "text": " If I wanted to be a little more thoughtful about this, I could try to add a little bit",
        "tokens": [
          51488,
          759,
          286,
          1415,
          281,
          312,
          257,
          707,
          544,
          21566,
          466,
          341,
          11,
          286,
          727,
          853,
          281,
          909,
          257,
          707,
          857,
          51700
        ]
      },
      {
        "avg_logprob": -0.18494151571522588,
        "compression_ratio": 1.6449511400651466,
        "end": 4121.32,
        "id": 1296,
        "no_speech_prob": 0.01566261798143387,
        "seek": 411988,
        "start": 4119.88,
        "temperature": 0,
        "text": " of natural language processing.",
        "tokens": [
          50364,
          295,
          3303,
          2856,
          9007,
          13,
          50436
        ]
      },
      {
        "avg_logprob": -0.18494151571522588,
        "compression_ratio": 1.6449511400651466,
        "end": 4127.96,
        "id": 1297,
        "no_speech_prob": 0.01566261798143387,
        "seek": 411988,
        "start": 4121.32,
        "temperature": 0,
        "text": " For example, the JavaScript library NLP compromise that I demonstrated can look for if a statement",
        "tokens": [
          50436,
          1171,
          1365,
          11,
          264,
          15778,
          6405,
          426,
          45196,
          18577,
          300,
          286,
          18772,
          393,
          574,
          337,
          498,
          257,
          5629,
          50768
        ]
      },
      {
        "avg_logprob": -0.18494151571522588,
        "compression_ratio": 1.6449511400651466,
        "end": 4130.84,
        "id": 1298,
        "no_speech_prob": 0.01566261798143387,
        "seek": 411988,
        "start": 4127.96,
        "temperature": 0,
        "text": " is a negation, and you could perhaps invert the score.",
        "tokens": [
          50768,
          307,
          257,
          2485,
          399,
          11,
          293,
          291,
          727,
          4317,
          33966,
          264,
          6175,
          13,
          50912
        ]
      },
      {
        "avg_logprob": -0.18494151571522588,
        "compression_ratio": 1.6449511400651466,
        "end": 4135.64,
        "id": 1299,
        "no_speech_prob": 0.01566261798143387,
        "seek": 411988,
        "start": 4130.84,
        "temperature": 0,
        "text": " And then, of course, I could use a more sophisticated training methodology of actually",
        "tokens": [
          50912,
          400,
          550,
          11,
          295,
          1164,
          11,
          286,
          727,
          764,
          257,
          544,
          16950,
          3097,
          24850,
          295,
          767,
          51152
        ]
      },
      {
        "avg_logprob": -0.18494151571522588,
        "compression_ratio": 1.6449511400651466,
        "end": 4140.28,
        "id": 1300,
        "no_speech_prob": 0.01566261798143387,
        "seek": 411988,
        "start": 4135.64,
        "temperature": 0,
        "text": " not using a word list, but having a machine learning system learn about positive text,",
        "tokens": [
          51152,
          406,
          1228,
          257,
          1349,
          1329,
          11,
          457,
          1419,
          257,
          3479,
          2539,
          1185,
          1466,
          466,
          3353,
          2487,
          11,
          51384
        ]
      },
      {
        "avg_logprob": -0.18494151571522588,
        "compression_ratio": 1.6449511400651466,
        "end": 4144.68,
        "id": 1301,
        "no_speech_prob": 0.01566261798143387,
        "seek": 411988,
        "start": 4140.28,
        "temperature": 0,
        "text": " learn about negative text based on just word frequencies and words being next to each other",
        "tokens": [
          51384,
          1466,
          466,
          3671,
          2487,
          2361,
          322,
          445,
          1349,
          20250,
          293,
          2283,
          885,
          958,
          281,
          1184,
          661,
          51604
        ]
      },
      {
        "avg_logprob": -0.18494151571522588,
        "compression_ratio": 1.6449511400651466,
        "end": 4146.68,
        "id": 1302,
        "no_speech_prob": 0.01566261798143387,
        "seek": 411988,
        "start": 4144.68,
        "temperature": 0,
        "text": " and that sort of thing in a much more open-ended way.",
        "tokens": [
          51604,
          293,
          300,
          1333,
          295,
          551,
          294,
          257,
          709,
          544,
          1269,
          12,
          3502,
          636,
          13,
          51704
        ]
      },
      {
        "avg_logprob": -0.2197034897342805,
        "compression_ratio": 1.6666666666666667,
        "end": 4151.240000000001,
        "id": 1303,
        "no_speech_prob": 0.003172591095790267,
        "seek": 414668,
        "start": 4146.68,
        "temperature": 0,
        "text": " But this hopefully should get you started on something if you're interested in text",
        "tokens": [
          50364,
          583,
          341,
          4696,
          820,
          483,
          291,
          1409,
          322,
          746,
          498,
          291,
          434,
          3102,
          294,
          2487,
          50592
        ]
      },
      {
        "avg_logprob": -0.2197034897342805,
        "compression_ratio": 1.6666666666666667,
        "end": 4155.64,
        "id": 1304,
        "no_speech_prob": 0.003172591095790267,
        "seek": 414668,
        "start": 4151.240000000001,
        "temperature": 0,
        "text": " analysis and how you might apply this to what type of data source and how you might show",
        "tokens": [
          50592,
          5215,
          293,
          577,
          291,
          1062,
          3079,
          341,
          281,
          437,
          2010,
          295,
          1412,
          4009,
          293,
          577,
          291,
          1062,
          855,
          50812
        ]
      },
      {
        "avg_logprob": -0.2197034897342805,
        "compression_ratio": 1.6666666666666667,
        "end": 4160.360000000001,
        "id": 1305,
        "no_speech_prob": 0.003172591095790267,
        "seek": 414668,
        "start": 4155.64,
        "temperature": 0,
        "text": " the result or how you might create an interface for people to type into and give us some information",
        "tokens": [
          50812,
          264,
          1874,
          420,
          577,
          291,
          1062,
          1884,
          364,
          9226,
          337,
          561,
          281,
          2010,
          666,
          293,
          976,
          505,
          512,
          1589,
          51048
        ]
      },
      {
        "avg_logprob": -0.2197034897342805,
        "compression_ratio": 1.6666666666666667,
        "end": 4161.08,
        "id": 1306,
        "no_speech_prob": 0.003172591095790267,
        "seek": 414668,
        "start": 4160.360000000001,
        "temperature": 0,
        "text": " back.",
        "tokens": [
          51048,
          646,
          13,
          51084
        ]
      },
      {
        "avg_logprob": -0.2197034897342805,
        "compression_ratio": 1.6666666666666667,
        "end": 4161.4800000000005,
        "id": 1307,
        "no_speech_prob": 0.003172591095790267,
        "seek": 414668,
        "start": 4161.08,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51084,
          2264,
          13,
          51104
        ]
      },
      {
        "avg_logprob": -0.2197034897342805,
        "compression_ratio": 1.6666666666666667,
        "end": 4167.56,
        "id": 1308,
        "no_speech_prob": 0.003172591095790267,
        "seek": 414668,
        "start": 4163.08,
        "temperature": 0,
        "text": " So in the chat, Gaurav writes, you must be sad.",
        "tokens": [
          51184,
          407,
          294,
          264,
          5081,
          11,
          460,
          3463,
          706,
          13657,
          11,
          291,
          1633,
          312,
          4227,
          13,
          51408
        ]
      },
      {
        "avg_logprob": -0.2197034897342805,
        "compression_ratio": 1.6666666666666667,
        "end": 4169.400000000001,
        "id": 1309,
        "no_speech_prob": 0.003172591095790267,
        "seek": 414668,
        "start": 4167.56,
        "temperature": 0,
        "text": " That's why you were insisting on it very much.",
        "tokens": [
          51408,
          663,
          311,
          983,
          291,
          645,
          13466,
          278,
          322,
          309,
          588,
          709,
          13,
          51500
        ]
      },
      {
        "avg_logprob": -0.2197034897342805,
        "compression_ratio": 1.6666666666666667,
        "end": 4169.96,
        "id": 1310,
        "no_speech_prob": 0.003172591095790267,
        "seek": 414668,
        "start": 4169.400000000001,
        "temperature": 0,
        "text": " And you know what?",
        "tokens": [
          51500,
          400,
          291,
          458,
          437,
          30,
          51528
        ]
      },
      {
        "avg_logprob": -0.2197034897342805,
        "compression_ratio": 1.6666666666666667,
        "end": 4175.320000000001,
        "id": 1311,
        "no_speech_prob": 0.003172591095790267,
        "seek": 414668,
        "start": 4169.96,
        "temperature": 0,
        "text": " I think maybe this is a smarter sentiment analysis technique than I knew, because maybe",
        "tokens": [
          51528,
          286,
          519,
          1310,
          341,
          307,
          257,
          20294,
          16149,
          5215,
          6532,
          813,
          286,
          2586,
          11,
          570,
          1310,
          51796
        ]
      },
      {
        "avg_logprob": -0.26129133224487305,
        "compression_ratio": 1.4326923076923077,
        "end": 4176.759999999999,
        "id": 1312,
        "no_speech_prob": 0.027584513649344444,
        "seek": 417532,
        "start": 4175.32,
        "temperature": 0,
        "text": " it can read in between the lines.",
        "tokens": [
          50364,
          309,
          393,
          1401,
          294,
          1296,
          264,
          3876,
          13,
          50436
        ]
      },
      {
        "avg_logprob": -0.26129133224487305,
        "compression_ratio": 1.4326923076923077,
        "end": 4177.08,
        "id": 1313,
        "no_speech_prob": 0.027584513649344444,
        "seek": 417532,
        "start": 4176.759999999999,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50436,
          2264,
          13,
          50452
        ]
      },
      {
        "avg_logprob": -0.26129133224487305,
        "compression_ratio": 1.4326923076923077,
        "end": 4182.84,
        "id": 1314,
        "no_speech_prob": 0.027584513649344444,
        "seek": 417532,
        "start": 4177.08,
        "temperature": 0,
        "text": " Thanks very much for watching this sentiment analysis video, and I'll see you in other",
        "tokens": [
          50452,
          2561,
          588,
          709,
          337,
          1976,
          341,
          16149,
          5215,
          960,
          11,
          293,
          286,
          603,
          536,
          291,
          294,
          661,
          50740
        ]
      },
      {
        "avg_logprob": -0.26129133224487305,
        "compression_ratio": 1.4326923076923077,
        "end": 4184.2,
        "id": 1315,
        "no_speech_prob": 0.027584513649344444,
        "seek": 417532,
        "start": 4182.84,
        "temperature": 0,
        "text": " videos in the future, perhaps.",
        "tokens": [
          50740,
          2145,
          294,
          264,
          2027,
          11,
          4317,
          13,
          50808
        ]
      },
      {
        "avg_logprob": -0.26129133224487305,
        "compression_ratio": 1.4326923076923077,
        "end": 4187.24,
        "id": 1316,
        "no_speech_prob": 0.027584513649344444,
        "seek": 417532,
        "start": 4186.84,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50940,
          2264,
          13,
          50960
        ]
      },
      {
        "avg_logprob": -0.26129133224487305,
        "compression_ratio": 1.4326923076923077,
        "end": 4191.88,
        "id": 1317,
        "no_speech_prob": 0.027584513649344444,
        "seek": 417532,
        "start": 4190.28,
        "temperature": 0,
        "text": " She's doing cycle analysis, too.",
        "tokens": [
          51112,
          1240,
          311,
          884,
          6586,
          5215,
          11,
          886,
          13,
          51192
        ]
      },
      {
        "avg_logprob": -0.26129133224487305,
        "compression_ratio": 1.4326923076923077,
        "end": 4192.44,
        "id": 1318,
        "no_speech_prob": 0.027584513649344444,
        "seek": 417532,
        "start": 4191.88,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51192,
          2264,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.26129133224487305,
        "compression_ratio": 1.4326923076923077,
        "end": 4194.28,
        "id": 1319,
        "no_speech_prob": 0.027584513649344444,
        "seek": 417532,
        "start": 4192.44,
        "temperature": 0,
        "text": " It is now 4.30.",
        "tokens": [
          51220,
          467,
          307,
          586,
          1017,
          13,
          3446,
          13,
          51312
        ]
      },
      {
        "avg_logprob": -0.26129133224487305,
        "compression_ratio": 1.4326923076923077,
        "end": 4194.599999999999,
        "id": 1320,
        "no_speech_prob": 0.027584513649344444,
        "seek": 417532,
        "start": 4194.28,
        "temperature": 0,
        "text": " Ah!",
        "tokens": [
          51312,
          2438,
          0,
          51328
        ]
      },
      {
        "avg_logprob": -0.26129133224487305,
        "compression_ratio": 1.4326923076923077,
        "end": 4197.5599999999995,
        "id": 1321,
        "no_speech_prob": 0.027584513649344444,
        "seek": 417532,
        "start": 4195.16,
        "temperature": 0,
        "text": " Wow, this took me, how long was this?",
        "tokens": [
          51356,
          3153,
          11,
          341,
          1890,
          385,
          11,
          577,
          938,
          390,
          341,
          30,
          51476
        ]
      },
      {
        "avg_logprob": -0.26129133224487305,
        "compression_ratio": 1.4326923076923077,
        "end": 4200.599999999999,
        "id": 1322,
        "no_speech_prob": 0.027584513649344444,
        "seek": 417532,
        "start": 4197.5599999999995,
        "temperature": 0,
        "text": " Did I really spend like 45 minutes on this?",
        "tokens": [
          51476,
          2589,
          286,
          534,
          3496,
          411,
          6905,
          2077,
          322,
          341,
          30,
          51628
        ]
      },
      {
        "avg_logprob": -0.4836143493652344,
        "compression_ratio": 1.4143646408839778,
        "end": 4202.6,
        "id": 1323,
        "no_speech_prob": 0.004264600574970245,
        "seek": 420060,
        "start": 4200.6,
        "temperature": 0,
        "text": " Wow, that's crazy if I did.",
        "tokens": [
          50364,
          3153,
          11,
          300,
          311,
          3219,
          498,
          286,
          630,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.4836143493652344,
        "compression_ratio": 1.4143646408839778,
        "end": 4208.620000000001,
        "id": 1324,
        "no_speech_prob": 0.004264600574970245,
        "seek": 420060,
        "start": 4208.120000000001,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50740,
          2264,
          13,
          50765
        ]
      },
      {
        "avg_logprob": -0.4836143493652344,
        "compression_ratio": 1.4143646408839778,
        "end": 4213.64,
        "id": 1325,
        "no_speech_prob": 0.004264600574970245,
        "seek": 420060,
        "start": 4209.08,
        "temperature": 0,
        "text": " Let's think about what I have time for, because there isn't a ton of time left.",
        "tokens": [
          50788,
          961,
          311,
          519,
          466,
          437,
          286,
          362,
          565,
          337,
          11,
          570,
          456,
          1943,
          380,
          257,
          2952,
          295,
          565,
          1411,
          13,
          51016
        ]
      },
      {
        "avg_logprob": -0.4836143493652344,
        "compression_ratio": 1.4143646408839778,
        "end": 4216.68,
        "id": 1326,
        "no_speech_prob": 0.004264600574970245,
        "seek": 420060,
        "start": 4216.04,
        "temperature": 0,
        "text": " 35 minutes.",
        "tokens": [
          51136,
          6976,
          2077,
          13,
          51168
        ]
      },
      {
        "avg_logprob": -0.4836143493652344,
        "compression_ratio": 1.4143646408839778,
        "end": 4217.240000000001,
        "id": 1327,
        "no_speech_prob": 0.004264600574970245,
        "seek": 420060,
        "start": 4216.68,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51168,
          2264,
          13,
          51196
        ]
      },
      {
        "avg_logprob": -0.4836143493652344,
        "compression_ratio": 1.4143646408839778,
        "end": 4220.84,
        "id": 1328,
        "no_speech_prob": 0.004264600574970245,
        "seek": 420060,
        "start": 4217.240000000001,
        "temperature": 0,
        "text": " Maybe that could be, maybe some of the editing, the debugging could be edited out.",
        "tokens": [
          51196,
          2704,
          300,
          727,
          312,
          11,
          1310,
          512,
          295,
          264,
          10000,
          11,
          264,
          45592,
          727,
          312,
          23016,
          484,
          13,
          51376
        ]
      },
      {
        "avg_logprob": -0.4836143493652344,
        "compression_ratio": 1.4143646408839778,
        "end": 4223.8,
        "id": 1329,
        "no_speech_prob": 0.004264600574970245,
        "seek": 420060,
        "start": 4223.320000000001,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51500,
          1057,
          558,
          13,
          51524
        ]
      },
      {
        "avg_logprob": -0.4836143493652344,
        "compression_ratio": 1.4143646408839778,
        "end": 4227,
        "id": 1330,
        "no_speech_prob": 0.004264600574970245,
        "seek": 420060,
        "start": 4223.8,
        "temperature": 0,
        "text": " So what do I want to look at next?",
        "tokens": [
          51524,
          407,
          437,
          360,
          286,
          528,
          281,
          574,
          412,
          958,
          30,
          51684
        ]
      },
      {
        "avg_logprob": -0.5545870652839319,
        "compression_ratio": 1.5,
        "end": 4238.68,
        "id": 1331,
        "no_speech_prob": 0.001032198779284954,
        "seek": 422700,
        "start": 4227.96,
        "temperature": 0,
        "text": " Let's see if we have time to go back to the, I'm sorry, I'm just thinking here.",
        "tokens": [
          50412,
          961,
          311,
          536,
          498,
          321,
          362,
          565,
          281,
          352,
          646,
          281,
          264,
          11,
          286,
          478,
          2597,
          11,
          286,
          478,
          445,
          1953,
          510,
          13,
          50948
        ]
      },
      {
        "avg_logprob": -0.5545870652839319,
        "compression_ratio": 1.5,
        "end": 4243.24,
        "id": 1332,
        "no_speech_prob": 0.001032198779284954,
        "seek": 422700,
        "start": 4238.68,
        "temperature": 0,
        "text": " Let's go back to the node program.",
        "tokens": [
          50948,
          961,
          311,
          352,
          646,
          281,
          264,
          9984,
          1461,
          13,
          51176
        ]
      },
      {
        "avg_logprob": -0.5545870652839319,
        "compression_ratio": 1.5,
        "end": 4244.04,
        "id": 1333,
        "no_speech_prob": 0.001032198779284954,
        "seek": 422700,
        "start": 4243.24,
        "temperature": 0,
        "text": " Let me pull that up.",
        "tokens": [
          51176,
          961,
          385,
          2235,
          300,
          493,
          13,
          51216
        ]
      },
      {
        "avg_logprob": -0.5545870652839319,
        "compression_ratio": 1.5,
        "end": 4252.28,
        "id": 1334,
        "no_speech_prob": 0.001032198779284954,
        "seek": 422700,
        "start": 4248.44,
        "temperature": 0,
        "text": " So I'm going to copy this and say, oh, I'm going to copy this.",
        "tokens": [
          51436,
          407,
          286,
          478,
          516,
          281,
          5055,
          341,
          293,
          584,
          11,
          1954,
          11,
          286,
          478,
          516,
          281,
          5055,
          341,
          13,
          51628
        ]
      },
      {
        "avg_logprob": -0.37727884565080916,
        "compression_ratio": 1.3511904761904763,
        "end": 4255.24,
        "id": 1335,
        "no_speech_prob": 0.00017952756024897099,
        "seek": 425228,
        "start": 4253.24,
        "temperature": 0,
        "text": " So I'm going to copy this and say API 3.",
        "tokens": [
          50412,
          407,
          286,
          478,
          516,
          281,
          5055,
          341,
          293,
          584,
          9362,
          805,
          13,
          50512
        ]
      },
      {
        "avg_logprob": -0.37727884565080916,
        "compression_ratio": 1.3511904761904763,
        "end": 4258.679999999999,
        "id": 1336,
        "no_speech_prob": 0.00017952756024897099,
        "seek": 425228,
        "start": 4255.24,
        "temperature": 0,
        "text": " You know, I realize I haven't posted any of this code on GitHub in so long, but I've been,",
        "tokens": [
          50512,
          509,
          458,
          11,
          286,
          4325,
          286,
          2378,
          380,
          9437,
          604,
          295,
          341,
          3089,
          322,
          23331,
          294,
          370,
          938,
          11,
          457,
          286,
          600,
          668,
          11,
          50684
        ]
      },
      {
        "avg_logprob": -0.37727884565080916,
        "compression_ratio": 1.3511904761904763,
        "end": 4261.719999999999,
        "id": 1337,
        "no_speech_prob": 0.00017952756024897099,
        "seek": 425228,
        "start": 4259.719999999999,
        "temperature": 0,
        "text": " let's go make API 3.",
        "tokens": [
          50736,
          718,
          311,
          352,
          652,
          9362,
          805,
          13,
          50836
        ]
      },
      {
        "avg_logprob": -0.37727884565080916,
        "compression_ratio": 1.3511904761904763,
        "end": 4280.36,
        "id": 1338,
        "no_speech_prob": 0.00017952756024897099,
        "seek": 425228,
        "start": 4270.92,
        "temperature": 0,
        "text": " And let's go to, I will be doing tutorials about machine learning in 2017.",
        "tokens": [
          51296,
          400,
          718,
          311,
          352,
          281,
          11,
          286,
          486,
          312,
          884,
          17616,
          466,
          3479,
          2539,
          294,
          6591,
          13,
          51768
        ]
      },
      {
        "avg_logprob": -0.24877899075731819,
        "compression_ratio": 1.3595505617977528,
        "end": 4282.92,
        "id": 1339,
        "no_speech_prob": 0.00008349600830115378,
        "seek": 428036,
        "start": 4281.32,
        "temperature": 0,
        "text": " In 2017.",
        "tokens": [
          50412,
          682,
          6591,
          13,
          50492
        ]
      },
      {
        "avg_logprob": -0.24877899075731819,
        "compression_ratio": 1.3595505617977528,
        "end": 4287.32,
        "id": 1340,
        "no_speech_prob": 0.00008349600830115378,
        "seek": 428036,
        "start": 4282.92,
        "temperature": 0,
        "text": " Maybe I'll do some on this all day adventure that I would like to do.",
        "tokens": [
          50492,
          2704,
          286,
          603,
          360,
          512,
          322,
          341,
          439,
          786,
          9868,
          300,
          286,
          576,
          411,
          281,
          360,
          13,
          50712
        ]
      },
      {
        "avg_logprob": -0.24877899075731819,
        "compression_ratio": 1.3595505617977528,
        "end": 4292.2,
        "id": 1341,
        "no_speech_prob": 0.00008349600830115378,
        "seek": 428036,
        "start": 4288.28,
        "temperature": 0,
        "text": " But I'm trying to finish up this other list that I have first.",
        "tokens": [
          50760,
          583,
          286,
          478,
          1382,
          281,
          2413,
          493,
          341,
          661,
          1329,
          300,
          286,
          362,
          700,
          13,
          50956
        ]
      },
      {
        "avg_logprob": -0.24877899075731819,
        "compression_ratio": 1.3595505617977528,
        "end": 4294.839999999999,
        "id": 1342,
        "no_speech_prob": 0.00008349600830115378,
        "seek": 428036,
        "start": 4293.24,
        "temperature": 0,
        "text": " So let's just say node server.",
        "tokens": [
          51008,
          407,
          718,
          311,
          445,
          584,
          9984,
          7154,
          13,
          51088
        ]
      },
      {
        "avg_logprob": -0.24877899075731819,
        "compression_ratio": 1.3595505617977528,
        "end": 4297.08,
        "id": 1343,
        "no_speech_prob": 0.00008349600830115378,
        "seek": 428036,
        "start": 4295.48,
        "temperature": 0,
        "text": " Let's see what this is doing.",
        "tokens": [
          51120,
          961,
          311,
          536,
          437,
          341,
          307,
          884,
          13,
          51200
        ]
      },
      {
        "avg_logprob": -0.24877899075731819,
        "compression_ratio": 1.3595505617977528,
        "end": 4300.7,
        "id": 1344,
        "no_speech_prob": 0.00008349600830115378,
        "seek": 428036,
        "start": 4300.2,
        "temperature": 0,
        "text": " Oops.",
        "tokens": [
          51356,
          21726,
          13,
          51381
        ]
      },
      {
        "avg_logprob": -0.24877899075731819,
        "compression_ratio": 1.3595505617977528,
        "end": 4304.5199999999995,
        "id": 1345,
        "no_speech_prob": 0.00008349600830115378,
        "seek": 428036,
        "start": 4301.32,
        "temperature": 0,
        "text": " Sorry, localhost 3000.",
        "tokens": [
          51412,
          4919,
          11,
          2654,
          6037,
          20984,
          13,
          51572
        ]
      },
      {
        "avg_logprob": -0.24877899075731819,
        "compression_ratio": 1.3595505617977528,
        "end": 4306.12,
        "id": 1346,
        "no_speech_prob": 0.00008349600830115378,
        "seek": 428036,
        "start": 4305.48,
        "temperature": 0,
        "text": " OK, right.",
        "tokens": [
          51620,
          2264,
          11,
          558,
          13,
          51652
        ]
      },
      {
        "avg_logprob": -0.2782147884368896,
        "compression_ratio": 1.188118811881188,
        "end": 4314.12,
        "id": 1347,
        "no_speech_prob": 0.00020662875613197684,
        "seek": 430612,
        "start": 4306.92,
        "temperature": 0,
        "text": " So now I remember that this, if you recall where I was last, is I made a simple,",
        "tokens": [
          50404,
          407,
          586,
          286,
          1604,
          300,
          341,
          11,
          498,
          291,
          9901,
          689,
          286,
          390,
          1036,
          11,
          307,
          286,
          1027,
          257,
          2199,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.2782147884368896,
        "compression_ratio": 1.188118811881188,
        "end": 4321.24,
        "id": 1348,
        "no_speech_prob": 0.00020662875613197684,
        "seek": 430612,
        "start": 4317.72,
        "temperature": 0,
        "text": " and let me open this one up too.",
        "tokens": [
          50944,
          293,
          718,
          385,
          1269,
          341,
          472,
          493,
          886,
          13,
          51120
        ]
      },
      {
        "avg_logprob": -0.2782147884368896,
        "compression_ratio": 1.188118811881188,
        "end": 4321.74,
        "id": 1349,
        "no_speech_prob": 0.00020662875613197684,
        "seek": 430612,
        "start": 4321.24,
        "temperature": 0,
        "text": " Sorry.",
        "tokens": [
          51120,
          4919,
          13,
          51145
        ]
      },
      {
        "avg_logprob": -0.3253180405189251,
        "compression_ratio": 1.05,
        "end": 4322.24,
        "id": 1350,
        "no_speech_prob": 0.007577117998152971,
        "seek": 432174,
        "start": 4321.74,
        "temperature": 0,
        "text": " Sorry.",
        "tokens": [
          50364,
          4919,
          13,
          50389
        ]
      },
      {
        "avg_logprob": -0.3253180405189251,
        "compression_ratio": 1.05,
        "end": 4332.54,
        "id": 1351,
        "no_speech_prob": 0.007577117998152971,
        "seek": 432174,
        "start": 4326.0599999999995,
        "temperature": 0,
        "text": " I made a simple API that allows you to",
        "tokens": [
          50580,
          286,
          1027,
          257,
          2199,
          9362,
          300,
          4045,
          291,
          281,
          50904
        ]
      },
      {
        "avg_logprob": -0.3253180405189251,
        "compression_ratio": 1.05,
        "end": 4341.74,
        "id": 1352,
        "no_speech_prob": 0.007577117998152971,
        "seek": 432174,
        "start": 4337.099999999999,
        "temperature": 0,
        "text": " add a word with a score to a database.",
        "tokens": [
          51132,
          909,
          257,
          1349,
          365,
          257,
          6175,
          281,
          257,
          8149,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.35683250427246094,
        "compression_ratio": 1.6613756613756614,
        "end": 4351.66,
        "id": 1353,
        "no_speech_prob": 0.0017545816954225302,
        "seek": 434174,
        "start": 4341.82,
        "temperature": 0,
        "text": " And so you could build, you could have a crowdsourced AFIN111 style list.",
        "tokens": [
          50368,
          400,
          370,
          291,
          727,
          1322,
          11,
          291,
          727,
          362,
          257,
          26070,
          396,
          1232,
          20389,
          1464,
          5348,
          16,
          3758,
          1329,
          13,
          50860
        ]
      },
      {
        "avg_logprob": -0.35683250427246094,
        "compression_ratio": 1.6613756613756614,
        "end": 4358.0599999999995,
        "id": 1354,
        "no_speech_prob": 0.0017545816954225302,
        "seek": 434174,
        "start": 4351.66,
        "temperature": 0,
        "text": " And you can see this is a front end to this that shows you everything that's been in there so far.",
        "tokens": [
          50860,
          400,
          291,
          393,
          536,
          341,
          307,
          257,
          1868,
          917,
          281,
          341,
          300,
          3110,
          291,
          1203,
          300,
          311,
          668,
          294,
          456,
          370,
          1400,
          13,
          51180
        ]
      },
      {
        "avg_logprob": -0.35683250427246094,
        "compression_ratio": 1.6613756613756614,
        "end": 4363.66,
        "id": 1355,
        "no_speech_prob": 0.0017545816954225302,
        "seek": 434174,
        "start": 4358.0599999999995,
        "temperature": 0,
        "text": " So if I were to add happy and give it a score of five, if I were to add sad and give it a score of",
        "tokens": [
          51180,
          407,
          498,
          286,
          645,
          281,
          909,
          2055,
          293,
          976,
          309,
          257,
          6175,
          295,
          1732,
          11,
          498,
          286,
          645,
          281,
          909,
          4227,
          293,
          976,
          309,
          257,
          6175,
          295,
          51460
        ]
      },
      {
        "avg_logprob": -0.35683250427246094,
        "compression_ratio": 1.6613756613756614,
        "end": 4366.54,
        "id": 1356,
        "no_speech_prob": 0.0017545816954225302,
        "seek": 434174,
        "start": 4363.66,
        "temperature": 0,
        "text": " negative three, you can see those show up.",
        "tokens": [
          51460,
          3671,
          1045,
          11,
          291,
          393,
          536,
          729,
          855,
          493,
          13,
          51604
        ]
      },
      {
        "avg_logprob": -0.21702991485595702,
        "compression_ratio": 1.579646017699115,
        "end": 4370.22,
        "id": 1357,
        "no_speech_prob": 0.02675837278366089,
        "seek": 436654,
        "start": 4366.78,
        "temperature": 0,
        "text": " And give it a score of negative three, you can see those show up.",
        "tokens": [
          50376,
          400,
          976,
          309,
          257,
          6175,
          295,
          3671,
          1045,
          11,
          291,
          393,
          536,
          729,
          855,
          493,
          13,
          50548
        ]
      },
      {
        "avg_logprob": -0.21702991485595702,
        "compression_ratio": 1.579646017699115,
        "end": 4375.1,
        "id": 1358,
        "no_speech_prob": 0.02675837278366089,
        "seek": 436654,
        "start": 4370.22,
        "temperature": 0,
        "text": " And the API also, if I go to this particular route slash all,",
        "tokens": [
          50548,
          400,
          264,
          9362,
          611,
          11,
          498,
          286,
          352,
          281,
          341,
          1729,
          7955,
          17330,
          439,
          11,
          50792
        ]
      },
      {
        "avg_logprob": -0.21702991485595702,
        "compression_ratio": 1.579646017699115,
        "end": 4379.34,
        "id": 1359,
        "no_speech_prob": 0.02675837278366089,
        "seek": 436654,
        "start": 4376.54,
        "temperature": 0,
        "text": " shows me everything that's currently in the database.",
        "tokens": [
          50864,
          3110,
          385,
          1203,
          300,
          311,
          4362,
          294,
          264,
          8149,
          13,
          51004
        ]
      },
      {
        "avg_logprob": -0.21702991485595702,
        "compression_ratio": 1.579646017699115,
        "end": 4380.22,
        "id": 1360,
        "no_speech_prob": 0.02675837278366089,
        "seek": 436654,
        "start": 4379.34,
        "temperature": 0,
        "text": " It's not really a database.",
        "tokens": [
          51004,
          467,
          311,
          406,
          534,
          257,
          8149,
          13,
          51048
        ]
      },
      {
        "avg_logprob": -0.21702991485595702,
        "compression_ratio": 1.579646017699115,
        "end": 4383.82,
        "id": 1361,
        "no_speech_prob": 0.02675837278366089,
        "seek": 436654,
        "start": 4380.22,
        "temperature": 0,
        "text": " It's just a text file and their scores.",
        "tokens": [
          51048,
          467,
          311,
          445,
          257,
          2487,
          3991,
          293,
          641,
          13444,
          13,
          51228
        ]
      },
      {
        "avg_logprob": -0.21702991485595702,
        "compression_ratio": 1.579646017699115,
        "end": 4387.34,
        "id": 1362,
        "no_speech_prob": 0.02675837278366089,
        "seek": 436654,
        "start": 4383.82,
        "temperature": 0,
        "text": " So what I think I would like to do now is,",
        "tokens": [
          51228,
          407,
          437,
          286,
          519,
          286,
          576,
          411,
          281,
          360,
          586,
          307,
          11,
          51404
        ]
      },
      {
        "avg_logprob": -0.21702991485595702,
        "compression_ratio": 1.579646017699115,
        "end": 4395.42,
        "id": 1363,
        "no_speech_prob": 0.02675837278366089,
        "seek": 436654,
        "start": 4391.74,
        "temperature": 0,
        "text": " I'm sorry, I'm reading the chat's interesting suggestions there.",
        "tokens": [
          51624,
          286,
          478,
          2597,
          11,
          286,
          478,
          3760,
          264,
          5081,
          311,
          1880,
          13396,
          456,
          13,
          51808
        ]
      },
      {
        "avg_logprob": -0.21799850463867188,
        "compression_ratio": 1.3850931677018634,
        "end": 4401.26,
        "id": 1364,
        "no_speech_prob": 0.00005225200948189013,
        "seek": 439542,
        "start": 4395.42,
        "temperature": 0,
        "text": " What I would like to do now is finally finish off this example by adding",
        "tokens": [
          50364,
          708,
          286,
          576,
          411,
          281,
          360,
          586,
          307,
          2721,
          2413,
          766,
          341,
          1365,
          538,
          5127,
          50656
        ]
      },
      {
        "avg_logprob": -0.21799850463867188,
        "compression_ratio": 1.3850931677018634,
        "end": 4415.18,
        "id": 1365,
        "no_speech_prob": 0.00005225200948189013,
        "seek": 439542,
        "start": 4404.78,
        "temperature": 0,
        "text": " the ability to put text into a text field, post it to the API, and then get a score back.",
        "tokens": [
          50832,
          264,
          3485,
          281,
          829,
          2487,
          666,
          257,
          2487,
          2519,
          11,
          2183,
          309,
          281,
          264,
          9362,
          11,
          293,
          550,
          483,
          257,
          6175,
          646,
          13,
          51352
        ]
      },
      {
        "avg_logprob": -0.21799850463867188,
        "compression_ratio": 1.3850931677018634,
        "end": 4422.7,
        "id": 1366,
        "no_speech_prob": 0.00005225200948189013,
        "seek": 439542,
        "start": 4416.14,
        "temperature": 0,
        "text": " And then also combine this list with the AFIN111 list.",
        "tokens": [
          51400,
          400,
          550,
          611,
          10432,
          341,
          1329,
          365,
          264,
          20389,
          1464,
          5348,
          16,
          1329,
          13,
          51728
        ]
      },
      {
        "avg_logprob": -0.21799850463867188,
        "compression_ratio": 1.3850931677018634,
        "end": 4423.2,
        "id": 1367,
        "no_speech_prob": 0.00005225200948189013,
        "seek": 439542,
        "start": 4422.7,
        "temperature": 0,
        "text": " Okay?",
        "tokens": [
          51728,
          1033,
          30,
          51753
        ]
      },
      {
        "avg_logprob": -0.28218709268877584,
        "compression_ratio": 1.6260162601626016,
        "end": 4424.58,
        "id": 1368,
        "no_speech_prob": 0.000020145556845818646,
        "seek": 442320,
        "start": 4424.08,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50408,
          1033,
          13,
          50433
        ]
      },
      {
        "avg_logprob": -0.28218709268877584,
        "compression_ratio": 1.6260162601626016,
        "end": 4426.88,
        "id": 1369,
        "no_speech_prob": 0.000020145556845818646,
        "seek": 442320,
        "start": 4425.84,
        "temperature": 0,
        "text": " So I'm going to do that.",
        "tokens": [
          50496,
          407,
          286,
          478,
          516,
          281,
          360,
          300,
          13,
          50548
        ]
      },
      {
        "avg_logprob": -0.28218709268877584,
        "compression_ratio": 1.6260162601626016,
        "end": 4428.88,
        "id": 1370,
        "no_speech_prob": 0.000020145556845818646,
        "seek": 442320,
        "start": 4426.88,
        "temperature": 0,
        "text": " That'll be, unfortunately, the last thing I'm going to do today.",
        "tokens": [
          50548,
          663,
          603,
          312,
          11,
          7015,
          11,
          264,
          1036,
          551,
          286,
          478,
          516,
          281,
          360,
          965,
          13,
          50648
        ]
      },
      {
        "avg_logprob": -0.28218709268877584,
        "compression_ratio": 1.6260162601626016,
        "end": 4430.639999999999,
        "id": 1371,
        "no_speech_prob": 0.000020145556845818646,
        "seek": 442320,
        "start": 4428.88,
        "temperature": 0,
        "text": " I had ambitions of getting further.",
        "tokens": [
          50648,
          286,
          632,
          34475,
          295,
          1242,
          3052,
          13,
          50736
        ]
      },
      {
        "avg_logprob": -0.28218709268877584,
        "compression_ratio": 1.6260162601626016,
        "end": 4438.88,
        "id": 1372,
        "no_speech_prob": 0.000020145556845818646,
        "seek": 442320,
        "start": 4433.76,
        "temperature": 0,
        "text": " But I do really want to finish this playlist about building your own API in Node.",
        "tokens": [
          50892,
          583,
          286,
          360,
          534,
          528,
          281,
          2413,
          341,
          16788,
          466,
          2390,
          428,
          1065,
          9362,
          294,
          38640,
          13,
          51148
        ]
      },
      {
        "avg_logprob": -0.28218709268877584,
        "compression_ratio": 1.6260162601626016,
        "end": 4440.58,
        "id": 1373,
        "no_speech_prob": 0.000020145556845818646,
        "seek": 442320,
        "start": 4440.08,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51208,
          1033,
          13,
          51233
        ]
      },
      {
        "avg_logprob": -0.28218709268877584,
        "compression_ratio": 1.6260162601626016,
        "end": 4441.599999999999,
        "id": 1374,
        "no_speech_prob": 0.000020145556845818646,
        "seek": 442320,
        "start": 4440.58,
        "temperature": 0,
        "text": " Ah, it's 3 AM in India.",
        "tokens": [
          51233,
          2438,
          11,
          309,
          311,
          805,
          6475,
          294,
          5282,
          13,
          51284
        ]
      },
      {
        "avg_logprob": -0.28218709268877584,
        "compression_ratio": 1.6260162601626016,
        "end": 4443.12,
        "id": 1375,
        "no_speech_prob": 0.000020145556845818646,
        "seek": 442320,
        "start": 4441.599999999999,
        "temperature": 0,
        "text": " I'm impressed that you're up and watching.",
        "tokens": [
          51284,
          286,
          478,
          11679,
          300,
          291,
          434,
          493,
          293,
          1976,
          13,
          51360
        ]
      },
      {
        "avg_logprob": -0.28218709268877584,
        "compression_ratio": 1.6260162601626016,
        "end": 4444.24,
        "id": 1376,
        "no_speech_prob": 0.000020145556845818646,
        "seek": 442320,
        "start": 4443.76,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51392,
          1033,
          13,
          51416
        ]
      },
      {
        "avg_logprob": -0.28218709268877584,
        "compression_ratio": 1.6260162601626016,
        "end": 4447.5199999999995,
        "id": 1377,
        "no_speech_prob": 0.000020145556845818646,
        "seek": 442320,
        "start": 4444.24,
        "temperature": 0,
        "text": " So let me get myself organized here.",
        "tokens": [
          51416,
          407,
          718,
          385,
          483,
          2059,
          9983,
          510,
          13,
          51580
        ]
      },
      {
        "avg_logprob": -0.28218709268877584,
        "compression_ratio": 1.6260162601626016,
        "end": 4451.5199999999995,
        "id": 1378,
        "no_speech_prob": 0.000020145556845818646,
        "seek": 442320,
        "start": 4448.08,
        "temperature": 0,
        "text": " As always, I always forget the this dot, this dot, this dot, this dot.",
        "tokens": [
          51608,
          1018,
          1009,
          11,
          286,
          1009,
          2870,
          264,
          341,
          5893,
          11,
          341,
          5893,
          11,
          341,
          5893,
          11,
          341,
          5893,
          13,
          51780
        ]
      },
      {
        "avg_logprob": -0.5377803802490234,
        "compression_ratio": 1.75,
        "end": 4466.56,
        "id": 1379,
        "no_speech_prob": 0.038448963314294815,
        "seek": 445152,
        "start": 4452.240000000001,
        "temperature": 0.4,
        "text": " I'm going to do this dot, this dot, this dot, this dot, this dot, this dot.",
        "tokens": [
          50400,
          286,
          478,
          516,
          281,
          360,
          341,
          5893,
          11,
          341,
          5893,
          11,
          341,
          5893,
          11,
          341,
          5893,
          11,
          341,
          5893,
          11,
          341,
          5893,
          13,
          51116
        ]
      },
      {
        "avg_logprob": -0.5377803802490234,
        "compression_ratio": 1.75,
        "end": 4479.6,
        "id": 1380,
        "no_speech_prob": 0.038448963314294815,
        "seek": 445152,
        "start": 4479.360000000001,
        "temperature": 0.4,
        "text": " All right.",
        "tokens": [
          51756,
          1057,
          558,
          13,
          51768
        ]
      },
      {
        "avg_logprob": -0.5377803802490234,
        "compression_ratio": 1.75,
        "end": 4480.64,
        "id": 1381,
        "no_speech_prob": 0.038448963314294815,
        "seek": 445152,
        "start": 4479.6,
        "temperature": 0.4,
        "text": " I think I'm ready.",
        "tokens": [
          51768,
          286,
          519,
          286,
          478,
          1919,
          13,
          51820
        ]
      },
      {
        "avg_logprob": -0.1950416411122968,
        "compression_ratio": 1.2657342657342658,
        "end": 4486.320000000001,
        "id": 1382,
        "no_speech_prob": 0.0003569619730114937,
        "seek": 448064,
        "start": 4480.64,
        "temperature": 0,
        "text": " Let me cycle these cameras.",
        "tokens": [
          50364,
          961,
          385,
          6586,
          613,
          8622,
          13,
          50648
        ]
      },
      {
        "avg_logprob": -0.1950416411122968,
        "compression_ratio": 1.2657342657342658,
        "end": 4493.76,
        "id": 1383,
        "no_speech_prob": 0.0003569619730114937,
        "seek": 448064,
        "start": 4491.4400000000005,
        "temperature": 0,
        "text": " And let me make sure I have my pen and eraser.",
        "tokens": [
          50904,
          400,
          718,
          385,
          652,
          988,
          286,
          362,
          452,
          3435,
          293,
          46018,
          13,
          51020
        ]
      },
      {
        "avg_logprob": -0.1950416411122968,
        "compression_ratio": 1.2657342657342658,
        "end": 4496.320000000001,
        "id": 1384,
        "no_speech_prob": 0.0003569619730114937,
        "seek": 448064,
        "start": 4494.72,
        "temperature": 0,
        "text": " Hey, somebody's in Bushwick watching.",
        "tokens": [
          51068,
          1911,
          11,
          2618,
          311,
          294,
          15782,
          16038,
          1976,
          13,
          51148
        ]
      },
      {
        "avg_logprob": -0.1950416411122968,
        "compression_ratio": 1.2657342657342658,
        "end": 4497.200000000001,
        "id": 1385,
        "no_speech_prob": 0.0003569619730114937,
        "seek": 448064,
        "start": 4496.320000000001,
        "temperature": 0,
        "text": " That's not too far away.",
        "tokens": [
          51148,
          663,
          311,
          406,
          886,
          1400,
          1314,
          13,
          51192
        ]
      },
      {
        "avg_logprob": -0.1950416411122968,
        "compression_ratio": 1.2657342657342658,
        "end": 4498.4800000000005,
        "id": 1386,
        "no_speech_prob": 0.0003569619730114937,
        "seek": 448064,
        "start": 4497.200000000001,
        "temperature": 0,
        "text": " I'm impressed and amazed.",
        "tokens": [
          51192,
          286,
          478,
          11679,
          293,
          20507,
          13,
          51256
        ]
      },
      {
        "avg_logprob": -0.1950416411122968,
        "compression_ratio": 1.2657342657342658,
        "end": 4500.740000000001,
        "id": 1387,
        "no_speech_prob": 0.0003569619730114937,
        "seek": 448064,
        "start": 4500.240000000001,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51344,
          1033,
          13,
          51369
        ]
      },
      {
        "avg_logprob": -0.1950416411122968,
        "compression_ratio": 1.2657342657342658,
        "end": 4501.84,
        "id": 1388,
        "no_speech_prob": 0.0003569619730114937,
        "seek": 448064,
        "start": 4501.280000000001,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          51396,
          1692,
          321,
          352,
          13,
          51424
        ]
      },
      {
        "avg_logprob": -0.38022716228778547,
        "compression_ratio": 1.3937007874015748,
        "end": 4510.32,
        "id": 1389,
        "no_speech_prob": 0.06754117459058762,
        "seek": 450184,
        "start": 4501.84,
        "temperature": 0,
        "text": " So welcome to another...",
        "tokens": [
          50364,
          407,
          2928,
          281,
          1071,
          485,
          50788
        ]
      },
      {
        "avg_logprob": -0.38022716228778547,
        "compression_ratio": 1.3937007874015748,
        "end": 4513.92,
        "id": 1390,
        "no_speech_prob": 0.06754117459058762,
        "seek": 450184,
        "start": 4512.88,
        "temperature": 0,
        "text": " We started that over.",
        "tokens": [
          50916,
          492,
          1409,
          300,
          670,
          13,
          50968
        ]
      },
      {
        "avg_logprob": -0.38022716228778547,
        "compression_ratio": 1.3937007874015748,
        "end": 4521.4400000000005,
        "id": 1391,
        "no_speech_prob": 0.06754117459058762,
        "seek": 450184,
        "start": 4518.32,
        "temperature": 0,
        "text": " My throat has really never recovered from that illness I had a month ago.",
        "tokens": [
          51188,
          1222,
          12394,
          575,
          534,
          1128,
          19542,
          490,
          300,
          10152,
          286,
          632,
          257,
          1618,
          2057,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.38022716228778547,
        "compression_ratio": 1.3937007874015748,
        "end": 4521.9400000000005,
        "id": 1392,
        "no_speech_prob": 0.06754117459058762,
        "seek": 450184,
        "start": 4521.4400000000005,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51344,
          1033,
          13,
          51369
        ]
      },
      {
        "avg_logprob": -0.38022716228778547,
        "compression_ratio": 1.3937007874015748,
        "end": 4526.400000000001,
        "id": 1393,
        "no_speech_prob": 0.06754117459058762,
        "seek": 450184,
        "start": 4524.08,
        "temperature": 0,
        "text": " Welcome to yet another...",
        "tokens": [
          51476,
          4027,
          281,
          1939,
          1071,
          485,
          51592
        ]
      },
      {
        "avg_logprob": -0.38022716228778547,
        "compression_ratio": 1.3937007874015748,
        "end": 4529.12,
        "id": 1394,
        "no_speech_prob": 0.06754117459058762,
        "seek": 450184,
        "start": 4528.08,
        "temperature": 0,
        "text": " I'm losing my mind here.",
        "tokens": [
          51676,
          286,
          478,
          7027,
          452,
          1575,
          510,
          13,
          51728
        ]
      },
      {
        "avg_logprob": -0.1816294511159261,
        "compression_ratio": 1.6514084507042253,
        "end": 4536.64,
        "id": 1395,
        "no_speech_prob": 0.00003219210702809505,
        "seek": 453184,
        "start": 4531.84,
        "temperature": 0,
        "text": " Welcome to another and what might possibly actually be the last video in this playlist",
        "tokens": [
          50364,
          4027,
          281,
          1071,
          293,
          437,
          1062,
          6264,
          767,
          312,
          264,
          1036,
          960,
          294,
          341,
          16788,
          50604
        ]
      },
      {
        "avg_logprob": -0.1816294511159261,
        "compression_ratio": 1.6514084507042253,
        "end": 4540.24,
        "id": 1396,
        "no_speech_prob": 0.00003219210702809505,
        "seek": 453184,
        "start": 4536.64,
        "temperature": 0,
        "text": " about how to build your own API in Node.",
        "tokens": [
          50604,
          466,
          577,
          281,
          1322,
          428,
          1065,
          9362,
          294,
          38640,
          13,
          50784
        ]
      },
      {
        "avg_logprob": -0.1816294511159261,
        "compression_ratio": 1.6514084507042253,
        "end": 4544.72,
        "id": 1397,
        "no_speech_prob": 0.00003219210702809505,
        "seek": 453184,
        "start": 4540.24,
        "temperature": 0,
        "text": " So if you remember, you might have just watched the last video, but it's been a while since I",
        "tokens": [
          50784,
          407,
          498,
          291,
          1604,
          11,
          291,
          1062,
          362,
          445,
          6337,
          264,
          1036,
          960,
          11,
          457,
          309,
          311,
          668,
          257,
          1339,
          1670,
          286,
          51008
        ]
      },
      {
        "avg_logprob": -0.1816294511159261,
        "compression_ratio": 1.6514084507042253,
        "end": 4545.12,
        "id": 1398,
        "no_speech_prob": 0.00003219210702809505,
        "seek": 453184,
        "start": 4544.72,
        "temperature": 0,
        "text": " made it.",
        "tokens": [
          51008,
          1027,
          309,
          13,
          51028
        ]
      },
      {
        "avg_logprob": -0.1816294511159261,
        "compression_ratio": 1.6514084507042253,
        "end": 4547.84,
        "id": 1399,
        "no_speech_prob": 0.00003219210702809505,
        "seek": 453184,
        "start": 4545.12,
        "temperature": 0,
        "text": " So I'm going to just kind of set the stage here very, very briefly.",
        "tokens": [
          51028,
          407,
          286,
          478,
          516,
          281,
          445,
          733,
          295,
          992,
          264,
          3233,
          510,
          588,
          11,
          588,
          10515,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1816294511159261,
        "compression_ratio": 1.6514084507042253,
        "end": 4557.2,
        "id": 1400,
        "no_speech_prob": 0.00003219210702809505,
        "seek": 453184,
        "start": 4548.8,
        "temperature": 0,
        "text": " We have so far an API made in Node that saves words and a score, a kind of positive or negative",
        "tokens": [
          51212,
          492,
          362,
          370,
          1400,
          364,
          9362,
          1027,
          294,
          38640,
          300,
          19155,
          2283,
          293,
          257,
          6175,
          11,
          257,
          733,
          295,
          3353,
          420,
          3671,
          51632
        ]
      },
      {
        "avg_logprob": -0.1816294511159261,
        "compression_ratio": 1.6514084507042253,
        "end": 4560.96,
        "id": 1401,
        "no_speech_prob": 0.00003219210702809505,
        "seek": 453184,
        "start": 4557.2,
        "temperature": 0,
        "text": " valence, the idea that we're going to do a sentiment analysis application.",
        "tokens": [
          51632,
          1323,
          655,
          11,
          264,
          1558,
          300,
          321,
          434,
          516,
          281,
          360,
          257,
          16149,
          5215,
          3861,
          13,
          51820
        ]
      },
      {
        "avg_logprob": -0.20819425153302717,
        "compression_ratio": 1.7768240343347639,
        "end": 4564,
        "id": 1402,
        "no_speech_prob": 0.0002131865912815556,
        "seek": 456184,
        "start": 4561.84,
        "temperature": 0,
        "text": " That stores those words over time.",
        "tokens": [
          50364,
          663,
          9512,
          729,
          2283,
          670,
          565,
          13,
          50472
        ]
      },
      {
        "avg_logprob": -0.20819425153302717,
        "compression_ratio": 1.7768240343347639,
        "end": 4570.32,
        "id": 1403,
        "no_speech_prob": 0.0002131865912815556,
        "seek": 456184,
        "start": 4564,
        "temperature": 0,
        "text": " So I have a particular route where if I go to the server slash all, I can see all the",
        "tokens": [
          50472,
          407,
          286,
          362,
          257,
          1729,
          7955,
          689,
          498,
          286,
          352,
          281,
          264,
          7154,
          17330,
          439,
          11,
          286,
          393,
          536,
          439,
          264,
          50788
        ]
      },
      {
        "avg_logprob": -0.20819425153302717,
        "compression_ratio": 1.7768240343347639,
        "end": 4572.64,
        "id": 1404,
        "no_speech_prob": 0.0002131865912815556,
        "seek": 456184,
        "start": 4570.32,
        "temperature": 0,
        "text": " words that are in a particular... in that database.",
        "tokens": [
          50788,
          2283,
          300,
          366,
          294,
          257,
          1729,
          485,
          294,
          300,
          8149,
          13,
          50904
        ]
      },
      {
        "avg_logprob": -0.20819425153302717,
        "compression_ratio": 1.7768240343347639,
        "end": 4580,
        "id": 1405,
        "no_speech_prob": 0.0002131865912815556,
        "seek": 456184,
        "start": 4572.64,
        "temperature": 0,
        "text": " I also made a little front end that if I add a word like kitten and I give it a score like",
        "tokens": [
          50904,
          286,
          611,
          1027,
          257,
          707,
          1868,
          917,
          300,
          498,
          286,
          909,
          257,
          1349,
          411,
          39696,
          293,
          286,
          976,
          309,
          257,
          6175,
          411,
          51272
        ]
      },
      {
        "avg_logprob": -0.20819425153302717,
        "compression_ratio": 1.7768240343347639,
        "end": 4585.92,
        "id": 1406,
        "no_speech_prob": 0.0002131865912815556,
        "seek": 456184,
        "start": 4580,
        "temperature": 0,
        "text": " four and I hit submit and then I can hit refresh here and we can see now kitten has now been",
        "tokens": [
          51272,
          1451,
          293,
          286,
          2045,
          10315,
          293,
          550,
          286,
          393,
          2045,
          15134,
          510,
          293,
          321,
          393,
          536,
          586,
          39696,
          575,
          586,
          668,
          51568
        ]
      },
      {
        "avg_logprob": -0.20819425153302717,
        "compression_ratio": 1.7768240343347639,
        "end": 4587.12,
        "id": 1407,
        "no_speech_prob": 0.0002131865912815556,
        "seek": 456184,
        "start": 4585.92,
        "temperature": 0,
        "text": " added to that database.",
        "tokens": [
          51568,
          3869,
          281,
          300,
          8149,
          13,
          51628
        ]
      },
      {
        "avg_logprob": -0.20819425153302717,
        "compression_ratio": 1.7768240343347639,
        "end": 4589.12,
        "id": 1408,
        "no_speech_prob": 0.0002131865912815556,
        "seek": 456184,
        "start": 4587.12,
        "temperature": 0,
        "text": " Now it's not actually a database.",
        "tokens": [
          51628,
          823,
          309,
          311,
          406,
          767,
          257,
          8149,
          13,
          51728
        ]
      },
      {
        "avg_logprob": -0.20006779004942696,
        "compression_ratio": 1.6234309623430963,
        "end": 4596.88,
        "id": 1409,
        "no_speech_prob": 0.00012339414388407022,
        "seek": 458912,
        "start": 4589.12,
        "temperature": 0,
        "text": " It is simply just a list, a JSON file, but the Node program is receiving the word and",
        "tokens": [
          50364,
          467,
          307,
          2935,
          445,
          257,
          1329,
          11,
          257,
          31828,
          3991,
          11,
          457,
          264,
          38640,
          1461,
          307,
          10040,
          264,
          1349,
          293,
          50752
        ]
      },
      {
        "avg_logprob": -0.20006779004942696,
        "compression_ratio": 1.6234309623430963,
        "end": 4601.44,
        "id": 1410,
        "no_speech_prob": 0.00012339414388407022,
        "seek": 458912,
        "start": 4596.88,
        "temperature": 0,
        "text": " score from the client, saving it to the JSON file and loading again for later use.",
        "tokens": [
          50752,
          6175,
          490,
          264,
          6423,
          11,
          6816,
          309,
          281,
          264,
          31828,
          3991,
          293,
          15114,
          797,
          337,
          1780,
          764,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.20006779004942696,
        "compression_ratio": 1.6234309623430963,
        "end": 4606.16,
        "id": 1411,
        "no_speech_prob": 0.00012339414388407022,
        "seek": 458912,
        "start": 4601.44,
        "temperature": 0,
        "text": " So there are two things in this video that I want to add to this particular application.",
        "tokens": [
          50980,
          407,
          456,
          366,
          732,
          721,
          294,
          341,
          960,
          300,
          286,
          528,
          281,
          909,
          281,
          341,
          1729,
          3861,
          13,
          51216
        ]
      },
      {
        "avg_logprob": -0.20006779004942696,
        "compression_ratio": 1.6234309623430963,
        "end": 4608.72,
        "id": 1412,
        "no_speech_prob": 0.00012339414388407022,
        "seek": 458912,
        "start": 4606.16,
        "temperature": 0,
        "text": " Number one, I want to use...",
        "tokens": [
          51216,
          5118,
          472,
          11,
          286,
          528,
          281,
          764,
          485,
          51344
        ]
      },
      {
        "avg_logprob": -0.20006779004942696,
        "compression_ratio": 1.6234309623430963,
        "end": 4614.32,
        "id": 1413,
        "no_speech_prob": 0.00012339414388407022,
        "seek": 458912,
        "start": 4610,
        "temperature": 0,
        "text": " I want to add a pre-existing list of words and valence scores.",
        "tokens": [
          51408,
          286,
          528,
          281,
          909,
          257,
          659,
          12,
          36447,
          1329,
          295,
          2283,
          293,
          1323,
          655,
          13444,
          13,
          51624
        ]
      },
      {
        "avg_logprob": -0.20006779004942696,
        "compression_ratio": 1.6234309623430963,
        "end": 4617.04,
        "id": 1414,
        "no_speech_prob": 0.00012339414388407022,
        "seek": 458912,
        "start": 4614.32,
        "temperature": 0,
        "text": " And this list is known as the AFIN111.",
        "tokens": [
          51624,
          400,
          341,
          1329,
          307,
          2570,
          382,
          264,
          20389,
          1464,
          5348,
          16,
          13,
          51760
        ]
      },
      {
        "avg_logprob": -0.18197620936802456,
        "compression_ratio": 1.6421725239616614,
        "end": 4620.48,
        "id": 1415,
        "no_speech_prob": 0.0005192921962589025,
        "seek": 461704,
        "start": 4617.04,
        "temperature": 0,
        "text": " So this will just make the sentiment analysis work a little better by giving us...",
        "tokens": [
          50364,
          407,
          341,
          486,
          445,
          652,
          264,
          16149,
          5215,
          589,
          257,
          707,
          1101,
          538,
          2902,
          505,
          485,
          50536
        ]
      },
      {
        "avg_logprob": -0.18197620936802456,
        "compression_ratio": 1.6421725239616614,
        "end": 4623.2,
        "id": 1416,
        "no_speech_prob": 0.0005192921962589025,
        "seek": 461704,
        "start": 4620.48,
        "temperature": 0,
        "text": " seeding it with a pre-existing list of words.",
        "tokens": [
          50536,
          8871,
          278,
          309,
          365,
          257,
          659,
          12,
          36447,
          1329,
          295,
          2283,
          13,
          50672
        ]
      },
      {
        "avg_logprob": -0.18197620936802456,
        "compression_ratio": 1.6421725239616614,
        "end": 4627.36,
        "id": 1417,
        "no_speech_prob": 0.0005192921962589025,
        "seek": 461704,
        "start": 4623.2,
        "temperature": 0,
        "text": " I made a separate video where I went over this in more detail, which I'll link to in",
        "tokens": [
          50672,
          286,
          1027,
          257,
          4994,
          960,
          689,
          286,
          1437,
          670,
          341,
          294,
          544,
          2607,
          11,
          597,
          286,
          603,
          2113,
          281,
          294,
          50880
        ]
      },
      {
        "avg_logprob": -0.18197620936802456,
        "compression_ratio": 1.6421725239616614,
        "end": 4633.68,
        "id": 1418,
        "no_speech_prob": 0.0005192921962589025,
        "seek": 461704,
        "start": 4627.36,
        "temperature": 0,
        "text": " this, but this list comes from this particular website and it was developed by Finn Arup",
        "tokens": [
          50880,
          341,
          11,
          457,
          341,
          1329,
          1487,
          490,
          341,
          1729,
          3144,
          293,
          309,
          390,
          4743,
          538,
          21066,
          316,
          11976,
          51196
        ]
      },
      {
        "avg_logprob": -0.18197620936802456,
        "compression_ratio": 1.6421725239616614,
        "end": 4638.24,
        "id": 1419,
        "no_speech_prob": 0.0005192921962589025,
        "seek": 461704,
        "start": 4633.68,
        "temperature": 0,
        "text": " Nielsen and if you use it, you should credit it and there's links and information about",
        "tokens": [
          51196,
          426,
          1187,
          6748,
          293,
          498,
          291,
          764,
          309,
          11,
          291,
          820,
          5397,
          309,
          293,
          456,
          311,
          6123,
          293,
          1589,
          466,
          51424
        ]
      },
      {
        "avg_logprob": -0.18197620936802456,
        "compression_ratio": 1.6421725239616614,
        "end": 4639.04,
        "id": 1420,
        "no_speech_prob": 0.0005192921962589025,
        "seek": 461704,
        "start": 4638.24,
        "temperature": 0,
        "text": " how to do that here.",
        "tokens": [
          51424,
          577,
          281,
          360,
          300,
          510,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18197620936802456,
        "compression_ratio": 1.6421725239616614,
        "end": 4641.68,
        "id": 1421,
        "no_speech_prob": 0.0005192921962589025,
        "seek": 461704,
        "start": 4640.48,
        "temperature": 0,
        "text": " Okay, so that exists.",
        "tokens": [
          51536,
          1033,
          11,
          370,
          300,
          8198,
          13,
          51596
        ]
      },
      {
        "avg_logprob": -0.18197620936802456,
        "compression_ratio": 1.6421725239616614,
        "end": 4642.48,
        "id": 1422,
        "no_speech_prob": 0.0005192921962589025,
        "seek": 461704,
        "start": 4641.68,
        "temperature": 0,
        "text": " That's number one.",
        "tokens": [
          51596,
          663,
          311,
          1230,
          472,
          13,
          51636
        ]
      },
      {
        "avg_logprob": -0.18197620936802456,
        "compression_ratio": 1.6421725239616614,
        "end": 4643.6,
        "id": 1423,
        "no_speech_prob": 0.0005192921962589025,
        "seek": 461704,
        "start": 4642.48,
        "temperature": 0,
        "text": " I want to bring that list over.",
        "tokens": [
          51636,
          286,
          528,
          281,
          1565,
          300,
          1329,
          670,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.18197620936802456,
        "compression_ratio": 1.6421725239616614,
        "end": 4645.12,
        "id": 1424,
        "no_speech_prob": 0.0005192921962589025,
        "seek": 461704,
        "start": 4643.6,
        "temperature": 0,
        "text": " Let's actually do that first.",
        "tokens": [
          51692,
          961,
          311,
          767,
          360,
          300,
          700,
          13,
          51768
        ]
      },
      {
        "avg_logprob": -0.17878404324942263,
        "compression_ratio": 1.824,
        "end": 4646.88,
        "id": 1425,
        "no_speech_prob": 0.0022871969267725945,
        "seek": 464512,
        "start": 4645.12,
        "temperature": 0,
        "text": " I'll say what the number two is in a second.",
        "tokens": [
          50364,
          286,
          603,
          584,
          437,
          264,
          1230,
          732,
          307,
          294,
          257,
          1150,
          13,
          50452
        ]
      },
      {
        "avg_logprob": -0.17878404324942263,
        "compression_ratio": 1.824,
        "end": 4649.68,
        "id": 1426,
        "no_speech_prob": 0.0022871969267725945,
        "seek": 464512,
        "start": 4646.88,
        "temperature": 0,
        "text": " Number two is I want to look at a post to the API.",
        "tokens": [
          50452,
          5118,
          732,
          307,
          286,
          528,
          281,
          574,
          412,
          257,
          2183,
          281,
          264,
          9362,
          13,
          50592
        ]
      },
      {
        "avg_logprob": -0.17878404324942263,
        "compression_ratio": 1.824,
        "end": 4650.96,
        "id": 1427,
        "no_speech_prob": 0.0022871969267725945,
        "seek": 464512,
        "start": 4649.68,
        "temperature": 0,
        "text": " What's the difference between get and post?",
        "tokens": [
          50592,
          708,
          311,
          264,
          2649,
          1296,
          483,
          293,
          2183,
          30,
          50656
        ]
      },
      {
        "avg_logprob": -0.17878404324942263,
        "compression_ratio": 1.824,
        "end": 4652.48,
        "id": 1428,
        "no_speech_prob": 0.0022871969267725945,
        "seek": 464512,
        "start": 4650.96,
        "temperature": 0,
        "text": " That's going to be part of this video too.",
        "tokens": [
          50656,
          663,
          311,
          516,
          281,
          312,
          644,
          295,
          341,
          960,
          886,
          13,
          50732
        ]
      },
      {
        "avg_logprob": -0.17878404324942263,
        "compression_ratio": 1.824,
        "end": 4657.12,
        "id": 1429,
        "no_speech_prob": 0.0022871969267725945,
        "seek": 464512,
        "start": 4652.48,
        "temperature": 0,
        "text": " So I'm actually just going to absurdly just do save as and I'm going to go to my",
        "tokens": [
          50732,
          407,
          286,
          478,
          767,
          445,
          516,
          281,
          19774,
          356,
          445,
          360,
          3155,
          382,
          293,
          286,
          478,
          516,
          281,
          352,
          281,
          452,
          50964
        ]
      },
      {
        "avg_logprob": -0.17878404324942263,
        "compression_ratio": 1.824,
        "end": 4664.88,
        "id": 1430,
        "no_speech_prob": 0.0022871969267725945,
        "seek": 464512,
        "start": 4658.64,
        "temperature": 0,
        "text": " node folder and I'm going to save it as AFIN111.json and then I'm going to go to the server",
        "tokens": [
          51040,
          9984,
          10820,
          293,
          286,
          478,
          516,
          281,
          3155,
          309,
          382,
          20389,
          1464,
          5348,
          16,
          13,
          73,
          3015,
          293,
          550,
          286,
          478,
          516,
          281,
          352,
          281,
          264,
          7154,
          51352
        ]
      },
      {
        "avg_logprob": -0.17878404324942263,
        "compression_ratio": 1.824,
        "end": 4669.68,
        "id": 1431,
        "no_speech_prob": 0.0022871969267725945,
        "seek": 464512,
        "start": 4664.88,
        "temperature": 0,
        "text": " and we're going to look at where the server loads.",
        "tokens": [
          51352,
          293,
          321,
          434,
          516,
          281,
          574,
          412,
          689,
          264,
          7154,
          12668,
          13,
          51592
        ]
      },
      {
        "avg_logprob": -0.17878404324942263,
        "compression_ratio": 1.824,
        "end": 4673.36,
        "id": 1432,
        "no_speech_prob": 0.0022871969267725945,
        "seek": 464512,
        "start": 4671.5199999999995,
        "temperature": 0,
        "text": " Where does the server load that file?",
        "tokens": [
          51684,
          2305,
          775,
          264,
          7154,
          3677,
          300,
          3991,
          30,
          51776
        ]
      },
      {
        "avg_logprob": -0.17878404324942263,
        "compression_ratio": 1.824,
        "end": 4673.92,
        "id": 1433,
        "no_speech_prob": 0.0022871969267725945,
        "seek": 464512,
        "start": 4673.36,
        "temperature": 0,
        "text": " Right here.",
        "tokens": [
          51776,
          1779,
          510,
          13,
          51804
        ]
      },
      {
        "avg_logprob": -0.3030249554177989,
        "compression_ratio": 1.5294117647058822,
        "end": 4677.52,
        "id": 1434,
        "no_speech_prob": 0.000597659032791853,
        "seek": 467392,
        "start": 4674.56,
        "temperature": 0,
        "text": " var data equals read file sync words.json.",
        "tokens": [
          50396,
          1374,
          1412,
          6915,
          1401,
          3991,
          20271,
          2283,
          13,
          73,
          3015,
          13,
          50544
        ]
      },
      {
        "avg_logprob": -0.3030249554177989,
        "compression_ratio": 1.5294117647058822,
        "end": 4679.36,
        "id": 1435,
        "no_speech_prob": 0.000597659032791853,
        "seek": 467392,
        "start": 4677.52,
        "temperature": 0,
        "text": " So I also want to load.",
        "tokens": [
          50544,
          407,
          286,
          611,
          528,
          281,
          3677,
          13,
          50636
        ]
      },
      {
        "avg_logprob": -0.3030249554177989,
        "compression_ratio": 1.5294117647058822,
        "end": 4691.6,
        "id": 1436,
        "no_speech_prob": 0.000597659032791853,
        "seek": 467392,
        "start": 4682.72,
        "temperature": 0,
        "text": " AFIN, what is it for AFIN111.json into a variable called AFIN actually and I'll call this AFIN",
        "tokens": [
          50804,
          20389,
          1464,
          11,
          437,
          307,
          309,
          337,
          20389,
          1464,
          5348,
          16,
          13,
          73,
          3015,
          666,
          257,
          7006,
          1219,
          20389,
          1464,
          767,
          293,
          286,
          603,
          818,
          341,
          20389,
          1464,
          51248
        ]
      },
      {
        "avg_logprob": -0.3030249554177989,
        "compression_ratio": 1.5294117647058822,
        "end": 4700.4,
        "id": 1437,
        "no_speech_prob": 0.000597659032791853,
        "seek": 467392,
        "start": 4691.6,
        "temperature": 0,
        "text": " data and then I want to say var data equals json.parse AFIN data.",
        "tokens": [
          51248,
          1412,
          293,
          550,
          286,
          528,
          281,
          584,
          1374,
          1412,
          6915,
          361,
          3015,
          13,
          2181,
          405,
          20389,
          1464,
          1412,
          13,
          51688
        ]
      },
      {
        "avg_logprob": -0.3030249554177989,
        "compression_ratio": 1.5294117647058822,
        "end": 4701.12,
        "id": 1438,
        "no_speech_prob": 0.000597659032791853,
        "seek": 467392,
        "start": 4700.4,
        "temperature": 0,
        "text": " Oh, no, so far.",
        "tokens": [
          51688,
          876,
          11,
          572,
          11,
          370,
          1400,
          13,
          51724
        ]
      },
      {
        "avg_logprob": -0.3030249554177989,
        "compression_ratio": 1.5294117647058822,
        "end": 4702.4800000000005,
        "id": 1439,
        "no_speech_prob": 0.000597659032791853,
        "seek": 467392,
        "start": 4701.12,
        "temperature": 0,
        "text": " Sorry, var AFIN.",
        "tokens": [
          51724,
          4919,
          11,
          1374,
          20389,
          1464,
          13,
          51792
        ]
      },
      {
        "avg_logprob": -0.17012422225054571,
        "compression_ratio": 1.8208955223880596,
        "end": 4710.959999999999,
        "id": 1440,
        "no_speech_prob": 0.000011843123502330855,
        "seek": 470248,
        "start": 4702.48,
        "temperature": 0,
        "text": " So now my node server has both the word list that's being saved and the AFIN list.",
        "tokens": [
          50364,
          407,
          586,
          452,
          9984,
          7154,
          575,
          1293,
          264,
          1349,
          1329,
          300,
          311,
          885,
          6624,
          293,
          264,
          20389,
          1464,
          1329,
          13,
          50788
        ]
      },
      {
        "avg_logprob": -0.17012422225054571,
        "compression_ratio": 1.8208955223880596,
        "end": 4712.08,
        "id": 1441,
        "no_speech_prob": 0.000011843123502330855,
        "seek": 470248,
        "start": 4710.959999999999,
        "temperature": 0,
        "text": " Now here's the thing.",
        "tokens": [
          50788,
          823,
          510,
          311,
          264,
          551,
          13,
          50844
        ]
      },
      {
        "avg_logprob": -0.17012422225054571,
        "compression_ratio": 1.8208955223880596,
        "end": 4716.24,
        "id": 1442,
        "no_speech_prob": 0.000011843123502330855,
        "seek": 470248,
        "start": 4714.08,
        "temperature": 0,
        "text": " So I think what I want to do is just change this.",
        "tokens": [
          50944,
          407,
          286,
          519,
          437,
          286,
          528,
          281,
          360,
          307,
          445,
          1319,
          341,
          13,
          51052
        ]
      },
      {
        "avg_logprob": -0.17012422225054571,
        "compression_ratio": 1.8208955223880596,
        "end": 4718.16,
        "id": 1443,
        "no_speech_prob": 0.000011843123502330855,
        "seek": 470248,
        "start": 4716.24,
        "temperature": 0,
        "text": " I'm going to change this to additional.",
        "tokens": [
          51052,
          286,
          478,
          516,
          281,
          1319,
          341,
          281,
          4497,
          13,
          51148
        ]
      },
      {
        "avg_logprob": -0.17012422225054571,
        "compression_ratio": 1.8208955223880596,
        "end": 4722.879999999999,
        "id": 1444,
        "no_speech_prob": 0.000011843123502330855,
        "seek": 470248,
        "start": 4718.16,
        "temperature": 0,
        "text": " I think I'm going to keep these in separate files because this AFIN111 is never going",
        "tokens": [
          51148,
          286,
          519,
          286,
          478,
          516,
          281,
          1066,
          613,
          294,
          4994,
          7098,
          570,
          341,
          20389,
          1464,
          5348,
          16,
          307,
          1128,
          516,
          51384
        ]
      },
      {
        "avg_logprob": -0.17012422225054571,
        "compression_ratio": 1.8208955223880596,
        "end": 4730.959999999999,
        "id": 1445,
        "no_speech_prob": 0.000011843123502330855,
        "seek": 470248,
        "start": 4722.879999999999,
        "temperature": 0,
        "text": " to change and what I want to do is but I'm going to call that file additional just to",
        "tokens": [
          51384,
          281,
          1319,
          293,
          437,
          286,
          528,
          281,
          360,
          307,
          457,
          286,
          478,
          516,
          281,
          818,
          300,
          3991,
          4497,
          445,
          281,
          51788
        ]
      },
      {
        "avg_logprob": -0.21818744659423828,
        "compression_ratio": 1.719626168224299,
        "end": 4742,
        "id": 1446,
        "no_speech_prob": 0.0002824066614266485,
        "seek": 473096,
        "start": 4731.28,
        "temperature": 0,
        "text": " just for clarification additional and what I want to do now is I'm a server.",
        "tokens": [
          50380,
          445,
          337,
          34449,
          4497,
          293,
          437,
          286,
          528,
          281,
          360,
          586,
          307,
          286,
          478,
          257,
          7154,
          13,
          50916
        ]
      },
      {
        "avg_logprob": -0.21818744659423828,
        "compression_ratio": 1.719626168224299,
        "end": 4747.76,
        "id": 1447,
        "no_speech_prob": 0.0002824066614266485,
        "seek": 473096,
        "start": 4742,
        "temperature": 0,
        "text": " So I have them as two and I must have a save place somewhere else.",
        "tokens": [
          50916,
          407,
          286,
          362,
          552,
          382,
          732,
          293,
          286,
          1633,
          362,
          257,
          3155,
          1081,
          4079,
          1646,
          13,
          51204
        ]
      },
      {
        "avg_logprob": -0.21818744659423828,
        "compression_ratio": 1.719626168224299,
        "end": 4751.44,
        "id": 1448,
        "no_speech_prob": 0.0002824066614266485,
        "seek": 473096,
        "start": 4747.76,
        "temperature": 0,
        "text": " So I need to change this to additional as well where I save that file because what I",
        "tokens": [
          51204,
          407,
          286,
          643,
          281,
          1319,
          341,
          281,
          4497,
          382,
          731,
          689,
          286,
          3155,
          300,
          3991,
          570,
          437,
          286,
          51388
        ]
      },
      {
        "avg_logprob": -0.21818744659423828,
        "compression_ratio": 1.719626168224299,
        "end": 4756.88,
        "id": 1449,
        "no_speech_prob": 0.0002824066614266485,
        "seek": 473096,
        "start": 4751.44,
        "temperature": 0,
        "text": " want to do is when it comes time to do this sentiment analysis, I need to look both in",
        "tokens": [
          51388,
          528,
          281,
          360,
          307,
          562,
          309,
          1487,
          565,
          281,
          360,
          341,
          16149,
          5215,
          11,
          286,
          643,
          281,
          574,
          1293,
          294,
          51660
        ]
      },
      {
        "avg_logprob": -0.21818744659423828,
        "compression_ratio": 1.719626168224299,
        "end": 4757.84,
        "id": 1450,
        "no_speech_prob": 0.0002824066614266485,
        "seek": 473096,
        "start": 4756.88,
        "temperature": 0,
        "text": " both of those.",
        "tokens": [
          51660,
          1293,
          295,
          729,
          13,
          51708
        ]
      },
      {
        "avg_logprob": -0.21818744659423828,
        "compression_ratio": 1.719626168224299,
        "end": 4760.08,
        "id": 1451,
        "no_speech_prob": 0.0002824066614266485,
        "seek": 473096,
        "start": 4757.84,
        "temperature": 0,
        "text": " I need to look in the AFIN word list.",
        "tokens": [
          51708,
          286,
          643,
          281,
          574,
          294,
          264,
          20389,
          1464,
          1349,
          1329,
          13,
          51820
        ]
      },
      {
        "avg_logprob": -0.17927530256368346,
        "compression_ratio": 1.6403508771929824,
        "end": 4761.04,
        "id": 1452,
        "no_speech_prob": 0.000016442481864942238,
        "seek": 476008,
        "start": 4760.16,
        "temperature": 0,
        "text": " Is it there?",
        "tokens": [
          50368,
          1119,
          309,
          456,
          30,
          50412
        ]
      },
      {
        "avg_logprob": -0.17927530256368346,
        "compression_ratio": 1.6403508771929824,
        "end": 4766.64,
        "id": 1453,
        "no_speech_prob": 0.000016442481864942238,
        "seek": 476008,
        "start": 4761.04,
        "temperature": 0,
        "text": " If not, look in the additional word list and I should decide if one overrides the other.",
        "tokens": [
          50412,
          759,
          406,
          11,
          574,
          294,
          264,
          4497,
          1349,
          1329,
          293,
          286,
          820,
          4536,
          498,
          472,
          670,
          81,
          1875,
          264,
          661,
          13,
          50692
        ]
      },
      {
        "avg_logprob": -0.17927530256368346,
        "compression_ratio": 1.6403508771929824,
        "end": 4769.84,
        "id": 1454,
        "no_speech_prob": 0.000016442481864942238,
        "seek": 476008,
        "start": 4766.64,
        "temperature": 0,
        "text": " In this case, probably the additional should override the AFIN.",
        "tokens": [
          50692,
          682,
          341,
          1389,
          11,
          1391,
          264,
          4497,
          820,
          42321,
          264,
          20389,
          1464,
          13,
          50852
        ]
      },
      {
        "avg_logprob": -0.17927530256368346,
        "compression_ratio": 1.6403508771929824,
        "end": 4771.28,
        "id": 1455,
        "no_speech_prob": 0.000016442481864942238,
        "seek": 476008,
        "start": 4769.84,
        "temperature": 0,
        "text": " So I'll look in additional first.",
        "tokens": [
          50852,
          407,
          286,
          603,
          574,
          294,
          4497,
          700,
          13,
          50924
        ]
      },
      {
        "avg_logprob": -0.17927530256368346,
        "compression_ratio": 1.6403508771929824,
        "end": 4771.92,
        "id": 1456,
        "no_speech_prob": 0.000016442481864942238,
        "seek": 476008,
        "start": 4771.28,
        "temperature": 0,
        "text": " Okay, great.",
        "tokens": [
          50924,
          1033,
          11,
          869,
          13,
          50956
        ]
      },
      {
        "avg_logprob": -0.17927530256368346,
        "compression_ratio": 1.6403508771929824,
        "end": 4773.2,
        "id": 1457,
        "no_speech_prob": 0.000016442481864942238,
        "seek": 476008,
        "start": 4771.92,
        "temperature": 0,
        "text": " So actually done.",
        "tokens": [
          50956,
          407,
          767,
          1096,
          13,
          51020
        ]
      },
      {
        "avg_logprob": -0.17927530256368346,
        "compression_ratio": 1.6403508771929824,
        "end": 4775.28,
        "id": 1458,
        "no_speech_prob": 0.000016442481864942238,
        "seek": 476008,
        "start": 4774.48,
        "temperature": 0,
        "text": " We did it.",
        "tokens": [
          51084,
          492,
          630,
          309,
          13,
          51124
        ]
      },
      {
        "avg_logprob": -0.17927530256368346,
        "compression_ratio": 1.6403508771929824,
        "end": 4775.76,
        "id": 1459,
        "no_speech_prob": 0.000016442481864942238,
        "seek": 476008,
        "start": 4775.28,
        "temperature": 0,
        "text": " Yay.",
        "tokens": [
          51124,
          13268,
          13,
          51148
        ]
      },
      {
        "avg_logprob": -0.17927530256368346,
        "compression_ratio": 1.6403508771929824,
        "end": 4777.36,
        "id": 1460,
        "no_speech_prob": 0.000016442481864942238,
        "seek": 476008,
        "start": 4775.76,
        "temperature": 0,
        "text": " But I guess I could in all.",
        "tokens": [
          51148,
          583,
          286,
          2041,
          286,
          727,
          294,
          439,
          13,
          51228
        ]
      },
      {
        "avg_logprob": -0.17927530256368346,
        "compression_ratio": 1.6403508771929824,
        "end": 4780.32,
        "id": 1461,
        "no_speech_prob": 0.000016442481864942238,
        "seek": 476008,
        "start": 4778.4,
        "temperature": 0,
        "text": " Let's look at that all route again.",
        "tokens": [
          51280,
          961,
          311,
          574,
          412,
          300,
          439,
          7955,
          797,
          13,
          51376
        ]
      },
      {
        "avg_logprob": -0.17927530256368346,
        "compression_ratio": 1.6403508771929824,
        "end": 4782.5599999999995,
        "id": 1462,
        "no_speech_prob": 0.000016442481864942238,
        "seek": 476008,
        "start": 4781.44,
        "temperature": 0,
        "text": " Let's here.",
        "tokens": [
          51432,
          961,
          311,
          510,
          13,
          51488
        ]
      },
      {
        "avg_logprob": -0.17927530256368346,
        "compression_ratio": 1.6403508771929824,
        "end": 4785.28,
        "id": 1463,
        "no_speech_prob": 0.000016442481864942238,
        "seek": 476008,
        "start": 4782.5599999999995,
        "temperature": 0,
        "text": " Let's actually do something kind of a little goofy.",
        "tokens": [
          51488,
          961,
          311,
          767,
          360,
          746,
          733,
          295,
          257,
          707,
          42995,
          13,
          51624
        ]
      },
      {
        "avg_logprob": -0.22264463901519777,
        "compression_ratio": 1.6379310344827587,
        "end": 4799.28,
        "id": 1464,
        "no_speech_prob": 0.0022872155532240868,
        "seek": 478528,
        "start": 4785.28,
        "temperature": 0,
        "text": " I'm going to do I'm going to say the data is additional is a words and AFIN is the AFIN list.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          360,
          286,
          478,
          516,
          281,
          584,
          264,
          1412,
          307,
          4497,
          307,
          257,
          2283,
          293,
          20389,
          1464,
          307,
          264,
          20389,
          1464,
          1329,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.22264463901519777,
        "compression_ratio": 1.6379310344827587,
        "end": 4808.16,
        "id": 1465,
        "no_speech_prob": 0.0022872155532240868,
        "seek": 478528,
        "start": 4800.16,
        "temperature": 0,
        "text": " So then so I'm changing the server when you ask for all to not just give you the words",
        "tokens": [
          51108,
          407,
          550,
          370,
          286,
          478,
          4473,
          264,
          7154,
          562,
          291,
          1029,
          337,
          439,
          281,
          406,
          445,
          976,
          291,
          264,
          2283,
          51508
        ]
      },
      {
        "avg_logprob": -0.22264463901519777,
        "compression_ratio": 1.6379310344827587,
        "end": 4809.679999999999,
        "id": 1466,
        "no_speech_prob": 0.0022872155532240868,
        "seek": 478528,
        "start": 4808.16,
        "temperature": 0,
        "text": " that are in the database, but look at both of them.",
        "tokens": [
          51508,
          300,
          366,
          294,
          264,
          8149,
          11,
          457,
          574,
          412,
          1293,
          295,
          552,
          13,
          51584
        ]
      },
      {
        "avg_logprob": -0.22264463901519777,
        "compression_ratio": 1.6379310344827587,
        "end": 4812.08,
        "id": 1467,
        "no_speech_prob": 0.0022872155532240868,
        "seek": 478528,
        "start": 4809.679999999999,
        "temperature": 0,
        "text": " So this is just changing the response of the server.",
        "tokens": [
          51584,
          407,
          341,
          307,
          445,
          4473,
          264,
          4134,
          295,
          264,
          7154,
          13,
          51704
        ]
      },
      {
        "avg_logprob": -0.27707034570199474,
        "compression_ratio": 1.7061611374407584,
        "end": 4816.88,
        "id": 1468,
        "no_speech_prob": 0.0025508941616863012,
        "seek": 481208,
        "start": 4812.48,
        "temperature": 0,
        "text": " And what I'm going to do here, if you go here now, I have to restart the server.",
        "tokens": [
          50384,
          400,
          437,
          286,
          478,
          516,
          281,
          360,
          510,
          11,
          498,
          291,
          352,
          510,
          586,
          11,
          286,
          362,
          281,
          21022,
          264,
          7154,
          13,
          50604
        ]
      },
      {
        "avg_logprob": -0.27707034570199474,
        "compression_ratio": 1.7061611374407584,
        "end": 4818.4,
        "id": 1469,
        "no_speech_prob": 0.0025508941616863012,
        "seek": 481208,
        "start": 4818.08,
        "temperature": 0,
        "text": " Where?",
        "tokens": [
          50664,
          2305,
          30,
          50680
        ]
      },
      {
        "avg_logprob": -0.27707034570199474,
        "compression_ratio": 1.7061611374407584,
        "end": 4820,
        "id": 1470,
        "no_speech_prob": 0.0025508941616863012,
        "seek": 481208,
        "start": 4818.4,
        "temperature": 0,
        "text": " Oops, sorry, everybody.",
        "tokens": [
          50680,
          21726,
          11,
          2597,
          11,
          2201,
          13,
          50760
        ]
      },
      {
        "avg_logprob": -0.27707034570199474,
        "compression_ratio": 1.7061611374407584,
        "end": 4824.08,
        "id": 1471,
        "no_speech_prob": 0.0025508941616863012,
        "seek": 481208,
        "start": 4820,
        "temperature": 0,
        "text": " I'm going to restart the server and I'm going to do this.",
        "tokens": [
          50760,
          286,
          478,
          516,
          281,
          21022,
          264,
          7154,
          293,
          286,
          478,
          516,
          281,
          360,
          341,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.27707034570199474,
        "compression_ratio": 1.7061611374407584,
        "end": 4831.44,
        "id": 1472,
        "no_speech_prob": 0.0025508941616863012,
        "seek": 481208,
        "start": 4825.12,
        "temperature": 0,
        "text": " And we can see now I have both the additional list and the AFIN list.",
        "tokens": [
          51016,
          400,
          321,
          393,
          536,
          586,
          286,
          362,
          1293,
          264,
          4497,
          1329,
          293,
          264,
          20389,
          1464,
          1329,
          13,
          51332
        ]
      },
      {
        "avg_logprob": -0.27707034570199474,
        "compression_ratio": 1.7061611374407584,
        "end": 4832.24,
        "id": 1473,
        "no_speech_prob": 0.0025508941616863012,
        "seek": 481208,
        "start": 4831.44,
        "temperature": 0,
        "text": " Wonderful.",
        "tokens": [
          51332,
          22768,
          13,
          51372
        ]
      },
      {
        "avg_logprob": -0.27707034570199474,
        "compression_ratio": 1.7061611374407584,
        "end": 4840,
        "id": 1474,
        "no_speech_prob": 0.0025508941616863012,
        "seek": 481208,
        "start": 4832.24,
        "temperature": 0,
        "text": " Okay, so now and but this probably broke this part because the way I was parsing,",
        "tokens": [
          51372,
          1033,
          11,
          370,
          586,
          293,
          457,
          341,
          1391,
          6902,
          341,
          644,
          570,
          264,
          636,
          286,
          390,
          21156,
          278,
          11,
          51760
        ]
      },
      {
        "avg_logprob": -0.27707034570199474,
        "compression_ratio": 1.7061611374407584,
        "end": 4841.2,
        "id": 1475,
        "no_speech_prob": 0.0025508941616863012,
        "seek": 481208,
        "start": 4840,
        "temperature": 0,
        "text": " I was using that all route.",
        "tokens": [
          51760,
          286,
          390,
          1228,
          300,
          439,
          7955,
          13,
          51820
        ]
      },
      {
        "avg_logprob": -0.148317715353217,
        "compression_ratio": 1.793103448275862,
        "end": 4842,
        "id": 1476,
        "no_speech_prob": 0.00012731026799883693,
        "seek": 484120,
        "start": 4841.2,
        "temperature": 0,
        "text": " But you know what?",
        "tokens": [
          50364,
          583,
          291,
          458,
          437,
          30,
          50404
        ]
      },
      {
        "avg_logprob": -0.148317715353217,
        "compression_ratio": 1.793103448275862,
        "end": 4843.92,
        "id": 1477,
        "no_speech_prob": 0.00012731026799883693,
        "seek": 484120,
        "start": 4842,
        "temperature": 0,
        "text": " I'm going to get rid of this drawing thing.",
        "tokens": [
          50404,
          286,
          478,
          516,
          281,
          483,
          3973,
          295,
          341,
          6316,
          551,
          13,
          50500
        ]
      },
      {
        "avg_logprob": -0.148317715353217,
        "compression_ratio": 1.793103448275862,
        "end": 4845.2,
        "id": 1478,
        "no_speech_prob": 0.00012731026799883693,
        "seek": 484120,
        "start": 4843.92,
        "temperature": 0,
        "text": " It's sort of unnecessary right now.",
        "tokens": [
          50500,
          467,
          311,
          1333,
          295,
          19350,
          558,
          586,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.148317715353217,
        "compression_ratio": 1.793103448275862,
        "end": 4848.24,
        "id": 1479,
        "no_speech_prob": 0.00012731026799883693,
        "seek": 484120,
        "start": 4845.2,
        "temperature": 0,
        "text": " I just want to have this word score interface.",
        "tokens": [
          50564,
          286,
          445,
          528,
          281,
          362,
          341,
          1349,
          6175,
          9226,
          13,
          50716
        ]
      },
      {
        "avg_logprob": -0.148317715353217,
        "compression_ratio": 1.793103448275862,
        "end": 4851.76,
        "id": 1480,
        "no_speech_prob": 0.00012731026799883693,
        "seek": 484120,
        "start": 4848.24,
        "temperature": 0,
        "text": " So let's go back to the client, which is here.",
        "tokens": [
          50716,
          407,
          718,
          311,
          352,
          646,
          281,
          264,
          6423,
          11,
          597,
          307,
          510,
          13,
          50892
        ]
      },
      {
        "avg_logprob": -0.148317715353217,
        "compression_ratio": 1.793103448275862,
        "end": 4859.12,
        "id": 1481,
        "no_speech_prob": 0.00012731026799883693,
        "seek": 484120,
        "start": 4851.76,
        "temperature": 0,
        "text": " And let's get rid of the draw data thing, which we don't need to do anymore",
        "tokens": [
          50892,
          400,
          718,
          311,
          483,
          3973,
          295,
          264,
          2642,
          1412,
          551,
          11,
          597,
          321,
          500,
          380,
          643,
          281,
          360,
          3602,
          51260
        ]
      },
      {
        "avg_logprob": -0.148317715353217,
        "compression_ratio": 1.793103448275862,
        "end": 4863.12,
        "id": 1482,
        "no_speech_prob": 0.00012731026799883693,
        "seek": 484120,
        "start": 4860.48,
        "temperature": 0,
        "text": " because we're going to do some different stuff here.",
        "tokens": [
          51328,
          570,
          321,
          434,
          516,
          281,
          360,
          512,
          819,
          1507,
          510,
          13,
          51460
        ]
      },
      {
        "avg_logprob": -0.148317715353217,
        "compression_ratio": 1.793103448275862,
        "end": 4868.4,
        "id": 1483,
        "no_speech_prob": 0.00012731026799883693,
        "seek": 484120,
        "start": 4864,
        "temperature": 0,
        "text": " So I just want to see that this I don't need draw data anymore.",
        "tokens": [
          51504,
          407,
          286,
          445,
          528,
          281,
          536,
          300,
          341,
          286,
          500,
          380,
          643,
          2642,
          1412,
          3602,
          13,
          51724
        ]
      },
      {
        "avg_logprob": -0.148317715353217,
        "compression_ratio": 1.793103448275862,
        "end": 4869.5199999999995,
        "id": 1484,
        "no_speech_prob": 0.00012731026799883693,
        "seek": 484120,
        "start": 4868.4,
        "temperature": 0,
        "text": " I want to see that this works.",
        "tokens": [
          51724,
          286,
          528,
          281,
          536,
          300,
          341,
          1985,
          13,
          51780
        ]
      },
      {
        "avg_logprob": -0.2321097113869407,
        "compression_ratio": 1.5918367346938775,
        "end": 4872.56,
        "id": 1485,
        "no_speech_prob": 0.0016743765445426106,
        "seek": 486952,
        "start": 4870.320000000001,
        "temperature": 0,
        "text": " So I want to see what's another word that I could add.",
        "tokens": [
          50404,
          407,
          286,
          528,
          281,
          536,
          437,
          311,
          1071,
          1349,
          300,
          286,
          727,
          909,
          13,
          50516
        ]
      },
      {
        "avg_logprob": -0.2321097113869407,
        "compression_ratio": 1.5918367346938775,
        "end": 4877.84,
        "id": 1486,
        "no_speech_prob": 0.0016743765445426106,
        "seek": 486952,
        "start": 4874.320000000001,
        "temperature": 0,
        "text": " Puppy and three hit submit.",
        "tokens": [
          50604,
          13605,
          7966,
          293,
          1045,
          2045,
          10315,
          13,
          50780
        ]
      },
      {
        "avg_logprob": -0.2321097113869407,
        "compression_ratio": 1.5918367346938775,
        "end": 4881.68,
        "id": 1487,
        "no_speech_prob": 0.0016743765445426106,
        "seek": 486952,
        "start": 4878.4800000000005,
        "temperature": 0,
        "text": " And we can see that that worked.",
        "tokens": [
          50812,
          400,
          321,
          393,
          536,
          300,
          300,
          2732,
          13,
          50972
        ]
      },
      {
        "avg_logprob": -0.2321097113869407,
        "compression_ratio": 1.5918367346938775,
        "end": 4882.240000000001,
        "id": 1488,
        "no_speech_prob": 0.0016743765445426106,
        "seek": 486952,
        "start": 4881.68,
        "temperature": 0,
        "text": " Success.",
        "tokens": [
          50972,
          23669,
          13,
          51000
        ]
      },
      {
        "avg_logprob": -0.2321097113869407,
        "compression_ratio": 1.5918367346938775,
        "end": 4885.280000000001,
        "id": 1489,
        "no_speech_prob": 0.0016743765445426106,
        "seek": 486952,
        "start": 4882.240000000001,
        "temperature": 0,
        "text": " Although I probably again should add something to this page that says,",
        "tokens": [
          51000,
          5780,
          286,
          1391,
          797,
          820,
          909,
          746,
          281,
          341,
          3028,
          300,
          1619,
          11,
          51152
        ]
      },
      {
        "avg_logprob": -0.2321097113869407,
        "compression_ratio": 1.5918367346938775,
        "end": 4887.120000000001,
        "id": 1490,
        "no_speech_prob": 0.0016743765445426106,
        "seek": 486952,
        "start": 4885.280000000001,
        "temperature": 0,
        "text": " thank you, I added that word to the list.",
        "tokens": [
          51152,
          1309,
          291,
          11,
          286,
          3869,
          300,
          1349,
          281,
          264,
          1329,
          13,
          51244
        ]
      },
      {
        "avg_logprob": -0.2321097113869407,
        "compression_ratio": 1.5918367346938775,
        "end": 4889.52,
        "id": 1491,
        "no_speech_prob": 0.0016743765445426106,
        "seek": 486952,
        "start": 4887.92,
        "temperature": 0,
        "text": " That's a great exercise for you.",
        "tokens": [
          51284,
          663,
          311,
          257,
          869,
          5380,
          337,
          291,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2321097113869407,
        "compression_ratio": 1.5918367346938775,
        "end": 4894.56,
        "id": 1492,
        "no_speech_prob": 0.0016743765445426106,
        "seek": 486952,
        "start": 4889.52,
        "temperature": 0,
        "text": " But we can just confirm now that if I go back to here under additional, puppy is there.",
        "tokens": [
          51364,
          583,
          321,
          393,
          445,
          9064,
          586,
          300,
          498,
          286,
          352,
          646,
          281,
          510,
          833,
          4497,
          11,
          18196,
          307,
          456,
          13,
          51616
        ]
      },
      {
        "avg_logprob": -0.2321097113869407,
        "compression_ratio": 1.5918367346938775,
        "end": 4896.240000000001,
        "id": 1493,
        "no_speech_prob": 0.0016743765445426106,
        "seek": 486952,
        "start": 4894.56,
        "temperature": 0,
        "text": " Okay, so everything is working.",
        "tokens": [
          51616,
          1033,
          11,
          370,
          1203,
          307,
          1364,
          13,
          51700
        ]
      },
      {
        "avg_logprob": -0.21579198837280272,
        "compression_ratio": 1.5816733067729083,
        "end": 4900.719999999999,
        "id": 1494,
        "no_speech_prob": 0.00035696954000741243,
        "seek": 489624,
        "start": 4896.24,
        "temperature": 0,
        "text": " But my API behind the scenes has access to both the full afin list",
        "tokens": [
          50364,
          583,
          452,
          9362,
          2261,
          264,
          8026,
          575,
          2105,
          281,
          1293,
          264,
          1577,
          257,
          5194,
          1329,
          50588
        ]
      },
      {
        "avg_logprob": -0.21579198837280272,
        "compression_ratio": 1.5816733067729083,
        "end": 4903.28,
        "id": 1495,
        "no_speech_prob": 0.00035696954000741243,
        "seek": 489624,
        "start": 4900.719999999999,
        "temperature": 0,
        "text": " and any additional words that have been added.",
        "tokens": [
          50588,
          293,
          604,
          4497,
          2283,
          300,
          362,
          668,
          3869,
          13,
          50716
        ]
      },
      {
        "avg_logprob": -0.21579198837280272,
        "compression_ratio": 1.5816733067729083,
        "end": 4905.44,
        "id": 1496,
        "no_speech_prob": 0.00035696954000741243,
        "seek": 489624,
        "start": 4903.28,
        "temperature": 0,
        "text": " Notice how things are a little bit different here.",
        "tokens": [
          50716,
          13428,
          577,
          721,
          366,
          257,
          707,
          857,
          819,
          510,
          13,
          50824
        ]
      },
      {
        "avg_logprob": -0.21579198837280272,
        "compression_ratio": 1.5816733067729083,
        "end": 4908.96,
        "id": 1497,
        "no_speech_prob": 0.00035696954000741243,
        "seek": 489624,
        "start": 4905.44,
        "temperature": 0,
        "text": " I probably should have been more thoughtful about fixing this up",
        "tokens": [
          50824,
          286,
          1391,
          820,
          362,
          668,
          544,
          21566,
          466,
          19442,
          341,
          493,
          51000
        ]
      },
      {
        "avg_logprob": -0.21579198837280272,
        "compression_ratio": 1.5816733067729083,
        "end": 4911.12,
        "id": 1498,
        "no_speech_prob": 0.00035696954000741243,
        "seek": 489624,
        "start": 4908.96,
        "temperature": 0,
        "text": " so that these are actually numbers and not strings.",
        "tokens": [
          51000,
          370,
          300,
          613,
          366,
          767,
          3547,
          293,
          406,
          13985,
          13,
          51108
        ]
      },
      {
        "avg_logprob": -0.21579198837280272,
        "compression_ratio": 1.5816733067729083,
        "end": 4912.48,
        "id": 1499,
        "no_speech_prob": 0.00035696954000741243,
        "seek": 489624,
        "start": 4911.12,
        "temperature": 0,
        "text": " But I can deal with that later.",
        "tokens": [
          51108,
          583,
          286,
          393,
          2028,
          365,
          300,
          1780,
          13,
          51176
        ]
      },
      {
        "avg_logprob": -0.21579198837280272,
        "compression_ratio": 1.5816733067729083,
        "end": 4921.5199999999995,
        "id": 1500,
        "no_speech_prob": 0.00035696954000741243,
        "seek": 489624,
        "start": 4913.28,
        "temperature": 0,
        "text": " So okay, now the thing we need to change now is how do we send a large body of text",
        "tokens": [
          51216,
          407,
          1392,
          11,
          586,
          264,
          551,
          321,
          643,
          281,
          1319,
          586,
          307,
          577,
          360,
          321,
          2845,
          257,
          2416,
          1772,
          295,
          2487,
          51628
        ]
      },
      {
        "avg_logprob": -0.231425295593918,
        "compression_ratio": 1.541871921182266,
        "end": 4926.8,
        "id": 1501,
        "no_speech_prob": 0.0022170005831867456,
        "seek": 492152,
        "start": 4922.080000000001,
        "temperature": 0,
        "text": " from the client to the server.",
        "tokens": [
          50392,
          490,
          264,
          6423,
          281,
          264,
          7154,
          13,
          50628
        ]
      },
      {
        "avg_logprob": -0.231425295593918,
        "compression_ratio": 1.541871921182266,
        "end": 4930.72,
        "id": 1502,
        "no_speech_prob": 0.0022170005831867456,
        "seek": 492152,
        "start": 4926.8,
        "temperature": 0,
        "text": " And so I'm going to come over here for a second to oh boy, this camera is off.",
        "tokens": [
          50628,
          400,
          370,
          286,
          478,
          516,
          281,
          808,
          670,
          510,
          337,
          257,
          1150,
          281,
          1954,
          3237,
          11,
          341,
          2799,
          307,
          766,
          13,
          50824
        ]
      },
      {
        "avg_logprob": -0.231425295593918,
        "compression_ratio": 1.541871921182266,
        "end": 4932,
        "id": 1503,
        "no_speech_prob": 0.0022170005831867456,
        "seek": 492152,
        "start": 4930.72,
        "temperature": 0,
        "text": " I'm going to come to the void.",
        "tokens": [
          50824,
          286,
          478,
          516,
          281,
          808,
          281,
          264,
          22009,
          13,
          50888
        ]
      },
      {
        "avg_logprob": -0.231425295593918,
        "compression_ratio": 1.541871921182266,
        "end": 4936.8,
        "id": 1504,
        "no_speech_prob": 0.0022170005831867456,
        "seek": 492152,
        "start": 4932.88,
        "temperature": 0,
        "text": " And I want to talk about the difference between a get and a post.",
        "tokens": [
          50932,
          400,
          286,
          528,
          281,
          751,
          466,
          264,
          2649,
          1296,
          257,
          483,
          293,
          257,
          2183,
          13,
          51128
        ]
      },
      {
        "avg_logprob": -0.231425295593918,
        "compression_ratio": 1.541871921182266,
        "end": 4947.360000000001,
        "id": 1505,
        "no_speech_prob": 0.0022170005831867456,
        "seek": 492152,
        "start": 4940.4800000000005,
        "temperature": 0,
        "text": " So HTTP, which stands for Hyper Text Transfer Protocol.",
        "tokens": [
          51312,
          407,
          33283,
          11,
          597,
          7382,
          337,
          29592,
          18643,
          35025,
          48753,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.231425295593918,
        "compression_ratio": 1.541871921182266,
        "end": 4948.240000000001,
        "id": 1506,
        "no_speech_prob": 0.0022170005831867456,
        "seek": 492152,
        "start": 4947.360000000001,
        "temperature": 0,
        "text": " I don't know if that's right.",
        "tokens": [
          51656,
          286,
          500,
          380,
          458,
          498,
          300,
          311,
          558,
          13,
          51700
        ]
      },
      {
        "avg_logprob": -0.231425295593918,
        "compression_ratio": 1.541871921182266,
        "end": 4948.96,
        "id": 1507,
        "no_speech_prob": 0.0022170005831867456,
        "seek": 492152,
        "start": 4948.240000000001,
        "temperature": 0,
        "text": " It's probably right.",
        "tokens": [
          51700,
          467,
          311,
          1391,
          558,
          13,
          51736
        ]
      },
      {
        "avg_logprob": -0.31392216232587705,
        "compression_ratio": 1.7657657657657657,
        "end": 4952.72,
        "id": 1508,
        "no_speech_prob": 0.00003426841431064531,
        "seek": 494896,
        "start": 4949.2,
        "temperature": 0,
        "text": " There is a request and response protocol.",
        "tokens": [
          50376,
          821,
          307,
          257,
          5308,
          293,
          4134,
          10336,
          13,
          50552
        ]
      },
      {
        "avg_logprob": -0.31392216232587705,
        "compression_ratio": 1.7657657657657657,
        "end": 4955.52,
        "id": 1509,
        "no_speech_prob": 0.00003426841431064531,
        "seek": 494896,
        "start": 4953.36,
        "temperature": 0,
        "text": " Hi, I'm a web browser.",
        "tokens": [
          50584,
          2421,
          11,
          286,
          478,
          257,
          3670,
          11185,
          13,
          50692
        ]
      },
      {
        "avg_logprob": -0.31392216232587705,
        "compression_ratio": 1.7657657657657657,
        "end": 4961.28,
        "id": 1510,
        "no_speech_prob": 0.00003426841431064531,
        "seek": 494896,
        "start": 4956.16,
        "temperature": 0,
        "text": " Could I please, I'm making a request, have some information about where I could get some",
        "tokens": [
          50724,
          7497,
          286,
          1767,
          11,
          286,
          478,
          1455,
          257,
          5308,
          11,
          362,
          512,
          1589,
          466,
          689,
          286,
          727,
          483,
          512,
          50980
        ]
      },
      {
        "avg_logprob": -0.31392216232587705,
        "compression_ratio": 1.7657657657657657,
        "end": 4962.8,
        "id": 1511,
        "no_speech_prob": 0.00003426841431064531,
        "seek": 494896,
        "start": 4961.28,
        "temperature": 0,
        "text": " nice apples this time of year?",
        "tokens": [
          50980,
          1481,
          16814,
          341,
          565,
          295,
          1064,
          30,
          51056
        ]
      },
      {
        "avg_logprob": -0.31392216232587705,
        "compression_ratio": 1.7657657657657657,
        "end": 4964.08,
        "id": 1512,
        "no_speech_prob": 0.00003426841431064531,
        "seek": 494896,
        "start": 4962.8,
        "temperature": 0,
        "text": " And maybe I would ask that to Google.",
        "tokens": [
          51056,
          400,
          1310,
          286,
          576,
          1029,
          300,
          281,
          3329,
          13,
          51120
        ]
      },
      {
        "avg_logprob": -0.31392216232587705,
        "compression_ratio": 1.7657657657657657,
        "end": 4967.44,
        "id": 1513,
        "no_speech_prob": 0.00003426841431064531,
        "seek": 494896,
        "start": 4964.08,
        "temperature": 0,
        "text": " And Google being the server would say, hey, here's a response.",
        "tokens": [
          51120,
          400,
          3329,
          885,
          264,
          7154,
          576,
          584,
          11,
          4177,
          11,
          510,
          311,
          257,
          4134,
          13,
          51288
        ]
      },
      {
        "avg_logprob": -0.31392216232587705,
        "compression_ratio": 1.7657657657657657,
        "end": 4969.04,
        "id": 1514,
        "no_speech_prob": 0.00003426841431064531,
        "seek": 494896,
        "start": 4967.44,
        "temperature": 0,
        "text": " Here's some information.",
        "tokens": [
          51288,
          1692,
          311,
          512,
          1589,
          13,
          51368
        ]
      },
      {
        "avg_logprob": -0.31392216232587705,
        "compression_ratio": 1.7657657657657657,
        "end": 4974.08,
        "id": 1515,
        "no_speech_prob": 0.00003426841431064531,
        "seek": 494896,
        "start": 4969.04,
        "temperature": 0,
        "text": " And the way that I can talk to that server in this request and response protocol,",
        "tokens": [
          51368,
          400,
          264,
          636,
          300,
          286,
          393,
          751,
          281,
          300,
          7154,
          294,
          341,
          5308,
          293,
          4134,
          10336,
          11,
          51620
        ]
      },
      {
        "avg_logprob": -0.2954684556132615,
        "compression_ratio": 1.7850467289719627,
        "end": 4982.4,
        "id": 1516,
        "no_speech_prob": 0.005384774412959814,
        "seek": 497408,
        "start": 4974.16,
        "temperature": 0,
        "text": " if we have server and we have client, is I can make a get request, which is like,",
        "tokens": [
          50368,
          498,
          321,
          362,
          7154,
          293,
          321,
          362,
          6423,
          11,
          307,
          286,
          393,
          652,
          257,
          483,
          5308,
          11,
          597,
          307,
          411,
          11,
          50780
        ]
      },
      {
        "avg_logprob": -0.2954684556132615,
        "compression_ratio": 1.7850467289719627,
        "end": 4984.8,
        "id": 1517,
        "no_speech_prob": 0.005384774412959814,
        "seek": 497408,
        "start": 4982.4,
        "temperature": 0,
        "text": " could you please give me some information back?",
        "tokens": [
          50780,
          727,
          291,
          1767,
          976,
          385,
          512,
          1589,
          646,
          30,
          50900
        ]
      },
      {
        "avg_logprob": -0.2954684556132615,
        "compression_ratio": 1.7850467289719627,
        "end": 4991.12,
        "id": 1518,
        "no_speech_prob": 0.005384774412959814,
        "seek": 497408,
        "start": 4985.84,
        "temperature": 0,
        "text": " Or I could make a post request, which is, would you please take this information and",
        "tokens": [
          50952,
          1610,
          286,
          727,
          652,
          257,
          2183,
          5308,
          11,
          597,
          307,
          11,
          576,
          291,
          1767,
          747,
          341,
          1589,
          293,
          51216
        ]
      },
      {
        "avg_logprob": -0.2954684556132615,
        "compression_ratio": 1.7850467289719627,
        "end": 4993.6,
        "id": 1519,
        "no_speech_prob": 0.005384774412959814,
        "seek": 497408,
        "start": 4991.12,
        "temperature": 0,
        "text": " save it onto your server or do something with it?",
        "tokens": [
          51216,
          3155,
          309,
          3911,
          428,
          7154,
          420,
          360,
          746,
          365,
          309,
          30,
          51340
        ]
      },
      {
        "avg_logprob": -0.2954684556132615,
        "compression_ratio": 1.7850467289719627,
        "end": 5000,
        "id": 1520,
        "no_speech_prob": 0.005384774412959814,
        "seek": 497408,
        "start": 4993.6,
        "temperature": 0,
        "text": " So if I'm logging in with my username and password, that would be something I would",
        "tokens": [
          51340,
          407,
          498,
          286,
          478,
          27991,
          294,
          365,
          452,
          30351,
          293,
          11524,
          11,
          300,
          576,
          312,
          746,
          286,
          576,
          51660
        ]
      },
      {
        "avg_logprob": -0.2954684556132615,
        "compression_ratio": 1.7850467289719627,
        "end": 5002.4,
        "id": 1521,
        "no_speech_prob": 0.005384774412959814,
        "seek": 497408,
        "start": 5000,
        "temperature": 0,
        "text": " want to send with a post request.",
        "tokens": [
          51660,
          528,
          281,
          2845,
          365,
          257,
          2183,
          5308,
          13,
          51780
        ]
      },
      {
        "avg_logprob": -0.3020765319351078,
        "compression_ratio": 1.6113207547169812,
        "end": 5007.92,
        "id": 1522,
        "no_speech_prob": 0.0018386414740234613,
        "seek": 500240,
        "start": 5002.48,
        "temperature": 0,
        "text": " If I want the results of a search, I might ask, use a get request to get the results",
        "tokens": [
          50368,
          759,
          286,
          528,
          264,
          3542,
          295,
          257,
          3164,
          11,
          286,
          1062,
          1029,
          11,
          764,
          257,
          483,
          5308,
          281,
          483,
          264,
          3542,
          50640
        ]
      },
      {
        "avg_logprob": -0.3020765319351078,
        "compression_ratio": 1.6113207547169812,
        "end": 5008.42,
        "id": 1523,
        "no_speech_prob": 0.0018386414740234613,
        "seek": 500240,
        "start": 5007.92,
        "temperature": 0,
        "text": " back.",
        "tokens": [
          50640,
          646,
          13,
          50665
        ]
      },
      {
        "avg_logprob": -0.3020765319351078,
        "compression_ratio": 1.6113207547169812,
        "end": 5009.839999999999,
        "id": 1524,
        "no_speech_prob": 0.0018386414740234613,
        "seek": 500240,
        "start": 5009.12,
        "temperature": 0,
        "text": " Here's the thing.",
        "tokens": [
          50700,
          1692,
          311,
          264,
          551,
          13,
          50736
        ]
      },
      {
        "avg_logprob": -0.3020765319351078,
        "compression_ratio": 1.6113207547169812,
        "end": 5016.08,
        "id": 1525,
        "no_speech_prob": 0.0018386414740234613,
        "seek": 500240,
        "start": 5009.839999999999,
        "temperature": 0,
        "text": " Even if, even though this is how this protocol is designed and how it works, you'll notice",
        "tokens": [
          50736,
          2754,
          498,
          11,
          754,
          1673,
          341,
          307,
          577,
          341,
          10336,
          307,
          4761,
          293,
          577,
          309,
          1985,
          11,
          291,
          603,
          3449,
          51048
        ]
      },
      {
        "avg_logprob": -0.3020765319351078,
        "compression_ratio": 1.6113207547169812,
        "end": 5018.24,
        "id": 1526,
        "no_speech_prob": 0.0018386414740234613,
        "seek": 500240,
        "start": 5016.08,
        "temperature": 0,
        "text": " something in our program a little bit strange.",
        "tokens": [
          51048,
          746,
          294,
          527,
          1461,
          257,
          707,
          857,
          5861,
          13,
          51156
        ]
      },
      {
        "avg_logprob": -0.3020765319351078,
        "compression_ratio": 1.6113207547169812,
        "end": 5023.839999999999,
        "id": 1527,
        "no_speech_prob": 0.0018386414740234613,
        "seek": 500240,
        "start": 5019.679999999999,
        "temperature": 0,
        "text": " So if I go back to the code for a second and I look in the server, I can say, well, where",
        "tokens": [
          51228,
          407,
          498,
          286,
          352,
          646,
          281,
          264,
          3089,
          337,
          257,
          1150,
          293,
          286,
          574,
          294,
          264,
          7154,
          11,
          286,
          393,
          584,
          11,
          731,
          11,
          689,
          51436
        ]
      },
      {
        "avg_logprob": -0.3020765319351078,
        "compression_ratio": 1.6113207547169812,
        "end": 5025.12,
        "id": 1528,
        "no_speech_prob": 0.0018386414740234613,
        "seek": 500240,
        "start": 5023.839999999999,
        "temperature": 0,
        "text": " are these happening?",
        "tokens": [
          51436,
          366,
          613,
          2737,
          30,
          51500
        ]
      },
      {
        "avg_logprob": -0.3020765319351078,
        "compression_ratio": 1.6113207547169812,
        "end": 5027.2,
        "id": 1529,
        "no_speech_prob": 0.0018386414740234613,
        "seek": 500240,
        "start": 5025.12,
        "temperature": 0,
        "text": " This is a get, oh, I'm in the wrong place.",
        "tokens": [
          51500,
          639,
          307,
          257,
          483,
          11,
          1954,
          11,
          286,
          478,
          294,
          264,
          2085,
          1081,
          13,
          51604
        ]
      },
      {
        "avg_logprob": -0.3020765319351078,
        "compression_ratio": 1.6113207547169812,
        "end": 5029.36,
        "id": 1530,
        "no_speech_prob": 0.0018386414740234613,
        "seek": 500240,
        "start": 5027.2,
        "temperature": 0,
        "text": " If I go, we do that again.",
        "tokens": [
          51604,
          759,
          286,
          352,
          11,
          321,
          360,
          300,
          797,
          13,
          51712
        ]
      },
      {
        "avg_logprob": -0.3023988499360926,
        "compression_ratio": 1.7366071428571428,
        "end": 5035.599999999999,
        "id": 1531,
        "no_speech_prob": 0.0033244204241782427,
        "seek": 502936,
        "start": 5030,
        "temperature": 0,
        "text": " If I go back to the code for a second, you might ask, where are these happening?",
        "tokens": [
          50396,
          759,
          286,
          352,
          646,
          281,
          264,
          3089,
          337,
          257,
          1150,
          11,
          291,
          1062,
          1029,
          11,
          689,
          366,
          613,
          2737,
          30,
          50676
        ]
      },
      {
        "avg_logprob": -0.3023988499360926,
        "compression_ratio": 1.7366071428571428,
        "end": 5042.719999999999,
        "id": 1532,
        "no_speech_prob": 0.0033244204241782427,
        "seek": 502936,
        "start": 5035.599999999999,
        "temperature": 0,
        "text": " Well, right here, when I set up a route, I'm actually saying, this is handling a get request.",
        "tokens": [
          50676,
          1042,
          11,
          558,
          510,
          11,
          562,
          286,
          992,
          493,
          257,
          7955,
          11,
          286,
          478,
          767,
          1566,
          11,
          341,
          307,
          13175,
          257,
          483,
          5308,
          13,
          51032
        ]
      },
      {
        "avg_logprob": -0.3023988499360926,
        "compression_ratio": 1.7366071428571428,
        "end": 5050.16,
        "id": 1533,
        "no_speech_prob": 0.0033244204241782427,
        "seek": 502936,
        "start": 5042.719999999999,
        "temperature": 0,
        "text": " If the browser asks with a get request for slash all, send this information back as the",
        "tokens": [
          51032,
          759,
          264,
          11185,
          8962,
          365,
          257,
          483,
          5308,
          337,
          17330,
          439,
          11,
          2845,
          341,
          1589,
          646,
          382,
          264,
          51404
        ]
      },
      {
        "avg_logprob": -0.3023988499360926,
        "compression_ratio": 1.7366071428571428,
        "end": 5050.719999999999,
        "id": 1534,
        "no_speech_prob": 0.0033244204241782427,
        "seek": 502936,
        "start": 5050.16,
        "temperature": 0,
        "text": " response.",
        "tokens": [
          51404,
          4134,
          13,
          51432
        ]
      },
      {
        "avg_logprob": -0.3023988499360926,
        "compression_ratio": 1.7366071428571428,
        "end": 5054.639999999999,
        "id": 1535,
        "no_speech_prob": 0.0033244204241782427,
        "seek": 502936,
        "start": 5050.719999999999,
        "temperature": 0,
        "text": " Information that comes with the request is in this variable.",
        "tokens": [
          51432,
          15357,
          300,
          1487,
          365,
          264,
          5308,
          307,
          294,
          341,
          7006,
          13,
          51628
        ]
      },
      {
        "avg_logprob": -0.3023988499360926,
        "compression_ratio": 1.7366071428571428,
        "end": 5057.36,
        "id": 1536,
        "no_speech_prob": 0.0033244204241782427,
        "seek": 502936,
        "start": 5054.639999999999,
        "temperature": 0,
        "text": " Stuff that I want to do to respond is in this variable.",
        "tokens": [
          51628,
          31347,
          300,
          286,
          528,
          281,
          360,
          281,
          4196,
          307,
          294,
          341,
          7006,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.4251665788538316,
        "compression_ratio": 1.7207547169811321,
        "end": 5059.44,
        "id": 1537,
        "no_speech_prob": 0.0045383828692138195,
        "seek": 505736,
        "start": 5057.44,
        "temperature": 0,
        "text": " This is a get request, and it makes sense.",
        "tokens": [
          50368,
          639,
          307,
          257,
          483,
          5308,
          11,
          293,
          309,
          1669,
          2020,
          13,
          50468
        ]
      },
      {
        "avg_logprob": -0.4251665788538316,
        "compression_ratio": 1.7207547169811321,
        "end": 5061.92,
        "id": 1538,
        "no_speech_prob": 0.0045383828692138195,
        "seek": 505736,
        "start": 5059.44,
        "temperature": 0,
        "text": " I would like all of the data in the database, please.",
        "tokens": [
          50468,
          286,
          576,
          411,
          439,
          295,
          264,
          1412,
          294,
          264,
          8149,
          11,
          1767,
          13,
          50592
        ]
      },
      {
        "avg_logprob": -0.4251665788538316,
        "compression_ratio": 1.7207547169811321,
        "end": 5062.719999999999,
        "id": 1539,
        "no_speech_prob": 0.0045383828692138195,
        "seek": 505736,
        "start": 5061.92,
        "temperature": 0,
        "text": " Could I please have that?",
        "tokens": [
          50592,
          7497,
          286,
          1767,
          362,
          300,
          30,
          50632
        ]
      },
      {
        "avg_logprob": -0.4251665788538316,
        "compression_ratio": 1.7207547169811321,
        "end": 5063.28,
        "id": 1540,
        "no_speech_prob": 0.0045383828692138195,
        "seek": 505736,
        "start": 5062.719999999999,
        "temperature": 0,
        "text": " Thank you.",
        "tokens": [
          50632,
          1044,
          291,
          13,
          50660
        ]
      },
      {
        "avg_logprob": -0.4251665788538316,
        "compression_ratio": 1.7207547169811321,
        "end": 5065.679999999999,
        "id": 1541,
        "no_speech_prob": 0.0045383828692138195,
        "seek": 505736,
        "start": 5063.28,
        "temperature": 0,
        "text": " I really wish it was this, get please.",
        "tokens": [
          50660,
          286,
          534,
          3172,
          309,
          390,
          341,
          11,
          483,
          1767,
          13,
          50780
        ]
      },
      {
        "avg_logprob": -0.4251665788538316,
        "compression_ratio": 1.7207547169811321,
        "end": 5067.92,
        "id": 1542,
        "no_speech_prob": 0.0045383828692138195,
        "seek": 505736,
        "start": 5066.639999999999,
        "temperature": 0,
        "text": " But it's just get.",
        "tokens": [
          50828,
          583,
          309,
          311,
          445,
          483,
          13,
          50892
        ]
      },
      {
        "avg_logprob": -0.4251665788538316,
        "compression_ratio": 1.7207547169811321,
        "end": 5069.759999999999,
        "id": 1543,
        "no_speech_prob": 0.0045383828692138195,
        "seek": 505736,
        "start": 5067.92,
        "temperature": 0,
        "text": " I guess there's no need for politeness between computers.",
        "tokens": [
          50892,
          286,
          2041,
          456,
          311,
          572,
          643,
          337,
          2453,
          15264,
          1296,
          10807,
          13,
          50984
        ]
      },
      {
        "avg_logprob": -0.4251665788538316,
        "compression_ratio": 1.7207547169811321,
        "end": 5074,
        "id": 1544,
        "no_speech_prob": 0.0045383828692138195,
        "seek": 505736,
        "start": 5070.88,
        "temperature": 0,
        "text": " Kindness, there's something that needs to be said for kindness between computers, though,",
        "tokens": [
          51040,
          9242,
          1287,
          11,
          456,
          311,
          746,
          300,
          2203,
          281,
          312,
          848,
          337,
          18171,
          1296,
          10807,
          11,
          1673,
          11,
          51196
        ]
      },
      {
        "avg_logprob": -0.4251665788538316,
        "compression_ratio": 1.7207547169811321,
        "end": 5074.639999999999,
        "id": 1545,
        "no_speech_prob": 0.0045383828692138195,
        "seek": 505736,
        "start": 5074,
        "temperature": 0,
        "text": " and people.",
        "tokens": [
          51196,
          293,
          561,
          13,
          51228
        ]
      },
      {
        "avg_logprob": -0.4251665788538316,
        "compression_ratio": 1.7207547169811321,
        "end": 5076.4,
        "id": 1546,
        "no_speech_prob": 0.0045383828692138195,
        "seek": 505736,
        "start": 5074.639999999999,
        "temperature": 0,
        "text": " Anyway, I'm off track here.",
        "tokens": [
          51228,
          5684,
          11,
          286,
          478,
          766,
          2837,
          510,
          13,
          51316
        ]
      },
      {
        "avg_logprob": -0.4251665788538316,
        "compression_ratio": 1.7207547169811321,
        "end": 5077.679999999999,
        "id": 1547,
        "no_speech_prob": 0.0045383828692138195,
        "seek": 505736,
        "start": 5076.4,
        "temperature": 0,
        "text": " But you'll notice something.",
        "tokens": [
          51316,
          583,
          291,
          603,
          3449,
          746,
          13,
          51380
        ]
      },
      {
        "avg_logprob": -0.4251665788538316,
        "compression_ratio": 1.7207547169811321,
        "end": 5080.24,
        "id": 1548,
        "no_speech_prob": 0.0045383828692138195,
        "seek": 505736,
        "start": 5077.679999999999,
        "temperature": 0,
        "text": " This is also a get request.",
        "tokens": [
          51380,
          639,
          307,
          611,
          257,
          483,
          5308,
          13,
          51508
        ]
      },
      {
        "avg_logprob": -0.4251665788538316,
        "compression_ratio": 1.7207547169811321,
        "end": 5084,
        "id": 1549,
        "no_speech_prob": 0.0045383828692138195,
        "seek": 505736,
        "start": 5082,
        "temperature": 0,
        "text": " Get add word score.",
        "tokens": [
          51596,
          3240,
          909,
          1349,
          6175,
          13,
          51696
        ]
      },
      {
        "avg_logprob": -0.1621758033489359,
        "compression_ratio": 1.7627118644067796,
        "end": 5086.48,
        "id": 1550,
        "no_speech_prob": 0.0007208365714177489,
        "seek": 508400,
        "start": 5084.64,
        "temperature": 0,
        "text": " Get add word score.",
        "tokens": [
          50396,
          3240,
          909,
          1349,
          6175,
          13,
          50488
        ]
      },
      {
        "avg_logprob": -0.1621758033489359,
        "compression_ratio": 1.7627118644067796,
        "end": 5092.8,
        "id": 1551,
        "no_speech_prob": 0.0007208365714177489,
        "seek": 508400,
        "start": 5087.52,
        "temperature": 0,
        "text": " Now, it makes sense that you would have parameters for a get request like search.",
        "tokens": [
          50540,
          823,
          11,
          309,
          1669,
          2020,
          300,
          291,
          576,
          362,
          9834,
          337,
          257,
          483,
          5308,
          411,
          3164,
          13,
          50804
        ]
      },
      {
        "avg_logprob": -0.1621758033489359,
        "compression_ratio": 1.7627118644067796,
        "end": 5094.08,
        "id": 1552,
        "no_speech_prob": 0.0007208365714177489,
        "seek": 508400,
        "start": 5092.8,
        "temperature": 0,
        "text": " So this is a get request.",
        "tokens": [
          50804,
          407,
          341,
          307,
          257,
          483,
          5308,
          13,
          50868
        ]
      },
      {
        "avg_logprob": -0.1621758033489359,
        "compression_ratio": 1.7627118644067796,
        "end": 5095.04,
        "id": 1553,
        "no_speech_prob": 0.0007208365714177489,
        "seek": 508400,
        "start": 5094.64,
        "temperature": 0,
        "text": " Search.",
        "tokens": [
          50896,
          17180,
          13,
          50916
        ]
      },
      {
        "avg_logprob": -0.1621758033489359,
        "compression_ratio": 1.7627118644067796,
        "end": 5097.84,
        "id": 1554,
        "no_speech_prob": 0.0007208365714177489,
        "seek": 508400,
        "start": 5095.04,
        "temperature": 0,
        "text": " Do you have the word kitten in your database?",
        "tokens": [
          50916,
          1144,
          291,
          362,
          264,
          1349,
          39696,
          294,
          428,
          8149,
          30,
          51056
        ]
      },
      {
        "avg_logprob": -0.1621758033489359,
        "compression_ratio": 1.7627118644067796,
        "end": 5100.08,
        "id": 1555,
        "no_speech_prob": 0.0007208365714177489,
        "seek": 508400,
        "start": 5097.84,
        "temperature": 0,
        "text": " If so, could you please tell me its score?",
        "tokens": [
          51056,
          759,
          370,
          11,
          727,
          291,
          1767,
          980,
          385,
          1080,
          6175,
          30,
          51168
        ]
      },
      {
        "avg_logprob": -0.1621758033489359,
        "compression_ratio": 1.7627118644067796,
        "end": 5101.36,
        "id": 1556,
        "no_speech_prob": 0.0007208365714177489,
        "seek": 508400,
        "start": 5100.08,
        "temperature": 0,
        "text": " That's what's happening here.",
        "tokens": [
          51168,
          663,
          311,
          437,
          311,
          2737,
          510,
          13,
          51232
        ]
      },
      {
        "avg_logprob": -0.1621758033489359,
        "compression_ratio": 1.7627118644067796,
        "end": 5107.04,
        "id": 1557,
        "no_speech_prob": 0.0007208365714177489,
        "seek": 508400,
        "start": 5102.8,
        "temperature": 0,
        "text": " But in this particular route, this is a get request.",
        "tokens": [
          51304,
          583,
          294,
          341,
          1729,
          7955,
          11,
          341,
          307,
          257,
          483,
          5308,
          13,
          51516
        ]
      },
      {
        "avg_logprob": -0.1621758033489359,
        "compression_ratio": 1.7627118644067796,
        "end": 5111.76,
        "id": 1558,
        "no_speech_prob": 0.0007208365714177489,
        "seek": 508400,
        "start": 5107.04,
        "temperature": 0,
        "text": " And my get request is saying, here are this word and this score.",
        "tokens": [
          51516,
          400,
          452,
          483,
          5308,
          307,
          1566,
          11,
          510,
          366,
          341,
          1349,
          293,
          341,
          6175,
          13,
          51752
        ]
      },
      {
        "avg_logprob": -0.1621758033489359,
        "compression_ratio": 1.7627118644067796,
        "end": 5113.68,
        "id": 1559,
        "no_speech_prob": 0.0007208365714177489,
        "seek": 508400,
        "start": 5111.76,
        "temperature": 0,
        "text": " Will you please add those to your database?",
        "tokens": [
          51752,
          3099,
          291,
          1767,
          909,
          729,
          281,
          428,
          8149,
          30,
          51848
        ]
      },
      {
        "avg_logprob": -0.1954421333644701,
        "compression_ratio": 1.6627450980392158,
        "end": 5118.32,
        "id": 1560,
        "no_speech_prob": 0.000027535670596989803,
        "seek": 511400,
        "start": 5114.08,
        "temperature": 0,
        "text": " And according to my discussion over here, that should really be a post, right?",
        "tokens": [
          50368,
          400,
          4650,
          281,
          452,
          5017,
          670,
          510,
          11,
          300,
          820,
          534,
          312,
          257,
          2183,
          11,
          558,
          30,
          50580
        ]
      },
      {
        "avg_logprob": -0.1954421333644701,
        "compression_ratio": 1.6627450980392158,
        "end": 5123.12,
        "id": 1561,
        "no_speech_prob": 0.000027535670596989803,
        "seek": 511400,
        "start": 5118.32,
        "temperature": 0,
        "text": " If you're sending data to the server for the server to save, that's really a post and not a get.",
        "tokens": [
          50580,
          759,
          291,
          434,
          7750,
          1412,
          281,
          264,
          7154,
          337,
          264,
          7154,
          281,
          3155,
          11,
          300,
          311,
          534,
          257,
          2183,
          293,
          406,
          257,
          483,
          13,
          50820
        ]
      },
      {
        "avg_logprob": -0.1954421333644701,
        "compression_ratio": 1.6627450980392158,
        "end": 5129.92,
        "id": 1562,
        "no_speech_prob": 0.000027535670596989803,
        "seek": 511400,
        "start": 5123.68,
        "temperature": 0,
        "text": " The thing is, though, it's just so darn convenient to use a get.",
        "tokens": [
          50848,
          440,
          551,
          307,
          11,
          1673,
          11,
          309,
          311,
          445,
          370,
          29063,
          10851,
          281,
          764,
          257,
          483,
          13,
          51160
        ]
      },
      {
        "avg_logprob": -0.1954421333644701,
        "compression_ratio": 1.6627450980392158,
        "end": 5131.12,
        "id": 1563,
        "no_speech_prob": 0.000027535670596989803,
        "seek": 511400,
        "start": 5129.92,
        "temperature": 0,
        "text": " Why is it so convenient?",
        "tokens": [
          51160,
          1545,
          307,
          309,
          370,
          10851,
          30,
          51220
        ]
      },
      {
        "avg_logprob": -0.1954421333644701,
        "compression_ratio": 1.6627450980392158,
        "end": 5133.84,
        "id": 1564,
        "no_speech_prob": 0.000027535670596989803,
        "seek": 511400,
        "start": 5131.12,
        "temperature": 0,
        "text": " Because that's what the browser does natively on its own.",
        "tokens": [
          51220,
          1436,
          300,
          311,
          437,
          264,
          11185,
          775,
          8470,
          356,
          322,
          1080,
          1065,
          13,
          51356
        ]
      },
      {
        "avg_logprob": -0.1954421333644701,
        "compression_ratio": 1.6627450980392158,
        "end": 5134.88,
        "id": 1565,
        "no_speech_prob": 0.000027535670596989803,
        "seek": 511400,
        "start": 5133.84,
        "temperature": 0,
        "text": " I can actually now send.",
        "tokens": [
          51356,
          286,
          393,
          767,
          586,
          2845,
          13,
          51408
        ]
      },
      {
        "avg_logprob": -0.1954421333644701,
        "compression_ratio": 1.6627450980392158,
        "end": 5142.24,
        "id": 1566,
        "no_speech_prob": 0.000027535670596989803,
        "seek": 511400,
        "start": 5134.88,
        "temperature": 0,
        "text": " I can actually just make a get request by saying localhost 3000 add yellow,",
        "tokens": [
          51408,
          286,
          393,
          767,
          445,
          652,
          257,
          483,
          5308,
          538,
          1566,
          2654,
          6037,
          20984,
          909,
          5566,
          11,
          51776
        ]
      },
      {
        "avg_logprob": -0.18225000394101173,
        "compression_ratio": 1.8523489932885906,
        "end": 5144.5599999999995,
        "id": 1567,
        "no_speech_prob": 0.00031999731436371803,
        "seek": 514224,
        "start": 5142.24,
        "temperature": 0,
        "text": " which is maybe a neutral color or slightly positive.",
        "tokens": [
          50364,
          597,
          307,
          1310,
          257,
          10598,
          2017,
          420,
          4748,
          3353,
          13,
          50480
        ]
      },
      {
        "avg_logprob": -0.18225000394101173,
        "compression_ratio": 1.8523489932885906,
        "end": 5147.2,
        "id": 1568,
        "no_speech_prob": 0.00031999731436371803,
        "seek": 514224,
        "start": 5145.2,
        "temperature": 0,
        "text": " So this is me now making a get request.",
        "tokens": [
          50512,
          407,
          341,
          307,
          385,
          586,
          1455,
          257,
          483,
          5308,
          13,
          50612
        ]
      },
      {
        "avg_logprob": -0.18225000394101173,
        "compression_ratio": 1.8523489932885906,
        "end": 5148.4,
        "id": 1569,
        "no_speech_prob": 0.00031999731436371803,
        "seek": 514224,
        "start": 5147.2,
        "temperature": 0,
        "text": " That get request is done.",
        "tokens": [
          50612,
          663,
          483,
          5308,
          307,
          1096,
          13,
          50672
        ]
      },
      {
        "avg_logprob": -0.18225000394101173,
        "compression_ratio": 1.8523489932885906,
        "end": 5149.44,
        "id": 1570,
        "no_speech_prob": 0.00031999731436371803,
        "seek": 514224,
        "start": 5148.4,
        "temperature": 0,
        "text": " It saved it to the database.",
        "tokens": [
          50672,
          467,
          6624,
          309,
          281,
          264,
          8149,
          13,
          50724
        ]
      },
      {
        "avg_logprob": -0.18225000394101173,
        "compression_ratio": 1.8523489932885906,
        "end": 5155.76,
        "id": 1571,
        "no_speech_prob": 0.00031999731436371803,
        "seek": 514224,
        "start": 5149.44,
        "temperature": 0,
        "text": " I can use the fact that I can add parameters to a get request through the route or a query string.",
        "tokens": [
          50724,
          286,
          393,
          764,
          264,
          1186,
          300,
          286,
          393,
          909,
          9834,
          281,
          257,
          483,
          5308,
          807,
          264,
          7955,
          420,
          257,
          14581,
          6798,
          13,
          51040
        ]
      },
      {
        "avg_logprob": -0.18225000394101173,
        "compression_ratio": 1.8523489932885906,
        "end": 5159.12,
        "id": 1572,
        "no_speech_prob": 0.00031999731436371803,
        "seek": 514224,
        "start": 5155.76,
        "temperature": 0,
        "text": " There are lots of ways to do it to actually have the server save,",
        "tokens": [
          51040,
          821,
          366,
          3195,
          295,
          2098,
          281,
          360,
          309,
          281,
          767,
          362,
          264,
          7154,
          3155,
          11,
          51208
        ]
      },
      {
        "avg_logprob": -0.18225000394101173,
        "compression_ratio": 1.8523489932885906,
        "end": 5161.76,
        "id": 1573,
        "no_speech_prob": 0.00031999731436371803,
        "seek": 514224,
        "start": 5159.12,
        "temperature": 0,
        "text": " to send stuff to the server for it to do stuff with as well.",
        "tokens": [
          51208,
          281,
          2845,
          1507,
          281,
          264,
          7154,
          337,
          309,
          281,
          360,
          1507,
          365,
          382,
          731,
          13,
          51340
        ]
      },
      {
        "avg_logprob": -0.18225000394101173,
        "compression_ratio": 1.8523489932885906,
        "end": 5163.84,
        "id": 1574,
        "no_speech_prob": 0.00031999731436371803,
        "seek": 514224,
        "start": 5161.76,
        "temperature": 0,
        "text": " And because it's just like a little bit of data,",
        "tokens": [
          51340,
          400,
          570,
          309,
          311,
          445,
          411,
          257,
          707,
          857,
          295,
          1412,
          11,
          51444
        ]
      },
      {
        "avg_logprob": -0.18225000394101173,
        "compression_ratio": 1.8523489932885906,
        "end": 5166.32,
        "id": 1575,
        "no_speech_prob": 0.00031999731436371803,
        "seek": 514224,
        "start": 5163.84,
        "temperature": 0,
        "text": " it's just so easy to do it in the route with a get request.",
        "tokens": [
          51444,
          309,
          311,
          445,
          370,
          1858,
          281,
          360,
          309,
          294,
          264,
          7955,
          365,
          257,
          483,
          5308,
          13,
          51568
        ]
      },
      {
        "avg_logprob": -0.18225000394101173,
        "compression_ratio": 1.8523489932885906,
        "end": 5167.28,
        "id": 1576,
        "no_speech_prob": 0.00031999731436371803,
        "seek": 514224,
        "start": 5166.32,
        "temperature": 0,
        "text": " Why not?",
        "tokens": [
          51568,
          1545,
          406,
          30,
          51616
        ]
      },
      {
        "avg_logprob": -0.18225000394101173,
        "compression_ratio": 1.8523489932885906,
        "end": 5171.84,
        "id": 1577,
        "no_speech_prob": 0.00031999731436371803,
        "seek": 514224,
        "start": 5167.28,
        "temperature": 0,
        "text": " But there are times where this get request isn't sufficient.",
        "tokens": [
          51616,
          583,
          456,
          366,
          1413,
          689,
          341,
          483,
          5308,
          1943,
          380,
          11563,
          13,
          51844
        ]
      },
      {
        "avg_logprob": -0.19286476864534266,
        "compression_ratio": 1.7414965986394557,
        "end": 5174.32,
        "id": 1578,
        "no_speech_prob": 0.00004198579699732363,
        "seek": 517224,
        "start": 5172.32,
        "temperature": 0,
        "text": " And you really need to use a post.",
        "tokens": [
          50368,
          400,
          291,
          534,
          643,
          281,
          764,
          257,
          2183,
          13,
          50468
        ]
      },
      {
        "avg_logprob": -0.19286476864534266,
        "compression_ratio": 1.7414965986394557,
        "end": 5177.12,
        "id": 1579,
        "no_speech_prob": 0.00004198579699732363,
        "seek": 517224,
        "start": 5174.32,
        "temperature": 0,
        "text": " Well, one is like username and password.",
        "tokens": [
          50468,
          1042,
          11,
          472,
          307,
          411,
          30351,
          293,
          11524,
          13,
          50608
        ]
      },
      {
        "avg_logprob": -0.19286476864534266,
        "compression_ratio": 1.7414965986394557,
        "end": 5182.8,
        "id": 1580,
        "no_speech_prob": 0.00004198579699732363,
        "seek": 517224,
        "start": 5177.12,
        "temperature": 0,
        "text": " So if security matters, you don't want to have the username and password just in the URL path",
        "tokens": [
          50608,
          407,
          498,
          3825,
          7001,
          11,
          291,
          500,
          380,
          528,
          281,
          362,
          264,
          30351,
          293,
          11524,
          445,
          294,
          264,
          12905,
          3100,
          50892
        ]
      },
      {
        "avg_logprob": -0.19286476864534266,
        "compression_ratio": 1.7414965986394557,
        "end": 5186.719999999999,
        "id": 1581,
        "no_speech_prob": 0.00004198579699732363,
        "seek": 517224,
        "start": 5182.8,
        "temperature": 0,
        "text": " as part of a get request that anybody could potentially hack and get access to.",
        "tokens": [
          50892,
          382,
          644,
          295,
          257,
          483,
          5308,
          300,
          4472,
          727,
          7263,
          10339,
          293,
          483,
          2105,
          281,
          13,
          51088
        ]
      },
      {
        "avg_logprob": -0.19286476864534266,
        "compression_ratio": 1.7414965986394557,
        "end": 5190,
        "id": 1582,
        "no_speech_prob": 0.00004198579699732363,
        "seek": 517224,
        "start": 5186.719999999999,
        "temperature": 0,
        "text": " So this is really where for hidden data, it really needs to be a post.",
        "tokens": [
          51088,
          407,
          341,
          307,
          534,
          689,
          337,
          7633,
          1412,
          11,
          309,
          534,
          2203,
          281,
          312,
          257,
          2183,
          13,
          51252
        ]
      },
      {
        "avg_logprob": -0.19286476864534266,
        "compression_ratio": 1.7414965986394557,
        "end": 5192.32,
        "id": 1583,
        "no_speech_prob": 0.00004198579699732363,
        "seek": 517224,
        "start": 5190.88,
        "temperature": 0,
        "text": " The other thing is like media.",
        "tokens": [
          51296,
          440,
          661,
          551,
          307,
          411,
          3021,
          13,
          51368
        ]
      },
      {
        "avg_logprob": -0.19286476864534266,
        "compression_ratio": 1.7414965986394557,
        "end": 5196.8,
        "id": 1584,
        "no_speech_prob": 0.00004198579699732363,
        "seek": 517224,
        "start": 5192.96,
        "temperature": 0,
        "text": " If you want to upload an image to a server or upload a sound file,",
        "tokens": [
          51400,
          759,
          291,
          528,
          281,
          6580,
          364,
          3256,
          281,
          257,
          7154,
          420,
          6580,
          257,
          1626,
          3991,
          11,
          51592
        ]
      },
      {
        "avg_logprob": -0.19286476864534266,
        "compression_ratio": 1.7414965986394557,
        "end": 5198.8,
        "id": 1585,
        "no_speech_prob": 0.00004198579699732363,
        "seek": 517224,
        "start": 5196.8,
        "temperature": 0,
        "text": " you can't do that through a get request.",
        "tokens": [
          51592,
          291,
          393,
          380,
          360,
          300,
          807,
          257,
          483,
          5308,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.19286476864534266,
        "compression_ratio": 1.7414965986394557,
        "end": 5200.48,
        "id": 1586,
        "no_speech_prob": 0.00004198579699732363,
        "seek": 517224,
        "start": 5198.8,
        "temperature": 0,
        "text": " You can't easily, although there's some tricky ways.",
        "tokens": [
          51692,
          509,
          393,
          380,
          3612,
          11,
          4878,
          456,
          311,
          512,
          12414,
          2098,
          13,
          51776
        ]
      },
      {
        "avg_logprob": -0.23119059179583165,
        "compression_ratio": 1.6446886446886446,
        "end": 5205.28,
        "id": 1587,
        "no_speech_prob": 0.0004044794768560678,
        "seek": 520048,
        "start": 5200.48,
        "temperature": 0,
        "text": " You could base 64 encode your image into a number string that goes into the URL.",
        "tokens": [
          50364,
          509,
          727,
          3096,
          12145,
          2058,
          1429,
          428,
          3256,
          666,
          257,
          1230,
          6798,
          300,
          1709,
          666,
          264,
          12905,
          13,
          50604
        ]
      },
      {
        "avg_logprob": -0.23119059179583165,
        "compression_ratio": 1.6446886446886446,
        "end": 5211.04,
        "id": 1588,
        "no_speech_prob": 0.0004044794768560678,
        "seek": 520048,
        "start": 5205.28,
        "temperature": 0,
        "text": " But basically, for media, but really what I mean in a lot of ways is large data.",
        "tokens": [
          50604,
          583,
          1936,
          11,
          337,
          3021,
          11,
          457,
          534,
          437,
          286,
          914,
          294,
          257,
          688,
          295,
          2098,
          307,
          2416,
          1412,
          13,
          50892
        ]
      },
      {
        "avg_logprob": -0.23119059179583165,
        "compression_ratio": 1.6446886446886446,
        "end": 5216,
        "id": 1589,
        "no_speech_prob": 0.0004044794768560678,
        "seek": 520048,
        "start": 5211.04,
        "temperature": 0,
        "text": " So if I want to send a full paragraph to be our full many paragraphs,",
        "tokens": [
          50892,
          407,
          498,
          286,
          528,
          281,
          2845,
          257,
          1577,
          18865,
          281,
          312,
          527,
          1577,
          867,
          48910,
          11,
          51140
        ]
      },
      {
        "avg_logprob": -0.23119059179583165,
        "compression_ratio": 1.6446886446886446,
        "end": 5220,
        "id": 1590,
        "no_speech_prob": 0.0004044794768560678,
        "seek": 520048,
        "start": 5216,
        "temperature": 0,
        "text": " a thousand words to be analyzed and have the server send me a result back,",
        "tokens": [
          51140,
          257,
          4714,
          2283,
          281,
          312,
          28181,
          293,
          362,
          264,
          7154,
          2845,
          385,
          257,
          1874,
          646,
          11,
          51340
        ]
      },
      {
        "avg_logprob": -0.23119059179583165,
        "compression_ratio": 1.6446886446886446,
        "end": 5223.759999999999,
        "id": 1591,
        "no_speech_prob": 0.0004044794768560678,
        "seek": 520048,
        "start": 5220,
        "temperature": 0,
        "text": " I want to send that data through a post rather than a get.",
        "tokens": [
          51340,
          286,
          528,
          281,
          2845,
          300,
          1412,
          807,
          257,
          2183,
          2831,
          813,
          257,
          483,
          13,
          51528
        ]
      },
      {
        "avg_logprob": -0.23119059179583165,
        "compression_ratio": 1.6446886446886446,
        "end": 5228.24,
        "id": 1592,
        "no_speech_prob": 0.0004044794768560678,
        "seek": 520048,
        "start": 5223.759999999999,
        "temperature": 0,
        "text": " Because it's going to be much too awkward to try to encode a full paragraph of text",
        "tokens": [
          51528,
          1436,
          309,
          311,
          516,
          281,
          312,
          709,
          886,
          11411,
          281,
          853,
          281,
          2058,
          1429,
          257,
          1577,
          18865,
          295,
          2487,
          51752
        ]
      },
      {
        "avg_logprob": -0.19071490948016828,
        "compression_ratio": 1.6450511945392492,
        "end": 5231.12,
        "id": 1593,
        "no_speech_prob": 0.0000032887458019104088,
        "seek": 522824,
        "start": 5228.24,
        "temperature": 0,
        "text": " into some sort of route or URL query string.",
        "tokens": [
          50364,
          666,
          512,
          1333,
          295,
          7955,
          420,
          12905,
          14581,
          6798,
          13,
          50508
        ]
      },
      {
        "avg_logprob": -0.19071490948016828,
        "compression_ratio": 1.6450511945392492,
        "end": 5233.44,
        "id": 1594,
        "no_speech_prob": 0.0000032887458019104088,
        "seek": 522824,
        "start": 5231.12,
        "temperature": 0,
        "text": " So this is really the difference between get and post.",
        "tokens": [
          50508,
          407,
          341,
          307,
          534,
          264,
          2649,
          1296,
          483,
          293,
          2183,
          13,
          50624
        ]
      },
      {
        "avg_logprob": -0.19071490948016828,
        "compression_ratio": 1.6450511945392492,
        "end": 5234.719999999999,
        "id": 1595,
        "no_speech_prob": 0.0000032887458019104088,
        "seek": 522824,
        "start": 5233.44,
        "temperature": 0,
        "text": " Post is for sending data.",
        "tokens": [
          50624,
          10223,
          307,
          337,
          7750,
          1412,
          13,
          50688
        ]
      },
      {
        "avg_logprob": -0.19071490948016828,
        "compression_ratio": 1.6450511945392492,
        "end": 5237.04,
        "id": 1596,
        "no_speech_prob": 0.0000032887458019104088,
        "seek": 522824,
        "start": 5234.719999999999,
        "temperature": 0,
        "text": " It happens behind the scenes in an invisible way.",
        "tokens": [
          50688,
          467,
          2314,
          2261,
          264,
          8026,
          294,
          364,
          14603,
          636,
          13,
          50804
        ]
      },
      {
        "avg_logprob": -0.19071490948016828,
        "compression_ratio": 1.6450511945392492,
        "end": 5240.88,
        "id": 1597,
        "no_speech_prob": 0.0000032887458019104088,
        "seek": 522824,
        "start": 5237.599999999999,
        "temperature": 0,
        "text": " Get is for making a request and it happens right in a visible way",
        "tokens": [
          50832,
          3240,
          307,
          337,
          1455,
          257,
          5308,
          293,
          309,
          2314,
          558,
          294,
          257,
          8974,
          636,
          50996
        ]
      },
      {
        "avg_logprob": -0.19071490948016828,
        "compression_ratio": 1.6450511945392492,
        "end": 5246.719999999999,
        "id": 1598,
        "no_speech_prob": 0.0000032887458019104088,
        "seek": 522824,
        "start": 5240.88,
        "temperature": 0,
        "text": " because it's really basically the same as what you would be doing to type in a URL into the address bar.",
        "tokens": [
          50996,
          570,
          309,
          311,
          534,
          1936,
          264,
          912,
          382,
          437,
          291,
          576,
          312,
          884,
          281,
          2010,
          294,
          257,
          12905,
          666,
          264,
          2985,
          2159,
          13,
          51288
        ]
      },
      {
        "avg_logprob": -0.19071490948016828,
        "compression_ratio": 1.6450511945392492,
        "end": 5249.44,
        "id": 1599,
        "no_speech_prob": 0.0000032887458019104088,
        "seek": 522824,
        "start": 5246.719999999999,
        "temperature": 0,
        "text": " Okay, so now that we've covered that, how do I...",
        "tokens": [
          51288,
          1033,
          11,
          370,
          586,
          300,
          321,
          600,
          5343,
          300,
          11,
          577,
          360,
          286,
          485,
          51424
        ]
      },
      {
        "avg_logprob": -0.19071490948016828,
        "compression_ratio": 1.6450511945392492,
        "end": 5251.04,
        "id": 1600,
        "no_speech_prob": 0.0000032887458019104088,
        "seek": 522824,
        "start": 5249.44,
        "temperature": 0,
        "text": " There's two things I need to figure out.",
        "tokens": [
          51424,
          821,
          311,
          732,
          721,
          286,
          643,
          281,
          2573,
          484,
          13,
          51504
        ]
      },
      {
        "avg_logprob": -0.19071490948016828,
        "compression_ratio": 1.6450511945392492,
        "end": 5253.76,
        "id": 1601,
        "no_speech_prob": 0.0000032887458019104088,
        "seek": 522824,
        "start": 5251.04,
        "temperature": 0,
        "text": " One is how do I handle a post in the server?",
        "tokens": [
          51504,
          1485,
          307,
          577,
          360,
          286,
          4813,
          257,
          2183,
          294,
          264,
          7154,
          30,
          51640
        ]
      },
      {
        "avg_logprob": -0.26217748378885203,
        "compression_ratio": 1.5142857142857142,
        "end": 5260.64,
        "id": 1602,
        "no_speech_prob": 0.01243151817470789,
        "seek": 525376,
        "start": 5254.320000000001,
        "temperature": 0,
        "text": " The nice thing is you could imagine that it might be something like this,",
        "tokens": [
          50392,
          440,
          1481,
          551,
          307,
          291,
          727,
          3811,
          300,
          309,
          1062,
          312,
          746,
          411,
          341,
          11,
          50708
        ]
      },
      {
        "avg_logprob": -0.26217748378885203,
        "compression_ratio": 1.5142857142857142,
        "end": 5270.88,
        "id": 1603,
        "no_speech_prob": 0.01243151817470789,
        "seek": 525376,
        "start": 5260.64,
        "temperature": 0,
        "text": " app.post, analyze, analyze, and analyze this, right?",
        "tokens": [
          50708,
          724,
          13,
          23744,
          11,
          12477,
          11,
          12477,
          11,
          293,
          12477,
          341,
          11,
          558,
          30,
          51220
        ]
      },
      {
        "avg_logprob": -0.26217748378885203,
        "compression_ratio": 1.5142857142857142,
        "end": 5278.24,
        "id": 1604,
        "no_speech_prob": 0.01243151817470789,
        "seek": 525376,
        "start": 5270.88,
        "temperature": 0,
        "text": " So this is now, I'm going to write and I have a function to handle that post request.",
        "tokens": [
          51220,
          407,
          341,
          307,
          586,
          11,
          286,
          478,
          516,
          281,
          2464,
          293,
          286,
          362,
          257,
          2445,
          281,
          4813,
          300,
          2183,
          5308,
          13,
          51588
        ]
      },
      {
        "avg_logprob": -0.3034423760005406,
        "compression_ratio": 1.6653543307086613,
        "end": 5282.5599999999995,
        "id": 1605,
        "no_speech_prob": 0.00006709212175337598,
        "seek": 527824,
        "start": 5278.48,
        "temperature": 0,
        "text": " So this is now how instead of a get request in a node program,",
        "tokens": [
          50376,
          407,
          341,
          307,
          586,
          577,
          2602,
          295,
          257,
          483,
          5308,
          294,
          257,
          9984,
          1461,
          11,
          50580
        ]
      },
      {
        "avg_logprob": -0.3034423760005406,
        "compression_ratio": 1.6653543307086613,
        "end": 5286.639999999999,
        "id": 1606,
        "no_speech_prob": 0.00006709212175337598,
        "seek": 527824,
        "start": 5282.5599999999995,
        "temperature": 0,
        "text": " I can handle a post by saying app.post, analyze this.",
        "tokens": [
          50580,
          286,
          393,
          4813,
          257,
          2183,
          538,
          1566,
          724,
          13,
          23744,
          11,
          12477,
          341,
          13,
          50784
        ]
      },
      {
        "avg_logprob": -0.3034423760005406,
        "compression_ratio": 1.6653543307086613,
        "end": 5289.76,
        "id": 1607,
        "no_speech_prob": 0.00006709212175337598,
        "seek": 527824,
        "start": 5287.2,
        "temperature": 0,
        "text": " And then what's the other part?",
        "tokens": [
          50812,
          400,
          550,
          437,
          311,
          264,
          661,
          644,
          30,
          50940
        ]
      },
      {
        "avg_logprob": -0.3034423760005406,
        "compression_ratio": 1.6653543307086613,
        "end": 5292.16,
        "id": 1608,
        "no_speech_prob": 0.00006709212175337598,
        "seek": 527824,
        "start": 5289.76,
        "temperature": 0,
        "text": " How do I make a post request?",
        "tokens": [
          50940,
          1012,
          360,
          286,
          652,
          257,
          2183,
          5308,
          30,
          51060
        ]
      },
      {
        "avg_logprob": -0.3034423760005406,
        "compression_ratio": 1.6653543307086613,
        "end": 5295.599999999999,
        "id": 1609,
        "no_speech_prob": 0.00006709212175337598,
        "seek": 527824,
        "start": 5292.16,
        "temperature": 0,
        "text": " Well, there are countless ways you could do it because you could look at jQuery",
        "tokens": [
          51060,
          1042,
          11,
          456,
          366,
          19223,
          2098,
          291,
          727,
          360,
          309,
          570,
          291,
          727,
          574,
          412,
          361,
          35550,
          51232
        ]
      },
      {
        "avg_logprob": -0.3034423760005406,
        "compression_ratio": 1.6653543307086613,
        "end": 5300.8,
        "id": 1610,
        "no_speech_prob": 0.00006709212175337598,
        "seek": 527824,
        "start": 5295.599999999999,
        "temperature": 0,
        "text": " and you could look at native JavaScript and you could look at any JavaScript framework you want.",
        "tokens": [
          51232,
          293,
          291,
          727,
          574,
          412,
          8470,
          15778,
          293,
          291,
          727,
          574,
          412,
          604,
          15778,
          8388,
          291,
          528,
          13,
          51492
        ]
      },
      {
        "avg_logprob": -0.3034423760005406,
        "compression_ratio": 1.6653543307086613,
        "end": 5306.5599999999995,
        "id": 1611,
        "no_speech_prob": 0.00006709212175337598,
        "seek": 527824,
        "start": 5300.8,
        "temperature": 0,
        "text": " In p5, there's a very nice lovely little function called HTTP post.",
        "tokens": [
          51492,
          682,
          280,
          20,
          11,
          456,
          311,
          257,
          588,
          1481,
          7496,
          707,
          2445,
          1219,
          33283,
          2183,
          13,
          51780
        ]
      },
      {
        "avg_logprob": -0.4905547587076823,
        "compression_ratio": 1.7936507936507937,
        "end": 5308.72,
        "id": 1612,
        "no_speech_prob": 0.00051125418394804,
        "seek": 530656,
        "start": 5306.56,
        "temperature": 0,
        "text": " And so I'm going to add something.",
        "tokens": [
          50364,
          400,
          370,
          286,
          478,
          516,
          281,
          909,
          746,
          13,
          50472
        ]
      },
      {
        "avg_logprob": -0.4905547587076823,
        "compression_ratio": 1.7936507936507937,
        "end": 5311.84,
        "id": 1613,
        "no_speech_prob": 0.00051125418394804,
        "seek": 530656,
        "start": 5309.68,
        "temperature": 0,
        "text": " What I'm going to do is in the...",
        "tokens": [
          50520,
          708,
          286,
          478,
          516,
          281,
          360,
          307,
          294,
          264,
          485,
          50628
        ]
      },
      {
        "avg_logprob": -0.4905547587076823,
        "compression_ratio": 1.7936507936507937,
        "end": 5316.8,
        "id": 1614,
        "no_speech_prob": 0.00051125418394804,
        "seek": 530656,
        "start": 5313.200000000001,
        "temperature": 0,
        "text": " Here, I'm going to add a text area.",
        "tokens": [
          50696,
          1692,
          11,
          286,
          478,
          516,
          281,
          909,
          257,
          2487,
          1859,
          13,
          50876
        ]
      },
      {
        "avg_logprob": -0.4905547587076823,
        "compression_ratio": 1.7936507936507937,
        "end": 5321.92,
        "id": 1615,
        "no_speech_prob": 0.00051125418394804,
        "seek": 530656,
        "start": 5318.72,
        "temperature": 0,
        "text": " So I'm going to say, I'm going to make another paragraph.",
        "tokens": [
          50972,
          407,
          286,
          478,
          516,
          281,
          584,
          11,
          286,
          478,
          516,
          281,
          652,
          1071,
          18865,
          13,
          51132
        ]
      },
      {
        "avg_logprob": -0.4905547587076823,
        "compression_ratio": 1.7936507936507937,
        "end": 5329.68,
        "id": 1616,
        "no_speech_prob": 0.00051125418394804,
        "seek": 530656,
        "start": 5323.04,
        "temperature": 0,
        "text": " And I'm going to say text area id equals text input.",
        "tokens": [
          51188,
          400,
          286,
          478,
          516,
          281,
          584,
          2487,
          1859,
          4496,
          6915,
          2487,
          4846,
          13,
          51520
        ]
      },
      {
        "avg_logprob": -0.4905547587076823,
        "compression_ratio": 1.7936507936507937,
        "end": 5334.240000000001,
        "id": 1617,
        "no_speech_prob": 0.00051125418394804,
        "seek": 530656,
        "start": 5332.72,
        "temperature": 0,
        "text": " Text area.",
        "tokens": [
          51672,
          18643,
          1859,
          13,
          51748
        ]
      },
      {
        "avg_logprob": -0.19610601855862525,
        "compression_ratio": 1.5911330049261083,
        "end": 5335.599999999999,
        "id": 1618,
        "no_speech_prob": 0.0001795267453417182,
        "seek": 533424,
        "start": 5334.48,
        "temperature": 0,
        "text": " Text area.",
        "tokens": [
          50376,
          18643,
          1859,
          13,
          50432
        ]
      },
      {
        "avg_logprob": -0.19610601855862525,
        "compression_ratio": 1.5911330049261083,
        "end": 5340.16,
        "id": 1619,
        "no_speech_prob": 0.0001795267453417182,
        "seek": 533424,
        "start": 5336.16,
        "temperature": 0,
        "text": " Let's just do columns equals 40 and rows equals 5.",
        "tokens": [
          50460,
          961,
          311,
          445,
          360,
          13766,
          6915,
          3356,
          293,
          13241,
          6915,
          1025,
          13,
          50660
        ]
      },
      {
        "avg_logprob": -0.19610601855862525,
        "compression_ratio": 1.5911330049261083,
        "end": 5346.16,
        "id": 1620,
        "no_speech_prob": 0.0001795267453417182,
        "seek": 533424,
        "start": 5341.12,
        "temperature": 0,
        "text": " And so if I go now to here, we should see there's a text area there.",
        "tokens": [
          50708,
          400,
          370,
          498,
          286,
          352,
          586,
          281,
          510,
          11,
          321,
          820,
          536,
          456,
          311,
          257,
          2487,
          1859,
          456,
          13,
          50960
        ]
      },
      {
        "avg_logprob": -0.19610601855862525,
        "compression_ratio": 1.5911330049261083,
        "end": 5353.12,
        "id": 1621,
        "no_speech_prob": 0.0001795267453417182,
        "seek": 533424,
        "start": 5346.16,
        "temperature": 0,
        "text": " So what I want to do is when I add another submit button, I'll call it analyze.",
        "tokens": [
          50960,
          407,
          437,
          286,
          528,
          281,
          360,
          307,
          562,
          286,
          909,
          1071,
          10315,
          2960,
          11,
          286,
          603,
          818,
          309,
          12477,
          13,
          51308
        ]
      },
      {
        "avg_logprob": -0.19610601855862525,
        "compression_ratio": 1.5911330049261083,
        "end": 5358.639999999999,
        "id": 1622,
        "no_speech_prob": 0.0001795267453417182,
        "seek": 533424,
        "start": 5357.2,
        "temperature": 0,
        "text": " So now I have an analyze button.",
        "tokens": [
          51512,
          407,
          586,
          286,
          362,
          364,
          12477,
          2960,
          13,
          51584
        ]
      },
      {
        "avg_logprob": -0.19610601855862525,
        "compression_ratio": 1.5911330049261083,
        "end": 5363.44,
        "id": 1623,
        "no_speech_prob": 0.0001795267453417182,
        "seek": 533424,
        "start": 5358.639999999999,
        "temperature": 0,
        "text": " What I want is when I analyze this button to make a post request to the server,",
        "tokens": [
          51584,
          708,
          286,
          528,
          307,
          562,
          286,
          12477,
          341,
          2960,
          281,
          652,
          257,
          2183,
          5308,
          281,
          264,
          7154,
          11,
          51824
        ]
      },
      {
        "avg_logprob": -0.23804218628827264,
        "compression_ratio": 1.5931034482758621,
        "end": 5371.2,
        "id": 1624,
        "no_speech_prob": 0.00007602440018672496,
        "seek": 536424,
        "start": 5364.8,
        "temperature": 0,
        "text": " so what I need to do is I need to also in JavaScript get access to the analyze button.",
        "tokens": [
          50392,
          370,
          437,
          286,
          643,
          281,
          360,
          307,
          286,
          643,
          281,
          611,
          294,
          15778,
          483,
          2105,
          281,
          264,
          12477,
          2960,
          13,
          50712
        ]
      },
      {
        "avg_logprob": -0.23804218628827264,
        "compression_ratio": 1.5931034482758621,
        "end": 5376.96,
        "id": 1625,
        "no_speech_prob": 0.00007602440018672496,
        "seek": 536424,
        "start": 5373.92,
        "temperature": 0,
        "text": " Button A for analyze and analyze.",
        "tokens": [
          50848,
          38435,
          316,
          337,
          12477,
          293,
          12477,
          13,
          51000
        ]
      },
      {
        "avg_logprob": -0.23804218628827264,
        "compression_ratio": 1.5931034482758621,
        "end": 5382.16,
        "id": 1626,
        "no_speech_prob": 0.00007602440018672496,
        "seek": 536424,
        "start": 5379.76,
        "temperature": 0,
        "text": " And analyze this, I'll say.",
        "tokens": [
          51140,
          400,
          12477,
          341,
          11,
          286,
          603,
          584,
          13,
          51260
        ]
      },
      {
        "avg_logprob": -0.23804218628827264,
        "compression_ratio": 1.5931034482758621,
        "end": 5386,
        "id": 1627,
        "no_speech_prob": 0.00007602440018672496,
        "seek": 536424,
        "start": 5383.76,
        "temperature": 0,
        "text": " Function analyze this.",
        "tokens": [
          51340,
          11166,
          882,
          12477,
          341,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.23804218628827264,
        "compression_ratio": 1.5931034482758621,
        "end": 5392,
        "id": 1628,
        "no_speech_prob": 0.00007602440018672496,
        "seek": 536424,
        "start": 5386.639999999999,
        "temperature": 0,
        "text": " And here what I want to do is get the text, which is the...",
        "tokens": [
          51484,
          400,
          510,
          437,
          286,
          528,
          281,
          360,
          307,
          483,
          264,
          2487,
          11,
          597,
          307,
          264,
          485,
          51752
        ]
      },
      {
        "avg_logprob": -0.22420140748382897,
        "compression_ratio": 1.6701030927835052,
        "end": 5397.92,
        "id": 1629,
        "no_speech_prob": 0.000054759653721703216,
        "seek": 539200,
        "start": 5392.64,
        "temperature": 0,
        "text": " I can select the text input area and say dot value.",
        "tokens": [
          50396,
          286,
          393,
          3048,
          264,
          2487,
          4846,
          1859,
          293,
          584,
          5893,
          2158,
          13,
          50660
        ]
      },
      {
        "avg_logprob": -0.22420140748382897,
        "compression_ratio": 1.6701030927835052,
        "end": 5400.72,
        "id": 1630,
        "no_speech_prob": 0.000054759653721703216,
        "seek": 539200,
        "start": 5397.92,
        "temperature": 0,
        "text": " And then I want to make a post.",
        "tokens": [
          50660,
          400,
          550,
          286,
          528,
          281,
          652,
          257,
          2183,
          13,
          50800
        ]
      },
      {
        "avg_logprob": -0.22420140748382897,
        "compression_ratio": 1.6701030927835052,
        "end": 5406.72,
        "id": 1631,
        "no_speech_prob": 0.000054759653721703216,
        "seek": 539200,
        "start": 5400.72,
        "temperature": 0,
        "text": " And the way I make a post is with the p5 function HTTP post.",
        "tokens": [
          50800,
          400,
          264,
          636,
          286,
          652,
          257,
          2183,
          307,
          365,
          264,
          280,
          20,
          2445,
          33283,
          2183,
          13,
          51100
        ]
      },
      {
        "avg_logprob": -0.22420140748382897,
        "compression_ratio": 1.6701030927835052,
        "end": 5411.12,
        "id": 1632,
        "no_speech_prob": 0.000054759653721703216,
        "seek": 539200,
        "start": 5406.72,
        "temperature": 0,
        "text": " So when I wanted to make a get request, load JSON was all I needed to do.",
        "tokens": [
          51100,
          407,
          562,
          286,
          1415,
          281,
          652,
          257,
          483,
          5308,
          11,
          3677,
          31828,
          390,
          439,
          286,
          2978,
          281,
          360,
          13,
          51320
        ]
      },
      {
        "avg_logprob": -0.22420140748382897,
        "compression_ratio": 1.6701030927835052,
        "end": 5415.04,
        "id": 1633,
        "no_speech_prob": 0.000054759653721703216,
        "seek": 539200,
        "start": 5411.12,
        "temperature": 0,
        "text": " Because load JSON by default is a get request, just like load image or load...",
        "tokens": [
          51320,
          1436,
          3677,
          31828,
          538,
          7576,
          307,
          257,
          483,
          5308,
          11,
          445,
          411,
          3677,
          3256,
          420,
          3677,
          485,
          51516
        ]
      },
      {
        "avg_logprob": -0.22420140748382897,
        "compression_ratio": 1.6701030927835052,
        "end": 5418,
        "id": 1634,
        "no_speech_prob": 0.000054759653721703216,
        "seek": 539200,
        "start": 5416.88,
        "temperature": 0,
        "text": " Any of the load functions.",
        "tokens": [
          51608,
          2639,
          295,
          264,
          3677,
          6828,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20818698817286,
        "compression_ratio": 1.5932203389830508,
        "end": 5424.88,
        "id": 1635,
        "no_speech_prob": 0.00010071374708786607,
        "seek": 541800,
        "start": 5418,
        "temperature": 0,
        "text": " There is, by the way, an HTTP get method, which allows you to have more control over that get request.",
        "tokens": [
          50364,
          821,
          307,
          11,
          538,
          264,
          636,
          11,
          364,
          33283,
          483,
          3170,
          11,
          597,
          4045,
          291,
          281,
          362,
          544,
          1969,
          670,
          300,
          483,
          5308,
          13,
          50708
        ]
      },
      {
        "avg_logprob": -0.20818698817286,
        "compression_ratio": 1.5932203389830508,
        "end": 5426.48,
        "id": 1636,
        "no_speech_prob": 0.00010071374708786607,
        "seek": 541800,
        "start": 5424.88,
        "temperature": 0,
        "text": " But here I just want to make a post.",
        "tokens": [
          50708,
          583,
          510,
          286,
          445,
          528,
          281,
          652,
          257,
          2183,
          13,
          50788
        ]
      },
      {
        "avg_logprob": -0.20818698817286,
        "compression_ratio": 1.5932203389830508,
        "end": 5428.96,
        "id": 1637,
        "no_speech_prob": 0.00010071374708786607,
        "seek": 541800,
        "start": 5426.48,
        "temperature": 0,
        "text": " So, OK.",
        "tokens": [
          50788,
          407,
          11,
          2264,
          13,
          50912
        ]
      },
      {
        "avg_logprob": -0.20818698817286,
        "compression_ratio": 1.5932203389830508,
        "end": 5431.44,
        "id": 1638,
        "no_speech_prob": 0.00010071374708786607,
        "seek": 541800,
        "start": 5428.96,
        "temperature": 0,
        "text": " So I'm going to do p5.js reference.",
        "tokens": [
          50912,
          407,
          286,
          478,
          516,
          281,
          360,
          280,
          20,
          13,
          25530,
          6408,
          13,
          51036
        ]
      },
      {
        "avg_logprob": -0.20818698817286,
        "compression_ratio": 1.5932203389830508,
        "end": 5436.32,
        "id": 1639,
        "no_speech_prob": 0.00010071374708786607,
        "seek": 541800,
        "start": 5432.24,
        "temperature": 0,
        "text": " And I'm going to look at HTTP post.",
        "tokens": [
          51076,
          400,
          286,
          478,
          516,
          281,
          574,
          412,
          33283,
          2183,
          13,
          51280
        ]
      },
      {
        "avg_logprob": -0.20818698817286,
        "compression_ratio": 1.5932203389830508,
        "end": 5437.84,
        "id": 1640,
        "no_speech_prob": 0.00010071374708786607,
        "seek": 541800,
        "start": 5436.32,
        "temperature": 0,
        "text": " And let's look at this page.",
        "tokens": [
          51280,
          400,
          718,
          311,
          574,
          412,
          341,
          3028,
          13,
          51356
        ]
      },
      {
        "avg_logprob": -0.20818698817286,
        "compression_ratio": 1.5932203389830508,
        "end": 5440,
        "id": 1641,
        "no_speech_prob": 0.00010071374708786607,
        "seek": 541800,
        "start": 5437.84,
        "temperature": 0,
        "text": " The difference is... and boy, does this look confusing.",
        "tokens": [
          51356,
          440,
          2649,
          307,
          485,
          293,
          3237,
          11,
          775,
          341,
          574,
          13181,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20818698817286,
        "compression_ratio": 1.5932203389830508,
        "end": 5445.68,
        "id": 1642,
        "no_speech_prob": 0.00010071374708786607,
        "seek": 541800,
        "start": 5440.88,
        "temperature": 0,
        "text": " The difference is when I make a post, I need to send it a whole object,",
        "tokens": [
          51508,
          440,
          2649,
          307,
          562,
          286,
          652,
          257,
          2183,
          11,
          286,
          643,
          281,
          2845,
          309,
          257,
          1379,
          2657,
          11,
          51748
        ]
      },
      {
        "avg_logprob": -0.2018651894643797,
        "compression_ratio": 1.7403508771929825,
        "end": 5449.04,
        "id": 1643,
        "no_speech_prob": 0.0011159959249198437,
        "seek": 544568,
        "start": 5445.68,
        "temperature": 0,
        "text": " which is all the data that I want included as part of the post.",
        "tokens": [
          50364,
          597,
          307,
          439,
          264,
          1412,
          300,
          286,
          528,
          5556,
          382,
          644,
          295,
          264,
          2183,
          13,
          50532
        ]
      },
      {
        "avg_logprob": -0.2018651894643797,
        "compression_ratio": 1.7403508771929825,
        "end": 5454.320000000001,
        "id": 1644,
        "no_speech_prob": 0.0011159959249198437,
        "seek": 544568,
        "start": 5449.04,
        "temperature": 0,
        "text": " So this allows for a lot of possibilities, because I can have multiple fields and I have multiple kinds of data.",
        "tokens": [
          50532,
          407,
          341,
          4045,
          337,
          257,
          688,
          295,
          12178,
          11,
          570,
          286,
          393,
          362,
          3866,
          7909,
          293,
          286,
          362,
          3866,
          3685,
          295,
          1412,
          13,
          50796
        ]
      },
      {
        "avg_logprob": -0.2018651894643797,
        "compression_ratio": 1.7403508771929825,
        "end": 5456.400000000001,
        "id": 1645,
        "no_speech_prob": 0.0011159959249198437,
        "seek": 544568,
        "start": 5454.320000000001,
        "temperature": 0,
        "text": " So really, there's a bunch of stuff I need here.",
        "tokens": [
          50796,
          407,
          534,
          11,
          456,
          311,
          257,
          3840,
          295,
          1507,
          286,
          643,
          510,
          13,
          50900
        ]
      },
      {
        "avg_logprob": -0.2018651894643797,
        "compression_ratio": 1.7403508771929825,
        "end": 5459.360000000001,
        "id": 1646,
        "no_speech_prob": 0.0011159959249198437,
        "seek": 544568,
        "start": 5456.400000000001,
        "temperature": 0,
        "text": " But what I care about most right now is the...",
        "tokens": [
          50900,
          583,
          437,
          286,
          1127,
          466,
          881,
          558,
          586,
          307,
          264,
          485,
          51048
        ]
      },
      {
        "avg_logprob": -0.2018651894643797,
        "compression_ratio": 1.7403508771929825,
        "end": 5465.68,
        "id": 1647,
        "no_speech_prob": 0.0011159959249198437,
        "seek": 544568,
        "start": 5461.6,
        "temperature": 0,
        "text": " I need to give it the path, which is the route, the data that I want to send,",
        "tokens": [
          51160,
          286,
          643,
          281,
          976,
          309,
          264,
          3100,
          11,
          597,
          307,
          264,
          7955,
          11,
          264,
          1412,
          300,
          286,
          528,
          281,
          2845,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.2018651894643797,
        "compression_ratio": 1.7403508771929825,
        "end": 5469.92,
        "id": 1648,
        "no_speech_prob": 0.0011159959249198437,
        "seek": 544568,
        "start": 5465.68,
        "temperature": 0,
        "text": " I guess what kind of data it is, which I'm going to make it JSON-based data,",
        "tokens": [
          51364,
          286,
          2041,
          437,
          733,
          295,
          1412,
          309,
          307,
          11,
          597,
          286,
          478,
          516,
          281,
          652,
          309,
          31828,
          12,
          6032,
          1412,
          11,
          51576
        ]
      },
      {
        "avg_logprob": -0.2018651894643797,
        "compression_ratio": 1.7403508771929825,
        "end": 5472.08,
        "id": 1649,
        "no_speech_prob": 0.0011159959249198437,
        "seek": 544568,
        "start": 5469.92,
        "temperature": 0,
        "text": " and then a callback for when it's finished.",
        "tokens": [
          51576,
          293,
          550,
          257,
          818,
          3207,
          337,
          562,
          309,
          311,
          4335,
          13,
          51684
        ]
      },
      {
        "avg_logprob": -0.2018651894643797,
        "compression_ratio": 1.7403508771929825,
        "end": 5473.280000000001,
        "id": 1650,
        "no_speech_prob": 0.0011159959249198437,
        "seek": 544568,
        "start": 5472.08,
        "temperature": 0,
        "text": " So let's do all of that.",
        "tokens": [
          51684,
          407,
          718,
          311,
          360,
          439,
          295,
          300,
          13,
          51744
        ]
      },
      {
        "avg_logprob": -0.2322165686804969,
        "compression_ratio": 1.5781990521327014,
        "end": 5476.48,
        "id": 1651,
        "no_speech_prob": 0.02194746769964695,
        "seek": 547328,
        "start": 5474.08,
        "temperature": 0,
        "text": " And I'm going to say... where was that?",
        "tokens": [
          50404,
          400,
          286,
          478,
          516,
          281,
          584,
          485,
          689,
          390,
          300,
          30,
          50524
        ]
      },
      {
        "avg_logprob": -0.2322165686804969,
        "compression_ratio": 1.5781990521327014,
        "end": 5477.5199999999995,
        "id": 1652,
        "no_speech_prob": 0.02194746769964695,
        "seek": 547328,
        "start": 5476.48,
        "temperature": 0,
        "text": " HTTP post.",
        "tokens": [
          50524,
          33283,
          2183,
          13,
          50576
        ]
      },
      {
        "avg_logprob": -0.2322165686804969,
        "compression_ratio": 1.5781990521327014,
        "end": 5484.08,
        "id": 1653,
        "no_speech_prob": 0.02194746769964695,
        "seek": 547328,
        "start": 5477.5199999999995,
        "temperature": 0,
        "text": " So first, I need to say data is the text.",
        "tokens": [
          50576,
          407,
          700,
          11,
          286,
          643,
          281,
          584,
          1412,
          307,
          264,
          2487,
          13,
          50904
        ]
      },
      {
        "avg_logprob": -0.2322165686804969,
        "compression_ratio": 1.5781990521327014,
        "end": 5485.679999999999,
        "id": 1654,
        "no_speech_prob": 0.02194746769964695,
        "seek": 547328,
        "start": 5484.08,
        "temperature": 0,
        "text": " Is the text.",
        "tokens": [
          50904,
          1119,
          264,
          2487,
          13,
          50984
        ]
      },
      {
        "avg_logprob": -0.2322165686804969,
        "compression_ratio": 1.5781990521327014,
        "end": 5490.16,
        "id": 1655,
        "no_speech_prob": 0.02194746769964695,
        "seek": 547328,
        "start": 5486.719999999999,
        "temperature": 0,
        "text": " And that's actually all I need to post is just what's in there.",
        "tokens": [
          51036,
          400,
          300,
          311,
          767,
          439,
          286,
          643,
          281,
          2183,
          307,
          445,
          437,
          311,
          294,
          456,
          13,
          51208
        ]
      },
      {
        "avg_logprob": -0.2322165686804969,
        "compression_ratio": 1.5781990521327014,
        "end": 5493.679999999999,
        "id": 1656,
        "no_speech_prob": 0.02194746769964695,
        "seek": 547328,
        "start": 5491.12,
        "temperature": 0,
        "text": " But I could add a lot more things into this object.",
        "tokens": [
          51256,
          583,
          286,
          727,
          909,
          257,
          688,
          544,
          721,
          666,
          341,
          2657,
          13,
          51384
        ]
      },
      {
        "avg_logprob": -0.2322165686804969,
        "compression_ratio": 1.5781990521327014,
        "end": 5497.12,
        "id": 1657,
        "no_speech_prob": 0.02194746769964695,
        "seek": 547328,
        "start": 5493.679999999999,
        "temperature": 0,
        "text": " And I want to go to slash analyze.",
        "tokens": [
          51384,
          400,
          286,
          528,
          281,
          352,
          281,
          17330,
          12477,
          13,
          51556
        ]
      },
      {
        "avg_logprob": -0.2322165686804969,
        "compression_ratio": 1.5781990521327014,
        "end": 5501.2,
        "id": 1658,
        "no_speech_prob": 0.02194746769964695,
        "seek": 547328,
        "start": 5498.24,
        "temperature": 0,
        "text": " Is that how I did it in the load JSON?",
        "tokens": [
          51612,
          1119,
          300,
          577,
          286,
          630,
          309,
          294,
          264,
          3677,
          31828,
          30,
          51760
        ]
      },
      {
        "avg_logprob": -0.2322165686804969,
        "compression_ratio": 1.5781990521327014,
        "end": 5501.44,
        "id": 1659,
        "no_speech_prob": 0.02194746769964695,
        "seek": 547328,
        "start": 5501.2,
        "temperature": 0,
        "text": " Add.",
        "tokens": [
          51760,
          5349,
          13,
          51772
        ]
      },
      {
        "avg_logprob": -0.2322165686804969,
        "compression_ratio": 1.5781990521327014,
        "end": 5502.639999999999,
        "id": 1660,
        "no_speech_prob": 0.02194746769964695,
        "seek": 547328,
        "start": 5501.44,
        "temperature": 0,
        "text": " I don't need the slash in front.",
        "tokens": [
          51772,
          286,
          500,
          380,
          643,
          264,
          17330,
          294,
          1868,
          13,
          51832
        ]
      },
      {
        "avg_logprob": -0.23270124547621784,
        "compression_ratio": 1.7348066298342542,
        "end": 5502.96,
        "id": 1661,
        "no_speech_prob": 0.0002959549310617149,
        "seek": 550264,
        "start": 5502.64,
        "temperature": 0,
        "text": " Sorry.",
        "tokens": [
          50364,
          4919,
          13,
          50380
        ]
      },
      {
        "avg_logprob": -0.23270124547621784,
        "compression_ratio": 1.7348066298342542,
        "end": 5504.320000000001,
        "id": 1662,
        "no_speech_prob": 0.0002959549310617149,
        "seek": 550264,
        "start": 5503.76,
        "temperature": 0,
        "text": " Analyze.",
        "tokens": [
          50420,
          1107,
          5222,
          1381,
          13,
          50448
        ]
      },
      {
        "avg_logprob": -0.23270124547621784,
        "compression_ratio": 1.7348066298342542,
        "end": 5508.160000000001,
        "id": 1663,
        "no_speech_prob": 0.0002959549310617149,
        "seek": 550264,
        "start": 5505.04,
        "temperature": 0,
        "text": " And then I need to say it's going to be JSON.",
        "tokens": [
          50484,
          400,
          550,
          286,
          643,
          281,
          584,
          309,
          311,
          516,
          281,
          312,
          31828,
          13,
          50640
        ]
      },
      {
        "avg_logprob": -0.23270124547621784,
        "compression_ratio": 1.7348066298342542,
        "end": 5513.92,
        "id": 1664,
        "no_speech_prob": 0.0002959549310617149,
        "seek": 550264,
        "start": 5509.12,
        "temperature": 0,
        "text": " And then I need to say data posted.",
        "tokens": [
          50688,
          400,
          550,
          286,
          643,
          281,
          584,
          1412,
          9437,
          13,
          50928
        ]
      },
      {
        "avg_logprob": -0.23270124547621784,
        "compression_ratio": 1.7348066298342542,
        "end": 5516.400000000001,
        "id": 1665,
        "no_speech_prob": 0.0002959549310617149,
        "seek": 550264,
        "start": 5514.64,
        "temperature": 0,
        "text": " And then I could also say data error.",
        "tokens": [
          50964,
          400,
          550,
          286,
          727,
          611,
          584,
          1412,
          6713,
          13,
          51052
        ]
      },
      {
        "avg_logprob": -0.23270124547621784,
        "compression_ratio": 1.7348066298342542,
        "end": 5518.64,
        "id": 1666,
        "no_speech_prob": 0.0002959549310617149,
        "seek": 550264,
        "start": 5516.400000000001,
        "temperature": 0,
        "text": " But let's skip the error right now.",
        "tokens": [
          51052,
          583,
          718,
          311,
          10023,
          264,
          6713,
          558,
          586,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.23270124547621784,
        "compression_ratio": 1.7348066298342542,
        "end": 5522.56,
        "id": 1667,
        "no_speech_prob": 0.0002959549310617149,
        "seek": 550264,
        "start": 5518.64,
        "temperature": 0,
        "text": " I should actually probably data post error.",
        "tokens": [
          51164,
          286,
          820,
          767,
          1391,
          1412,
          2183,
          6713,
          13,
          51360
        ]
      },
      {
        "avg_logprob": -0.23270124547621784,
        "compression_ratio": 1.7348066298342542,
        "end": 5524.88,
        "id": 1668,
        "no_speech_prob": 0.0002959549310617149,
        "seek": 550264,
        "start": 5523.200000000001,
        "temperature": 0,
        "text": " So let's write those functions.",
        "tokens": [
          51392,
          407,
          718,
          311,
          2464,
          729,
          6828,
          13,
          51476
        ]
      },
      {
        "avg_logprob": -0.23270124547621784,
        "compression_ratio": 1.7348066298342542,
        "end": 5527.92,
        "id": 1669,
        "no_speech_prob": 0.0002959549310617149,
        "seek": 550264,
        "start": 5526.240000000001,
        "temperature": 0,
        "text": " Function data posted.",
        "tokens": [
          51544,
          11166,
          882,
          1412,
          9437,
          13,
          51628
        ]
      },
      {
        "avg_logprob": -0.23270124547621784,
        "compression_ratio": 1.7348066298342542,
        "end": 5529.92,
        "id": 1670,
        "no_speech_prob": 0.0002959549310617149,
        "seek": 550264,
        "start": 5529.4400000000005,
        "temperature": 0,
        "text": " Result.",
        "tokens": [
          51704,
          5015,
          723,
          13,
          51728
        ]
      },
      {
        "avg_logprob": -0.23270124547621784,
        "compression_ratio": 1.7348066298342542,
        "end": 5532.4800000000005,
        "id": 1671,
        "no_speech_prob": 0.0002959549310617149,
        "seek": 550264,
        "start": 5530.4800000000005,
        "temperature": 0,
        "text": " I'm going to say console.log result.",
        "tokens": [
          51756,
          286,
          478,
          516,
          281,
          584,
          11076,
          13,
          4987,
          1874,
          13,
          51856
        ]
      },
      {
        "avg_logprob": -0.20151572000412715,
        "compression_ratio": 1.541899441340782,
        "end": 5534.96,
        "id": 1672,
        "no_speech_prob": 0.00020662946917582303,
        "seek": 553264,
        "start": 5533.360000000001,
        "temperature": 0,
        "text": " And in the server now...",
        "tokens": [
          50400,
          400,
          294,
          264,
          7154,
          586,
          485,
          50480
        ]
      },
      {
        "avg_logprob": -0.20151572000412715,
        "compression_ratio": 1.541899441340782,
        "end": 5538.64,
        "id": 1673,
        "no_speech_prob": 0.00020662946917582303,
        "seek": 553264,
        "start": 5534.96,
        "temperature": 0,
        "text": " So now I've posted this data to the server.",
        "tokens": [
          50480,
          407,
          586,
          286,
          600,
          9437,
          341,
          1412,
          281,
          264,
          7154,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20151572000412715,
        "compression_ratio": 1.541899441340782,
        "end": 5541.76,
        "id": 1674,
        "no_speech_prob": 0.00020662946917582303,
        "seek": 553264,
        "start": 5538.64,
        "temperature": 0,
        "text": " And again, this could be a lot more stuff than just that text.",
        "tokens": [
          50664,
          400,
          797,
          11,
          341,
          727,
          312,
          257,
          688,
          544,
          1507,
          813,
          445,
          300,
          2487,
          13,
          50820
        ]
      },
      {
        "avg_logprob": -0.20151572000412715,
        "compression_ratio": 1.541899441340782,
        "end": 5545.6,
        "id": 1675,
        "no_speech_prob": 0.00020662946917582303,
        "seek": 553264,
        "start": 5543.12,
        "temperature": 0,
        "text": " And in this function...",
        "tokens": [
          50888,
          400,
          294,
          341,
          2445,
          485,
          51012
        ]
      },
      {
        "avg_logprob": -0.20151572000412715,
        "compression_ratio": 1.541899441340782,
        "end": 5553.6,
        "id": 1676,
        "no_speech_prob": 0.00020662946917582303,
        "seek": 553264,
        "start": 5549.68,
        "temperature": 0,
        "text": " And post, I should have a callback for error.",
        "tokens": [
          51216,
          400,
          2183,
          11,
          286,
          820,
          362,
          257,
          818,
          3207,
          337,
          6713,
          13,
          51412
        ]
      },
      {
        "avg_logprob": -0.20151572000412715,
        "compression_ratio": 1.541899441340782,
        "end": 5558.4800000000005,
        "id": 1677,
        "no_speech_prob": 0.00020662946917582303,
        "seek": 553264,
        "start": 5554.4800000000005,
        "temperature": 0,
        "text": " And so now I just want to look at what comes back after it's posted.",
        "tokens": [
          51456,
          400,
          370,
          586,
          286,
          445,
          528,
          281,
          574,
          412,
          437,
          1487,
          646,
          934,
          309,
          311,
          9437,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.20151572000412715,
        "compression_ratio": 1.541899441340782,
        "end": 5558.8,
        "id": 1678,
        "no_speech_prob": 0.00020662946917582303,
        "seek": 553264,
        "start": 5558.4800000000005,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51656,
          1033,
          13,
          51672
        ]
      },
      {
        "avg_logprob": -0.21479732175416585,
        "compression_ratio": 1.5384615384615385,
        "end": 5567.360000000001,
        "id": 1679,
        "no_speech_prob": 0.00048029489698819816,
        "seek": 555880,
        "start": 5559.360000000001,
        "temperature": 0,
        "text": " So now in the server, I'm just going to say response.send thank you.",
        "tokens": [
          50392,
          407,
          586,
          294,
          264,
          7154,
          11,
          286,
          478,
          445,
          516,
          281,
          584,
          4134,
          13,
          82,
          521,
          1309,
          291,
          13,
          50792
        ]
      },
      {
        "avg_logprob": -0.21479732175416585,
        "compression_ratio": 1.5384615384615385,
        "end": 5574.08,
        "id": 1680,
        "no_speech_prob": 0.00048029489698819816,
        "seek": 555880,
        "start": 5571.04,
        "temperature": 0,
        "text": " And actually, let's make this a reply message.",
        "tokens": [
          50976,
          400,
          767,
          11,
          718,
          311,
          652,
          341,
          257,
          16972,
          3636,
          13,
          51128
        ]
      },
      {
        "avg_logprob": -0.21479732175416585,
        "compression_ratio": 1.5384615384615385,
        "end": 5575.2,
        "id": 1681,
        "no_speech_prob": 0.00048029489698819816,
        "seek": 555880,
        "start": 5574.72,
        "temperature": 0,
        "text": " Thank you.",
        "tokens": [
          51160,
          1044,
          291,
          13,
          51184
        ]
      },
      {
        "avg_logprob": -0.21479732175416585,
        "compression_ratio": 1.5384615384615385,
        "end": 5578.08,
        "id": 1682,
        "no_speech_prob": 0.00048029489698819816,
        "seek": 555880,
        "start": 5576.72,
        "temperature": 0,
        "text": " And send that reply.",
        "tokens": [
          51260,
          400,
          2845,
          300,
          16972,
          13,
          51328
        ]
      },
      {
        "avg_logprob": -0.21479732175416585,
        "compression_ratio": 1.5384615384615385,
        "end": 5583.84,
        "id": 1683,
        "no_speech_prob": 0.00048029489698819816,
        "seek": 555880,
        "start": 5579.28,
        "temperature": 0,
        "text": " And let's just look at console.log request.",
        "tokens": [
          51388,
          400,
          718,
          311,
          445,
          574,
          412,
          11076,
          13,
          4987,
          5308,
          13,
          51616
        ]
      },
      {
        "avg_logprob": -0.21479732175416585,
        "compression_ratio": 1.5384615384615385,
        "end": 5588.16,
        "id": 1684,
        "no_speech_prob": 0.00048029489698819816,
        "seek": 555880,
        "start": 5584.96,
        "temperature": 0,
        "text": " So we're going to figure out how do we get the stuff that was posted",
        "tokens": [
          51672,
          407,
          321,
          434,
          516,
          281,
          2573,
          484,
          577,
          360,
          321,
          483,
          264,
          1507,
          300,
          390,
          9437,
          51832
        ]
      },
      {
        "avg_logprob": -0.18715316708348378,
        "compression_ratio": 1.5645933014354068,
        "end": 5589.92,
        "id": 1685,
        "no_speech_prob": 0.0002066292508970946,
        "seek": 558816,
        "start": 5588.24,
        "temperature": 0,
        "text": " right here in the request.",
        "tokens": [
          50368,
          558,
          510,
          294,
          264,
          5308,
          13,
          50452
        ]
      },
      {
        "avg_logprob": -0.18715316708348378,
        "compression_ratio": 1.5645933014354068,
        "end": 5590.24,
        "id": 1686,
        "no_speech_prob": 0.0002066292508970946,
        "seek": 558816,
        "start": 5589.92,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50452,
          1033,
          13,
          50468
        ]
      },
      {
        "avg_logprob": -0.18715316708348378,
        "compression_ratio": 1.5645933014354068,
        "end": 5592.639999999999,
        "id": 1687,
        "no_speech_prob": 0.0002066292508970946,
        "seek": 558816,
        "start": 5590.8,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          50496,
          1692,
          321,
          352,
          13,
          50588
        ]
      },
      {
        "avg_logprob": -0.18715316708348378,
        "compression_ratio": 1.5645933014354068,
        "end": 5595.44,
        "id": 1688,
        "no_speech_prob": 0.0002066292508970946,
        "seek": 558816,
        "start": 5593.84,
        "temperature": 0,
        "text": " So let's see how far did we get here.",
        "tokens": [
          50648,
          407,
          718,
          311,
          536,
          577,
          1400,
          630,
          321,
          483,
          510,
          13,
          50728
        ]
      },
      {
        "avg_logprob": -0.18715316708348378,
        "compression_ratio": 1.5645933014354068,
        "end": 5597.04,
        "id": 1689,
        "no_speech_prob": 0.0002066292508970946,
        "seek": 558816,
        "start": 5595.44,
        "temperature": 0,
        "text": " First, I need to restart the server.",
        "tokens": [
          50728,
          2386,
          11,
          286,
          643,
          281,
          21022,
          264,
          7154,
          13,
          50808
        ]
      },
      {
        "avg_logprob": -0.18715316708348378,
        "compression_ratio": 1.5645933014354068,
        "end": 5602.08,
        "id": 1690,
        "no_speech_prob": 0.0002066292508970946,
        "seek": 558816,
        "start": 5599.04,
        "temperature": 0,
        "text": " And I want to go to this page here.",
        "tokens": [
          50908,
          400,
          286,
          528,
          281,
          352,
          281,
          341,
          3028,
          510,
          13,
          51060
        ]
      },
      {
        "avg_logprob": -0.18715316708348378,
        "compression_ratio": 1.5645933014354068,
        "end": 5603.46,
        "id": 1691,
        "no_speech_prob": 0.0002066292508970946,
        "seek": 558816,
        "start": 5602.96,
        "temperature": 0,
        "text": " The...",
        "tokens": [
          51104,
          440,
          485,
          51129
        ]
      },
      {
        "avg_logprob": -0.18715316708348378,
        "compression_ratio": 1.5645933014354068,
        "end": 5604.72,
        "id": 1692,
        "no_speech_prob": 0.0002066292508970946,
        "seek": 558816,
        "start": 5604,
        "temperature": 0,
        "text": " Here.",
        "tokens": [
          51156,
          1692,
          13,
          51192
        ]
      },
      {
        "avg_logprob": -0.18715316708348378,
        "compression_ratio": 1.5645933014354068,
        "end": 5605.68,
        "id": 1693,
        "no_speech_prob": 0.0002066292508970946,
        "seek": 558816,
        "start": 5604.72,
        "temperature": 0,
        "text": " Which I should see this.",
        "tokens": [
          51192,
          3013,
          286,
          820,
          536,
          341,
          13,
          51240
        ]
      },
      {
        "avg_logprob": -0.18715316708348378,
        "compression_ratio": 1.5645933014354068,
        "end": 5607.599999999999,
        "id": 1694,
        "no_speech_prob": 0.0002066292508970946,
        "seek": 558816,
        "start": 5605.68,
        "temperature": 0,
        "text": " I want to look at the console.",
        "tokens": [
          51240,
          286,
          528,
          281,
          574,
          412,
          264,
          11076,
          13,
          51336
        ]
      },
      {
        "avg_logprob": -0.18715316708348378,
        "compression_ratio": 1.5645933014354068,
        "end": 5608.72,
        "id": 1695,
        "no_speech_prob": 0.0002066292508970946,
        "seek": 558816,
        "start": 5607.599999999999,
        "temperature": 0,
        "text": " And now if I...",
        "tokens": [
          51336,
          400,
          586,
          498,
          286,
          485,
          51392
        ]
      },
      {
        "avg_logprob": -0.18715316708348378,
        "compression_ratio": 1.5645933014354068,
        "end": 5610.24,
        "id": 1696,
        "no_speech_prob": 0.0002066292508970946,
        "seek": 558816,
        "start": 5608.72,
        "temperature": 0,
        "text": " This is a test.",
        "tokens": [
          51392,
          639,
          307,
          257,
          1500,
          13,
          51468
        ]
      },
      {
        "avg_logprob": -0.18715316708348378,
        "compression_ratio": 1.5645933014354068,
        "end": 5611.599999999999,
        "id": 1697,
        "no_speech_prob": 0.0002066292508970946,
        "seek": 558816,
        "start": 5610.24,
        "temperature": 0,
        "text": " And I hit analyze.",
        "tokens": [
          51468,
          400,
          286,
          2045,
          12477,
          13,
          51536
        ]
      },
      {
        "avg_logprob": -0.18715316708348378,
        "compression_ratio": 1.5645933014354068,
        "end": 5613.12,
        "id": 1698,
        "no_speech_prob": 0.0002066292508970946,
        "seek": 558816,
        "start": 5611.599999999999,
        "temperature": 0,
        "text": " I got the message back.",
        "tokens": [
          51536,
          286,
          658,
          264,
          3636,
          646,
          13,
          51612
        ]
      },
      {
        "avg_logprob": -0.18715316708348378,
        "compression_ratio": 1.5645933014354068,
        "end": 5614.88,
        "id": 1699,
        "no_speech_prob": 0.0002066292508970946,
        "seek": 558816,
        "start": 5613.12,
        "temperature": 0,
        "text": " So the round trip happened.",
        "tokens": [
          51612,
          407,
          264,
          3098,
          4931,
          2011,
          13,
          51700
        ]
      },
      {
        "avg_logprob": -0.23668752034505208,
        "compression_ratio": 1.6885813148788926,
        "end": 5619.28,
        "id": 1700,
        "no_speech_prob": 0.0006986733642406762,
        "seek": 561488,
        "start": 5615.84,
        "temperature": 0,
        "text": " The question now is let's look at what's in the request.",
        "tokens": [
          50412,
          440,
          1168,
          586,
          307,
          718,
          311,
          574,
          412,
          437,
          311,
          294,
          264,
          5308,
          13,
          50584
        ]
      },
      {
        "avg_logprob": -0.23668752034505208,
        "compression_ratio": 1.6885813148788926,
        "end": 5620.400000000001,
        "id": 1701,
        "no_speech_prob": 0.0006986733642406762,
        "seek": 561488,
        "start": 5619.28,
        "temperature": 0,
        "text": " Oh my goodness.",
        "tokens": [
          50584,
          876,
          452,
          8387,
          13,
          50640
        ]
      },
      {
        "avg_logprob": -0.23668752034505208,
        "compression_ratio": 1.6885813148788926,
        "end": 5624.24,
        "id": 1702,
        "no_speech_prob": 0.0006986733642406762,
        "seek": 561488,
        "start": 5620.400000000001,
        "temperature": 0,
        "text": " How am I ever going to look through all this and find the data that was posted?",
        "tokens": [
          50640,
          1012,
          669,
          286,
          1562,
          516,
          281,
          574,
          807,
          439,
          341,
          293,
          915,
          264,
          1412,
          300,
          390,
          9437,
          30,
          50832
        ]
      },
      {
        "avg_logprob": -0.23668752034505208,
        "compression_ratio": 1.6885813148788926,
        "end": 5625.2,
        "id": 1703,
        "no_speech_prob": 0.0006986733642406762,
        "seek": 561488,
        "start": 5624.24,
        "temperature": 0,
        "text": " So here's the thing.",
        "tokens": [
          50832,
          407,
          510,
          311,
          264,
          551,
          13,
          50880
        ]
      },
      {
        "avg_logprob": -0.23668752034505208,
        "compression_ratio": 1.6885813148788926,
        "end": 5628.64,
        "id": 1704,
        "no_speech_prob": 0.0006986733642406762,
        "seek": 561488,
        "start": 5627.92,
        "temperature": 0,
        "text": " Pause.",
        "tokens": [
          51016,
          31973,
          13,
          51052
        ]
      },
      {
        "avg_logprob": -0.23668752034505208,
        "compression_ratio": 1.6885813148788926,
        "end": 5629.28,
        "id": 1705,
        "no_speech_prob": 0.0006986733642406762,
        "seek": 561488,
        "start": 5628.64,
        "temperature": 0,
        "text": " Time out.",
        "tokens": [
          51052,
          6161,
          484,
          13,
          51084
        ]
      },
      {
        "avg_logprob": -0.23668752034505208,
        "compression_ratio": 1.6885813148788926,
        "end": 5632.8,
        "id": 1706,
        "no_speech_prob": 0.0006986733642406762,
        "seek": 561488,
        "start": 5632.400000000001,
        "temperature": 0,
        "text": " Oh, by...",
        "tokens": [
          51240,
          876,
          11,
          538,
          485,
          51260
        ]
      },
      {
        "avg_logprob": -0.23668752034505208,
        "compression_ratio": 1.6885813148788926,
        "end": 5633.84,
        "id": 1707,
        "no_speech_prob": 0.0006986733642406762,
        "seek": 561488,
        "start": 5632.8,
        "temperature": 0,
        "text": " So if somebody in the chat, by the way...",
        "tokens": [
          51260,
          407,
          498,
          2618,
          294,
          264,
          5081,
          11,
          538,
          264,
          636,
          485,
          51312
        ]
      },
      {
        "avg_logprob": -0.23668752034505208,
        "compression_ratio": 1.6885813148788926,
        "end": 5635.52,
        "id": 1708,
        "no_speech_prob": 0.0006986733642406762,
        "seek": 561488,
        "start": 5633.84,
        "temperature": 0,
        "text": " So this part's going to have to get edited out.",
        "tokens": [
          51312,
          407,
          341,
          644,
          311,
          516,
          281,
          362,
          281,
          483,
          23016,
          484,
          13,
          51396
        ]
      },
      {
        "avg_logprob": -0.23668752034505208,
        "compression_ratio": 1.6885813148788926,
        "end": 5636.400000000001,
        "id": 1709,
        "no_speech_prob": 0.0006986733642406762,
        "seek": 561488,
        "start": 5635.52,
        "temperature": 0,
        "text": " Thank you, Matia.",
        "tokens": [
          51396,
          1044,
          291,
          11,
          6789,
          654,
          13,
          51440
        ]
      },
      {
        "avg_logprob": -0.23668752034505208,
        "compression_ratio": 1.6885813148788926,
        "end": 5638.96,
        "id": 1710,
        "no_speech_prob": 0.0006986733642406762,
        "seek": 561488,
        "start": 5636.400000000001,
        "temperature": 0,
        "text": " Somebody in the chat says I keep changing my localhost port.",
        "tokens": [
          51440,
          13463,
          294,
          264,
          5081,
          1619,
          286,
          1066,
          4473,
          452,
          2654,
          6037,
          2436,
          13,
          51568
        ]
      },
      {
        "avg_logprob": -0.23668752034505208,
        "compression_ratio": 1.6885813148788926,
        "end": 5642.88,
        "id": 1711,
        "no_speech_prob": 0.0006986733642406762,
        "seek": 561488,
        "start": 5638.96,
        "temperature": 0,
        "text": " So I'm using a different port for the node stuff as when I run like a Python server.",
        "tokens": [
          51568,
          407,
          286,
          478,
          1228,
          257,
          819,
          2436,
          337,
          264,
          9984,
          1507,
          382,
          562,
          286,
          1190,
          411,
          257,
          15329,
          7154,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.23668752034505208,
        "compression_ratio": 1.6885813148788926,
        "end": 5644.16,
        "id": 1712,
        "no_speech_prob": 0.0006986733642406762,
        "seek": 561488,
        "start": 5642.88,
        "temperature": 0,
        "text": " But yes, I do keep changing that.",
        "tokens": [
          51764,
          583,
          2086,
          11,
          286,
          360,
          1066,
          4473,
          300,
          13,
          51828
        ]
      },
      {
        "avg_logprob": -0.2000058859833016,
        "compression_ratio": 1.6595744680851063,
        "end": 5647.599999999999,
        "id": 1713,
        "no_speech_prob": 0.00009314527414971963,
        "seek": 564416,
        "start": 5644.16,
        "temperature": 0,
        "text": " So I need to look something up because I forgot what it is.",
        "tokens": [
          50364,
          407,
          286,
          643,
          281,
          574,
          746,
          493,
          570,
          286,
          5298,
          437,
          309,
          307,
          13,
          50536
        ]
      },
      {
        "avg_logprob": -0.2000058859833016,
        "compression_ratio": 1.6595744680851063,
        "end": 5651.84,
        "id": 1714,
        "no_speech_prob": 0.00009314527414971963,
        "seek": 564416,
        "start": 5648.72,
        "temperature": 0,
        "text": " And I just want to not look it up in the video tutorial.",
        "tokens": [
          50592,
          400,
          286,
          445,
          528,
          281,
          406,
          574,
          309,
          493,
          294,
          264,
          960,
          7073,
          13,
          50748
        ]
      },
      {
        "avg_logprob": -0.2000058859833016,
        "compression_ratio": 1.6595744680851063,
        "end": 5653.2,
        "id": 1715,
        "no_speech_prob": 0.00009314527414971963,
        "seek": 564416,
        "start": 5651.84,
        "temperature": 0,
        "text": " I want to act like I know what I'm doing.",
        "tokens": [
          50748,
          286,
          528,
          281,
          605,
          411,
          286,
          458,
          437,
          286,
          478,
          884,
          13,
          50816
        ]
      },
      {
        "avg_logprob": -0.2000058859833016,
        "compression_ratio": 1.6595744680851063,
        "end": 5655.12,
        "id": 1716,
        "no_speech_prob": 0.00009314527414971963,
        "seek": 564416,
        "start": 5653.84,
        "temperature": 0,
        "text": " Because I particularly do not.",
        "tokens": [
          50848,
          1436,
          286,
          4098,
          360,
          406,
          13,
          50912
        ]
      },
      {
        "avg_logprob": -0.2000058859833016,
        "compression_ratio": 1.6595744680851063,
        "end": 5660.24,
        "id": 1717,
        "no_speech_prob": 0.00009314527414971963,
        "seek": 564416,
        "start": 5656,
        "temperature": 0,
        "text": " And I'm going to go to node API.",
        "tokens": [
          50956,
          400,
          286,
          478,
          516,
          281,
          352,
          281,
          9984,
          9362,
          13,
          51168
        ]
      },
      {
        "avg_logprob": -0.2000058859833016,
        "compression_ratio": 1.6595744680851063,
        "end": 5662.4,
        "id": 1718,
        "no_speech_prob": 0.00009314527414971963,
        "seek": 564416,
        "start": 5660.24,
        "temperature": 0,
        "text": " Maybe this one's actually going to have a simpler one.",
        "tokens": [
          51168,
          2704,
          341,
          472,
          311,
          767,
          516,
          281,
          362,
          257,
          18587,
          472,
          13,
          51276
        ]
      },
      {
        "avg_logprob": -0.2000058859833016,
        "compression_ratio": 1.6595744680851063,
        "end": 5665.2,
        "id": 1719,
        "no_speech_prob": 0.00009314527414971963,
        "seek": 564416,
        "start": 5663.84,
        "temperature": 0,
        "text": " No, this one won't have the post.",
        "tokens": [
          51348,
          883,
          11,
          341,
          472,
          1582,
          380,
          362,
          264,
          2183,
          13,
          51416
        ]
      },
      {
        "avg_logprob": -0.2000058859833016,
        "compression_ratio": 1.6595744680851063,
        "end": 5667.12,
        "id": 1720,
        "no_speech_prob": 0.00009314527414971963,
        "seek": 564416,
        "start": 5666.16,
        "temperature": 0,
        "text": " This is an example.",
        "tokens": [
          51464,
          639,
          307,
          364,
          1365,
          13,
          51512
        ]
      },
      {
        "avg_logprob": -0.2000058859833016,
        "compression_ratio": 1.6595744680851063,
        "end": 5671.5199999999995,
        "id": 1721,
        "no_speech_prob": 0.00009314527414971963,
        "seek": 564416,
        "start": 5668.08,
        "temperature": 0,
        "text": " Oh, this is a totally different one that I made.",
        "tokens": [
          51560,
          876,
          11,
          341,
          307,
          257,
          3879,
          819,
          472,
          300,
          286,
          1027,
          13,
          51732
        ]
      },
      {
        "avg_logprob": -0.2000058859833016,
        "compression_ratio": 1.6595744680851063,
        "end": 5672.5599999999995,
        "id": 1722,
        "no_speech_prob": 0.00009314527414971963,
        "seek": 564416,
        "start": 5671.5199999999995,
        "temperature": 0,
        "text": " Oh, yeah.",
        "tokens": [
          51732,
          876,
          11,
          1338,
          13,
          51784
        ]
      },
      {
        "avg_logprob": -0.19474310689158253,
        "compression_ratio": 1.4746835443037976,
        "end": 5674,
        "id": 1723,
        "no_speech_prob": 0.0007436835439875722,
        "seek": 567256,
        "start": 5672.56,
        "temperature": 0,
        "text": " So I need this.",
        "tokens": [
          50364,
          407,
          286,
          643,
          341,
          13,
          50436
        ]
      },
      {
        "avg_logprob": -0.19474310689158253,
        "compression_ratio": 1.4746835443037976,
        "end": 5677.68,
        "id": 1724,
        "no_speech_prob": 0.0007436835439875722,
        "seek": 567256,
        "start": 5675.6,
        "temperature": 0,
        "text": " I need the body parser package.",
        "tokens": [
          50516,
          286,
          643,
          264,
          1772,
          21156,
          260,
          7372,
          13,
          50620
        ]
      },
      {
        "avg_logprob": -0.19474310689158253,
        "compression_ratio": 1.4746835443037976,
        "end": 5685.52,
        "id": 1725,
        "no_speech_prob": 0.0007436835439875722,
        "seek": 567256,
        "start": 5678.400000000001,
        "temperature": 0,
        "text": " So let's look for that body parser node package.",
        "tokens": [
          50656,
          407,
          718,
          311,
          574,
          337,
          300,
          1772,
          21156,
          260,
          9984,
          7372,
          13,
          51012
        ]
      },
      {
        "avg_logprob": -0.19474310689158253,
        "compression_ratio": 1.4746835443037976,
        "end": 5691.92,
        "id": 1726,
        "no_speech_prob": 0.0007436835439875722,
        "seek": 567256,
        "start": 5689.52,
        "temperature": 0,
        "text": " And I just want to look it up on GitHub.",
        "tokens": [
          51212,
          400,
          286,
          445,
          528,
          281,
          574,
          309,
          493,
          322,
          23331,
          13,
          51332
        ]
      },
      {
        "avg_logprob": -0.19474310689158253,
        "compression_ratio": 1.4746835443037976,
        "end": 5697.04,
        "id": 1727,
        "no_speech_prob": 0.0007436835439875722,
        "seek": 567256,
        "start": 5692.4800000000005,
        "temperature": 0,
        "text": " Because let's see if there is a very simple example.",
        "tokens": [
          51360,
          1436,
          718,
          311,
          536,
          498,
          456,
          307,
          257,
          588,
          2199,
          1365,
          13,
          51588
        ]
      },
      {
        "avg_logprob": -0.19474310689158253,
        "compression_ratio": 1.4746835443037976,
        "end": 5699.84,
        "id": 1728,
        "no_speech_prob": 0.0007436835439875722,
        "seek": 567256,
        "start": 5698.64,
        "temperature": 0,
        "text": " Oh, why isn't there like a...",
        "tokens": [
          51668,
          876,
          11,
          983,
          1943,
          380,
          456,
          411,
          257,
          485,
          51728
        ]
      },
      {
        "avg_logprob": -0.19474310689158253,
        "compression_ratio": 1.4746835443037976,
        "end": 5700.320000000001,
        "id": 1729,
        "no_speech_prob": 0.0007436835439875722,
        "seek": 567256,
        "start": 5699.84,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51728,
          821,
          321,
          352,
          13,
          51752
        ]
      },
      {
        "avg_logprob": -0.6226117835854584,
        "compression_ratio": 1.5025125628140703,
        "end": 5702.08,
        "id": 1730,
        "no_speech_prob": 0.00047284827451221645,
        "seek": 570032,
        "start": 5700.48,
        "temperature": 0,
        "text": " So I'm just looking at this.",
        "tokens": [
          50372,
          407,
          286,
          478,
          445,
          1237,
          412,
          341,
          13,
          50452
        ]
      },
      {
        "avg_logprob": -0.6226117835854584,
        "compression_ratio": 1.5025125628140703,
        "end": 5706.48,
        "id": 1731,
        "no_speech_prob": 0.00047284827451221645,
        "seek": 570032,
        "start": 5704.96,
        "temperature": 0,
        "text": " So this is the example.",
        "tokens": [
          50596,
          407,
          341,
          307,
          264,
          1365,
          13,
          50672
        ]
      },
      {
        "avg_logprob": -0.6226117835854584,
        "compression_ratio": 1.5025125628140703,
        "end": 5711.28,
        "id": 1732,
        "no_speech_prob": 0.00047284827451221645,
        "seek": 570032,
        "start": 5706.48,
        "temperature": 0,
        "text": " And then in my example, is that the same body parser.json?",
        "tokens": [
          50672,
          400,
          550,
          294,
          452,
          1365,
          11,
          307,
          300,
          264,
          912,
          1772,
          21156,
          260,
          13,
          73,
          3015,
          30,
          50912
        ]
      },
      {
        "avg_logprob": -0.6226117835854584,
        "compression_ratio": 1.5025125628140703,
        "end": 5712.96,
        "id": 1733,
        "no_speech_prob": 0.00047284827451221645,
        "seek": 570032,
        "start": 5712.4,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          50968,
          1079,
          13,
          50996
        ]
      },
      {
        "avg_logprob": -0.6226117835854584,
        "compression_ratio": 1.5025125628140703,
        "end": 5717.759999999999,
        "id": 1734,
        "no_speech_prob": 0.00047284827451221645,
        "seek": 570032,
        "start": 5713.92,
        "temperature": 0,
        "text": " And app.usebodyparser, URL encoded, extended true.",
        "tokens": [
          51044,
          400,
          724,
          13,
          438,
          1067,
          79,
          685,
          260,
          11,
          12905,
          2058,
          12340,
          11,
          10913,
          2074,
          13,
          51236
        ]
      },
      {
        "avg_logprob": -0.6226117835854584,
        "compression_ratio": 1.5025125628140703,
        "end": 5719.759999999999,
        "id": 1735,
        "no_speech_prob": 0.00047284827451221645,
        "seek": 570032,
        "start": 5718.799999999999,
        "temperature": 0,
        "text": " Extended false.",
        "tokens": [
          51288,
          9881,
          3502,
          7908,
          13,
          51336
        ]
      },
      {
        "avg_logprob": -0.6226117835854584,
        "compression_ratio": 1.5025125628140703,
        "end": 5720.32,
        "id": 1736,
        "no_speech_prob": 0.00047284827451221645,
        "seek": 570032,
        "start": 5719.759999999999,
        "temperature": 0,
        "text": " Whatever.",
        "tokens": [
          51336,
          8541,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.6226117835854584,
        "compression_ratio": 1.5025125628140703,
        "end": 5725.04,
        "id": 1737,
        "no_speech_prob": 0.00047284827451221645,
        "seek": 570032,
        "start": 5721.04,
        "temperature": 0,
        "text": " And then what I did is...",
        "tokens": [
          51400,
          400,
          550,
          437,
          286,
          630,
          307,
          485,
          51600
        ]
      },
      {
        "avg_logprob": -0.6226117835854584,
        "compression_ratio": 1.5025125628140703,
        "end": 5726.24,
        "id": 1738,
        "no_speech_prob": 0.00047284827451221645,
        "seek": 570032,
        "start": 5725.04,
        "temperature": 0,
        "text": " I know you probably can't see it.",
        "tokens": [
          51600,
          286,
          458,
          291,
          1391,
          393,
          380,
          536,
          309,
          13,
          51660
        ]
      },
      {
        "avg_logprob": -0.6226117835854584,
        "compression_ratio": 1.5025125628140703,
        "end": 5727.84,
        "id": 1739,
        "no_speech_prob": 0.00047284827451221645,
        "seek": 570032,
        "start": 5726.24,
        "temperature": 0,
        "text": " But I'm just going to do a little bit of a...",
        "tokens": [
          51660,
          583,
          286,
          478,
          445,
          516,
          281,
          360,
          257,
          707,
          857,
          295,
          257,
          485,
          51740
        ]
      },
      {
        "avg_logprob": -0.2552435057503836,
        "compression_ratio": 1.368421052631579,
        "end": 5729.06,
        "id": 1740,
        "no_speech_prob": 0.03258856013417244,
        "seek": 572784,
        "start": 5728.56,
        "temperature": 0,
        "text": " Is...",
        "tokens": [
          50400,
          1119,
          485,
          50425
        ]
      },
      {
        "avg_logprob": -0.2552435057503836,
        "compression_ratio": 1.368421052631579,
        "end": 5730.88,
        "id": 1741,
        "no_speech_prob": 0.03258856013417244,
        "seek": 572784,
        "start": 5729.12,
        "temperature": 0,
        "text": " I know you probably can't see this.",
        "tokens": [
          50428,
          286,
          458,
          291,
          1391,
          393,
          380,
          536,
          341,
          13,
          50516
        ]
      },
      {
        "avg_logprob": -0.2552435057503836,
        "compression_ratio": 1.368421052631579,
        "end": 5731.92,
        "id": 1742,
        "no_speech_prob": 0.03258856013417244,
        "seek": 572784,
        "start": 5730.88,
        "temperature": 0,
        "text": " I'm just looking this up.",
        "tokens": [
          50516,
          286,
          478,
          445,
          1237,
          341,
          493,
          13,
          50568
        ]
      },
      {
        "avg_logprob": -0.2552435057503836,
        "compression_ratio": 1.368421052631579,
        "end": 5733.84,
        "id": 1743,
        "no_speech_prob": 0.03258856013417244,
        "seek": 572784,
        "start": 5731.92,
        "temperature": 0,
        "text": " Request.body.text.",
        "tokens": [
          50568,
          1300,
          20343,
          13,
          1067,
          13,
          25111,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2552435057503836,
        "compression_ratio": 1.368421052631579,
        "end": 5734.4800000000005,
        "id": 1744,
        "no_speech_prob": 0.03258856013417244,
        "seek": 572784,
        "start": 5733.84,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50664,
          1033,
          13,
          50696
        ]
      },
      {
        "avg_logprob": -0.2552435057503836,
        "compression_ratio": 1.368421052631579,
        "end": 5736.32,
        "id": 1745,
        "no_speech_prob": 0.03258856013417244,
        "seek": 572784,
        "start": 5734.4800000000005,
        "temperature": 0,
        "text": " So that should do it.",
        "tokens": [
          50696,
          407,
          300,
          820,
          360,
          309,
          13,
          50788
        ]
      },
      {
        "avg_logprob": -0.2552435057503836,
        "compression_ratio": 1.368421052631579,
        "end": 5736.82,
        "id": 1746,
        "no_speech_prob": 0.03258856013417244,
        "seek": 572784,
        "start": 5736.32,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50788,
          1033,
          13,
          50813
        ]
      },
      {
        "avg_logprob": -0.2552435057503836,
        "compression_ratio": 1.368421052631579,
        "end": 5741.2,
        "id": 1747,
        "no_speech_prob": 0.03258856013417244,
        "seek": 572784,
        "start": 5740.400000000001,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50992,
          1033,
          13,
          51032
        ]
      },
      {
        "avg_logprob": -0.2552435057503836,
        "compression_ratio": 1.368421052631579,
        "end": 5744.32,
        "id": 1748,
        "no_speech_prob": 0.03258856013417244,
        "seek": 572784,
        "start": 5741.2,
        "temperature": 0,
        "text": " So I am good here.",
        "tokens": [
          51032,
          407,
          286,
          669,
          665,
          510,
          13,
          51188
        ]
      },
      {
        "avg_logprob": -0.2552435057503836,
        "compression_ratio": 1.368421052631579,
        "end": 5746.32,
        "id": 1749,
        "no_speech_prob": 0.03258856013417244,
        "seek": 572784,
        "start": 5746,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51272,
          1033,
          13,
          51288
        ]
      },
      {
        "avg_logprob": -0.2552435057503836,
        "compression_ratio": 1.368421052631579,
        "end": 5747.92,
        "id": 1750,
        "no_speech_prob": 0.03258856013417244,
        "seek": 572784,
        "start": 5746.32,
        "temperature": 0,
        "text": " So where was I?",
        "tokens": [
          51288,
          407,
          689,
          390,
          286,
          30,
          51368
        ]
      },
      {
        "avg_logprob": -0.2552435057503836,
        "compression_ratio": 1.368421052631579,
        "end": 5748.4800000000005,
        "id": 1751,
        "no_speech_prob": 0.03258856013417244,
        "seek": 572784,
        "start": 5747.92,
        "temperature": 0,
        "text": " Ah, yes.",
        "tokens": [
          51368,
          2438,
          11,
          2086,
          13,
          51396
        ]
      },
      {
        "avg_logprob": -0.2552435057503836,
        "compression_ratio": 1.368421052631579,
        "end": 5750.82,
        "id": 1752,
        "no_speech_prob": 0.03258856013417244,
        "seek": 572784,
        "start": 5750.32,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51488,
          1033,
          13,
          51513
        ]
      },
      {
        "avg_logprob": -0.19864303286712948,
        "compression_ratio": 1.721951219512195,
        "end": 5752.28,
        "id": 1753,
        "no_speech_prob": 0.00031503784703090787,
        "seek": 575082,
        "start": 5751.78,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          50412,
          865,
          13,
          50437
        ]
      },
      {
        "avg_logprob": -0.19864303286712948,
        "compression_ratio": 1.721951219512195,
        "end": 5759.219999999999,
        "id": 1754,
        "no_speech_prob": 0.00031503784703090787,
        "seek": 575082,
        "start": 5756.5,
        "temperature": 0,
        "text": " How do I find that text?",
        "tokens": [
          50648,
          1012,
          360,
          286,
          915,
          300,
          2487,
          30,
          50784
        ]
      },
      {
        "avg_logprob": -0.19864303286712948,
        "compression_ratio": 1.721951219512195,
        "end": 5761.94,
        "id": 1755,
        "no_speech_prob": 0.00031503784703090787,
        "seek": 575082,
        "start": 5759.219999999999,
        "temperature": 0,
        "text": " This is a mess of data that comes in with the request.",
        "tokens": [
          50784,
          639,
          307,
          257,
          2082,
          295,
          1412,
          300,
          1487,
          294,
          365,
          264,
          5308,
          13,
          50920
        ]
      },
      {
        "avg_logprob": -0.19864303286712948,
        "compression_ratio": 1.721951219512195,
        "end": 5767.0599999999995,
        "id": 1756,
        "no_speech_prob": 0.00031503784703090787,
        "seek": 575082,
        "start": 5761.94,
        "temperature": 0,
        "text": " Now we know if you go back to the server when I had a get request.",
        "tokens": [
          50920,
          823,
          321,
          458,
          498,
          291,
          352,
          646,
          281,
          264,
          7154,
          562,
          286,
          632,
          257,
          483,
          5308,
          13,
          51176
        ]
      },
      {
        "avg_logprob": -0.19864303286712948,
        "compression_ratio": 1.721951219512195,
        "end": 5770.42,
        "id": 1757,
        "no_speech_prob": 0.00031503784703090787,
        "seek": 575082,
        "start": 5767.0599999999995,
        "temperature": 0,
        "text": " I can simply just look at the request's parameters.",
        "tokens": [
          51176,
          286,
          393,
          2935,
          445,
          574,
          412,
          264,
          5308,
          311,
          9834,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.19864303286712948,
        "compression_ratio": 1.721951219512195,
        "end": 5773.7,
        "id": 1758,
        "no_speech_prob": 0.00031503784703090787,
        "seek": 575082,
        "start": 5770.42,
        "temperature": 0,
        "text": " Because these are the parameters that come in with the request with a get.",
        "tokens": [
          51344,
          1436,
          613,
          366,
          264,
          9834,
          300,
          808,
          294,
          365,
          264,
          5308,
          365,
          257,
          483,
          13,
          51508
        ]
      },
      {
        "avg_logprob": -0.19864303286712948,
        "compression_ratio": 1.721951219512195,
        "end": 5776.34,
        "id": 1759,
        "no_speech_prob": 0.00031503784703090787,
        "seek": 575082,
        "start": 5773.7,
        "temperature": 0,
        "text": " With a post request, it's not so simple.",
        "tokens": [
          51508,
          2022,
          257,
          2183,
          5308,
          11,
          309,
          311,
          406,
          370,
          2199,
          13,
          51640
        ]
      },
      {
        "avg_logprob": -0.19864303286712948,
        "compression_ratio": 1.721951219512195,
        "end": 5778.259999999999,
        "id": 1760,
        "no_speech_prob": 0.00031503784703090787,
        "seek": 575082,
        "start": 5776.34,
        "temperature": 0,
        "text": " There isn't just the parameters.",
        "tokens": [
          51640,
          821,
          1943,
          380,
          445,
          264,
          9834,
          13,
          51736
        ]
      },
      {
        "avg_logprob": -0.1877850890159607,
        "compression_ratio": 1.8878923766816142,
        "end": 5782.66,
        "id": 1761,
        "no_speech_prob": 0.0029809779953211546,
        "seek": 577826,
        "start": 5778.26,
        "temperature": 0,
        "text": " There's this part of it called the body which has all this information in it.",
        "tokens": [
          50364,
          821,
          311,
          341,
          644,
          295,
          309,
          1219,
          264,
          1772,
          597,
          575,
          439,
          341,
          1589,
          294,
          309,
          13,
          50584
        ]
      },
      {
        "avg_logprob": -0.1877850890159607,
        "compression_ratio": 1.8878923766816142,
        "end": 5783.62,
        "id": 1762,
        "no_speech_prob": 0.0029809779953211546,
        "seek": 577826,
        "start": 5782.66,
        "temperature": 0,
        "text": " And I actually...",
        "tokens": [
          50584,
          400,
          286,
          767,
          485,
          50632
        ]
      },
      {
        "avg_logprob": -0.1877850890159607,
        "compression_ratio": 1.8878923766816142,
        "end": 5785.14,
        "id": 1763,
        "no_speech_prob": 0.0029809779953211546,
        "seek": 577826,
        "start": 5784.18,
        "temperature": 0,
        "text": " And I have to parse it.",
        "tokens": [
          50660,
          400,
          286,
          362,
          281,
          48377,
          309,
          13,
          50708
        ]
      },
      {
        "avg_logprob": -0.1877850890159607,
        "compression_ratio": 1.8878923766816142,
        "end": 5790.42,
        "id": 1764,
        "no_speech_prob": 0.0029809779953211546,
        "seek": 577826,
        "start": 5786.18,
        "temperature": 0,
        "text": " Luckily for us, there's a node package which will do this parsing for us.",
        "tokens": [
          50760,
          19726,
          337,
          505,
          11,
          456,
          311,
          257,
          9984,
          7372,
          597,
          486,
          360,
          341,
          21156,
          278,
          337,
          505,
          13,
          50972
        ]
      },
      {
        "avg_logprob": -0.1877850890159607,
        "compression_ratio": 1.8878923766816142,
        "end": 5791.38,
        "id": 1765,
        "no_speech_prob": 0.0029809779953211546,
        "seek": 577826,
        "start": 5790.42,
        "temperature": 0,
        "text": " And this parsing...",
        "tokens": [
          50972,
          400,
          341,
          21156,
          278,
          485,
          51020
        ]
      },
      {
        "avg_logprob": -0.1877850890159607,
        "compression_ratio": 1.8878923766816142,
        "end": 5794.26,
        "id": 1766,
        "no_speech_prob": 0.0029809779953211546,
        "seek": 577826,
        "start": 5792.02,
        "temperature": 0,
        "text": " This package is called body parser.",
        "tokens": [
          51052,
          639,
          7372,
          307,
          1219,
          1772,
          21156,
          260,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1877850890159607,
        "compression_ratio": 1.8878923766816142,
        "end": 5798.5,
        "id": 1767,
        "no_speech_prob": 0.0029809779953211546,
        "seek": 577826,
        "start": 5794.26,
        "temperature": 0,
        "text": " So what I need to do is I need to install that package.",
        "tokens": [
          51164,
          407,
          437,
          286,
          643,
          281,
          360,
          307,
          286,
          643,
          281,
          3625,
          300,
          7372,
          13,
          51376
        ]
      },
      {
        "avg_logprob": -0.1877850890159607,
        "compression_ratio": 1.8878923766816142,
        "end": 5800.26,
        "id": 1768,
        "no_speech_prob": 0.0029809779953211546,
        "seek": 577826,
        "start": 5798.5,
        "temperature": 0,
        "text": " Body parser.",
        "tokens": [
          51376,
          21329,
          21156,
          260,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1877850890159607,
        "compression_ratio": 1.8878923766816142,
        "end": 5804.18,
        "id": 1769,
        "no_speech_prob": 0.0029809779953211546,
        "seek": 577826,
        "start": 5801.7,
        "temperature": 0,
        "text": " And I want to save that as part of this project.",
        "tokens": [
          51536,
          400,
          286,
          528,
          281,
          3155,
          300,
          382,
          644,
          295,
          341,
          1716,
          13,
          51660
        ]
      },
      {
        "avg_logprob": -0.1877850890159607,
        "compression_ratio": 1.8878923766816142,
        "end": 5804.900000000001,
        "id": 1770,
        "no_speech_prob": 0.0029809779953211546,
        "seek": 577826,
        "start": 5804.18,
        "temperature": 0,
        "text": " So I'm saving it.",
        "tokens": [
          51660,
          407,
          286,
          478,
          6816,
          309,
          13,
          51696
        ]
      },
      {
        "avg_logprob": -0.1877850890159607,
        "compression_ratio": 1.8878923766816142,
        "end": 5806.900000000001,
        "id": 1771,
        "no_speech_prob": 0.0029809779953211546,
        "seek": 577826,
        "start": 5804.900000000001,
        "temperature": 0,
        "text": " Now I have the body parser package.",
        "tokens": [
          51696,
          823,
          286,
          362,
          264,
          1772,
          21156,
          260,
          7372,
          13,
          51796
        ]
      },
      {
        "avg_logprob": -0.17204157043905818,
        "compression_ratio": 1.7137546468401488,
        "end": 5807.94,
        "id": 1772,
        "no_speech_prob": 0.0011335451854392886,
        "seek": 580690,
        "start": 5806.9,
        "temperature": 0,
        "text": " And then what I want to do...",
        "tokens": [
          50364,
          400,
          550,
          437,
          286,
          528,
          281,
          360,
          485,
          50416
        ]
      },
      {
        "avg_logprob": -0.17204157043905818,
        "compression_ratio": 1.7137546468401488,
        "end": 5811.139999999999,
        "id": 1773,
        "no_speech_prob": 0.0011335451854392886,
        "seek": 580690,
        "start": 5809.379999999999,
        "temperature": 0,
        "text": " I'll include a link in this video's description.",
        "tokens": [
          50488,
          286,
          603,
          4090,
          257,
          2113,
          294,
          341,
          960,
          311,
          3855,
          13,
          50576
        ]
      },
      {
        "avg_logprob": -0.17204157043905818,
        "compression_ratio": 1.7137546468401488,
        "end": 5812.58,
        "id": 1774,
        "no_speech_prob": 0.0011335451854392886,
        "seek": 580690,
        "start": 5811.139999999999,
        "temperature": 0,
        "text": " But I'm on the GitHub repository.",
        "tokens": [
          50576,
          583,
          286,
          478,
          322,
          264,
          23331,
          25841,
          13,
          50648
        ]
      },
      {
        "avg_logprob": -0.17204157043905818,
        "compression_ratio": 1.7137546468401488,
        "end": 5813.62,
        "id": 1775,
        "no_speech_prob": 0.0011335451854392886,
        "seek": 580690,
        "start": 5812.58,
        "temperature": 0,
        "text": " I just want to look at...",
        "tokens": [
          50648,
          286,
          445,
          528,
          281,
          574,
          412,
          485,
          50700
        ]
      },
      {
        "avg_logprob": -0.17204157043905818,
        "compression_ratio": 1.7137546468401488,
        "end": 5815.54,
        "id": 1776,
        "no_speech_prob": 0.0011335451854392886,
        "seek": 580690,
        "start": 5814.58,
        "temperature": 0,
        "text": " I need to require it.",
        "tokens": [
          50748,
          286,
          643,
          281,
          3651,
          309,
          13,
          50796
        ]
      },
      {
        "avg_logprob": -0.17204157043905818,
        "compression_ratio": 1.7137546468401488,
        "end": 5820.74,
        "id": 1777,
        "no_speech_prob": 0.0011335451854392886,
        "seek": 580690,
        "start": 5817.94,
        "temperature": 0,
        "text": " So I need to add it to my code at the top.",
        "tokens": [
          50916,
          407,
          286,
          643,
          281,
          909,
          309,
          281,
          452,
          3089,
          412,
          264,
          1192,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.17204157043905818,
        "compression_ratio": 1.7137546468401488,
        "end": 5821.299999999999,
        "id": 1778,
        "no_speech_prob": 0.0011335451854392886,
        "seek": 580690,
        "start": 5820.74,
        "temperature": 0,
        "text": " Or it doesn't really...",
        "tokens": [
          51056,
          1610,
          309,
          1177,
          380,
          534,
          485,
          51084
        ]
      },
      {
        "avg_logprob": -0.17204157043905818,
        "compression_ratio": 1.7137546468401488,
        "end": 5824.179999999999,
        "id": 1779,
        "no_speech_prob": 0.0011335451854392886,
        "seek": 580690,
        "start": 5821.299999999999,
        "temperature": 0,
        "text": " I'm going to add it here where I require express.",
        "tokens": [
          51084,
          286,
          478,
          516,
          281,
          909,
          309,
          510,
          689,
          286,
          3651,
          5109,
          13,
          51228
        ]
      },
      {
        "avg_logprob": -0.17204157043905818,
        "compression_ratio": 1.7137546468401488,
        "end": 5829.379999999999,
        "id": 1780,
        "no_speech_prob": 0.0011335451854392886,
        "seek": 580690,
        "start": 5824.82,
        "temperature": 0,
        "text": " And then after I create the app, this is serving static files.",
        "tokens": [
          51260,
          400,
          550,
          934,
          286,
          1884,
          264,
          724,
          11,
          341,
          307,
          8148,
          13437,
          7098,
          13,
          51488
        ]
      },
      {
        "avg_logprob": -0.17204157043905818,
        "compression_ratio": 1.7137546468401488,
        "end": 5831.94,
        "id": 1781,
        "no_speech_prob": 0.0011335451854392886,
        "seek": 580690,
        "start": 5829.379999999999,
        "temperature": 0,
        "text": " I now want to use this body parser package.",
        "tokens": [
          51488,
          286,
          586,
          528,
          281,
          764,
          341,
          1772,
          21156,
          260,
          7372,
          13,
          51616
        ]
      },
      {
        "avg_logprob": -0.17204157043905818,
        "compression_ratio": 1.7137546468401488,
        "end": 5835.78,
        "id": 1782,
        "no_speech_prob": 0.0011335451854392886,
        "seek": 580690,
        "start": 5831.94,
        "temperature": 0,
        "text": " So I'm going to just scroll all the way down here on this documentation page",
        "tokens": [
          51616,
          407,
          286,
          478,
          516,
          281,
          445,
          11369,
          439,
          264,
          636,
          760,
          510,
          322,
          341,
          14333,
          3028,
          51808
        ]
      },
      {
        "avg_logprob": -0.1631112061729727,
        "compression_ratio": 1.7549407114624507,
        "end": 5837.62,
        "id": 1783,
        "no_speech_prob": 0.0008969234768301249,
        "seek": 583578,
        "start": 5835.78,
        "temperature": 0,
        "text": " where I know there's a quick example.",
        "tokens": [
          50364,
          689,
          286,
          458,
          456,
          311,
          257,
          1702,
          1365,
          13,
          50456
        ]
      },
      {
        "avg_logprob": -0.1631112061729727,
        "compression_ratio": 1.7549407114624507,
        "end": 5838.98,
        "id": 1784,
        "no_speech_prob": 0.0008969234768301249,
        "seek": 583578,
        "start": 5837.62,
        "temperature": 0,
        "text": " And I can grab this code.",
        "tokens": [
          50456,
          400,
          286,
          393,
          4444,
          341,
          3089,
          13,
          50524
        ]
      },
      {
        "avg_logprob": -0.1631112061729727,
        "compression_ratio": 1.7549407114624507,
        "end": 5841.46,
        "id": 1785,
        "no_speech_prob": 0.0008969234768301249,
        "seek": 583578,
        "start": 5840.34,
        "temperature": 0,
        "text": " And I can add it in.",
        "tokens": [
          50592,
          400,
          286,
          393,
          909,
          309,
          294,
          13,
          50648
        ]
      },
      {
        "avg_logprob": -0.1631112061729727,
        "compression_ratio": 1.7549407114624507,
        "end": 5845.94,
        "id": 1786,
        "no_speech_prob": 0.0008969234768301249,
        "seek": 583578,
        "start": 5842.099999999999,
        "temperature": 0,
        "text": " So I now am telling this app, this web application,",
        "tokens": [
          50680,
          407,
          286,
          586,
          669,
          3585,
          341,
          724,
          11,
          341,
          3670,
          3861,
          11,
          50872
        ]
      },
      {
        "avg_logprob": -0.1631112061729727,
        "compression_ratio": 1.7549407114624507,
        "end": 5849.46,
        "id": 1787,
        "no_speech_prob": 0.0008969234768301249,
        "seek": 583578,
        "start": 5845.94,
        "temperature": 0,
        "text": " which is an express application that's listening on this port,",
        "tokens": [
          50872,
          597,
          307,
          364,
          5109,
          3861,
          300,
          311,
          4764,
          322,
          341,
          2436,
          11,
          51048
        ]
      },
      {
        "avg_logprob": -0.1631112061729727,
        "compression_ratio": 1.7549407114624507,
        "end": 5852.82,
        "id": 1788,
        "no_speech_prob": 0.0008969234768301249,
        "seek": 583578,
        "start": 5849.46,
        "temperature": 0,
        "text": " which uses static hosting for the stuff in the website folder,",
        "tokens": [
          51048,
          597,
          4960,
          13437,
          16058,
          337,
          264,
          1507,
          294,
          264,
          3144,
          10820,
          11,
          51216
        ]
      },
      {
        "avg_logprob": -0.1631112061729727,
        "compression_ratio": 1.7549407114624507,
        "end": 5854.98,
        "id": 1789,
        "no_speech_prob": 0.0008969234768301249,
        "seek": 583578,
        "start": 5852.82,
        "temperature": 0,
        "text": " now also has the body parser.",
        "tokens": [
          51216,
          586,
          611,
          575,
          264,
          1772,
          21156,
          260,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.1631112061729727,
        "compression_ratio": 1.7549407114624507,
        "end": 5858.5,
        "id": 1790,
        "no_speech_prob": 0.0008969234768301249,
        "seek": 583578,
        "start": 5854.98,
        "temperature": 0,
        "text": " And I want to use JSON because I want to get the stuff...",
        "tokens": [
          51324,
          400,
          286,
          528,
          281,
          764,
          31828,
          570,
          286,
          528,
          281,
          483,
          264,
          1507,
          485,
          51500
        ]
      },
      {
        "avg_logprob": -0.1631112061729727,
        "compression_ratio": 1.7549407114624507,
        "end": 5861.0599999999995,
        "id": 1791,
        "no_speech_prob": 0.0008969234768301249,
        "seek": 583578,
        "start": 5859.219999999999,
        "temperature": 0,
        "text": " I want to parse everything as JSON.",
        "tokens": [
          51536,
          286,
          528,
          281,
          48377,
          1203,
          382,
          31828,
          13,
          51628
        ]
      },
      {
        "avg_logprob": -0.1631112061729727,
        "compression_ratio": 1.7549407114624507,
        "end": 5861.62,
        "id": 1792,
        "no_speech_prob": 0.0008969234768301249,
        "seek": 583578,
        "start": 5861.0599999999995,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51628,
          1033,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.1631112061729727,
        "compression_ratio": 1.7549407114624507,
        "end": 5864.58,
        "id": 1793,
        "no_speech_prob": 0.0008969234768301249,
        "seek": 583578,
        "start": 5861.62,
        "temperature": 0,
        "text": " So now that I have that, I should be able to say...",
        "tokens": [
          51656,
          407,
          586,
          300,
          286,
          362,
          300,
          11,
          286,
          820,
          312,
          1075,
          281,
          584,
          485,
          51804
        ]
      },
      {
        "avg_logprob": -0.20817184448242188,
        "compression_ratio": 1.6796116504854368,
        "end": 5866.26,
        "id": 1794,
        "no_speech_prob": 0.000041986018914030865,
        "seek": 586458,
        "start": 5864.58,
        "temperature": 0,
        "text": " Oh boy, do I hope that that's true.",
        "tokens": [
          50364,
          876,
          3237,
          11,
          360,
          286,
          1454,
          300,
          300,
          311,
          2074,
          13,
          50448
        ]
      },
      {
        "avg_logprob": -0.20817184448242188,
        "compression_ratio": 1.6796116504854368,
        "end": 5873.22,
        "id": 1795,
        "no_speech_prob": 0.000041986018914030865,
        "seek": 586458,
        "start": 5868.42,
        "temperature": 0,
        "text": " In the post, where I'm handling the post, I've already lost it right here.",
        "tokens": [
          50556,
          682,
          264,
          2183,
          11,
          689,
          286,
          478,
          13175,
          264,
          2183,
          11,
          286,
          600,
          1217,
          2731,
          309,
          558,
          510,
          13,
          50796
        ]
      },
      {
        "avg_logprob": -0.20817184448242188,
        "compression_ratio": 1.6796116504854368,
        "end": 5875.86,
        "id": 1796,
        "no_speech_prob": 0.000041986018914030865,
        "seek": 586458,
        "start": 5873.22,
        "temperature": 0,
        "text": " Let's say console.log request.body.",
        "tokens": [
          50796,
          961,
          311,
          584,
          11076,
          13,
          4987,
          5308,
          13,
          1067,
          13,
          50928
        ]
      },
      {
        "avg_logprob": -0.20817184448242188,
        "compression_ratio": 1.6796116504854368,
        "end": 5880.1,
        "id": 1797,
        "no_speech_prob": 0.000041986018914030865,
        "seek": 586458,
        "start": 5877.0599999999995,
        "temperature": 0,
        "text": " And so I'm going to restart the server.",
        "tokens": [
          50988,
          400,
          370,
          286,
          478,
          516,
          281,
          21022,
          264,
          7154,
          13,
          51140
        ]
      },
      {
        "avg_logprob": -0.20817184448242188,
        "compression_ratio": 1.6796116504854368,
        "end": 5881.16,
        "id": 1798,
        "no_speech_prob": 0.000041986018914030865,
        "seek": 586458,
        "start": 5880.66,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          51168,
          45263,
          13,
          51193
        ]
      },
      {
        "avg_logprob": -0.20817184448242188,
        "compression_ratio": 1.6796116504854368,
        "end": 5886.42,
        "id": 1799,
        "no_speech_prob": 0.000041986018914030865,
        "seek": 586458,
        "start": 5882.66,
        "temperature": 0,
        "text": " And I'm going to refresh this page.",
        "tokens": [
          51268,
          400,
          286,
          478,
          516,
          281,
          15134,
          341,
          3028,
          13,
          51456
        ]
      },
      {
        "avg_logprob": -0.20817184448242188,
        "compression_ratio": 1.6796116504854368,
        "end": 5888.42,
        "id": 1800,
        "no_speech_prob": 0.000041986018914030865,
        "seek": 586458,
        "start": 5886.42,
        "temperature": 0,
        "text": " I'm going to say this is a test.",
        "tokens": [
          51456,
          286,
          478,
          516,
          281,
          584,
          341,
          307,
          257,
          1500,
          13,
          51556
        ]
      },
      {
        "avg_logprob": -0.20817184448242188,
        "compression_ratio": 1.6796116504854368,
        "end": 5889.86,
        "id": 1801,
        "no_speech_prob": 0.000041986018914030865,
        "seek": 586458,
        "start": 5888.42,
        "temperature": 0,
        "text": " I'm going to hit analyze.",
        "tokens": [
          51556,
          286,
          478,
          516,
          281,
          2045,
          12477,
          13,
          51628
        ]
      },
      {
        "avg_logprob": -0.20817184448242188,
        "compression_ratio": 1.6796116504854368,
        "end": 5891.38,
        "id": 1802,
        "no_speech_prob": 0.000041986018914030865,
        "seek": 586458,
        "start": 5889.86,
        "temperature": 0,
        "text": " I got the message back.",
        "tokens": [
          51628,
          286,
          658,
          264,
          3636,
          646,
          13,
          51704
        ]
      },
      {
        "avg_logprob": -0.20817184448242188,
        "compression_ratio": 1.6796116504854368,
        "end": 5891.94,
        "id": 1803,
        "no_speech_prob": 0.000041986018914030865,
        "seek": 586458,
        "start": 5891.38,
        "temperature": 0,
        "text": " And oops.",
        "tokens": [
          51704,
          400,
          34166,
          13,
          51732
        ]
      },
      {
        "avg_logprob": -0.20817184448242188,
        "compression_ratio": 1.6796116504854368,
        "end": 5894.0199999999995,
        "id": 1804,
        "no_speech_prob": 0.000041986018914030865,
        "seek": 586458,
        "start": 5892.82,
        "temperature": 0,
        "text": " I got an empty object.",
        "tokens": [
          51776,
          286,
          658,
          364,
          6707,
          2657,
          13,
          51836
        ]
      },
      {
        "avg_logprob": -0.23528682031939108,
        "compression_ratio": 1.5416666666666667,
        "end": 5901.38,
        "id": 1805,
        "no_speech_prob": 0.0001420233165845275,
        "seek": 589402,
        "start": 5894.02,
        "temperature": 0,
        "text": " But I think maybe just the console isn't logging it properly.",
        "tokens": [
          50364,
          583,
          286,
          519,
          1310,
          445,
          264,
          11076,
          1943,
          380,
          27991,
          309,
          6108,
          13,
          50732
        ]
      },
      {
        "avg_logprob": -0.23528682031939108,
        "compression_ratio": 1.5416666666666667,
        "end": 5904.18,
        "id": 1806,
        "no_speech_prob": 0.0001420233165845275,
        "seek": 589402,
        "start": 5901.9400000000005,
        "temperature": 0,
        "text": " And so at some point, I want to show other ways of debugging",
        "tokens": [
          50760,
          400,
          370,
          412,
          512,
          935,
          11,
          286,
          528,
          281,
          855,
          661,
          2098,
          295,
          45592,
          50872
        ]
      },
      {
        "avg_logprob": -0.23528682031939108,
        "compression_ratio": 1.5416666666666667,
        "end": 5906.1,
        "id": 1807,
        "no_speech_prob": 0.0001420233165845275,
        "seek": 589402,
        "start": 5904.18,
        "temperature": 0,
        "text": " and know where you can get a nice JavaScript console.",
        "tokens": [
          50872,
          293,
          458,
          689,
          291,
          393,
          483,
          257,
          1481,
          15778,
          11076,
          13,
          50968
        ]
      },
      {
        "avg_logprob": -0.23528682031939108,
        "compression_ratio": 1.5416666666666667,
        "end": 5907.860000000001,
        "id": 1808,
        "no_speech_prob": 0.0001420233165845275,
        "seek": 589402,
        "start": 5906.1,
        "temperature": 0,
        "text": " But I'll have to do that in another video.",
        "tokens": [
          50968,
          583,
          286,
          603,
          362,
          281,
          360,
          300,
          294,
          1071,
          960,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.23528682031939108,
        "compression_ratio": 1.5416666666666667,
        "end": 5909.540000000001,
        "id": 1809,
        "no_speech_prob": 0.0001420233165845275,
        "seek": 589402,
        "start": 5907.860000000001,
        "temperature": 0,
        "text": " Let's look if I can say...",
        "tokens": [
          51056,
          961,
          311,
          574,
          498,
          286,
          393,
          584,
          485,
          51140
        ]
      },
      {
        "avg_logprob": -0.23528682031939108,
        "compression_ratio": 1.5416666666666667,
        "end": 5910.900000000001,
        "id": 1810,
        "no_speech_prob": 0.0001420233165845275,
        "seek": 589402,
        "start": 5910.18,
        "temperature": 0,
        "text": " Where am I here?",
        "tokens": [
          51172,
          2305,
          669,
          286,
          510,
          30,
          51208
        ]
      },
      {
        "avg_logprob": -0.23528682031939108,
        "compression_ratio": 1.5416666666666667,
        "end": 5911.9400000000005,
        "id": 1811,
        "no_speech_prob": 0.0001420233165845275,
        "seek": 589402,
        "start": 5911.540000000001,
        "temperature": 0,
        "text": " Body.",
        "tokens": [
          51240,
          21329,
          13,
          51260
        ]
      },
      {
        "avg_logprob": -0.23528682031939108,
        "compression_ratio": 1.5416666666666667,
        "end": 5913.38,
        "id": 1812,
        "no_speech_prob": 0.0001420233165845275,
        "seek": 589402,
        "start": 5912.900000000001,
        "temperature": 0,
        "text": " And what...",
        "tokens": [
          51308,
          400,
          437,
          485,
          51332
        ]
      },
      {
        "avg_logprob": -0.23528682031939108,
        "compression_ratio": 1.5416666666666667,
        "end": 5917.3,
        "id": 1813,
        "no_speech_prob": 0.0001420233165845275,
        "seek": 589402,
        "start": 5913.9400000000005,
        "temperature": 0,
        "text": " In Sketch.js, boy, this is getting complicated.",
        "tokens": [
          51360,
          682,
          49245,
          13,
          25530,
          11,
          3237,
          11,
          341,
          307,
          1242,
          6179,
          13,
          51528
        ]
      },
      {
        "avg_logprob": -0.23528682031939108,
        "compression_ratio": 1.5416666666666667,
        "end": 5920.42,
        "id": 1814,
        "no_speech_prob": 0.0001420233165845275,
        "seek": 589402,
        "start": 5917.3,
        "temperature": 0,
        "text": " I sent it as data with a text property.",
        "tokens": [
          51528,
          286,
          2279,
          309,
          382,
          1412,
          365,
          257,
          2487,
          4707,
          13,
          51684
        ]
      },
      {
        "avg_logprob": -0.23528682031939108,
        "compression_ratio": 1.5416666666666667,
        "end": 5922.820000000001,
        "id": 1815,
        "no_speech_prob": 0.0001420233165845275,
        "seek": 589402,
        "start": 5920.42,
        "temperature": 0,
        "text": " So I should be able to say body.text.",
        "tokens": [
          51684,
          407,
          286,
          820,
          312,
          1075,
          281,
          584,
          1772,
          13,
          25111,
          13,
          51804
        ]
      },
      {
        "avg_logprob": -0.19151567945293352,
        "compression_ratio": 1.5078534031413613,
        "end": 5924.66,
        "id": 1816,
        "no_speech_prob": 0.0030753405299037695,
        "seek": 592282,
        "start": 5922.82,
        "temperature": 0,
        "text": " And I should see what was sent.",
        "tokens": [
          50364,
          400,
          286,
          820,
          536,
          437,
          390,
          2279,
          13,
          50456
        ]
      },
      {
        "avg_logprob": -0.19151567945293352,
        "compression_ratio": 1.5078534031413613,
        "end": 5929.38,
        "id": 1817,
        "no_speech_prob": 0.0030753405299037695,
        "seek": 592282,
        "start": 5924.66,
        "temperature": 0,
        "text": " So let me try doing this one more time and hitting refresh.",
        "tokens": [
          50456,
          407,
          718,
          385,
          853,
          884,
          341,
          472,
          544,
          565,
          293,
          8850,
          15134,
          13,
          50692
        ]
      },
      {
        "avg_logprob": -0.19151567945293352,
        "compression_ratio": 1.5078534031413613,
        "end": 5930.66,
        "id": 1818,
        "no_speech_prob": 0.0030753405299037695,
        "seek": 592282,
        "start": 5929.38,
        "temperature": 0,
        "text": " And this is a test.",
        "tokens": [
          50692,
          400,
          341,
          307,
          257,
          1500,
          13,
          50756
        ]
      },
      {
        "avg_logprob": -0.19151567945293352,
        "compression_ratio": 1.5078534031413613,
        "end": 5933.86,
        "id": 1819,
        "no_speech_prob": 0.0030753405299037695,
        "seek": 592282,
        "start": 5932.5,
        "temperature": 0,
        "text": " And I look in here.",
        "tokens": [
          50848,
          400,
          286,
          574,
          294,
          510,
          13,
          50916
        ]
      },
      {
        "avg_logprob": -0.19151567945293352,
        "compression_ratio": 1.5078534031413613,
        "end": 5934.58,
        "id": 1820,
        "no_speech_prob": 0.0030753405299037695,
        "seek": 592282,
        "start": 5933.86,
        "temperature": 0,
        "text": " Undefined.",
        "tokens": [
          50916,
          2719,
          5666,
          2001,
          13,
          50952
        ]
      },
      {
        "avg_logprob": -0.19151567945293352,
        "compression_ratio": 1.5078534031413613,
        "end": 5936.179999999999,
        "id": 1821,
        "no_speech_prob": 0.0030753405299037695,
        "seek": 592282,
        "start": 5935.62,
        "temperature": 0,
        "text": " Time out.",
        "tokens": [
          51004,
          6161,
          484,
          13,
          51032
        ]
      },
      {
        "avg_logprob": -0.19151567945293352,
        "compression_ratio": 1.5078534031413613,
        "end": 5938.259999999999,
        "id": 1822,
        "no_speech_prob": 0.0030753405299037695,
        "seek": 592282,
        "start": 5936.82,
        "temperature": 0,
        "text": " I'm going to have to debug this.",
        "tokens": [
          51064,
          286,
          478,
          516,
          281,
          362,
          281,
          24083,
          341,
          13,
          51136
        ]
      },
      {
        "avg_logprob": -0.19151567945293352,
        "compression_ratio": 1.5078534031413613,
        "end": 5939.38,
        "id": 1823,
        "no_speech_prob": 0.0030753405299037695,
        "seek": 592282,
        "start": 5938.259999999999,
        "temperature": 0,
        "text": " I forgot what I did wrong.",
        "tokens": [
          51136,
          286,
          5298,
          437,
          286,
          630,
          2085,
          13,
          51192
        ]
      },
      {
        "avg_logprob": -0.19151567945293352,
        "compression_ratio": 1.5078534031413613,
        "end": 5944.74,
        "id": 1824,
        "no_speech_prob": 0.0030753405299037695,
        "seek": 592282,
        "start": 5944.259999999999,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51436,
          2264,
          13,
          51460
        ]
      },
      {
        "avg_logprob": -0.19151567945293352,
        "compression_ratio": 1.5078534031413613,
        "end": 5945.54,
        "id": 1825,
        "no_speech_prob": 0.0030753405299037695,
        "seek": 592282,
        "start": 5944.74,
        "temperature": 0,
        "text": " Let's see here.",
        "tokens": [
          51460,
          961,
          311,
          536,
          510,
          13,
          51500
        ]
      },
      {
        "avg_logprob": -0.19151567945293352,
        "compression_ratio": 1.5078534031413613,
        "end": 5946.9,
        "id": 1826,
        "no_speech_prob": 0.0030753405299037695,
        "seek": 592282,
        "start": 5945.54,
        "temperature": 0,
        "text": " What did I do wrong?",
        "tokens": [
          51500,
          708,
          630,
          286,
          360,
          2085,
          30,
          51568
        ]
      },
      {
        "avg_logprob": -0.19151567945293352,
        "compression_ratio": 1.5078534031413613,
        "end": 5949.62,
        "id": 1827,
        "no_speech_prob": 0.0030753405299037695,
        "seek": 592282,
        "start": 5946.9,
        "temperature": 0,
        "text": " Let's look at my existing example.",
        "tokens": [
          51568,
          961,
          311,
          574,
          412,
          452,
          6741,
          1365,
          13,
          51704
        ]
      },
      {
        "avg_logprob": -0.1771391700295841,
        "compression_ratio": 1.48,
        "end": 5954.82,
        "id": 1828,
        "no_speech_prob": 0.000626332126557827,
        "seek": 595282,
        "start": 5953.54,
        "temperature": 0,
        "text": " Do I need this?",
        "tokens": [
          50400,
          1144,
          286,
          643,
          341,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.1771391700295841,
        "compression_ratio": 1.48,
        "end": 5957.38,
        "id": 1829,
        "no_speech_prob": 0.000626332126557827,
        "seek": 595282,
        "start": 5956.58,
        "temperature": 0,
        "text": " No, no.",
        "tokens": [
          50552,
          883,
          11,
          572,
          13,
          50592
        ]
      },
      {
        "avg_logprob": -0.1771391700295841,
        "compression_ratio": 1.48,
        "end": 5958.179999999999,
        "id": 1830,
        "no_speech_prob": 0.000626332126557827,
        "seek": 595282,
        "start": 5957.38,
        "temperature": 0,
        "text": " Use function.",
        "tokens": [
          50592,
          8278,
          2445,
          13,
          50632
        ]
      },
      {
        "avg_logprob": -0.1771391700295841,
        "compression_ratio": 1.48,
        "end": 5958.42,
        "id": 1831,
        "no_speech_prob": 0.000626332126557827,
        "seek": 595282,
        "start": 5958.179999999999,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50632,
          2264,
          13,
          50644
        ]
      },
      {
        "avg_logprob": -0.1771391700295841,
        "compression_ratio": 1.48,
        "end": 5961.38,
        "id": 1832,
        "no_speech_prob": 0.000626332126557827,
        "seek": 595282,
        "start": 5958.42,
        "temperature": 0,
        "text": " Let me see if there was something I missed in my other example.",
        "tokens": [
          50644,
          961,
          385,
          536,
          498,
          456,
          390,
          746,
          286,
          6721,
          294,
          452,
          661,
          1365,
          13,
          50792
        ]
      },
      {
        "avg_logprob": -0.1771391700295841,
        "compression_ratio": 1.48,
        "end": 5963.54,
        "id": 1833,
        "no_speech_prob": 0.000626332126557827,
        "seek": 595282,
        "start": 5963.219999999999,
        "temperature": 0,
        "text": " Oh, boy.",
        "tokens": [
          50884,
          876,
          11,
          3237,
          13,
          50900
        ]
      },
      {
        "avg_logprob": -0.1771391700295841,
        "compression_ratio": 1.48,
        "end": 5964.74,
        "id": 1834,
        "no_speech_prob": 0.000626332126557827,
        "seek": 595282,
        "start": 5963.54,
        "temperature": 0,
        "text": " It's already 5 o'clock.",
        "tokens": [
          50900,
          467,
          311,
          1217,
          1025,
          277,
          6,
          9023,
          13,
          50960
        ]
      },
      {
        "avg_logprob": -0.1771391700295841,
        "compression_ratio": 1.48,
        "end": 5965.24,
        "id": 1835,
        "no_speech_prob": 0.000626332126557827,
        "seek": 595282,
        "start": 5964.74,
        "temperature": 0,
        "text": " Wow.",
        "tokens": [
          50960,
          3153,
          13,
          50985
        ]
      },
      {
        "avg_logprob": -0.1771391700295841,
        "compression_ratio": 1.48,
        "end": 5970.42,
        "id": 1836,
        "no_speech_prob": 0.000626332126557827,
        "seek": 595282,
        "start": 5966.5,
        "temperature": 0,
        "text": " This stuff always takes twice as long, if not four times as long as I think.",
        "tokens": [
          51048,
          639,
          1507,
          1009,
          2516,
          6091,
          382,
          938,
          11,
          498,
          406,
          1451,
          1413,
          382,
          938,
          382,
          286,
          519,
          13,
          51244
        ]
      },
      {
        "avg_logprob": -0.1771391700295841,
        "compression_ratio": 1.48,
        "end": 5972.0199999999995,
        "id": 1837,
        "no_speech_prob": 0.000626332126557827,
        "seek": 595282,
        "start": 5970.42,
        "temperature": 0,
        "text": " But I'm close to the end of this.",
        "tokens": [
          51244,
          583,
          286,
          478,
          1998,
          281,
          264,
          917,
          295,
          341,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.1771391700295841,
        "compression_ratio": 1.48,
        "end": 5975.86,
        "id": 1838,
        "no_speech_prob": 0.000626332126557827,
        "seek": 595282,
        "start": 5974.5,
        "temperature": 0,
        "text": " I made an example that does this.",
        "tokens": [
          51448,
          286,
          1027,
          364,
          1365,
          300,
          775,
          341,
          13,
          51516
        ]
      },
      {
        "avg_logprob": -0.1771391700295841,
        "compression_ratio": 1.48,
        "end": 5976.82,
        "id": 1839,
        "no_speech_prob": 0.000626332126557827,
        "seek": 595282,
        "start": 5975.86,
        "temperature": 0,
        "text": " Let's look.",
        "tokens": [
          51516,
          961,
          311,
          574,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1771391700295841,
        "compression_ratio": 1.48,
        "end": 5978.099999999999,
        "id": 1840,
        "no_speech_prob": 0.000626332126557827,
        "seek": 595282,
        "start": 5976.82,
        "temperature": 0,
        "text": " Oh, and I want to mention cores.",
        "tokens": [
          51564,
          876,
          11,
          293,
          286,
          528,
          281,
          2152,
          24826,
          13,
          51628
        ]
      },
      {
        "avg_logprob": -0.5229219436645508,
        "compression_ratio": 1.272,
        "end": 5980.9800000000005,
        "id": 1841,
        "no_speech_prob": 0.0002913698263000697,
        "seek": 597810,
        "start": 5978.58,
        "temperature": 0,
        "text": " I mean, could extended true matter?",
        "tokens": [
          50388,
          286,
          914,
          11,
          727,
          10913,
          2074,
          1871,
          30,
          50508
        ]
      },
      {
        "avg_logprob": -0.5229219436645508,
        "compression_ratio": 1.272,
        "end": 5982.26,
        "id": 1842,
        "no_speech_prob": 0.0002913698263000697,
        "seek": 597810,
        "start": 5980.9800000000005,
        "temperature": 0,
        "text": " I don't think so.",
        "tokens": [
          50508,
          286,
          500,
          380,
          519,
          370,
          13,
          50572
        ]
      },
      {
        "avg_logprob": -0.5229219436645508,
        "compression_ratio": 1.272,
        "end": 5987.54,
        "id": 1843,
        "no_speech_prob": 0.0002913698263000697,
        "seek": 597810,
        "start": 5983.22,
        "temperature": 0,
        "text": " Let's just let me grab this.",
        "tokens": [
          50620,
          961,
          311,
          445,
          718,
          385,
          4444,
          341,
          13,
          50836
        ]
      },
      {
        "avg_logprob": -0.5229219436645508,
        "compression_ratio": 1.272,
        "end": 5993.46,
        "id": 1844,
        "no_speech_prob": 0.0002913698263000697,
        "seek": 597810,
        "start": 5992.34,
        "temperature": 0,
        "text": " Let me just make sure.",
        "tokens": [
          51076,
          961,
          385,
          445,
          652,
          988,
          13,
          51132
        ]
      },
      {
        "avg_logprob": -0.5229219436645508,
        "compression_ratio": 1.272,
        "end": 5995.54,
        "id": 1845,
        "no_speech_prob": 0.0002913698263000697,
        "seek": 597810,
        "start": 5994.42,
        "temperature": 0,
        "text": " This is the same, really.",
        "tokens": [
          51180,
          639,
          307,
          264,
          912,
          11,
          534,
          13,
          51236
        ]
      },
      {
        "avg_logprob": -0.5229219436645508,
        "compression_ratio": 1.272,
        "end": 6002.900000000001,
        "id": 1846,
        "no_speech_prob": 0.0002913698263000697,
        "seek": 597810,
        "start": 6002.42,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51580,
          2264,
          13,
          51604
        ]
      },
      {
        "avg_logprob": -0.5229219436645508,
        "compression_ratio": 1.272,
        "end": 6005.14,
        "id": 1847,
        "no_speech_prob": 0.0002913698263000697,
        "seek": 597810,
        "start": 6003.46,
        "temperature": 0,
        "text": " So this is what I have.",
        "tokens": [
          51632,
          407,
          341,
          307,
          437,
          286,
          362,
          13,
          51716
        ]
      },
      {
        "avg_logprob": -0.5165625413258871,
        "compression_ratio": 1.7046632124352332,
        "end": 6013.780000000001,
        "id": 1848,
        "no_speech_prob": 0.0002098826371366158,
        "seek": 600514,
        "start": 6005.700000000001,
        "temperature": 0,
        "text": " And then when I handle the post, analyze, analyze, request, response, request body text.",
        "tokens": [
          50392,
          400,
          550,
          562,
          286,
          4813,
          264,
          2183,
          11,
          12477,
          11,
          12477,
          11,
          5308,
          11,
          4134,
          11,
          5308,
          1772,
          2487,
          13,
          50796
        ]
      },
      {
        "avg_logprob": -0.5165625413258871,
        "compression_ratio": 1.7046632124352332,
        "end": 6016.820000000001,
        "id": 1849,
        "no_speech_prob": 0.0002098826371366158,
        "seek": 600514,
        "start": 6015.38,
        "temperature": 0,
        "text": " This looks the same, right?",
        "tokens": [
          50876,
          639,
          1542,
          264,
          912,
          11,
          558,
          30,
          50948
        ]
      },
      {
        "avg_logprob": -0.5165625413258871,
        "compression_ratio": 1.7046632124352332,
        "end": 6018.900000000001,
        "id": 1850,
        "no_speech_prob": 0.0002098826371366158,
        "seek": 600514,
        "start": 6018.42,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51028,
          1057,
          558,
          13,
          51052
        ]
      },
      {
        "avg_logprob": -0.5165625413258871,
        "compression_ratio": 1.7046632124352332,
        "end": 6024.9800000000005,
        "id": 1851,
        "no_speech_prob": 0.0002098826371366158,
        "seek": 600514,
        "start": 6021.3,
        "temperature": 0,
        "text": " I'm going to have to look at the client, obviously, to see if that's where it's different.",
        "tokens": [
          51172,
          286,
          478,
          516,
          281,
          362,
          281,
          574,
          412,
          264,
          6423,
          11,
          2745,
          11,
          281,
          536,
          498,
          300,
          311,
          689,
          309,
          311,
          819,
          13,
          51356
        ]
      },
      {
        "avg_logprob": -0.5165625413258871,
        "compression_ratio": 1.7046632124352332,
        "end": 6027.860000000001,
        "id": 1852,
        "no_speech_prob": 0.0002098826371366158,
        "seek": 600514,
        "start": 6024.9800000000005,
        "temperature": 0,
        "text": " And let's also go to the client.",
        "tokens": [
          51356,
          400,
          718,
          311,
          611,
          352,
          281,
          264,
          6423,
          13,
          51500
        ]
      },
      {
        "avg_logprob": -0.5165625413258871,
        "compression_ratio": 1.7046632124352332,
        "end": 6035.06,
        "id": 1853,
        "no_speech_prob": 0.0002098826371366158,
        "seek": 600514,
        "start": 6027.860000000001,
        "temperature": 0,
        "text": " Somebody, I don't know if anybody in the chat, I'm going to go to the client.",
        "tokens": [
          51500,
          13463,
          11,
          286,
          500,
          380,
          458,
          498,
          4472,
          294,
          264,
          5081,
          11,
          286,
          478,
          516,
          281,
          352,
          281,
          264,
          6423,
          13,
          51860
        ]
      },
      {
        "avg_logprob": -0.2599169197729078,
        "compression_ratio": 1.4044117647058822,
        "end": 6043.54,
        "id": 1854,
        "no_speech_prob": 0.002182706957682967,
        "seek": 603514,
        "start": 6035.22,
        "temperature": 0,
        "text": " The data is not in the post request.",
        "tokens": [
          50368,
          440,
          1412,
          307,
          406,
          294,
          264,
          2183,
          5308,
          13,
          50784
        ]
      },
      {
        "avg_logprob": -0.2599169197729078,
        "compression_ratio": 1.4044117647058822,
        "end": 6047.62,
        "id": 1855,
        "no_speech_prob": 0.002182706957682967,
        "seek": 603514,
        "start": 6045.9400000000005,
        "temperature": 0,
        "text": " Oh, I forgot to put data.",
        "tokens": [
          50904,
          876,
          11,
          286,
          5298,
          281,
          829,
          1412,
          13,
          50988
        ]
      },
      {
        "avg_logprob": -0.2599169197729078,
        "compression_ratio": 1.4044117647058822,
        "end": 6052.660000000001,
        "id": 1856,
        "no_speech_prob": 0.002182706957682967,
        "seek": 603514,
        "start": 6050.900000000001,
        "temperature": 0,
        "text": " I forgot to post the data.",
        "tokens": [
          51152,
          286,
          5298,
          281,
          2183,
          264,
          1412,
          13,
          51240
        ]
      },
      {
        "avg_logprob": -0.2599169197729078,
        "compression_ratio": 1.4044117647058822,
        "end": 6054.34,
        "id": 1857,
        "no_speech_prob": 0.002182706957682967,
        "seek": 603514,
        "start": 6053.38,
        "temperature": 0,
        "text": " I bet you that's it.",
        "tokens": [
          51276,
          286,
          778,
          291,
          300,
          311,
          309,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.2599169197729078,
        "compression_ratio": 1.4044117647058822,
        "end": 6062.18,
        "id": 1858,
        "no_speech_prob": 0.002182706957682967,
        "seek": 603514,
        "start": 6058.42,
        "temperature": 0,
        "text": " How many subscribers have I lost during the course of this making of this video?",
        "tokens": [
          51528,
          1012,
          867,
          11092,
          362,
          286,
          2731,
          1830,
          264,
          1164,
          295,
          341,
          1455,
          295,
          341,
          960,
          30,
          51716
        ]
      },
      {
        "avg_logprob": -0.21272610683067172,
        "compression_ratio": 1.5,
        "end": 6067.14,
        "id": 1859,
        "no_speech_prob": 0.00011959840776398778,
        "seek": 606218,
        "start": 6063.14,
        "temperature": 0,
        "text": " The test, analyze, thank you.",
        "tokens": [
          50412,
          440,
          1500,
          11,
          12477,
          11,
          1309,
          291,
          13,
          50612
        ]
      },
      {
        "avg_logprob": -0.21272610683067172,
        "compression_ratio": 1.5,
        "end": 6070.18,
        "id": 1860,
        "no_speech_prob": 0.00011959840776398778,
        "seek": 606218,
        "start": 6067.860000000001,
        "temperature": 0,
        "text": " And there we go.",
        "tokens": [
          50648,
          400,
          456,
          321,
          352,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21272610683067172,
        "compression_ratio": 1.5,
        "end": 6070.5,
        "id": 1861,
        "no_speech_prob": 0.00011959840776398778,
        "seek": 606218,
        "start": 6070.18,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50764,
          2264,
          13,
          50780
        ]
      },
      {
        "avg_logprob": -0.21272610683067172,
        "compression_ratio": 1.5,
        "end": 6078.820000000001,
        "id": 1862,
        "no_speech_prob": 0.00011959840776398778,
        "seek": 606218,
        "start": 6073.3,
        "temperature": 0,
        "text": " Thank you to David in the chat who helped me solve this problem.",
        "tokens": [
          50920,
          1044,
          291,
          281,
          4389,
          294,
          264,
          5081,
          567,
          4254,
          385,
          5039,
          341,
          1154,
          13,
          51196
        ]
      },
      {
        "avg_logprob": -0.21272610683067172,
        "compression_ratio": 1.5,
        "end": 6081.22,
        "id": 1863,
        "no_speech_prob": 0.00011959840776398778,
        "seek": 606218,
        "start": 6079.62,
        "temperature": 0,
        "text": " Hopefully, I would have noticed it eventually.",
        "tokens": [
          51236,
          10429,
          11,
          286,
          576,
          362,
          5694,
          309,
          4728,
          13,
          51316
        ]
      },
      {
        "avg_logprob": -0.21272610683067172,
        "compression_ratio": 1.5,
        "end": 6082.740000000001,
        "id": 1864,
        "no_speech_prob": 0.00011959840776398778,
        "seek": 606218,
        "start": 6081.22,
        "temperature": 0,
        "text": " But I just completely forgot this.",
        "tokens": [
          51316,
          583,
          286,
          445,
          2584,
          5298,
          341,
          13,
          51392
        ]
      },
      {
        "avg_logprob": -0.21272610683067172,
        "compression_ratio": 1.5,
        "end": 6083.780000000001,
        "id": 1865,
        "no_speech_prob": 0.00011959840776398778,
        "seek": 606218,
        "start": 6082.740000000001,
        "temperature": 0,
        "text": " I need to take this out.",
        "tokens": [
          51392,
          286,
          643,
          281,
          747,
          341,
          484,
          13,
          51444
        ]
      },
      {
        "avg_logprob": -0.21272610683067172,
        "compression_ratio": 1.5,
        "end": 6088.740000000001,
        "id": 1866,
        "no_speech_prob": 0.00011959840776398778,
        "seek": 606218,
        "start": 6084.42,
        "temperature": 0,
        "text": " I need to back up to here.",
        "tokens": [
          51476,
          286,
          643,
          281,
          646,
          493,
          281,
          510,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.21272610683067172,
        "compression_ratio": 1.5,
        "end": 6089.46,
        "id": 1867,
        "no_speech_prob": 0.00011959840776398778,
        "seek": 606218,
        "start": 6088.740000000001,
        "temperature": 0,
        "text": " This is the same.",
        "tokens": [
          51692,
          639,
          307,
          264,
          912,
          13,
          51728
        ]
      },
      {
        "avg_logprob": -0.21272610683067172,
        "compression_ratio": 1.5,
        "end": 6090.5,
        "id": 1868,
        "no_speech_prob": 0.00011959840776398778,
        "seek": 606218,
        "start": 6089.46,
        "temperature": 0,
        "text": " I just had this as false.",
        "tokens": [
          51728,
          286,
          445,
          632,
          341,
          382,
          7908,
          13,
          51780
        ]
      },
      {
        "avg_logprob": -0.21272610683067172,
        "compression_ratio": 1.5,
        "end": 6091.46,
        "id": 1869,
        "no_speech_prob": 0.00011959840776398778,
        "seek": 606218,
        "start": 6090.5,
        "temperature": 0,
        "text": " I don't think that matters.",
        "tokens": [
          51780,
          286,
          500,
          380,
          519,
          300,
          7001,
          13,
          51828
        ]
      },
      {
        "avg_logprob": -0.26729121776895787,
        "compression_ratio": 1.9644970414201184,
        "end": 6094.02,
        "id": 1870,
        "no_speech_prob": 0.000137654336867854,
        "seek": 609218,
        "start": 6092.5,
        "temperature": 0.2,
        "text": " Let me go down to here.",
        "tokens": [
          50380,
          961,
          385,
          352,
          760,
          281,
          510,
          13,
          50456
        ]
      },
      {
        "avg_logprob": -0.26729121776895787,
        "compression_ratio": 1.9644970414201184,
        "end": 6104.5,
        "id": 1871,
        "no_speech_prob": 0.000137654336867854,
        "seek": 609218,
        "start": 6094.820000000001,
        "temperature": 0.2,
        "text": " And let me go to back to here, console.log.",
        "tokens": [
          50496,
          400,
          718,
          385,
          352,
          281,
          646,
          281,
          510,
          11,
          11076,
          13,
          4987,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.26729121776895787,
        "compression_ratio": 1.9644970414201184,
        "end": 6113.22,
        "id": 1872,
        "no_speech_prob": 0.000137654336867854,
        "seek": 609218,
        "start": 6108.66,
        "temperature": 0.2,
        "text": " Console.log, where, where, where, where, where, where, where, where, where, where, where, where,",
        "tokens": [
          51188,
          44152,
          13,
          4987,
          11,
          689,
          11,
          689,
          11,
          689,
          11,
          689,
          11,
          689,
          11,
          689,
          11,
          689,
          11,
          689,
          11,
          689,
          11,
          689,
          11,
          689,
          11,
          689,
          11,
          51416
        ]
      },
      {
        "avg_logprob": -0.26729121776895787,
        "compression_ratio": 1.9644970414201184,
        "end": 6114.820000000001,
        "id": 1873,
        "no_speech_prob": 0.000137654336867854,
        "seek": 609218,
        "start": 6113.22,
        "temperature": 0.2,
        "text": " when it's finished or if there's an error.",
        "tokens": [
          51416,
          562,
          309,
          311,
          4335,
          420,
          498,
          456,
          311,
          364,
          6713,
          13,
          51496
        ]
      },
      {
        "avg_logprob": -0.26729121776895787,
        "compression_ratio": 1.9644970414201184,
        "end": 6115.38,
        "id": 1874,
        "no_speech_prob": 0.000137654336867854,
        "seek": 609218,
        "start": 6114.820000000001,
        "temperature": 0.2,
        "text": " What's missing?",
        "tokens": [
          51496,
          708,
          311,
          5361,
          30,
          51524
        ]
      },
      {
        "avg_logprob": -0.26729121776895787,
        "compression_ratio": 1.9644970414201184,
        "end": 6116.740000000001,
        "id": 1875,
        "no_speech_prob": 0.000137654336867854,
        "seek": 609218,
        "start": 6115.38,
        "temperature": 0.2,
        "text": " I just listed five things.",
        "tokens": [
          51524,
          286,
          445,
          10052,
          1732,
          721,
          13,
          51592
        ]
      },
      {
        "avg_logprob": -0.26729121776895787,
        "compression_ratio": 1.9644970414201184,
        "end": 6118.58,
        "id": 1876,
        "no_speech_prob": 0.000137654336867854,
        "seek": 609218,
        "start": 6116.740000000001,
        "temperature": 0.2,
        "text": " I forgot to actually send the data.",
        "tokens": [
          51592,
          286,
          5298,
          281,
          767,
          2845,
          264,
          1412,
          13,
          51684
        ]
      },
      {
        "avg_logprob": -0.26729121776895787,
        "compression_ratio": 1.9644970414201184,
        "end": 6119.62,
        "id": 1877,
        "no_speech_prob": 0.000137654336867854,
        "seek": 609218,
        "start": 6118.58,
        "temperature": 0.2,
        "text": " Data goes here.",
        "tokens": [
          51684,
          11888,
          1709,
          510,
          13,
          51736
        ]
      },
      {
        "avg_logprob": -0.26729121776895787,
        "compression_ratio": 1.9644970414201184,
        "end": 6120.900000000001,
        "id": 1878,
        "no_speech_prob": 0.000137654336867854,
        "seek": 609218,
        "start": 6119.62,
        "temperature": 0.2,
        "text": " So I forgot to post the data.",
        "tokens": [
          51736,
          407,
          286,
          5298,
          281,
          2183,
          264,
          1412,
          13,
          51800
        ]
      },
      {
        "avg_logprob": -0.18074920972188313,
        "compression_ratio": 1.6385542168674698,
        "end": 6124.0199999999995,
        "id": 1879,
        "no_speech_prob": 0.011508007533848286,
        "seek": 612090,
        "start": 6120.9,
        "temperature": 0,
        "text": " So there's no way for me to read or receive the data if I didn't post it.",
        "tokens": [
          50364,
          407,
          456,
          311,
          572,
          636,
          337,
          385,
          281,
          1401,
          420,
          4774,
          264,
          1412,
          498,
          286,
          994,
          380,
          2183,
          309,
          13,
          50520
        ]
      },
      {
        "avg_logprob": -0.18074920972188313,
        "compression_ratio": 1.6385542168674698,
        "end": 6125.0599999999995,
        "id": 1880,
        "no_speech_prob": 0.011508007533848286,
        "seek": 612090,
        "start": 6124.0199999999995,
        "temperature": 0,
        "text": " So that's done now.",
        "tokens": [
          50520,
          407,
          300,
          311,
          1096,
          586,
          13,
          50572
        ]
      },
      {
        "avg_logprob": -0.18074920972188313,
        "compression_ratio": 1.6385542168674698,
        "end": 6127.379999999999,
        "id": 1881,
        "no_speech_prob": 0.011508007533848286,
        "seek": 612090,
        "start": 6125.7,
        "temperature": 0,
        "text": " And I think it's going to work.",
        "tokens": [
          50604,
          400,
          286,
          519,
          309,
          311,
          516,
          281,
          589,
          13,
          50688
        ]
      },
      {
        "avg_logprob": -0.18074920972188313,
        "compression_ratio": 1.6385542168674698,
        "end": 6132.5,
        "id": 1882,
        "no_speech_prob": 0.011508007533848286,
        "seek": 612090,
        "start": 6127.379999999999,
        "temperature": 0,
        "text": " So let me, oh, I actually don't have to restart the server because I just changed the client code.",
        "tokens": [
          50688,
          407,
          718,
          385,
          11,
          1954,
          11,
          286,
          767,
          500,
          380,
          362,
          281,
          21022,
          264,
          7154,
          570,
          286,
          445,
          3105,
          264,
          6423,
          3089,
          13,
          50944
        ]
      },
      {
        "avg_logprob": -0.18074920972188313,
        "compression_ratio": 1.6385542168674698,
        "end": 6133.0599999999995,
        "id": 1883,
        "no_speech_prob": 0.011508007533848286,
        "seek": 612090,
        "start": 6132.5,
        "temperature": 0,
        "text": " And you know what?",
        "tokens": [
          50944,
          400,
          291,
          458,
          437,
          30,
          50972
        ]
      },
      {
        "avg_logprob": -0.18074920972188313,
        "compression_ratio": 1.6385542168674698,
        "end": 6134.339999999999,
        "id": 1884,
        "no_speech_prob": 0.011508007533848286,
        "seek": 612090,
        "start": 6133.0599999999995,
        "temperature": 0,
        "text": " This is driving me crazy.",
        "tokens": [
          50972,
          639,
          307,
          4840,
          385,
          3219,
          13,
          51036
        ]
      },
      {
        "avg_logprob": -0.18074920972188313,
        "compression_ratio": 1.6385542168674698,
        "end": 6143.219999999999,
        "id": 1885,
        "no_speech_prob": 0.011508007533848286,
        "seek": 612090,
        "start": 6134.339999999999,
        "temperature": 0,
        "text": " I just want to in the client, I just want to say, just add something here like, I am happy today",
        "tokens": [
          51036,
          286,
          445,
          528,
          281,
          294,
          264,
          6423,
          11,
          286,
          445,
          528,
          281,
          584,
          11,
          445,
          909,
          746,
          510,
          411,
          11,
          286,
          669,
          2055,
          965,
          51480
        ]
      },
      {
        "avg_logprob": -0.18074920972188313,
        "compression_ratio": 1.6385542168674698,
        "end": 6149.299999999999,
        "id": 1886,
        "no_speech_prob": 0.011508007533848286,
        "seek": 612090,
        "start": 6143.219999999999,
        "temperature": 0,
        "text": " because I saw a rainbow and some kittens.",
        "tokens": [
          51480,
          570,
          286,
          1866,
          257,
          18526,
          293,
          512,
          47363,
          13,
          51784
        ]
      },
      {
        "avg_logprob": -0.17876048454871543,
        "compression_ratio": 1.678714859437751,
        "end": 6154.74,
        "id": 1887,
        "no_speech_prob": 0.0003199967322871089,
        "seek": 614930,
        "start": 6149.9400000000005,
        "temperature": 0,
        "text": " OK, so now I have some text pre-filled in.",
        "tokens": [
          50396,
          2264,
          11,
          370,
          586,
          286,
          362,
          512,
          2487,
          659,
          12,
          35596,
          294,
          13,
          50636
        ]
      },
      {
        "avg_logprob": -0.17876048454871543,
        "compression_ratio": 1.678714859437751,
        "end": 6155.860000000001,
        "id": 1888,
        "no_speech_prob": 0.0003199967322871089,
        "seek": 614930,
        "start": 6154.74,
        "temperature": 0,
        "text": " I can hit analyze.",
        "tokens": [
          50636,
          286,
          393,
          2045,
          12477,
          13,
          50692
        ]
      },
      {
        "avg_logprob": -0.17876048454871543,
        "compression_ratio": 1.678714859437751,
        "end": 6158.66,
        "id": 1889,
        "no_speech_prob": 0.0003199967322871089,
        "seek": 614930,
        "start": 6156.5,
        "temperature": 0,
        "text": " I got a message saying thank you.",
        "tokens": [
          50724,
          286,
          658,
          257,
          3636,
          1566,
          1309,
          291,
          13,
          50832
        ]
      },
      {
        "avg_logprob": -0.17876048454871543,
        "compression_ratio": 1.678714859437751,
        "end": 6160.26,
        "id": 1890,
        "no_speech_prob": 0.0003199967322871089,
        "seek": 614930,
        "start": 6158.66,
        "temperature": 0,
        "text": " And I can go look at the server.",
        "tokens": [
          50832,
          400,
          286,
          393,
          352,
          574,
          412,
          264,
          7154,
          13,
          50912
        ]
      },
      {
        "avg_logprob": -0.17876048454871543,
        "compression_ratio": 1.678714859437751,
        "end": 6163.38,
        "id": 1891,
        "no_speech_prob": 0.0003199967322871089,
        "seek": 614930,
        "start": 6160.26,
        "temperature": 0,
        "text": " And I can see that that data came into the server via the post.",
        "tokens": [
          50912,
          400,
          286,
          393,
          536,
          300,
          300,
          1412,
          1361,
          666,
          264,
          7154,
          5766,
          264,
          2183,
          13,
          51068
        ]
      },
      {
        "avg_logprob": -0.17876048454871543,
        "compression_ratio": 1.678714859437751,
        "end": 6166.1,
        "id": 1892,
        "no_speech_prob": 0.0003199967322871089,
        "seek": 614930,
        "start": 6164.900000000001,
        "temperature": 0,
        "text": " We have a post.",
        "tokens": [
          51144,
          492,
          362,
          257,
          2183,
          13,
          51204
        ]
      },
      {
        "avg_logprob": -0.17876048454871543,
        "compression_ratio": 1.678714859437751,
        "end": 6167.38,
        "id": 1893,
        "no_speech_prob": 0.0003199967322871089,
        "seek": 614930,
        "start": 6166.1,
        "temperature": 0,
        "text": " We have a post working.",
        "tokens": [
          51204,
          492,
          362,
          257,
          2183,
          1364,
          13,
          51268
        ]
      },
      {
        "avg_logprob": -0.17876048454871543,
        "compression_ratio": 1.678714859437751,
        "end": 6168.34,
        "id": 1894,
        "no_speech_prob": 0.0003199967322871089,
        "seek": 614930,
        "start": 6167.38,
        "temperature": 0,
        "text": " That is awesome.",
        "tokens": [
          51268,
          663,
          307,
          3476,
          13,
          51316
        ]
      },
      {
        "avg_logprob": -0.17876048454871543,
        "compression_ratio": 1.678714859437751,
        "end": 6171.06,
        "id": 1895,
        "no_speech_prob": 0.0003199967322871089,
        "seek": 614930,
        "start": 6168.34,
        "temperature": 0,
        "text": " OK, so now all I need to do is do sentiment analysis.",
        "tokens": [
          51316,
          2264,
          11,
          370,
          586,
          439,
          286,
          643,
          281,
          360,
          307,
          360,
          16149,
          5215,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.17876048454871543,
        "compression_ratio": 1.678714859437751,
        "end": 6173.9400000000005,
        "id": 1896,
        "no_speech_prob": 0.0003199967322871089,
        "seek": 614930,
        "start": 6171.06,
        "temperature": 0,
        "text": " I really should just give this to you as an exercise and end this video now.",
        "tokens": [
          51452,
          286,
          534,
          820,
          445,
          976,
          341,
          281,
          291,
          382,
          364,
          5380,
          293,
          917,
          341,
          960,
          586,
          13,
          51596
        ]
      },
      {
        "avg_logprob": -0.17876048454871543,
        "compression_ratio": 1.678714859437751,
        "end": 6176.820000000001,
        "id": 1897,
        "no_speech_prob": 0.0003199967322871089,
        "seek": 614930,
        "start": 6173.9400000000005,
        "temperature": 0,
        "text": " But I'm going to finish it up myself.",
        "tokens": [
          51596,
          583,
          286,
          478,
          516,
          281,
          2413,
          309,
          493,
          2059,
          13,
          51740
        ]
      },
      {
        "avg_logprob": -0.15277757548322582,
        "compression_ratio": 1.6411483253588517,
        "end": 6183.7,
        "id": 1898,
        "no_speech_prob": 0.00014202333113644272,
        "seek": 617682,
        "start": 6176.82,
        "temperature": 0,
        "text": " So the nice thing is this isn't too hard for me to do now in the server.",
        "tokens": [
          50364,
          407,
          264,
          1481,
          551,
          307,
          341,
          1943,
          380,
          886,
          1152,
          337,
          385,
          281,
          360,
          586,
          294,
          264,
          7154,
          13,
          50708
        ]
      },
      {
        "avg_logprob": -0.15277757548322582,
        "compression_ratio": 1.6411483253588517,
        "end": 6186.099999999999,
        "id": 1899,
        "no_speech_prob": 0.00014202333113644272,
        "seek": 617682,
        "start": 6183.7,
        "temperature": 0,
        "text": " I'm going to go to the server code.",
        "tokens": [
          50708,
          286,
          478,
          516,
          281,
          352,
          281,
          264,
          7154,
          3089,
          13,
          50828
        ]
      },
      {
        "avg_logprob": -0.15277757548322582,
        "compression_ratio": 1.6411483253588517,
        "end": 6194.179999999999,
        "id": 1900,
        "no_speech_prob": 0.00014202333113644272,
        "seek": 617682,
        "start": 6186.099999999999,
        "temperature": 0,
        "text": " And right here, instead of console logging, I want to look at and say var text equals",
        "tokens": [
          50828,
          400,
          558,
          510,
          11,
          2602,
          295,
          11076,
          27991,
          11,
          286,
          528,
          281,
          574,
          412,
          293,
          584,
          1374,
          2487,
          6915,
          51232
        ]
      },
      {
        "avg_logprob": -0.15277757548322582,
        "compression_ratio": 1.6411483253588517,
        "end": 6196.58,
        "id": 1901,
        "no_speech_prob": 0.00014202333113644272,
        "seek": 617682,
        "start": 6194.179999999999,
        "temperature": 0,
        "text": " request.body text.",
        "tokens": [
          51232,
          5308,
          13,
          1067,
          2487,
          13,
          51352
        ]
      },
      {
        "avg_logprob": -0.15277757548322582,
        "compression_ratio": 1.6411483253588517,
        "end": 6199.86,
        "id": 1902,
        "no_speech_prob": 0.00014202333113644272,
        "seek": 617682,
        "start": 6196.58,
        "temperature": 0,
        "text": " Then I want to split it up, text.split.",
        "tokens": [
          51352,
          1396,
          286,
          528,
          281,
          7472,
          309,
          493,
          11,
          2487,
          13,
          46535,
          270,
          13,
          51516
        ]
      },
      {
        "avg_logprob": -0.15277757548322582,
        "compression_ratio": 1.6411483253588517,
        "end": 6205.38,
        "id": 1903,
        "no_speech_prob": 0.00014202333113644272,
        "seek": 617682,
        "start": 6199.86,
        "temperature": 0,
        "text": " And I'm going to use just a regular expression here to split it up into words by anything",
        "tokens": [
          51516,
          400,
          286,
          478,
          516,
          281,
          764,
          445,
          257,
          3890,
          6114,
          510,
          281,
          7472,
          309,
          493,
          666,
          2283,
          538,
          1340,
          51792
        ]
      },
      {
        "avg_logprob": -0.1938938727745643,
        "compression_ratio": 1.564516129032258,
        "end": 6208.02,
        "id": 1904,
        "no_speech_prob": 0.008061941713094711,
        "seek": 620538,
        "start": 6205.46,
        "temperature": 0,
        "text": " that's not a letter or number.",
        "tokens": [
          50368,
          300,
          311,
          406,
          257,
          5063,
          420,
          1230,
          13,
          50496
        ]
      },
      {
        "avg_logprob": -0.1938938727745643,
        "compression_ratio": 1.564516129032258,
        "end": 6211.14,
        "id": 1905,
        "no_speech_prob": 0.008061941713094711,
        "seek": 620538,
        "start": 6209.22,
        "temperature": 0,
        "text": " I explain this in so many videos.",
        "tokens": [
          50556,
          286,
          2903,
          341,
          294,
          370,
          867,
          2145,
          13,
          50652
        ]
      },
      {
        "avg_logprob": -0.1938938727745643,
        "compression_ratio": 1.564516129032258,
        "end": 6213.38,
        "id": 1906,
        "no_speech_prob": 0.008061941713094711,
        "seek": 620538,
        "start": 6211.14,
        "temperature": 0,
        "text": " But this is pattern matching.",
        "tokens": [
          50652,
          583,
          341,
          307,
          5102,
          14324,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1938938727745643,
        "compression_ratio": 1.564516129032258,
        "end": 6218.9800000000005,
        "id": 1907,
        "no_speech_prob": 0.008061941713094711,
        "seek": 620538,
        "start": 6213.38,
        "temperature": 0,
        "text": " And backslash capital W is anything that's not a to z or 0 through 9.",
        "tokens": [
          50764,
          400,
          646,
          10418,
          1299,
          4238,
          343,
          307,
          1340,
          300,
          311,
          406,
          257,
          281,
          710,
          420,
          1958,
          807,
          1722,
          13,
          51044
        ]
      },
      {
        "avg_logprob": -0.1938938727745643,
        "compression_ratio": 1.564516129032258,
        "end": 6222.900000000001,
        "id": 1908,
        "no_speech_prob": 0.008061941713094711,
        "seek": 620538,
        "start": 6218.9800000000005,
        "temperature": 0,
        "text": " And so now I can loop through those words.",
        "tokens": [
          51044,
          400,
          370,
          586,
          286,
          393,
          6367,
          807,
          729,
          2283,
          13,
          51240
        ]
      },
      {
        "avg_logprob": -0.1938938727745643,
        "compression_ratio": 1.564516129032258,
        "end": 6233.38,
        "id": 1909,
        "no_speech_prob": 0.008061941713094711,
        "seek": 620538,
        "start": 6227.38,
        "temperature": 0,
        "text": " And I can say now, what I want to do is I want to first look.",
        "tokens": [
          51464,
          400,
          286,
          393,
          584,
          586,
          11,
          437,
          286,
          528,
          281,
          360,
          307,
          286,
          528,
          281,
          700,
          574,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1938938727745643,
        "compression_ratio": 1.564516129032258,
        "end": 6234.58,
        "id": 1910,
        "no_speech_prob": 0.008061941713094711,
        "seek": 620538,
        "start": 6233.38,
        "temperature": 0,
        "text": " I need a total score.",
        "tokens": [
          51764,
          286,
          643,
          257,
          3217,
          6175,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.32348179817199707,
        "compression_ratio": 1.5163934426229508,
        "end": 6238.58,
        "id": 1911,
        "no_speech_prob": 0.0007793618715368211,
        "seek": 623458,
        "start": 6235.0599999999995,
        "temperature": 0,
        "text": " So I'm going to have a total score started at 0.",
        "tokens": [
          50388,
          407,
          286,
          478,
          516,
          281,
          362,
          257,
          3217,
          6175,
          1409,
          412,
          1958,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.32348179817199707,
        "compression_ratio": 1.5163934426229508,
        "end": 6249.38,
        "id": 1912,
        "no_speech_prob": 0.0007793618715368211,
        "seek": 623458,
        "start": 6238.58,
        "temperature": 0,
        "text": " I need to say if the what's it called additional pause.",
        "tokens": [
          50564,
          286,
          643,
          281,
          584,
          498,
          264,
          437,
          311,
          309,
          1219,
          4497,
          10465,
          13,
          51104
        ]
      },
      {
        "avg_logprob": -0.32348179817199707,
        "compression_ratio": 1.5163934426229508,
        "end": 6260.74,
        "id": 1913,
        "no_speech_prob": 0.0007793618715368211,
        "seek": 623458,
        "start": 6254.42,
        "temperature": 0,
        "text": " My two word lists are called words.",
        "tokens": [
          51356,
          1222,
          732,
          1349,
          14511,
          366,
          1219,
          2283,
          13,
          51672
        ]
      },
      {
        "avg_logprob": -0.32348179817199707,
        "compression_ratio": 1.5163934426229508,
        "end": 6263.62,
        "id": 1914,
        "no_speech_prob": 0.0007793618715368211,
        "seek": 623458,
        "start": 6260.74,
        "temperature": 0,
        "text": " My two word lists are called words and aphn.",
        "tokens": [
          51672,
          1222,
          732,
          1349,
          14511,
          366,
          1219,
          2283,
          293,
          257,
          950,
          77,
          13,
          51816
        ]
      },
      {
        "avg_logprob": -0.26305361797935084,
        "compression_ratio": 1.6462585034013606,
        "end": 6269.46,
        "id": 1915,
        "no_speech_prob": 0.0003859644930344075,
        "seek": 626362,
        "start": 6264.26,
        "temperature": 0,
        "text": " So what I want to do here is do if words.",
        "tokens": [
          50396,
          407,
          437,
          286,
          528,
          281,
          360,
          510,
          307,
          360,
          498,
          2283,
          13,
          50656
        ]
      },
      {
        "avg_logprob": -0.26305361797935084,
        "compression_ratio": 1.6462585034013606,
        "end": 6270.82,
        "id": 1916,
        "no_speech_prob": 0.0003859644930344075,
        "seek": 626362,
        "start": 6270.099999999999,
        "temperature": 0,
        "text": " Oh, boy.",
        "tokens": [
          50688,
          876,
          11,
          3237,
          13,
          50724
        ]
      },
      {
        "avg_logprob": -0.26305361797935084,
        "compression_ratio": 1.6462585034013606,
        "end": 6271.62,
        "id": 1917,
        "no_speech_prob": 0.0003859644930344075,
        "seek": 626362,
        "start": 6270.82,
        "temperature": 0,
        "text": " I should call this.",
        "tokens": [
          50724,
          286,
          820,
          818,
          341,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.26305361797935084,
        "compression_ratio": 1.6462585034013606,
        "end": 6274.0199999999995,
        "id": 1918,
        "no_speech_prob": 0.0003859644930344075,
        "seek": 626362,
        "start": 6271.62,
        "temperature": 0,
        "text": " I need to call this additional.",
        "tokens": [
          50764,
          286,
          643,
          281,
          818,
          341,
          4497,
          13,
          50884
        ]
      },
      {
        "avg_logprob": -0.26305361797935084,
        "compression_ratio": 1.6462585034013606,
        "end": 6277.86,
        "id": 1919,
        "no_speech_prob": 0.0003859644930344075,
        "seek": 626362,
        "start": 6275.78,
        "temperature": 0,
        "text": " So because that's going to be a problem.",
        "tokens": [
          50972,
          407,
          570,
          300,
          311,
          516,
          281,
          312,
          257,
          1154,
          13,
          51076
        ]
      },
      {
        "avg_logprob": -0.26305361797935084,
        "compression_ratio": 1.6462585034013606,
        "end": 6289.0599999999995,
        "id": 1920,
        "no_speech_prob": 0.0003859644930344075,
        "seek": 626362,
        "start": 6277.86,
        "temperature": 0,
        "text": " Let's look everywhere I use words because additional, additional, additional.",
        "tokens": [
          51076,
          961,
          311,
          574,
          5315,
          286,
          764,
          2283,
          570,
          4497,
          11,
          4497,
          11,
          4497,
          13,
          51636
        ]
      },
      {
        "avg_logprob": -0.26305361797935084,
        "compression_ratio": 1.6462585034013606,
        "end": 6290.66,
        "id": 1921,
        "no_speech_prob": 0.0003859644930344075,
        "seek": 626362,
        "start": 6290.099999999999,
        "temperature": 0,
        "text": " Oh, boy.",
        "tokens": [
          51688,
          876,
          11,
          3237,
          13,
          51716
        ]
      },
      {
        "avg_logprob": -0.26305361797935084,
        "compression_ratio": 1.6462585034013606,
        "end": 6292.099999999999,
        "id": 1922,
        "no_speech_prob": 0.0003859644930344075,
        "seek": 626362,
        "start": 6291.38,
        "temperature": 0,
        "text": " Additional.",
        "tokens": [
          51752,
          44272,
          13,
          51788
        ]
      },
      {
        "avg_logprob": -0.26735050447525516,
        "compression_ratio": 1.4807692307692308,
        "end": 6295.38,
        "id": 1923,
        "no_speech_prob": 0.00009610222332412377,
        "seek": 629210,
        "start": 6292.1,
        "temperature": 0,
        "text": " OK, I just don't want to confuse my variable names.",
        "tokens": [
          50364,
          2264,
          11,
          286,
          445,
          500,
          380,
          528,
          281,
          28584,
          452,
          7006,
          5288,
          13,
          50528
        ]
      },
      {
        "avg_logprob": -0.26735050447525516,
        "compression_ratio": 1.4807692307692308,
        "end": 6301.860000000001,
        "id": 1924,
        "no_speech_prob": 0.00009610222332412377,
        "seek": 629210,
        "start": 6297.9400000000005,
        "temperature": 0,
        "text": " So here I should just call that tokens that I wouldn't have that problem.",
        "tokens": [
          50656,
          407,
          510,
          286,
          820,
          445,
          818,
          300,
          22667,
          300,
          286,
          2759,
          380,
          362,
          300,
          1154,
          13,
          50852
        ]
      },
      {
        "avg_logprob": -0.26735050447525516,
        "compression_ratio": 1.4807692307692308,
        "end": 6305.700000000001,
        "id": 1925,
        "no_speech_prob": 0.00009610222332412377,
        "seek": 629210,
        "start": 6301.860000000001,
        "temperature": 0,
        "text": " But if additional has own property.",
        "tokens": [
          50852,
          583,
          498,
          4497,
          575,
          1065,
          4707,
          13,
          51044
        ]
      },
      {
        "avg_logprob": -0.26735050447525516,
        "compression_ratio": 1.4807692307692308,
        "end": 6313.620000000001,
        "id": 1926,
        "no_speech_prob": 0.00009610222332412377,
        "seek": 629210,
        "start": 6307.22,
        "temperature": 0,
        "text": " And I want to see if word equals words index I has own property word.",
        "tokens": [
          51120,
          400,
          286,
          528,
          281,
          536,
          498,
          1349,
          6915,
          2283,
          8186,
          286,
          575,
          1065,
          4707,
          1349,
          13,
          51440
        ]
      },
      {
        "avg_logprob": -0.39908472696940106,
        "compression_ratio": 1.5545023696682465,
        "end": 6317.38,
        "id": 1927,
        "no_speech_prob": 0.1441357135772705,
        "seek": 631362,
        "start": 6313.94,
        "temperature": 0,
        "text": " Then total score plus equal additional.",
        "tokens": [
          50380,
          1396,
          3217,
          6175,
          1804,
          2681,
          4497,
          13,
          50552
        ]
      },
      {
        "avg_logprob": -0.39908472696940106,
        "compression_ratio": 1.5545023696682465,
        "end": 6323.14,
        "id": 1928,
        "no_speech_prob": 0.1441357135772705,
        "seek": 631362,
        "start": 6319.38,
        "temperature": 0,
        "text": " That word the value and a number I'm doing this kind of fast.",
        "tokens": [
          50652,
          663,
          1349,
          264,
          2158,
          293,
          257,
          1230,
          286,
          478,
          884,
          341,
          733,
          295,
          2370,
          13,
          50840
        ]
      },
      {
        "avg_logprob": -0.39908472696940106,
        "compression_ratio": 1.5545023696682465,
        "end": 6324.58,
        "id": 1929,
        "no_speech_prob": 0.1441357135772705,
        "seek": 631362,
        "start": 6323.14,
        "temperature": 0,
        "text": " I should reference you.",
        "tokens": [
          50840,
          286,
          820,
          6408,
          291,
          13,
          50912
        ]
      },
      {
        "avg_logprob": -0.39908472696940106,
        "compression_ratio": 1.5545023696682465,
        "end": 6329.46,
        "id": 1930,
        "no_speech_prob": 0.1441357135772705,
        "seek": 631362,
        "start": 6324.58,
        "temperature": 0,
        "text": " I did this exact sentiment analysis entirely in a separate coding of a challenge,",
        "tokens": [
          50912,
          286,
          630,
          341,
          1900,
          16149,
          5215,
          7696,
          294,
          257,
          4994,
          17720,
          295,
          257,
          3430,
          11,
          51156
        ]
      },
      {
        "avg_logprob": -0.39908472696940106,
        "compression_ratio": 1.5545023696682465,
        "end": 6331.0599999999995,
        "id": 1931,
        "no_speech_prob": 0.1441357135772705,
        "seek": 631362,
        "start": 6329.46,
        "temperature": 0,
        "text": " which I went through in a little more detail.",
        "tokens": [
          51156,
          597,
          286,
          1437,
          807,
          294,
          257,
          707,
          544,
          2607,
          13,
          51236
        ]
      },
      {
        "avg_logprob": -0.39908472696940106,
        "compression_ratio": 1.5545023696682465,
        "end": 6333.38,
        "id": 1932,
        "no_speech_prob": 0.1441357135772705,
        "seek": 631362,
        "start": 6331.94,
        "temperature": 0,
        "text": " So I can check if it's there.",
        "tokens": [
          51280,
          407,
          286,
          393,
          1520,
          498,
          309,
          311,
          456,
          13,
          51352
        ]
      },
      {
        "avg_logprob": -0.39908472696940106,
        "compression_ratio": 1.5545023696682465,
        "end": 6335.94,
        "id": 1933,
        "no_speech_prob": 0.1441357135772705,
        "seek": 631362,
        "start": 6334.9,
        "temperature": 0,
        "text": " If it's not there.",
        "tokens": [
          51428,
          759,
          309,
          311,
          406,
          456,
          13,
          51480
        ]
      },
      {
        "avg_logprob": -0.39908472696940106,
        "compression_ratio": 1.5545023696682465,
        "end": 6340.82,
        "id": 1934,
        "no_speech_prob": 0.1441357135772705,
        "seek": 631362,
        "start": 6338.9,
        "temperature": 0,
        "text": " Then I should also check.",
        "tokens": [
          51628,
          1396,
          286,
          820,
          611,
          1520,
          13,
          51724
        ]
      },
      {
        "avg_logprob": -0.27557656823135,
        "compression_ratio": 1.6713286713286712,
        "end": 6345.78,
        "id": 1935,
        "no_speech_prob": 0.00012533694098237902,
        "seek": 634362,
        "start": 6343.62,
        "temperature": 0,
        "text": " If it is in the a list.",
        "tokens": [
          50364,
          759,
          309,
          307,
          294,
          264,
          257,
          1329,
          13,
          50472
        ]
      },
      {
        "avg_logprob": -0.27557656823135,
        "compression_ratio": 1.6713286713286712,
        "end": 6353.14,
        "id": 1936,
        "no_speech_prob": 0.00012533694098237902,
        "seek": 634362,
        "start": 6349.14,
        "temperature": 0,
        "text": " And if it's in either one of those, I also let's get make a word list.",
        "tokens": [
          50640,
          400,
          498,
          309,
          311,
          294,
          2139,
          472,
          295,
          729,
          11,
          286,
          611,
          718,
          311,
          483,
          652,
          257,
          1349,
          1329,
          13,
          50840
        ]
      },
      {
        "avg_logprob": -0.27557656823135,
        "compression_ratio": 1.6713286713286712,
        "end": 6359.22,
        "id": 1937,
        "no_speech_prob": 0.00012533694098237902,
        "seek": 634362,
        "start": 6357.38,
        "temperature": 0,
        "text": " We'll just make it a word list.",
        "tokens": [
          51052,
          492,
          603,
          445,
          652,
          309,
          257,
          1349,
          1329,
          13,
          51144
        ]
      },
      {
        "avg_logprob": -0.27557656823135,
        "compression_ratio": 1.6713286713286712,
        "end": 6362.98,
        "id": 1938,
        "no_speech_prob": 0.00012533694098237902,
        "seek": 634362,
        "start": 6360.18,
        "temperature": 0,
        "text": " So we'll actually make it a word list.",
        "tokens": [
          51192,
          407,
          321,
          603,
          767,
          652,
          309,
          257,
          1349,
          1329,
          13,
          51332
        ]
      },
      {
        "avg_logprob": -0.27557656823135,
        "compression_ratio": 1.6713286713286712,
        "end": 6363.78,
        "id": 1939,
        "no_speech_prob": 0.00012533694098237902,
        "seek": 634362,
        "start": 6362.98,
        "temperature": 0,
        "text": " Sure, an array.",
        "tokens": [
          51332,
          4894,
          11,
          364,
          10225,
          13,
          51372
        ]
      },
      {
        "avg_logprob": -0.27557656823135,
        "compression_ratio": 1.6713286713286712,
        "end": 6366.099999999999,
        "id": 1940,
        "no_speech_prob": 0.00012533694098237902,
        "seek": 634362,
        "start": 6364.42,
        "temperature": 0,
        "text": " I could say in either of these cases.",
        "tokens": [
          51404,
          286,
          727,
          584,
          294,
          2139,
          295,
          613,
          3331,
          13,
          51488
        ]
      },
      {
        "avg_logprob": -0.27557656823135,
        "compression_ratio": 1.6713286713286712,
        "end": 6369.3,
        "id": 1941,
        "no_speech_prob": 0.00012533694098237902,
        "seek": 634362,
        "start": 6366.98,
        "temperature": 0,
        "text": " Word list dot push.",
        "tokens": [
          51532,
          8725,
          1329,
          5893,
          2944,
          13,
          51648
        ]
      },
      {
        "avg_logprob": -0.3625995275136587,
        "compression_ratio": 1.5033112582781456,
        "end": 6371.860000000001,
        "id": 1942,
        "no_speech_prob": 0.0010004956275224686,
        "seek": 636930,
        "start": 6370.26,
        "temperature": 0,
        "text": " An object that has word.",
        "tokens": [
          50412,
          1107,
          2657,
          300,
          575,
          1349,
          13,
          50492
        ]
      },
      {
        "avg_logprob": -0.3625995275136587,
        "compression_ratio": 1.5033112582781456,
        "end": 6374.26,
        "id": 1943,
        "no_speech_prob": 0.0010004956275224686,
        "seek": 636930,
        "start": 6372.820000000001,
        "temperature": 0,
        "text": " Word score.",
        "tokens": [
          50540,
          8725,
          6175,
          13,
          50612
        ]
      },
      {
        "avg_logprob": -0.3625995275136587,
        "compression_ratio": 1.5033112582781456,
        "end": 6378.02,
        "id": 1944,
        "no_speech_prob": 0.0010004956275224686,
        "seek": 636930,
        "start": 6375.06,
        "temperature": 0,
        "text": " And then and the score is var.",
        "tokens": [
          50652,
          400,
          550,
          293,
          264,
          6175,
          307,
          1374,
          13,
          50800
        ]
      },
      {
        "avg_logprob": -0.3625995275136587,
        "compression_ratio": 1.5033112582781456,
        "end": 6379.14,
        "id": 1945,
        "no_speech_prob": 0.0010004956275224686,
        "seek": 636930,
        "start": 6378.02,
        "temperature": 0,
        "text": " The score is.",
        "tokens": [
          50800,
          440,
          6175,
          307,
          13,
          50856
        ]
      },
      {
        "avg_logprob": -0.3625995275136587,
        "compression_ratio": 1.5033112582781456,
        "end": 6385.06,
        "id": 1946,
        "no_speech_prob": 0.0010004956275224686,
        "seek": 636930,
        "start": 6381.3,
        "temperature": 0,
        "text": " I can say var score if it's in additional.",
        "tokens": [
          50964,
          286,
          393,
          584,
          1374,
          6175,
          498,
          309,
          311,
          294,
          4497,
          13,
          51152
        ]
      },
      {
        "avg_logprob": -0.3625995275136587,
        "compression_ratio": 1.5033112582781456,
        "end": 6385.54,
        "id": 1947,
        "no_speech_prob": 0.0010004956275224686,
        "seek": 636930,
        "start": 6385.06,
        "temperature": 0,
        "text": " Oh, yeah.",
        "tokens": [
          51152,
          876,
          11,
          1338,
          13,
          51176
        ]
      },
      {
        "avg_logprob": -0.3625995275136587,
        "compression_ratio": 1.5033112582781456,
        "end": 6390.66,
        "id": 1948,
        "no_speech_prob": 0.0010004956275224686,
        "seek": 636930,
        "start": 6387.22,
        "temperature": 0,
        "text": " Score equals number additional.",
        "tokens": [
          51260,
          47901,
          6915,
          1230,
          4497,
          13,
          51432
        ]
      },
      {
        "avg_logprob": -0.3625995275136587,
        "compression_ratio": 1.5033112582781456,
        "end": 6392.900000000001,
        "id": 1949,
        "no_speech_prob": 0.0010004956275224686,
        "seek": 636930,
        "start": 6391.78,
        "temperature": 0,
        "text": " And then add that.",
        "tokens": [
          51488,
          400,
          550,
          909,
          300,
          13,
          51544
        ]
      },
      {
        "avg_logprob": -0.3625995275136587,
        "compression_ratio": 1.5033112582781456,
        "end": 6397.14,
        "id": 1950,
        "no_speech_prob": 0.0010004956275224686,
        "seek": 636930,
        "start": 6394.900000000001,
        "temperature": 0,
        "text": " This is not interesting to watch anymore.",
        "tokens": [
          51644,
          639,
          307,
          406,
          1880,
          281,
          1159,
          3602,
          13,
          51756
        ]
      },
      {
        "avg_logprob": -0.3224118853372241,
        "compression_ratio": 1.2573529411764706,
        "end": 6402.34,
        "id": 1951,
        "no_speech_prob": 0.00015356177755165845,
        "seek": 639714,
        "start": 6398.1,
        "temperature": 0,
        "text": " And otherwise, if it's in a fin.",
        "tokens": [
          50412,
          400,
          5911,
          11,
          498,
          309,
          311,
          294,
          257,
          962,
          13,
          50624
        ]
      },
      {
        "avg_logprob": -0.3224118853372241,
        "compression_ratio": 1.2573529411764706,
        "end": 6405.22,
        "id": 1952,
        "no_speech_prob": 0.00015356177755165845,
        "seek": 639714,
        "start": 6404.34,
        "temperature": 0,
        "text": " That's the score.",
        "tokens": [
          50724,
          663,
          311,
          264,
          6175,
          13,
          50768
        ]
      },
      {
        "avg_logprob": -0.3224118853372241,
        "compression_ratio": 1.2573529411764706,
        "end": 6406.900000000001,
        "id": 1953,
        "no_speech_prob": 0.00015356177755165845,
        "seek": 639714,
        "start": 6406.58,
        "temperature": 0,
        "text": " And.",
        "tokens": [
          50836,
          400,
          13,
          50852
        ]
      },
      {
        "avg_logprob": -0.3224118853372241,
        "compression_ratio": 1.2573529411764706,
        "end": 6413.860000000001,
        "id": 1954,
        "no_speech_prob": 0.00015356177755165845,
        "seek": 639714,
        "start": 6412.1,
        "temperature": 0,
        "text": " And then sorry.",
        "tokens": [
          51112,
          400,
          550,
          2597,
          13,
          51200
        ]
      },
      {
        "avg_logprob": -0.3224118853372241,
        "compression_ratio": 1.2573529411764706,
        "end": 6417.62,
        "id": 1955,
        "no_speech_prob": 0.00015356177755165845,
        "seek": 639714,
        "start": 6416.18,
        "temperature": 0,
        "text": " If I and so.",
        "tokens": [
          51316,
          759,
          286,
          293,
          370,
          13,
          51388
        ]
      },
      {
        "avg_logprob": -0.3224118853372241,
        "compression_ratio": 1.2573529411764706,
        "end": 6419.860000000001,
        "id": 1956,
        "no_speech_prob": 0.00015356177755165845,
        "seek": 639714,
        "start": 6419.22,
        "temperature": 0,
        "text": " Number.",
        "tokens": [
          51468,
          5118,
          13,
          51500
        ]
      },
      {
        "avg_logprob": -0.3224118853372241,
        "compression_ratio": 1.2573529411764706,
        "end": 6424.740000000001,
        "id": 1957,
        "no_speech_prob": 0.00015356177755165845,
        "seek": 639714,
        "start": 6419.860000000001,
        "temperature": 0,
        "text": " OK, so I'm just cleaning this up because now I can say total score plus equal.",
        "tokens": [
          51500,
          2264,
          11,
          370,
          286,
          478,
          445,
          8924,
          341,
          493,
          570,
          586,
          286,
          393,
          584,
          3217,
          6175,
          1804,
          2681,
          13,
          51744
        ]
      },
      {
        "avg_logprob": -0.22226774042302913,
        "compression_ratio": 1.714975845410628,
        "end": 6427.54,
        "id": 1958,
        "no_speech_prob": 0.000059208985476288944,
        "seek": 642474,
        "start": 6425.54,
        "temperature": 0,
        "text": " A plus equal the score.",
        "tokens": [
          50404,
          316,
          1804,
          2681,
          264,
          6175,
          13,
          50504
        ]
      },
      {
        "avg_logprob": -0.22226774042302913,
        "compression_ratio": 1.714975845410628,
        "end": 6431.54,
        "id": 1959,
        "no_speech_prob": 0.000059208985476288944,
        "seek": 642474,
        "start": 6427.54,
        "temperature": 0,
        "text": " So the score can start for every word can be assumed to be zero.",
        "tokens": [
          50504,
          407,
          264,
          6175,
          393,
          722,
          337,
          633,
          1349,
          393,
          312,
          15895,
          281,
          312,
          4018,
          13,
          50704
        ]
      },
      {
        "avg_logprob": -0.22226774042302913,
        "compression_ratio": 1.714975845410628,
        "end": 6435.62,
        "id": 1960,
        "no_speech_prob": 0.000059208985476288944,
        "seek": 642474,
        "start": 6432.099999999999,
        "temperature": 0,
        "text": " And if it's in additional, add the score.",
        "tokens": [
          50732,
          400,
          498,
          309,
          311,
          294,
          4497,
          11,
          909,
          264,
          6175,
          13,
          50908
        ]
      },
      {
        "avg_logprob": -0.22226774042302913,
        "compression_ratio": 1.714975845410628,
        "end": 6439.139999999999,
        "id": 1961,
        "no_speech_prob": 0.000059208985476288944,
        "seek": 642474,
        "start": 6436.5,
        "temperature": 0,
        "text": " You know, actually, so I don't need this here anymore.",
        "tokens": [
          50952,
          509,
          458,
          11,
          767,
          11,
          370,
          286,
          500,
          380,
          643,
          341,
          510,
          3602,
          13,
          51084
        ]
      },
      {
        "avg_logprob": -0.22226774042302913,
        "compression_ratio": 1.714975845410628,
        "end": 6440.74,
        "id": 1962,
        "no_speech_prob": 0.000059208985476288944,
        "seek": 642474,
        "start": 6439.139999999999,
        "temperature": 0,
        "text": " Get the score from additional.",
        "tokens": [
          51084,
          3240,
          264,
          6175,
          490,
          4497,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.22226774042302913,
        "compression_ratio": 1.714975845410628,
        "end": 6443.54,
        "id": 1963,
        "no_speech_prob": 0.000059208985476288944,
        "seek": 642474,
        "start": 6440.74,
        "temperature": 0,
        "text": " If it's in a fin, get the score from a fin.",
        "tokens": [
          51164,
          759,
          309,
          311,
          294,
          257,
          962,
          11,
          483,
          264,
          6175,
          490,
          257,
          962,
          13,
          51304
        ]
      },
      {
        "avg_logprob": -0.22226774042302913,
        "compression_ratio": 1.714975845410628,
        "end": 6446.42,
        "id": 1964,
        "no_speech_prob": 0.000059208985476288944,
        "seek": 642474,
        "start": 6443.54,
        "temperature": 0,
        "text": " And now what I could do, let's just get this working.",
        "tokens": [
          51304,
          400,
          586,
          437,
          286,
          727,
          360,
          11,
          718,
          311,
          445,
          483,
          341,
          1364,
          13,
          51448
        ]
      },
      {
        "avg_logprob": -0.22226774042302913,
        "compression_ratio": 1.714975845410628,
        "end": 6448.82,
        "id": 1965,
        "no_speech_prob": 0.000059208985476288944,
        "seek": 642474,
        "start": 6446.42,
        "temperature": 0,
        "text": " I could say reply is score.",
        "tokens": [
          51448,
          286,
          727,
          584,
          16972,
          307,
          6175,
          13,
          51568
        ]
      },
      {
        "avg_logprob": -0.22226774042302913,
        "compression_ratio": 1.714975845410628,
        "end": 6451.54,
        "id": 1966,
        "no_speech_prob": 0.000059208985476288944,
        "seek": 642474,
        "start": 6450.82,
        "temperature": 0,
        "text": " Total score.",
        "tokens": [
          51668,
          23170,
          6175,
          13,
          51704
        ]
      },
      {
        "avg_logprob": -0.48814203547335216,
        "compression_ratio": 1.6797752808988764,
        "end": 6453.3,
        "id": 1967,
        "no_speech_prob": 0.00026118927053175867,
        "seek": 645154,
        "start": 6452.26,
        "temperature": 0,
        "text": " And comparative.",
        "tokens": [
          50400,
          400,
          39292,
          13,
          50452
        ]
      },
      {
        "avg_logprob": -0.48814203547335216,
        "compression_ratio": 1.6797752808988764,
        "end": 6456.66,
        "id": 1968,
        "no_speech_prob": 0.00026118927053175867,
        "seek": 645154,
        "start": 6455.86,
        "temperature": 0,
        "text": " Comparative.",
        "tokens": [
          50580,
          2432,
          2181,
          1166,
          13,
          50620
        ]
      },
      {
        "avg_logprob": -0.48814203547335216,
        "compression_ratio": 1.6797752808988764,
        "end": 6458.66,
        "id": 1969,
        "no_speech_prob": 0.00026118927053175867,
        "seek": 645154,
        "start": 6457.86,
        "temperature": 0,
        "text": " Comparative.",
        "tokens": [
          50680,
          2432,
          2181,
          1166,
          13,
          50720
        ]
      },
      {
        "avg_logprob": -0.48814203547335216,
        "compression_ratio": 1.6797752808988764,
        "end": 6466.9,
        "id": 1970,
        "no_speech_prob": 0.00026118927053175867,
        "seek": 645154,
        "start": 6459.54,
        "temperature": 0,
        "text": " Comparative in the Afin111 sentiment analysis, the comparative value is the total score.",
        "tokens": [
          50764,
          2432,
          2181,
          1166,
          294,
          264,
          316,
          5194,
          5348,
          16,
          16149,
          5215,
          11,
          264,
          39292,
          2158,
          307,
          264,
          3217,
          6175,
          13,
          51132
        ]
      },
      {
        "avg_logprob": -0.48814203547335216,
        "compression_ratio": 1.6797752808988764,
        "end": 6471.7,
        "id": 1971,
        "no_speech_prob": 0.00026118927053175867,
        "seek": 645154,
        "start": 6468.34,
        "temperature": 0,
        "text": " Divided by how many words are in the text words dot length.",
        "tokens": [
          51204,
          413,
          1843,
          292,
          538,
          577,
          867,
          2283,
          366,
          294,
          264,
          2487,
          2283,
          5893,
          4641,
          13,
          51372
        ]
      },
      {
        "avg_logprob": -0.48814203547335216,
        "compression_ratio": 1.6797752808988764,
        "end": 6475.86,
        "id": 1972,
        "no_speech_prob": 0.00026118927053175867,
        "seek": 645154,
        "start": 6472.82,
        "temperature": 0,
        "text": " So now we should see that I'm getting the text.",
        "tokens": [
          51428,
          407,
          586,
          321,
          820,
          536,
          300,
          286,
          478,
          1242,
          264,
          2487,
          13,
          51580
        ]
      },
      {
        "avg_logprob": -0.48814203547335216,
        "compression_ratio": 1.6797752808988764,
        "end": 6479.54,
        "id": 1973,
        "no_speech_prob": 0.00026118927053175867,
        "seek": 645154,
        "start": 6476.58,
        "temperature": 0,
        "text": " So my server is now receiving the text as the post request.",
        "tokens": [
          51616,
          407,
          452,
          7154,
          307,
          586,
          10040,
          264,
          2487,
          382,
          264,
          2183,
          5308,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.4007271785362094,
        "compression_ratio": 1.5844748858447488,
        "end": 6484.1,
        "id": 1974,
        "no_speech_prob": 0.001455051708035171,
        "seek": 647954,
        "start": 6479.54,
        "temperature": 0,
        "text": " Chopping up into words, looking at every single word, seeing if it's in one of the lists,",
        "tokens": [
          50364,
          25615,
          3381,
          493,
          666,
          2283,
          11,
          1237,
          412,
          633,
          2167,
          1349,
          11,
          2577,
          498,
          309,
          311,
          294,
          472,
          295,
          264,
          14511,
          11,
          50592
        ]
      },
      {
        "avg_logprob": -0.4007271785362094,
        "compression_ratio": 1.5844748858447488,
        "end": 6485.62,
        "id": 1975,
        "no_speech_prob": 0.001455051708035171,
        "seek": 647954,
        "start": 6484.1,
        "temperature": 0,
        "text": " and then spitting back.",
        "tokens": [
          50592,
          293,
          550,
          637,
          2414,
          646,
          13,
          50668
        ]
      },
      {
        "avg_logprob": -0.4007271785362094,
        "compression_ratio": 1.5844748858447488,
        "end": 6488.5,
        "id": 1976,
        "no_speech_prob": 0.001455051708035171,
        "seek": 647954,
        "start": 6486.5,
        "temperature": 0,
        "text": " So let's run this.",
        "tokens": [
          50712,
          407,
          718,
          311,
          1190,
          341,
          13,
          50812
        ]
      },
      {
        "avg_logprob": -0.4007271785362094,
        "compression_ratio": 1.5844748858447488,
        "end": 6491.86,
        "id": 1977,
        "no_speech_prob": 0.001455051708035171,
        "seek": 647954,
        "start": 6490.1,
        "temperature": 0,
        "text": " Oh, I need to restart the server.",
        "tokens": [
          50892,
          876,
          11,
          286,
          643,
          281,
          21022,
          264,
          7154,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.4007271785362094,
        "compression_ratio": 1.5844748858447488,
        "end": 6493.14,
        "id": 1978,
        "no_speech_prob": 0.001455051708035171,
        "seek": 647954,
        "start": 6492.58,
        "temperature": 0,
        "text": " I have an error.",
        "tokens": [
          51016,
          286,
          362,
          364,
          6713,
          13,
          51044
        ]
      },
      {
        "avg_logprob": -0.4007271785362094,
        "compression_ratio": 1.5844748858447488,
        "end": 6499.22,
        "id": 1979,
        "no_speech_prob": 0.001455051708035171,
        "seek": 647954,
        "start": 6493.14,
        "temperature": 0,
        "text": " Words is not defined where in line number six, which is here.",
        "tokens": [
          51044,
          32857,
          307,
          406,
          7642,
          689,
          294,
          1622,
          1230,
          2309,
          11,
          597,
          307,
          510,
          13,
          51348
        ]
      },
      {
        "avg_logprob": -0.4007271785362094,
        "compression_ratio": 1.5844748858447488,
        "end": 6501.94,
        "id": 1980,
        "no_speech_prob": 0.001455051708035171,
        "seek": 647954,
        "start": 6499.22,
        "temperature": 0,
        "text": " I don't actually need this console log was just for debugging earlier.",
        "tokens": [
          51348,
          286,
          500,
          380,
          767,
          643,
          341,
          11076,
          3565,
          390,
          445,
          337,
          45592,
          3071,
          13,
          51484
        ]
      },
      {
        "avg_logprob": -0.4007271785362094,
        "compression_ratio": 1.5844748858447488,
        "end": 6506.42,
        "id": 1981,
        "no_speech_prob": 0.001455051708035171,
        "seek": 647954,
        "start": 6504.5,
        "temperature": 0,
        "text": " So let's run the server again.",
        "tokens": [
          51612,
          407,
          718,
          311,
          1190,
          264,
          7154,
          797,
          13,
          51708
        ]
      },
      {
        "avg_logprob": -0.21098178141825907,
        "compression_ratio": 1.538812785388128,
        "end": 6508.9,
        "id": 1982,
        "no_speech_prob": 0.0008830404258333147,
        "seek": 650642,
        "start": 6507.06,
        "temperature": 0,
        "text": " So let's run the server again.",
        "tokens": [
          50396,
          407,
          718,
          311,
          1190,
          264,
          7154,
          797,
          13,
          50488
        ]
      },
      {
        "avg_logprob": -0.21098178141825907,
        "compression_ratio": 1.538812785388128,
        "end": 6514.34,
        "id": 1983,
        "no_speech_prob": 0.0008830404258333147,
        "seek": 650642,
        "start": 6511.38,
        "temperature": 0,
        "text": " Refresh and hit analyze.",
        "tokens": [
          50612,
          16957,
          3644,
          293,
          2045,
          12477,
          13,
          50760
        ]
      },
      {
        "avg_logprob": -0.21098178141825907,
        "compression_ratio": 1.538812785388128,
        "end": 6515.86,
        "id": 1984,
        "no_speech_prob": 0.0008830404258333147,
        "seek": 650642,
        "start": 6514.34,
        "temperature": 0,
        "text": " And we got an error.",
        "tokens": [
          50760,
          400,
          321,
          658,
          364,
          6713,
          13,
          50836
        ]
      },
      {
        "avg_logprob": -0.21098178141825907,
        "compression_ratio": 1.538812785388128,
        "end": 6517.46,
        "id": 1985,
        "no_speech_prob": 0.0008830404258333147,
        "seek": 650642,
        "start": 6517.14,
        "temperature": 0,
        "text": " False.",
        "tokens": [
          50900,
          50040,
          13,
          50916
        ]
      },
      {
        "avg_logprob": -0.21098178141825907,
        "compression_ratio": 1.538812785388128,
        "end": 6518.58,
        "id": 1986,
        "no_speech_prob": 0.0008830404258333147,
        "seek": 650642,
        "start": 6517.46,
        "temperature": 0,
        "text": " I got some error.",
        "tokens": [
          50916,
          286,
          658,
          512,
          6713,
          13,
          50972
        ]
      },
      {
        "avg_logprob": -0.21098178141825907,
        "compression_ratio": 1.538812785388128,
        "end": 6519.7,
        "id": 1987,
        "no_speech_prob": 0.0008830404258333147,
        "seek": 650642,
        "start": 6519.14,
        "temperature": 0,
        "text": " So what happened?",
        "tokens": [
          51000,
          407,
          437,
          2011,
          30,
          51028
        ]
      },
      {
        "avg_logprob": -0.21098178141825907,
        "compression_ratio": 1.538812785388128,
        "end": 6521.14,
        "id": 1988,
        "no_speech_prob": 0.0008830404258333147,
        "seek": 650642,
        "start": 6519.7,
        "temperature": 0,
        "text": " Let's look at the console.",
        "tokens": [
          51028,
          961,
          311,
          574,
          412,
          264,
          11076,
          13,
          51100
        ]
      },
      {
        "avg_logprob": -0.21098178141825907,
        "compression_ratio": 1.538812785388128,
        "end": 6522.1,
        "id": 1989,
        "no_speech_prob": 0.0008830404258333147,
        "seek": 650642,
        "start": 6521.14,
        "temperature": 0,
        "text": " Oh, yeah, I got an error.",
        "tokens": [
          51100,
          876,
          11,
          1338,
          11,
          286,
          658,
          364,
          6713,
          13,
          51148
        ]
      },
      {
        "avg_logprob": -0.21098178141825907,
        "compression_ratio": 1.538812785388128,
        "end": 6524.66,
        "id": 1990,
        "no_speech_prob": 0.0008830404258333147,
        "seek": 650642,
        "start": 6523.46,
        "temperature": 0,
        "text": " Comp is not defined.",
        "tokens": [
          51216,
          6620,
          307,
          406,
          7642,
          13,
          51276
        ]
      },
      {
        "avg_logprob": -0.21098178141825907,
        "compression_ratio": 1.538812785388128,
        "end": 6530.74,
        "id": 1991,
        "no_speech_prob": 0.0008830404258333147,
        "seek": 650642,
        "start": 6526.1,
        "temperature": 0,
        "text": " So I made a mistake because I'm trying to do this so quickly, and I'm not being careful.",
        "tokens": [
          51348,
          407,
          286,
          1027,
          257,
          6146,
          570,
          286,
          478,
          1382,
          281,
          360,
          341,
          370,
          2661,
          11,
          293,
          286,
          478,
          406,
          885,
          5026,
          13,
          51580
        ]
      },
      {
        "avg_logprob": -0.21098178141825907,
        "compression_ratio": 1.538812785388128,
        "end": 6533.9400000000005,
        "id": 1992,
        "no_speech_prob": 0.0008830404258333147,
        "seek": 650642,
        "start": 6530.74,
        "temperature": 0,
        "text": " And where is where I have lost where the code this is.",
        "tokens": [
          51580,
          400,
          689,
          307,
          689,
          286,
          362,
          2731,
          689,
          264,
          3089,
          341,
          307,
          13,
          51740
        ]
      },
      {
        "avg_logprob": -0.21648298899332682,
        "compression_ratio": 1.4973544973544974,
        "end": 6535.78,
        "id": 1993,
        "no_speech_prob": 0.000060141243011457846,
        "seek": 653394,
        "start": 6533.94,
        "temperature": 0,
        "text": " Oh, comp.",
        "tokens": [
          50364,
          876,
          11,
          715,
          13,
          50456
        ]
      },
      {
        "avg_logprob": -0.21648298899332682,
        "compression_ratio": 1.4973544973544974,
        "end": 6538.0199999999995,
        "id": 1994,
        "no_speech_prob": 0.000060141243011457846,
        "seek": 653394,
        "start": 6536.82,
        "temperature": 0,
        "text": " Oh, wait, comp.",
        "tokens": [
          50508,
          876,
          11,
          1699,
          11,
          715,
          13,
          50568
        ]
      },
      {
        "avg_logprob": -0.21648298899332682,
        "compression_ratio": 1.4973544973544974,
        "end": 6540.9,
        "id": 1995,
        "no_speech_prob": 0.000060141243011457846,
        "seek": 653394,
        "start": 6539.46,
        "temperature": 0,
        "text": " And then this could be comparative.",
        "tokens": [
          50640,
          400,
          550,
          341,
          727,
          312,
          39292,
          13,
          50712
        ]
      },
      {
        "avg_logprob": -0.21648298899332682,
        "compression_ratio": 1.4973544973544974,
        "end": 6543.46,
        "id": 1996,
        "no_speech_prob": 0.000060141243011457846,
        "seek": 653394,
        "start": 6541.46,
        "temperature": 0,
        "text": " I'm just not naming things carefully.",
        "tokens": [
          50740,
          286,
          478,
          445,
          406,
          25290,
          721,
          7500,
          13,
          50840
        ]
      },
      {
        "avg_logprob": -0.21648298899332682,
        "compression_ratio": 1.4973544973544974,
        "end": 6545.299999999999,
        "id": 1997,
        "no_speech_prob": 0.000060141243011457846,
        "seek": 653394,
        "start": 6543.46,
        "temperature": 0,
        "text": " So this is the reply that I want to send back.",
        "tokens": [
          50840,
          407,
          341,
          307,
          264,
          16972,
          300,
          286,
          528,
          281,
          2845,
          646,
          13,
          50932
        ]
      },
      {
        "avg_logprob": -0.21648298899332682,
        "compression_ratio": 1.4973544973544974,
        "end": 6550.98,
        "id": 1998,
        "no_speech_prob": 0.000060141243011457846,
        "seek": 653394,
        "start": 6549.54,
        "temperature": 0,
        "text": " Oops, I have to restart the server.",
        "tokens": [
          51144,
          21726,
          11,
          286,
          362,
          281,
          21022,
          264,
          7154,
          13,
          51216
        ]
      },
      {
        "avg_logprob": -0.21648298899332682,
        "compression_ratio": 1.4973544973544974,
        "end": 6556.58,
        "id": 1999,
        "no_speech_prob": 0.000060141243011457846,
        "seek": 653394,
        "start": 6555.7,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51452,
          821,
          321,
          352,
          13,
          51496
        ]
      },
      {
        "avg_logprob": -0.21648298899332682,
        "compression_ratio": 1.4973544973544974,
        "end": 6557.62,
        "id": 2000,
        "no_speech_prob": 0.000060141243011457846,
        "seek": 653394,
        "start": 6556.58,
        "temperature": 0,
        "text": " And look at this.",
        "tokens": [
          51496,
          400,
          574,
          412,
          341,
          13,
          51548
        ]
      },
      {
        "avg_logprob": -0.21648298899332682,
        "compression_ratio": 1.4973544973544974,
        "end": 6561.379999999999,
        "id": 2001,
        "no_speech_prob": 0.000060141243011457846,
        "seek": 653394,
        "start": 6557.62,
        "temperature": 0,
        "text": " Every time I analyze, I get both the comparative score and the score.",
        "tokens": [
          51548,
          2048,
          565,
          286,
          12477,
          11,
          286,
          483,
          1293,
          264,
          39292,
          6175,
          293,
          264,
          6175,
          13,
          51736
        ]
      },
      {
        "avg_logprob": -0.17965570572883852,
        "compression_ratio": 1.8783783783783783,
        "end": 6563.62,
        "id": 2002,
        "no_speech_prob": 0.002590947551652789,
        "seek": 656138,
        "start": 6561.38,
        "temperature": 0,
        "text": " Now, I really want to also send back a list of words.",
        "tokens": [
          50364,
          823,
          11,
          286,
          534,
          528,
          281,
          611,
          2845,
          646,
          257,
          1329,
          295,
          2283,
          13,
          50476
        ]
      },
      {
        "avg_logprob": -0.17965570572883852,
        "compression_ratio": 1.8783783783783783,
        "end": 6565.62,
        "id": 2003,
        "no_speech_prob": 0.002590947551652789,
        "seek": 656138,
        "start": 6563.62,
        "temperature": 0,
        "text": " And I want this to be an exercise.",
        "tokens": [
          50476,
          400,
          286,
          528,
          341,
          281,
          312,
          364,
          5380,
          13,
          50576
        ]
      },
      {
        "avg_logprob": -0.17965570572883852,
        "compression_ratio": 1.8783783783783783,
        "end": 6567.7,
        "id": 2004,
        "no_speech_prob": 0.002590947551652789,
        "seek": 656138,
        "start": 6565.62,
        "temperature": 0,
        "text": " I'm going to do it anyway, because I want to see it here.",
        "tokens": [
          50576,
          286,
          478,
          516,
          281,
          360,
          309,
          4033,
          11,
          570,
          286,
          528,
          281,
          536,
          309,
          510,
          13,
          50680
        ]
      },
      {
        "avg_logprob": -0.17965570572883852,
        "compression_ratio": 1.8783783783783783,
        "end": 6573.38,
        "id": 2005,
        "no_speech_prob": 0.002590947551652789,
        "seek": 656138,
        "start": 6567.7,
        "temperature": 0,
        "text": " So what I'm going to do is I am going to also say I'm going to make a variable called found.",
        "tokens": [
          50680,
          407,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          669,
          516,
          281,
          611,
          584,
          286,
          478,
          516,
          281,
          652,
          257,
          7006,
          1219,
          1352,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.17965570572883852,
        "compression_ratio": 1.8783783783783783,
        "end": 6580.26,
        "id": 2006,
        "no_speech_prob": 0.002590947551652789,
        "seek": 656138,
        "start": 6573.9400000000005,
        "temperature": 0,
        "text": " Just add into an I'm going to make an array of objects with word, word, score, score,",
        "tokens": [
          50992,
          1449,
          909,
          666,
          364,
          286,
          478,
          516,
          281,
          652,
          364,
          10225,
          295,
          6565,
          365,
          1349,
          11,
          1349,
          11,
          6175,
          11,
          6175,
          11,
          51308
        ]
      },
      {
        "avg_logprob": -0.17965570572883852,
        "compression_ratio": 1.8783783783783783,
        "end": 6581.54,
        "id": 2007,
        "no_speech_prob": 0.002590947551652789,
        "seek": 656138,
        "start": 6580.26,
        "temperature": 0,
        "text": " which is a little awkward.",
        "tokens": [
          51308,
          597,
          307,
          257,
          707,
          11411,
          13,
          51372
        ]
      },
      {
        "avg_logprob": -0.17965570572883852,
        "compression_ratio": 1.8783783783783783,
        "end": 6588.18,
        "id": 2008,
        "no_speech_prob": 0.002590947551652789,
        "seek": 656138,
        "start": 6581.54,
        "temperature": 0,
        "text": " But now what I can do is I can also send back the list of words.",
        "tokens": [
          51372,
          583,
          586,
          437,
          286,
          393,
          360,
          307,
          286,
          393,
          611,
          2845,
          646,
          264,
          1329,
          295,
          2283,
          13,
          51704
        ]
      },
      {
        "avg_logprob": -0.3796234130859375,
        "compression_ratio": 1.4310344827586208,
        "end": 6593.46,
        "id": 2009,
        "no_speech_prob": 0.0018386533483862877,
        "seek": 658818,
        "start": 6589.06,
        "temperature": 0,
        "text": " So I'm just saving every word and its score if it was found in one of those lists.",
        "tokens": [
          50408,
          407,
          286,
          478,
          445,
          6816,
          633,
          1349,
          293,
          1080,
          6175,
          498,
          309,
          390,
          1352,
          294,
          472,
          295,
          729,
          14511,
          13,
          50628
        ]
      },
      {
        "avg_logprob": -0.3796234130859375,
        "compression_ratio": 1.4310344827586208,
        "end": 6600.5,
        "id": 2010,
        "no_speech_prob": 0.0018386533483862877,
        "seek": 658818,
        "start": 6593.46,
        "temperature": 0,
        "text": " Because now if I run this again, and it hits analyze array zero.",
        "tokens": [
          50628,
          1436,
          586,
          498,
          286,
          1190,
          341,
          797,
          11,
          293,
          309,
          8664,
          12477,
          10225,
          4018,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.3796234130859375,
        "compression_ratio": 1.4310344827586208,
        "end": 6602.02,
        "id": 2011,
        "no_speech_prob": 0.0018386533483862877,
        "seek": 658818,
        "start": 6600.5,
        "temperature": 0,
        "text": " So I did something wrong.",
        "tokens": [
          50980,
          407,
          286,
          630,
          746,
          2085,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.3796234130859375,
        "compression_ratio": 1.4310344827586208,
        "end": 6603.3,
        "id": 2012,
        "no_speech_prob": 0.0018386533483862877,
        "seek": 658818,
        "start": 6602.02,
        "temperature": 0,
        "text": " Let's look at this again.",
        "tokens": [
          51056,
          961,
          311,
          574,
          412,
          341,
          797,
          13,
          51120
        ]
      },
      {
        "avg_logprob": -0.3796234130859375,
        "compression_ratio": 1.4310344827586208,
        "end": 6606.34,
        "id": 2013,
        "no_speech_prob": 0.0018386533483862877,
        "seek": 658818,
        "start": 6605.3,
        "temperature": 0,
        "text": " Found is false.",
        "tokens": [
          51220,
          8207,
          307,
          7908,
          13,
          51272
        ]
      },
      {
        "avg_logprob": -0.3796234130859375,
        "compression_ratio": 1.4310344827586208,
        "end": 6610.58,
        "id": 2014,
        "no_speech_prob": 0.0018386533483862877,
        "seek": 658818,
        "start": 6606.34,
        "temperature": 0,
        "text": " Now, if found word list dot push.",
        "tokens": [
          51272,
          823,
          11,
          498,
          1352,
          1349,
          1329,
          5893,
          2944,
          13,
          51484
        ]
      },
      {
        "avg_logprob": -0.2814730475930607,
        "compression_ratio": 1.6407185628742516,
        "end": 6611.54,
        "id": 2015,
        "no_speech_prob": 0.060083549469709396,
        "seek": 661058,
        "start": 6610.82,
        "temperature": 0,
        "text": " Dot push.",
        "tokens": [
          50376,
          38753,
          2944,
          13,
          50412
        ]
      },
      {
        "avg_logprob": -0.2814730475930607,
        "compression_ratio": 1.6407185628742516,
        "end": 6618.66,
        "id": 2016,
        "no_speech_prob": 0.060083549469709396,
        "seek": 661058,
        "start": 6615.3,
        "temperature": 0,
        "text": " So why would the list have nothing in it?",
        "tokens": [
          50600,
          407,
          983,
          576,
          264,
          1329,
          362,
          1825,
          294,
          309,
          30,
          50768
        ]
      },
      {
        "avg_logprob": -0.2814730475930607,
        "compression_ratio": 1.6407185628742516,
        "end": 6625.54,
        "id": 2017,
        "no_speech_prob": 0.060083549469709396,
        "seek": 661058,
        "start": 6624.66,
        "temperature": 0,
        "text": " Edit this part out.",
        "tokens": [
          51068,
          33241,
          341,
          644,
          484,
          13,
          51112
        ]
      },
      {
        "avg_logprob": -0.2814730475930607,
        "compression_ratio": 1.6407185628742516,
        "end": 6626.18,
        "id": 2018,
        "no_speech_prob": 0.060083549469709396,
        "seek": 661058,
        "start": 6625.54,
        "temperature": 0,
        "text": " La la la la la.",
        "tokens": [
          51112,
          2369,
          635,
          635,
          635,
          635,
          13,
          51144
        ]
      },
      {
        "avg_logprob": -0.2814730475930607,
        "compression_ratio": 1.6407185628742516,
        "end": 6627.38,
        "id": 2019,
        "no_speech_prob": 0.060083549469709396,
        "seek": 661058,
        "start": 6626.18,
        "temperature": 0,
        "text": " I'm thinking, thinking, thinking.",
        "tokens": [
          51144,
          286,
          478,
          1953,
          11,
          1953,
          11,
          1953,
          13,
          51204
        ]
      },
      {
        "avg_logprob": -0.2814730475930607,
        "compression_ratio": 1.6407185628742516,
        "end": 6628.98,
        "id": 2020,
        "no_speech_prob": 0.060083549469709396,
        "seek": 661058,
        "start": 6628.0199999999995,
        "temperature": 0,
        "text": " Word list push.",
        "tokens": [
          51236,
          8725,
          1329,
          2944,
          13,
          51284
        ]
      },
      {
        "avg_logprob": -0.2814730475930607,
        "compression_ratio": 1.6407185628742516,
        "end": 6629.78,
        "id": 2021,
        "no_speech_prob": 0.060083549469709396,
        "seek": 661058,
        "start": 6629.54,
        "temperature": 0,
        "text": " Right.",
        "tokens": [
          51312,
          1779,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.2814730475930607,
        "compression_ratio": 1.6407185628742516,
        "end": 6631.94,
        "id": 2022,
        "no_speech_prob": 0.060083549469709396,
        "seek": 661058,
        "start": 6629.78,
        "temperature": 0,
        "text": " I made a word list with an empty.",
        "tokens": [
          51324,
          286,
          1027,
          257,
          1349,
          1329,
          365,
          364,
          6707,
          13,
          51432
        ]
      },
      {
        "avg_logprob": -0.2814730475930607,
        "compression_ratio": 1.6407185628742516,
        "end": 6634.1,
        "id": 2023,
        "no_speech_prob": 0.060083549469709396,
        "seek": 661058,
        "start": 6631.94,
        "temperature": 0,
        "text": " And then I say if it's in there, found.",
        "tokens": [
          51432,
          400,
          550,
          286,
          584,
          498,
          309,
          311,
          294,
          456,
          11,
          1352,
          13,
          51540
        ]
      },
      {
        "avg_logprob": -0.2814730475930607,
        "compression_ratio": 1.6407185628742516,
        "end": 6636.0199999999995,
        "id": 2024,
        "no_speech_prob": 0.060083549469709396,
        "seek": 661058,
        "start": 6634.1,
        "temperature": 0,
        "text": " If it's in there, found.",
        "tokens": [
          51540,
          759,
          309,
          311,
          294,
          456,
          11,
          1352,
          13,
          51636
        ]
      },
      {
        "avg_logprob": -0.2814730475930607,
        "compression_ratio": 1.6407185628742516,
        "end": 6637.3,
        "id": 2025,
        "no_speech_prob": 0.060083549469709396,
        "seek": 661058,
        "start": 6636.58,
        "temperature": 0,
        "text": " If found.",
        "tokens": [
          51664,
          759,
          1352,
          13,
          51700
        ]
      },
      {
        "avg_logprob": -0.2814730475930607,
        "compression_ratio": 1.6407185628742516,
        "end": 6638.74,
        "id": 2026,
        "no_speech_prob": 0.060083549469709396,
        "seek": 661058,
        "start": 6637.86,
        "temperature": 0,
        "text": " Push it in the list.",
        "tokens": [
          51728,
          18229,
          309,
          294,
          264,
          1329,
          13,
          51772
        ]
      },
      {
        "avg_logprob": -0.23267681458417108,
        "compression_ratio": 1.6891891891891893,
        "end": 6639.38,
        "id": 2027,
        "no_speech_prob": 0.0013458544854074717,
        "seek": 663874,
        "start": 6638.74,
        "temperature": 0,
        "text": " All right, well, let's.",
        "tokens": [
          50364,
          1057,
          558,
          11,
          731,
          11,
          718,
          311,
          13,
          50396
        ]
      },
      {
        "avg_logprob": -0.23267681458417108,
        "compression_ratio": 1.6891891891891893,
        "end": 6643.139999999999,
        "id": 2028,
        "no_speech_prob": 0.0013458544854074717,
        "seek": 663874,
        "start": 6641.7,
        "temperature": 0,
        "text": " Oh, whoa.",
        "tokens": [
          50512,
          876,
          11,
          13310,
          13,
          50584
        ]
      },
      {
        "avg_logprob": -0.23267681458417108,
        "compression_ratio": 1.6891891891891893,
        "end": 6645.139999999999,
        "id": 2029,
        "no_speech_prob": 0.0013458544854074717,
        "seek": 663874,
        "start": 6643.86,
        "temperature": 0,
        "text": " The word list has to be out here.",
        "tokens": [
          50620,
          440,
          1349,
          1329,
          575,
          281,
          312,
          484,
          510,
          13,
          50684
        ]
      },
      {
        "avg_logprob": -0.23267681458417108,
        "compression_ratio": 1.6891891891891893,
        "end": 6646.5,
        "id": 2030,
        "no_speech_prob": 0.0013458544854074717,
        "seek": 663874,
        "start": 6645.139999999999,
        "temperature": 0,
        "text": " I initialized the array.",
        "tokens": [
          50684,
          286,
          5883,
          1602,
          264,
          10225,
          13,
          50752
        ]
      },
      {
        "avg_logprob": -0.23267681458417108,
        "compression_ratio": 1.6891891891891893,
        "end": 6648.9,
        "id": 2031,
        "no_speech_prob": 0.0013458544854074717,
        "seek": 663874,
        "start": 6646.5,
        "temperature": 0,
        "text": " Oh, I reinitialized the array in there.",
        "tokens": [
          50752,
          876,
          11,
          286,
          6561,
          270,
          831,
          1602,
          264,
          10225,
          294,
          456,
          13,
          50872
        ]
      },
      {
        "avg_logprob": -0.23267681458417108,
        "compression_ratio": 1.6891891891891893,
        "end": 6649.54,
        "id": 2032,
        "no_speech_prob": 0.0013458544854074717,
        "seek": 663874,
        "start": 6648.9,
        "temperature": 0,
        "text": " Wait, hold on.",
        "tokens": [
          50872,
          3802,
          11,
          1797,
          322,
          13,
          50904
        ]
      },
      {
        "avg_logprob": -0.23267681458417108,
        "compression_ratio": 1.6891891891891893,
        "end": 6654.0199999999995,
        "id": 2033,
        "no_speech_prob": 0.0013458544854074717,
        "seek": 663874,
        "start": 6653.62,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          51108,
          45263,
          13,
          51128
        ]
      },
      {
        "avg_logprob": -0.23267681458417108,
        "compression_ratio": 1.6891891891891893,
        "end": 6656.82,
        "id": 2034,
        "no_speech_prob": 0.0013458544854074717,
        "seek": 663874,
        "start": 6654.0199999999995,
        "temperature": 0,
        "text": " I initialized the array in the loop, which means I kept clearing it out.",
        "tokens": [
          51128,
          286,
          5883,
          1602,
          264,
          10225,
          294,
          264,
          6367,
          11,
          597,
          1355,
          286,
          4305,
          23937,
          309,
          484,
          13,
          51268
        ]
      },
      {
        "avg_logprob": -0.23267681458417108,
        "compression_ratio": 1.6891891891891893,
        "end": 6658.58,
        "id": 2035,
        "no_speech_prob": 0.0013458544854074717,
        "seek": 663874,
        "start": 6656.82,
        "temperature": 0,
        "text": " So of course, there's nothing in the array.",
        "tokens": [
          51268,
          407,
          295,
          1164,
          11,
          456,
          311,
          1825,
          294,
          264,
          10225,
          13,
          51356
        ]
      },
      {
        "avg_logprob": -0.23267681458417108,
        "compression_ratio": 1.6891891891891893,
        "end": 6659.78,
        "id": 2036,
        "no_speech_prob": 0.0013458544854074717,
        "seek": 663874,
        "start": 6658.58,
        "temperature": 0,
        "text": " Let me take that out there.",
        "tokens": [
          51356,
          961,
          385,
          747,
          300,
          484,
          456,
          13,
          51416
        ]
      },
      {
        "avg_logprob": -0.23267681458417108,
        "compression_ratio": 1.6891891891891893,
        "end": 6661.94,
        "id": 2037,
        "no_speech_prob": 0.0013458544854074717,
        "seek": 663874,
        "start": 6661.139999999999,
        "temperature": 0,
        "text": " Run this again.",
        "tokens": [
          51484,
          8950,
          341,
          797,
          13,
          51524
        ]
      },
      {
        "avg_logprob": -0.23267681458417108,
        "compression_ratio": 1.6891891891891893,
        "end": 6663.54,
        "id": 2038,
        "no_speech_prob": 0.0013458544854074717,
        "seek": 663874,
        "start": 6662.58,
        "temperature": 0,
        "text": " Refresh.",
        "tokens": [
          51556,
          16957,
          3644,
          13,
          51604
        ]
      },
      {
        "avg_logprob": -0.23267681458417108,
        "compression_ratio": 1.6891891891891893,
        "end": 6664.26,
        "id": 2039,
        "no_speech_prob": 0.0013458544854074717,
        "seek": 663874,
        "start": 6663.54,
        "temperature": 0,
        "text": " Analyze.",
        "tokens": [
          51604,
          1107,
          5222,
          1381,
          13,
          51640
        ]
      },
      {
        "avg_logprob": -0.23267681458417108,
        "compression_ratio": 1.6891891891891893,
        "end": 6665.139999999999,
        "id": 2040,
        "no_speech_prob": 0.0013458544854074717,
        "seek": 663874,
        "start": 6664.26,
        "temperature": 0,
        "text": " And now we can see.",
        "tokens": [
          51640,
          400,
          586,
          321,
          393,
          536,
          13,
          51684
        ]
      },
      {
        "avg_logprob": -0.23267681458417108,
        "compression_ratio": 1.6891891891891893,
        "end": 6668.58,
        "id": 2041,
        "no_speech_prob": 0.0013458544854074717,
        "seek": 663874,
        "start": 6667.219999999999,
        "temperature": 0,
        "text": " This is what it got.",
        "tokens": [
          51788,
          639,
          307,
          437,
          309,
          658,
          13,
          51856
        ]
      },
      {
        "avg_logprob": -0.20137443271934563,
        "compression_ratio": 1.7469387755102042,
        "end": 6669.86,
        "id": 2042,
        "no_speech_prob": 0.000044001058995490894,
        "seek": 666858,
        "start": 6668.58,
        "temperature": 0,
        "text": " This is the comparative.",
        "tokens": [
          50364,
          639,
          307,
          264,
          39292,
          13,
          50428
        ]
      },
      {
        "avg_logprob": -0.20137443271934563,
        "compression_ratio": 1.7469387755102042,
        "end": 6671.46,
        "id": 2043,
        "no_speech_prob": 0.000044001058995490894,
        "seek": 666858,
        "start": 6669.86,
        "temperature": 0,
        "text": " This is very small for you to read.",
        "tokens": [
          50428,
          639,
          307,
          588,
          1359,
          337,
          291,
          281,
          1401,
          13,
          50508
        ]
      },
      {
        "avg_logprob": -0.20137443271934563,
        "compression_ratio": 1.7469387755102042,
        "end": 6673.7,
        "id": 2044,
        "no_speech_prob": 0.000044001058995490894,
        "seek": 666858,
        "start": 6673.38,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          50604,
          45263,
          13,
          50620
        ]
      },
      {
        "avg_logprob": -0.20137443271934563,
        "compression_ratio": 1.7469387755102042,
        "end": 6676.98,
        "id": 2045,
        "no_speech_prob": 0.000044001058995490894,
        "seek": 666858,
        "start": 6674.66,
        "temperature": 0,
        "text": " You can see here that this is the comparative.",
        "tokens": [
          50668,
          509,
          393,
          536,
          510,
          300,
          341,
          307,
          264,
          39292,
          13,
          50784
        ]
      },
      {
        "avg_logprob": -0.20137443271934563,
        "compression_ratio": 1.7469387755102042,
        "end": 6678.26,
        "id": 2046,
        "no_speech_prob": 0.000044001058995490894,
        "seek": 666858,
        "start": 6676.98,
        "temperature": 0,
        "text": " That's the score.",
        "tokens": [
          50784,
          663,
          311,
          264,
          6175,
          13,
          50848
        ]
      },
      {
        "avg_logprob": -0.20137443271934563,
        "compression_ratio": 1.7469387755102042,
        "end": 6679.22,
        "id": 2047,
        "no_speech_prob": 0.000044001058995490894,
        "seek": 666858,
        "start": 6678.26,
        "temperature": 0,
        "text": " And this is the list.",
        "tokens": [
          50848,
          400,
          341,
          307,
          264,
          1329,
          13,
          50896
        ]
      },
      {
        "avg_logprob": -0.20137443271934563,
        "compression_ratio": 1.7469387755102042,
        "end": 6679.94,
        "id": 2048,
        "no_speech_prob": 0.000044001058995490894,
        "seek": 666858,
        "start": 6679.22,
        "temperature": 0,
        "text": " Happy and rainbow.",
        "tokens": [
          50896,
          8277,
          293,
          18526,
          13,
          50932
        ]
      },
      {
        "avg_logprob": -0.20137443271934563,
        "compression_ratio": 1.7469387755102042,
        "end": 6683.46,
        "id": 2049,
        "no_speech_prob": 0.000044001058995490894,
        "seek": 666858,
        "start": 6679.94,
        "temperature": 0,
        "text": " So what I could say is, why didn't it get kittens?",
        "tokens": [
          50932,
          407,
          437,
          286,
          727,
          584,
          307,
          11,
          983,
          994,
          380,
          309,
          483,
          47363,
          30,
          51108
        ]
      },
      {
        "avg_logprob": -0.20137443271934563,
        "compression_ratio": 1.7469387755102042,
        "end": 6686.0199999999995,
        "id": 2050,
        "no_speech_prob": 0.000044001058995490894,
        "seek": 666858,
        "start": 6683.46,
        "temperature": 0,
        "text": " So what I would like to do is add kittens.",
        "tokens": [
          51108,
          407,
          437,
          286,
          576,
          411,
          281,
          360,
          307,
          909,
          47363,
          13,
          51236
        ]
      },
      {
        "avg_logprob": -0.20137443271934563,
        "compression_ratio": 1.7469387755102042,
        "end": 6687.46,
        "id": 2051,
        "no_speech_prob": 0.000044001058995490894,
        "seek": 666858,
        "start": 6686.0199999999995,
        "temperature": 0,
        "text": " And kittens should have a score of four.",
        "tokens": [
          51236,
          400,
          47363,
          820,
          362,
          257,
          6175,
          295,
          1451,
          13,
          51308
        ]
      },
      {
        "avg_logprob": -0.20137443271934563,
        "compression_ratio": 1.7469387755102042,
        "end": 6689.38,
        "id": 2052,
        "no_speech_prob": 0.000044001058995490894,
        "seek": 666858,
        "start": 6688.18,
        "temperature": 0,
        "text": " So I'm now going to hit submit.",
        "tokens": [
          51344,
          407,
          286,
          478,
          586,
          516,
          281,
          2045,
          10315,
          13,
          51404
        ]
      },
      {
        "avg_logprob": -0.20137443271934563,
        "compression_ratio": 1.7469387755102042,
        "end": 6691.54,
        "id": 2053,
        "no_speech_prob": 0.000044001058995490894,
        "seek": 666858,
        "start": 6690.18,
        "temperature": 0,
        "text": " And now when I analyze it again.",
        "tokens": [
          51444,
          400,
          586,
          562,
          286,
          12477,
          309,
          797,
          13,
          51512
        ]
      },
      {
        "avg_logprob": -0.20137443271934563,
        "compression_ratio": 1.7469387755102042,
        "end": 6692.9,
        "id": 2054,
        "no_speech_prob": 0.000044001058995490894,
        "seek": 666858,
        "start": 6692.34,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          51552,
          45263,
          13,
          51580
        ]
      },
      {
        "avg_logprob": -0.20137443271934563,
        "compression_ratio": 1.7469387755102042,
        "end": 6694.9,
        "id": 2055,
        "no_speech_prob": 0.000044001058995490894,
        "seek": 666858,
        "start": 6692.9,
        "temperature": 0,
        "text": " We can see that I got a.",
        "tokens": [
          51580,
          492,
          393,
          536,
          300,
          286,
          658,
          257,
          13,
          51680
        ]
      },
      {
        "avg_logprob": -0.20137443271934563,
        "compression_ratio": 1.7469387755102042,
        "end": 6696.98,
        "id": 2056,
        "no_speech_prob": 0.000044001058995490894,
        "seek": 666858,
        "start": 6695.78,
        "temperature": 0,
        "text": " I got a score of 14.",
        "tokens": [
          51724,
          286,
          658,
          257,
          6175,
          295,
          3499,
          13,
          51784
        ]
      },
      {
        "avg_logprob": -0.18212860822677612,
        "compression_ratio": 1.7032520325203253,
        "end": 6701.78,
        "id": 2057,
        "no_speech_prob": 0.001187898451462388,
        "seek": 669698,
        "start": 6697.54,
        "temperature": 0,
        "text": " And let's say today is really positive with a number 100.",
        "tokens": [
          50392,
          400,
          718,
          311,
          584,
          965,
          307,
          534,
          3353,
          365,
          257,
          1230,
          2319,
          13,
          50604
        ]
      },
      {
        "avg_logprob": -0.18212860822677612,
        "compression_ratio": 1.7032520325203253,
        "end": 6704.419999999999,
        "id": 2058,
        "no_speech_prob": 0.001187898451462388,
        "seek": 669698,
        "start": 6701.78,
        "temperature": 0,
        "text": " I can add that to the database and analyze again.",
        "tokens": [
          50604,
          286,
          393,
          909,
          300,
          281,
          264,
          8149,
          293,
          12477,
          797,
          13,
          50736
        ]
      },
      {
        "avg_logprob": -0.18212860822677612,
        "compression_ratio": 1.7032520325203253,
        "end": 6706.58,
        "id": 2059,
        "no_speech_prob": 0.001187898451462388,
        "seek": 669698,
        "start": 6704.419999999999,
        "temperature": 0,
        "text": " And now I have a score of 114.",
        "tokens": [
          50736,
          400,
          586,
          286,
          362,
          257,
          6175,
          295,
          2975,
          19,
          13,
          50844
        ]
      },
      {
        "avg_logprob": -0.18212860822677612,
        "compression_ratio": 1.7032520325203253,
        "end": 6708.419999999999,
        "id": 2060,
        "no_speech_prob": 0.001187898451462388,
        "seek": 669698,
        "start": 6706.58,
        "temperature": 0,
        "text": " So now I have both.",
        "tokens": [
          50844,
          407,
          586,
          286,
          362,
          1293,
          13,
          50936
        ]
      },
      {
        "avg_logprob": -0.18212860822677612,
        "compression_ratio": 1.7032520325203253,
        "end": 6710.9,
        "id": 2061,
        "no_speech_prob": 0.001187898451462388,
        "seek": 669698,
        "start": 6708.419999999999,
        "temperature": 0,
        "text": " And on one page, I have both a system.",
        "tokens": [
          50936,
          400,
          322,
          472,
          3028,
          11,
          286,
          362,
          1293,
          257,
          1185,
          13,
          51060
        ]
      },
      {
        "avg_logprob": -0.18212860822677612,
        "compression_ratio": 1.7032520325203253,
        "end": 6712.9,
        "id": 2062,
        "no_speech_prob": 0.001187898451462388,
        "seek": 669698,
        "start": 6710.9,
        "temperature": 0,
        "text": " Wow, we've really finished this example.",
        "tokens": [
          51060,
          3153,
          11,
          321,
          600,
          534,
          4335,
          341,
          1365,
          13,
          51160
        ]
      },
      {
        "avg_logprob": -0.18212860822677612,
        "compression_ratio": 1.7032520325203253,
        "end": 6716.5,
        "id": 2063,
        "no_speech_prob": 0.001187898451462388,
        "seek": 669698,
        "start": 6712.9,
        "temperature": 0,
        "text": " Where I can submit to the database using a get request.",
        "tokens": [
          51160,
          2305,
          286,
          393,
          10315,
          281,
          264,
          8149,
          1228,
          257,
          483,
          5308,
          13,
          51340
        ]
      },
      {
        "avg_logprob": -0.18212860822677612,
        "compression_ratio": 1.7032520325203253,
        "end": 6719.139999999999,
        "id": 2064,
        "no_speech_prob": 0.001187898451462388,
        "seek": 669698,
        "start": 6716.5,
        "temperature": 0,
        "text": " I can post to have text analyzed.",
        "tokens": [
          51340,
          286,
          393,
          2183,
          281,
          362,
          2487,
          28181,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -0.18212860822677612,
        "compression_ratio": 1.7032520325203253,
        "end": 6723.78,
        "id": 2065,
        "no_speech_prob": 0.001187898451462388,
        "seek": 669698,
        "start": 6719.139999999999,
        "temperature": 0,
        "text": " I can submit to the API with a post.",
        "tokens": [
          51472,
          286,
          393,
          10315,
          281,
          264,
          9362,
          365,
          257,
          2183,
          13,
          51704
        ]
      },
      {
        "avg_logprob": -0.18212860822677612,
        "compression_ratio": 1.7032520325203253,
        "end": 6725.219999999999,
        "id": 2066,
        "no_speech_prob": 0.001187898451462388,
        "seek": 669698,
        "start": 6723.78,
        "temperature": 0,
        "text": " And I can get back the results.",
        "tokens": [
          51704,
          400,
          286,
          393,
          483,
          646,
          264,
          3542,
          13,
          51776
        ]
      },
      {
        "avg_logprob": -0.18212860822677612,
        "compression_ratio": 1.7032520325203253,
        "end": 6726.339999999999,
        "id": 2067,
        "no_speech_prob": 0.001187898451462388,
        "seek": 669698,
        "start": 6725.219999999999,
        "temperature": 0,
        "text": " Now here's the thing.",
        "tokens": [
          51776,
          823,
          510,
          311,
          264,
          551,
          13,
          51832
        ]
      },
      {
        "avg_logprob": -0.22412720771685038,
        "compression_ratio": 1.7913907284768211,
        "end": 6730.74,
        "id": 2068,
        "no_speech_prob": 0.0011513791978359222,
        "seek": 672634,
        "start": 6726.42,
        "temperature": 0,
        "text": " As a challenge, as an exercise, take this exact code.",
        "tokens": [
          50368,
          1018,
          257,
          3430,
          11,
          382,
          364,
          5380,
          11,
          747,
          341,
          1900,
          3089,
          13,
          50584
        ]
      },
      {
        "avg_logprob": -0.22412720771685038,
        "compression_ratio": 1.7913907284768211,
        "end": 6733.38,
        "id": 2069,
        "no_speech_prob": 0.0011513791978359222,
        "seek": 672634,
        "start": 6730.74,
        "temperature": 0,
        "text": " And really work on the interaction here.",
        "tokens": [
          50584,
          400,
          534,
          589,
          322,
          264,
          9285,
          510,
          13,
          50716
        ]
      },
      {
        "avg_logprob": -0.22412720771685038,
        "compression_ratio": 1.7913907284768211,
        "end": 6734.34,
        "id": 2070,
        "no_speech_prob": 0.0011513791978359222,
        "seek": 672634,
        "start": 6733.38,
        "temperature": 0,
        "text": " And how this works.",
        "tokens": [
          50716,
          400,
          577,
          341,
          1985,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.22412720771685038,
        "compression_ratio": 1.7913907284768211,
        "end": 6738.900000000001,
        "id": 2071,
        "no_speech_prob": 0.0011513791978359222,
        "seek": 672634,
        "start": 6734.34,
        "temperature": 0,
        "text": " How could you actually effectively crowd source a full word list?",
        "tokens": [
          50764,
          1012,
          727,
          291,
          767,
          8659,
          6919,
          4009,
          257,
          1577,
          1349,
          1329,
          30,
          50992
        ]
      },
      {
        "avg_logprob": -0.22412720771685038,
        "compression_ratio": 1.7913907284768211,
        "end": 6741.46,
        "id": 2072,
        "no_speech_prob": 0.0011513791978359222,
        "seek": 672634,
        "start": 6738.900000000001,
        "temperature": 0,
        "text": " How could you use an animation?",
        "tokens": [
          50992,
          1012,
          727,
          291,
          764,
          364,
          9603,
          30,
          51120
        ]
      },
      {
        "avg_logprob": -0.22412720771685038,
        "compression_ratio": 1.7913907284768211,
        "end": 6744.58,
        "id": 2073,
        "no_speech_prob": 0.0011513791978359222,
        "seek": 672634,
        "start": 6741.46,
        "temperature": 0,
        "text": " Or use design to show the results in the word list?",
        "tokens": [
          51120,
          1610,
          764,
          1715,
          281,
          855,
          264,
          3542,
          294,
          264,
          1349,
          1329,
          30,
          51276
        ]
      },
      {
        "avg_logprob": -0.22412720771685038,
        "compression_ratio": 1.7913907284768211,
        "end": 6745.38,
        "id": 2074,
        "no_speech_prob": 0.0011513791978359222,
        "seek": 672634,
        "start": 6744.58,
        "temperature": 0,
        "text": " You could click on them.",
        "tokens": [
          51276,
          509,
          727,
          2052,
          322,
          552,
          13,
          51316
        ]
      },
      {
        "avg_logprob": -0.22412720771685038,
        "compression_ratio": 1.7913907284768211,
        "end": 6747.14,
        "id": 2075,
        "no_speech_prob": 0.0011513791978359222,
        "seek": 672634,
        "start": 6745.38,
        "temperature": 0,
        "text": " And what if it showed you all the words here?",
        "tokens": [
          51316,
          400,
          437,
          498,
          309,
          4712,
          291,
          439,
          264,
          2283,
          510,
          30,
          51404
        ]
      },
      {
        "avg_logprob": -0.22412720771685038,
        "compression_ratio": 1.7913907284768211,
        "end": 6747.9400000000005,
        "id": 2076,
        "no_speech_prob": 0.0011513791978359222,
        "seek": 672634,
        "start": 6747.14,
        "temperature": 0,
        "text": " And the ones that are missing.",
        "tokens": [
          51404,
          400,
          264,
          2306,
          300,
          366,
          5361,
          13,
          51444
        ]
      },
      {
        "avg_logprob": -0.22412720771685038,
        "compression_ratio": 1.7913907284768211,
        "end": 6749.62,
        "id": 2077,
        "no_speech_prob": 0.0011513791978359222,
        "seek": 672634,
        "start": 6747.9400000000005,
        "temperature": 0,
        "text": " And it let you type them in and hit submit.",
        "tokens": [
          51444,
          400,
          309,
          718,
          291,
          2010,
          552,
          294,
          293,
          2045,
          10315,
          13,
          51528
        ]
      },
      {
        "avg_logprob": -0.22412720771685038,
        "compression_ratio": 1.7913907284768211,
        "end": 6750.900000000001,
        "id": 2078,
        "no_speech_prob": 0.0011513791978359222,
        "seek": 672634,
        "start": 6749.62,
        "temperature": 0,
        "text": " So you could kind of like.",
        "tokens": [
          51528,
          407,
          291,
          727,
          733,
          295,
          411,
          13,
          51592
        ]
      },
      {
        "avg_logprob": -0.22412720771685038,
        "compression_ratio": 1.7913907284768211,
        "end": 6753.78,
        "id": 2079,
        "no_speech_prob": 0.0011513791978359222,
        "seek": 672634,
        "start": 6750.900000000001,
        "temperature": 0,
        "text": " How could you train this to have a larger database of words?",
        "tokens": [
          51592,
          1012,
          727,
          291,
          3847,
          341,
          281,
          362,
          257,
          4833,
          8149,
          295,
          2283,
          30,
          51736
        ]
      },
      {
        "avg_logprob": -0.22412720771685038,
        "compression_ratio": 1.7913907284768211,
        "end": 6756.26,
        "id": 2080,
        "no_speech_prob": 0.0011513791978359222,
        "seek": 672634,
        "start": 6753.78,
        "temperature": 0,
        "text": " For more sophisticated sentiment analysis?",
        "tokens": [
          51736,
          1171,
          544,
          16950,
          16149,
          5215,
          30,
          51860
        ]
      },
      {
        "avg_logprob": -0.21856920421123505,
        "compression_ratio": 1.8157894736842106,
        "end": 6759.3,
        "id": 2081,
        "no_speech_prob": 0.0003101546026300639,
        "seek": 675626,
        "start": 6756.74,
        "temperature": 0,
        "text": " I think this would be a challenge for you to take this and take it further.",
        "tokens": [
          50388,
          286,
          519,
          341,
          576,
          312,
          257,
          3430,
          337,
          291,
          281,
          747,
          341,
          293,
          747,
          309,
          3052,
          13,
          50516
        ]
      },
      {
        "avg_logprob": -0.21856920421123505,
        "compression_ratio": 1.8157894736842106,
        "end": 6761.22,
        "id": 2082,
        "no_speech_prob": 0.0003101546026300639,
        "seek": 675626,
        "start": 6759.3,
        "temperature": 0,
        "text": " But this is a fully functioning API.",
        "tokens": [
          50516,
          583,
          341,
          307,
          257,
          4498,
          18483,
          9362,
          13,
          50612
        ]
      },
      {
        "avg_logprob": -0.21856920421123505,
        "compression_ratio": 1.8157894736842106,
        "end": 6763.46,
        "id": 2083,
        "no_speech_prob": 0.0003101546026300639,
        "seek": 675626,
        "start": 6761.22,
        "temperature": 0,
        "text": " There's one piece of this that I think I should mention.",
        "tokens": [
          50612,
          821,
          311,
          472,
          2522,
          295,
          341,
          300,
          286,
          519,
          286,
          820,
          2152,
          13,
          50724
        ]
      },
      {
        "avg_logprob": -0.21856920421123505,
        "compression_ratio": 1.8157894736842106,
        "end": 6768.900000000001,
        "id": 2084,
        "no_speech_prob": 0.0003101546026300639,
        "seek": 675626,
        "start": 6765.62,
        "temperature": 0,
        "text": " This API can be accessed by my.",
        "tokens": [
          50832,
          639,
          9362,
          393,
          312,
          34211,
          538,
          452,
          13,
          50996
        ]
      },
      {
        "avg_logprob": -0.21856920421123505,
        "compression_ratio": 1.8157894736842106,
        "end": 6772.26,
        "id": 2085,
        "no_speech_prob": 0.0003101546026300639,
        "seek": 675626,
        "start": 6768.900000000001,
        "temperature": 0,
        "text": " So the server, the Node server, the thing running right here.",
        "tokens": [
          50996,
          407,
          264,
          7154,
          11,
          264,
          38640,
          7154,
          11,
          264,
          551,
          2614,
          558,
          510,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.21856920421123505,
        "compression_ratio": 1.8157894736842106,
        "end": 6775.14,
        "id": 2086,
        "no_speech_prob": 0.0003101546026300639,
        "seek": 675626,
        "start": 6772.26,
        "temperature": 0,
        "text": " Can be accessed by this web page.",
        "tokens": [
          51164,
          1664,
          312,
          34211,
          538,
          341,
          3670,
          3028,
          13,
          51308
        ]
      },
      {
        "avg_logprob": -0.21856920421123505,
        "compression_ratio": 1.8157894736842106,
        "end": 6778.26,
        "id": 2087,
        "no_speech_prob": 0.0003101546026300639,
        "seek": 675626,
        "start": 6775.14,
        "temperature": 0,
        "text": " Because this web page is hosted on this server.",
        "tokens": [
          51308,
          1436,
          341,
          3670,
          3028,
          307,
          19204,
          322,
          341,
          7154,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.21856920421123505,
        "compression_ratio": 1.8157894736842106,
        "end": 6781.7,
        "id": 2088,
        "no_speech_prob": 0.0003101546026300639,
        "seek": 675626,
        "start": 6778.26,
        "temperature": 0,
        "text": " But what if you wanted to make a sentiment analysis API.",
        "tokens": [
          51464,
          583,
          437,
          498,
          291,
          1415,
          281,
          652,
          257,
          16149,
          5215,
          9362,
          13,
          51636
        ]
      },
      {
        "avg_logprob": -0.21856920421123505,
        "compression_ratio": 1.8157894736842106,
        "end": 6782.820000000001,
        "id": 2089,
        "no_speech_prob": 0.0003101546026300639,
        "seek": 675626,
        "start": 6781.7,
        "temperature": 0,
        "text": " That is running somewhere.",
        "tokens": [
          51636,
          663,
          307,
          2614,
          4079,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.21856920421123505,
        "compression_ratio": 1.8157894736842106,
        "end": 6785.54,
        "id": 2090,
        "no_speech_prob": 0.0003101546026300639,
        "seek": 675626,
        "start": 6782.820000000001,
        "temperature": 0,
        "text": " But anybody could access it from their own web pages.",
        "tokens": [
          51692,
          583,
          4472,
          727,
          2105,
          309,
          490,
          641,
          1065,
          3670,
          7183,
          13,
          51828
        ]
      },
      {
        "avg_logprob": -0.20598473420014252,
        "compression_ratio": 1.9276315789473684,
        "end": 6788.18,
        "id": 2091,
        "no_speech_prob": 0.039637960493564606,
        "seek": 678554,
        "start": 6785.54,
        "temperature": 0,
        "text": " And their own programming without being the programmer of the server.",
        "tokens": [
          50364,
          400,
          641,
          1065,
          9410,
          1553,
          885,
          264,
          32116,
          295,
          264,
          7154,
          13,
          50496
        ]
      },
      {
        "avg_logprob": -0.20598473420014252,
        "compression_ratio": 1.9276315789473684,
        "end": 6789.38,
        "id": 2092,
        "no_speech_prob": 0.039637960493564606,
        "seek": 678554,
        "start": 6788.18,
        "temperature": 0,
        "text": " Well to do that.",
        "tokens": [
          50496,
          1042,
          281,
          360,
          300,
          13,
          50556
        ]
      },
      {
        "avg_logprob": -0.20598473420014252,
        "compression_ratio": 1.9276315789473684,
        "end": 6792.5,
        "id": 2093,
        "no_speech_prob": 0.039637960493564606,
        "seek": 678554,
        "start": 6790.1,
        "temperature": 0,
        "text": " What you want to do is open up on your server.",
        "tokens": [
          50592,
          708,
          291,
          528,
          281,
          360,
          307,
          1269,
          493,
          322,
          428,
          7154,
          13,
          50712
        ]
      },
      {
        "avg_logprob": -0.20598473420014252,
        "compression_ratio": 1.9276315789473684,
        "end": 6795.06,
        "id": 2094,
        "no_speech_prob": 0.039637960493564606,
        "seek": 678554,
        "start": 6792.5,
        "temperature": 0,
        "text": " Something called cross origin resource sharing.",
        "tokens": [
          50712,
          6595,
          1219,
          3278,
          4957,
          7684,
          5414,
          13,
          50840
        ]
      },
      {
        "avg_logprob": -0.20598473420014252,
        "compression_ratio": 1.9276315789473684,
        "end": 6795.62,
        "id": 2095,
        "no_speech_prob": 0.039637960493564606,
        "seek": 678554,
        "start": 6795.06,
        "temperature": 0,
        "text": " You want to say.",
        "tokens": [
          50840,
          509,
          528,
          281,
          584,
          13,
          50868
        ]
      },
      {
        "avg_logprob": -0.20598473420014252,
        "compression_ratio": 1.9276315789473684,
        "end": 6799.14,
        "id": 2096,
        "no_speech_prob": 0.039637960493564606,
        "seek": 678554,
        "start": 6795.62,
        "temperature": 0,
        "text": " I want other people to be allowed to send get requests.",
        "tokens": [
          50868,
          286,
          528,
          661,
          561,
          281,
          312,
          4350,
          281,
          2845,
          483,
          12475,
          13,
          51044
        ]
      },
      {
        "avg_logprob": -0.20598473420014252,
        "compression_ratio": 1.9276315789473684,
        "end": 6801.3,
        "id": 2097,
        "no_speech_prob": 0.039637960493564606,
        "seek": 678554,
        "start": 6799.14,
        "temperature": 0,
        "text": " Or post requests to this server.",
        "tokens": [
          51044,
          1610,
          2183,
          12475,
          281,
          341,
          7154,
          13,
          51152
        ]
      },
      {
        "avg_logprob": -0.20598473420014252,
        "compression_ratio": 1.9276315789473684,
        "end": 6803.22,
        "id": 2098,
        "no_speech_prob": 0.039637960493564606,
        "seek": 678554,
        "start": 6801.3,
        "temperature": 0,
        "text": " Not just me the programmer of the server.",
        "tokens": [
          51152,
          1726,
          445,
          385,
          264,
          32116,
          295,
          264,
          7154,
          13,
          51248
        ]
      },
      {
        "avg_logprob": -0.20598473420014252,
        "compression_ratio": 1.9276315789473684,
        "end": 6806.66,
        "id": 2099,
        "no_speech_prob": 0.039637960493564606,
        "seek": 678554,
        "start": 6803.22,
        "temperature": 0,
        "text": " Who also is hosting like HTML files packaged with it.",
        "tokens": [
          51248,
          2102,
          611,
          307,
          16058,
          411,
          17995,
          7098,
          38162,
          365,
          309,
          13,
          51420
        ]
      },
      {
        "avg_logprob": -0.20598473420014252,
        "compression_ratio": 1.9276315789473684,
        "end": 6808.9,
        "id": 2100,
        "no_speech_prob": 0.039637960493564606,
        "seek": 678554,
        "start": 6806.66,
        "temperature": 0,
        "text": " And to do that you need to enable cores.",
        "tokens": [
          51420,
          400,
          281,
          360,
          300,
          291,
          643,
          281,
          9528,
          24826,
          13,
          51532
        ]
      },
      {
        "avg_logprob": -0.20598473420014252,
        "compression_ratio": 1.9276315789473684,
        "end": 6810.74,
        "id": 2101,
        "no_speech_prob": 0.039637960493564606,
        "seek": 678554,
        "start": 6808.9,
        "temperature": 0,
        "text": " Which stands for cross origin resource sharing.",
        "tokens": [
          51532,
          3013,
          7382,
          337,
          3278,
          4957,
          7684,
          5414,
          13,
          51624
        ]
      },
      {
        "avg_logprob": -0.20598473420014252,
        "compression_ratio": 1.9276315789473684,
        "end": 6812.98,
        "id": 2102,
        "no_speech_prob": 0.039637960493564606,
        "seek": 678554,
        "start": 6810.74,
        "temperature": 0,
        "text": " You've probably encountered the flip side of this error.",
        "tokens": [
          51624,
          509,
          600,
          1391,
          20381,
          264,
          7929,
          1252,
          295,
          341,
          6713,
          13,
          51736
        ]
      },
      {
        "avg_logprob": -0.20598473420014252,
        "compression_ratio": 1.9276315789473684,
        "end": 6815.3,
        "id": 2103,
        "no_speech_prob": 0.039637960493564606,
        "seek": 678554,
        "start": 6812.98,
        "temperature": 0,
        "text": " Anytime you've tried to request something from a server.",
        "tokens": [
          51736,
          39401,
          291,
          600,
          3031,
          281,
          5308,
          746,
          490,
          257,
          7154,
          13,
          51852
        ]
      },
      {
        "avg_logprob": -0.2687654283311632,
        "compression_ratio": 1.6218905472636815,
        "end": 6817.22,
        "id": 2104,
        "no_speech_prob": 0.00005391053855419159,
        "seek": 681530,
        "start": 6815.62,
        "temperature": 0,
        "text": " You've got this XML request.",
        "tokens": [
          50380,
          509,
          600,
          658,
          341,
          43484,
          5308,
          13,
          50460
        ]
      },
      {
        "avg_logprob": -0.2687654283311632,
        "compression_ratio": 1.6218905472636815,
        "end": 6818.18,
        "id": 2105,
        "no_speech_prob": 0.00005391053855419159,
        "seek": 681530,
        "start": 6817.22,
        "temperature": 0,
        "text": " HTML not allowed.",
        "tokens": [
          50460,
          17995,
          406,
          4350,
          13,
          50508
        ]
      },
      {
        "avg_logprob": -0.2687654283311632,
        "compression_ratio": 1.6218905472636815,
        "end": 6820.1,
        "id": 2106,
        "no_speech_prob": 0.00005391053855419159,
        "seek": 681530,
        "start": 6818.18,
        "temperature": 0,
        "text": " Cross origin resource not enabled.",
        "tokens": [
          50508,
          11623,
          4957,
          7684,
          406,
          15172,
          13,
          50604
        ]
      },
      {
        "avg_logprob": -0.2687654283311632,
        "compression_ratio": 1.6218905472636815,
        "end": 6822.18,
        "id": 2107,
        "no_speech_prob": 0.00005391053855419159,
        "seek": 681530,
        "start": 6820.1,
        "temperature": 0,
        "text": " So if I want to enable cores.",
        "tokens": [
          50604,
          407,
          498,
          286,
          528,
          281,
          9528,
          24826,
          13,
          50708
        ]
      },
      {
        "avg_logprob": -0.2687654283311632,
        "compression_ratio": 1.6218905472636815,
        "end": 6825.38,
        "id": 2108,
        "no_speech_prob": 0.00005391053855419159,
        "seek": 681530,
        "start": 6822.18,
        "temperature": 0,
        "text": " I can search for cores node package express.",
        "tokens": [
          50708,
          286,
          393,
          3164,
          337,
          24826,
          9984,
          7372,
          5109,
          13,
          50868
        ]
      },
      {
        "avg_logprob": -0.2687654283311632,
        "compression_ratio": 1.6218905472636815,
        "end": 6829.3,
        "id": 2109,
        "no_speech_prob": 0.00005391053855419159,
        "seek": 681530,
        "start": 6826.900000000001,
        "temperature": 0,
        "text": " This is something I can enable with express.",
        "tokens": [
          50944,
          639,
          307,
          746,
          286,
          393,
          9528,
          365,
          5109,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2687654283311632,
        "compression_ratio": 1.6218905472636815,
        "end": 6835.06,
        "id": 2110,
        "no_speech_prob": 0.00005391053855419159,
        "seek": 681530,
        "start": 6829.3,
        "temperature": 0,
        "text": " And I can actually just install this cores package.",
        "tokens": [
          51064,
          400,
          286,
          393,
          767,
          445,
          3625,
          341,
          24826,
          7372,
          13,
          51352
        ]
      },
      {
        "avg_logprob": -0.2687654283311632,
        "compression_ratio": 1.6218905472636815,
        "end": 6842.42,
        "id": 2111,
        "no_speech_prob": 0.00005391053855419159,
        "seek": 681530,
        "start": 6836.74,
        "temperature": 0,
        "text": " And I can say npm install cores dash dash save.",
        "tokens": [
          51436,
          400,
          286,
          393,
          584,
          297,
          14395,
          3625,
          24826,
          8240,
          8240,
          3155,
          13,
          51720
        ]
      },
      {
        "avg_logprob": -0.2687654283311632,
        "compression_ratio": 1.6218905472636815,
        "end": 6844.74,
        "id": 2112,
        "no_speech_prob": 0.00005391053855419159,
        "seek": 681530,
        "start": 6843.54,
        "temperature": 0,
        "text": " Now I've installed that.",
        "tokens": [
          51776,
          823,
          286,
          600,
          8899,
          300,
          13,
          51836
        ]
      },
      {
        "avg_logprob": -0.2270012055673907,
        "compression_ratio": 1.7252252252252251,
        "end": 6846.42,
        "id": 2113,
        "no_speech_prob": 0.00013135085464455187,
        "seek": 684530,
        "start": 6845.46,
        "temperature": 0,
        "text": " Node package.",
        "tokens": [
          50372,
          38640,
          7372,
          13,
          50420
        ]
      },
      {
        "avg_logprob": -0.2270012055673907,
        "compression_ratio": 1.7252252252252251,
        "end": 6848.02,
        "id": 2114,
        "no_speech_prob": 0.00013135085464455187,
        "seek": 684530,
        "start": 6846.42,
        "temperature": 0,
        "text": " And I can go here.",
        "tokens": [
          50420,
          400,
          286,
          393,
          352,
          510,
          13,
          50500
        ]
      },
      {
        "avg_logprob": -0.2270012055673907,
        "compression_ratio": 1.7252252252252251,
        "end": 6850.58,
        "id": 2115,
        "no_speech_prob": 0.00013135085464455187,
        "seek": 684530,
        "start": 6848.02,
        "temperature": 0,
        "text": " And I can just grab app dot use.",
        "tokens": [
          50500,
          400,
          286,
          393,
          445,
          4444,
          724,
          5893,
          764,
          13,
          50628
        ]
      },
      {
        "avg_logprob": -0.2270012055673907,
        "compression_ratio": 1.7252252252252251,
        "end": 6852.820000000001,
        "id": 2116,
        "no_speech_prob": 0.00013135085464455187,
        "seek": 684530,
        "start": 6850.58,
        "temperature": 0,
        "text": " Oh I can say cores require cores.",
        "tokens": [
          50628,
          876,
          286,
          393,
          584,
          24826,
          3651,
          24826,
          13,
          50740
        ]
      },
      {
        "avg_logprob": -0.2270012055673907,
        "compression_ratio": 1.7252252252252251,
        "end": 6855.46,
        "id": 2117,
        "no_speech_prob": 0.00013135085464455187,
        "seek": 684530,
        "start": 6854.58,
        "temperature": 0,
        "text": " Right up here.",
        "tokens": [
          50828,
          1779,
          493,
          510,
          13,
          50872
        ]
      },
      {
        "avg_logprob": -0.2270012055673907,
        "compression_ratio": 1.7252252252252251,
        "end": 6857.46,
        "id": 2118,
        "no_speech_prob": 0.00013135085464455187,
        "seek": 684530,
        "start": 6855.46,
        "temperature": 0,
        "text": " The same place that I used body parser.",
        "tokens": [
          50872,
          440,
          912,
          1081,
          300,
          286,
          1143,
          1772,
          21156,
          260,
          13,
          50972
        ]
      },
      {
        "avg_logprob": -0.2270012055673907,
        "compression_ratio": 1.7252252252252251,
        "end": 6860.66,
        "id": 2119,
        "no_speech_prob": 0.00013135085464455187,
        "seek": 684530,
        "start": 6858.1,
        "temperature": 0,
        "text": " Var cores equals require cores.",
        "tokens": [
          51004,
          14662,
          24826,
          6915,
          3651,
          24826,
          13,
          51132
        ]
      },
      {
        "avg_logprob": -0.2270012055673907,
        "compression_ratio": 1.7252252252252251,
        "end": 6863.62,
        "id": 2120,
        "no_speech_prob": 0.00013135085464455187,
        "seek": 684530,
        "start": 6860.66,
        "temperature": 0,
        "text": " And app use body parser.",
        "tokens": [
          51132,
          400,
          724,
          764,
          1772,
          21156,
          260,
          13,
          51280
        ]
      },
      {
        "avg_logprob": -0.2270012055673907,
        "compression_ratio": 1.7252252252252251,
        "end": 6864.5,
        "id": 2121,
        "no_speech_prob": 0.00013135085464455187,
        "seek": 684530,
        "start": 6863.62,
        "temperature": 0,
        "text": " App use etc.",
        "tokens": [
          51280,
          3132,
          764,
          5183,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.2270012055673907,
        "compression_ratio": 1.7252252252252251,
        "end": 6866.58,
        "id": 2122,
        "no_speech_prob": 0.00013135085464455187,
        "seek": 684530,
        "start": 6864.5,
        "temperature": 0,
        "text": " And app use cores.",
        "tokens": [
          51324,
          400,
          724,
          764,
          24826,
          13,
          51428
        ]
      },
      {
        "avg_logprob": -0.2270012055673907,
        "compression_ratio": 1.7252252252252251,
        "end": 6868.820000000001,
        "id": 2123,
        "no_speech_prob": 0.00013135085464455187,
        "seek": 684530,
        "start": 6866.58,
        "temperature": 0,
        "text": " So now I now have enabled cores.",
        "tokens": [
          51428,
          407,
          586,
          286,
          586,
          362,
          15172,
          24826,
          13,
          51540
        ]
      },
      {
        "avg_logprob": -0.2270012055673907,
        "compression_ratio": 1.7252252252252251,
        "end": 6869.860000000001,
        "id": 2124,
        "no_speech_prob": 0.00013135085464455187,
        "seek": 684530,
        "start": 6868.820000000001,
        "temperature": 0,
        "text": " So if I put this.",
        "tokens": [
          51540,
          407,
          498,
          286,
          829,
          341,
          13,
          51592
        ]
      },
      {
        "avg_logprob": -0.2270012055673907,
        "compression_ratio": 1.7252252252252251,
        "end": 6872.18,
        "id": 2125,
        "no_speech_prob": 0.00013135085464455187,
        "seek": 684530,
        "start": 6869.860000000001,
        "temperature": 0,
        "text": " If I deploy this to Heroku or Digital Ocean.",
        "tokens": [
          51592,
          759,
          286,
          7274,
          341,
          281,
          3204,
          13275,
          420,
          15522,
          18101,
          13,
          51708
        ]
      },
      {
        "avg_logprob": -0.2270012055673907,
        "compression_ratio": 1.7252252252252251,
        "end": 6874.1,
        "id": 2126,
        "no_speech_prob": 0.00013135085464455187,
        "seek": 684530,
        "start": 6872.18,
        "temperature": 0,
        "text": " Or whatever web server hosting environment.",
        "tokens": [
          51708,
          1610,
          2035,
          3670,
          7154,
          16058,
          2823,
          13,
          51804
        ]
      },
      {
        "avg_logprob": -0.18194652425831762,
        "compression_ratio": 1.6013745704467355,
        "end": 6875.3,
        "id": 2127,
        "no_speech_prob": 0.00003426844341447577,
        "seek": 687410,
        "start": 6874.1,
        "temperature": 0,
        "text": " Wherever my server is.",
        "tokens": [
          50364,
          30903,
          452,
          7154,
          307,
          13,
          50424
        ]
      },
      {
        "avg_logprob": -0.18194652425831762,
        "compression_ratio": 1.6013745704467355,
        "end": 6878.26,
        "id": 2128,
        "no_speech_prob": 0.00003426844341447577,
        "seek": 687410,
        "start": 6875.3,
        "temperature": 0,
        "text": " Now if I handed out the IP address or the URL.",
        "tokens": [
          50424,
          823,
          498,
          286,
          16013,
          484,
          264,
          8671,
          2985,
          420,
          264,
          12905,
          13,
          50572
        ]
      },
      {
        "avg_logprob": -0.18194652425831762,
        "compression_ratio": 1.6013745704467355,
        "end": 6880.02,
        "id": 2129,
        "no_speech_prob": 0.00003426844341447577,
        "seek": 687410,
        "start": 6878.26,
        "temperature": 0,
        "text": " Other people could call load JSON.",
        "tokens": [
          50572,
          5358,
          561,
          727,
          818,
          3677,
          31828,
          13,
          50660
        ]
      },
      {
        "avg_logprob": -0.18194652425831762,
        "compression_ratio": 1.6013745704467355,
        "end": 6884.02,
        "id": 2130,
        "no_speech_prob": 0.00003426844341447577,
        "seek": 687410,
        "start": 6880.660000000001,
        "temperature": 0,
        "text": " Or HTTP post from their own p5.js code.",
        "tokens": [
          50692,
          1610,
          33283,
          2183,
          490,
          641,
          1065,
          280,
          20,
          13,
          25530,
          3089,
          13,
          50860
        ]
      },
      {
        "avg_logprob": -0.18194652425831762,
        "compression_ratio": 1.6013745704467355,
        "end": 6886.660000000001,
        "id": 2131,
        "no_speech_prob": 0.00003426844341447577,
        "seek": 687410,
        "start": 6884.02,
        "temperature": 0,
        "text": " Running on their computer to your particular server.",
        "tokens": [
          50860,
          28136,
          322,
          641,
          3820,
          281,
          428,
          1729,
          7154,
          13,
          50992
        ]
      },
      {
        "avg_logprob": -0.18194652425831762,
        "compression_ratio": 1.6013745704467355,
        "end": 6888.5,
        "id": 2132,
        "no_speech_prob": 0.00003426844341447577,
        "seek": 687410,
        "start": 6886.660000000001,
        "temperature": 0,
        "text": " Let's just run this again to make sure I don't see.",
        "tokens": [
          50992,
          961,
          311,
          445,
          1190,
          341,
          797,
          281,
          652,
          988,
          286,
          500,
          380,
          536,
          13,
          51084
        ]
      },
      {
        "avg_logprob": -0.18194652425831762,
        "compression_ratio": 1.6013745704467355,
        "end": 6889.620000000001,
        "id": 2133,
        "no_speech_prob": 0.00003426844341447577,
        "seek": 687410,
        "start": 6888.5,
        "temperature": 0,
        "text": " I won't be able to see this.",
        "tokens": [
          51084,
          286,
          1582,
          380,
          312,
          1075,
          281,
          536,
          341,
          13,
          51140
        ]
      },
      {
        "avg_logprob": -0.18194652425831762,
        "compression_ratio": 1.6013745704467355,
        "end": 6892.5,
        "id": 2134,
        "no_speech_prob": 0.00003426844341447577,
        "seek": 687410,
        "start": 6890.18,
        "temperature": 0,
        "text": " Because I'm still.",
        "tokens": [
          51168,
          1436,
          286,
          478,
          920,
          13,
          51284
        ]
      },
      {
        "avg_logprob": -0.18194652425831762,
        "compression_ratio": 1.6013745704467355,
        "end": 6894.1,
        "id": 2135,
        "no_speech_prob": 0.00003426844341447577,
        "seek": 687410,
        "start": 6892.5,
        "temperature": 0,
        "text": " But hopefully this all still works.",
        "tokens": [
          51284,
          583,
          4696,
          341,
          439,
          920,
          1985,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18194652425831762,
        "compression_ratio": 1.6013745704467355,
        "end": 6896.900000000001,
        "id": 2136,
        "no_speech_prob": 0.00003426844341447577,
        "seek": 687410,
        "start": 6894.660000000001,
        "temperature": 0,
        "text": " And I can run this.",
        "tokens": [
          51392,
          400,
          286,
          393,
          1190,
          341,
          13,
          51504
        ]
      },
      {
        "avg_logprob": -0.18194652425831762,
        "compression_ratio": 1.6013745704467355,
        "end": 6899.22,
        "id": 2137,
        "no_speech_prob": 0.00003426844341447577,
        "seek": 687410,
        "start": 6897.700000000001,
        "temperature": 0,
        "text": " And I can analyze.",
        "tokens": [
          51544,
          400,
          286,
          393,
          12477,
          13,
          51620
        ]
      },
      {
        "avg_logprob": -0.18194652425831762,
        "compression_ratio": 1.6013745704467355,
        "end": 6900.42,
        "id": 2138,
        "no_speech_prob": 0.00003426844341447577,
        "seek": 687410,
        "start": 6899.22,
        "temperature": 0,
        "text": " And I've got that score.",
        "tokens": [
          51620,
          400,
          286,
          600,
          658,
          300,
          6175,
          13,
          51680
        ]
      },
      {
        "avg_logprob": -0.18194652425831762,
        "compression_ratio": 1.6013745704467355,
        "end": 6902.02,
        "id": 2139,
        "no_speech_prob": 0.00003426844341447577,
        "seek": 687410,
        "start": 6900.42,
        "temperature": 0,
        "text": " And by the way I should fix today.",
        "tokens": [
          51680,
          400,
          538,
          264,
          636,
          286,
          820,
          3191,
          965,
          13,
          51760
        ]
      },
      {
        "avg_logprob": -0.18194652425831762,
        "compression_ratio": 1.6013745704467355,
        "end": 6903.620000000001,
        "id": 2140,
        "no_speech_prob": 0.00003426844341447577,
        "seek": 687410,
        "start": 6902.02,
        "temperature": 0,
        "text": " Let's give today a score of zero.",
        "tokens": [
          51760,
          961,
          311,
          976,
          965,
          257,
          6175,
          295,
          4018,
          13,
          51840
        ]
      },
      {
        "avg_logprob": -0.2357074192592076,
        "compression_ratio": 1.4744897959183674,
        "end": 6905.46,
        "id": 2141,
        "no_speech_prob": 0.00021654304873663932,
        "seek": 690410,
        "start": 6904.34,
        "temperature": 0,
        "text": " Override that back.",
        "tokens": [
          50376,
          4886,
          25502,
          300,
          646,
          13,
          50432
        ]
      },
      {
        "avg_logprob": -0.2357074192592076,
        "compression_ratio": 1.4744897959183674,
        "end": 6906.26,
        "id": 2142,
        "no_speech_prob": 0.00021654304873663932,
        "seek": 690410,
        "start": 6905.46,
        "temperature": 0,
        "text": " Hit analyze.",
        "tokens": [
          50432,
          9217,
          12477,
          13,
          50472
        ]
      },
      {
        "avg_logprob": -0.2357074192592076,
        "compression_ratio": 1.4744897959183674,
        "end": 6906.76,
        "id": 2143,
        "no_speech_prob": 0.00021654304873663932,
        "seek": 690410,
        "start": 6906.26,
        "temperature": 0,
        "text": " Oops.",
        "tokens": [
          50472,
          21726,
          13,
          50497
        ]
      },
      {
        "avg_logprob": -0.2357074192592076,
        "compression_ratio": 1.4744897959183674,
        "end": 6909.46,
        "id": 2144,
        "no_speech_prob": 0.00021654304873663932,
        "seek": 690410,
        "start": 6908.58,
        "temperature": 0,
        "text": " Why didn't that work?",
        "tokens": [
          50588,
          1545,
          994,
          380,
          300,
          589,
          30,
          50632
        ]
      },
      {
        "avg_logprob": -0.2357074192592076,
        "compression_ratio": 1.4744897959183674,
        "end": 6916.280000000001,
        "id": 2145,
        "no_speech_prob": 0.00021654304873663932,
        "seek": 690410,
        "start": 6915.780000000001,
        "temperature": 0,
        "text": " Pause.",
        "tokens": [
          50948,
          31973,
          13,
          50973
        ]
      },
      {
        "avg_logprob": -0.2357074192592076,
        "compression_ratio": 1.4744897959183674,
        "end": 6920.740000000001,
        "id": 2146,
        "no_speech_prob": 0.00021654304873663932,
        "seek": 690410,
        "start": 6918.820000000001,
        "temperature": 0,
        "text": " Does it not override today?",
        "tokens": [
          51100,
          4402,
          309,
          406,
          42321,
          965,
          30,
          51196
        ]
      },
      {
        "avg_logprob": -0.2357074192592076,
        "compression_ratio": 1.4744897959183674,
        "end": 6921.780000000001,
        "id": 2147,
        "no_speech_prob": 0.00021654304873663932,
        "seek": 690410,
        "start": 6920.740000000001,
        "temperature": 0,
        "text": " It still has a hundred.",
        "tokens": [
          51196,
          467,
          920,
          575,
          257,
          3262,
          13,
          51248
        ]
      },
      {
        "avg_logprob": -0.2357074192592076,
        "compression_ratio": 1.4744897959183674,
        "end": 6924.02,
        "id": 2148,
        "no_speech_prob": 0.00021654304873663932,
        "seek": 690410,
        "start": 6922.42,
        "temperature": 0,
        "text": " It should override it right?",
        "tokens": [
          51280,
          467,
          820,
          42321,
          309,
          558,
          30,
          51360
        ]
      },
      {
        "avg_logprob": -0.2357074192592076,
        "compression_ratio": 1.4744897959183674,
        "end": 6925.14,
        "id": 2149,
        "no_speech_prob": 0.00021654304873663932,
        "seek": 690410,
        "start": 6924.02,
        "temperature": 0,
        "text": " If it's already in there.",
        "tokens": [
          51360,
          759,
          309,
          311,
          1217,
          294,
          456,
          13,
          51416
        ]
      },
      {
        "avg_logprob": -0.2357074192592076,
        "compression_ratio": 1.4744897959183674,
        "end": 6927.9400000000005,
        "id": 2150,
        "no_speech_prob": 0.00021654304873663932,
        "seek": 690410,
        "start": 6925.9400000000005,
        "temperature": 0,
        "text": " I don't know why I attempted to do something.",
        "tokens": [
          51456,
          286,
          500,
          380,
          458,
          983,
          286,
          18997,
          281,
          360,
          746,
          13,
          51556
        ]
      },
      {
        "avg_logprob": -0.2357074192592076,
        "compression_ratio": 1.4744897959183674,
        "end": 6929.46,
        "id": 2151,
        "no_speech_prob": 0.00021654304873663932,
        "seek": 690410,
        "start": 6927.9400000000005,
        "temperature": 0,
        "text": " In this last minute of this video.",
        "tokens": [
          51556,
          682,
          341,
          1036,
          3456,
          295,
          341,
          960,
          13,
          51632
        ]
      },
      {
        "avg_logprob": -0.2357074192592076,
        "compression_ratio": 1.4744897959183674,
        "end": 6931.14,
        "id": 2152,
        "no_speech_prob": 0.00021654304873663932,
        "seek": 690410,
        "start": 6930.42,
        "temperature": 0,
        "text": " I was done.",
        "tokens": [
          51680,
          286,
          390,
          1096,
          13,
          51716
        ]
      },
      {
        "avg_logprob": -0.2357074192592076,
        "compression_ratio": 1.4744897959183674,
        "end": 6933.46,
        "id": 2153,
        "no_speech_prob": 0.00021654304873663932,
        "seek": 690410,
        "start": 6932.02,
        "temperature": 0,
        "text": " Oh score is required.",
        "tokens": [
          51760,
          876,
          6175,
          307,
          4739,
          13,
          51832
        ]
      },
      {
        "avg_logprob": -0.21379552236417446,
        "compression_ratio": 1.4303797468354431,
        "end": 6934.6,
        "id": 2154,
        "no_speech_prob": 0.00006502809992525727,
        "seek": 693410,
        "start": 6934.1,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          50364,
          876,
          13,
          50389
        ]
      },
      {
        "avg_logprob": -0.21379552236417446,
        "compression_ratio": 1.4303797468354431,
        "end": 6937.3,
        "id": 2155,
        "no_speech_prob": 0.00006502809992525727,
        "seek": 693410,
        "start": 6936.5,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          50484,
          45263,
          13,
          50524
        ]
      },
      {
        "avg_logprob": -0.21379552236417446,
        "compression_ratio": 1.4303797468354431,
        "end": 6938.26,
        "id": 2156,
        "no_speech_prob": 0.00006502809992525727,
        "seek": 693410,
        "start": 6937.3,
        "temperature": 0,
        "text": " What did I mess up?",
        "tokens": [
          50524,
          708,
          630,
          286,
          2082,
          493,
          30,
          50572
        ]
      },
      {
        "avg_logprob": -0.21379552236417446,
        "compression_ratio": 1.4303797468354431,
        "end": 6943.06,
        "id": 2157,
        "no_speech_prob": 0.00006502809992525727,
        "seek": 693410,
        "start": 6941.780000000001,
        "temperature": 0,
        "text": " Sorry something got broken.",
        "tokens": [
          50748,
          4919,
          746,
          658,
          5463,
          13,
          50812
        ]
      },
      {
        "avg_logprob": -0.21379552236417446,
        "compression_ratio": 1.4303797468354431,
        "end": 6945.22,
        "id": 2158,
        "no_speech_prob": 0.00006502809992525727,
        "seek": 693410,
        "start": 6944.1,
        "temperature": 0,
        "text": " I'm debugging.",
        "tokens": [
          50864,
          286,
          478,
          45592,
          13,
          50920
        ]
      },
      {
        "avg_logprob": -0.21379552236417446,
        "compression_ratio": 1.4303797468354431,
        "end": 6946.5,
        "id": 2159,
        "no_speech_prob": 0.00006502809992525727,
        "seek": 693410,
        "start": 6945.22,
        "temperature": 0,
        "text": " I'm debugging.",
        "tokens": [
          50920,
          286,
          478,
          45592,
          13,
          50984
        ]
      },
      {
        "avg_logprob": -0.21379552236417446,
        "compression_ratio": 1.4303797468354431,
        "end": 6947.46,
        "id": 2160,
        "no_speech_prob": 0.00006502809992525727,
        "seek": 693410,
        "start": 6946.5,
        "temperature": 0,
        "text": " Submit word.",
        "tokens": [
          50984,
          8511,
          3508,
          1349,
          13,
          51032
        ]
      },
      {
        "avg_logprob": -0.21379552236417446,
        "compression_ratio": 1.4303797468354431,
        "end": 6949.88,
        "id": 2161,
        "no_speech_prob": 0.00006502809992525727,
        "seek": 693410,
        "start": 6949.38,
        "temperature": 0,
        "text": " Word.",
        "tokens": [
          51128,
          8725,
          13,
          51153
        ]
      },
      {
        "avg_logprob": -0.21379552236417446,
        "compression_ratio": 1.4303797468354431,
        "end": 6950.84,
        "id": 2162,
        "no_speech_prob": 0.00006502809992525727,
        "seek": 693410,
        "start": 6950.34,
        "temperature": 0,
        "text": " Score.",
        "tokens": [
          51176,
          47901,
          13,
          51201
        ]
      },
      {
        "avg_logprob": -0.21379552236417446,
        "compression_ratio": 1.4303797468354431,
        "end": 6952.9800000000005,
        "id": 2163,
        "no_speech_prob": 0.00006502809992525727,
        "seek": 693410,
        "start": 6951.780000000001,
        "temperature": 0,
        "text": " Oh I'm probably.",
        "tokens": [
          51248,
          876,
          286,
          478,
          1391,
          13,
          51308
        ]
      },
      {
        "avg_logprob": -0.21379552236417446,
        "compression_ratio": 1.4303797468354431,
        "end": 6956.42,
        "id": 2164,
        "no_speech_prob": 0.00006502809992525727,
        "seek": 693410,
        "start": 6952.9800000000005,
        "temperature": 0,
        "text": " Once again I have this score variable.",
        "tokens": [
          51308,
          3443,
          797,
          286,
          362,
          341,
          6175,
          7006,
          13,
          51480
        ]
      },
      {
        "avg_logprob": -0.21379552236417446,
        "compression_ratio": 1.4303797468354431,
        "end": 6958.5,
        "id": 2165,
        "no_speech_prob": 0.00006502809992525727,
        "seek": 693410,
        "start": 6956.42,
        "temperature": 0,
        "text": " Too many different places thing probably.",
        "tokens": [
          51480,
          11395,
          867,
          819,
          3190,
          551,
          1391,
          13,
          51584
        ]
      },
      {
        "avg_logprob": -0.21379552236417446,
        "compression_ratio": 1.4303797468354431,
        "end": 6961.700000000001,
        "id": 2166,
        "no_speech_prob": 0.00006502809992525727,
        "seek": 693410,
        "start": 6960.02,
        "temperature": 0,
        "text": " Score input.",
        "tokens": [
          51660,
          47901,
          4846,
          13,
          51744
        ]
      },
      {
        "avg_logprob": -0.3939917842044106,
        "compression_ratio": 1.5182481751824817,
        "end": 6963.54,
        "id": 2167,
        "no_speech_prob": 0.0004238831461407244,
        "seek": 696170,
        "start": 6962.179999999999,
        "temperature": 0,
        "text": " Let's just change that.",
        "tokens": [
          50388,
          961,
          311,
          445,
          1319,
          300,
          13,
          50456
        ]
      },
      {
        "avg_logprob": -0.3939917842044106,
        "compression_ratio": 1.5182481751824817,
        "end": 6964.9,
        "id": 2168,
        "no_speech_prob": 0.0004238831461407244,
        "seek": 696170,
        "start": 6964.34,
        "temperature": 0,
        "text": " I bet.",
        "tokens": [
          50496,
          286,
          778,
          13,
          50524
        ]
      },
      {
        "avg_logprob": -0.3939917842044106,
        "compression_ratio": 1.5182481751824817,
        "end": 6969.46,
        "id": 2169,
        "no_speech_prob": 0.0004238831461407244,
        "seek": 696170,
        "start": 6967.78,
        "temperature": 0,
        "text": " Let's see if that's the problem.",
        "tokens": [
          50668,
          961,
          311,
          536,
          498,
          300,
          311,
          264,
          1154,
          13,
          50752
        ]
      },
      {
        "avg_logprob": -0.3939917842044106,
        "compression_ratio": 1.5182481751824817,
        "end": 6974.82,
        "id": 2170,
        "no_speech_prob": 0.0004238831461407244,
        "seek": 696170,
        "start": 6974.0199999999995,
        "temperature": 0,
        "text": " Add word.",
        "tokens": [
          50980,
          5349,
          1349,
          13,
          51020
        ]
      },
      {
        "avg_logprob": -0.3939917842044106,
        "compression_ratio": 1.5182481751824817,
        "end": 6977.62,
        "id": 2171,
        "no_speech_prob": 0.0004238831461407244,
        "seek": 696170,
        "start": 6976.5,
        "temperature": 0,
        "text": " Plus score.",
        "tokens": [
          51104,
          7721,
          6175,
          13,
          51160
        ]
      },
      {
        "avg_logprob": -0.3939917842044106,
        "compression_ratio": 1.5182481751824817,
        "end": 6978.82,
        "id": 2172,
        "no_speech_prob": 0.0004238831461407244,
        "seek": 696170,
        "start": 6977.62,
        "temperature": 0,
        "text": " Let's try that again.",
        "tokens": [
          51160,
          961,
          311,
          853,
          300,
          797,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.3939917842044106,
        "compression_ratio": 1.5182481751824817,
        "end": 6984.58,
        "id": 2173,
        "no_speech_prob": 0.0004238831461407244,
        "seek": 696170,
        "start": 6982.5,
        "temperature": 0,
        "text": " Oh I wonder if you send it zero.",
        "tokens": [
          51404,
          876,
          286,
          2441,
          498,
          291,
          2845,
          309,
          4018,
          13,
          51508
        ]
      },
      {
        "avg_logprob": -0.3939917842044106,
        "compression_ratio": 1.5182481751824817,
        "end": 6985.86,
        "id": 2174,
        "no_speech_prob": 0.0004238831461407244,
        "seek": 696170,
        "start": 6984.58,
        "temperature": 0,
        "text": " You can't give it a score of.",
        "tokens": [
          51508,
          509,
          393,
          380,
          976,
          309,
          257,
          6175,
          295,
          13,
          51572
        ]
      },
      {
        "avg_logprob": -0.3939917842044106,
        "compression_ratio": 1.5182481751824817,
        "end": 6988.099999999999,
        "id": 2175,
        "no_speech_prob": 0.0004238831461407244,
        "seek": 696170,
        "start": 6985.86,
        "temperature": 0,
        "text": " Oh you can't give it a score of zero.",
        "tokens": [
          51572,
          876,
          291,
          393,
          380,
          976,
          309,
          257,
          6175,
          295,
          4018,
          13,
          51684
        ]
      },
      {
        "avg_logprob": -0.44323875654989214,
        "compression_ratio": 1.9078341013824884,
        "end": 6990.740000000001,
        "id": 2176,
        "no_speech_prob": 0.0055548520758748055,
        "seek": 698810,
        "start": 6988.34,
        "temperature": 0,
        "text": " Because zero must be like false or something.",
        "tokens": [
          50376,
          1436,
          4018,
          1633,
          312,
          411,
          7908,
          420,
          746,
          13,
          50496
        ]
      },
      {
        "avg_logprob": -0.44323875654989214,
        "compression_ratio": 1.9078341013824884,
        "end": 6993.06,
        "id": 2177,
        "no_speech_prob": 0.0055548520758748055,
        "seek": 698810,
        "start": 6990.740000000001,
        "temperature": 0,
        "text": " Oh yeah zero is evaluated as false.",
        "tokens": [
          50496,
          876,
          1338,
          4018,
          307,
          25509,
          382,
          7908,
          13,
          50612
        ]
      },
      {
        "avg_logprob": -0.44323875654989214,
        "compression_ratio": 1.9078341013824884,
        "end": 6994.42,
        "id": 2178,
        "no_speech_prob": 0.0055548520758748055,
        "seek": 698810,
        "start": 6993.06,
        "temperature": 0,
        "text": " Oh that's just a little like.",
        "tokens": [
          50612,
          876,
          300,
          311,
          445,
          257,
          707,
          411,
          13,
          50680
        ]
      },
      {
        "avg_logprob": -0.44323875654989214,
        "compression_ratio": 1.9078341013824884,
        "end": 6997.780000000001,
        "id": 2179,
        "no_speech_prob": 0.0055548520758748055,
        "seek": 698810,
        "start": 6995.3,
        "temperature": 0,
        "text": " Mistake that I have in mind.",
        "tokens": [
          50724,
          20166,
          619,
          300,
          286,
          362,
          294,
          1575,
          13,
          50848
        ]
      },
      {
        "avg_logprob": -0.44323875654989214,
        "compression_ratio": 1.9078341013824884,
        "end": 7000.34,
        "id": 2180,
        "no_speech_prob": 0.0055548520758748055,
        "seek": 698810,
        "start": 6999.38,
        "temperature": 0,
        "text": " Now that I gave it.",
        "tokens": [
          50928,
          823,
          300,
          286,
          2729,
          309,
          13,
          50976
        ]
      },
      {
        "avg_logprob": -0.44323875654989214,
        "compression_ratio": 1.9078341013824884,
        "end": 7003.700000000001,
        "id": 2181,
        "no_speech_prob": 0.0055548520758748055,
        "seek": 698810,
        "start": 7002.9800000000005,
        "temperature": 0,
        "text": " I don't know what this.",
        "tokens": [
          51108,
          286,
          500,
          380,
          458,
          437,
          341,
          13,
          51144
        ]
      },
      {
        "avg_logprob": -0.44323875654989214,
        "compression_ratio": 1.9078341013824884,
        "end": 7005.620000000001,
        "id": 2182,
        "no_speech_prob": 0.0055548520758748055,
        "seek": 698810,
        "start": 7004.58,
        "temperature": 0,
        "text": " Cut this part out.",
        "tokens": [
          51188,
          9431,
          341,
          644,
          484,
          13,
          51240
        ]
      },
      {
        "avg_logprob": -0.44323875654989214,
        "compression_ratio": 1.9078341013824884,
        "end": 7009.14,
        "id": 2183,
        "no_speech_prob": 0.0055548520758748055,
        "seek": 698810,
        "start": 7007.14,
        "temperature": 0,
        "text": " I don't know why I was just like fixing that.",
        "tokens": [
          51316,
          286,
          500,
          380,
          458,
          983,
          286,
          390,
          445,
          411,
          19442,
          300,
          13,
          51416
        ]
      },
      {
        "avg_logprob": -0.44323875654989214,
        "compression_ratio": 1.9078341013824884,
        "end": 7010.26,
        "id": 2184,
        "no_speech_prob": 0.0055548520758748055,
        "seek": 698810,
        "start": 7009.14,
        "temperature": 0,
        "text": " Where was I in this video?",
        "tokens": [
          51416,
          2305,
          390,
          286,
          294,
          341,
          960,
          30,
          51472
        ]
      },
      {
        "avg_logprob": -0.44323875654989214,
        "compression_ratio": 1.9078341013824884,
        "end": 7013.3,
        "id": 2185,
        "no_speech_prob": 0.0055548520758748055,
        "seek": 698810,
        "start": 7010.26,
        "temperature": 0,
        "text": " Cut cut back or rewind rewind.",
        "tokens": [
          51472,
          9431,
          1723,
          646,
          420,
          41458,
          41458,
          13,
          51624
        ]
      },
      {
        "avg_logprob": -0.44323875654989214,
        "compression_ratio": 1.9078341013824884,
        "end": 7014.58,
        "id": 2186,
        "no_speech_prob": 0.0055548520758748055,
        "seek": 698810,
        "start": 7013.3,
        "temperature": 0,
        "text": " Let me finish this video off.",
        "tokens": [
          51624,
          961,
          385,
          2413,
          341,
          960,
          766,
          13,
          51688
        ]
      },
      {
        "avg_logprob": -0.44323875654989214,
        "compression_ratio": 1.9078341013824884,
        "end": 7015.54,
        "id": 2187,
        "no_speech_prob": 0.0055548520758748055,
        "seek": 698810,
        "start": 7014.58,
        "temperature": 0,
        "text": " I don't know it'll cut it out.",
        "tokens": [
          51688,
          286,
          500,
          380,
          458,
          309,
          603,
          1723,
          309,
          484,
          13,
          51736
        ]
      },
      {
        "avg_logprob": -0.44323875654989214,
        "compression_ratio": 1.9078341013824884,
        "end": 7017.54,
        "id": 2188,
        "no_speech_prob": 0.0055548520758748055,
        "seek": 698810,
        "start": 7015.54,
        "temperature": 0,
        "text": " I don't know why I was just like fixing that.",
        "tokens": [
          51736,
          286,
          500,
          380,
          458,
          983,
          286,
          390,
          445,
          411,
          19442,
          300,
          13,
          51836
        ]
      },
      {
        "avg_logprob": -0.22221264839172364,
        "compression_ratio": 1.6451612903225807,
        "end": 7018.74,
        "id": 2189,
        "no_speech_prob": 0.0002034264907706529,
        "seek": 701754,
        "start": 7017.54,
        "temperature": 0,
        "text": " I don't know it'll cut at some point.",
        "tokens": [
          50364,
          286,
          500,
          380,
          458,
          309,
          603,
          1723,
          412,
          512,
          935,
          13,
          50424
        ]
      },
      {
        "avg_logprob": -0.22221264839172364,
        "compression_ratio": 1.6451612903225807,
        "end": 7022.1,
        "id": 2190,
        "no_speech_prob": 0.0002034264907706529,
        "seek": 701754,
        "start": 7020.5,
        "temperature": 0,
        "text": " I just wanted to like make sure it was still working.",
        "tokens": [
          50512,
          286,
          445,
          1415,
          281,
          411,
          652,
          988,
          309,
          390,
          920,
          1364,
          13,
          50592
        ]
      },
      {
        "avg_logprob": -0.22221264839172364,
        "compression_ratio": 1.6451612903225807,
        "end": 7023.54,
        "id": 2191,
        "no_speech_prob": 0.0002034264907706529,
        "seek": 701754,
        "start": 7022.1,
        "temperature": 0,
        "text": " It's still working but I'll fix that.",
        "tokens": [
          50592,
          467,
          311,
          920,
          1364,
          457,
          286,
          603,
          3191,
          300,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.22221264839172364,
        "compression_ratio": 1.6451612903225807,
        "end": 7024.66,
        "id": 2192,
        "no_speech_prob": 0.0002034264907706529,
        "seek": 701754,
        "start": 7023.54,
        "temperature": 0,
        "text": " Let me actually fix that.",
        "tokens": [
          50664,
          961,
          385,
          767,
          3191,
          300,
          13,
          50720
        ]
      },
      {
        "avg_logprob": -0.22221264839172364,
        "compression_ratio": 1.6451612903225807,
        "end": 7026.18,
        "id": 2193,
        "no_speech_prob": 0.0002034264907706529,
        "seek": 701754,
        "start": 7024.66,
        "temperature": 0,
        "text": " Let me show you what I mean in case you're wondering.",
        "tokens": [
          50720,
          961,
          385,
          855,
          291,
          437,
          286,
          914,
          294,
          1389,
          291,
          434,
          6359,
          13,
          50796
        ]
      },
      {
        "avg_logprob": -0.22221264839172364,
        "compression_ratio": 1.6451612903225807,
        "end": 7029.62,
        "id": 2194,
        "no_speech_prob": 0.0002034264907706529,
        "seek": 701754,
        "start": 7026.18,
        "temperature": 0,
        "text": " This doesn't need to make it into the actual like published version.",
        "tokens": [
          50796,
          639,
          1177,
          380,
          643,
          281,
          652,
          309,
          666,
          264,
          3539,
          411,
          6572,
          3037,
          13,
          50968
        ]
      },
      {
        "avg_logprob": -0.22221264839172364,
        "compression_ratio": 1.6451612903225807,
        "end": 7031.94,
        "id": 2195,
        "no_speech_prob": 0.0002034264907706529,
        "seek": 701754,
        "start": 7029.62,
        "temperature": 0,
        "text": " The edited version of this tutorial.",
        "tokens": [
          50968,
          440,
          23016,
          3037,
          295,
          341,
          7073,
          13,
          51084
        ]
      },
      {
        "avg_logprob": -0.22221264839172364,
        "compression_ratio": 1.6451612903225807,
        "end": 7036.1,
        "id": 2196,
        "no_speech_prob": 0.0002034264907706529,
        "seek": 701754,
        "start": 7031.94,
        "temperature": 0,
        "text": " But if I go to the get request for.",
        "tokens": [
          51084,
          583,
          498,
          286,
          352,
          281,
          264,
          483,
          5308,
          337,
          13,
          51292
        ]
      },
      {
        "avg_logprob": -0.22221264839172364,
        "compression_ratio": 1.6451612903225807,
        "end": 7039.94,
        "id": 2197,
        "no_speech_prob": 0.0002034264907706529,
        "seek": 701754,
        "start": 7038.0199999999995,
        "temperature": 0,
        "text": " Add I have this.",
        "tokens": [
          51388,
          5349,
          286,
          362,
          341,
          13,
          51484
        ]
      },
      {
        "avg_logprob": -0.22221264839172364,
        "compression_ratio": 1.6451612903225807,
        "end": 7041.78,
        "id": 2198,
        "no_speech_prob": 0.0002034264907706529,
        "seek": 701754,
        "start": 7039.94,
        "temperature": 0,
        "text": " I'm doing so much scrolling it's crazy.",
        "tokens": [
          51484,
          286,
          478,
          884,
          370,
          709,
          29053,
          309,
          311,
          3219,
          13,
          51576
        ]
      },
      {
        "avg_logprob": -0.49887627049496297,
        "compression_ratio": 1.6865671641791045,
        "end": 7044.82,
        "id": 2199,
        "no_speech_prob": 0.006289878394454718,
        "seek": 704178,
        "start": 7042.5,
        "temperature": 0,
        "text": " What I'm doing is I'm saying if there is no score.",
        "tokens": [
          50400,
          708,
          286,
          478,
          884,
          307,
          286,
          478,
          1566,
          498,
          456,
          307,
          572,
          6175,
          13,
          50516
        ]
      },
      {
        "avg_logprob": -0.49887627049496297,
        "compression_ratio": 1.6865671641791045,
        "end": 7050.0199999999995,
        "id": 2200,
        "no_speech_prob": 0.006289878394454718,
        "seek": 704178,
        "start": 7045.78,
        "temperature": 0,
        "text": " Score is required but if the score is zero that'll evaluate.",
        "tokens": [
          50564,
          47901,
          307,
          4739,
          457,
          498,
          264,
          6175,
          307,
          4018,
          300,
          603,
          13059,
          13,
          50776
        ]
      },
      {
        "avg_logprob": -0.49887627049496297,
        "compression_ratio": 1.6865671641791045,
        "end": 7052.0199999999995,
        "id": 2201,
        "no_speech_prob": 0.006289878394454718,
        "seek": 704178,
        "start": 7050.0199999999995,
        "temperature": 0,
        "text": " So I want to say if.",
        "tokens": [
          50776,
          407,
          286,
          528,
          281,
          584,
          498,
          13,
          50876
        ]
      },
      {
        "avg_logprob": -0.49887627049496297,
        "compression_ratio": 1.6865671641791045,
        "end": 7054.099999999999,
        "id": 2202,
        "no_speech_prob": 0.006289878394454718,
        "seek": 704178,
        "start": 7053.3,
        "temperature": 0,
        "text": " If score.",
        "tokens": [
          50940,
          759,
          6175,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.49887627049496297,
        "compression_ratio": 1.6865671641791045,
        "end": 7058.74,
        "id": 2203,
        "no_speech_prob": 0.006289878394454718,
        "seek": 704178,
        "start": 7056.0199999999995,
        "temperature": 0,
        "text": " Does not does not equal zero.",
        "tokens": [
          51076,
          4402,
          406,
          775,
          406,
          2681,
          4018,
          13,
          51212
        ]
      },
      {
        "avg_logprob": -0.49887627049496297,
        "compression_ratio": 1.6865671641791045,
        "end": 7062.34,
        "id": 2204,
        "no_speech_prob": 0.006289878394454718,
        "seek": 704178,
        "start": 7061.62,
        "temperature": 0,
        "text": " If score.",
        "tokens": [
          51356,
          759,
          6175,
          13,
          51392
        ]
      },
      {
        "avg_logprob": -0.49887627049496297,
        "compression_ratio": 1.6865671641791045,
        "end": 7065.62,
        "id": 2205,
        "no_speech_prob": 0.006289878394454718,
        "seek": 704178,
        "start": 7064.66,
        "temperature": 0,
        "text": " If no score.",
        "tokens": [
          51508,
          759,
          572,
          6175,
          13,
          51556
        ]
      },
      {
        "avg_logprob": -0.49887627049496297,
        "compression_ratio": 1.6865671641791045,
        "end": 7069.62,
        "id": 2206,
        "no_speech_prob": 0.006289878394454718,
        "seek": 704178,
        "start": 7067.62,
        "temperature": 0,
        "text": " And score does not equal zero.",
        "tokens": [
          51656,
          400,
          6175,
          775,
          406,
          2681,
          4018,
          13,
          51756
        ]
      },
      {
        "avg_logprob": -0.21176236112352828,
        "compression_ratio": 1.8716981132075472,
        "end": 7072.74,
        "id": 2207,
        "no_speech_prob": 0.00019411268294788897,
        "seek": 706962,
        "start": 7070.18,
        "temperature": 0,
        "text": " And score does not equal zero.",
        "tokens": [
          50392,
          400,
          6175,
          775,
          406,
          2681,
          4018,
          13,
          50520
        ]
      },
      {
        "avg_logprob": -0.21176236112352828,
        "compression_ratio": 1.8716981132075472,
        "end": 7077.38,
        "id": 2208,
        "no_speech_prob": 0.00019411268294788897,
        "seek": 706962,
        "start": 7073.54,
        "temperature": 0,
        "text": " So this is me just checking like I mean I could also say if score equals undefined.",
        "tokens": [
          50560,
          407,
          341,
          307,
          385,
          445,
          8568,
          411,
          286,
          914,
          286,
          727,
          611,
          584,
          498,
          6175,
          6915,
          674,
          5666,
          2001,
          13,
          50752
        ]
      },
      {
        "avg_logprob": -0.21176236112352828,
        "compression_ratio": 1.8716981132075472,
        "end": 7078.5,
        "id": 2209,
        "no_speech_prob": 0.00019411268294788897,
        "seek": 706962,
        "start": 7077.38,
        "temperature": 0,
        "text": " Because I think that's what it would be.",
        "tokens": [
          50752,
          1436,
          286,
          519,
          300,
          311,
          437,
          309,
          576,
          312,
          13,
          50808
        ]
      },
      {
        "avg_logprob": -0.21176236112352828,
        "compression_ratio": 1.8716981132075472,
        "end": 7082.58,
        "id": 2210,
        "no_speech_prob": 0.00019411268294788897,
        "seek": 706962,
        "start": 7079.0599999999995,
        "temperature": 0,
        "text": " But I could just sort of say here let me just double check.",
        "tokens": [
          50836,
          583,
          286,
          727,
          445,
          1333,
          295,
          584,
          510,
          718,
          385,
          445,
          3834,
          1520,
          13,
          51012
        ]
      },
      {
        "avg_logprob": -0.21176236112352828,
        "compression_ratio": 1.8716981132075472,
        "end": 7084.42,
        "id": 2211,
        "no_speech_prob": 0.00019411268294788897,
        "seek": 706962,
        "start": 7082.58,
        "temperature": 0,
        "text": " And make sure that like.",
        "tokens": [
          51012,
          400,
          652,
          988,
          300,
          411,
          13,
          51104
        ]
      },
      {
        "avg_logprob": -0.21176236112352828,
        "compression_ratio": 1.8716981132075472,
        "end": 7087.78,
        "id": 2212,
        "no_speech_prob": 0.00019411268294788897,
        "seek": 706962,
        "start": 7085.38,
        "temperature": 0,
        "text": " I want this is for things that are invalid.",
        "tokens": [
          51152,
          286,
          528,
          341,
          307,
          337,
          721,
          300,
          366,
          34702,
          13,
          51272
        ]
      },
      {
        "avg_logprob": -0.21176236112352828,
        "compression_ratio": 1.8716981132075472,
        "end": 7088.98,
        "id": 2213,
        "no_speech_prob": 0.00019411268294788897,
        "seek": 706962,
        "start": 7087.78,
        "temperature": 0,
        "text": " And I want zero to be valid.",
        "tokens": [
          51272,
          400,
          286,
          528,
          4018,
          281,
          312,
          7363,
          13,
          51332
        ]
      },
      {
        "avg_logprob": -0.21176236112352828,
        "compression_ratio": 1.8716981132075472,
        "end": 7093.38,
        "id": 2214,
        "no_speech_prob": 0.00019411268294788897,
        "seek": 706962,
        "start": 7088.98,
        "temperature": 0,
        "text": " So it's only invalid if it's like something like null or undefined or hello.",
        "tokens": [
          51332,
          407,
          309,
          311,
          787,
          34702,
          498,
          309,
          311,
          411,
          746,
          411,
          18184,
          420,
          674,
          5666,
          2001,
          420,
          7751,
          13,
          51552
        ]
      },
      {
        "avg_logprob": -0.21176236112352828,
        "compression_ratio": 1.8716981132075472,
        "end": 7095.62,
        "id": 2215,
        "no_speech_prob": 0.00019411268294788897,
        "seek": 706962,
        "start": 7093.38,
        "temperature": 0,
        "text": " Some text but not zero.",
        "tokens": [
          51552,
          2188,
          2487,
          457,
          406,
          4018,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21176236112352828,
        "compression_ratio": 1.8716981132075472,
        "end": 7097.86,
        "id": 2216,
        "no_speech_prob": 0.00019411268294788897,
        "seek": 706962,
        "start": 7095.62,
        "temperature": 0,
        "text": " So I mean I need better error checking here.",
        "tokens": [
          51664,
          407,
          286,
          914,
          286,
          643,
          1101,
          6713,
          8568,
          510,
          13,
          51776
        ]
      },
      {
        "avg_logprob": -0.21176236112352828,
        "compression_ratio": 1.8716981132075472,
        "end": 7099.3,
        "id": 2217,
        "no_speech_prob": 0.00019411268294788897,
        "seek": 706962,
        "start": 7097.86,
        "temperature": 0,
        "text": " But let me just see that that works.",
        "tokens": [
          51776,
          583,
          718,
          385,
          445,
          536,
          300,
          300,
          1985,
          13,
          51848
        ]
      },
      {
        "avg_logprob": -0.23546729264435945,
        "compression_ratio": 1.5260869565217392,
        "end": 7102.82,
        "id": 2218,
        "no_speech_prob": 0.00014202312740962952,
        "seek": 709962,
        "start": 7100.5,
        "temperature": 0,
        "text": " Uh and then today zero.",
        "tokens": [
          50408,
          4019,
          293,
          550,
          965,
          4018,
          13,
          50524
        ]
      },
      {
        "avg_logprob": -0.23546729264435945,
        "compression_ratio": 1.5260869565217392,
        "end": 7106.0199999999995,
        "id": 2219,
        "no_speech_prob": 0.00014202312740962952,
        "seek": 709962,
        "start": 7104.18,
        "temperature": 0,
        "text": " So it had a sign so that fixed it.",
        "tokens": [
          50592,
          407,
          309,
          632,
          257,
          1465,
          370,
          300,
          6806,
          309,
          13,
          50684
        ]
      },
      {
        "avg_logprob": -0.23546729264435945,
        "compression_ratio": 1.5260869565217392,
        "end": 7108.66,
        "id": 2220,
        "no_speech_prob": 0.00014202312740962952,
        "seek": 709962,
        "start": 7106.0199999999995,
        "temperature": 0,
        "text": " Okay so um I don't know where I was.",
        "tokens": [
          50684,
          1033,
          370,
          1105,
          286,
          500,
          380,
          458,
          689,
          286,
          390,
          13,
          50816
        ]
      },
      {
        "avg_logprob": -0.23546729264435945,
        "compression_ratio": 1.5260869565217392,
        "end": 7110.26,
        "id": 2221,
        "no_speech_prob": 0.00014202312740962952,
        "seek": 709962,
        "start": 7108.66,
        "temperature": 0,
        "text": " I was checking to make sure this works.",
        "tokens": [
          50816,
          286,
          390,
          8568,
          281,
          652,
          988,
          341,
          1985,
          13,
          50896
        ]
      },
      {
        "avg_logprob": -0.23546729264435945,
        "compression_ratio": 1.5260869565217392,
        "end": 7115.22,
        "id": 2222,
        "no_speech_prob": 0.00014202312740962952,
        "seek": 709962,
        "start": 7111.94,
        "temperature": 0,
        "text": " So and then but I'm just going to like finish off this video.",
        "tokens": [
          50980,
          407,
          293,
          550,
          457,
          286,
          478,
          445,
          516,
          281,
          411,
          2413,
          766,
          341,
          960,
          13,
          51144
        ]
      },
      {
        "avg_logprob": -0.23546729264435945,
        "compression_ratio": 1.5260869565217392,
        "end": 7118.0199999999995,
        "id": 2223,
        "no_speech_prob": 0.00014202312740962952,
        "seek": 709962,
        "start": 7116.5,
        "temperature": 0,
        "text": " I'll just say some wrap-up words.",
        "tokens": [
          51208,
          286,
          603,
          445,
          584,
          512,
          7019,
          12,
          1010,
          2283,
          13,
          51284
        ]
      },
      {
        "avg_logprob": -0.23546729264435945,
        "compression_ratio": 1.5260869565217392,
        "end": 7126.26,
        "id": 2224,
        "no_speech_prob": 0.00014202312740962952,
        "seek": 709962,
        "start": 7120.82,
        "temperature": 0,
        "text": " So this concludes my series about how to build an API from scratch.",
        "tokens": [
          51424,
          407,
          341,
          24643,
          452,
          2638,
          466,
          577,
          281,
          1322,
          364,
          9362,
          490,
          8459,
          13,
          51696
        ]
      },
      {
        "avg_logprob": -0.23546729264435945,
        "compression_ratio": 1.5260869565217392,
        "end": 7129.54,
        "id": 2225,
        "no_speech_prob": 0.00014202312740962952,
        "seek": 709962,
        "start": 7126.26,
        "temperature": 0,
        "text": " Using node and a front end to that API using p5.js.",
        "tokens": [
          51696,
          11142,
          9984,
          293,
          257,
          1868,
          917,
          281,
          300,
          9362,
          1228,
          280,
          20,
          13,
          25530,
          13,
          51860
        ]
      },
      {
        "avg_logprob": -0.22814966837565104,
        "compression_ratio": 1.605095541401274,
        "end": 7131.3,
        "id": 2226,
        "no_speech_prob": 0.00007031094719422981,
        "seek": 712954,
        "start": 7130.0199999999995,
        "temperature": 0,
        "text": " Hopefully you found this useful.",
        "tokens": [
          50388,
          10429,
          291,
          1352,
          341,
          4420,
          13,
          50452
        ]
      },
      {
        "avg_logprob": -0.22814966837565104,
        "compression_ratio": 1.605095541401274,
        "end": 7132.18,
        "id": 2227,
        "no_speech_prob": 0.00007031094719422981,
        "seek": 712954,
        "start": 7131.3,
        "temperature": 0,
        "text": " If you make an API.",
        "tokens": [
          50452,
          759,
          291,
          652,
          364,
          9362,
          13,
          50496
        ]
      },
      {
        "avg_logprob": -0.22814966837565104,
        "compression_ratio": 1.605095541401274,
        "end": 7133.22,
        "id": 2228,
        "no_speech_prob": 0.00007031094719422981,
        "seek": 712954,
        "start": 7132.18,
        "temperature": 0,
        "text": " If you build something.",
        "tokens": [
          50496,
          759,
          291,
          1322,
          746,
          13,
          50548
        ]
      },
      {
        "avg_logprob": -0.22814966837565104,
        "compression_ratio": 1.605095541401274,
        "end": 7133.94,
        "id": 2229,
        "no_speech_prob": 0.00007031094719422981,
        "seek": 712954,
        "start": 7133.22,
        "temperature": 0,
        "text": " Share it with me.",
        "tokens": [
          50548,
          14945,
          309,
          365,
          385,
          13,
          50584
        ]
      },
      {
        "avg_logprob": -0.22814966837565104,
        "compression_ratio": 1.605095541401274,
        "end": 7135.7,
        "id": 2230,
        "no_speech_prob": 0.00007031094719422981,
        "seek": 712954,
        "start": 7133.94,
        "temperature": 0,
        "text": " Ask in the comments.",
        "tokens": [
          50584,
          12320,
          294,
          264,
          3053,
          13,
          50672
        ]
      },
      {
        "avg_logprob": -0.22814966837565104,
        "compression_ratio": 1.605095541401274,
        "end": 7136.66,
        "id": 2231,
        "no_speech_prob": 0.00007031094719422981,
        "seek": 712954,
        "start": 7135.7,
        "temperature": 0,
        "text": " Like share this video.",
        "tokens": [
          50672,
          1743,
          2073,
          341,
          960,
          13,
          50720
        ]
      },
      {
        "avg_logprob": -0.22814966837565104,
        "compression_ratio": 1.605095541401274,
        "end": 7138.42,
        "id": 2232,
        "no_speech_prob": 0.00007031094719422981,
        "seek": 712954,
        "start": 7136.66,
        "temperature": 0,
        "text": " I guess those are the things I'm supposed to say.",
        "tokens": [
          50720,
          286,
          2041,
          729,
          366,
          264,
          721,
          286,
          478,
          3442,
          281,
          584,
          13,
          50808
        ]
      },
      {
        "avg_logprob": -0.22814966837565104,
        "compression_ratio": 1.605095541401274,
        "end": 7139.54,
        "id": 2233,
        "no_speech_prob": 0.00007031094719422981,
        "seek": 712954,
        "start": 7138.42,
        "temperature": 0,
        "text": " And I look forward to seeing you.",
        "tokens": [
          50808,
          400,
          286,
          574,
          2128,
          281,
          2577,
          291,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.22814966837565104,
        "compression_ratio": 1.605095541401274,
        "end": 7142.0199999999995,
        "id": 2234,
        "no_speech_prob": 0.00007031094719422981,
        "seek": 712954,
        "start": 7139.54,
        "temperature": 0,
        "text": " I'll do some follow-up videos as part of this playlist.",
        "tokens": [
          50864,
          286,
          603,
          360,
          512,
          1524,
          12,
          1010,
          2145,
          382,
          644,
          295,
          341,
          16788,
          13,
          50988
        ]
      },
      {
        "avg_logprob": -0.22814966837565104,
        "compression_ratio": 1.605095541401274,
        "end": 7144.42,
        "id": 2235,
        "no_speech_prob": 0.00007031094719422981,
        "seek": 712954,
        "start": 7142.0199999999995,
        "temperature": 0,
        "text": " If there are some good questions or other features that I think of adding.",
        "tokens": [
          50988,
          759,
          456,
          366,
          512,
          665,
          1651,
          420,
          661,
          4122,
          300,
          286,
          519,
          295,
          5127,
          13,
          51108
        ]
      },
      {
        "avg_logprob": -0.22814966837565104,
        "compression_ratio": 1.605095541401274,
        "end": 7145.54,
        "id": 2236,
        "no_speech_prob": 0.00007031094719422981,
        "seek": 712954,
        "start": 7144.42,
        "temperature": 0,
        "text": " Okay see you soon.",
        "tokens": [
          51108,
          1033,
          536,
          291,
          2321,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.22814966837565104,
        "compression_ratio": 1.605095541401274,
        "end": 7146.0199999999995,
        "id": 2237,
        "no_speech_prob": 0.00007031094719422981,
        "seek": 712954,
        "start": 7145.54,
        "temperature": 0,
        "text": " Goodbye.",
        "tokens": [
          51164,
          15528,
          13,
          51188
        ]
      },
      {
        "avg_logprob": -0.22814966837565104,
        "compression_ratio": 1.605095541401274,
        "end": 7153.78,
        "id": 2238,
        "no_speech_prob": 0.00007031094719422981,
        "seek": 712954,
        "start": 7148.82,
        "temperature": 0,
        "text": " Yes lordius I could say score does not equal undefined.",
        "tokens": [
          51328,
          1079,
          15448,
          4872,
          286,
          727,
          584,
          6175,
          775,
          406,
          2681,
          674,
          5666,
          2001,
          13,
          51576
        ]
      },
      {
        "avg_logprob": -0.22814966837565104,
        "compression_ratio": 1.605095541401274,
        "end": 7157.94,
        "id": 2239,
        "no_speech_prob": 0.00007031094719422981,
        "seek": 712954,
        "start": 7153.78,
        "temperature": 0,
        "text": " All right so um thank you everybody for watching today.",
        "tokens": [
          51576,
          1057,
          558,
          370,
          1105,
          1309,
          291,
          2201,
          337,
          1976,
          965,
          13,
          51784
        ]
      },
      {
        "avg_logprob": -0.22814966837565104,
        "compression_ratio": 1.605095541401274,
        "end": 7159.14,
        "id": 2240,
        "no_speech_prob": 0.00007031094719422981,
        "seek": 712954,
        "start": 7157.94,
        "temperature": 0,
        "text": " It is 520.",
        "tokens": [
          51784,
          467,
          307,
          1025,
          2009,
          13,
          51844
        ]
      },
      {
        "avg_logprob": -0.3689943593698782,
        "compression_ratio": 1.6715328467153285,
        "end": 7160.900000000001,
        "id": 2241,
        "no_speech_prob": 0.001926695927977562,
        "seek": 715914,
        "start": 7159.3,
        "temperature": 0.8,
        "text": " Oh my goodness this has been a.",
        "tokens": [
          50372,
          876,
          452,
          8387,
          341,
          575,
          668,
          257,
          13,
          50452
        ]
      },
      {
        "avg_logprob": -0.3689943593698782,
        "compression_ratio": 1.6715328467153285,
        "end": 7165.38,
        "id": 2242,
        "no_speech_prob": 0.001926695927977562,
        "seek": 715914,
        "start": 7164.740000000001,
        "temperature": 0.8,
        "text": " Weirdly.",
        "tokens": [
          50644,
          32033,
          356,
          13,
          50676
        ]
      },
      {
        "avg_logprob": -0.3689943593698782,
        "compression_ratio": 1.6715328467153285,
        "end": 7168.9800000000005,
        "id": 2243,
        "no_speech_prob": 0.001926695927977562,
        "seek": 715914,
        "start": 7166.42,
        "temperature": 0.8,
        "text": " The live stream since it's only been going for 10 minutes.",
        "tokens": [
          50728,
          440,
          1621,
          2242,
          335,
          1670,
          309,
          311,
          787,
          668,
          516,
          337,
          1266,
          2077,
          13,
          50856
        ]
      },
      {
        "avg_logprob": -0.3689943593698782,
        "compression_ratio": 1.6715328467153285,
        "end": 7170.58,
        "id": 2244,
        "no_speech_prob": 0.001926695927977562,
        "seek": 715914,
        "start": 7168.9800000000005,
        "temperature": 0.8,
        "text": " Does it like stop and restart.",
        "tokens": [
          50856,
          4402,
          309,
          411,
          1590,
          293,
          21022,
          13,
          50936
        ]
      },
      {
        "avg_logprob": -0.3689943593698782,
        "compression_ratio": 1.6715328467153285,
        "end": 7171.9400000000005,
        "id": 2245,
        "no_speech_prob": 0.001926695927977562,
        "seek": 715914,
        "start": 7170.58,
        "temperature": 0.8,
        "text": " I don't know why it's saying that.",
        "tokens": [
          50936,
          286,
          500,
          380,
          350,
          3785,
          983,
          309,
          311,
          1566,
          300,
          13,
          51004
        ]
      },
      {
        "avg_logprob": -0.3689943593698782,
        "compression_ratio": 1.6715328467153285,
        "end": 7173.22,
        "id": 2246,
        "no_speech_prob": 0.001926695927977562,
        "seek": 715914,
        "start": 7171.9400000000005,
        "temperature": 0.8,
        "text": " But this has been two hours.",
        "tokens": [
          51004,
          583,
          341,
          575,
          668,
          732,
          2496,
          13,
          51068
        ]
      },
      {
        "avg_logprob": -0.3689943593698782,
        "compression_ratio": 1.6715328467153285,
        "end": 7175.62,
        "id": 2247,
        "no_speech_prob": 0.001926695927977562,
        "seek": 715914,
        "start": 7174.02,
        "temperature": 0.8,
        "text": " Hopefully the live stream archive is okay.",
        "tokens": [
          51108,
          10429,
          264,
          1621,
          4309,
          23507,
          307,
          1392,
          13,
          51188
        ]
      },
      {
        "avg_logprob": -0.3689943593698782,
        "compression_ratio": 1.6715328467153285,
        "end": 7176.58,
        "id": 2248,
        "no_speech_prob": 0.001926695927977562,
        "seek": 715914,
        "start": 7175.62,
        "temperature": 0.8,
        "text": " But I've been recording this.",
        "tokens": [
          51188,
          583,
          286,
          600,
          668,
          6613,
          341,
          13,
          51236
        ]
      },
      {
        "avg_logprob": -0.3689943593698782,
        "compression_ratio": 1.6715328467153285,
        "end": 7179.860000000001,
        "id": 2249,
        "no_speech_prob": 0.001926695927977562,
        "seek": 715914,
        "start": 7177.860000000001,
        "temperature": 0.8,
        "text": " I lost when did I lose all those viewers.",
        "tokens": [
          51300,
          286,
          2731,
          562,
          630,
          286,
          3624,
          439,
          729,
          8499,
          13,
          51400
        ]
      },
      {
        "avg_logprob": -0.3689943593698782,
        "compression_ratio": 1.6715328467153285,
        "end": 7184.660000000001,
        "id": 2250,
        "no_speech_prob": 0.001926695927977562,
        "seek": 715914,
        "start": 7180.660000000001,
        "temperature": 0.8,
        "text": " There was some point where I went from 112 to 88.",
        "tokens": [
          51440,
          821,
          390,
          512,
          935,
          689,
          286,
          1437,
          490,
          45835,
          281,
          24587,
          13,
          51640
        ]
      },
      {
        "avg_logprob": -0.3689943593698782,
        "compression_ratio": 1.6715328467153285,
        "end": 7185.700000000001,
        "id": 2251,
        "no_speech_prob": 0.001926695927977562,
        "seek": 715914,
        "start": 7184.660000000001,
        "temperature": 0.8,
        "text": " I have this like graph.",
        "tokens": [
          51640,
          286,
          362,
          341,
          411,
          4295,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.3689943593698782,
        "compression_ratio": 1.6715328467153285,
        "end": 7186.58,
        "id": 2252,
        "no_speech_prob": 0.001926695927977562,
        "seek": 715914,
        "start": 7185.700000000001,
        "temperature": 0.8,
        "text": " You guys can't see this.",
        "tokens": [
          51692,
          509,
          1074,
          393,
          380,
          536,
          341,
          13,
          51736
        ]
      },
      {
        "avg_logprob": -0.3689943593698782,
        "compression_ratio": 1.6715328467153285,
        "end": 7187.46,
        "id": 2253,
        "no_speech_prob": 0.001926695927977562,
        "seek": 715914,
        "start": 7186.58,
        "temperature": 0.8,
        "text": " I should show this to you.",
        "tokens": [
          51736,
          286,
          820,
          855,
          341,
          281,
          291,
          13,
          51780
        ]
      },
      {
        "avg_logprob": -0.3689943593698782,
        "compression_ratio": 1.6715328467153285,
        "end": 7188.740000000001,
        "id": 2254,
        "no_speech_prob": 0.001926695927977562,
        "seek": 715914,
        "start": 7187.46,
        "temperature": 0.8,
        "text": " This graph of viewers.",
        "tokens": [
          51780,
          639,
          4295,
          295,
          4941,
          5364,
          13,
          51844
        ]
      },
      {
        "avg_logprob": -0.19415321006431235,
        "compression_ratio": 1.5696202531645569,
        "end": 7191.78,
        "id": 2255,
        "no_speech_prob": 0.00498174736276269,
        "seek": 718874,
        "start": 7188.74,
        "temperature": 0,
        "text": " What I was doing a little after five where I lost everybody.",
        "tokens": [
          50364,
          708,
          286,
          390,
          884,
          257,
          707,
          934,
          1732,
          689,
          286,
          2731,
          2201,
          13,
          50516
        ]
      },
      {
        "avg_logprob": -0.19415321006431235,
        "compression_ratio": 1.5696202531645569,
        "end": 7198.0199999999995,
        "id": 2256,
        "no_speech_prob": 0.00498174736276269,
        "seek": 718874,
        "start": 7196.099999999999,
        "temperature": 0,
        "text": " Oh it restarted a few times.",
        "tokens": [
          50732,
          876,
          309,
          21022,
          292,
          257,
          1326,
          1413,
          13,
          50828
        ]
      },
      {
        "avg_logprob": -0.19415321006431235,
        "compression_ratio": 1.5696202531645569,
        "end": 7200.98,
        "id": 2257,
        "no_speech_prob": 0.00498174736276269,
        "seek": 718874,
        "start": 7198.0199999999995,
        "temperature": 0,
        "text": " I wonder why it did that because it didn't on my end.",
        "tokens": [
          50828,
          286,
          2441,
          983,
          309,
          630,
          300,
          570,
          309,
          994,
          380,
          322,
          452,
          917,
          13,
          50976
        ]
      },
      {
        "avg_logprob": -0.19415321006431235,
        "compression_ratio": 1.5696202531645569,
        "end": 7202.34,
        "id": 2258,
        "no_speech_prob": 0.00498174736276269,
        "seek": 718874,
        "start": 7200.98,
        "temperature": 0,
        "text": " So I hopefully it didn't.",
        "tokens": [
          50976,
          407,
          286,
          4696,
          309,
          994,
          380,
          13,
          51044
        ]
      },
      {
        "avg_logprob": -0.19415321006431235,
        "compression_ratio": 1.5696202531645569,
        "end": 7208.74,
        "id": 2259,
        "no_speech_prob": 0.00498174736276269,
        "seek": 718874,
        "start": 7202.34,
        "temperature": 0,
        "text": " I don't know if it's chopped it up into multiple videos.",
        "tokens": [
          51044,
          286,
          500,
          380,
          458,
          498,
          309,
          311,
          16497,
          309,
          493,
          666,
          3866,
          2145,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19415321006431235,
        "compression_ratio": 1.5696202531645569,
        "end": 7210.5,
        "id": 2260,
        "no_speech_prob": 0.00498174736276269,
        "seek": 718874,
        "start": 7208.74,
        "temperature": 0,
        "text": " But we'll have to fix that later.",
        "tokens": [
          51364,
          583,
          321,
          603,
          362,
          281,
          3191,
          300,
          1780,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.19415321006431235,
        "compression_ratio": 1.5696202531645569,
        "end": 7211.78,
        "id": 2261,
        "no_speech_prob": 0.00498174736276269,
        "seek": 718874,
        "start": 7210.5,
        "temperature": 0,
        "text": " I had 200 at one time.",
        "tokens": [
          51452,
          286,
          632,
          2331,
          412,
          472,
          565,
          13,
          51516
        ]
      },
      {
        "avg_logprob": -0.19415321006431235,
        "compression_ratio": 1.5696202531645569,
        "end": 7212.9,
        "id": 2262,
        "no_speech_prob": 0.00498174736276269,
        "seek": 718874,
        "start": 7211.78,
        "temperature": 0,
        "text": " That's crazy.",
        "tokens": [
          51516,
          663,
          311,
          3219,
          13,
          51572
        ]
      },
      {
        "avg_logprob": -0.19415321006431235,
        "compression_ratio": 1.5696202531645569,
        "end": 7217.46,
        "id": 2263,
        "no_speech_prob": 0.00498174736276269,
        "seek": 718874,
        "start": 7212.9,
        "temperature": 0,
        "text": " But I can understand why not everybody wanted to watch it this whole time.",
        "tokens": [
          51572,
          583,
          286,
          393,
          1223,
          983,
          406,
          2201,
          1415,
          281,
          1159,
          309,
          341,
          1379,
          565,
          13,
          51800
        ]
      },
      {
        "avg_logprob": -0.2271414738075406,
        "compression_ratio": 1.3307692307692307,
        "end": 7220.1,
        "id": 2264,
        "no_speech_prob": 0.0006986532243900001,
        "seek": 721746,
        "start": 7218.34,
        "temperature": 0,
        "text": " So thank you guys for tuning in.",
        "tokens": [
          50408,
          407,
          1309,
          291,
          1074,
          337,
          15164,
          294,
          13,
          50496
        ]
      },
      {
        "avg_logprob": -0.2271414738075406,
        "compression_ratio": 1.3307692307692307,
        "end": 7221.46,
        "id": 2265,
        "no_speech_prob": 0.0006986532243900001,
        "seek": 721746,
        "start": 7220.1,
        "temperature": 0,
        "text": " I definitely have to go.",
        "tokens": [
          50496,
          286,
          2138,
          362,
          281,
          352,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2271414738075406,
        "compression_ratio": 1.3307692307692307,
        "end": 7228.82,
        "id": 2266,
        "no_speech_prob": 0.0006986532243900001,
        "seek": 721746,
        "start": 7222.5,
        "temperature": 0,
        "text": " But I will stay here for five minutes to see if there are any last questions in the chat.",
        "tokens": [
          50616,
          583,
          286,
          486,
          1754,
          510,
          337,
          1732,
          2077,
          281,
          536,
          498,
          456,
          366,
          604,
          1036,
          1651,
          294,
          264,
          5081,
          13,
          50932
        ]
      },
      {
        "avg_logprob": -0.2271414738075406,
        "compression_ratio": 1.3307692307692307,
        "end": 7240.5,
        "id": 2267,
        "no_speech_prob": 0.0006986532243900001,
        "seek": 721746,
        "start": 7237.94,
        "temperature": 0,
        "text": " Next week I will be back.",
        "tokens": [
          51388,
          3087,
          1243,
          286,
          486,
          312,
          646,
          13,
          51516
        ]
      },
      {
        "avg_logprob": -0.2635113456032493,
        "compression_ratio": 1.570281124497992,
        "end": 7247.86,
        "id": 2268,
        "no_speech_prob": 0.303939551115036,
        "seek": 724050,
        "start": 7241.3,
        "temperature": 0,
        "text": " And the things that I have not gotten to are how to build a Chrome extension.",
        "tokens": [
          50404,
          400,
          264,
          721,
          300,
          286,
          362,
          406,
          5768,
          281,
          366,
          577,
          281,
          1322,
          257,
          15327,
          10320,
          13,
          50732
        ]
      },
      {
        "avg_logprob": -0.2635113456032493,
        "compression_ratio": 1.570281124497992,
        "end": 7249.54,
        "id": 2269,
        "no_speech_prob": 0.303939551115036,
        "seek": 724050,
        "start": 7247.86,
        "temperature": 0,
        "text": " That's going to be a full set of tutorials.",
        "tokens": [
          50732,
          663,
          311,
          516,
          281,
          312,
          257,
          1577,
          992,
          295,
          17616,
          13,
          50816
        ]
      },
      {
        "avg_logprob": -0.2635113456032493,
        "compression_ratio": 1.570281124497992,
        "end": 7250.58,
        "id": 2270,
        "no_speech_prob": 0.303939551115036,
        "seek": 724050,
        "start": 7249.54,
        "temperature": 0,
        "text": " Maybe I'll do that next week.",
        "tokens": [
          50816,
          2704,
          286,
          603,
          360,
          300,
          958,
          1243,
          13,
          50868
        ]
      },
      {
        "avg_logprob": -0.2635113456032493,
        "compression_ratio": 1.570281124497992,
        "end": 7261.14,
        "id": 2271,
        "no_speech_prob": 0.303939551115036,
        "seek": 724050,
        "start": 7251.54,
        "temperature": 0,
        "text": " I wanted to do videos on using Shih Tzu which is an API for basically turn a Google sheet",
        "tokens": [
          50916,
          286,
          1415,
          281,
          360,
          2145,
          322,
          1228,
          1160,
          4247,
          314,
          11728,
          597,
          307,
          364,
          9362,
          337,
          1936,
          1261,
          257,
          3329,
          8193,
          51396
        ]
      },
      {
        "avg_logprob": -0.2635113456032493,
        "compression_ratio": 1.570281124497992,
        "end": 7264.26,
        "id": 2272,
        "no_speech_prob": 0.303939551115036,
        "seek": 724050,
        "start": 7261.14,
        "temperature": 0,
        "text": " into an API which is very useful as well as Firebase.",
        "tokens": [
          51396,
          666,
          364,
          9362,
          597,
          307,
          588,
          4420,
          382,
          731,
          382,
          35173,
          13,
          51552
        ]
      },
      {
        "avg_logprob": -0.2635113456032493,
        "compression_ratio": 1.570281124497992,
        "end": 7266.66,
        "id": 2273,
        "no_speech_prob": 0.303939551115036,
        "seek": 724050,
        "start": 7264.26,
        "temperature": 0,
        "text": " So I wanted to look at oh did I win the Hamilton lottery.",
        "tokens": [
          51552,
          407,
          286,
          1415,
          281,
          574,
          412,
          1954,
          630,
          286,
          1942,
          264,
          18484,
          27391,
          13,
          51672
        ]
      },
      {
        "avg_logprob": -0.2635113456032493,
        "compression_ratio": 1.570281124497992,
        "end": 7268.5,
        "id": 2274,
        "no_speech_prob": 0.303939551115036,
        "seek": 724050,
        "start": 7267.54,
        "temperature": 0,
        "text": " Thank you guys.",
        "tokens": [
          51716,
          1044,
          291,
          1074,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2635113456032493,
        "compression_ratio": 1.570281124497992,
        "end": 7270.02,
        "id": 2275,
        "no_speech_prob": 0.303939551115036,
        "seek": 724050,
        "start": 7268.5,
        "temperature": 0,
        "text": " Thank you for asking.",
        "tokens": [
          51764,
          1044,
          291,
          337,
          3365,
          13,
          51840
        ]
      },
      {
        "avg_logprob": -0.21838230556911892,
        "compression_ratio": 1.6713615023474178,
        "end": 7270.580000000001,
        "id": 2276,
        "no_speech_prob": 0.004133803304284811,
        "seek": 727002,
        "start": 7270.02,
        "temperature": 0,
        "text": " Let me check.",
        "tokens": [
          50364,
          961,
          385,
          1520,
          13,
          50392
        ]
      },
      {
        "avg_logprob": -0.21838230556911892,
        "compression_ratio": 1.6713615023474178,
        "end": 7277.38,
        "id": 2277,
        "no_speech_prob": 0.004133803304284811,
        "seek": 727002,
        "start": 7273.06,
        "temperature": 0,
        "text": " Because you know you have to claim the tickets by like oh shoot I think I already missed",
        "tokens": [
          50516,
          1436,
          291,
          458,
          291,
          362,
          281,
          3932,
          264,
          12628,
          538,
          411,
          1954,
          3076,
          286,
          519,
          286,
          1217,
          6721,
          50732
        ]
      },
      {
        "avg_logprob": -0.21838230556911892,
        "compression_ratio": 1.6713615023474178,
        "end": 7278.1,
        "id": 2278,
        "no_speech_prob": 0.004133803304284811,
        "seek": 727002,
        "start": 7277.38,
        "temperature": 0,
        "text": " claiming the tickets.",
        "tokens": [
          50732,
          19232,
          264,
          12628,
          13,
          50768
        ]
      },
      {
        "avg_logprob": -0.21838230556911892,
        "compression_ratio": 1.6713615023474178,
        "end": 7279.3,
        "id": 2279,
        "no_speech_prob": 0.004133803304284811,
        "seek": 727002,
        "start": 7278.1,
        "temperature": 0,
        "text": " I think you have to do it within an hour.",
        "tokens": [
          50768,
          286,
          519,
          291,
          362,
          281,
          360,
          309,
          1951,
          364,
          1773,
          13,
          50828
        ]
      },
      {
        "avg_logprob": -0.21838230556911892,
        "compression_ratio": 1.6713615023474178,
        "end": 7280.5,
        "id": 2280,
        "no_speech_prob": 0.004133803304284811,
        "seek": 727002,
        "start": 7279.3,
        "temperature": 0,
        "text": " I really hope I didn't win.",
        "tokens": [
          50828,
          286,
          534,
          1454,
          286,
          994,
          380,
          1942,
          13,
          50888
        ]
      },
      {
        "avg_logprob": -0.21838230556911892,
        "compression_ratio": 1.6713615023474178,
        "end": 7285.3,
        "id": 2281,
        "no_speech_prob": 0.004133803304284811,
        "seek": 727002,
        "start": 7283.540000000001,
        "temperature": 0,
        "text": " Boy wouldn't that be crazy if I won.",
        "tokens": [
          51040,
          9486,
          2759,
          380,
          300,
          312,
          3219,
          498,
          286,
          1582,
          13,
          51128
        ]
      },
      {
        "avg_logprob": -0.21838230556911892,
        "compression_ratio": 1.6713615023474178,
        "end": 7288.42,
        "id": 2282,
        "no_speech_prob": 0.004133803304284811,
        "seek": 727002,
        "start": 7287.620000000001,
        "temperature": 0,
        "text": " Hamilton lottery.",
        "tokens": [
          51244,
          18484,
          27391,
          13,
          51284
        ]
      },
      {
        "avg_logprob": -0.21838230556911892,
        "compression_ratio": 1.6713615023474178,
        "end": 7289.3,
        "id": 2283,
        "no_speech_prob": 0.004133803304284811,
        "seek": 727002,
        "start": 7288.42,
        "temperature": 0,
        "text": " Hamilton lottery.",
        "tokens": [
          51284,
          18484,
          27391,
          13,
          51328
        ]
      },
      {
        "avg_logprob": -0.21838230556911892,
        "compression_ratio": 1.6713615023474178,
        "end": 7292.580000000001,
        "id": 2284,
        "no_speech_prob": 0.004133803304284811,
        "seek": 727002,
        "start": 7290.820000000001,
        "temperature": 0,
        "text": " Unfortunately you were not selected.",
        "tokens": [
          51404,
          8590,
          291,
          645,
          406,
          8209,
          13,
          51492
        ]
      },
      {
        "avg_logprob": -0.21838230556911892,
        "compression_ratio": 1.6713615023474178,
        "end": 7294.900000000001,
        "id": 2285,
        "no_speech_prob": 0.004133803304284811,
        "seek": 727002,
        "start": 7293.620000000001,
        "temperature": 0,
        "text": " So not to worry.",
        "tokens": [
          51544,
          407,
          406,
          281,
          3292,
          13,
          51608
        ]
      },
      {
        "avg_logprob": -0.21838230556911892,
        "compression_ratio": 1.6713615023474178,
        "end": 7296.660000000001,
        "id": 2286,
        "no_speech_prob": 0.004133803304284811,
        "seek": 727002,
        "start": 7295.9400000000005,
        "temperature": 0,
        "text": " I didn't win.",
        "tokens": [
          51660,
          286,
          994,
          380,
          1942,
          13,
          51696
        ]
      },
      {
        "avg_logprob": -0.21838230556911892,
        "compression_ratio": 1.6713615023474178,
        "end": 7299.14,
        "id": 2287,
        "no_speech_prob": 0.004133803304284811,
        "seek": 727002,
        "start": 7297.540000000001,
        "temperature": 0,
        "text": " But maybe next time.",
        "tokens": [
          51740,
          583,
          1310,
          958,
          565,
          13,
          51820
        ]
      },
      {
        "avg_logprob": -0.2438435821533203,
        "compression_ratio": 1.6619718309859155,
        "end": 7299.46,
        "id": 2288,
        "no_speech_prob": 0.00030060866265557706,
        "seek": 729914,
        "start": 7299.14,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50364,
          2264,
          13,
          50380
        ]
      },
      {
        "avg_logprob": -0.2438435821533203,
        "compression_ratio": 1.6619718309859155,
        "end": 7300.740000000001,
        "id": 2289,
        "no_speech_prob": 0.00030060866265557706,
        "seek": 729914,
        "start": 7300.02,
        "temperature": 0,
        "text": " When did I start.",
        "tokens": [
          50408,
          1133,
          630,
          286,
          722,
          13,
          50444
        ]
      },
      {
        "avg_logprob": -0.2438435821533203,
        "compression_ratio": 1.6619718309859155,
        "end": 7303.14,
        "id": 2290,
        "no_speech_prob": 0.00030060866265557706,
        "seek": 729914,
        "start": 7300.740000000001,
        "temperature": 0,
        "text": " Oh when did I start programming and are using.",
        "tokens": [
          50444,
          876,
          562,
          630,
          286,
          722,
          9410,
          293,
          366,
          1228,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2438435821533203,
        "compression_ratio": 1.6619718309859155,
        "end": 7304.26,
        "id": 2291,
        "no_speech_prob": 0.00030060866265557706,
        "seek": 729914,
        "start": 7303.14,
        "temperature": 0,
        "text": " You know what I forgot something.",
        "tokens": [
          50564,
          509,
          458,
          437,
          286,
          5298,
          746,
          13,
          50620
        ]
      },
      {
        "avg_logprob": -0.2438435821533203,
        "compression_ratio": 1.6619718309859155,
        "end": 7307.62,
        "id": 2292,
        "no_speech_prob": 0.00030060866265557706,
        "seek": 729914,
        "start": 7305.46,
        "temperature": 0,
        "text": " So this is great because this question is being asked.",
        "tokens": [
          50680,
          407,
          341,
          307,
          869,
          570,
          341,
          1168,
          307,
          885,
          2351,
          13,
          50788
        ]
      },
      {
        "avg_logprob": -0.2438435821533203,
        "compression_ratio": 1.6619718309859155,
        "end": 7313.06,
        "id": 2293,
        "no_speech_prob": 0.00030060866265557706,
        "seek": 729914,
        "start": 7307.62,
        "temperature": 0,
        "text": " I always forget to mention this and it came up in a discussion on Facebook recently which",
        "tokens": [
          50788,
          286,
          1009,
          2870,
          281,
          2152,
          341,
          293,
          309,
          1361,
          493,
          294,
          257,
          5017,
          322,
          4384,
          3938,
          597,
          51060
        ]
      },
      {
        "avg_logprob": -0.2438435821533203,
        "compression_ratio": 1.6619718309859155,
        "end": 7318.26,
        "id": 2294,
        "no_speech_prob": 0.00030060866265557706,
        "seek": 729914,
        "start": 7313.06,
        "temperature": 0,
        "text": " is that so some people sometimes ask where I first discovered processing and how I got",
        "tokens": [
          51060,
          307,
          300,
          370,
          512,
          561,
          2171,
          1029,
          689,
          286,
          700,
          6941,
          9007,
          293,
          577,
          286,
          658,
          51320
        ]
      },
      {
        "avg_logprob": -0.2438435821533203,
        "compression_ratio": 1.6619718309859155,
        "end": 7319.22,
        "id": 2295,
        "no_speech_prob": 0.00030060866265557706,
        "seek": 729914,
        "start": 7318.26,
        "temperature": 0,
        "text": " involved with it.",
        "tokens": [
          51320,
          3288,
          365,
          309,
          13,
          51368
        ]
      },
      {
        "avg_logprob": -0.2438435821533203,
        "compression_ratio": 1.6619718309859155,
        "end": 7323.3,
        "id": 2296,
        "no_speech_prob": 0.00030060866265557706,
        "seek": 729914,
        "start": 7319.22,
        "temperature": 0,
        "text": " And I was a student at ITP between 2001 and 2003.",
        "tokens": [
          51368,
          400,
          286,
          390,
          257,
          3107,
          412,
          6783,
          47,
          1296,
          16382,
          293,
          16416,
          13,
          51572
        ]
      },
      {
        "avg_logprob": -0.2438435821533203,
        "compression_ratio": 1.6619718309859155,
        "end": 7325.700000000001,
        "id": 2297,
        "no_speech_prob": 0.00030060866265557706,
        "seek": 729914,
        "start": 7323.3,
        "temperature": 0,
        "text": " And at the time I was programming in director.",
        "tokens": [
          51572,
          400,
          412,
          264,
          565,
          286,
          390,
          9410,
          294,
          5391,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.2438435821533203,
        "compression_ratio": 1.6619718309859155,
        "end": 7328.1,
        "id": 2298,
        "no_speech_prob": 0.00030060866265557706,
        "seek": 729914,
        "start": 7326.9800000000005,
        "temperature": 0,
        "text": " A Macromedia director.",
        "tokens": [
          51756,
          316,
          5707,
          4397,
          14212,
          5391,
          13,
          51812
        ]
      },
      {
        "avg_logprob": -0.26667463899862887,
        "compression_ratio": 1.6422018348623852,
        "end": 7332.42,
        "id": 2299,
        "no_speech_prob": 0.0006263062241487205,
        "seek": 732810,
        "start": 7328.1,
        "temperature": 0,
        "text": " I was programming in Java just plain old Java and I was programming C++ plain old C++.",
        "tokens": [
          50364,
          286,
          390,
          9410,
          294,
          10745,
          445,
          11121,
          1331,
          10745,
          293,
          286,
          390,
          9410,
          383,
          25472,
          11121,
          1331,
          383,
          25472,
          13,
          50580
        ]
      },
      {
        "avg_logprob": -0.26667463899862887,
        "compression_ratio": 1.6422018348623852,
        "end": 7334.820000000001,
        "id": 2300,
        "no_speech_prob": 0.0006263062241487205,
        "seek": 732810,
        "start": 7333.46,
        "temperature": 0,
        "text": " Open Framework, Cinder.",
        "tokens": [
          50632,
          7238,
          31628,
          1902,
          11,
          383,
          5669,
          13,
          50700
        ]
      },
      {
        "avg_logprob": -0.26667463899862887,
        "compression_ratio": 1.6422018348623852,
        "end": 7336.9800000000005,
        "id": 2301,
        "no_speech_prob": 0.0006263062241487205,
        "seek": 732810,
        "start": 7335.860000000001,
        "temperature": 0,
        "text": " None of these things existed.",
        "tokens": [
          50752,
          14492,
          295,
          613,
          721,
          13135,
          13,
          50808
        ]
      },
      {
        "avg_logprob": -0.26667463899862887,
        "compression_ratio": 1.6422018348623852,
        "end": 7339.14,
        "id": 2302,
        "no_speech_prob": 0.0006263062241487205,
        "seek": 732810,
        "start": 7336.9800000000005,
        "temperature": 0,
        "text": " Processing did exist but I was not aware of it.",
        "tokens": [
          50808,
          31093,
          278,
          630,
          2514,
          457,
          286,
          390,
          406,
          3650,
          295,
          309,
          13,
          50916
        ]
      },
      {
        "avg_logprob": -0.26667463899862887,
        "compression_ratio": 1.6422018348623852,
        "end": 7347.700000000001,
        "id": 2303,
        "no_speech_prob": 0.0006263062241487205,
        "seek": 732810,
        "start": 7340.1,
        "temperature": 0,
        "text": " And the first person to run a processing workshop at ITP and this is actually still online.",
        "tokens": [
          50964,
          400,
          264,
          700,
          954,
          281,
          1190,
          257,
          9007,
          13541,
          412,
          6783,
          47,
          293,
          341,
          307,
          767,
          920,
          2950,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.26667463899862887,
        "compression_ratio": 1.6422018348623852,
        "end": 7351.14,
        "id": 2304,
        "no_speech_prob": 0.0006263062241487205,
        "seek": 732810,
        "start": 7348.5,
        "temperature": 0,
        "text": " JT Nimoy processing workshop.",
        "tokens": [
          51384,
          508,
          51,
          45251,
          939,
          9007,
          13541,
          13,
          51516
        ]
      },
      {
        "avg_logprob": -0.26667463899862887,
        "compression_ratio": 1.6422018348623852,
        "end": 7352.900000000001,
        "id": 2305,
        "no_speech_prob": 0.0006263062241487205,
        "seek": 732810,
        "start": 7351.700000000001,
        "temperature": 0,
        "text": " Notes from this workshop.",
        "tokens": [
          51544,
          41360,
          490,
          341,
          13541,
          13,
          51604
        ]
      },
      {
        "avg_logprob": -0.26667463899862887,
        "compression_ratio": 1.6422018348623852,
        "end": 7353.9400000000005,
        "id": 2306,
        "no_speech_prob": 0.0006263062241487205,
        "seek": 732810,
        "start": 7352.900000000001,
        "temperature": 0,
        "text": " It's really terrific.",
        "tokens": [
          51604,
          467,
          311,
          534,
          20899,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.47035913114194516,
        "compression_ratio": 1.4952380952380953,
        "end": 7355.379999999999,
        "id": 2307,
        "no_speech_prob": 0.0020829089917242527,
        "seek": 735394,
        "start": 7354.179999999999,
        "temperature": 0,
        "text": " If I can find it.",
        "tokens": [
          50376,
          759,
          286,
          393,
          915,
          309,
          13,
          50436
        ]
      },
      {
        "avg_logprob": -0.47035913114194516,
        "compression_ratio": 1.4952380952380953,
        "end": 7359.299999999999,
        "id": 2308,
        "no_speech_prob": 0.0020829089917242527,
        "seek": 735394,
        "start": 7358.0199999999995,
        "temperature": 0,
        "text": " How come I can't find it right now.",
        "tokens": [
          50568,
          1012,
          808,
          286,
          393,
          380,
          915,
          309,
          558,
          586,
          13,
          50632
        ]
      },
      {
        "avg_logprob": -0.47035913114194516,
        "compression_ratio": 1.4952380952380953,
        "end": 7360.98,
        "id": 2309,
        "no_speech_prob": 0.0020829089917242527,
        "seek": 735394,
        "start": 7360.419999999999,
        "temperature": 0,
        "text": " Fail.",
        "tokens": [
          50688,
          39094,
          13,
          50716
        ]
      },
      {
        "avg_logprob": -0.47035913114194516,
        "compression_ratio": 1.4952380952380953,
        "end": 7363.379999999999,
        "id": 2310,
        "no_speech_prob": 0.0020829089917242527,
        "seek": 735394,
        "start": 7362.259999999999,
        "temperature": 0,
        "text": " Processing workshop.",
        "tokens": [
          50780,
          31093,
          278,
          13541,
          13,
          50836
        ]
      },
      {
        "avg_logprob": -0.47035913114194516,
        "compression_ratio": 1.4952380952380953,
        "end": 7364.339999999999,
        "id": 2311,
        "no_speech_prob": 0.0020829089917242527,
        "seek": 735394,
        "start": 7363.379999999999,
        "temperature": 0,
        "text": " Let's put in ITP.",
        "tokens": [
          50836,
          961,
          311,
          829,
          294,
          6783,
          47,
          13,
          50884
        ]
      },
      {
        "avg_logprob": -0.47035913114194516,
        "compression_ratio": 1.4952380952380953,
        "end": 7368.5,
        "id": 2312,
        "no_speech_prob": 0.0020829089917242527,
        "seek": 735394,
        "start": 7366.9,
        "temperature": 0,
        "text": " Let's just put in Nimoy.",
        "tokens": [
          51012,
          961,
          311,
          445,
          829,
          294,
          45251,
          939,
          13,
          51092
        ]
      },
      {
        "avg_logprob": -0.47035913114194516,
        "compression_ratio": 1.4952380952380953,
        "end": 7371.0599999999995,
        "id": 2313,
        "no_speech_prob": 0.0020829089917242527,
        "seek": 735394,
        "start": 7370.5,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51192,
          821,
          321,
          352,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.47035913114194516,
        "compression_ratio": 1.4952380952380953,
        "end": 7371.62,
        "id": 2314,
        "no_speech_prob": 0.0020829089917242527,
        "seek": 735394,
        "start": 7371.0599999999995,
        "temperature": 0,
        "text": " Here it is.",
        "tokens": [
          51220,
          1692,
          309,
          307,
          13,
          51248
        ]
      },
      {
        "avg_logprob": -0.47035913114194516,
        "compression_ratio": 1.4952380952380953,
        "end": 7372.74,
        "id": 2315,
        "no_speech_prob": 0.0020829089917242527,
        "seek": 735394,
        "start": 7372.179999999999,
        "temperature": 0,
        "text": " So this is.",
        "tokens": [
          51276,
          407,
          341,
          307,
          13,
          51304
        ]
      },
      {
        "avg_logprob": -0.47035913114194516,
        "compression_ratio": 1.4952380952380953,
        "end": 7377.54,
        "id": 2316,
        "no_speech_prob": 0.0020829089917242527,
        "seek": 735394,
        "start": 7373.62,
        "temperature": 0,
        "text": " So this is a tutorial from I believe 2003.",
        "tokens": [
          51348,
          407,
          341,
          307,
          257,
          7073,
          490,
          286,
          1697,
          16416,
          13,
          51544
        ]
      },
      {
        "avg_logprob": -0.47035913114194516,
        "compression_ratio": 1.4952380952380953,
        "end": 7381.139999999999,
        "id": 2317,
        "no_speech_prob": 0.0020829089917242527,
        "seek": 735394,
        "start": 7377.54,
        "temperature": 0,
        "text": " Can read it for my first year of ITP that I love social engineering to bring open source",
        "tokens": [
          51544,
          1664,
          1401,
          309,
          337,
          452,
          700,
          1064,
          295,
          6783,
          47,
          300,
          286,
          959,
          2093,
          7043,
          281,
          1565,
          1269,
          4009,
          51724
        ]
      },
      {
        "avg_logprob": -0.47035913114194516,
        "compression_ratio": 1.4952380952380953,
        "end": 7382.74,
        "id": 2318,
        "no_speech_prob": 0.0020829089917242527,
        "seek": 735394,
        "start": 7381.139999999999,
        "temperature": 0,
        "text": " culture to attention.",
        "tokens": [
          51724,
          3713,
          281,
          3202,
          13,
          51804
        ]
      },
      {
        "avg_logprob": -0.4660168861856266,
        "compression_ratio": 1.7114624505928853,
        "end": 7387.46,
        "id": 2319,
        "no_speech_prob": 0.000310147792333737,
        "seek": 738274,
        "start": 7383.7,
        "temperature": 0,
        "text": " I taught early releases of processing to students and faculty and current faculty who were students",
        "tokens": [
          50412,
          286,
          5928,
          2440,
          16952,
          295,
          9007,
          281,
          1731,
          293,
          6389,
          293,
          2190,
          6389,
          567,
          645,
          1731,
          50600
        ]
      },
      {
        "avg_logprob": -0.4660168861856266,
        "compression_ratio": 1.7114624505928853,
        "end": 7389.7,
        "id": 2320,
        "no_speech_prob": 0.000310147792333737,
        "seek": 738274,
        "start": 7387.46,
        "temperature": 0,
        "text": " then myself included.",
        "tokens": [
          50600,
          550,
          2059,
          5556,
          13,
          50712
        ]
      },
      {
        "avg_logprob": -0.4660168861856266,
        "compression_ratio": 1.7114624505928853,
        "end": 7394.0199999999995,
        "id": 2321,
        "no_speech_prob": 0.000310147792333737,
        "seek": 738274,
        "start": 7390.9,
        "temperature": 0,
        "text": " And chose to use processing to create a number of projects.",
        "tokens": [
          50772,
          400,
          5111,
          281,
          764,
          9007,
          281,
          1884,
          257,
          1230,
          295,
          4455,
          13,
          50928
        ]
      },
      {
        "avg_logprob": -0.4660168861856266,
        "compression_ratio": 1.7114624505928853,
        "end": 7399.38,
        "id": 2322,
        "no_speech_prob": 0.000310147792333737,
        "seek": 738274,
        "start": 7394.9,
        "temperature": 0,
        "text": " Processing we actually had two fives in the name then because of the URL processing was",
        "tokens": [
          50972,
          31093,
          278,
          321,
          767,
          632,
          732,
          283,
          1539,
          294,
          264,
          1315,
          550,
          570,
          295,
          264,
          12905,
          9007,
          390,
          51196
        ]
      },
      {
        "avg_logprob": -0.4660168861856266,
        "compression_ratio": 1.7114624505928853,
        "end": 7399.94,
        "id": 2323,
        "no_speech_prob": 0.000310147792333737,
        "seek": 738274,
        "start": 7399.38,
        "temperature": 0,
        "text": " not available.",
        "tokens": [
          51196,
          406,
          2435,
          13,
          51224
        ]
      },
      {
        "avg_logprob": -0.4660168861856266,
        "compression_ratio": 1.7114624505928853,
        "end": 7403.54,
        "id": 2324,
        "no_speech_prob": 0.000310147792333737,
        "seek": 738274,
        "start": 7401.0599999999995,
        "temperature": 0,
        "text": " And so this workshop which you can see here.",
        "tokens": [
          51280,
          400,
          370,
          341,
          13541,
          597,
          291,
          393,
          536,
          510,
          13,
          51404
        ]
      },
      {
        "avg_logprob": -0.4660168861856266,
        "compression_ratio": 1.7114624505928853,
        "end": 7409.7,
        "id": 2325,
        "no_speech_prob": 0.000310147792333737,
        "seek": 738274,
        "start": 7404.66,
        "temperature": 0,
        "text": " And then by the fall semester 2004 processing was adopted into the introduction to computational",
        "tokens": [
          51460,
          400,
          550,
          538,
          264,
          2100,
          11894,
          15817,
          9007,
          390,
          12175,
          666,
          264,
          9339,
          281,
          28270,
          51712
        ]
      },
      {
        "avg_logprob": -0.4660168861856266,
        "compression_ratio": 1.7114624505928853,
        "end": 7410.26,
        "id": 2326,
        "no_speech_prob": 0.000310147792333737,
        "seek": 738274,
        "start": 7409.7,
        "temperature": 0,
        "text": " media.",
        "tokens": [
          51712,
          3021,
          13,
          51740
        ]
      },
      {
        "avg_logprob": -0.358103283381058,
        "compression_ratio": 1.7137809187279152,
        "end": 7412.900000000001,
        "id": 2327,
        "no_speech_prob": 0.004133718553930521,
        "seek": 741026,
        "start": 7410.34,
        "temperature": 0,
        "text": " Course series as a primary teaching tool.",
        "tokens": [
          50368,
          27327,
          2638,
          382,
          257,
          6194,
          4571,
          2290,
          13,
          50496
        ]
      },
      {
        "avg_logprob": -0.358103283381058,
        "compression_ratio": 1.7137809187279152,
        "end": 7417.14,
        "id": 2328,
        "no_speech_prob": 0.004133718553930521,
        "seek": 741026,
        "start": 7412.900000000001,
        "temperature": 0,
        "text": " So if you're interested a little history the original date of this was Saturday February",
        "tokens": [
          50496,
          407,
          498,
          291,
          434,
          3102,
          257,
          707,
          2503,
          264,
          3380,
          4002,
          295,
          341,
          390,
          8803,
          8711,
          50708
        ]
      },
      {
        "avg_logprob": -0.358103283381058,
        "compression_ratio": 1.7137809187279152,
        "end": 7420.18,
        "id": 2329,
        "no_speech_prob": 0.004133718553930521,
        "seek": 741026,
        "start": 7417.14,
        "temperature": 0,
        "text": " 8th 2003.",
        "tokens": [
          50708,
          1649,
          392,
          16416,
          13,
          50860
        ]
      },
      {
        "avg_logprob": -0.358103283381058,
        "compression_ratio": 1.7137809187279152,
        "end": 7424.820000000001,
        "id": 2330,
        "no_speech_prob": 0.004133718553930521,
        "seek": 741026,
        "start": 7420.18,
        "temperature": 0,
        "text": " And you can look at the tutorial is both in English and was also translated in Japanese.",
        "tokens": [
          50860,
          400,
          291,
          393,
          574,
          412,
          264,
          7073,
          307,
          1293,
          294,
          3669,
          293,
          390,
          611,
          16805,
          294,
          5433,
          13,
          51092
        ]
      },
      {
        "avg_logprob": -0.358103283381058,
        "compression_ratio": 1.7137809187279152,
        "end": 7428.820000000001,
        "id": 2331,
        "no_speech_prob": 0.004133718553930521,
        "seek": 741026,
        "start": 7424.820000000001,
        "temperature": 0,
        "text": " And you can find this tutorial and you can see what's interesting about this is to see",
        "tokens": [
          51092,
          400,
          291,
          393,
          915,
          341,
          7073,
          293,
          291,
          393,
          536,
          437,
          311,
          1880,
          466,
          341,
          307,
          281,
          536,
          51292
        ]
      },
      {
        "avg_logprob": -0.358103283381058,
        "compression_ratio": 1.7137809187279152,
        "end": 7432.02,
        "id": 2332,
        "no_speech_prob": 0.004133718553930521,
        "seek": 741026,
        "start": 7429.38,
        "temperature": 0,
        "text": " it's comparing it to flash.",
        "tokens": [
          51320,
          309,
          311,
          15763,
          309,
          281,
          7319,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.358103283381058,
        "compression_ratio": 1.7137809187279152,
        "end": 7435.860000000001,
        "id": 2333,
        "no_speech_prob": 0.004133718553930521,
        "seek": 741026,
        "start": 7432.02,
        "temperature": 0,
        "text": " And I remember looking at this tutorial and being fascinated and amazed by it.",
        "tokens": [
          51452,
          400,
          286,
          1604,
          1237,
          412,
          341,
          7073,
          293,
          885,
          24597,
          293,
          20507,
          538,
          309,
          13,
          51644
        ]
      },
      {
        "avg_logprob": -0.358103283381058,
        "compression_ratio": 1.7137809187279152,
        "end": 7438.58,
        "id": 2334,
        "no_speech_prob": 0.004133718553930521,
        "seek": 741026,
        "start": 7435.860000000001,
        "temperature": 0,
        "text": " And this I think is really an inspiration to a lot of people.",
        "tokens": [
          51644,
          400,
          341,
          286,
          519,
          307,
          534,
          364,
          10249,
          281,
          257,
          688,
          295,
          561,
          13,
          51780
        ]
      },
      {
        "avg_logprob": -0.3036149211765565,
        "compression_ratio": 1.6853448275862069,
        "end": 7441.54,
        "id": 2335,
        "no_speech_prob": 0.08386737108230591,
        "seek": 743858,
        "start": 7438.66,
        "temperature": 0,
        "text": " I think is really an inspiration to a lot of the stuff that I did with teaching and",
        "tokens": [
          50368,
          286,
          519,
          307,
          534,
          364,
          10249,
          281,
          257,
          688,
          295,
          264,
          1507,
          300,
          286,
          630,
          365,
          4571,
          293,
          50512
        ]
      },
      {
        "avg_logprob": -0.3036149211765565,
        "compression_ratio": 1.6853448275862069,
        "end": 7443.46,
        "id": 2336,
        "no_speech_prob": 0.08386737108230591,
        "seek": 743858,
        "start": 7441.54,
        "temperature": 0,
        "text": " processing right time and motion here.",
        "tokens": [
          50512,
          9007,
          558,
          565,
          293,
          5394,
          510,
          13,
          50608
        ]
      },
      {
        "avg_logprob": -0.3036149211765565,
        "compression_ratio": 1.6853448275862069,
        "end": 7444.74,
        "id": 2337,
        "no_speech_prob": 0.08386737108230591,
        "seek": 743858,
        "start": 7443.46,
        "temperature": 0,
        "text": " So I encourage you to check this out.",
        "tokens": [
          50608,
          407,
          286,
          5373,
          291,
          281,
          1520,
          341,
          484,
          13,
          50672
        ]
      },
      {
        "avg_logprob": -0.3036149211765565,
        "compression_ratio": 1.6853448275862069,
        "end": 7450.58,
        "id": 2338,
        "no_speech_prob": 0.08386737108230591,
        "seek": 743858,
        "start": 7444.74,
        "temperature": 0,
        "text": " Also at the time Amit Pataru was teaching a class called code and me.",
        "tokens": [
          50672,
          2743,
          412,
          264,
          565,
          2012,
          270,
          4379,
          16870,
          390,
          4571,
          257,
          1508,
          1219,
          3089,
          293,
          385,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.3036149211765565,
        "compression_ratio": 1.6853448275862069,
        "end": 7459.22,
        "id": 2339,
        "no_speech_prob": 0.08386737108230591,
        "seek": 743858,
        "start": 7450.58,
        "temperature": 0,
        "text": " I wonder if there's any documentation of this online archives code and me.",
        "tokens": [
          50964,
          286,
          2441,
          498,
          456,
          311,
          604,
          14333,
          295,
          341,
          2950,
          25607,
          3089,
          293,
          385,
          13,
          51396
        ]
      },
      {
        "avg_logprob": -0.3036149211765565,
        "compression_ratio": 1.6853448275862069,
        "end": 7462.98,
        "id": 2340,
        "no_speech_prob": 0.08386737108230591,
        "seek": 743858,
        "start": 7459.22,
        "temperature": 0,
        "text": " So anyway if somebody if you know little if somebody wants to try to do some internet",
        "tokens": [
          51396,
          407,
          4033,
          498,
          2618,
          498,
          291,
          458,
          707,
          498,
          2618,
          2738,
          281,
          853,
          281,
          360,
          512,
          4705,
          51584
        ]
      },
      {
        "avg_logprob": -0.2284314031186311,
        "compression_ratio": 1.670995670995671,
        "end": 7470.98,
        "id": 2341,
        "no_speech_prob": 0.11121238768100739,
        "seek": 746298,
        "start": 7462.98,
        "temperature": 0,
        "text": " research and can find can find the code and me Amit's syllabus.",
        "tokens": [
          50364,
          2132,
          293,
          393,
          915,
          393,
          915,
          264,
          3089,
          293,
          385,
          2012,
          270,
          311,
          48077,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2284314031186311,
        "compression_ratio": 1.670995670995671,
        "end": 7474.58,
        "id": 2342,
        "no_speech_prob": 0.11121238768100739,
        "seek": 746298,
        "start": 7473.86,
        "temperature": 0,
        "text": " See if you can find it.",
        "tokens": [
          50908,
          3008,
          498,
          291,
          393,
          915,
          309,
          13,
          50944
        ]
      },
      {
        "avg_logprob": -0.2284314031186311,
        "compression_ratio": 1.670995670995671,
        "end": 7478.58,
        "id": 2343,
        "no_speech_prob": 0.11121238768100739,
        "seek": 746298,
        "start": 7474.58,
        "temperature": 0,
        "text": " There's Amit on Twitter and I believe JT Nimoy on Twitter is at JT Nimoy as well.",
        "tokens": [
          50944,
          821,
          311,
          2012,
          270,
          322,
          5794,
          293,
          286,
          1697,
          508,
          51,
          45251,
          939,
          322,
          5794,
          307,
          412,
          508,
          51,
          45251,
          939,
          382,
          731,
          13,
          51144
        ]
      },
      {
        "avg_logprob": -0.2284314031186311,
        "compression_ratio": 1.670995670995671,
        "end": 7482.98,
        "id": 2344,
        "no_speech_prob": 0.11121238768100739,
        "seek": 746298,
        "start": 7479.379999999999,
        "temperature": 0,
        "text": " And JT has done all sorts of amazing stuff a lot of graphics for Tron and I encourage",
        "tokens": [
          51184,
          400,
          508,
          51,
          575,
          1096,
          439,
          7527,
          295,
          2243,
          1507,
          257,
          688,
          295,
          11837,
          337,
          1765,
          266,
          293,
          286,
          5373,
          51364
        ]
      },
      {
        "avg_logprob": -0.2284314031186311,
        "compression_ratio": 1.670995670995671,
        "end": 7486.66,
        "id": 2345,
        "no_speech_prob": 0.11121238768100739,
        "seek": 746298,
        "start": 7482.98,
        "temperature": 0,
        "text": " you to check out the work of JT Nimoy as well.",
        "tokens": [
          51364,
          291,
          281,
          1520,
          484,
          264,
          589,
          295,
          508,
          51,
          45251,
          939,
          382,
          731,
          13,
          51548
        ]
      },
      {
        "avg_logprob": -0.2284314031186311,
        "compression_ratio": 1.670995670995671,
        "end": 7492.419999999999,
        "id": 2346,
        "no_speech_prob": 0.11121238768100739,
        "seek": 746298,
        "start": 7486.66,
        "temperature": 0,
        "text": " Okay so I wanted to bring that up because it's come up and I didn't pause the song.",
        "tokens": [
          51548,
          1033,
          370,
          286,
          1415,
          281,
          1565,
          300,
          493,
          570,
          309,
          311,
          808,
          493,
          293,
          286,
          994,
          380,
          10465,
          264,
          2153,
          13,
          51836
        ]
      },
      {
        "avg_logprob": -0.23634743444698372,
        "compression_ratio": 1.6486486486486487,
        "end": 7492.9800000000005,
        "id": 2347,
        "no_speech_prob": 0.0008692789706401527,
        "seek": 749242,
        "start": 7492.42,
        "temperature": 0,
        "text": " So let's see.",
        "tokens": [
          50364,
          407,
          718,
          311,
          536,
          13,
          50392
        ]
      },
      {
        "avg_logprob": -0.23634743444698372,
        "compression_ratio": 1.6486486486486487,
        "end": 7498.9,
        "id": 2348,
        "no_speech_prob": 0.0008692789706401527,
        "seek": 749242,
        "start": 7493.86,
        "temperature": 0,
        "text": " Oh can you give some more info about the application process for the processing fellowship.",
        "tokens": [
          50436,
          876,
          393,
          291,
          976,
          512,
          544,
          13614,
          466,
          264,
          3861,
          1399,
          337,
          264,
          9007,
          24989,
          13,
          50688
        ]
      },
      {
        "avg_logprob": -0.23634743444698372,
        "compression_ratio": 1.6486486486486487,
        "end": 7501.14,
        "id": 2349,
        "no_speech_prob": 0.0008692789706401527,
        "seek": 749242,
        "start": 7500.82,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          50784,
          1079,
          13,
          50800
        ]
      },
      {
        "avg_logprob": -0.23634743444698372,
        "compression_ratio": 1.6486486486486487,
        "end": 7503.38,
        "id": 2350,
        "no_speech_prob": 0.0008692789706401527,
        "seek": 749242,
        "start": 7502.82,
        "temperature": 0,
        "text": " You pause.",
        "tokens": [
          50884,
          509,
          10465,
          13,
          50912
        ]
      },
      {
        "avg_logprob": -0.23634743444698372,
        "compression_ratio": 1.6486486486486487,
        "end": 7507.38,
        "id": 2351,
        "no_speech_prob": 0.0008692789706401527,
        "seek": 749242,
        "start": 7504.9,
        "temperature": 0,
        "text": " Processing foundation fellowships.",
        "tokens": [
          50988,
          31093,
          278,
          7030,
          24989,
          82,
          13,
          51112
        ]
      },
      {
        "avg_logprob": -0.23634743444698372,
        "compression_ratio": 1.6486486486486487,
        "end": 7509.06,
        "id": 2352,
        "no_speech_prob": 0.0008692789706401527,
        "seek": 749242,
        "start": 7507.38,
        "temperature": 0,
        "text": " So this is the application process.",
        "tokens": [
          51112,
          407,
          341,
          307,
          264,
          3861,
          1399,
          13,
          51196
        ]
      },
      {
        "avg_logprob": -0.23634743444698372,
        "compression_ratio": 1.6486486486486487,
        "end": 7512.34,
        "id": 2353,
        "no_speech_prob": 0.0008692789706401527,
        "seek": 749242,
        "start": 7510.1,
        "temperature": 0,
        "text": " The deadline is December 19th.",
        "tokens": [
          51248,
          440,
          20615,
          307,
          7687,
          1294,
          392,
          13,
          51360
        ]
      },
      {
        "avg_logprob": -0.23634743444698372,
        "compression_ratio": 1.6486486486486487,
        "end": 7515.3,
        "id": 2354,
        "no_speech_prob": 0.0008692789706401527,
        "seek": 749242,
        "start": 7512.34,
        "temperature": 0,
        "text": " So you have several weeks still there.",
        "tokens": [
          51360,
          407,
          291,
          362,
          2940,
          3259,
          920,
          456,
          13,
          51508
        ]
      },
      {
        "avg_logprob": -0.23634743444698372,
        "compression_ratio": 1.6486486486486487,
        "end": 7520.34,
        "id": 2355,
        "no_speech_prob": 0.0008692789706401527,
        "seek": 749242,
        "start": 7515.3,
        "temperature": 0,
        "text": " I would read through this whole page and then I would look at what the fellowships were",
        "tokens": [
          51508,
          286,
          576,
          1401,
          807,
          341,
          1379,
          3028,
          293,
          550,
          286,
          576,
          574,
          412,
          437,
          264,
          24989,
          82,
          645,
          51760
        ]
      },
      {
        "avg_logprob": -0.23634743444698372,
        "compression_ratio": 1.6486486486486487,
        "end": 7521.3,
        "id": 2356,
        "no_speech_prob": 0.0008692789706401527,
        "seek": 749242,
        "start": 7520.34,
        "temperature": 0,
        "text": " from last year.",
        "tokens": [
          51760,
          490,
          1036,
          1064,
          13,
          51808
        ]
      },
      {
        "avg_logprob": -0.21339146596080852,
        "compression_ratio": 1.831896551724138,
        "end": 7526.9800000000005,
        "id": 2357,
        "no_speech_prob": 0.0007208125316537917,
        "seek": 752242,
        "start": 7522.5,
        "temperature": 0,
        "text": " And to apply there's a Google form and the Google form will talk will go through you",
        "tokens": [
          50368,
          400,
          281,
          3079,
          456,
          311,
          257,
          3329,
          1254,
          293,
          264,
          3329,
          1254,
          486,
          751,
          486,
          352,
          807,
          291,
          50592
        ]
      },
      {
        "avg_logprob": -0.21339146596080852,
        "compression_ratio": 1.831896551724138,
        "end": 7530.9,
        "id": 2358,
        "no_speech_prob": 0.0007208125316537917,
        "seek": 752242,
        "start": 7526.9800000000005,
        "temperature": 0,
        "text": " need to write a description of the project you need to write up a plan for the project",
        "tokens": [
          50592,
          643,
          281,
          2464,
          257,
          3855,
          295,
          264,
          1716,
          291,
          643,
          281,
          2464,
          493,
          257,
          1393,
          337,
          264,
          1716,
          50788
        ]
      },
      {
        "avg_logprob": -0.21339146596080852,
        "compression_ratio": 1.831896551724138,
        "end": 7532.18,
        "id": 2359,
        "no_speech_prob": 0.0007208125316537917,
        "seek": 752242,
        "start": 7530.9,
        "temperature": 0,
        "text": " and schedule for it.",
        "tokens": [
          50788,
          293,
          7567,
          337,
          309,
          13,
          50852
        ]
      },
      {
        "avg_logprob": -0.21339146596080852,
        "compression_ratio": 1.831896551724138,
        "end": 7539.46,
        "id": 2360,
        "no_speech_prob": 0.0007208125316537917,
        "seek": 752242,
        "start": 7532.18,
        "temperature": 0,
        "text": " And the other thing maybe it's on the it's the link is maybe is on the application submission",
        "tokens": [
          50852,
          400,
          264,
          661,
          551,
          1310,
          309,
          311,
          322,
          264,
          309,
          311,
          264,
          2113,
          307,
          1310,
          307,
          322,
          264,
          3861,
          23689,
          51216
        ]
      },
      {
        "avg_logprob": -0.21339146596080852,
        "compression_ratio": 1.831896551724138,
        "end": 7539.78,
        "id": 2361,
        "no_speech_prob": 0.0007208125316537917,
        "seek": 752242,
        "start": 7539.46,
        "temperature": 0,
        "text": " form.",
        "tokens": [
          51216,
          1254,
          13,
          51232
        ]
      },
      {
        "avg_logprob": -0.21339146596080852,
        "compression_ratio": 1.831896551724138,
        "end": 7547.06,
        "id": 2362,
        "no_speech_prob": 0.0007208125316537917,
        "seek": 752242,
        "start": 7542.26,
        "temperature": 0,
        "text": " But what I'm looking for which I'm looking for here something that's important I'm not",
        "tokens": [
          51356,
          583,
          437,
          286,
          478,
          1237,
          337,
          597,
          286,
          478,
          1237,
          337,
          510,
          746,
          300,
          311,
          1021,
          286,
          478,
          406,
          51596
        ]
      },
      {
        "avg_logprob": -0.21339146596080852,
        "compression_ratio": 1.831896551724138,
        "end": 7548.9800000000005,
        "id": 2363,
        "no_speech_prob": 0.0007208125316537917,
        "seek": 752242,
        "start": 7547.06,
        "temperature": 0,
        "text": " seeing it just scanning through very quickly.",
        "tokens": [
          51596,
          2577,
          309,
          445,
          27019,
          807,
          588,
          2661,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.20089196686697477,
        "compression_ratio": 1.654320987654321,
        "end": 7553.0599999999995,
        "id": 2364,
        "no_speech_prob": 0.00043055182322859764,
        "seek": 754898,
        "start": 7549.94,
        "temperature": 0,
        "text": " A project ideas ideas.",
        "tokens": [
          50412,
          316,
          1716,
          3487,
          3487,
          13,
          50568
        ]
      },
      {
        "avg_logprob": -0.20089196686697477,
        "compression_ratio": 1.654320987654321,
        "end": 7554.0199999999995,
        "id": 2365,
        "no_speech_prob": 0.00043055182322859764,
        "seek": 754898,
        "start": 7553.78,
        "temperature": 0,
        "text": " Ah.",
        "tokens": [
          50604,
          2438,
          13,
          50616
        ]
      },
      {
        "avg_logprob": -0.20089196686697477,
        "compression_ratio": 1.654320987654321,
        "end": 7560.099999999999,
        "id": 2366,
        "no_speech_prob": 0.00043055182322859764,
        "seek": 754898,
        "start": 7555.7,
        "temperature": 0,
        "text": " So this link here applicants are encouraged to familiarize themselves with the list of",
        "tokens": [
          50700,
          407,
          341,
          2113,
          510,
          28767,
          366,
          14658,
          281,
          4963,
          1125,
          2969,
          365,
          264,
          1329,
          295,
          50920
        ]
      },
      {
        "avg_logprob": -0.20089196686697477,
        "compression_ratio": 1.654320987654321,
        "end": 7561.459999999999,
        "id": 2367,
        "no_speech_prob": 0.00043055182322859764,
        "seek": 754898,
        "start": 7560.099999999999,
        "temperature": 0,
        "text": " fellowship ideas.",
        "tokens": [
          50920,
          24989,
          3487,
          13,
          50988
        ]
      },
      {
        "avg_logprob": -0.20089196686697477,
        "compression_ratio": 1.654320987654321,
        "end": 7566.9,
        "id": 2368,
        "no_speech_prob": 0.00043055182322859764,
        "seek": 754898,
        "start": 7561.459999999999,
        "temperature": 0,
        "text": " This is another page which has some more ideas about the kinds of things that we're thinking",
        "tokens": [
          50988,
          639,
          307,
          1071,
          3028,
          597,
          575,
          512,
          544,
          3487,
          466,
          264,
          3685,
          295,
          721,
          300,
          321,
          434,
          1953,
          51260
        ]
      },
      {
        "avg_logprob": -0.20089196686697477,
        "compression_ratio": 1.654320987654321,
        "end": 7567.379999999999,
        "id": 2369,
        "no_speech_prob": 0.00043055182322859764,
        "seek": 754898,
        "start": 7566.9,
        "temperature": 0,
        "text": " about.",
        "tokens": [
          51260,
          466,
          13,
          51284
        ]
      },
      {
        "avg_logprob": -0.20089196686697477,
        "compression_ratio": 1.654320987654321,
        "end": 7570.259999999999,
        "id": 2370,
        "no_speech_prob": 0.00043055182322859764,
        "seek": 754898,
        "start": 7567.379999999999,
        "temperature": 0,
        "text": " You do not need to propose something on this list.",
        "tokens": [
          51284,
          509,
          360,
          406,
          643,
          281,
          17421,
          746,
          322,
          341,
          1329,
          13,
          51428
        ]
      },
      {
        "avg_logprob": -0.20089196686697477,
        "compression_ratio": 1.654320987654321,
        "end": 7573.459999999999,
        "id": 2371,
        "no_speech_prob": 0.00043055182322859764,
        "seek": 754898,
        "start": 7570.259999999999,
        "temperature": 0,
        "text": " But if you're trying to brainstorm or think about what's possible I would encourage you",
        "tokens": [
          51428,
          583,
          498,
          291,
          434,
          1382,
          281,
          35245,
          420,
          519,
          466,
          437,
          311,
          1944,
          286,
          576,
          5373,
          291,
          51588
        ]
      },
      {
        "avg_logprob": -0.20089196686697477,
        "compression_ratio": 1.654320987654321,
        "end": 7575.299999999999,
        "id": 2372,
        "no_speech_prob": 0.00043055182322859764,
        "seek": 754898,
        "start": 7573.459999999999,
        "temperature": 0,
        "text": " to check out this list as well.",
        "tokens": [
          51588,
          281,
          1520,
          484,
          341,
          1329,
          382,
          731,
          13,
          51680
        ]
      },
      {
        "avg_logprob": -0.3073353128334911,
        "compression_ratio": 1.5674603174603174,
        "end": 7580.66,
        "id": 2373,
        "no_speech_prob": 0.08388139307498932,
        "seek": 757530,
        "start": 7575.3,
        "temperature": 0,
        "text": " And I'll make sure to include links to the application the fellowship page the application",
        "tokens": [
          50364,
          400,
          286,
          603,
          652,
          988,
          281,
          4090,
          6123,
          281,
          264,
          3861,
          264,
          24989,
          3028,
          264,
          3861,
          50632
        ]
      },
      {
        "avg_logprob": -0.3073353128334911,
        "compression_ratio": 1.5674603174603174,
        "end": 7583.3,
        "id": 2374,
        "no_speech_prob": 0.08388139307498932,
        "seek": 757530,
        "start": 7580.66,
        "temperature": 0,
        "text": " and this GitHub page in this archives description.",
        "tokens": [
          50632,
          293,
          341,
          23331,
          3028,
          294,
          341,
          25607,
          3855,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.3073353128334911,
        "compression_ratio": 1.5674603174603174,
        "end": 7591.38,
        "id": 2375,
        "no_speech_prob": 0.08388139307498932,
        "seek": 757530,
        "start": 7585.62,
        "temperature": 0,
        "text": " The live stream is over unfortunately it has been going for two hours and 10 minutes and",
        "tokens": [
          50880,
          440,
          1621,
          4309,
          307,
          670,
          7015,
          309,
          575,
          668,
          516,
          337,
          732,
          2496,
          293,
          1266,
          2077,
          293,
          51168
        ]
      },
      {
        "avg_logprob": -0.3073353128334911,
        "compression_ratio": 1.5674603174603174,
        "end": 7596.5,
        "id": 2376,
        "no_speech_prob": 0.08388139307498932,
        "seek": 757530,
        "start": 7591.38,
        "temperature": 0,
        "text": " I I'm actually going to tonight if you're in New York City I encourage you to at one",
        "tokens": [
          51168,
          286,
          286,
          478,
          767,
          516,
          281,
          4440,
          498,
          291,
          434,
          294,
          1873,
          3609,
          4392,
          286,
          5373,
          291,
          281,
          412,
          472,
          51424
        ]
      },
      {
        "avg_logprob": -0.3073353128334911,
        "compression_ratio": 1.5674603174603174,
        "end": 7599.14,
        "id": 2377,
        "no_speech_prob": 0.08388139307498932,
        "seek": 757530,
        "start": 7596.5,
        "temperature": 0,
        "text": " of the fellows from last year's Tiga Brain who did a guest.",
        "tokens": [
          51424,
          295,
          264,
          35595,
          490,
          1036,
          1064,
          311,
          314,
          9900,
          29783,
          567,
          630,
          257,
          8341,
          13,
          51556
        ]
      },
      {
        "avg_logprob": -0.3073353128334911,
        "compression_ratio": 1.5674603174603174,
        "end": 7602.18,
        "id": 2378,
        "no_speech_prob": 0.08388139307498932,
        "seek": 757530,
        "start": 7600.900000000001,
        "temperature": 0,
        "text": " ICP learn to teach.",
        "tokens": [
          51644,
          14360,
          47,
          1466,
          281,
          2924,
          13,
          51708
        ]
      },
      {
        "avg_logprob": -0.27737801593282946,
        "compression_ratio": 1.5412186379928314,
        "end": 7606.5,
        "id": 2379,
        "no_speech_prob": 0.006690720561891794,
        "seek": 760218,
        "start": 7603.06,
        "temperature": 0,
        "text": " This event I want to get to it starts at 630.",
        "tokens": [
          50408,
          639,
          2280,
          286,
          528,
          281,
          483,
          281,
          309,
          3719,
          412,
          1386,
          3446,
          13,
          50580
        ]
      },
      {
        "avg_logprob": -0.27737801593282946,
        "compression_ratio": 1.5412186379928314,
        "end": 7608.1,
        "id": 2380,
        "no_speech_prob": 0.006690720561891794,
        "seek": 760218,
        "start": 7606.5,
        "temperature": 0,
        "text": " I have a bunch of things to do beforehand.",
        "tokens": [
          50580,
          286,
          362,
          257,
          3840,
          295,
          721,
          281,
          360,
          22893,
          13,
          50660
        ]
      },
      {
        "avg_logprob": -0.27737801593282946,
        "compression_ratio": 1.5412186379928314,
        "end": 7614.5,
        "id": 2381,
        "no_speech_prob": 0.006690720561891794,
        "seek": 760218,
        "start": 7608.1,
        "temperature": 0,
        "text": " I really have to go learning to teach is a event here in New York City co-organized by",
        "tokens": [
          50660,
          286,
          534,
          362,
          281,
          352,
          2539,
          281,
          2924,
          307,
          257,
          2280,
          510,
          294,
          1873,
          3609,
          4392,
          598,
          12,
          12372,
          1602,
          538,
          50980
        ]
      },
      {
        "avg_logprob": -0.27737801593282946,
        "compression_ratio": 1.5412186379928314,
        "end": 7619.9400000000005,
        "id": 2382,
        "no_speech_prob": 0.006690720561891794,
        "seek": 760218,
        "start": 7614.5,
        "temperature": 0,
        "text": " the Processing Foundation and Tiga Brain will be presenting there along with DeAngela Duff",
        "tokens": [
          50980,
          264,
          31093,
          278,
          10335,
          293,
          314,
          9900,
          29783,
          486,
          312,
          15578,
          456,
          2051,
          365,
          1346,
          23156,
          4053,
          413,
          1245,
          51252
        ]
      },
      {
        "avg_logprob": -0.27737801593282946,
        "compression_ratio": 1.5412186379928314,
        "end": 7624.34,
        "id": 2383,
        "no_speech_prob": 0.006690720561891794,
        "seek": 760218,
        "start": 7619.9400000000005,
        "temperature": 0,
        "text": " who is also amazing I should have her as a guest and Ankit Patel who works for the Department",
        "tokens": [
          51252,
          567,
          307,
          611,
          2243,
          286,
          820,
          362,
          720,
          382,
          257,
          8341,
          293,
          1107,
          22681,
          4379,
          338,
          567,
          1985,
          337,
          264,
          5982,
          51472
        ]
      },
      {
        "avg_logprob": -0.27737801593282946,
        "compression_ratio": 1.5412186379928314,
        "end": 7625.46,
        "id": 2384,
        "no_speech_prob": 0.006690720561891794,
        "seek": 760218,
        "start": 7624.34,
        "temperature": 0,
        "text": " of Education.",
        "tokens": [
          51472,
          295,
          10680,
          13,
          51528
        ]
      },
      {
        "avg_logprob": -0.27737801593282946,
        "compression_ratio": 1.5412186379928314,
        "end": 7629.54,
        "id": 2385,
        "no_speech_prob": 0.006690720561891794,
        "seek": 760218,
        "start": 7625.46,
        "temperature": 0,
        "text": " BBQ Dave Sheinkopf about education and creative coding.",
        "tokens": [
          51528,
          19168,
          48,
          11017,
          1240,
          475,
          21828,
          466,
          3309,
          293,
          5880,
          17720,
          13,
          51732
        ]
      },
      {
        "avg_logprob": -0.2535628457354684,
        "compression_ratio": 1.6591760299625469,
        "end": 7630.92,
        "id": 2386,
        "no_speech_prob": 0.04271553456783295,
        "seek": 762954,
        "start": 7630.42,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50408,
          2264,
          13,
          50433
        ]
      },
      {
        "avg_logprob": -0.2535628457354684,
        "compression_ratio": 1.6591760299625469,
        "end": 7632.98,
        "id": 2387,
        "no_speech_prob": 0.04271553456783295,
        "seek": 762954,
        "start": 7632.1,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50492,
          1057,
          558,
          13,
          50536
        ]
      },
      {
        "avg_logprob": -0.2535628457354684,
        "compression_ratio": 1.6591760299625469,
        "end": 7634.5,
        "id": 2388,
        "no_speech_prob": 0.04271553456783295,
        "seek": 762954,
        "start": 7632.98,
        "temperature": 0,
        "text": " So I really have got to go.",
        "tokens": [
          50536,
          407,
          286,
          534,
          362,
          658,
          281,
          352,
          13,
          50612
        ]
      },
      {
        "avg_logprob": -0.2535628457354684,
        "compression_ratio": 1.6591760299625469,
        "end": 7639.86,
        "id": 2389,
        "no_speech_prob": 0.04271553456783295,
        "seek": 762954,
        "start": 7634.5,
        "temperature": 0,
        "text": " I thank you all so much for tuning in for watching for being supportive.",
        "tokens": [
          50612,
          286,
          1309,
          291,
          439,
          370,
          709,
          337,
          15164,
          294,
          337,
          1976,
          337,
          885,
          14435,
          13,
          50880
        ]
      },
      {
        "avg_logprob": -0.2535628457354684,
        "compression_ratio": 1.6591760299625469,
        "end": 7643.14,
        "id": 2390,
        "no_speech_prob": 0.04271553456783295,
        "seek": 762954,
        "start": 7639.86,
        "temperature": 0,
        "text": " I feel like today was kind of a mess but I often feel that way and then people seem to",
        "tokens": [
          50880,
          286,
          841,
          411,
          965,
          390,
          733,
          295,
          257,
          2082,
          457,
          286,
          2049,
          841,
          300,
          636,
          293,
          550,
          561,
          1643,
          281,
          51044
        ]
      },
      {
        "avg_logprob": -0.2535628457354684,
        "compression_ratio": 1.6591760299625469,
        "end": 7644.26,
        "id": 2391,
        "no_speech_prob": 0.04271553456783295,
        "seek": 762954,
        "start": 7643.14,
        "temperature": 0,
        "text": " think it was fine anyway.",
        "tokens": [
          51044,
          519,
          309,
          390,
          2489,
          4033,
          13,
          51100
        ]
      },
      {
        "avg_logprob": -0.2535628457354684,
        "compression_ratio": 1.6591760299625469,
        "end": 7650.26,
        "id": 2392,
        "no_speech_prob": 0.04271553456783295,
        "seek": 762954,
        "start": 7646.42,
        "temperature": 0,
        "text": " And so out of this I think we'll really only come maybe there's a maybe those should be",
        "tokens": [
          51208,
          400,
          370,
          484,
          295,
          341,
          286,
          519,
          321,
          603,
          534,
          787,
          808,
          1310,
          456,
          311,
          257,
          1310,
          729,
          820,
          312,
          51400
        ]
      },
      {
        "avg_logprob": -0.2535628457354684,
        "compression_ratio": 1.6591760299625469,
        "end": 7651.94,
        "id": 2393,
        "no_speech_prob": 0.04271553456783295,
        "seek": 762954,
        "start": 7650.26,
        "temperature": 0,
        "text": " separated into more than two videos.",
        "tokens": [
          51400,
          12005,
          666,
          544,
          813,
          732,
          2145,
          13,
          51484
        ]
      },
      {
        "avg_logprob": -0.2535628457354684,
        "compression_ratio": 1.6591760299625469,
        "end": 7655.94,
        "id": 2394,
        "no_speech_prob": 0.04271553456783295,
        "seek": 762954,
        "start": 7651.94,
        "temperature": 0,
        "text": " We'll think about that but certainly there's the sentiment house coding challenge and the",
        "tokens": [
          51484,
          492,
          603,
          519,
          466,
          300,
          457,
          3297,
          456,
          311,
          264,
          16149,
          1782,
          17720,
          3430,
          293,
          264,
          51684
        ]
      },
      {
        "avg_logprob": -0.2363001936573093,
        "compression_ratio": 1.623574144486692,
        "end": 7662.179999999999,
        "id": 2395,
        "no_speech_prob": 0.21462221443653107,
        "seek": 765594,
        "start": 7655.94,
        "temperature": 0,
        "text": " sentiment analysis node API video and next week I'll be back with hopefully Chrome extensions",
        "tokens": [
          50364,
          16149,
          5215,
          9984,
          9362,
          960,
          293,
          958,
          1243,
          286,
          603,
          312,
          646,
          365,
          4696,
          15327,
          25129,
          50676
        ]
      },
      {
        "avg_logprob": -0.2363001936573093,
        "compression_ratio": 1.623574144486692,
        "end": 7663.94,
        "id": 2396,
        "no_speech_prob": 0.21462221443653107,
        "seek": 765594,
        "start": 7662.179999999999,
        "temperature": 0,
        "text": " or more about a data persistence.",
        "tokens": [
          50676,
          420,
          544,
          466,
          257,
          1412,
          37617,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2363001936573093,
        "compression_ratio": 1.623574144486692,
        "end": 7665.219999999999,
        "id": 2397,
        "no_speech_prob": 0.21462221443653107,
        "seek": 765594,
        "start": 7664.5,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50792,
          2264,
          13,
          50828
        ]
      },
      {
        "avg_logprob": -0.2363001936573093,
        "compression_ratio": 1.623574144486692,
        "end": 7668.66,
        "id": 2398,
        "no_speech_prob": 0.21462221443653107,
        "seek": 765594,
        "start": 7665.219999999999,
        "temperature": 0,
        "text": " And I'll see you guys in the future.",
        "tokens": [
          50828,
          400,
          286,
          603,
          536,
          291,
          1074,
          294,
          264,
          2027,
          13,
          51000
        ]
      },
      {
        "avg_logprob": -0.2363001936573093,
        "compression_ratio": 1.623574144486692,
        "end": 7670.259999999999,
        "id": 2399,
        "no_speech_prob": 0.21462221443653107,
        "seek": 765594,
        "start": 7668.66,
        "temperature": 0,
        "text": " Stay in touch next week.",
        "tokens": [
          51000,
          8691,
          294,
          2557,
          958,
          1243,
          13,
          51080
        ]
      },
      {
        "avg_logprob": -0.2363001936573093,
        "compression_ratio": 1.623574144486692,
        "end": 7673.299999999999,
        "id": 2400,
        "no_speech_prob": 0.21462221443653107,
        "seek": 765594,
        "start": 7670.259999999999,
        "temperature": 0,
        "text": " I don't know when I don't know if I'll have a live stream next week just yet.",
        "tokens": [
          51080,
          286,
          500,
          380,
          458,
          562,
          286,
          500,
          380,
          458,
          498,
          286,
          603,
          362,
          257,
          1621,
          4309,
          958,
          1243,
          445,
          1939,
          13,
          51232
        ]
      },
      {
        "avg_logprob": -0.2363001936573093,
        "compression_ratio": 1.623574144486692,
        "end": 7674.5,
        "id": 2401,
        "no_speech_prob": 0.21462221443653107,
        "seek": 765594,
        "start": 7673.299999999999,
        "temperature": 0,
        "text": " Stay tuned to Twitter.",
        "tokens": [
          51232,
          8691,
          10870,
          281,
          5794,
          13,
          51292
        ]
      },
      {
        "avg_logprob": -0.2363001936573093,
        "compression_ratio": 1.623574144486692,
        "end": 7676.66,
        "id": 2402,
        "no_speech_prob": 0.21462221443653107,
        "seek": 765594,
        "start": 7674.5,
        "temperature": 0,
        "text": " I forgot to announce this on Twitter today.",
        "tokens": [
          51292,
          286,
          5298,
          281,
          7478,
          341,
          322,
          5794,
          965,
          13,
          51400
        ]
      },
      {
        "avg_logprob": -0.2363001936573093,
        "compression_ratio": 1.623574144486692,
        "end": 7681.94,
        "id": 2403,
        "no_speech_prob": 0.21462221443653107,
        "seek": 765594,
        "start": 7676.66,
        "temperature": 0,
        "text": " Still had 200 viewers which is kind of amazing and I'll see you all soon.",
        "tokens": [
          51400,
          8291,
          632,
          2331,
          8499,
          597,
          307,
          733,
          295,
          2243,
          293,
          286,
          603,
          536,
          291,
          439,
          2321,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2363001936573093,
        "compression_ratio": 1.623574144486692,
        "end": 7684.339999999999,
        "id": 2404,
        "no_speech_prob": 0.21462221443653107,
        "seek": 765594,
        "start": 7683.54,
        "temperature": 0,
        "text": " Thank you all.",
        "tokens": [
          51744,
          1044,
          291,
          439,
          13,
          51784
        ]
      },
      {
        "avg_logprob": -0.4429530702788254,
        "compression_ratio": 2.015228426395939,
        "end": 7689.78,
        "id": 2405,
        "no_speech_prob": 0.154009148478508,
        "seek": 768594,
        "start": 7686.74,
        "temperature": 0,
        "text": " I'll play the this song as I turn things off.",
        "tokens": [
          50404,
          286,
          603,
          862,
          264,
          341,
          2153,
          382,
          286,
          1261,
          721,
          766,
          13,
          50556
        ]
      },
      {
        "avg_logprob": -0.4429530702788254,
        "compression_ratio": 2.015228426395939,
        "end": 7691.0599999999995,
        "id": 2406,
        "no_speech_prob": 0.154009148478508,
        "seek": 768594,
        "start": 7689.78,
        "temperature": 0,
        "text": " I always forget to this.",
        "tokens": [
          50556,
          286,
          1009,
          2870,
          281,
          341,
          13,
          50620
        ]
      },
      {
        "avg_logprob": -0.4429530702788254,
        "compression_ratio": 2.015228426395939,
        "end": 7691.62,
        "id": 2407,
        "no_speech_prob": 0.154009148478508,
        "seek": 768594,
        "start": 7691.0599999999995,
        "temperature": 0,
        "text": " This.",
        "tokens": [
          50620,
          639,
          13,
          50648
        ]
      },
      {
        "avg_logprob": -0.4429530702788254,
        "compression_ratio": 2.015228426395939,
        "end": 7692.099999999999,
        "id": 2408,
        "no_speech_prob": 0.154009148478508,
        "seek": 768594,
        "start": 7691.62,
        "temperature": 0,
        "text": " This.",
        "tokens": [
          50648,
          639,
          13,
          50672
        ]
      },
      {
        "avg_logprob": -0.4429530702788254,
        "compression_ratio": 2.015228426395939,
        "end": 7692.74,
        "id": 2409,
        "no_speech_prob": 0.154009148478508,
        "seek": 768594,
        "start": 7692.099999999999,
        "temperature": 0,
        "text": " This.",
        "tokens": [
          50672,
          639,
          13,
          50704
        ]
      },
      {
        "avg_logprob": -0.4429530702788254,
        "compression_ratio": 2.015228426395939,
        "end": 7693.94,
        "id": 2410,
        "no_speech_prob": 0.154009148478508,
        "seek": 768594,
        "start": 7692.74,
        "temperature": 0,
        "text": " I'm going to do this.",
        "tokens": [
          50704,
          286,
          478,
          516,
          281,
          360,
          341,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.4429530702788254,
        "compression_ratio": 2.015228426395939,
        "end": 7694.5,
        "id": 2411,
        "no_speech_prob": 0.154009148478508,
        "seek": 768594,
        "start": 7693.94,
        "temperature": 0,
        "text": " This.",
        "tokens": [
          50764,
          639,
          13,
          50792
        ]
      },
      {
        "avg_logprob": -0.4429530702788254,
        "compression_ratio": 2.015228426395939,
        "end": 7695.219999999999,
        "id": 2412,
        "no_speech_prob": 0.154009148478508,
        "seek": 768594,
        "start": 7694.5,
        "temperature": 0,
        "text": " I'm going to do this.",
        "tokens": [
          50792,
          286,
          478,
          516,
          281,
          360,
          341,
          13,
          50828
        ]
      },
      {
        "avg_logprob": -0.4429530702788254,
        "compression_ratio": 2.015228426395939,
        "end": 7695.78,
        "id": 2413,
        "no_speech_prob": 0.154009148478508,
        "seek": 768594,
        "start": 7695.219999999999,
        "temperature": 0,
        "text": " This.",
        "tokens": [
          50828,
          639,
          13,
          50856
        ]
      },
      {
        "avg_logprob": -0.4429530702788254,
        "compression_ratio": 2.015228426395939,
        "end": 7696.259999999999,
        "id": 2414,
        "no_speech_prob": 0.154009148478508,
        "seek": 768594,
        "start": 7695.78,
        "temperature": 0,
        "text": " This.",
        "tokens": [
          50856,
          639,
          13,
          50880
        ]
      },
      {
        "avg_logprob": -0.4429530702788254,
        "compression_ratio": 2.015228426395939,
        "end": 7696.9,
        "id": 2415,
        "no_speech_prob": 0.154009148478508,
        "seek": 768594,
        "start": 7696.259999999999,
        "temperature": 0,
        "text": " This.",
        "tokens": [
          50880,
          639,
          13,
          50912
        ]
      },
      {
        "avg_logprob": -0.4429530702788254,
        "compression_ratio": 2.015228426395939,
        "end": 7697.94,
        "id": 2416,
        "no_speech_prob": 0.154009148478508,
        "seek": 768594,
        "start": 7696.9,
        "temperature": 0,
        "text": " I'm going to do this.",
        "tokens": [
          50912,
          286,
          478,
          516,
          281,
          360,
          341,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.4429530702788254,
        "compression_ratio": 2.015228426395939,
        "end": 7698.9,
        "id": 2417,
        "no_speech_prob": 0.154009148478508,
        "seek": 768594,
        "start": 7697.94,
        "temperature": 0,
        "text": " This.",
        "tokens": [
          50964,
          639,
          13,
          51012
        ]
      },
      {
        "avg_logprob": -0.4429530702788254,
        "compression_ratio": 2.015228426395939,
        "end": 7702.66,
        "id": 2418,
        "no_speech_prob": 0.154009148478508,
        "seek": 768594,
        "start": 7698.9,
        "temperature": 0,
        "text": " I'm going to flip a blank screen but you'll be able to listen to the rest of the song.",
        "tokens": [
          51012,
          286,
          478,
          516,
          281,
          7929,
          257,
          8247,
          2568,
          457,
          291,
          603,
          312,
          1075,
          281,
          2140,
          281,
          264,
          1472,
          295,
          264,
          2153,
          13,
          51200
        ]
      },
      {
        "avg_logprob": -0.4429530702788254,
        "compression_ratio": 2.015228426395939,
        "end": 7710.099999999999,
        "id": 2419,
        "no_speech_prob": 0.154009148478508,
        "seek": 768594,
        "start": 7706.9,
        "temperature": 0,
        "text": " You can't hear the song on that blank screen because I don't have the audio typed into",
        "tokens": [
          51412,
          509,
          393,
          380,
          1568,
          264,
          2153,
          322,
          300,
          8247,
          2568,
          570,
          286,
          500,
          380,
          362,
          264,
          6278,
          33941,
          666,
          51572
        ]
      },
      {
        "avg_logprob": -0.4429530702788254,
        "compression_ratio": 2.015228426395939,
        "end": 7710.5,
        "id": 2420,
        "no_speech_prob": 0.154009148478508,
        "seek": 768594,
        "start": 7710.099999999999,
        "temperature": 0,
        "text": " that.",
        "tokens": [
          51572,
          300,
          13,
          51592
        ]
      },
      {
        "avg_logprob": -0.4429530702788254,
        "compression_ratio": 2.015228426395939,
        "end": 7711.139999999999,
        "id": 2421,
        "no_speech_prob": 0.154009148478508,
        "seek": 768594,
        "start": 7710.5,
        "temperature": 0,
        "text": " Wire cast.",
        "tokens": [
          51592,
          32598,
          4193,
          13,
          51624
        ]
      },
      {
        "avg_logprob": -0.4429530702788254,
        "compression_ratio": 2.015228426395939,
        "end": 7713.54,
        "id": 2422,
        "no_speech_prob": 0.154009148478508,
        "seek": 768594,
        "start": 7712.58,
        "temperature": 0,
        "text": " I'll just stand here.",
        "tokens": [
          51696,
          286,
          603,
          445,
          1463,
          510,
          13,
          51744
        ]
      },
      {
        "avg_logprob": -0.9098977770124163,
        "compression_ratio": 1.1704545454545454,
        "end": 7714.26,
        "id": 2423,
        "no_speech_prob": 0.20936614274978638,
        "seek": 771354,
        "start": 7713.7,
        "temperature": 0.6000000000000001,
        "text": " Like.",
        "tokens": [
          50372,
          1743,
          13,
          50400
        ]
      },
      {
        "avg_logprob": -0.9098977770124163,
        "compression_ratio": 1.1704545454545454,
        "end": 7723.7,
        "id": 2424,
        "no_speech_prob": 0.20936614274978638,
        "seek": 771354,
        "start": 7721.22,
        "temperature": 0.6000000000000001,
        "text": " While I look and check out my email.",
        "tokens": [
          50748,
          3987,
          286,
          574,
          293,
          1520,
          484,
          452,
          3796,
          13,
          50872
        ]
      },
      {
        "avg_logprob": -0.9098977770124163,
        "compression_ratio": 1.1704545454545454,
        "end": 7725.14,
        "id": 2425,
        "no_speech_prob": 0.20936614274978638,
        "seek": 771354,
        "start": 7723.7,
        "temperature": 0.6000000000000001,
        "text": " I see all the messages.",
        "tokens": [
          50872,
          286,
          536,
          439,
          264,
          7897,
          13,
          50944
        ]
      },
      {
        "avg_logprob": -0.9098977770124163,
        "compression_ratio": 1.1704545454545454,
        "end": 7729.3,
        "id": 2426,
        "no_speech_prob": 0.20936614274978638,
        "seek": 771354,
        "start": 7727.14,
        "temperature": 0.6000000000000001,
        "text": " When the song is over I say goodbye.",
        "tokens": [
          51044,
          1133,
          264,
          2153,
          307,
          670,
          286,
          584,
          12084,
          13,
          51152
        ]
      },
      {
        "avg_logprob": -0.3315471649169922,
        "compression_ratio": 1.951219512195122,
        "end": 7749.38,
        "id": 2427,
        "no_speech_prob": 0.005213486962020397,
        "seek": 774354,
        "start": 7743.54,
        "temperature": 0,
        "text": " This dot, this dot, this dot, never forget the this dot.",
        "tokens": [
          50364,
          639,
          5893,
          11,
          341,
          5893,
          11,
          341,
          5893,
          11,
          1128,
          2870,
          264,
          341,
          5893,
          13,
          50656
        ]
      },
      {
        "avg_logprob": -0.3315471649169922,
        "compression_ratio": 1.951219512195122,
        "end": 7753.7,
        "id": 2428,
        "no_speech_prob": 0.005213486962020397,
        "seek": 774354,
        "start": 7750.1,
        "temperature": 0,
        "text": " I'm gonna do the this dot, this dot, this dot, this dot, the this dot song,",
        "tokens": [
          50692,
          286,
          478,
          799,
          360,
          264,
          341,
          5893,
          11,
          341,
          5893,
          11,
          341,
          5893,
          11,
          341,
          5893,
          11,
          264,
          341,
          5893,
          2153,
          11,
          50872
        ]
      },
      {
        "avg_logprob": -0.3315471649169922,
        "compression_ratio": 1.951219512195122,
        "end": 7754.82,
        "id": 2429,
        "no_speech_prob": 0.005213486962020397,
        "seek": 774354,
        "start": 7753.7,
        "temperature": 0,
        "text": " never forget the this dot.",
        "tokens": [
          50872,
          1128,
          2870,
          264,
          341,
          5893,
          13,
          50928
        ]
      },
      {
        "avg_logprob": -0.3315471649169922,
        "compression_ratio": 1.951219512195122,
        "end": 7757.3,
        "id": 2430,
        "no_speech_prob": 0.005213486962020397,
        "seek": 774354,
        "start": 7755.86,
        "temperature": 0,
        "text": " Somebody compose that song for me.",
        "tokens": [
          50980,
          13463,
          35925,
          300,
          2153,
          337,
          385,
          13,
          51052
        ]
      },
      {
        "avg_logprob": -0.3315471649169922,
        "compression_ratio": 1.951219512195122,
        "end": 7761.06,
        "id": 2431,
        "no_speech_prob": 0.005213486962020397,
        "seek": 774354,
        "start": 7758.5,
        "temperature": 0,
        "text": " Thanks for watching everybody, see you later.",
        "tokens": [
          51112,
          2561,
          337,
          1976,
          2201,
          11,
          536,
          291,
          1780,
          13,
          51240
        ]
      }
    ],
    "transcription": " Did you think that learning coding would be really rough? Throw your hands up in the air and say, enough's enough! Do you want to learn to code and make some awesome stuff? Learn that anyone can when you're coding with Dan on! Whether you're a pro or this is all brand new, learn the overarching concepts and some fun stuff too! And with Dan as your guide, come along for the ride on! Make a crazy pixel mirror to reflect your face, you can make a jump to light speed into outer space, you can generate a maze that can go on for days, you can make your own terrain and some purple rain, you can make a retro game to see how it's done, and then tweak a piece to make it yours for everyone! Make some fractally trees or twitter bots if you please, and when the seeds are a stone, you can make them your own! Run the colors of code, you can follow the road too! Hello, welcome to another episode of... I don't know what it is. Okay, so hopefully you're there and watching. I am here. It's been two weeks since I've been here on the YouTube. And I'm very excited and glad to be back. And this has been a very tricky month with busy end of semester for me, with my other job, and with the holidays that have been here in New York, this crazy election thing that happened, which I am upsetting on so many different kinds of levels. But here I am anyway, alive in this room here at the School for Poetic Computation in the West Village of New York City. And it's around 3.20 p.m. I don't think it's December yet. I'm pretty sure it's still just November. Please don't be November. Actually, you know what? December. Fine, let's bring on December. Bring on 2000. Some jump, let's jump a bunch of years into the future. And maybe that'll be a good thing. Anyway, what's up with the colors? Is anything looking weird? Am I, you know, I have a little, I have some, I'm sort of lighting challenged. So I don't know if there's some weird colored things going on. And, but yes, I did have a haircut. Thank you for noticing. I don't know. This is probably not what you tuned in for, or perhaps it is what you tuned in for. So what's going on with this thing? So my name is Dan. I do live streams on YouTube weekly, except for the weeks where that I miss, like last week, where I demonstrate a variety of different programming, coding techniques, generally in the creative sphere of applications. So look at generative algorithms for visual art, different kinds of algorithms for generating and analyzing text, which has been my focus this fall. I noticed somebody in the chat mentioned, mentioned, somebody in the chat mentioned machine learning. And that's actually on my list of topics. That's going to be one of my main focuses this spring in the new year in 2017. But so today, what I wanted to do, I want to do a couple things. One is I want to talk about the processing fellowships, which might be something that you aren't aware of. So I'm gonna spend a little time talking about the processing foundation and the fellowship program that's out now that any of you might be interested in, interested in applying to. Sorry, I'm trying to keep an eye on the chat, which it's very difficult to have this, to speak and have a continuous thought and read a chat at the same time. Hi, Arson. Arson, yes, I do remember. And yes, there will be JavaScript stuff today. So the coding that I will do after I talk about the processing fellowships, I'm going to look at sentiment analysis with a word list known as the AFIN111. Is that what you woke? You were like, you're lying in bed. Your alarm went off. And you woke up and you thought, I know what I'm going to do today. I'm going to turn off my computer. I'm going to watch somebody talk about AFIN111 sentiment analysis on YouTube. Well, that's what's happening. Oh, yeah. By the way, I noticed that Lourdes in the chat mentions everyone check out Siraj's channel. I noticed, actually, I got a notification that Siraj was also doing a live stream. Does anyone know if that's still going on? Let's pull it up. Let's see if we can embed a live stream. Siraj YouTube. No, that's not right. Sirajology. Sirajology? Sirajology. Is he live right now? Live. Oh, but this is finished. So I won't. I won't. So anyway, I'm sure this was a great live stream. Oh, by the way, am I in focus? The camera was all out of focus. I just randomly focused it. So I don't know if I got myself in focus. Siraj, I've been talking about Siraj doing a collaboration with him. So I hope hopefully that will come at some point soon. I'm hoping to do some videos about machine learning. He does a ton of them. They're really terrific. I love them. I watch them. And then I think, oh, maybe I could learn this stuff too. OK. Sorry, I got sidetracked. What was I talking about? OK, so the AFIN111 text stuff, I'm going to finish off. So I want to do a coding challenge of just AFIN111 in the browser just to look at, hey, I typed some text into a text field, and it gives me a sentiment score at the bottom. And then I'll also talk about other kinds of sentiment analysis beyond just this one technique, which is a very simple approach. And then if there's, and then I want to also finish off my examples about building your own API in Node. So once we do the sentiment analysis in the browser, we'll transfer that into Node and make a sentiment analysis API and look at what it means to make a POST request versus a GET request. So that's on my list for today. And then if there's extra time, I got some other things I would love to do. I keep whacking the microphone. I hope that's not making a weird sound for you. So let me say just a few quick words of where to find out more. So at this website, which is hmmhmm.com, if you go there, you can subscribe. You can become a patron if you are so inclined. And there's a Slack channel that comes as a benefit of being a patron on this service called Patreon. One thing I just want to point out, though, is I get this question a lot. So these days with my live streams, I'm kind of off into the weeds of doing examples and coding ideas, assuming that the people watching have done some programming before. And obviously, everybody watching, I'm sure, has a variety of different levels of experience. But I always get the question, oh, what should I do if I don't know anything, if I want to start learning to program from scratch? And so this playlist that's at the CodingRainbow.com website, you can look at that one, this will assume no knowledge of programming whatsoever and get you started using JavaScript. Of course, there are many other languages and other videos and books and things you can use to get started. But if you're looking for my stuff, this is what I would recommend right here. I also have another playlist for processing, which is a Java-based environment, which is beginner, for complete beginners that you can look at. And there's a textbook that goes along with that as well. OK. So what else do I need to mention? So I mentioned that I do send out emails periodically when I have a schedule for my live stream. And you can also sign up for that here. Let's see. Anything else? I do have my little soundboard, if you guys want to indulge me for a second. I can try to get that hooked up. Let me see something here. Let's go back to Siraj and see if, because I want to see if sound is working. We're going to play. Oops. Oh, no, add. I'm not being paid to play this ad. Skip. I don't think you guys can hear Siraj. So I need to fix this. System preferences, sound, multi-output device. This might change the sound in a second. Speak, Siraj. See who we got. What is that sound? OK. I heard some music. Oh, what is that? What is that? Hi, Siraj. This is like some sort of weird meta performance thing where I'm speaking to you as if. Come on. It's OK. The sound is working. You're live, except you're not. This is recorded. Hearing something. See, look, we're doing a collaboration already. I didn't realize it. Somebody snapshot this and tweet it to Siraj. I'm sure he would appreciate this weird thing that's happening right here. But I think you're hearing the sound. And I could also do this and talk to myself. And that would be a little bit weird. OK. Now what I want to do here is go to soundboard. I have this soundboard app. And I can airplay it to this laptop. You're going to see it in a second. Oh, mirroring on. There we go. And now you're seeing my soundboard, by the way. This is how this little behind the scenes. Behind the music. So let's see if this works. Does that sound horribly loud? As always, I always forget the this dot, this dot, this dot, this dot. I'm going to do this dot, this dot. I'm going to do this, this dot, this dot, this dot. I'm going to do this. So it looks like I have a soundboard working. In case I need to play some music or things, I can minimize this. You guys can let me know if the audio is a problem. Nobody could get that screenshot in time. You can reverse back in time. Maybe somebody else got it. It doesn't really matter. This will be there. Somebody will watch this later and then screenshot it then, thinking they're watching it live. OK. All right. You guys love that song. Somebody sent me a new song. Lost G Bear on Slack sent me a new song that I don't have loaded yet. If you're watching, I don't know if I got the name right. Let me know. Maybe I'll play that song. I'm hoping to have a new logo, a new name. A new song, a new video, all of these things. It's really unfortunate that I have this name and logo and video and song. And unfortunately, I can't use the name anymore. So there was a lot of time and effort went into that. And there just hasn't been a lot of time to do anything new. But I will get started on that. OK. Hello to Brazil. Oh, yes. So if you're looking for the this dot song, there are actually two this dot songs. One by F Looper and one by Christian Peterson. If you're looking for those, since it was asked. If you go to SoundCloud, I think if I just look Daniel Shiffman playlist, this dot, well, this comes up. But yeah, Daniel Shiffman's Coding Rainbow, the remixes is a few different remixes. So this is random. This is noise. This is Perlin noise. That is in the core random algorithm, the actual random algorithm itself. Those numbers aren't related at all. I'm picking random numbers between 0 and 10. 9, 2, 7, 6, 1, 9, 4, 8, 9, 2, 1, 3. So you guys can download and enjoy these songs. If anybody wants to make more songs, I love it. Nothing thrills me more than music. I'm just like a failed musical theater wannabe person. And then I just make programming videos on YouTube. So if I could somehow, you know, I forgot to enter the Hamilton lottery today. Maybe there's still time. Maybe I should enter it live. Because usually you can enter it till 4. You guys don't mind, do you? I have an app. It's really fast, I swear. I'll put on the This Dot song for you guys. As always, I always forget the This Dot. This Dot, This Dot, This Dot. I'm going to do This Dot, This Dot. I'm going to do This Dot, This Dot, This Dot. I'm going to do This Dot, This Dot, This Dot. What's today? This Dot. I'm going to do Wednesday. Yes, Wednesday. This Dot. This Dot, This Dot, This Dot. Enter. This Dot. Closes at 4 PM. Live on the air. I can't check at 4 o'clock. Somebody can remind me. I have to make sure I'm a pro. I have to select all the images with graphs. I'm selecting all the images with graphs. I'm entering the lottery. Oh, the cameras are going off. I'm going to enter it. Hold on. At 4 o'clock, I can check to see if I won the Hamilton lottery. $10 front row ticket. This Dot. I'm going to do This Dot, This Dot. I'm going to do This Dot, This Dot. This Dot, This Dot, Sorry. This Dot, This Dot, This Dot. Select all the images with trees. Oh my god. Watermelon is not a tree, is it? It's a little stressful. This Dot, This Dot, This Dot. I always feel so stressed out. I'm going to get in trouble if I don't answer the right one. There's trees on this one. OK, fine. This Dot, This Dot, This Dot. The This Dot song. Never forget the This Dot. Somebody composed that song for me. OK, I've now entered the Hamilton lottery. And this camera went off. Let me just fix that. Let me cycle this one. I need to erase the whiteboard. I don't know where the eraser is. Hmm. Where is the eraser? Where is that eraser? Erasure. Eraser. Oh. OK, hold on, everyone. Oh, here it is. I found it. I found it. I found it. Everything's going to be OK, everybody. I found it. I found it. I found it. I found it. I found it. I found it. Everything's going to be OK, everybody. I'm going to, this is what I had. Oh, look. Uh. Let me erase all this. This is such a nice eraser. Makes such a nice sound, too. Go to sleep. Go to sleep. Go to sleep, little eyes. Go to sleep. OK, I'm wrong. Oh, it's been a weird few weeks. OK. OK. All right. So the first thing I want to do, I'm actually going to start, weirdly, with a coding challenge. And that coding challenge, you should be confused, is to ch-ch-ch-ch-ch-ch-ch-ch-afin 111. So what I'm going to do, a lot of you might have watched these before, but the live streams, typically, I do a lot of talking and researching and clicking and getting set up. And at a certain point, I start an actual tutorial or coding challenge, where I pretend as if I'm recording a video, even though that's what I'm doing all this time. So let me first get set up here. Let's get some links that are relevant and talk to you a little bit about afin 111. So afin is a list of English words rated for valence, meaning positivity or negativity, with an integer between minus 5 and plus 5. And so these words were manually labeled by Fin Arup Nielsen, which is why it's called the afin. And afin 111 is the newest version that has 2,477 words and phrases. So if you are a scientist, I am not a scientist, I hope you would reference the above paper. I will reference the above paper and this link in this video's description. This database is copyright protected and distributed under the Open Database license. So what I'm going to do is I'm going to download it so we can take a look at it. OK. Afin. Oh, look, I downloaded it last week or two weeks ago. So let's look at the readme. This is what it says already on the site. OK, now let's look at this. Now, here's the thing. I really, really, really, really, really, really, really, really, really, really, really would like to have this list in JSON format. So the question I have for myself is do I make the coding challenge itself, part of it converting this to JSON? And also, what's up with this? What's up with this list? Like, wow, wow, wow, wow, with two Ws, I guess. Yes, there's a lot of words, but why is there no space there between the number? Huh. So I feel like, oh, there's probably a tab. This is probably tab delimited, right? Yeah, so there's actually a space there. It's just, yeah, it's just there's a tab there. OK, so what I want to do is I'm going to do, I can't decide if I should do this as two separate coding challenges or I'm seeing in the chat that a note that the video quality is not good. So I don't know if sometimes with the stream, depending on your connection, you can get low quality. It is only seven. I am only broadcasting at 720p. So I'm not sure if I'm going to get 720p. It is only seven. I am only broadcasting at 720p because I don't have a good enough connection here, I think, to support 108 broadcasting at 1080p. But so let me know if anybody else is experiencing issues with quality. OK, so what I want to do, let's do, hmm. I mean, this is not a complicated problem. I'm just trying to decide if I want to do it all together. Let's do it all together as one video. Why not? You know, who cares? So this video, what I'm going to do is I'm going to talk about what AFIN111 is. I'm going to grab this file. I'm going to open it in p5. I'm going to convert it to JSON. Then I am going to save it as JSON. And then I'm going to make a new sketch that loads it as JSON and does the sentiment analysis part. OK, so great. Um, here we go. So I think I'm ready for this. Let me check here. Let me get a little more set up. I'll play you another song. You can have the Perlin Noise one now. Oh, that's just a clip. Who knows? Uh, yeah, that was just a clip. As always, I always forget the this stop. Oh, that's the this stop. This stop. This stop. This stop. This stop. This stop. This stop. Empty examples should be good. This stop. This stop. This stop. 0.5, 0.4 is a good version of p5. This stop. This stop. This stop. Never forget this stop. This stop. This stop. This stop. Let's make this A to Z. Session. This is still session eight, if you can believe that. Always a good one. This stop. This stop. I mean, in a way, this example is. This stop. This stop. From that earlier session. When you say sublime or Adam, these days. I'm gonna do this, this, this, this, this, this, this, this, this. Stop song. Never forget the this dot. Somebody composed that song for me. Oops. Well, here we go. This. Okay. I'm just opening up this project. Getting the code. There we go. I'm gonna clean this up for a second. I want to have, I don't need the sound library. But I do need the dom library. And sketch dot JS. And index dot HTML. And I'm gonna say title. Title. A fin one eleven demo. Just get a few things set up here. And then I want to run a server. Tempted. Okay. Oops. Let's run a server. Session eight. And let's take a look at everything in the browser. And let's get a console open. Let's. Do no canvas. Console dot log sentiment. Okay. So it looks like we are up and running. I need to have the website. I need also this URL. I will have open here. Okay. Just checking the chat. Are you supposed to hear the audio from the computer? You are. Did you not? Hold on. Oh, you can't hear my voice when I'm playing the music at the same time. Okay. That's good to know. I can turn on my music. I can turn on my music. I can turn on my music. I can turn on my music. I can turn on my music. I can turn on my music. I can turn on my music. I can turn I can also turn down the music and all that stuff. But I'm not going to worry about it right now. All right. Wow. This has been the least amount I shouldn't say. I was going to say the least amount of technical difficulties I've had doing this in a while. But I shouldn't say anything because now everything's going to start crashing and burning. Okay. So I'm checking at the in the chat to see if anyone is saying anything important. Like nothing is working. I can't see anything. It looks okay. So I am now going to get started. Oh, hold on. This microphone is awkwardly positioned. That's a little bit better. So this first video that I'm going to do, first of all, the reason why I'm doing this is because I don't know. Why not? But what I want to do is have the node API that I'm making do be an example just be a sentiment analysis API. So I thought it would be worth before going and adding all that code to node to just sort of show one simple technique for doing sentiment analysis and do that in a coding challenge. Also, just kind of like there's a lot of stuff I think that's interesting to explore here. So here we go. The little shadow on the green screen. I know. It's because one of my lights is broken. Let's see if I might be able to do something about it. I shouldn't. I'm a little bit afraid to do this. Whoa. Hey, that shadow is gone now. Oh, no, it's worse. Okay, better not do that. Okay, we're just gonna have to live with it. It's if I step over here, it gets worse. If I stay over here, it's better. So that's just how it's going to be for now. Okay. Audio is awesome. All right. All right, here we go, everybody. This is a tutorial. It is 3. Oh, my God, it's 3.45 already. That's not good. Okay. 25. Oh, I forgot. I was going to talk about the processing fellowships. So that was my first thing that I was going to talk about. Let's do that now. So, oh, boy. Okay, I'm going to do this. So I just want to mention this because I think it's worth mentioning to kind of let the broadest audience know about this opportunity for those of you who might be interested. Processing Foundation, I've talked about before on live streams, is a non-for-profit foundation whose primary mission is to promote software literacy and make code and creative work with code accessible and available to diverse communities. And so in addition to education and diversity initiatives that we sponsor, which you can find out on the Processing Foundation's initiative page, we maintain that what you're probably more familiar with, the platform's processing, which is a Java-based creative coding platform, p5.js, which is the JavaScript library that I'm using in a lot of my examples, at least the ones that I'll do today. There's also a Python version of processing. You can't see I'm like hovering with this like tiny little pointer on these links. So you might be familiar with all of these different projects. What we started last year is a fellowship program. And the fellowship program currently has its open call right now. So just to let you know briefly, let me scroll down here and get, these are the fellows from last year, Alison Parrish, who worked on advocacy documentation and tutorials for processing Python mode. Claire Kearney-Volpe, who was a guest here on this YouTube channel to talk about her work with accessibility, working with low vision and blind people in code. Digital Citizens Lab created a learning platform about code using comics, worked with an after school program here in the Bronx in New York City. Jessica Klein and Atul Varma worked on a bunch of different features to make p5 more friendly and accessible. So these are some of the, oh, and sorry, I didn't scroll all the way down. Tiga Brain and Luisa Pereira, who worked on tutorials for p5. Tiga also did a tutorial for this channel. And these are some previous fellowships, Vilm Tobin, who worked on the processing sound library. Lauren McCarthy, who now is a core director of the Processing Foundation, the inventor of p5.js, what originally started as a fellowship. Greg Bornstein, who did a fellowship on OpenCV with processing. So these are fellowships that we've sponsored, and we now have an open call. The idea is that for you to propose a project that you want to spend about 100 hours on between February 1st and May 31st. And there is a $3,000 stipend, US dollars, but you don't have to be a US citizen. You don't have to live in New York or the United States or anywhere to apply for the fellowship. And if you are selected for the fellowship, you're assigned a mentor to work and develop this project. This is very similar to Google Summer of Code, which is a program that some of you might familiar with. The key difference between the Processing Fellowship and Google Summer of Code, however, is that community-based education, diversity, projects about bringing processing to different and diverse communities, or documentation, tutorials, these are valid processing fellowships, which is different than Google Summer of Code, which requires projects to be about writing code. So you don't have to be a professional programmer. You don't have to be an advanced programmer. You can be a beginner. You can be a teacher. If you want to write curriculum, these are types of things that are possible for the Processing Fellowship. So I just wanted to mention that if you are interested in the fellowship and have questions about it, on Twitter is twitter.com slash processing org. You can tweet at processing org. You can ask questions on the processing forum, which is forum.processing.org. And certainly, you can get in touch with me in the comments of this video. I'm having trouble keeping up with YouTube comments, but I do read them. And so that's what I just wanted to make an announcement about and plug a little bit about this fellowship program. OK, so the other thing I'll mention very briefly also, if I go to twitter.com processing org. So this is the link for the Processing Fellowships. And then also, if we do here, yes. So we have a community survey. So I would also encourage you, if you are a user or a teacher or if you're a student, a teacher, a professional, a hobbyist, if you use processing p5.js, processing.py, please fill out this survey to help us understand how people use the software and make priorities for the next year. Good question. Is I came here lately. Is it available outside the USA? So yes, the you can apply for the fellowship outside of the United States. Absolutely. There is, you know, there are no restrictions on who can apply. It is open to anyone. OK. OK. OK, so that is I wanted to mention and talk about. Can you kind of link the survey? So I'll link this. If someone in the chat is a moderator. Oh, thank you. I think Alvaro in the chat link the survey. I will try and Matiu who helps me with this, of course, will try to remember to put a link to the survey also in this video's description. OK. Thank you, everyone, for listening. And being supportive of the Processing Foundation. By the way, I have this weird idea. I shouldn't mention it. But the last week of not the last week of December, but the last week before the winter holiday, I think, which ends December 23rd, I have a fairly free week that week, not the beginning of the week, but towards the end of the week. And I had this idea that that I see that people are getting banned in the chat, but I should just like let that happen. I'm sure it distracts me a little bit too much. I had this idea of kind of doing an all day live stream. And by all day, I don't mean I mean something like starting at 10 or 11 and finishing at four or five, maybe with a little lunch break in the middle. Maybe a guest would come in and do something. I would go have some lunch. I almost think of it as like a telethon. Just like catch up on a lot of tutorials, have some fun. It's sort of like end of the year celebration of creative code stuff. And I thought it could be kind of like a telethon to raise money for the Processing Foundation, or maybe there's another cause you should consider raising money for. So anyway, I'm thinking about that. You could encourage or discourage me. I'm sure you all would. But if that happens, it would be on the 22nd or the 23rd. So keep that in mind. I would love to if you're in the Slack channel, if you're a patron in the Slack channel, you can tell me your ideas about this there. OK. OK, cool. What's Nerdfighters? I don't know what that is. But I'm definitely looking to do more collaborations and things with other folks on YouTube, especially if they don't look like me, or have different ideas and come from a different background. OK, so let's get back to that AFIN111 thing. I've got to do something programming-wise today. I want to just apologize that things have been a little light this month. I missed a week. I missed two weeks, I think. There's some of the when I didn't miss a week, I had shorter streams. And today is no exception. I hope that December and January will bring back more of a regular routine of content. And I have more ideas about that in the future. OK. OK, so let's see. I'm going to cycle the cameras again since I babbled on for way too long. And it's so quiet today here. Eerie. OK, let's do AFIN111. Hold on. Sorry, everybody. I just want to like try to, ah! I'm like so overly, neurotically, anal retentive in this. I'm like, ah! I'm like, ah! I'm like, ah! I'm like, ah! I'm like, ah! I'm like, ah! I'm like, ah! I'm like, ah! I'm like, ah! I'm like, ah! I'm like, ah! OK, let's see. I think we're good. I think we're good. OK, so now we're good. OK, so now we're good. I wish this had like a little bit of a prettier image. But what can you help? What if I do sentiment analysis images? This works for me. OK, I want to do a whole. I also want to do like a whole live stream only about emojis, which I find to be sort of like fascinating. OK, where are the barking dogs? Not today, I guess. Where's my bumper music? Can you hear that? Is it loud? Is that loud? It's so quiet for me. OK. OK, sorry, I'm paying too much attention to the chat. Wow, there are really 160 people watching? That is insane. Oh my goodness. OK, OK, here we go. I'm going to try that again. Hello, welcome to a coding challenge again. In this coding challenge, I am going to build from scratch a web application that does sentiment analysis. What is sentiment analysis? So first of all, I want to mention that the actual, oops, I'm in the wrong page. The particular technique I'm going to use is a score-based system using a list of words known as the AFIN111. So there are a lot of ways to do sentiment analysis. What I mean by sentiment analysis is here's some text, here's some information I want to determine. Is it positive? Is it negative? And I want to assign it a score. Is it a high number, meaning very positive? Is it 0, meaning completely neutral? Is it a low negative number, meaning very negative? And there are different ways you can do this. There are machine learning systems that can be trained. Here's a lot of very positive essays, and here's a lot of really negative essays. Learn about them. Here's an essay. Please give it a score. There's neural networks can do this. There's a technique known as Bayesian classification that can be trained to look, also be trained based on positive and negative text. And there's, I'm sure, a list of many other techniques here. But the technique that I want to look at in this particular video is quite a simple one, and it involves a pre-made list of words that are assigned a valence, a positivity or negativity score. And so this list is a well-known list, the AFIN111. It is the newest version with 2,477 words and phrases, and these were labeled by Fin Arup-Nielsen in 2009, 2011. So the way this works is you take a body of text, you read through it, you look for any time a word that appears on the AFIN111 list is, you look for any words that appear on that list, you look up its score, and you add all the scores together. I don't know why I felt like this video is going fine, but I just realized I don't have a marker. And I was going to, I was like, kept thinking, oh, I should just like do this on the white board. And then I realized I don't have a marker, and then I lost my train of thought. And Denmark. Oh, OK. So I'm going to do something a little weird. Mathias seems to be in the chat. I'm going to re-explain the AFIN111 thing, but I'm going to do it over by the white board. And so you're just going to have to, I think you can just cut out that quick explanation and splice in this new, better explanation with the white board, and then I'll keep going. Sorry. If it doesn't work, whatever, we'll figure it out. So what is the AFIN111 technique? The AFIN111 technique involves a pre-assigned list of words. So if I were to say like happy, this has a score of 5. Each word gets a positive or negative valence score, 5 being very positive. Sad, very negative. No rainbow. Also very positive. 5. I don't want to give rainbow the score of 4 and happy 5. And I could think of what's like, you know, turtle. Turtles are like a little bit sad. I don't know, turtles are happy. Turtle 2, right? Okay, so you get the idea. I'm not going to try to make, clearly I'm not qualified to make up a list of words and scores. So if you have this pre-made list of words, and these could be in any language, this is a particular list in the English language. And if you have thousands and thousands of them, then if you have a particular text with a lot of words in it, you could write a computer program to just look at each word and ask, is it in the list? If it's in the list, look up its score and add it to a running total. And at the end, you're going to get some value, like you might get 27. And it's going to be, that's going to be a positive. This is a positive email, a positive tweet, positive essay. Or you might get negative 31. And this is very, very negative. So you can get the total score. And you can also get what's known as the comparable score. I think that's right. Comparable score. What is that called? Okay, wait, wait, wait. What's that called? I don't want to get it wrong. Comparable. Comparable. Oh, look, I'm going to look at this. This is exactly, by the way, I've seen this web page before. This is exactly what I'm going to build. I am happy. Comparative. Why did I say? Okay, coming back to here. Okay, oh, camera's still on the whiteboard. Sorry, everybody, but that's fine. I was just looking something up. Comparative. I don't know why I said comparable. So thank you, Mattheo, for being a master editor. I would basically have to quit doing this if it wasn't for you. Okay. So this is what would be known as the total score. But you can also look at the comparative score. Just because you have a really long document with the word happy in it a lot of times, is that more positive than a short document with the word happy in it fewer times? So the comparative score would be the total score divided by the total number of words. Okay, so this is exactly what I want to implement. So let's look back here. Sorry. So the AFIN111 is a particular list of words. This was manually made by Finn Arup-Nielsen. You can imagine what kind of research and thought went into this. And I encourage you to read the paper. And also, if you use this list, you should also reference the paper. And everything is on this website, which is linked in this video's description. Okay, so what I'm going to actually do is just download it. Oh, I've already downloaded it. I did that before it started. It's like a cooking show. Here's my AFIN111 list, except this is a fan. By the way, isn't it random that I just, like, underneath this desk, I have a monitor? What else do I have? Nothing is the sad thing. Oh, watch this, though. I have another fan. It's just like, in here, I have a magical, oh, look at this. Look at this. Over here, I have a monitor. There's lots of stuff. It's like a magical bag of things that people are telling me to concentrate. I don't do a good job of that. Okay, so I've already downloaded this list. I can't pull it out, and let's go take a look at it. So where would it be? It would be in my downloads. And here it is under AFIN111. So here, I'm going to open this up, and we can take a look at this list. So you can see this has several thousand words, and you can see abandon being negative two, abandon negative two, et cetera, et cetera, et cetera, compelled one, congratulations two, et cetera. You can see here all the words and all their scores. I can scroll through the whole thing. So the first thing that I want to do in this challenge, I think, is it would be so much more convenient if this text file was actually a JSON file. So let's write a little quick program to convert it to JSON. I could do that in like Node or Python or something, but I'm going to somewhat absurdly just do this in the browser. So first, what I want to do is I need to get this list, and I need to go to my folder that has my code, and I'm going to paste it in here. So right now, I have a folder that has an HTML file. I have a libraries folder because I'm using the p5.js and the p5.dom library, and sketch.js is where I'm going to have my JavaScript code. OK, so now what I want to do is, so here's the thing. This file, which I can load up here, this is actually, I'm almost certain, is a tab delimited file, meaning each word, the format of this file is word tab score. So there's a variety of ways I could parse this, and this may not actually work, but let's test the p5.js library and see if load table works with this file. So what I'm going to do is go back to my code, and I'm going to say var table, function pre, I'm going to use preload, which is a function that I can use to make sure certain images or media or data files are loaded before the page, the sketch even begins. Load table, and then I need to give it the file name, afin111.txt, and then I'm just going to say console.log table, and let's see what happens. And this is my, so that's good. Look at this. This is very promising. You can see that a table object got loaded, and it includes an array of rows with 2,477. So frankly, there's not really a huge need to turn this into JSON, because I have it in this nice table object, which makes it very easy to parse, but let's, for lookup, when I want to look up the scores, I'm going to want it as a JavaScript object. So let's see, how do we iterate over this table? So for var i equals 0, i is less than table.getRowCount. Here's the thing. I don't know the table API off the top of my head. So let's go to p5js.org, reference, and then what I'm going to do is look for table, and we can see load table, p5 table. So let's go to p5 table, and we can see a bunch of the functions, like getRowCount. So this is something I certainly need to, that I want to iterate over all the rows. So I can say for var i equals 0, i is less than table.getRowCount, i plus plus. And then I can get each row, probably by saying, getRow i. That seems probably like it's the case. Let's say console.log row. Let's see if that works. Whoops, let me go back over here. So this looks good. Like, I'm getting a row object for every row in that table, and I probably can say var word equals table.get 0, and var score equals table.get 1. And why am I saying that? Because if this file is in a table, and each line of this text file is a row, think of it as a spreadsheet, a board is in column 0, 1 is in column 1. So this is me saying, load that text file into a table, look at every single row, get every row, and then get the stuff that's in column 0, and get the stuff that's in column 1. And by the way, I could actually label the columns with headers and use that. There's lots of fancier things you can do with tables in p5n processing, but this should do. So let's say console.log word score, and let's run this. Undefined, undefined, undefined. So get, I suppose, is not the actual function. Oh, and I said table, because I need to say row. Probably all of you are noticing this. I see in the chat that everyone noticed this like five minutes ago. So row.get, because of course what I want to do is get column 0 from that row, not from the table. Sorry about that. And then we can see, now why do I still see some undefines? Oh, look at this. It didn't split it. It wasn't able to do it by tabs. That's so sad. Load table. So this might be a p5.js bug, or I might just be wrong about how this table is formatted, or I might need to give it a file extension. Let's try that. Oh, look at that. That worked. So what I needed to do is, because it's.txt, p5 couldn't auto-detect that it was a tab-delimited file, so I'm able to give it a second argument and give it an extension, tsv, to tell it that it is a tab-separated file. If it were a comma-separated file, meaning commas in between instead of tabs, then that's what I had before. It was getting the whole thing, and then there's no second column. OK, so that fixed that. OK, so tsv. Great. So now what I want to do is I'm going to make an object called the afin, and it's an empty JavaScript object. And what I want to do is I want to say I want to put in that object the word as the key, the number as the value. Word is the key, number is the value. So I'm going to say afin word equals score. And then at the very end, I'm going to say console.log afin, and we're going to look at this, and we can see, look at that. There it is. There now is that afin list in a JavaScript object, every word with a score. And I'm kind of scrolling through it just to see if anything broke, like if there was a weird apostrophe or something that broke it, but it doesn't look like it did. And just to remind you, remember, if I have an object and I say object something.x equals 100, this is the same. My laptop's about to fall over, as saying this. So since these words are all strings, and I want those to be the keys, the properties of the objects, I need to pass them in using this bracket syntax. I can't do it like this, because it's not a variable name at this point. It's coming in as a string. OK, so now that that's done, one of the lovely things about using p5 is I can just say save afin111.json afin. And I'm saying it's with two n's, I think, right? Yeah. So now I can just save that file, save that data as a JSON file, and it should auto download that to me in the browser. So let's run it again. Ooh, file name index of. Ooh, OK. So I think maybe I'm supposed to say it the other way around. First, the data, and then the file name. That seems right. There we go. And you can see my browser. I'm standing in front of it, but my browser auto downloaded this file called afinb, because I must have put that in my code by accident. Oh, where's my code? Yeah, whoops. Two n's there, but that doesn't really matter. The point is, now I have this file, afin, and I can put that here instead of the text file. So let me rename it to fix it. So what I did just is now instead of this text file, I now converted that to a JSON file. And of course, it won't. Oh, but this is my, I can open it right through here. And we can see there it is. So this is great, because now to do the text analysis, the sentiment analysis, it's going to be so much easier if I already have this data in a JSON file. And by the way, you could probably Google afin111 JSON. Countless people all over the world and internet have done this already. But I thought it was a useful demonstration to show in p5 how to convert between one format to another. Let's do the, so all of you who were like, I wanted to watch the video about sentiment analysis. Maybe I can put a little time code in this challenge of skip ahead to the sentiment analysis part. So now we're actually ready to do the sentiment analysis. So what I'm going to do is I'm going to just actually save this as the JavaScript file. I'm going to call it convert.js. And I'm just going to get rid of everything and start over. Because I don't, what am I trying to say here? I don't need to ever do that again. I've already converted it to JSON. But it's good to save that code if you want to take a look at it. OK, so here we go. Part two. I don't know if there should be two videos. Just in case. Where's my bell? Part two of afin111 sentiment analysis. OK, here we go. So the first thing that I need to do is I want to load this file. So let's make a variable. I'm going to call it afin again. afin equals load JSON, afin111.json. And I just want to see that that worked. I'm going to say console.log afin. OK, so we're starting up. And I just want to see, great. So we can see that that list has been loaded, which is wonderful. Now, the next thing I need is I want to have a place. So let's add some stuff here. afin sentiment demo. Let's say type here. And make a text area like this. textarea id equals text textarea. OK, so now I should have on the HTML page, we should see, whoops. I definitely did something wrong. textarea textarea. There we go. OK, so we should see, oh, a global function text. Because your code has already used it. So I think it's a bad idea to, so let's call this txt. OK, so we can see here that, now, how do I, by the way, with textarea, I kind of just want it to already start as like a slightly bigger thing, which is kind of unnecessary. I'm going to say columns equals 50. So that's good. And rows equals 10. OK, so now I can, the idea here is that what I want to do is, as I type here, I am happy, how are you? What I want to do is I want to live calculate the sentiment of this text and have it appear below, as I press every single key. So first, I need to bind some sort of event. So I need an event for every time I type into this text area. So first of all, I need access to this text area in JavaScript. And I can do that with the select function. If I were jQuery, I'd use that dollar sign thing or document.getElementById with regular JavaScript. So I called id was txt. So what I need to do is say var txt equals select by the id txt. And then the event that I want to track is called an input event. There's a changed event. There's a change event and an input event. It's a little weird in the browser. The changed event is only if I hit Enter or Tab, if I finished my action. But the input event happens anytime I press a key at all. So text.input, I'm going to call this event typing. And I'm going to say now function typing. And I'm just going to say console.log txt.value. So what I want to see is, as I'm typing, I just want to see that I have access to the words that are in what I'm typing. OK, so let's refresh this and say, hello, how are you? And you can see that this is working. That as I type what I'm typing, every time I hit a key, it comes out in the console there. OK, so that's perfect. That's what I want. Now I can start to calculate the sentiment score. So what should I, how should I calculate the sentiment score? The first thing I need to do is split up the text by words. And I can use a regular expression. See my videos about regular expressions using the split function. So I'm going to say var, I'm going to say tokens, I'm going to say words. Words equals txt.split. And then I want to split by a regular expression. And a regular expression in JavaScript is a string, like a sequence of characters that goes between forward slashes rather than between quotes. And it defines a pattern in the text. And I have a whole set of videos all about regular expressions. What the pattern is, what separates the words? So whitespace, commas, periods, punctuation, whitespace, that sort of thing. Basically, I'm going to do something kind of silly and simple here. I'm going to say anything that's not a letter or number. And so there's, I can actually just say backslash w. So this is slash w is any letter or number. And backslash capital W is any non-letter, non-number. And I could also say, maybe I should say or an apostrophe. Oh no, but that's included. No, I should have let it be or not. Anyway, whatever. This will be good enough for now. You could spend your life trying to define the best regular expression for splitting, tokenizing a sentence into words or a paragraph into sentences or essay into paragraphs, all that sort of thing. OK, so I'm going to do that. And then I'm just going to see that this works. I'm going to say console.log words just to check that. Hello. Oh, txt.split is not a function. Well, of course it's not a function because txt, I can't come up with variable names. Word, text input, fine, equals txt.value. So I want to get the value. That's the contents. And then I need to split that. So it's good that I checked that. And now I'm going to say, hello, this is a test. So you can see as I type, it's splitting up into an array of words. Perfect. So now I need to iterate over that array of words. So I need to say for var i equals 0, i is less than words.length, i plus plus. Now, here's something that's important. Let's go back to our AFIN111 list. Notice something here. All of these words are entirely lowercase. There is not a single uppercase letter in this particular word list. So one thing I definitely want to do is when I'm in my code, the first thing I want to do is say word equals words index i dot to lowercase. Because when I look up to see what its score is, I need a lowercase word. So now that I've done that, then I want to say, does that word exist? So if AFIN word, does it exist? Now, I could use this has. I should probably use the has own property thing. So this is me asking, let's say the word is cat. If cat is in the AFIN word list, I'm going to get the score for cat, like 3. Maybe kitten would be like 4. I don't know. Cats and kittens, they're equal. I love it. Anyway, what am I talking about? I'm so worried about offending words with their positive negative score. It's a very strange personality I have. OK, but there was a point to what I was saying, which is that, that, ah, right. If cat exists, I'll get the score, like 4. If it doesn't, I'll get undefined, which will evaluate to false. But there's a weird sort of issue here. Like sometimes, like there might be like some built-in JavaScript properties that happen to have the same word as a word in the essay. So to be 100% sure, I can say has own property. This will evaluate to true or false if word is a particular property of this list that I've developed that's not part of the sort of JavaScript object thingy language itself, whatever. OK, so if it does, first of all, I need to say score equals 0. I can say score plus equals AFIN word. So now I can look up the score and add it. And then what I'm going to do is let's add a little area for results. I'm going to say PID equals score. And I'm going to add some things. Score, comparative, and what else? Maybe I'll do a word list just so we can see everything on the page. So OK, so I added three paragraphs because I want to report some information on the page. So the first thing I can do now in JavaScript here is say, I can say var scoreP equals select score. And then say scoreP.html is the score. This is sort of, there's better ways I could do this, but this will work just fine. Comparative, select comparative. And then the comparative is the score divided by words.length. So the score divided by the number of words in the file. And then also maybe word list, select word list, and word list HTML. Oh, I'm not saving the words. So let's make a list. So let's make a list. We'll call it scored words. And it's an empty array. And if I ever find one of those, I'm going to say scored words.push the word. Oh, and maybe colon its score, something like that. So I'm not being very thoughtful about the design of the display of the results. But comparative. OK, but let's see if this works. Hello. Uncaught reference error. Score words is not defined. Scored words, scored words. And scored words. I don't know what I'm doing here. OK, let's try this. So OK, let's try typing. I love kittens and rainbows. Also, unicorns and the color purple and pink and red and green and blue. I am happy. So, so very, very happy and joyful. So you can see, oh, a couple of things are wrong here. This is not at all correct. So what's happening here? It's getting the information from the JSON file. And it's adding those numbers together. It's saying 3 plus 3 plus 3 plus 3 equals 3, 3, 3, 3, 3. So it's not adding them as numbers. It thinks everything is a string, which is also why I'm getting some goofy results here. So one thing that I need to do here is make sure that when I get that score, I convert it to a number. So let's fix that. That score that's coming out of the word list, I need to convert it to a number. I should have just happy, sad, not so sad, but not so happy. Happy and joyful and full of scared fear for things that scream and monsters. But I like, am I still recording a video tutorial? Or did I just become hypnotized by my weird nonsensical typing? So you can see, I'm now getting, now, I'm seeing some weird stuff going on here, which might just be the fact that I'm not being very thoughtful about how I display the information. But let's do some more tests here. If I say sad, OK, that works. Score is negative 2. Oops, camera went off. If I say sad, exactly what I would expect. Let me move this over here. I got a total score of negative 2. Comparative is negative 2 because it's negative 2 divided by one word total. If I say happy, OK, so this is working. And abandoned, I remember, was in there, is negative 1. So it's just the formatting. So we're really done. I could copy and paste some text. Like, I don't know, if I go to kittens Wikipedia, let's get some text about kittens. And see what happens if I paste it in here. And we can see I got a score of 4. Comparative of 0.04. This is positive text. The words that I got were solid and enjoy. I should get a score of 6. So something is wrong here, right? What did I forget? I made a, there's a bug in my code. Score plus equals. Let's say, let's just do console.log word and score. Yeah, something's wrong with the math. What did I say? Solid 2. What was the other word? Whatever, happy. 5. Solid, ooh, wait. Solid 0, happy 2. Huh? Debugging time, hold on, hold on. Solid has a score of 2. But why is that coming out as 0? Oh, I don't have a variable. Oh, sorry. Okay, hold on. Oh, no. Did something, you know, sometimes if I have an element named with an, oh, whoops. Sorry, this is, remind me later. I don't need a software update. Sometimes if I have an element, things in JavaScript can be, happen in weird things. Like I named this variable score, and I happen to have a DOM element with an ID of score. I wonder if that's causing me a weird sort of problem. So I'm going to go here and say score p, comparative p, word list p. Word list p. And I'm going to go back to my sketch. I'm just going to see if that's an issue. Oh, I also just not, oh, I'm being score p dot, oh, no, no, score. Yeah, that's right. And comparative word list p. Let's see. Let me just make all the variables name different to overdo it. Solid, happy. Solid is two, happy is three. Why am I seeing happy five here? So this is correct. This is correct. And this is wrong. I'm a little skeptical of, oh, I put the score, once again. Once again, I'm conflating the total score and the individual word score. So I should really, if I want to be thoughtful about this, boy, I'm terrible at this sort of stuff. I should really say var score equals, I don't think it was that at all. I think it was, this was my problem all along. So I want to make sure I have a difference between the individual word score and the actual total score that I'm adding up. And so this is the total score. And this is the total score. And the things that I'm putting into the list, just add some padding here for formatting. Now, happy, sad, this is better, yes, no, no, no, no, no, no, no, no, no, no, no. OK, so there we go. You can see now I have real time sentiment analysis where I could be much, if you're watching this video, if you're going to make something with this, you could be so much more thoughtful in terms of how you display the results, whether it's color or visualization, formatting the numbers nicely, formatting the list of words in a different way. But you have the basic framework for it here. I will show you that there is a major issue with this particular approach. OK, so here's a particular issue. Here is my text that I am going to type right now. I am not sad. I am not at all unhappy. I am not feeling worse today. So you can see I've got a really, really negative score of negative 6, even though I said I'm not sad, I am not at all unhappy, I am not feeling worse today. Because this particular technique is only looking at the raw counts of words and those scores. If I wanted to be a little more thoughtful about this, I could try to add a little bit of natural language processing. For example, the JavaScript library NLP compromise that I demonstrated can look for if a statement is a negation, and you could perhaps invert the score. And then, of course, I could use a more sophisticated training methodology of actually not using a word list, but having a machine learning system learn about positive text, learn about negative text based on just word frequencies and words being next to each other and that sort of thing in a much more open-ended way. But this hopefully should get you started on something if you're interested in text analysis and how you might apply this to what type of data source and how you might show the result or how you might create an interface for people to type into and give us some information back. OK. So in the chat, Gaurav writes, you must be sad. That's why you were insisting on it very much. And you know what? I think maybe this is a smarter sentiment analysis technique than I knew, because maybe it can read in between the lines. OK. Thanks very much for watching this sentiment analysis video, and I'll see you in other videos in the future, perhaps. OK. She's doing cycle analysis, too. OK. It is now 4.30. Ah! Wow, this took me, how long was this? Did I really spend like 45 minutes on this? Wow, that's crazy if I did. OK. Let's think about what I have time for, because there isn't a ton of time left. 35 minutes. OK. Maybe that could be, maybe some of the editing, the debugging could be edited out. All right. So what do I want to look at next? Let's see if we have time to go back to the, I'm sorry, I'm just thinking here. Let's go back to the node program. Let me pull that up. So I'm going to copy this and say, oh, I'm going to copy this. So I'm going to copy this and say API 3. You know, I realize I haven't posted any of this code on GitHub in so long, but I've been, let's go make API 3. And let's go to, I will be doing tutorials about machine learning in 2017. In 2017. Maybe I'll do some on this all day adventure that I would like to do. But I'm trying to finish up this other list that I have first. So let's just say node server. Let's see what this is doing. Oops. Sorry, localhost 3000. OK, right. So now I remember that this, if you recall where I was last, is I made a simple, and let me open this one up too. Sorry. Sorry. I made a simple API that allows you to add a word with a score to a database. And so you could build, you could have a crowdsourced AFIN111 style list. And you can see this is a front end to this that shows you everything that's been in there so far. So if I were to add happy and give it a score of five, if I were to add sad and give it a score of negative three, you can see those show up. And give it a score of negative three, you can see those show up. And the API also, if I go to this particular route slash all, shows me everything that's currently in the database. It's not really a database. It's just a text file and their scores. So what I think I would like to do now is, I'm sorry, I'm reading the chat's interesting suggestions there. What I would like to do now is finally finish off this example by adding the ability to put text into a text field, post it to the API, and then get a score back. And then also combine this list with the AFIN111 list. Okay? Okay. So I'm going to do that. That'll be, unfortunately, the last thing I'm going to do today. I had ambitions of getting further. But I do really want to finish this playlist about building your own API in Node. Okay. Ah, it's 3 AM in India. I'm impressed that you're up and watching. Okay. So let me get myself organized here. As always, I always forget the this dot, this dot, this dot, this dot. I'm going to do this dot, this dot, this dot, this dot, this dot, this dot. All right. I think I'm ready. Let me cycle these cameras. And let me make sure I have my pen and eraser. Hey, somebody's in Bushwick watching. That's not too far away. I'm impressed and amazed. Okay. Here we go. So welcome to another... We started that over. My throat has really never recovered from that illness I had a month ago. Okay. Welcome to yet another... I'm losing my mind here. Welcome to another and what might possibly actually be the last video in this playlist about how to build your own API in Node. So if you remember, you might have just watched the last video, but it's been a while since I made it. So I'm going to just kind of set the stage here very, very briefly. We have so far an API made in Node that saves words and a score, a kind of positive or negative valence, the idea that we're going to do a sentiment analysis application. That stores those words over time. So I have a particular route where if I go to the server slash all, I can see all the words that are in a particular... in that database. I also made a little front end that if I add a word like kitten and I give it a score like four and I hit submit and then I can hit refresh here and we can see now kitten has now been added to that database. Now it's not actually a database. It is simply just a list, a JSON file, but the Node program is receiving the word and score from the client, saving it to the JSON file and loading again for later use. So there are two things in this video that I want to add to this particular application. Number one, I want to use... I want to add a pre-existing list of words and valence scores. And this list is known as the AFIN111. So this will just make the sentiment analysis work a little better by giving us... seeding it with a pre-existing list of words. I made a separate video where I went over this in more detail, which I'll link to in this, but this list comes from this particular website and it was developed by Finn Arup Nielsen and if you use it, you should credit it and there's links and information about how to do that here. Okay, so that exists. That's number one. I want to bring that list over. Let's actually do that first. I'll say what the number two is in a second. Number two is I want to look at a post to the API. What's the difference between get and post? That's going to be part of this video too. So I'm actually just going to absurdly just do save as and I'm going to go to my node folder and I'm going to save it as AFIN111.json and then I'm going to go to the server and we're going to look at where the server loads. Where does the server load that file? Right here. var data equals read file sync words.json. So I also want to load. AFIN, what is it for AFIN111.json into a variable called AFIN actually and I'll call this AFIN data and then I want to say var data equals json.parse AFIN data. Oh, no, so far. Sorry, var AFIN. So now my node server has both the word list that's being saved and the AFIN list. Now here's the thing. So I think what I want to do is just change this. I'm going to change this to additional. I think I'm going to keep these in separate files because this AFIN111 is never going to change and what I want to do is but I'm going to call that file additional just to just for clarification additional and what I want to do now is I'm a server. So I have them as two and I must have a save place somewhere else. So I need to change this to additional as well where I save that file because what I want to do is when it comes time to do this sentiment analysis, I need to look both in both of those. I need to look in the AFIN word list. Is it there? If not, look in the additional word list and I should decide if one overrides the other. In this case, probably the additional should override the AFIN. So I'll look in additional first. Okay, great. So actually done. We did it. Yay. But I guess I could in all. Let's look at that all route again. Let's here. Let's actually do something kind of a little goofy. I'm going to do I'm going to say the data is additional is a words and AFIN is the AFIN list. So then so I'm changing the server when you ask for all to not just give you the words that are in the database, but look at both of them. So this is just changing the response of the server. And what I'm going to do here, if you go here now, I have to restart the server. Where? Oops, sorry, everybody. I'm going to restart the server and I'm going to do this. And we can see now I have both the additional list and the AFIN list. Wonderful. Okay, so now and but this probably broke this part because the way I was parsing, I was using that all route. But you know what? I'm going to get rid of this drawing thing. It's sort of unnecessary right now. I just want to have this word score interface. So let's go back to the client, which is here. And let's get rid of the draw data thing, which we don't need to do anymore because we're going to do some different stuff here. So I just want to see that this I don't need draw data anymore. I want to see that this works. So I want to see what's another word that I could add. Puppy and three hit submit. And we can see that that worked. Success. Although I probably again should add something to this page that says, thank you, I added that word to the list. That's a great exercise for you. But we can just confirm now that if I go back to here under additional, puppy is there. Okay, so everything is working. But my API behind the scenes has access to both the full afin list and any additional words that have been added. Notice how things are a little bit different here. I probably should have been more thoughtful about fixing this up so that these are actually numbers and not strings. But I can deal with that later. So okay, now the thing we need to change now is how do we send a large body of text from the client to the server. And so I'm going to come over here for a second to oh boy, this camera is off. I'm going to come to the void. And I want to talk about the difference between a get and a post. So HTTP, which stands for Hyper Text Transfer Protocol. I don't know if that's right. It's probably right. There is a request and response protocol. Hi, I'm a web browser. Could I please, I'm making a request, have some information about where I could get some nice apples this time of year? And maybe I would ask that to Google. And Google being the server would say, hey, here's a response. Here's some information. And the way that I can talk to that server in this request and response protocol, if we have server and we have client, is I can make a get request, which is like, could you please give me some information back? Or I could make a post request, which is, would you please take this information and save it onto your server or do something with it? So if I'm logging in with my username and password, that would be something I would want to send with a post request. If I want the results of a search, I might ask, use a get request to get the results back. Here's the thing. Even if, even though this is how this protocol is designed and how it works, you'll notice something in our program a little bit strange. So if I go back to the code for a second and I look in the server, I can say, well, where are these happening? This is a get, oh, I'm in the wrong place. If I go, we do that again. If I go back to the code for a second, you might ask, where are these happening? Well, right here, when I set up a route, I'm actually saying, this is handling a get request. If the browser asks with a get request for slash all, send this information back as the response. Information that comes with the request is in this variable. Stuff that I want to do to respond is in this variable. This is a get request, and it makes sense. I would like all of the data in the database, please. Could I please have that? Thank you. I really wish it was this, get please. But it's just get. I guess there's no need for politeness between computers. Kindness, there's something that needs to be said for kindness between computers, though, and people. Anyway, I'm off track here. But you'll notice something. This is also a get request. Get add word score. Get add word score. Now, it makes sense that you would have parameters for a get request like search. So this is a get request. Search. Do you have the word kitten in your database? If so, could you please tell me its score? That's what's happening here. But in this particular route, this is a get request. And my get request is saying, here are this word and this score. Will you please add those to your database? And according to my discussion over here, that should really be a post, right? If you're sending data to the server for the server to save, that's really a post and not a get. The thing is, though, it's just so darn convenient to use a get. Why is it so convenient? Because that's what the browser does natively on its own. I can actually now send. I can actually just make a get request by saying localhost 3000 add yellow, which is maybe a neutral color or slightly positive. So this is me now making a get request. That get request is done. It saved it to the database. I can use the fact that I can add parameters to a get request through the route or a query string. There are lots of ways to do it to actually have the server save, to send stuff to the server for it to do stuff with as well. And because it's just like a little bit of data, it's just so easy to do it in the route with a get request. Why not? But there are times where this get request isn't sufficient. And you really need to use a post. Well, one is like username and password. So if security matters, you don't want to have the username and password just in the URL path as part of a get request that anybody could potentially hack and get access to. So this is really where for hidden data, it really needs to be a post. The other thing is like media. If you want to upload an image to a server or upload a sound file, you can't do that through a get request. You can't easily, although there's some tricky ways. You could base 64 encode your image into a number string that goes into the URL. But basically, for media, but really what I mean in a lot of ways is large data. So if I want to send a full paragraph to be our full many paragraphs, a thousand words to be analyzed and have the server send me a result back, I want to send that data through a post rather than a get. Because it's going to be much too awkward to try to encode a full paragraph of text into some sort of route or URL query string. So this is really the difference between get and post. Post is for sending data. It happens behind the scenes in an invisible way. Get is for making a request and it happens right in a visible way because it's really basically the same as what you would be doing to type in a URL into the address bar. Okay, so now that we've covered that, how do I... There's two things I need to figure out. One is how do I handle a post in the server? The nice thing is you could imagine that it might be something like this, app.post, analyze, analyze, and analyze this, right? So this is now, I'm going to write and I have a function to handle that post request. So this is now how instead of a get request in a node program, I can handle a post by saying app.post, analyze this. And then what's the other part? How do I make a post request? Well, there are countless ways you could do it because you could look at jQuery and you could look at native JavaScript and you could look at any JavaScript framework you want. In p5, there's a very nice lovely little function called HTTP post. And so I'm going to add something. What I'm going to do is in the... Here, I'm going to add a text area. So I'm going to say, I'm going to make another paragraph. And I'm going to say text area id equals text input. Text area. Text area. Let's just do columns equals 40 and rows equals 5. And so if I go now to here, we should see there's a text area there. So what I want to do is when I add another submit button, I'll call it analyze. So now I have an analyze button. What I want is when I analyze this button to make a post request to the server, so what I need to do is I need to also in JavaScript get access to the analyze button. Button A for analyze and analyze. And analyze this, I'll say. Function analyze this. And here what I want to do is get the text, which is the... I can select the text input area and say dot value. And then I want to make a post. And the way I make a post is with the p5 function HTTP post. So when I wanted to make a get request, load JSON was all I needed to do. Because load JSON by default is a get request, just like load image or load... Any of the load functions. There is, by the way, an HTTP get method, which allows you to have more control over that get request. But here I just want to make a post. So, OK. So I'm going to do p5.js reference. And I'm going to look at HTTP post. And let's look at this page. The difference is... and boy, does this look confusing. The difference is when I make a post, I need to send it a whole object, which is all the data that I want included as part of the post. So this allows for a lot of possibilities, because I can have multiple fields and I have multiple kinds of data. So really, there's a bunch of stuff I need here. But what I care about most right now is the... I need to give it the path, which is the route, the data that I want to send, I guess what kind of data it is, which I'm going to make it JSON-based data, and then a callback for when it's finished. So let's do all of that. And I'm going to say... where was that? HTTP post. So first, I need to say data is the text. Is the text. And that's actually all I need to post is just what's in there. But I could add a lot more things into this object. And I want to go to slash analyze. Is that how I did it in the load JSON? Add. I don't need the slash in front. Sorry. Analyze. And then I need to say it's going to be JSON. And then I need to say data posted. And then I could also say data error. But let's skip the error right now. I should actually probably data post error. So let's write those functions. Function data posted. Result. I'm going to say console.log result. And in the server now... So now I've posted this data to the server. And again, this could be a lot more stuff than just that text. And in this function... And post, I should have a callback for error. And so now I just want to look at what comes back after it's posted. Okay. So now in the server, I'm just going to say response.send thank you. And actually, let's make this a reply message. Thank you. And send that reply. And let's just look at console.log request. So we're going to figure out how do we get the stuff that was posted right here in the request. Okay. Here we go. So let's see how far did we get here. First, I need to restart the server. And I want to go to this page here. The... Here. Which I should see this. I want to look at the console. And now if I... This is a test. And I hit analyze. I got the message back. So the round trip happened. The question now is let's look at what's in the request. Oh my goodness. How am I ever going to look through all this and find the data that was posted? So here's the thing. Pause. Time out. Oh, by... So if somebody in the chat, by the way... So this part's going to have to get edited out. Thank you, Matia. Somebody in the chat says I keep changing my localhost port. So I'm using a different port for the node stuff as when I run like a Python server. But yes, I do keep changing that. So I need to look something up because I forgot what it is. And I just want to not look it up in the video tutorial. I want to act like I know what I'm doing. Because I particularly do not. And I'm going to go to node API. Maybe this one's actually going to have a simpler one. No, this one won't have the post. This is an example. Oh, this is a totally different one that I made. Oh, yeah. So I need this. I need the body parser package. So let's look for that body parser node package. And I just want to look it up on GitHub. Because let's see if there is a very simple example. Oh, why isn't there like a... There we go. So I'm just looking at this. So this is the example. And then in my example, is that the same body parser.json? Yes. And app.usebodyparser, URL encoded, extended true. Extended false. Whatever. And then what I did is... I know you probably can't see it. But I'm just going to do a little bit of a... Is... I know you probably can't see this. I'm just looking this up. Request.body.text. Okay. So that should do it. Okay. Okay. So I am good here. Okay. So where was I? Ah, yes. Okay. Yeah. How do I find that text? This is a mess of data that comes in with the request. Now we know if you go back to the server when I had a get request. I can simply just look at the request's parameters. Because these are the parameters that come in with the request with a get. With a post request, it's not so simple. There isn't just the parameters. There's this part of it called the body which has all this information in it. And I actually... And I have to parse it. Luckily for us, there's a node package which will do this parsing for us. And this parsing... This package is called body parser. So what I need to do is I need to install that package. Body parser. And I want to save that as part of this project. So I'm saving it. Now I have the body parser package. And then what I want to do... I'll include a link in this video's description. But I'm on the GitHub repository. I just want to look at... I need to require it. So I need to add it to my code at the top. Or it doesn't really... I'm going to add it here where I require express. And then after I create the app, this is serving static files. I now want to use this body parser package. So I'm going to just scroll all the way down here on this documentation page where I know there's a quick example. And I can grab this code. And I can add it in. So I now am telling this app, this web application, which is an express application that's listening on this port, which uses static hosting for the stuff in the website folder, now also has the body parser. And I want to use JSON because I want to get the stuff... I want to parse everything as JSON. Okay. So now that I have that, I should be able to say... Oh boy, do I hope that that's true. In the post, where I'm handling the post, I've already lost it right here. Let's say console.log request.body. And so I'm going to restart the server. Whoops. And I'm going to refresh this page. I'm going to say this is a test. I'm going to hit analyze. I got the message back. And oops. I got an empty object. But I think maybe just the console isn't logging it properly. And so at some point, I want to show other ways of debugging and know where you can get a nice JavaScript console. But I'll have to do that in another video. Let's look if I can say... Where am I here? Body. And what... In Sketch.js, boy, this is getting complicated. I sent it as data with a text property. So I should be able to say body.text. And I should see what was sent. So let me try doing this one more time and hitting refresh. And this is a test. And I look in here. Undefined. Time out. I'm going to have to debug this. I forgot what I did wrong. OK. Let's see here. What did I do wrong? Let's look at my existing example. Do I need this? No, no. Use function. OK. Let me see if there was something I missed in my other example. Oh, boy. It's already 5 o'clock. Wow. This stuff always takes twice as long, if not four times as long as I think. But I'm close to the end of this. I made an example that does this. Let's look. Oh, and I want to mention cores. I mean, could extended true matter? I don't think so. Let's just let me grab this. Let me just make sure. This is the same, really. OK. So this is what I have. And then when I handle the post, analyze, analyze, request, response, request body text. This looks the same, right? All right. I'm going to have to look at the client, obviously, to see if that's where it's different. And let's also go to the client. Somebody, I don't know if anybody in the chat, I'm going to go to the client. The data is not in the post request. Oh, I forgot to put data. I forgot to post the data. I bet you that's it. How many subscribers have I lost during the course of this making of this video? The test, analyze, thank you. And there we go. OK. Thank you to David in the chat who helped me solve this problem. Hopefully, I would have noticed it eventually. But I just completely forgot this. I need to take this out. I need to back up to here. This is the same. I just had this as false. I don't think that matters. Let me go down to here. And let me go to back to here, console.log. Console.log, where, where, where, where, where, where, where, where, where, where, where, where, when it's finished or if there's an error. What's missing? I just listed five things. I forgot to actually send the data. Data goes here. So I forgot to post the data. So there's no way for me to read or receive the data if I didn't post it. So that's done now. And I think it's going to work. So let me, oh, I actually don't have to restart the server because I just changed the client code. And you know what? This is driving me crazy. I just want to in the client, I just want to say, just add something here like, I am happy today because I saw a rainbow and some kittens. OK, so now I have some text pre-filled in. I can hit analyze. I got a message saying thank you. And I can go look at the server. And I can see that that data came into the server via the post. We have a post. We have a post working. That is awesome. OK, so now all I need to do is do sentiment analysis. I really should just give this to you as an exercise and end this video now. But I'm going to finish it up myself. So the nice thing is this isn't too hard for me to do now in the server. I'm going to go to the server code. And right here, instead of console logging, I want to look at and say var text equals request.body text. Then I want to split it up, text.split. And I'm going to use just a regular expression here to split it up into words by anything that's not a letter or number. I explain this in so many videos. But this is pattern matching. And backslash capital W is anything that's not a to z or 0 through 9. And so now I can loop through those words. And I can say now, what I want to do is I want to first look. I need a total score. So I'm going to have a total score started at 0. I need to say if the what's it called additional pause. My two word lists are called words. My two word lists are called words and aphn. So what I want to do here is do if words. Oh, boy. I should call this. I need to call this additional. So because that's going to be a problem. Let's look everywhere I use words because additional, additional, additional. Oh, boy. Additional. OK, I just don't want to confuse my variable names. So here I should just call that tokens that I wouldn't have that problem. But if additional has own property. And I want to see if word equals words index I has own property word. Then total score plus equal additional. That word the value and a number I'm doing this kind of fast. I should reference you. I did this exact sentiment analysis entirely in a separate coding of a challenge, which I went through in a little more detail. So I can check if it's there. If it's not there. Then I should also check. If it is in the a list. And if it's in either one of those, I also let's get make a word list. We'll just make it a word list. So we'll actually make it a word list. Sure, an array. I could say in either of these cases. Word list dot push. An object that has word. Word score. And then and the score is var. The score is. I can say var score if it's in additional. Oh, yeah. Score equals number additional. And then add that. This is not interesting to watch anymore. And otherwise, if it's in a fin. That's the score. And. And then sorry. If I and so. Number. OK, so I'm just cleaning this up because now I can say total score plus equal. A plus equal the score. So the score can start for every word can be assumed to be zero. And if it's in additional, add the score. You know, actually, so I don't need this here anymore. Get the score from additional. If it's in a fin, get the score from a fin. And now what I could do, let's just get this working. I could say reply is score. Total score. And comparative. Comparative. Comparative. Comparative in the Afin111 sentiment analysis, the comparative value is the total score. Divided by how many words are in the text words dot length. So now we should see that I'm getting the text. So my server is now receiving the text as the post request. Chopping up into words, looking at every single word, seeing if it's in one of the lists, and then spitting back. So let's run this. Oh, I need to restart the server. I have an error. Words is not defined where in line number six, which is here. I don't actually need this console log was just for debugging earlier. So let's run the server again. So let's run the server again. Refresh and hit analyze. And we got an error. False. I got some error. So what happened? Let's look at the console. Oh, yeah, I got an error. Comp is not defined. So I made a mistake because I'm trying to do this so quickly, and I'm not being careful. And where is where I have lost where the code this is. Oh, comp. Oh, wait, comp. And then this could be comparative. I'm just not naming things carefully. So this is the reply that I want to send back. Oops, I have to restart the server. There we go. And look at this. Every time I analyze, I get both the comparative score and the score. Now, I really want to also send back a list of words. And I want this to be an exercise. I'm going to do it anyway, because I want to see it here. So what I'm going to do is I am going to also say I'm going to make a variable called found. Just add into an I'm going to make an array of objects with word, word, score, score, which is a little awkward. But now what I can do is I can also send back the list of words. So I'm just saving every word and its score if it was found in one of those lists. Because now if I run this again, and it hits analyze array zero. So I did something wrong. Let's look at this again. Found is false. Now, if found word list dot push. Dot push. So why would the list have nothing in it? Edit this part out. La la la la la. I'm thinking, thinking, thinking. Word list push. Right. I made a word list with an empty. And then I say if it's in there, found. If it's in there, found. If found. Push it in the list. All right, well, let's. Oh, whoa. The word list has to be out here. I initialized the array. Oh, I reinitialized the array in there. Wait, hold on. Whoops. I initialized the array in the loop, which means I kept clearing it out. So of course, there's nothing in the array. Let me take that out there. Run this again. Refresh. Analyze. And now we can see. This is what it got. This is the comparative. This is very small for you to read. Whoops. You can see here that this is the comparative. That's the score. And this is the list. Happy and rainbow. So what I could say is, why didn't it get kittens? So what I would like to do is add kittens. And kittens should have a score of four. So I'm now going to hit submit. And now when I analyze it again. Whoops. We can see that I got a. I got a score of 14. And let's say today is really positive with a number 100. I can add that to the database and analyze again. And now I have a score of 114. So now I have both. And on one page, I have both a system. Wow, we've really finished this example. Where I can submit to the database using a get request. I can post to have text analyzed. I can submit to the API with a post. And I can get back the results. Now here's the thing. As a challenge, as an exercise, take this exact code. And really work on the interaction here. And how this works. How could you actually effectively crowd source a full word list? How could you use an animation? Or use design to show the results in the word list? You could click on them. And what if it showed you all the words here? And the ones that are missing. And it let you type them in and hit submit. So you could kind of like. How could you train this to have a larger database of words? For more sophisticated sentiment analysis? I think this would be a challenge for you to take this and take it further. But this is a fully functioning API. There's one piece of this that I think I should mention. This API can be accessed by my. So the server, the Node server, the thing running right here. Can be accessed by this web page. Because this web page is hosted on this server. But what if you wanted to make a sentiment analysis API. That is running somewhere. But anybody could access it from their own web pages. And their own programming without being the programmer of the server. Well to do that. What you want to do is open up on your server. Something called cross origin resource sharing. You want to say. I want other people to be allowed to send get requests. Or post requests to this server. Not just me the programmer of the server. Who also is hosting like HTML files packaged with it. And to do that you need to enable cores. Which stands for cross origin resource sharing. You've probably encountered the flip side of this error. Anytime you've tried to request something from a server. You've got this XML request. HTML not allowed. Cross origin resource not enabled. So if I want to enable cores. I can search for cores node package express. This is something I can enable with express. And I can actually just install this cores package. And I can say npm install cores dash dash save. Now I've installed that. Node package. And I can go here. And I can just grab app dot use. Oh I can say cores require cores. Right up here. The same place that I used body parser. Var cores equals require cores. And app use body parser. App use etc. And app use cores. So now I now have enabled cores. So if I put this. If I deploy this to Heroku or Digital Ocean. Or whatever web server hosting environment. Wherever my server is. Now if I handed out the IP address or the URL. Other people could call load JSON. Or HTTP post from their own p5.js code. Running on their computer to your particular server. Let's just run this again to make sure I don't see. I won't be able to see this. Because I'm still. But hopefully this all still works. And I can run this. And I can analyze. And I've got that score. And by the way I should fix today. Let's give today a score of zero. Override that back. Hit analyze. Oops. Why didn't that work? Pause. Does it not override today? It still has a hundred. It should override it right? If it's already in there. I don't know why I attempted to do something. In this last minute of this video. I was done. Oh score is required. Oh. Whoops. What did I mess up? Sorry something got broken. I'm debugging. I'm debugging. Submit word. Word. Score. Oh I'm probably. Once again I have this score variable. Too many different places thing probably. Score input. Let's just change that. I bet. Let's see if that's the problem. Add word. Plus score. Let's try that again. Oh I wonder if you send it zero. You can't give it a score of. Oh you can't give it a score of zero. Because zero must be like false or something. Oh yeah zero is evaluated as false. Oh that's just a little like. Mistake that I have in mind. Now that I gave it. I don't know what this. Cut this part out. I don't know why I was just like fixing that. Where was I in this video? Cut cut back or rewind rewind. Let me finish this video off. I don't know it'll cut it out. I don't know why I was just like fixing that. I don't know it'll cut at some point. I just wanted to like make sure it was still working. It's still working but I'll fix that. Let me actually fix that. Let me show you what I mean in case you're wondering. This doesn't need to make it into the actual like published version. The edited version of this tutorial. But if I go to the get request for. Add I have this. I'm doing so much scrolling it's crazy. What I'm doing is I'm saying if there is no score. Score is required but if the score is zero that'll evaluate. So I want to say if. If score. Does not does not equal zero. If score. If no score. And score does not equal zero. And score does not equal zero. So this is me just checking like I mean I could also say if score equals undefined. Because I think that's what it would be. But I could just sort of say here let me just double check. And make sure that like. I want this is for things that are invalid. And I want zero to be valid. So it's only invalid if it's like something like null or undefined or hello. Some text but not zero. So I mean I need better error checking here. But let me just see that that works. Uh and then today zero. So it had a sign so that fixed it. Okay so um I don't know where I was. I was checking to make sure this works. So and then but I'm just going to like finish off this video. I'll just say some wrap-up words. So this concludes my series about how to build an API from scratch. Using node and a front end to that API using p5.js. Hopefully you found this useful. If you make an API. If you build something. Share it with me. Ask in the comments. Like share this video. I guess those are the things I'm supposed to say. And I look forward to seeing you. I'll do some follow-up videos as part of this playlist. If there are some good questions or other features that I think of adding. Okay see you soon. Goodbye. Yes lordius I could say score does not equal undefined. All right so um thank you everybody for watching today. It is 520. Oh my goodness this has been a. Weirdly. The live stream since it's only been going for 10 minutes. Does it like stop and restart. I don't know why it's saying that. But this has been two hours. Hopefully the live stream archive is okay. But I've been recording this. I lost when did I lose all those viewers. There was some point where I went from 112 to 88. I have this like graph. You guys can't see this. I should show this to you. This graph of viewers. What I was doing a little after five where I lost everybody. Oh it restarted a few times. I wonder why it did that because it didn't on my end. So I hopefully it didn't. I don't know if it's chopped it up into multiple videos. But we'll have to fix that later. I had 200 at one time. That's crazy. But I can understand why not everybody wanted to watch it this whole time. So thank you guys for tuning in. I definitely have to go. But I will stay here for five minutes to see if there are any last questions in the chat. Next week I will be back. And the things that I have not gotten to are how to build a Chrome extension. That's going to be a full set of tutorials. Maybe I'll do that next week. I wanted to do videos on using Shih Tzu which is an API for basically turn a Google sheet into an API which is very useful as well as Firebase. So I wanted to look at oh did I win the Hamilton lottery. Thank you guys. Thank you for asking. Let me check. Because you know you have to claim the tickets by like oh shoot I think I already missed claiming the tickets. I think you have to do it within an hour. I really hope I didn't win. Boy wouldn't that be crazy if I won. Hamilton lottery. Hamilton lottery. Unfortunately you were not selected. So not to worry. I didn't win. But maybe next time. OK. When did I start. Oh when did I start programming and are using. You know what I forgot something. So this is great because this question is being asked. I always forget to mention this and it came up in a discussion on Facebook recently which is that so some people sometimes ask where I first discovered processing and how I got involved with it. And I was a student at ITP between 2001 and 2003. And at the time I was programming in director. A Macromedia director. I was programming in Java just plain old Java and I was programming C++ plain old C++. Open Framework, Cinder. None of these things existed. Processing did exist but I was not aware of it. And the first person to run a processing workshop at ITP and this is actually still online. JT Nimoy processing workshop. Notes from this workshop. It's really terrific. If I can find it. How come I can't find it right now. Fail. Processing workshop. Let's put in ITP. Let's just put in Nimoy. There we go. Here it is. So this is. So this is a tutorial from I believe 2003. Can read it for my first year of ITP that I love social engineering to bring open source culture to attention. I taught early releases of processing to students and faculty and current faculty who were students then myself included. And chose to use processing to create a number of projects. Processing we actually had two fives in the name then because of the URL processing was not available. And so this workshop which you can see here. And then by the fall semester 2004 processing was adopted into the introduction to computational media. Course series as a primary teaching tool. So if you're interested a little history the original date of this was Saturday February 8th 2003. And you can look at the tutorial is both in English and was also translated in Japanese. And you can find this tutorial and you can see what's interesting about this is to see it's comparing it to flash. And I remember looking at this tutorial and being fascinated and amazed by it. And this I think is really an inspiration to a lot of people. I think is really an inspiration to a lot of the stuff that I did with teaching and processing right time and motion here. So I encourage you to check this out. Also at the time Amit Pataru was teaching a class called code and me. I wonder if there's any documentation of this online archives code and me. So anyway if somebody if you know little if somebody wants to try to do some internet research and can find can find the code and me Amit's syllabus. See if you can find it. There's Amit on Twitter and I believe JT Nimoy on Twitter is at JT Nimoy as well. And JT has done all sorts of amazing stuff a lot of graphics for Tron and I encourage you to check out the work of JT Nimoy as well. Okay so I wanted to bring that up because it's come up and I didn't pause the song. So let's see. Oh can you give some more info about the application process for the processing fellowship. Yes. You pause. Processing foundation fellowships. So this is the application process. The deadline is December 19th. So you have several weeks still there. I would read through this whole page and then I would look at what the fellowships were from last year. And to apply there's a Google form and the Google form will talk will go through you need to write a description of the project you need to write up a plan for the project and schedule for it. And the other thing maybe it's on the it's the link is maybe is on the application submission form. But what I'm looking for which I'm looking for here something that's important I'm not seeing it just scanning through very quickly. A project ideas ideas. Ah. So this link here applicants are encouraged to familiarize themselves with the list of fellowship ideas. This is another page which has some more ideas about the kinds of things that we're thinking about. You do not need to propose something on this list. But if you're trying to brainstorm or think about what's possible I would encourage you to check out this list as well. And I'll make sure to include links to the application the fellowship page the application and this GitHub page in this archives description. The live stream is over unfortunately it has been going for two hours and 10 minutes and I I'm actually going to tonight if you're in New York City I encourage you to at one of the fellows from last year's Tiga Brain who did a guest. ICP learn to teach. This event I want to get to it starts at 630. I have a bunch of things to do beforehand. I really have to go learning to teach is a event here in New York City co-organized by the Processing Foundation and Tiga Brain will be presenting there along with DeAngela Duff who is also amazing I should have her as a guest and Ankit Patel who works for the Department of Education. BBQ Dave Sheinkopf about education and creative coding. OK. All right. So I really have got to go. I thank you all so much for tuning in for watching for being supportive. I feel like today was kind of a mess but I often feel that way and then people seem to think it was fine anyway. And so out of this I think we'll really only come maybe there's a maybe those should be separated into more than two videos. We'll think about that but certainly there's the sentiment house coding challenge and the sentiment analysis node API video and next week I'll be back with hopefully Chrome extensions or more about a data persistence. OK. And I'll see you guys in the future. Stay in touch next week. I don't know when I don't know if I'll have a live stream next week just yet. Stay tuned to Twitter. I forgot to announce this on Twitter today. Still had 200 viewers which is kind of amazing and I'll see you all soon. Thank you all. I'll play the this song as I turn things off. I always forget to this. This. This. This. I'm going to do this. This. I'm going to do this. This. This. This. I'm going to do this. This. I'm going to flip a blank screen but you'll be able to listen to the rest of the song. You can't hear the song on that blank screen because I don't have the audio typed into that. Wire cast. I'll just stand here. Like. While I look and check out my email. I see all the messages. When the song is over I say goodbye. This dot, this dot, this dot, never forget the this dot. I'm gonna do the this dot, this dot, this dot, this dot, the this dot song, never forget the this dot. Somebody compose that song for me. Thanks for watching everybody, see you later.",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:49:56.015782Z",
  "started_at": "2023-09-26T21:51:52.314891Z",
  "completed_at": "2023-09-26T22:19:01.477164Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=lCzB9V9L8d0",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 1629.162273
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/jasiy2bbpyhwtnuse2du3ody4m/cancel",
    "get": "https://api.replicate.com/v1/predictions/jasiy2bbpyhwtnuse2du3ody4m"
  }
}